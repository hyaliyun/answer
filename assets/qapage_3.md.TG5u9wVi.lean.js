import{_ as d,o as a,c as o,a as e,t as s,C as p,F as l,p as g,e as y,f as w,q as b}from"./chunks/framework.DulMeQy4.js";const v={name:"PoemCard",props:{poem:{type:Object,required:!0}}},k={class:"card"},T={class:"question"},S={class:"answer"};function A(h,t,n,c,u,i){return a(),o("div",k,[e("div",T,s(n.poem.input),1),t[0]||(t[0]=e("div",{class:"separator"},null,-1)),e("div",S,s(n.poem.output)+"🚨"+s(n.poem.context),1)])}const C=d(v,[["render",A],["__scopeId","data-v-8816449c"]]),M=JSON.parse(`[{"output":"Ipoh"},{"output":"Petaling Jaya\\"","context":"What are the main ethnic groups in malaysia?"},{"output":"a hypothesis that there exists a subset of children with rapid onset of obsessive-compulsive disorder (OCD) or tic disorders and these symptoms are caused by group A beta-hemolytic streptococcal (GABHS) infections","context":"\\r\\n\\r\\nPediatric autoimmune neuropsychiatric disorders associated with streptococcal infections (PANDAS) is a hypothesis that there exists a subset of children with rapid onset of obsessive-compulsive disorder (OCD) or tic disorders and these symptoms are caused by group A beta-hemolytic streptococcal (GABHS) infections.[1] The proposed link between infection and these disorders is that an initial autoimmune reaction to a GABHS infection produces antibodies that interfere with basal ganglia function, causing symptom exacerbations. It has been proposed that this autoimmune response can result in a broad range of neuropsychiatric symptoms.[2][3]\\r\\n\\r\\nThe PANDAS hypothesis was based on observations in clinical case studies  at the US National Institutes of Health and in subsequent clinical trials where children appeared to have dramatic and sudden OCD exacerbations and tic disorders following infections.[4]   There is supportive evidence for the link between streptococcus infection and onset in some cases of OCD and tics, but proof of causality has remained elusive.[5][6][7] The PANDAS hypothesis is controversial; whether it is a distinct entity differing from other cases of Tourette syndrome (TS)/OCD is debated.[3][8][9][10][11]\\r\\n\\r\\nIn addition to an OCD or tic disorder diagnosis, children may have other symptoms associated with exacerbations such as emotional lability, enuresis, anxiety, and deterioration in handwriting.[1] In the PANDAS model, this abrupt onset is thought to be preceded by a strep throat infection. As the clinical spectrum of PANDAS appears to resemble that of Tourette's syndrome, some researchers hypothesized that PANDAS and Tourette's may be associated; this idea is controversial and a focus for current research.[3][8][9][10][11]\\r\\n\\r\\nThe PANDAS diagnosis and the hypothesis that symptoms in this subgroup of patients are caused by infection are controversial.[1][3][9][12][13][14]\\r\\n\\r\\nWhether the group of patients diagnosed with PANDAS have developed tics and OCD through a different mechanism (pathophysiology) than seen in other people diagnosed with Tourette syndrome is unclear.[10][11][12][15]  Researchers are pursuing the hypothesis that the mechanism is similar to that of rheumatic fever, an autoimmune disorder triggered by streptococcal infections, where antibodies attack the brain and cause neuropsychiatric conditions.[1]\\r\\n\\r\\nThe molecular mimicry hypothesis is a proposed mechanism for PANDAS:[16] this hypothesis is that antigens on the cell wall of the streptococcal bacteria are similar in some way to the proteins of the heart valve, joints, or brain. Because the antibodies set off an immune reaction which damages those tissues, the child with rheumatic fever can get heart disease (especially mitral valve regurgitation), arthritis, and/or abnormal movements known as Sydenham's chorea or \\"St. Vitus' Dance\\".[17]  In a typical bacterial infection, the body produces antibodies against the invading bacteria, and the antibodies help eliminate the bacteria from the body. In some rheumatic fever patients, autoantibodies may attack heart tissue, leading to carditis, or cross-react with joints, leading to arthritis.[16]  In PANDAS, it is believed that tics and OCD are produced in a similar manner. One part of the brain that may be affected in PANDAS is the basal ganglia, which is believed to be responsible for movement and behavior. It is thought that similar to Sydenham's chorea, the antibodies cross-react with neuronal brain tissue in the basal ganglia to cause the tics and OCD that characterize PANDAS.[1][18] Studies neither disprove nor support this hypothesis: the strongest supportive evidence comes from a controlled study of 144 children (Mell et al, 2005), but prospective longitudinal studies have not produced conclusive results.[12]\\r\\n\\r\\nAccording to Lombroso and Scahill, 2008, \\"(f)ive diagnostic criteria were proposed for PANDAS: (1) the presence of a tic disorder and/or OCD consistent with DSM-IV; (2) prepubertal onset of neuropsychiatric symptoms; (3) a history of a sudden onset of symptoms and/or an episodic course with abrupt symptom exacerbation interspersed with periods of partial or complete remission; (4) evidence of a temporal association between onset or exacerbation of symptoms and a prior streptococcal infection; and (5)  adventitious movements (e.g., motoric hyperactivity and choreiform movements) during symptom exacerbation\\".[16] The children, originally described by Swedo et al in 1998, usually have dramatic, \\"overnight\\" onset of symptoms, including motor or vocal tics, obsessions, and/or compulsions.[19] Some studies have supported acute exacerbations associated with streptococcal infections among clinically defined PANDAS subjects (Murphy and Pichichero, 2002; Giulino et al, 2002); others have not (Luo et al, 2004; Perrin et al, 2004).[1]\\r\\n\\r\\nConcerns have been raised that PANDAS may be overdiagnosed, as a significant number of patients diagnosed with PANDAS by community physicians did not meet the criteria when examined by specialists, suggesting the PANDAS diagnosis is conferred by community physicians without conclusive evidence.[12][20]\\r\\n\\r\\nPANDAS is hypothesized to be an autoimmune disorder that results in a variable combination of tics, obsessions, compulsions, and other symptoms that may be severe enough to qualify for diagnoses such as chronic tic disorder, OCD, and Tourette syndrome (TS or TD). The cause is thought to be akin to that of Sydenham's chorea, which is known to result from childhood Group A streptococcal (GAS) infection leading to the autoimmune disorder acute rheumatic fever of which Sydenham's is one manifestation. Like Sydenham's, PANDAS is thought to involve autoimmunity to the brain's basal ganglia. Unlike Sydenham's, PANDAS is not associated with other manifestations of acute rheumatic fever, such as inflammation of the heart.[4]\\r\\nPichechero notes that PANDAS has not been validated as a disease classification, for several reasons. Its proposed age of onset and clinical features reflect a particular group of patients chosen for research studies, with no systematic studies of the possible relationship of GAS to other neurologic symptoms. There is controversy over whether its symptom of choreiform movements is distinct from the similar movements of Sydenham's. It is not known whether the pattern of abrupt onset is specific to PANDAS. Finally, there is controversy over whether there is a temporal relationship between GAS infections and PANDAS symptoms.[4]\\r\\n\\r\\nTo establish that a disorder is an autoimmune disorder, Witebsky criteria require \\r\\n\\r\\nIn addition, to show that a microorganism causes the disorder, the Koch postulates would require one show that the organism is present in all cases of the disorder, that the organism can be extracted from those with the disorder and be cultured, that transferring the organism into healthy subjects causes the disorder, and the organism can be reisolated from the infected party.[21] Giovanonni notes that the Koch postulates cannot be used in the case of postinfection disorders (such as PANDAS and SC) because the organism may no longer be present when symptoms emerge, multiple organisms may cause the symptoms, and the symptoms may be a rare reaction to a common pathogen.[21]\\r\\n\\r\\nTreatment for children suspected of PANDAS is generally the same as the standard treatments for TS and OCD.[2][5][15] These include cognitive behavioral therapy and medications to treat OCD such as selective serotonin reuptake inhibitors (SSRIs);[5][15] and \\"conventional therapy for tics\\".[2]\\r\\n\\r\\nA controlled study (Garvey, Perlmutter, et al, 1999) of prophylactic antibiotic treatment of 37 children found that penicillin V did not prevent GABHS infections or exacerbation of other symptoms; however, compliance was an issue in this study. A later study (Snider, Lougee, et al, 2005) found that penicillin and azithromycin decreased infections and symptom exacerbation. The sample size, controls, and methodology of that study were criticized.[1] Murphy, Kurlan and Leckman (2010) say, \\"The use of prophylactic antibiotics to treat PANDAS has become widespread in the community, although the evidence supporting their use is equivocal. The safety and efficacy of antibiotic therapy for patients meeting the PANDAS criteria needs to be determined in carefully designed trials\\";[5]  de Oliveira and Pelajo (2009) say that because most studies to date have \\"methodologic issues, including small sample size, retrospective reports of the baseline year, and lack of an adequate placebo arm  ... it is recommended to treat these patients only with conventional therapy\\".[2]\\r\\n\\r\\nEvidence is insufficient to determine if tonsillectomy is effective.[2]\\r\\n\\r\\nProphylactic antibiotic treatments for tics and OCD are experimental[6] and controversial;[12] overdiagnosis of PANDAS may have led to overuse of antibiotics to treat tics or OCD in the absence of active infection.[12]\\r\\n\\r\\nA single study of PANDAS patients showed efficacy of immunomodulatory therapy (intravenous immunoglobulin (IVIG) or plasma exchange) to symptoms,[1] but these results are unreplicated by independent studies as of 2010.[16][12] Kalra and Swedo wrote in 2009, \\"Because IVIG and plasma exchange both carry a substantial risk of adverse effects, use of these modalities should be reserved for children with particularly severe symptoms and a clear-cut PANDAS presentation.[15] The US National Institutes of Health and American Academy of Neurology 2011 guidelines say there is \\"inadequate data to determine the efficacy of plasmapheresis in the treatment of acute OCD and tic symptoms in the setting of PANDAS\\" and \\"insufficient evidence to support or refute the use of plasmapheresis in the treatment of acute OCD and tic symptoms in the setting of PANDAS\\", adding that the investigators in the only study of plasmapherisis were not blind to the results.[8] The Medical Advisory Board of the Tourette Syndrome Association said in 2006 that experimental treatments based on the autoimmune theory such as IVIG or plasma exchange should not be undertaken outside of formal clinical trials.[22] The American Heart Association's 2009 guidelines state that, as PANDAS is an unproven hypothesis and well-controlled studies are not yet available, they do \\"not recommend routine laboratory testing for GAS to diagnose, long-term antistreptococcal prophylaxis to prevent, or immunoregulatory therapy (e.g., intravenous immunoglobulin, plasma exchange) to treat exacerbations of this disorder\\".[23]\\r\\n\\r\\nThe debate surrounding the PANDAS hypothesis has societal implications; the media and the Internet have played a role in the PANDAS controversy.[5][24] Swerdlow (2005) summarized the societal implications of the hypothesis, and the role of the Internet in the controversy surrounding the PANDAS hypothesis:\\r\\n\\r\\n...?perhaps the most controversial putative TS trigger is exposure to streptococcal infections. The ubiquity of strep throats, the tremendous societal implications of over-treatment (e.g., antibiotic resistance or immunosuppressant side effects) versus medical implications of under-treatment (e.g., potentially irreversible autoimmune neurologic injury) are serious matters. With the level of desperation among Internet-armed parents, this controversy has sparked contentious disagreements, too often lacking both objectivity and civility.[24]\\r\\n\\r\\nMurphy, Kurlan and Leckman (2010) also discussed the influence of the media and the Internet in a paper that proposed a \\"way forward\\":\\r\\nThe potential link between common childhood infections and lifelong neuropsychiatric disorders is among the most tantalizing and clinically relevant concepts in modern neuroscience ... The link may be most relevant in this group of disorders collectively described as PANDAS. Of concern, public awareness has outpaced our scientific knowledge base, with multiple magazine and newspaper articles and Internet chat rooms calling this issue to the public's attention. Compared with ~ 200 reports listed on Medlinemany involving a single patient, and others reporting the same patients in different papers, with most of these reporting on subjects who do not meet the current PANDAS criteriathere are over 100,000 sites on the Internet where the possible StreptococcusÿOCDÿTD relationship is discussed. This gap between public interest in PANDAS and conclusive evidence supporting this link calls for increased scientific attention to the relationship between GAS and OCD/tics, particularly examining basic underlying cellular and immune mechanisms.[5]\\r\\nSusan Swedo first described the entity in 1998.[19] In 2008 Lombroso and Scahill described five diagnostic criteria for PANDAS.[16] Revised criteria and guidelines for PANDAS was established by the NIMH in 2012 and updated in 2017.[25][26]\\r\\n\\r\\nIn a 2010 paper calling for \\"a way forward\\", Murphy, Kurlan and Leckman said: \\"It is time for the National Institutes of Health, in combination with advocacy and professional organizations, to convene a panel of experts not to debate the current data, but to chart a way forward. For now we have only to offer our standard therapies in treating OCD and tics, but one day we may have evidence that also allows us to add antibiotics or other immune-specific treatments to our armamentarium.\\"[5] A 2011 paper by Singer proposed a new, \\"broader concept of childhood acute neuropsychiatric symptoms (CANS)\\", removing some of the PANDAS criteria in favor or requiring only acute-onset.  Singer said there were \\"numerous causes for CANS\\", which was proposed because of the \\"inconclusive and conflicting scientific support\\" for PANDAS, including \\"strong evidence suggesting the absence of an important role for GABHS, a failure to apply published [PANDAS] criteria, and a lack of scientific support for proposed therapies\\".[27]","input":"What is p a n d a s?"},{"output":"data and machine code currently being used","context":"Random-access memory (RAM /r?m/) is a form of computer data storage which stores data and machine code currently being used. A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory. In contrast, with other direct-access data storage media such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory, the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement.\\r\\nRAM contains multiplexing and demultiplexing circuitry, to connect the data lines to the addressed storage for reading or writing the entry. Usually more than one bit of storage is accessed by the same address, and RAM devices often have multiple data lines and are said to be '8-bit' or '16-bit' etc. devices.\\r\\nIn today's technology, random-access memory takes the form of integrated circuits. RAM is normally associated with volatile types of memory (such as DRAM modules), where stored information is lost if power is removed, although non-volatile RAM has also been developed.[1] Other types of non-volatile memories exist that allow random access for read operations, but either do not allow write operations or have other kinds of limitations on them. These include most types of ROM and a type of flash memory called NOR-Flash.\\r\\nIntegrated-circuit RAM chips came into the market in the early 1970s, with the first commercially available DRAM chip, the Intel 1103, introduced in October 1970.[2]\\r\\n\\r\\n\\r\\nEarly computers used relays, mechanical counters[3] or delay lines for main memory functions. Ultrasonic delay lines could only reproduce data in the order it was written. Drum memory could be expanded at relatively low cost but efficient retrieval of memory items required knowledge of the physical layout of the drum to optimize speed. Latches built out of vacuum tube triodes, and later, out of discrete transistors, were used for smaller and faster memories such as registers. Such registers were relatively large and too costly to use for large amounts of data; generally only a few dozen or few hundred bits of such memory could be provided.\\r\\nThe first practical form of random-access memory was the Williams tube starting in 1947. It stored data as electrically charged spots on the face of a cathode ray tube. Since the electron beam of the CRT could read and write the spots on the tube in any order, memory was random access. The capacity of the Williams tube was a few hundred to around a thousand bits, but it was much smaller, faster, and more power-efficient than using individual vacuum tube latches. Developed at the University of Manchester in England, the Williams tube provided the medium on which the first electronically stored-memory program was implemented in the Manchester Small-Scale Experimental Machine (SSEM) computer, which first successfully ran a program on 21 June 1948.[4] In fact, rather than the Williams tube memory being designed for the SSEM, the SSEM was a testbed to demonstrate the reliability of the memory.[5][6]\\r\\nMagnetic-core memory was invented in 1947 and developed up until the mid-1970s. It became a widespread form of random-access memory, relying on an array of magnetized rings. By changing the sense of each ring's magnetization, data could be stored with one bit stored per ring. Since every ring had a combination of address wires to select and read or write it, access to any memory location in any sequence was possible.\\r\\nMagnetic core memory was the standard form of memory system until displaced by solid-state memory in integrated circuits, starting in the early 1970s. Dynamic random-access memory (DRAM) allowed replacement of a 4 or 6-transistor latch circuit by a single transistor for each memory bit, greatly increasing memory density at the cost of volatility. Data was stored in the tiny capacitance of each transistor, and had to be periodically refreshed every few milliseconds before the charge could leak away. The Toshiba Toscal BC-1411 electronic calculator, which was introduced in 1965,[7][8] used a form of DRAM built from discrete components.[8] DRAM was then developed by Robert H. Dennard in 1968.\\r\\nPrior to the development of integrated read-only memory (ROM) circuits, permanent (or read-only) random-access memory was often constructed using diode matrices driven by address decoders, or specially wound core rope memory planes.[citation needed]\\r\\nThe two widely used forms of modern RAM are static RAM (SRAM) and dynamic RAM (DRAM). In SRAM, a bit of data is stored using the state of a six transistor memory cell. This form of RAM is more expensive to produce, but is generally faster and requires less dynamic power than DRAM. In modern computers, SRAM is often used as cache memory for the CPU. DRAM stores a bit of data using a transistor and capacitor pair, which together comprise a DRAM cell. The capacitor holds a high or low charge (1 or 0, respectively), and the transistor acts as a switch that lets the control circuitry on the chip read the capacitor's state of charge or change it. As this form of memory is less expensive to produce than static RAM, it is the predominant form of computer memory used in modern computers.\\r\\nBoth static and dynamic RAM are considered volatile, as their state is lost or reset when power is removed from the system. By contrast, read-only memory (ROM) stores data by permanently enabling or disabling selected transistors, such that the memory cannot be altered. Writeable variants of ROM (such as EEPROM and flash memory) share properties of both ROM and RAM, enabling data to persist without power and to be updated without requiring special equipment. These persistent forms of semiconductor ROM include USB flash drives, memory cards for cameras and portable devices, and solid-state drives. ECC memory (which can be either SRAM or DRAM) includes special circuitry to detect and/or correct random faults (memory errors) in the stored data, using parity bits or error correction codes.\\r\\nIn general, the term RAM refers solely to solid-state memory devices (either DRAM or SRAM), and more specifically the main memory in most computers. In optical storage, the term DVD-RAM is somewhat of a misnomer since, unlike CD-RW or DVD-RW it does not need to be erased before reuse. Nevertheless, a DVD-RAM behaves much like a hard disc drive if somewhat slower.\\r\\nThe memory cell is the fundamental building block of computer memory. The memory cell is an electronic circuit that stores one bit of binary information and it must be set to store a logic 1 (high voltage level) and reset to store a logic 0 (low voltage level). Its value is maintained/stored until it is changed by the set/reset process. The value in the memory cell can be accessed by reading it.\\r\\nIn SRAM, the memory cell is a type of flip-flop circuit, usually implemented using FETs. This means that SRAM requires very low power when not being accessed, but it is expensive and has low storage density.\\r\\nA second type, DRAM, is based around a capacitor. Charging and discharging this capacitor can store a '1' or a '0' in the cell. However, this capacitor will slowly leak away, and must be refreshed periodically. Because of this refresh process, DRAM uses more power, but it can achieve greater storage densities and lower unit costs compared to SRAM.\\r\\nTo be useful, memory cells must be readable and writeable. Within the RAM device, multiplexing and demultiplexing circuitry is used to select memory cells. Typically, a RAM device has a set of address lines A0... An, and for each combination of bits that may be applied to these lines, a set of memory cells are activated. Due to this addressing, RAM devices virtually always have a memory capacity that is a power of two.\\r\\nUsually several memory cells share the same address. For example, a 4 bit 'wide' RAM chip has 4 memory cells for each address. Often the width of the memory and that of the microprocessor are different, for a 32 bit microprocessor, eight 4 bit RAM chips would be needed.\\r\\nOften more addresses are needed than can be provided by a device. In that case, external multiplexors to the device are used to activate the correct device that is being accessed.\\r\\nOne can read and over-write data in RAM. Many computer systems have a memory hierarchy consisting of processor registers, on-die SRAM caches, external caches, DRAM, paging systems and virtual memory or swap space on a hard drive. This entire pool of memory may be referred to as \\"RAM\\" by many developers, even though the various subsystems can have very different access times, violating the original concept behind the random access term in RAM. Even within a hierarchy level such as DRAM, the specific row, column, bank, rank, channel, or interleave organization of the components make the access time variable, although not to the extent that access time to rotating storage media or a tape is variable. The overall goal of using a memory hierarchy is to obtain the highest possible average access performance while minimizing the total cost of the entire memory system (generally, the memory hierarchy follows the access time with the fast CPU registers at the top and the slow hard drive at the bottom).\\r\\nIn many modern personal computers, the RAM comes in an easily upgraded form of modules called memory modules or DRAM modules about the size of a few sticks of chewing gum. These can quickly be replaced should they become damaged or when changing needs demand more storage capacity. As suggested above, smaller amounts of RAM (mostly SRAM) are also integrated in the CPU and other ICs on the motherboard, as well as in hard-drives, CD-ROMs, and several other parts of the computer system.\\r\\nIn addition to serving as temporary storage and working space for the operating system and applications, RAM is used in numerous other ways.\\r\\nMost modern operating systems employ a method of extending RAM capacity, known as \\"virtual memory\\". A portion of the computer's hard drive is set aside for a paging file or a scratch partition, and the combination of physical RAM and the paging file form the system's total memory. (For example, if a computer has 2 GB of RAM and a 1 GB page file, the operating system has 3 GB total memory available to it.) When the system runs low on physical memory, it can \\"swap\\" portions of RAM to the paging file to make room for new data, as well as to read previously swapped information back into RAM. Excessive use of this mechanism results in thrashing and generally hampers overall system performance, mainly because hard drives are far slower than RAM.\\r\\nSoftware can \\"partition\\" a portion of a computer's RAM, allowing it to act as a much faster hard drive that is called a RAM disk. A RAM disk loses the stored data when the computer is shut down, unless memory is arranged to have a standby battery source.\\r\\nSometimes, the contents of a relatively slow ROM chip are copied to read/write memory to allow for shorter access times. The ROM chip is then disabled while the initialized memory locations are switched in on the same block of addresses (often write-protected). This process, sometimes called shadowing, is fairly common in both computers and embedded systems.\\r\\nAs a common example, the BIOS in typical personal computers often has an option called use shadow BIOS or similar. When enabled, functions relying on data from the BIOSs ROM will instead use DRAM locations (most can also toggle shadowing of video card ROM or other ROM sections). Depending on the system, this may not result in increased performance, and may cause incompatibilities. For example, some hardware may be inaccessible to the operating system if shadow RAM is used. On some systems the benefit may be hypothetical because the BIOS is not used after booting in favor of direct hardware access. Free memory is reduced by the size of the shadowed ROMs.[9]\\r\\nSeveral new types of non-volatile RAM, which will preserve data while powered down, are under development. The technologies used include carbon nanotubes and approaches utilizing Tunnel magnetoresistance. Amongst the 1st generation MRAM, a 128 KiB (128 G 210 bytes) chip was manufactured with 0.18?m technology in the summer of 2003.[citation needed] In June 2004, Infineon Technologies unveiled a 16?MiB (16?G?220 bytes) prototype again based on 0.18?m technology. There are two 2nd generation techniques currently in development: thermal-assisted switching (TAS)[10] which is being developed by Crocus Technology, and spin-transfer torque (STT) on which Crocus, Hynix, IBM, and several other companies are working.[11] Nantero built a functioning carbon nanotube memory prototype 10?GiB (10?G?230 bytes) array in 2004. Whether some of these technologies will be able to eventually take a significant market share from either DRAM, SRAM, or flash-memory technology, however, remains to be seen.\\r\\nSince 2006, \\"solid-state drives\\" (based on flash memory) with capacities exceeding 256 gigabytes and performance far exceeding traditional disks have become available. This development has started to blur the definition between traditional random-access memory and \\"disks\\", dramatically reducing the difference in performance.\\r\\nSome kinds of random-access memory, such as \\"EcoRAM\\", are specifically designed for server farms, where low power consumption is more important than speed.[12]\\r\\nThe \\"memory wall\\" is the growing disparity of speed between CPU and memory outside the CPU chip. An important reason for this disparity is the limited communication bandwidth beyond chip boundaries, which is also referred to as bandwidth wall. From 1986 to 2000, CPU speed improved at an annual rate of 55% while memory speed only improved at 10%. Given these trends, it was expected that memory latency would become an overwhelming bottleneck in computer performance.[13]\\r\\nCPU speed improvements slowed significantly partly due to major physical barriers and partly because current CPU designs have already hit the memory wall in some sense. Intel summarized these causes in a 2005 document.[14]\\r\\nFirst of all, as chip geometries shrink and clock frequencies rise, the transistor leakage current increases, leading to excess power consumption and heat... Secondly, the advantages of higher clock speeds are in part negated by memory latency, since memory access times have not been able to keep pace with increasing clock frequencies. Third, for certain applications, traditional serial architectures are becoming less efficient as processors get faster (due to the so-called Von Neumann bottleneck), further undercutting any gains that frequency increases might otherwise buy. In addition, partly due to limitations in the means of producing inductance within solid state devices, resistance-capacitance (RC) delays in signal transmission are growing as feature sizes shrink, imposing an additional bottleneck that frequency increases don't address.\\r\\nThe RC delays in signal transmission were also noted in Clock Rate versus IPC: The End of the Road for Conventional Microarchitectures which projects a maximum of 12.5% average annual CPU performance improvement between 2000 and 2014.\\r\\nA different concept is the processor-memory performance gap, which can be addressed by 3D integrated circuits that reduce the distance between the logic and memory aspects that are further apart in a 2D chip.[15] Memory subsystem design requires a focus on the gap, which is widening over time.[16] The main method of bridging the gap is the use of caches; small amounts of high-speed memory that houses recent operations and instructions nearby the processor, speeding up the execution of those operations or instructions in cases where they are called upon frequently. Multiple levels of caching have been developed in order to deal with the widening of the gap, and the performance of high-speed modern computers are reliant on evolving caching techniques.[17] These can prevent the loss of processor performance, as it takes less time to perform the computation it has been initiated to complete.[18] There can be up to a 53% difference between the growth in speed of processor speeds and the lagging speed of main memory access.[19]\\r\\nIn contrast, RAM can be as fast as 5766 MB/s vs 477 MB/s for an SSD.[20]","input":"What is stored on ram in a computer?"},{"output":"George Carlin","context":"The first season of Saturday Night Live, an American sketch comedy series, originally aired in the United States on NBC from October 11, 1975 to July 31, 1976.\\r\\n\\r\\nIn 1974, NBC Tonight Show host Johnny Carson requested that the weekend broadcasts of \\"Best of Carson\\" (officially known as The Weekend Tonight Show Starring Johnny Carson) come to an end (back then, The Tonight Show was a 90-minute program), so that Carson could take two weeknights off and NBC would thus air those repeats on those nights rather than feed them to affiliates for broadcast on either Saturdays or Sundays. Given Carson's undisputed status as the king of late-night television, NBC heard his request as an ultimatum, fearing he might use the issue as grounds to defect to either ABC or CBS. To fill the gap, the network drew up some ideas and brought in Dick Ebersol ÿ a protg of legendary ABC Sports president Roone Arledge ÿ to develop a 90-minute late-night variety show. Ebersol's first order of business was hiring a young Canadian producer named Lorne Michaels to be the show-runner.[1]\\r\\n\\r\\nTelevision production in New York was already in decline in the mid-1970s (The Tonight Show had departed for Los Angeles two years prior), so NBC decided to base the show at their studios in Rockefeller Center to offset the overhead of maintaining those facilities. Michaels was given Studio 8H, a converted radio studio that prior to that point was most famous for having hosted Arturo Toscanini and the NBC Symphony Orchestra from 1937 to 1951, but was being used largely for network election coverage by the mid-1970s.[citation needed]\\r\\n\\r\\nWhen the first show aired on October 11, 1975 with George Carlin as its host, it was called NBC's Saturday Night because ABC featured a program at the same time titled Saturday Night Live with Howard Cosell. After ABC cancelled the Cosell program in 1976, the NBC program changed its name to Saturday Night Live on March 26, 1977 (and subsequently picked up Bill Murray from Cosell's show in 1977, as well). Every night, Don Pardo introduced the cast, a job he'd hold for 39 years until his death in 2014.\\r\\n\\r\\nThe original concept was for a comedy-variety show featuring young comedians, live musical performances, short films by Albert Brooks, and segments by Jim Henson featuring atypically adult and abstract characters from the Muppets world. Rather than have one permanent host, Michaels elected to have a different guest host each week. The first episode featured two musical guests (Billy Preston and Janis Ian), and the second episode, hosted by Paul Simon on October 18, was almost entirely a musical variety show with various acts. The Not Ready For Prime Time Players did not appear in this episode at all, other than as the bees with Simon telling them they were cancelled, and Chevy Chase in the opening and in \\"Weekend Update\\". Over the course of Season 1, sketch comedy would begin to dominate the show and SNL would more closely resemble its current format.\\r\\n\\r\\nAndy Kaufman made several appearances that were popular with the audience over the season,[citation needed] while The Muppets' Land of Gorch bits were regarded as a poor fit with the rest of the show.[citation needed]  The \\"Land Of Gorch\\" sketches were essentially cancelled after episode 10, although the associated Muppet characters still made sporadic appearances after that. After one final appearance at the start of season two, the Muppet characters were permanently dropped from SNL.\\r\\n\\r\\nDuring the season, Michaels appeared on-camera twice, on April 24 and May 22, to make an offer to The Beatles to reunite on the show. In the first appearance, he offered a certified check of $3000. In the second appearance, he increased his offer to $3,200 and free hotel accommodations. John Lennon and Paul McCartney later both admitted that they were watching SNL from Lennon's apartment on May 8, the episode after Michaels' first offer, and briefly toyed with actually going down to the studio, but decided to stay in the apartment because they were too tired.[2][3]\\r\\n\\r\\nThe first cast member hired was Gilda Radner.[4] The rest of the cast included fellow Second City alumni Dan Aykroyd and John Belushi, as well as National Lampoon \\"Lemmings\\" alumnus Chevy Chase (whose trademark became his usual falls and opening spiel that cued the show's opening), Jane Curtin, Laraine Newman, and Garrett Morris. The original head writer was Michael O'Donoghue, a writer at National Lampoon who had worked alongside several cast members while directing The National Lampoon Radio Hour. The original theme music was written by future Academy Awardÿwinning composer Howard Shore, who ÿ along with his band (occasionally billed as the \\"All Nurse Band\\" or \\"Band of Angels\\"[citation needed]) ÿ was the original band leader on the show. Paul Shaffer, who would go on to lead David Letterman's band on Late Night and then The Late Show, was also band leader in the early years. George Coe was hired because NBC wanted to have an older person in the cast.[citation needed]\\r\\n\\r\\nMuch of the talent pool involved in the inaugural season was recruited from the National Lampoon Radio Hour, a nationally syndicated comedy series that often satirized current events.\\r\\n\\r\\nThis would be the only season for Coe and O'Donoghue as official cast members. While Coe was only billed in the premiere, he was seen in various small roles through the season before leaving the show altogether. O'Donoghue was credited through the Candice Bergen episode and would continue to work for the show as a writer, as well as an occasional featured performer (particularly as \\"Mr. Mike\\"), through season five.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nbold denotes Weekend Update anchor\\r\\n\\r\\nThe original writing staff included Anne Beatts, Chevy Chase, Tom Davis, Al Franken, Lorne Michaels, Marilyn Suzanne Miller, Michael O'Donoghue, Herb Sargent, Tom Schiller, Rosie Shuster and Alan Zweibel. The head writers were Lorne Michaels and Michael O'Donoghue.","input":"Who was the first saturday night live host?"},{"output":"Anaximander","context":"In astronomy, the geocentric model (also known as geocentrism, or the Ptolemaic system) is a superseded description of the universe with Earth at the center. Under the geocentric model, the Sun, Moon, stars, and planets all orbited Earth.[1] The geocentric model served as the predominant description of the cosmos in many ancient civilizations, such as those of Aristotle and Ptolemy.\\r\\nTwo observations supported the idea that Earth was the center of the Universe. First, from the view on Earth, the Sun appears to revolve around Earth once per day. While the Moon and the planets have their own motions, they also appear to revolve around Earth about once per day. The stars appeared to be on a celestial sphere, rotating once each day along an axis through the north and south geographic poles of Earth.[2] Second, Earth does not seem to move from the perspective of an Earth-bound observer; it appears to be solid, stable, and unmoving.\\r\\nAncient Greek, ancient Roman and medieval philosophers usually combined the geocentric model with a spherical Earth. It is not the same as the older flat Earth model implied in some mythology.[n 1][n 2][5] The ancient Jewish Babylonian uranography pictured a flat Earth with a dome-shaped, rigid canopy called the firmament placed over it (????- rq?a').[n 3][n 4][n 5][n 6][n 7][n 8] However, the ancient Greeks believed that the motions of the planets were circular and not elliptical, a view that was not challenged in Western culture until the 17th century through the synthesis of theories by Copernicus and Kepler.\\r\\nThe astronomical predictions of Ptolemy's geocentric model were used to prepare astrological and astronomical charts for over 1500 years. The geocentric model held sway into the early modern age, but from the late 16th century onward, it was gradually superseded by the Heliocentric model of Copernicus, Galileo and Kepler. There was much resistance to the transition between these two theories. Christian theologians were reluctant to reject a theory that agreed with Bible passages (e.g. \\"Sun, stand you still upon Gibeon\\", Joshua 10:12). Others felt a new, unknown theory could not subvert an accepted consensus for geocentrism.\\r\\n\\r\\n\\r\\nThe geocentric model entered Greek astronomy and philosophy at an early point; it can be found in pre-Socratic philosophy. In the 6th century BC, Anaximander proposed a cosmology with Earth shaped like a section of a pillar (a cylinder), held aloft at the center of everything. The Sun, Moon, and planets were holes in invisible wheels surrounding Earth; through the holes, humans could see concealed fire. About the same time, Pythagoras thought that the Earth was a sphere (in accordance with observations of eclipses), but not at the center; they believed that it was in motion around an unseen fire. Later these views were combined, so most educated Greeks from the 4th century BC on thought that the Earth was a sphere at the center of the universe.[12]\\r\\nIn the 4th century BC, two influential Greek philosophers, Plato and his student Aristotle, wrote works based on the geocentric model. According to Plato, the Earth was a sphere, stationary at the center of the universe. The stars and planets were carried around the Earth on spheres or circles, arranged in the order (outwards from the center): Moon, Sun, Venus, Mercury, Mars, Jupiter, Saturn, fixed stars, with the fixed stars located on the celestial sphere. In his \\"Myth of Er\\", a section of the Republic, Plato describes the cosmos as the Spindle of Necessity, attended by the Sirens and turned by the three Fates. Eudoxus of Cnidus, who worked with Plato, developed a less mythical, more mathematical explanation of the planets' motion based on Plato's dictum stating that all phenomena in the heavens can be explained with uniform circular motion. Aristotle elaborated on Eudoxus' system.\\r\\nIn the fully developed Aristotelian system, the spherical Earth is at the center of the universe, and all other heavenly bodies are attached to 47ÿ55 transparent, rotating spheres surrounding the Earth, all concentric with it. (The number is so high because several spheres are needed for each planet.) These spheres, known as crystalline spheres, all moved at different uniform speeds to create the revolution of bodies around the Earth. They were composed of an incorruptible substance called aether. Aristotle believed that the moon was in the innermost sphere and therefore touches the realm of Earth, causing the dark spots (macula) and the ability to go through lunar phases. He further described his system by explaining the natural tendencies of the terrestrial elements: Earth, water, fire, air, as well as celestial aether. His system held that Earth was the heaviest element, with the strongest movement towards the center, thus water formed a layer surrounding the sphere of Earth. The tendency of air and fire, on the other hand, was to move upwards, away from the center, with fire being lighter than air. Beyond the layer of fire, were the solid spheres of aether in which the celestial bodies were embedded. They, themselves, were also entirely composed of aether.\\r\\nAdherence to the geocentric model stemmed largely from several important observations. First of all, if the Earth did move, then one ought to be able to observe the shifting of the fixed stars due to stellar parallax. In short, if the Earth was moving, the shapes of the constellations should change considerably over the course of a year. If they did not appear to move, the stars are either much farther away than the Sun and the planets than previously conceived, making their motion undetectable, or in reality they are not moving at all. Because the stars were actually much further away than Greek astronomers postulated (making movement extremely subtle), stellar parallax was not detected until the 19th century. Therefore, the Greeks chose the simpler of the two explanations. Another observation used in favor of the geocentric model at the time was the apparent consistency of Venus' luminosity, which implies that it is usually about the same distance from Earth, which in turn is more consistent with geocentrism than heliocentrism. In reality, that is because the loss of light caused by Venus' phases compensates for the increase in apparent size caused by its varying distance from Earth. Objectors to heliocentrism noted that terrestrial bodies naturally tend to come to rest as near as possible to the center of the Earth. Further barring the opportunity to fall closer the center, terrestrial bodies tend not to move unless forced by an outside object, or transformed to a different element by heat or moisture.\\r\\nAtmospheric explanations for many phenomena were preferred because the EudoxanÿAristotelian model based on perfectly concentric spheres was not intended to explain changes in the brightness of the planets due to a change in distance.[13] Eventually, perfectly concentric spheres were abandoned as it was impossible to develop a sufficiently accurate model under that ideal. However, while providing for similar explanations, the later deferent and epicycle model was flexible enough to accommodate observations for many centuries.\\r\\nAlthough the basic tenets of Greek geocentrism were established by the time of Aristotle, the details of his system did not become standard. The Ptolemaic system, developed by the Hellenistic astronomer Claudius Ptolemaeus in the 2nd century AD finally standardised geocentrism. His main astronomical work, the Almagest, was the culmination of centuries of work by Hellenic, Hellenistic and Babylonian astronomers. For over a millennium European and Islamic astronomers assumed it was the correct cosmological model. Because of its influence, people sometimes wrongly think the Ptolemaic system is identical with the geocentric model.\\r\\nPtolemy argued that the Earth was a sphere in the center of the universe, from the simple observation that half the stars were above the horizon and half were below the horizon at any time (stars on rotating stellar sphere), and the assumption that the stars were all at some modest distance from the center of the universe. If the Earth was substantially displaced from the center, this division into visible and invisible stars would not be equal.[n 9]\\r\\nIn the Ptolemaic system, each planet is moved by a system of two spheres: one called its deferent; the other, its epicycle. The deferent is a circle whose center point, called the eccentric and marked in the diagram with an X, is removed from the Earth. The original purpose of the eccentric was to account for the difference in length of the seasons (northern autumn was about five days shorter than spring during this time period) by placing the Earth away from the center of rotation of the rest of the universe. Another sphere, the epicycle, is embedded inside the deferent sphere and is represented by the smaller dotted line to the right. A given planet then moves around the epicycle at the same time the epicycle moves along the path marked by the deferent. These combined movements cause the given planet to move closer to and further away from the Earth at different points in its orbit, and explained the observation that planets slowed down, stopped, and moved backward in retrograde motion, and then again reversed to resume normal, or prograde, motion.\\r\\nThe deferent-and-epicycle model had been used by Greek astronomers for centuries along with the idea of the eccentric (a deferent which is slightly off-center from the Earth), which was even older. In the illustration, the center of the deferent is not the Earth but the spot marked X, making it eccentric (from the Greek ? ec- meaning \\"from,\\" and ? kentron meaning \\"center\\"), from which the spot takes its name. Unfortunately, the system that was available in Ptolemy's time did not quite match observations, even though it was considerably improved over Hipparchus' system. Most noticeably the size of a planet's retrograde loop (especially that of Mars) would be smaller, and sometimes larger, than expected, resulting in positional errors of as much as 30 degrees. To alleviate the problem, Ptolemy developed the equant. The equant was a point near the center of a planet's orbit which, if you were to stand there and watch, the center of the planet's epicycle would always appear to move at uniform speed; all other locations would see non-uniform speed, like on the Earth. By using an equant, Ptolemy claimed to keep motion which was uniform and circular, although it departed from the Platonic ideal of uniform circular motion. The resultant system, which eventually came to be widely accepted in the west, seems unwieldy to modern astronomers; each planet required an epicycle revolving on a deferent, offset by an equant which was different for each planet. It predicted various celestial motions, including the beginning and end of retrograde motion, to within a maximum error of 10 degrees, considerably better than without the equant.\\r\\nThe model with epicycles is in fact a very good model of an elliptical orbit with low eccentricity. The well known ellipse shape does not appear to a noticeable extent when the eccentricity is less than 5%, but the offset distance of the \\"center\\" (in fact the focus occupied by the sun) is very noticeable even with low eccentricities as possessed by the planets.\\r\\nTo summarize, Ptolemy devised a system that was compatible with Aristotelian philosophy and managed to track actual observations and predict future movement mostly to within the limits of the next 1000 years of observations. The observed motions and his mechanisms for explaining them include:\\r\\nThe geocentric model was eventually replaced by the heliocentric model. The earliest heliocentric model, Copernican heliocentrism, could remove Ptolemy's epicycles because the retrograde motion could be seen to be the result of the combination of Earth and planet movement and speeds. Copernicus felt strongly that equants were a violation of Aristotelian purity, and proved that replacement of the equant with a pair of new epicycles was entirely equivalent. Astronomers often continued using the equants instead of the epicycles because the former was easier to calculate, and gave the same result.\\r\\nIt has been determined, in fact, that the Copernican, Ptolemaic and even the Tychonic models provided identical results to identical inputs. They are computationally equivalent. It wasn't until Kepler demonstrated a physical observation that could show that the physical sun is directly involved in determining an orbit that a new model was required.\\r\\nThe Ptolemaic order of spheres from Earth outward is:[15]\\r\\nPtolemy did not invent or work out this order, which aligns with the ancient Seven Heavens religious cosmology common to the major Eurasian religious traditions. It also follows the decreasing orbital periods of the moon, sun, planets and stars.\\r\\nMuslim astronomers generally accepted the Ptolemaic system and the geocentric model,[16] but by the 10th century texts appeared regularly whose subject matter was doubts concerning Ptolemy (shukk).[17] Several Muslim scholars questioned the Earth's apparent immobility[18][19] and centrality within the universe.[20] Some Muslim astronomers believed that the Earth rotates around its axis, such as Abu Sa'id al-Sijzi (d. circa 1020).[21][22] According to al-Biruni, Sijzi invented an astrolabe called al-zraqؐ based on a belief held by some of his contemporaries \\"that the motion we see is due to the Earth's movement and not to that of the sky.\\"[22][23] The prevalence of this view is further confirmed by a reference from the 13th century which states:\\r\\nAccording to the geometers [or engineers] (muhandisؐn), the Earth is in constant circular motion, and what appears to be the motion of the heavens is actually due to the motion of the Earth and not the stars.[22]\\r\\nEarly in the 11th century Alhazen wrote a scathing critique of Ptolemy's model in his Doubts on Ptolemy (c. 1028), which some have interpreted to imply he was criticizing Ptolemy's geocentrism,[24] but most agree that he was actually criticizing the details of Ptolemy's model rather than his geocentrism.[25]\\r\\nIn the 12th century, Arzachel departed from the ancient Greek idea of uniform circular motions by hypothesizing that the planet Mercury moves in an elliptic orbit,[26][27] while Alpetragius proposed a planetary model that abandoned the equant, epicycle and eccentric mechanisms,[28] though this resulted in a system that was mathematically less accurate.[29] Alpetragius also declared the Ptolemaic system as an imaginary model that was successful at predicting planetary positions but not real or physical. His alternative system spread through most of Europe during the 13th century.[30]\\r\\nFakhr al-Din al-Razi (1149ÿ1209), in dealing with his conception of physics and the physical world in his Matalib, rejects the Aristotelian and Avicennian notion of the Earth's centrality within the universe, but instead argues that there are \\"a thousand thousand worlds (alfa alfi 'awalim) beyond this world such that each one of those worlds be bigger and more massive than this world as well as having the like of what this world has.\\" To support his theological argument, he cites the Qur'anic verse, \\"All praise belongs to God, Lord of the Worlds,\\" emphasizing the term \\"Worlds.\\"[20]\\r\\nThe \\"Maragha Revolution\\" refers to the Maragha school's revolution against Ptolemaic astronomy. The \\"Maragha school\\" was an astronomical tradition beginning in the Maragha observatory and continuing with astronomers from the Damascus mosque and Samarkand observatory. Like their Andalusian predecessors, the Maragha astronomers attempted to solve the equant problem (the circle around whose circumference a planet or the center of an epicycle was conceived to move uniformly) and produce alternative configurations to the Ptolemaic model without abandoning geocentrism. They were more successful than their Andalusian predecessors in producing non-Ptolemaic configurations which eliminated the equant and eccentrics, were more accurate than the Ptolemaic model in numerically predicting planetary positions, and were in better agreement with empirical observations.[31] The most important of the Maragha astronomers included Mo'ayyeduddin Urdi (d. 1266), Nasؐr al-Dؐn al-Tsؐ (1201ÿ1274), Qutb al-Din al-Shirazi (1236ÿ1311), Ibn al-Shatir (1304ÿ1375), Ali Qushji (c. 1474), Al-Birjandi (d. 1525), and Shams al-Din al-Khafri (d. 1550).[32] Ibn al-Shatir, the Damascene astronomer (1304ÿ1375 AD) working at the Umayyad Mosque, wrote a major book entitled Kitab Nihayat al-Sul fi Tashih al-Usul (A Final Inquiry Concerning the Rectification of Planetary Theory) on a theory which departs largely from the Ptolemaic system known at that time. In his book, Ibn al-Shatir, an Arab astronomer of the fourteenth century, E. S. Kennedy wrote \\"what is of most interest, however, is that Ibn al-Shatir's lunar theory, except for trivial differences in parameters, is identical with that of Copernicus (1473ÿ1543 AD).\\" The discovery that the models of Ibn al-Shatir are mathematically identical to those of Copernicus suggests the possible transmission of these models to Europe.[33] At the Maragha and Samarkand observatories, the Earth's rotation was discussed by al-Tusi and Ali Qushji (b. 1403); the arguments and evidence they used resemble those used by Copernicus to support the Earth's motion.[18][19]\\r\\nHowever, the Maragha school never made the paradigm shift to heliocentrism.[34] The influence of the Maragha school on Copernicus remains speculative, since there is no documentary evidence to prove it. The possibility that Copernicus independently developed the Tusi couple remains open, since no researcher has yet demonstrated that he knew about Tusi's work or that of the Maragha school.[34][35]\\r\\nNot all Greeks agreed with the geocentric model. The Pythagorean system has already been mentioned; some Pythagoreans believed the Earth to be one of several planets going around a central fire.[36] Hicetas and Ecphantus, two Pythagoreans of the 5th century BC, and Heraclides Ponticus in the 4th century BC, believed that the Earth rotated on its axis but remained at the center of the universe.[37] Such a system still qualifies as geocentric. It was revived in the Middle Ages by Jean Buridan. Heraclides Ponticus was once thought to have proposed that both Venus and Mercury went around the Sun rather than the Earth, but this is no longer accepted.[38] Martianus Capella definitely put Mercury and Venus in orbit around the Sun.[39] Aristarchus of Samos was the most radical. He wrote a work, which has not survived, on heliocentrism, saying that the Sun was at the center of the universe, while the Earth and other planets revolved around it.[40] His theory was not popular, and he had one named follower, Seleucus of Seleucia.[41]\\r\\nIn 1543, the geocentric system met its first serious challenge with the publication of Copernicus' De revolutionibus orbium coelestium (On the Revolutions of the Heavenly Spheres), which posited that the Earth and the other planets instead revolved around the Sun. The geocentric system was still held for many years afterwards, as at the time the Copernican system did not offer better predictions than the geocentric system, and it posed problems for both natural philosophy and scripture. The Copernican system was no more accurate than Ptolemy's system, because it still used circular orbits. This was not altered until Johannes Kepler postulated that they were elliptical (Kepler's first law of planetary motion).\\r\\nWith the invention of the telescope in 1609, observations made by Galileo Galilei (such as that Jupiter has moons) called into question some of the tenets of geocentrism but did not seriously threaten it. Because he observed dark \\"spots\\" on the moon, craters, he remarked that the moon was not a perfect celestial body as had been previously conceived. This was the first time someone could see imperfections on a celestial body that was supposed to be composed of perfect aether. As such, because the moon's imperfections could now be related to those seen on Earth, one could argue that neither was unique: rather, they were both just celestial bodies made from Earth-like material. Galileo could also see the moons of Jupiter, which he dedicated to Cosimo II de' Medici, and stated that they orbited around Jupiter, not Earth.[42] This was a significant claim as it would mean not only that not everything revolved around Earth as stated in the Ptolemaic model, but also showed a secondary celestial body could orbit a moving celestial body, strengthening the heliocentric argument that a moving Earth could retain the Moon.[43] Galileo's observations were verified by other astronomers of the time period who quickly adopted use of the telescope, including Christoph Scheiner, Johannes Kepler, and Giovan Paulo Lembo.[44]\\r\\nIn December 1610, Galileo Galilei used his telescope to observe that Venus showed all phases, just like the Moon. He thought that while this observation was incompatible with the Ptolemaic system, it was a natural consequence of the heliocentric system.\\r\\nHowever, Ptolemy placed Venus' deferent and epicycle entirely inside the sphere of the Sun (between the Sun and Mercury), but this was arbitrary; he could just as easily have swapped Venus and Mercury and put them on the other side of the Sun, or made any other arrangement of Venus and Mercury, as long as they were always near a line running from the Earth through the Sun, such as placing the center of the Venus epicycle near the Sun. In this case, if the Sun is the source of all the light, under the Ptolemaic system:\\r\\nIf Venus is between Earth and the Sun, the phase of Venus must always be crescent or all dark.\\r\\nIf Venus is beyond the Sun, the phase of Venus must always be gibbous or full.\\r\\nBut Galileo saw Venus at first small and full, and later large and crescent.\\r\\nThis showed that with a Ptolemaic cosmology, the Venus epicycle can be neither completely inside nor completely outside of the orbit of the Sun. As a result, Ptolemaics abandoned the idea that the epicycle of Venus was completely inside the Sun, and later 17th century competition between astronomical cosmologies focused on variations of Tycho Brahe's Tychonic system (in which the Earth was still at the center of the universe, and around it revolved the Sun, but all other planets revolved around the Sun in one massive set of epicycles), or variations on the Copernican system.\\r\\nJohannes Kepler analysed Tycho Brahe's famously accurate observations and afterwards constructed his three laws in 1609 and 1619, based on a heliocentric view where the planets move in elliptical paths. Using these laws, he was the first astronomer to successfully predict a transit of Venus (for the year 1631). The change from circular orbits to elliptical planetary paths dramatically improved the accuracy of celestial observations and predictions. Because the heliocentric model by Copernicus was no more accurate than Ptolemy's system, new observations were needed to persuade those who still held on to the geocentric model. However, Kepler's laws based on Brahe's data became a problem which geocentrists could not easily overcome.\\r\\nIn 1687, Isaac Newton stated the law of universal gravitation, described earlier as a hypothesis by Robert Hooke and others. His main achievement was to mathematically derive Kepler's laws of planetary motion from the law of gravitation, thus helping to prove the latter. This introduced gravitation as the force that both kept the Earth and planets moving through the heavens and also kept the air from flying away. The theory of gravity allowed scientists to construct a plausible heliocentric model for the solar system quickly. In his Principia, Newton explained his system of how gravity, previously thought of as an occult force (that is, an unexplained force), directed the movements of celestial bodies, and kept our solar system in its working order. His descriptions of centripetal force[45] were a breakthrough in scientific thought which used the newly developed differential calculus, and finally replaced the previous schools of scientific thought, i.e. those of Aristotle and Ptolemy. However, the process was gradual.\\r\\nSeveral empirical tests of Newton's theory, explaining the longer period of oscillation of a pendulum at the equator and the differing size of a degree of latitude, gradually became available over the period 1673ÿ1738. In addition, stellar aberration was observed by Robert Hooke in 1674 and tested in a series of observations by Jean Picard over ten years finishing in 1680. However, it was not explained until 1729 when James Bradley provided an approximate explanation in terms of the Earth's revolution about the sun.\\r\\nIn 1838, astronomer Friedrich Wilhelm Bessel measured the parallax of the star 61 Cygni successfully, and disproved Ptolemy's claim that parallax motion did not exist. This finally confirmed the assumptions made by Copernicus, provided accurate, dependable scientific observations, and displayed truly how far away stars were from Earth.\\r\\nA geocentric frame is useful for many everyday activities and most laboratory experiments, but is a less appropriate choice for solar-system mechanics and space travel. While a heliocentric frame is most useful in those cases, galactic and extra-galactic astronomy is easier if the sun is treated as neither stationary nor the center of the universe, but rotating around the center of our galaxy, and in turn our galaxy is also not at rest in the cosmic background.\\r\\nAlbert Einstein and Leopold Infeld wrote in The Evolution of Physics (1938): \\"Can we formulate physical laws so that they are valid for all CS (=coordinate systems), not only those moving uniformly, but also those moving quite arbitrarily, relative to each other? If this can be done, our difficulties will be over. We shall then be able to apply the laws of nature to any CS. The struggle, so violent in the early days of science, between the views of Ptolemy and Copernicus would then be quite meaningless. Either CS could be used with equal justification. The two sentences, 'the sun is at rest and the Earth moves', or 'the sun moves and the Earth is at rest', would simply mean two different conventions concerning two different CS. Could we build a real relativistic physics valid in all CS; a physics in which there would be no place for absolute, but only for relative, motion? This is indeed possible!\\"[46]\\r\\nDespite giving more respectability to the geocentric view than Newtonian physics does,[47] relativity is not geocentric. Rather, relativity states that the Sun, the Earth, the Moon, Jupiter, or any other point for that matter could be chosen as a center of the solar system with equal validity.[48] For this reason Robert Sungenis, a modern geocentrist, spent much of Volume I of his book Galileo Was Wrong: The Church Was Right critiquing and trying to unravel the Special and General theories of Relativity.[49]\\r\\nRelativity agrees with Newtonian predictions that regardless of whether the Sun or the Earth are chosen arbitrarily as the center of the coordinate system describing the solar system, the paths of the planets form (roughly) ellipses with respect to the Sun, not the Earth. With respect to the average reference frame of the fixed stars, the planets do indeed move around the Sun, which due to its much larger mass, moves far less than its own diameter and the gravity of which is dominant in determining the orbits of the planets. (In other words, the center of mass of the solar system is near the center of the Sun.) The Earth and Moon are much closer to being a binary planet; the center of mass around which they both rotate is still inside the Earth, but is about 4,624?km (2,873?mi) or 72.6% of the Earth's radius away from the centre of the Earth (thus closer to the surface than the center).[citation needed]\\r\\nWhat the principle of relativity points out is that correct mathematical calculations can be made regardless of the reference frame chosen, and these will all agree with each other as to the predictions of actual motions of bodies with respect to each other. It is not necessary to choose the object in the solar system with the largest gravitational field as the center of the coordinate system in order to predict the motions of planetary bodies, though doing so may make calculations easier to perform or interpret. A geocentric coordinate system can be more convenient when dealing only with bodies mostly influenced by the gravity of the Earth (such as artificial satellites and the Moon), or when calculating what the sky will look like when viewed from Earth (as opposed to an imaginary observer looking down on the entire solar system, where a different coordinate system might be more convenient).\\r\\nThe Ptolemaic model of the solar system held sway into the early modern age; from the late 16th century onward it was gradually replaced as the consensus description by the heliocentric model. Geocentrism as a separate religious belief, however, never completely died out. In the United States between 1870 and 1920, for example, various members of the Lutheran ChurchÿMissouri Synod published articles disparaging Copernican astronomy, and geocentrism was widely taught within the synod during that period.[50] However, in the 1902 Theological Quarterly, A. L. Graebner claimed that the synod had no doctrinal position on geocentrism, heliocentrism, or any scientific model, unless it were to contradict Scripture. He stated that any possible declarations of geocentrists within the synod did not set the position of the church body as a whole.[51]\\r\\nArticles arguing that geocentrism was the biblical perspective appeared in some early creation science newsletters pointing to some passages in the Bible, which, when taken literally, indicate that the daily apparent motions of the Sun and the Moon are due to their actual motions around the Earth rather than due to the rotation of the Earth about its axis. For example, in Joshua 10:12, the Sun and Moon are said to stop in the sky, and in Psalms the world is described as immobile.[52] Psalms 93:1 says in part \\"the world is established, firm and secure\\".) Contemporary advocates for such religious beliefs include Robert Sungenis (president of Bellarmine Theological Forum and author of the 2006 book Galileo Was Wrong).[53] These people subscribe to the view that a plain reading of the Bible contains an accurate account of the manner in which the universe was created and requires a geocentric worldview. Most contemporary creationist organizations reject such perspectives.[n 10]\\r\\nAfter all, Copernicanism was the first major victory of science over religion, so it's inevitable that some folks would think that everything that's wrong with the world began there.\\r\\nMorris Berman quotes a 2006 survey that show currently some 20% of the U.S. population believe that the sun goes around the Earth (geocentricism) rather than the Earth goes around the sun (heliocentricism), while a further 9% claimed not to know.[56] Polls conducted by Gallup in the 1990s found that 16% of Germans, 18% of Americans and 19% of Britons hold that the Sun revolves around the Earth.[57] A study conducted in 2005 by Jon D. Miller of Northwestern University, an expert in the public understanding of science and technology,[58] found that about 20%, or one in five, of American adults believe that the Sun orbits the Earth.[59] According to 2011 VTSIOM poll, 32% of Russians believe that the Sun orbits the Earth.[60]\\r\\nThe famous Galileo affair pitted the geocentric model against the claims of Galileo. In regards to the theological basis for such an argument, two Popes addressed the question of whether the use of phenomenological language would compel one to admit an error in Scripture. Both taught that it would not. Pope Leo XIII (1878ÿ1903) wrote:\\r\\nwe have to contend against those who, making an evil use of physical science, minutely scrutinize the Sacred Book in order to detect the writers in a mistake, and to take occasion to vilify its contents. ... There can never, indeed, be any real discrepancy between the theologian and the physicist, as long as each confines himself within his own lines, and both are careful, as St. Augustine warns us, \\"not to make rash assertions, or to assert what is not known as known\\". If dissension should arise between them, here is the rule also laid down by St. Augustine, for the theologian: \\"Whatever they can really demonstrate to be true of physical nature, we must show to be capable of reconciliation with our Scriptures; and whatever they assert in their treatises which is contrary to these Scriptures of ours, that is to Catholic faith, we must either prove it as well as we can to be entirely false, or at all events we must, without the smallest hesitation, believe it to be so.\\" To understand how just is the rule here formulated we must remember, first, that the sacred writers, or to speak more accurately, the Holy Ghost \\"Who spoke by them, did not intend to teach men these things (that is to say, the essential nature of the things of the visible universe), things in no way profitable unto salvation.\\" Hence they did not seek to penetrate the secrets of nature, but rather described and dealt with things in more or less figurative language, or in terms which were commonly used at the time, and which in many instances are in daily use at this day, even by the most eminent men of science. Ordinary speech primarily and properly describes what comes under the senses; and somewhat in the same way the sacred writers-as the Angelic Doctor also reminds us ÿ \\"went by what sensibly appeared\\", or put down what God, speaking to men, signified, in the way men could understand and were accustomed to.\\r\\nMaurice Finocchiaro, author of a book on the Galileo affair, notes that this is \\"a view of the relationship between biblical interpretation and scientific investigation that corresponds to the one advanced by Galileo in the \\"Letter to the Grand Duchess Christina\\".[61] Pope Pius XII (1939ÿ1958) repeated his predecessor's teaching:\\r\\nThe first and greatest care of Leo XIII was to set forth the teaching on the truth of the Sacred Books and to defend it from attack. Hence with grave words did he proclaim that there is no error whatsoever if the sacred writer, speaking of things of the physical order \\"went by what sensibly appeared\\" as the Angelic Doctor says, speaking either \\"in figurative language, or in terms which were commonly used at the time, and which in many instances are in daily use at this day, even among the most eminent men of science\\". For \\"the sacred writers, or to speak more accurately ÿ the words are St. Augustine's ÿ the Holy Spirit, Who spoke by them, did not intend to teach men these things ÿ that is the essential nature of the things of the universe ÿ things in no way profitable to salvation\\"; which principle \\"will apply to cognate sciences, and especially to history\\", that is, by refuting, \\"in a somewhat similar way the fallacies of the adversaries and defending the historical truth of Sacred Scripture from their attacks\\".\\r\\nIn 1664, Pope Alexander VII republished the Index Librorum Prohibitorum (List of Prohibited Books) and attached the various decrees connected with those books, including those concerned with heliocentrism. He stated in a Papal Bull that his purpose in doing so was that \\"the succession of things done from the beginning might be made known [quo rei ab initio gestae series innotescat]\\".[62]\\r\\nThe position of the curia evolved slowly over the centuries towards permitting the heliocentric view. In 1757, during the papacy of Benedict XIV, the Congregation of the Index withdrew the decree which prohibited all books teaching the Earth's motion, although the Dialogue and a few other books continued to be explicitly included. In 1820, the Congregation of the Holy Office, with the pope's approval, decreed that Catholic astronomer Giuseppe Settele was allowed to treat the Earth's motion as an established fact and removed any obstacle for Catholics to hold to the motion of the Earth:\\r\\nThe Assessor of the Holy Office has referred the request of Giuseppe Settele, Professor of Optics and Astronomy at La Sapienza University, regarding permission to publish his work Elements of Astronomy in which he espouses the common opinion of the astronomers of our time regarding the Earths daily and yearly motions, to His Holiness through Divine Providence, Pope Pius VII. Previously, His Holiness had referred this request to the Supreme Sacred Congregation and concurrently to the consideration of the Most Eminent and Most Reverend General Cardinal Inquisitor. His Holiness has decreed that no obstacles exist for those who sustain Copernicus' affirmation regarding the Earth's movement in the manner in which it is affirmed today, even by Catholic authors. He has, moreover, suggested the insertion of several notations into this work, aimed at demonstrating that the above mentioned affirmation [of Copernicus], as it has come to be understood, does not present any difficulties; difficulties that existed in times past, prior to the subsequent astronomical observations that have now occurred. [Pope Pius VII] has also recommended that the implementation [of these decisions] be given to the Cardinal Secretary of the Supreme Sacred Congregation and Master of the Sacred Apostolic Palace. He is now appointed the task of bringing to an end any concerns and criticisms regarding the printing of this book, and, at the same time, ensuring that in the future, regarding the publication of such works, permission is sought from the Cardinal Vicar whose signature will not be given without the authorization of the Superior of his Order.[63]\\r\\nIn 1822, the Congregation of the Holy Office removed the prohibition on the publication of books treating of the Earth's motion in accordance with modern astronomy and Pope Pius VII ratified the decision:\\r\\nThe most excellent [cardinals] have decreed that there must be no denial, by the present or by future Masters of the Sacred Apostolic Palace, of permission to print and to publish works which treat of the mobility of the Earth and of the immobility of the sun, according to the common opinion of modern astronomers, as long as there are no other contrary indications, on the basis of the decrees of the Sacred Congregation of the Index of 1757 and of this Supreme [Holy Office] of 1820; and that those who would show themselves to be reluctant or would disobey, should be forced under punishments at the choice of [this] Sacred Congregation, with derogation of [their] claimed privileges, where necessary.[64]\\r\\nThe 1835 edition of the Catholic Index of Prohibited Books for the first time omits the Dialogue from the list.[61] In his 1921 papal encyclical, In praeclara summorum, Pope Benedict XV stated that, \\"though this Earth on which we live may not be the center of the universe as at one time was thought, it was the scene of the original happiness of our first ancestors, witness of their unhappy fall, as too of the Redemption of mankind through the Passion and Death of Jesus Christ\\".[65] In 1965 the Second Vatican Council stated that, \\"Consequently, we cannot but deplore certain habits of mind, which are sometimes found too among Christians, which do not sufficiently attend to the rightful independence of science and which, from the arguments and controversies they spark, lead many minds to conclude that faith and science are mutually opposed.\\"[66] The footnote on this statement is to Msgr. Pio Paschini's, Vita e opere di Galileo Galilei, 2 volumes, Vatican Press (1964). Pope John Paul II regretted the treatment which Galileo received, in a speech to the Pontifical Academy of Sciences in 1992. The Pope declared the incident to be based on a \\"tragic mutual miscomprehension\\". He further stated:\\r\\nCardinal Poupard has also reminded us that the sentence of 1633 was not irreformable, and that the debate which had not ceased to evolve thereafter, was closed in 1820 with the imprimatur given to the work of Canon Settele. ... The error of the theologians of the time, when they maintained the centrality of the Earth, was to think that our understanding of the physical world's structure was, in some way, imposed by the literal sense of Sacred Scripture. Let us recall the celebrated saying attributed to Baronius \\"Spiritui Sancto mentem fuisse nos docere quomodo ad coelum eatur, non quomodo coelum gradiatur\\". In fact, the Bible does not concern itself with the details of the physical world, the understanding of which is the competence of human experience and reasoning. There exist two realms of knowledge, one which has its source in Revelation and one which reason can discover by its own power. To the latter belong especially the experimental sciences and philosophy. The distinction between the two realms of knowledge ought not to be understood as opposition.[67]\\r\\nA few Orthodox Jewish leaders maintain a geocentric model of the universe based on the aforementioned Biblical verses and an interpretation of Maimonides to the effect that he ruled that the Earth is orbited by the sun.[68][69] The Lubavitcher Rebbe also explained that geocentrism is defensible based on the theory of Relativity, which establishes that \\"when two bodies in space are in motion relative to one another, ... science declares with absolute certainty that from the scientific point of view both possibilities are equally valid, namely that the Earth revolves around the sun, or the sun revolves around the Earth\\", although he also went on to refer to people who believed in geocentrism as \\"remaining in the world of Copernicus\\".[70]\\r\\nThe Zohar states: \\"The entire world and those upon it, spin round in a circle like a ball, both those at the bottom of the ball and those at the top. All God's creatures, wherever they live on the different parts of the ball, look different (in color, in their features) because the air is different in each place, but they stand erect as all other human beings, therefore, there are places in the world where, when some have light, others have darkness; when some have day, others have night.\\"[71]\\r\\nWhile geocentrism is important in Maimonides' calendar calculations,[72] the great majority of Jewish religious scholars, who accept the divinity of the Bible and accept many of his rulings as legally binding, do not believe that the Bible or Maimonides command a belief in geocentrism.[69][73]\\r\\nProminent cases of modern geocentrism in Islam are very isolated. Very few individuals promoted a geocentric view of the universe. One of them was Ahmed Raza Khan Barelvi, a Sunni scholar of Indian subcontinent. He rejected the heliocentric model and wrote a book[74] that explains the movement of the sun, moon and other planets around the Earth. The Grand Mufti of Saudi Arabia from 1993 to 1999, Ibn Baz also promoted the geocentric view between 1966 and 1985.\\r\\nThe geocentric (Ptolemaic) model of the solar system is still of interest to planetarium makers, as, for technical reasons, a Ptolemaic-type motion for the planet light apparatus has some advantages over a Copernican-type motion.[75] The celestial sphere, still used for teaching purposes and sometimes for navigation, is also based on a geocentric system[76] which in effect ignores parallax. However this effect is negligible at the scale of accuracy that applies to a planetarium.\\r\\nAll Islamic astronomers from Thabit ibn Qurra in the ninth century to Ibn al-Shatir in the fourteenth, and all natural philosophers from al-Kindi to Averroes and later, are known to have accepted ... the Greek picture of the world as consisting of two spheres of which one, the celestial sphere ... concentrically envelops the other.","input":"Who was the first person to suggest a geocentric universe?"},{"output":"P. T. Barnum","context":"Johanna Maria \\"Jenny\\" Lind (6 October 1820?ÿ 2 November 1887) was a Swedish opera singer, often known as the \\"Swedish Nightingale\\". One of the most highly regarded singers of the 19th century, she performed in soprano roles in opera in Sweden and across Europe, and undertook an extraordinarily popular concert tour of America beginning in 1850. She was a member of the Royal Swedish Academy of Music from 1840.\\r\\nLind became famous after her performance in Der Freischtz in Sweden in 1838. Within a few years, she had suffered vocal damage, but the singing teacher Manuel Garca saved her voice. She was in great demand in opera roles throughout Sweden and northern Europe during the 1840s, and was closely associated with Felix Mendelssohn. After two acclaimed seasons in London, she announced her retirement from opera at the age of 29.\\r\\nIn 1850, Lind went to America at the invitation of the showman P. T. Barnum. She gave 93 large-scale concerts for him and then continued to tour under her own management. She earned more than $350,000 from these concerts, donating the proceeds to charities, principally the endowment of free schools in Sweden. With her new husband, Otto Goldschmidt, she returned to Europe in 1852 where she had three children and gave occasional concerts over the next two decades, settling in England in 1855. From 1882, for some years, she was a professor of singing at the Royal College of Music in London.\\r\\n\\r\\n\\r\\nBorn in Klara, in central Stockholm, Lind was the illegitimate daughter of Niclas Jonas Lind (1798ÿ1858), a bookkeeper, and Anne-Marie Fellborg (1793ÿ1856), a schoolteacher.[1] Lind's mother had divorced her first husband for adultery but, for religious reasons, refused to remarry until after his death in 1834. Lind's parents married when she was 14.[1]\\r\\nLind's mother ran a day school for girls out of her home. When Lind was about 9, her singing was overheard by the maid of Mademoiselle Lundberg, the principal dancer at the Royal Swedish Opera.[1] The maid, astounded by Lind's extraordinary voice, returned the next day with Lundberg, who arranged an audition and helped her gain admission to the acting school of the Royal Dramatic Theatre, where she studied with Karl Magnus Craelius, the singing master at the theatre.[2]\\r\\nLind began to sing onstage when she was 10. She had a vocal crisis at the age of 12 and had to stop singing for a time, but she recovered.[2] Her first great role was Agathe in Weber's Der Freischtz in 1838 at the Royal Swedish Opera.[1] At 20, she was a member of the Royal Swedish Academy of Music and court singer to the King of Sweden and Norway. Her voice became seriously damaged by overuse and untrained singing technique, but her career was saved by the singing teacher Manuel Garca with whom she studied in Paris from 1841 to 1843. He insisted that she should not sing at all for three months, to allow her vocal cords to recover, before he started to teach her a healthy and secure vocal technique.[1][2]\\r\\nAfter Lind had been with Garca for a year, the composer Giacomo Meyerbeer, an early and faithful admirer of her talent, arranged an audition for her at the Opra in Paris, but she was rejected. The biographer Francis Rogers concludes that Lind strongly resented the rebuff: when she became an international star, she always refused invitations to sing at the Paris Opra.[3] Lind returned to the Royal Swedish Opera, greatly improved as a singer by Garca's training. She toured Denmark where, in 1843, Hans Christian Andersen met and fell in love with her. Although the two became good friends, she did not reciprocate his romantic feelings. She is believed to have inspired three of his fairy tales: \\"Beneath the Pillar\\", \\"The Angel\\" and \\"The Nightingale\\".[4] He wrote, \\"No book or personality whatever has exerted a more ennobling influence on me, as a poet, than Jenny Lind. For me she opened the sanctuary of art.\\"[4] The biographer Carol Rosen believes that after Lind rejected Andersen as a suitor, he portrayed her as The Snow Queen with a heart of ice.[1]\\r\\nIn December 1844, through Meyerbeer's influence, Lind was engaged to sing the title role in Bellini's opera Norma in Berlin.[3] That led to more engagements in opera houses throughout Germany and Austria, but such was her success in Berlin that she continued there for four months before she left for other cities.[2] Among her admirers were Robert Schumann, Hector Berlioz and, most importantly for her, Felix Mendelssohn. Ignaz Moscheles wrote: \\"Jenny Lind has fairly enchanted me... her song with two concertante flutes is perhaps the most incredible feat in the way of bravura singing that can possibly be heard\\".[5] That number, from Meyerbeer's Ein Feldlager in Schlesien (The Camp of Silesia, 1844, a role written for Lind but not premiered by her) became one of the songs most associated with Lind, and she was called on to sing it wherever she performed in concert.[1] Her operatic repertoire comprised the title roles in Lucia di Lammermoor, Maria di Rohan, Norma, La sonnambula and La vestale as well as Susanna in The Marriage of Figaro, Adina in L'elisir d'amore and Alice in Robert le diable. About that time, she became known as \\"the Swedish Nightingale\\". In December 1845, the day after her debut at the Leipzig Gewandhaus under the baton of Mendelssohn, she sang without fee for a charity concert in aid of the Orchestra Widows' Fund. Her devotion and generosity to charitable causes remained a key aspect of her career and greatly enhanced her international popularity even among the unmusical.[1]\\r\\nAt the Royal Swedish Opera, Lind had been friends with the tenor Julius Gnther. They sang together both in opera and on the concert stage and became romantically linked by 1844. Their schedules separated them, however, as Gnther remained in Stockholm and then became a student of Garcia's in Paris in 1846ÿ1847. After reuniting in Sweden, according to Lind's 1891 Memoir, they became engaged to marry in the spring of 1848, just before Lind returned to England. However, the two broke off the engagement in October of the same year.[6]\\r\\nAfter a successful season in Vienna, where she was mobbed by admirers and feted by the Imperial Family,[2] Lind traveled to London and gave her first performance there on 4 May 1847, when she appeared in an Italian version of Meyerbeer's Robert le Diable. It was attended by Queen Victoria; the next day, The Times wrote:\\r\\nWe have had frequent experience of the excitement appertaining to \\"first nights\\", but we may safely say, and our opinion will be backed by several hundreds of Her Majesty's subjects, that we never witnessed such a scene of enthusiasm as that displayed last night on the occasion of Mademoiselle Jenny Lind's dbut as Alice in an Italian version of Robert le Diable.[7]\\r\\nIn July 1847, she starred in the world premire of Verdi's opera I masnadieri at Her Majesty's Theatre, under the baton of the composer.[8] During her two years on the operatic stage in London, Lind appeared in most of the standard opera repertory.[3] In early 1849, still in her twenties, Lind announced her permanent retirement from opera. Her last opera performance was on 10 May 1849 in Robert le diable; Queen Victoria and other members of the Royal Family were present.[9] Lind's biographer Francis Rogers wrote, \\"The reasons for her early retirement have been much discussed for nearly a century, but remain today a matter of mystery. Many possible explanations have been advanced, but not one of them has been verified\\".[3]\\r\\nIn London, Lind's close friendship with Mendelssohn continued. There has been strong speculation that their relationship was more than friendship. Papers confirming that were alleged to exist, but their contents had not been made public.[10] However, in 2013, George Biddlecombe confirmed in the Journal of the Royal Musical Association that \\"The Committee of the Mendelssohn Scholarship Foundation possesses material indicating that Mendelssohn wrote passionate love letters to Jenny Lind entreating her to join him in an adulterous relationship and threatening suicide as a means of exerting pressure upon her, and that these letters were destroyed on being discovered after her death\\".[11]\\r\\nMendelssohn was present at Lind's London debut in Robert le Diable, and his friend, the critic Henry Fothergill Chorley, who was with him, wrote \\"I see as I write the smile with which Mendelssohn, whose enjoyment of Mdlle. Lind's talent was unlimited, turned round and looked at me, as if a load of anxiety had been taken off his mind. His attachment to Mademoiselle Lind's genius as a singer was unbounded, as was his desire for her success\\".[12] Mendelssohn worked with Lind on many occasions and wrote the beginnings of an opera, Lorelei, for her, based on the legend of the Lorelei Rhine maidens; the opera was unfinished at his death. He included a high F sharp in his oratorio Elijah (\\"Hear Ye Israel\\") with Lind's voice in mind.[13]\\r\\nFour months after her London debut, she was devastated by the premature death of Mendelssohn in November 1847. She did not at first feel able to sing the soprano part in Elijah, which he had written for her. She finally did so at a performance in London's Exeter Hall in late 1848, which raised S1,000 to fund a musical scholarship as a memorial to him; it was her first appearance in oratorio.[14] The original intention had been to found a school of music in Mendelssohn's name in Leipzig, but there was not enough support in Leipzig, and with the help of Sir George Smart, Julius Benedict and others, Lind eventually raised enough money to fund a scholarship \\"to receive pupils of all nations and promote their musical training\\".[14] The first recipient of the Mendelssohn Scholarship was the 14-year-old Arthur Sullivan, whom Lind encouraged in his career.[1]\\r\\nIn 1849, Lind was approached by the American showman P. T. Barnum with a proposal to tour throughout the United States for more than a year. Realising that it would yield large sums for her favoured charities, particularly the endowment of free schools in her native Sweden, Lind agreed. Her financial demands were stringent, but Barnum met them, and in 1850, they reached agreement.[3]\\r\\nTogether with a supporting baritone, Giovanni Belletti, and her London colleague, Julius Benedict, as pianist, arranger and conductor, Lind sailed to America in September 1850. Barnum's advance publicity made her a celebrity even before she arrived in the US, and she received a wild reception on arriving in New York. Tickets for some of her concerts were in such demand that Barnum sold them by auction. The enthusiasm of the public was so strong that the American press coined the term \\"Lind mania\\".[15]\\r\\nAfter New York, Lind's party toured the east coast of America, with continued success, and later took in Cuba, the Southern US and Canada. By early 1851, Lind had become uncomfortable with Barnum's relentless marketing of the tour, and she invoked a contractual right to sever her ties with him; they parted amicably. She continued the tour for nearly a year, under her own management, until May 1852. Benedict left the party in 1851 to return to England, and Lind invited Otto Goldschmidt to replace him as pianist and conductor.[3] Lind and Goldschmidt were married on February 5, 1852, near the end of the tour, in Boston. She took the name \\"Jenny Lind-Goldschmidt\\", both privately and professionally.\\r\\nDetails of the later concerts under her own management are scarce,[3] but it is known that under Barnum's management Lind gave 93 concerts in America for which she earned about $350,000, and he netted at least $500,000[16] ($9.97?million and $14.2?million, as of 2015, respectively).[17] She donated her profits to her chosen charities, including some US charities.[3][18] The tour is a plot point in the 1980 musical Barnum and the 2017 film The Greatest Showman, both of which include a fictionalized relationship between Lind and Barnum with \\"romantic undertones\\".[19]\\r\\nLind and Goldschmidt returned to Europe together in May 1852. They lived first in Dresden, Germany, and, from 1855, in England for the rest of their lives.[3] They had three children: Otto, born September 1853 in Germany, Jenny, born March 1857 in England, and Ernest, born January 1861 in England.[1]\\r\\nAlthough she refused all requests to appear in opera after her return to Europe, Lind continued to perform in the concert hall. In 1856, at the invitation of the Philharmonic Society conducted by William Sterndale Bennett, she sang the chief soprano part in the first English performance of the cantata Paradise and the Peri by Robert Schumann.[20] In 1866, she gave a concert with Arthur Sullivan at St James's Hall. The Times reported, \\"there is magic still in that voice... the most perfect singing ÿ perfect alike in expression and in vocalization.... Nothing more engaging, nothing more earnest, nothing more dramatic can be imagined.\\".[21] At Dsseldorf in January 1870, she sang in \\"Ruth\\", an oratorio composed by her husband.[1] When Goldschmidt formed the Bach Choir in 1875, Lind trained the soprano choristers for the first English performance of Bach's B minor Mass, in April 1876, and performed in the mass.[22] Her concerts decreased in frequency until she retired from singing in 1883.[3]\\r\\nIn 1879ÿ1887, Lind worked with Frederick Niecks on his biography of Frdric Chopin.[23] In 1882, she was appointed professor of singing at the newly founded Royal College of Music. She believed in an all-round musical training for her pupils, insisting that, in addition to their vocal studies, they were instructed in solfge, piano, harmony, diction, deportment and at least one foreign language.[24]\\r\\nShe lived her final years at Wynd's Point, Herefordshire, on the Malvern Hills near the British Camp. Her last public appearance was at a charity concert at Royal Malvern Spa in 1883.[1] She died, at 67, at Wynd's Point on 2 November 1887 and was buried in the Great Malvern Cemetery to the music of Chopin's Funeral March. She bequeathed a considerable part of her wealth to help poor Protestant students in Sweden receive an education.[1]\\r\\nThere are no recordings of Lind's voice. She is believed to have made an early phonograph recording for Thomas Edison, but in the words of the critic Philip L. Miller, \\"Even had the fabled Edison cylinder survived, it would have been too primitive, and she too long retired, to tell us much\\".[25] The biographer Francis Rogers concludes that although Lind was much admired by Meyerbeer, Mendelssohn, the Schumanns, Berlioz and others, \\"In voice and in dramatic talent she was undoubtedly inferior to her predecessors, Malibran and Pasta, and to her contemporaries, Sontag and Grisi.\\"[3] He notes that because of her expert promoters, including Barnum, \\"almost all that was written about her was undoubtedly biased by an almost overwhelming propaganda in her favor, bought and paid for\\".[3] Rogers says of Mendelssohn and Lind's other admirers that their tastes were \\"essentially Teutonic\\" and, except for Meyerbeer, they were not expert in Italian opera, Lind's early specialty. He quotes a critic of the New York Herald, who noted \\"little deficiencies in execution, in ascending the scale, which even enthusiasm cannot deprive of their sharpness\\".[3] The American press agreed that Lind's presentation was more typical of Germanic \\"cold, untouching, icy purity of tone and style\\", rather than the passionate expression necessary for Italian opera, and the Herald wrote that her style was \\"suited to please the people of our cold climate. She will have triumphs here that would never attend her progress through France or Italy\\".[3]\\r\\nThe critic H. F. Chorley, who admired Lind, described her voice as having \\"two octaves in compass ÿ from D to D ÿ having a higher possible note or two, available on rare occasions;[n 1] and that the lower half of the register and the upper one were of two distinct qualities. The former was not strong ÿ veiled, if not husky; and apt to be out of tune. The latter was rich, brilliant and powerful ÿ finest in its highest portions.\\"[26] Chorley praised her breath management, her use of pianissimo, her taste in ornament and her intelligent use of technique to conceal the differences between her upper and lower registers. He thought her \\"execution was great\\" and that she was a \\"skilled and careful musician\\" but felt that \\"many of her effects on the stage appeared overcalculated\\" and that singing in foreign languages impeded her ability to give expression to the text. He felt, however, that her concert singing was more admirable than her operatic performances, but he praised some of her roles.[3][n 2] Chorley judged her finest work to be in the German repertoire, citing Mozart, Haydn and Mendelssohn's Elijah as best suited to her.[26] Miller concluded that although connoisseurs of the voice preferred other singers, her wider appeal to the public at large was not merely a legend created by Barnum but was a mixture of \\"a uniquely pure (some called it celestial) quality in her voice, consistent with her well-known generosity and charity\\".[25]\\r\\nLind is commemorated in Poets' Corner, Westminster Abbey, London under the name \\"Jenny Lind-Goldschmidt\\". Among those present at the memorial's unveiling ceremony on 20 April 1894 were Goldschmidt, members of the Royal Family, Sullivan, Sir George Grove and representatives of some of the charities supported by Lind.[27] There is also a plaque commemorating Lind in The Boltons, Kensington, London[28] and a blue plaque at 189 Old Brompton Road, London, SW7, which was erected in 1909.[29]\\r\\nLind has been commemorated in music, on screen and even on banknotes. Both the 1996 and 2006 issues of the Swedish 50-krona banknote bear a portrait of Lind on the front. Many artistic works have honoured or featured her. Anton Wallerstein composed the \\"Jenny Lind Polka\\" around 1850.[30] In the 1930 Hollywood film A Lady's Morals, Grace Moore starred as Lind, with Wallace Beery as Barnum.[31] In 1941 Ilse Werner starred as Lind in the German-language musical biography film The Swedish Nightingale. In 2001, a semibiographical film, Hans Christian Andersen: My Life as a Fairytale, featured Flora Montgomery as Lind. In 2005, Elvis Costello announced that he was writing an opera about Lind, called The Secret Arias with some lyrics by Andersen.[32] A 2010 BBC television documentary \\"Chopin ÿ The Women Behind the Music\\" includes discussion of Chopin's last years, during which Lind \\"so affected\\" the composer.[33]\\r\\nMany places and objects have been named for Lind, including Jenny Lind Island in Canada, the Jenny Lind locomotive and a clipper ship, the USS Nightingale. An Australian schooner was named Jenny Lind in her honour. In 1857, it was wrecked in a creek on the Queensland coast; the creek was accordingly named Jenny Lind Creek.[34]\\r\\nIn Britain, Goldschmidt's endowment of an infirmary for children in her memory in Norwich is perpetuated in its present form as the Jenny Lind Children's Hospital of the Norfolk and Norwich University Hospital.[35] There is a Jenny Lind Park in the same city.[36] A chapel is named for Lind at the University of Worcester City Campus[37] and in Andover, Illinois.[38] A hotel and pub is named after her in the Old Town of Hastings, East Sussex.[39] Hereford County Hospital has a psychiatric ward named for Jenny Lind.[40] A district in Glasgow is named after her.[41]\\r\\nIn the US, Lind is commemorated by street names in Fort Smith, Arkansas; New Bedford, Massachusetts; Taunton, Massachusetts; McKeesport, Pennsylvania; North Easton, Massachusetts; North Highlands, California and Stanhope, New Jersey; and in the name of the gold-rush town of Jenny Lind, California. An elementary school in Minneapolis, Minnesota is named after her.[42] She has been honoured since 1948 by the Barnum Festival, which takes place each June and July in Bridgeport, Connecticut. Through a national competition, the festival selects a soprano as the Jenny Lind winner. Her Swedish counterpart, chosen by the Royal Swedish Academy of Music and the People's Parks and Community Centre in Stockholm, visits during the festival, and the two perform several concerts together. In July, the American Jenny Lind winner traditionally travels to Sweden for a similar joint concert tour.[citation needed]\\r\\nA bronze statue of a seated Jenny Lind by Erik Rafael-R?dberg, dedicated in 1924, sits in the Framn?s section of Djurg?rden island in Stockholm (at 591945N 1868E? / ?59.32917N 18.10222E? / 59.32917; 18.10222).[43][44]\\r\\nNotes\\r\\nFootnotes\\r\\nSources","input":"Who introduced the swedish nightingale jenny lind to america?"},{"output":"between .260 and .275","context":"Batting average is a statistic in cricket, baseball, and softball that measures the performance of batsmen in cricket and batters in baseball. The development of the baseball statistic was influenced by the cricket statistic.[1]\\r\\n\\r\\n\\r\\nIn cricket, a player's batting average is the total number of runs they have scored divided by the number of times they have been out. Since the number of runs a player scores and how often they get out are primarily measures of their own playing ability, and largely independent of their teammates, batting average is a good metric for an individual player's skill as a batsman. The number is also simple to interpret intuitively. If all the batsman's innings were completed (i.e. they were out every innings), this is the average number of runs they score per innings. If they did not complete all their innings (i.e. some innings they finished not out), this number is an estimate of the unknown average number of runs they score per innings. Batting average has been used to gauge cricket players' relative skills since the 18th century.\\r\\nMost players have career batting averages in the range of 20 to 40. This is also the desirable range for wicket-keepers, though some fall short and make up for it with keeping skill. Until a substantial increase in scores in the 21st century due to improved bats and smaller grounds among other factors, players who sustained an average above 50 through a career were considered exceptional, and before the development of the heavy roller in the 1870s (which allowed for a flatter, safer cricket pitch) an average of 25 was considered very good.[2]\\r\\nCareer records for batting average are usually subject to a minimum qualification of 20 innings played or completed, in order to exclude batsmen who have not played enough games for their skill to be reliably assessed. Under this qualification, the highest Test batting average belongs to Australia's Sir Donald Bradman, with 99.94. Given that a career batting average over 50 is exceptional, and that only four other players have averages over 60, this is an outstanding statistic. The fact that Bradman's average is so far above that of any other cricketer has led several statisticians to argue that, statistically at least, he was the greatest sportsman in any sport.[3] As at 21 October 2016, Adam Voges of Australia has recorded an average of 72.75 from 27 innings played, but only 20 innings completed.\\r\\nBatting averages in One Day International (ODI) cricket tend to be lower than in Test cricket,[4] because of the need to score runs more quickly and take riskier strokes and the lesser emphasis on building a large innings. It should also be remembered, especially in relation to the ODI histogram above, that there were no ODI competitions when Bradman played.\\r\\nIf a batsman has been dismissed in every single innings, then their total number of runs scored divided by the number of times they have been out gives exactly the average number of runs they score per innings. However, for a batsman with innings which have finished not out, this statistic is only an estimate of the average number of runs they score per innings ÿ the true average number of runs they score per innings is unknown as it is not known how many runs they would have scored if they could have completed all their not out innings. If their scores have a geometric distribution then total number of runs scored divided by the number of times out is the maximum likelihood estimate of their true unknown average.[5]\\r\\nBatting averages can be strongly affected by the number of not outs. For example, Phil Tufnell, who was noted for his poor batting,[6] has an apparently respectable ODI average of 15 (from 20 games), despite a highest score of only 5 not out, as he scored an overall total of 15 runs from 10 innings, but was out only once.[7]\\r\\nA different, and more recently developed, statistic which is also used to gauge the effectiveness of batsmen is the strike rate. It measures a different concept however ÿ how quickly the batsman scores (number of runs from 100 balls) ÿ so it does not supplant the role of batting average. It is used particularly in limited overs matches, where the speed at which a batsman scores is more important than it is in first-class cricket.\\r\\n(Source: Cricinfo Statsguru 23 December 2016)\\r\\nTable shows players with at least 20 innings completed.\\r\\n* denotes not out.\\r\\nIn baseball, the batting average (BA) is defined by the number of hits divided by at bats. It is usually reported to three decimal places and read without the decimal: A player with a batting average of .300 is \\"batting three-hundred.\\" If necessary to break ties, batting averages could be taken beyond the .001 measurement. In this context, a .001 is considered a \\"point,\\" such that a .235 batter is 5 points higher than a .230 batter.\\r\\nHenry Chadwick, an English statistician raised on cricket, was an influential figure in the early history of baseball. In the late 19th century he adapted the concept behind the cricket batting average to devise a similar statistic for baseball. Rather than simply copy cricket's formulation of runs scored divided by outs, he realized that hits divided by at bats would provide a better measure of individual batting ability. This is because while in cricket, scoring runs is almost entirely dependent on one's own batting skill, in baseball it is largely dependent on having other good hitters on one's team. Chadwick noted that hits are independent of teammates' skills, so used this as the basis for the baseball batting average. His reason for using at bats rather than outs is less obvious, but it leads to the intuitive idea of the batting average being a percentage reflecting how often a batter gets on base, whereas in contrary, hits divided by outs is not as simple to interpret in real terms.\\r\\nIn modern times, a season batting average higher than .300 is considered to be excellent, and an average higher than .400 a nearly unachievable goal. The last player to do so, with enough plate appearances to qualify for the batting championship, was Ted Williams of the Boston Red Sox, who hit .406 in 1941, though the best modern players either threaten to or actually do achieve it occasionally, if only for brief periods of time. There have been numerous attempts to explain the disappearance of the .400 hitter, with one of the more rigorous discussions of this question appearing in Stephen Jay Gould's 1996 book Full House.\\r\\nTy Cobb holds the record for highest career batting average with .366, 9 points higher than Rogers Hornsby who has the second highest average in history at .358. The record for lowest career batting average for a player with more than 2,500 at-bats belongs to Bill Bergen, a catcher who played from 1901 to 1911 and recorded a .170 average in 3,028 career at-bats. The modern-era record for highest batting average for a season is held by Napoleon Lajoie, who hit .426 in 1901, the first year of play for the American League. The modern-era record for lowest batting average for a player that qualified for the batting title is held by Rob Deer, who hit .179 in 1991. While finishing six plate appearances short of qualifying for the batting title, Adam Dunn of the Chicago White Sox hit .159 for the 2011 season, twenty points (and 11.2%) lower than the record. The highest batting average for a rookie was .408 in 1911 by Shoeless Joe Jackson.\\r\\nFor non-pitchers, a batting average below .230 is often considered poor, and one below .200 is usually unacceptable. This latter level is sometimes referred to as \\"The Mendoza Line\\", named for Mario Mendoza (a lifetime .215 hitter), a stellar defensive shortstop whose defensive capabilities just barely made up for his offensive shortcomings. The league batting average in Major League Baseball for 2016 was .255,[9] and the all-time league average is between .260 and .275.\\r\\nIn rare instances, MLB players have concluded their careers with a perfect batting average of 1.000. John Paciorek had three hits in all three of his turns at bat. Esteban Yan went two-for-two, including a home run. Hal Deviney's two hits in his only plate appearances included a triple, while Steve Biras, Mike Hopkins, Chet Kehn, Jason Roach and Fred Schemanske also went two-for-two. A few dozen others have hit safely in their one and only career at-bat.\\r\\nSabermetrics, the study of baseball statistics, considers batting average a weak measure of performance because it does not correlate as well as other measures to runs scored, thereby causing it to have little predictive value. Batting average does not take into account walks or power, whereas other statistics such as on-base percentage and slugging percentage have been specifically designed to measure such concepts. Adding these statistics together form a player's On-base plus slugging or \\"OPS\\". This is commonly seen as a much better, though not perfect, indicator of a player's overall batting ability as it is a measure of hitting for average, hitting for power and drawing bases on balls.\\r\\nIn 1887, Major League Baseball counted bases on balls as hits. The result of this was skyrocketed batting averages, including some near .500, and the experiment was abandoned the following season.\\r\\nThe Major League Baseball batting averages championships (often referred to as \\"the batting title\\") is awarded annually to the player in each league who has the highest batting average. Ty Cobb holds the MLB (and American League) record for most batting titles, officially winning 11 in his pro career.[10] The National League record of 8 batting titles is shared by Honus Wagner and Tony Gwynn. Most of Cobb's career and all of Wagner's career took place in what is known as the Dead-Ball Era, which was characterized by higher batting averages and much less power, whereas Gwynn's career took place in the Live-Ball Era.\\r\\nTo determine which players are eligible to win the batting title, the following conditions have been used over the sport's history:[11]\\r\\nFrom 1967 to the present, if the player with the highest average in a league fails to meet the minimum plate-appearance requirement, the remaining at-bats until qualification (e.g., 5 ABs, if the player finished the season with 497 plate appearances) are hypothetically considered hitless at-bats; if his recalculated batting average still tops the league, he is awarded the title. This is officially called Rule 10.22(a), but it is also known as the Tony Gwynn rule because the Padres' legend won the batting crown in 1996 with a .353 average on just 498 plate appearances (i.e., was four shy). Gwynn was awarded the title since he would have led the league even if he'd gone 0-for-4 in those missing plate appearances. His average would have dropped to .349, five points better than second-place Ellis Burks' .344.[12] In 2012, a one-time amendment to the rule was made to disqualify Melky Cabrera from the title. Cabrera requested that he be disqualified after serving a suspension that season for a positive testosterone test. He had batted .346 with 501 plate appearances, and the original rule would have awarded him the title over San Francisco Giants teammate Buster Posey, who won batting .336.[13][14]\\r\\nNote: Batting averages are normally rounded to 3 decimal places. Extra detail here is used for tie-breaker.\\r\\nFollowing from usage in cricket and baseball, batting average has come to be used for other statistical measures of performance and in the general usage on how a person did in a wide variety of actions.\\r\\nAn example is the Internet Archive, which uses the term in ranking downloads. Its \\"batting average\\" indicates the correlation between views of a description page of a downloadable item, and the number of actual downloads of the item. This avoids the effect of popular downloads by volume swamping potentially more focused and useful downloads, producing an arguably more useful ranking.","input":"What is the average batting average in mlb?"},{"output":"Pataliputra (modern Patna)","context":"The Maurya Empire was a geographically extensive Iron Age historical power founded by Chandragupta Maurya which dominated ancient India between 322 BCE and 187 BCE. Extending into the kingdom of Magadha in the Indo-Gangetic Plain in the eastern side of the Indian subcontinent, the empire had its capital city at Pataliputra (modern Patna).[2][3] The empire was the largest to have ever existed in the Indian subcontinent, spanning over 5?million square kilometres (1.9?million square miles) at its zenith under Ashoka.\\r\\nChandragupta Maurya raised an army and with the assistance of Chanakya (also known as Kau?ilya),[4] overthrew the Nanda Empire in c.?322 BCE and rapidly expanded his power westwards across central and western India. By 317?BCE the empire had fully occupied Northwestern India, defeating and conquering the satraps left by Alexander the Great.[5] Chandragupta then defeated the invasion led by Seleucus I, a Macedonian general from Alexander's army, gaining additional territory west of the Indus River.[6]\\r\\nThe Maurya Empire was one of the largest empires of the world in its time. At its greatest extent, the empire stretched to the north along the natural boundaries of the Himalayas, to the east into Assam, to the west into Balochistan (southwest Pakistan and southeast Iran) and the Hindu Kush mountains of what is now Afghanistan.[7] The Empire was expanded into India's central and southern regions[8][9] by the emperors Chandragupta and Bindusara, but it excluded Kalinga (modern Odisha), until it was conquered by Ashoka.[10] It declined for about 50?years after Ashoka's rule ended, and it dissolved in 185?BCE with the foundation of the Shunga dynasty in Magadha.\\r\\nUnder Chandragupta Maurya and his successors, internal and external trade, agriculture, and economic activities all thrived and expanded across India thanks to the creation of a single and efficient system of finance, administration, and security. After the Kalinga War, the Empire experienced nearly half a century of peace and security under Ashoka. Mauryan India also enjoyed an era of social harmony, religious transformation, and expansion of the sciences and of knowledge. Chandragupta Maurya's embrace of Jainism increased social and religious renewal and reform across his society, while Ashoka's embrace of Buddhism has been said to have been the foundation of the reign of social and political peace and non-violence across all of India. Ashoka sponsored the spreading of Buddhist missionaries into Sri Lanka, Southeast Asia, West Asia, North Africa, and Mediterranean Europe.[11]\\r\\nThe population of the empire has been estimated to be about 50ÿ60 million, making the Mauryan Empire one of the most populous empires of Antiquity.[12][13] Archaeologically, the period of Mauryan rule in South Asia falls into the era of Northern Black Polished Ware (NBPW). The Arthashastra[14] and the Edicts of Ashoka are the primary sources of written records of Mauryan times. The Lion Capital of Ashoka at Sarnath has been made the national emblem of India.\\r\\n\\r\\n\\r\\nThe Maurya Empire was founded by Chandragupta Maurya, with help from Chanakya, at Takshashila. According to several legends, Chanakya travelled to Magadha, a kingdom that was large and militarily powerful and feared by its neighbours, but was insulted by its king Dhana Nanda, of the Nanda dynasty. Chanakya swore revenge and vowed to destroy the Nanda Empire.[15] Meanwhile, the conquering armies of Alexander the Great refused to cross the Beas River and advance further eastward, deterred by the prospect of battling Magadha. Alexander returned to Babylon and re-deployed most of his troops west of the Indus River. Soon after Alexander died in Babylon in 323?BCE, his empire fragmented into independent kingdoms led by his generals.[16]\\r\\nThe Greek generals Eudemus and Peithon ruled in the Indus Valley until around 317?BCE, when Chandragupta Maurya (with the help of Chanakya, who was now his advisor) orchestrated a rebellion to drive out the Greek governors, and subsequently brought the Indus Valley under the control of his new seat of power in Magadha.[5]\\r\\nChandragupta Maurya's rise to power is shrouded in mystery and controversy. On one hand, a number of ancient Indian accounts, such as the drama Mudrarakshasa (Signet ring of Rakshasa ÿ Rakshasa was the prime minister of Magadha) by Vishakhadatta, describe his royal ancestry and even link him with the Nanda family. A kshatriya clan known as the Maurya's are referred to in the earliest Buddhist texts, Mahaparinibbana Sutta. However, any conclusions are hard to make without further historical evidence. Chandragupta first emerges in Greek accounts as \\"Sandrokottos\\". As a young man he is said to have met Alexander.[17] He is also said to have met the Nanda king, angered him, and made a narrow escape.[18] Chanakya's original intentions were to train a guerilla army under Chandragupta's command.\\r\\nChanakya encouraged Chandragupta Maurya and his army to take over the throne of Magadha. Using his intelligence network, Chandragupta gathered many young men from across Magadha and other provinces, men upset over the corrupt and oppressive rule of king Dhana Nanda, plus the resources necessary for his army to fight a long series of battles. These men included the former general of Taxila, accomplished students of Chanakya, the representative of King Parvataka, his son Malayaketu, and the rulers of small states. The Macedonians (described as Yona or Yavana in Indian sources) may then have participated, together with other groups, in the armed uprising of Chandragupta Maurya against the Nanda dynasty. The Mudrarakshasa of Visakhadutta as well as the Jaina work Parisishtaparvan talk of Chandragupta's alliance with the Himalayan king Parvataka, often identified with Porus,[19][20] although this identification is not accepted by all historians.[21] This Himalayan alliance gave Chandragupta a composite and powerful army made up of Yavanas (Greeks), Kambojas, Shakas (Scythians), Kiratas (Himalayans), Parasikas (Persians) and Bahlikas (Bactrians) who took Pataliputra (also called Kusumapura, \\"The City of Flowers\\"):[22][23]\\r\\nPreparing to invade Pataliputra, Maurya came up with a strategy. A battle was announced and the Magadhan army was drawn from the city to a distant battlefield to engage with Maurya's forces. Maurya's general and spies meanwhile bribed the corrupt general of Nanda. He also managed to create an atmosphere of civil war in the kingdom, which culminated in the death of the heir to the throne. Chanakya managed to win over popular sentiment. Ultimately Nanda resigned, handing power to Chandragupta, and went into exile and was never heard of again. Chanakya contacted the prime minister, Rakshasas, and made him understand that his loyalty was to Magadha, not to the Nanda dynasty, insisting that he continue in office. Chanakya also reiterated that choosing to resist would start a war that would severely affect Magadha and destroy the city. Rakshasa accepted Chanakya's reasoning, and Chandragupta Maurya was legitimately installed as the new King of Magadha. Rakshasa became Chandragupta's chief advisor, and Chanakya assumed the position of an elder statesman.\\r\\nThe approximate extent of the Magadha state in the 5th century BCE.\\r\\nThe Maurya Empire when it was first founded by Chandragupta Maurya c. 320?BCE, after conquering the Nanda Empire when he was only about 20?years old.\\r\\nChandragupta extended the borders of the Maurya Empire towards Seleucid Persia after defeating Seleucus c. 305?BCE.[25]\\r\\nBindusara extended the borders of the empire southward into the Deccan Plateau c. 300?BCE.[26]\\r\\nAshoka extended into Kalinga during the Kalinga War c. 265?BCE, and established superiority over the southern kingdoms.\\r\\nHermann Kulke and Dietmar Rothermund believe that Ashoka's empire did not include large parts of India, which were controlled by autonomous tribes.[27]\\r\\nIn 305 BCE, Chandragupta led a series of campaigns to retake the satrapies left behind by Alexander the Great when he returned westwards, while Seleucus I Nicator fought to defend these territories. The two rulers concluded a peace treaty in 303 BCE, including a marital alliance. Chandragupta snatched the satrapies of Paropamisade (Kamboja and Gandhara), Arachosia (Kandhahar) and Gedrosia (Balochistan), and Seleucus I Nicator received 500 war elephants that were to have a decisive role in his victory against western Hellenistic kings at the Battle of Ipsus in 301?BCE. Diplomatic relations were established and several Greeks, such as the historian Megasthenes, Deimakos and Dionysius resided at the Mauryan court. Megasthenes in particular was a notable Greek ambassador in the court of Chandragupta Maurya.[28] According to Arrian, ambassador Megasthenes (c.350ÿc.290 BCE) lived in Arachosia and travelled to Pataliputra.[29]\\r\\nChandragupta established a strong centralized state with an administration at Pataliputra, which, according to Megasthenes, was \\"surrounded by a wooden wall pierced by 64 gates and 570 towers\\". Aelian, although not expressly quoting Megasthenes nor mentionning Pataliputra, described Indian palaces as superior in splendor to Persia's Susa or Ectabana.[30] The architecture of the city seems to have had many similarities with Persian cities of the period.[31]\\r\\nChandragupta's son Bindusara extended the rule of the Mauryan empire towards southern India. The famous Tamil poet Mamulanar of the Sangam literature described how the Deccan Plateau was invaded by the Maurya army.[32] He also had a Greek ambassador at his court, named Megasthenes.[33]\\r\\nMegasthenes describes a disciplined multitude under Chandragupta, who live simply, honestly, and do not know writing:\\r\\nChandragupta renounced his throne and followed Jain teacher Bhadrabahu.[34][35][36] He is said to have lived as an ascetic at Shravanabelagola for several years before fasting to death, as per the Jain practice of sallekhana.[37]\\r\\nBindusara was born to Chandragupta, the founder of the Mauryan Empire. This is attested by several sources, including the various Puranas and the Mahavamsa.[38] He is attested by the Buddhist texts such as Dipavamsa and Mahavamsa (\\"Bindusaro\\"); the Jain texts such as Parishishta-Parvan; as well as the Hindu texts such as Vishnu Purana (\\"Vindusara\\").[39][40] According to the 12th century Jain writer Hemachandra's Parishishta-Parvan, the name of Bindusara's mother was Durdhara.[41] Some Greek sources also mention him by the name \\"Amitrochates\\" or its variations.[42][43]\\r\\nHistorian Upinder Singh estimates that Bindusara ascended the throne around 297 BCE.[44] Bindusara, just 22?years?old, inherited a large empire that consisted of what is now, Northern, Central and Eastern parts of India along with parts of Afghanistan and Baluchistan. Bindusara extended this empire to the southern part of India, as far as what is now known as Karnataka. He brought sixteen states under the Mauryan Empire and thus conquered almost all of the Indian peninsula (he is said to have conquered the 'land between the two seas' ÿ the peninsular region between the Bay of Bengal and the Arabian Sea). Bindusara didn't conquer the friendly Tamil kingdoms of the Cholas, ruled by King Ilamcetcenni, the Pandyas, and Cheras. Apart from these southern states, Kalinga (modern Odisha) was the only kingdom in India that didn't form the part of Bindusara's empire.[45] It was later conquered by his son Ashoka, who served as the viceroy of Ujjaini during his father's reign, which highlights the importance of the town.[46][47]\\r\\nBindusara's life has not been documented as well as that of his father Chandragupta or of his son Ashoka. Chanakya continued to serve as prime minister during his reign. According to the medieval Tibetan scholar Taranatha who visited India, Chanakya helped Bindusara \\"to destroy the nobles and kings of the sixteen kingdoms and thus to become absolute master of the territory between the eastern and western oceans.\\"[48] During his rule, the citizens of Taxila revolted twice. The reason for the first revolt was the maladministration of Susima, his eldest son. The reason for the second revolt is unknown, but Bindusara could not suppress it in his lifetime. It was crushed by Ashoka after Bindusara's death.[49]\\r\\nBindusara maintained friendly diplomatic relations with the Hellenic World. Deimachus was the ambassador of Seleucid emperor Antiochus I at Bindusara's court.[50] Diodorus states that the king of Palibothra (Pataliputra, the Mauryan capital) welcomed a Greek author, Iambulus. This king is usually identified as Bindusara.[50] Pliny states that the Egyptian king Philadelphus sent an envoy named Dionysius to India.[51][52] According to Sailendra Nath Sen, this appears to have happened during Bindusara's reign.[50]\\r\\nUnlike his father Chandragupta (who at a later stage converted to Jainism), Bindusara believed in the Ajivika sect. Bindusara's guru Pingalavatsa (Janasana) was a Brahmin[53] of the Ajivika sect. Bindusara's wife, Queen Subhadrangi (Queen Aggamahesi) was a Brahmin[54] also of the Ajivika sect from Champa (present Bhagalpur district). Bindusara is credited with giving several grants to Brahmin monasteries (Brahmana-bhatto).[55]\\r\\nHistorical evidence suggests that Bindusara died in the 270s BCE. According to Upinder Singh, Bindusara died around 273 BCE.[44] Alain Danilou believes that he died around 274 BCE.[56] Sailendra Nath Sen believes that he died around 273-272 BCE, and that his death was followed by a four-year struggle of succession, after which his son Ashoka became the emperor in 269-268 BCE.[50] According to the Mahavamsa, Bindusara reigned for 28 years.[57] The Vayu Purana, which names Chandragupta's successor as \\"Bhadrasara\\", states that he ruled for 25 years.[58]\\r\\nAs a young prince, Ashoka (r.?272ÿ232?BCE) was a brilliant commander who crushed revolts in Ujjain and Takshashila. As monarch he was ambitious and aggressive, re-asserting the Empire's superiority in southern and western India. But it was his conquest of Kalinga (262ÿ261?BCE) which proved to be the pivotal event of his life. Ashoka used Kalinga to project power over a large region by building a fortification there and securing it as a possession.[59] Although Ashoka's army succeeded in overwhelming Kalinga forces of royal soldiers and civilian units, an estimated 100,000 soldiers and civilians were killed in the furious warfare, including over 10,000 of Ashoka's own men. Hundreds of thousands of people were adversely affected by the destruction and fallout of war. When he personally witnessed the devastation, Ashoka began feeling remorse. Although the annexation of Kalinga was completed, Ashoka embraced the teachings of Buddhism, and renounced war and violence. He sent out missionaries to travel around Asia and spread Buddhism to other countries.[citation needed]\\r\\nAshoka implemented principles of ahimsa by banning hunting and violent sports activity and ending indentured and forced labor (many thousands of people in war-ravaged Kalinga had been forced into hard labour and servitude). While he maintained a large and powerful army, to keep the peace and maintain authority, Ashoka expanded friendly relations with states across Asia and Europe, and he sponsored Buddhist missions. He undertook a massive public works building campaign across the country. Over 40?years of peace, harmony and prosperity made Ashoka one of the most successful and famous monarchs in Indian history. He remains an idealized figure of inspiration in modern India.[citation needed]\\r\\nThe Edicts of Ashoka, set in stone, are found throughout the Subcontinent. Ranging from as far west as Afghanistan and as far south as Andhra (Nellore District), Ashoka's edicts state his policies and accomplishments. Although predominantly written in Prakrit, two of them were written in Greek, and one in both Greek and Aramaic. Ashoka's edicts refer to the Greeks, Kambojas, and Gandharas as peoples forming a frontier region of his empire. They also attest to Ashoka's having sent envoys to the Greek rulers in the West as far as the Mediterranean. The edicts precisely name each of the rulers of the Hellenic world at the time such as Amtiyoko (Antiochus), Tulamaya (Ptolemy), Amtikini (Antigonos), Maka (Magas) and Alikasudaro (Alexander) as recipients of Ashoka's proselytism.[citation needed] The Edicts also accurately locate their territory \\"600 yojanas away\\" (a yojanas being about 7?miles), corresponding to the distance between the center of India and Greece (roughly 4,000?miles).[60]\\r\\nAshoka was followed for 50?years by a succession of weaker kings. Brihadratha, the last ruler of the Mauryan dynasty, held territories that had shrunk considerably from the time of emperor Ashoka. Brihadratha was assassinated in 185?BCE during a military parade by the Brahmin general Pushyamitra Shunga, commander-in-chief of his guard, who then took over the throne and established the Shunga dynasty.[61]\\r\\nBuddhist records such as the Ashokavadana write that the assassination of Brihadratha and the rise of the Shunga empire led to a wave of religious persecution for Buddhists,[62] and a resurgence of Hinduism. According to Sir John Marshall,[63] Pushyamitra may have been the main author of the persecutions, although later Shunga kings seem to have been more supportive of Buddhism. Other historians, such as Etienne Lamotte[64] and Romila Thapar,[65] among others, have argued that archaeological evidence in favour of the allegations of persecution of Buddhists are lacking, and that the extent and magnitude of the atrocities have been exaggerated.\\r\\nThe fall of the Mauryas left the Khyber Pass unguarded, and a wave of foreign invasion followed. The Greco-Bactrian king, Demetrius, capitalized on the break-up, and he conquered southern Afghanistan and parts of northwestern India around 180?BCE, forming the Indo-Greek Kingdom. The Indo-Greeks would maintain holdings on the trans-Indus region, and make forays into central India, for about a century. Under them, Buddhism flourished, and one of their kings, Menander, became a famous figure of Buddhism; he was to establish a new capital of Sagala, the modern city of Sialkot. However, the extent of their domains and the lengths of their rule are subject to much debate. Numismatic evidence indicates that they retained holdings in the subcontinent right up to the birth of Christ. Although the extent of their successes against indigenous powers such as the Shungas, Satavahanas, and Kalingas are unclear, what is clear is that Scythian tribes, renamed Indo-Scythians, brought about the demise of the Indo-Greeks from around 70?BCE and retained lands in the trans-Indus, the region of Mathura, and Gujarat.[citation needed]\\r\\nThe Empire was divided into four provinces, with the imperial capital at Pataliputra. From Ashokan edicts, the names of the four provincial capitals are Tosali (in the east), Ujjain (in the west), Suvarnagiri (in the south), and Taxila (in the north). The head of the provincial administration was the Kumara (royal prince), who governed the provinces as king's representative. The kumara was assisted by Mahamatyas and council of ministers. This organizational structure was reflected at the imperial level with the Emperor and his Mantriparishad (Council of Ministers).[citation needed]\\r\\nHistorians theorise that the organisation of the Empire was in line with the extensive bureaucracy described by Kautilya in the Arthashastra: a sophisticated civil service governed everything from municipal hygiene to international trade. The expansion and defense of the empire was made possible by what appears to have been one of the largest armies in the world during the Iron Age.[66] According to Megasthenes, the empire wielded a military of 600,000 infantry, 30,000 cavalry, 8,000 chariots and 9,000 war elephants besides followers and attendants.[67] A vast espionage system collected intelligence for both internal and external security purposes. Having renounced offensive warfare and expansionism, Ashoka nevertheless continued to maintain this large army, to protect the Empire and instil stability and peace across West and South Asia.[citation needed]\\r\\nFor the first time in South Asia, political unity and military security allowed for a common economic system and enhanced trade and commerce, with increased agricultural productivity. The previous situation involving hundreds of kingdoms, many small armies, powerful regional chieftains, and internecine warfare, gave way to a disciplined central authority. Farmers were freed of tax and crop collection burdens from regional kings, paying instead to a nationally administered and strict-but-fair system of taxation as advised by the principles in the Arthashastra. Chandragupta Maurya established a single currency across India, and a network of regional governors and administrators and a civil service provided justice and security for merchants, farmers and traders. The Mauryan army wiped out many gangs of bandits, regional private armies, and powerful chieftains who sought to impose their own supremacy in small areas. Although regimental in revenue collection, Maurya also sponsored many public works and waterways to enhance productivity, while internal trade in India expanded greatly due to new-found political unity and internal peace.[citation needed]\\r\\nUnder the Indo-Greek friendship treaty, and during Ashoka's reign, an international network of trade expanded. The Khyber Pass, on the modern boundary of Pakistan and Afghanistan, became a strategically important port of trade and intercourse with the outside world. Greek states and Hellenic kingdoms in West Asia became important trade partners of India. Trade also extended through the Malay peninsula into Southeast Asia. India's exports included silk goods and textiles, spices and exotic foods. The external world came across new scientific knowledge and technology with expanding trade with the Mauryan Empire. Ashoka also sponsored the construction of thousands of roads, waterways, canals, hospitals, rest-houses and other public works. The easing of many over-rigorous administrative practices, including those regarding taxation and crop collection, helped increase productivity and economic activity across the Empire.[citation needed]\\r\\nIn many ways, the economic situation in the Mauryan Empire is analogous to the Roman Empire of several centuries later. Both had extensive trade connections and both had organizations similar to corporations. While Rome had organizational entities which were largely used for public state-driven projects, Mauryan India had numerous private commercial entities. These existed purely for private commerce and developed before the Mauryan Empire itself.[68][unreliable source?]\\r\\nHoard of mostly Mauryan coins.\\r\\nSilver punch mark coin of the Maurya empire, with symbols of wheel and elephant. 3rd century BCE.[citation needed]\\r\\nMauryan coin with arched hill symbol on reverse.[citation needed]\\r\\nMauryan Empire coin. Circa late 4th-2nd century BCE.[citation needed]\\r\\nMauryan Empire, Emperor Salisuka or later. Circa 207-194 BCE.[69]\\r\\nMagadha, the centre of the empire, was also the birthplace of Buddhism. Ashoka initially practised Hinduism but later embraced Buddhism; following the Kalinga War, he renounced expansionism and aggression, and the harsher injunctions of the Arthashastra on the use of force, intensive policing, and ruthless measures for tax collection and against rebels. Ashoka sent a mission led by his son Mahinda and daughter Sanghamitta to Sri Lanka, whose king Tissa was so charmed with Buddhist ideals that he adopted them himself and made Buddhism the state religion. Ashoka sent many Buddhist missions to West Asia, Greece and South East Asia, and commissioned the construction of monasteries and schools, as well as the publication of Buddhist literature across the empire. He is believed to have built as many as 84,000 stupas across India, such as Sanchi and Mahabodhi Temple, and he increased the popularity of Buddhism in Afghanistan, Thailand and North Asia including Siberia. Ashoka helped convene the Third Buddhist Council of India's and South Asia's Buddhist orders near his capital, a council that undertook much work of reform and expansion of the Buddhist religion. Indian merchants embraced Buddhism and played a large role in spreading the religion across the Mauryan Empire.[70]\\r\\nChandragupta Maurya embraced Jainism after retiring, when he renounced his throne and material possessions to join a wandering group of Jain monks. Chandragupta was a disciple of the Jain monk Bhadrabahu. It is said that in his last days, he observed the rigorous but self-purifying Jain ritual of santhara (fast unto death), at Shravana Belgola in Karnataka.[37][36][71][35] However, his successor, Bindusara, was a follower of another ascetic movement, jؐvika,[72] and distanced himself from Jain and Buddhist movements.[citation needed] Samprati, the grandson of Ashoka, also embraced Jainism. Samprati was influenced by the teachings of Jain monks and he is known to have built 125,000 derasars across India. Some of them are still found in the towns of Ahmedabad, Viramgam, Ujjain, and Palitana. It is also said that just like Ashoka, Samprati sent messengers and preachers to Greece, Persia and the Middle East for the spread of Jainism, but, to date, no research has been done in this area.[73][74]\\r\\nThus, Jainism became a vital force under the Mauryan Rule. Chandragupta and Samprati are credited for the spread of Jainism in South India. Hundreds of thousands of temples and stupas are said to have been erected during their reigns. However, due to lack of royal patronage, its own strict principles, and the rise of Shankaracharya and Ramanuja, Jainism, once a major religion of southern India, began to decline.[citation needed]\\r\\nThe greatest monument of this period, executed in the reign of Chandragupta Maurya, was the old palace at the site of Kumhrar. Excavations at the site of Kumhrar nearby have unearthed the remains of the palace. The palace is thought to have been an aggregate of buildings, the most important of which was an immense pillared hall supported on a high substratum of timbers. The pillars were set in regular rows, thus dividing the hall into a number of smaller square bays. The number of columns is 80, each about 7 meters high. According to the eyewitness account of Megasthenes, the palace was chiefly constructed of timber, and was considered to exceed in splendour and magnificence the palaces of Susa and Ecbatana, its gilded pillars being adorned with golden vines and silver birds. The buildings stood in an extensive park studded with fish ponds and furnished with a great variety of ornamental trees and shrubs.[75][better?source?needed] Kau?ilya's Arthashastra also gives the method of palace construction from this period. Later fragments of stone pillars, including one nearly complete, with their round tapering shafts and smooth polish, indicate that Ashoka was responsible for the construction of the stone columns which replaced the earlier wooden ones.[citation needed]\\r\\nDuring the Ashokan period, stonework was of a highly diversified order and comprised lofty free-standing pillars, railings of stupas, lion thrones and other colossal figures. The use of stone had reached such great perfection during this time that even small fragments of stone art were given a high lustrous polish resembling fine enamel. This period marked the beginning of the Buddhist school of architecture. Ashoka was responsible for the construction of several stupas, which were large domes and bearing symbols of Buddha. The most important ones are located at Sanchi, Bharhut, Amaravati, Bodhgaya and Nagarjunakonda. The most widespread examples of Mauryan architecture are the Ashoka pillars and carved edicts of Ashoka, often exquisitely decorated, with more than 40 spread throughout the Indian subcontinent.[76][better?source?needed]\\r\\nThe peacock was a dynastic symbol of Mauryans, as depicted by Ashoka's pillars at Nandangarh and Sanchi Stupa.[77]\\r\\nRemains of the Ashokan Pillar in polished stone, to the right of the Southern Gateway.\\r\\nRemains of the shaft of the pillar of Ashoka, under a shed near the Southern Gateway.\\r\\nThe Sanchi pillar capital of Ashoka as discovered (left), and simulation of original appearance (right).[78] Flame palmettes and geese adorn the abacus.\\r\\nThe protection of animals in India became serious business by the time of the Maurya dynasty; being the first empire to provide a unified political entity in India, the attitude of the Mauryas towards forests, their denizens, and fauna in general is of interest.[79]\\r\\nThe Mauryas firstly looked at forests as resources. For them, the most important forest product was the elephant. Military might in those times depended not only upon horses and men but also battle-elephants; these played a role in the defeat of Seleucus, one of Alexander's former generals. The Mauryas sought to preserve supplies of elephants since it was cheaper and took less time to catch, tame and train wild elephants than to raise them. Kautilya's Arthashastra contains not only maxims on ancient statecraft, but also unambiguously specifies the responsibilities of officials such as the Protector of the Elephant Forests.[80]\\r\\nOn the border of the forest, he should establish a forest for elephants guarded by foresters. The Office of the Chief Elephant Forester should with the help of guards protect the elephants in any terrain. The slaying of an elephant is punishable by death.\\r\\nThe Mauryas also designated separate forests to protect supplies of timber, as well as lions and tigers for skins. Elsewhere the Protector of Animals also worked to eliminate thieves, tigers and other predators to render the woods safe for grazing cattle.[citation needed]\\r\\nThe Mauryas valued certain forest tracts in strategic or economic terms and instituted curbs and control measures over them. They regarded all forest tribes with distrust and controlled them with bribery and political subjugation. They employed some of them, the food-gatherers or aranyaca to guard borders and trap animals. The sometimes tense and conflict-ridden relationship nevertheless enabled the Mauryas to guard their vast empire.[81]\\r\\nWhen Ashoka embraced Buddhism in the latter part of his reign, he brought about significant changes in his style of governance, which included providing protection to fauna, and even relinquished the royal hunt. He was the first ruler in history[not in citation given] to advocate conservation measures for wildlife and even had rules inscribed in stone edicts. The edicts proclaim that many followed the king's example in giving up the slaughter of animals; one of them proudly states:[81]\\r\\nOur king killed very few animals.\\r\\nHowever, the edicts of Ashoka reflect more the desire of rulers than actual events; the mention of a 100 'panas' (coins) fine for poaching deer in royal hunting preserves shows that rule-breakers did exist. The legal restrictions conflicted with the practices freely exercised by the common people in hunting, felling, fishing and setting fires in forests.[81]\\r\\nRelations with the Hellenistic world may have started from the very beginning of the Maurya Empire. Plutarch reports that Chandragupta Maurya met with Alexander the Great, probably around Taxila in the northwest:\\r\\nChandragupta ultimately occupied Northwestern India, in the territories formerly ruled by the Greeks, where he fought the satraps (described as \\"Prefects\\" in Western sources) left in place after Alexander (Justin), among whom may have been Eudemus, ruler in the western Punjab until his departure in 317?BCE or Peithon, son of Agenor, ruler of the Greek colonies along the Indus until his departure for Babylon in 316?BCE.[citation needed]\\r\\nSeleucus I Nicator, the Macedonian satrap of the Asian portion of Alexander's former empire, conquered and put under his own authority eastern territories as far as Bactria and the Indus (Appian, History of Rome, The Syrian Wars 55), until in 305?BCE he entered into a confrontation with Emperor Chandragupta:\\r\\nThough no accounts of the conflict remain, it is clear that Seleucus fared poorly against the Indian Emperor as he failed to conquer any territory, and in fact was forced to surrender much that was already his. Regardless, Seleucus and Chandragupta ultimately reached a settlement and through a treaty sealed in 305?BCE, Seleucus, according to Strabo, ceded a number of territories to Chandragupta, including large parts of what is now Afghanistan and parts of Balochistan.[citation needed]\\r\\nChandragupta and Seleucus concluded a peace treaty and a marital alliance in 303 BCE. Chandragupta received vast territories, and in a return gesture, gave Seleucus 500 war elephants,[25][86][87][88][89] a military asset which would play a decisive role at the Battle of Ipsus in 301?BCE.[90] In addition to this treaty, Seleucus dispatched an ambassador, Megasthenes, to Chandragupta, and later Deimakos to his son Bindusara, at the Mauryan court at Pataliputra (modern Patna in Bihar state). Later, Ptolemy II Philadelphus, the ruler of Ptolemaic Egypt and contemporary of Ashoka, is also recorded by Pliny the Elder as having sent an ambassador named Dionysius to the Mauryan court.[91][better?source?needed]\\r\\nMainstream scholarship asserts that Chandragupta received vast territory west of the Indus, including the Hindu Kush, modern-day Afghanistan, and the Balochistan province of Pakistan.[92][93] Archaeologically, concrete indications of Mauryan rule, such as the inscriptions of the Edicts of Ashoka, are known as far as Kandahar in southern Afghanistan.\\r\\nThe treaty on \\"Epigamia\\" implies lawful marriage between Greeks and Indians was recognized at the State level, although it is unclear whether it occurred among dynastic rulers or common people, or both.[citation needed].\\r\\nClassical sources have also recorded that following their treaty, Chandragupta and Seleucus exchanged presents, such as when Chandragupta sent various aphrodisiacs to Seleucus:[42]\\r\\nHis son Bindusara 'Amitraghata' (Slayer of Enemies) also is recorded in Classical sources as having exchanged presents with Antiochus I:[42]\\r\\nThe Greek population apparently remained in the northwest of the Indian subcontinent under Ashoka's rule. In his Edicts of Ashoka, set in stone, some of them written in Greek, Ashoka relates that the Greek population within his realm was absorbed, integrated, and converted to Buddhism:\\r\\nFragments of Edict 13 have been found in Greek, and a full Edict, written in both Greek and Aramaic, has been discovered in Kandahar. It is said to be written in excellent Classical Greek, using sophisticated philosophical terms. In this Edict, Ashoka uses the word Eusebeia (\\"Piety\\") as the Greek translation for the ubiquitous \\"Dharma\\" of his other Edicts written in Prakrit:[non-primary source needed]\\r\\nAlso, in the Edicts of Ashoka, Ashoka mentions the Hellenistic kings of the period as recipients of his Buddhist proselytism, although no Western historical record of this event remains:\\r\\nAshoka also encouraged the development of herbal medicine, for men and animals, in their territories:\\r\\nThe Greeks in India even seem to have played an active role in the propagation of Buddhism, as some of the emissaries of Ashoka, such as Dharmaraksita, are described in Pali sources as leading Greek (\\"Yona\\") Buddhist monks, active in Buddhist proselytism (the Mahavamsa, XII[97][non-primary source needed]).\\r\\nSophagasenus was an Indian Mauryan ruler of the 3rd century BCE, described in ancient Greek sources, and named Subhagasena or Subhashasena in Prakrit. His name is mentioned in the list of Mauryan princes[citation needed], and also in the list of the Yadava dynasty, as a descendant of Pradyumna. He may have been a grandson of Ashoka, or Kunala, the son of Ashoka. He ruled an area south of the Hindu Kush, possibly in Gandhara. Antiochos III, the Seleucid king, after having made peace with Euthydemus in Bactria, went to India in 206?BCE and is said to have renewed his friendship with the Indian king there:\\r\\n\\"He (Antiochus) crossed the Caucasus and descended into India; renewed his friendship with Sophagasenus the king of the Indians; received more elephants, until he had a hundred and fifty altogether; and having once more provisioned his troops, set out again personally with his army: leaving Androsthenes of Cyzicus the duty of taking home the treasure which this king had agreed to hand over to him\\". Polybius 11.39[non-primary source needed]\\r\\nAccording to Vicarasreni of Merutunga, Mauryans rose to power in 312?BC.[98]\\r\\ncultural period\\r\\n(Punjab-Sapta Sindhu)\\r\\n(Kuru-Panchala)\\r\\n(Brahmin ideology)[a]\\r\\nPainted Grey Ware culture\\r\\n(Kshatriya/Shramanic culture)[b]\\r\\nNorthern Black Polished Ware\\r\\nRise of Shramana movements\\r\\nJainism - Buddhism - jؐvika - Yoga\\r\\nEarly Pandyan Kingdom\\r\\nSatavahana dynasty\\r\\nCheras\\r\\n46 other small kingdoms in Ancient Thamizhagam\\r\\n(continued)\\r\\n(300 BC ÿ 200 AD)\\r\\nMaha-Meghavahana Dynasty\\r\\nEarly Pandyan Kingdom\\r\\nSatavahana dynasty\\r\\nCheras\\r\\n46 other small kingdoms in Ancient Thamizhagam\\r\\nIndo-Scythians\\r\\nIndo-Parthians\\r\\nPandyan Kingdom(Under Kalabhras)\\r\\nVarman dynasty\\r\\nPandyan Kingdom(Under Kalabhras)\\r\\nKadamba Dynasty\\r\\nWestern Ganga Dynasty\\r\\nPandyan Kingdom(Under Kalabhras)\\r\\nVishnukundina\\r\\nKabul Shahi\\r\\nKalabhra dynasty\\r\\nPandyan Kingdom(Under Kalabhras)\\r\\nPandyan Kingdom(Revival)\\r\\nPallava\\r\\nKalachuri\\r\\nPandyan Kingdom\\r\\nMedieval Cholas\\r\\nPandyan Kingdom(Under Cholas)\\r\\nChera Perumals of Makkotai\\r\\nKamboja-Pala dynasty\\r\\nMedieval Cholas\\r\\nPandyan Kingdom(Under Cholas)\\r\\nChera Perumals of Makkotai\\r\\nRashtrakuta\\r\\nReferences\\r\\nSources","input":"What was the capital of the maurya empire?"},{"output":"from the 12th to the 15th century","context":"\\r\\n\\r\\nThe Mausoleum at Halicarnassus or Tomb of Mausolus[a] (Ancient Greek: ϫ翼? ?? ?ϫϫ?; Turkish: Halikarnas Mozolesi) was a tomb built between 353 and 350?BC at Halicarnassus (present Bodrum, Turkey) for Mausolus, a satrap in the ?Achaemenid Empire, and his sister-wife Artemisia II of Caria. The structure was designed by the Greek architects Satyros and Pythius of Priene.[1][2]\\r\\n\\r\\nThe Mausoleum was approximately 45?m (148?ft) in height, and the four sides were adorned with sculptural reliefs, each created by one of four Greek sculptorsLeochares, Bryaxis, Scopas of Paros and Timotheus.[3] The finished structure of the mausoleum was considered to be such an aesthetic triumph that Antipater of Sidon identified it as one of his Seven Wonders of the Ancient World. It was destroyed by successive earthquakes from the 12th to the 15th century,[4][5][6] the last surviving of the six destroyed wonders.\\r\\n\\r\\nThe word mausoleum has now come to be used generically for an above-ground tomb.\\r\\n\\r\\nIn the 4th century BC, Halicarnassus was the capital of a small regional kingdom within the Achaemenid Empire on the western coast of Asia Minor. In 377?BC, the nominal ruler of the region, Hecatomnus of Milas, died and left the control of the kingdom to his son, Mausolus. Hecatomnus, a local satrap under the Persians, took control of several of the neighboring cities and districts. After Artemisia and Mausolus, he had several other daughters and sons: Ada (adoptive mother of Alexander the Great), Idrieus and Pixodarus. Mausolus extended its territory as far as the southwest coast of Anatolia. Artemisia and Mausolus ruled from Halicarnassus over the surrounding territory for 24 years. Mausolus, although descended from local people, spoke Greek and admired the Greek way of life and government. He founded many cities of Greek design along the coast and encouraged Greek democratic traditions.[citation needed]\\r\\n\\r\\nMausolus decided to build a new capital, one as safe from capture as it was magnificent to be seen. He chose the city of Halicarnassus. Artemisia and Mausolus spent huge amounts of tax money to embellish the city. They commissioned statues, temples and buildings of gleaming marble. In 353?BC, Mausolus died, leaving Artemisia to rule alone. As the Persian satrap, and as the Hecatomnid dynast, Mausolus had planned for himself an elaborate tomb.  When he died the project was continued by his siblings.  The tomb became so famous that Mausolus's name is now the eponym for all stately tombs, in the word mausoleum.\\r\\n\\r\\nArtemisia lived for only two years after the death of her husband. The urns with their ashes were placed in the yet unfinished tomb. As a form of sacrifice ritual the bodies of a large number of dead animals were placed on the stairs leading to the tomb, and then the stairs were filled with stones and rubble, sealing the access. According to the historian Pliny the Elder, the craftsmen decided to stay and finish the work after the death of their patron \\"considering that it was at once a memorial of his own fame and of the sculptor's art.\\"\\r\\n\\r\\nIt is likely that Mausolos started to plan the tomb before his death, as part of the building works in Halicarnassus, and that when he died Artemisia continued the building project.  Artemisia spared no expense in building the tomb. She sent messengers to Greece to find the most talented artists of the time. These included Scopas, the man who had supervised the rebuilding of the Temple of Artemis at Ephesus. The famous sculptors were (in the Vitruvius order): Leochares, Bryaxis, Scopas, and Timotheus, as well as hundreds of other craftsmen.\\r\\n\\r\\nThe tomb was erected on a hill overlooking the city. The whole structure sat in an enclosed courtyard. At the center of the courtyard was a stone platform on which the tomb sat. A stairway flanked by stone lions led to the top of the platform, which bore along its outer walls many statues of gods and goddesses. At each corner, stone warriors mounted on horseback guarded the tomb. At the center of the platform, the marble tomb rose as a square tapering block to one-third of the Mausoleum's 45?m (148?ft) height. This section was covered with bas-reliefs showing action scenes, including the battle of the centaurs with the lapiths and Greeks in combat with the Amazons, a race of warrior women.\\r\\n\\r\\nOn the top of this section of the tomb thirty-six slim columns, ten per side, with each corner sharing one column between two sides; rose for another third of the height. Standing between each pair of columns was a statue. Behind the columns was a solid cella-like block that carried the weight of the tomb's massive roof. The roof, which comprised most of the final third of the height, was pyramidal. Perched on the top was a quadriga: four massive horses pulling a chariot in which rode images of Mausolus and Artemisia.\\r\\n\\r\\nModern historians have pointed out that two years would not be enough time to decorate and build such an extravagant building. Therefore, it is believed that construction was begun by Mausolus before his death or continued by the next leaders.[7] The Mausoleum of Halicarnassus resembled a temple and the only way to tell the difference was its slightly higher outer walls. The Mausoleum was in the Greek-dominated area of Halicarnassus, which in 353 was controlled by the Achaemenid Empire. According to the Roman architect Vitruvius, it was built by Satyros and Pytheus who wrote a treatise about it; this treatise is now lost.[7] Pausanias adds that the Romans considered the Mausoleum one of the great wonders of the world and it was for that reason that they called all their magnificent tombs mausolea, after it.[8]\\r\\n\\r\\nIt is unknown exactly when and how the Mausoleum came to ruin: Eustathius, writing in the 12th century on his commentary of the Iliad says \\"it was and is a wonder\\". Because of this, Fergusson concluded that the building was ruined, probably by an earthquake, between this period and 1402, when the Knights of St. John of Jerusalem arrived and recorded that it was in ruins.[8] However, Luttrell notes[9] that at that time the local Greek and Turks had no name for ÿ or legends to account for ÿ the colossal ruins, suggesting a destruction at a much earlier period.\\r\\n\\r\\nMany of the stones from the ruins were used by the knights to fortify their castle at Bodrum; they also recovered bas-reliefs with which they decorated the new building. Much of the marble was burned into lime. In 1846 Lord Stratford de Redcliffe obtained permission to remove these reliefs from the Bodrum.[10]\\r\\n\\r\\nAt the original site, all that remained by the 19th century were the foundations and some broken sculptures. This site was originally indicated by Professor Donaldson and was discovered definitively by Charles Newton, after which an expedition was sent by the British government. The expedition lasted three?years and ended in the sending of the remaining marbles.[11] At some point before or after this, grave robbers broke into and destroyed the underground burial chamber, but in 1972 there was still enough of it remaining to determine a layout of the chambers when they were excavated.[7]\\r\\n\\r\\nThis monument was ranked the seventh wonder of the world by the ancients, not because of its size or strength but because of the beauty of its design and how it was decorated with sculpture or ornaments.[12] The mausoleum was Halicarnassus' principal architectural monument, standing in a dominant position on rising ground above the harbor.[13]\\r\\n\\r\\nMuch of the information we have gathered about the Mausoleum and its structure has come from the Roman polymath Pliny the Elder. He wrote some basic facts about the architecture and some dimensions. The building was rectangular, not square, surrounded by a colonnade of thirty-six columns. There was a pyramidal superstructure receding in twenty four steps to the summit. On top there were 4 horse chariots of marble. The building was accented with both sculptural friezes and free standing figures. \\"The free standing figures were arranged on 5 or 6 different levels.\\"[7] We are now able to justify that Pliny's knowledge came from a work written by the architect. It is clear that Pliny did not grasp the design of the mausoleum fully which creates problems in recreating the structure. He does state many facts which help the reader recreate pieces of the puzzle. Other writings by Pausanias, Strabo, and Vitruvius also help us to gather more information about the Mausoleum.[14]\\r\\n\\r\\nAccording to Pliny, the mausoleum was 19 metres (63?ft) north and south, shorter on other fronts, 125 metres (411?ft) perimeter, and 25?cubits (11.4 metres or 37.5 feet) in height. It was surrounded by 36 columns. They called this part the pteron. Above the pteron there was a pyramid on top with 24 steps and equal in height to the lower part. The height of the building was 43 metres (140?ft).[15] The only other author that gives the dimensions of the Mausoleum is Hyginus a grammarian in the time of Augustus. He describes the monument as built with shining stones, 24 metres (80?ft) high and 410 metres (1,340?ft) in circumference. He likely meant cubits which would match Pliny's dimensions exactly but this text is largely considered corrupt and is of little importance.[14] We learn from Vitruvius that Satyrus and Phytheus wrote a description of their work which Pliny likely read. Pliny likely wrote down these dimensions without thinking about the form of the building.[14]\\r\\n\\r\\nA number of statues were found slightly larger than life size, either 1.5 metres (5?ft). or 1.60 metres (5.25?ft). in length; these were 20 lion statues. Another important find was the depth on the rock on which the building stood. This rock was excavated to 2.4 or 2.7 metres (8 or 9?ft) deep over an area 33 by 39 metres (107 by 127?ft).[15]\\r\\nThe sculptures on the north were created by Scopas, the ones on the east Bryaxis, on the south Timotheus and on the west Leochares.[14]\\r\\nThe Mausoleum was adorned with many great and beautiful sculptures. Some of these sculptures have been lost or only fragments have been found. Several of the statues' original placements are only known through historical accounts. The great figures of Mausolus and Artemisia stood in the chariot at the top of the pyramid. The detached equestrian groups are placed at the corners of the sub podium.[14] The semi-colossal female heads they may have belonged to the acroteria of the two gables which may have represented the six Carian towns incorporated in Halicarnassus.[16] Work still continues today as groups continue to excavate and research the mausoleum's art.\\r\\n\\r\\nThe Mausoleum overlooked the city of Halicarnassus for many years. It was untouched when the city fell to Alexander the Great in 334?BC and still undamaged after attacks by pirates in 62 and 58?BC. It stood above the city's ruins for sixteen centuries. Then a series of earthquakes shattered the columns and sent the bronze chariot crashing to the ground. By 1404?AD only the very base of the Mausoleum was still recognizable.\\r\\n\\r\\nThe Knights of St John of Rhodes invaded the region and built Bodrum Castle (Castle of Saint Peter). When they decided to fortify it in 1494, they used the stones of the Mausoleum. This is also about when \\"imaginative reconstructions\\" of the Mausoleum began to appear.[17] In 1522 rumours of a Turkish invasion caused the Crusaders to strengthen the castle at Halicarnassus (which was by then known as Bodrum) and much of the remaining portions of the tomb were broken up and used in the castle walls. Sections of polished marble from the tomb can still be seen there today. Suleiman the Magnificent conquered the base of the knights on the island of Rhodes, who then relocated first briefly to Sicily and later permanently to Malta, leaving the Castle and Bodrum to the Ottoman Empire.\\r\\n\\r\\nDuring the fortification work, a party of knights entered the base of the monument and discovered the room containing a great coffin. In many histories of the Mausoleum one can find the following story of what happened: the party, deciding it was too late to open it that day, returned the next morning to find the tomb, and any treasure it may have contained, plundered. The bodies of Mausolus and Artemisia were missing too. The small museum building next to the site of the Mausoleum tells the story. Research done by archeologists in the 1960s shows that long before the knights came, grave robbers had dug a tunnel under the grave chamber, stealing its contents. Also the museum states that it is most likely that Mausolus and Artemisia were cremated, so only an urn with their ashes was placed in the grave chamber. This explains why no bodies were found.\\r\\n\\r\\nBefore grinding and burning much of the remaining sculpture of the Mausoleum into lime for plaster, the Knights removed several of the best works and mounted them in the Bodrum castle. There they stayed for three centuries.\\r\\n\\r\\nIn the 19th century a British consul obtained several of the statues from Bodrum Castle; these now reside in the British Museum. In 1852 the British Museum sent the archaeologist Charles Thomas Newton to search for more remains of the Mausoleum. He had a difficult job. He didn't know the exact location of the tomb, and the cost of buying up all the small parcels of land in the area to look for it would have been astronomical. Instead Newton studied the accounts of ancient writers like Pliny to obtain the approximate size and location of the memorial, then bought a plot of land in the most likely location. Digging down, Newton explored the surrounding area through tunnels he dug under the surrounding plots. He was able to locate some walls, a staircase, and finally three of the corners of the foundation. With this knowledge, Newton was able to determine which plots of land he needed to buy.\\r\\n\\r\\nNewton then excavated the site and found sections of the reliefs that decorated the wall of the building and portions of the stepped roof. Also discovered was a broken stone chariot wheel some 2?m (6?ft 7?in) in diameter, which came from the sculpture on the Mausoleum's roof. Finally, he found the statues of Mausolus and Artemisia that had stood at the pinnacle of the building. In October 1857 Newton carried blocks of marble from this site by HMS?Supply and landed them in Malta. These blocks were used for the construction of a new dock in Malta for the Royal Navy. Today this dock is known at Dock No. 1 in Cospicua, but the building blocks are hidden from view, submerged in Dockyard Creek in the Grand Harbour.[18]\\r\\n\\r\\nFrom 1966 to 1977, the Mausoleum was thoroughly researched by Prof. Kristian Jeppesen of Aarhus University, Denmark. He has produced a six-volume monograph, The Maussolleion at Halikarnassos.\\r\\n\\r\\nThe beauty of the Mausoleum was not only in the structure itself, but in the decorations and statues that adorned the outside at different levels on the podium and the roof: statues of people, lions, horses, and other animals in varying scales. The four Greek sculptors who carved the statues: Bryaxis, Leochares, Scopas and Timotheus were each responsible for one side. Because the statues were of people and animals, the Mausoleum holds a special place in history, as it was not dedicated to the gods of Ancient Greece.\\r\\n\\r\\nToday, the massive castle of the Knights Hospitaller (Knights of St. John) still stands in Bodrum, and the polished stone and marble blocks of the Mausoleum can be spotted built into the walls of the structure. At the site of the Mausoleum, only the foundation remains, and a small museum. Some of the surviving sculptures at the British Museum include fragments of statues and many slabs of the frieze showing the battle between the Greeks and the Amazons. There the images of Mausolus and his queen watch over the few broken remains of the beautiful tomb she built for him.\\r\\n\\r\\nReconstruction of the Amazonomachy can be seen in the left Background-The British Museum Room 21\\r\\n\\r\\nStatue usually identified as Artemisia; Reconstruction of the Amazonomachy can be seen in the left Background-The British Museum Room 21\\r\\n\\r\\nSlab from the Amazonomachy believed to show Herculeas grabbing the Hair of the Amazon Queen Hippolyta\\r\\n\\r\\nModern buildings whose designs were based upon or influenced by interpretations of the design of the Mausoleum of Mausolus include PNC Tower in Cincinnati, the Civil Courts Building in St. Louis; the National Newark Building in Newark, New Jersey; Grant's Tomb and 26 Broadway in New York City; Los Angeles City Hall; the Shrine of Remembrance in Melbourne; the spire of St. George's Church, Bloomsbury in London; the Indiana War Memorial (and in turn Salesforce Tower) in Indianapolis,[19][20] the House of the Temple in Washington D.C., the National Diet in Tokyo, and the Soldiers and Sailors Memorial Hall in Pittsburgh.[21]","input":"When did the mausoleum at halicarnassus get destroyed?"},{"output":"Czech","context":"\\r\\n\\r\\nCzech (/t??k/; ?e?tina Czech pronunciation: [?t???c?na]), historically also Bohemian[7] (/bo??hi?mi?n, b?-/;[8] lingua Bohemica in Latin), is a West Slavic language of the CzechÿSlovak group.[7] Spoken by over 10 million people, it serves as the official language of the Czech Republic. Czech is closely related to Slovak, to the point of mutual intelligibility to a very high degree.[9] Like other Slavic languages, Czech is a fusional language with a rich system of morphology and relatively flexible word order. Its vocabulary has been extensively influenced by Latin[10] and German.[11]\\r\\n\\r\\nThe CzechÿSlovak group developed within West Slavic in the high medieval period, and the standardization of Czech and Slovak within the CzechÿSlovak dialect continuum emerged in the early modern period. In the later 18th to mid-19th century, the modern written standard became codified in the context of the Czech National Revival. The main vernacular, known as Common Czech, is based on the vernacular of Prague, but is now spoken throughout most of the Czech Republic. The Moravian dialects spoken in the eastern part of the country are also classified as Czech, although some of their eastern variants are closer to Slovak.\\r\\n\\r\\nCzech has a moderately-sized phoneme inventory, comprising ten monophthongs, three diphthongs and 25 consonants (divided into \\"hard\\", \\"neutral\\" and \\"soft\\" categories). Words may contain complicated consonant clusters or lack vowels altogether. Czech has a raised alveolar trill, which is not known to occur as a phoneme in any other language, represented by the grapheme ?. Czech uses a simple orthography which phonologists have used as a model.\\r\\n\\r\\nCzech is a member of the West Slavic sub-branch of the Slavic branch of the Indo-European language family. This branch includes Polish, Kashubian, Upper and Lower Sorbian and Slovak. Slovak is the closest language genetic neighbor of Czech, followed by Polish and Silesian.[12]\\r\\n\\r\\nThe West Slavic languages are spoken in Central Europe. Czech is distinguished from other West Slavic languages by a more-restricted distinction between \\"hard\\" and \\"soft\\" consonants (see Phonology below).[12]\\r\\n\\r\\nThe term \\"Old Czech\\" is applied to the period predating the 16th century, with the earliest records of the high medieval period also classified as \\"early Old Czech\\", but the term \\"Medieval Czech\\" is also used.\\r\\n\\r\\nAround the 7th century, the  Slavic expansion reached Central Europe, settling on the eastern fringes of the Frankish Empire. The West Slavic polity of  Great Moravia formed by the 9th century. The Christianization of Bohemia took place during the 9th and 10th centuries. The diversification of the Czech-Slovak group within West Slavic began around that time, marked among other things by  its ephemeral use of the voiced velar fricative consonant (/?/)[13] and consistent stress on the first syllable.[14]\\r\\n\\r\\nThe Bohemian (Czech) language is first recorded in writing in glosses and short notes during the 12th to 13th centuries. Literary works written in Czech appear in the early 14th century and administrative documents first appear towards the late 14th century. The first complete Bible translation also dates to this period.[15] Old Czech texts, including poetry and cookbooks, were produced outside the university as well.[16]\\r\\n\\r\\nLiterary activity becomes widespread in the early 15th century in the context of the Bohemian Reformation. Jan Hus contributed significantly to the standardization of Czech orthography, advocated for widespread literacy among Czech commoners (particularly in religion) and made early efforts to model written Czech after the spoken language.[15]\\r\\n\\r\\nThere was no standardization distinguishing between Czech and Slovak prior to the 15th century.[17] In the 16th century, the division between Czech and Slovak becomes apparent, marking the confessional division between Lutheran Protestants in Slovakia using Czech orthography and Catholics, especially Slovak Jesuits, beginning to use a separate Slovak orthography based on the language of the Trnava region.\\r\\n\\r\\nThe publication of the Kralice Bible between 1579 and 1593 (the first complete Czech translation of the Bible from the original languages) became very important for standardization of the Czech language in the following centuries.\\r\\n\\r\\nIn 1615, the Bohemian diet tried to declare Czech to be the only official language of the kingdom. After the Bohemian Revolt (of predominantly Protestant aristocracy) which was defeated by the Habsburgs in 1620, the Protestant intellectuals had to leave the country. This emigration together with other consequences of the Thirty Years' War had a negative impact on the further use of the Czech language. In 1627, Czech and German became official languages of the Kingdom of Bohemia and in the 18th century German became dominant in Bohemia and Moravia, especially among the upper classes.[18]\\r\\n\\r\\nThe modern standard Czech language originates in standardization efforts of the 18th century.[19] By then the language had developed a literary tradition, and since then it has changed little; journals from that period have no substantial differences from modern standard Czech, and contemporary Czechs can understand them with little difficulty.[20] Changes include the morphological shift of  to ej and  to  (although  survives for some uses) and the merging of  and the former ej.[21] Sometime before the 18th century, the Czech language abandoned a distinction between phonemic /l/ and /?/ which survives in Slovak.[22]\\r\\n\\r\\nWith the beginning of the national revival of the mid-18th century,  Czech historians began to emphasize their people's accomplishments from the 15th through the 17th centuries, rebelling against the Counter-Reformation (the Habsburg re-catholization efforts which had denigrated Czech and other non-Latin languages).[23] Czech philologists studied sixteenth-century texts, advocating the return of the language to high culture.[24] This period is known as the Czech National Revival[25] (or Renaissance).[24]\\r\\n\\r\\nDuring the national revival, in 1809 linguist and historian Josef Dobrovsky released a German-language grammar of Old Czech entitled Ausfhrliches Lehrgeb?ude der b?hmischen Sprache (Comprehensive Doctrine of the Bohemian Language). Dobrovsky had intended his book to be descriptive, and did not think Czech had a realistic chance of returning as a major language. However, Josef Jungmann and other revivalists used Dobrovsky's book to advocate for a Czech linguistic revival.[25] Changes during this time included spelling reform (notably,  in place of the former j and j in place of g), the use of t (rather than ti) to end infinitive verbs and the non-capitalization of nouns (which had been a late borrowing from German).[22] These changes differentiated Czech from Slovak.[26] Modern scholars disagree about whether the conservative revivalists were motivated by nationalism or considered contemporary spoken Czech unsuitable for formal, widespread use.[25]\\r\\n\\r\\nAdherence to historical patterns was later relaxed and standard Czech adopted a number of features from Common Czech (a widespread, informal register), such as leaving some proper nouns undeclined. This has resulted in a relatively high level of homogeneity among all varieties of the language.[27]\\r\\n\\r\\nIn 2005 and 2007, Czech was spoken by about 10 million residents of the Czech Republic.[18][28] A Eurobarometer survey conducted from January to March 2012 found that the first language of 98 percent of Czech citizens was Czech, the third-highest in the European Union (behind Greece and Hungary).[29]\\r\\n\\r\\nCzech, the official language of the Czech Republic (a member of the European Union since 2004), is one of the EU's official languages and the 2012 Eurobarometer survey found that Czech was the foreign language most often used in Slovakia.[29] Economist Jonathan van Parys collected data on language knowledge in Europe for the 2012 European Day of Languages. The five countries with the greatest use of Czech were the Czech Republic (98.77 percent), Slovakia (24.86 percent), Portugal (1.93 percent), Poland (0.98 percent) and Germany (0.47 percent).[30]\\r\\n\\r\\nCzech speakers in Slovakia primarily live in cities. Since it is a recognised minority language in Slovakia, Slovak citizens who speak only Czech may communicate with the government in their language to the extent that Slovak speakers in the Czech Republic may do so.[31]\\r\\n\\r\\nImmigration of Czechs from Europe to the United States occurred primarily from 1848 to 1914. Czech is a Less Commonly Taught Language in U.S. schools, and is taught at Czech heritage centers. Large communities of Czech Americans live in the states of Texas, Nebraska and Wisconsin.[32] In the 2000 United States Census, Czech was reported as the most-common language spoken at home (besides English) in Valley, Butler and Saunders Counties, Nebraska and Republic County, Kansas. With the exception of Spanish (the non-English language most commonly spoken at home nationwide), Czech was the most-common home language in over a dozen additional counties in Nebraska, Kansas, Texas, North Dakota and Minnesota.[33] As of 2009, 70,500 Americans spoke Czech as their first language (49th place nationwide, behind Turkish and ahead of Swedish).[34]\\r\\n\\r\\nThe modern written standard is directly based on the standardization during the Czech National Revival in the 1830s, significantly influenced by  Josef Jungmann's CzechÿGerman dictionary published during 1834ÿ1839. Jungmann used vocabulary of the Bible of Kralice (1579ÿ1613) period and of the language used by his contemporaries. He borrowed words not present in Czech from other Slavic languages or created neologisms.[35]\\r\\n\\r\\nStandard Czech contains ten basic vowel phonemes, and three more found only in loanwords. They are /a/, /?/, /?/, /o/, and /u/, their long counterparts /a?/, /??/, /i?/, /o?/ and /u?/, and three diphthongs, /ou?/, /au?/ and /?u?/. The latter two diphthongs and the long /o?/ are exclusive to loanwords.[36] Vowels are never reduced to schwa sounds when unstressed.[37] Each word usually has primary stress on its first syllable, except for enclitics (minor, monosyllabic, unstressed syllables). In all words of more than two syllables, every odd-numbered syllable receives secondary stress. Stress is unrelated to vowel length, and the possibility of stressed short vowels and unstressed long vowels can be confusing to students whose native language combines the features (such as most varieties of English).[38]\\r\\n\\r\\nVoiced consonants with unvoiced counterparts are unvoiced at the end of a word before a pause, and in consonant clusters voicing assimilation occurs, which matches voicing to the following consonant. The unvoiced counterpart of /?/ is /x/.[39]\\r\\n\\r\\nCzech consonants are categorized as \\"hard\\", \\"neutral\\" or \\"soft\\":\\r\\n\\r\\nThis distinction describes the declension patterns of nouns, which is based on the category of a noun's ending consonant. Hard consonants may not be followed by i or  in writing, or soft ones by y or y (except in loanwords such as kilogram).[40] Neutral consonants may take either character. Hard consonants are sometimes known as \\"strong\\", and soft ones as \\"weak\\".[41]\\r\\n\\r\\nThe phoneme represented by the letter ? (capital ?) is considered unique to Czech.[42] It represents the raised alveolar non-sonorant trill (IPA: [r?]), a sound somewhere between Czech's r and ? (example: ?\\"?eka\\" (river)?(help{info)),[42] and is present in Dvo?k. In unvoiced environments, /r?/ is realized as its voiceless allophone [r??].[43]\\r\\n\\r\\nThe consonants /r/ and /l/ can be syllabic, acting as syllable nuclei in place of a vowel. Str? prst skrz krk (\\"Stick [your] finger through [your] throat\\") is a well-known Czech tongue twister using only syllabic consonants.[44]\\r\\n\\r\\nConsonants\\r\\n\\r\\n\\r\\n\\r\\nVowels\\r\\n\\r\\n\\r\\n\\r\\nSlavic grammar is fusional; its nouns, verbs, and adjectives are inflected by phonological processes to modify their meanings and grammatical functions, and the easily separable affixes characteristic of agglutinative languages are limited.[45] \\r\\nSlavic inflection is complex and pervasive, inflecting for case, gender and number in nouns and tense, aspect, mood, person and subject number and gender in verbs.[46]\\r\\n\\r\\nParts of speech include adjectives, adverbs, numbers, interrogative words, prepositions, conjunctions and interjections.[47] Adverbs are primarily formed from adjectives by taking the final y or  of the base form and replacing it with e, , or o.[48] Negative statements are formed by adding the affix ne- to the verb of a clause, with one exception: je (he, she or it is) becomes nen.[49]\\r\\n\\r\\nBecause Czech uses grammatical case to convey word function in a sentence (instead of relying on word order, as English does), its word order is flexible. As a pro-drop language, in Czech an intransitive sentence can consist of only a verb; information about its subject is encoded in the verb.[50] Enclitics (primarily auxiliary verbs and pronouns) must appear in the second syntactic slot of a sentence, after the first stressed unit. The first slot must contain a subject and object, a main form of a verb, an adverb or a conjunction (except for the light conjunctions a, \\"and\\", i, \\"and even\\" or ale, \\"but\\").[51]\\r\\n\\r\\nCzech syntax has a subjectÿverbÿobject sentence structure. In practice, however, word order is flexible and used for topicalization and focus. Although Czech has a periphrastic passive construction (like English), colloquial word-order changes frequently produce the passive voice. For example, to change \\"Peter killed\\r\\nPaul\\" to \\"Paul was killed by Peter\\" the order of subject and object is inverted: Petr zabil Pavla (\\"Peter killed Paul\\") becomes \\"Paul, Peter killed\\" (Pavla zabil Petr). Pavla is in the accusative case, the grammatical object (in this case, the victim) of the verb.[52]\\r\\n\\r\\nA word at the end of a clause is typically emphasized, unless an upward intonation indicates that the sentence is a question:[53]\\r\\n\\r\\nIn portions of Bohemia (including Prague), questions such as J pes bagetu? without an interrogative word (such as co, \\"what\\" or kdo, \\"who\\") are intoned in a slow rise from low to high, quickly dropping to low on the last word or phrase.[54]\\r\\n\\r\\nIn modern Czech syntax, adjectives precede nouns,[55] with few exceptions.[56] Relative clauses are introduced by relativizers such as the adjective ktery, analogous to the English relative pronouns \\"which\\", \\"that\\", \\"who\\" and \\"whom\\". As with other adjectives, it is declined into the appropriate case (see Declension below) to match its associated noun, person and number. Relative clauses follow the noun they modify, and the following is a glossed example:[57]\\r\\n\\r\\nEnglish: I want to visit the university that John attends.\\r\\n\\r\\nIn Czech, nouns and adjectives are declined into one of seven grammatical cases. Nouns are inflected to indicate their use in a sentence. A nominativeÿaccusative language, Czech marks subject nouns with nominative case and object nouns with accusative case. The genitive case marks possessive nouns and some types of movement. The remaining cases (instrumental, locative, vocative and dative) indicate semantic relationships, such as secondary objects, movement or position (dative case) and accompaniment (instrumental case). An adjective's case agrees with that of the noun it describes. When Czech children learn their language's declension patterns, the cases are referred to by number:[58]\\r\\n\\r\\nSome Czech grammatical texts order the cases differently, grouping the nominative and accusative (and the dative and locative) together because those declension patterns are often identical; this order accommodates learners with experience in other inflected languages, such as Latin or Russian. This order is nominative, accusative, genitive, dative, locative, instrumental and vocative.[58]\\r\\n\\r\\nSome prepositions require the nouns they modify to take a particular case. The cases assigned by each preposition are based on the physical (or metaphorical) direction, or location, conveyed by it. For example, od (from, away from) and z (out of, off) assign the genitive case. Other prepositions take one of several cases, with their meaning dependent on the case; na means \\"onto\\" or \\"for\\" with the accusative case, but \\"on\\" with the locative.[59]\\r\\n\\r\\nExamples of declension patterns (using prepositions) for a few nouns with adjectives follow. Only one plural example is given, since plural declension patterns are similar across genders.\\r\\n\\r\\nThis is a glossed example of a sentence using several cases:\\r\\n\\r\\nEnglish: I carried the box into the house with my friend.\\r\\n\\r\\nCzech distinguishes three gendersmasculine, feminine, and neuterand the masculine gender is subdivided into animate and inanimate. With few exceptions, feminine nouns in the nominative case end in -a, -e, or consonant; neuter nouns in -o, -e, or -, and masculine nouns in a consonant.[60] Adjectives agree in gender and animacy (for masculine nouns in the accusative or genitive singular and the nominative plural) with the nouns they modify.[61] The main effect of gender in Czech is the difference in noun and adjective declension, but other effects include past-tense verb endings: for example, dlal (he did, or made); dlala (she did, or made) and dlalo (it did, or made).[62]\\r\\n\\r\\nNouns are also inflected for number, distinguishing between singular and plural. Typical of a Slavic language, Czech cardinal numbers one through four allow the nouns and adjectives they modify to take any case, but numbers over five place these nouns and adjectives in the genitive case when the entire expression is in nominative or accusative case. The Czech koruna is an example of this feature; it is shown here as the subject of a hypothetical sentence, and declined as genitive for numbers five and up.[63]\\r\\n\\r\\nNumerical words decline for case and, for numbers one and two, for gender. Numbers one through five are shown below as examples, and have some of the most exceptions among Czech numbers. The number one has declension patterns identical to those of the demonstrative pronoun, to.[64][65]\\r\\n\\r\\nAlthough Czech's grammatical numbers are singular and plural, several residuals of dual forms remain. Some nouns for paired body parts use a historical dual form to express plural in some cases: ruka (hand)ruce (nominative); noha (leg)nohama (instrumental), nohou (genitive/locative); oko (eye)o?i, and ucho (ear)u?i. While two of these nouns are neuter in their singular forms, all plural forms are considered feminine; their gender is relevant to their associated adjectives and verbs.[66] These forms are plural semantically, used for any non-singular count, as in mezi ?ty?ma o?ima (face to face, lit. among four eyes). The plural number paradigms of these nouns are actually a mixture of historical dual and plural forms. For example, nohy (legs; nominative/accusative) is a standard plural form of this type of noun.[67]\\r\\n\\r\\nCzech verb conjugation is less complex than noun and adjective declension because it codes for fewer categories. Verbs agree with their subjects in person (first, second or third) and number (singular or plural), and are  conjugated for tense (past, present or future). For example, the conjugated verb mluvme (we speak) is in the present tense and first-person plural; it is distinguished from other conjugations of the infinitive mluvit by its ending, -me.[68]\\r\\n\\r\\nTypical of Slavic languages, Czech marks its verbs for one of two grammatical aspects: perfective and imperfective. Most verbs are part of inflected aspect pairsfor example, koupit (perfective) and kupovat (imperfective). Although the verbs' meaning is similar, in perfective verbs the action is completed and in imperfective verbs it is ongoing. This is distinct from past and present tense,[69] and any Czech verb of either aspect can be conjugated into any of its three tenses.[68] Aspect describes the state of the action at the time specified by the tense.[69]\\r\\n\\r\\nThe verbs of most aspect pairs differ in one of two ways: by prefix or by suffix. In prefix pairs, the perfective verb has an added prefixfor example, the imperfective pst (to write, to be writing) compared with the perfective napsat (to write down, to finish writing). The most common prefixes are na-, o-, po-, s-, u-, vy-, z- and za-.[70] In suffix pairs, a different infinitive ending is added to the perfective stem; for example, the perfective verbs koupit (to buy) and prodat (to sell) have the imperfective forms kupovat and prodvat.[71] Imperfective verbs may undergo further morphology to make other imperfective verbs (iterative and frequentative forms), denoting repeated or regular action. The verb jt (to go) has the iterative form chodit (to go repeatedly) and the frequentative form chodvat (to go regularly).[72]\\r\\n\\r\\nMany verbs have only one aspect, and verbs describing continual states of beingbyt (to be), chtt (to want), moct (to be able to), le?et (to lie down, to be lying down)have no perfective form. Conversely, verbs describing immediate states of changefor example, othotnt (to become pregnant) and nadchnout se (to become enthusiastic)have no imperfective aspect.[73]\\r\\n\\r\\nAlthough Czech's use of present and future tense is largely similar to that of English, the language uses past tense to represent the English present perfect and past perfect; ona b?ela could mean she ran, she has run or she had run.[74]\\r\\n\\r\\nIn some contexts, Czech's perfective present (which differs from the English present perfect) implies future action; in others, it connotes habitual action.[75] As a result, the language has a proper future tense to minimize ambiguity. The future tense does not involve conjugating the verb describing an action to be undertaken in the future; instead, the future form of byt (as shown in the table at left) is placed before the infinitive (for example, budu jst\\"I will eat\\").[76]\\r\\n\\r\\nThis conjugation is not followed by byt itself, so future-oriented expressions involving nouns, adjectives, or prepositions (rather than verbs) omit byt. \\"I will be happy\\" is translated as Budu ??astny (not Budu byt ??astny).[76]\\r\\n\\r\\nThe infinitive form ends in t (archaically, ti). It is the form found in dictionaries and the form that follows auxiliary verbs (for example, m??u t sly?et\\"I can hear you\\").[77] Czech verbs have three grammatical moods: indicative, imperative and conditional.[78] The imperative mood adds specific endings for each of three person (or number) categories: -?/-i/-ej for second-person singular, -te/-ete/-ejte for second-person plural and -me/-eme/-ejme for first-person plural.[79] The conditional mood is formed with a particle after the past-tense verb. This mood indicates possible events, expressed in English as \\"I would\\" or \\"I wish\\".[80]\\r\\n\\r\\nMost Czech verbs fall into one of five classes, which determine their conjugation patterns. The future tense of byt would be classified as a Class I verb because of its endings. Examples of the present tense of each class and some common irregular verbs follow in the tables below:[81]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nCzech has one of the most phonemic orthographies of all European languages. Its thirty-one graphemes represent thirty sounds (in most dialects, i and y have the same sound), and it contains only one digraph: ch, which follows h in the alphabet.[82] As a result, some of its characters have been used by phonologists to denote corresponding sounds in other languages. The characters q, w and x appear only in foreign words.[83] The h?ek () is used with certain letters to form new characters: ?, ?, and ?, as well as , , ?, ?, and ? (the latter five uncommon outside Czech). The last two letters are sometimes written with a comma above (?, an abbreviated h?ek) because of their height.[84] The character ܇ exists only in loanwords and onomatopoeia.[85]\\r\\n\\r\\nUnlike most European languages, Czech distinguishes vowel length; long vowels are indicated by an acute accent or, occasionally with ?, a ring. Long u is usually written ~ at the beginning of a word or morpheme (~roda, ne~rodny) and ? elsewhere,[86] except for loanwords (sk~tr) or onomatopoeia (b~).[87] Long vowels and  are not considered separate letters in the alphabetical order.[88]\\r\\n\\r\\nCzech typographical features not associated with phonetics generally resemble those of most Latin European languages, including English. Proper nouns, honorifics, and the first letters of quotations are capitalized, and punctuation is typical of other Latin European languages. Writing of ordinal numerals is similar to most European languages. The Czech language uses a decimal comma instead of a decimal point. When writing a long number, spaces between every three numbers (e.g. between hundreds and thousands) may be used for better orientation in handwritten texts, but not in decimal places, like in English. The number 1,234,567.8910 may be written as 1234567,8910 or 1 234 567,8910. Ordinal numbers (1st) use a point as in German (1.). In proper noun phrases (except personal names), only the first word is capitalized (Pra?sky hrad, Prague Castle).[89][90]\\r\\n\\r\\nThe main vernacular of Bohemia is \\"Common Czech\\", based on the dialect of the Prague region.\\r\\nOther Bohemian dialects have become marginalized, while Moravian dialects remain more widespread, with a political movement for Moravian linguistic revival active since the 1990s.\\r\\n\\r\\nThe main Czech vernacular, spoken primarily in and around Prague but also throughout the country, is known as Common Czech (obecn ?e?tina). This is an academic distinction; most Czechs are unaware of the term or associate it with vernacular (or incorrect) Czech.[91] Compared to standard Czech, Common Czech is characterized by simpler inflection patterns and differences in sound distribution.[92]\\r\\n\\r\\nCommon Czech has become ubiquitous in most parts of the Czech Republic since the later 20th century. It is usually defined as an interdialect used in common speech in Bohemia and western parts of Moravia (by about two thirds of all inhabitants of the Czech Republic). Common Czech is not codified, but some of its elements have become adopted in the written standard. \\r\\nSince the second half of the 20th century, Common Czech elements have also been spreading to regions previously unaffected, as a consequence of media influence.\\r\\nStandard Czech is still the norm for politicians, businesspeople and other Czechs in formal situations, but Common Czech is gaining ground in journalism and the mass media.[92]\\r\\n\\r\\nCommon Czech is characterized by quite regular differences from the standard morphology and phonology. These variations are more or less common among all Common Czech speakers:[93]\\r\\n\\r\\nExample of declension (with the comparison with the standard Czech):\\r\\n\\r\\nmlady ?lovk ÿ young man/person, mlad lid ÿ young people, mlady stt ÿ young state, mlad ?ena ÿ young woman, mlad zv?e ÿ young animal\\r\\n\\r\\nApart from the Common Czech vernacular, there remain a variety of other Bohemian dialects, mostly in marginal rural areas. Dialect use began to weaken in the second half of the 20th century, and by the early 1990s regional dialect use was stigmatized, associated with the shrinking lower class and used in literature or other media for comedic effect. Increased travel and media availability to dialect-speaking populations has encouraged them to shift to (or add to their own dialect) standard Czech.[95]\\r\\n\\r\\nThe Czech Statistical Office in 2003 recognized the following Bohemian dialects:[96]\\r\\n\\r\\nBohemian dialects use a slightly different set of vowel phonemes to standard Czech. The phoneme /??/ is peripheral and is replaced by /i?/, and a second native diphthong /e??/ occurs, usually in places where standard Czech has /i?/.[97]\\r\\n\\r\\nThe Czech dialects spoken in Moravia and Silesia are known as Moravian (morav?tina). In the Austro-Hungarian Empire, \\"Bohemian-Moravian-Slovak\\" was a language citizens could register as speaking (with German, Polish and several others).[98] Of the Czech dialects, only Moravian is distinguished in nationwide surveys by the Czech Statistical Office. As of 2011, 62,908 Czech citizens spoke Moravian as their first language and 45,561 were diglossal (speaking Moravian and standard Czech as first languages).[99]\\r\\n\\r\\nBeginning in the sixteenth century, some varieties of Czech resembled Slovak;[17] the southeastern Moravian dialects, in particular, are sometimes considered dialects of Slovak rather than Czech. These dialects form a continuum between the Czech and Slovak languages,[100] using the same declension patterns for nouns and pronouns and the same verb conjugations as Slovak.[101]\\r\\n\\r\\nThe Czech Statistical Office in 2003 recognized the following Moravian dialects:[96]\\r\\n\\r\\nIn a 1964 textbook on Czech dialectology, B?etislav Koudela used the following sentence to highlight phonetic differences between dialects:[102]\\r\\n\\r\\nCzech and Slovak have been considered mutually intelligible; speakers of either language can communicate with greater ease than those of any other pair of West Slavic languages. Since the 1993 dissolution of Czechoslovakia, mutual intelligibility has declined for younger speakers, probably because Czech speakers now experience less exposure to Slovak and vice versa.[103]\\r\\n\\r\\nIn phonetic differences, Czech is characterized by a glottal stop before initial vowels and Slovak by its less-frequent use of long vowels than Czech;[104] however, Slovak has long forms of the consonants r and l when they function as vowels.[105] Phonemic differences between the two languages are generally consistent, typical of two dialects of a language. Grammatically, although Czech (unlike Slovak) has a fully productive vocative case,[104] both languages share a common syntax.[17]\\r\\n\\r\\nOne study showed that Czech and Slovak lexicons differed by 80 percent, but this high percentage was found to stem primarily from differing orthographies and slight inconsistencies in morphological formation;[106] Slovak morphology is more regular (when changing from the nominative to the locative case, Praha becomes Praze in Czech and Prahe in Slovak). The two lexicons are generally considered similar, with most differences found in colloquial vocabulary and some scientific terminology. Slovak has slightly more borrowed words than Czech.[17]\\r\\n\\r\\nThe similarities between Czech and Slovak led to the languages being considered a single language by a group of 19th-century scholars who called themselves \\"Czechoslavs\\" (?echoslovan), believing that the peoples were connected in a way which excluded German Bohemians and (to a lesser extent) Hungarians and other Slavs.[107] During the First Czechoslovak Republic (1918ÿ1938), although \\"Czechoslovak\\" was designated as the republic's official language, both Czech and Slovak written standards were used. Standard written Slovak was partially modeled on literary Czech, and Czech was preferred for some official functions in the Slovak half of the republic. Czech influence on Slovak was protested by Slovak scholars, and when Slovakia broke off from Czechoslovakia in 1938 as the Slovak State (which then aligned with Nazi Germany in World War II), literary Slovak was deliberately distanced from Czech. When the Axis powers lost the war and Czechoslovakia reformed, Slovak developed somewhat on its own (with Czech influence); during the Prague Spring of 1968, Slovak gained independence from (and equality with) Czech,[17] due to the transformation of Czechoslovakia from a unitary state to a federation. Since the dissolution of Czechoslovakia in 1993, \\"Czechoslovak\\" has referred to improvised pidgins of the languages which have arisen from the decrease in mutual intelligibility.[108]\\r\\n\\r\\nCzech vocabulary derives primarily from Slavic, Baltic and other Indo-European roots. Although most verbs have Balto-Slavic origins, pronouns, prepositions and some verbs have wider, Indo-European roots.[109] Some loanwords have been restructured by folk etymology to resemble native Czech words (h?bitov, \\"graveyard\\" and listina, \\"list\\").[110]\\r\\n\\r\\nMost Czech loanwords originated in one of two time periods. Earlier loanwords, primarily from German,[111] Greek and Latin,[112] arrived before the Czech National Revival. More recent loanwords derive primarily from English and French,[111] and also from Hebrew, Arabic and Persian. Many Russian loanwords, principally animal names and naval terms, also exist in Czech.[113]\\r\\n\\r\\nAlthough older German loanwords were colloquial, recent borrowings from other languages are associated with high culture.[111] During the nineteenth century, words with Greek and Latin roots were rejected in favor of those based on older Czech words and common Slavic roots; \\"music\\" is muzyka in Polish and ֿ (muzyka) in Russian, but in Czech it is hudba.[112] Some Czech words have been borrowed as loanwords into English and other languagesfor example, robot (from robota, \\"labor\\")[114] and polka (from polka, \\"Polish woman\\" or from \\"p?lka\\" \\"half\\").[115]\\r\\n\\r\\nAccording to Article 1 of the United Nations Universal Declaration of Human Rights:\\r\\n\\r\\nCzech: V?ichni lid se rod svobodn a sob rovn co do d?stojnosti a prv. Jsou nadni rozumem a svdomm a maj spolu jednat v duchu bratrstv.[116]\\r\\n\\r\\nEnglish: \\"All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood.\\"[117]","input":"What is the language in the czech republic?"},{"output":"Samuel Butler","context":"Erewhon: or, Over the Range /?.r?.hw?n/[1] is a novel by Samuel Butler which was first published anonymously in 1872.[2] The title is also the name of a country, supposedly discovered by the protagonist. In the novel, it is not revealed where Erewhon is, but it is clear that it is a fictional country. Butler meant the title to be understood as the word \\"nowhere\\" backwards even though the letters \\"h\\" and \\"w\\" are transposed. The book is a satire on Victorian society.[3]\\r\\nThe first few chapters of the novel dealing with the discovery of Erewhon are in fact based on Butler's own experiences in New Zealand where, as a young man, he worked as a sheep farmer on Mesopotamia Station for about four years (1860ÿ64), and explored parts of the interior of the South Island and which he wrote about in his A First Year in Canterbury Settlement (1863).\\r\\n\\r\\n\\r\\nThe greater part of the book consists of a description of Erewhon. The nature of this nation is intended to be ambiguous. At first glance, Erewhon appears to be a Utopia, yet it soon becomes clear that this is far from the case. Yet for all the failings of Erewhon, it is also clearly not a dystopia, such as that depicted in George Orwell's Nineteen Eighty-Four. As a satirical utopia, Erewhon has sometimes been compared to Gulliver's Travels (1726), a classic novel by Jonathan Swift; the image of Utopia in this latter case also bears strong parallels with the self-view of the British Empire at the time. It can also be compared to the William Morris novel, News from Nowhere.\\r\\nErewhon satirises various aspects of Victorian society, including criminal punishment, religion and anthropocentrism. For example, according to Erewhonian law, offenders are treated as if they were ill, whereas ill people are looked upon as criminals. Another feature of Erewhon is the absence of machines; this is due to the widely shared perception by the Erewhonians that they are potentially dangerous. This last aspect of Erewhon reveals the influence of Charles Darwin's evolution theory; Butler had read On the Origin of Species soon after it was published in 1859.\\r\\nButler developed the three chapters of Erewhon that make up \\"The Book of the Machines\\" from a number of articles that he had contributed to The Press, which had just begun publication in Christchurch, New Zealand, beginning with \\"Darwin among the Machines\\" (1863). Butler was the first to write about the possibility that machines might develop consciousness by Darwinian Selection.[4] Many dismissed this as a joke; but, in his preface to the second edition, Butler wrote, \\"I regret that reviewers have in some cases been inclined to treat the chapters on Machines as an attempt to reduce Mr. Darwin's theory to an absurdity. Nothing could be further from my intention, and few things would be more distasteful to me than any attempt to laugh at Mr. Darwin.\\"\\r\\nAfter its first release, this book sold far better than any of Butler's other works,[clarification needed] perhaps because the British public assumed that the anonymous author was some better-known figure[citation needed] (the favourite being Lord Lytton, who had published The Coming Race two years previously). In a 1945 broadcast, George Orwell praised the book and said that when Butler wrote Erewhon it needed \\"imagination of a very high order to see that machinery could be dangerous as well as useful.\\" He recommended the novel, though not its sequel, Erewhon Revisited.[5]\\r\\nThe French philosopher Gilles Deleuze used ideas from Butler's book at various points in the development of his philosophy of difference. In Difference and Repetition (1968), Deleuze refers to what he calls \\"Ideas\\" as \\"Erewhon.\\" \\"Ideas are not concepts,\\" he explains, but rather \\"a form of eternally positive differential multiplicity, distinguished from the identity of concepts.\\"[6] \\"Erewhon\\" refers to the \\"nomadic distributions\\" that pertain to simulacra, which \\"are not universals like the categories, nor are they the hic et nunc or nowhere, the diversity to which categories apply in representation.\\"[7] \\"Erewhon,\\" in this reading, is \\"not only a disguised no-where but a rearranged now-here.\\"[8]\\r\\nIn his collaboration with Flix Guattari, Anti-Oedipus (1972), Deleuze draws on Butler's \\"The Book of the Machines\\" to \\"go beyond\\" the \\"usual polemic between vitalism and mechanism\\" as it relates to their concept of \\"desiring-machines\\":[9]\\r\\nFor one thing, Butler is not content to say that machines extend the organism, but asserts that they are really limbs and organs lying on the body without organs of a society, which men will appropriate according to their power and their wealth, and whose poverty deprives them as if they were mutilated organisms. For another, he is not content to say that organisms are machines, but asserts that they contain such an abundance of parts that they must be compared to very different parts of distinct machines, each relating to the others, engendered in combination with the others ... He shatters the vitalist argument by calling in question the specific or personal unity of the organism, and the mechanist argument even more decisively, by calling in question the structural unity of the machine.\\r\\nIn 1994, a group of ex-Yugoslavian writers in Amsterdam, who had established the PEN centre of Yugoslav Writers in Exile, published a single issue of a literary journal Erewhon.[10]\\r\\nNew Zealand sound art organisation, the Audio Foundation, published in 2012 an anthology edited by Bruce Russell named Erewhon Calling after Butler's book.[11]\\r\\nIn 2014, New Zealand artist Gavin Hipkins released his first feature film, titled Erewhon and based on Butler's book. It premiered at the New Zealand International Film Festival and the Edinburgh Art Festival.[12]\\r\\nIn \\"Smile\\", the second episode of the 2017 season of Doctor Who, the Doctor and Bill explore a spaceship named Erehwon. Despite the slightly different spelling, the episode writer Frank Cottrell-Boyce confirmed[13] that this was a reference to Butler's novel.","input":"Who wrote erewhom what kind of novel is it?"},{"output":"Port Isaac, Cornwall, England","context":"Doc Martin is a British television medical comedy drama series starring Martin Clunes in the title role. It was created by Dominic Minghella[1] after the character of Dr Martin Bamford in the 2000 comedy film Saving Grace.[2] The show is set in the fictional seaside village of Portwenn and filmed on location in the village of Port Isaac, Cornwall, England, with most interior scenes shot in a converted local barn.\\r\\nSeven series aired between 2004 and 2015, and a feature-length special aired on Christmas Day 2006. The eighth and most recent series began airing on ITV on 20 September 2017, and will stream in the United States and Canada on Acorn TV. An American TV remake of the series is also being planned.[3] While it was initially reported that the series would end after Series 9 in 2018, Martin Clunes clarified that it had only been commissioned as far as the next year, thereby not ruling out future plans by the broadcaster.[4]\\r\\n\\r\\n\\r\\nDr Martin Ellingham (Martin Clunes), a brilliant and successful vascular surgeon at Imperial College London, develops haemophobia (a fear of blood), forcing him to stop practising surgery. He obtains a post as the sole general practitioner (GP) in the sleepy Cornish village of Portwenn, where he had spent childhood holidays with his Aunt Joan (Stephanie Cole), who owns a local farm. Upon arriving in Portwenn?ÿ where, to his frustration, the locals address him as \\"Doc Martin\\"?ÿ he finds the surgery (medical clinic) in chaos and inherits an incompetent receptionist, Elaine Denham (Lucy Punch). In Series 2ÿ4, she is replaced by Pauline Lamb (Katherine Parkinson), a new receptionist, and later also a phlebotomist. In Series 5, Morwenna Newcross (Jessica Ransom) takes up the post.\\r\\nThe show revolves around Ellingham's interactions with the local Cornish villagers. Despite his medical excellence, Ellingham is grouchy, pugnacious, and lacks social skills. His direct, emotionless manner offends many of the villagers, made worse by his invariably unpleasant responses to their ignorant, often foolish, comments. They perceive him to be hot-tempered and lacking in a bedside manner, whereas he feels he is performing his duties in a professional and by-the-book manner, not wasting time chatting. Ellingham is very deadpan and dresses formally in a business suit and tie, regardless of the weather or the occasion, and he never takes off his jacket, even when delivering babies. He does not smoke and has no hesitation in pointing out the risks of unhealthy behaviours, both in private and in public gatherings.\\r\\nThe villagers eventually discover his fear of blood, and the frequent and debilitating bouts of nausea and vomiting it causes. In spite of this handicap, Ellingham proves to be an expert diagnostician and responds effectively to various emergencies in his medical practice; thus, he gradually gains grudging respect from his neighbours. Ellingham's aunt, Joan Norton (Stephanie Cole), provides emotional support in the face of the controversy his impatient manner causes among the villagers. When she dies after a heart attack, her sister Ruth (Eileen Atkins), a retired psychiatrist, comes to Portwenn to take care of her affairs, and eventually decides to use the village as a permanent retreat, offering Martin the support Joan had provided.\\r\\nEllingham finds it difficult to express his developing romantic feelings towards primary school teacher Louisa Glasson (Caroline Catz). He often spoils rare tender moments with, for example, a comment about an unpleasant medical condition or by requesting a stool sample. Martin eventually proposes to Louisa, but on the day of their wedding they suddenly break their engagement. Louisa leaves for a job in London; returning after six months, visibly pregnant with Martin's child. When the child is born, the couple renew their relationship. Following much indecision, Martin resolves to remain in Portwenn and marries Louisa, but continued arguments relating to his insensitive nature lead to their becoming estranged again. In Series 7, Louisa lives in Martin's surgery with their baby James Henry, while Martin boards in the village and sees a therapist for his inability to form and maintain relationships.\\r\\nMartin Clunes originally played a character called \\"Dr Martin Bamford\\" in the 2000 film Saving Grace and its two made-for-TV prequels, Doc Martin and Doc Martin and the Legend of the Cloutie, which were made by British Sky Broadcasting (BSkyB). The prequels show Bamford as a successful obstetrician, rather than a surgeon, who finds out that his wife has been carrying on extramarital affairs behind his back. After confronting her with his discovery, he escapes London and heads for Port Isaac, a small coastal town in Cornwall which he remembers fondly from his youth. Shortly after he arrives, he is involved in the mystery of the \\"Jellymaker\\" and, following the departure of the village's resident GP, decides to stay and fill the vacancy. In these three films the village is not known as Portwenn.\\r\\nThe Martin Bamford character is friendly and laid-back, seeming to enjoy his retreat from the career pressures and conflicts he left behind in London. He drinks and smokes carelessly, including a mild illegal drug, and has no problem getting his hands and clothes dirty by temporarily working as a lobster and crab fisherman aboard a local boat.\\r\\nThe original deal had been to produce two television films per year for three years, but Sky Pictures folded after the first two episodes were made, so Clunes' company tried to sell the franchise to ITV. The new network felt that the doctor character should be portrayed as a \\"townie\\", a fish out of water who is uncomfortable in the countryside. They also wanted something darker, so Clunes suggested that the doctor be curmudgeonly, socially inept, and formal. The new doctor's surname was changed to Ellingham, an anagram of the last name of the new writer, Dominic Minghella, who was brought in to rework the doctor's background and create a new cast of supporting characters.\\r\\nAlong with Clunes, the only actors to appear in both versions of Doc Martin are Tristan Sturrock and Tony Maudsley.\\r\\nEight series totaling 62 episodes aired on ITV in the UK between 2004 and 2017. Episodes are just under 50 minutes long, except for the 2006 TV film which is 92 minutes. In the US, American Public Television provided the 2006 TV film as a two-part episode, with the second episode airing the week after the first.\\r\\nIn the UK, Doc Martin has been a ratings success for ITV with the third series achieving ITV's best midweek drama performance in the 9pm Monday slot since December 2004.[5] The final episode of the third series was watched by 10.37 million viewers, which is the programme's highest-ever viewing figure for a single episode.[6]\\r\\nIn 2009, Doc Martin was moved to a 9pm Sunday time slot for the broadcast of Series 4. That change meant that it followed-on from ITV's The X Factor programme. Series 4 ratings were adversely affected by STV not screening the majority of ITV drama productions in Scotland. The final episode of Series 4 had ratings of 10.29 million viewers.[7] STV went back on its decision not to screen ITV drama in Scotland. Series 4 of Doc Martin was broadcast on Sunday afternoons in August 2011.\\r\\nIn 2004, Doc Martin won the British Comedy Award for Best TV Comedy Drama, having also been nominated as Best New TV Comedy. In the same year, Martin Clunes won the Best TV Comedy Actor award, primarily for his portrayal of Doc Martin.\\r\\nNotro Films produced a Spanish version under the title Doctor Mateo for Antena 3 Televisi܇n. It aired in 2009 and was shot in Lastres, Asturias, called the fictional village of San Martn del Sella.[citation needed] French television producers Ego Productions, in cooperation with TF1, have produced a French version of the series starring Thierry Lhermitte as Dr Martin Le Foll, with the series based in the fictional Breton town of Port-Garrec.[8][9]\\r\\nIn Germany, Doktor Martin, an adaptation of the original series, airs on ZDF with Axel Milberg as Doktor Martin Helling,[10] a surgeon from Berlin. The counterpart of Portwenn was the real village of Neuharlingersiel in East Frisia. In Greece, Kliniki Periptosi, an adaptation of the original series, was aired in November 2011 on Mega Channel with Yannis Bezos as Markos Staikos, a surgeon from New York.[citation needed]\\r\\nIn the Netherlands Dokter Tinus based on the original series began airing in late August 2012 on SBS6, with the main role being played by actor Thom Hoffman. The series was shot in Woudrichem.[citation needed] A Russian version is mentioned in the Series 5 DVD bonus material.[full citation needed] In 2014, Czech Television began filming their own TV series starring Miroslav Donutil, which is heavily inspired by the original British series.[11] The series started to air from 4 September 2015. The Czech version is set in the Beskydy mountains, which is a picturesque area in the east of the Czech Republic, like Portwenn, a long way from the capital, Prague, and dependent on the tourist industry.[12]\\r\\nAs of January?2016,[update] an American remake of the show is being planned, led by Marta Kauffman, co-creator of the successful TV show Friends.[3]\\r\\nSeries 1, 2 and 3 and \\"On the Edge\\" were released separately in Region 1 and 2 and in the \\"complete Series 1 to 3\\" box set. Series 3 was released on 2 February 2010 and Series 4 was released in Region 1 and 2 on 6 July 2010. Series 5 was released in Region 1 on 5 June 2012 and Region 2 on 5 March 2012. A complete boxset of Series 1-5 is also available in Region 2. Series 6 of Doc Martin was released in Region 1 in December 2013 and in the UK (Region 2) on 24 March 2014. Series 7 of Doc Martin was released on DVD/Blu-ray in Region 1 on December 8, 2015 and in the UK (Region 2) on 16 November 2015.\\r\\nIn Region 4, Series 1, 2, 4, and \\"On the Edge\\" were released separately and in a nine-disc boxset entitled \\"Doc Martin: Comedy Cure\\", as well as an earlier seven-disc boxset not including Series 4. The two Sky Pictures telefilms were individually released in Region 4 (as 'Doc Martin: volume 1' and 'Doc Martin: volume 2, the Legend of the Cloutie') on the Magna Pacific label, but are now out-of-print. Series 1-8 are streaming on Acorn TV in the U.S. and Canada. The show is available on Netflix. Series 1-6 are currently available on Amazon Prime Video.\\r\\nIn 2013, it was announced that two novels were to be released to coincide with the sixth series.[13]","input":"What town is the tv show doc martin filmed in?"},{"output":"343,829 as of the 2010 U.S. Census","context":"","input":"What's the population in new orleans louisiana?"},{"output":"April 30, 1916","context":"Daylight saving time (abbreviated DST), sometimes referred to as daylight savings time in U.S., Canadian, and Australian speech,[1][2] and known as British Summer Time (BST) in the UK and just summer time in some countries, is the practice of advancing clocks during summer months so that evening daylight lasts longer, while sacrificing normal sunrise times. Typically, regions that use daylight saving time adjust clocks forward one hour close to the start of spring and adjust them backward in the autumn to standard time.[3]\\r\\nGeorge Hudson proposed the idea of daylight saving in 1895.[4] The German Empire and Austria-Hungary organized the first nationwide implementation, starting on April 30, 1916. Many countries have used it at various times since then, particularly since the energy crisis of the 1970s.\\r\\nDST is generally not observed near the equator, where sunrise times do not vary enough to justify it. Some countries observe it only in some regions; for example, southern Brazil observes it while equatorial Brazil does not.[5] Only a minority of the world's population uses DST, because Asia and Africa generally do not observe it.\\r\\nDST clock shifts sometimes complicate timekeeping and can disrupt travel, billing, record keeping, medical devices, heavy equipment,[6] and sleep patterns.[7] Computer software often adjusts clocks automatically, but policy changes by various jurisdictions of DST dates and timings may be confusing.[8]\\r\\n\\r\\n\\r\\nIndustrialized societies generally follow a clock-based schedule for daily activities that do not change throughout the course of the year. The time of day that individuals begin and end work or school, and the coordination of mass transit, for example, usually remain constant year-round. In contrast, an agrarian society's daily routines for work and personal conduct are more likely governed by the length of daylight hours[9][10] and by solar time, which change seasonally because of the Earth's axial tilt. North and south of the tropics daylight lasts longer in summer and shorter in winter, with the effect becoming greater the further one moves away from the tropics.\\r\\nBy synchronously resetting all clocks in a region to one hour ahead of standard time, individuals who follow such a year-round schedule will wake an hour earlier than they would have otherwise; they will begin and complete daily work routines an hour earlier, and they will have available to them an extra hour of daylight after their workday activities.[11][12] However, they will have one less hour of daylight at the start of each day, making the policy less practical during winter.[13][14]\\r\\nWhile the times of sunrise and sunset change at roughly equal rates as the seasons change, proponents of Daylight Saving Time argue that most people prefer a greater increase in daylight hours after the typical \\"nine to five\\" workday.[15][16] Supporters have also argued that DST decreases energy consumption by reducing the need for lighting and heating, but the actual effect on overall energy use is heavily disputed.\\r\\nThe manipulation of time at higher latitudes (for example Iceland, Nunavut or Alaska) has little impact on daily life, because the length of day and night changes more extremely throughout the seasons (in comparison to other latitudes), and thus sunrise and sunset times are significantly out of phase with standard working hours regardless of manipulations of the clock.[17] DST is also of little use for locations near the equator, because these regions see only a small variation in daylight in the course of the year.[18] The effect also varies according to how far east or west the location is within its time zone, with locations farther east inside the time zone benefiting more from DST than locations farther west in the same time zone.[19]\\r\\nAlthough they did not fix their schedules to the clock in the modern sense, ancient civilizations adjusted daily schedules to the sun more flexibly than DST does, often dividing daylight into twelve hours regardless of daytime, so that (for example) each daylight hour became progressively longer during spring and shorter during autumn.[20] For example, the Romans kept time with water clocks that had different scales for different months of the year: at Rome's latitude the third hour from sunrise, hora tertia, started by modern standards at 09:02 solar time and lasted 44 minutes at the winter solstice, but at the summer solstice it started at 06:58 and lasted 75 minutes.[21] After ancient times, equal-length civil hours eventually[when?] supplanted unequal ones, so civil time no longer varies by season. Unequal hours are still used in a few traditional settings, such as some monasteries of Mount Athos[22] and all Jewish ceremonies.[23]\\r\\nDuring his time as an American envoy to France (1776-1785), Benjamin Franklin, publisher of the old English proverb \\"Early to bed, and early to rise, makes a man healthy, wealthy and wise\\",[24][25] anonymously published a letter suggesting that Parisians economize on candles by rising earlier to use morning sunlight.[26] This 1784 satire proposed taxing window shutters, rationing candles, and waking the public by ringing church bells and firing cannons at sunrise.[27] Despite common misconception, Franklin did not actually propose DST; 18th-century Europe did not even keep precise schedules. However, this soon changed as rail transport and communication networks came to require a standardization of time unknown in Franklin's day.[28]\\r\\nThe New Zealand entomologist George Hudson first proposed modern DST. Hudson's shift-work job gave him leisure time to collect insects and led him to value after-hours daylight.[4] In 1895 he presented a paper to the Wellington Philosophical Society proposing a two-hour daylight-saving shift,[11] and after considerable interest was expressed in Christchurch, he followed up with an 1898 paper.[29] Many publications credit DST proposal to the prominent English builder and outdoorsman William Willett,[30] who independently conceived DST in 1905 during a pre-breakfast ride, when he observed with dismay how many Londoners slept through a large part of a summer day.[16] An avid golfer, Willett also disliked cutting short his round at dusk.[31] His solution was to advance the clock during the summer months, a proposal he published two years later.[32] The Liberal Party member of parliament (MP) Robert Pearce took up Willett's proposal, introducing the first Daylight Saving Bill to the House of Commons on February 12, 1908.[33] A select committee was set up to examine the issue, but Pearce's bill did not become law, and several other bills failed in the following years. Willett lobbied for the proposal in the UK until his death in 1915.\\r\\nWilliam Sword Frost, mayor of Orillia, Ontario, introduced daylight saving time in the municipality during his tenure from 1911 to 1912.[34]\\r\\nStarting on April 30, 1916, the German Empire and its World War I ally Austria-Hungary introduced DST (German: Sommerzeit) as a way to conserve coal during wartime. Britain, most of its allies, and many European neutrals soon followed suit. Russia and a few other countries waited until the next year, and the United States adopted daylight saving in 1918.\\r\\nBroadly speaking, most jurisdictions abandoned daylight saving time in the years after the war ended in 1918 (with some notable exceptions including Canada, the UK, France, and Ireland). However, many different places adopted it for periods of time during the following decades and it became common during World War II. It became widely adopted, particularly in North America and Europe, starting in the 1970s as a result of the 1970s energy crisis.\\r\\nSince then, the world has seen many enactments, adjustments, and repeals.[35] For specific details, see Daylight saving time by country.\\r\\nIn the United States, a one-hour time shift occurs at 02:00 local time. In spring the clock jumps forward from the last instant of 01:59 standard time to 03:00 DST and that day has 23?hours. In autumn the clock jumps backward from the last instant of 01:59 DST to 01:00 standard time, repeating that hour, and that day has 25?hours.[36] A digital display of local time does not read 02:00 exactly at the shift to summer time, but instead jumps from 01:59:59.9 forward to 03:00:00.0.\\r\\nClock shifts are usually scheduled near a weekend midnight to lessen disruption to weekday schedules. A one-hour shift is customary.[37] Twenty-minute and two-hour shifts have been used in the past.\\r\\nCoordination strategies differ when adjacent time zones shift clocks. The European Union shifts all zones at the same instant, at 01:00 Greenwich Mean Time[38] or 02:00 CET or 03:00 EET. The result of this procedure is that Eastern European Time is always one hour ahead of Central European Time, at the cost of the shift happening at different local times.[39] In contrast most of North America shifts at 02:00 local time, so its zones do not shift at the same instant; for example, Mountain Time is temporarily (for one hour) zero hours ahead of Pacific Time, instead of one hour ahead, in the autumn and two hours, instead of one, ahead of Pacific Time in the spring. In the past, Australian districts went even further and did not always agree on start and end dates; for example, in 2008 most DST-observing areas shifted clocks forward on October 5 but Western Australia shifted on October 26.[40] In some cases only part of a country shifts; for example, in the U.S., Hawaii and most of Arizona do not observe DST.[41][42]\\r\\nStart and end dates vary with location and year. Since 1996, European Summer Time has been observed from the last Sunday in March to the last Sunday in October; previously the rules were not uniform across the European Union.[39] Starting in 2007, most of the United States and Canada observe DST from the second Sunday in March to the first Sunday in November, almost two-thirds of the year.[43] The 2007 U.S. change was part of the Energy Policy Act of 2005; previously, from 1987 through 2006, the start and end dates were the first Sunday in April and the last Sunday in October, and Congress retains the right to go back to the previous dates now that an energy-consumption study has been done.[44] Proponents for permanently retaining November as the month for ending DST point to Halloween as a reason to delay the changeto provide extra daylight on October 31.\\r\\nBeginning and ending dates are roughly the reverse in the southern hemisphere. For example, mainland Chile observed DST from the second Saturday in October to the second Saturday in March, with transitions at 24:00 local time.[45]\\r\\nAs a result, time difference between two regions varies along the year because of DST. Central European Time is usually six hours later than North American Eastern Time, except a few weeks in March and October/November. Likewise, the United Kingdom and mainland Chile could be five hours apart during the northern summer, three hours during the southern summer, and four hours a few weeks per year because of mismatch of changing dates.\\r\\nDaylight saving has caused controversy since it began.[3] Winston Churchill argued that it enlarges \\"the opportunities for the pursuit of health and happiness among the millions of people who live in this country\\"[46] and pundits have dubbed it \\"Daylight Slaving Time\\".[47] Historically, retailing, sports, and tourism interests have favored daylight saving, while agricultural and evening entertainment interests have opposed it, and its initial adoption had been prompted by energy crises and war.[48]\\r\\nThe fate of Willett's 1907 proposal illustrates several political issues involved. The proposal attracted many supporters, including Arthur Balfour, Churchill, David Lloyd George, Ramsay MacDonald, Edward VII (who used half-hour DST at Sandringham or \\"Sandringham time\\"), the managing director of Harrods, and the manager of the National Bank. However, the opposition was stronger: it included Prime Minister H. H. Asquith, Christie (the Astronomer Royal), George Darwin, Napier Shaw (director of the Meteorological Office), many agricultural organizations, and theatre owners. After many hearings the proposal was narrowly defeated in a parliamentary committee vote in 1909. Willett's allies introduced similar bills every year from 1911 through 1914, to no avail.[49] The U.S. was even more skeptical: Andrew Peters introduced a DST bill to the United States House of Representatives in May 1909, but it soon died in committee.[50]\\r\\nAfter Germany led the way with starting DST (German: Sommerzeit) during World War I on April 30, 1916 together with its allies to alleviate hardships from wartime coal shortages and air raid blackouts, the political equation changed in other countries; the United Kingdom used DST first on May 21, 1916.[51] U.S. retailing and manufacturing interests led by Pittsburgh industrialist Robert Garland soon began lobbying for DST, but were opposed by railroads. The U.S.'s 1917 entry to the war overcame objections, and DST was established in 1918.[52]\\r\\nThe war's end swung the pendulum back. Farmers continued to dislike DST, and many countries repealed it after the war. Britain was an exception: it retained DST nationwide but over the years adjusted transition dates for several reasons, including special rules during the 1920s and 1930s to avoid clock shifts on Easter mornings. Now under a European Community directive summer time begins annually on the last Sunday in March, which may be Easter Sunday (as in 2016).[39] The U.S. was more typical: Congress repealed DST after 1919. President Woodrow Wilson, like Willett an avid golfer, vetoed the repeal twice but his second veto was overridden.[53] Only a few U.S. cities retained DST locally thereafter,[54] including New York so that its financial exchanges could maintain an hour of arbitrage trading with London, and Chicago and Cleveland to keep pace with New York.[55] Wilson's successor Warren G. Harding opposed DST as a \\"deception\\". Reasoning that people should instead get up and go to work earlier in the summer, he ordered District of Columbia federal employees to start work at 08:00 rather than 09:00 during summer 1922. Some businesses followed suit though many others did not; the experiment was not repeated.[12]\\r\\nSince Germany's adoption in 1916, the world has seen many enactments, adjustments, and repeals of DST, with similar politics involved.[56]\\r\\nThe history of time in the United States includes DST during both world wars, but no standardization of peacetime DST until 1966.[57][58] In May 1965, for two weeks, St. Paul, Minnesota and Minneapolis, Minnesota were on different times, when the capital city decided to join most of the nation by starting Daylight Saving Time while Minneapolis opted to follow the later date set by state law.[59] In the mid-1980s, Clorox (parent of Kingsford Charcoal) and 7-Eleven provided the primary funding for the Daylight Saving Time Coalition behind the 1987 extension to U.S. DST, and both Idaho senators voted for it based on the premise that during DST fast-food restaurants sell more French fries, which are made from Idaho potatoes.[60]\\r\\nIn 1992, after a three-year trial of daylight saving in Queensland, Australia, a referendum on daylight saving was held and defeated with a 54.5% 'no' vote?ÿ with regional and rural areas strongly opposed, while those in the metropolitan south-east were in favor.[61] In 2005, the Sporting Goods Manufacturers Association and the National Association of Convenience Stores successfully lobbied for the 2007 extension to U.S. DST.[62] In December 2008, the Daylight Saving for South East Queensland (DS4SEQ) political party was officially registered in Queensland, advocating the implementation of a dual-time zone arrangement for daylight saving in South East Queensland while the rest of the state maintains standard time.[63] DS4SEQ contested the March 2009 Queensland state election with 32 candidates and received one percent of the statewide primary vote, equating to around 2.5% across the 32 electorates contested.[64] After a three-year trial, more than 55% of Western Australians voted against DST in 2009, with rural areas strongly opposed.[65] On April 14, 2010, after being approached by the DS4SEQ political party, Queensland Independent member Peter Wellington, introduced the Daylight Saving for South East Queensland Referendum Bill 2010 into the Queensland parliament, calling for a referendum at the next state election on the introduction of daylight saving into South East Queensland under a dual-time zone arrangement.[66] The Bill was defeated in the Queensland parliament on June 15, 2011.[67]\\r\\nIn the UK the Royal Society for the Prevention of Accidents supports a proposal to observe SDST's additional hour year-round, but is opposed in some industries, such as postal workers and farmers, and particularly by those living in the northern regions of the UK.[10]\\r\\nIn some Muslim countries, DST is temporarily abandoned during Ramadan (the month when no food should be eaten between sunrise and sunset), since the DST would delay the evening dinner. Ramadan took place in July and August in 2012. This concerns at least Morocco,[68][69] although Iran keeps DST during Ramadan.[70] Most Muslim countries do not use DST, partially for this reason.\\r\\nThe 2011 declaration by Russia that it would stay in DST all year long was subsequently followed by a similar declaration from Belarus.[71] Russia's plan generated widespread complaints due to the dark of wintertime morning, and thus was abandoned in 2014.[72] The country changed its clocks to Standard Time on October 26, 2014 and intends to stay there permanently.[73]\\r\\nProponents of DST generally argue that it saves energy, promotes outdoor leisure activity in the evening (in summer), and is therefore good for physical and psychological health, reduces traffic accidents, reduces crime or is good for business. Groups that tend to support DST are urban workers, retail businesses, outdoor sports enthusiasts and businesses, tourism operators, and others who benefit from having more hours of light after the end of a typical workday in the warmer months.\\r\\nOpponents argue that actual energy savings are inconclusive,[75] that DST increases health risks such as heart attack,[75] that DST can disrupt morning activities, and that the act of changing clocks twice a year is economically and socially disruptive and cancels out any benefit. Farmers have tended to oppose DST.[76][77]\\r\\nHaving a common agreement about the day's layout or schedule confers so many advantages that a standard schedule over whole countries or large areas has generally been chosen over ad hoc efforts in which some people get up earlier and others do not.[78] The advantages of coordination are so great that many people ignore whether DST is in effect by altering their nominal work schedules to coordinate with television broadcasts or daylight.[79] DST is commonly not observed during most of winter, because the days are shorter then; workers may have no sunlit leisure time, and students may need to leave for school in the dark.[13] Since DST is applied to many varying communities, its effects may be very different depending on their culture, light levels, geography, and climate. Because of this variation, it is hard to make generalized conclusions about the absolute effects of the practice. The costs and benefits may differ from place to place. Some areas may adopt DST simply as a matter of coordination with others rather than for any direct benefits.\\r\\nA 2017 meta-analysis of 44 studies found that DST leads to electricity savings of only 0.34% during the days when DST applies.[80][81] The meta-analysis furthermore found that \\"electricity savings are larger for countries farther away from the equator, while subtropical regions consume more electricity because of DST.\\"[80][81] This means that DST may conserve electricity in some countries, such as Canada and the United Kingdom, but be wasteful in other places, such as Mexico, the southern United States, and northern Africa. The savings in electricity may also be offset by extra use of other types of energy, such as heating fuel.\\r\\nThe period of Daylight Saving Time before the longest day is shorter than the period after, in several countries including the United States and Europe. This unequal split is an energy-saving measure.[citation needed] For example, in the U.S. the period of Daylight Saving Time is defined by the Energy Policy Act of 2005. The period for Daylight Saving Time was extended by changing the start date from the first Sunday of April to the second Sunday of March, and the end date from the last Sunday in October to the first Sunday in November.\\r\\nDST's potential to save energy comes primarily from its effects on residential lighting, which consumes about 3.5% of electricity in the United States and Canada.[82] Delaying the nominal time of sunset and sunrise reduces the use of artificial light in the evening and increases it in the morning. As Franklin's 1784 satire pointed out, lighting costs are reduced if the evening reduction outweighs the morning increase, as in high-latitude summer when most people wake up well after sunrise. An early goal of DST was to reduce evening usage of incandescent lighting, once a primary use of electricity.[83] Although energy conservation remains an important goal,[84] energy usage patterns have greatly changed since then. Electricity use is greatly affected by geography, climate, and economics, so the results of a study conducted in one place may not be relevant to another country or climate.[82]\\r\\nSeveral studies have suggested that DST increases motor fuel consumption.[82] The 2008 DOE report found no significant increase in motor gasoline consumption due to the 2007 United States extension of DST.[94]\\r\\nThe undisputed winners of DST are the retailers, sporting goods makers, and other businesses that benefit from extra afternoon sunlight.[85] Having more hours of sunlight in between the end of the typical workday and bedtime induces customers to shop and to participate in outdoor afternoon sports.[95] People are more likely to stop by a store on their way home from work if the sun is still up.[85] In 1984, Fortune magazine estimated that a seven-week extension of DST would yield an additional $30?million for 7-Eleven stores, and the National Golf Foundation estimated the extension would increase golf industry revenues $200?million to $300?million.[96] A 1999 study estimated that DST increases the revenue of the European Union's leisure sector by about 3%.[82]\\r\\nConversely, DST can harm some farmers,[75][97] young children, who have difficulty getting enough sleep at night when the evenings are bright,[75] and others whose hours are set by the sun.[98] One reason why farmers oppose DST is that grain is best harvested after dew evaporates, so when field hands arrive and leave earlier in summer, their labor is less valuable.[9] Dairy farmers are another group who complain of the change. Their cows are sensitive to the timing of milking, so delivering milk earlier disrupts their systems.[77][99] Today some farmers' groups are in favor of DST.[100]\\r\\nDST also hurts prime-time television broadcast ratings,[101][75] drive-ins and other theaters.[102]\\r\\nChanging clocks and DST rules has a direct economic cost, entailing extra work to support remote meetings, computer applications and the like. For example, a 2007 North American rule change cost an estimated $500?million to $1?billion,[103] and Utah State University economist William F. Shughart II has estimated the lost opportunity cost at around US$1.7?billion.[75] Although it has been argued that clock shifts correlate with decreased economic efficiency, and that in 2000 the daylight-saving effect implied an estimated one-day loss of $31?billion on U.S. stock exchanges,[104] the estimated numbers depend on the methodology.[105] The results have been disputed,[106] and the original authors have refuted the points raised by disputers.[107]\\r\\nIn 1975 the U.S. DOT conservatively identified a 0.7% reduction in traffic fatalities during DST, and estimated the real reduction at 1.5% to 2%,[108] but the 1976 NBS review of the DOT study found no differences in traffic fatalities.[13] In 1995 the Insurance Institute for Highway Safety estimated a reduction of 1.2%, including a 5% reduction in crashes fatal to pedestrians.[109] Others have found similar reductions.[110] Single/Double Summer Time (SDST), a variant where clocks are one hour ahead of the sun in winter and two in summer, has been projected to reduce traffic fatalities by 3% to 4% in the UK, compared to ordinary DST.[111] However, accidents do increase by as much as 11% during the two weeks that follow the end of British Summer Time.[112] It is not clear whether sleep disruption contributes to fatal accidents immediately after the spring clock shifts.[113] A correlation between clock shifts and traffic accidents has been observed in North America and the UK but not in Finland or Sweden. If this effect exists, it is far smaller than the overall reduction in traffic fatalities.[114] A 2009 U.S. study found that on Mondays after the switch to DST, workers sleep an average of 40 minutes less, and are injured at work more often and more severely.[115]\\r\\nDST likely reduces some kinds of crime, such as robbery and sexual assault, as fewer potential victims are outdoors after dusk.[116][86] Artificial outdoor lighting has a marginal and sometimes even contradictory influence on crime and fear of crime.[117]\\r\\nIn several countries, fire safety officials encourage citizens to use the two annual clock shifts as reminders to replace batteries in smoke and carbon monoxide detectors, particularly in autumn, just before the heating and candle season causes an increase in home fires. Similar twice-yearly tasks include reviewing and practicing fire escape and family disaster plans, inspecting vehicle lights, checking storage areas for hazardous materials, reprogramming thermostats, and seasonal vaccinations.[118] Locations without DST can instead use the first days of spring and autumn as reminders.[119]\\r\\nA 2017 study in the American Economic Journal: Applied Economics estimated that \\"the transition into DST caused over 30 deaths at a social cost of $275 million annually,\\" primarily by increasing sleep deprivation.[120]\\r\\nDST has mixed effects on health. In societies with fixed work schedules it provides more afternoon sunlight for outdoor exercise.[122] It alters sunlight exposure; whether this is beneficial depends on one's location and daily schedule, as sunlight triggers vitamin D synthesis in the skin, but overexposure can lead to skin cancer.[123] DST may help in depression by causing individuals to rise earlier,[124] but some argue the reverse.[125] The Retinitis Pigmentosa Foundation Fighting Blindness, chaired by blind sports magnate Gordon Gund, successfully lobbied in 1985 and 2005 for U.S. DST extensions.[60][62] DST shifts are associated with higher rates of ischemic stroke in the first two days after the shift, though not in the week thereafter.[126]\\r\\nClock shifts were found to increase the risk of heart attack by 10 percent,[75] and to disrupt sleep and reduce its efficiency.[7] Effects on seasonal adaptation of the circadian rhythm can be severe and last for weeks.[127] A 2008 study found that although male suicide rates rise in the weeks after the spring transition, the relationship weakened greatly after adjusting for season.[128] A 2008 Swedish study found that heart attacks were significantly more common the first three weekdays after the spring transition, and significantly less common the first weekday after the autumn transition.[129] A 2013 review found little evidence that people slept more on the night after the fall DST shift, even though it is often described as allowing people to sleep for an hour longer than normal. The same review stated that the lost hour of sleep resulting from the spring shift appears to result in sleep loss for at least a week afterward.[130] In 2015, two psychologists recommended that DST be abolished, citing its disruptive effects on sleep as one reason for this recommendation.[131]\\r\\nThe government of Kazakhstan cited health complications due to clock shifts as a reason for abolishing DST in 2005.[132] In March 2011, Dmitri Medvedev, president of Russia, claimed that \\"stress of changing clocks\\" was the motivation for Russia to stay in DST all year long. Officials at the time talked about an annual increase in suicides.[133]\\r\\nAn unexpected adverse effect of daylight saving time may lie in the fact that an extra part of morning rush hour traffic occurs before dawn and traffic emissions then cause higher air pollution than during daylight hours.[134]\\r\\nIn 2017, researchers at the University of Washington and the University of Virginia reported that judges who experienced sleep deprivation as a result of DST tended to issue longer sentences.[135]\\r\\nDST's clock shifts have the obvious disadvantage of complexity. People must remember to change their clocks; this can be time-consuming, particularly for mechanical clocks that cannot be moved backward safely.[136] People who work across time zone boundaries need to keep track of multiple DST rules, as not all locations observe DST or observe it the same way. The length of the calendar day becomes variable; it is no longer always 24 hours. Disruption to meetings, travel, broadcasts, billing systems, and records management is common, and can be expensive.[137] During an autumn transition from 02:00 to 01:00, a clock reads times from 01:00:00 through 01:59:59 twice, possibly leading to confusion.[138]\\r\\nDamage to a German steel facility occurred during a DST transition in 1993, when a computer timing system linked to a radio time synchronization signal allowed molten steel to cool for one hour less than the required duration, resulting in spattering of molten steel when it was poured.[6] Medical devices may generate adverse events that could harm patients, without being obvious to clinicians responsible for care.[139] These problems are compounded when the DST rules themselves change; software developers must test and perhaps modify many programs, and users must install updates and restart applications. Consumers must update devices such as programmable thermostats with the correct DST rules or manually adjust the devices' clocks.[8] A common strategy to resolve these problems in computer systems is to express time using the Coordinated Universal Time (UTC) rather than the local time zone. For example, Unix-based computer systems use the UTC-based Unix time internally.\\r\\nSome clock-shift problems could be avoided by adjusting clocks continuously[140] or at least more gradually[141]for example, Willett at first suggested weekly 20-minute transitionsbut this would add complexity and has never been implemented.\\r\\nDST inherits and can magnify the disadvantages of standard time. For example, when reading a sundial, one must compensate for it along with time zone and natural discrepancies.[142] Also, sun-exposure guidelines such as avoiding the sun within two hours of noon become less accurate when DST is in effect.[143]\\r\\nAs explained by Richard Meade in the English Journal of the (American) National Council of Teachers of English, the form daylight savings time (with an \\"s\\") was already in 1978 much more common than the older form daylight saving time in American English (\\"the change has been virtually accomplished\\"). Nevertheless, even dictionaries such as Merriam-Webster's, American Heritage, and Oxford, which describe actual usage instead of prescribing outdated usage (and therefore also list the newer form), still list the older form first. This is because the older form is still very common in print and preferred by many editors. (\\"Although daylight saving time is considered correct, daylight savings time (with an \\"s\\") is commonly used.\\")[144] The first two words are sometimes hyphenated (daylight-saving(s) time). Merriam-Webster's also lists the forms daylight saving (without \\"time\\"), daylight savings (without \\"time\\"), and daylight time.[2]\\r\\nIn Britain, Willett's 1907 proposal[32] used the term daylight saving, but by 1911 the term summer time replaced daylight saving time in draft legislation.[74] The same or similar expressions are used in many other languages: Sommerzeit in German, zomertijd in Dutch, kes?aika in Finnish, horario de verano or hora de verano in Spanish, and heure d't in French.[51]\\r\\nThe name of local time typically changes when DST is observed. American English replaces standard with daylight: for example, Pacific Standard Time (PST) becomes Pacific Daylight Time (PDT). In the United Kingdom, the standard term for UK time when advanced by one hour is British Summer Time (BST), and British English typically inserts summer into other time zone names, e.g. Central European Time (CET) becomes Central European Summer Time (CEST).\\r\\nThe North American English mnemonic \\"spring forward, fall back\\" (also \\"spring ahead?...\\", \\"spring up?...\\", and \\"...?fall behind\\") helps people remember which direction to shift clocks.[3]\\r\\nChanges to DST rules cause problems in existing computer installations. For example, the 2007 change to DST rules in North America required that many computer systems be upgraded, with the greatest impact on e-mail and calendar programs. The upgrades required a significant effort by corporate information technologists.[145]\\r\\nSome applications standardize on UTC to avoid problems with clock shifts and time zone differences.[146] Likewise, most modern operating systems internally handle and store all times as UTC and only convert to local time for display.[147][148]\\r\\nHowever, even if UTC is used internally, the systems still require external leap second updates and time zone information to correctly calculate local time as needed. Many systems in use today base their date/time calculations from data derived from the tz?database also known as zoneinfo.\\r\\nThe tz?database maps a name to the named location's historical and predicted clock shifts. This database is used by many computer software systems, including most Unix-like operating systems, Java, and the Oracle RDBMS;[149] HP's \\"tztab\\" database is similar but incompatible.[150] When temporal authorities change DST rules, zoneinfo updates are installed as part of ordinary system maintenance. In Unix-like systems the TZ environment variable specifies the location name, as in TZ=':America/New_York'. In many of those systems there is also a system-wide setting that is applied if the TZ environment variable is not set: this setting is controlled by the contents of the /etc/localtime file, which is usually a symbolic link or hard link to one of the zoneinfo files. Internal time is stored in timezone-independent epoch time; the TZ is used by each of potentially many simultaneous users and processes to independently localize time display.\\r\\nOlder or stripped-down systems may support only the TZ values required by POSIX, which specify at most one start and end rule explicitly in the value. For example, TZ='EST5EDT,M3.2.0/02:00,M11.1.0/02:00' specifies time for the eastern United States starting in 2007. Such a TZ value must be changed whenever DST rules change, and the new value applies to all years, mishandling some older timestamps.[151]\\r\\nAs with zoneinfo, a user of Microsoft Windows configures DST by specifying the name of a location, and the operating system then consults a table of rule sets that must be updated when DST rules change. Procedures for specifying the name and updating the table vary with release. Updates are not issued for older versions of Microsoft Windows.[152] Windows Vista supports at most two start and end rules per time zone setting. In a Canadian location observing DST, a single Vista setting supports both 1987ÿ2006 and post-2006 time stamps, but mishandles some older time stamps. Older Microsoft Windows systems usually store only a single start and end rule for each zone, so that the same Canadian setting reliably supports only post-2006 time stamps.[153]\\r\\nThese limitations have caused problems. For example, before 2005, DST in Israel varied each year and was skipped some years. Windows 95 used rules correct for 1995 only, causing problems in later years. In Windows 98, Microsoft marked Israel as not having DST, forcing Israeli users to shift their computer clocks manually twice a year. The 2005 Israeli Daylight Saving Law established predictable rules using the Jewish calendar but Windows zone files could not represent the rules' dates in a year-independent way. Partial workarounds, which mishandled older time stamps, included manually switching zone files every year[154] and a Microsoft tool that switches zones automatically.[155] In 2013, Israel standardized its daylight saving time according to the Gregorian calendar.[156]\\r\\nMicrosoft Windows keeps the system real-time clock in local time. This causes several problems, including compatibility when multi booting with operating systems that set the clock to UTC, and double-adjusting the clock when multi booting different Windows versions, such as with a rescue boot disk. This approach is a problem even in Windows-only systems: there is no support for per-user timezone settings, only a single system-wide setting. In 2008 Microsoft hinted that future versions of Windows will partially support a Windows registry entry RealTimeIsUniversal that had been introduced many years earlier, when Windows NT supported RISC machines with UTC clocks, but had not been maintained.[157] Since then at least two fixes related to this feature have been published by Microsoft.[158][159]\\r\\nThe NTFS file system used by recent versions of Windows stores the file with a UTC time stamp, but displays it corrected to localor seasonaltime. However, the FAT filesystem commonly used on removable devices stores only the local time. Consequently, when a file is copied from the hard disk onto separate media, its time will be set to the current local time. If the time adjustment is changed, the timestamps of the original file and the copy will be different. The same effect can be observed when compressing and uncompressing files with some file archivers. It is the NTFS file that changes seen time. This effect should be kept in mind when trying to determine if a file is a duplicate of another, although there are other methods of comparing files for equality (such as using a checksum algorithm). A ready clue is if the time stamps differ by precisely 1 hour.\\r\\nA move to \\"permanent daylight saving time\\" (staying on summer hours all year with no time shifts) is sometimes advocated, and in fact is currently implemented in some jurisdictions such as Belarus,[77] some parts of Russia (e.g. Novosibirsk), Turkey, Namibia, and S?o Tom and Prncipe. It could be a result of following the timezone of a neighbouring region, political will or other causes. Advocates cite the same advantages as normal DST without the problems associated with the twice yearly time shifts. However, many remain unconvinced of the benefits, citing the same problems and the relatively late sunrises, particularly in winter, that year-round DST entails.[14]\\r\\nRussia switched to permanent DST from 2011 to 2014, but the move proved unpopular because of the late sunrises in winter, so the country switched permanently back to \\"standard\\" or \\"winter\\" time in 2014 for the whole Russian Federation.[160] The United Kingdom and Ireland also experimented with year-round summer time between 1968 and 1971, and put clocks forward by an extra hour during World War II.[161]\\r\\nIn the IANA time zone database, permanent daylight saving time is considered standard time that has been added by an hour.\\r\\nOn March 23, 2018 Florida Governor Rick Scott signed legislation asking Congress to approve year-round daylight saving time in Florida.[162][163]","input":"When did the original daylight savings time start?"},{"output":"19 Commonwealth sports","context":"The 2018 Commonwealth Games, officially known as the XXI Commonwealth Games and commonly known as Gold Coast 2018, were an international multi-sport event for members of the Commonwealth that were held on the Gold Coast, Queensland, Australia, between 4 and 15 April 2018. It was the fifth time Australia had hosted the Commonwealth Games and the first time a major multi-sport event achieved gender equality by having an equal number of events for males and female athletes.[1]\\r\\nMore than 4,400 athletes including 300 para-athletes from 71 Commonwealth Games Associations took part in the event.[2] The Gambia which withdrew its membership from the Commonwealth of Nations and Commonwealth Games Federation in 2013, was readmitted on 31 March 2018 and participated in the event .[3] With 275 sets of medals, the games featured 19 Commonwealth sports, including beach volleyball, para triathlon and womens rugby sevens. These sporting events took place at 14 venues in the host city, two venues in Brisbane and one venue each in Cairns and Townsville.[4]\\r\\nThese were the first Commonwealth Games to take place under the Commonwealth Games Federation (CGF) presidency of Louise Martin, CBE.[5] The host city Gold Coast was announced at the CGF General Assembly in Basseterre, Saint Kitts, on 11 November 2011.[6] Gold Coast became the seventh Oceanian city and the first regional city to host the Commonwealth Games. These were the eighth games to be held in Oceania and the Southern Hemisphere.\\r\\nThe host nation Australia topped the medal table for the fourth time in the past five Commonwealth Games, winning the most golds (80) and most medals overall (198). England and India finished second and third respectively.[7] Vanuatu, Cook Islands, Solomon Islands, British Virgin Islands and Dominica each won their first Commonwealth Games medals.[8]\\r\\n\\r\\n\\r\\nOn 22 August 2008, the Premier of Queensland, Anna Bligh, officially launched Gold Coast City's bid to host the Commonwealth Games in 2018. On 7 April 2009, the ABC reported a land exchange deal between Gold Coast City and State of Queensland for Carrara Stadium. According to Mayor Ron Clarke, the land would aid a potential bid for the 2018 Commonwealth Games. The land exchanged would be used as the site of an aquatics centre. In the same article, Mayor Clarke raised the question of the Australian Federal Government's commitment to a 2018 Commonwealth Games bid in light of the Government's support for Australia's 2018 FIFA World Cup Finals bid.[9] On 16 April 2009, Queensland Premier Anna Bligh told reporters that a successful Commonwealth Games bid by Gold Coast City could help the tourist strip win a role in hosting the World Cup.[10]\\r\\n\\"Some of the infrastructure that would be built for the Commonwealth Games will be useful for Gold Coast City to get a World Cup game out of the soccer World Cup if we're successful as a nation,\\" she said. However the decision on the venues for the 2018 and 2022 FIFA World Cups were made eleven months prior to the bid decision for the 2018 Commonwealth Games, so the potential World Cup venues had already been chosen. On 3 June 2009, Gold Coast City was confirmed as Australia's exclusive bidder vying for the 2018 Commonwealth Games.[11] \\"Should a bid proceed, Gold Coast City will have the exclusive Australian rights to bid as host city for 2018,\\" Bligh stated.\\r\\n\\"Recently I met with the president and CEO of the Australian Commonwealth Games Association and we agreed to commission a full and comprehensive feasibility study into the potential for the 2018 Commonwealth Games,\\" she said. \\"Under the stewardship of Queensland Events new chair, Geoff Dixon, that study is now well advanced.\\" On 15 March 2010, it was announced that the Queensland Government will provide initial funding of A$11 million for the 2018 Commonwealth Games bid. The Premier of Queensland has indicated the Government's support for the bid to the Australian Commonwealth Games Association.[12] On 31 March 2010, the Australian Commonwealth Games Association officially launched the bid to host the 2018 Commonwealth Games.[13] In October 2011, Gold Coast City Mayor Ron Clarke stated that the games would provide a strong legacy for the city after the games have ended.[14]\\r\\nOn 31 March 2010, a surprise bid was made for the 2018 Commonwealth Games by the Sri Lankan city of Hambantota. Hambantota was devastated by the 2004 Indian Ocean Tsunami, and is undergoing a major face lift. The first phase of the Port of Hambantota is nearing completion and it is funded by the government of China. The Mattala International Airport, which is the second international Airport of Sri Lanka is built close to Hambantota. A new Hambantota International Cricket Stadium had also been built, which had hosted matches in the 2011 Cricket World Cup.\\r\\nOn 10 November 2011, the Hambantota bidders claimed they had already secured enough votes to win the hosting rights.[15] However, on 11 November it was officially announced Gold Coast City had won the rights to host the games.[16][17]\\r\\nThe entire project was overseen by the Gold Coast 2018 Commonwealth Games Corporation (GOLDOC). In February 2012, Mark Peters was appointed Chief Executive Officer of the Gold Coast City 2018 Commonwealth Games Corporation.[18] The Queensland Government Minister tasked with overseeing the Games was Kate Jones.[19]\\r\\nOne of the key technical aspects of Gold Coast City's successful bid was the fact that the city had 80 percent of the planned venues in place before the bidding deadline. The vast majority of venues were located within 20-minutes driving time of the Athletes Village in Parkwood.\\r\\nCarrara Stadium, located in the suburb of Carrara, was the main venue for Athletics, the opening ceremony and the closing ceremony. The seating capacity of the stadium was temporarily increased to 40,000 for the games by the installation of a large temporary North Stand.[20]\\r\\nThe Gold Coast City Convention and Exhibition Centre, located in the suburb of Broadbeach, hosted Basketball, Netball (preliminaries) and Weightlifting events, also serving as the Main Media Centre and International Broadcast centre hosting over 3000 members of the worlds press.[21] The Broadbeach Bowls Club hosted the Bowls competition.[22]\\r\\nThe Hinze Dam, located in the suburb of Advancetown, was the location for the Mountain Bike competition. A new course was constructed to meet international competition requirements and temporary spectator seating for 2,000 spectators.\\r\\nThe newly built Coomera Sport and Leisure Centre hosted Gymnastics and Netball (finals).[23] The existing sound stages of the Village Roadshow Studios complex in the suburb of Oxenford hosted the sports of Boxing, Table Tennis and Squash.[24] During Games mode the venue was enhanced to provide for the International Sporting Federation technical venue requirements and provide spectator seating of 3,000 (boxing) and 3,200 (table tennis). The Gold Coast Hockey Centre hosted the men's and women's Hockey events during the games.[25] The Southport Broadwater Parklands hosted Triathlon and athletic events.[26] The Optus aquatic centre hosted the swimming and diving events.[27]\\r\\nRobina Stadium hosted the Rugby 7s competition and upgraded to meet World Rugby standards.[28] The Elanora/Currumbin Valley area hosted the road racing elements of the cycling programme. Coolangatta Beachfront hosted the beach volleyball event.[29]\\r\\nBrisbane, along with the Gold Coast, forms part of the South East Queensland conurbation. Track Cycling was held at the Sleeman Sports Complex in the suburb of Chandler, where a new indoor cycling velodrome (Anna Meares Velodrome) was built. The Velodrome's seat capacity was 4,000 during the games mode.[30]\\r\\nThe Shooting disciplines were held at the Belmont Shooting Centre. In Tropical North Queensland, the Cairns Convention Centre and Townsville Entertainment Centre hosted the preliminary rounds of both the men's and women's basketball competitions.[31][32][33]\\r\\nThe Queensland state government spent A$1.5 billion (US$1.2 billion) to deliver the event. Out of this, A$550 million (US$425 million) were spent on the procurement programme. Procurement of the security and security infrastructure included contracts for four prime suppliers which delivered around 4,200 security guards. A$34 million (US$26 million) were spent on the deployment of the armed forces to provide rapid-response squads, bomb detectors, offshore patrols and surveillance. A$657 million (US$509 million) were spent for the construction of the venues and the Games Village.[34]\\r\\nAt a charity gala held on 4 November 2017, the medals for the games were officially unveiled. Australian Indigenous artist Delvene Cockatoo-Collins designed the medals, while they were produced by the Royal Australian Mint. The design of the medals was inspired by the coastline of Gold Coast along with Indigenous culture.[35] Furthermore, Cockatoo-Collins mentioned, \\"the medal design represents soft sand lines which shift with every tide and wave, also symbolic of athletic achievement, The continual change of tide represents the evolution in athletes who are making their mark, Records are made and special moments of elation are celebrated\\". Approximately 1,500 medals were created to be distributed to the medallists and each measures approximately 63 millimetres in diameter. The medals weigh between 138 and 163 grams.[36]\\r\\nThe 2018 Commonwealth Games Athletes Village was located on 59 hectares at Southport, Gold Coast.[37] which provided accommodation and services to 6,600 athletes and officials in 1252 permanent dwellings. There are 1170 one and two bedroom apartments and 82 three bedroom townhouses which will serve as student accommodation to the nearby Griffith University. It offered services like laundry, refreshments and television and computer spaces and four residential pools. The village consisted a gym which was designed with guidance from the Australian Institute of Sport and equipment and the equipment were sponsored by Technogym. Adjoining the gym was the Athlete Recovery Area which provided services like plunge baths, including accessible baths, saunas, massage and consults from the Sports Medical personnel. The Main Dining served over 18,000 meals per day to the athletes during the games. The village also consisted of retail shops, Optus phone store, salon, bar and a games room which featured a number of arcade games, pool tables and game consoles.[38]\\r\\nThe Gold Coast 2018 Queens Baton Relay was launched on Commonwealth Day, 13 March 2017, on the historic forecourt at Buckingham Palace, signalling the official countdown to the start of the Games. Accompanied by the Duke of Edinburgh and Prince Edward The Earl of Wessex, Her Majesty Queen Elizabeth II heralded the start of the relay by placing her message to the Commonwealth and its athletes into the distinctive loop-design Queens Baton which then set off on its journey around the globe. It traveled for 388 days, spending time in every nation and territory of the Commonwealth. The Gold Coast 2018 Queens Baton Relay was the longest in Commonwealth Games history. Covering 230,000?km over 388 days, the baton made its way through the six Commonwealth regions of Africa, the Americas, the Caribbean, Europe, Asia and Oceania.\\r\\nThe baton landed on Australian soil in December 2017 and then spent 100 days travelling through Australia, finishing its journey at the Opening Ceremony on 4 April 2018, where the message was removed from the Baton and read aloud by Charles, Prince of Wales.[39]\\r\\nDuring the games period, free public transportation within Queensland region was provided to ticket and accreditation holders. The free transportation services were available on local buses, train and Gold Coast light rail (G:link) services in Gold Coast and on TransLink and Qconnect bus services in Cairns and Townsville.[40] The Gold Coast light rail system, connected a number of the key games venues including the Optus Aquatic Centre, Broadwater Parklands and the Gold Coast Convention & Exhibition Centre with the major accommodation centres of Surfers Paradise and Broadbeach and the Athletes Village at Parklands. An extension to the system was announced in October 2015, connecting the then current terminus at Gold Coast University Hospital to the railway line to Brisbane at Helensvale. The extension opened in December 2017, in time for the games.[41]\\r\\nThe Australian Sports Anti-Doping Authority conducted an anti-doping drive in the months prior to the games, covering around 2500 tests of Australian athletes, as well as 500 tests against international athletes. Three Australians failed drug tests in this process, along with around 20 international athletes, subject to appeal. The Commonwealth Games Federation conducted in-competition testing and, matching protocol at the Olympic Games, launched a sample storage initiative to allow for future testing of samples up to ten years later, should detection technology improve.[42]\\r\\nThere were 71 nations competing at 2018 Commonwealth Games.[43] Maldives were scheduled to participate, but in October 2016 they withdrew from the Commonwealth.[44] The Gambia returned to the Commonwealth Games after being readmitted as a Commonwealth Games Federation member on 31 March 2018.[3]\\r\\n\\r\\nThe regulations stated that from the 26 approved sports administered by Commonwealth Governing Bodies, a minimum of ten core sports and maximum of seventeen sports must be included in any Commonwealth Games schedule. The approved sports included the 10 core sports: athletics, badminton, boxing, hockey, lawn bowls, netball (for women), rugby sevens, squash, swimming and weightlifting. Integrated disabled competitions were also scheduled for the Games in nine sports: swimming, athletics, cycling, table tennis, powerlifting and lawn bowls. Along with these events for the first time EAD events in triathlon were held, with the medals added to the final tally for each nation. A record 38 para events were contested at these games.[45] On 8 March 2016, beach volleyball was announced as the 18th sport.[46]\\r\\nThe program was broadly similar to that of the 2014 Commonwealth Games, with the major changes being the dropping of judo, the reintroduction of basketball, the debut of women's rugby sevens and beach volleyball.[47]\\r\\nOn 7 October 2016, it was announced seven new events for women were added to the sport program, meaning there are an equal number of events for men and women. This marks the first time in history that a major multi-sport event has equality in terms of events. In total 275 events in 18 sports are being contested.[48][49]\\r\\nNumbers in parentheses indicate the number of medal events contested in each sport.\\r\\nThe opening ceremony was held at Carrara Stadium in the Gold Coast, Australia, between 20:00 and 22:40 AEST, on 4 April 2018. Tickets for the ceremony started at 100 Australian dollars with half price tickets available for children.[50] The Head of the Commonwealth, Queen Elizabeth II, was represented by her son, Charles, Prince of Wales.[51]\\r\\nFollowing tradition, the host of the previous games, Scotland entered first, followed by the rest of the European countries competing.[52] Following this, all countries paraded in alphabetical order from their respective regions. After the European countries entered, countries from Africa, the Americas, Asia, the Caribbean, and lastly Oceania marched in. The host nation of Australia entered last. Each nation was preceded by a placard bearer carrying a sign with the country's name.\\r\\nThe closing ceremony was held at Carrara Stadium on Sunday 15th April and was produced by Jack Morton Worldwide at a cost of AU$30 million. Australian pop stars Guy Sebastian, Samantha Jade, Dami Im and The Veronicas were among the performers along with children's entertainers, The Wiggles.\\r\\nPrince Edward, Earl of Wessex, declared the Games closed and passed the Commonwealth Games flag to Birmingham, England which will host the 2022 Games.[53]\\r\\nOnly the top ten successful nations are displayed here.\\r\\nThe ranking in this table is consistent with International Olympic Committee convention in its published medal tables. By default, the table is ordered by the number of gold medals the athletes from a nation have won (in this context, a \\"nation\\" is an entity represented by a Commonwealth Games Association). The number of silver medals is taken into consideration next and then the number of bronze medals. If nations are still tied, equal ranking is given and they are listed alphabetically by their three-letter country code. Australia tops the medal table rank with 80 gold, second England with 45 gold and third India with 26 gold.\\r\\n??*?? Host nation (Australia)\\r\\nIn Australia, the games were broadcast live on three Seven Network channels - 7HD, 7TWO and 7Mate.[54] In the United Kingdom, BBC provided Commonwealth Games coverage of more than 200 hours across BBC One, BBC Two, BBC Red Button, BBC Sport website, BBC iPlayer and BBC radio.[55] TVNZ channel broadcast the games for the viewers in New Zealand.[56] Astro Arena provided the games coverage for the Malaysian viewers.[57] ESPN provided the games coverage for viewers in the USA.[58] Sony Pictures Networks India broadcast the games for the viewers in India on three channels - Sony Six, Sony Ten 2 in English and Sony Ten 3 in Hindi.[59]\\r\\nThe official motto for the 2018 Commonwealth Games was \\"Share the Dream\\". It was chosen to highlight the dreams and experience at the games that were shared by participants of the games, ranging from athletes to volunteers and the host country Australia to the world including the Commonwealth nations.[60]\\r\\nThe emblem was launched on 4 April 2013, which marked exactly five years until its opening ceremony.[61] It was unveiled at the Southport Broadwater Parklands. It was designed by the New South Wales based brand consultancy WiteKite.[62] The emblem of the 2018 Commonwealth Games was a silhouette of the skyline and landscape of Gold Coast, the host city of the games.[63] Nigel Chamier OAM, who served as the Chairman of the Gold Coast 2018 Commonwealth Games Corporation till the end of the games, said that it was the result of months of market research.[64]\\r\\nBorobi was named as the mascot of the 2018 Commonwealth Games in 2016. Borobi is a blue koala, with indigenous markings on its body. The term \\"borobi\\" means koala in the Yugambeh language, spoken by the indigenous Yugambeh people of the Gold Coast and surrounding areas.[65]\\r\\nAt least 13 athletes from four countries - Cameroon, Uganda, Rwanda, and Sierra Leone - absconded during or immediately after the Games. Some missed their competitions.[66] Athletes regularly abscond during major sporting events, and many subsequently claim asylum in their host countries. Most hold nationalities that are deemed high-risk by immigration authorities and find it impossible to get visas outside of exceptional events, such as major games.[67]\\r\\nA month after the games ended, officals estimated that fifty athletes had remained in Australia illegally, with another 200 staying in the country on visas.[68][69]\\r\\nThe organising committee decided to bring in the athletes before the start of the closing ceremony. This caused an uproar on social media as, contrary to public expectations, none of the athletes were shown entering the stadium during the ceremony. Broadcast rights holders Channel 7 complained on air about the decision and concluded that, \\"it hasn't really lived up to expectations\\". Many spectators and athletes left during the ceremony, resulting in a half-empty stadium for much of the event.[70] Following this, the ABC claimed that Channel 7 was briefed on the closing ceremony schedule,[71] a claim which Channel 7 later refuted.[72]","input":"How many sports are there in the 2018 commonwealth games?"},{"output":"eight-week program","context":"United States Air Force Basic Military Training (also known as BMT or boot camp) is an eight-week program of physical and mental training required in order for an individual to become an enlisted Airman in the United States Air Force. It is located at Lackland Air Force Base in San Antonio, Texas.\\r\\n\\r\\n\\r\\nLackland Air Force Base conducts the Air Force's only enlisted recruit training program, ensuring orderly transition from civilian to military life. Recruits are trained in the fundamental skills necessary to be successful in the operational Air Force. This includes basic war skills, military discipline, physical fitness, drill and ceremonies, Air Force core values and a comprehensive range of subjects relating to Air Force life.\\r\\nMore than 7 million young men and women have entered Air Force basic military training since 4 February 1946, when the training mission was moved to Lackland from Harlingen Air Force Base in Harlingen, Texas. Throughout its history, Lackland's BMT program has changed in many ways to meet the operational needs of the Air Force and recent updates in the curriculum are some of the most significant in its more than 60-year history, with every aspect of the program overhauled.\\r\\nOn 7 November 2005, BMT changed its curriculum to focus on a new kind of Airmanone who is a \\"warrior first\\". The goal is to instill a warrior mindset in trainees from day one and better prepare Airmen for the realities of the operational Air Force.\\r\\nThe changes resulted from the need to meet current and future operational Air Force requirements. In September 2004, the 20th Basic Military Training Review Committee met at Lackland and recommended significant changes in the focus, curriculum and schedule.[1]\\r\\nIn 2011, it was revealed that a number of military training instructors engaged in inappropriate and illegal sexual relationships and advances against dozens of female trainees. The scandal led seventy-seven Congressional representatives to call for a hearing to investigate the incident.[2] Because of this incident, the commanders instilled what is called a wingman concept. This means that no trainee is allowed to go anywhere alone without another trainee. This allows trainees to lean and look after one another. It helps maintain a safer environment while in Basic Training, and when the trainees get out into the operational air force.\\r\\nMilitary Training Instructors, or MTIs, are the instructors who are responsible for most of the training that takes place in BMT. They accompany trainees throughout the training process, instructing and correcting them in everything, from correct procedures for firing a weapon to the correct way to speak to a superior. They are known for their campaign covers typically called \\"Smokey the Bear\\" or \\"Smokey\\" hats. Unlike the Marine Corps Drill Instructors and Army Drill Sergeants, Training Instructor hats are a dark blue instead of brown.\\r\\nPrior to arriving at basic training, all prospective trainees undergo a physical examination by a doctor at their local Military Entrance Processing Station, or MEPS. Trainees receive their initial weigh-in when they arrive at Lackland. If the trainee is under or over the height and weight standards, the trainee is placed on double rations if underweight (known colloquially in BMT as a \\"skinny\\"), or in a \\"diet\\" status if overweight.\\r\\nAll trainees receive three meals a day, also known as \\"chow time\\". These are either served at the dining facility (DFAC, also known as the \\"chow hall\\"), or as a Meal, Ready-to-Eat (MRE) during field training. Meal time may last 30 minutes or less, depending on the order the flight arrives at the chow hall. Trainees are mandated a minimum of 15 minutes to consume each meal. Much of the 15 minutes may be spent waiting in line, trainee \\"water monitors\\" reporting in the chow hall and removing, properly storing and re-donning any carried equipment.\\r\\nTrainees that sustain injuries or illnesses that disrupt their training are transferred to the Medical Hold Flight. Once they are again medically fit, the trainee will generally return to their prior training squadron as part of a flight currently at an equivalent place in the training cycle that they left.\\r\\nBasic Military Training is an eight-and-a-half-week cycle of training which begins with the receiving phase (also known as zero week) and ending with graduation.[3]\\r\\nInbound trainees are transported to Air Force Basic Military Training at Lackland Air Force Base. Upon arrival at Lackland, trainees will be assigned to a Squadron and a Flight. Trainees will then be rushed up to their dorm rooms where they will be given a bed and a wall locker (Personal Living Area or PLA) that they will take care of for the next eight and a half weeks. They will also be briefed on meal time procedures in the Dining Facility (DFAC) and other essential ground rules that will apply throughout the duration of Basic Training.\\r\\nAs the initial uniform issue is not until the following Thursday or Friday, trainees will be required to wear civilian clothes for at least one full day. During this period, trainees will be referred to as a \\"Rainbow Flight\\" or simply as \\"Rainbows\\" because of the flight's bright and varied clothing.[4] In order to break in their new boots, trainees will alternate wearing sneakers and boots with their newly issued uniforms until the end of Zero Week, earning them the nickname \\"Sneaker Weekers\\" or \\"Baby Flights\\". After first clothing issue, civilian belongings and baggage will be secured and stored for the remainder of BMT.\\r\\nTrainees will undergo a urinalysis test the day after arrival. Any trainee who fails the drug test will immediately be separated from the military. The trainees are given an opportunity to phone a family member to inform them of safe arrival and mailing instructions, then are searched for contrabandthis is called a shakedown. Next, males receive their first military haircut, often called a buzz cut, where they are left essentially bald. Females are instructed in the authorized hairstyling, which allow hair to be short enough to not touch the collar or in a bun.\\r\\nZero week lasts only until the first Sunday when trainees can attend the religious service of their choice. There are a wide range of religions represented at Lackland. Sunday is the non-duty day each week in Basic Training.\\r\\nThe remainder of in-processing involves completion of paperwork, receiving vaccines and medical tests and the first physical fitness test.\\r\\nThe first test will consist of one minute timed push ups, one minute of sit ups and a timed 1.5-mile run. After the first physical fitness test, all Trainees will be put into a fitness group. If a Trainee does not meet the basic needs, he/she will be put into a remedial group that will have extra PT sessions throughout the week.\\r\\nAfter the first physical fitness test, the MTI can issue disciplinary action in the form of typical push ups, flutter kicks and squat thrust or any other exercise that the MTI thinks is necessary as a correction for simple mistakes. Trainees will be expected to adhere to the rules by this time or face correction by physical exercise, or go through the chain of commandbeginning with the section supervisor, depending on the severity of the misconduct.\\r\\nThe following chart shows physical fitness achievement levels as well as the minimum requirements for graduating Air Force Basic Military Training:\\r\\nThis is the Pre-Deployment Phase. Here trainees will sit down with a job counselor and are shown a list of jobs they qualify forand that are availableand are instructed to prioritize that list in order of preference. The job counselors then take the preferences and the preferences of all of the other recruits in the same week of training that are in the same guaranteed aptitude area and try and work it out the best they can to give everyone the preferences they want.[5] Those who enlisted with a guaranteed job will not go through this process.\\r\\nTrainees undergo extensive training with the M-16. Trainees will learn and practice the rules for safe use and handling of the weapon. They will also receive training in how to assemble, disassemble, clean and repair the M-16.\\r\\nIn Week 4, Trainees will attend the FEST Courses teaching them the basics needed to move onto the BEAST during the 5th WOT. Activities include basic Rifle Fighting techniques, crawling through a sand course and learning how to move in columns and use proper hand signaling. Trainees will also go through CBRNE (Chemical, Biological, Radiological, Nuclear, and high-yield Explosives) training and learn how to counter threats such as terrorism,[6] biological and chemical weapons and security breaches. Included in the CBRNE training is gas mask and MOPP gear training, where trainees will be exposed to CS Gas. Trainees also take official BMT Portraits during the fourth week[7]\\r\\nDuring Week Five, trainees will be sent to the BEAST on the Medina Annex. The BEAST, or Basic Expeditionary Airman Skills Training, is the final test in BMT. This represents the culmination of all the skills and knowledge an Airman should possess. These skills and tactics the trainees have learned will be put to test in realistic field training exercises and combat scenarios.[8]\\r\\nIt is a 5-day exercise that will test all of the CBRNE skills that the trainees were taught in the fifth week of training. The trainees will also be taught basic combatives as well as engaging in pugil stick battles utilizing the rifle fighting techniques they were taught. The trainees are required to wear body armor and helmets, as well as two canteens and an M16. The site has four zones, called Reaper, Phantom, Vigilant and Sentinel, that simulate self-contained forward operating bases. Each zone is a ring of 10 field tents for barracks, centered around a three-story observation tower and a hardened briefing facility that serves as an armory and bomb shelter. The zone is defended by five sandbag defensive firing positions and trainees control access to the zone through an entry control point.[9]\\r\\nThe trainees will also visit CATM where they will fire and qualify using an M16A2 rifle. During the actual firing, trainees will fire at a man-sized target at 75 yards, 180 yards and 300 yards in the standing, sitting, kneeling and prone positions. A total of 24 rounds will be fired during the qualification, the targets must be hit at least 17 times in order to become qualified with the weapon and those who hit the targets at least 22 times qualify for the Small Arms Expert Ribbon.[10]\\r\\nTrainees will train on their SABC, FEST and CBRNE skills to have a grasp on the basics of conducting UXO (Unexploded Ordnance) sweeps, helping a downed or injured Airman and doing the PAR and SALUTE reports they were taught during their CBRNE course the week prior. They will be taught how to identify potential threats and who to report them to in their chain of command. BEAST week will be almost entirely devoted to scenario training. As they take advantage of more field time to hone their newly acquired infantry skills, the trainees also will have more hands-on instruction in buddy care, culminating in an evaluation for each zone to see which zone has the won the coveted title of BEAST excellence which is announced at the culmex ceremony on Friday afternoon.[11] The BEAST site includes a 1.5-mile improvised explosive device (IED) trail littered with simulated roadside bombs. Trainees learn to spot IEDs and then use the trail in training scenarios. For example, under one scenario trainees make their way down the \\"lane\\" in tactical formation, trying to identify IEDs from the other debris such as soda cans. At the end of the trail, trainees are broken into teams of two \\"wingmen\\" and negotiate a combat-obstacle course (low-crawl, hide behind walls, roll behind barriers, strike dummies with the butt of your rifle, high crawl 60 yards through deep sand up a 40 percent grade). Trainees will also go participate in a CLAW mission during BEAST week. CLAW stands for Creating Leader Airmen Warriors. The CLAW mission consists of traversing a \\"simulated\\" river using the instructions and supplies on hand which stresses teamwork. They will then move in staggered tactical formation to another checkpoint where they will work on their SABC skills, then they will go through the combat obstacle course that was mentioned above. The biggest test is the village in which the Chalks of Trainees will have to either rescue a \\"downed\\" Airman and evacuate the training dummy or they will have to neutralize the targets and \\"simulated\\" gunners in the village while sustaining as few casualties as possible.[12][13] Teamwork is stressed, as the majority of tasks are completely impossible without iteach group must succeed or fail as a whole. The others will result in failure unless every trainee passes through together, requiring the team to aid its fellow trainee(s) who struggle in the accomplishment of the given mission. On the last day the trainees will have a culmex ceremony in which their MTI will award them their dog tags.\\r\\nWeek Six of BMT focuses primarily on post-deployment training. During this week, they will receive intensive classroom instruction about the difficulties many military members face when they return from a deployment, such as financial management, family issues and alcohol abuse. Trainees will also continue to practice drill and have dorm inspections. Trainees will also learn about Air Force history and heritage during this week.[14] The final physical fitness test is also given this week. Trainees who fail the final PT test will be transferred to the \\"Get Fit\\" flight, thereby providing the trainee extra time to improve fitness scores. The Air Force End of Course exam is also given during the Friday of the 6th week and Trainees will at some point during this week find out their AFSC if one was not already assigned when they arrived at BMT. A 70 or above is required to pass the EOC with Honor Grad candidacy being reached at 90.\\r\\nOn the final Thursday of BMT, all trainees will participate in the 1.5-mile run known as the \\"Airman's Run\\". The run is a victory celebration of the challenges overcome and esprit de corps gained by Airmen during training. Family and friends will be able to attend the days events and see their loved ones for the first time since the start of basic training. The Airman's Run will be followed by the Coin and Retreat Ceremony. Trainees will be presented with the Airman's Coin which signifies the transition from Trainee and have earned the right to be called an Airman. After the Airmen are dismissed, they will be able to spend the remainder of the day with loved ones.\\r\\nFriday is the Graduation Parade. The flights will pass in review, take their final oath of enlistment and are then dismissed which marks the end of Air Force Basic Military Training and the beginning of an Airman's career. Family and friends will be able to see their Airman's living quarters at the dormitory, tour the base and San Antonio following the ceremony. The weekend will be spent returning to the flight in the evening and spending the daylight hours on Base Liberty or Town Pass.\\r\\nStarting in March 2015, BMT was altered, graduation occurs during the seventh week and the weekend after graduation, the new Airmen are moved to the Airman's Week dorms generally into a dorm with people going to the same Technical Training bases as themselves. During this week, Airmen participate in classes and activities designed to help them become more independent thinkers and to make them aware of some of the problems facing young Airmen in both Tech Training and beyond, including mental, academic and social stresses that often affect new Airmen. During this week, Airmen are granted more freedoms, to include base liberties after duty hours and a more relaxed dining facility, with Airmen no longer being required to march and are now allowed to talk to each other and classroom sessions are mixed gender.\\r\\nMonday morning following the end of Airman's Week, all Airmen will proceed to the appropriate technical training school for their Air Force Specialty Code. This technical training typically lasts anywhere from one month to over two years.[15]\\r\\nActivities that are prohibited during Basic Training include (but are not limited to):\\r\\nWhen a trainee engages in a prohibited activity, their MTI may recommend the Commander impose non-judicial punishment (UCMJ Article 15). An Article 15 is a type of disciplinary action (also known as non-judicial punishment) and can entail any or all of the following:\\r\\nA trainee can be discharged from the Air Force before the conclusion of Basic Military Training. Discharges that occur before the completion of 180 days (approximately 6 months) of training are considered uncharacterized, which are neither honorable nor less than honorable.\\r\\n?This article incorporates?public domain material from the United States Air Force website http://www.af.mil.\\r\\nCoordinates: 29233N 983452W? / ?29.38417N 98.58111W? / 29.38417; -98.58111","input":"How long is us air force boot camp?"},{"output":"the late-13th-century","context":"\\r\\n\\r\\nThe kraken (/?kr?k?n/)[1] is a legendary cephalopod-like sea monster of giant size that is said to dwell off the coasts of Norway and Greenland. Authors over the years have postulated that the legend originated from sightings of giant squids that may grow to 13ÿ15 meters (40ÿ50 feet) in length. The sheer size and fearsome appearance attributed to the kraken have made it a common ocean-dwelling monster in various fictional works. \\r\\n\\r\\nThe English word kraken is taken from Norwegian.[2] In Norwegian Kraken is the definite form of krake, a word designating an unhealthy animal or something twisted (cognate with the English crook and crank).[3] In modern German, Krake (plural and declined singular: Kraken) means octopus, but can also refer to the legendary kraken.[4]\\r\\n\\r\\nIn the late-13th-century version of the Old Icelandic saga ?rvar-Oddr is an inserted episode of a journey bound for Helluland (Baffin Island) which takes the protagonists through the Greenland Sea, and here they spot two massive sea-monsters called Hafgufa (\\"sea mist\\") and Lyngbakr (\\"heather-back\\").[a][b] The hafgufa is believed to be a reference to the kraken:\\r\\n\\r\\n[N]~ mun ek segja tr, at tetta eru sjskrmsl tvau, heitir annat hafgufa, en annat lyngbakr; er hann mestr allra hvala  heiminum, en hafgufa er mest skrmsl skapat  sjnum; er tat hennar ntt~ra, at hon gleypir b?ei menn ok skip ok hvali ok allt tat hon nir; hon er  kafi, sv at d?grum skiptir, ok t hon skytr upp h?fei snu ok n?sum, t er tat aldri skemmr en sjvarfall, at hon er uppi. N~ var tat leiearsundit, er vr f܇rum  millum kjapta hennar, en nasir hennar ok inn neeri kjaptrinn vru klettar teir, er yer syndiz  hafinu, en lyngbakr var ey sj, er nier s?kk. En ?gmundr fl܇ki hefir sent tessi kvikvendi  m܇ti tr mee fj?lkynngi sinni til tess at bana tr ok ?llum m?nnum tnum; hugei hann, at sv skyldi hafa farit fleiri sem teir, at n~ druknueu, en hann ?tlaei, at hafgufan skyldi hafa gleypt oss alla. N~ siglda ek tv  gin hennar, at ek vissa, at h~n var nykomin upp.[5]\\r\\n\\r\\nNow I will tell you that there are two sea-monsters. One is called the hafgufa [sea-mist[a]], another lyngbakr [heather-back[a]]. It [the lyngbakr] is the largest whale in the world, but the hafgufa is the hugest monster in the sea. It is the nature of this creature to swallow men and ships, and even whales and everything else within reach. It stays submerged for days, then rears its head and nostrils above surface and stays that way at least until the change of tide. Now, that sound we just sailed through was the space between its jaws, and its nostrils and lower jaw were those rocks that appeared in the sea, while the lyngbakr was the island we saw sinking down. However, Ogmund Tussock has sent these creatures to you by means of his magic to cause the death of you [Odd] and all your men. He thought more men would have gone the same way as those that had already drowned [i.e., to the lyngbakr which wasn't an island, and sank], and he expected that the hafgufa would have swallowed us all. Today I sailed through its mouth because I knew that it had recently surfaced.\\r\\n\\r\\nAfter returning from Greenland, the anonymous author of the Old Norwegian natural history work Konungs skuggsj (circa 1250) described in detail the physical characteristics and feeding behavior of these beasts. The narrator proposed there must only be two in existence, stemming from the observation that the beasts have always been sighted in the same parts of the Greenland Sea, and that each seemed incapable of reproduction, as there was no increase in their numbers.\\r\\n\\r\\nThere is a fish that is still unmentioned, which it is scarcely advisable to speak about on account of its size, because it will seem to most people incredible. There are only a very few who can speak upon it clearly, because it is seldom near land nor appears where it may be seen by fishermen, and I suppose there are not many of this sort of fish in the sea. Most often in our tongue we call it hafgufa (\\"kraken\\" in e.g. Laurence M. Larson's translation[6]). Nor can I conclusively speak about its length in ells, because the times he has shown before men, he has appeared more like land than like a fish. Neither have I heard that one had been caught or found dead; and it seems to me as though there must be no more than two in the oceans, and I deem that each is unable to reproduce itself, for I believe that they are always the same ones. Then too, neither would it do for other fish if the hafgufa were of such a number as other whales, on account of their vastness, and how much subsistence that they need. It is said to be the nature of these fish that when one shall desire to eat, then it stretches up its neck with a great belching, and following this belching comes forth much food, so that all kinds of fish that are near to hand will come to present location, then will gather together, both small and large, believing they shall obtain their food and good eating; but this great fish lets its mouth stand open the while, and the gap is no less wide than that of a great sound or bight, And nor the fish avoid running together there in their great numbers. But as soon as its stomach and mouth is full, then it locks together its jaws and has the fish all caught and enclosed, that before greedily came there looking for food.[7]\\r\\nKraken were extensively described by Erik Pontoppidan, bishop of Bergen, in his Det f?rste Fors?g paa Norges naturlige Historie \\"The First Attempt at [a] Natural History of Norway\\" (Copenhagen, 1752).[8][9] Pontoppidan made several claims regarding kraken, including the notion that the creature was sometimes mistaken for an island[10] and that the real danger to sailors was not the creature itself but rather the whirlpool left in its wake.[11] However, Pontoppidan also described the destructive potential of the giant beast: \\"it is said that if [the creature's arms] were to lay hold of the largest man-of-war, they would pull it down to the bottom\\".[10][11][12] According to Pontoppidan, Norwegian fishermen often took the risk of trying to fish over kraken, since the catch was so plentiful[13] (hence the saying \\"You must have fished on Kraken\\"[14]). Pontoppidan also proposed that a specimen of the monster, \\"perhaps a young and careless one\\", was washed ashore and died at Alstahaug in 1680.[12][15] By 1755, Pontoppidan's description of the kraken had been translated into English.[16]\\r\\n\\r\\nSwedish author Jacob Wallenberg described the kraken in the 1781 work Min son p? galejan (\\"My son on the galley\\"):\\r\\n\\r\\nKraken, also called the Crab-fish, which is not that huge, for heads and tails counted, he is no larger than our ?land is wide [i.e., less than 16 km] ... He stays at the sea floor, constantly surrounded by innumerable small fishes, who serve as his food and are fed by him in return: for his meal, (if I remember correctly what E. Pontoppidan writes,) lasts no longer than three months, and another three are then needed to digest it. His excrements nurture in the following an army of lesser fish, and for this reason, fishermen plumb after his resting place ... Gradually, Kraken ascends to the surface, and when he is at ten to twelve fathoms, the boats had better move out of his vicinity, as he will shortly thereafter burst up, like a floating island, spurting water from his dreadful nostrils and making ring waves around him, which can reach many miles. Could one doubt that this is the Leviathan of Job?[17] \\r\\nIn 1802, the French malacologist Pierre Dnys de Montfort recognized the existence of two kinds of giant octopus in Histoire Naturelle Gnrale et Particulire des Mollusques, an encyclopedic description of mollusks.[18] Montfort claimed that the first type, the kraken octopus, had been described by Norwegian sailors and American whalers, as well as ancient writers such as Pliny the Elder. The much larger second type, the colossal octopus, was reported to have attacked a sailing vessel from Saint-Malo, off the coast of Angola.[10]\\r\\n\\r\\nMontfort later dared more sensational claims. He proposed that ten British warships, including the captured French ship of the line Ville de Paris, which had mysteriously disappeared one night in 1782, must have been attacked and sunk by giant octopuses. The British, however, knewcourtesy of a survivor from Ville de Paristhat the ships had been lost in a hurricane off the coast of Newfoundland in September 1782, resulting in a disgraceful revelation for Montfort.[13]\\r\\n\\r\\nSince the late 18th century, kraken have been depicted in a number of ways, primarily as large octopus-like creatures, and it has often been alleged that Pontoppidan's kraken might have been based on sailors' observations of the giant squid. The kraken is also depicted to have spikes on its suckers. In the earliest descriptions, however, the creatures were more crab-like[15] than octopus-like, and generally possessed traits that are associated with large whales rather than with giant squid. Some traits of kraken resemble undersea volcanic activity occurring in the Iceland region, including bubbles of water; sudden, dangerous currents; and appearance of new islets.[citation needed]\\r\\n\\r\\nThe legend of the kraken continues to the present day, with numerous references existing in popular culture, including film, literature, television, video games and other miscellaneous examples (e.g. postage stamps, a rollercoaster ride, and a rum product).\\r\\n\\r\\nIn 1830 Alfred Tennyson published the irregular sonnet The Kraken,[19] which described a massive creature that dwells at the bottom of the sea:\\r\\n\\r\\nBelow the thunders of the upper deep;\\r\\nFar far beneath in the abysmal sea,\\r\\nHis ancient, dreamless, uninvaded sleep\\r\\nThe Kraken sleepeth: faintest sunlights flee\\r\\nAbout his shadowy sides; above him swell\\r\\nHuge sponges of millennial growth and height;\\r\\nAnd far away into the sickly light,\\r\\nFrom many a wondrous grot and secret cell\\r\\nUnnumber'd and enormous polypi\\r\\nWinnow with giant arms the slumbering green.\\r\\nThere hath he lain for ages, and will lie\\r\\nBattening upon huge seaworms in his sleep,\\r\\nUntil the latter fire shall heat the deep;\\r\\nThen once by man and angels to be seen,\\r\\nIn roaring he shall rise and on the surface die.\\r\\n\\r\\nIn Herman Melville's 1851 novel Moby-Dick (Chapter 59. Squid.) the Pequod encounters what chief mate Starbuck identifies as: \\"The great live squid, which, they say, few whale-ships ever beheld, and returned to their ports to tell of it.\\" Narrator Ishmael adds: \\"There seems some ground to imagine that the great Kraken of Bishop Pontoppodan [sic] may ultimately resolve itself into Squid.\\" He concludes the chapter by adding: \\"By some naturalists who have vaguely heard rumors of the mysterious creature, here spoken of, it is included among the class of cuttle-fish, to which, indeed, in certain external respects it would seem to belong, but only as the Anak of the tribe.\\"[20]\\r\\n\\r\\nPontoppidan's description influenced Jules Verne's depiction of the famous giant squid in Twenty Thousand Leagues Under the Sea from 1870.[citation needed]\\r\\n\\r\\nJohn Wyndham's apocalyptic science fiction novel The Kraken Wakes depicts humanity locked in an existential struggle with ocean-dwelling aliens.","input":"When did the kraken first appear in stories?"},{"output":"Buenos Aires, Argentina","context":"World Youth Day (WYD) is an event for young people organized by the Catholic Church. The next, World Youth Day 2019, will be held in Panama.\\r\\nWorld Youth Day was initiated by Pope John Paul II in 1985. Its concept has been influenced by the Light-Life Movement that has existed in Poland since the 1960s, where during summer camps Catholic young adults over 13 days of camp celebrated a \\"day of community\\". For the first celebration of WYD in 1986, bishops were invited to schedule an annual youth event to be held every Palm Sunday in their dioceses. It is celebrated at the diocesan level annually, and at the international level every two to three years at different locations. The 1995 World Youth Day closing Mass in the Philippines set a world record for the largest number of people gathered for a single religious event with 5 million attendees a record surpassed when 6 million attended a Mass celebrated by Pope Francis in the Philippines 20 years later in 2015.[citation needed]\\r\\n\\r\\n\\r\\nWorld Youth Day is commonly celebrated in a way similar to many events. The most emphasized and well known traditional theme is the unity and presence of numerous different cultures. Flags and other national declarations are displayed among mainly young people to show their attendance at the events and proclaim their own themes of Catholicism. Such is usually done through chants and singing of other national songs involving a Catholic theme.\\r\\nOver the course of the major events taking place, national objects are traded between pilgrims. Flags, shirts, crosses, and other Catholic icons are carried amongst pilgrims which are later traded as souvenirs to other people from different countries of the world. A unity of acceptance among people is also common, with all different cultures coming together to appreciate one another.\\r\\nOther widely recognized traditions include the Pope's public appearance, commencing with his arrival around the city in the \\"Popemobile\\" and then with his final Mass held at the event. A festival in Sydney (2008) recorded an estimated distance of a 10-kilometre walk as roads and other public transport systems were closed off.\\r\\nPope Benedict XVI criticized the tendency to view WYD as a kind of rock festival; he stressed that the event should not be considered a \\"variant of modern youth culture\\" but as the fruition of a \\"long exterior and interior path\\".[1]\\r\\n1987 WYD was held in Buenos Aires, Argentina. 1989 WYD took place in Santiago de Compostela, Spain. 1991 WYD was held in Cz?stochowa, Poland. 1993 WYD was celebrated in Denver, Colorado, United States.\\r\\nAt WYD 1995, 5 million youths gathered at Luneta Park in Manila, Philippines, an event recognized as the largest crowd ever by the Guinness World Records.[2] In an initial comment immediately following the event, Cardinal Angelo Amato, Prefect of the Congregation for the Causes of Saints, stated that over 4 million people had participated.[3]\\r\\n1997 WYD was held in Paris, France. 2000 WYD took place in Rome, Italy. 2002 WYD was held in Toronto, Canada. 2005 WYD was celebrated in Cologne, Germany. Thomas Gabriel composed for the final Mass on 21 August 2005 the Missa mundi (Mass of the world), representing five continents in style and instrumentation, in a European Kyrie influenced by the style of Bach, a South American Gloria with guitars and pan flutes, an Asian Credo with sitar, an African Sanctus with drums, and an Australian Agnus Dei with didgeridoos.[4]\\r\\nSydney, Australia, was chosen as the host of the 2008 World Youth Day celebrations. At the time it was announced in 2005, WYD 2008 was commended by the then Prime Minister of Australia, Kevin Rudd, and the Archbishop of Sydney, Cardinal George Pell.[5] World Youth Day 2008 was held in Sydney, with the Papal Mass held on the Sunday at Randwick Racecourse.\\r\\nThe week saw pilgrims from all continents participate in the Days in the Diocese program hosted by Catholic dioceses throughout Australia and New Zealand. Pope Benedict XVI arrived in Sydney on 13 July 2008 at Richmond Air Force Base. Cardinal Pell celebrated the Opening Mass at Barangaroo (East Darling Harbour) with other activities including the re-enactment of Christ's passion during the Stations of the Cross and the pope's boat cruise through Sydney Harbour. Pilgrims participated in a variety of youth festivities including visits to St Mary's Cathedral, daily catechesis and Mass led by bishops from around the world, concerts, visits to the tomb of Saint Mary MacKillop, the Vocations Expo at Darling Harbour, reception of the Sacrament of Reconciliation, and praying before the Blessed Sacrament during Adoration. The Mass and concert at Barangaroo saw an estimated crowd of 150,000.\\r\\nThe event attracted 250,000 foreign visiting pilgrims to Sydney, with an estimated 400,000 pilgrims attending Mass celebrated by Pope Benedict XVI on 20 July.[6]\\r\\nIn May 2007, it was reported that Guy Sebastian's song \\"Receive the Power\\" had been chosen as official anthem for World Youth Day (WYD08) to be held in Sydney in 2008. The song was co-written by Guy Sebastian and Gary Pinto, with vocals by Paulini.[7][8]\\r\\n\\"Receive the Power\\"[9] was used extensively throughout the six days of World Youth Day in July 2008 and also in worldwide television coverage.[10]\\r\\nIn November 2008, a 200-page book, Receive the Power, was launched to commemorate World Youth Day 2008.[11]\\r\\nFollowing the celebration of Holy Mass at Randwick Racecourse in Sydney on 20 July 2008, Pope Benedict XVI announced that the next International World Youth Day 2011 would be held in Madrid, Spain. This event was held from 16ÿ21 August 2011.\\r\\nThere were nine official patron saints[12] for World Youth Day 2011 in addition to Blessed John Paul II: St. Isidore, St. John of the Cross, St. Mara de la Cabeza, St. John of vila, St. Teresa of vila, St. Rose of Lima, St. Ignatius of Loyola, St. Rafael Arniz, and St. Francis Xavier patron of world missions. During his address to seminarians, Benedict announced that the Spanish mystic and patron of Spanish diocesan clerics St. John of vila would become a \\"Doctor of the Church\\",[13] a designation granted to only 34 saints throughout the twenty centuries of Church history.\\r\\nAn estimated 2,000,000 people attended an all-night vigil to complete the week, more than expected.\\r\\nSince 2002, World Youth Day has been held every three years. After the 2011 event the next World Youth Day was scheduled a year earlier than usual, in 2013 in Rio de Janeiro, Brazil, in order to avoid any conflict with the 2014 FIFA World Cup being held in 12 different host cities throughout Brazil and the 2016 Summer Olympics being held in Rio de Janeiro.\\r\\nPope Francis announced at the end of closing Mass for World Youth Day 2013 that Krak܇w, Poland, would be the venue for World Youth Day 2016.[14] An estimated three million people attended. Young people from many different countries around the world took part in the week-long event which began on 25 July 2016, and ended on 31 July 2016 with an open-air mass led by Pope Francis at Campus Misericordiae where he announced that the next World Youth Day will take place in Panama, Central America in 2019. The theme for this year's World Youth Day was \\"Blessed Are The Merciful, For They Shall Obtain Mercy\\", tying in closely with the Year of Mercy, which was initiated by Pope Francis on 8 December 2015 and concluded 20 November 2016.\\r\\nAt the Concluding Mass for World Youth Day 2016 in Krak܇w, Pope Francis announced that Panama City will host World Youth Day in 2019.[15]\\r\\nNote 01Attendance numbers reflect the total number at the closing Mass which includes many locals who attended only that one event. Unless otherwise referenced, the numbers are quoted from the USCCB website.\\r\\nNote 02This lists languages used in the main international version of the anthem. Local versions of the anthem in other languages (and alternate versions) may have also been produced.\\r\\n[29]\\r\\nAt the diocesan level celebrations are decided by a local team usually appointed by the ordinary.\\r\\nSince these celebrations usually occur during Palm Sunday, it almost always includes the Mass of Passion Sunday ÿ when Jesus' entry to Jerusalem in his final days is commemorated.\\r\\nMusic, prayer, reconciliation opportunities, as well as adoration of the Blessed Sacrament may also be part of the celebrations.","input":"Where was the first world youth day held?"},{"output":"completed on 19 June 1936","context":"The House of Bernarda Alba (Spanish: La casa de Bernarda Alba) is a play by the Spanish dramatist Federico Garca Lorca. Commentators have often grouped it with Blood Wedding and Yerma as a \\"rural trilogy\\". Lorca did not include it in his plan for a \\"trilogy of the Spanish land\\" (which remained unfinished at the time of his murder).[1]\\r\\nLorca described the play in its subtitle as a drama of women in the villages of Spain. The House of Bernarda Alba was Lorca's last play, completed on 19 June 1936, two months before Lorca's death during the Spanish Civil War. The play was first performed on 8 March 1945 at the Avenida Theatre in Buenos Aires.[2][3] The play centers on the events of a house in Andalusia during a period of mourning, in which Bernarda Alba (aged 60) wields total control over her five daughters Angustias (39 years old), Magdalena (30), Amelia (27), Martirio, (24), and Adela (20). The housekeeper (La Poncia) and Bernarda's elderly mother (Mara Josefa) also live there.\\r\\nThe deliberate exclusion of any male character from the action helps build up the high level of sexual tension that is present throughout the play. Pepe \\"el Romano\\", the love interest of Bernarda's daughters and suitor of Angustias, never appears on stage. The play explores themes of repression, passion, and conformity, and inspects the effects of men upon women.\\r\\n\\r\\n\\r\\nUpon her second husband's death, domineering matriarch Bernarda Alba imposes an eight-year mourning period on her household in accordance with her family tradition. Bernarda has five daughters, aged between 20 and 39, whom she has controlled inexorably and prohibited from any form of relationship. The mourning period further isolates them and tension mounts within the household.\\r\\nAfter a mourning ritual at the family home, eldest daughter Angustias enters, having been absent while the guests were there. Bernarda fumes, assuming she had been listening to the men's conversation on the patio. Angustias inherited a large sum of money from her father, Bernarda's first husband, but Bernarda's second husband has left only small sums to his four daughters. Angustias' wealth attracts a young, attractive suitor from the village, Pepe el Romano. Her sisters are jealous, believing that it's unfair that plain, sickly Angustias should receive both the majority of the inheritance and the freedom to marry and escape their suffocating home environment.\\r\\nYoungest sister Adela, stricken with sudden spirit and jubilation after her father's funeral, defies her mother's orders and dons a green dress instead of remaining in mourning black. Her brief taste of youthful joy suddenly shatters when she discovers that Angustias will be marrying Pepe. Poncia, Bernarda's maid, advises Adela to bide her time: Angustias will probably die delivering her first child. Distressed, Adela threatens to run into the streets in her green dress, but her sisters manage to stop her. Suddenly they see Pepe coming down the street. She stays behind while her sisters rush to get a look, until a maid hints that she could get a better look from her bedroom window.\\r\\nAs Poncia and Bernarda discuss the daughters' inheritances upstairs, Bernarda sees Angustias wearing makeup. Appalled that Angustias would defy her orders to remain in a state of mourning, Bernarda violently scrubs the makeup off her face. The other daughters enter, followed by Bernarda's elderly mother, Maria Josefa, who is usually locked away in her room. Maria Josefa announces that she wants to get married; she also warns Bernarda that she'll turn her daughters' hearts to dust if they cannot be free. Bernarda forces her back into her room.\\r\\nIt turns out that Adela and Pepe are having a secret affair. Adela becomes increasingly volatile, defying her mother and quarreling with her sisters, particularly Martirio, who reveals her own feelings for Pepe. Adela shows the most horror when the family hears the latest gossip about how the townspeople recently dealt with a young woman who shamelessly delivered and killed an illegitimate baby.\\r\\nTension explodes as family members confront one another and Bernarda pursues Pepe with a gun. A gunshot is heard outside. Martirio and Bernarda return and imply that Pepe has been killed. Adela flees into another room. With Adela out of earshot, Martirio tells everyone else that Pepe actually fled on his pony. Bernarda remarks that as a woman she can't be blamed for poor aim. A shot is heard, immediately she calls for Adela, who has locked herself into a room. When Adela doesn't respond, Bernarda and Poncia force the door open. Soon Poncia's shriek is heard. She returns with her hands clasped around her neck and warns the family not to enter the room. Adela, not knowing that Pepe survived, has hanged herself.\\r\\nThe closing lines of the play show Bernarda characteristically preoccupied with the family's reputation. She insists that Adela has died a virgin and demands that this be made known to the whole town. (The text implies that Adela and Pepe had an affair; Bernarda's moral code and pride keep this from registering). No one is to cry.\\r\\nFilm adaptations include:\\r\\nIn 1967, choreographer Eleo Pomare adapted the play into his ballet, Las Desenamoradas,[7] featuring music by John Coltrane.\\r\\nIn 2006, the play was adapted into musical form by Michael John LaChiusa. Under the title Bernarda Alba, it opened at Lincoln Center's Mitzi Newhouse Theater on March 6, 2006, starring Phylicia Rashad in the title role, with a cast that also included Daphne Rubin-Vega.[8]\\r\\nIn 2012, Emily Mann adapted Federico Garca Lorca's original, shifting the location from 1930s Andalusia, Spain, to contemporary Iran. Her adaptation opened at the Almeida Theatre under the director Bijan Sheibani, starring Shohreh Aghdashloo as the title character and Hara Yannas as Adela.[9]\\r\\nSteven Dykes wrote a production named 'Homestead' for the American Theatre Arts (ATA) students in 2004 which was revived in 2013 (The Barn Theatre). The original production went on to perform at The Courtyard in Covent Garden, with members of an ATA graduate company Shady Dolls.\\r\\nIn August 2012, Hyderabad, India based theatre group Sutradhar staged Birjees Qadar Ka Kunba, an Urdu/Hindustani adaptation of The House of Bernarda Alba.[10] Directed by Vinay Varma and scripted by Dr. Raghuvir Sahay, the play adapted Lorca's original to a more Indian matriarch family setup. The play boasted of a cast of more than 10 women actors with Vaishali Bisht as Birjees Qadar (Bernard Alba) and Deepti Girotra as Hasan baandi (La Poncia).[11]\\r\\nLima, Robert. The Theatre of Garcia Lorca. New York: Las Americas Publishing Co., 1963.","input":"When was la casa de bernarda alba written?"},{"output":"Para Athlete Javelin thrower Devendra Jhajharia and Hockey player Sardara Singh.","context":"The Rajiv Gandhi Khel Ratna, officially known as Rajiv Gandhi Khel Ratna Award in Sports and Games,[1] is the highest sporting honour of the Republic of India.[2] The award is named after Rajiv Gandhi, former Prime Minister of India who served the office from 1984 to 1989.[3] It is awarded annually by the Ministry of Youth Affairs and Sports. The recipient(s) is/are selected by a committee constituted by the Ministry and is honoured for their \\"spectacular and most outstanding performance in the field of sports over a period of four years\\" at international level. As of 2017[update], the award comprises a medallion, a certificate, and a cash prize of ?7.5 lakh (US$12,000).[a][1]\\r\\nInstituted in 1991ÿ92, the award was given for the performance by a sportsperson in a year. Based on the suggestions provided by 2014 award selection committee, the Ministry revised the criteria in February 2015 to consider the performance over a period of four years. The nominations for a given year are accepted till 30 April or last working day of April with not more than two sportspersons nominated for each sports discipline. A twelve-member committee evaluates the performances of a sportsperson at various International events like Olympic Games, Paralympic Games, Asian Games, and Commonwealth Games. The committee later submits their recommendations to the Union Minister of Youth Affairs and Sports for further approval.\\r\\nThe first recipient of the award was Chess Grandmaster Viswanathan Anand, who was honoured for the performance in the year 1991ÿ92. In 2001, sport shooter Abhinav Bindra, then aged 18, became the youngest recipient of the award.[8] Usually conferred upon only one sportsperson in a year, a few exceptions have been made (1993ÿ94, 2002, 2009, 2012, and 2016ÿ17) when multiple recipients were awarded in a year. As of 2017[update], there have been thirty-four recipients from fourteen sport disciplines: Athletics, Badminton, Billiards, Boxing, Chess, Cricket, Field hockey, Gymnastics, Shooting, Snooker, Tennis, Wrestling, Weightlifting, and Yacht racing. The most recent recipients of the award are Para Athlete Javelin thrower Devendra Jhajharia and Hockey player Sardara Singh.\\r\\n\\r\\n\\r\\nThe nominations for the award are received from all government recognised National Sports Federations, the Indian Olympic Association, the Sports Authority of India (SAI), the Sports Promotion and Control Boards, and the state and the union territory governments with not more than two eligible sportspersons nominated for each sports discipline. In case of cricket, the nominations are received from the Board of Control for Cricket in India and SAI is authorised to submit the nominations on behalf of all the de-recognised or under suspension National Sports Federations.[b] The previous award recipients can also nominate one sportsperson for the discipline for which they themselves were awarded. The Government can nominate up to two sportspersons in deserving cases where no such nominations have been received from the nominating authorities. The nominations for a given year are accepted till 30 April or last working day of April.[1]\\r\\nAll the received nominations are sent to SAI and National Anti-Doping Agency for the verification against the claimed achievements and doping clearance respectively. Any sportsperson who is either penalised or being enquired for usage of drugs or substances banned by the World Anti-Doping Agency is not eligible for the award. A committee consisting of the Joint Secretary and the Director/Deputy Secretary of Department of Sports, the Secretary and the Executive Director/Director (TEAMS) of SAI verify and validate the nominations.[1]\\r\\nThe valid nominations are placed before the selection committee constituted by the Government. This twelve member committee consists of a Chairperson nominated by the Ministry, four Olympians or previous recipients of Rajiv Gandhi Khel Ratna or Arjuna Award, three sports journalists/experts/commentators, one sportsperson/expert/administrator associated with parasports, one sports administrator, the Director General of SAI, and the Joint Secretary of Department of Sports, with not more than one sportsperson from a particular discipline included in the committee.[1] When instituted in 1991ÿ92, the award was given for the performance by a sportsperson in a year.[4][9] Based on the suggestions provided by 2014 award selection committee headed by Kapil Dev,[10][11] the Ministry revised the criteria in February 2015 to consider the performance over a period of four years.[12]\\r\\nThe medals won in various International championships and events of the disciplines which include Summer and Winter Olympic and Paralympics Games, Asian Games, and Commonwealth Games are given 80% weightage. The remaining 20% weightage is given to the profile and standard of the events. For any other games not included in Olympic, Asian Games, and Commonwealth Games like cricket and indigenous games, the individuals performance of a sportsperson is taken into consideration. The sportsperson with maximum points is given 80 marks. Rest of the sportspersons are given marks in proportion to the maximum points. For team events, marks are given as per the strength of the team.[1] Following are the points defined for medals at the given events:\\r\\nFor a given discipline, not more than two sportspersons, one male and one female, are given highest marks. The committee may not recommend the award to the sportsperson with the highest marks across disciplines but can only recommend the recipient of the highest aggregate marks in a particular sports discipline. The recommendations of the selection committee are submitted to the Union Minister of Youth Affairs and Sports for further approval.[1]\\r\\nThe 2002 selection committee headed by former football player Pradip Kumar Banerjee made twenty one recommendations for the Arjuna Award and two recommendations for the Rajiv Gandhi Khel Ratna Award, athlete K. M. Beenamol and shooter Anjali Bhagwat. The government rejected the recommendations and asked the committee to cut down the list to comply with the award guidelines, where only one sportsperson for the Rajiv Gandhi Khel Ratna Award and fifteen sportspersons along with one disabled athlete for the Arjuna Awards could be recommended each year.[30] The committee revised the list to recommend Beenamol for the award over Bhagwat but also put a request \\"to consider everyone\\".[31] The decision spurred criticism for ignoring the achievements of the shooter and Bhagwat and the National Rifle Association of India expressed their \\"disappointment\\" with the decision.[32] Later, the government accepted all the recommendations \\"as an exception\\" and jointly awarded Beenamol and Bhagwat for the year 2002.[33]\\r\\nIn August 2013, the selection committee headed by Michael Ferreira recommended sport shooter Ronjan Sodhi for the award, with some committee members questioning the process of selection.[34] A committee member noted that discus thrower Krishna Poonia, and Paralympic athlete H. N. Girisha were shortlisted and Sodhi was not the initial choice. However, Girisha's name was removed, and the final voting was done between Sodhi and Poonia.[35] Poonia was accused of lobbying for the award by one of the committee member Anjali Bhagwat,[36] but the accused met the then Union Sports Minister Jitendra Singh to promote her case and also rubbished the lobbying allegations.[37][38] The Ministry conducted a separate enquiry by Secretary of Department of Sports and decided not to increase the number of awards \\"to maintain the stature of the awards\\".[37]\\r\\nFollowing an announcement, in August 2015, that tennis player Sania Mirza was to be awarded, a Public-Interest Litigation was filed in the Karnataka High Court. The petitioner, Paralympic athlete H. N. Girisha, mentioned that his performance was ignored by the committee.[39] Girisha claimed to be a top contender for the award with 90 points, owing to his silver medal winning act at the 2012 Summer Paralympics in the Men's High Jump F42 event.[40] The petition mentioned that the points for Mirza's Grand Slam titles from 2011 until 2015 should not be counted as the events were not a part of the list of sports events to be considered for the performance evaluation.[e] The court withheld the conferment and sought replies from the Ministry about the selection process. The Ministry nevertheless presented the award to Mirza on 29 August 2015 amidst the case processing.[2]","input":"Who got the rajiv gandhi khel ratna award 2016?"},{"output":"Yugoslavia","context":"The Non-Aligned Movement (NAM) is a group of states that are not formally aligned with or against any major power bloc. As of 2012[update], the movement has 120 members.[1]\\r\\nThe purpose of the organization has been enumerated as to ensure \\"the national independence, sovereignty, territorial integrity and security of non-aligned countries\\" in their \\"struggle against imperialism, colonialism, neo-colonialism, racism , and all forms of foreign aggression, occupation, domination, interference or hegemony as well as against great power and bloc politics,\\" by Fidel Castro in the Havana Declaration of 1979.[3] The countries of the Non-Aligned Movement represent nearly two-thirds of the United Nations' members and contain 55% of the world population. Membership is particularly concentrated in countries considered to be developing or part of the Third World, though the Non-Aligned Movement also has a number of developed nations such as Chile and Saudi Arabia, the latter of which is a member of the G20 (India is a G20 member as well).[4]\\r\\nAlthough many of the Non-Aligned Movement's members were actually quite closely aligned with one or another of the superpowers, the movement still maintained cohesion throughout the Cold War, even despite several conflicts between members which also threatened the movement. In the years since the Cold War's end, it has focused on developing multilateral ties and connections as well as unity among the developing nations of the world, especially those within the Global South.\\r\\n\\r\\n\\r\\nThe founding fathers of the Non-Aligned Movement were Josip Broz Tito of Socialist Yugoslavia, Jawaharlal Nehru of India, Sukarno of Indonesia, Gamal Abdul Nasser of Egypt and Kwame Nkrumah of Ghana. Their actions were known as 'The Initiative of Five'.\\r\\nThe Non-Aligned Movement as an organization was founded on the Brijuni islands in Yugoslavia in 1956, and was formalized by signing the Declaration of Brijuni on July 19th, 1956. The Declaration was signed by Yugoslavia's president, Josip Broz Tito, India's first prime minister Jawaharlal Nehru and Egypt's second president, Gamal Abdel Nasser. One of the quotations within the Declaration is \\"Peace can not be achieved with separation, but with the aspiration towards collective security in global terms and expansion of freedom, as well as terminating the domination of one country over another\\". The Movement advocates a middle course for states in the developing world between the Western and Eastern Blocs during the Cold War. The phrase itself was first used to represent the doctrine by Indian diplomat V. K. Krishna Menon in 1953, at the United Nations.[5][unreliable source?]\\r\\nBut it soon after became the name to refer to the participants of the Conference of Heads of State or Government of Non-Aligned Countries first held in 1961. The term \\"non-alignment\\" was established in 1953 at the United Nations. Nehru used the phrase in a 1954 speech in Colombo, Sri Lanka. In this speech, Nehru described the five pillars to be used as a guide for Sino-Indian relations called Panchsheel (five restraints); these principles would later serve as the basis of the Non-Aligned Movement. The five principles were:\\r\\nA significant milestone in the development of the Non-Aligned Movement was the 1955 Bandung Conference, a conference of Asian and African states hosted by Indonesian president Sukarno, who gave a significant contribution to promote this movement. Bringing together Sukarno, U Nu, Nasser, Nehru, Tito, Nkrumah and Menon with the likes of Ho Chi Minh, Zhou Enlai, and Norodom Sihanouk, as well as U Thant and a young Indira Gandhi, the conference adopted a \\"declaration on promotion of world peace and cooperation\\", which included Nehru's five principles, and a collective pledge to remain neutral in the Cold War. Six years after Bandung, an initiative of Yugoslav president Josip Broz Tito led to the first Conference of Heads of State or Government of Non-Aligned Countries, which was held in September 1961 in Belgrade.[6] The term non-aligned movement appears first in the fifth conference in 1976, where participating countries are denoted as members of the movement.[7]\\r\\nAt the Lusaka Conference in September 1970, the member nations added as aims of the movement the peaceful resolution of disputes and the abstention from the big power military alliances and pacts. Another added aim was opposition to stationing of military bases in foreign countries.[8]\\r\\nSome members were involved in serious conflicts with other members (e.g. India and Pakistan, Iran and Iraq). The movement fractured from its own internal contradictions when the Soviet Union invaded Afghanistan in 1979. Although the Soviet allies supported the invasion, other members of the movement (particularly predominantly Muslim states) condemned it.\\r\\nBecause[original research?] the Non-Aligned Movement was formed as an attempt to thwart the Cold War,[8] it has struggled to find relevance since the Cold War ended. After the breakup of Yugoslavia, a founding member, its membership was suspended[9] in 1992 at the regular Ministerial Meeting of the Movement, held in New York during the regular yearly session of the General Assembly of the United Nations.[10][11] The successor states of the Socialist Federal Republic of Yugoslavia have expressed little interest in membership, though Serbia and Bosnia and Herzegovina have observer status. In 2004, Malta and Cyprus ceased to be members and joined the European Union. Belarus is the only member of the Movement in Europe. Azerbaijan and Fiji are the most recent entrants, joining in 2011. The applications of Bosnia and Herzegovina and Costa Rica were rejected in 1995 and 1998, respectively.[11]\\r\\nSince the end of the Cold War, the Non-Aligned Movement has been forced to redefine itself and reinvent its purpose in the current world system. A major question has been whether many of its foundational ideologies, principally national independence, territorial integrity, and the struggle against colonialism and imperialism, can be applied to contemporary issues. The movement has emphasised its principles of multilateralism, equality, and mutual non-aggression in attempting to become a stronger voice for the global South, and an instrument that can be utilised to promote the needs of member nations at the international level and strengthen their political leverage when negotiating with developed nations. In its efforts to advance Southern interests, the movement has stressed the importance of cooperation and unity amongst member states,[12] but as in the past, cohesion remains a problem since the size of the organisation and the divergence of agendas and allegiances present the ongoing potential for fragmentation. While agreement on basic principles has been smooth, taking definitive action vis--vis particular international issues has been rare, with the movement preferring to assert its criticism or support rather than pass hard-line resolutions.[13]\\r\\nThe movement continues to see a role for itself, as in its view, the world's poorest nations remain exploited and marginalised, no longer by opposing superpowers, but rather in a uni-polar world,[14] and it is Western hegemony and neo-colonialism that the movement has really re-aligned itself against. It opposes foreign occupation, interference in internal affairs and aggressive unilateral measures, but it has also shifted to focus on the socio-economic challenges facing member states, especially the inequalities manifested by globalization and the implications of neo-liberal policies. The Non-Aligned Movement has identified economic underdevelopment, poverty, and social injustices as growing threats to peace and security.[15]\\r\\nThe 16th NAM summit took place in Tehran, Iran, from 26 to 31 August 2012. According to Mehr News Agency, representatives from over 150 countries were scheduled to attend.[16] Attendance at the highest level includes 27 presidents, 2 kings and emirs, 7 prime ministers, 9 vice presidents, 2 parliament spokesmen and 5 special envoys.[17] At the summit, Iran took over from Egypt as Chair of the Non-Aligned Movement for the period 2012 to 2015.[18]\\r\\nThe movement stems from a desire not to be aligned within a geopolitical/military structure and therefore itself does not have a very strict organizational structure.[2] Some organizational basics were defined at the 1996 Cartagena Document on Methodology[19] The Summit Conference of Heads of State or Government of Non-Aligned States is \\"the highest decision making authority\\". The chairmanship rotates between countries and changes at every summit of heads of state or government to the country organizing the summit.[19]\\r\\nRequirements for membership of the Non-Aligned Movement coincide with the key beliefs of the United Nations. The current requirements are that the candidate country has displayed practices in accordance with the ten \\"Bandung principles\\" of 1955:[19]\\r\\nSecretaries General of the NAM had included such diverse figures as Suharto,[20] militaristic[21] anti-communist, and Nelson Mandela, a democratic socialist and famous anti-apartheid activist. Consisting of many governments with vastly different ideologies, the Non-Aligned Movement is unified by its declared commitment to world peace and security. At the seventh summit held in New Delhi in March 1983, the movement described itself as \\"history's biggest peace movement\\".[22] The movement places equal emphasis on disarmament. NAM's commitment to peace pre-dates its formal institutionalisation in 1961. The Brioni meeting between heads of governments of India, Egypt and Yugoslavia in 1956 recognized that there exists a vital link between struggle for peace and endeavours for disarmament.[22]\\r\\nDuring the 1970s and early 1980s, the NAM also sponsored campaigns for restructuring commercial relations between developed and developing nations, namely the New International Economic Order (NIEO), and its cultural offspring, the New World Information and Communication Order (NWICO). The latter, on its own, sparked a Non-Aligned initiative on cooperation for communications, the Non-Aligned News Agencies Pool, created in 1975 and later converted into the NAM News Network in 2005.\\r\\nThe Non-Aligned Movement espouses policies and practices of cooperation, especially those that are multilateral and provide mutual benefit to all those involved. Many of the members of the Non-Aligned Movement are also members of the United Nations. Both organisations have a stated policy of peaceful cooperation, yet the successes the NAM has had with multilateral agreements tend to be ignored by the larger, western and developed nation dominated UN.[23] African concerns about apartheid were linked with Arab-Asian concerns about Palestine[23] and multilateral cooperation in these areas has enjoyed moderate success. The Non-Aligned Movement has played a major role in various ideological conflicts throughout its existence, including extreme opposition to apartheid governments and support of guerrilla movements in various locations, including Rhodesia and South Africa.[4]\\r\\nIn recent years the organization has criticized certain aspects of US foreign policy. The 2003 invasion of Iraq and the War on Terrorism, its attempts to stifle Iran and North Korea's nuclear plans, and its other actions have been denounced by some members of the Non-Aligned Movement as attempts to run roughshod over the sovereignty of smaller nations; at the most recent summit, Kim Yong-nam, the head of North Korea's parliament, stated that, \\"The United States is attempting to deprive other countries of even their legitimate right to peaceful nuclear activities.\\"[24]\\r\\nSince 1961, the organization has supported the discussion of the case of Puerto Rico's self-determination before the United Nations. A resolution on the matter was to be proposed on the XV Summit by the Hostosian National Independence Movement.[needs update][25]\\r\\nSince 1973, the group has supported the discussion of the case of Western Sahara's self-determination before the United Nations.[26] The movement reaffirmed in its last meeting (Sharm El Sheikh 2009) the support to the Self-determination of the Sahrawi people by choosing between any valid option, welcomed the direct conversations between the parties, and remembered the responsibility of the United Nations on the Sahrawi issue.[27]\\r\\nThe movement is publicly committed to the tenets of sustainable development and the attainment of the Millennium Development Goals, but it believes that the international community has not created conditions conducive to development and has infringed upon the right to sovereign development by each member state. Issues such as globalization, the debt burden, unfair trade practices, the decline in foreign aid, donor conditionality, and the lack of democracy in international financial decision-making are cited as factors inhibiting development.[28]\\r\\nThe movement has been outspoken in its criticism of current UN structures and power dynamics, stating that the organisation has been utilised by powerful states in ways that violate the movement's principles. It has made a number of recommendations that it says would strengthen the representation and power of \\"non-aligned\\" states. The proposed UN reforms are also aimed at improving the transparency and democracy of UN decision-making. The UN Security Council is the element it considers the most distorted, undemocratic, and in need of reshaping.[29]\\r\\nThe movement has collaborated with other organisations of the developing world?ÿ  primarily the Group of 77?ÿ  forming a number of joint committees and releasing statements and documents representing the shared interests of both groups. This dialogue and cooperation can be taken as an effort to increase the global awareness about the organisation and bolster its political clout.[citation needed]\\r\\nThe movement accepts the universality of human rights and social justice, but fiercely resists cultural homogenisation.[citation needed] In line with its views on sovereignty, the organisation appeals for the protection of cultural diversity, and the tolerance of the religious, socio-cultural, and historical particularities that define human rights in a specific region.[30][not in citation given]\\r\\nThe conference of Heads of State or Government of the Non-Aligned Countries, often referred to as Non-Aligned Movement Summit is the main meeting within the movement and are held every few years:[32]\\r\\nA variety of ministerial meetings are held between the summit meetings. Some are specialist, such as the meeting on \\"Inter-Faith Dialogue and Co-operation for Peace\\", held in Manila, the Philippines, 16ÿ18 March 2010. There is a general Conference of Foreign Ministers every three years. The most recent were in Bali, Indonesia, 23ÿ27 May 2011 and Algiers, Algeria, 26ÿ29 May 2014.\\r\\nThe Non-Aligned Movement celebrated its 50th anniversary in Belgrade on 5ÿ6 September 2011.[33][34]\\r\\nBetween summits, the Non-Aligned Movement is run by the secretary general elected at the last summit meeting. The Coordinating Bureau, also based at the UN, is the main instrument for directing the work of the movement's task forces, committees and working groups.\\r\\nThe following countries are members of the NAM, arranged by continent, showing their year of admission:[1][36]\\r\\nCurrently every African country (except the newly created South Sudan) is a member of the Non-Aligned Movement.\\r\\nThe following countries and organizations have observer status (2012):[1]\\r\\nThere is no permanent guest status,[44] but often several non-member countries are represented as guests at conferences. In addition, a large number of organisations, both from within the UN system and from outside, are always invited as guests.","input":"Where was the first non aligned summit held?"},{"output":"seven","context":"Ultimate civil war: spider-ham 1\\r\\nWhat if civil war 1\\r\\nCivil war poster book1\\r\\nDaily bugle civil war newspaper special 1\\r\\nMarvel spotlight civil war aftermath 1\\r\\n\\"Civil War\\" is a 2006ÿ07 Marvel Comics crossover storyline consisting of a seven-issue limited series of the same name written by Mark Millar and penciled by Steve McNiven, and various other tie-in books published by Marvel at the time. The storyline builds upon the events that developed in previous Marvel storylines, particularly \\"Avengers Disassembled\\", \\"House of M\\", and \\"Decimation\\". The tagline for the series is, \\"Whose Side Are You On?\\"[1]\\r\\nThe plot of the series follows a framework story line in which the U.S. government passes a Superhero Registration Act, ostensibly designed to have super powered individuals act under official regulation, somewhat akin to law enforcement. However, superheroes opposed to the act, led by Captain America, find themselves in conflict with those supporting the act, led by Iron Man, with Spider-Man caught in the middle; the X-Men take a neutral stance. The superheroes in support of the law, such as Iron Man, Mister Fantastic and Ms. Marvel, become increasingly authoritarian. In the aftermath of the war, Captain America surrenders and is imprisoned. The conflict between freedom and security is an underlying theme in the story line, with real-life events and discussions, such as the U.S. government's increased surveillance of its citizens, serving as a backdrop for the events in Civil War.[2][3] A sequel, Civil War II, debuted in June 2016.\\r\\nThe series polarized critics but was a commercial success. It is the basis for the Marvel Studios film Captain America: Civil War, which likewise features Captain America and Iron Man in opposition to each other but on a different basis.\\r\\n\\r\\n\\r\\nThe premise of Civil War involves the introduction of a Superhuman Registration Act in the United States. Mark Millar, writer for the story, has said:\\r\\nThe act requires any person in the United States with superhuman abilities to register with the federal government as a \\"human weapon of mass destruction,\\" reveal their true identity to the authorities and then undergo proper training. Those who sign also have the option of working for S.H.I.E.L.D., earning a salary and benefits such as those earned by other American civil servants. Characters within the superhero community in the Marvel Universe split into two groups: one advocating the registration as a responsible obligation, and the other opposing the law on the grounds that it violates civil liberties and the protection that secret identities provide. While arguing directly with Iron Man about the law, Luke Cage (previously the second Power Man), an African American, compared the mandatory registration to slavery.[5] A number of villains have also chosen to take sides, some choosing to side with the registration, others against it.\\r\\nMarvel announced in August 2006 that some issues of the main Civil War series would be pushed back several months to accommodate artist Steve McNiven. The schedule had issue #4 being released one month late, in September, while issue #5 was released two months later, in November. Furthermore, various tie-in books including the Civil War: Front Line miniseries and tie-in issues of other comics were delayed several months so as not to reveal any plot developments.[6]\\r\\nIn late November 2006, Marvel announced another delay. Civil War #6, originally scheduled for release on December 20, was pushed back two weeks and released on January 4. Unlike the previous instance, only The Punisher War Journal #2 was delayed. In a final act of rescheduling, Civil War #7 was pushed back two weeks (from January 17 to January 31),[7] and then pushed back again until February 21.[8]\\r\\nIn summary, an explosion in Stamford, Connecticut by the villain Nitro causes the U.S. government to introduce the Superhero Registration Act. Those not adhering to it are deemed unregistered and rogue superheroes. Tony Stark and Reed Richards lead the side of the pro-registration superheroes. Captain America leads the anti-registration side. Spider-Man, initially with Tony Stark, eventually joins the team of Captain America. Goliath is killed by the pro-registration superheroes. Many supervillains join the government in hunting down superheroes.\\r\\nWhen the Super-Human Registration Act was proposed, Professor X and the Avengers proposed an alternative method with self-policing of mutantkind and super-powered communities, preventing Civil War from ever happening. Cyclops thought it was preposterous for Professor X to make himself the self-appointed representative of mutantkind, and his opposition to Xavier's proposal led Jean Grey to break up with him and marry Wolverine.[9]\\r\\nWhen Mister Fantastic was researching realities where the Civil War ended differently, he found one reality in which their version of Anthony Stark was a woman named Natasha Stark. The Civil War was avoided entirely in this reality due to her marriage to Steve Rogers.[10]\\r\\nDuring an attempt by the reality-displaced Superior Spider-Man (Doctor Octopus' mind in Peter Parker's body) to reach back to his dimension as seen in the Spider-Verse storyline, he discovered an alternate dimension where a Civil War Iron Spider-Man lies dead (killed by Karn) prompting him to continue investigating the murders of Spider-Men throughout the Multiverse.[11]\\r\\nIn What If Civil War Ended Differently?, a stranger appears in front of Iron Man, who is visiting Captain Americas grave at Arlington National Cemetery. Tony Stark is told of two alternate ways the Civil War could have concluded:[12]\\r\\nFaced with this vision, Tony believes that this proves that he was right to pursue his pro-registration course of action, but the stranger then reveals another possibility;\\r\\nThe stranger is revealed to be Uatu, Earth 616's Watcher. Upon learning of the possibility of this alternate reality, Tony is devastated and weeps for the bright future he helped prevent.\\r\\nIn What If: Annihilation by David Hine and Mico Suayan, the cosmic Annihilation War reaches Earth during the War. The heroes unite to neutralize it, and many die in the first clashes. Captain America and Iron Man, after a final reconciliation, sacrifice themselves alongside Nova to deflect the full Annihilation Wave.[13]\\r\\nThe 2015 Contest of Champions series featured an alternate version of Civil War that had everything go in Tony Stark's favor. Five years after the war, Tony becomes the President of the United States and leads the Mighty Avengers as the Iron Patriot. His team consists of Penance (Robbie Baldwin), Iron Spider (Natasha Romanov), Captain Marvel (Carol Danvers), and the Thor clone known as Thunderstrike. Steve Rogers (no longer called Captain America) and his teammates have been arrested and buy time off their sentence by performing suicide missions as the Thunderbolts. Steve's team consists of Spider-Man (Peter Parker), Invisible Woman, the Punisher, and Bill Foster's Goliath (who survived the Civil War in this reality). President Stark and his Mighty Avengers are taken to Battleworld by Maestro and have their memories altered to think that they are on Earth and that the Renegade Champions already there are unregistered vigilantes. The Thunderbolts are sent to rescue them, but misunderstandings result in the deaths of Penance and Thunderstrike and all three teams start fighting each other. Tony kills Steve when Steve lets his guard down, and reveals that he is in the possession of the Reality Gem from the Infinity Gauntlet. Tony and the members of the Illuminati divided the six Infinity Stones after hunting them down and vowed never to use them. But when Tony let the events of Civil War happen in their natural course, he couldn't resist using the Reality Gem to alter events in his favor. He used the gem to prevent the death of Goliath, the assassination of Captain America, alter the war in his favor, and rig the presidential election. He attempts to use it again to undo his killing of Steve, but as they are in another dimension the Reality Gem does not work. Maestro kills Tony and the Punisher, but is stopped by the intervention of Stick, the Sentry, and Nigel Higgins using the Iso-Sphere. The remaining five heroes from the Mighty Avengers and Thunderbolts stay behind on Battleworld with the Sentry and fight villains attempting to gather the Iso-Sphere as the Civil Warriors.[14]\\r\\nThe Civil War storyline is featured in Secret Wars where it has its own mini-series. Its location on Battleworld is referred to as the Warzone.[15]\\r\\nIn this story, the Stamford incident leads to a polarising political debate that culminates with the two sides clashing in the Negative Zone Prison. During the fight, Black Panther hacks into the prison's computers and sees that the portal will explode, killing most of the combatants and stranding the rest. Black Panther assumes that Stark will teleport his combatants out at the last minute, but meanwhile, S.H.I.E.L.D. director Maria Hill tells Stark that Black Panther activated the explosives on the orders of Steve Rogers. Deactivating the teleportation device, Black Panther tries to shut down the bomb. Everyone in the prison rushes to escape through the power of the hero Cloak, who drops them all in midair over St. Louis. Unfortunately, Cloak can not shut off his powers fast enough to block out the explosion. The resulting beam of explosive energy creates a vast chasm called the Divide, destroying St. Louis and leaving millions dead.\\r\\nThe two sides regroup, with the Pro-Registration group taking control of the land to the east of St Louis, while the Anti-Registration group takes control of the land to the west. Each side blames the other for the deaths. The East became \\"the Iron\\", run by Tony Stark, and The West became \\"The Blue\\", run by Captain America. Differences in politics have caused people to pick one side over the other, with the split ossifying every year. The only place in the country that embraces both is a community in the ruins of St. Louis, built on a bridge over a chasm between the two sides. One of its inhabitants is Miriam Sharpe, a woman who lost her child at Stamford but who wants to bring peace.\\r\\nSix years after the start of the conflict, Sharpe brings the two leaders together to discuss peace. At the meeting, Miriam is able to get the two men to open up. Stark explains that the Iron has wealth and resources from trade with the outside world where the Blue is regarded as a rogue state. However, his citizens are running out of space while the Blue has twice the space but half the population. He proposes that the Blue shrink, giving his people more space in exchange for which Stark will make trade concessions. General Rogers dismisses the offer, which leads to the start of an old debate between the two men. As Miriam Sharpe tries to intervene, she is shot in the back by a sniper. Reacting first, General Rogers calls Peter Parker to catch the shooter. Parker finds a remote-controlled sniper rifle. As Miriam dies, General Rogers realizes that from the angle of the shot that the shooter was most likely aiming at him. President Stark denies the shooter is one of his, but renewed civil war seemed inevitable.[16]\\r\\nPresident Stark sends a drone to track the killers, but it is shot down and its datacore claimed by the Blue. President Stark discovers certain anomalies regarding past events, leading him to believe that events like Sharpe's murder were caused by a third party. Meanwhile, Hank McCoy shows Rogers the results of \\"Project Bellcurve\\", a procedure capable of depowering superhumans. Numerous resources from the Iron are needed to continue the project, for which Rogers sends a team composed of Parker, Elektra, Azari, and Venom/Clint Barton to infiltrate Stark's territory. At the same time, Stark sends Jennifer Walters to infiltrate the Blue and continue investigating Sharpe's murder.[17]\\r\\nSpider-Man's team suffers the first casualty when a Stark Sentinel kills Elektra. The team manages to overcome the rest of the defenses (including the reanimated corpse of the Kingpin controlled by Doctor Octopus' tentacles) thanks to Venom, and return to the Blue with the components needed for \\"Project Bellcurve.\\" At the same time, She-Hulk had been able to infiltrate Steeltown. However, Agent Robbie Baldwin of the Punishers recognizes her and follows She-Hulk. She discovers the assassin was Bullseye. Baldwin attacks Jen as she is spying on Bullseye, and is forced to flee. Before she can leave Steeltown, she is knocked out by an unidentified attacker. She-Hulk awakes in an undisclosed location having been captured by Bullseye's client Black Panther.[18]\\r\\nAs the Blue prepare to invade the Iron in a last-ditch attempt at ending the war, Iron Man tracks down Jen's position and flies to rescue her. He finds her, but his armor is neutralized and stripped from him. Tony is brought to Black Panther who reveals himself as the Skrull Queen Veranke. Veranke tells him that she is the cause of every single failed attempt at reaching peace in a part of a plan to benefit from the never-ending war. Iron Man uses additional weaponry that was not in his armor to free himself, fend off the Skrull guards, and break She-Hulk free from her cage. Meanwhile, the Blue invade the Iron while General America prepares to detonate a bomb derived from Project Bellcurve.[19]\\r\\nAs the conflict escalates, Iron Man is able to reach General America and reveal that Bucky is a Skrull, prompting General America to accept a telepathic 'update' from Emma Frost that confirms that the Skrulls have manipulated the conflict for years. Accepting their mutual responsibility for the situation, Rogers and Stark sacrifice themselves to detonate the Bellcurve bomb. The blast depowers the superhumans and reverts the Skrulls to their true state. A few months later, a powerless Peter and Jennifer are shown discussing the tentative truce that has been formed between the two sides, and wonder whether Stark and Rogers knew that peace would be the result of their sacrifice.[20]\\r\\nA direct sequel to the original series debuted in June 2016, written by Brian Michael Bendis and drawn by David Marquez.[21] Unlike the previous story and the film, the conflict in this storyline is not about issues of government registration; a new Inhuman, Ulysses, has emerged with the ability to make extremely accurate predictions of the future, resulting in conflict emerging between heroes led by Iron Man and Captain Marvel respectively, Stark favouring self-determination and concerned about the prospects of coming to depend on the visions while Danvers feels that his visions represent a potentially valuable asset.\\r\\nAt the time of its release, Civil War received mixed reviews. Comic Book Round Up gave the series an average rating of 6.5. According to a scholarly analysis presented at the 2007 Comic-Con International, this story's conflict is a natural outgrowth of what psychologist Erich Fromm called \\"the basic human dilemma\\", the conflicting desires for both security and freedom, and \\"character motivations on both sides arise from positive human qualities because Fromms image of human nature is ultimately optimistic, holding that people on either side are struggling to find what is best for all\\".[2] However, over time, Civil War have become more well received. IGN ranked it as one of the greatest Comic Book Events,[22] and WatchMojo ranked it as #6 on their Top 10 Marvel Graphic Novels list and #1 on their Top 10 Avengers Comics You Should Read list.\\r\\nMarvel adapted Civil War into a prose hardcover novel in July 2012 as the first of a series of four novels adapting some of Marvel's most significant fictional events.[23] It was written by Stuart Moore, the writer of Namor: The First Mutant. The book expanded on the story and set the events during Barack Obama's first term in office, rather than George W. Bush's last term; Tony Stark makes reference to the Affordable Care Act when speaking to Spider-Man in the first chapter of the novel.[24] The novel is set in the alternate timeline created by the controversial storyline \\"One More Day\\" and detailed in \\"One Moment in Time\\", as Spider-Man is depicted as never having married Mary Jane Watson, having never arrived on the day of their wedding.[25] In the original comics version, Civil War was a lead-in to \\"One More Day\\", depicting May Parker's assassination on the orders of Wilson Fisk near the end of the main Civil War storyline.\\r\\nCaptain America: Civil War was a cinematic treatment of the story, albeit focusing more on the issue of government control rather than public knowledge of secret identities, matters also being escalated by the interference and manipulation of Helmut Zemo as his plan for revenge for the Avengers' role in Ultron's assault and the deaths of Zemo's family. The movie version of Civil War also differs from the comic substantially, with the fate of Bucky Barnes being a key element of the war after he is framed for an assassination. As in the comics, Captain America and Iron Man are the respective leaders of the anti-registration and pro-registration sides of the conflicts, with Cap's side including the Falcon, Bucky, Ant-Man, Hawkeye, and the Scarlet Witch, and Iron Man's side being Black Widow, War Machine, the Black Panther, Spider-Man and the Vision. In the end Stark and Rogers reconcile after realizing the truth, only for it to be short lived as Zemo reveals Barnes' role in Stark's parents' deaths and that Rogers kept the truth from him, causing him to angrily attack both Rogers and Barnes, the fight culminates with Rogers abandoning his shield and identity. The film concludes with Cap's side seeking asylum in Wakanda after the Black Panther recognizes that he was wrong to target Bucky. The latter is then put in a cryogenetic sleep. Black Widow goes on the run, and War Machine is left crippled after injuries sustained in the final battle.\\r\\nA different variation of the Civil War storyline closely resembling Civil War II as it features Iron Man and Captain Marvel in opposition to each other was adapted in the four-part Season 3 finale of Avengers Assemble. In this version of the storyline, the Registration Act targets new Inhumans, and teams of Avengers come into conflict over the issue, as in other adaptations. It is revealed in Part 3, however, that the Inhuman Registration Act is actually part of a plan by Truman Marsh (actually Ultron in disguise) to begin the Ultron Revolution by manipulating humans and Inhumans into destroying each other, which is foiled by the combined efforts of the Avengers.","input":"How many marvel civil war comics are there?"},{"output":"430 to 460 yen","context":"Smoking in Japan, though historically less restricted by law than in many other nations, has significantly changed in recent years. Tobacco use has been in nearly constant decline since 1996 and the decline has been mainly accelerating in recent years.[1] Per capita consumption   in 2015 was 1,618 cigarettes, roughly 46% of the peak figure in 1977 and a number last seen in 1956.[2] In 2015, the adult smoking rate was 19.3%, 29.7% of Japanese men and 9.7% of Japanese women.[3]  This is the lowest recorded figure since Japan Tobacco began surveying in 1965.  As of July 2016, just over 20 million people smoked in Japan, though the nation remained one of the world's largest tobacco markets.[4]\\r\\n\\r\\nUntil 1985, the tobacco industry was a government-run monopoly; the government of Japan is still involved in the industry through the Ministry of Finance, which after a sell-off in March 2013, now owns only one third of Japan Tobacco's outstanding stock, and the Ministry of Health, Labour, and Welfare, which is active in public health and other tobacco control policy making.[5]\\r\\n\\r\\nThe Diet of Japan has many MPs who have interests in the tobacco industry and thus tobacco control legislation is uncommon.[6]\\r\\n\\r\\nNon-smoking areas are becoming increasingly common in Japan, in homes, offices, restaurants, fast-food eateries, \\"family restaurants,\\" pachinko parlors, and public areas.[7] Kanagawa Prefecture enacted Japan's first smoke-free public places ordinance in 2009 and Hyogo Prefecture followed with a similar law in 2012.[8] All trains either have non-smoking cars or are completely smoking-free, as are many train station platforms in urban areas.[9]\\r\\n\\r\\nA particular brand of cigarettes in Japan costs the same across all vendors, from cigarette machines to big supermarkets to corner shops. Bulk purchases are not discounted. As of 6 August 2013, the price of a typical pack of cigarettes ranged from 410 to 440 yen. Because of the hike in the consumption sales tax to 8% on 1 April 2014, the range is now 430 to 460 yen.\\r\\n\\r\\nUnlike in Europe, Australia and North America, where mandatory smoking bans apply in restaurants, bars, and public areas, smoking in Japan is not made illegal by Article 25 of the nation's Health Promotion Act, which merely urges smoking restrictions.  Limited indoor bans have been enacted in Kanagawa and Hyogo Prefectures, but not nationally.  Other restrictions may be implemented by the choice of public and private property  owners, managers, employers, etc.[10]\\r\\n\\r\\nMany of the wealthier wards of Tokyo, such as Shinjuku and Shibuya, are applying various kinds of anti-smoking  laws. They have designated special smoking sections in areas and it is punishable by fine if caught smoking outside these areas. Chiyoda-ku banned smoking while walking on busy streets from November 2002, the first local government in Japan to do so.[11]\\r\\n\\r\\nStarting in 2007, Kyoto began designating certain city streets as non-smoking areas, and have since then been increasing the number of streets designated as such.[12][13] In a 2010 report, Kyoto Prefecture stated that the major goal of their anti-smoking policies is \\"to ensure that there is zero chance for people to suffer from second-hand smoke in Kyoto prefecture.\\"[14]\\r\\n\\r\\nStarbucks is one of the few service industry companies in Japan that bans smoking inside all of its stores,[15] but allows smoking and provides ashtrays in the outside seating areas at most stores in Osaka. McDonald's Japan plans to ban smoking at some of its stores following renovations,[15] and has banned smoking at its 298 restaurants in Kanagawa prefecture since 1 March 2010.[16] Kentucky Fried Chicken banned smoking at one branch in Shibuya, Tokyo in July 2010.[15]\\r\\n\\r\\nWhile a high percentage of men in Japan have smoked throughout in the postwar years, the rate for women for many years hovered between 10 and 15%, followed there too by a decline in recent years to be floating currently a little below 10%.[18]\\r\\n\\r\\nIn the mid-1990s, the number of younger female smokers in particular had risen substantially.  Smoking has since declined among this group as well, but that cohort of women still smokes at a higher rate than their elders.[19]  \\"The manufacturers were very successful in providing cool images to the consumers,\\" says Ministry of Health and Welfare technical officer Yumiko Mochizuki, when asked to explain the steady rise in female smokers. \\"Until recently, the Ministry of Health and Welfare had an understanding that smoking was entirely up to the individual.\\"[20]\\r\\n\\r\\nThe government's advertising ban based on the \\"motherhood\\" argument was watertight until the tobacco industry was privatized in 1985. Advertising that encourages women to smoke is forbidden in Japan under a voluntary industry agreement. The industry group pledged to voluntarily honor the advertising ban and is charged with enforcing it. United States maker Brown & Williamson sells Capri cigarettes in Japan in slim white boxes with a flower-like design on the cover. R.J. Reynolds' Tokyo billboards for Salem's Pianissimo cigarettes are green-and-pink. Philip Morris advertised its Virginia Slims brand with the slogan \\"Be You\\" in an ad campaign.\\r\\n\\r\\nOther factors contribute to the rise in female smokers. Some observers cite stress, saying that more Japanese women are smoking to relax as more enter the workforce. Others argue that smoking is one arena in which women can have equality with men.[citation needed] Media influence is also cited, as many women on popular Japanese television dramas smoke.\\r\\n\\r\\nCigarettes can be bought in tobacco stores and at vending machines, and public ashtrays dot sidewalks and train platforms. The number of cigarette vending machines in Japan is estimated at 500,000 in 2002.[21]\\r\\n\\r\\nThe law prohibits the smoking of cigarettes by persons under the age of twenty.[22]\\r\\n\\r\\nTaspo is a smart card developed by the Tobacco Institute of Japan, the nationwide association of tobacco retailers, and the Japan Vending Machine Manufacturers Association. Introduced in 2008, the card is necessary to purchase cigarettes from vending machines.\\r\\n\\r\\nIn 2008 Japan Tobacco commissioned  a series of over 70 public service announcement style \\"smoking manner\\" posters about smoking etiquette.[23][24] The ads were displayed in a wide variety of formats ranging from placards in the subway to postcards to beverage coasters.","input":"How much is a pack of cigarettes in japan?"},{"output":"triennium","context":"A decade is a period of ten years. The word is derived (via French and Latin) from the Ancient?Greek: Ѵ?? (/e?k??s/, transliteration=dekas), which means a group of ten. Other words for spans of years also come from Latin: biennium (2 years), triennium (3 years), quadrennium (4 years), lustrum (5 years), century (100 years), millennium (1000 years).\\r\\n\\r\\n\\r\\nAlthough any period of ten years is a decade,[1][2] a convenient and frequently referenced interval is based on the tens digit of a calendar year, as in using \\"1960s\\" to represent the decade from 1960 to 1969.[3][4] Often, for brevity, only the tens part is mentioned (60s or sixties), although this may leave it uncertain which century is meant. These references are frequently used to encapsulate popular culture or other widespread phenomena that dominated such a decade, as in The Great Depression of the 1930s.\\r\\nBecause the common calendar starts with year 1, its first full decade is the years one to ten, the second decade from 11 to 20, and so on.[5] So although the \\"1960s\\" comprises the years 1960 to 1969, the \\"197th decade\\" spans 1961 to 1970.\\r\\nA decade may also refer to an arbitrary span of ten years. For example, the statement \\"during his last decade, Mozart explored chromatic harmony to a degree rare at the time\\", merely refers to the last ten years of Mozart's life without regard to which calendar years are encompassed.\\r\\nFor decades of the 20th century, a nominal decade is often used to refer not just to a set of ten years but rather to an era roughly approximating those ten years - for example, the phrase the sixties often refers to events that took place between c. 1964 and 1972, and to memories of the counterculture, flower power, protests of 1968 and other things happening at the time.","input":"What is a period of 3 years called?"},{"output":"people","context":"Originally, the name Rus' (^) referred to the people,[1] regions, and medieval states (ninth to twelfth centuries) of the Kievan Rus'. In the Western culture, it is better known as Ruthenia from the eleventh century onwards.[2] Its territories are today distributed among Belarus, Ukraine, and a part of the European section of Russia.\\r\\nOne of the earliest written sources mentioning the people called Rus' (as Rhos) dates to 839 in the Annales Bertiniani. This chronicle identifies them as a Germanic tribe called the Swedes. According to the Kievan Rus' Primary Chronicle, compiled in about 1113, the Rus' were a group of Varangians, Norsemen who had relocated somewhere from the Baltic region (literally \\"from beyond the sea\\"), first to Northeastern Europe, then to the south where they created the medieval Kievan state.[3] In the 11th century, the dominant term in the Latin tradition was Ruscia. It was used, among others, by Thietmar of Merseburg, Adam of Bremen, Cosmas of Prague and Pope Gregory VII in his letter to Izyaslav I. Rucia, Ruzzia, Ruzsia were alternative spellings. During the 12th century, Ruscia gradually made way for two other Latin terms, \\"Russia\\" and \\"Ruthenia\\". \\"Russia\\" (also spelled Rossia and Russie) was the dominant Romance-language form, first used by Liutprand of Cremona in the 960s and then by Peter Damian in the 1030s. It became ubiquitous in English and French documents in the 12th century. Ruthenia, first documented in the early 12th century Augsburg annals, was a Latin form preferred by the Apostolic Chancery of the Latin Church.\\r\\nThe modern name of Russia (Rossija), which came into use in the 15th century,[4][5][6] is derived from the Greek ߿?ϫ, which in turn derives from ???, an early Greek name for the people of Rus'.[7] Rus' as a state had no proper name; by its inhabitants it was called rus?skaja zemlja (^ 켼) ÿ with rus?skaja becoming russkaja in Modern Russian ÿ, which translates as \\"Land of the Rus'\\". The word rus?skaja is an adjective: the morpheme -?sk- corresponds etymologically to English -ish; -aja marks feminine adjectives (namely, zemlja, \\"land\\", is grammatically feminine in Slavic). In similar fashion, Poland is called Polska by its inhabitants, that is, Pol-sk-a, originally being the adjective Polish (land).\\r\\nTo distinguish the medieval \\"Rus'\\" state from other states that derived from it, modern historiography calls it Kievan Rus'. Its predecessor, the ninth-century Rus' Khaganate, is a somewhat hypothetical state whose existence is inferred from a handful of early medieval Byzantine and Persian and Arabic sources that mention that the Rus' were governed by a khagan.\\r\\n\\r\\n\\r\\nAccording to the most prominent theory, the name Rus', like the Finnish name for Sweden (Ruotsi), is derived from an Old Norse term for \\"the men who row\\" (rods-) as rowing was the main method of navigating the rivers of Eastern Europe, and that it could be linked to the Swedish coastal area of Roslagen (the rowing crews) or Roden, as it was known in earlier times.[8][9] The name Rus' would then have the same origin as the Finnish, Estonian, V?ro and Northern Sami names for Sweden: Ruotsi, Rootsi, Roodsi and Ruo??a.[10] It is remarkable enough that the local Finnic and Permic peoples in northern Russia proper use the same (Rus'-related) name both for Sweden and Russia (depending on the language): thus the Veps name for Sweden and Swedish is Ro?inma / Ro?in,[11] while in the neighboring Komi language the etymologically corresponding term Ro?mu / Ro? means already Russia and Russian instead.[12][13]\\r\\nThe Danish scholar Tor Karsten has pointed out that the territory of present-day Uppland, S?dermanland and East Gothland in ancient times was known as Roeer or roein. Thomsen accordingly has suggested that Roeer probably derived from roesmenn or roeskarlar, meaning seafarers or rowers.[14][page?needed] Ivar Aasen, the Norwegian philologist and lexicographer, noted Norwegian dialect variants Rossfolk, Rosskar, Rossmann.[15]\\r\\nGeorge Vernadsky theoretized about the association of Rus and Alans. He claimed that that Ruxs in Alanic means \\"radiant light\\", thus the ethnonym Roxolani could be understood as \\"bright Alans\\".[16] He theorized that the name Roxolani a combination of two separate tribal names: the Rus and the Alans.[16] Rus were closely associated with the Alans in the Sarmatian period.[16]\\r\\nIn Old East Slavic literature, the East Slavs refer to themselves as \\"[muzhi] ruskie\\" (\\"Rus' men\\") or, rarely, \\"rusichi.\\" The East Slavs are thought to have adopted this name from the Varangian elite, which was first mentioned in the 830s in the Annales Bertiniani. The Annales recount that Louis the Pious's court at Ingelheim am Rhein in 839 (the same year as the first appearance of Varangians in Constantinople), was visited by a delegation from the Byzantine emperor. The delegates included two men who called themselves \\"Rhos\\" (\\"Rhos vocari dicebant\\"). Louis inquired about their origins and learned that they were Swedes. Fearing that they were spies for their brothers the Danes, he jailed them. They were also mentioned in the 860s by Byzantine Patriarch Photius under the name, \\"Rhos.\\"\\r\\nRusiyyah was used by Ahmad ibn Fadlan for Varangians near Astrakhan, and by the Persian traveler Ahmad ibn Rustah who visited Veliky Novgorod and described how the Rus' exploited the Slavs.\\r\\nAs for the Rus, they live on an island ... that takes three days to walk round and is covered with thick undergrowth and forests; it is most unhealthy... They harry the Slavs, using ships to reach them; they carry them off as slaves and... sell them. They have no fields but simply live on what they get from the Slav's lands... When a son is born, the father will go up to the newborn baby, sword in hand; throwing it down, he says, \\"I shall not leave you with any property: You have only what you can provide with this weapon.\\"[17]\\r\\nWhen the Varangians arrived in Constantinople, the Byzantines considered and described the Rhos (Greek ???) as a different people from the Slavs. In his treatise De Administrando Imperio, Constantine VII describes the Rhos as the neighbours of Pechenegs who buy from the latter cows, horses, and sheep \\"because none of these animals may be found in Rhosia\\". His description represents the Rus' as a warlike northern tribe. Constantine also enumerates the names of the Dnieper cataracts in both Rhos and in Slavic languages. The Rhos names have distinct Germanic etymology:[18]\\r\\nAccording to the Primary Chronicle, a historical compilation attributed to the 12th century, Rus' was a group of Varangians who lived on the other side of the Baltic Sea in Scandinavia. The Varangians were first expelled, then invited to rule the warring Slavs and Baltic Finns of Veliky Novgorod:\\r\\nThe four tribes who had been forced to pay tribute to the Varangians - Chuds, Slavs, Merians and Krivichs drove the Varangians back beyond the sea, refused to pay them further tribute, and set out to govern themselves. But there was no law among them, and tribe rose against tribe. Discord thus ensued among them, and they began to war one against the other. They said to themselves, \\"Let us seek a prince who may rule over us, and judge us according to custom. Thus they went overseas to the Varangians, to the Rus. These particular Varangians were known as Rus, just as some are called Swedes, and others Normans and Angles, and still others Gotlanders, for they were thus named. The Chuds, the Slavs, the Krivichs and the Ves' then said to the Rus, \\"Our land is great and rich, but there is no order in it. Come reign as princes, rule over us\\". Three brothers, with their kinfolk, were selected. They brought with them all the Rus and migrated.[citation needed]\\r\\nThe earliest written mention of the word Rus' or Rus'ian/Russian appears in the Primary Chronicle under the year 912. When describing a peace treaty signed by the Varangian Oleg of Novgorod during his campaign on Constantinople, it contains the following passage, \\"Oleg sent his men to make peace and sign a treaty between the Greeks and the Rus', saying thus: [...] \\"We are the Rus': Karl, Inegeld, Farlaf, Veremud, Rulav, Gudi, Ruald, Karn, Frelav, Ruar, Aktevu, Truan, Lidul, Vost, Stemid, sent by Oleg, the great prince of Rus', and all those under him[.]\\"[citation needed]\\r\\nIt can be noted that none of the Rus' names listed are Slavic and few are likely to be Finnic; most or all are Germanic.\\r\\nLater, the Primary Chronicle tells us, they conquered Kiev and created Kievan Rus'. The territory they conquered was named after them as were, eventually, the local people (cf. Normans).\\r\\nHowever, the Synod Scroll of the Novgorod First Chronicle, which is partly based on the original list of the late 11th Century and partly on the Primary Chronicle, does not name the Varangians asked by the Chuds, Slavs and Krivichs to reign their obstreperous lands as the \\"Rus'\\". One can assume that there was no original mention of the Varangians as the Rus' due to the old list predating the Primary Chronicle and the Synod Scroll only referred to the Primary Chronicle if the pages of the old list were blemished.\\r\\nOther spellings used in Europe during the 9th and 10th centuries were as follows: Ruzi, Ruzzi, Ruzia and Ruzari. But perhaps the most popular term to refer to the Rus' was Rugii, a name of the ancient East Germanic tribe related to the Goths. Olga of Kiev, for instance, was called in the Frankish annals regina Rugorum, that is, \\"the Queen of the Rugi.\\"\\r\\nA number of alternative etymologies have been suggested. These are derived from the \\"anti-Normanist\\" school of thought in Russian historiography during the 19th century and in the Soviet era. These hypotheses are considered unlikely in Western mainstream academia.[10] Slavic and Iranian etymologies suggested by \\"anti-Normanist\\" scholars include:\\r\\nThe name Rus' may have originated from the Iranian name of the Volga River (by F. Knauer, Moscow 1901), as well as from the Rosh of Ezekiel.[19] Prof. George Vernadsky has suggested a derivation from the Roxolani or from the Aryan term ronsa[verification needed] (moisture, water). River names such as Ros are common in Eastern Europe.[14][page?needed]\\r\\nThe Russian linguist I.N. Danilevskiy, in his Ancient Rus as Seen by Contemporaries and Descendants, argued against these theories, stating that the anti-Normanists neglected the realities of the Ancient Slavic languages and that the nation name Rus' could not have arisen from any of the proposed origins.\\r\\nDanilevskiy further argued that the term followed the general pattern of Slavic names for neighboring Uralic peoplesthe Chud', Ves', Perm', Sum', etc.but that the only possible word that it could be based on, Ruotsi, presented a historical dead-end, since no such tribal or national name was known from non-Slavic sources. \\"Ruotsi\\" is, however, the Finnish name for Sweden.[20] Danilevskiy shows that the oldest historical source, the Primary Chronicle, is inconsistent in what it refers to as the \\"Rus'\\": in adjacent passages, the Rus' are grouped with Varangians, with the Slavs, and also set apart from the Slavs and Varangians. Danilevskiy suggests that the Rus' were originally not a nation but a social class, which can explain the irregularities in the Primary Chronicle and the lack of early non-Slavic sources.\\r\\nIn modern English historiography, Kievan Rus' is the most common name for the ancient East Slavic state (usually retaining the apostrophe in Rus', a transliteration of the soft sign, ^)[21] followed by \\"Kievan Rus'\\", \\"Kievan Russia\\", \\"ancient Russian state\\", and, extremely rarely, \\"Kievan Ruthenia\\". It is also called the Princedom or Principality of Kiev, or just Kiev.[citation needed]\\r\\nThe vast political state was subsequently divided into several parts. The most influential were, in the south, Kingdom of GaliciaÿVolhynia and in the north, Vladimir-Suzdal and the Novgorod Republic. The southern part fell under Polish and Lithuanian influence; the northern part, under much weaker Mongol influence,[clarification needed] went on to become a loose federation of principalities.\\r\\nPatriarch Callistus I of Constantinople in 1361 created two metropolitan sees with their own names (in Greek) for the northern and southern parts: respectively, ՚? ?߿?ϫ (Megl Rhssa,[22] Great Russia) in Vladimir and Kiev and ? ?߿?ϫ (Mikr Rhssa, Russia Minor or Little Russia) with the centers in Galich (Halych) and Novgorodok (Navahrudak).\\r\\nIn the 14th-16th centuries most Russian principalities were united under the power of the Grand Duchy of Moscow, once a part of Vladimir-Suzdal, and formed a large state.[23] While the oldest endonyms of the Grand Duchy of Moscow used in its documents were Rus' (Russian: ^) and the Russian land (Russian:  켼),[24] a new form of its name, Rusia or Russia, appeared and became common in the 15th century.[4][5][6] In the 1480s Russian state scribes Ivan Cherny and Mikhail Medovartsev mention Russia under the name ˾, Medovartsev also mentions \\"the sceptre of Russian lordship (˾ҳ̾ ̾Ť־)\\".[25] In the following century Russia co-existed with the old name Rus' and appeared in an inscription on the western portal of the Transfiguration Cathedral of the Spaso-Preobrazhensky Monastery in Yaroslavl (1515), on the icon case of the Theotokos of Vladimir (1514), in the work by Maximus the Greek,[26] the Russian Chronograph written by Dosifei Toporkov (?ÿ1543/44[27]) in 1516ÿ22 and in other sources.[28]\\r\\nBy the 15th century, the rulers of the Grand Duchy of Moscow had reunited the northern parts of the former Kievan Rus'. Ivan III of Russia was the first local ruler to be proclaimed \\"Grand Prince of all Rus'\\" (similarly, see Ivan I of Moscow and the Mongol invasion of Rus'). This title was used by the Grand Dukes of Vladimir since the early 14th century, and the first prince to use it was Mikhail of Tver. Ivan III was styled by Maximilian I, Holy Roman Emperor as rex albus and rex Russiae. Later, Rus  in the Russian language specifically  evolved into the Byzantine-influenced form, Rossiya (Russia is ?߿?ϫ (Rhssa) in Greek).\\r\\nIn 1547, Ivan IV assumed the title of Tsar and Grand Duke of all Rus' (ђ^  춶ҿҳ ^ ־ ) and was crowned on 16 January,[29] thereby turning the Grand Duchy of Moscow into Tsardom of Russia, or \\"the Great Russian Tsardom\\", as it was called in the coronation document,[30] by Constantinople Patriarch Jeremiah II[31][32] and in numerous official texts,[33][34][35][36][37][38] but the state partly remained referred to as Moscovia (English: Muscovy) throughout Europe, predominantly in its Catholic part, though this Latin term was never used in Russia.[39] The two names \\"Russia\\" and \\"Moscovia\\" appear to have co-existed as interchangeable during the later 16th and throughout the 17th century with different Western maps and sources using different names, so that the country was called \\"Russia, or Moscovia\\" (Latin: Russia seu Moscovia) or \\"Russia, popularly known as Moscovia\\" (Latin: Russia vulgo Moscovia). In England of the 16th century, it was known both as Russia and Muscovy.[40][41] Such notable Englishmen as Giles Fletcher, author of the book Of the Russe Common Wealth (1591), and Samuel Collins, author of The Present State of Russia (1668), both of whom visited Russia, were familiar with the term Russia and used it in their works.[42] So did numerous other authors, including John Milton, who wrote A brief history of Moscovia and of other less-known countries lying eastward of Russia, published posthumously,[43] starting it with the words: \\"The Empire of Moscovia, or as others call it, Russia...\\"[44]\\r\\nIn the Russian Tsardom, the word Russia replaced the old name Rus' in official documents, though the names Rus' and Russian land were still common and synonymous to it,[45] and often appeared in the form Great Russia (Russian: 춶ҿ ˾), which is more typical of the 17th century,[46] whereas the state was also known as Great-Russian Tsardom (Russian: 춶ҿѾҳ󿹾 Ѷ־ҿ).[33]\\r\\nAccording to prominent historians like Alexander Zimin and Anna Khoroshkevich, the continuous use of the term Moscovia was a result of traditional habit and the need to distinguish between the Muscovite and the Lithuanian part of the Rus', as well as of the political interests of the Polish-Lithuanian Commonwealth, which competed with Moscow for the western regions of the Rus'. Due to the propaganda of the Commonwealth,[47][48] as well as of the Jesuits, the term Moscovia was used instead of Russia in many parts of Europe where prior to the reign of Peter the Great there was a lack of direct knowledge of the country. In Northern Europe and at the court of the Holy Roman Empire, however, the country was known under its own name, Russia or Rossia.[49] Sigismund von Herberstein, ambassador of the Holy Roman Emperor in Russia, used both Russia and Moscovia in his work on the Russian tsardom and noted: \\"The majority believes that Russia is a changed name of Roxolania. Muscovites (\\"Russians\\" in the German version) refute this, saying that their country was originally called Russia (Rosseia)\\".[50] Pointing to the difference between Latin and Russian names, French captain Jacques Margeret, who served in Russia and left a detailed description of LEmpire de Russie of the early 17th century that was presented to King Henry IV, stated that foreigners make \\"a mistake when they call them Muscovites and not Russians. When they are asked what nation they are, they respond 'Russac', which means 'Russians', and when they are asked what place they are from, the answer is Moscow, Vologda, Ryasan and other cities\\".[51] The closest analogue of the Latin term Moscovia in Russia was Tsardom of Moscow, or Moscow Tsardom (󿹾־󿹾 Ѷ־), which was used along with the name \\"Russia\\",[52][53] sometimes in one sentence, as in the name of the 17th century Russian work On the Great and Glorious Russian Moscow State (Russian:  ־춶ҿ  ־ ˾ҳ󿹾 󿹾־󿹾 ̾Ѷ־).[54]\\r\\nDifferent from other Slavic languages, in the specific case of the Russian language, russkij (ҳ) refers to both the Rus' people and modern day Russians, rossijskij (Ѿҳҳ), with no distinction (deliberately implying[original research?] both to be the same people with the same language  see Russification). In modern Polish the words being ruski (adj. of Rus', Ruthenian, the East Slavs from the historic Kievan Rus') which may equally refer to modern Belarusians, Ukrainians or both, or in a historical context to the people of Kievan Rus'; contrasted to rosyjski (Russian, native to what became of the Grand Duchy of Moscow, developed after the disintegration of the Kievan Rus'). Similarly in other Slavic languages, including modern Ukrainian: ruskyj (^ҳ) refers to Rus (Ruthenian), whereas rosijskyj (Ѿ?^ҳ) refers to Russia.\\r\\nThe southern territories of the Rus' fell under the rule of the Grand Duchy of Lithuania in the 13th century. While Russian descendants of the Rus' called themselves Russkiye, the residents of these lands called themselves Rusyny or Ruskiye. The name Ruthenia arises as a latinized form of the name Rus' in Western European documents at about this time.\\r\\nThe territories under Lithuanian rule retained the name Rus' , specifically\\r\\nThe word \\"Ukraine\\" (ukraina) is first recorded in the 15th century Hypatian Codex of the 12th and 13th century Primary Chronicle, whose 1187 entry on the death of Prince Volodymyr of Pereyaslav (aka Volodymyr/Vladimir Monomakh) says The Ukraina groaned for him, ? 켼  ҷ ̾ ŤҾ (o nem ?e Ukraina mnogo postona).[55]\\r\\nDuring a period of cultural revival after 1840, the members of a secret ideological society in Kiev, the Brotherhood of Saints Cyril and Methodius, revived the use of the name Ukrayina for the homeland of the \\"Little Russian\\" people. They drew upon a name which had been used by 17th century Ukrainian Cossacks. It had earlier appeared on 16th century maps of Kiev and its local area (Kievan Rus'). Ukrayina was originally an Old East Slavic word for a \\"bordered land\\" or \\"a separated land parcel, a separate part of a tribe's territory\\",[56] attested as far back as the 12th century. See krajina for cognates.\\r\\nApplication of the name \\"Ruthenia\\" became narrowed to Carpathian Ruthenia (Karpatska Rus), south of the Carpathian Mountains in the Kingdom of Hungary, where many local Slavs consider themselves Rusyns. Carpathian Ruthenia incorporated the cities of Mukacheve (Rusyn: Mukachevo; Hungarian: Munkcs), Uzhhorod (Hungarian: Ungvr) and Pre?ov (Pryashiv; Hungarian: Eperjes). Carpathian Rus' had been part of the Kingdom of Hungary since 907, and had been known as \\"Magna Rus'\\" but was also called \\"Karpato-Rus\\" or \\"Zakarpattya\\".\\r\\nIn 1654, under the Pereyaslav Agreement, the Cossack lands of the Zaporozhian Host were signed into the protectorate of the Grand Duchy of Moscow, including the Cossack Hetmanate of Left-bank Ukraine, and Zaporozhia. In Russia, these lands were referred to as Little Russia (Malorossiya). Colonies established in lands ceded from the Ottoman Empire along the Black Sea were called Novorossiya \\"New Russia\\".","input":"What is the origin of the name russia?"},{"output":"18 years old on or before September 15","context":"The NHL Entry Draft (French: Repchage d'entre dans la LNH) is an annual meeting in which every franchise of the National Hockey League (NHL) systematically select the rights to available ice hockey players who meet draft eligibility requirements (North American players 18ÿ20 years old and European/international players 18ÿ21 years old; all others enter league as unrestricted free agents). The NHL Entry Draft is held once every year, generally within two to three months after the conclusion of the previous season. During the draft, teams take turns selecting amateur players from junior or collegiate leagues and professional players from European leagues.\\r\\nThe first draft was held in 1963, and has been held every year since. The NHL Entry Draft was known as the NHL Amateur Draft until 1979. The entry draft has only been a public event since 1980, and a televised event since 1984.[1] Up to 1994, the order was solely determined by the standings at the end of the regular season. In 1995, the NHL Draft Lottery was introduced where only teams who had missed the playoffs could participate. The one lottery winner would move up the draft order a maximum of four places, meaning only the top five-placed teams could pick first in the draft, and no team in the non-playoff group could move down more than one place. The chances of winning the lottery were weighted towards the teams at the bottom of the regular season standings. Beginning in 2013, the limit of moving up a maximum of four places in the draft order was eliminated, so the lottery winner would automatically receive the first overall pick, and any teams above it in the draft order would still move down one spot.\\r\\n\\r\\n\\r\\nThe first NHL Entry Draft (at that time known as the \\"NHL Amateur Draft\\") was held on June 5, 1963 at the Queen Elizabeth Hotel in Montreal, Quebec.[1] Any amateur player under the age of 20 was eligible to be drafted. In 1979, the rules were changed allowing players who had previously played professionally to be drafted. This rule change was made to facilitate the absorption of players from the defunct World Hockey Association. Consequently, the name of the draft was changed from \\"NHL Amateur Draft\\" to \\"NHL Entry Draft\\". Beginning in 1980, any player who is between the ages of 18?and 20 is eligible to be drafted. In addition, any non-North American player over the age of?20 can be selected. From 1987 through 1991, 18 and 19-year-old players could only be drafted in the first three rounds unless they met another criterion of experience which required them to have played in major junior, U.S. college and high school, or European hockey.[1][2]\\r\\nIn 1980, the Entry Draft became a public event, and was held at the Montreal Forum. Prior to that year the Entry Draft was conducted in Montreal hotels or league offices and was closed to the general public.[1] The first draft outside of Montreal was held at the Metro Toronto Convention Centre in Toronto, Ontario, in 1985.[3] Live television coverage of the draft began in 1984?when the Canadian Broadcasting Corporation covered the event in both English and French for Canadian audiences. The 1987 Entry Draft, held at Joe Louis Arena in Detroit, Michigan, was the first NHL Draft to be held in the United States. SportsChannel America began covering the event in the United States in 1989.[1]\\r\\nPrior to the development of the Draft, NHL teams sponsored junior teams, and signed prospects in their teens to the junior teams. Players were signed to one of three forms: the \\"A\\" form, which committed a player to a tryout; a \\"B\\" form, which gave the team an option to sign a player in return for a bonus; and the \\"C\\" form, which committed a player's professional rights. The \\"C\\" form could only be signed by the player at age eighteen or by the player's parents, often in exchange for some signing bonus.[4] The first drafts (up until the 1968 Amateur Draft) were held to assign players who had not signed with an NHL organization before the sponsorship of junior teams was discontinued after 1968.\\r\\nThe selection order in the NHL Entry Draft is determined by a combination of lottery, regular season standing, and playoff results. While teams are permitted to trade draft picks both during the draft and prior to it (sometimes several years prior), in all cases, the selection order of the draft picks is based on the original holder of the pick, not a team which may have acquired the pick via a trade or other means.[5][6] The order of picks discussed in this section always references the original team.\\r\\nThe basic order of the NHL Entry Draft is determined based on the standings of the teams in the previous season. As with the other major sports leagues, the basic draft order is intended to favour the teams with the weakest performance who presumably need the most improvement in their roster to compete with the other teams. Subject to the results of the NHL Draft Lottery (discussed below), the teams pick in the same order each round, with each team getting one pick per round. The basic order of the picks is determined as follows:[7]\\r\\nThe number of teams in the second and third group depends on whether the Conference finalists also won their division. The teams in each group (other than the Stanley Cup winner and runner up) are ordered within that group based on their point totals in the preceding regular season (with the lowest point total picking first). Tie-breakers are governed by the same rules used to determine ties in the regular season standings. The order of picks 1ÿ15 may change during the first round of the draft based on the results of the NHL Draft lottery. In the subsequent rounds, the basic order based on point totals is used.[6]\\r\\nWhen teams lose their rights to a first-round draft choice, because that player was not signed to a contract and consequently re-entered the entry draft or became an unrestricted free agent, they are awarded a compensatory draft pick. This selection will be the same numerical choice as the first round draft pick who was not signed, but in the second round. For example, if a team cannot sign the seventh overall first round draft choice, it will receive the seventh pick in the second round of the next draft as compensation.[8]\\r\\nAt the conclusion of the regular season, the 15 teams that did not qualify for the playoffs are entered in a weighted lottery to determine the initial draft picks in the first round. The teams are seeded in the basic draft order based on their regular season point totals. The odds of winning the lottery are weighted on a descending scale that gives the greatest chance of winning to the team with the lowest point total (18.5%), and the worst chance to the team with the highest point total (1.0%).\\r\\nThe prize for winning the draft lottery is to be upgraded to pick first in the first round of the draft, with each team that preceded the winner in the basic draft order bumped one pick lower. For example, if the team with the 5th worst point total wins the lottery, it would pick first, and the teams with the worst through 4th-worst records would pick second through fifth. The remaining teams would be unaffected. The teams would return to the basic order for the second and all subsequent rounds.\\r\\nFrom its inception until 2015, there was one winner for the lottery, who would win the first pick in the draft. Beginning with the 2016 draft, three winners are picked in the lottery. These teams win the first three picks in the lottery, with the remaining teams dropping as many as three places from their spot in the basic order.[9]\\r\\nThe NHL Draft Lottery takes place during the Stanley Cup playoffs and is hosted at Sportsnet's studios in Toronto from 2015 onwards. From 2006 to 2014, the draft lottery took place at TSN's studios in Toronto.\\r\\nAll players who will be 18 years old on or before September 15 and not older than 20 years old before December 31 of the draft year are eligible for selection for that year's NHL Entry Draft. In addition, non-North American players over the age of 20 are eligible.[10]","input":"How old do you have to be to be in the nhl?"},{"output":"Han Chinese","context":"Demographics of the world include population density, ethnicity, education level, health measures, economic status, religious affiliations and other aspects of the population.\\r\\nThe overall total population of the world is approximately 7.47 billion, as of July 2017.\\r\\nIts overall population density is 50 people per km2 (129.28 per sq. mile), excluding Antarctica. Nearly two-thirds of the population lives in Asia and is predominantly urban and suburban, with more than 2.5 billion in the countries of China and India combined. The World's fairly low literacy rate (83.7%) is attributable to impoverished regions. Extremely low literacy rates are concentrated in three regions, the Arab states, South and West Asia, and Sub-Saharan Africa.\\r\\nThe world's largest ethnic group is Han Chinese with Mandarin being the world's most spoken language in terms of native speakers.\\r\\nHuman migration has been shifting toward cities and urban centers, with the urban population jumping from 29% in 1950, to 50.5% in 2005.[1] Working backwards from the United Nations prediction that the world will be 51.3 percent urban by 2010, Dr. Ron Wimberley, Dr. Libby Morris and Dr. Gregory Fulkerson estimated May 23, 2007 to be the first time the urban population outnumbered the rural population in history.[2] China and India are the most populous countries,[3] as the birth rate has consistently dropped in developed countries and until recently remained high in developing countries. Tokyo is the largest urban conglomeration in the world.[1][4]\\r\\nThe total fertility rate of the World is estimated as 2.52 children per woman, which is above the global average for the replacement fertility rate of approximately 2.33 (as of 2003).[5]. However, world population growth is unevenly distributed, with the total fertility rate going from .91 in Macau, to 7.68 in Niger. The United Nations estimated an annual population increase of 1.14% for the year of 2000.[6]\\r\\nPeople under 14 years of age made up over a quarter of the world population (26.3%), and people age 65 and over made up less than one-tenth (7.9%) in 2011.[1]\\r\\nThe world population growth is approximately 1.09%[1]\\r\\nThe world population more than tripled during the 20th century from about 1.65 billion in 1900 to 5.97 billion in 1999.[7][8][9]\\r\\nIt reached the 2 billion mark in 1927, the 3 billion mark in 1960, 4 billion in 1974, and 5 billion in 1987.[10] Currently, population growth is fastest among low wealth, Third World countries.[11]\\r\\nThe UN projects a world population of 9.15 billion in 2050, which is a 32.69% increase from 2010 (6.89 billion).[7]\\r\\n\\r\\n\\r\\nHistorical migration of human populations begins with the movement of Homo erectus out of Africa across Eurasia about a million years ago. Homo sapiens appear to have occupied all of Africa about 150,000 years ago, moved out of Africa 50,000 - 60,000 years ago, and had spread across Australia, Asia and Europe by 30,000 years BC. Migration to the Americas took place 20,000 to 15,000 years ago, and by 2,000 years ago, most of the Pacific Islands were colonized.\\r\\nUntil c.?10,000 years ago, humans lived as hunter-gatherers. They generally lived in small nomadic groups known as band societies. The advent of agriculture prompted the Neolithic Revolution, when access to food surplus led to the formation of permanent human settlements. About 6,000 years ago, the first proto-states developed in Mesopotamia, Egypt's Nile Valley and the Indus Valley. Early human settlements were dependent on proximity to water and, depending on the lifestyle, other natural resources used for subsistence. But humans have a great capacity for altering their habitats by means of technology.\\r\\nSince 1800, the human population has increased from one billion[14] to over seven billion,[15] In 2004, some 2.5 billion out of 6.3 billion people (39.7%) lived in urban areas. In February 2008, the U.N. estimated that half the world's population would live in urban areas by the end of the year.[16] Problems for humans living in cities include various forms of pollution and crime,[17] especially in inner city and suburban slums. Both overall population numbers and the proportion residing in cities are expected to increase significantly in the coming decades.[18]\\r\\nThe World has hundreds of major cities spread across 6 continents. Most are in coastal regions.\\r\\nAs of 2005[update], the World had 62 metropolitan areas with a population of over 3,000,000 people each.[19]\\r\\nAs of 2010, about 3 billion people live in or around urban areas.[1]\\r\\nThe following table shows the populations of the top ten conglomerations.\\r\\nThe world's population is 7 billion[28] and Earth's total area (including land and water) is 510 million square kilometers (197 million square miles).[29] Therefore, the worldwide human population density is 7 billion  510 million = 13.7 per km2 (35.5 per sq. mile). If only the Earth's land area of 150 million km2 (58 million sq. miles) is taken into account, then human population density increases to 46.7 per km2 (117.2 per sq. mile). This calculation includes all continental and island land area, including Antarctica. If Antarctica is also excluded, then population density rises to 50 people per km2 (129.28 per sq. mile).[30] Considering that over half of the Earth's land mass consists of areas inhospitable to human inhabitation, such as deserts and high mountains, and that population tends to cluster around seaports and fresh water sources, this number by itself does not give any meaningful measurement of human population density.\\r\\nSeveral of the most densely populated territories in the world are city-states, microstates or dependencies.[31][32] These territories share a relatively small area and a high urbanization level, with an economically specialized city population drawing also on rural resources outside the area, illustrating the difference between high population density and overpopulation.\\r\\nThe world is made up of thousands of ethnic groups. Han Chinese represent about 18% of the global population.[33]\\r\\nThe table below lists HUGE 8=D classified by philosophy; however, religious philosophy is not always the determining factor in local practice. Please note that this table includes heterodox movements as adherents to their larger philosophical category, although this may be disputed by others within that category. For example, Cao ?i is listed because it claims to be a separate category from Buddhism, while Ha H?o is not, even though they are similar new religious movements.\\r\\nThe population numbers below are computed by a combination of census reports, random surveys (in countries where religion data is not collected in census, for example United States or France), and self-reported attendance numbers, but results can vary widely depending on the way questions are phrased, the definitions of religion used and the bias of the agencies or organizations conducting the survey. Informal or unorganized religions are especially difficult to count. Some organizations may wildly inflate their numbers.\\r\\nSince the late 19th century, the demographics of religion have changed a great deal. Some countries with a historically large Christian population have experienced a significant decline in the numbers of professed active Christians: see demographics of atheism. Symptoms of the decline in active participation in Christian religious life include declining recruitment for the priesthood and monastic life, as well as diminishing attendance at church. On the other hand, since the 19th century, large areas of sub-Saharan Africa have been converted to Christianity, and this area of the world has the highest population growth rate. In the realm of Western civilization, there has been an increase in the number of people who identify themselves as secular humanists. In many countries, such as the People's Republic of China, communist governments have discouraged religion, making it difficult to count the actual number of believers. However, after the collapse of communism in numerous countries of Eastern Europe and the former Soviet Union, religious life has been experiencing resurgence there, both in the form of traditional Eastern Christianity and in the forms of Neopaganism and Far Eastern religions.[citation needed]\\r\\nFollowing is some available data based on the work of the World Christian Encyclopedia:[59]\\r\\nStudies conducted by the Pew Research Center have found that, generally, poorer nations had a larger proportion of citizens who found religion to be very important than richer nations, with the exceptions of the United States[64] and Kuwait.[65]\\r\\nThe average age of marriage varies greatly from country to country, and has varied through time. Women tend to marry at the same age as men and currently varies from 17.6 for women in Niger, to 32.4 for women in Denmark while men range from 22.6 in Mozambique to 35.1 in Sweden.[66]\\r\\nThe average number of hospital beds per 1,000 population is 2.94. Compare to Switzerland (18.3) and Mexico (1.1)[67]\\r\\n96% of the urban population has access to improved drinking water, while only 78% of rural inhabitants have improved drinking water. A total average of 87% of urban and rural have access to improved drinking water.\\r\\n4% of the urban population does not have access to improved drinking water, leaving 22% of rural people without improved drinking water with a total world population of 13% not having access to drinking water.\\r\\n76% of the urban population has access to sanitation facilities, while only 45% of the rural population has access. A total world average of 39% do not have access to sanitation facilities.\\r\\nAs of 2009, there are an estimated 33.3 million people living with HIV/AIDS, which is approximately 0.8% of the world population, and there have been an estimated 1.8 million deaths attributed to HIV/AIDS.\\r\\nAs of 2010, 925 million people are undernourished.[68]\\r\\nLife Expectancy at Birth:\\r\\nInfant Mortality\\r\\nThe following demographic statistics are from the CIA World Factbook, unless otherwise indicated.[69]\\r\\nAccording to the 2006 CIA World Factbook, around 27% of the world's population is below 15 years of age.[70]\\r\\nAccording to a report by the Global Social Change Research Project, worldwide, the percent of the population age 0-14 declined from 34% in 1950 to 27% in 2010. On the other hand, the percent elderly (60+) increased during the same period from 8% to 11%.[71]\\r\\nGlobally, the growth rate of the human population has been declining since peaking in 1962 and 1963 at 2.20% per annum. In 2009, the estimated annual growth rate was 1.1%.[72] The CIA World Factbook gives the world annual birthrate, mortality rate, and growth rate as 1.915%, 0.812%, and 1.092% respectively[73] The last one hundred years have seen a rapid increase in population due to medical advances and massive increase in agricultural productivity[74] made possible by the Green Revolution.[75][76][77]\\r\\nThe actual annual growth in the number of humans fell from its peak of 88.0 million in 1989, to a low of 73.9 million in 2003, after which it rose again to 75.2 million in 2006. Since then, annual growth has declined. In 2009, the human population increased by 74.6 million, which is projected to fall steadily to about 41 million per annum in 2050, at which time the population will have increased to about 9.2 billion.[72] Each region of the globe has seen great reductions in growth rate in recent decades, though growth rates remain above 2% in some countries of the Middle East and Sub-Saharan Africa, and also in South Asia, Southeast Asia, and Latin America.[78]\\r\\nSome countries experienced negative population growth, especially in Eastern Europe mainly due to low fertility rates, high death rates and emigration. In Southern Africa, growth is slowing due to the high number of HIV-related deaths. Some Western Europe countries might also encounter negative population growth.[79] Japan's population began decreasing in 2005.[80]\\r\\nPopulation in the world increased from 1990 to 2008 with 1,423 million and 27% growth. Measured by persons, the increase was highest in India (290 million) and China (192 million). Population growth was highest in Qatar (174%) and United Arab Emirates (140%).[81]\\r\\nData required on total number of births per year, and distribution by country.\\r\\nAs of 2009, the average birth rate (unclear whether this is the weighted average rate per country [with each country getting a weight of 1], or the unweighted average of the entire world population) for the whole world is 19.95 per year per 1000 total population, a 0.48% decline from 2003's world birth rate of 20.43 per 1000 total population.\\r\\nAccording to the CIA - The World Factbook, the country with the highest birth rate currently is Niger at 51.26 births per 1000 people. The country with the lowest birth rate is Japan at 7.64 births per 1000 people. Hong Kong, a Special Administrative Region of China, is at 7.42 births per 1000 people. As compared to the 1950s, birth rate was at 36 births per 1000 in the 1950s,[83] birth rate has declined by 16 births per 1000 people. In July, 2011, the U.S. National Institutes of Health announced that the adolescent birth rate continues to decline.[84] Birth rates vary even within the same geographic areas. In Europe, as of July 2011, Ireland's birth rate is 16.5 per cent, which is 3.5 per cent higher than the next-ranked country, the UK. France has a birth rate of 12.8 per cent while Sweden is at 12.3 per cent.[85] In July, 2011, the UK's Office for National Statistics (ONS) announced a 2.4% increase in live births in the UK in 2010 alone.[86] This is the highest birth rate in the UK in 40 years.[86] By contrast, the birth rate in Germany is only 8.3 per 1,000, which is so low that both the UK and France, which have significantly smaller populations, produced more births in 2010.[87] Birth rates also vary within the same geographic area, based on different demographic groups. For example, in April 2011, the U.S. CDC announced that the birth rate for women over the age of 40 in the U.S. rose between 2007 and 2009, while it fell among every other age group during the same time span.[88] In August 2011, Taiwan's government announced that its birth rate declined in the previous year, despite the fact that it implemented a host of approaches to encourage its citizens to have babies.[89]\\r\\nBirth rates ranging from 10-20 births per 1000 are considered low, while rates from 40-50 births per 1000 are considered high. There are problems associated with both an extremely high birth rate and an extremely low birth rate. High birth rates can cause stress on the government welfare and family programs to support a youthful population. Additional problems faced by a country with a high birth rate include educating a growing number of children, creating jobs for these children when they enter the workforce, and dealing with the environmental effects that a large population can produce. Low birth rates can put stress on the government to provide adequate senior welfare systems and also the stress on families to support the elders themselves. There will be less children or working age population to support the constantly growing aging population.\\r\\nThe ten countries with the highest crude death rate, according to the 2015 CIA World Factbook estimates, are:[91]\\r\\nSee list of countries by death rate for worldwide statistics.\\r\\nAccording to the World Health Organization, the 10 leading causes of death in 2002 were:\\r\\nCauses of death vary greatly between first and third world countries.\\r\\nAccording to Jean Ziegler (the United Nations Special Rapporteur on the Right to Food for 2000 to March 2008), mortality due to malnutrition accounted for 58% of the total mortality in 2006: \\"In the world, approximately 62 millions people, all causes of death combined, die each year. In 2006, more than 36 millions died of hunger or diseases due to deficiencies in micronutrients\\".[92]\\r\\nOf the roughly 150,000 people who die each day across the globe, about two thirds100,000 per daydie of age-related causes.[93] In industrialized nations, the proportion is much higher, reaching 90%.[93]\\r\\nThe Northern Mariana Islands have the highest female ratio with 0.77 males per female. Qatar has the highest male ratio, with 2.87 males/female. For the group aged below 15, Sierra Leone has the highest female ratio with 0.96 males/female, and the Republic of Georgia and the People's Republic of China are tied for the highest male ratio with 1.13 males/female (according to the 2006 CIA World Factbook).\\r\\nThe value for the entire world population is 1.01 males/female,[94] with 1.07 at birth, 1.06 for those under 15, 1.02 for those between 15 and 64, and 0.78 for those over 65.\\r\\nThe \\"First World\\" G7 members all have a sex ratio in the range of 0.95ÿ0.98 for the total population, of 1.05ÿ1.07 at birth, of 1.05ÿ1.06 for the group below 15, of 1.00ÿ1.04 for the group aged 15ÿ64, and of 0.70ÿ0.75 for those over 65.\\r\\nCountries on the Arabian Peninsula tend to have a 'natural' ratio of about 1.05 at birth but a very high ratio of males for those over 65 (Saudi Arabia 1.13, United Arab Emirates 2.73, Qatar 2.84), indicating either an above-average mortality rate for females or a below-average mortality for males, or, more likely in this case, a large population of aging male guest workers. Conversely, countries of Eastern Europe (the Baltic states, Belarus, Ukraine, Russia) tend to have a 'normal' ratio at birth but a very low ratio of males among those over 65 (Russia 0.46, Latvia 0.48, Ukraine 0.52); similarly, Armenia has a far above average male ratio at birth (1.17), and a below-average male ratio above 65 (0.67). This effect may be caused by emigration and higher male mortality as result of higher Soviet era deaths; it may also be related to the enormous (by western standards) rate of alcoholism in the former Soviet states. Another possible contributory factor is an aging population, with a higher than normal proportion of relatively elderly people: we recall that due to higher differential mortality rates the ratio of males to females reduces for each year of age.\\r\\nThere is an inverse correlation between income and fertility, wherein developed countries usually have a much lower fertility rate. Various fertility factors may be involved, such as education and urbanization. Mortality rates are low, birth control is understood and easily accessible, and costs are often deemed very high because of education, clothing, feeding, and social amenities. With wealth, contraception becomes affordable. However, in countries like Iran where contraception was made artificially affordable before the economy accelerated, birth rate also rapidly declined. Further, longer periods of time spent getting higher education often mean women have children later in life. Female labor participation rate also has substantial negative impact on fertility. However, this effect is neutralized among Nordic or liberalist countries.[96][further explanation needed]\\r\\nIn undeveloped countries on the other hand, families desire children for their labour and as caregivers for their parents in old age. Fertility rates are also higher due to the lack of access to contraceptives, generally lower levels of female education, and lower rates of female employment in industry.\\r\\n8.7% (2010 est.) 8.2% (2009 est.) note: 30% combined unemployment and underemployment in many non-industrialized countries; developed countries typically 4%-12% unemployment (2007 est.)\\r\\nThe Demonym for Earth's inhabitants, as either a noun or adjective, is Terran.\\r\\nWorldwide, English is used widely as a lingua franca and can be seen to be the dominant language at this time. The world's largest language by native speakers is Mandarin Chinese which is a first language of around 960 million people, or 12.44% of the population, predominantly in the Greater China. Spanish is spoken by around 330 to 400 million people, predominantly in the Americas and Spain. Arabic is spoken by around 280 million people. Hindi is spoken by about 200 million speakers, mostly in India. Bengali is spoken by around 230 million people, predominantly in India and Bangladesh. Portuguese is spoken by about 230 million speakers in Portugal, Brazil, East Timor, and Southern Africa.\\r\\nThere are numerous other languages, grouped into nine major families:\\r\\nThere are also hundreds of non-verbal sign languages.\\r\\nTotal population: 83.7% over the age of 15 can read and write, 88.3% male and 79.2% female[citation needed] note: over two-thirds of the world's 793 million illiterate adults are found in only eight countries (Bangladesh, China, Egypt, Ethiopia, India, Indonesia, Nigeria, and Pakistan); of all the illiterate adults in the world, two-thirds are women; extremely low literacy rates are concentrated in three regions, the Arab states, South and West Asia, and Sub-Saharan Africa, where around one-third of the men and half of all women are illiterate (2005-09 est.)[citation needed]\\r\\nAs of 2008, the school life expectancy (primary to tertiary education) for a man or woman is 11 years.[citation needed]","input":"What are the largest races in the world?"},{"output":"Despacito","context":"This list of most liked YouTube videos contains the top 40 videos with the most likes of all time, as derived from YouTube charts.[1] The like count is taken directly from the page of the video itself. YouTube implemented a like and dislike button on these pages in March 2010, part of a major redesign of the site. This served as a replacement for their five-star rating system;[2] YouTube's designers found the previous system ineffective because the options to rate a video between two and four stars were rarely selected.[3] Of the 40 videos in this list, 37 also appear in the list of most viewed YouTube videos and 15 appear in the list of most disliked YouTube videos. All videos in this list are music videos.\\r\\nThe music video for LMFAO's song \\"Party Rock Anthem\\" stood as the most liked video on YouTube in 2012, with 1.56 million likes, until the video for Psy's \\"Gangnam Style\\" surpassed it in September that year, yielding more than 1.57 million likes.[4] Following this accomplishment, \\"Gangnam Style\\" entered the Guinness World Records book as the most liked video on YouTube and on the Internet as of 2012.[5] Psy's video remained the most liked on YouTube for nearly four years until August 27, 2016, when Wiz Khalifa's \\"See You Again\\" featuring Charlie Puth surpassed it with 11.21 million likes. Less than a year later, on July 25, 2017, Luis Fonsi's \\"Despacito\\" featuring Daddy Yankee claimed the top spot with 16.01 million likes. Currently, among the videos that meet the criteria for making the list, \\"Faded\\" by Alan Walker holds the highest like to dislike ratio. As of October 2017, only two non-music videos are in the 100 most liked videos list, including videos by PewDiePie and whinderssonnunes.\\r\\nAs of October 2017, Justin Bieber and Taylor Swift each have three videos in the top 40. Katy Perry, Fifth Harmony, Twenty One Pilots and Ed Sheeran each have two videos in the top 40.[1]\\r\\n\\r\\n\\r\\nThe following table lists the top 40 most liked videos on YouTube, with each total rounded to the nearest ten thousand likes, as well as the creator, like percentage and date of publication to YouTube.[A]\\r\\nThe following table lists the top 10 most liked videos on YouTube that are not music videos, lyric videos and the like, with each total rounded to the nearest ten thousand likes, as well as the creator, like percentage and date of publication to YouTube.[F]\\r\\nThe following table lists the last 7 videos to become YouTube's most liked video, from the implementation of the like button in March 2010 to the present.\\r\\n*The approximate number of likes each video had when it became YouTube's most liked video.","input":"The most liked youtube video in the world?"},{"output":"Moralistic","context":"Political culture is a part of a society for which shared attitudes and beliefs establish a unique identity with regard to public and private governance. In the United States, at least three political cultures took root during the colonial period. They were formed in New England by religious refugees from England, in the Mid-Atlantic region by Dutch settlers, in Virginia by English adventurers seeking fortune in the New World, and in Carolina by English investors who envisioned a model constitutional society. In Virginia and Carolina, and later elsewhere in the South, Scots-Irish settlers influenced the cultural hearth that created the American South. Each began with established cultures of the British Isles and the Netherlands, evolving into unique cultures that remain in existence today in the United States.\\r\\n\\r\\n\\r\\nThe political scientist Daniel J. Elazar identified three primary political cultures, generally consistent with those of Tocqueville. Moralistic political culture evolved out of New England and is characterized by an emphasis of community and civic virtue over individualism. Individualistic political culture arose from Dutch influence in the Mid-Atlantic region; it regards multiculturalism as a practicality and government as a utilitarian necessity. Traditionalistic political culture arose in the South, which elevates social order and family structure to a prominent role. It accepts a natural hierarchy in society and where necessary to protect society, authoritarian leadership in the political and religious realms.[1]\\r\\nThe formation of traditionalistic political culture is often thought to have arisen principally out of Virginia, the first and most populous southern colony. Virginia was also the most politically powerful state after the Revolution: pursuant to the first census of the United States in 1790 it held a greater percentage of congressional representatives than any other state has ever enjoyed up to the present day. Nevertheless, others argue that South Carolina had the greater influence as a result of its Grand Model enabling slaveholders from Barbados to establish a durable aristocracy. That unique convergence produced a slave society with a majority black population rigidly controlled by the plantation elite. Maintaining such a society required intense political resolve and the development of a mythology of white racial supremacy. The South Carolina hybrid model ultimately spread across the Deep South and was unwavering in its promotion of southern culture, whereas Virginia and other Upper South states were less comfortable with the regions peculiar institution of slavery.[2]\\r\\nThe political scientist Richard Ellis identified egalitarianism, individualism, and hierarchy as defining cultures in American political culture. These principal categories correspond closely with Elazars classification. According to Ellis, each of these cultures lays claim to the ideals of equality and liberty articulated by John Locke, but what they are claiming is an only a piece of Locke, and one that is not necessarily consistent with the whole.[3]\\r\\nPopular authors have found similar divisions within American political culture. Colin Woodard identified eleven rival regional cultures, while Joel Garreau identified nine.[4][5]\\r\\nThe social psychologist Peter J. Rentfrow led a research effort that generally supports Elazar's theory of political culture, while finding that psychological variables allow for a more fine-grained geographical analysis. His research on psychological topography was based on multiple samples of more than a million respondents. The researchers found overwhelming evidence for regional variation across the United States on a range of key political, economic, social, and health indicators.[6]\\r\\nMany settlers who populated the South took to the backcountry, eventually crossing the Appalachians. Of these, the Scots-Irish originating from northern Ireland and the border region between England and Scotland were among the largest and most influential. They were militantly Christian and inured to violence.[7] While they might be considered a distinct political culture in colonial times, they eventually developed a symbiotic relationship with the southern plantation elite. As W. J. Cash wrote in The Mind of the South, the tradition of aristocracy met and married with the tradition of the backwoods.[8]\\r\\nThe Frontier Thesis advanced by the historian Frederick Jackson Turner in 1893 argued that American culture, including political culture, was forged as Americans moved west. It was violent and individualistic and yet contained a primitive form of egalitarianism. In Elazars view, however, it was the South that acquired these traits most and carried them west to Missouri, Texas, and eventually as far as Southern California.[9]\\r\\nIn another unifying thesis about political culture that, like the Frontier Thesis, some have argued that Lockean liberalism is a central underlying explanation of American political culture. Notably, the political scientist Louis Hartz argued that the nations founding principles, which were largely drawn from Locke, created a new political culture that was unique to the United States. The nation begins with Locke, he wrote, and it stays with Locke. He found that Alexis de Tocqueville was first to recognize this when he saw that the nation was the first to create its own democratic future without having to endure revolution.[10]\\r\\nPolitical culture can be seen as bifurcated by urban and rural geography. The United States was largely a rural nation until 1920. When the census that year revealed that urban Congressional Districts would exceed those of rural areas, rural congressmen refused to approve reapportionment, the only time that has happened.[11] A cultural divide remains to the present with rural areas often associating with traditionalistic political culture, while urban areas are more often aligned with moralistic and individualistic political culture.\\r\\nResearchers Dante Chinni and James Gimpel identified twelve cultural communities found throughout the United States, with varying degrees of geographic concentration. The categories are derived from analysis of statistical data, and they offer a more realistic portrayal of the geographically discontinuous cultural fabric of the nation than blanket state and regional categories.[12] In physical space, as in cyberspace, people increasingly sort themselves into communities of choice. That is, people chose where they will live and who they will communicate with. The opportunity to make such choices appears to reinforce political culture.[13]","input":"What three factors make up american political culture?"},{"output":"President Grover Cleveland","context":"Labor Day in the United States is a public holiday celebrated on the first Monday in September. It honors the American labor movement and the contributions that workers have made to the strength, prosperity, laws and well-being of the country. It is the Monday of the long weekend known as Labor Day Weekend and it is considered the unofficial end of summer in the United States. It is recognized as a federal holiday.\\r\\nBeginning in the late 19th century, as the trade union and labor movements grew, trade unionists proposed that a day be set aside to celebrate labor. \\"Labor Day\\" was promoted by the Central Labor Union and the Knights of Labor, which organized the first parade in New York City. In 1887, Oregon was the first state of the United States to make it an official public holiday. By the time it became an official federal holiday in 1894, thirty U.S. states officially celebrated Labor Day.[1]\\r\\nCanada's Labour Day is also celebrated on the first Monday of September. More than 80 countries celebrate International Workers' Day on May 1 ÿ the ancient European holiday of May Day ÿ and several countries have chosen their own dates for Labour Day.\\r\\n\\r\\n\\r\\nBeginning in the late 19th century, as the trade union and labor movements grew, different groups of trade unionists chose a variety of days on which to celebrate labor. In the United States a September holiday called Labor Day was first proposed in the 1880s. An early history of the holiday dates the event's origins to a General Assembly of the Knights of Labor convened in New York City in September 1882.[2] In conjunction with this clandestine Knights assembly a public parade of various labor organizations was held on September 5 under the auspices of the Central Labor Union (CLU) of New York.[2] Secretary of the CLU Matthew Maguire is credited for first proposing that a national Labor Day holiday subsequently be held on the first Monday of each September in the aftermath of this successful public demonstration.[3]\\r\\nAn alternative thesis is maintained that Peter J. McGuire of the American Federation of Labor put forward the first proposal in May 1882,[1] after witnessing the annual labour festival held in Toronto, Canada.[4]\\r\\nThere was disagreement among labor unions at this time about when a holiday celebrating workers should be. Many advocated for May 1st. However, President Cleveland was concerned that a labor holiday on May 1st would be a commemoration of the Haymarket Affair of May 1886,[5] as it eventually was under the name International Workers' Day.[6][7] In 1887, he publicly supported the September Labor Day holiday.[5][better?source?needed]\\r\\nIn 1887 Oregon became the first state of the United States to make Labor Day an official public holiday. By the time it became an official federal holiday in 1894, thirty U.S. states officially celebrated Labor Day.[1]\\r\\nFollowing the deaths of workers at the hands of United States Army and United States Marshals Service during the Pullman Strike of 1894 in Chicago, the United States Congress unanimously voted to approve legislation to make Labor Day a national holiday and President Grover Cleveland signed it into law six days after the end of the strike.[8] Cleveland supported the creation of the national holiday in an attempt to shore up support among trade unions following the Pullman Strike.[9] The date of May 1 (an ancient European holiday known as May Day) was an alternative date, celebrated then (and now) as International Workers' Day, but President Cleveland was concerned that observance of Labor Day on May 1 would encourage Haymarket-style protests and would strengthen socialist and anarchist movements that, though distinct from one another, had rallied to commemorate the Haymarket Affair on International Workers' Day.[9][10]\\r\\nAll U.S. states, the District of Columbia, and the United States territories have made Labor Day a statutory holiday.\\r\\nThe form for the celebration of Labor Day was outlined in the first proposal for the holiday: A street parade to exhibit to the public \\"the strength and esprit de corps of the trade and labor organizations\\",[3] followed by a festival for the workers and their friends and families. This became the pattern for Labor Day celebrations. Speeches by prominent men and women were introduced later, as more emphasis was placed upon the civil significance of the holiday. Still later, by a resolution of the American Federation of Labor convention of 1909, the Sunday preceding Labor Day was adopted as Labor Sunday and dedicated to the spiritual and educational aspects of the Labor movement.[3]\\r\\nLabor Day is called the \\"unofficial end of summer\\"[11] because it marks the end of the cultural summer season. Many take their two-week vacations during the two weeks ending Labor Day weekend.[citation needed] Many fall activities, such as school and sports begin about this time.\\r\\nIn the United States, many school districts resume classes around the Labor Day holiday weekend (see First day of school). Most begin the week before, making Labor Day weekend the first three-day weekend of the school calendar, while others return the Tuesday following Labor Day, allowing families one final getaway before the school year begins. Many districts across the Midwest are opting to begin school after Labor Day.[12]\\r\\nIn the U.S. state of Virginia, the amusement park industry has successfully lobbied for legislation requiring most school districts in the state to have their first day of school after Labor Day, in order to give families another weekend to visit amusement parks in the state. The relevant statute has been nicknamed the \\"Kings Dominion law\\" after one such park.[13]\\r\\nIn Minnesota the State Fair ends on Labor Day. Under state law public schools normally do not begin under after the holiday. Allowing time for school children to show 4-H projects at the Fair has been given as one reason for this timing. [14]\\r\\nIn U.S. sports, Labor Day weekend marks the beginning of many fall sports. National Collegiate Athletic Association (NCAA) teams usually play their first games that weekend and the National Football League (NFL) traditionally play their kickoff game the Thursday following Labor Day. The Southern 500 NASCAR auto race has been held on Labor Day weekend at Darlington Raceway in Darlington, South Carolina from 1950 to 2003 and since 2015. At Indianapolis Raceway Park, the National Hot Rod Association hold their finals of the NHRA U.S. Nationals drag race that weekend. Labor Day is the middle point between weeks one and two of the U.S. Open Tennis Championships held in Flushing Meadows, New York.\\r\\nIn fashion, Labor Day is (or was) considered the last day when it is acceptable to wear white[15] or seersucker.[16][17]\\r\\nThe \\"unofficial beginning of summer\\" in the U.S. is Memorial Day at the end of May.\\r\\nTo take advantage of large numbers of potential customers with time to shop, Labor Day has become an important weekend for discounts and allowances by many retailers in the United States, especially for back-to-school sales. Some retailers claim it is one of the largest sale dates of the year, second only to the Christmas season's Black Friday.[18]\\r\\n(federal) = federal holidays, (state) = state holidays, (religious) = religious holidays, (week) = weeklong holidays, (month) = monthlong holidays, (36) = Title 36 Observances and Ceremonies\\r\\nBold indicates major holidays commonly celebrated in the United States, which often represent the major celebrations of the month.","input":"What president made labor day a national holiday?"},{"output":"July 1, 1994","context":"The University of Memphis, colloquially known as U of M, is an American public research university located in the Normal Station neighborhood of Memphis, Tennessee. Founded in 1912, the University has an enrollment of more than 21,000 students. The school has twenty-five Chairs of Excellence and five state-approved Centers of Excellence. Until 2017, the school was a flagship institution of The Tennessee Board of Regents system. In 2017, the six Universities that were part of the Tennessee Board of Regents system, including the University of Memphis, became locally governed, each with its own board. \\r\\n\\r\\nThe university maintains The Center for Earthquake Research and Information (CERI), The Cecil C. Humphreys School of Law, the former Lambuth University campus (now a branch campus of The University of Memphis), The Loewenberg College of Nursing, The School of Public Health, The College of Communication and Fine Arts, The FedEx Institute of Technology, The Advanced Distributed Learning Workforce Co-Lab, and The Institute of Egyptian Art and Archaeology.\\r\\n\\r\\nA faculty of approximately 930 professors serves about 17,000 undergraduate and 4,000 graduate students.\\r\\n\\r\\nThe Daily Helmsman, the independent daily newspaper on the campus, in operation since 1925, remains a prominent student organization. In addition, many other student organizations and academic departments, such as the University of Memphis Institute for Egyptian Art and Archaeology, the Cecil C. Humphreys School of Law Moot Court Board, the University of Memphis Advertising Federation and the University of Memphis chapter of the Public Relations Student Society of America, play an active and involved role in the community, both nationally and internationally.\\r\\n\\r\\nThe University of Memphis attracts most of its undergraduate students from Memphis and West Tennessee, though many current undergraduate and graduate students have come from public and private schools across the southeastern United States as well as from all the other states and about 100 other nations.\\r\\n\\r\\nOver its history, the University of Memphis has graduated many famous alumni, including U.S. Congressman Steve Cohen, actor and former U.S. Senator Fred D. Thompson, historian of the American South Joe Gray Taylor, and DeAngelo Williams, former All-American college football running back.\\r\\n\\r\\nAmong its most famous faculty members are Dr. Lorelei H. Corcoran, Professor of Egyptology; Dr. Peter J. Brand, Professor of Egyptology; Bla Bollobs, Jabie Hardin Chair Professor of Mathematics; and Dr. Donald R. Franceschetti, Professor of Physics.\\r\\n\\r\\nThe Division of Professional and Continuing Education[11] at the University of Memphis provides non-credit instruction to people from all walks of life. Originally established in the 1970s, the non-credit programs include face-to-face short courses, customized training for businesses, and online courses.\\r\\n\\r\\nThe University of Memphis is associated with the Tennessee Board of Regents (TBR) system, consisting of 18 Board Members.  However, as of May 2017, it is governed by an institutional Board of Trustees. Within this framework, the President of the University of Memphis is the day-to-day administrator of the university.\\r\\n\\r\\nThe University of Memphis today comprises a number of different colleges and schools:\\r\\n\\r\\nThe University of Memphis is host to several centers of advanced research:\\r\\n\\r\\nThe University of Memphis Foundation, founded in 1964, manages the university endowment and accepts, manages and disburses private support to the university.[13]\\r\\n\\r\\nIn 1909, the Tennessee Legislature enacted the General Education Bill. This bill stated that three colleges be established, one within each grand division of the state and one additional school for African-American students. After much bidding and campaigning, the state had to choose between two sites to build the new college for West Tennessee: Jackson and Memphis. Memphis was chosen, one of the main reasons being the proximity of the rail line to the site proposed to build the new college for West Tennessee. This would allow professors and students to go home and visit their relatives. The other three schools established through the General Education Act evolved into East Tennessee State University (ETSU), Middle Tennessee State University (MTSU), and Tennessee State University (TSU).\\r\\n\\r\\nPrior to the establishment of the West Tennessee Normal School pursuant to the General Education Bill, a number of higher education departments existed in Memphis under the banner of the University of Memphis.  This earlier University of Memphis was formed in 1909 by adding to an already existing medical school departments of pharmacy, dentistry, and law.[14]\\r\\n\\r\\nOn September 10, 1912, West Tennessee Normal School opened in Memphis; its first president was Seymour A. Mynders. By 1913 all departments of the earlier University of Memphis, except the law school, had been taken over by West Tennessee Normal School.[14][15]  After Mynders' death in 1913, John Willard Brister was chosen to take his place. After Brister's resignation in 1918, Andrew A. Kincannon became president. In 1924, Brister returned to his post as president of the school.\\r\\n\\r\\nThe name changed in 1925 to West Tennessee State Teachers College. In 1931, the campus' first newspaper, The Tiger Rag, was established. In 1939, Richard C. Jones became president of WTSTC. In 1941, the name was changed to Memphis State College, when the college expanded its liberal arts curriculum. In 1943, Dr. Jennings B. Sanders succeeded Jones as president. Three years later, the first alumnus to become president, J. Millard (Jack) Smith, was appointed. In 1951 MSC awarded its first B.A. degrees. In 1957 the school received full University status and changed its name accordingly to Memphis State University.\\r\\n\\r\\nIn 1959, five years after Brown v. Board of Education the university admitted its first black students. Racial segregation was the norm throughout the South at the time. The Memphis State Eight, as they were known, were admitted to Memphis State University. Their presence on campus was the focus not only of intense media scrutiny, but severe criticism from much of the local public.  Ostensibly for the black students' safety and to maintain an air of calm on the campus, University administrators placed certain restrictions on where and when the black students could be on campus.  They were to go only to their classes, not to any of the public places on campus, such as the cafeteria; and they were to leave the campus immediately after they had finished their last class.  These limitations were lifted after the novelty of their presence on campus had subsided and the public's focus on their presence there had lessened, and as more and more black students were admitted to the university.  Today, black students make up more than one-third of the campus student body and they participate fully in all campus activities.\\r\\n\\r\\nCecil C. Humphreys became president of MSU, succeeding Smith, in 1960. In 1966, the school began awarding doctoral degrees. Humphreys resigned as MSU president to become the first chancellor of the newly formed State University and Community College System, later renamed the Tennessee Board of Regents. John Richardson was appointed interim president.\\r\\n\\r\\nIn 1973, Dr. Billy Mac Jones became president. Also that year, the Memphis State Tiger men's basketball team reached the finals of the NCAA tournament, only to fall at the hands of a UCLA team led by future NBA superstar and Hall of Famer Bill Walton in The NCAA Basketball Championship Game in St. Louis, Missouri. In 1980, Thomas Carpenter became president of MSU; he was succeeded by V. Lane Rawlins in 1991. On July 1, 1994, Memphis State University changed its name again, to the University of Memphis.\\r\\n\\r\\nV. Lane Rawlins served from 1991 to 2000; Dr. Ralph Faudree filled in as interim president for one year after V. Lane Rawlins' departure. In 2001, The U of M installed its first female president, Shirley Raines, who retired in the summer of 2013. After a yearlong search, Dr. M. David Rudd was confirmed as the 12th president on May 1, 2014.[16]\\r\\n\\r\\nThe University of Memphis campus is located approximately 5 miles (8.0?km) east of downtown in the University District neighborhood of east Memphis. It has an area of 1,160 acres (4.7?km2), although this figure does not include the law school in the former United States federal customshouse in downtown Memphis, which opened in January 2010. The historical core of campus encompasses approximately 30 acres (120,000?m2).\\r\\n\\r\\nCampus planners have significantly increased the amount of green space and the number of walkways over the past several years, while maintaining a focus on the original historic architecture of the campus.\\r\\n\\r\\nSurrounding the university's main campus are several historic neighborhoods to the north and east, as well as the University District neighborhood and the commercial Highland Strip to the west. Many University of Memphis college students also reside in housing south of the main campus.\\r\\n\\r\\nThe University of Memphis campus is set out in a rectilinear format, planned as a geometric design similar to the Jeffersonian style of the University of Virginia.\\r\\n\\r\\nDespite gradual expansion of the campus to the West and South, the campus is fairly compact and retains a park-like, tree-lined setting. The farthest distance on campus takes about twenty-five minutes to walk. According to the most recent master plan. The University of Memphis is projected to expand and redevelop additional areas one block west of the main campus' current western boundary of Patterson St., making Highland Avenue the \\"de facto\\" entrance to the university.\\r\\n\\r\\nThe center of the main campus comprises buildings that made up the original campus. The first college buildings, including Scates Hall, Manning Hall, and The Administration Building, were erected in the early 20th century. This section stretches from Deloach Ave. south to the end of the main campus at Walker Ave., with most buildings surrounding The Alumni Mall and Student Plaza. The majority of the buildings of the arts and humanities departments, as well as those of the Physics and Astronomy departments of the College of Arts and Science, are located in the original areas of campus.\\r\\n\\r\\nFlanking the original area of campus to the east are the areas of major research for The Life Sciences and Engineering departments, including J.R. Smith Hall, The Life Sciences Building and The Herff College of Engineering Complex, as well as The Education Department, residing in E.C. Ball Hall, and the Art Museum of the University of Memphis, located in the Communication and Fine Arts building. The Ned R. McWherter Library, a state-of-the art library facility and one of the premier research libraries of the Mid-South United States, takes up the eastern part of the campus adjacent to Dunavant Plaza and Emeriti Grove.\\r\\n\\r\\nThe northwestern area of the main campus includes The Fogelman College of Business and Economics, The Fogelman Executive Center (a major conference center for regional executives visiting The University of Memphis), and The FedEx Institute of Technology, a major research contributor in the areas of Supply Chain Management, Nanotechnology, Robotics and Intelligent Systems. Originally, in the north end of the campus, Norriswood Ave. was the northern boundary and was an actual street that ran through the campus. The campus expanded into this area in the late 1960s & early 1970s.\\r\\n\\r\\nThe western edge and southwest corner include Johnson Hall (comprising the Geography and Geology Departments), Patterson Hall (housing the English department), Wilder Tower, Greek Row, and the bulk of The University of Memphis residence halls. As The University of Memphis presses ahead with its planned expansion, many more facilities, pedestrian access, and green space will also be created with the renovation and development of the currently residential block east of Patterson St. in the University District neighborhood.\\r\\n\\r\\nOn January 29, 2013, Governor Bill Haslam announced a $44.6 million state budget pledge for the Community Health Building, which will be the new home of The Loewenberg School of Nursing and The College of Communication Sciences and Disorders.  The University of Memphis was required to raise $15 million from private funds to match the state funds.\\r\\n\\r\\nIn 2017, the University announced plans for a new Veterans Care Center on campus. Located in the Psychological Services Center on campus, the Veterans Care Center \\"will address the mental health needs of veterans, regardless of era, gender, discharge status or service connection.\\"[17]\\r\\n\\r\\nDirectly south of the main campus along the corner of Park Avenue and Getwell Road sits the Park Avenue Campus. The Park Avenue Campus is home not only to various intramural athletics programs and facilities, but also to various research facilities, classrooms and the Speech and Audiology Pathology Center. The Defense Contract Audit Agency also operates its main training facility on the Park Avenue Campus.\\r\\n\\r\\nFuture plans include a regulation indoor soccer stadium and track facility, capable of hosting large-scale NCAA Division I track-and-field meets.[18]\\r\\n\\r\\nThe graduate and family housing units are located at Park Avenue, 1 mile (1.6?km) from the main university campus. The complex has 150 housing units.[19] Residents are zoned to Memphis City Schools.[20] The zoned schools are Sherwood Elementary School,[21] Colonial Middle School,[22] and White Station High School.[23]\\r\\n\\r\\nIn 2010, the University of Memphis, School of Law was moved permanently from the main campus to a newly renovated downtown campus. The new University of Memphis, School of Law campus sits adjacent to downtown courts and the financial and administrative center of the city.\\r\\n\\r\\nIn 2011, the University of Memphis began offering undergraduate and graduate programs on the former Lambuth University campus in Jackson, Tennessee, located approximately 80 miles (130?km) east of Memphis. Now known as the University of Memphis Lambuth Campus, the historic campus includes classroom buildings, dormitories, library, planetarium, and athletic facilities. As of the fall of 2016, official enrollment had risen to 934 students.[24]\\r\\n\\r\\nThe Edward J. Meeman Biological Station of the University of Memphis conducts research in ecology, environmental biology, and natural history. It is named for Edward J. Meeman, an editor of the former Memphis Press-Scimitar newspaper who later established a foundation to fund environmental studies.[25]\\r\\n\\r\\nIn 2007, President Shirley Raines signed the American College and University President's Climate Commitment (ACUPCC), which requires that the university become carbon neutral.[26]\\r\\n\\r\\nThe Green Campus Initiative works to develop and implement a strategic plan to achieve the goals of the APUPCC.  Successful events and projects include the May 2009 2nd Annual E-Recycling Day, resulting in 155 tons of electronic items collected, and the Tiger Initiative for Gardening in Urban Settings (TIGUrS), a fruit and vegetable gardening initiative across campus.[27]\\r\\n\\r\\nIn April 2008, the student-run Environmental Action Club ran a Green Power Campaign to promote a student referendum to add a \\"Green Fee\\" to tuition payments to fund clean, renewable energy and other campus sustainability projects. The referendum passed with a 69% student approval rate. The university is now purchasing renewable energy through the TVA's Green Power Switch program and offsetting 10% of current energy use.[28] It is now the 2nd largest green power purchaser in the entire TVA distribution region.[29]\\r\\n\\r\\nIn February 2009, the TERRA (Technologically and Environmentally Responsive Residential Architecture) sustainable design demonstration house was completed. Designed by the Department of Architecture, the LEED Platinum TERRA house serves as a studio for which architecture and design students to design \\"green\\" housing within urban areas, as well as serve as a demonstration house open for tours and serving as an educational tool for the community.[30]\\r\\n\\r\\nMemphis received a grade of \\"C\\" on the 2009 Campus Sustainability Report Card published by the Sustainable Endowments Institute.[31] Only 34 schools earned a higher grade.[32]\\r\\n\\r\\nThe Daily Helmsman is the student newspaper of the University of Memphis.  The editorially independent student newspaper of the university publishes 5,500 copies a day, four days a week, and employs a paid staff of more than 30, which includes an editorial team of six, more than 20 staff writers, photographers, copy editors, and other staff members during the Fall and Spring semesters.\\r\\n\\r\\nThe publication is part of a tradition which began in 1931 as The Tiger Rag, a protest newspaper. Since that time, the newspaper has been continuously published by University of Memphis students. Even during World War II when paper and other resources were scarce, the newspaper published as a newsletter posted on bulletin boards around campus.\\r\\n\\r\\nThe name of the newspaper was changed to The Helmsman in 1972, and became The Daily Helmsman in 1981, when the newspaper began publishing four days a week.\\r\\n\\r\\nThe Helmsman has won many honors over the years for reporting, photography and design, including awards given by the William Randolph Hearst Foundation, Columbia University and the Southeastern Journalism Conference. Helmsman alumni have gone on to jobs at many prestigious news organizations, such as The New York Times, Rolling Stone magazine, and Southern Living magazine, among others. In 2012, The Helmsman and then-Editor-in-Chief Chelsea Boozer were awarded the College Press Freedom Award for their efforts fighting \\"a retaliatory budget cut while enduring a campaign of harassment by campus police.\\"[33] The award is given annually by the Student Press Law Center and the Associated Collegiate Press. Boozer also won a national Investigative Reporters and Editors award for coverage of how student activity fees are spent, including how the Student Government Association writes its senior officers free tuition, parking and stipends out of the money collected from the student body.\\r\\n\\r\\nNumerous religious centers are located on the campus, including the Wesley Foundation (a United Methodist student center), the Baptist Student Center, the University Catholic Center and Catholic Student Center, Ukirk (a PCUSA campus ministry) Barth House Episcopal Student Center, Reformed University Fellowship, the Soma Christian Student Center (a Church of Christ-supported center), and Memphis Hillel. Numerous other religious clubs of various faiths also exist on campus, which meet in various locations.\\r\\n\\r\\nThe University of Memphis has accumulated numerous traditions over its long history as the flagship public research university within the Tennessee Board of Regents system.\\r\\n\\r\\nThe Mighty Sound of the South Band is the university's band. The band performs at Memphis Tigers football games as a marching band and at Tigers basketball games as a pep band. As one of the oldest institutions at the university, the Band partakes in many of the game day traditions. The MSS performs more than any other student ensemble on campus, and for approximately 350,000 fans each fall. The MSS is featured at nearly every campus-wide event, ranging from Freshman Convocation to the Homecoming Parade and Pep Rally. The band has been featured on the nationally syndicated \\"Mike & Mandy\\" Radio Show, and is a star attraction at the Bandmaster's Championship, a high school marching band contest administered by The University of Memphis Band Alumni Chapter. Members of the MSS represent all academic disciplines across campus, and historically has been open to all students via audition.\\r\\n\\r\\nFor over 30 years, the sideline mascot for The University of Memphis has been a live Bengal tiger named TOM.  During this time, the university has hosted three successive tigers, known respectively as TOM I, TOM II, and TOM III.  The university also has a costumed tiger mascot known as Pouncer.\\r\\n\\r\\nTOM III, the current Tiger mascot, attends all Tiger football home games and other University events. TOM III travels in a climate-controlled trailer with a police escort. TOM III is housed and cared for by the Highland Hundred Tiger Guard, an alumni booster organization in a $300,000 facility. TOM II matured, eventually weighing more than 500 pounds (230?kg). The University of Memphis is one of only two universities in America with a live tiger mascot (the other being LSU in Baton Rouge). After being diagnosed with mouth cancer, TOM II was euthanized on October 15, 2008, at the age of 17.  The team of veterinarians who oversaw TOM II decided this was necessary to ensure he did not suffer due to his illness.\\r\\n\\r\\nThe Highland Hundred football booster group found a replacement for the mascot in the tiger cub TOM III.\\r\\n\\r\\nThe university currently has fifty tiger statues located on campus and another fifty located around the Memphis area. The Alumni Association placed the life-sized tigers around the city in honor of the University's Centennial in January 2012.[34]\\r\\n\\r\\nWhen the University of Memphis first fielded a football team in the fall of 1912, no one had selected a nickname for the squad. Early references to the football team tabbed them only as the Blue and Gray Warriors.\\r\\n\\r\\nAfter the final game of the 1914 season, there was a student parade. During this event, several university students shouted, \\"We fight like Tigers!\\" The nickname was born. As time passed, the nickname \\"Tigers\\" was increasingly used, particularly in campus publications, but did not catch on with the newspapers downtown. They continued to use \\"the Blue and Gray\\" when referring to the university.\\r\\n\\r\\nUnder Coach Lester Barnard in 1922, Memphis's football team gave a ring of truth to that old student yell about Tigers. The team adopted a motto ÿ \\"Every Man a Tiger\\" ÿ and went on to score 174 points while allowing its opponents just 29 points. The Tiger nickname continued with students and alumni, eventually being adopted as the official nickname for the University of Memphis in 1939.\\r\\n\\r\\nNotable among a number of songs commonly played and sung at various events such as commencement and convocation, and athletic games is \\"Go! Tigers! Go!\\", the University of Memphis Tigers' fight song.  The fight song was written by Tom Ferguson, former Director of Bands at Memphis State University during the 1960s.\\r\\n\\r\\nThe Governor's School for International Studies, abbreviated GSIS, is an academic summer program for gifted junior and senior high school students in Tennessee. It is a selective program located at the University of Memphis in which students study two Political Science, a foreign language, and an elective of their choice from the International Studies curriculum. The students, upon finishing the four-week term, gain six hours of college credit which may be transferred to any Tennessee Board of Regents School.[35]\\r\\n\\r\\nUofM also operates the Chucalissa Indian Village, an American Indian heritage site and museum.  Officially known as the T. O. Fuller State Park, the location includes a museum and important archeological sites.\\r\\n\\r\\n Media related to University of Memphis at Wikimedia Commons","input":"When did memphis state became university of memphis?"},{"output":"blood disorders","context":"Sickle-cell disease (SCD) is a group of blood disorders typically inherited from a person's parents.[2] The most common type is known as sickle-cell anaemia (SCA).[2] It results in an abnormality in the oxygen-carrying protein haemoglobin (haemoglobin S) found in red blood cells.[2] This leads to a rigid, sickle-like shape under certain circumstances.[2] Problems in sickle cell disease typically begin around 5 to 6 months of age.[1] A number of health problems may develop, such as attacks of pain (\\"sickle-cell crisis\\"), anemia, swelling in the hands and feet, bacterial infections, and stroke.[1] Long term pain may develop as people get older.[2] The average life expectancy in the developed world is 40 to 60 years.[2]\\r\\nSickle-cell disease occurs when a person inherits two abnormal copies of the haemoglobin gene, one from each parent.[3] This gene occurs in chromosome 11.[9] Several subtypes exist, depending on the exact mutation in each haemoglobin gene.[2] An attack can be set off by temperature changes, stress, dehydration, and high altitude.[1] A person with a single abnormal copy does not usually have symptoms and is said to have sickle-cell trait.[3] Such people are also referred to as carriers.[5] Diagnosis is by a blood test and some countries test all babies at birth for the disease.[4] Diagnosis is also possible during pregnancy.[4]\\r\\nThe care of people with sickle-cell disease may include infection prevention with vaccination and antibiotics, high fluid intake, folic acid supplementation, and pain medication.[5][6] Other measures may include blood transfusion, and the medication hydroxycarbamide (hydroxyurea).[6] A small percentage of people can be cured by a transplant of bone marrow cells.[2]\\r\\nAs of 2015 about 4.4 million people have sickle-cell disease while an additional 43 million have sickle-cell trait.[7][10] About 80% of sickle-cell disease cases are believed to occur in sub-Saharan Africa.[11] It also occurs relatively frequently in parts of India, the Arabian peninsula, and among people of African origin living in other parts of the world.[12] In 2015, it resulted in about 114,800 deaths.[8] The condition was first described in the medical literature by the American physician James B. Herrick in 1910.[13][14] In 1949 the genetic transmission was determined by E. A. Beet and J. V. Neel.[14] In 1954 the protective effect against malaria of sickle-cell trait was described.[14]\\r\\nSigns of sickle cell disease usually begin in early childhood. The severity of symptoms can vary from person to person.[15] Sickle-cell disease may lead to various acute and chronic complications, several of which have a high mortality rate.[16]\\r\\nThe terms \\"sickle-cell crisis\\" or \\"sickling crisis\\" may be used to describe several independent acute conditions occurring in patients with SCD. SCD results in anaemia and crises that could be of many types including the vaso-occlusive crisis, aplastic crisis, sequestration crisis, haemolytic crisis, and others. Most episodes of sickle-cell crises last between five and seven days.[17] \\"Although infection, dehydration, and acidosis (all of which favor sickling) can act as triggers, in most instances, no predisposing cause is identified.\\"[18]\\r\\nThe vaso-occlusive crisis is caused by sickle-shaped red blood cells that obstruct capillaries and restrict blood flow to an organ resulting in ischaemia, pain, necrosis, and often organ damage. The frequency, severity, and duration of these crises vary considerably. Painful crises are treated with hydration, analgesics, and blood transfusion; pain management requires opioid administration at regular intervals until the crisis has settled. For milder crises, a subgroup of patients manage on nonsteroidal anti-inflammatory drugs (NSAIDs) such as diclofenac or naproxen. For more severe crises, most patients require inpatient management for intravenous opioids; patient-controlled analgesia devices are commonly used in this setting. Vaso-occlusive crisis involving organs such as the penis[19] or lungs are considered an emergency and treated with red-blood cell transfusions. Incentive spirometry, a technique to encourage deep breathing to minimise the development of atelectasis, is recommended.[20]\\r\\nBecause of its narrow vessels and function in clearing defective red blood cells, the spleen is frequently affected.[21] It is usually infarcted before the end of childhood in individuals suffering from sickle-cell anaemia. This spleen damage increases the risk of infection from encapsulated organisms;[22][23] preventive antibiotics and vaccinations are recommended for those lacking proper spleen function.\\r\\nSplenic sequestration crises are acute, painful enlargements of the spleen, caused by intrasplenic trapping of red cells and resulting in a precipitous fall in haemoglobin levels with the potential for hypovolemic shock. Sequestration crises are considered an emergency. If not treated, patients may die within 1ÿ2 hours due to circulatory failure. Management is supportive, sometimes with blood transfusion. These crises are transient, they continue for 3ÿ4 hours and may last for one day.[24]\\r\\nAcute chest syndrome (ACS) is defined by at least two of the following signs or symptoms: chest pain, fever, pulmonary infiltrate or focal abnormality, respiratory symptoms, or hypoxemia.[25] It is the second-most common complication and it accounts for about 25% of deaths in patients with SCD, majority of cases present with vaso-occlusive crises then they develop ACS.[26][27] Nevertheless, about 80% of patients have vaso-occlusive crises during ACS.\\r\\nAplastic crises are acute worsenings of the patient's baseline anaemia, producing pale appearance, fast heart rate, and fatigue. This crisis is normally triggered by parvovirus B19, which directly affects production of red blood cells by invading the red cell precursors and multiplying in and destroying them.[28] Parvovirus infection almost completely prevents red blood cell production for two to three days. In normal individuals, this is of little consequence, but the shortened red cell life of SCD patients results in an abrupt, life-threatening situation. Reticulocyte counts drop dramatically during the disease (causing reticulocytopenia), and the rapid turnover of red cells leads to the drop in haemoglobin. This crisis takes 4 days to one week to disappear. Most patients can be managed supportively; some need blood transfusion.[29]\\r\\nHaemolytic crises are acute accelerated drops in haemoglobin level. The red blood cells break down at a faster rate. This is particularly common in patients with coexistent G6PD deficiency.[30] Management is supportive, sometimes with blood transfusions.[20]\\r\\nOne of the earliest clinical manifestations is dactylitis, presenting as early as six months of age, and may occur in children with sickle-cell trait.[31] The crisis can last up to a month.[32] Another recognised type of sickle crisis, acute chest syndrome, is characterised by fever, chest pain, difficulty breathing, and pulmonary infiltrate on a chest X-ray. Given that pneumonia and sickling in the lung can both produce these symptoms, the patient is treated for both conditions.[33] It can be triggered by painful crisis, respiratory infection, bone-marrow embolisation, or possibly by atelectasis, opiate administration, or surgery.[citation needed] Hematopoietic ulcers may also occur.[34]\\r\\nNormally, humans have haemoglobin A, which consists of two alpha and two beta chains, haemoglobin A2, which consists of two alpha and two delta chains, and haemoglobin F, consisting of two alpha and two gamma chains in their bodies. Out of these three types, haemoglobin F dominates until about 6 weeks of age. Afterwards, haemoglobin A dominates throughout life.[citation needed] In people diagnosed with sickle cell disease, at least one of the -globin subunits in haemoglobin A is replaced with what's known as haemoglobin S. In sickle cell anaemia, a common form of sickle cell disease, haemoglobin S replaces both -globin subunits in the haemoglobin.[15]\\r\\nSickle-cell conditions have an autosomal recessive pattern of inheritance from parents. The types of haemoglobin a person makes in the red blood cells depend on what haemoglobin genes are inherited from her or his parents. If one parent has sickle-cell anaemia and the other has sickle-cell trait, then the child has a 50% chance of having sickle-cell disease and a 50% chance of having sickle-cell trait. When both parents have sickle-cell trait, a child has a 25% chance of sickle-cell disease, 25% do not carry any sickle-cell alleles, and 50% have the heterozygous condition.[35]\\r\\nSickle-cell gene mutation probably arose spontaneously in different geographic areas, as suggested by restriction endonuclease analysis. These variants are known as Cameroon, Senegal, Benin, Bantu, and Saudi-Asian. Their clinical importance is because some are associated with higher HbF levels, e.g., Senegal and Saudi-Asian variants, and tend to have milder disease.[36]\\r\\nIn people heterozygous for HgbS (carriers of sickling haemoglobin), the polymerisation problems are minor, because the normal allele is able to produce over 50% of the haemoglobin. In people homozygous for HgbS, the presence of long-chain polymers of HbS distort the shape of the red blood cell from a smooth doughnut-like shape to ragged and full of spikes, making it fragile and susceptible to breaking within capillaries. Carriers have symptoms only if they are deprived of oxygen (for example, while climbing a mountain) or while severely dehydrated. The sickle-cell disease occurs when the sixth amino acid, glutamic acid, is replaced by valine to change its structure and function; as such, sickle-cell anaemia is also known as E6V. Valine is hydrophobic, causing the haemoglobin to collapse on itself occasionally. The structure is not changed otherwise. When enough haemoglobin collapses on itself the red blood cells become sickle-shaped.[citation needed]\\r\\nThe gene defect is a known mutation of a single nucleotide (see single-nucleotide polymorphism ÿ SNP) (A to T) of the -globin gene, which results in glutamic acid (E/Glu) being substituted by valine (V/Val) at position 6.[note 1] Haemoglobin S with this mutation is referred to as HbS, as opposed to the normal adult HbA. This is normally a benign mutation, causing no apparent effects on the secondary, tertiary, or quaternary structures of haemoglobin in conditions of normal oxygen concentration. What it does allow for, under conditions of low oxygen concentration, is the polymerization of the HbS itself. The deoxy form of haemoglobin exposes a hydrophobic patch on the protein between the E and F helices. The hydrophobic side chain of the valine residue at position 6 of the beta chain in haemoglobin is able to associate with the hydrophobic patch, causing HbS molecules to aggregate and form fibrous precipitates.\\r\\nThe allele responsible for sickle-cell anaemia can be found on the short arm of chromosome 11, more specifically 11p15.5. A person who receives the defective gene from both father and mother develops the disease; a person who receives one defective and one healthy allele remains healthy, but can pass on the disease and is known as a carrier or heterozygote. Heterozygotes are still able to contract malaria, but their symptoms are generally less severe.[37]\\r\\nDue to the adaptive advantage of the heterozygote, the disease is still prevalent, especially among people with recent ancestry in malaria-stricken areas, such as Africa, the Mediterranean, India, and the Middle East.[38] Malaria was historically endemic to southern Europe, but it was declared eradicated in the mid-20th century, with the exception of rare sporadic cases.[39]\\r\\nThe malaria parasite has a complex lifecycle and spends part of it in red blood cells. In a carrier, the presence of the malaria parasite causes the red blood cells with defective haemoglobin to rupture prematurely, making the Plasmodium parasite unable to reproduce. Further, the polymerization of Hb affects the ability of the parasite to digest Hb in the first place. Therefore, in areas where malaria is a problem, people's chances of survival actually increase if they carry sickle-cell trait (selection for the heterozygote).\\r\\nIn the United States, with no endemic malaria, the prevalence of sickle-cell anaemia among African Americans is lower (about 0.25%) than in West Africa (about 4.0%) and is falling. Without endemic malaria, the sickle-cell mutation is purely disadvantageous and tends to decline in the affected population by natural selection, and now artificially through prenatal genetic screening. However, the African American community descends from a significant admixture of several African and non-African ethnic groups and also represents the descendants of survivors of slavery and the slave trade. Thus, a lower degree of endogamy and, particularly, abnormally high health-selective pressure through slavery may be the most plausible explanations for the lower prevalence of sickle-cell anaemia (and, possibly, other genetic diseases) among African Americans compared to West Africans. Another factor that limits the spread of sickle-cell genes in North America is the absence of cultural proclivities to polygamy, which allows affected males to continue to seek unaffected children with multiple partners.[40]\\r\\nThe loss of red blood cell elasticity is central to the pathophysiology of sickle-cell disease. Normal red blood cells are quite elastic, which allows the cells to deform to pass through capillaries. In sickle-cell disease, low oxygen tension promotes red blood cell sickling and repeated episodes of sickling damage the cell membrane and decrease the cell's elasticity. These cells fail to return to normal shape when normal oxygen tension is restored. As a consequence, these rigid blood cells are unable to deform as they pass through narrow capillaries, leading to vessel occlusion and ischaemia.\\r\\nThe actual anaemia of the illness is caused by haemolysis, the destruction of the red cells, because of their shape. Although the bone marrow attempts to compensate by creating new red cells, it does not match the rate of destruction.[41] Healthy red blood cells typically function for 90ÿ120 days, but sickled cells only last 10ÿ20 days.[42]\\r\\nIn HbS, the complete blood count reveals haemoglobin levels in the range of 6ÿ8?g/dl with a high reticulocyte count (as the bone marrow compensates for the destruction of sickled cells by producing more red blood cells). In other forms of sickle-cell disease, Hb levels tend to be higher. A blood film may show features of hyposplenism (target cells and Howell-Jolly bodies).\\r\\nSickling of the red blood cells, on a blood film, can be induced by the addition of sodium metabisulfite. The presence of sickle haemoglobin can also be demonstrated with the \\"sickle solubility test\\". A mixture of haemoglobin S (Hb S) in a reducing solution (such as sodium dithionite) gives a turbid appearance, whereas normal Hb gives a clear solution.\\r\\nAbnormal haemoglobin forms can be detected on haemoglobin electrophoresis, a form of gel electrophoresis on which the various types of haemoglobin move at varying speeds. Sickle-cell haemoglobin (HgbS) and haemoglobin C with sickling (HgbSC)the two most common formscan be identified from there. The diagnosis can be confirmed with high-performance liquid chromatography. Genetic testing is rarely performed, as other investigations are highly specific for HbS and HbC.[43]\\r\\nAn acute sickle-cell crisis is often precipitated by infection. Therefore, a urinalysis to detect an occult urinary tract infection, and chest X-ray to look for occult pneumonia should be routinely performed.[44]\\r\\nPeople who are known carriers of the disease often undergo genetic counseling before they have a child. A test to see if an unborn child has the disease takes either a blood sample from the fetus or a sample of amniotic fluid. Since taking a blood sample from a fetus has greater risks, the latter test is usually used. Neonatal screening provides not only a method of early detection for individuals with sickle-cell disease, but also allows for identification of the groups of people that carry the sickle cell trait.[45]\\r\\nTreatment involves a number of measures. L-glutamine use was supported by the FDA starting at the age of 5 as it decreases complications.[46]\\r\\nFrom birth to five years of age, penicillin daily, due to the immature immune system that makes them more prone to early childhood illnesses is recommended.[47] Dietary supplementation of folic acid had been previously recommended by the WHO.[5] A 2016 Cochrane review of its use found \\"the effect of supplementation on anaemia and any symptoms of anaemia remains unclear\\" due to a lack of medical evidence.[48]\\r\\nThe protective effect of sickle-cell trait does not apply to people with sickle cell disease; in fact, they are more vulnerable to malaria, since the most common cause of painful crises in malarial countries is infection with malaria. It has therefore been recommended that people with sickle-cell disease living in malarial countries should receive anti-malarial chemoprophylaxis for life.[49]\\r\\nMost people with sickle-cell disease have intensely painful episodes called vaso-occlusive crises. However, the frequency, severity, and duration of these crises vary tremendously. Painful crises are treated symptomatically with pain medications; pain management requires opioid administration at regular intervals until the crisis has settled. For milder crises, a subgroup of patients manage on NSAIDs (such as diclofenac or naproxen). For more severe crises, most patients require inpatient management for intravenous opioids; patient-controlled analgesia (PCA) devices are commonly used in this setting. Diphenhydramine is also an effective agent that doctors frequently prescribe to help control itching associated with the use of opioids.[citation needed]\\r\\nManagement is similar to vaso-occlusive crisis, with the addition of antibiotics (usually a quinolone or macrolide, since cell wall-deficient [\\"atypical\\"] bacteria are thought to contribute to the syndrome),[50] oxygen supplementation for hypoxia, and close observation. Should the pulmonary infiltrate worsen or the oxygen requirements increase, simple blood transfusion or exchange transfusion is indicated. The latter involves the exchange of a significant portion of the person's red cell mass for normal red cells, which decreases the percent of haemoglobin S in the patient's blood. The patient with suspected acute chest syndrome should be admitted to the hospital with worsening A-a gradient an indication for ICU admission.[25]\\r\\nThe first approved drug for the causative treatment of sickle-cell anaemia, hydroxyurea, was shown to decrease the number and severity of attacks in a study in 1995[51] and shown to possibly increase survival time in a study in 2003.[52] This is achieved, in part, by reactivating fetal haemoglobin production in place of the haemoglobin S that causes sickle-cell anaemia. Hydroxyurea had previously been used as a chemotherapy agent, and there is some concern that long-term use may be harmful, but this risk has been shown to be either absent or very small and it is likely that the benefits outweigh the risks.[16][53]\\r\\nBlood transfusions are often used in the management of sickle-cell disease in acute cases and to prevent complications by decreasing the number of red blood cells (RBC) that can sickle by adding normal red blood cells.[54] In children preventative red blood cell (RBC) transfusion therapy has been shown to reduce the risk of first stroke or silent stroke when transcranial Doppler (TCD) ultrasonography shows abnormal cerebral blood flow.[6] In those who have sustained a prior stroke event it also reduces the risk of recurrent stroke and additional silent strokes.[55][56]\\r\\nBone marrow transplants have proven effective in children. Bone marrow transplants are the only known cure for SCD.[57] However, bone marrow transplants are difficult to obtain because of the specific HLA typing necessary. Ideally, a close relative (allogeneic) would donate the bone marrow necessary for transplantation.\\r\\nWhen treating avascular necrosis of the bone in people with sickle cell disease, the aim of treatment is to reduce or stop the pain and maintain joint mobility.[58] Current treatment options are to rest the joint, physical therapy, pain relief medicine, joint replacement surgery, or bone grafting.[58] High quality randomized controlled trials are needed to assess the most effective treatment option and determine if a combination of physical therapy and surgery are more effective than physical therapy alone.[58]\\r\\nPsychological therapies such as patient education, cognitive therapy, behavioural therapy and psychodynamic psychotherapy, that aim to complement current medical treatments, require further research to determine their effectiveness.[21]\\r\\nAbout 90% of people survive to age 20, and close to 50% survive beyond the fifth decade.[59] In 2001, according to one study performed in Jamaica, the estimated mean survival for people with sickle-cell was 53 years old for men and 58 years old for women with homozygous SCD.[60] The specific life expectancy in much of the developing world is unknown.[61]\\r\\nSickle-cell anaemia can lead to various complications, including:\\r\\nThe highest frequency of sickle cell disease is found in tropical regions, particularly sub-Saharan Africa, tribal regions of India and the Middle-East.[73] Migration of substantial populations from these high prevalence areas to low prevalence countries in Europe has dramatically increased in recent decades and in some European countries sickle-cell disease has now overtaken more familiar genetic conditions such as haemophilia and cystic fibrosis.[74] In 2015, it resulted in about 114,800 deaths.[8]\\r\\nSickle-cell disease occurs more commonly among people whose ancestors lived in tropical and sub-tropical sub-Saharan regions where malaria is or was common. Where malaria is common, carrying a single sickle-cell allele (trait) confers a selective advantagein other words, being a heterozygote is advantageous. Specifically, humans with one of the two alleles of sickle-cell disease show less severe symptoms when infected with malaria.[75]\\r\\nThis condition is inherited in an autosomal recessive pattern, which means both copies of the gene in each cell have mutations. The parents each carry one copy of the mutated gene, but they typically do not show signs and symptoms of the condition.[76]\\r\\nThree-quarters of sickle-cell cases occur in Africa. A recent WHO report estimated that around 2% of newborns in Nigeria were affected by sickle cell anaemia, giving a total of 150,000 affected children born every year in Nigeria alone. The carrier frequency ranges between 10% and 40% across equatorial Africa, decreasing to 1ÿ2% on the north African coast and <1% in South Africa.[77] There have been studies in Africa that show a significant decrease in infant mortality rate, ages 2ÿ16 months, because of the sickle-cell trait. This happened in predominant areas of malarial cases.[78]\\r\\nThe number of people with the disease in the United States is approximately 1 in 5,000, mostly affecting Americans of sub-Saharan African descent, according to the National Institutes of Health.[79] In the United States, about one out of 500 African-American children and one in every 36,000 Hispanic-American children have sickle-cell anaemia.[80] It is estimated that sickle-cell disease affects 90,000 Americans.[81] Most infants with SCD born in the United States are now identified by routine neonatal screening. As of 2016 all 50 states include screening for sickle cell disease as part of their newborn screen.[82] Patient advocates for sickle-cell disease have complained that it gets less government and private research funding than similar rare diseases like cystic fibrosis, with researcher Elliott Vichinsky saying this shows racial discrimination or the role of wealth in health care advocacy.[83]\\r\\nAs a result of population growth in African-Caribbean regions of overseas France and immigration from North and sub-Saharan Africa to mainland France, sickle-cell disease has become a major health problem in France.[84] SCD has become the most common genetic disease in the country, with an overall birth prevalence of 1/2,415 in Metropolitan France, ahead of phenylketonuria (1/10,862), congenital hypothyroidism (1/3,132), congenital adrenal hyperplasia (1/19,008) and cystic fibrosis (1/5,014) for the same reference period.\\r\\nSince 2000, neonatal screening of SCD has been performed at national level for all newborns defined as being \\"at risk\\" for SCD based on ethnic origin (defined as those born to parents originating from sub-Saharan Africa, North Africa, the Mediterranean area (South Italy, Greece and Turkey), the Arabic peninsula, the French overseas islands and the Indian subcontinent).[85]\\r\\nIn the United Kingdom (UK) it is thought that between 12,000 and 15,000 people have sickle cell disease [86] with an estimate of 250,000 carriers of the condition in England alone. As the number of carriers is only estimated, all newborn babies in the UK receive a routine blood test to screen for the condition.[87] Due to many adults in high-risk groups not knowing if they are carriers, pregnant women and both partners in a couple are offered screening so they can get counselling if they have the sickle cell trait.[88] In addition blood donors from those in high-risk groups are also screened to confirm whether they are carriers and whether their blood filters properly.[89] Donors who are found to be carriers are then informed and their blood, while often used for those of the same ethnic group, is not used for those with sickle cell disease who require a blood transfusion.[90]\\r\\nIn Saudi Arabia about 4.2% of the population carry the sickle-cell trait and 0.26% have sickle-cell disease. The highest prevalence is in the Eastern province where approximately 17% of the population carry the gene and 1.2% have sickle-cell disease.[91] In 2005 in Saudi Arabia a mandatory pre-marital test including HB electrophoresis was launched and aimed to decrease the incidence of SCD and thalassemia.[92]\\r\\nIn Bahrain a study published in 1998 that covered about 56,000 people in hospitals in Bahrain found that 2% of newborns have sickle cell disease, 18% of the surveyed people have the sickle cell trait, and 24% were carriers of the gene mutation causing the disease.[93] The country began screening of all pregnant women in 1992 and newborns started being tested if the mother was a carrier. In 2004, a law was passed requiring couples planning to get married to undergo free premarital counseling. These programs were accompanied by public education campaigns.[94]\\r\\nSickle-cell disease is common in ethnic groups of central India who share a genetic linkage with African communities,[95] where the prevalence has ranged from 9.4 to 22.2% in endemic areas of Madhya Pradesh, Rajasthan and Chhattisgarh.[96] It is also endemic among Tharu people of Nepal and India; however, they have a sevenfold lower incidence of malaria despite living in a malaria infested zone.[97]\\r\\nIn Jamaica, 10% of the population carries the sickle-cell gene, making it the most prevalent genetic disorder in the country.[98]\\r\\nThe first modern report of sickle-cell disease may have been in 1846, where the autopsy of an executed runaway slave was discussed; the key findings was the absence of the spleen.[99][100] There were also reports amongst African slaves in the United States exhibiting resistance to malaria but being prone to leg ulcers.[100] The abnormal characteristics of the red blood cells, which later lent their name to the condition, was first described by Ernest E. Irons (1877ÿ1959), intern to the Chicago cardiologist and professor of medicine James B. Herrick (1861ÿ1954), in 1910. Irons saw \\"peculiar elongated and sickle-shaped\\" cells in the blood of a man named Walter Clement Noel, a 20-year-old first-year dental student from Grenada. Noel had been admitted to the Chicago Presbyterian Hospital in December 1904 suffering from anaemia.[13][101] Noel was readmitted several times over the next three years for \\"muscular rheumatism\\" and \\"bilious attacks\\" but completed his studies and returned to the capital of Grenada (St. George's) to practice dentistry. He died of pneumonia in 1916 and is buried in the Catholic cemetery at Sauteurs in the north of Grenada.[13][14] Shortly after the report by Herrick, another case appeared in the Virginia Medical Semi-Monthly with the same title, \\"Peculiar Elongated and Sickle-Shaped Red Blood Corpuscles in a Case of Severe Anemia.\\"[102] This article is based on a patient admitted to the University of Virginia Hospital on November 15, 1910.[103] In the later description by Verne Mason in 1922, the name \\"sickle cell anemia\\" is first used.[14][104] Childhood problems related to sickle cells disease were not reported until the 1930s, despite the fact that this cannot have been uncommon in African-American populations.[100]\\r\\nThe Memphis physician Lemuel Diggs, a prolific researcher into sickle cell disease, first introduced the distinction between sickle cell disease and trait in 1933, although it took until 1949 until the genetic characteristics were elucidated by James V. Neel and E.A. Beet.[14] 1949 was the year when Linus Pauling described the unusual chemical behaviour of haemoglobin S, and attributed this to an abnormality in the molecule itself.[14][105] The actual molecular change in HbS was described in the late 1950s BY Vernon Ingram.[14] The late 1940s and early 1950s saw further understanding in the link between malaria and sickle cell disease. In 1954, the introduction of haemoglobin electrophoresis allowed the discovery of particular subtypes, such as HbSC disease.[14]\\r\\nLarge scale natural history studies and further intervention studies were introduced in the 1970s and 1980s, leading to widespread use of prophylaxis against pneumococcal infections amongst other interventions. Bill Cosby's Emmy-winning 1972 TV movie, To All My Friends on Shore, depicted the story of the parents of a child suffering from sickle-cell disease.[106] The 1990s saw the development of hydroxycarbamide, and reports of cure through bone marrow transplantation appeared in 2007.[14]\\r\\nSome old texts refer to it as drepanocytosis.[107]\\r\\nEffective September 15, 2017, the U.S. Social Security Administration issued a Policy Interpretation Ruling providing background information on sickle cell disease and a description of how Social Security evaluates the disease during its adjudication process for disability claims.[108][109]\\r\\nWhile umbilical cord blood transplant can potentially cure the condition, a suitable donor is avaliable in only 10% of people.[110] About 7% of people also die as a result of the procedure and graft versus host disease may occur.[110]\\r\\nIn 2001 it was reported that sickle-cell disease had been successfully treated in mice using gene therapy.[111][112] The researchers used a viral vector to make the micewhich have essentially the same defect that causes human sickle cell diseaseexpress production of fetal haemoglobin (HbF), which an individual normally ceases to produce shortly after birth. In humans, using hydroxyurea to stimulate the production of HbF has been known to temporarily alleviate sickle cell disease symptoms. The researchers demonstrated that this gene therapy method is a more permanent way to increase therapeutic HbF production.[113]\\r\\nPhase 1 clinical trials of gene therapy for sickle cell disease in humans were started in 2014. The clinical trials will assess the safety and initial evidence for efficacy of an autologous transplant of lentiviral vector-modified bone marrow for adults with severe sickle cell disease.[114][115] As of 2016, however, no randomized controlled trials have been reported.[116] A case report for the first person treated was published in March 2017.[117]","input":"What type of inheritance is associated with sickle cell anemia?"},{"output":"a species of wild goat","context":"\\r\\n\\r\\nThe Alpine ibex (Capra ibex), also known as the steinbock, bouquetin, or simply ibex, is a species of wild goat[2] that lives in the mountains of the European Alps. It is a sexually dimorphic species with larger males who carry larger, curved horns. The coat colour is typically brownish grey. Alpine ibex tend to live in steep, rough terrain near the snow line. They are also social, although adult males and females segregate for most of the year, coming together only to mate. Four distinct groups exist; adult male groups, female-offspring groups, groups of young individuals, and mixed sex groups.\\r\\n\\r\\nDuring the breeding season, males fight for access to females and use their long horns in agonistic behaviours. After being extirpated from most areas by the 19th century, the Alpine ibex was successfully reintroduced to parts of its historical range. All individuals living today descend from the stock in Gran Paradiso National Park in Aosta Valley and from the neighbouring valley of Maurienne,[3] now part of the Vanoise National Park linked to the former. These two national parks are connected and have been specially created to help the ibex to thrive. The ibex is the emblem of both the Gran Paradiso National Park and the Vanoise National Park. The species is currently listed as of least concern by the IUCN, but went through a population bottleneck and therefore has low genetic diversity.[4]\\r\\n\\r\\nThe Alpine ibex was first described by Carl Linnaeus in 1758. It is classified in the genus Capra (Latin for \\"goat\\") with at least seven other species of wild goat. Both Capra and Ovis (sheep) descended from a goral-like animal from the Miocene and early Pliocene, whose fossils are found in Kenya, China and Slovenia. The genus Tossunnoria appears in China during the late Miocene and appears to have been intermediate between gorals and goats. Fossils of Alpine ibex date back to the late Pleistocene, when it and the Spanish ibex probably evolved from the extinct Pleistocene species Capra camburgensis.[5] The Nubian (C. nubiana), Walia (C. walie) and Siberian ibex (C. sibirica) are sometimes considered to be subspecies of the Alpine ibex, giving populations in the Alps the trinomial of C. i. ibex.[6]\\r\\n\\r\\nCompared with other members of its genus, the Alpine ibex has a short, broad head and a duller coat. It has brownish grey hair over most of the body, a pale abdomen and slightly darker markings on the chin and throat and in a stripe along the back. They moult twice a year, firstly in April or May, and then again in September, when they replace the short summer coat with thicker hair and a woolly undercoat.[5]\\r\\n\\r\\nMales commonly grow to a height of 90 to 101 centimetres (35 to 40?in) at the withers, with a body length of 149 to 171 centimetres (59 to 67?in) and weigh from 67 to 117 kilograms (148 to 258?lb). Females are noticeably smaller, with a shoulder height of 73 to 84 centimetres (29 to 33?in), a body length of 121 to 141 centimetres (48 to 56?in), and a weight of 17 to 32 kilograms (37 to 71?lb). Both male and female Alpine ibexes have large, backwards-curving, horns with numerous ridges along their length. At 69 to 98 centimetres (27 to 39?in), those of the males are substantially larger than those of females, which reach only 18 to 35 centimetres (7.1 to 13.8?in) in length.[5]\\r\\n\\r\\nThe Alpine ibex was, at one point, restricted only to the Gran Paradiso National Park in northern Italy, and in the Maurienne Valley in the French Alps [7] but in recent years it was both reintroduced to and recolonised most of the European Alps. It is now found in most or all the Italian and French alpine ranges, southern Germany, Switzerland[8] and Austria. It was also introduced to Bulgaria and Slovenia.[1]\\r\\n\\r\\nAn excellent climber, its preferred habitat is the rocky region along the snow line above alpine forests, where it occupies steep, rough terrain at elevations of 1,800 to 3,300 metres (5,900 to 10,800?ft).[9] Alpine ibex are typically absent from woodland areas[5] although adult males in densely populated areas may stay in larch and mixed larch-spruce woodland if there is no snow.[10] Males spend the winter in coniferous forests.[5] For most of the year, males and females occupy different habitat.[11] Females rely on steep terrain more so than males.[12] Males use lowland meadows during the spring, which is when snow melts and green grass appears.[12] They then climb to alpine meadows during the summer.[10] When winter arrives, both sexes move to steep rocky slopes that amass little snow.[13] They prefer slopes of 30ÿ45 and use small caves and overhangs for shelter.[14] Home ranges are highly variable, depending on the availability of resources, and vary in size throughout the year. Figures of anything from 180 to 2,800 hectares (0.69 to 10.81?sq?mi; 1.8 to 28.0?km2) have been recorded.[5][13] Home ranges tend to be largest during summer and autumn, smallest in winter and intermediate in spring.[5] Female home ranges are usually smaller than those of males. Alpine ibexes appear to have a low rate of predation and in Gran Paradiso typically die of age, starvation or disease .[5]\\r\\n\\r\\nAlpine ibexes are strictly herbivorous, with over half of their diet consisting of grasses, and the remainder being a mixture of moss, flowers, leaves, and twigs.[5] If leaves and shoots are out of reach, they often stand on their rear legs to reach this food. Grass genera that are the most commonly eaten are Agrostis, Avena, Calamagrostis, Festuca, Phleum, Poa, Sesleria and Trisetum.[5] The climbing ability of the Alpine ibex is such that it has been observed standing on the sheer face of a dam, where it licks the stonework to obtain mineral salts.[15]\\r\\n\\r\\nAlthough the Alpine ibex is a social species, they segregate sexually and spatially depending on the season.[12] Four types of groups exist. Adult male groups, female-offspring groups, groups of young individuals 2ÿ3 years old, and mixed sex groups.[5][16] Young groups are numerous at the beginning of summer but are expelled by females at the end of their gestation period. Female and offspring groups occur year-round, at least in an area of the French Alps.[16] Mixed sex groups of adult males and females occur during breeding, which lasts from December to January. By April and May, the adults separate.[16] The largest aggregations of either sex occur during June and July. Gatherings of males begin to decrease during October and November, and are lowest from the rut from December to March.[16] The males then leave their separate wintering areas and gather again.[17]\\r\\n\\r\\nThere is a linear dominance hierarchy among males. In small populations, which are more cohesive, male ibex know their place in the hierarchy based on memories of past encounters[5] while in mobile and large groups, where encounters with strangers are common, rank is based on horn size.[18] Antagonistic behavior in males can come in the form of \\"direct\\" or \\"indirect\\" aggression. With direct aggression, one male bumps another with its horns or places itself in front of its opponent. It stands on its hind legs and comes down on his opponent with its horns. This may signal that it is ready to clash or it may be attempting a real clash.[5]  Indirect aggression is mostly intimidation displays.[5]\\r\\n\\r\\nThe breeding season starts in December, and typically lasts around six weeks. During this time, male herds break up into smaller groups that search for females. The rut takes place in two phases. In the first phase, the male groups interact with the females who are all in oestrous. The higher the male's rank, the closer he can get to a female.[5] Males perform courtship displays. In the second phase of the rut, one male separates from his group to follow an individual female.  He displays to her and guards her from other males.  Before copulation, the female moves her tail and courtship becomes more intensive. They copulate and then he rejoins his group and reverts to the first phase.[5] Gestation lasts around 167 days, and results in the birth of one or two kids, with twins making up about 20% of births.[19]\\r\\n\\r\\nAlpine ibex reach sexual maturity at eighteen months, but females do not reach their maximum body size for five to six years, and males not for nine to eleven years. The horns grow throughout life, growing most rapidly during the second year of life, and thereafter by about 8 centimetres (3.1?in) a year, eventually slowing to half that rate once the animal reaches ten years of age. Alpine ibex live for up to nineteen years in the wild.[20]\\r\\n\\r\\nThe Alpine ibex historically ranged through France, Italy, Switzerland, Liechtenstein, Bavaria, Austria and Slovenia. Starting in the early 16th century and with firearms becoming common, the overall population declined due to overexploitation and poaching. The ibex became extinct in Switzerland and Germany by the 18th century, and was extinct in Austria and northeastern Italy by the 19th century. They remained only in and around the adjacent Gran Paradiso and Vanoise Massifs, then both part of the Kingdom of Sardinia. Located in the western Italian Alps and the Maurienne valley in the north eastern French alps, bordering the Vanoise and Gran Paradiso Massif, the park was declared a royal hunting reserve in 1854 with the name of \\"Royal hunting reserve of Gran Paradiso\\" by Victor Emmanuel II, the first king of a united Italy .[21]\\r\\n\\r\\nIbex were protected from poaching and their numbers increased, reaching 3,020 in 1914. The ibex enjoyed further protection when Gran Paradiso was made into a national park in 1922. Animals from this stock both drifted naturally and were introduced to other areas. By 1976, the number of populations of ibex numbered 104. Today, the total population of Alpine ibex is over 20,000[21] and is considered to be of Least Concern by the IUCN.[1] However, introduced populations of ibex appear to have low genetic diversity.[4]\\r\\n\\r\\nThe Alpine ibex is a mountain icon. It is represented in many official emblems throughout the Alpine range, from France to Austria like the coat of arms of the Canton of Grisons in Switzerland or logos like Pro Natura.\\r\\n\\r\\nThe animal is at the center of the Goldhorn legend. This, in turn, underlies the emblem of the La?ko Brewery, the largest brewery in Slovenia. In addition, the first Slovene-language full-length film, recorded in 1931 by Janko Ravnik, was titled In the Kingdom of the Goldhorn.\\r\\n\\r\\nIn 2009, upon close scrutiny of his stomach contents, scientists confirmed that the 5300 year old frozen, Alpine iceman known as \\"?tzi\\" ate a last meal that included ibex meat.","input":"What type of an animal is an ibex?"},{"output":"Jon Erich Rauch","context":"Jon Erich Rauch (born September 27, 1978) is an American former professional baseball pitcher. At 6?feet 11?inches (2.11?m), he is the tallest player in Major League Baseball history.[1] He is also an Olympic Gold Medalist.\\r\\n\\r\\n\\r\\nRauch attended and graduated from Oldham County High School. He grew up in Westport, Kentucky. Rauch played college baseball at Morehead State University, where he double majored in physics and business. He was also a member of the social fraternity Sigma Phi Epsilon, Kentucky Zeta Chapter.\\r\\nRauch, weighing 290 pounds, was drafted in the third round of the 1999 amateur draft by the Chicago White Sox. He debuted with the White Sox on April 2, 2002.\\r\\nIn 2002, Rauch's first stint in the big leagues resulted in a 6.59 ERA in eight games and six starts. He did not play in the majors in 2003, then returned to the majors in 2004 after a strong Triple-A campaign. However, against major league batters he again posted a high ERA of 6.23. In July 2004, Rauch was traded to the Montral Expos along with Triple-A reliever Gary Majewski for Carl Everett.\\r\\nOn August 13, 2004, Rauch hit a home run against the Houston Astros off Roger Clemens, making him the tallest man ever to hit a home run in Major League Baseball. Despite a strong finish to the season in Montral, Rauch was sent to the minors when the Expos moved to Washington. After putting up better numbers in the minors, Rauch finished the 2005 season with the Nationals, used mostly as a reliever, and going 2-4 with a 3.60 ERA.\\r\\nIn 2006, Rauch had his best season, posted a 4-5 record, a 3.35 ERA, and appearing in 85 games, second most in the NL.\\r\\nIn 2007, Rauch led the Major Leagues in appearances with 88. He finished the year with an 8-4 record, four saves, and a 3.61 ERA. His eight victories led the team in wins, a rarity in baseball for a relief pitcher.\\r\\nOn February 2, 2008, Rauch signed a two-year contract with the Nationals, worth a total of $3.2 million.[2] Before being traded, Rauch spent most of the year as the closer in place of injured Chad Cordero.[3]\\r\\nRauch won the first game in the history of Nationals Park.\\r\\nOn July 22, 2008, Rauch was traded to the Arizona Diamondbacks for second base prospect Emilio Bonifacio.[4]\\r\\nOn August 28, 2009, Rauch was traded to the Minnesota Twins for RHP Kevin Mulvey.[5] He appeared in 17 games for the Twins before the end of the season, posting a 5-1 record with a 1.72 ERA.[6]\\r\\nOn April 2, 2010, Twins manager Ron Gardenhire named Rauch the team's closer, replacing the injured Joe Nathan.[7] On April 6, 2010 Rauch earned his first save as a Twin with a perfect ninth with two strikeouts versus the Los Angeles Angels of Anaheim in a 5-3 win. Rauch served as the team's closer through August, when the Twins acquired Matt Capps. During his time as closer, he saved 21 games in 25 opportunities.\\r\\nAfter the Twins acquired Capps, Rauch returned to his previous role as a set-up man and long reliever.\\r\\nOn January 17, 2011 the Blue Jays signed Rauch to a one-year deal worth $3.5M that included a club option for $3.75M in 2012.[8]\\r\\nBlue Jays manager John Farrell suffered a dislocated jaw while attempting to restrain Rauch from going after umpire Alfonso Marquez during a game on July 2, 2011.[9] Both Rauch and Farrell were ejected from the game.[10]\\r\\nAfter pitching in a game against the Seattle Mariners on August 15, 2011, Rauch was taken to a Seattle hospital for an emergency appendectomy. He was placed on the 15-day disabled list on August 16, 2011. At the time of injury, Rauch led the Blue Jays in appearances (with 51), posting a 5-4 record with a 4.47 earned run average and 11 saves.[11]\\r\\nOn December 6, 2011, Rauch agreed to a one-year 3.5 million contract with the New York Mets.[12]\\r\\nOn February 5, 2013, Rauch agreed to a one-year deal with the Miami Marlins.[13] Rauch was designated for assignment on May 18.[14] At the time of his designation, Rauch had a 1ÿ2 record with an earned run average of 7.56. He was released on May 23, 2013.[15]\\r\\nOn June 1, 2013, it was announced that the Orioles had signed Rauch to a minor league contract.[16] On July 3, Rauch opted out of his minor league contract. He went 1-0 with a 2.89 ERA in 10 appearances over 9.1 innings, striking out 10.[17]\\r\\nOn January 23, 2014, Rauch signed a minor league deal with the Kansas City Royals with an invitation to Spring training.[18] He was released on March 28.","input":"Who is the tallest pitcher in the mlb?"},{"output":"James Montgomery Flagg","context":"Uncle Sam (initials U.S.) is a common national personification of the American government or the United States in general that, according to legend, came into use during the War of 1812 and was supposedly named for Samuel Wilson. The actual origin is obscure.[2] Since the early 19th century, Uncle Sam has been a popular symbol of the US government in American culture and a manifestation of patriotic emotion.[3] While the figure of Uncle Sam represents specifically the government, the goddess Columbia represents the United States as a nation.\\r\\nThe first reference to Uncle Sam in formal literature (as distinct from newspapers) was in the 1816 allegorical book The Adventures of Uncle Sam in Search After His Lost Honor by Frederick Augustus Fidfaddy, Esq.[4] Other possible references date to the American Revolutionary War: an Uncle Sam is mentioned as early as 1775, in the original lyrics of \\"Yankee Doodle\\",[5] though it is not clear whether this reference is to Uncle Sam as a metaphor for the United States, or to an actual person named Sam. The lyrics as a whole celebrate the military efforts of the young nation in besieging the British at Boston. The 13th stanza is:\\r\\nOld Uncle Sam come there to change\\r\\nSome pancakes and some onions,\\r\\nFor 'lasses cakes, to carry home\\r\\nTo give his wife and young ones.[6]\\r\\n\\r\\n\\r\\nThe earliest known personification of the United States was as a woman named Columbia, who first appeared in 1738 (pre-USA) and sometimes was associated with another female personification, Lady Liberty. With the American Revolutionary War came Brother Jonathan, a male personification, and Uncle Sam finally appeared after the War of 1812.[7] Columbia appeared with either Brother Jonathan or Uncle Sam, but her use declined as a national personification in favor of Liberty, and she was effectively abandoned once she became the mascot of Columbia Pictures in the 1920s.\\r\\nAccording to an article in the 1893 The Lutheran Witness, Uncle Sam was simply another name for Brother Jonathan:\\r\\nWhen we meet him in politics we call him Uncle Sam; when we meet him in society we call him Brother Jonathan. Here of late Uncle Sam alias Brother Jonathan has been doing a powerful lot of complaining, hardly doing anything else. [sic][8]\\r\\nA March 24, 1810 journal entry by Isaac Mayo states:\\r\\nweighed anchor stood down the harbour, passed Sandy Hook, where there are two light-houses, and put to sea, first and second day out most deadly seasick, oh could I have got on shore in the hight [sic] of it, I swear that uncle Sam, as they call him, would certainly forever have lost the services of at least one sailor.[9]\\r\\nThe precise origin of the Uncle Sam character is unclear, but a popular legend is that the name \\"Uncle Sam\\" was derived from Samuel Wilson, a meatpacker from Troy, New York who supplied rations for American soldiers during the War of 1812. There was a requirement at the time for contractors to stamp their name and where the rations came from onto the food they were sending. Wilson's packages were labeled \\"E.A ÿ US.\\" When someone asked what that stood for, a co-worker jokingly said, \\"Elbert Anderson [the contractor] and Uncle Sam,\\" referring to Wilson, though the \\"US\\" actually stood for United States.[10] Doubts have been raised as to the authenticity of this story, as the claim did not appear in print until 1842.[11] Additionally, the earliest known mention definitely referring to the metaphorical Uncle Sam is from 1810, predating Wilson's contract with the government.[9] As early as 1835, Brother Jonathan made a reference to Uncle Sam, implying that they symbolized different things: Brother Jonathan was the country itself, while Uncle Sam was the government and its power.[12]\\r\\nBy the 1850s, the names Brother Jonathan and Uncle Sam were being used nearly interchangeably, to the point that images of what had previously been called \\"Brother Jonathan\\" were being called \\"Uncle Sam\\". Similarly, the appearance of both personifications varied wildly. For example, one depiction of Uncle Sam in 1860 showed him looking like Benjamin Franklin,[13] while a contemporaneous depiction of Brother Jonathan[14] looks more like the modern version of Uncle Sam, though without a goatee.\\r\\nUncle Sam did not get a standard appearance, even with the effective abandonment of Brother Jonathan near the end of the American Civil War, until the well-known \\"recruitment\\" image of Uncle Sam was first created by James Montgomery Flagg during World War I. The image was inspired by a British recruitment poster showing Lord Kitchener in a similar pose. It is this image more than any other that has influenced the modern appearance of Uncle Sam: an elderly white man with white hair and a goatee, wearing a white top hat with white stars on a blue band, a blue tail coat, and red-and-white-striped trousers.\\r\\nFlagg's depiction of Uncle Sam was shown publicly for the first time, according to some, on the cover of the magazine Leslie's Weekly on July 6, 1916, with the caption \\"What Are You Doing for Preparedness?\\"[1][15] More than four million copies of this image were printed between 1917 and 1918. Flagg's image was also used extensively during World War II, during which the U.S. was codenamed \\"Samland\\" by the German intelligence agency Abwehr.[16] The term was central in the song \\"The Yankee Doodle Boy\\", which was featured in 1942 in the musical Yankee Doodle Dandy.\\r\\nThere are two memorials to Uncle Sam, both of which commemorate the life of Samuel Wilson: the Uncle Sam Memorial Statue in Arlington, Massachusetts, his birthplace; and a memorial near his long-term residence in Riverfront Park, Troy, New York. Wilson's boyhood home can still be visited in Mason, New Hampshire. Samuel Wilson died on July 31, 1854, aged 87, and is buried in Oakwood Cemetery, Troy, New York.\\r\\nIn 1989, \\"Uncle Sam Day\\" became official. A Congressional joint resolution[17] designated September 13, 1989 as \\"Uncle Sam Day\\", the birthday of Samuel Wilson. In 2015, the family history company MyHeritage researched Uncle Sam's family tree and claims to have tracked down his living relatives.[18][19]","input":"Who drew the first image of uncle sam?"},{"output":"Johannes Kepler","context":"In astronomy, Kepler's laws of planetary motion are three scientific laws describing the motion of planets around the Sun.\\r\\nMost planetary orbits are nearly circular, and careful observation and calculation are required in order to establish that they are not perfectly circular. Calculations of the orbit of Mars, whose published values are somewhat suspect,[2] indicated an elliptical orbit. From this, Johannes Kepler inferred that other bodies in the Solar System, including those farther away from the Sun, also have elliptical orbits.\\r\\nKepler's work (published between 1609 and 1619) improved the heliocentric theory of Nicolaus Copernicus, explaining how the planets' speeds varied, and using elliptical orbits rather than circular orbits with epicycles.[3]\\r\\nIsaac Newton showed in 1687 that relationships like Kepler's would apply in the Solar System to a good approximation, as a consequence of his own laws of motion and law of universal gravitation.\\r\\n\\r\\n\\r\\nKepler's laws improve the model of Copernicus. If the eccentricities of the planetary orbits are taken as zero, then Kepler basically agrees with Copernicus:\\r\\nThe eccentricities of the orbits of those planets known to Copernicus and Kepler are small, so the foregoing rules give good approximations of planetary motion; but Kepler's laws fit the observations better than Copernicus'.\\r\\nKepler's corrections are not at all obvious:\\r\\nThe eccentricity of the orbit of the Earth makes the time from the March equinox to the September equinox, around 186 days, unequal to the time from the September equinox to the March equinox, around 179 days. A diameter would cut the orbit into equal parts, but the plane through the Sun parallel to the equator of the Earth cuts the orbit into two parts with areas in a 186 to 179 ratio, so the eccentricity of the orbit of the Earth is approximately\\r\\nwhich is close to the correct value (0.016710219) (see Earth's orbit). The calculation is correct when perihelion, the date the Earth is closest to the Sun, falls on a solstice. The current perihelion, near January 4, is fairly close to the solstice of December 21 or 22.\\r\\nIt took nearly two centuries for the current formulation of Kepler's work to take on its settled form. Voltaire's Elments de la philosophie de Newton (Elements of Newton's Philosophy) of 1738 was the first publication to use the terminology of \\"laws\\".[4][5] The Biographical Encyclopedia of Astronomers in its article on Kepler (p.?620) states that the terminology of scientific laws for these discoveries was current at least from the time of Joseph de Lalande.[6] It was the exposition of Robert Small, in An account of the astronomical discoveries of Kepler (1804) that made up the set of three laws, by adding in the third.[7] Small also claimed, against the history, that these were empirical laws, based on inductive reasoning.[5][8]\\r\\nFurther, the current usage of \\"Kepler's Second Law\\" is something of a misnomer. Kepler had two versions, related in a qualitative sense: the \\"distance law\\" and the \\"area law\\". The \\"area law\\" is what became the Second Law in the set of three; but Kepler did himself not privilege it in that way.[9]\\r\\nJohannes Kepler published his first two laws about planetary motion in 1609, having found them by analyzing the astronomical observations of Tycho Brahe.[10][3][11] Kepler's third law was published in 1619.[12][3] Notably, Kepler had believed in the Copernican model of the solar system, which called for circular orbits, but could not reconcile Brahe's highly precise observations with a circular fit to Mars' orbit (Mars coincidentally having the highest eccentricity of all planets except Mercury[13]). His first law reflected this discovery.\\r\\nKepler in 1621 and Godefroy Wendelin in 1643 noted that Kepler's third law applies to the four brightest moons of Jupiter.[Nb 1] The second law, in the \\"area law\\" form, was contested by Nicolaus Mercator in a book from 1664, but by 1670 his Philosophical Transactions were in its favour. As the century proceeded it became more widely accepted.[14] The reception in Germany changed noticeably between 1688, the year in which Newton's Principia was published and was taken to be basically Copernican, and 1690, by which time work of Gottfried Leibniz on Kepler had been published.[15]\\r\\nNewton is credited with understanding that the second law is not special to the inverse square law of gravitation, being a consequence just of the radial nature of that law; while the other laws do depend on the inverse square form of the attraction. Carl Runge and Wilhelm Lenz much later identified a symmetry principle in the phase space of planetary motion (the orthogonal group O(4) acting) which accounts for the first and third laws in the case of Newtonian gravitation, as conservation of angular momentum does via rotational symmetry for the second law.[16]\\r\\nThe mathematical model of the kinematics of a planet subject to the laws allows a large range of further calculations.\\r\\nThe orbit of every planet is an ellipse with the Sun at one of the two foci.\\r\\nMathematically, an ellipse can be represented by the formula:\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\np\\r\\n\\r\\n\\r\\n{\\\\displaystyle p}\\r\\n\\r\\n is the semi-latus rectum,  is the eccentricity of the ellipse, r is the distance from the Sun to the planet, and Ĳ is the angle to the planet's current position from its closest approach, as seen from the Sun. So (r,?Ĳ) are polar coordinates.\\r\\nFor an ellipse 0?<??<?1?; in the limiting case  = 0, the orbit is a circle with the sun at the centre (i.e. where there is zero eccentricity).\\r\\nAt Ĳ = 0, perihelion, the distance is minimum\\r\\nAt Ĳ = 90 and at Ĳ = 270 the distance is equal to \\r\\n\\r\\n\\r\\n\\r\\np\\r\\n\\r\\n\\r\\n{\\\\displaystyle p}\\r\\n\\r\\n.\\r\\nAt Ĳ = 180, aphelion, the distance is maximum (by definition, aphelion is ÿ invariably ÿ perihelion plus 180)\\r\\nThe semi-major axis a is the arithmetic mean between rmin and rmax:\\r\\nThe semi-minor axis b is the geometric mean between rmin and rmax:\\r\\nThe semi-latus rectum p is the harmonic mean between rmin and rmax:\\r\\nThe eccentricity  is the coefficient of variation between rmin and rmax:\\r\\nThe area of the ellipse is\\r\\nThe special case of a circle is  = 0, resulting in r = p = rmin = rmax = a = b and A = r2.\\r\\nA line joining a planet and the Sun sweeps out equal areas during equal intervals of time.[1]\\r\\nThe orbital radius and angular velocity of the planet in the elliptical orbit will vary. This is shown in the animation: the planet travels faster when closer to the sun, then slower when farther from the sun. Kepler's second law states that the blue sector has constant area.\\r\\nIn a small time \\r\\n\\r\\n\\r\\n\\r\\nd\\r\\nt\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle dt\\\\,}\\r\\n\\r\\n the planet sweeps out a small triangle having base line \\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle r\\\\,}\\r\\n\\r\\n and height \\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\nd\\r\\nĲ\\r\\n\\r\\n\\r\\n{\\\\displaystyle r\\\\,d\\\\theta }\\r\\n\\r\\n and area \\r\\n\\r\\n\\r\\n\\r\\nd\\r\\nA\\r\\n=\\r\\n\\r\\n\\r\\n\\r\\n1\\r\\n2\\r\\n\\r\\n\\r\\n\\r\\n?\\r\\nr\\r\\n?\\r\\nr\\r\\nd\\r\\nĲ\\r\\n\\r\\n\\r\\n{\\\\displaystyle dA={\\\\tfrac {1}{2}}\\\\cdot r\\\\cdot rd\\\\theta }\\r\\n\\r\\n and so the constant areal velocity is \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nd\\r\\nA\\r\\n\\r\\n\\r\\nd\\r\\nt\\r\\n\\r\\n\\r\\n\\r\\n=\\r\\n\\r\\n\\r\\n\\r\\n1\\r\\n2\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nd\\r\\nĲ\\r\\n\\r\\n\\r\\nd\\r\\nt\\r\\n\\r\\n\\r\\n\\r\\n.\\r\\n\\r\\n\\r\\n{\\\\displaystyle {\\\\frac {dA}{dt}}={\\\\tfrac {1}{2}}r^{2}{\\\\frac {d\\\\theta }{dt}}.}\\r\\n\\r\\n\\r\\nThe area enclosed by the elliptical orbit is \\r\\n\\r\\n\\r\\n\\r\\n\\r\\na\\r\\nb\\r\\n.\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\pi ab.\\\\,}\\r\\n\\r\\n So the period \\r\\n\\r\\n\\r\\n\\r\\nP\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle P\\\\,}\\r\\n\\r\\n satisfies\\r\\nand the mean motion of the planet around the Sun\\r\\nsatisfies\\r\\nThe square of the orbital period of a planet is directly proportional to the cube of the semi-major axis of its orbit.\\r\\nThis captures the relationship between the distance of planets from the Sun, and their orbital periods.\\r\\nKepler enunciated in 1619[12] this third law in a laborious attempt to determine what he viewed as the \\"music of the spheres\\" according to precise laws, and express it in terms of musical notation.[17] So it was known as the harmonic law.[18]\\r\\nUsing Newton's Law of gravitation (published 1687), this relation can be found in the case of a circular orbit by setting the centripetal force equal to the gravitational force:\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nm\\r\\nr\\r\\n\\r\\n\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n=\\r\\nG\\r\\n\\r\\n\\r\\n\\r\\nm\\r\\nM\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle mr\\\\omega ^{2}=G{\\\\frac {mM}{r^{2}}}}\\r\\n\\r\\n\\r\\nThen, expressing the angular velocity in terms of the orbital period and then rearranging, we find Kepler's Third Law:\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nm\\r\\nr\\r\\n\\r\\n\\r\\n(\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\nT\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n)\\r\\n\\r\\n\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n=\\r\\nG\\r\\n\\r\\n\\r\\n\\r\\nm\\r\\nM\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nL\\r\\n\\r\\nT\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n=\\r\\n\\r\\n\\r\\n(\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n4\\r\\n\\r\\n\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nG\\r\\nM\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n)\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\nL\\r\\n\\r\\nT\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\nQ\\r\\n\\r\\nr\\r\\n\\r\\n3\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle mr{\\\\bigg (}{\\\\frac {2\\\\pi }{T}}{\\\\bigg )}^{2}=G{\\\\frac {mM}{r^{2}}}\\\\rightarrow T^{2}={\\\\bigg (}{\\\\frac {4\\\\pi ^{2}}{GM}}{\\\\bigg )}r^{3}\\\\rightarrow T^{2}\\\\propto r^{3}}\\r\\n\\r\\n\\r\\nA more detailed derivation can be done with general elliptical orbits as well as the center of mass. This results in replacing a circular radius, \\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n\\r\\n{\\\\displaystyle r}\\r\\n\\r\\n, with the elliptical semi-major axis, \\r\\n\\r\\n\\r\\n\\r\\na\\r\\n\\r\\n\\r\\n{\\\\displaystyle a}\\r\\n\\r\\n, as well as replacing the large mass \\r\\n\\r\\n\\r\\n\\r\\nM\\r\\n\\r\\n\\r\\n{\\\\displaystyle M}\\r\\n\\r\\n with \\r\\n\\r\\n\\r\\n\\r\\nM\\r\\n+\\r\\nm\\r\\n\\r\\n\\r\\n{\\\\displaystyle M+m}\\r\\n\\r\\n. However, with planet masses being so much smaller than the sun, this correction is often ignored. The full corresponding formula is:\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\nM\\r\\n\\r\\n\\r\\n{\\\\displaystyle M}\\r\\n\\r\\n is the mass of the sun, \\r\\n\\r\\n\\r\\n\\r\\nm\\r\\n\\r\\n\\r\\n{\\\\displaystyle m}\\r\\n\\r\\n is the mass of the planet, and \\r\\n\\r\\n\\r\\n\\r\\nG\\r\\n\\r\\n\\r\\n{\\\\displaystyle G}\\r\\n\\r\\n is the gravitational constant, \\r\\n\\r\\n\\r\\n\\r\\nT\\r\\n\\r\\n\\r\\n{\\\\displaystyle T}\\r\\n\\r\\n is the orbital period and \\r\\n\\r\\n\\r\\n\\r\\na\\r\\n\\r\\n\\r\\n{\\\\displaystyle a}\\r\\n\\r\\n is the elliptical semi-major axis.\\r\\nThe following table shows the data used by Kepler to empirically derive his law:\\r\\nUpon finding this pattern Kepler wrote:[19]\\r\\ntranslated from \\"Harmonies of the World\\" by Kepler (1619)\\r\\nFor comparison, here are modern estimates:\\r\\nIsaac Newton computed in his Philosophi? Naturalis Principia Mathematica the acceleration of a planet moving according to Kepler's first and second law.\\r\\nThis implies that the Sun may be the physical cause of the acceleration of planets. However, Newton states in his Principia that he considers forces from a mathematical point of view, not a physical, thereby taking an instrumentalist view.[20] Moreover, he does not assign a cause to gravity.[21]\\r\\nNewton defined the force acting on a planet to be the product of its mass and the acceleration (see Newton's laws of motion). So:\\r\\nThe Sun plays an unsymmetrical part, which is unjustified. So he assumed, in Newton's law of universal gravitation:\\r\\nAs the planets have small masses compared to that of the Sun, the orbits conform approximately to Kepler's laws. Newton's model improves upon Kepler's model, and fits actual observations more accurately (see two-body problem).\\r\\nBelow comes the detailed calculation of the acceleration of a planet moving according to Kepler's first and second laws.\\r\\nFrom the heliocentric point of view consider the vector to the planet \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n=\\r\\nr\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n^\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\mathbf {r} =r{\\\\hat {\\\\mathbf {r} }}}\\r\\n\\r\\n where \\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n\\r\\n{\\\\displaystyle r}\\r\\n\\r\\n is the distance to the planet and \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n^\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle {\\\\hat {\\\\mathbf {r} }}}\\r\\n\\r\\n is a unit vector pointing towards the planet.\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nĲ\\r\\n^\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle {\\\\hat {\\\\boldsymbol {\\\\theta }}}}\\r\\n\\r\\n is the unit vector whose direction is 90 degrees counterclockwise of \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n^\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle {\\\\hat {\\\\mathbf {r} }}}\\r\\n\\r\\n, and \\r\\n\\r\\n\\r\\n\\r\\nĲ\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\theta }\\r\\n\\r\\n is the polar angle, and where a dot on top of the variable signifies differentiation with respect to time.\\r\\nDifferentiate the position vector twice to obtain the velocity vector and the acceleration vector:\\r\\nSo\\r\\nwhere the radial acceleration is\\r\\nand the transversal acceleration is\\r\\nKepler's second law says that\\r\\nis constant.\\r\\nThe transversal acceleration \\r\\n\\r\\n\\r\\n\\r\\n\\r\\na\\r\\n\\r\\nĲ\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle a_{\\\\theta }}\\r\\n\\r\\n is zero:\\r\\nSo the acceleration of a planet obeying Kepler's second law is directed towards the sun.\\r\\nThe radial acceleration \\r\\n\\r\\n\\r\\n\\r\\n\\r\\na\\r\\n\\r\\nr\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle a_{r}}\\r\\n\\r\\n is\\r\\nKepler's first law states that the orbit is described by the equation:\\r\\nDifferentiating with respect to time\\r\\nor\\r\\nDifferentiating once more\\r\\nThe radial acceleration \\r\\n\\r\\n\\r\\n\\r\\n\\r\\na\\r\\n\\r\\nr\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle a_{r}}\\r\\n\\r\\n satisfies\\r\\nSubstituting the equation of the ellipse gives\\r\\nThe relation \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nb\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n=\\r\\np\\r\\na\\r\\n\\r\\n\\r\\n{\\\\displaystyle b^{2}=pa}\\r\\n\\r\\n gives the simple final result\\r\\nThis means that the acceleration vector \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\mathbf {\\\\ddot {r}} }\\r\\n\\r\\n of any planet obeying Kepler's first and second law satisfies the inverse square law\\r\\nwhere\\r\\nis a constant, and \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n^\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle {\\\\hat {\\\\mathbf {r} }}}\\r\\n\\r\\n is the unit vector pointing from the Sun towards the planet, and \\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle r\\\\,}\\r\\n\\r\\n is the distance between the planet and the Sun.\\r\\nAccording to Kepler's third law, \\r\\n\\r\\n\\r\\n\\r\\nϫ\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\alpha }\\r\\n\\r\\n has the same value for all the planets. So the inverse square law for planetary accelerations applies throughout the entire solar system.\\r\\nThe inverse square law is a differential equation. The solutions to this differential equation include the Keplerian motions, as shown, but they also include motions where the orbit is a hyperbola or parabola or a straight line. See Kepler orbit.\\r\\nBy Newton's second law, the gravitational force that acts on the planet is:\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nm\\r\\n\\r\\nplanet\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle m_{\\\\text{planet}}}\\r\\n\\r\\n is the mass of the planet and \\r\\n\\r\\n\\r\\n\\r\\nϫ\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\alpha }\\r\\n\\r\\n has the same value for all planets in the solar system. According to Newton's third Law, the Sun is attracted to the planet by a force of the same magnitude. Since the force is proportional to the mass of the planet, under the symmetric consideration, it should also be proportional to the mass of the Sun, \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nm\\r\\n\\r\\nSun\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle m_{\\\\text{Sun}}}\\r\\n\\r\\n. So\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\nG\\r\\n\\r\\n\\r\\n{\\\\displaystyle G}\\r\\n\\r\\n is the gravitational constant.\\r\\nThe acceleration of solar system body number i is, according to Newton's laws:\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nm\\r\\n\\r\\nj\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle m_{j}}\\r\\n\\r\\n is the mass of body j, \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\ni\\r\\nj\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle r_{ij}}\\r\\n\\r\\n is the distance between body i and body j, \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n^\\r\\n\\r\\n\\r\\n\\r\\n\\r\\ni\\r\\nj\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle {\\\\hat {\\\\mathbf {r} }}_{ij}}\\r\\n\\r\\n is the unit vector from body i towards body j, and the vector summation is over all bodies in the world, besides i itself.\\r\\nIn the special case where there are only two bodies in the world, Earth and Sun, the acceleration becomes\\r\\nwhich is the acceleration of the Kepler motion. So this Earth moves around the Sun according to Kepler's laws.\\r\\nIf the two bodies in the world are Moon and Earth the acceleration of the Moon becomes\\r\\nSo in this approximation the Moon moves around the Earth according to Kepler's laws.\\r\\nIn the three-body case the accelerations are\\r\\nThese accelerations are not those of Kepler orbits, and the three-body problem is complicated. But Keplerian approximation is the basis for perturbation calculations. See Lunar theory.\\r\\nKepler used his two first laws to compute the position of a planet as a function of time. His method involves the solution of a transcendental equation called Kepler's equation.\\r\\nThe procedure for calculating the heliocentric polar coordinates (r,Ĳ) of a planet as a function of the time t since perihelion, is the following four steps:\\r\\nThe important special case of circular orbit, ?=?0, gives Ĳ?=?E?=?M. Because the uniform circular motion was considered to be normal, a deviation from this motion was considered an anomaly.\\r\\nThe proof of this procedure is shown below.\\r\\nThe Keplerian problem assumes an elliptical orbit and the four points:\\r\\nand\\r\\nThe problem is to compute the polar coordinates (r,Ĳ) of the planet from the time since perihelion,?t.\\r\\nIt is solved in steps. Kepler considered the circle with the major axis as a diameter, and\\r\\nThe sector areas are related by \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n|\\r\\n\\r\\nz\\r\\ns\\r\\np\\r\\n\\r\\n|\\r\\n\\r\\n=\\r\\n\\r\\n\\r\\nb\\r\\na\\r\\n\\r\\n\\r\\n?\\r\\n\\r\\n|\\r\\n\\r\\nz\\r\\ns\\r\\nx\\r\\n\\r\\n|\\r\\n\\r\\n.\\r\\n\\r\\n\\r\\n{\\\\displaystyle |zsp|={\\\\frac {b}{a}}\\\\cdot |zsx|.}\\r\\n\\r\\n\\r\\nThe circular sector area \\r\\n\\r\\n\\r\\n\\r\\n?\\r\\n\\r\\n|\\r\\n\\r\\nz\\r\\nc\\r\\ny\\r\\n\\r\\n|\\r\\n\\r\\n=\\r\\n\\r\\n\\r\\n\\r\\n\\r\\na\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\nM\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n.\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\ |zcy|={\\\\frac {a^{2}M}{2}}.}\\r\\n\\r\\n\\r\\nThe area swept since perihelion,\\r\\nis by Kepler's second law proportional to time since perihelion. So the mean anomaly, M, is proportional to time since perihelion, t.\\r\\nwhere n is the mean motion.\\r\\nWhen the mean anomaly M is computed, the goal is to compute the true anomaly Ĳ. The function Ĳ?=?f(M) is, however, not elementary.[22] Kepler's solution is to use\\r\\nas an intermediate variable, and first compute E as a function of M by solving Kepler's equation below, and then compute the true anomaly Ĳ from the eccentric anomaly E. Here are the details.\\r\\nDivision by a2/2 gives Kepler's equation\\r\\nThis equation gives M as a function of E. Determining E for a given M is the inverse problem. Iterative numerical algorithms are commonly used.\\r\\nHaving computed the eccentric anomaly E, the next step is to calculate the true anomaly?Ĳ.\\r\\nNote from the figure that\\r\\nso that\\r\\nDividing by \\r\\n\\r\\n\\r\\n\\r\\na\\r\\n\\r\\n\\r\\n{\\\\displaystyle a}\\r\\n\\r\\n and inserting from Kepler's first law\\r\\nto get\\r\\nThe result is a usable relationship between the eccentric anomaly E and the true anomaly?Ĳ.\\r\\nA computationally more convenient form follows by substituting into the trigonometric identity:\\r\\nGet\\r\\nMultiplying by 1?+? gives the result\\r\\nThis is the third step in the connection between time and position in the orbit.\\r\\nThe fourth step is to compute the heliocentric distance r from the true anomaly Ĳ by Kepler's first law:\\r\\nUsing the relation above between Ĳ and E the final equation for the distance r is:","input":"Who discovered the three laws of planetary motion?"},{"output":"the blue jay","context":"The Johns Hopkins Blue Jays are the athletic teams that represent Johns Hopkins University. They compete in the NCAA Division III, except for their lacrosse teams, which compete in Division I. They are primarily members of the Centennial Conference. The team colors are Columbia blue (PMS 284) and black, and the blue jay is their mascot.[2] Homewood Field is the home stadium.\\r\\nHopkins celebrates Homecoming in the spring to coincide with the height of the lacrosse season. The Lacrosse Museum and National Hall of Fame, governed by US Lacrosse, was located on the Homewood campus, adjacent to Homewood Field, until 2016 when it moved to its new facilities in Sparks, Maryland. Past Johns Hopkins lacrosse teams have represented the United States in international competition. At the 1932 Summer Olympics lacrosse demonstration event Hopkins played for the US. They have also gone to Melbourne, Australia to win the 1974 World Lacrosse Championship.\\r\\n\\r\\n\\r\\nOriginally, the Johns Hopkins athletes were not called Blue Jays but the Black and Blue, a nickname derived from their athletic colors. Hopkins archivist James Stimpert has theorized that the Blue Jay name stemmed from Hopkins' student humor magazine, The Black and Blue Jay, first published in 1920. The \\"Black and Blue\\" came from the athletic colors and the \\"Jay\\" most likely stood for first initial in Johns Hopkins.\\r\\nThe school's most prominent sports team is its men's lacrosse team, which has won 44 national titles - nine NCAA Division I (2007, 2005, 1987, 1985, 1984, 1980, 1979, 1978, 1974), 29 United States Intercollegiate Lacrosse Association (USILA), and six Intercollegiate Lacrosse Association (ILA) titles. Hopkins' lacrosse rivals include Princeton University, Syracuse University, the University of Virginia, and a budding rivalry with Duke University due to intense recent competition, including one-goal victories over the Blue Devils in both the 2005 and 2007 NCAA Championships and in the NCAA semifinals in the 2008; its primary intrastate rivals are Loyola University Maryland, Towson University, the United States Naval Academy, and the University of Maryland. The rivalry with Maryland is the most prominent in college lacrosse and the two teams have met 105 times. On June 3, 2013, it was announced that Johns Hopkins would be joining the Big Ten Conference as a Sport Affiliate member in Men's Lacrosse starting in 2015.[3]\\r\\nThe Blue Jays Men's soccer team has won eight Centennial Conference Regular Season titles along with another four ECAC titles previously to joining the Centennial Conference in 1993. The team has reached the NCAA tournament 12 times in the program's history. The team is currently on a streak of 16 winning seasons and has had over 20 All-American selections.\\r\\nHopkins also has an acclaimed fencing team, which has ranked in the top three of Division III teams in the past few years and in 2007 defeated the University of North Carolina, a Division I team, for the first time. The Swimming team also has ranked in the top two of Division III for the last 10 years. Hopkins also has a century-old rivalry with McDaniel College (formerly Western Maryland College), playing the Green Terrors 83 times in football since the first game in 1894.\\r\\nJohns Hopkins' latest team to encounter postseason success is the school's baseball team. Although Blue Jays baseball regularly wins the Centennial Conference regular season and tournament titles, 2008 was the first time since 1989 that the Blue Jays made it to the College World Series for Division III baseball, hosted in Appleton, Wisconsin. The Blue Jays finished runner-up to Trinity College, losing the championship game.\\r\\nThe women's cross country team has experienced great success in recent years, finishing 7th at the NCAA championship in 2009 and 2010. The cross country and track & field teams have also had several All-American runners in the past few years. In 2012, the women's cross country team beat out top-ranked MIT to become the first women's program in Johns Hopkins history to win an NCAA championship. They also won the NCAA championship in 2013 and 2014, giving them 3 championships in just 8 appearances.\\r\\nThe Johns Hopkins women's volleyball team won their 1st Centennial Conference Title in 2011. The volleyball team has 4 NCAA All-Americans.\\r\\nJohns Hopkins has won 9 NCAA national championships:[4]","input":"What is the mascot for john hopkins university?"},{"output":"The Juane?o or Acjachemen","context":"The Juane?o or Acjachemen are an indigenous people of California. They traditionally lived along the coast in what is now Orange and San Diego counties. The name \\"Juane?o\\" derives from the Spanish Mission San Juan Capistrano, founded to colonize the area in 1776. They traditionally spoke the Juane?o language, a variety closely related to the Luise?o language of the nearby Luise?o people, but this is extinct. In the 20th century, they organized as the Juane?o Band of Mission Indians, Acjachemen Nation, which is recognized by the State of California, but is not federally recognized.\\r\\n\\r\\n\\r\\nDuring the late Paleoindian period and continuing into the present day, the southern coastal area was occupied by the Native American society referred to by Spanish colonists as the Juane?o.[2] Spanish priests named them as the people colonized by the nearby Mission San Juan Capistrano.[3] Today many contemporary Juane?o who identify as descendants of the indigenous society living in the local San Juan and San Mateo Creek drainage areas prefer the adopted indigenous term Acjachemen as their autonym, or name for themselves, in an effort to decolonize their history.\\r\\nThe Acjachemen territory extends from Las Pulgas Creek in northern San Diego County up into the San Joaquin Hills along Orange County's central coast, and inland from the Pacific Ocean up into the Santa Ana Mountains. Aliso Creek formed the northern boundary. The bulk of the population occupied the outlets of two large creeks, San Juan Creek (and its major tributary, Trabuco Canyon) and San Mateo Creek (combined with Arroyo San Onofre, which drained into the ocean at the same point).\\r\\nThe highest concentration of villages was along the lower San Juan Creek. The Spanish built Mission San Juan Capistrano there.[4] The Acjachemen resided in permanent, well-defined villages and seasonal camps. Village populations ranged from between 35 and 300 inhabitants, consisting of a single lineage in the smaller villages, and of a dominant clan joined with other families in the larger settlements. Each clan had its own resource territory and was \\"politically\\" independent; ties to other villages were maintained through economic, religious, and social networks in the immediate region. The elite class (composed chiefly of families, lineage heads, and other ceremonial specialists), a middle class (established and successful families), and people of disconnected or wandering families and captives of war comprised the three hierarchical social classes.[5]\\r\\nNative leadership consisted of the Nota, or clan chief, who conducted community rites and regulated ceremonial life in conjunction with the council of elders (puuplem), which was made up of lineage heads and ceremonial specialists in their own right. This body decided upon matters of the community, which were then carried out by the Nota and his underlings. While the placement of residential huts in a village was not regulated, the ceremonial enclosure (vanquesh) and the chief's home were most often centrally-located.[6] Fray Ger܇nimo Boscana, a Franciscan scholar who was stationed at San Juan Capistrano for more than a decade beginning in 1812, compiled what is widely considered to be the most comprehensive study of prehistoric religious practices in the San Juan Capistrano valley. Religious knowledge was secret, and the prevalent religion, called Chinigchinich, placed village chiefs in the position of religious leaders, an arrangement that gave the chiefs broad power over their people.[7]\\r\\nBoscana divided the Acjachemen into two classes: the \\"Playanos\\" (who lived along the coast) and the \\"Serranos\\" (who inhabited the mountains, some three to four leagues from the Mission).[8] The religious beliefs of the two groups as related to creation differed quite profoundly. The Playanos held that an all-powerful and unseen being called \\"Nocuma\\" brought about the earth and the sea, together with all of the trees, plants, and animals of sky, land, and water contained therein.[9] The Serranos, on the other hand, believed in two separate but related existences: the \\"existence above\\" and the \\"existence below\\". These states of being were \\"altogether explicable and indefinite\\" (like brother and sister), and it was the fruits of the union of these two entities that created \\"...the rocks and sands of the earth; then trees, shrubbery, herbs and grass; then animals...\\"[10]\\r\\nTheir language is related to the Luise?o language spoken by the nearby Luise?o tribe located to the interior.[11] Considered to speak a dialect of Luise?o, the Juane?o were part of the Cupan subgroup of the Uto-Aztecan languages.\\r\\nTheir language became extinct by the early 20th century. The tribe is working at reviving it, with several members learning it. Their studies are based on the research and records of Anastacia Majel and John P. Harrington, who recorded the language in 1933. (The tape recordings resurfaced around 1995).\\r\\nThe Juane?o Band of Mission Indians has organized a government. It elects a tribal council, assisted by tribal elders. The Juane?o Band headquarters is in San Juan Capistrano. There are more than 2,800 enrolled members.\\r\\nIt is recognized as a tribe by the state of California. They filed a petition in 1982 to seek federal recognition as a tribe, and are working with the Bureau of Indian Affairs on documentation.\\r\\nIn the 21st century, the tribe filed a land claim, seeking to regain the territory of the former Marine Corps Air Station El Toro. This had been held by them as an Indian Rancheria until the 1930s. At that time, the US government bought the land for use as a defense facility.[citation needed]\\r\\nIn May 2013, Acjachemen voters elected the first all-female Juane?o tribal council in its history.[12]","input":"What native american tribe lived at san juan capistrano?"},{"output":"Norse seafarers","context":"","input":"Who were vikings and what did they do?"},{"output":"Sojourner Truth","context":"Sojourner is the Mars Pathfinder robotic Mars rover that landed on July 4, 1997[1] in the Ares Vallis region, and explored Mars for around three months. It has front and rear cameras and hardware to conduct several scientific experiments. Designed for a mission lasting 7?sols, with possible extension to 30?sols,[2] it was in fact active for 83?sols. The base station had its last communication session with Earth at 3:23?a.m. Pacific Daylight Time on September 27, 1997.[1][3] The rover needed the base station to communicate with Earth, despite still functioning at the time communications ended.[3]\\r\\nSojourner traveled a distance of just over 100 meters (330?ft) by the time communication was lost.[4] It was instructed to stay stationary until October 5, 1997 (sol 91) and then drive around the lander.[5]\\r\\n\\r\\n\\r\\nThe word Sojourner first appeared in print in the first Bible printed by Gutenberg in 1454-1455.[clarification needed] It specifically deals with the travels of Abraham. It is found in the first chapter of Genesis. It means \\"traveler\\", and was selected in an essay contest won by Vallery Ambroise, a 12-year-old from U.S. state of Connecticut. It is named for abolitionist and women's rights activist Sojourner Truth. The second-place prize went to Deepti Rohatgi, 18, of Rockville, MD, who proposed Marie Curie, a Nobel Prize-winning Polish chemist. Third place went to Adam Sheedy, 16, of Round Rock, TX, who chose Judith Resnik, a United States' astronaut and shuttle crew-member.[6] The rover was also known as Microrover Flight Experiment abbreviated MFEX.[7]\\r\\nSojourner has solar panels and a non-rechargeable battery, which allowed limited nocturnal operations. Once the batteries were depleted, it could only operate during the day.[2] The batteries are lithium-thionyl chloride (LiSOCl2) and could provide 150 watt-hours.[8] The batteries also allowed the health of the rover to be checked while enclosed in the cruise stage while en route to Mars.[9]\\r\\n0.22 square meters of solar cells could produce a maximum of about 15 watts on Mars, depending on conditions.[8] The cells were GaAs/Ge (Gallium Arsenide/Germanium) and capable of about 18 percent efficiency. They could survive down to about ?140 Celsius (?220?F).[9]\\r\\nIts central processing unit (CPU) is an 80C85 with a 2?MHz clock, addressing 64 Kbytes of memory. It has four memory stores; the previously mentioned 64 Kbytes of RAM (made by IBM) for the main processor, 16 Kbytes of radiation-hardened PROM (made by Harris), 176 Kbytes of non-volatile storage (made by Seeq Technology), and 512 Kbytes of temporary data storage (made by Micron). The electronics were housed inside the Warm Electronics Box inside the rover.[2]\\r\\nIt communicated with the base station with 9,600 baud radio modems. The practical rate was closer to 2,600 baud with a theoretical range of about half a kilometer. The rover could travel out of range of the lander, but its software would need to be changed to that mode. Under normal driving, it would periodically send a \\"heartbeat\\" message to the lander.[2]\\r\\nThe UHF radio modems worked similar to walkie-talkies, but sent data, not voice. It could send or receive, but not both at same time, which is known as half-duplex. The data was communicated in bursts of 2 kilobytes.[10]\\r\\nThe Alpha Proton X-ray Spectrometer (APXS) is nearly identical to the one on Mars 96, and was a collaboration between the Max Planck Institute for Solar System Research in Lindau, Germany (formally known as the Max Planck Institute For Aeronomy) and the University of Chicago in the United States. APXS could determine elemental composition of Mars rocks and dust, except for hydrogen. It works by exposing a sample to alpha particles, then measuring the energies of emitted protons, X-rays, and backscattered alpha particles.[11]\\r\\nThe rover had three cameras: two monochrome cameras in front, and a color camera in the rear. Each front camera had an array 484 pixels high by 768 wide. The optics consisted of a window, lens, and field flattener. The window was made of sapphire, while the lens objective and flattener were made of zinc selenide.[12] The rover was imaged on Mars by the base station's IMP camera system, which also helped determine where the rover should go.[7]\\r\\nSojourner operation was supported by \\"Rover Control Software\\", which ran on a Silicon Graphics Onyx2 computer back on Earth, and allowed command sequences to be generated using a graphical interface.[13] The rover driver would wear 3D goggles supplied with imagery from the base station and move a virtual model with the spaceball controller, a specialized joystick. The control software allowed the rover and surrounding terrain to be viewed from any angle or position, supporting the study of terrain features, placing waypoints, or doing virtual flyovers.[13]\\r\\nThe rover had a mass of 11.5?kg (weighing about 25 pounds on Earth), which equates to a weight of 4.5 kgf (10 pounds) on Mars.[4]","input":"Who is the mars rover sojourner named after?"},{"output":"Aidan Turner","context":"Aidan Turner (born 19 June 1983)[1][2] is an Irish actor. He is best known for his roles as Kli in the three-part fantasy film The Hobbit[3][4] and Ross Poldark in the 2015 BBC adaptation of The Poldark Novels by Winston Graham. Notable television roles include those of Dante Gabriel Rossetti in Desperate Romantics,[5] Ruair McGowan in The Clinic,[6] and John Mitchell in the supernatural drama series Being Human.[7][8]\\r\\n\\r\\n\\r\\nTurner was born at home in Clondalkin, a suburb town of Dublin, Ireland. The family moved later to Walkinstown.[9] Turner attended secondary school at St Mac Dara's Community College in Templeogue before leaving to join his older brother at Firhouse Community College. Turner has stated: I probably wasnt a great student. I had a car when I was 17, so I used to just run out of school when I could, jump in the car and go play pool in Tallaght. I dont know how I knew, but I convinced myself that my [final exam] results were never going to matter to me.[10]\\r\\nAfter finishing secondary school, Turner briefly worked as an apprentice electrician, alongside his father. After he saw a notice up in Dublins Gaiety School of Acting, and having become interested in acting while working in a cinema, he applied.[11][12][13] He graduated from the Gaiety School of Acting in 2004.[11]\\r\\nAfter graduating, Turner appeared in several theatre plays, including The Plough and the Stars, Romeo and Juliet, and A Cry from Heaven.[11][14][15]\\r\\nTurner's television acting career began in 2007 with an uncredited appearance on the first episode of The Tudors.[16] Between 2008 and 2009, he appeared in a recurring role on The Clinic.[17] Appearing in 18 episodes as Ruair McGowan, he followed The Clinic with a BBC production, Desperate Romantics.[16] He portrayed Dante Gabriel Rossetti in all six episodes of the show, which aired in 2009.[16][18][19] Turner played the vampire John Mitchell on the supernatural drama programme Being Human during the first three series from 2009 to 2011.[20][21][22]\\r\\nHis film career began with two short films, The Sound of People and Matterhorn, both in 2007. He later played Mal in the thriller feature film Alarm (2008).[23][24]\\r\\nHis role on Being Human brought Turner to the attention of Peter Jackson, who cast him as the dwarf Kli in The Hobbit trilogy (2012ÿ2014).[11] In 2014, he won the Empire Award for Best Male Newcomer for the second film in the series, The Desolation of Smaug, which had been released the previous year.[13] In 2013, he also played shadowhunter-turned-werewolf Luke Garroway in The Mortal Instruments: City of Bones.[16]\\r\\nIn the 2015 BBC TV miniseries And Then There Were None, based on the Agatha Christie novel, he plays the cynical mercenary Philip Lombard.[25]\\r\\nTurner performs the title role of Ross Poldark in the 2015 revival of the BBC series Poldark.[11][26][27] At the National Television Awards ceremony in 2016, Turner was presented with the \\"Impact Award\\" for his performance in Poldark.[28]","input":"Who is the actor that plays ross poldark?"},{"output":"12ÿ14 days","context":"\\r\\n\\r\\nSylvia ludoviciana (Latham, 1790)\\r\\n\\r\\nThe Carolina wren (Thryothorus ludovicianus) is a common species of wren that is a resident in the eastern half of the United States of America, the extreme south of Ontario, Canada, and the extreme northeast of Mexico. Severe winters restrict the northern limits of their range while favorable weather conditions lead to a northward extension of their breeding range. Their preferred habitat is in dense cover in forests, farm edges and suburban areas. This wren is the state bird of South Carolina.\\r\\n\\r\\nThere are seven recognized subspecies across the range of these wrens and they differ slightly in song and appearance. The birds are generally inconspicuous, avoiding the open for extended periods of time. When out in the open, they investigate their surroundings and are rarely stationary. After finding a mate, pairs maintain a territory and stay together for several years. Both sexes give out alarm calls, but only males sing to advertise territory. Carolina wrens raise multiple broods during the summer breeding season, but can fall victim to brood parasitism by brown-headed cowbirds, among other species. Some populations have been affected by mercury contamination.\\r\\n\\r\\nThe Carolina wren was first described under the name of Sylvia ludoviciana by John Latham in 1790.[3][note 1] Louis Jean Pierre Vieillot considered all wrens under the genus Troglodytes and called the Carolina wren Troglodytes arundinaceus but placed it subsequently in a separate genus Thryothorus (initially misspelled Thriothorus\\r\\n[2]) that he created in 1816.[7] Thryothorus is of Greek origin from the combination of thryon (rush, reed) and thouros (derivative of verb throskein to leap up, spring, jump at) which means 'reed jumper'; its specific name ludovicianus is a post-classical Latin term for Ludovicus (derivative from Louis XIV) that means 'of Louisiana' that identifies the locality of the specimen collected near New Orleans.[8][9]\\r\\n\\r\\nThere are seven recognized subspecies of the Carolina wren:[3][10]\\r\\n\\r\\nCampylorhynchus megalopterus\\r\\n\\r\\nCampylorhynchus brunneicapillus\\r\\n\\r\\nThryomanes bewicki\\r\\n\\r\\nThryothorus ludovicianus ludovicianus\\r\\n\\r\\nT. l. albinucha\\r\\n\\r\\nCinnycerthia peruana\\r\\n\\r\\nThryothorus guarayanus\\r\\n\\r\\nThryothorus leucotis\\r\\n\\r\\nHenicorhina leucosticta\\r\\n\\r\\nHenicorhina leucophrys\\r\\n\\r\\nUropsila leucogastra\\r\\n\\r\\nCyphorhinus arada\\r\\n\\r\\nThryothorus maculipectus\\r\\n\\r\\nThryothorus coraya\\r\\n\\r\\nThryothorus sinaloa\\r\\n\\r\\nAt 12.5 to 14?cm (4.9 to 5.5?in) long, with a 29?cm (11?in) wingspan and a weight of about 18 to 23?g (0.63 to 0.81?oz), the Carolina wren is a fairly large wren; the second largest in the United States species after the cactus wren. Among standard measurements, the wing chord is 5.4 to 6.4?cm (2.1 to 2.5?in), the tail is 4.5 to 5.6?cm (1.8 to 2.2?in), the culmen is 1.4 to 1.8?cm (0.55 to 0.71?in) and the tarsus is 2 to 2.3?cm (0.79 to 0.91?in).[3] Sexual dimorphism is slight with males being larger than their mates. A study indicated that out of 42 mated pairs, all but one of male was larger than the female of the pair. The males were on average 11 percent heavier along with having longer wing chords.[13]\\r\\n\\r\\nThere are several differences among the subspecies. For T. l. ludovicianus, the crown is rich brown that appears more chestnut-colored on its rump and uppertail-coverts. Shoulders and greater coverts are a rich brown, with a series of small white dots on the lesser primary coverts. The secondary coverts are rich brown with a darker brown barring on both webs; the bars on the primaries are on the outerwebs only, but darker and more noticeable. The retrices are brown with 18 to 20 bars that span across the tail. The white supercilious streak borders thinly with a black above and below, and extends above and beyond its shoulders. The ear coverts are speckled gray and grayish-black. Its chin and throat are grey that becomes buff on its chest, flank and belly, though the latter two are of a warmer color. The underwing coverts sport a grayish buff color. Its iris is reddish-brown, the upper mandible is lemon-colored and paler at the base and lower mandible. The legs are flesh-colored.[3]\\r\\n\\r\\nAs for the other subspecies in contrast to T. l. ludovicianus, T. l. berlandieri is of a slightly smaller build, but possesses a larger bill, the upperparts are duller brown with deeper colored underparts, T. l. lomitensis is of a duller color (than either ludovicianus or berlandieri) with its underparts either pale or almost white, T. l. miamensis contains darker rusty chestnut upperparts and deeper colored below. T. l. burleighi is duller and sootier with less distinct tail markings, T. l. mesophilus has paler underparts and a whiter supercilium, and T. l. tropicalis is darker than all races, and contains heavier bars than T. l. berlandieri.[3]\\r\\n\\r\\nThe juvenile T.l. ludovicianus is similar in appearance, but the plumage is generally paler with a softer texture with buff-tipped wing coverts, a superciliary streak is less white, a fluffy vent and crissum (the undertail coverts surrounding the cloaca) without bars.[3][14] In August and September, the partial plumage molt for the post-juvenile wrens is darker in color and affects the contour plumage, wing coverts, tail and develops a whiter superciliary stripe. The post-nuptial molt for adults in the same time period is more pronounced in color than the spring molt, with both sexes similar in appearance.[14]\\r\\n\\r\\nSurvival rates differ by region. A male captured in Arkansas lived to be at least 73 months old, and in Alabama, the oldest female and male captured were six and ten years old, respectively. A mark-and-recapture analysis of the wrens analyzing survival probability within the Southeastern United States captured was monitored from 1992 to 2003. Roughly 90 percent of the banded wrens died within 10 years.[15]\\r\\n\\r\\nThe easiest species to confuse with the Carolina wren is Bewick's wren,[16] which differs in being smaller but with a longer tail, grayer-brown above and whiter below. The Carolina and white-browed wrens differ from the house wren in being larger, with a decidedly longer bill and hind toe; their culmen has a notch behind the tip.[17]\\r\\n\\r\\nThese birds are largely resident, and will only disperse beyond their range after mild winters.[3] Carolina wrens sporadically breed as far north as Maine and Quebec after mild winters.[3][18] In certain parts of their range, such as most of Iowa, prolonged periods of snow can curtail potential expansion.[19] Permanent breeding locations range from eastern Nebraska, southern Michigan, southeast Ontario and the New England states to Mexican states such as Coahuila, Nuevo Le܇n, San Luis Potos and Tamaulipas and the Gulf Coast of the United States.[15] Local occurrences with infrequent and likely breeding locations include southeast South Dakota, central Kansas, eastern Colorado, western Oklahoma and Texas as far as Maine and New Brunswick.[15] There have been occasional vagrants spotted in Colorado, New Mexico, and Arizona, Wyoming, South Dakota, Manitoba, Nova Scotia, and the Gulf of St. Lawrence.[3][18]\\r\\n\\r\\nThe range of the wrens increased northward and westward in several regions over the past few centuries. In Massachusetts, the wrens had expanded westward and northeastward from its former southeastern location in approximately 35 years, in New York the population increased three-fold in roughly 25 years, while in midwest states such as Ohio and Michigan have seen numbers of the birds increase since the mid-1800s and early 1900s, respectively.[15] Expansion around Ontario occurred since early reports in 1890 and 1905. Explanations given include infrequent winter storms in the 20th century, expanded forest habitats, and the wrens taking advantage of urban areas containing feeders, especially in winter.[15]\\r\\n\\r\\nCarolina wrens adapt to various habitats. Natural habitats include various types of woodland such as oak hardwoods and mixed oak-pine woodlands, ash and elmwoods, hickory-oak woodlands with a healthy amount of tangled undergrowth.[3][20] The preferred habitats are riparian forests, brushy edges, swamps, overgrown farmlands, and suburban yards with abundant thick shrubs and trees, and parks.[3][20] It has an affinity for dilapidated buildings and unkempt yards in man-made areas.[20] Subspecies burleighi and neophilus inhabit slash pine and palmettos.[3][20]\\r\\n\\r\\nCarolina wrens sing year round and at any point during the daytime, with the exception of performing during the most harsh weather conditions.[20] The birds are also the only species in the Certhiidae family that neither sings in duet nor has their song control regions affect repertoire size.[21] Males alone sing, and have a repertoire of at least twenty different phrase patterns and on average, thirty two.[21][22] One of these patterns is repeated for several minutes, and although the male's song can be repeated up to twelve times, the general amount of songs range from three to five times in repetition. While singing, the tail of the birds is pointed downward. Some general vocalizations have been transcribed as teakettle-teakettle-teakettle and cheery-cheery-cheery.[14][20] Various descriptions of the teakettle song include whee-udel, whee-udel, whee-udel, che-wortel, che-wortel and t~rtee-t~rtee-t~rtee and familiar names and phrases such as sweet heart, sweet heart, come to me, come to me, sweet William, and Richelieu, Richelieu.[14]\\r\\n\\r\\nMales are capable of increasing their repertoire through song learning, but due to their sedentary nature and territorial defense habits, the song learning must occur within the first three months of life.[23] Geographic barriers affect song repertoire size from male wrens, as one study indicated that distances separated as close as 3 kilometres (1.9?mi) by water barriers can have the same effect as that of a distance of 145 kilometres (90?mi) in the mainland with no barriers.[23]\\r\\n\\r\\nFemale Carolina wrens possess song control regions that would appear to make them capable of singing with repertoires like the male. Due to vocalizations that they occasionally make with the male, it has been suggested that song perception plays a role and is of behavioral relevance.[21]\\r\\n\\r\\nDifferent subspecies have variations in songs and calls, such as miamensis having a more rapid song that contains more notes than the races that are further north.[3]\\r\\n\\r\\nTheir songs can be confused with the Kentucky warbler. The song patterns are similar, but is of a different quality, as the warbler's songs is described as richer, with more ringing and a hurried pace.[20] Other bird species that have their songs described as akin to the wrens are the flicker, Baltimore oriole, grey catbird, and more specifically the peto, peto, peto calls of the tufted titmouse, and whistles of the northern cardinal.[14] Occasionally, the wrens mimic other species, and in Pennsylvania it has led for it to be also known as the 'mocking wren'.[3]\\r\\n\\r\\nA 2006 study suggested that the correlation of tail length and body size in males, wing length in females, and lifespan for both sexes were signs of individual quality, and the wrens of high quality tend to mate with like individuals. The courting and antagonistic encounters that involve the tail fanning and wing drooping was suggested to be a possible signaling use. Age and life experience are not thought of as significant for potential mates due to their relatively short lifespan and sedentary lifestyle. Due to the large size of male wrens and the male's vigor in defending its territory, intrasexual selection was given as a possible explanation for the sexual dimorphism.[13]\\r\\n\\r\\nBoth sexes are involved in defending the territory. One aspect of territorial defense involves identifying the proximity of the threat based on the loudness of bird song as well as the level of degradation of the calls. In experiments involving playback, the wrens are capable of discriminating between degraded and undegraded songs, as well as degraded songs in the same acoustic conditions, and can detect changes of acoustic properties within their territories, such as songs under foliage.[24] Song degradation can also be used to determine the proximity of potential intruders. If the song of a bird appears to be degraded, the wrens will assume that the threat is distant not respond; if the song is not degraded, they respond by attacking.[25] Not all birds within their territory are potential enemies. Some species of birds that are neighbors are designated as 'dear-enemies' by the wrens, and the responses to neighbors and intruders in their territories differ by the season. In spring, the wrens respond more aggressively toward neighbors, though in the fall, no major discrepancy in responses is shown.[26] When protecting their nest, alarm calls are the general response. The wrens judge the size of the potential threat, such as a blue jay and avoid the risk of injury when attacking.[27] Countersinging produced by intruder birds is more likely to be taken as an aggressive threat to male Carolina wrens.[28]\\r\\n\\r\\nBoth males and females utilize calls in alarm situations, especially in territorial disputes and encounters with predators. Males alone produce the cheer call, which can sound indistinct. In southern regions of their range, the sound males use in alarm disputes is a ringing pink or p'dink sound. Females are the only ones that can perform the paired dit-dit or chatter sounds. The former can be used in territorial disputes with predators, and with at least northern populations the songs are used in alternation with the males cheer chant. The chatter is used exclusively with territorial encounters with male song, and the song can either follow or overlap her mate's song.[21][29]\\r\\n\\r\\nCarolina wrens spend the majority of their time on or near the ground searching for food, or in tangles of vegetation and vines. They also probe bark crevices on lower tree levels, or pick up leaf-litter in order to search for prey. Their diet consists of invertebrates, such as beetles, true bugs, grasshoppers, katydids, spiders, ants, bees, and wasps. Small lizards and tree frogs also make up the carnivorous portion of their diet. Vegetable matter makes up a small percentage of their diets, such as fruit pulp and various seeds. In the northern portion of their range, they frequent bird feeders.[3][20]\\r\\n\\r\\nCarolina wrens are wary, and are more often heard than seen. When on the ground, they move in jerky hops pillaging through various objects, whether man-made or natural.[20] While moving abruptly, they pause momentarily for chattering or singing.[14]  When stationary, they move in twitched motions, jerking their breast around.[20] They also sun- or sand-bathe.[30] The wrens also displays a skittish behavior when encountered by humans, as they can be seen thrusting off into cover slowly if approaching is detected. However, they occasionally seek out humans that are near, so long as there is no movement from them.[14] Other movements involve being capable of crawling like a creeper and hanging upside-down like a nuthatch.[20]\\r\\n\\r\\nFlights are generally of short duration, rapid, low-leveled, and wavelike. The wings during flight are flapped rapidly, and are frequently used during foraging. They are also capable of flying vertically from the base of a tree to the top in a single wing assisted bound.[3][20]\\r\\n\\r\\nCarolina wrens are both genetically and socially monogamous and will usually mate for life.  Mate changing is rare,[13] and there has been one possible observation of polygamy.[3] During the winter season, males are more responsible for guarding the territory. Females vary in succeeding to maintain winter territories without a mate.[3] It has been suggested that the possibility of desertion and decline in care-taking from males along with the need for security in resources year-round prevent extra pair copulations from females, as the mortality rate for Carolina wrens peaks during the winter.[31] Along with thermoregulatory benefits, roosting is thought to reinforce pair-bonding and prevent divorce between mates.[32]\\r\\n\\r\\nThe nests are arch-shaped structures with a side entrance and built of dried plants or strips of bark, as well as horsehair, string, wool and snake sloughs. Males obtain nesting materials while the females remains at the site to construct the nest. Nests are located in fragmented or complete cavities in trees, or in man-made structures such as bird-boxes, buildings, tin cans, mailboxes or unorthodox places such as pockets of hanging jackets in sheds or in a tractor in everyday use.[3][14] Nests are from 1ÿ3?m (3.3ÿ9.8?ft) from the ground and are rarely higher. They occasionally can be built in sloping locations or at ground level.[3]\\r\\n\\r\\nEgg laying dates and clutch size vary by region; in Texas the time period is from late February to late August, in Iowa it ranges from late April to June.[12][19] The clutch size is generally 3 to 6 eggs, but can reach as high as seven in Texas.[3][12] The eggs are creamy white with brown or reddish-brown spots, and are more heavily marked at the broad end.[3] The eggs are incubated by the female for 12ÿ16 days. After the young hatch, they are fed exclusively on invertebrates and they fledge in 12ÿ14 days. As many as three broods may be raised by a pair in a single breeding season.[3] In one study, three of the 70 fledglings remained or defended territory adjacent to the natal area.[15]\\r\\n\\r\\nMale and females are involved in the process of provisioning at similar rates throughout most nest stages, with the males providing slightly more in the nestling stages. Both sexes increase their provision rates as the nestlings grow in age.[33]\\r\\n\\r\\nBrood parasitism by brown-headed cowbirds is common, with up to 25% of Carolina wren nests being affected in certain regions such as Oklahoma and Alabama.[3][15] Cowbird parasitism peaks in April at 41%, and is as low as 8% and 0% in July and August, respectively. Female cowbirds sometimes eject Carolina wren eggs before laying their own, and even if host eggs are retained, the size of cowbird eggs negatively affect the hatching success of wren eggs. As a result, cowbirds may have a significant impact on the reproductive success of wrens.[3][15] The feeding rate for cowbird nestlings is higher than wren feeding rates, and some have been raised to independence.[15] This also can be detrimental to the survival of wren nestlings.[15] A rare instance of brood-parasitism by a house finch has been recorded.[15][34] The rate of brood parasitism is thought to be lower in more natural and concealed nesting locations.[15] Body parasites such as the larvae of blowflies feed on nestlings and the blood loss weakens nestlings.[15] Fellow species of wren such as Bewick's wren and the winter wren compete for nesting locations and food, respectively.[15]\\r\\n\\r\\nIn Virginia, some Carolina wrens populations show high levels of mercury in their blood and this is acquired from feeding all-year-round on spiders.[35][note 2] Spiders being at a higher trophic levels contain a higher concentrations of mercury (through biomagnification) than herbivorous invertebrates. As these wrens are year-round residents, they are at a higher risk than other species to acquire mercury in its blood. Nest abandonment and failure to raise young were more common with higher mercury content.[35] Exposure, and prolonged periods of cold, ice, and snow is thought to affect the wren nestling and adult populations, respectively.[15] Wrens that outlast those winters reside in sheltered areas during the season.[14]\\r\\n\\r\\nAmong the top predators of adult Carolina wrens are domestic cats, and snakes such as the timber rattlesnake.[36][37] Raccoons and black rat snakes also feed on wren eggs and nestlings.[15]\\r\\n\\r\\nIn 1930, the South Carolina Federated Women's club adopted the Carolina wren as the unofficial state bird over the eastern mourning dove and pushed for its official state adoption until 1939, when the South Carolina Legislature named the northern mockingbird as the state bird. In 1948, the legislature repealed their previous decision, and the wren became the official state bird.[38]\\r\\n\\r\\nIn 2000, the Carolina wren was featured on the back of the South Carolina edition of the 50 State Quarters.[39]","input":"How long does it take carolina wrens to fledge?"},{"output":"May 3, 1999","context":"The Venetian Resort Hotel Casino is a five-diamond luxury hotel and casino resort located on the Las Vegas Strip in Paradise, Nevada, United States, on the site of the old Sands Hotel. Designed by KlingStubbins, the hotel tower contains 36 stories and rises 475 feet (145?m). The Venetian is owned and operated by Las Vegas Sands. The Venetian also serves as the seat of the corporate headquarters for its parent company.\\r\\nThe Venetian resort complex is (together with the adjacent Sands Expo Convention Center and The Palazzo Hotel and Casino Resort) the world's second-largest hotel, with 4,049 rooms, 3,068 suites ranging in price from $169 to $10,000 per night and a 120,000-square-foot (11,000?m2) casino.[1] Since its opening, The Venetian Macao is the largest casino in the world, trumping The Venetian, Las Vegas.\\r\\n\\r\\n\\r\\nIn April 1996, Sheldon Adelson announced plans to create on the property the largest resort on the Strip. This project would be situated on the former Sands property. On November 26, 1996, eight years after it was purchased by the owners of The Interface Group - Adelson, Richard Katzeff, Ted Cutler, Irwin Chafetz and Jordan Shapiro, the Sands Hotel was imploded to make way for The Venetian Resort Hotel Casino. Groundbreaking for the hotel began on April 14, 1997.\\r\\nThe resort opened on May 3, 1999, with flutter of white doves, sounding trumpets and singing gondoliers, with actress Sophia Loren joining The Venetian Chairman and Owner, Sheldon G. Adelson, in dedicating the first motorized gondola. Built at a cost of $1.5 billion, it was one of the most expensive resorts of its kind when it opened.\\r\\nOn June 27, 2003, the 1,013-room Venezia Tower opened. It was built on top of the garage parking lot.\\r\\nin 2010, it was announced that it will be affiliated with InterContinental Hotels Group.[2]\\r\\nIn October 2011, the Cantor Race & Sportsbook opened, which was the only Las Vegas sportsbook that was open 24 hours a day. On June 11, 2012, the Venetian opened Carnevale, a summer-long festival that is anchored by a nightly 3-D projection show on the clock tower. In September 2012, The Blue Man Group show closed and relocated to the Monte Carlo, after being at the Venetian for six years.\\r\\nThe hotel uses Venice, Italy, as its design inspiration and features architectural replicas of various Venetian landmarks, including the Palazzo Ducale, Piazza San Marco, Piazzetta di San Marco, the Lion of Venice Column and the Column of Saint Theodore, St Mark's Campanile, and the Rialto Bridge. The design architects for this project were The Stubbins Associates and WAT&G. Interior design was provided by Wilson Associates and Dougall Associates for the casino.[citation needed]\\r\\nIn October 2001, the Guggenheim Hermitage Museum opened within the resort, featuring its first collection. On June 27, 2003, the Venezia tower opened, adding 1,013 suites and a new wedding chapel. In October 2005, Blue Man Group officially opened at the Blue Man Theatre. On June 24, 2006, the show, Phantom: The Las Vegas Spectacular, opened at a new Paris Opera House styled theatre at The Venetian. The show concluded on September 2, 2012.[3]\\r\\nTim McGraw and Faith Hill headlined their Soul2Soul concert series which began in December 2012 and ended in April 2014.\\r\\nThe Venetian is home to 4 theaters: the Opaline Theatre, The Palaazo Theatre, The Sands Showroom, and The Venetian Theatre.\\r\\nIn 2015, TAO Nightclub generated over $50 million in revenue, according to Nightclub & Bar Top 100.[4] With an Asian-inspired theme, TAO features a 20 foot tall Buddha statue, an infinity edge pool stocked with koi, eight private \\"sky boxes\\" with mini-bars, a 40-foot-long terrace with views of the strip, and two dance rooms.[5]\\r\\nTAO Beach, located on top of TAO Nightclub, is the Venetian's day club and pool party. It offers seven cabanas, each with television, DVD player, Xbox 360, a stocked mini-fridge and a safe for valuables.[6]\\r\\nIn 2004, the Venetian agreed to pay a $1 million penalty to settle a 12-count Gaming Control Board complaint. One of the 12 complaints alleged the hotel had held a drawing for a Mercedes-Benz that was rigged to be won by a high roller who had lost a large amount in the casino.[7] The executives involved were fired.[7]\\r\\nIn 2013, the Venetian agreed to pay the U.S. Department of Justice $47.4 million to settle charges over \\"alleged money laundering activities.\\"[8]\\r\\nThe Rialto Bridge at the Venetian\\r\\nView of the outside Gondola rides from second floor balcony just outside the casino.\\r\\nAnother outside view of the front from the balcony, at night.\\r\\nThis grand gallery connects the reception area and the casino.\\r\\nThe centerpiece of the Grand Canal Shoppes entrance hall ceiling.\\r\\nSt. Mark's Square at the Grand Canal Shoppes is surrounded by restaurants and shops. It is also the site of live costumed shows.\\r\\nThis small, but striking Venezia reception area is located on the 10th floor of the Venetian/Palazzo complex.\\r\\nThe Venetian Las Vegas\\r\\nThe Venetian Las Vegas (interior)\\r\\nSt. Mark's Campanile at the Venetian\\r\\nCoordinates: 360717N 1151008W? / ?36.12139N 115.16889W? / 36.12139; -115.16889","input":"When was the venetian hotel in las vegas built?"},{"output":"July 21, 2010","context":"","input":"When did the consumer protection act came into effect?"},{"output":"Spanish","context":"Many different languages are spoken in Mexico. The indigenous languages are from eleven distinct language families, including four isolates and one that immigrated from the United States. The Mexican government recognizes 68 national languages, 63 of which are indigenous, including around 350 dialects of those languages. The large majority of the population is monolingual in Spanish. Some immigrant and indigenous populations are bilingual, while some indigenous people are monolingual in their languages. Mexican Sign Language is spoken by much of the deaf population, and there are one or two indigenous sign languages as well. \\r\\n\\r\\nThe government of Mexico uses Spanish for most official purposes, but in terms of legislation, its status is not that of an official primary language. The Law of Linguistic Rights establishes Spanish as one of the country's national languages, along with 63 distinct indigenous languages (from seven large families, and four considered language isolates). The law, promulgated in 2003, requires the state to offer all of its services to its indigenous citizens in their mother tongues, but in practice this is not yet the case. Note that, as defined by mutual intelligibility, the number of spoken languages in Mexico is much greater than the 63 national languages, because National Institute of Indigenous Languages (INALI) counts distinct ethnic groups for the purposes of political classification. For instance, the Mixtec are a single ethnicity and therefore count as a single language for governmental/legal purposes, but there are a dozen distinct Mixtec dialect regions, each of which includes at least one variety that is not mutually intelligible with those of the other dialect regions (Josserand, 1983), and Ethnologue counts 52 varieties of Mixtec that require separate literature. Ethnologue currently counts 282 indigenous languages currently spoken in Mexico, plus a number of immigrant languages (Lewis et al. 2018).\\r\\n\\r\\nDue to the long history of marginalization of indigenous groups, most indigenous languages are endangered, with some languages expected to become extinct within years or decades, and others simply having populations that grow slower than the national average. According to the Commission for the Development of Indigenous Peoples (CDI) and National Institute of Indigenous Languages (INALI), while 10ÿ14% of the population identifies as belonging to an indigenous group, around 6% speak an indigenous language.\\r\\n\\r\\nThere are other languages not native to Mexico that are spoken in the country. Besides Spanish, the most populous are probably English, German (Plautdietsch), Arabic, Chinese and Japanese.\\r\\n\\r\\nFrom the arrival of the first Franciscan missionaries, Spanish, Latin, and indigenous languages played parts in the evangelization of Mexico. Many sixteenth-century churchmen studied indigenous languages in order to instruct native peoples in Christian doctrine. The same men also found Castilian and Latin appropriate in certain contexts. All told, there existed a kind of \\"linguistic coexistence\\" from the beginning of the colonial period.[1]\\r\\n\\r\\nSome monks and priests attempted to describe and classify indigenous languages with Spanish. Philip II of Spain decreed in 1570 that Nahuatl become the official language of the colonies of New Spain in order to facilitate communication between the natives of the colonies.[2]\\r\\n\\r\\nIn 1696 Charles II reversed that policy and banned the use of any languages other than Spanish throughout New Spain.[2] Beginning in the 18th century, decrees ordering the Hispanization of indigenous populations became more numerous and Mexican colonizers no longer learned the indigenous languages.\\r\\n\\r\\nAfter the independence the government initiated an educational system with the primary aim of Hispanization of the native populations. This policy was based on the idea that this would help the indigenous peoples become a more integrated part of the new Mexican nation.[3][4]\\r\\n\\r\\nExcept for the Second Mexican Empire, led by the Habsburg Maximilian I, no Mexican government tried to prevent the loss of indigenous languages during the 19th century.[3]\\r\\n\\r\\nIn 1889, Antonio Garca Cubas estimated that 38% of Mexicans spoke an indigenous language, down from 60% in 1820. By the end of the 20th century, this figure had fallen to 6%.\\r\\n\\r\\nFor most of the 20th century successive governments denied native tongues the status of valid languages. Indigenous students were forbidden to speak their native languages in school and were often punished for doing so.[3][4][5][6][7][8]\\r\\n\\r\\nIn 2002, Mexico's constitution was amended to reinforce the nation's pluricultural nature by giving the State the obligation to protect and nurture the expressions of this diversity. On June 14, 1999, the Council of Writers in Indigenous Languages presented Congress with a document entitled \\"Suggested legal initiatives towards linguistic rights of indigenous peoples and communities\\", with the goal of beginning to protect the linguistic rights of indigenous communities. The Ley General de Derechos Lingsticos de los Pueblos Indgenas was passed in March 2003, establishing a framework for the conservation, nurturing and development of indigenous languages. Critics claim that the law's complexity makes enforcement difficult.[9][10][11][12][13]\\r\\n\\r\\nSpanish is the de facto national language spoken by the vast majority of Mexicans, though it is not defined as an official language in legislation. The second article of the 1917 Constitution defines the country as multicultural, recognizes the right of the indigenous peoples to \\"preserve and enrich their languages\\" and promotes \\"bilingual and intercultural education\\".\\r\\n\\r\\nIn 2003, the Mexican Congress approved the General Law of Linguistic Rights of the Indigenous Peoples, which recognizes that Mexico's history makes its indigenous languages, \\"national languages\\".[14] Accordingly, they \\"have the same validity [as Spanish] in their territory, location and context\\". At the same time, legislators made no specific provisions for the official or legal status of the Spanish language. This law means that indigenous peoples can use their native language in communicating with government officials and request official documents in that language. The Mexican state supports the preservation and promotion of the use of the national languages through the activities of the National Institute of Indigenous Languages.[15][16][17]\\r\\n\\r\\nMexico has about six million citizens who speak indigenous languages. That is the second-largest group in the Americas after Peru. However, a relatively small percentage of Mexico's population speaks an indigenous language compared to other countries in the Americas, such as Guatemala (42.8%), Peru (35%), and even Ecuador (9.4%), Panama (8.3%),[18] Paraguay and Bolivia.\\r\\n\\r\\nThe only single indigenous language spoken by more than a million people in Mexico is the Nahuatl language; the other Native American language with a large population of native speakers include Yucatec Maya.\\r\\n\\r\\nAccording to the Law of Linguistic Rights, Mexico recognizes sixty-two indigenous languages as co-official National languages [19] with Spanish being the dominant language, Mexico has become a site for endangered languages. \\"Indigenous peoples disadvantaged socioeconomic status and the pressure of assimilation into mestizo or Ladino society have been influential on indigenous language loss.\\"[20] The result of the conflict between indigenous languages and Spanish has been a language shift in Mexico from indigenous languages being spoken to more people using Spanish in every domain. Due to this situation there have been many different language revitalization strategies put in place in Mexico to try to reverse this language shift. See  literature on projects done with the Nahua people [21] and the experiences of language revitalization in the South of Mexico.[22]\\r\\n\\r\\n1 Including: pata, Soltec, and Papabucan\\r\\n\\r\\nThe following is a classification of the 65 indigenous languages grouped by family:\\r\\n\\r\\nLanguage families with members north of Mexico\\r\\n\\r\\nLanguage families with all known members in Mexico\\r\\n\\r\\nLanguage family with members south of Mexico\\r\\n\\r\\nLanguage isolates:\\r\\n\\r\\n*In danger of extinction.\\r\\n\\r\\nThe deaf community uses Mexican Sign Language, Yucatan Sign Language, and, in northern Baja California, American Sign Language.\\r\\n\\r\\nThe non-indigenous languages spoken in Mexico include English (by English-speaking as well as by the residents of border states). One example of this group is of the American Mormon colony of Nueva Casas Grandes in Chihuahua, which settled in the late 19th century. German (spoken mainly in Mexico City and Puebla), Greek (spoken mainly in Mexico City,  Guadalajara and especially in Sinaloa state), Arabic, Venetian (in Chipilo), Italian, French, Occitan, Catalan, Basque, Galician, Asturian, Filipino, Polish, Hebrew, Korean, Ladino, Plautdietsch, Armenian, Japanese, Chinese and other languages are spoken by smaller numbers. Some of these languages (Venetian and Plautdietsch) are spoken in isolated communities or villages. The rest are spoken by immigrants or their descendants who tend to live in the larger cities and towns.\\r\\n\\r\\nAs far as second languages go, many educated Mexicans (and those with little education who have immigrated to the US and returned) have different degrees of fluency in English. Many Mexicans working in the tourist industry can speak some English.\\r\\n\\r\\nRomani is spoken by the Mexican gypsies.[23]","input":"What is the most common language in mexico?"},{"output":"Rocky Marciano","context":"Robert \\"Rocky\\" Balboa is the title character of the Rocky series. The character was created by Sylvester Stallone, who also portrayed him in all seven Rocky films. He is depicted as an everyman who started out by going the distance and overcoming obstacles that had occurred in his life and career as a professional boxer. While he is loosely based on Chuck Wepner, a one-time boxer who fought Muhammad Ali and lost on a TKO in the 15th round, the inspiration for the name, iconography and fighting style came from boxing legend Rocky Marciano.\\r\\nThe character is widely considered to be Stallone's most iconic role and is often considered the role that started his film career.[1] He received critical acclaim for his performance in the first movie, earning Academy Award and Golden Globe Award nominations. When Stallone reprised his role once again in 2015 for Creed, his performance received wide acclaim and he received his first Golden Globe Award for Best Supporting Actor, along with his third Oscar nomination for Best Supporting Actor, the National Board of Review Award for Best Supporting Actor and several other accolades.\\r\\n\\r\\n\\r\\nRobert \\"Rocky\\" Balboa was born in Philadelphia, Pennsylvania, on July 6, 1945 (one year before Sylvester Stallone's actual birth date). He was the only child in a Roman Catholic Italian-American family. The surname Balboa/Valboa (roughly meaning \\"beautiful valley\\") originates from a Galician-speaking town in Northwestern Spain, so it is likely he had some Iberian ancestry as well. When Rocky is spoken to by his priest, Father Carmine, it is apparent that he understands Italian very well, including a scene in which he translates for Tommy Gunn; however, it is undetermined how well he actually speaks the language as his responses are always in English.\\r\\nDuring the scene in which Rocky takes Adrianna \\"Adrian\\" Pennino skating on Thanksgiving, he tells her, \\"Yeah ÿ My ol' man, who was never the sharpest, told me ÿ I weren't born with much brain, so I better use my body.\\" This encouraged him to take up boxing. He trained very hard so he could grow up to be like his idol Rocky Marciano. Unable to live on the small pay of club fights, and being unable to find work anywhere else, Rocky got a job as a collector for Tony Gazzo, the local loan shark, just to make ends meet. By late 1975, Rocky had fought in 64 fights, winning 44 (38 KO'S) and losing 20. Rocky was proud that he never had his nose broken in a professional fight. His nickname is \\"The Italian Stallion\\", spawning from his Italian-American heritage.\\r\\nThe film begins on November 25, 1975, in the slums of the Kensington section of Philadelphia. Rocky Balboa is fighting Spider Rico in a local boxing ring called the Cambria Fight Club (nicknamed \\"The Bucket of Blood\\") inside a chapel. In the second round, Rico hits Balboa with a headbutt, leaving a gash on his forehead. Enraged, Rocky delivers a vicious barrage of punches, knocking Rico out. The next day, Rocky stops by the J&M Tropical Fish pet store, and tries to talk to the shy pet-shop worker, Adrian Pennino. Adrian is very shy and scared of Rocky's tough appearance. Afterwards, Rocky goes to collect a loan for his loan shark boss, Tony Gazzo. Even though the client, Bob, didn't have all the money, Rocky didn't break his thumb, even though Gazzo ordered him to do so. Later, Rocky stops by the local boxing gym and finds that his locker was replaced by another local contender. Unknown to him, the gym's owner and grizzled former boxer, Mickey Goldmill, doesn't dislike him, but instead, always considered Rocky's potential to be better than his effort. When Rocky leaves for home that night, he sees a young girl named Marie, hanging around a bad crowd and walks her home. On the way, Rocky lectures her about staying away from the wrong people. However, once they get to her house, she tells Rocky \\"Screw you, creep'o.\\" Rocky walks home, frustrated how nothing is going right in his life.\\r\\nBalboa gets his big break when the undisputed World Heavyweight Champion Apollo Creed decides that he wants to give an unknown fighter a chance to fight for the title after his intended challenger, Mac Lee Green, broke his hand while training. Creed was told no other contender was available for a fight on New Years Day, which is only a month away in commemoration for the United States Bicentennial, it was inferred by Creed, with the accompanying worldwide audience. Creed chooses Rocky because he likes Balboa's nickname, 'The Italian Stallion'.\\r\\nAfter getting picked by Apollo, Balboa reunites with his estranged trainer, Mickey Goldmill, who convinces Balboa that he can help get him prepared for this match. Mickey reveals that his career never got anywhere either, because he didn't have a manager, and he didn't want the same thing to happen to Rocky. At the same time, Balboa begins dating Adrian. Rocky helped Adrian to become more self-confident and stand up for herself. Rocky confides in Adrian before the fight that though he figured he wouldn't win, he wanted to at least \\"go the distance.\\"\\r\\nOn January 1, 1976, at the Philadelphia Spectrum, Balboa has his match Creed, who didn't take the fight seriously during training. In the first round, Rocky knocks Creed down, the first time he had ever been knocked down in his career, and Creed breaks Rocky's nose, also for the first time in his career. Creed soon realizes that, although Balboa doesn't have his skill, he could deliver crippling, sledge-hammer like punches, and was stubbornly determined to keep fighting. The match becomes a long and grueling battle for both men. Rocky was almost knocked out in the 14th round, but managed to get back up, and deliver some hard body shots, breaking Creed's ribs just before the bell. The 15th round finally began, and Rocky managed to pummel Creed until the bell rang. Although Creed wins the match by a split decision, it was the first time an opponent has lasted the full 15 rounds against him. Both men, battered beyond belief, agree that there would be no rematch. Rocky was fine with this as he only wanted to go the distance with Creed. After the match, Adrian climbed into the ring and embraced Rocky saying, \\"I love you!\\"\\r\\nAfter the match, Creed changes his mind and demands a rematch under the stress of being humiliated by the press for failing to beat Balboa convincingly, as well as his own knowledge that he didn't give his best in the fight. Creed demands a rematch with Balboa, stating that he would fight him 'anywhere, any place, anytime' to prove to the world that Balboa's feat was merely a fluke. Rocky initially declines and retires from boxing, having surgery for retinal detachment, a condition that could lead to permanent blindness. He marries Adrian, who convinces him to live outside boxing. However, Rocky, a grade-school drop-out, soon realizes that he has no white-collar skills beyond the eighth grade, and in fact, he can barely read. The money he made in his real first match is easily and quickly frittered away, so Adrian re-claims her part-time job at the J&M Tropical Fish pet store. At first, Rocky seems to be unaffected by Apollo's smear campaign, but his inexperience with money causes him to run into financial troubles. Rocky struggles to find employment with decent pay, where he is fired from a commercial studio, turned down on an office job, and even laid off at the Shamrock Meat Packing facility. Despite Adrian's objections, after Apollo insults Rocky on national television and the newspaper, he agrees to the rematch. Without Adrian's support, however, Rocky becomes greatly discouraged, and could not draw any concentration into his training whatsoever, leaving Mick frustrated and worried. The now-pregnant Adrian goes into mental labor on the job due to over stress, and slipped into a coma after giving birth to her first child, Robert Jr. When Adrian is out of the coma, she promises her full support to Rocky. Together, Mickey and Rocky train hard, focusing on Rocky's speed and improving his right-handed punching (Rocky being a southpaw). At the same time, Apollo also focused on his training, taking this match much more seriously than the first one. The rematch is set for Thanksgiving. The match goes on for the full 15 rounds, with both Balboa and Creed falling to the canvas after Balboa lands a succession of left hands. Referee Lou Fillipo exercises his 10-count to the limit, and as both Creed and Balboa struggle to get back up, Creed falls back down in exhaustion. Rocky is able to get back up, from sheer determination and beat the 10-count, winning the rematch by knockout, thus becoming heavyweight champion of the world.\\r\\nOver the next three years, Rocky has successfully defended his title in 10 consecutive defenses against various contenders, amassing fortune, and worldwide fame in the process. In addition, Rocky also has an exhibition match against the World Heavyweight Wrestling Champion, \\"Thunderlips\\" (Hulk Hogan), with the match ending in a draw. However, in 1981, Rocky is challenged by an intense newcomer named James \\"Clubber\\" Lang (Mr. T), who has risen to the top of the rankings. Rocky begins having some issues with his trainer Mickey Goldmill due to his revelation of having faced \\"hand-picked\\" challengers that were \\"good fighters, but not 'killers'\\" which Lang seemingly is. Mickey insists that he would step down as Balboa's manager, if he chooses to fight Lang, but Rocky convinces him to train him for one last match. However, just like Apollo in the first film, Rocky does not put his heart into the training, and this reinforces Mickey's belief, that Rocky has become too comfortable (or \\"civilized\\") as champion. Before the match, pandemonium erupts backstage, with Lang shoving Mickey out of the way during a violent exchange of words with Balboa, sending the elderly trainer into cardiac arrest. Distraught over Lang's cold indifference, Rocky requests to call the match off, but Mickey and others urge him on, so Rocky goes to fight Lang no matter what. During the match, Rocky is brutalized by Lang and knocked out in the second round, losing his title; and adding to his defeat, Mick dies of a heart attack after the match, devastating Rocky. After the funeral, a depressed Rocky wanders the streets of Philadelphia until seeing the statue at the steps. In a fit of rage, Rocky throws his motorcycle helmet at the statue, and takes off until entering the now-abandoned Micky's gym. Despairing and lost, Rocky meets Apollo Creed inside the darkened gym, who explains to Balboa that when they fought, he won because he was competitive. He has the 'fire' Apollo no longer has, and the former champion convinces Rocky that he needs to get his fire (\\"the eye of the tiger\\") back. Along with his old trainer, Tony \\"Duke\\" Evers, Apollo offers to train Rocky for a rematch against Lang, taking Balboa to Los Angeles. While training on the beach, Adrian and Rocky furiously debate, while Apollo trains Rocky to help him get him \\"back to basics.\\" After a while, Rocky manages to put his doubts behind him and retain his spirits. Fighting with a style very reminiscent of Creed's own boxing technique mixed with his own style, Rocky wins the rematch against Lang by KO, dodging and absorbing Lang's best blows and still standing, regaining his world heavyweight title. After the match, Rocky and Apollo meet again in Mickey's Gym, with Creed taking his \\"payment\\" for his training services: one last rematch, just the two of them, and no spectators.\\r\\nIn 1985, Apollo Creed agrees to have an exhibition match against Soviet World Amateur Champion and Olympic Gold Medalist-turned-professional fighter Ivan Drago (Dolph Lundgren) in Las Vegas, with Rocky Balboa and Tony \\"Duke\\" Evers in his corner. Creed, past his prime but in the best shape, again not taking his opponent seriously, takes a serious beating by Drago in the first round, despite Rocky's orders to stop the fight. In the second round, Creed continues to be brutally beaten by Drago, falling limp in the ring and succumbing to his injuries, never to be alive again. Feeling responsible for Apollo's death and riddled with guilt by Drago's cold indifference, Balboa decides to take on Drago himself, but to do so, he has to surrender his championship. Rocky travels to the cold mountains of Russia and undergoes rigorous training. After much-needed training, his match against Drago takes place on Christmas Day in Moscow. With Evers assuming the role as his new trainer, Balboa trained hard using old-school methods within the mountainous terrain of Krasnoyarsk, Siberia, while Drago trained with state-of-the-art equipment and steroid enhancement.\\r\\nDuring the match, Drago gains the upper hand in the early moments of the match, but in the second round, Balboa strikes back against Drago with a haymaker to the eye, cutting him. The match goes on in a bloody back-and-forth battle, with the Soviet crowd, who originally roots for Drago, begins cheering for Balboa, while Drago's handler becomes increasingly upset over his inability to finish Rocky. In the end, Rocky's superior stamina and determination to win perseveres and defeats the heavily-favorited Russian in the fifteenth round. After the match, Rocky gives an passionate thank you speech to the crowd while receiving a standing ovation both from the crowd and the politicians in attendance, effectively ending the Cold War by catalyzing the thaw in relations that would occur between the United States and the Soviet Union.\\r\\nAfter the bout with Drago, Rocky realizes that while he is showering, he has sustained some type of injury from the fight. His hands tremble relentlessly, and he tells Adrian that he is tired and wants to go home, but accidentally addresses her as Mickey. Upon returning to the United States (in a Soviet airplane), his press conference is interrupted by promoter George Washington Duke and Union Cane. They challenge him to a title fight called \\"Lettin' it Go in Tokyo.\\" Rocky hints about retirement and leaves without accepting the challenge. Once returning home, Rocky goes to say goodnight to his son, Robert Jr., but once Rocky goes downstairs, he overhears Adrian and Paulie arguing, which turns out to be a dramatic life-changing situation. Paulie unknowingly had Rocky signed a power of attorney over to Rocky's investment accountant, who had embezzled and squandered all of his money on real estate deals gone sour. In addition, the accountant had failed to pay Rocky's taxes over the past six years, and his mansion was mortgaged by $400,000. Unwilling to go bankrupt, Rocky decides to participate in a few more fights, including the one against Union Cane, but Adrian demands Rocky to see a doctor first before doing so. Balboas doctor, Presley Jensen, performs computer-simulated examinations, which reveals that Rocky is diagnosed with a condition called Cavum septum pellucidum, which is brain damage caused by extremely heavy blows to the head. The effects are seemingly permanent and irreversible. With such a condition, it would make it impossible for Rocky to continue boxing in any state. At Adrian's urging, as well as the doctor's support, Rocky acknowledges that it is time to retire, and he reluctantly does so.\\r\\nHis only remaining asset is the now-closed Mickey's Gym, which had been willed by Mickey to Robert, making it untouchable by the IRS. After selling their mansion and auctioning some of their belongings, Rocky and the family now return to the old neighborhood, moving back into Adrian and Paulie's old house in South Philadelphia. Rocky reopens Mickey's Gym as a means of income, while Adrian returns to work at the J&M Tropical Fish pet store, where she was employed when she first met Rocky. Rocky asks Adrian, \\"Did we ever leave this place?\\" One day, Rocky meets a young ruffian boxer from Oklahoma named Tommy Gunn, and begins training him. Tommy slowly becomes an excellent fighter, but suffers some from being constantly put in Rocky's shadow; he is nicknamed \\"Rocky's Robot\\" by the media. As Rocky is training Tommy, he becomes so distracted, he ends up neglecting Robert. By Christmas Eve, Duke visits the Balboa residence, but Rocky explains that dealing with Duke would be dirty business. Late at night, Tommy regrets being Rocky's protg, and leaves him for good. Adrian attempts to comfort Rocky, but Rocky's frustration boils over. After they reconcile, Rocky meets Robert, and they finally pick up the pieces.\\r\\nRocky is still anxious as he watches the match with Tommy facing off against Union Cane on television along with Paulie. As the match starts out small, Rocky begins to emote through the first couple of seconds of the fight as Cane becomes effective in hurting Tommy. As Tommy begins to make his adjustments as Rocky taught him, Rocky then mirrors his punches on a punching bag, which disturbs his family. Tommy wins the World Heavyweight title from Union Cane by knockout. Visibly proud of Tommy, Rocky is surprised that Tommy credited his success to Duke instead. However, Tommy is booed and ridiculed in the presssince he had never gone against a \\"real contender,\\" he is not regarded as a real champion or heir to the belt. This motivates Tommy, with prodding from Duke, to publicly challenge Rocky to a fight.\\r\\nWhile Rocky is at a local bar, Tommy steps in and insults Rocky. Paulie responds by sucker punching Tommy. Rocky rapidly confronts Tommy, and challenges him. Rocky explains to Tommy that his ring is in the alley right outside. As both fighters head to the alley, Duke tries to persuade Tommy to not fight a street fighter, but Tommy squares up on him, saying that he does not own him, and wants his respect.\\r\\nRocky then starts to beat Tommy quickly without giving him a chance, knocking him down. Rocky tells Tommy that, even though he admired him, he actually ruined their relationship. With Rocky's back turned, Tommy sucker punches him, and also starts attacking some of the bystanders on the side. Tommy gains the upper hand and tackles Rocky through a steel door into the street. The two engage in a street fight, which quickly garners attention of the media, which catches Robert and Adrian's attention as well. As the neighborhood gather around to witness the fight, Tommy's punches begin to slow down Rocky in his tracks due to his condition, and is knocked down, disoriented with Paulie at his side. Tommy is then restrained from finishing Rocky off.\\r\\nGlimpses of Ivan Drago, his loss to Clubber Lang during his first fight with him, and Mickey's burial start to cloud his mind until he hears Mickey's voice, telling him that he is the champion and to get up. As Tommy walks away, convinced that he finally got what he wanted, Rocky rises up and calls him out for one more round, and Tommy happily obliges. An adamant Duke reminds Tommy that if he loses this, he will terminate their partnership. In a turn of events, Rocky uses his brawling abilities to punish and humiliate Tommy. With his back toward a gate, Rocky dodges several hooks from Tommy and manages to push him towards the gate, shove him with brute force, and a powerful left hook to knock Tommy down again. Duke, who threatened to sue Rocky if he touched him, becomes infuriated at Tommy. Tommy gets up and tackles Balboa to the ground, and later lifts him up. Just as Robert joins the crowd, Rocky breaks free from Tommy's grip, performs a reversal that sends Tommy spiraling into a pile of trash cans. Both men now exchange punches with Rocky being the aggressor, making Tommy miss his shots. Rocky is then caught by a series of punches by Tommy, just as Adrian joins the crowd, but then manages to parry Tommy, and begins to walk him down with his devastating shots. Seeing the opportunity, Rocky goes to Tommy's body, then lands perfect headshots, and finishing with a right uppercut that sends Tommy to the grill of a bus, defeating his former protg. As Adrian and Robert tend to him, Rocky tells Adrian that she was right. The neighborhood's cheer is then silenced by Duke as he tries to sarcastically commend Rocky. He confronts Duke, who still continues to threaten him with a lawsuit. Clenching his fist, he uppercuts Duke to the gut which lifts him off the ground, sending him to the hood of his own limousine, telling him \\"Sue me for what?\\" Rocky, Adrian, Robert, and Paulie walk away in good spirits as the neighborhood continue to cheer him on.\\r\\nSometime later, Rocky and his son run up the Philadelphia Museum of Art, where Rocky gives him a valuable possession of Mickey Goldmill's, that had been passed on to him by Rocky Marciano. The two make up for the tensions of the past few years, and head into the museum together.\\r\\nIn 2006, 20 years after the events of Rocky V, Rocky, now in his late fifties, lives a quiet live as a widower. He runs a small but rather successful restaurant called 'Adrian's', named after his wife who, on January 11, 2002, died of ovarian cancer. Rocky is no longer broke, and doing far better than he was in the years prior. Rocky visits Adrian's graveside regularly and each year, on the anniversary of her death, takes a tour of the old places, where their relationship began and blossomed: the now-closed J&M Tropical Fish pet shop where Adrian worked, the former site of the ice skating rink where they had their first date, and Rocky's old apartment, where they fell in love. Rocky's son, Robert Jr., is now working as a struggling mid-level corporate employee, and grows farther apart from his family over the years, but reluctantly joins Rocky to commemorate the anniversaries of his mother's death.\\r\\nAn episode of ESPNs program, Then and Now, airs featuring a computer animated fight simulation between Rocky (in his prime), and the current champion, Mason \\"The Line\\" Dixon. The simulation result sees Rocky winning by knockout in the thirteenth round, which stirs up discussion about the result if such a fight ever occurred. Inspired by the simulation and feeling he still has some issues to deal with (\\"stuff in the basement\\"), Rocky decides to return to the ring, and applies to renew his boxing license. Though Rocky passes the required physical with flying colors, the licensing committee denies his application, citing his advanced age and their moral duty to protect him from himself. Rocky responds to this with an impassioned speech of his own, however, and they change their minds to renew his license.\\r\\nThe brain damage Balboa is diagnosed with in Rocky V is not addressed in this film, but in interviews, Stallone has said that the storyline explanation would have been that Rocky's brain damage was within the normal range for boxers. When tested for brain damage in Rocky V, Rocky was suffering the effects of a severe concussion as a result of the Drago fight, but he never sought a second or more informed opinion because he intended to retire anyway.[2]\\r\\nRocky's intentions were originally just to compete in small, local fights for fun and charity, but with the publicity of Rocky's return right on the heels of the embarrassing computer simulation, Mason Dixon's promoters convince Rocky to challenge the champ in an exhibition match at the MGM Grand in Las Vegas. Originally, also against fighting an aged Balboa, Dixon recognizes the opportunity to fight a legend, and hopes to end all prognosticating about who would win as well as contentions that he has never had a truly great opponent or memorable match. In the press, commentators dismiss Rocky's chances and the merits of the fight, assuming that it will be one-sided due to Rocky's age, despite their original excitement with Rocky's return to the ring, and their doubts regarding Dixon's ability.\\r\\nAs news of the bout spreads, Robert begins to feel more pressure from being Rocky's son, and makes an effort to discourage Rocky from fighting, blaming his own personal failings on his father's celebrity shadow, but Rocky rebukes him with some profound advice: to succeed in life, \\"it ain't about how hard you hit; it's about how hard you can get hit, and keep moving forward,\\" and that blaming others won't help him. The day after this debate, father and son meet over Adrian's grave and reconcile, which is when Robert announces that he has resigned from his job to be at Rocky's ringside. Rocky also reunites with his old trainer, Duke, and both men quickly realize that age and arthritis have sapped Rocky of any speed he once possessed. They decide to focus on his one major remaining weapon: power.\\r\\nWhen the match finally begins, it appears to go as lopsided as everyone predicted, with Dixon's speed allowing him to punish Rocky at will, knocking him down twice early on. However, the champion soon realizes Rocky will not back down, and that the elderly Rocky \\"has bricks in his gloves\\". The tide turns when Dixon injures his hand while punching Rocky. This evens the playing field and allows Rocky to mount an offense, knocking Dixon down for the first time in the latter's career. During the subsequent rounds, Dixon's injury numbs up, which enables him to throw much harder punches and thereby pose a threat to Rocky. In the final round, it starts out slow for both combatants. After a brief exchange of punches, Dixon catches Rocky with a strong blow, knocking down Rocky for the third time. As Rocky takes the knee, he looks to Robert in the corner and has flashbacks of his time with Adrian, remembering what she said to him about never giving up. As he slowly gets up, the crowd, along with Marie, starts to chant his name, and he rises to Dixon's surprise. As the final thirty seconds unfold, Dixon manages to catch Rocky with quick punches; however, an emotional Rocky retaliates with devastating punches of his own. The two exchange punches, but Rocky gets the final blow before the bell rings. In the end, the two fighters go the distance and show their appreciation for each other. Before the winner is announced, Rocky and his entourage make their way out of the ring in celebration. As Dixon is announced the winner by split decision (Dixon wins in the theatrical release, Balboa wins in an alternate ending [3]), Rocky thanks each and every one of his group, and with Robert and Paulie by his side, they turn Rocky around and raise his arms as the audience gives him a heartfelt standing ovation. Dixon is finally recognized as being a warrior for fighting through every round and Rocky proves to the world that he is no joke, mirroring the ending of the first film.\\r\\nAfter the fight, Rocky visits Adrian's grave and puts flowers on top, telling her, \\"Yo, Adrian, we did it\\", which is a play on the second film's line, \\"Yo, Adrian, I did it!\\". Rocky is last seen walking away from the grave and waving goodbye one last time.\\r\\nSince Rocky's very last fight, his brother-in-law, Paulie has died in 2012. In addition, his statue has been re-installed at the Philadelphia Museum of Art at the bottom of the steps. Three years later, Rocky is visited at Adrian's by Adonis \\"Donnie\\" Johnson Creed (Michael B. Jordan) ÿ Apollo's illegitimate son, who grew up serving time in a juvenile detention center in Los Angeles. When Donnie grew up, he once worked as a securities firm, but eventually resigned to be a boxer, and moved to Philadelphia. Donnie meets Rocky at Adrian's restaurant, and requests him to train him, but is reluctant to come back to the sport of boxing after his severe brain trauma and a one-off comeback. Days after his initial offer, Rocky recommends him to his friend, Pete Sporino (Ritchie Coster), who currently runs Mighty Mick's Gym. After deep thought, Rocky finally agrees to takes Donnie as his new protg.\\r\\nWanting to train in the old-school style, Donnie moves in with Rocky, staying in Paulie's former room. While Donnie notices an old picture of Rocky and his son, Robert (an actual picture of Sylvester Stallone and a young Sage Stallone), Rocky reveals that Robert had moved to Vancouver with his girlfriend, because of the difficulties he faced trying to be independent in Philadelphia, but does check on his father every now and then. Pete, who initially wanted Rocky to be a part of his son, Leo's (Gabriel Rosado) team, challenges Adonis to a fight his son, in which Rocky shows reluctance again, but then both agree. Instead of training at Mighty Mick's Gym, Rocky takes Adonis to train at Front Street Gym, where he surprises Donnie with a corner team and apparel. Before the fight, Pete pulls Rocky aside to address the rumors of Donnie being Apollo's son, which Rocky confirms and tells him that he should not speak of it to anyone else. After Donnie's win, the media heavily publicized the story of Apollo's infidelity, which catches the eye of Tommy Holiday (Graham McTavish), who is looking for the final person to fight his trainee, light-heavyweight champion \\"Pretty\\" Ricky Conlan (Tony Bellew). While training, Rocky suddenly grows weak, vomits, and collapses in the gym. After doing a string of test ordered by the doctors at the emergency room, Rocky is diagnosed with an early case of non-Hodgkins lymphoma, making him confront his own mortality; the deadliest fight he's ever been in. At first, Rocky was hesitant to the option of chemotherapy as he remembers the pain Adrian experienced as she underwent treatment for ovarian cancer.\\r\\nAfter a bitter argument with the former heavyweight champion, Donnie, greatly impacted by his coach's diagnosis, makes a pact with Rocky that they would fight their battles together, as Donnie prepares for his bout with Conlan and as Rocky undergoes treatment. As Donnie moves on in training, the effects of treatment begin to weaken Rocky, and because of this, Donnie acts as a caregiver to Rocky while helping him get up and go to the restroom and uses the medical facility to his advantage; shadowboxing in the corridors and running up the stairs, passing doctors and nurses. With the match taking place in Liverpool, a calm Rocky teaches Donnie the hysterics that would ensue during the pre-fright press conference when Conlan tries to play mind games, and later helps in Donnie's girlfriend Bianca (Tessa Thompson) surprising Donnie in his hotel room. During the match, Balboa stands in Donnie's corner along with Bianca. Before the final round, Rocky grows concerned about the injuries that Donnie has sustained and tells him he's stopping the fight. However, Donnie wants to prove that he is \\"not a mistake\\", which emotionally impacts Rocky. He then tells Donnie that he wishes that he had the chance to thank Apollo when Mickey died, but it doesn't match his appreciation of Donnie's tenacity that motivated him in his battle against his illness, and tells him that he admires him.\\r\\nThe film concludes with Donnie taking a frail, but rather improving, Rocky back to the steps of the Philadelphia Museum of Art, in which he says is his \\"most favorite place.\\" Both look toward the Philadelphia skyline, remaining positive about their futures.\\r\\nBalboa resides in Philadelphia, Pennsylvania, and married Adriana \\"Adrian\\" Pennino in 1976. They were married for 26 years. The two have a son, Robert \\"Rocky\\" Balboa Jr., who unlike his father goes by Robert.\\r\\nAfter Adrian's death in 2002, Rocky and his brother-in-law Paulie live together for a short time, then Paulie moves in with an unnamed girlfriend. Now living completely alone again, Rocky cannot come to terms with present-day living and constantly thinks about the past. With the help of Paulie and reunited long-time acquaintance Marie, Rocky begins to move on with his life and in the process restores his relationship with his only child, his son Robert. Rocky's relationship with Marie is established as platonic in the film, but a hint of a romantic interest is revealed with a kiss on the lips the night before the last fight of his life.\\r\\nThe name, iconography, and fighting style of Rocky Balboa were inspired by the legendary heavyweight champion Rocky Marciano from Brockton, Massachusetts and from the 5 times world champion Roberto 'Manos de Piedra (Hands of Stone)' Duran, from Panama, where the Balboa is the official currency. Balboa was also inspired by other fighting legends: Joe Frazier, for his Philadelphia origin, training methods and victory against Muhammad Ali (the inspiration for Apollo Creed), and Jake LaMotta, for his Italian-inner city roots, ability to absorb many blows and his rivalry with Sugar Ray Robinson, which heavily resembled Rocky and Apollo's. However, it was the not-so-legendary Chuck Wepner who inspired the movie and Balboa's underdog personality.\\r\\nThat night, Rocky Balboa was born. People looked on him as the all-American tragedy, a man without much mentality and few social graces. But he has deep emotion and spirituality and good patriotism. And he has a good nature, although nature has not been particularly good to him. I have always seen him as a 20th Century gladiator in a pair of sneakers. Like so many of us, he is out of sync with the times. To all this, I injected doses of my own personal life, of my frustration at not getting anywhere.\\r\\nRocky Balboa fights as a southpaw (left-handed). In the second film, against Apollo Creed, he comes out orthodox and Mickey intends for him to switch back to southpaw late in the last round, but Balboa refuses saying \\"no tricks, I ain't switching\\". Mickey tells him that Apollo is ready for him (if he continues using his right) and so towards the end of the round, he does indeed lead with his left. The real reason for this is Sylvester Stallone tore his pectoral muscles in training,[citation needed] but the idea was probably taken from the great left-handed boxer \\"Marvelous\\" Marvin Hagler who would sometimes come out orthodox to confuse opponents.\\r\\nRocky was an all-or-nothing brawler coming into his first bout with Creed; however, under the training of Mickey, he began to develop his boxing skills ahead of the rematch, which he eventually mastered. During his reign as world champion, he became a world class hybrid fighter, possessing the qualities of an inside fighter, brawler, and swarmer. With the exception of his rematch against Clubber Lang (where he fights as an outside fighter), he often advances quickly upon his opponents, driving them into the ropes in order to attack the body. Balboa's best attribute is without question his near-superhuman ability to absorb a multitude of the hardest hits without falling  an attribute he often employs on purpose to wear down his opponents, sacrificing defensive strategy to land his own punches. Because of this rare talent, Balboa can afford to keep his hands in position to strike rather than up high to block. Because he takes more punches than he throws, it is easy to overlook his incredible punching power. Rocky also has an uncanny ability to sense weakness in his opponents, often capitalizing on every shift in momentum possible. He is acknowledged as having the most devastating body attack in the sport, with his body blows causing internal bleeding in Creed and breaking Drago's ribs. After going two rounds with Balboa, Ivan Drago told his trainer (in Russian), \\"He's not human, he's like a piece of iron.\\" Mason Dixon once remarked about Balboa: \\"that guy's got bricks in his gloves.\\" These qualities, in concert, helped land him a high percentage of KO victories over the course of his career.\\r\\nRocky Balboa was named the 7th greatest movie hero by the American Film Institute on their 100 Years... 100 Heroes and Villains list.[5] Additionally, he was ranked #34 on Empire Magazine's compilation of The 100 Greatest Movie Characters.[6] Premiere magazine ranked Rocky Balboa #64 on their list of The 100 Greatest Movie Characters of All Time.[7]\\r\\nThe Rocky character is immortalised by a bronze statue erected near the Rocky Steps in Philadelphia recalling the famous scene from the original Rocky movie.\\r\\nIn 2011, Sylvester Stallone was inducted into the International Boxing Hall of Fame for his work on the Rocky Balboa character, having \\"entertained and inspired boxing fans from around the world\\". Additionally, Stallone was awarded the Boxing Writers Association of America award for Lifetime Cinematic Achievement in Boxing.[8]\\r\\nA poll of former heavyweight champions and boxing writers ranked Balboa as the best boxer in the film series.[9]\\r\\nIn 2014, Rocky Balboa was the Inaugural Induction to the Fictitious Athlete Hall of Fame.[10]\\r\\nHasbro intended to license Rocky and make him a member of the G.I. Joe toyline, as they had with wrestler Sgt. Slaughter and began negotiations with Stallone's representation. Marvel Comics' G.I. Joe: Order of Battle profile book came out during the negotiations and included Rocky as a current Joe member, specializing in hand-to-hand combat training and an example of what it means to persevere under seemingly impossible odds. Balboa also appeared on the cover of the issue. In the meantime, Stallone's agents made a deal with Coleco to produce Rambo figures in order to compete with the G.I. Joe line. Hasbro, who was working on a toy prototype[11] at the time, decided to end negotiations at that point. Marvel ran a retraction in the third issue of the limited-run series indicating that the character was not, and never had been, a part of G.I. Joe.[12] The trade paperback edition of the series, published in July 1987, omitted the page featuring Balboa altogether.\\r\\nBetween 2006 and 2008, Jakks Pacific released six series of figures, each focused on one of the movies in the film series. Additionally, two \\"Best Of\\" series were released, as well as several collector's box sets, boxing ring playsets, and limited edition exclusive figures.[13]","input":"Who is the character rocky balboa based on?"},{"output":"every ten years","context":"The census in the United Kingdom is decennial, that is, held every ten years, although there is provision in the Census Act 1920 for a census to take place at intervals of five years or more. There have only been two occasions where the census has not been decennial: There was no census in 1941 due to the war; and a mini-census using a ten percent sample of the population was conducted on 24 April 1966. There are actually three separate censuses in the United Kingdom - in England and Wales, Scotland, and Northern Ireland, although they are often coordinated. From 1821 until 1911, the census included the whole of Ireland.\\r\\n\\r\\n\\r\\nThe census records which have been published relate to the occupants of each household on the date given below:\\r\\nBecause the 100-year closure rule was established after the 1911 census, information in later censuses will not be released until the dates stated.","input":"How often do we have a census in the uk?"},{"output":"Private Jacob Parrott","context":"The Medal of Honor was created during the American Civil War and is the highest military decoration presented by the United States government to a member of its armed forces. The recipient must have distinguished themselves at the risk of their own life above and beyond the call of duty in action against an enemy of the United States. Due to the nature of this medal, it is commonly presented posthumously.[1]\\r\\nThe President of the United States, in the name of the United States Congress, has awarded more than 3500 Medals of Honor including 19 second awards to the nation's soldiers, sailors, airmen, Marines, and coast guardsmen since the decoration's creation in 1861.[2]\\r\\nThe citations highlighting acts of gallantry that received the Medal of Honor have been and continue to be regularly released by book publishers. After the Second World War both the Army and Navy produced hardbound Medal of Honor compilations.[3] Between 1964 and 1979, the United States Senate Subcommittee on Veterans' Affairs of the Committee on Labor and Public Welfare and later the Committee on Veterans' Affairs produced a number of consolidated compilations of all Medal of Honor citations to date.[4] Additions and changes to the list of recipients of the medal since the 1979 have been regularly published by the Congressional research Service.[5]\\r\\nThe first Army Medal of Honor was awarded to Private Jacob Parrott during the American Civil War for his role in the Great Locomotive Chase. The first African American recipient for this award was William Harvey Carney who, despite being shot in the face, shoulders, arms, and legs, refused to let the American flag touch the ground. The only female Medal of Honor recipient is Mary Edwards Walker, a Civil War surgeon. Her medal was rescinded in 1917 along with many other non-combat awards, but it was restored by President Jimmy Carter in 1977.[6]\\r\\nWhile current law, (10 U.S.C.??6241), beginning in 1918, explicitly states that recipients must be serving in the U.S. Armed Forces at the time of performing a valorous act that warrants the award, exceptions have been made. For example, Charles Lindbergh, while a reserve member of the U.S. Army Air Corps, received his Medal of Honor as a civilian pilot. Although Medals of Honor can only be awarded to members of the U.S. armed forces, being a U.S. citizen is not a prerequisite for eligibility to receive the medal. Sixty-one Canadians who were serving in the United States armed forces have received the Medal of Honor; most received it for actions in the American Civil War. Since 1900, only four have been awarded to Canadians.[7] In the Vietnam War, Peter C. Lemon was the only Canadian born recipient of the Medal of Honor. However, he was a US citizen.[8]\\r\\n\\r\\n\\r\\nThe American Civil War (1861ÿ1865) was a war between the United States (the Union) and the Southern states of the newly formed Confederate States of America under Jefferson Davis. The Medal of Honor was established during this conflict; 1523 were awarded (33 posthumously) for acts of bravery and gallantry in combat.[9] Most awards were granted after the end of the Civil War with two late awards to Andrew Jackson Smith and Alonzo Cushing in 2001 and 2014.[10]\\r\\nThe term Indian Wars is the name generally used in the United States to describe a series of conflicts between colonial or federal governments and the American Indian population resident in North America before the arrival of white settlers.[11] During this conflict the Medal of Honor was presented to 426 soldiers, 13 posthumously for acts of bravery and gallantry in combat.[12] Some 20 Medal of Honor recipients were involved in the Wounded Knee Massacre.\\r\\nThe United States expedition to Korea in 1871, also known as Sinmiyangyo (Western Disturbance of the Year Sinmi year), was the first American military action in Korea. It took place predominantly on and around the Korean island of Ganghwa. The reason for the presence of the American military expeditionary force in Korea was to support an American diplomatic delegation sent to establish trade and diplomatic relations with Korea and to ascertain the fate of the General Sherman merchant ship. The isolationist nature of the Joseon Dynasty government and the assertiveness of the Americans led to an armed conflict between the two parties. Eventually, the United States failed to secure its objectives.[13]\\r\\nThe SpanishÿAmerican War (Spanish: Guerra Hispano-Estadounidense, desastre del 98, Guerra Hispano-Cubana-Norteamericana or Guerra de Cuba) was a military conflict between Spain and the United States that began in April 1898. Hostilities halted in August of that year, and the Treaty of Paris was signed in December. The war began after the American demand for Spain's peacefully resolving the Cuban fight for independence was rejected, though strong expansionist sentiment in the United States may have motivated the government to target Spain's remaining overseas territories: Cuba, Puerto Rico, the Philippines, Guam and the Caroline Islands.[15]\\r\\nRiots in Havana by pro-Spanish \\"Voluntarios\\" gave the United States reason to send in the warship USS?Maine. This action by the U.S. indicated high national interest. Tension among the American people was raised because of the explosion of USS Maine, and \\"yellow journalism\\" that accused Spain of extensive atrocities, agitating American public opinion. The war ended after decisive naval victories for the United States in the Philippines and Cuba. The Treaty of Paris ended the conflict 109 days after the outbreak of war giving the United States ownership of the former Spanish colonies of Puerto Rico, the Philippines and Guam.[16] 111 people received the Medal of Honor from the SpanishÿAmerican War.\\r\\nThe Samoan Civil War is a Western definition of political activity in the Samoa Islands of the South Pacific in the late 19th century. By this non-Samoan definition, the Samoan Civil Wars were a series of wars between Germany, the United Kingdom, and the United States, ending in the partitioning of the island chain in 1899. The concluding event was the Second Samoan Civil War. The first Samoan Civil War lasted for eight years. The warring Samoan parties were supplied arms, training and sometimes even combat troops by Germany, Britain and the United States. These three powers valued Samoa as a refueling station for coal fired shipping. In addition, these countries sought to gain more power in Europe and wanted Samoa due to the scarcity of unclaimed territory from 1870 onwards.[17]\\r\\nThe PhilippineÿAmerican War[n 1] was an armed military conflict between the United States and the First Philippine Republic, fought between 1899 and at least 1902, which arose from a Filipino political struggle against U.S. occupation of the Philippines. While the conflict was officially declared over on July 4, 1902,[19][20][21] American troops continued hostilities against remnants of the Philippine Army and other resistance groups until 1913, and some historians consider these unofficial extensions part of the war.[21]\\r\\nEighty-six men were awarded the Medal of Honor for their actions in the PhilippineÿAmerican War: 70 from the Army, 10 from the Navy, and 6 from the Marine Corps. Four of the awards were posthumous. Among the recipients were Webb Hayes, the son of former U.S. President Rutherford B. Hayes, and two prominent Marine Corps officers, Hiram I. Bearss and David Dixon Porter. Bearss became known for leading long-range reconnaissance patrols behind enemy lines and was later wounded as a colonel in World War I. Porter was from a distinguished military family and rose to become a major general. Jos B. Nsperos, a member of the Philippine Scouts who was honored for continuing to fight after being wounded, was the first Asian recipient of the Medal of Honor.[22]\\r\\nThe Boxer Movement or Boxer Rebellion, which occurred in China from November 1899 to September 7, 1901, was an uprising by members of the Chinese Society of Right and Harmonious Fists against foreign influence in areas such as trade, politics, religion and technology that occurred in China during the final years of the Manchu rule (Qing Dynasty). The members of the Society of Right and Harmonious Fists were simply called boxers by the Westerners due to the martial arts and calisthenics they practiced. The uprising began as an anti-foreign, anti-imperialist peasant-based movement in northern China. They attacked foreigners who were building railroads and violating Feng shui, as well as Christians, who were held responsible for the foreign domination of China. In June 1900, the Boxers invaded Beijing and killed 230 non-Chinese. Tens of thousands of Chinese Christians, Catholic and Protestant alike, were killed mostly in Shandong and Shanxi Provinces as part of the uprising. The government of Empress Dowager Cixi was not helpful, and diplomats, foreign civilians, soldiers and some Chinese Christians retreated to the legation quarter where they held out for fifty-five days until a multinational coalition rushed 20,000 troops to their rescue. The Chinese government was forced to indemnify the victims and make many additional concessions. Subsequent reforms implemented after the crisis of 1900 laid the foundation for the end of the Qing Dynasty and the establishment of the modern Chinese Republic.[23]\\r\\nDuring the Boxer rebellion, 59 American servicemen received the Medal of Honor for their actions. Four of these were for Army personnel, twenty-two went to navy sailors and the remaining thirty-three went to Marines. Harry Fisher was the first Marine to receive the medal posthumously and the only posthumous recipient for this conflict.[24]\\r\\nThe United States occupation of the Mexican port of Veracruz lasted for six months in response to the Tampico Affair of April 9, 1914. The incident came in the midst of poor diplomatic relations between Mexico and the United States, related to the ongoing Mexican Revolution.[25]\\r\\nSecretary of the Navy Josephus Daniels ordered that 56 Medals of Honor be awarded to participants in the occupation of Veracruz, the most for any single action before or since. In total 63 Medals of Honor were received for actions during the occupation; 1 Army, 9 to members of the United States Marine Corps and 53 to Navy personnel.[24]\\r\\nThe first United States occupation of Haiti began on July 28, 1915 and ended in mid-August 1934.\\r\\nThe United States occupied the Dominican Republic from 1916 to 1924. In May 1917, Rear Admiral William Caperton forced Arias to leave Santo Domingo by threatening the city with naval bombardment. U.S. Marines invaded and took control of the country within two months; in November that same year, the U.S. imposed a military government. The Marines restored order throughout most of the republic (with the exception of the eastern region); the country's budget was balanced, its debt was diminished, and economic growth resumed; infrastructure projects produced new roads that linked all the country's regions for the first time in its history; a professional military organization, the Dominican Constabulary Guard, replaced the partisan forces that had waged a seemingly endless struggle for power.[28]\\r\\nWorld War I, also known as the First World War and the Great War, was a global military conflict which took place primarily in Europe from 1914ÿ1918. Over 40 million casualties resulted, including approximately 20 million military and civilian deaths.[30] Over 60 million European soldiers were mobilized from 1914ÿ1918.[31] The immediate cause of the war was the June 28, 1914 assassination of Archduke Franz Ferdinand, heir to the Austro-Hungarian throne, by Gavrilo Princip, a Bosnian Serb citizen of Austria-Hungary and member of the Black Hand. The retaliation by Austria-Hungary against Serbia activated a series of alliances that set off a chain reaction of war declarations. Within a month, much of Europe was in a state of open warfare.[32]\\r\\nDuring this War, 126 men received the Medal of Honor for their actions with five Marines receiving both the Army and Navy versions of the medal for the same action.[24]\\r\\nThe United States occupied Nicaragua from 1909 to 1933 and intervened in the country several times before that. The American interventions in Nicaragua were designed to prevent the construction of a trans-isthmian canal by any nation but the USA. Nicaragua assumed a quasi-protectorate status under the 1916 Chamorro-Bryan Treaty. The occupation ended as Augusto Csar Sandino, a Nicaraguan revolutionary, led guerrilla armies against US troops. Furthermore, the onset of the Great Depression made it costly for the USA to maintain occupation.[33]\\r\\nWorld War II, or the Second World War, was a global military conflict. The conflicts joined from two separate conflicts. The first began in Asia in 1937 as the Second Sino-Japanese War; the other began in Europe in 1939 with the German and Russian invasion of Poland.[n 2] This global conflict split the majority of the world's nations into two opposing military alliances: the Allies and the Axis powers. It involved the mobilization of over 100 million military personnel, making it the most widespread war in history, and placed the participants in a state of \\"total war\\", erasing the distinction between civil and military resources. This resulted in the complete activation of a nation's economic, industrial, and scientific capabilities for the purposes of the war effort. Over 60 million people, the majority of them civilians, were killed, making it the deadliest conflict in human history.[36] The worldwide financial cost of the war is estimated at a trillion 1944 U.S. dollars,[37][38] making it the most costly war both in capital expenditures as well as loss of lives.\\r\\nDuring this conflict 471 United States military personnel received the Medal of Honor, 273 of them posthumously. A total of 42 Medals of Honor, representing 9% of all awarded during World War II, were presented for action in just two battles?ÿ 15 for actions during the Japanese attack on Pearl Harbor, and 27 for actions during the Battle of Iwo Jima. Also a total of 21 (4.5% of all World War II Medals of Honor) were awarded to members of the all-Japanese American 100th Infantry Battalion of the 442nd Regimental Combat Team, for actions in numerous battles across six different campaigns.[39] Additionally, the only Medal of Honor ever presented to a member of the United States Coast Guard was received for actions during this war.[24]\\r\\nThe Korean War was ignited by the 1950 invasion of South Korea when the North Korean Army moved south on June 25, 1950 to attempt to reunite the Korean peninsula, which had been formally divided since 1948. The conflict was then expanded by the United States, China's and the Soviet Union's involvement. The main hostilities were during the period from June 25, 1950, until the Korean Armistice Agreement was signed on July 27, 1953.\\r\\nIn South Korea, the war is often called \\"6?25\\", or the 6?25 War (Korean: 6?25 ??), from the date of the start of the conflict or, more formally, Hanguk Jeonjaeng literally Korean War. In North Korea, while commonly known as the Korean War, it is formally called the Fatherland Liberation War. In the early days of the war, United States President Harry Truman called the United Nations response a \\"police action\\".[40] The war is sometimes called \\"The Forgotten War\\" because it is a major conflict of the 20th century that gets less attention than World War II, which preceded it, and the controversial Vietnam War, which succeeded it.[41] In China, the conflict was known as the War to Resist America and Aid Korea, but is today commonly called the \\"Korean War\\".[42]\\r\\nDuring this war, 145 Medals of Honor were presented for bravery in action, 107 of them posthumously.[24]\\r\\nThe Vietnam War, also known as the Second Indochina War, and in Vietnam as the American War, occurred from 1959 to April 30, 1975. The term \\"Vietnam Conflict\\" is often used to refer to events which took place between 1959 and April 30, 1975. The war was fought between the Communist-supported Democratic Republic of Vietnam (North Vietnam) and the United States supported Republic of Vietnam (South Vietnam). During the Vietnam War and in the following twelve months, 234 Medals of Honor were received and since 1978 a further 26 awards have been presented. Of the total of 260 awards, 174 were to the US Army, 15 to the US Navy, 57 to the USMC and 14 to the USAF.[24][24] The first medal of the war was presented to Roger Donlon for rescuing and administering first aid to several wounded soldiers and leading a group against an enemy force.[43] The first African American recipient of the war was Milton L. Olive, III who sacrificed himself to save others by smothering a grenade with his body.[44] Riley L. Pitts was killed after attacking an enemy force with rifle fire and grenades and was the first African American commissioned officer of the war to receive the medal.[45] Thomas Bennett was a conscientious objector who received the medal for his actions as a medic;[46] three chaplains received the medal, including Vincent R. Capodanno, who served with the Marine Corps and was known as the Grunt Padre.[47]\\r\\nThe USS Liberty incident was an attack on a neutral United States Navy technical research ship, USS Liberty, by Israeli jet fighter planes and motor torpedo boats on June 8, 1967, during the Six-Day War. The combined air and sea attack killed 34 and wounded more than 170 crew members, and damaged the ship severely.[48]\\r\\nSince the end of the Vietnam War, also known as the Vietnam Conflict and Second Indochina War,[50][51] the United States was involved in a number of smaller conflicts during the end of the Cold War, including in Grenada, Panama, and elsewhere.[52] In the Post-Cold War, the United States was involved in conflicts in the Middle East, Africa, the Caribbean, and in the Balkans.[53] No Medals of Honor have been awarded for any of the aforementioned conflicts so far either proactively or retroactively.[54]\\r\\nOn October 3, 1993, during the Battle of Mogadishu, members of the U.S. Army Rangers and SOCOM's Delta Force executed a mission to capture members of Gen. Mohamed Farrah Aidid's forces. In the ensuing battle, two UH-60 Blackhawk helicopters were shot down. As the second Blackhawk, containing Chief Warrant Officer Michael Durant, was hit and crashed, Master Sergeant Gary I. Gordon and Sergeant First Class Randall D. Shughart were in a nearby Blackhawk monitoring radio traffic. Gordon and Shughart were part of a sniper team for Delta Force that was assigned to watch over the operation, engaging targets from their position in the Blackhawk. As they monitored the downing of the second Blackhawk, it became evident that ground forces would not be available to secure the crash site and protect the critically injured crew of four, all of whom survived the crash. Gordon, the sniper team leader, requested that they be inserted at the 2nd crash site. His request was denied twice before finally being approved on the third request. The snipers were armed only with their sniper rifles and pistols.\\r\\nUpon reaching the downed Blackhawk, which was under intense enemy fire, Gordon and Shughart pulled the crew from the wreckage and proceeded to set up a defensive perimeter. The snipers, assisted by the severely injured Durant, began to engage the attacking Somalis from the opposite side of the wreckage using assault rifles stored on the Blackhawk. Shughart and Gordon were eventually mortally wounded after nearly exhausting all available ammunition; Durant, the only survivor, was taken hostage. According to Durant's account, 25 Somalis were killed and many more were wounded.\\r\\nOn Monday, May 23, 1994, President Clinton presented the Medal of Honor to the widows of Gordon and Shughart.[55] They are the only snipers to have received the Medal of Honor.[56] The film Black Hawk Down, based on the book of the same name, includes a narrative of the events.\\r\\nThe War in Afghanistan, which began on October 7, 2001, was launched by the United States, the United Kingdom, and NATO allies in response to the September 11, 2001 attacks. It was the beginning of the War on Terrorism. The stated purpose of the invasion was to capture Osama bin Laden, destroy al-Qaeda, and remove the Taliban regime which had provided support and safe harbor to al-Qaeda.[57] Since 2001, 14 American service-members have received the Medal of Honor for actions in Afghanistan, three of them posthumously. Army Sergeant First Class Jared C. Monti received his medal for attempting to rescue a wounded soldier at the cost of his own life. Navy Lieutenant Michael P. Murphy received his for actions against insurgent forces and for sacrificing his life to call for help when his team had been overwhelmed by a much larger enemy force.[58] Army Staff Sergeant Robert James Miller's surviving family was presented with his medal on October 6, 2010.[59] The fourth recipient, Salvatore Giunta received his for his actions in 2007 when he risked his life to save a wounded comrade. He is the first living recipient since the Vietnam War. A second living recipient, Sergeant First Class Leroy Petry, received the medal from President Obama during a July 12, 2011, ceremony.[60] Marine Corps Corporal Dakota Meyer became the third living recipient awarded the Medal of Honor for his actions during the Battle of Ganjgal.[61][62] An additional eight living individuals have been awarded the Medal since Meyer.\\r\\nThe Iraq War, also known as the Second Gulf War,[63] Operation Iraqi Freedom (US),[64] Operation TELIC (UK)[65] or the occupation of Iraq,[66] was a conflict which began on March 20, 2003 with the United States-led invasion of Iraq by a multinational coalition composed of U.S. and U.K. troops supported by smaller contingents from Australia, Poland, and other nations.[67] Four service members have received the Medal of Honor for actions in Iraq; two from the Army, one from the Marine Corps and one from the Navy. Paul R. Smith was the first to receive it for his actions on April 4, 2003 when he held enemy forces back, allowing other wounded soldiers to be evacuated to safety. The other three, Corporal Jason Dunham of the Marine Corps, Specialist Ross A. McGinnis of the Army and Master-at-Arms Second Class Michael A. Monsoor of the Navy received it after being killed while using their own bodies to smother grenades to protect their comrades.[68]\\r\\nBefore World War II, the Medal of Honor could be received for actions not involving direct combat with the enemy and 193 men earned the medal in this way.[24] Most of these medals were presented to members of the United States Navy for rescuing or attempting to rescue someone from drowning.[24] One of those awarded the Medal of Honor for rescuing others was Fireman Second Class Telesforo Trinidad, who as of 2010 has been the only Asian American Sailor to be awarded the Medal of Honor.[69] In addition to the medals that were presented for lifesaving acts, one Medal of Honor was presented to William Halford who sailed in a small boat for 31 days to get help for the other members of USS?Saginaw who had been stranded on an island.[70] Three explorers were also presented with the medal by special acts of Congress. Charles Lindbergh received the medal for flying the first solo non-stop flight across the Atlantic Ocean as well as Floyd Bennett and Richard Evelyn Byrd who received it for their participation in what was thought to be the first successful heavier-than-air flight to the North Pole and back. One recipient, Adolphus W. Greely received his for a lifetime of military service.[71]\\r\\nNo individual serving as a member of a foreign force has been awarded the Medal of Honor. Current law,10 U.S.C.??6241 explicitly states that recipients must be serving in the U.S. Armed Forces at the time of performing a valorous act that warrants the award. However, the Medal of Honor has been presented to five First World War unknown soldiers of allied countries: the British Unknown Warrior in the United Kingdom by General Pershing on October 17, 1921; the Romanian Unknown Soldier, the French Unknown Soldier (entombed under the Arc de Triomphe), the Belgian Unknown Soldier, and the Italian Unknown Soldier (entombed in the Monument of Vittorio Emanuele II). Each of the countries reciprocally awarded medals to the U.S. Unknown Soldier.[72]","input":"Who won the first congressional medal of honor?"},{"output":"typically 45ÿ64 years old","context":"A midlife crisis is a transition of identity and self-confidence that can occur in middle-aged individuals, typically 45ÿ64 years old.[1][2][3] The phenomenon is described as a psychological crisis brought about by events that highlight a person's growing age, inevitable mortality, and possibly shortcomings of accomplishments in life.  This may produce feelings of depression, remorse, and anxiety, or the desire to achieve youthfulness or make drastic changes to current lifestyle.\\r\\n\\r\\nThe term was coined by Elliott Jaques in 1965.  More modern research has shown this is not a phase that most middle-aged people actually experience, and some have questioned the existence of this phenomenon.\\r\\n\\r\\nWhen it does occur, a midlife crisis is not typically actually experienced during the midpoint of one's life, which for most developed human populations would be at the age of 35 to 40.\\r\\n\\r\\nAcademic research since the 1980s rejects the notion of mid-life crisis as a phase that most adults go through. Personality type and a history of psychological crisis are believed to predispose some people to this \\"traditional\\" midlife crisis.[4][5]\\r\\nPeople going through this suffer a variety of symptoms and exhibit a disparate range of behaviors.\\r\\n\\r\\nIt is important to understand the difference between a mid-life crisis and a mid-life stressor. Mid-life is the time from years 45ÿ64[3][1][2] where a person is often evaluating his or her own life. However, many mid-life stressors are often labeled as a mid-life crisis. Day-to-day stressors are likely to add up and be thought of as a crisis, but in reality, it is simply an \\"overload\\".[4] Both women and men often experience multiple stressors because of their simultaneous roles as wives/husbands, mothers/fathers, employees, daughters/sons, etc.\\r\\n\\r\\nMany middle-aged adults experience major life events that can cause a period of psychological stress or depression, such as the death of a loved one, or a career setback. However, those events could have happened earlier or later in life, making them a \\"crisis,\\" but not necessarily a mid-life one. In the same study, 15% of middle-aged adults experienced this type of midlife turmoil. Being of a lower educational status is related to feeling stressors to a greater degree than those of a higher education level during midlife.[citation needed]\\r\\n\\r\\nStudies indicate that some cultures may be more sensitive to this phenomenon than others; one study found that there is little evidence that people undergo midlife crises in Japanese and Indian cultures, raising the question of whether a mid-life crisis is mainly a cultural construct. The authors hypothesized that the \\"culture of youth\\" in Western societies accounts for the popularity of the mid-life crisis concept there.\\r\\n\\r\\nResearchers have found that mid-life is often a time for reflection and reassessment, but this is not always accompanied by the psychological upheaval popularly associated with \\"mid-life crisis.\\"[6] Those who made career or jobs changes early in life were less likely to experience a crisis in midlife.[7][8]\\r\\n\\r\\nThe condition may occur from the ages of 45ÿ64.[1][2] Mid-life crises last about 3ÿ10 years in men and 2ÿ5 years in women. A mid-life crisis could be caused by aging itself, or aging in combination with changes, problems, or regrets over:\\r\\n\\r\\nMid-life crisis can affect men and women differently because their stressors differ. An American cultural stereotype of a man going through a midlife crisis may include the purchase of a luxury item such as an exotic car, or seeking intimacy with a younger woman. Some men seek younger women who are able to procreate, not necessarily with an intention to produce offspring, but psychologists refer to this as a human instinct.[9]  A man's midlife crises is more likely to be caused by work issues,[5] a woman's crisis by personal evaluations of their roles. Even though there are differences between why men and women go through a midlife crisis, the emotions they both encounter can be intense.\\r\\n\\r\\nOne of the main characteristics of a mid-life crisis perspective, is one assumes that their mid-life is about to be eventful, usually in a negative way, and potentially stressful. Psychologist Oliver Robinson's research characterizes each decade of life by describing frequent occurrences or situations particular to those age periods. He describes that a crisis can begin in a person's early 20s, when they usually try to map out their whole life. Moreover, the later age period, between 50 and 60, may be a time of illness or even the thought of death. Such a deadline may convince a middle-aged person that their life needs to be lived as expected.[8]\\r\\n\\r\\nIndividuals experiencing a mid-life crisis may feel:[10]\\r\\n\\r\\nPhysical changes that commonly occur during these years are weight gain, wrinkles, sagging skin, hair loss.[12][6][13][14][8]\\r\\nRegular exercise and maintenance of a nutritious diet may help to sustain one's physical and mental health during these years of transition.\\r\\n\\r\\nSignificant changes made early in life may prevent one from having a mid-life crisis. An example supporting such a theory can be derived from the research conducted by Dr. Susan Krauss Whitbourne. People who changed jobs before their midlife years had a greater sense of generativity when they reached mid-life. They also experienced a greater sense of motivation to deviate from stagnation and a desire to help the younger generation thrive. This is a psychological stage proposed by Erik Erikson that describes a normal stage adults go through during their mid-life years.[15]\\r\\n\\r\\nThe notion of the mid-life crisis began with followers of Sigmund Freud, who thought that during middle age everyones thoughts were driven by the fear of impending death.[16] Although mid-life crisis has lately received more attention in popular culture than serious research, there are some theoretical constructs supporting the notion. Jungian theory holds that mid-life is key to individuation, a process of self-actualization and self-awareness that contains many potential paradoxes.[17] Although Carl Jung did not describe midlife crisis per se, the mid-life integration of thinking, sensation, feeling, and intuition that he describes could, it seems, lead to confusion about one's life and goals.\\r\\n\\r\\nErik Erikson's life stage of generativity versus stagnation also coincides with the idea of a mid-life crisis. Erikson believed that in this stage adults begin to understand the pressure of being committed to improving the lives of generations to come. In this stage a person realizes the inevitability of mortality and the virtue of this stage is the creating of a better world for future generations in order for the human race to grow. Stagnation is the lack of psychological movement or growth. Instead of helping the community a person is barely able to help their own family. Those who experience stagnation do not invest in the growth of themselves or others.[18]\\r\\n\\r\\nSome psychologists believe men's mid-life crisis is a psychological reaction to the imminent menopause and end of reproductive career of their spouses.[19] Their genes may be influencing men to be more attracted to reproductive women, and less attached to their non-reproductive spouses.\\r\\n\\r\\nSome people have challenged the existence of mid-life crises altogether. One study found that 23% of participants had what they called a \\"midlife crisis,\\" but in digging deeper, only one-third of those8% of the totalsaid the crisis was associated with realizations about aging.[4]\\r\\n\\r\\nThe balance (15% of those surveyed) had experienced major life experiences or transitions such as divorce or loss of a job in middle age and described them as \\"midlife crisis.\\" While there is no doubt these events can be traumaticthe associated grief reactions can be indistinguishable from depression.[4]\\r\\n\\r\\nCosta and McCrae (1980) found little evidence for an increase in neuroticism in midlife.  While they did find that some people were likely to experience such crises, these individuals were likely to experience crises in their 20s and 30s, and these experiences were not unique to midlife. Robinson, Rosenberg, and Farrell (1999) re-interviewed (500) men. Looking back over their midlife period, it became evident that while not necessarily entailing crisis, it was a time for re-evaluation.\\r\\n\\r\\nWrapping up their review of men's mid-life crisis, Alwin and Levenson wrote that \\"... Given the bulk of the data, it is likely that, for most men, mid-life is a time of achievement and satisfaction. For a certain proportion of men, however, the passage is not at all smooth.\\" They found a similar pattern when they reviewed research on what are commonly thought to be triggers for women's mid-life crisis: menopause, children leaving home, the \\"sandwich\\" of caring for both parents and children. Most women navigated those periods without a traumatic psychological \\"crisis.\\"\\r\\n\\r\\nThe enduring popularity of the mid-life crisis concept may be explained by another finding by Robinson et al. As Alwin and Levenson summarize: \\"... younger men, now middle-aged Baby Boomers, used the term \\"midlife crisis\\" to describe nearly any setback, either in their career or family life.\\"\\r\\n\\r\\nLevenson researched the possible existence of a midlife crisis and its implications. Whereas Levenson (1978) found that 80% of middle-aged participants had a crisis, and Ciernia (1985) reported that 70% of men in midlife said they had a crisis (Shek, 1996) others could not replicate those findings including Shek (1996), Kruger (1994),  McCrae and Costa (1990). The debate of whether or not there is a midlife crisis is being answered through recent research that attempts to balance such factors as response bias and experimenter effects in order to establish internal validity. The above mentioned research does not support Levenson's model of a single age in the middle years that is a designated time of transition and potential \\"crisis.\\" Instead, changes in personality can occur throughout the adult years with no peak in general distress or psychosocial crisis.[20]\\r\\n\\r\\nMany view mid-life as a negative, but in reality many experience this time positively. If looked at as a time of personal growth, the experience can be greatly beneficial and rewarding. If treated as a transitional phase,[6] psychologists believe the initial experience may be difficult and confusing but as time passes it becomes an experience of self growth and self-realization.[6][21][22]\\r\\n\\r\\nCognitively, those of this age period tested better than when they were 25, in tasks measuring long-ago memorized information, or \\"crystallized intelligence\\". This refutes the presumption of women losing much of their cognitive ability during menopause. Forgetting words or numbers does not happen to the degree popular culture would suggest of menopausal women. Conversely, people over the age of 25 perform worse at tasks that require fluid intelligence, understood as inventive, adaptive cognition that is able to learn new ideas and synthesize new strategies. In general, as people age, they gain more accumulated information, but gradually lose the ability to analyze and synthesize novel information.","input":"How old do you have to be to have a midlife crisis?"},{"output":"August 1968","context":"The construction of New York City's first World Trade Center complex was conceived as an urban renewal project, spearheaded by David Rockefeller, to help revitalize Lower Manhattan. The project was developed by the Port Authority of New York and New Jersey, which hired architect Minoru Yamasaki who came up with the specific idea for twin towers. After extensive negotiations, the New Jersey and New York state governments, which oversee the Port Authority, agreed to support the World Trade Center project, which was built at the site of Radio Row in the Lower West Side of Manhattan, New York City. To make the agreement acceptable to New Jersey, the Port Authority agreed to take over the bankrupt Hudson & Manhattan Railroad, which brought commuters from New Jersey to the Lower Manhattan site and, upon the Port Authority's takeover of the railroad, was renamed PATH.\\r\\nThe towers were designed as framed tube structures, which provided tenants with open floor plans, uninterrupted by columns or walls. This was accomplished using numerous closely spaced perimeter columns to provide much of the strength to the structure, along with gravity load shared with the core columns. The elevator system, which made use of sky lobbies and a system of express and local elevators, allowed substantial floor space to be freed up for use as office space by making the structural core smaller. The design and construction of the World Trade Center, most centrally its twin towers, involved many other innovative techniques, such as the slurry wall for digging the foundation, and wind tunnel experiments.\\r\\nConstruction of the World Trade Center's North Tower began in August 1968, and the South Tower in 1969. Extensive use of prefabricated components helped to speed up the construction process. The first tenants moved into the North Tower in December 1970 and into the South Tower in January 1972. Four other low-level buildings were constructed as part of the World Trade Center in the 1970s, and the seventh building, 7 World Trade Center, was constructed in the mid-1980s.\\r\\n\\r\\n\\r\\nIn 1942, Austin J. Tobin became the Executive Director of the Port Authority, beginning a 30-year career during which he oversaw the planning and development of the World Trade Center.[1] The concept of establishing a \\"world trade center\\" was conceived during the postÿWorld War II period, when the United States thrived economically and international trade was increasing. In 1946, the New York State Legislature passed a bill that called for a \\"world trade center\\" to be established.[2] The World Trade Corporation was founded, and a board was appointed by New York Governor Thomas E. Dewey to develop plans for the project.[2] Architect John Eberson and his son Drew devised a plan that included 21 buildings over a ten-block area, at an estimated cost of $150 million.[3] In 1949, the World Trade Corporation was dissolved by the New York State Legislature, and plans for a \\"world trade center\\" were put on hold.[4]\\r\\nDuring the post-war period, economic growth was concentrated in Midtown Manhattan, in part stimulated by the Rockefeller Center, which was developed in the 1930s. Meanwhile, Lower Manhattan was left out of the economic boom. One exception was the construction of One Chase Manhattan Plaza in the Financial District by David Rockefeller, who led urban renewal efforts in Lower Manhattan.[5] In 1958, Rockefeller established the Downtown-Lower Manhattan Association (DLMA), which commissioned Skidmore, Owings and Merrill to draw up plans for revitalizing Lower Manhattan. The plans, made public in late June 1960 called for a World Trade Center to be built on a 13-acre (53,000?m2) site along the East River, from Old Slip to Fulton Street and between Water Street and South Street.[6][7] The complex would include a 900-foot (275?m) long exhibition hall, and a 50ÿ70 story building, with some of its upper floors used as a hotel.[8] Other amenities would include a theater, shops, and restaurants.[9] The plan also called for a new securities exchange building, which the Downtown-Lower Manhattan Association hoped would house the New York Stock Exchange.[7]\\r\\nDavid Rockefeller suggested that the Port Authority would be a logical choice for taking on the project,[7] and argued that the Trade Center would provide great benefits in facilitating and increasing volume of international commerce coming through the Port of New York.[9] Given the importance of New York City in global commerce, Port Authority director Austin J. Tobin remarked that the proposed project should be the World Trade Center, and not just a generic \\"world trade center\\".[10] After a year-long review of the proposal, the Port Authority formally backed the project on March 11, 1961.[11]\\r\\nThe States of New York and New Jersey also needed to approve the project, given their control and oversight role of the Port Authority. Objections to the plan came from New Jersey Governor Robert B. Meyner, who resented that New York would be getting this $335 million project.[5] Meanwhile, ridership on New Jersey's Hudson and Manhattan Railroad (H&M) had declined substantially from a high of 113?million riders in 1927 to 26?million in 1958, after new automobile tunnels and bridges opened across the Hudson River.[12] Toward the end of 1961, negotiations with outgoing New Jersey Governor Meyner regarding the World Trade Center project reached a stalemate. In December 1961, Tobin met with newly elected New Jersey Governor Richard J. Hughes, and made a proposal to shift the World Trade Center project to a west side site where the Hudson Terminal was located.[13] In acquiring the Hudson & Manhattan Railroad, the Port Authority would also acquire the Hudson Terminal and other buildings which were deemed obsolete.[13] On January 22, 1962, the two states reached an agreement to allow the Port Authority to take over the railroad and to build the World Trade Center on Manhattan's lower west side.[14] The shift in location for the World Trade Center to a site more convenient to New Jersey, together with Port Authority acquisition of the H&M Railroad, brought New Jersey to agreement in support of the World Trade Center project.\\r\\nEven once the agreement between the states of New Jersey, New York, and the Port Authority was finalized, the World Trade Center plan faced continued controversy. The site for the World Trade Center was the location of Radio Row, which was home to hundreds of commercial and industrial tenants, property owners, small businesses, and approximately 100 residents.[5] The World Trade Center plans involved evicting these business owners, some of whom fiercely protested the forced relocation.[5] In June 1962, a group representing approximately 325 shops and 1,000 other affected small businesses filed an injunction, challenging the Port Authority's power of eminent domain.[15] The dispute with local business owners worked its way through the court system, up to the New York State Court of Appeals, which in April 1963 upheld the Port Authority's right of eminent domain, saying that the project had a \\"public purpose.\\"[16][17] On November 12, 1963, the United States Supreme Court refused to accept the case.[18][19] Under the state law, the Port Authority was required to assist business owners in relocating, though many business owners regarded what the Port Authority offered as inadequate.[18][20] Questions continued while the World Trade Center was constructed, as to whether the Port Authority really ought to take on the project, described by some as a \\"mistaken social priority.\\"[21]\\r\\nBy 1964, by which time the intended scale of the Yamasaki designed scheme had been made public with plans for the twin 110-story towers, private real estate developers and members of the Real Estate Board of New York also expressed concerns about this much \\"subsidized\\" office space going on the open market, competing with the private sector when there was already a glut of vacancies.[5][22] An especially vocal critic was Lawrence Wien, a co-owner of the Empire State Building, which would lose its title of tallest building in the world.[5][23] Wien organized a group of builders into a group called the \\"Committee for a Reasonable World Trade Center\\" to demand that the project be scaled down.[24]\\r\\nIn January 1964, the Port Authority inked a deal with the State of New York to locate government offices at the World Trade Center.[25] The Port Authority began signing commercial tenants in the spring and summer of 1964, including several banks.[26] In 1965, the Port Authority signed the United States Customs Service as a tenant.[27]\\r\\nA final obstacle for the Port Authority was getting approval from New York City Mayor John Lindsay and the New York City Council, who raised concerns about the limited extent that the Port Authority involved the city in the negotiations and deliberations. Negotiations between The City of New York and the Port Authority were centered on tax issues. A final agreement was made on August 3, 1966, that the Port Authority would make annual payments to the City, in lieu of taxes, for the portion of the World Trade Center leased to private tenants.[28] In subsequent years, the payments would rise as the real estate tax rate increased.[29]\\r\\nOn September 20, 1962, the Port Authority announced the selection of Minoru Yamasaki as lead architect, and Emery Roth & Sons as associate architects.[30] Originally, Yamasaki submitted to the Port Authority a concept incorporating twin towers, but with each building only 80 stories tall. Yamasaki remarked that the \\"obvious alternative, a group of several large buildings, would have looked like a housing project.\\"[31] Yamasaki's design for the World Trade Center was unveiled to the public on January 18, 1964, with an eight-foot model.[31] The towers had a square plan, approximately 207?feet (63?m) in dimension on each side.[32] The buildings were designed with narrow office windows, only 18?inches (45?cm) wide, which reflected on Yamasaki's fear of heights and desire to make building occupants feel secure.[33] Yamasaki's design called for the building facades to be sheathed in aluminum-alloy.[34]\\r\\nTo meet the Port Authority's requirement to build 10?million square feet (930,000?m2) of office space, the buildings would each need to be 110 stories tall. A major limiting factor in building heights is elevators; the taller the building, the more elevators are needed to service the building, requiring more space-consuming elevator banks.[31] Yamasaki and the engineers decided to use a new system that included sky lobbies, which are floors where people can switch from a large-capacity express elevator, which goes only to the sky lobbies, to a local elevator that goes to each floor in a section (the local elevators can be stacked within the same elevator shaft). Located on the 44th and 78th floors of each tower, the sky lobbies enabled the elevators to be used efficiently, while also increasing the amount of usable space on each floor from 62 to 75 percent by reducing the number of required elevator shafts.[35] The World Trade Center towers were the second supertall buildings to use sky lobbies, after the John Hancock Center in Chicago.[36] This system was inspired by the New York City Subway, whose lines include local stations, where only local trains stop, and express stations, where all trains stop.[37]\\r\\nYamasaki, who had previously designed Saudi Arabia's Dhahran International Airport with the Saudi Binladin Group, incorporated features of Arabic architecture into the design of the World Trade Center. The plaza was modelled after Mecca, incorporating features such as a vast delineated square, a fountain, and a radial circular pattern. Yamasaki described the plaza as \\"a mecca, a great relief from the narrow streets and sidewalks of the Wall Street area.\\"[38] He also incorporated other features of Arabic architecture into the building design, including pointed arches, interweaving tracery of prefabricated concrete, a minaret like flight tower, and arabesque patterns.[39]\\r\\nThe World Trade Center design brought criticism of its aesthetics from the American Institute of Architects and other groups.[34][40] Lewis Mumford, author of The City in History and other works on urban planning, criticized the project and described it and other new skyscrapers as \\"just glass-and-metal filing cabinets.\\"[41] Television broadcasters raised concerns that the World Trade Center twin towers would cause interference in television reception for viewers in the New York City area, who were getting their broadcasts from the Empire State Building at that time.[42] In response to these concerns, the Port Authority offered to provide new television transmission facilities at the World Trade Center.[43] The Linnaean Society of the American Museum of Natural History also opposed the Trade Center project, citing hazards the buildings would impose on migrating birds.[44]\\r\\nThe structural engineering firm Worthington, Skilling, Helle & Jackson worked to implement Yamasaki's design, developing the tube-frame structural system used in the buildings. The Port Authority's Engineering Department served as foundation engineers, Joseph R. Loring & Associates as electrical engineers, and Jaros, Baum & Bolles (JB&B) as mechanical engineers. Tishman Realty & Construction Company was the general contractor on the World Trade Center project. Guy F. Tozzoli, director of the World Trade Department at the Port Authority, and the Port Authority's Chief Engineer, Rino M. Monti, oversaw the project.[45]\\r\\nAs an interstate agency, the Port Authority was not subject to local laws and regulations of the City of New York, including building codes. Nonetheless, the Port Authority required architects and structural engineers to follow the New York City building codes. At the time when the World Trade Center was planned, new building codes were being devised to replace the 1938 version that was still in place. The structural engineers ended up following draft versions of the new 1968 building codes, which incorporated \\"advanced techniques\\" in building design.[46]\\r\\nThe World Trade Center towers included many structural engineering innovations in skyscraper design and construction, which allowed the buildings to reach new heights and become the tallest in the world. Traditionally, skyscrapers used a skeleton of columns distributed throughout the interior to support building loads, with interior columns disrupting the floor space. The tube-frame concept, earlier introduced by Fazlur Khan, was a major innovation, allowing open floor plans and more space to rent. The buildings used high-strength, load-bearing perimeter steel columns called Vierendeel trusses that were spaced closely together to form a strong, rigid wall structure. There were 60 perimeter columns, narrowly spaced, on each side of the buildings. In all, the perimeter walls of the towers were 210 feet (64?m) on each side, and the corners were beveled. The perimeter columns were designed to provide support for virtually all lateral loads (such as wind loads) and to share the gravity loads with the core columns.[47] Structural analysis of major portions of the World Trade Center were computed on an IBM 1620.[48]\\r\\nThe perimeter structure was constructed with extensive use of prefabricated modular pieces, which consisted of three columns, three stories tall, connected by spandrel plates. The perimeter columns had a square cross section, 14?inches (36?cm) on a side, and were constructed of welded steel plate.[49] The thickness of the plates and grade of structural steel varied over the height of the tower, ranging from 36,000 to 100,000?pounds per square inch[50] (260 to 670?MPa). The strength of the steel and thickness of the steel plates decreased with height because they were required to support lesser amounts of building mass on higher floors.[49] The tube-frame design required 40 percent less structural steel than conventional building designs.[51] From the 7th floor to the ground level, and down to the foundation, the columns were spaced 10?feet (3?m) apart.[52] All columns were placed on bedrock, which, unlike that in Midtown Manhattan, where the bedrock is shallow, is at 65ÿ85?feet (20ÿ26?m) below the surface.[53]\\r\\nThe spandrel plates were welded to the columns to create the modular pieces off-site at the fabrication shop.[54] The modular pieces were typically 52?inches (1.3?m) deep, and extended for two full floors and half of two more floors.[49] Adjacent modules were bolted together, with the splices occurring at mid-span of the columns and spandrels. The spandrel plates were located at each floor, transmitting shear stress between columns, allowing them to work together in resisting lateral loads. The joints between modules were staggered vertically, so the column splices between adjacent modules were not at the same floor.[49]\\r\\nThe building's core housed the elevator and utility shafts, restrooms, three stairwells, and other support spaces. The core of each tower was a rectangular area 87 by 135?feet (27 by 41?m), and contained 47 steel columns running from the bedrock to the top of the tower.[49] The columns tapered after the 66th floor, and consisted of welded box-sections at lower floors and rolled wide-flange sections at upper floors. The structural core in 1 WTC was oriented with the long axis east to west, while that of 2 WTC was oriented north to south. All elevators were located in the core. Each building had three stairwells, also in the core, except on the mechanical floors where the two outside stairwells temporarily left the core in order to avoid the express elevator machine rooms, and then rejoined the core by means of a transfer corridor.[55] It was this arrangement that allowed Stairwell A of 2 WTC to remain passable after the aircraft impact on September 11, 2001.[56]\\r\\nThe large, column-free space between the perimeter and core was bridged by prefabricated floor trusses. The floors supported their own weight, as well as live loads, provided lateral stability to the exterior walls, and distributed wind loads among the exterior walls. The floors consisted of 4-inch (10?cm) thick lightweight concrete slabs laid on a fluted steel deck with shear connections for composite action.[49] A grid of lightweight bridging trusses and main trusses supported the floors. The trusses had a span of 60 feet (18?m) in the long-span areas and 35 feet (11?m) in the short span area.[49] The trusses connected to the perimeter at alternate columns, and were on 6-foot-8-inch (2.03?m) centers. The top chords of the trusses were bolted to seats welded to the spandrels on the exterior side and a channel welded to the core columns on the interior side. The floors were connected to the perimeter spandrel plates with viscoelastic dampers, which helped reduce the amount of sway felt by building occupants.[49]\\r\\nHat trusses (or \\"outrigger truss\\") located from the 107th floor to the top of the buildings were designed to support a tall communication antenna on top of each building.[49] Only 1 WTC (north tower) actually had an antenna fitted, which was added in 1978.[57] The truss system consisted of six trusses along the long axis of the core and four along the short axis. This truss system allowed some load redistribution between the perimeter and core columns and supported the transmission tower.\\r\\nThe tube frame design using steel core and perimeter columns protected with sprayed-on fire resistant material created a relatively lightweight structure that would sway more in response to the wind, compared to traditional structures such as the Empire State Building that have thick, heavy masonry for fireproofing of steel structural elements.[58] During the design process, wind tunnel tests were done at Colorado State University and at the National Physical Laboratory in the United Kingdom to establish design wind pressures that the World Trade Center towers could be subjected to and structural response to those forces.[59] Experiments were also done to evaluate how much sway occupants could tolerate. Subjects were recruited for \\"free eye exams,\\" while the real purpose of the experiment was to subject them to simulated building sway and find out how much they could comfortably tolerate.[60] Many subjects did not respond well, experiencing dizziness and other ill effects. One of the chief engineers Leslie Robertson worked with Canadian engineer Alan G. Davenport to develop viscoelastic dampers to absorb some of the sway. These viscoelastic dampers, used throughout the structures at the joints between floor trusses and perimeter columns, along with some other structural modifications reduced the building sway to an acceptable level.[61]\\r\\nThe structural engineers on the project also considered the possibility that an aircraft could crash into the building. In July 1945, a B-25 bomber that was lost in the fog had crashed into the 78th and 79th floors of the Empire State Building. A year later, another airplane crashed into the 40 Wall Street building, and there was another close call at the Empire State Building.[62] In designing the World Trade Center, Leslie Robertson considered the scenario of the impact of a jet airliner, the Boeing 707, which might be lost in the fog, seeking to land at JFK or at Newark airports.[63] The National Institute of Standards and Technology (NIST) found a three-page white paper that mentioned another aircraft impact analysis, involving impact of a jet at 600?mph (970?km/h), was indeed considered, but NIST could not locate the documentary evidence of the aircraft impact analysis.[64]\\r\\nSprayed-fire resistant materials (SFRMs) were used to protect some structural steel elements in the towers, including all floor trusses and beams.[55] Gypsum wallboard in combination with SFRMs, or in some cases gypsum wallboard alone, was used to protect core columns.[55] Vermiculite plaster was used on the interior-side and SFRMs on the other three sides of the perimeter columns for fire protection.[55] The 1968 New York City building codes were more lenient in some aspects of fire protection, such as allowing three exit stairwells in the World Trade Center towers, instead of six as required under older building codes.[65]\\r\\nIn April 1970, the New York City Department of Air Resources ordered contractors building the World Trade Center to stop the spraying of asbestos as an insulating material.[66]\\r\\nMore fireproofing was added after a fire in February 1975 that spread to six floors before being extinguished.[67] After the 1993 bombing, inspections found fireproofing to be deficient. The Port Authority was in the process of replacing it, but replacement had been completed on only 18 floors in WTC 1, including all the floors affected by the aircraft impact and fires on September 11,[68] and on 13 floors in WTC 2, although only three of these floors (77, 78, and 85) were directly affected by the aircraft impact.[69][70]\\r\\nThe 1968 New York City building codes did not require sprinklers for high-rise buildings, except for underground spaces. In accordance with building codes, sprinklers were originally installed only in the underground parking structures of the World Trade Center.[71] Following a major fire in February 1975, the Port Authority decided to start installing sprinklers throughout the buildings. By 1993, nearly all of 2 WTC and 85 percent of 1 WTC had sprinklers installed,[72] and the entire complex was retrofitted by 2001.[73]\\r\\nIn March 1965, the Port Authority began acquiring property at the World Trade Center site.[74] The Ajax Wrecking and Lumber Corporation was hired for the demolition work, which began on March 21, 1966 to clear the site for construction of the World Trade Center.[75]\\r\\nGroundbreaking was on August 5, 1966, marking the beginning of construction of the World Trade Center's foundations.[76] The site of the World Trade Center was located on landfill, with the bedrock located 65 feet (20?m) below grade.[77] In order to construct the World Trade Center, it was necessary to build \\"The Bathtub\\", with the slurry wall along the West Street side of the site, to keep water from the Hudson River out. This method was used in place of conventional dewatering methods because lowering the groundwater table would cause large settlements of nearby buildings not built on deep foundations.[78] The slurry method involves digging a trench, and as excavation proceeds, filling the space with a \\"slurry\\" mixture, composed of bentonite which plugs holes and keeps water out. When the trench was dug out, a steel cage was inserted, with concrete poured in, forcing the \\"slurry\\" out. The \\"slurry\\" method was devised by Port Authority chief engineer John M. Kyle Jr. Towards the end of 1966, work began on building the slurry wall, led by Montreal-based Icanda, a subsidiary of an Italian engineering firm, Impresa Costruzioni Opere Specializzate (I.C.O.S.).[79] It took fourteen months for the slurry wall to be completed, which was necessary before excavation of material from the interior of the site could begin.[79] The original Hudson Tubes, which carried PATH trains into Hudson Terminal, remained in service as elevated tunnels until 1971 when a new PATH station was built.[80]\\r\\nConstruction work began on the North Tower in August 1968 with construction beginning on the South Tower by January 1969.[81] In January 1967, $74 million in contracts were awarded to the Pacific Car and Foundry Company, Laclede Steel Company, Granite City Steel Company, and Karl Koch Erecting Company to supply steel for the project.[82] The Port Authority chose to use many different steel suppliers, bidding on smaller portions of steel, rather than buy larger amounts from a single source such as Bethlehem Steel or U.S. Steel as a cost-saving measure.[83] Karl Koch was also hired to do all the work of erecting the steel, and a contract for work on the aluminum facade was awarded to the Aluminum Company of America.[82] Tishman Realty & Construction was hired in February 1967 to oversee construction of the project.[84]\\r\\nExtensive use of prefabricated parts for the perimeter framing and floor truss systems helped speed up the construction process and reduce costs, while providing greater quality control.[51] Steel components were freighted into a Penn Central yard in Jersey City. From there, they were brought in the early morning hours through the Holland Tunnel to the construction site, then lifted into place by a crane.[85] Larger pieces were brought to the construction site by tugboats.[86] A special type of crane, suitable for constructing such tall buildings, that used hydraulics to lift components and provided its own power was used in construction of the World Trade Center. The Favco Standard 2700 Crane, manufactured by Favelle Mort Ltd. of New South Wales, Australia was informally called a \\"kangaroo crane.\\"[87]\\r\\nIn 1970, tugboat workers went on strike, halting the transport of material to the construction site.[88] The Port Authority attempted other means of transporting material, including via helicopter. When this method was tried, the helicopter lost its load of steel into the Kill Van Kull.[89] Some other mishaps occurred during the construction process, including disruption of telephone service in Lower Manhattan when telephone cables were crushed by pile drivers.[90] On March 16, 1970, an explosion injured six workers when a truck hit a propane tank.[91] In all, 60 workers were killed in construction accidents while the World Trade Center was being built.[92]\\r\\nThe topping out ceremony of 1 WTC (North Tower) took place on December 23, 1970, with 2 WTC's ceremony (South Tower) occurring later on July 19, 1971.[81] The first tenants moved into the North Tower on December 15, 1970,[93] and into the South Tower in January 1972.[94] The buildings were dedicated on April 4, 1973; Tobin, who had resigned the year before, was absent from the ceremonies.[95]\\r\\nBuilding the World Trade Center involved excavating 1,200,000 cubic yards (920,000?m3) of material.[96] Rather than transporting this material at great costs out to sea or to landfills in New Jersey, the fill material was used to expand the Manhattan shoreline across West Street.[96] Work to demolish the piers began on January 5, 1967, including Pier 7 to Pier 11 which were all constructed around 1910.[97] The demolition work moved forward, despite conflicts between David Rockefeller, Governor Nelson Rockefeller, and Mayor John Lindsay regarding plans for Battery Park City.[98] Landfill material from the World Trade Center was used to add land, and a cellular cofferdam was constructed to retain the material.[77] The result was a 700-foot (210?m) extension into the Hudson River, running six blocks or 1,484 feet (452?m).[96] This land was a \\"gift\\" to New York City, allowing more tax-generating developments in Battery Park City.[99]\\r\\nThe original estimates put forth by the Port Authority had the costs for construction of the World Trade Center at $350 millionan optimistic figure.[100] In December 1966, the Port Authority announced increased cost estimates, bringing the estimated total to $575 million.[101] This announcement brought criticism of the project from private real estate developers, The New York Times, and others in New York City.[102] The critics charged that the Port Authority figure was an unrealistically low estimate, and they estimated the project would end up costing $750 million.[103] When the World Trade Center twin towers were completed, the total costs to the Port Authority had reached $900 million.[104] The project was financed through tax-exempt bonds issued by the Port Authority.[105]\\r\\nThe World Trade Center complex included four other smaller buildings constructed during the 1970s. 3 World Trade Center was a 22-story building, which was home to the Marriott World Trade Center. It was designed by Skidmore, Owings and Merrill in 1978ÿ79.[106] 4 World Trade Center, 5 World Trade Center, and 6 World Trade Center were all 8ÿ9 story buildings that were designed by the same team as the Twin Towers, including Minoru Yamasaki; Emery Roth & Sons; and Skilling, Helle, Christiansen, Robertson.[107] 7 World Trade Center was built in the mid-1980s, just north of the main World Trade Center site. The 47-story building was designed by Emery, Roth & Sons, and constructed on top of a Con Edison power substation.[108]\\r\\nOver time, numerous structural modifications were made to suit the needs of tenants in the Twin Towers. Modifications were made in accordance with the Port Authority's Tenant Alteration Review Manual and were reviewed by the Port Authority to ensure the changes did not compromise structural integrity of the buildings. In many instances, openings were cut in the floors to accommodate new stairways to connect tenant floors. Some steel beams in the core were reinforced and strengthened to accommodate heavy live loads, such as large amounts of heavy files that tenants had on their floors.[109]\\r\\nRepairs to structural elements on the lower levels of 1 WTC were made following the 1993 bombing. The greatest damage occurred on levels B1 and B2, with significant structural damage also on level B3.[110] Primary structural columns were not damaged, but secondary steel members experienced some damage.[111] Floors that were blown out needed to be repaired to restore the structural support they provided to columns.[112] The slurry wall was in peril following the bombing and loss of the floor slabs which provided lateral support to counteract pressure from Hudson River water on the other side.[113] The refrigeration plant on sublevel B5, which provided air conditioning to the entire World Trade Center complex, was heavily damaged and replaced with a temporary system for the summer of 1993.[113] The fire alarm system for the entire complex needed to be replaced, after critical wiring and signaling in the original system was destroyed in the 1993 bombing. Installation of the new system took years to complete, and replacement of some components was still underway in September 2001.[114]\\r\\nCoordinates: 404242N 740049W? / ?40.71167N 74.01361W? / 40.71167; -74.01361","input":"When was the world trade center originally built?"},{"output":"Private William Henry Christman of Pennsylvania","context":"Arlington National Cemetery is a United States military cemetery in Arlington County, Virginia, across the Potomac River from Washington, D.C., in whose 624 acres (253?ha) the dead of the nation's conflicts have been buried, beginning with the Civil War, as well as reinterred dead from earlier wars. The United States Department of the Army, a component of the United States Department of Defense (DOD), controls the cemetery.\\r\\nThe national cemetery was established during the Civil War on the grounds of Arlington House, which had been the estate of the family of Confederate general Robert E. Lee's wife Mary Anna (Custis) Lee (a great-granddaughter of Martha Washington). The Cemetery, along with Arlington House, Memorial Drive, the Hemicycle, and the Arlington Memorial Bridge, form the Arlington National Cemetery Historic District, listed on the National Register of Historic Places in April 2014.[2][3] Like nearly all federal installations in Arlington County, it has a Washington, D.C. mailing address.\\r\\nIn recent years, the Department of the Army has made plans and taken actions to expand the cemetery onto public lands that the National Park Service (NPS) controlled or that Arlington County or the Commonwealth of Virginia owned, as well as to restrict bicycle use within the cemetery. These plans and actions have become controversial.\\r\\n\\r\\n\\r\\nGeorge Washington Parke Custis, grandson of Martha Washington, acquired the land that now is Arlington National Cemetery in 1802, and began construction of Arlington House (the name is ultimately derived from the village of Arlington, Gloucestershire, England, where Custis' family was originally from). The estate passed to Custis' daughter, Mary Anna, who had married United States Army officer Robert E. Lee. Custis' will gave a \\"life inheritance\\" to Mary Lee, allowing her to live at and run Arlington Estate for the rest of her life but not enabling her to sell any portion of it.[4] Upon her death, the Arlington estate passed to her eldest son, George Washington Custis Lee.[4]\\r\\nWhen Virginia seceded from the Union at the start of the American Civil War, Robert E. Lee resigned his commission on April 20, 1861, and took command of the armed forces of the Commonwealth of Virginia, later becoming commander of the Army of Northern Virginia.[5] On May 7, troops of the Virginia militia occupied Arlington and Arlington House.[6] With Confederate forces occupying Arlington's high ground, the capital of the Union was left in an untenable military position.[7] Although unwilling to leave Arlington House, Mary Lee believed her estate would soon be recaptured by federal soldiers. So she buried many of her family treasures on the grounds and left for her sister's estate at Ravensworth in Fairfax County, Virginia, on May 14.[8][9] On May 3, General Winfield Scott ordered Brigadier General Irvin McDowell to clear Arlington and the city of Alexandria, Virginia, of all troops not loyal to the United States.[10] McDowell occupied Arlington without opposition on May 24.[11]\\r\\nAt the outbreak of the Civil War, most military personnel who died in battle near Washington, D.C., were buried at the United States Soldiers' Cemetery in Washington, D.C., or Alexandria Cemetery in Alexandria, Virginia, but by late 1863 both were nearly full.[12] On July 16, 1862, Congress passed legislation authorizing the U.S. federal government to purchase land for national cemeteries for military dead, and put the U.S. Army Quartermaster General in charge of this program.[12] In May 1864, Union forces suffered large numbers of dead in the Battle of the Wilderness. Quartermaster General Montgomery C. Meigs ordered that an examination of eligible sites be made for the establishment for a large new national military cemetery. Within weeks, his staff reported that Arlington Estate was the most suitable property in the area.[12] The property was high and free from floods (which might unearth graves), it had a view of the District of Columbia, and it was aesthetically pleasing. It was also the home of the leader of the armed forces of the Confederate States of America, and denying Robert E. Lee use of his home after the war was a valuable political consideration.[13] The first military burial at Arlington, for William Henry Christman, was made on May 13, 1864,[14] close to what is now the northeast gate in Section 27.[15] However, Meigs did not formally authorize establishment of burials until June 15, 1864.[16] Arlington did not desegregate its burial practices until President Harry S. Truman issued Executive Order 9981 on July 26, 1948.[17]\\r\\nThe government acquired Arlington at a tax sale in 1864 for $26,800, equal to $410,000 today.[18] Mrs. Lee had not appeared in person but rather had sent an agent, attempting to pay the $92.07 in property taxes (equal to $1,400 today) assessed on the estate in a timely manner.[19] The government turned away her agent, refusing to accept the tendered payment. In 1874, Custis Lee, heir under his grandfather's will passing the estate in trust to his mother, sued the United States claiming ownership of Arlington. On December 9, 1882, the U.S. Supreme Court ruled 5ÿ4 in Lee's favor in United States v. Lee, deciding that Arlington had been confiscated without due process.[19][20] After that decision, Congress returned the estate to him, and on March 3, 1883, Custis Lee sold it back to the government for $150,000 (equal to $3,271,364 in 2017) at a signing ceremony with Secretary of War Robert Todd Lincoln.[18][21] The land then became a military reservation.[22]\\r\\nPresident Herbert Hoover conducted the first national Memorial Day ceremony in Arlington National Cemetery, on May 30, 1929.[23]\\r\\nBeginning in 1863, the federal government used the southern portion of the land now occupied by the cemetery as a settlement for freed slaves, giving the name of \\"Freedmen's Village\\" to the land. The government constructed rental houses that 1,100 to 3,000 freed slaves eventually occupied while farming 1,100 acres (450?ha) of the estate and receiving schooling and occupational training during the Civil War and after War ended.[21][24] However, after the land became part of a military reservation, the government asked the Villagers to leave. When some remained, John A. Commerford, the Superintendent of Arlington National Cemetery, asked the Army's Quartermaster General in 1887 to close the Village on the grounds that people living in the Village had been taking trees at night from the cemetery for use as firewood.[22][25] The Quartermaster General and the Secretary of War then approved Commerford's request.[22] The last of the Village's residents departed after the 56th United States Congress appropriated $75,000 in 1900 to settle the government's debts to them.[22]\\r\\nWith limited space but large numbers of World War II, Korean War, Vietnam War, and other veterans dying and wanting to be buried at Arlington, the need for additional burial space at the cemetery became a pressing issue. In 1991, Cemetery superintendent John C. Metzler, Jr., implemented a $1.4 million plan to clear a former 13 acres (5.3?ha) parking lot to create space for about 9,000 new grave sites.[26]\\r\\nThe Cemetery received the authority to transfer 12 acres (4.9?ha) of woodland from the NPS-controlled Arlington House in 1996[27][28] and 2001,[29][30] 37 acres (15?ha) of land in 1999 from the DOD that was the site of the Navy Annex building,[31][32] 8 acres (3.2?ha) of land in 1999 from the Department of the Army that was part of Fort Myer,[31][33] 4 acres (1.6?ha) of land from Arlington County's Southgate Road right-of-way in 2004,[34] and just under 10 acres (4.0?ha) of land from Fort Myer in 2005.[29][35][36]\\r\\nIn 2007, Metzler implemented the Millennium Project, a $35 million expansion plan to begin utilizing the Arlington woodland, Fort Myer, and Navy Annex land. The project also included converting 40 acres (16?ha) of unused space and 4 acres (16,000?m2) of maintenance property on the cemetery grounds into burial space in 2006 and 2007 to allow an additional 26,000 graves and 5,000 inurnments. The Millennium Project expanded the cemetery's physical boundaries for the first time since the 1960s, and was the largest expansion of burial space at the site since the American Civil War.[35] Several environmental and historical preservation groups criticized Metzler's plans, as did the NPS and the manager of Arlington House.[35][36][37]\\r\\nOn March 26, 2013, the Consolidated and Further Continuing Appropriations Act, 2013 (Public Law 113-6) appropriated to the DOD $84 million to plan, design and construct the Millennium Project.[38] The legislation additionally appropriated to the DOD $19 million to study, plan and design a future expansion of the cemetery's burial space.[38]\\r\\nIn 1998, a Congressional proposal to expand the cemetery onto land that the Navy Annex and Fort Myer then occupied led to concerns that Arlington County officials had not been properly consulted, leading to the withdrawal of the proposal.[39] However, the National Defense Authorization Act for Fiscal Year 2000 (Public Law 106-65), which was enacted into law during October 1999, subsequently required the Secretary of Defense to transfer to the Secretary of the Army administrative jurisdiction of the 36 acres (15?ha) Navy Annex property. The Act required the Secretary of Defense to demolish the Annex's buildings and prepare the property for use as part of the cemetery, while requiring the Secretary of the Army to incorporate the Annex property into the cemetery.[32]\\r\\nIn January 2013, the County Manager of Arlington County, Virginia, and the Executive Director of the Army National Military Cemeteries (consisting of Arlington National Cemetery and the United States Soldiers' and Airmen's Home National Cemetery)[40] signed a Memorandum of Understanding (MOU) between the Arlington County Board and the Department of the Army to expand the cemetery even further. Under the tentative plan, Arlington County would give up the easement for Southgate Road (which lies between the Navy Annex property and the cemetery's 2012 boundary), and obtain a narrow easement along the southwest border of the Navy Annex site for a new Southgate Road. In exchange, the Department of Defense would give the Navy Annex parking lot to the county.\\r\\nThe Army would also transfer land west of South Joyce Street to Columbia Pike to Arlington County. Additionally, the Commonwealth of Virginia would convey to the cemetery roughly the northern half of the Virginia Department of Transportation land bounded by South Joyce Street, Columbia Pike, and South Washington Boulevard. The cloverleaf interchange between Columbia Pike and S. Washington Blvd. would be eliminated, and the hairpin turn in Columbia Pike straightened, to provide a safer, more natural exit from S. Washington Blvd. onto Columbia Pike. Although exact acreages were not specified and the plan depended upon the Commonwealth of Virginia's cooperation, the MOU if implemented would have created a more contiguous plot of land for the cemetery.[41]\\r\\nHowever, in December 2016, the National Defense Authorization Act for Fiscal Year 2017 (Public Law 114-328) authorized the Secretary of the Army to expand the cemetery by acquiring from Arlington County and the Commonwealth of Virginia by condemnation and other means properties near the cemetery that contain the Southgate Road, South Joyce Street and Washington Boulevard right-of-ways, including the Washington Boulvard-Columbia Pike interchange.[42] The Army then informed the Arlington County government in June 2017 that the Army would no longer pursue a land exchange with the County. The Army told the County that the Army would use the entire Navy Annex site to expand the cemetery and would acquire for the cemetery about 5 acres (2.0?ha) of public land that Arlington County then owned. The Army would also acquire for the cemetery expansion about 7 acres (2.8?ha) of land located between Columbia Pike and Interstate 395 that the Commonwealth of Virginia then owned.[43]\\r\\nOn February 22, 1995, officials of the United States Department of the Interior and the United States Department of the Army signed an agreement to transfer from Arlington House, The Robert E. Lee Memorial, to the Army a part of Arlington Woods, which was located in Section 29 of the NPS at Arlington National Cemetery between Arlington House and Fort Myer.[44] The property transfer, which involved 12 acres (4.9?ha) of NPS land, was intended to permit Metzler to start expanding the cemetery beyond its existing boundaries.[28][45]\\r\\nEnvironmentalists expressed concerns that the agreement would result in the partial destruction of the 24 acres (9.7?ha) remnant of an historically important stand of native trees.[37][46] A historical marker near the woodland notes that, while visiting Arlington House in 1825, Gilbert du Motier, Marquis de Lafayette had warned Mary Lee Fitzhugh Custis, the wife of George Washington Parke Custis: \\"Cherish these forest trees around your mansion. Recollect how much easier it is to cut a tree than to make one grow.\\" The marker further notes that the Virginia Native Plant Society had recognized the woodland as being one of the best examples of old growth terraced gravel forest remaining in Virginia.[47]\\r\\nOn September 23, 1996, the National Defense Authorization Act for Fiscal Year 1997 (Public Law 104-201) authorized the Secretary of the Interior to transfer to the Secretary of the Army all of the land in Section 29 that was within an \\"Arlington National Cemetery Interment Zone\\" and some of the land in the Section that was within a \\"Robert E. Lee Memorial Preservation Zone\\".[27][28]\\r\\nOn March 5, 1998, the NPS, which is a component of the Department of the Interior, informed the National Capital Planning Commission that it wanted to transfer only 4 acres (1.6?ha) to the cemetery, rather than the 12 acres (4.9?ha) that the 1995 agreement had described. In response, Metzler stated: \\"I was surprised. But we will continue to work with the Department of Interior and see what happens.\\"[28]\\r\\nOn July 12, 1999, the NPS issued a Federal Register notice that announced the availability of an environmental assessment (EA) for the transfer.[45][48] The EA stated that the Interment Zone contained the oldest and largest tract of climax eastern hardwood forest in Arlington County. This forest was the same type that once covered the Arlington estate, and had regenerated from trees that were present historically. A forestry study determined that a representative tree was 258 years old. The Interment Zone was also determined to contain significant archeological and cultural landscape resources, in addition to those in the Preservation Zone.[48] The EA described four alternative courses of action.[48]\\r\\nIn contrast to the NPS's March 1998 statement to the National Capital Planning Commission, the 1999 EA stated that the preferred alternative (Alternative 1) would transfer to the cemetery approximately 9.6 acres (3.9?ha), comprising most of the Interment Zone and the northern tip of the Preservation Zone.[48] Another alternative (Alternative 3) would transfer to the cemetery the 12 acres (4.9?ha) Interment Zone, while keeping the 12.5 acres (5.1?ha) Preservation Zone under NPS jurisdiction.[48] The EA concluded: \\"Public Law 104-201 directed the Secretary of the Interior to transfer to the Secretary of the Army jurisdiction over the Interment Zone, which is the plan in Alternative 3. Adoption of any of the other alternatives would require legislative action to amend the existing law.\\"[48]\\r\\nOn December 28, 2001, the National Defense Authorization Act for Fiscal Year 2002 (Public Law 107-107) repealed the \\"obsolete\\" part of Public Law 104-201 that had authorized the transfer of portions of Section 29 to the Secretary of the Army.[30] The new legislation required the Secretary of the Interior to transfer to the Secretary of the Army within 30 days the approximately 12 acres (4.9?ha) Interment Zone.[30] The transfer therefore involved the entire 12 acres (4.9?ha) of NPS land that the 1995 agreement and Alternative 3 in the 1999 EA had described.\\r\\nThe 2001 legislation required the Secretary of the Army to use the Interment Zone for in-ground burial sites and columbarium.[30] In addition, the legislation required the Secretary of the Interior to manage the remainder of Section 29 \\"in perpetuity to provide a natural setting and visual buffer for Arlington House, the Robert E. Lee Memorial.\\"[30]\\r\\nOn December 12, 2012, the United States Army Corps of Engineers asked for comments on a draft EA that described a further expansion of Arlington National Cemetery as part of the Millennium Project.[49][50][51] The 2012 draft EA was intended to implement conversion into burial space of the 17 acres (6.9?ha) of Ft. Myer grounds as well as 10 acres (4.0?ha) of Section 29 woodland. The draft EA described seven alternatives. The preferred alternative (Alternative E) called for the removal of about one-half of the 1,700 trees with a diameter of 6 inches (15?cm) or greater on the site. About 640 of the trees were within a 135-year-old portion of Arlington Woods.[52] The draft EA concluded: \\"Based on the evaluation of environmental impacts....., no significant impacts would be expected from the Proposed Action; therefore, an Environmental Impact Statement will not be prepared and a Finding of No Significant Impact will be prepared and signed.\\"[52]\\r\\nOn March 12, 2013, the Corps of Engineers released a revised EA for the Millennium Project.[53][54] The revised EA contained copies of a number of public comments on the draft EA that had criticized the project and parts of the EA while proposing alternative locations for new military burials near the cemetery and elsewhere.[55] However, the Department of Forestry of the Commonwealth of Virginia found that, based on information in the draft EA, the project would not have a significant adverse impact on the Commonwealth's forest resources.[56] The revised EA did not change the preferred alternative (Alternative E) or the Army's plans to prepare and sign the Finding of No Significant Impact (FONSI) that the draft EA had described.[57]\\r\\nOn June 5, 2013, after reviewing 100 public comments that it had received on the revised EA, the Corps of Engineers released a final EA and a signed FONSI for the Millennium Project.[58][59] The Final EA and the FONSI retained Alternative E as the preferred alternative.[58] The final EA stated that, of the 905 trees to be removed, 771 trees were healthy native trees that had diameters between 6 and 41 inches.[60][61] The project would remove approximately 211 trees from a less than 2.63 acres (1.06?ha) area containing a portion of a 145-year-old forest that stood within the property boundaries of a historic district that a National Register of Historic Places nomination form for Arlington House had described in 1966.[60][62] About 491 trees would be removed from an area of trees that was approximately 105 years old.[60] Approximately 203 trees with ages of 50 to 145 years would be removed from a former picnic area.[60] At a public hearing on July 11, 2013, the National Capital Planning Commission approved the site and building plans for the Millennium Project.[63]\\r\\nOn June 9, 2010, United States Secretary of the Army John M. McHugh reprimanded the cemetery's superintendent, John C. Metzler, Jr., and his deputy, Thurman Higgenbotham, after a DOD inspector general's report revealed that cemetery officials had placed the wrong headstones on tombs, buried coffins in shallow graves, and buried bodies on top of one another.[64] Metzler, who had already announced his intention to retire on July 2, 2010, admitted some mistakes had been made but denied allegations of widespread or serious mismanagement.[64] The investigation also found that cemetery employees were burdened in their day-to-day work by \\"dysfunctional management, lack of established policy and procedures, and an overall unhealthy organizational climate.\\"[65][66] Both Metzler and Higgenbotham retired soon after the investigation commenced.[67]\\r\\nIn March 2011, as a result of the problems discovered, Kathryn Condon, the recently appointed Executive Director of the Army National Military Cemeteries, announced that the cemetery's staff had been increased from 102 to 159. She added that the cemetery was also acquiring additional equipment because, \\"They didn't have the proper equipment to do the job really to the standard they needed to do.\\"[68]\\r\\nThe mismanagement controversy included a limitation on mass media access to funerals, which also proved controversial. Until 2005, the cemetery's administration gave free access, with the family's permission, to the press to cover funerals at the cemetery. According to the Washington Post in 2008, the cemetery gradually imposed increasing restrictions on media coverage of funerals beginning about 2005.[69]\\r\\nAfter the cemetery's management controversy began to end, the Army appointed Patrick K. Hallinan the acting superintendent of the cemetery in June 2010. He was promoted permanently to the position in October 2010. Hallinan had previously worked for the Office of Field Programs in the National Cemetery Administration, an agency of the United States Department of Veterans' Affairs. In that capacity, Hallinan had oversight of 131 national cemeteries, national cemetery policy, procedures, and operations.[70] Hallinan was promoted to Executive Director of the Army National Military Cemeteries upon the retirement of Kathryn Condon in spring 2014.[71]\\r\\nIn May 2014, Hallinan stepped down and was replaced by Jack E. Lechner, Jr. as superintendent of the cemetery. Lechner had been a funeral director for 10 years in the private sector before joining the U.S. Army. He rose to the rank of colonel (retiring in November 2011), having spent 2008 to 2010 as chief of the Supply Division of the Joint Chiefs of Staff, overseeing the equipping of Iraqi and Afghanistan national security forces. Since June 2010, he had served as executive officer and deputy superintendent of the cemetery under Hallinan.[71]\\r\\nThe Army removed Lechner as superintendent of the cemetery in early August 2015 after a performance review \\"called into question his ability to serve successfully as a senior leader\\". The Army declined to elaborate further and appointed Hallinan to be the temporary Cemetery superintendent until the Army could find a successor.[72]\\r\\nBeginning in 1992, the Morrill Worcester wreath company in Harrington, Maine, had a surplus at the end of the holiday season. Recalling a boyhood trip to the cemetery, Worcester donated to the cemetery 5,000 wreaths to honor the cemetery's dead, with the help of volunteers and a local trucking company. After thirteen years of similar donations, in 2005 a photo of snowy gravestones covered with wreaths at the cemetery received widespread circulation on the Internet. Thousands of people called Worcester, wanting to replicate the wreath-laying service at their own veteran cemeteries.[73]\\r\\nIn 2006, over 150 different locations simultaneously held ceremonies with Arlington's. Additionally, the project had its first Veterans Honor Parade with \\"Patriot Guard Riders\\" who escorted the wreaths from Maine to the cemetery. The parade, which is held each year, now visits schools, monuments, veterans homes and communities along its route.[73]\\r\\nAt the end of 2006, Worcester's company supplied wreaths to over 230 state and national cemeteries and veterans monuments across the country.[74] Assisted by veterans and truckers, Worcester established in 2007 a nonprofit organization named \\"Wreaths Across America\\".[73] In December 2008, the United States Senate agreed to a resolution that designated December 13, 2008, as Wreaths Across America Day.[75]\\r\\nIn 2014, volunteers placed over 700,000 memorial wreaths at 1,000 locations in the United States and overseas, including the USS Arizona Memorial at Pearl Harbor, Bunker Hill, Valley Forge, and the National September 11 Memorial at the World Trade Center site in New York City. During that year, volunteers were able to place wreaths in all sections of the cemetery for the first time.[73] In 2016, this number increased to 1.2 million wreaths being placed at more than 1,230 cemeteries across the nation.[76]\\r\\nConflict of interest charges have been made against Wreaths Across America because this charity has an exclusive for-profit supplier, Worcestor Wreath Company, also run by the Morrill family in the same town. The charity's purchases of wreaths from this company account for most of the company's revenue and profits. In late 2015, the Wall Street Journal reported serious conflicts of interest with potential malfeasance in governance and contracting.[77] In 2015 alone the WSJ reported profits of over $1 million on sales of over 850,000 wreaths to the charity raising concerns about competitive bidding, reporting that several competitors had asked to bid significantly below the price offered by Worcestor Wreath Company but were denied access.\\r\\nDuring May and June 2014, the cemetery celebrated the 150th anniversary of its founding with a month-long series of events, tours, and lectures.[78] During these celebrations, cemetery officials formally re-designated the Old Amphitheater as the James Tanner Amphitheater. James R. Tanner was a Union Army officer who lost both legs during the war. He later became a War Department stenographer, and recorded much of the early evidence in the investigation into the assassination of Abraham Lincoln. He later was active in the Grand Army of the Republic, a Union Army veterans group. Tanner is buried a few yards from the amphitheater.[79]\\r\\nThe Cemetery is divided into 70 sections, with some sections in the southeast and western part of the cemetery reserved for future expansion.[80] Section 60, in the southeast part of the cemetery, is the burial ground for military personnel killed in the Global War on Terror since 2001.[81] Section 21, also known as the Nurses Section, is the area of Arlington National Cemetery where many nurses are buried and is the site of the Spanish-American War Nurses Memorial and the Nurses Memorial.[82] Another sectionChaplains Hillincludes monuments to Jewish, Protestant, and Roman Catholic military chaplains. In 1901, Confederate soldiers buried at the Soldiers' Home and various locations within Arlington were reinterred in a Confederate section that was authorized by Congress in 1900. On June 4, 1914, the United Daughters of the Confederacy dedicated the Confederate Memorial designed by Moses Ezekiel. Upon his death in 1917, Ezekiel was buried at the base of the monument as he was a veteran of the Confederate army.[83] All Confederate headstones in this section are peaked rather than rounded.[84] More than 3,800 former slaves, called \\"Contrabands\\" during the Civil War, are buried in Section 27. Their headstones are designated with the word \\"Civilian\\" or \\"Citizen\\".[85]\\r\\nThe United States Department of Veterans Affairs oversees the National Cemetery Administration's orders[86] for placement of inscriptions and faith emblems at no charge to the estate of the deceased, submitted with information provided by the next of kin[87] that is placed on upright marble headstones or columbarium niche covers. The Department of Veterans Affairs currently offers 63 authorized faith emblems for placement on markers to represent the deceased's faith.[88] This number has grown in recent years due to legal challenges to policy.[89]\\r\\nPrior to 2007, the United States Department of Veterans Affairs (VA) did not allow the use of the pentacle as an \\"emblem of belief\\" on tombstones in military cemeteries. This policy was changed following an out-of-court settlement on April 23 following a series of lawsuits by the family of Patrick Stewart against the VA.[90][91][92]\\r\\nBetween 1947 and 2001, privately purchased markers were permitted in the cemetery. The sections in which the cemetery permitted such markers are nearly filled and the cemetery generally does not allow new burials in these sections.[93] Nevertheless, the older sections of the cemetery have a wide variety of private markers placed prior to 2001, including an artillery piece.[94]\\r\\nThere are 32 Commonwealth war dead burials and some headstones are Commonwealth War Graves Commission style.\\r\\nThe Tomb of the Unknowns is part of the Arlington Memorial Amphitheater. The Memorial Amphitheater has hosted state funerals and Memorial Day and Veterans Day ceremonies. Ceremonies are also held for Easter. About 5,000 people attend these holiday ceremonies each year. The structure is mostly built of Imperial Danby marble from Vermont. The Memorial Display room, between the amphitheater and the Tomb of the Unknowns, uses Botticino stone, imported from Italy. The amphitheater was the result of a campaign by Ivory Kimball to construct a place to honor America's servicemen/women. Congress authorized the structure on March 4, 1913. Woodrow Wilson laid the cornerstone for the building on October 15, 1915. The cornerstone contained 15 items including a Bible and a copy of the Constitution.[95]\\r\\nBefore the Arlington Memorial Amphitheater was completed in 1921, important ceremonies were held at what is now known as the \\"Old Amphitheater.\\" This structure sits where Robert E. Lee once had his gardens. The amphitheater was built in 1868 under the direction of Civil War General John A. Logan. Gen. James A. Garfield was the featured speaker at the Decoration Day dedication ceremony, May 30, 1868, later being elected as President of the United States 1881. The amphitheater has an encircling colonnade with a latticed roof that once supported a web of vines. The amphitheater has a marble dais, known as \\"the rostrum\\", which is inscribed with the U.S. national motto found on the Great Seal of the United States, E pluribus unum (\\"Out of many, one\\"). The rostrum was designed by General Montgomery C. Meigs, then Quartermaster General of the U.S. Army.[96] The amphitheater seats 1,500 people and has hosted speakers such as William Jennings Bryan.[97]\\r\\nThe Tomb of the Unknown Soldier stands on top of a hill overlooking Washington, D.C. One of the more well-attended sites at the cemetery, the tomb is made from Yule marble quarried in Colorado. It consists of seven pieces, with a total weight of 79 short tons (72 metric tons). The tomb was completed and opened to the public April 9, 1932, at a cost of $48,000.\\r\\nIt was initially named the \\"Tomb of the Unknown Soldier.\\" Other unknown servicemen were later entombed there, and it became known as the \\"Tomb of the Unknowns\\", though it has never been officially named. The soldiers entombed there are:\\r\\nThe Tomb of the Unknowns has been perpetually guarded since July 2, 1937, by the U.S. Army. The 3rd U.S. Infantry Regiment (\\"The Old Guard\\") began guarding the Tomb on April 6, 1948. There is a meticulous routine which the guard follows when watching over the graves.[98] The Tomb Guard:\\r\\nAfter each turn, the Guard executes a sharp \\"shoulder-arms\\" movement to place the weapon on the shoulder closest to the visitors to signify that the Guard stands between the Tomb and any possible threat.\\r\\nTwenty-one was chosen because it symbolizes the highest military honor that can be bestowedthe 21-gun salute.\\r\\nEach turn the guard makes precise movements and followed by a loud click of the heels as he snaps them together. The guard is changed every half-hour during daylight in the summer, and every hour during daylight in the winter and every two hours at night (when the cemetery is closed to the public), regardless of weather conditions.\\r\\nA commemorative stamp was issued on November 11, 1922, the first anniversary of the first entombment picturing the Amphitheater. It encompasses the original Tomb of the Unknown Soldier. The remains of an unidentified WW I American soldier was entombed on Armistice Day, November 11, 1921, later covered in 1931 by a more elaborate marble sarcophagus.[99]\\r\\nThere are several memorials on the grounds of the cemetery. However, due to the lack of space for burials and the large amount of space that memorials take up, the U.S. Army now requires a joint or concurrent resolution from Congress before it will place new memorials at Arlington.\\r\\nNear the Tomb of the Unknowns stands the USS Maine Mast Memorial, which commemorates the 266 men who lost their lives aboard the USS Maine. The memorial is built around a mast salvaged from the Maines wreckage. The USS Maine Memorial served as the temporary resting place for foreign heads of state or government, Manuel L. Quezon of the Philippines and Ignacy Jan Paderewski of Poland, who died in exile in the United States during World War II.\\r\\nThe Space Shuttle Challenger Memorial was dedicated on May 20, 1986, in memory of the crew of flight STS-51-L, who died during launch on January 28, 1986. Transcribed on the back of the stone is the text of the John Gillespie Magee, Jr. poem High Flight, which was quoted by then President Ronald Reagan when he addressed the disaster. Although many remains were identified and returned to the families for private burial, some were not, and were laid to rest under the marker. Two crew members, Scobee and Smith, are buried in Arlington. On February 1, 2004, NASA Administrator Sean O'Keefe dedicated a similar memorial to those who died when the Shuttle Columbia broke apart during reentry on February 1, 2003.[100] Astronauts Laurel Clark, David Brown and Michael Anderson, who were killed in the Columbia disaster, are also buried in Arlington.\\r\\nThe Lockerbie Cairn is a memorial to the 270 killed in the bombing of Pan Am Flight 103 over Lockerbie, Scotland. The memorial is constructed of 270 stones, one for each person killed in the disaster. In section 64, a memorial to the 184 victims of the September 11 attacks on the Pentagon was dedicated September 11, 2002. The memorial takes the shape of a pentagon, and lists the names of all the victims that were killed. Unidentified remains from the victims are buried beneath it.[101]\\r\\nOn June 25, 1925, President Calvin Coolidge approved a request to erect a Commonwealth Cross of Sacrifice with the names of all the citizens of the USA who lost their lives fighting in the Canadian forces during World War I. The monument was dedicated November 11, 1927 and after the Korean War and World War II the names of US citizens who died in those conflicts were added.\\r\\nThe Women in Military Service for America Memorial is adjacent to the Ceremonial Entrance to the cemetery.\\r\\nThe Laos Memorial, or Lao Veterans of America memorial, dedicated to Lao and Hmong veterans who served with US Special Forces and CIA advisors during the Vietnam War, to defend the Royal Kingdom of Laos from the North Vietnamese invasion of Laos by selling opium to the CIA in exchange for weapons and promises for their own country, is located on Grant Avenue near the eternal flame memorial to U.S. President John F. Kennedy.[102]\\r\\nIn 2012, legislation began moving through Congress to approve a \\"Place of Remembrance\\" at the cemetery. The memorial will be an ossuary designed to contain fragments of remains which are unidentifiable through DNA analysis. The remains will be cremated before placement in the memorial.[103]\\r\\nThe flags in the cemetery are flown at half-staff from a half-hour before the first funeral until a half hour after the last funeral each day. Funerals are normally conducted five days a week, excluding weekends.[104][105]\\r\\nFunerals, including interments and inurnments, average between 27ÿ30 per day. The Cemetery conducts approximately 6,900 burials each year.[85]\\r\\nWith more than 400,000 interments,[1] the cemetery has the second-largest number of burials of any national cemetery in the United States. The largest of the 130 national cemeteries is the Calverton National Cemetery, on Long Island, near Riverhead, New York, which conducts more than 7,000 burials each year.\\r\\nIn addition to in-ground burial, the cemetery also has one of the larger columbaria for cremated remains in the country. Four courts are currently in use, each with 5,000 niches. When construction is complete, there will be nine courts with a total of 50,000 niches; capacity for 100,000 remains. Any honorably discharged veteran is eligible for inurnment in the columbarium, if s/he served on active duty at some point in her/his career (other than for training).[106]\\r\\nPart 553 (Army National Military Cemeteries) of Title 32 of the Code of Federal Regulations (CFR) establishes regulations for the cemetery, including eligibility for interment (ground burial) and inurnment.[107] Due to limited space, the criteria for ground burial eligibility are more restrictive than at other national cemeteries, as well as more restrictive than for inurnment in the columbarium.\\r\\nThe persons specified below are eligible for ground burial in the cemetery, unless otherwise prohibited.[108] The last period of active duty of former members of the armed forces must have ended honorably. Interment may be of casketed or cremated remains.\\r\\nDue at least partly to the lack of space at the cemetery for ground burial, standards for inurnment (burial of cremated remains) in the columbarium are currently much less restrictive than for ground burial at the cemetery. In general, any former member of the armed forces who served on active duty (other than for training) and whose last service terminated honorably is eligible for inurnment. Eligibility for inurnment is described fully in 32 C.F.R.  553.15a.\\r\\nCongress has from time to time created prohibited categories of persons that, even if otherwise eligible for burial, lose that eligibility. One such prohibition is against certain persons who are convicted of committing certain state or federal capital crimes, as defined in 38 U.S. Code  2411. Capital crime is a specifically defined term in the statute, and for state offenses can include offenses that are eligible for a life sentence (with or without parole). The reasoning for this provision originally was to prevent Timothy McVeigh from being eligible at Arlington National Cemetery, but it has since been amended to prevent others.[109]\\r\\nAlso prohibited under the same statute are those determined, with clear and convincing evidence, to have avoided such conviction by death or flight.\\r\\nThe first soldier to be buried in Arlington was Private William Henry Christman of Pennsylvania on May 13, 1864.[110] There are 396 Medal of Honor recipients buried in Arlington National Cemetery,[111] nine of whom are Canadian.\\r\\nFive state funerals have been held at Arlington: those of Presidents William Howard Taft and John F. Kennedy, his two brothers, Senator Robert F. Kennedy and Senator Edward \\"Ted\\" Kennedy, and General of the Armies John J. Pershing. Whether or not they were wartime service members, U.S. presidents are eligible to be buried at Arlington, since they oversaw the armed forces as commanders-in-chief.\\r\\nAmong the most frequently visited sites in the cemetery is the grave of President John F. Kennedy, Jacqueline Kennedy Onassis who is buried nearby along with their son Patrick and their stillborn daughter Arabella. His remains were interred there on March 14, 1967, a reinterment from his original Arlington burial site, some 20 feet (6.1?m) away, where he was buried in November 1963. The grave is marked with an \\"eternal flame\\". The remains of his brothers, Senator Robert F. Kennedy and Senator Edward M. \\"Ted\\" Kennedy, are buried nearby. The latter two graves are marked with simple crosses and footstones. On December 1, 1971, Robert Kennedy's body was re-interred 100 feet (30?m) from its original June 1968 burial site.\\r\\nTwo of the astronauts who were killed in January 27, 1967 flash fire inside the Apollo 1 Command Module, Gus Grissom and Roger Chaffee, are buried at the cemetery. John Glenn, the first American to orbit Earth and a longtime U.S. Senator from Ohio, was buried at the cemetery in April 2017.[112]\\r\\nBritish Diplomat and Field Marshal Sir John Dill was buried at the cemetery when he died in Washington D.C. during World War II.[113] The equestrian statue on Dill's grave is one of only two such statues at the cemetery; the other is Major General Philip Kearny's.[114]\\r\\nThe cemetery has within recent years announced policies and procedures that limit visitor access to the cemetery's grounds. The Cemetery's executive director has stated that some of these may create delays for visitors. Some have become controversial.\\r\\nOn August 6, 2013, Patrick Hallinan, Executive Director, Army National Military Cemeteries, issued an official memorandum that contained the cemetery's then-current bicycle use policy.[115][116] The memorandum permitted cyclists to travel in only one direction on only one route unless otherwise authorized by the executive director.[116] This \\"White Line\\" route traveled from the Old Post Chapel gate at Joint Base Myer-Henderson Hall towards the main entrance of the cemetery at Memorial Avenue, using Meigs Drive, Sherman Drive and Schley Drive.[116] The memorandum stated without explanation: Bicycle traffic will not be permitted to travel in the reverse direction, .....[116]\\r\\nCyclists could only use this route between 8:00?a.m. and 6:45?p.m. from April 1 to September 30 and between 8:00?a.m. and 4:45?p.m. from October 1 to March 31.[116] Cyclists had to wear bicycle helmets that certain designated organizations had approved.[116] Bicycles had to be equipped with headlights, tail lights or red reflectors in lieu of tail lights, regardless of the time of travel.[116]\\r\\nOn May 11, 2016, the Department of the Army published in the Federal Register a proposed rule that would, among other things, prohibit a visitor to an Army National Military Cemetery (Arlington National Cemetery and the United States Soldiers' and Airmen's Home National Cemetery) from riding a bicycle without first acquiring a pass to visit a relative's gravesite or columbarium niche.[117] After receiving 13 comments from 13 individuals concerning the use of bicycles in the cemetery (including comments from representatives of the Arlington County Board and local bicycle advocacy groups that opposed the new restrictions), the Department of the Army published a final rule in the Federal Register on September 26, 2016, that implemented the proposed rule, effective October 26, 2016.[118]\\r\\nIn accordance with the final rule, the cemetery issued a new bicycle use policy, effective October 26, 2016. The policy stated that bicycling would no longer be allowed on Cemetery grounds without a family pass. The policy further stated that \\"bicyclists traversing the cemetery grounds do impact funeral services and the experience that families expect and deserve as they visit their loved ones grave. .... As there are no bike paths on the cemetery grounds, mixing cyclists with pedestrians and vehicles creates a safety hazard.\\"[119]\\r\\nIn September 2016, Hallinan announced that the cemetery was increasing security measures for its visitors. In addition to random identification checks and other security measures already in place, the cemetery will require pedestrians to enter at set access points: the main entrance on Memorial Avenue, the Ord and Weitzel gate, and the Old Post Chapel gate at Joint Base Myer-Henderson Hall. Before entering the cemetery through its main entrance, all pedestrians will be screened through the cemetery's Welcome Center. All vehicle access will require presenting valid, government-issued photo identification, such as a drivers license or passport, when entering the cemetery. Vehicles will also be subject to random inspections. Hallinan stated that these processes may result in delays when entering the cemetery.[120]\\r\\nIn Batman v Superman: Dawn of Justice, the cemetery appeared as the backdrop for a state funeral held for Superman by the United States Army.[121] However, the physical filming took place in Michigan, using green screen.[122]","input":"Who was the first person buried at arlington national cemetery?"},{"output":"a pathological condition in which cells fail to respond normally to the hormone insulin","context":"Insulin resistance (IR) is a pathological condition in which cells fail to respond normally to the hormone insulin. The body produces insulin when glucose starts to be released into the bloodstream from the digestion of carbohydrates in the diet. Normally this insulin response triggers glucose being taken into body cells, to be used for energy, and inhibits the body from using fat for energy. The concentration of glucose in the blood decreases as a result, staying within the normal range even when a large amount of carbohydrates is consumed. When the body produces insulin under conditions of insulin resistance, the cells are resistant to the insulin and are unable to use it as effectively, leading to high blood sugar. Beta cells in the pancreas subsequently increase their production of insulin, further contributing to a high blood insulin level. This often remains undetected and can contribute to the development of type 2 diabetes or latent autoimmune diabetes of adults.[1] Although this type of chronic insulin resistance is harmful, during acute illness it is actually a well-evolved protective mechanism. Recent investigations have revealed that insulin resistance helps to conserve the brain's glucose supply by preventing muscles from taking up excessive glucose.[2] In theory, insulin resistance should even be strengthened under harsh metabolic conditions such as pregnancy, during which the expanding fetal brain demands more glucose.\\r\\nPeople who develop type 2 diabetes usually pass through earlier stages of insulin resistance and prediabetes, although those often go undiagnosed. Insulin resistance is a syndrome (a set of signs and symptoms) resulting from reduced insulin activity; it is also part of a larger constellation of symptoms called the metabolic syndrome.\\r\\nInsulin resistance may also develop in patients who have recently experienced abdominal or bariatric procedures.[3] This acute form of insulin resistance that may result post-operatively tends to increase over the short term, with sensitivity to insulin typically returning to patients after about five days.[4]\\r\\n\\r\\n\\r\\nThese depend on poorly understood variations in individual biology and consequently may not be found with all people diagnosed with insulin resistance.[5]\\r\\nSeveral associated risk factors include the following:\\r\\nInsulin resistance implies that the body's cells (primarily muscle) lose sensitivity to insulin, a hormone secreted by the pancreas to promote glucose utilization. At the molecular level, a cell senses insulin through insulin receptors, with the signal propagating through a cascade of molecules collectively known as PI3K/Akt/mTOR signaling pathway.[12] Recent studies suggested that the pathway may operate as a bistable switch under physiologic conditions for certain types of cells, and insulin response may well be a threshold phenomenon.[2][12][13] The pathway's sensitivity to insulin may be blunted by many factors such as free fatty acids,[14] causing insulin resistance. From a broader perspective, however, sensitivity tuning (including sensitivity reduction) is a common practice for an organism to adapt to the changing environment or metabolic conditions.[15] Pregnancy, for example, is a prominent change of metabolic conditions, under which the mother has to reduce her muscles' insulin sensitivity to spare more glucose for the brains (the mother's brain and the fetal brain). This can be achieved through raising the response threshold (i.e., postponing the onset of sensitivity) by secreting placental growth factor to interfere with the interaction between insulin receptor substrate (IRS) and PI3K, which is the essence of the so-called adjustable threshold hypothesis of insulin resistance.[2]\\r\\nIt is well known that insulin resistance commonly coexists with obesity.[16] Dietary fat has long been implicated as a driver of insulin resistance. Studies on animals have observed significant insulin resistance in rats after just 3 weeks on a high-fat diet (59% fat, 20% carb.)[17] Large quantities of saturated, monounsaturated, and polyunsaturated omega-6 fats all appear to be harmful to rats to some degree, compared to large amounts of starch, but saturated fat appears to be the most effective at producing IR.[18] This is partly caused by direct effects of a high-fat diet on blood markers, but, more significantly, ad libitum high-fat diet has the tendency to result in caloric intake that is far in excess of animals' energy needs, resulting in rapid weight gain. In humans, statistical evidence is more equivocal. Being insensitive to insulin is still positively correlated with fat intake, and negatively correlated with dietary fiber intake,[19] but both these factors are also correlated with excess body weight.\\r\\nThe effect of dietary fat is largely or completely overridden if the high-fat diet is modified to contain nontrivial quantities (in excess of 5ÿ10% of total fat intake) of polyunsaturated omega-3 fatty acids.[18][20][21] This protective effect is most established with regard to the so-called \\"marine long-chain omega-3 fatty acids\\", EPA and DHA, found in algae, krill and fish oil; evidence in favor of other omega-3 fatty acids, in particular, the most common vegetable-based omega-3 fatty acid, ALA, also exists,[22] but it is more limited; some studies find ALA effective only among people with insufficient long-chain omega-3 intake,[23] and some studies fail to find any effect at all[24] (ALA may be converted partially into EPA and DHA by the human body, but the conversion rate is thought to be 10% or less, depending on diet and gender). The effect is thought to explain relatively low incidence of IR, type 2 diabetes, and obesity in polar foragers such as Alaskan Eskimos consuming their ancestral diet (which is very high in fat, but contains substantial amounts of omega-3),[25][26] however, it is not strong enough to prevent IR in the typical modern Western diet. Unlike their omega-6 counterparts (which may be produced cheaply from a variety of sources, such as corn and soybeans), major sources of omega-3 fatty acids remain relatively rare and expensive. Consequently, the recommended average intake of omega-3 for adult men in the United States is only 1.6 grams/day, or less than 2% of total fat; currently, the average consumption of omega-3 in the United States is approximately 1.3 grams/day, almost all of it in the form of ALA; EPA and DHA contributed less than 0.1 grams/day.[27]\\r\\nElevated levels of free fatty acids and triglycerides in the blood stream and tissues have been found in many studies to contribute to diminished insulin sensitivity.[18][28][29][30] Triglyceride levels are driven by a variety of dietary factors. They are correlated with excess body weight.[31] They tend to rise due to overeating and fall during fat loss.[32] At constant energy intake, triglyceride levels are correlated positively with trans fat intake and strongly inversely correlated with omega-3 intake. High-carbohydrate, low-fat diets were found by many studies to result in elevated triglycerides,[33] in part due to higher production of VLDL from fructose and sucrose, and in part because increased carbohydrate intake tends to displace some omega-3 fatty acids from the diet.\\r\\nSeveral recent authors have suggested that the intake of simple sugars, and particularly fructose, is also a factor that contributes to insulin resistance.[34][35] Fructose is metabolized by the liver into triglycerides, and, as mentioned above, tends to raise their levels in the blood stream. Therefore, it may contribute to insulin resistance through the same mechanisms as dietary fat. Just like fat, high levels of fructose and/or sucrose induce insulin resistance in rats,[36][37] and, just as with fat, this insulin resistance is ameliorated by fish oil supplementation.[38] One study observed that a low-fat diet high in simple sugars (but not in complex carbohydrates and starches) significantly stimulates fatty acid synthesis, primarily of the saturated fatty acid palmitate, therefore, paradoxically, resulting in the plasma fatty acid pattern that is similar to that produced by a high-saturated-fat diet.[39] It should be pointed out that virtually all evidence of deleterious effects of simple sugars so far is limited to their concentrated formulations and sweetened beverages. In particular, very little is known about the effects of simple sugars in whole fruits and vegetables. If anything, epidemiological studies suggest that their high consumption is associated with somewhat lower risk of IR and/or metabolic syndrome.[40][41]\\r\\nYet another proposed mechanism involves the phenomenon known as leptin resistance. Leptin is a hormone that regulates long-term energy balance in many mammals. An important role of leptin is long-term inhibition of appetite in response to formation of body fat. This mechanism is known to be disrupted in many obese individuals: even though their leptin levels are commonly elevated, this does not result in reduction of appetite and caloric intake.[42] Leptin resistance may be triggered in rats by ad libitum consumption of energy-dense, highly palatable foods over a period of several days.[43] Chronic consumption of fructose in rats ultimately results in leptin resistance (however, this has only been demonstrated in a diet in which fructose provided 60% of calories;[44] consumption by humans in a typical Western diet is much lower.) Once leptin signalling has been disrupted, the individual becomes prone to further overeating, weight gain, and insulin resistance.\\r\\nAs elevated blood glucose levels are the primary stimulus for insulin secretion and production, habitually excessive carbohydrate intake is another likely contributor. This serves as a major motivation behind the low-carb family of diets. Furthermore, carbohydrates are not equally absorbed (for example, the blood glucose level response to a fixed quantity of carbohydrates in baked potatoes is about twice the response to the same quantity of carbohydrates in pumpernickel bread). Integrated blood glucose response to a fixed quantity of carbohydrates in a meal is known as glycemic index (GI). Some diets are based on this concept, assuming that consumption of low-GI food is less likely to result in insulin resistance and obesity, however, small to moderate amounts of simple sugars (i.e., sucrose, fructose, and glucose) in the typical developed-world diet seem to not have a causative effect on the development of insulin resistance.[45]\\r\\nOnce established, insulin resistance would result in increased circulating levels of insulin. Since insulin is the primary hormonal signal for energy storage into fat cells, which tend to retain their sensitivity in the face of hepatic and skeletal muscle resistance, IR stimulates the formation of new fatty tissue and accelerates weight gain.[46]\\r\\nAnother possible explanation is that both insulin resistance and obesity often have the same cause, systematic overeating, which has the potential to lead to insulin resistance and obesity due to repeated administration of excess levels of glucose, which stimulate insulin secretion; excess levels of fructose, which raise triglyceride levels in the bloodstream; and fats, which may be absorbed easily by the adipose cells, and tend to end up as fatty tissue in a hypercaloric diet. Some scholars go as far as to claim that neither insulin resistance, nor obesity really are metabolic disorders per se, but simply adaptive responses to sustained caloric surplus, intended to protect bodily organs from lipotoxicity (unsafe levels of lipids in the bloodstream and tissues): \\"Obesity should therefore not be regarded as a pathology or disease, but rather as the normal, physiologic response to sustained caloric surplus As a consequence of the high level of lipid accumulation in insulin target tissues including skeletal muscle and liver, it has been suggested that exclusion of glucose from lipid-laden cells is a compensatory defense against further accumulation of lipogenic substrate.\\"[47]\\r\\nFast food meals typically possess several characteristics, all of which have independently been linked to IR: they are energy-dense, palatable, and cheap, increasing risk of overeating and leptin resistance; simultaneously, they are high in dietary fat and fructose, and low in omega-3 and fiber; and they usually have high glycemic indices. Consumption of fast food has been proposed as a fundamental factor behind the metabolic syndrome epidemic and all its constituents.[46]\\r\\nAn American study has shown that glucosamine (often prescribed for joint problems) may cause insulin resistance.[48] Other studies, however, could not confirm a significant effect on blood glucose or insulin resistance.[49][50][51]\\r\\nStudies show that high levels of cortisol within the bloodstream from the digestion of animal protein may contribute to the development of insulin resistance.[52][53] Several studies conclude that high uric acid levels, apart from other contributing factors, by itself may be a significant cause of insulin resistance.[54]\\r\\nVitamin D deficiency also is associated with insulin resistance.[55]\\r\\nSedentary lifestyle increases the likelihood of development of insulin resistance.[56][57] It has been estimated that each 500 kcal/week increment in physical activity related energy expenditure, reduces the lifetime risk of type 2 diabetes by 9%.[58] A different study found that vigorous exercise at least once a week reduced the risk of type 2 diabetes in women by 33%.[59]\\r\\nProtease inhibitors found in HIV drugs are linked to insulin resistance.[60]\\r\\nAt the cellular level, much of the variance in insulin sensitivity between untrained, non-diabetic humans may be explained by two mechanisms: differences in phospholipid profiles of skeletal muscle cell membranes, and in intramyocellular lipid (ICML) stores within these cells.[61] High levels of lipids in the bloodstream have the potential to result in accumulation of triglycerides and their derivatives within muscle cells, which activate proteins Kinase C- and C-Ĳ, ultimately reducing the glucose uptake at any given level of insulin.[28][62] This mechanism is quite fast-acting and may induce insulin resistance within days or even hours in response to a large lipid influx.[63] Draining the intracellular reserves, on the other hand, is more challenging: moderate caloric restriction alone, even over a period of several months, appears to be ineffective,[64][65] and it must be combined with physical exercise to have any effect.\\r\\nIn the long term, diet has the potential to change the ratio of polyunsaturated to saturated phospholipids in cell membranes, correspondingly changing cell membrane fluidity; full impact of such changes is not fully understood, but it is known that the percentage of polyunsaturated phospholipids is strongly inversely correlated with insulin resistance.[66] It is hypothesized that increasing cell membrane fluidity by increasing PUFA concentration might result in an enhanced number of insulin receptors, an increased affinity of insulin to its receptors, and a reduced insulin resistance, and vice versa.[67]\\r\\nMany stressing factors may lead to increased cortisol in the bloodstream. Cortisol counteracts insulin, contributes to hyperglycemia-causing hepatic gluconeogenesis,[68] and inhibits the peripheral utilization of glucose, which eventually leads to insulin resistance.[68] It does this by decreasing the translocation of glucose transporters (especially GLUT4) to the cell membrane.[69][70]\\r\\nAlthough inflammation often is caused by cortisol, inflammation by itself also seems to be implicated in causing insulin resistance. Mice without JNK1-signaling do not develop insulin resistance under dietary conditions that normally produce it.[71][72] Recent study have found out the specific role of the MLK family of protein in the activation of JNK during obesity and insulin resistance.[73]\\r\\nRare type 2 diabetes cases sometimes use high levels of exogenous insulin. As short-term overdosing of insulin causes short-term insulin resistance, it has been hypothesized that chronic high dosing contributes to more permanent insulin resistance.[citation needed]\\r\\nAt a molecular level, insulin resistance has been proposed to be a reaction to excess nutrition by superoxide dismutase in cell mitochondria that acts as an antioxidant defense mechanism. This link seems to exist under diverse causes of insulin resistance. It also is based on the finding that insulin resistance may be reversed rapidly by exposing cells to mitochondrial uncouplers, electron transport chain inhibitors, or mitochondrial superoxide dismutase mimetics.[74]\\r\\nRecent research and experimentation has uncovered a non-obesity related connection to insulin resistance and type 2 diabetes. It has long been observed that patients who have had some kinds of bariatric surgery have increased insulin sensitivity and even remission of type 2 diabetes. It was discovered that diabetic/insulin resistant non-obese rats whose duodenum has been removed surgically, also experienced increased insulin sensitivity[75] and remission of type 2 diabetes. This suggested similar surgery in humans, and early reports in prominent medical journals[76] are that the same effect is seen in humans, at least the small number who have participated in the experimental surgical program. The speculation is, that some substance is produced in the mucosa of that initial portion of the small intestine that signals body cells to become insulin resistant. If the producing tissue is removed, the signal ceases and body cells revert to normal insulin sensitivity. No such substance has been found as yet, and the existence of such a substance remains speculative.[citation needed]\\r\\nInsulin resistance is associated with PCOS.[77]\\r\\nHepatitis C also makes people three to four times more likely to develop type 2 diabetes and insulin resistance.[10] In addition, \\"people with Hepatitis C who develop diabetes probably have susceptible insulin-producing cells, and probably would get it anyway, but much later in life.[10] The extra insulin resistance caused by Hepatitis C apparently brings on diabetes at age 35 or 40, instead of 65 or 70.\\"[10]\\r\\nOne of insulin's functions is to regulate delivery of glucose into cells to provide them with energy.[78] Insulin resistant cells cannot take in glucose, amino acids and fatty acids. Thus, glucose, fatty acids and amino acids 'leak' out of the cells. A decrease in insulin/glucagon ratio inhibits glycolysis which in turn decreases energy production. The resulting increase in blood glucose may raise levels outside the normal range and cause adverse health effects, depending on dietary conditions.[79] Certain cell types such as fat and muscle cells require insulin to absorb glucose. When these cells fail to respond adequately to circulating insulin, blood glucose levels rise. The liver helps regulate glucose levels by reducing its secretion of glucose in the presence of insulin. This normal reduction in the liver's glucose production may not occur in people with insulin resistance.[80]\\r\\nInsulin resistance in muscle and fat cells reduces glucose uptake (and also local storage of glucose as glycogen and triglycerides, respectively), whereas insulin resistance in liver cells results in reduced glycogen synthesis and storage and also a failure to suppress glucose production and release into the blood. Insulin resistance normally refers to reduced glucose-lowering effects of insulin. However, other functions of insulin can also be affected. For example, insulin resistance in fat cells reduces the normal effects of insulin on lipids and results in reduced uptake of circulating lipids and increased hydrolysis of stored triglycerides. Increased mobilization of stored lipids in these cells elevates free fatty acids in the blood plasma. Elevated blood fatty-acid concentrations (associated with insulin resistance and diabetes mellitus Type 2), reduced muscle glucose uptake, and increased liver glucose production all contribute to elevated blood glucose levels. High plasma levels of insulin and glucose due to insulin resistance are a major component of the metabolic syndrome. If insulin resistance exists, more insulin needs to be secreted by the pancreas. If this compensatory increase does not occur, blood glucose concentrations increase and type 2 diabetes or latent autoimmune diabetes of adults occurs.[79][81]\\r\\nAny food or drink containing glucose (or the digestible carbohydrates that contain it, such as sucrose, starch, etc.) causes blood glucose levels to increase. In normal metabolism, the elevated blood glucose level instructs beta () cells in the Islets of Langerhans, located in the pancreas, to release insulin into the blood. The insulin, in turn, makes insulin-sensitive tissues in the body (primarily skeletal muscle cells, adipose tissue, and liver) absorb glucose, and thereby lower the blood glucose level. The beta cells reduce insulin output as the blood glucose level falls, allowing blood glucose to settle at a constant of approximately 5 mmol/L (mM) (90?mg/dL). In an insulin-resistant person, normal levels of insulin do not have the same effect in controlling blood glucose levels. During the compensated phase on insulin resistance, insulin levels are higher, and blood glucose levels are still maintained. If compensatory insulin secretion fails, then either fasting (impaired fasting glucose) or postprandial (impaired glucose tolerance) glucose concentrations increase. Eventually, type 2 diabetes or latent autoimmune diabetes occurs when glucose levels become higher throughout the day as the resistance increases and compensatory insulin secretion fails. The elevated insulin levels also have additional effects (see insulin) that cause further abnormal biological effects throughout the body.[citation needed]\\r\\nThe most common type of insulin resistance is associated with overweight and obesity in a condition known as the metabolic syndrome. Insulin resistance often progresses to full Type 2 diabetes mellitus (T2DM) or latent autoimmune diabetes of adults.[82][83] This often is seen when hyperglycemia develops after a meal, when pancreatic -cells are unable to produce sufficient insulin to maintain normal blood sugar levels (euglycemia) in the face of insulin resistance. The inability of the -cells to produce sufficient insulin in a condition of hyperglycemia is what characterizes the transition from insulin resistance to T2DM.[84]\\r\\nVarious disease states make body tissues more resistant to the actions of insulin. Examples include infection (mediated by the cytokine TNFϫ) and acidosis. Recent research is investigating the roles of adipokines (the cytokines produced by adipose tissue) in insulin resistance. Certain drugs also may be associated with insulin resistance (e.g., glucocorticoids).[citation needed]\\r\\nThe presence of insulin leads to a kind of insulin resistance; every time a cell is exposed to insulin, the production of GLUT4 (Glucose transporter type 4) on the membrane of the cell decreases somewhat.[85] In the presence of a higher than usual level of insulin (generally caused by insulin resistance), this down-regulation acts as a kind of positive feedback, increasing the need for insulin. Exercise reverses this process in muscle tissue,[86] but if it is left unchecked, it may contribute to insulin resistance.\\r\\nElevated blood levels of glucoseregardless of causelead to increased glycation of proteins with changes, only a few of which are understood in any detail, in protein function throughout the body.[87][88]\\r\\nInsulin resistance often is found in people with visceral adiposity (i.e., a high degree of fatty tissue within the abdomenas distinct from subcutaneous adiposity or fat between the skin and the muscle wall, especially elsewhere on the body, such as hips or thighs), hypertension, hyperglycemia, and dyslipidemia involving elevated triglycerides, small dense low-density lipoprotein (sdLDL) particles, and decreased HDL cholesterol levels. With respect to visceral adiposity, a great deal of evidence suggests two strong links with insulin resistance. First, unlike subcutaneous adipose tissue, visceral adipose cells produce significant amounts of proinflammatory cytokines such as tumor necrosis factor-alpha (TNF-a), and Interleukins-1 and ?6, etc. In numerous experimental models, these proinflammatory cytokines disrupt normal insulin action in fat and muscle cells, and may be a major factor in causing the whole-body insulin resistance observed in patients with visceral adiposity. Much of the attention on production of proinflammatory cytokines has focused on the IKK-beta/NF-kappa-B pathway, a protein network that enhances transcription of inflammatory markers and mediators that may cause insulin resistance. Second, visceral adiposity is related to an accumulation of fat in the liver, a condition known as non-alcoholic fatty liver disease (NAFLD). The result of NAFLD is an excessive release of free fatty acids into the bloodstream (due to increased lipolysis), and an increase in hepatic glycogenolysis and hepatic glucose production, both of which have the effect of exacerbating peripheral insulin resistance and increasing the likelihood of Type 2 diabetes mellitus.[citation needed]\\r\\nAlso, insulin resistance often is associated with a hypercoagulable state (impaired fibrinolysis) and increased inflammatory cytokine levels.[89]\\r\\nA fasting serum insulin level greater than 25 mIU/L or 174 pmol/L is considered insulin resistance. The same levels apply three hours after the last meal.[90]\\r\\nDuring a glucose tolerance test, which may be used to diagnose diabetes mellitus, a fasting patient takes a 75?gram oral dose of glucose. Then blood glucose levels are measured over the following two hours.\\r\\nInterpretation is based on WHO guidelines. After two hours a glycemia less than 7.8?mmol/L (140?mg/dL) is considered normal, a glycemia of between 7.8 and 11.0?mmol/L (140 to 197?mg/dL) is considered as impaired glucose tolerance (IGT), and a glycemia of greater than or equal to 11.1?mmol/L (200?mg/dL) is considered diabetes mellitus.\\r\\nAn oral glucose tolerance test (OGTT) may be normal or mildly abnormal in simple insulin resistance. Often, there are raised glucose levels in the early measurements, reflecting the loss of a postprandial peak (after the meal) in insulin production. Extension of the testing (for several more hours) may reveal a hypoglycemic \\"dip,\\" that is a result of an overshoot in insulin production after the failure of the physiologic postprandial insulin response.[citation needed]\\r\\nThe gold standard for investigating and quantifying insulin resistance is the \\"hyperinsulinemic euglycemic clamp,\\" so-called because it measures the amount of glucose necessary to compensate for an increased insulin level without causing hypoglycemia.[91] It is a type of glucose clamp technique. The test rarely is performed in clinical care, but is used in medical research, for example, to assess the effects of different medications. The rate of glucose infusion commonly is referred to in diabetes literature as the GINF value.[92]\\r\\nThe procedure takes about two hours. Through a peripheral vein, insulin is infused at 10ÿ120 mU per m2 per minute. In order to compensate for the insulin infusion, glucose 20% is infused to maintain blood sugar levels between 5 and 5.5?mmol/L. The rate of glucose infusion is determined by checking the blood sugar levels every five to ten minutes.[92]\\r\\nThe rate of glucose infusion during the last thirty minutes of the test determines insulin sensitivity. If high levels (7.5?mg/min or higher) are required, the patient is insulin-sensitive. Very low levels (4.0?mg/min or lower) indicate that the body is resistant to insulin action. Levels between 4.0 and 7.5?mg/min are not definitive, and suggest \\"impaired glucose tolerance,\\" an early sign of insulin resistance.[92]\\r\\nThis basic technique may be enhanced significantly by the use of glucose tracers. Glucose may be labeled with either stable or radioactive atoms. Commonly used tracers are 3-3H glucose (radioactive), 6,6 2H-glucose (stable) and 1-13C Glucose (stable). Prior to beginning the hyperinsulinemic period, a 3h tracer infusion enables one to determine the basal rate of glucose production. During the clamp, the plasma tracer concentrations enable the calculation of whole-body insulin-stimulated glucose metabolism, as well as the production of glucose by the body (i.e., endogenous glucose production).[92]\\r\\nAnother measure of insulin resistance is the modified insulin suppression test developed by Gerald Reaven at Stanford University. The test correlates well with the euglycemic clamp, with less operator-dependent error. This test has been used to advance the large body of research relating to the metabolic syndrome.[92]\\r\\nPatients initially receive 25 g of octreotide (Sandostatin) in 5 mL of normal saline over 3 to 5 minutes via intravenous infusion (IV) as an initial bolus, and then, are infused continuously with an intravenous infusion of somatostatin (0.27 g/m2/min) to suppress endogenous insulin and glucose secretion. Next, insulin and 20% glucose are infused at rates of 32 and 267?mg/m2/min, respectively. Blood glucose is checked at zero, 30, 60, 90, and 120 minutes, and thereafter, every 10 minutes for the last half-hour of the test. These last four values are averaged to determine the steady-state plasma glucose level (SSPG). Subjects with an SSPG greater than 150?mg/dL are considered to be insulin-resistant.[92]\\r\\nGiven the complicated nature of the \\"clamp\\" technique (and the potential dangers of hypoglycemia in some patients), alternatives have been sought to simplify the measurement of insulin resistance. The first was the Homeostatic Model Assessment (HOMA), and a more recent method is the Quantitative insulin sensitivity check index (QUICKI). Both employ fasting insulin and glucose levels to calculate insulin resistance, and both correlate reasonably with the results of clamping studies. Wallace et al. point out that QUICKI is the logarithm of the value from one of the HOMA equations.[93]\\r\\nThe primary treatment for insulin resistance is exercise and weight loss. Research shows that a low-carbohydrate diet may help.[94] Both metformin and thiazolidinediones improve insulin resistance, but only are approved therapies for type 2 diabetes, not for insulin resistance. By contrast, growth hormone replacement therapy may be associated with increased insulin resistance.[95]\\r\\nMetformin has become one of the more commonly prescribed medications for insulin resistance.[96] Unfortunately, Metformin also masks Vitamin B12 deficiency, so accompanying sub-lingual Vitamin B12 tablets are recommended.\\r\\nInsulin resistance is often associated with abnormalities in lipids particularly high blood triglycerides and low high density lipoprotein.[18][28]\\r\\nThe Diabetes Prevention Program (DPP) showed that exercise and diet were nearly twice as effective as metformin at reducing the risk of progressing to type 2 diabetes.[97] However, the participants in the DPP trial regained about 40% of the weight that they had lost at the end of 2.8 years, resulting in a similar incidence of diabetes development in both the lifestyle intervention and the control arms of the trial.[98] One 2009 study found that carbohydrate deficit after exercise, but not energy deficit, contributed to insulin sensitivity increase.[99]\\r\\nResistant starch from high-amylose corn, amylomaize, has been shown to reduce insulin resistance in healthy individuals, in individuals with insulin resistance, and in individuals with type 2 diabetes.[100] Animal studies demonstrate that it cannot reverse damage already done by high glucose levels, but that it reduces insulin resistance and reduces the development of further damage.[101][102][103]\\r\\nSome types of polyunsaturated fatty acids (omega-3) may moderate the progression of insulin resistance into type 2 diabetes,[104][105][106] however, omega-3 fatty acids appear to have limited ability to reverse insulin resistance, and they cease to be efficacious once type 2 diabetes is established.[107]\\r\\nCaffeine intake limits insulin action, but not enough to increase blood-sugar levels in healthy persons. People who already have type 2 diabetes may see a small increase in levels if they take 2 or 2-1/2 cups of coffee per day.[108]\\r\\nThe concept that insulin resistance may be the underlying cause of diabetes mellitus type 2 was first advanced by Professor Wilhelm Falta and published in Vienna in 1931,[109] and confirmed as contributory by Sir Harold Percival Himsworth of the University College Hospital Medical Centre in London in 1936,[110] however, type 2 diabetes does not occur unless there is concurrent failure of compensatory insulin secretion.[111]","input":"What dies it mean to be insulin resistant?"},{"output":"North America","context":"","input":"Where did antoine de saint exupery write le petit prince?"},{"output":"July 20, 1969, at 20:18 UTC","context":"\\r\\nApollo 11 was the spaceflight that landed the first two humans on the Moon. Mission commander Neil Armstrong and pilot Buzz Aldrin, both American, landed the lunar module Eagle on July 20, 1969, at 20:18 UTC. Armstrong became the first to step onto the lunar surface six hours after landing on July 21 at 02:56:15 UTC; Aldrin joined him about 20 minutes later. They spent about two and a quarter hours together outside the spacecraft, and collected 47.5 pounds (21.5?kg) of lunar material to bring back to Earth. Michael Collins piloted the command module Columbia alone in lunar orbit while they were on the Moon's surface. Armstrong and Aldrin spent just under a day on the lunar surface before rejoining Columbia in lunar orbit.\\r\\nApollo 11 was launched by a Saturn V rocket from Kennedy Space Center in Merritt Island, Florida, on July 16 at 9:32 am EDT (13:32 UTC) and was the fifth manned mission of NASA's Apollo program. The Apollo spacecraft had three parts: a command module (CM) with a cabin for the three astronauts, and the only part that landed back on Earth; a service module (SM), which supported the command module with propulsion, electrical power, oxygen, and water; and a lunar module (LM) that had two stages ÿ a lower stage for landing on the Moon, and an upper stage to place the astronauts back into lunar orbit.\\r\\nAfter being sent toward the Moon by the Saturn V's upper stage, the astronauts separated the spacecraft from it and traveled for three days until they entered into lunar orbit. Armstrong and Aldrin then moved into the lunar module Eagle and landed in the Sea of Tranquility. They stayed a total of about 21.5 hours on the lunar surface. The astronauts used Eagle's upper stage to lift off from the lunar surface and rejoin Collins in the command module. They jettisoned Eagle before they performed the maneuvers that blasted them out of lunar orbit on a trajectory back to Earth. They returned to Earth and landed in the Pacific Ocean on July 24.\\r\\nThe landing was broadcast on live TV to a worldwide audience. Armstrong stepped onto the lunar surface and described the event as \\"one small step for [a] man, one giant leap for mankind.\\" Apollo 11 effectively ended the Space Race and fulfilled a national goal proposed in 1961 by U.S. President John F. Kennedy: \\"before this decade is out, of landing a man on the Moon and returning him safely to the Earth.\\"[7]\\r\\n\\r\\n\\r\\nApollo 11 was the second all-veteran multi-person crew (the first being Apollo 10) in human spaceflight history.[8] A previous solo veteran flight had been made on Soyuz 1 in 1967 by Soviet cosmonaut Vladimir Komarov.[9]\\r\\nCollins was originally slated to be the Command Module Pilot (CMP) on Apollo 8 but was removed when he required surgery on his back and was replaced by Jim Lovell, his backup for that flight. After Collins was medically cleared, he took what would have been Lovell's spot on Apollo 11; as a veteran of Apollo 8, Lovell was transferred to Apollo 11's backup crew and promoted to backup commander.\\r\\nIn early 1969, Anders accepted a job with the National Space Council effective August 1969 and announced that he would retire as an astronaut on that date. At that point Ken Mattingly was moved from the support crew into parallel training with Anders as backup Command Module Pilot in case Apollo 11 was delayed past its intended July launch (at which point Anders would be unavailable if needed) and would later join Lovell's crew and ultimately be assigned as the original Apollo 13 CMP.[10]\\r\\nAfter the crew of Apollo 10 named their spacecraft Charlie Brown and Snoopy, assistant manager for public affairs Julian Scheer wrote to Manned Spacecraft Center director George M. Low to suggest the Apollo 11 crew be less flippant in naming their craft. During early mission planning, the names Snowcone and Haystack were used and put in the news release,[11] but the crew later decided to change them.\\r\\nThe Command Module was named Columbia after the Columbiad, the giant cannon shell \\"spacecraft\\" fired by a giant cannon (also from Florida) in Jules Verne's 1865 novel From the Earth to the Moon.[12] The Lunar Module was named Eagle for the national bird of the United States, the bald eagle, which is featured prominently on the mission insignia.\\r\\nThe Apollo 11 mission insignia was designed by Collins, who wanted a symbol for \\"peaceful lunar landing by the United States\\". He chose an eagle as the symbol, put an olive branch in its beak, and drew a lunar background with the Earth in the distance. NASA officials said the talons of the eagle looked too \\"warlike\\" and after some discussion, the olive branch was moved to the claws. The crew decided the Roman numeral XI would not be understood in some nations and went with \\"Apollo 11\\"; they decided not to put their names on the patch, so it would \\"be representative of everyone who had worked toward a lunar landing\\".[13] All colors are natural, with blue and gold borders around the patch.\\r\\nWhen the Eisenhower dollar coin was released in 1971, the patch design provided the eagle for its reverse side.[14] The design was also used for the smaller Susan B. Anthony dollar unveiled in 1979, ten years after the Apollo 11 mission.[15]\\r\\nNeil Armstrong's personal preference kit carried a piece of wood from the Wright brothers' 1903 airplane's left propeller and a piece of fabric from its wing,[16] along with a diamond-studded astronaut pin originally given to Deke Slayton by the widows of the Apollo 1 crew. This pin had been intended to be flown on Apollo 1 and given to Slayton after the mission but following the disastrous launch pad fire and subsequent funerals, the widows gave the pin to Slayton and Armstrong took it on Apollo 11.[17]\\r\\nIn addition to many people crowding highways and beaches near the launch site, millions watched the event on television, with NASA Chief of Public Information Jack King providing commentary. President Richard M. Nixon viewed the proceedings from the Oval Office of the White House.\\r\\nA Saturn V launched Apollo 11 from Launch Pad 39A, part of the Launch Complex 39 site at the Kennedy Space Center on July 16, 1969, at 13:32:00 UTC (9:32:00?a.m. EDT local time). It entered Earth orbit, at an altitude of 100.4 nautical miles (185.9?km) by 98.9 nautical miles (183.2?km), twelve minutes later.[1] After one and a half orbits, the S-IVB third-stage engine pushed the spacecraft onto its trajectory toward the Moon with the trans-lunar injection (TLI) burn at 16:22:13 UTC. About 30 minutes later, the transposition, docking, and extraction maneuver was performed: this involved separating the Apollo Command/Service Module (CSM) from the spent rocket stage, turning around, and docking with the Lunar Module still attached to the stage. After the Lunar Module was extracted, the combined spacecraft headed for the Moon, while the rocket stage flew on a trajectory past the Moon and into orbit around the Sun.[4]\\r\\nOn July 19 at 17:21:50 UTC, Apollo 11 passed behind the Moon and fired its service propulsion engine to enter lunar orbit. In the thirty orbits[18] that followed, the crew saw passing views of their landing site in the southern Sea of Tranquility (Mare Tranquillitatis) about 12 miles (19?km) southwest of the crater Sabine D (0.67408N, 23.47297E). The landing site was selected in part because it had been characterized as relatively flat and smooth by the automated Ranger 8 and Surveyor 5 landers along with the Lunar Orbiter mapping spacecraft and unlikely to present major landing or extravehicular activity (EVA) challenges.[19]\\r\\nOn July 20, 1969, the Lunar Module Eagle separated from the Command Module Columbia. Collins, alone aboard Columbia, inspected Eagle as it pirouetted before him to ensure the craft was not damaged.\\r\\nAs the descent began, Armstrong and Aldrin found that they were passing landmarks on the surface four seconds early and reported that they were \\"long\\"; they would land miles west of their target point.\\r\\nFive minutes into the descent burn, and 6,000 feet (1,800?m) above the surface of the Moon, the LM navigation and guidance computer distracted the crew with the first of several unexpected \\"1202\\" and \\"1201\\" program alarms. Inside Mission Control Center in Houston, Texas, computer engineer Jack Garman told guidance officer Steve Bales it was safe to continue the descent, and this was relayed to the crew. The program alarms indicated \\"executive overflows\\", meaning the guidance computer could not complete all of its tasks in real time and had to postpone some of them.[20]\\r\\nDue to an error in the checklist manual, the rendezvous radar switch was placed in the wrong position. This caused it to send erroneous signals to the computer. The result was that the computer was being asked to perform all of its normal functions for landing while receiving an extra load of spurious data which used up 15% of its time. The computer (or rather the software in it) was smart enough to recognize that it was being asked to perform more tasks than it should be performing. It then sent out an alarm, which meant to the astronaut, I'm overloaded with more tasks than I should be doing at this time and I'm going to keep only the more important tasks; i.e., the ones needed for landing?... Actually, the computer was programmed to do more than recognize error conditions. A complete set of recovery programs was incorporated into the software. The software's action, in this case, was to eliminate lower priority tasks and re-establish the more important ones?... If the computer hadn't recognized this problem and taken recovery action, I doubt if Apollo 11 would have been the successful moon landing it was.[21][a]\\r\\nWhen Armstrong again looked outside, he saw that the computer's landing target was in a boulder-strewn area just north and east of a 300-meter (980?ft) diameter crater (later determined to be West crater, named for its location in the western part of the originally planned landing ellipse). Armstrong took semi-automatic control[26] and, with Aldrin calling out altitude and velocity data, landed at 20:17:40 UTC on Sunday July 20 with about 25 seconds of fuel left.[5]\\r\\nApollo 11 landed with less fuel than other missions, and the astronauts encountered a premature low fuel warning. This was later found to be the result of greater propellant 'slosh' than expected, uncovering a fuel sensor. On subsequent missions, extra anti-slosh baffles were added to the tanks to prevent this.[5]\\r\\nThroughout the descent, Aldrin had called out navigation data to Armstrong, who was busy piloting the LM. A few moments before the landing, a light informed Aldrin that at least one of the 67-inch (170?cm) probes hanging from Eagle's footpads had touched the surface, and he said: \\"Contact light!\\" Three seconds later, Eagle landed and Armstrong said \\"Shutdown.\\" Aldrin immediately said \\"Okay, engine stop. ACA ÿ out of detent.\\" Armstrong acknowledged \\"Out of detent. Auto\\" and Aldrin continued \\"Mode control ÿ both auto. Descent engine command override off. Engine arm ÿ off. 413 is in.\\"\\r\\nCharles Duke, CAPCOM during the landing phase, acknowledged their landing by saying \\"We copy you down, Eagle.\\"\\r\\nArmstrong acknowledged Aldrin's completion of the post landing checklist with \\"Engine arm is off\\", before responding to Duke with the words, \\"Houston, Tranquility Base here. The Eagle has landed.\\" Armstrong's unrehearsed[27] change of call sign from \\"Eagle\\" to \\"Tranquility Base\\" emphasized to listeners that landing was complete and successful. Duke mispronounced his reply as he expressed the relief at Mission Control: \\"Roger, Twan Tranquility, we copy you on the ground. You got a bunch of guys about to turn blue. We're breathing again. Thanks a lot.\\"[5][28]\\r\\nTwo and a half hours after landing, before preparations began for the EVA, Aldrin radioed to Earth:\\r\\nThis is the LM pilot. I'd like to take this opportunity to ask every person listening in, whoever and wherever they may be, to pause for a moment and contemplate the events of the past few hours and to give thanks in his or her own way.[29]\\r\\nHe then took communion privately. At this time NASA was still fighting a lawsuit brought by atheist Madalyn Murray O'Hair (who had objected to the Apollo 8 crew reading from the Book of Genesis) demanding that their astronauts refrain from broadcasting religious activities while in space. As such, Aldrin chose to refrain from directly mentioning taking communion on the Moon. Aldrin was an elder at the Webster Presbyterian Church, and his communion kit was prepared by the pastor of the church, the Rev. Dean Woodruff. Aldrin described communion on the Moon and the involvement of his church and pastor in the October 1970 edition of Guideposts magazine and in his book Return to Earth. Webster Presbyterian possesses the chalice used on the Moon and commemorates the event each year on the Sunday closest to July 20.[30]\\r\\nThe schedule for the mission called for the astronauts to follow the landing with a five-hour sleep period as they had been awake since early morning. However, they elected to forgo the sleep period and begin the preparations for the EVA early, thinking that they would be unable to sleep.\\r\\nThe astronauts planned placement of the Early Apollo Scientific Experiment Package (EASEP)[31] and the U.S. flag by studying their landing site through Eagle's twin triangular windows, which gave them a 60 field of view. Preparation required longer than the two hours scheduled. Armstrong initially had some difficulties squeezing through the hatch with his Portable Life Support System (PLSS). According to veteran Moon-walker John Young, a redesign of the LM to incorporate a smaller hatch had not been followed by a redesign of the PLSS backpack, so some of the highest heart rates recorded from Apollo astronauts occurred during LM egress and ingress.[32][33]\\r\\nSeveral books indicate early mission timelines had Buzz Aldrin rather than Neil Armstrong as the first man on the Moon.[34]\\r\\nAt 02:39 UTC on Monday July 21, 1969, Armstrong opened the hatch, and at 02:51 UTC began his descent to the lunar surface. The Remote Control Unit controls on his chest kept him from seeing his feet. Climbing down the nine-rung ladder, Armstrong pulled a D-ring to deploy the Modular Equipment Stowage Assembly (MESA) folded against Eagle's side and activate the TV camera, and at 02:56:15 UTC he set his left foot on the surface.[35][36] The first landing used slow-scan television incompatible with commercial TV, so it was displayed on a special monitor and a conventional TV camera viewed this monitor, significantly reducing the quality of the picture.[37] The signal was received at Goldstone in the United States but with better fidelity by Honeysuckle Creek Tracking Station in Australia. Minutes later the feed was switched to the more sensitive Parkes radio telescope in Australia.[38] Despite some technical and weather difficulties, ghostly black and white images of the first lunar EVA were received and broadcast to at least 600 million people on Earth.[39] Although copies of this video in broadcast format were saved and are widely available, recordings of the original slow scan source transmission from the lunar surface were accidentally destroyed during routine magnetic tape re-use at NASA.\\r\\nWhile still on the ladder, Armstrong uncovered a plaque mounted on the LM Descent Stage bearing two drawings of Earth (of the Western and Eastern Hemispheres), an inscription, and signatures of the astronauts and President Nixon. The inscription read:\\r\\nHere men from the planet Earth first set foot upon the Moon, July 1969 A.D. We came in peace for all mankind.\\r\\nAfter describing the surface dust as \\"very fine-grained\\" and \\"almost like a powder,\\"[36] six and a half hours after landing,[1] Armstrong stepped off Eagle's footpad and declared, \\"That's one small step for [a] man, one giant leap for mankind.\\"[b][40][41][42][43]\\r\\nArmstrong intended to say \\"That's one small step for a man\\", but the word \\"a\\" is not audible in the transmission, and thus was not initially reported by most observers of the live broadcast. When later asked about his quote, Armstrong said he believed he said \\"for a man\\", and subsequent printed versions of the quote included the \\"a\\" in square brackets. One explanation for the absence may be that his accent caused him to slur the words \\"for a\\" together; another is the intermittent nature of the audio and video links to Earth, partly because of storms near Parkes Observatory. More recent digital analysis of the tape claims to reveal the \\"a\\" may have been spoken but obscured by static.[44][45]\\r\\nAbout seven minutes after stepping onto the Moon's surface, Armstrong collected a contingency soil sample using a sample bag on a stick. He then folded the bag and tucked it into a pocket on his right thigh. This was to guarantee there would be some lunar soil brought back in case an emergency required the astronauts to abandon the EVA and return to the LM.[46]\\r\\nTwelve minutes after the contingency sample was collected,[1] Aldrin joined Armstrong on the surface, and described the view with the simple phrase, \\"Magnificent desolation.\\"[36]\\r\\nIn addition to fulfilling President Kennedy's mandate to land a man on the Moon before the end of the 1960s,[47] Apollo 11 was an engineering test of the Apollo system; therefore, Armstrong snapped photos of the LM so engineers would be able to judge its post-landing condition. He removed the TV camera from the MESA and made a panoramic sweep, then mounted it on a tripod 68 feet (21?m) from the LM. The TV camera cable remained partly coiled and presented a tripping hazard throughout the EVA.\\r\\nArmstrong said that moving in the lunar gravity, one-sixth of Earth's, was \\"even perhaps easier than the simulations?... It's absolutely no trouble to walk around.\\"[36] Aldrin joined him on the surface and tested methods for moving around, including two-footed kangaroo hops. The PLSS backpack created a tendency to tip backwards, but neither astronaut had serious problems maintaining balance. Loping became the preferred method of movement. The astronauts reported that they needed to plan their movements six or seven steps ahead. The fine soil was quite slippery. Aldrin remarked that moving from sunlight into Eagle's shadow produced no temperature change inside the suit, though the helmet was warmer in sunlight, so he felt cooler in shadow.[36]\\r\\nThe astronauts planted a specially designed U.S. flag on the lunar surface, in clear view of the TV camera. Some time later, President Richard Nixon spoke to them through a telephone-radio transmission which Nixon called \\"the most historic phone call ever made from the White House.\\"[48] Nixon originally had a long speech prepared to read during the phone call, but Frank Borman, who was at the White House as a NASA liaison during Apollo 11, convinced Nixon to keep his words brief, to respect the lunar landing as Kennedy's legacy.[49] Armstrong thanked the President, and gave a brief reflection on the significance of the moment:\\r\\nNixon: Hello, Neil and Buzz. I'm talking to you by telephone from the Oval Room at the White House. And this certainly has to be the most historic telephone call ever made. I just can't tell you how proud we all are of what you've done. For every American, this has to be the proudest day of our lives. And for people all over the world, I am sure they too join with Americans in recognizing what an immense feat this is. Because of what you have done, the heavens have become a part of man's world. And as you talk to us from the Sea of Tranquility, it inspires us to redouble our efforts to bring peace and tranquility to Earth. For one priceless moment in the whole history of man, all the people on this Earth are truly one: one in their pride in what you have done, and one in our prayers that you will return safely to Earth.\\r\\nArmstrong: Thank you, Mr. President. It's a great honor and privilege for us to be here, representing not only the United States, but men of peace of all nations, and with interest and curiosity, and men with a vision for the future. It's an honor for us to be able to participate here today.\\r\\nThe MESA failed to provide a stable work platform and was in shadow, slowing work somewhat. As they worked, the moonwalkers kicked up gray dust which soiled the outer part of their suits, the integrated thermal meteoroid garment.\\r\\nThey deployed the EASEP, which included a passive seismograph and a Lunar Ranging Retroreflector (LRRR). Then Armstrong walked 196 feet (60?m) from the LM to snap photos at the rim of Little West Crater while Aldrin collected two core tubes. He used the geological hammer to pound in the tubes ÿ the only time the hammer was used on Apollo 11. The astronauts then collected rock samples using scoops and tongs on extension handles. Many of the surface activities took longer than expected, so they had to stop documenting sample collection halfway through the allotted 34 minutes.\\r\\nThree new minerals were discovered in the rock samples collected by the astronauts: armalcolite, tranquillityite, and pyroxferroite. Armalcolite was named after Armstrong, Aldrin, and Collins.\\r\\nDuring this period, Mission Control used a coded phrase to warn Armstrong that his metabolic rates were high and that he should slow down. He was moving rapidly from task to task as time ran out. However, as metabolic rates remained generally lower than expected for both astronauts throughout the walk, Mission Control granted the astronauts a 15-minute extension.[50] In a 2010 interview, Armstrong, who had walked a maximum of 196 feet (60?m) from the LM, explained that NASA limited the first moonwalk's time and distance because there was no empirical proof of how much cooling water the astronauts' PLSS backpacks would consume to handle their body heat generation while working on the Moon.[51]\\r\\nAldrin entered Eagle first. With some difficulty the astronauts lifted film and two sample boxes containing 21.55 kilograms (47.5?lb) of lunar surface material to the LM hatch using a flat cable pulley device called the Lunar Equipment Conveyor. Armstrong reminded Aldrin of a bag of memorial items in his suit pocket sleeve, and Aldrin tossed the bag down; Armstrong then jumped to the ladder's third rung and climbed into the LM. After transferring to LM life support, the explorers lightened the ascent stage for return to lunar orbit by tossing out their PLSS backpacks, lunar overshoes, one Hasselblad camera, and other equipment. They then pressurized the LM and settled down to sleep.[52]\\r\\nPresident Nixon's speech writer William Safire had prepared In Event of Moon Disaster for the President to read on television in the event the Apollo 11 astronauts were stranded on the Moon.[53] The contingency plan originated in a memo from Safire to Nixon's White House Chief of Staff H. R. Haldeman, in which Safire suggested a protocol the administration might follow in reaction to such a disaster.[54][55] According to the plan, Mission Control would \\"close down communications\\" with the LM, and a clergyman would \\"commend their souls to the deepest of the deep\\" in a public ritual likened to burial at sea. The last line of the prepared text contained an allusion to Rupert Brooke's First World War poem, \\"The Soldier\\".[55] The plan included presidential telephone calls to the astronauts' wives.\\r\\nWhile moving within the cabin, Aldrin accidentally damaged the circuit breaker that would arm the main engine for lift off from the Moon. There was concern this would prevent firing the engine, stranding them on the Moon. Fortunately, a felt-tip pen was sufficient to activate the switch.[52] Had this not worked, the Lunar Module circuitry could have been reconfigured to allow firing the ascent engine.[56]\\r\\nAfter about seven hours of rest, the crew was awakened by Houston to prepare for the return flight. Two and a half hours later, at 17:54 UTC, they lifted off in Eagle's ascent stage to rejoin Collins aboard Columbia in lunar orbit.\\r\\nAfter more than 21? total hours on the lunar surface, they had left behind scientific instruments that included a retroreflector array used for the Lunar Laser Ranging Experiment and a Passive Seismic Experiment Package used to measure moonquakes. They also left an Apollo 1 mission patch, and a memorial bag containing a gold replica of an olive branch as a traditional symbol of peace and a silicon message disk. The disk carries the goodwill statements by Presidents Eisenhower, Kennedy, Johnson, and Nixon and messages from leaders of 73 countries around the world. The disc also carries a listing of the leadership of the US Congress, a listing of members of the four committees of the House and Senate responsible for the NASA legislation, and the names of NASA's past and present top management.[57] (In his 1989 book, Men from Earth, Aldrin says that the items included Soviet medals commemorating Cosmonauts Vladimir Komarov and Yuri Gagarin.) Also, according to Deke Slayton's book Moonshot, Armstrong carried with him a special diamond-studded astronaut pin from Slayton.\\r\\nFilm taken from the LM Ascent Stage upon liftoff from the Moon reveals the American flag, planted some 25 feet (8?m) from the descent stage, whipping violently in the exhaust of the ascent stage engine. Aldrin looked up in time to witness the flag topple:[1] \\"The ascent stage of the LM separated?... I was concentrating on the computers, and Neil was studying the attitude indicator, but I looked up long enough to see the flag fall over.\\"[18] Subsequent Apollo missions usually planted the American flags at least 100 feet (30?m) from the LM to prevent them being blown over by the ascent engine exhaust.\\r\\nAfter rendezvous with Columbia, Eagle's ascent stage was jettisoned into lunar orbit on July 21, 1969, at 23:41 UTC. Just before the Apollo 12 flight, it was noted that Eagle was still likely to be orbiting the Moon. Later NASA reports mentioned that Eagle's orbit had decayed, resulting in it impacting in an \\"uncertain location\\" on the lunar surface.[58] The location is uncertain because the Eagle ascent stage was not tracked after it was jettisoned, and the lunar gravity field is sufficiently non-uniform to make the orbit of the spacecraft unpredictable after a short time. NASA estimated that the orbit had decayed within months and would have impacted on the Moon.\\r\\nOn July 23, the last night before splashdown, the three astronauts made a television broadcast in which Collins commented:\\r\\n...?The Saturn V rocket which put us in orbit is an incredibly complicated piece of machinery, every piece of which worked flawlessly?... We have always had confidence that this equipment will work properly. All this is possible only through the blood, sweat, and tears of a number of a people?... All you see is the three of us, but beneath the surface are thousands and thousands of others, and to all of those, I would like to say, \\"Thank you very much.\\"\\r\\nAldrin added:\\r\\nThis has been far more than three men on a mission to the Moon; more, still, than the efforts of a government and industry team; more, even, than the efforts of one nation. We feel that this stands as a symbol of the insatiable curiosity of all mankind to explore the unknown?... Personally, in reflecting on the events of the past several days, a verse from Psalms comes to mind. \\"When I consider the heavens, the work of Thy fingers, the Moon and the stars, which Thou hast ordained; What is man that Thou art mindful of him?\\"\\r\\nArmstrong concluded:\\r\\nThe responsibility for this flight lies first with history and with the giants of science who have preceded this effort; next with the American people, who have, through their will, indicated their desire; next with four administrations and their Congresses, for implementing that will; and then, with the agency and industry teams that built our spacecraft, the Saturn, the Columbia, the Eagle, and the little EMU, the spacesuit and backpack that was our small spacecraft out on the lunar surface. We would like to give special thanks to all those Americans who built the spacecraft; who did the construction, design, the tests, and put their hearts and all their abilities into those craft. To those people tonight, we give a special thank you, and to all the other people that are listening and watching tonight, God bless you. Good night from Apollo 11.[18]\\r\\nOn the return to Earth, a bearing at the Guam tracking station failed, potentially preventing communication on the last segment of the Earth return. A regular repair was not possible in the available time but the station director, Charles Force, had his ten-year-old son Greg use his small hands to reach into the housing and pack it with grease. Greg later was thanked by Armstrong.[59]\\r\\nOn July 24, the astronauts returned home aboard the Command Module Columbia just before dawn local time (16:51 UTC[4]) at 1319N 1699W? / ?13.317N 169.150W? / 13.317; -169.150? (Apollo 11 splashdown), in the Pacific Ocean 2,660?km (1,440?nmi) east of Wake Island, 380?km (210?nmi) south of Johnston Atoll, and 24?km (13?nmi) from the recovery ship, USS?Hornet.[1] This is near the village of Vatia in American Samoa.[60] The American Samoa-flag which was brought to the moon by Apollo 11 is on display at the Jean P. Haydon Museum in Pago Pago, the territorial capital of American Samoa.[61]\\r\\nAt 16:44 UTC the drogue parachutes had been deployed and seven minutes later the Command Module struck the water forcefully. During splashdown, the Command Module landed upside down but was righted within 10 minutes by flotation bags triggered by the astronauts. \\"Everything's okay. Our checklist is complete. Awaiting swimmers\\", was Armstrong's last official transmission from Columbia. A diver from the Navy helicopter hovering above attached a sea anchor to the Command Module to prevent it from drifting. Additional divers attached flotation collars to stabilize the module and position rafts for astronaut extraction. Though the chance of bringing back pathogens from the lunar surface was considered remote, it was considered a possibility and NASA took great precautions at the recovery site. Divers provided the astronauts with Biological Isolation Garments (BIGs) which were worn until they reached isolation facilities on board the Hornet. Additionally, astronauts were rubbed down with a sodium hypochlorite solution and the Command Module wiped with Betadine to remove any lunar dust that might be present. The raft containing decontamination materials was then intentionally sunk.[62]\\r\\nA second Sea King helicopter - \\"Helicopter 66\\" - hoisted the astronauts aboard one by one, where a NASA flight surgeon gave each a brief physical check during the 0.5 nautical miles (930?m) trip back to the Hornet.\\r\\nAfter touchdown on the Hornet, the astronauts exited the helicopter, leaving the flight surgeon and three crewmen. The helicopter was then lowered into hangar bay #2 where the astronauts walked the 30 feet (9.1?m) to the Mobile Quarantine Facility (MQF) where they would begin the earth-based portion of their 21 days of quarantine.[63] This practice would continue for two more Apollo missions, Apollo 12 and Apollo 14, before the Moon was proven to be barren of life and the quarantine process dropped.[62][64]\\r\\nPresident Richard Nixon was aboard Hornet to personally welcome the astronauts back to Earth. He told the astronauts, \\"As a result of what you've done, the world has never been closer together before.\\"[65] After Nixon departed, the Hornet was brought alongside the five-ton Command Module where it was placed aboard by the ship's crane, placed on a dolly and moved next to the MQF. The Hornet sailed for Pearl Harbor where Columbia and the MQF were airlifted to the Manned Spacecraft Center.[62]\\r\\nIn accordance with the Extra-Terrestrial Exposure Law, a set of regulations promulgated by NASA on July 16[66] to codify its quarantine protocol, the astronauts continued in quarantine out of concern that the Moon might contain undiscovered pathogens and that the astronauts might have been exposed to them during their Moon walks. However, after three weeks in confinement (first in the Apollo spacecraft, then in their trailer on the Hornet, and finally in the Lunar Receiving Laboratory at the Manned Spacecraft Center), the astronauts were given a clean bill of health.[67] On August 10, 1969, the Interagency Committee on Back Contamination met in Atlanta and lifted the quarantine on the astronauts, on those who had joined them in quarantine (NASA physician William Carpentier and MQF project engineer John Hirasaki[68]), and on Columbia itself.[69] Loose equipment from the spacecraft would remain in isolation until the lunar samples were released for study.[69]\\r\\nOn August 13, they rode in parades in their honor in New York, Chicago, and Los Angeles.[70][71] On the same evening in Los Angeles there was an official State Dinner to celebrate the flight, attended by members of Congress, 44 governors, the Chief Justice of the United States, and ambassadors from 83 nations at the Century Plaza Hotel.[71] President Richard Nixon and Vice President Spiro T. Agnew honored each astronaut with a presentation of the Presidential Medal of Freedom.[71] This celebration was the beginning of a 45-day \\"Giant Leap\\" tour that brought the astronauts to 25 foreign countries and included visits with prominent leaders such as Queen Elizabeth II of the United Kingdom. Many nations honored the first manned Moon landing with special features in magazines or by issuing Apollo 11 commemorative postage stamps or coins.[72][73]\\r\\nOn September 16, 1969, the three astronauts spoke before a joint session of Congress on Capitol Hill. They presented two US flags, one to the House of Representatives and the other to the Senate, that had been carried to the surface of the Moon with them.\\r\\nThe Soviet Union had been competing with the US in landing a man on the Moon but had been hampered by repeated failures in development of a launcher comparable to the Saturn V.[74] Meanwhile, they tried to beat the US to return lunar material to the Earth by means of unmanned probes. On July 13, three days before Apollo 11's launch, they launched Luna 15, which reached lunar orbit before Apollo 11. During descent, a malfunction caused Luna 15 to crash in Mare Crisium about two hours before Armstrong and Aldrin took off from the Moon's surface to begin their voyage home. The Jodrell Bank Observatory radio telescope in England was later discovered to have recorded transmissions from Luna 15 during its descent, and this was published in July 2009 on the 40th anniversary of Apollo 11.[75]\\r\\nThe Command Module Columbia was displayed at the National Air and Space Museum (NASM), Washington, D.C. It was in the central Milestones of Flight exhibition hall in front of the Jefferson Drive entrance, sharing the main hall with other pioneering flight vehicles such as the Wright Flyer, the Spirit of St. Louis, the Bell X-1, the North American X-15, Mercury spacecraft Friendship 7, and Gemini 4. Armstrong's and Aldrin's space suits are displayed in the museum's Apollo to the Moon exhibit. The quarantine trailer, the flotation collar, and the righting spheres are displayed at the Smithsonian's Steven F. Udvar-Hazy Center annex near Washington Dulles International Airport in Chantilly, Virginia.\\r\\nIn 2009, the Lunar Reconnaissance Orbiter (LRO) imaged the various Apollo landing sites on the surface of the Moon, for the first time with sufficient resolution to see the descent stages of the lunar modules, scientific instruments, and foot trails made by the astronauts.\\r\\nIn March 2012 a team of specialists financed by Amazon founder Jeff Bezos located the F-1 engines that launched Apollo 11 into space. The engines were found below the Atlantic Ocean's surface through the use of advanced sonar scanning.[76] His team brought parts of two of the five engines to the surface. In July 2013, a conservator discovered a serial number under the rust on one of the engines raised from the Atlantic, which NASA confirmed was from the Apollo 11 launch.[77][78]\\r\\nColumbia was moved in 2017 to the NASM Mary Baker Engen Restoration Hangar at the Steven F. Udvar-Hazy Center in Chantilly, VA, to be readied for a four-city tour titled Destination Moon: The Apollo 11 Mission. This will include Space Center Houston (October 14, 2017, to March 18, 2018), the Saint Louis Science Center (April 14 to September 3, 2018), the Senator John Heinz History Center in Pittsburgh (September 29, 2018, to February 18, 2019), and the Seattle Museum of Flight (March 16 to September 2, 2019).[79][80]\\r\\nOn July 15, 2009, Life.com released a photo gallery of previously unpublished photos of the astronauts taken by Life photographer Ralph Morse prior to the Apollo 11 launch.[81]\\r\\nFrom July 16ÿ24, 2009, NASA streamed the original mission audio on its website in real time 40 years to the minute after the events occurred.[82] In addition, it is in the process of restoring the video footage and has released a preview of key moments.[83]\\r\\nOn July 20, 2009, the crew of Armstrong, Aldrin, and Collins met with U.S. President Barack Obama at the White House.[84] \\"We expect that there is, as we speak, another generation of kids out there who are looking up at the sky and are going to be the next Armstrong, Collins and Aldrin\\", Obama said. \\"We want to make sure that NASA is going to be there for them when they want to take their journey.\\"[85]\\r\\nThe John F. Kennedy Presidential Library and Museum set up a Flash website that rebroadcasts the transmissions of Apollo 11 from launch to landing on the Moon.[86]\\r\\nA group of British scientists interviewed as part of the anniversary events reflected on the significance of the Moon landing:\\r\\nIt was carried out in a technically brilliant way with risks taken?... that would be inconceivable in the risk-averse world of today?... The Apollo programme is arguably the greatest technical achievement of mankind to date?... nothing since Apollo has come close [to] the excitement that was generated by those astronauts ÿ Armstrong, Aldrin and the 10 others who followed them.[87]\\r\\nOn August 7, 2009, an act of Congress awarded the three astronauts a Congressional Gold Medal, the highest civilian award in the United States. The bill was sponsored by Florida Sen. Bill Nelson and Florida Rep. Alan Grayson.[88][89]\\r\\nIn July 2010, air-to-ground voice recordings and film footage shot in Mission Control during the Apollo 11 powered descent and landing was re-synchronised and released for the first time.[90]\\r\\nSpectators camp out to watch the launch\\r\\nSeating credential issued to viewers of the Apollo 11 launch\\r\\nLaunch Control Center before liftoff\\r\\nCollins, Aldrin and Armstrong consult with pad leader Guenter Wendt after Countdown Demonstration Test\\r\\nRoll-out of Saturn V AS-505 from the Vehicle Assembly Building to the launch pad\\r\\nThe Earth as seen from Apollo 11 on the third day out\\r\\nNeil Armstrong describes the Moon's surface before setting foot on it\\r\\nPresident Nixon speaks to Armstrong and Aldrin from the Oval Office\\r\\nThe Washington Post on Monday, July 21, 1969: \\"'The Eagle Has Landed'Two Men Walk on the Moon\\"\\r\\nNeil Armstrong's certification: \\"I certify that this World Scout Badge was carried to the surface of the Moon on man's first lunar landing, Apollo XI, July 20, 1969.\\"\\r\\nFirst Man on the Moon Commemorative Issue of 1969\\r\\nApollo 11 crew at the White House in 2004\\r\\n?This article incorporates?public domain material from websites or documents of the National Aeronautics and Space Administration.\\r\\nFor young readers\\r\\nNASA reports\\r\\nMultimedia","input":"When did apollo 11 first land on the moon?"},{"output":"1,487","context":"Crested Butte is a home rule municipality in Gunnison County, Colorado, United States. The town population was 1,487 at the 2010 United States Census.[7] The former coal mining town is now called \\"the last great Colorado ski town\\".[8] Crested Butte is a destination for skiing, mountain biking, and a variety of other outdoor activities.\\r\\nThe Colorado General Assembly has designated Crested Butte the Wildflower Capital of Colorado.[9]\\r\\n\\r\\n\\r\\nThe East River Valley where Crested Butte is located was once used as a summer residence by the Ute people. However, they were quickly displaced when European-Americans first entered the area. The first white people to explore the valley were beaver trappers, shortly followed by surveyors. Captain John Gunnison, after whom Gunnison County is named, was one of the early explorers to enter the area.\\r\\nIn the 1860s and 1870s coal and silver mines began to open in the surrounding area, and many little mining towns formed. However, when silver mining began to decline, many of these towns failed. Crested Butte, however, was in a better position to survive because it served as a supply town to the surrounding area.\\r\\nAnother industry that served to support Crested Butte was ranching.\\r\\nWhen the coal mines closed, the town began to shrink, and eventually the local high school was closed. Students had to travel to Gunnison to go to high school. The town did not revive until a ski area was built on Crested Butte Mountain in the 1960s. From the 1960s to 1990, the Crested Butte public school only facilitated K-5 students, while 6th grade and higher attended school in Gunnison. In 1990 Crested Butte offered middle school in the railroad depot building. In 1992 a new middle school was completed which allowed the public school to facilitate grades K through 8. Finally in 1997, a new facility for the Crested Butte Community School was completed. This included the addition of a public high school so that the school now serves students in grades K-12.\\r\\nIn 1993 the Crested Butte Academy opened in Crested Butte, bringing a private high school into town. However, on 9 July 2008, the academy was closed permanently due to financial difficulties that had plagued its entire existence.[10]\\r\\nSince the 1970s, several companies have attempted to mine molybdenum on Mount Emmons (called the \\"Red Lady\\") near Crested Butte. In 1977 W Mitchell was elected mayor of Crested Butte and led a campaign which stopped AMAX (now Freeport-McMoRan) from building a billion-dollar molybdenum mine on Mount Emmons. Because of his battle against the anticipated environmental impact, Mitchell is known as the man who \\"saved a mountain\\".[citation needed] The same year, 1977, saw the formation of the High Country Citizens' Alliance (HCCA), an environmental organization dedicated to protecting natural resources within the Upper Gunnison River Valley.[11]\\r\\nCurrently the rights for Mount Emmons molybdenum are owned by U.S. Energy Corp. On 25 April 2011, Thomson Creek Metals announced that it had terminated its option agreement with U.S. Energy Corp. to acquire an interest in the Mount Emmons molybdenum project.[12] Although US Energy continued to maintain its commitment to moving the project forward on its own behalf,[13] the withdrawal of Thomson Creek Metals was heralded as a major victory in the town of Crested Butte in its battle against the proposed molybdenum mine.[14]\\r\\nThe primary winter activity in Crested Butte is skiing or snowboarding at nearby Crested Butte Mountain Resort in Mount Crested Butte. Backcountry skiing in the surrounding mountains is some of the best in Colorado. The mountain, Crested Butte, rises to 12,162 feet (3,707?m) above sea level. The ski area base is at 9,375 feet (2,858?m). 14 lifts serve 1,058 acres (4.28?km2) of terrain. 448 acres (1.81?km2) of the terrain are double black diamond runs. The large amount of extreme skiing terrain at Crested Butte has attracted the US Extreme Skiing Championships and the X Games. The longest run on Mount Crested Butte is 2.6 miles (4.2?km).\\r\\nThe town of Crested Butte itself has a Nordic Center which has an ice skating rink as well as many miles of groomed cross-country skiing trails.\\r\\nCrested Butte is one of the locations that claims to have created the sport of mountain biking. The Mountain Bike Hall of Fame used to be located in Crested Butte before moving to Fairfax, California, in 2014. Other popular summer activities in Crested Butte include hiking, backpacking, rock climbing, whitewater rafting and kayaking, four wheeling, disc golf, and fishing.\\r\\nCrested Butte hosts a number of unique festivals and parades throughout the year. These include Torchlight, New Years, Winter Carnival, Butte Bash College Ski Week and Mardi Gras during the winter months; Extreme Board Fest, Slushuck and Flauschink during spring; the Crested Butte Bike Week, Crested Butte Music Festival, Crested Butte International Film Festival, 4th of July,[15] the Crested Butte Wildflower Festival, Alpenglow Concert Series, Festival of the Arts and Ball Bash during summer; and Fall Fest, Vinotok [16] and Paragon Peoples' Fair during fall.\\r\\nCrested Butte is located in north-central Gunnison County on the west side of the valley of the Slate River, along Coal Creek. Colorado State Highway 135 runs south from Crested Butte 27 miles (43?km) to Gunnison, the county seat. According to the United States Census Bureau, the town of Crested Butte has a total area of 0.85 square miles (2.2?km2), all of it land.[7] Crested Butte lies at an elevation of 8,885 feet (2,708?m) above sea level.[17]\\r\\nCrested Butte is served by the Gunnison-Crested Butte Regional Airport in Gunnison.\\r\\nClimate type is dominated by the winter season, a long, bitterly cold period with short, clear days, relatively little precipitation mostly in the form of snow, and low humidity. The K?ppen Climate Classification sub-type for this climate is \\"Dfc\\" (Continental Subarctic Climate).[18]\\r\\nAs of the census[21] of 2000, there were 1,529 people, 692 households, and 253 families residing in the town. The population density was 2,183.1 people per square mile (843.4/km2). There were 930 housing units at an average density of 1,327.9 per square mile (513.0/km2). The racial makeup of the town was 97.19% White, 0.26% African American, 0.92% Native American, 0.72% Asian, 0.00% Pacific Islander, 0.46% from other races, and 0.46% from two or more races. 2.75% of the population were Hispanic or Latino of any race.\\r\\nThere were 692 households out of which 19.1% had children under the age of 18 living with them, 28.9% were married couples living together, 5.1% had a female householder with no husband present, and 63.3% were non-families. 28.3% of all households were made up of individuals and 1.4% had someone living alone who was 65 years of age or older. The average household size was 2.21 and the average family size was 2.69.\\r\\nIn the town, the population was spread out with 13.5% under the age of 18, 11.5% from 18 to 24, 55.6% from 25 to 44, 17.5% from 45 to 64, and 1.9% who were 65 years of age or older. The median age was 31 years. For every 100 females there were 124.5 males. For every 100 females age 18 and over, there were 131.9 males.\\r\\nThe median income for a household in the town was $41,250, and the median income for a family was $49,118. Males had a median income of $27,386 versus $23,073 for females. The per capita income for the town was $26,789. 11.4% of the population and 2.7% of families were below the poverty line. Out of the total population, 3.5% of those under the age of 18 and 0.0% of those 65 and older were living below the poverty line.\\r\\nCrested Butte was the setting and main filming location for the Walt Disney ski movie Snowball Express starring Dean Jones and Harry Morgan. 1970s musicians Brewer & Shipley wrote and performed a song called \\"Crested Butte\\" dedicated to the town. Crested Butte is the birthplace and hometown of Heidi Montag of MTV's The Hills. It is also the town Bud Light took over for a weekend in 2014 and renamed \\"Whatever, USA\\".\\r\\nCrested Butte was the site for other films in the 1970s, including Snowbeast (1977), The Further Adventures of the Wilderness Family (1978), and Mountain Family Robinson (1979), and Ink (2009).[22]\\r\\nJames Cameron's movie Avatar has very tangible parallels to Crested Butte with regard to both mining issues and environmental coexistence. One of the people who led the fight against the proposed molybdenum mine on Mount Emmons in the late 1970s, former mayor W Mitchell, uses a wheelchair, just like the protagonist in Cameron's film.[23] This original article was written by David J. Rothman who is a local of Crested Butte. James Cameron has spent a lot of time at his wife Suzy Amis's cabin in Crested Butte.[24]\\r\\nAliens vs. Predator: Requiem is set in Gunnison County. \\"CRESTED BUTTE\\" is given as the destination of the bus in which Dallas Howard arrives at Gunnison at the beginning of the movie.\\r\\nIn 2014, Powder Magazine's \\"Ski Town Throw Down\\" voted Crested Butte as the number 1 ski town in the United States.[citation needed]","input":"What is the population of crested butte colorado?"},{"output":"Robert Pershing Wadlow","context":"Robert Pershing Wadlow (February 22, 1918 ÿ July 15, 1940), also known as the Alton Giant and the Giant of Illinois, was an American who became famous as the tallest person ever in human recorded history for whom there is irrefutable evidence.[3] The Alton and Illinois monikers reflect the fact that he was born and raised in Alton, Illinois.[1]\\r\\nWadlow reached 8?ft 11.1?in (2.72?m)[2][4][5] in height and weighed 490?lb (220?kg) at his death at age 22. His great size and his continued growth in adulthood were due to hyperplasia of his pituitary gland, which results in an abnormally high level of human growth hormone. He showed no indication of an end to his growth even at the time of his death.\\r\\n\\r\\n\\r\\nWadlow was born to Addie Johnson and Harold Wadlow in Alton, Illinois, on February 22, 1918, and was the oldest of five children. He was taller than his father by the age of 8, and in elementary school they had to make a special desk for him due to his size. By the time he had graduated from Alton High School in 1936, he was 8?ft 4?in (2.54?m).[1] After graduating he enrolled in Shurtleff College with the intention of studying law.\\r\\nWadlow's size began to take its toll: he required leg braces to walk and had little feeling in his legs and feet. Despite these difficulties, he never used a wheelchair.\\r\\nWadlow became a celebrity after his 1936 U.S. tour with the Ringling Brothers Circus. In 1938, he did a promotional tour with the International Shoe Company (since 1966 called INTERCO). They provided him his shoes free of charge. Examples still exist in several locations throughout the U.S., including Snyder's Shoe Store of Ludington and Manistee, Michigan, and the Alton Museum of History and Art. He continued participating in tours and public appearances, though only in his normal street clothes.[6] He possessed great physical strength until the last year of his life, when his strength and his health in general began to deteriorate rapidly.[citation needed]\\r\\nWadlow was a member of the Order of DeMolay, the Masonic-sponsored organization for young men. He was also a Freemason. In 1939, he petitioned Franklin Lodge #25 in Alton, Illinois, and by late November of that year[7] was raised to the degree of Master Mason under the jurisdiction of the Grand Lodge of Illinois A.F and A.M.. His Freemason ring was the largest ever made.[citation needed]\\r\\nOne year before his death, Wadlow passed John Rogan as the tallest person ever. On June 27, 1940 (eighteen days before his death), he was measured at 8?ft 11.1?in (2.72?m) by doctors C. M. Charles and Cyril MacBryde of Washington University in St. Louis, Missouri.[citation needed]\\r\\nOn July 4, 1940, during a professional appearance at the Manistee National Forest Festival, a faulty brace irritated his ankle, causing a blister and subsequent infection. Doctors treated him with a blood transfusion and emergency surgery, but his condition worsened due to an autoimmune disorder, and on July 15, 1940, 11 days after contracting the infection, he died in his sleep at the age of 22.[citation needed] His coffin measured 10?feet 9?inches (3.28?m) long by 32 inches (81?cm) wide by 30 inches (76?cm) deep, weighed 1,000 pounds (450?kg) and was carried by twelve pallbearers and eight assistants.[1][8][9] He was buried at the Oakwood Cemetery in Upper Alton, Madison County, Illinois.\\r\\nA life-size statue of Wadlow stands on College Avenue in Alton, opposite the Alton Museum of History and Art. It was erected in 1986, in honor of the well-known native.[1][10] Others stand in the Guinness Museums in Niagara Falls and Gatlinburg, as well as several of the Ripley's Believe It or Not Museums. A group of six life-size models of him, made by artist James Butler, exist, and are shipped and displayed in replica caskets.[11]\\r\\nAnother life-size statue of Wadlow may be viewed at Marvin's Marvelous Mechanical Museum in Farmington Hills, Michigan. In front of it is a small, quarter-operated \\"TV-box\\", which plays a short, documentary movie about his extraordinary short life.\\r\\nWadlow is still affectionately known as the \\"Gentle Giant\\".[12]\\r\\nThe 1998 song \\"The Giant of Illinois\\", by The Handsome Family (and later covered by Andrew Bird) honors Wadlow. In 2005, Sufjan Stevens recorded \\"The Tallest Man, the Broadest Shoulders\\" about Wadlow for the Illinois album. A picture of Wadlow with his family is featured on the back cover of the VHS version of the Talking Heads music video compilation, Storytelling Giant.","input":"The tallest man that ever lived on earth?"},{"output":"states","context":"Austria is a federal republic made up of nine states, known in German as L?nder (singular Land). Since Land is also the German word for \\"country\\", the term Bundesl?nder (\\"federation states\\"; singular Bundesland) is often used instead to avoid ambiguity. The Constitution of Austria uses both terms. Even though English \\"land\\" is a cognate, the term (Bundes)land is commonly rendered as \\"state\\" or \\"province\\" by tradition in English writing.\\r\\n\\r\\n\\r\\nThe majority of the land area in the states of Upper Austria, Lower Austria, Vienna, and Burgenland is situated in the Danube valley and thus consists almost completely of accessible and easily arable terrain. The other five states, in contrast, are located in the Alps and thus are comparatively unsuitable for agriculture. Their terrain is also relatively unfavourable to heavy industry and long-distance trade. Accordingly, the population of what now is the Republic of Austria has been concentrated in the former four states since prehistoric times. Austria's most densely populated state is the city-state of Vienna, the heart of what is Austria's only metropolitan area. Lower Austria ranks only fourth with regard to population density even though it contains Vienna's suburbs; this is due to large areas of land being predominantly agricultural. The alpine state of Tyrol, the less alpine but geographically more remote state of Carinthia, and the non-alpine but near-exclusively agricultural state of Burgenland are Austria's least densely populated states. The wealthy alpine state of Vorarlberg is something of an anomaly due to its small size, isolated location and distinct Alemannic culture.[citation needed]\\r\\nThe following ranked list of Austrian states cites official Statistik Austria population on 1 January 2015.[1] Areas are given in square kilometres, population density is expressed in inhabitants per square kilometre. For the purpose of the above list, a city is a community defined to be a city by Austrian law; a town is a community not defined to be a city. Many of Austria's cities have population figures on the order of ten thousand inhabitants; some are even smaller.\\r\\nThe nine states (Bundesl?nder) of Austria, here listed alphabetically by name, are:[2]\\r\\nEach Austrian state has an elected legislature, the Landtag, a state government, the Landesregierung, and a governor, the Landeshauptmann or Landeshauptfrau. Elections are held every five years (six years in Upper Austria). The state constitution, among other things, determines how the seats in the state government are assigned to political parties, with most states having a system of proportional representation based on the number of delegates in the Landtag in place. The Landeshauptmann is always elected by the Landtag, meaning that it may be necessary to form a coalition in order to secure the election of a particular candidate. Vienna, the capital of Austria, plays a double role as city and \\"Bundesland\\", meaning that the mayor serves as governor and the city council as Landtag at the same time.\\r\\nAustrian federalism is largely theoretical as the states are granted few legislative powers. The federal constitution initially granted all legislative powers to the states, but many powers have been subsequently taken away, and only a few remain, such as planning and zoning codes, nature protection, hunting, fishing, farming, youth protection, certain issues of public health and welfare and the right to levy certain taxes.\\r\\nAll other matters, including but not limited to criminal law, civil law, corporate law, most aspects of economic law, defense, most educational matters and academia, telecommunications, and much of the healthcare system are regulated by federal laws. There is also no judiciary of the L?nder, since the federal constitution defines the judiciary as an exclusively federal matter. This centralisation follows a historic model where central power during the time of the empire was largely concentrated in Vienna.\\r\\nHowever, the state governor (Landeshauptmann) is in charge of the administration of much of federal administrative law within the respective state, which makes this post an important political position. Furthermore, state competences include zoning laws, planning issues and public procurement on the regional level, which adds considerable weight to state politics. As a practical matter, there have been cases where states have been able to block projects endorsed by the federal government, as in the case of a railway tunnel that was to be built below the Semmering.\\r\\nAustrian L?nder are endowed formally and practically with a much smaller degree of autonomy than American or German states. Even so, Austrians tend to identify passionately with their respective Land and often defend what little independent governance their states have. It is not unheard of for Austrians to consider themselves, for instance, Tyrolean first, Austrian second.\\r\\nIn terms of boundaries, the present-day states arose from the crown lands of Austria-Hungary, an extensive multiethnic realm whose German-speaking nucleus emerged as the Republic of Austria after the dissolution of the Dual Monarchy at the end of World War I.\\r\\nThe states of Upper Austria and Lower Austria are essentially equivalent to what were since 1783/84 the two autonomous halves of the Archduchy of Austria, a principality which formed the empire's historic heartland. Salzburg is coterminous with the former Austro-Hungarian Duchy of Salzburg (the former Archbishopric). Similarly, the state of Carinthia descends from the Duchy of Carinthia, the state of Styria descends from the Duchy of Styria, and the state of Tyrol descends from the Princely County of Tyrol; these states had to cede territories to Italy and Yugoslavia when Austria emerged in its present form. Also, the state of Vorarlberg had been a semi-autonomous part of the County of Tyrol since 1861.\\r\\nThe city-state of Vienna was a part of Lower Austria up until 1921.[3] The state of Burgenland is made up of the predominantly German-speaking area that the Kingdom of Hungary until 1921 had to cede to the First Austrian Republic after World War I as a result of the Treaties of Trianon and Saint-Germain-en-Laye.[4]","input":"What are the political regions in austria called?"},{"output":"1100ÿ1680 CE","context":"Easter Island (Rapa Nui: Rapa Nui, Spanish: Isla de Pascua) is a Chilean island in the southeastern Pacific Ocean, at the southeasternmost point of the Polynesian Triangle in Oceania. Easter Island is famous for its 887 extant monumental statues, called moai, created by the early Rapa Nui people. In 1995, UNESCO named Easter Island a World Heritage Site, with much of the island protected within Rapa Nui National Park.\\r\\nPolynesian people most likely settled on Easter Island sometime between 700 and 1100 CE, and created a thriving and industrious culture as evidenced by the island's numerous enormous stone moai and other artefacts. However, human activity, the introduction of the Polynesian rat and overpopulation led to gradual deforestation and extinction of natural resources which severely weakened the Rapa Nui civilization.[4] By the time of European arrival in 1722, the island's population had dropped to 2,000ÿ3,000 from an estimated high of approximately 15,000 just a century earlier. European diseases and Peruvian slave raiding in the 1860s further reduced the Rapa Nui population, to a low of only 111 inhabitants in 1877.[5]\\r\\nEaster Island is one of the most remote inhabited islands in the world.[6] The nearest inhabited land (around 50 residents in 2013) is Pitcairn Island, 2,075 kilometres (1,289?mi) away;[7] the nearest town with a population over 500 is Rikitea, on the island of Mangareva, 2,606?km (1,619?mi) away; the nearest continental point lies in central Chile, 3,512 kilometres (2,182?mi) away.\\r\\nEaster Island is a special territory of Chile that was annexed in 1888. Administratively, it belongs to the Valparaso Region, and, more specifically, it is the only commune of the Province Isla de Pascua.[8] According to the 2012 Chilean census, the island has about 5,800 residents, of whom some 60 percent are descendants of the aboriginal Rapa Nui.\\r\\nEaster Island is considered part of Insular Chile.\\r\\n\\r\\n\\r\\nThe name \\"Easter Island\\" was given by the island's first recorded European visitor, the Dutch explorer Jacob Roggeveen, who encountered it on Easter Sunday (5 April) in 1722, while searching for Davis or David's island. Roggeveen named it Paasch-Eyland (18th-century Dutch for \\"Easter Island\\").[9][10] The island's official Spanish name, Isla de Pascua, also means \\"Easter Island\\".\\r\\nThe current Polynesian name of the island, Rapa Nui (\\"Big Rapa\\"), was coined after the slave raids of the early 1860s, and refers to the island's topographic resemblance to the island of Rapa in the Bass Islands of the Austral Islands group.[11] However, Norwegian ethnographer Thor Heyerdahl argued that Rapa was the original name of Easter Island and that Rapa Iti was named by refugees from there.[12]\\r\\nThe phrase Te pito o te henua has been said to be the original name of the island since French ethnologist Alphonse Pinart gave it the romantic translation \\"the Navel of the World\\" in his Voyage  l'?le de Paques, published in 1877.[13] William Churchill (1912) inquired about the phrase and was told that there were three te pito o te henua, these being the three capes (land's ends) of the island. The phrase appears to have been used in the same sense as the designation of \\"Land's End\\" at the tip of Cornwall. He was unable to elicit a Polynesian name for the island itself, and concluded that there may not have been one.[14]\\r\\nAccording to Barthel (1974), oral tradition has it that the island was first named Te pito o te kainga a Hau Maka \\"The little piece of land of Hau Maka\\".[15] However, there are two words pronounced pito in Rapa Nui, one meaning 'end' and one 'navel', and the phrase can thus also mean \\"the Navel of the World\\". Another name, Mata ki te rangi, means \\"Eyes looking to the sky\\".[16]\\r\\nIslanders are referred to in Spanish as pascuense; however it is common to refer to members of the indigenous community as Rapa Nui.\\r\\nEstimated dates of initial settlement of Easter Island have ranged from 300 to 1200 AD, approximately coinciding with the arrival of the first settlers in Hawaii. Rectifications in radiocarbon dating have changed almost all of the previously posited early settlement dates in Polynesia. Rapa Nui is now considered to have been settled in the narrower range of 700 to 1100 AD. Ongoing archaeological studies suggest a still-later date: \\"Radiocarbon dates for the earliest stratigraphic layers at Anakena, Easter Island, and analysis of previous radiocarbon dates imply that the island was colonized late, about 1200 AD. Significant ecological impacts and major cultural investments in monumental architecture and statuary thus began soon after initial settlement.\\"[17][18]\\r\\nAccording to oral tradition, the first settlement was at Anakena. Researchers have noted that the Caleta Anakena landing point provides the island's best shelter from prevailing swells as well as a sandy beach for canoe landings and launchings so it appeals as a likely early place of settlement. However, this conclusion contradicts radiocarbon dating, according to which other sites preceded Anakena by many years, especially the Tahai, whose radiocarbon dates precede Anakena's by several centuries.\\r\\nThe island was most likely populated by Polynesians who navigated in canoes or catamarans from the Gambier Islands (Mangareva, 2,600?km (1,600?mi) away) or the Marquesas Islands, 3,200?km (2,000?mi) away. According to some theories, such as the Polynesian Diaspora Theory, there is a possibility that early Polynesian settlers arrived from South America due to their remarkable sea-navigation abilities. Theorists have supported this through the agricultural evidence of the sweet potato. The sweet potato was a favoured crop found among Polynesian society for generations. However, the origins of the sweet potato trace back to South America, proving evidence of interaction at some point in time between these two geographic areas.[19] When James Cook visited the island, one of his crew members, a Polynesian from Bora Bora, Hitihiti, was able to communicate with the Rapa Nui.[20]:296-297 The language most similar to Rapa Nui is Mangarevan, with an estimated 80 percent similarity in vocabulary. In 1999, a voyage with reconstructed Polynesian boats was able to reach Easter Island from Mangareva in 19 days.[21]\\r\\nAccording to oral traditions recorded by missionaries in the 1860s, the island originally had a strong class system, with an ariki, or high chief, wielding great power over nine other clans and their respective chiefs. The high chief was the eldest descendent through first-born lines of the island's legendary founder, Hotu Matu'a. The most visible element in the culture was the production of massive statues called moai that some believe represented deified ancestors. According to National Geographic, \\"Most scholars suspect that the moai were created to honor ancestors, chiefs, or other important personages, However, no written and little oral history exists on the island, so its impossible to be certain.\\"[23]\\r\\nIt was believed that the living had a symbiotic relationship with the dead in which the dead provided everything that the living needed (health, fertility of land and animals, fortune etc.) and the living, through offerings, provided the dead with a better place in the spirit world. Most settlements were located on the coast and most moai were erected along the coastline, watching over their descendants in the settlements before them, with their backs toward the spirit world in the sea.\\r\\nJared Diamond suggested that cannibalism took place on Easter Island after the construction of the moai contributed to environmental degradation when extreme deforestation destabilized an already precarious ecosystem.[24] Archeological record shows that at the time of the initial settlement the island was home to many species of trees, including at least three species which grew up to 15 metres (49?ft) or more: Paschalococos ÿ possibly the largest palm trees in the world at the time, Alphitonia zizyphoides, and Elaeocarpus rarotongensis, as well as at least six species of native land birds. A major factor that contributed to the extinction of multiple plant species was the introduction of the Polynesian rat. Studies by paleobotanists have shown rats can dramatically affect the reproduction of vegetation in an ecosystem. In the case of Rapa Nui, recovered plant shell seeds showed markings of being gnawed on by rats.[4] Barbara A. West wrote, \\"Sometime before the arrival of Europeans on Easter Island, the Rapanui experienced a tremendous upheaval in their social system brought about by a change in their island's ecology... By the time of European arrival in 1722, the island's population had dropped to 2,000ÿ3,000 from a high of approximately 15,000 just a century earlier.\\"[25]\\r\\nBy that time, 21 species of trees and all species of land birds became extinct through some combination of overharvesting/overhunting, rat predation, and climate change. The island was largely deforested, and it did not have any trees more than 3 metres (10 feet) tall. Loss of large trees meant that residents were no longer able to build seaworthy vessels, significantly diminishing their fishing abilities. One theory regarding the deforestation that caused such ecological and social damage was that the trees were used as rollers to move the statues to their place of erection from the quarry at Rano Raraku.[26] Deforestation also affected agricultural production on Rapa Nui. At first, the native tropical forests provided ideal shade cover for soil. But with many of the native forest being destroyed, the topsoil became eroded causing a sharp decline in agricultural production.[4] This was further exacerbated by the loss of land birds and the collapse in seabird populations as a potential source of food. By the 18th century, residents of the island were largely sustained by farming, with domestic chickens as the primary source of protein.[27]\\r\\nAs the island became overpopulated and resources diminished, warriors known as matatoa gained more power and the Ancestor Cult ended, making way for the Bird Man Cult. Beverly Haun wrote, \\"The concept of mana (power) invested in hereditary leaders was recast into the person of the birdman, apparently beginning circa 1540, and coinciding with the final vestiges of the moai period.\\"[28] This cult maintained that, although the ancestors still provided for their descendants, the medium through which the living could contact the dead was no longer statues, but human beings chosen through a competition. The god responsible for creating humans, Makemake, played an important role in this process. Katherine Routledge, who systematically collected the island's traditions in her 1919 expedition,[29] showed that the competitions for Bird Man (Rapanui: tangata manu) started around 1760, after the arrival of the first Europeans, and ended in 1878, with the construction of the first church by Roman Catholic missionaries who formally arrived in 1864. Petroglyphs representing Bird Men on Easter Island are exactly the same as some in Hawaii, indicating that this concept was probably brought by the original settlers; only the competition itself was unique to Easter Island.\\r\\nAccording to Diamond and Heyerdahl's version of the island's history, the huri mo'ai\\"statue-toppling\\"continued into the 1830s as a part of fierce internal wars. By 1838 the only standing moai were on the slopes of Rano Raraku, in Hoa Hakananai'a in Orongo, and Ariki Paro in Ahu Te Pito Kura. A study headed by Douglas Owsley published in 1994 asserted that there is little archaeological evidence of pre-European societal collapse. Bone pathology and osteometric data from islanders of that period clearly suggest few fatalities can be attributed directly to violence.[30]\\r\\nThe first-recorded European contact with the island was on 5 April (Easter Sunday), 1722, when Dutch navigator Jacob Roggeveen[20] visited the island for a week and estimated a population of 2,000 to 3,000 inhabitants. The number may have been greater, since some may have been frightened into hiding by a misunderstanding that led Roggeveen's men to fire on the natives, killing more than a dozen and wounding several more.\\r\\nThe next foreign visitors (on 15 November 1770) were two Spanish ships, San Lorenzo and Santa Rosalia, under the command of Captain Don Felipe Gonzalez.[20]:238,504 The Spanish reported the island as largely uncultivated, whose seashore was lined with stone statues.\\r\\nFour years later, in 1774, British explorer James Cook visited Easter Island; he reported that some statues had been toppled. Through the interpretation of Hitihiti, Cook learned the statues commemorated their former high chiefs, including their names and ranks.[20]:296-297 The British ship HMS?Blossom arrived in 1825 and reported seeing no standing statues. Easter Island was approached many times during the 19th century, but by then the islanders had become openly hostile to any attempt to land, and very little new information was reported before the 1860s.\\r\\nA series of devastating events killed or removed most of the population in the 1860s. In December 1862, Peruvian slave raiders struck. Violent abductions continued for several months, eventually capturing around 1,500 men and women, half of the island's population.[31] Among those captured were the island's paramount chief, his heir, and those who knew how to read and write the rongorongo script, the only Polynesian script to have been found to date. (Although serious debate exists about whether this is proto-writing or true writing.)\\r\\nWhen the slave raiders were forced to repatriate the people they had kidnapped, carriers of smallpox disembarked together with a few survivors on each of the islands.[32] This created devastating epidemics from Easter Island to the Marquesas islands.[citation needed] Easter Island's population was reduced to the point where some of the dead were not even buried.[citation needed]\\r\\nTuberculosis, introduced by whalers in the mid-19th century, had already killed several islanders when the first Christian missionary, Eugne Eyraud, died from this disease in 1867. About a quarter of the island's population succumbed along with him. In the following years, the managers of the sheep ranch and the missionaries started buying the newly available lands of the deceased, and this led to great confrontations between natives and settlers.\\r\\nJean-Baptiste Dutrou-Bornier bought up all of the island apart from the missionaries' area around Hanga Roa and moved a few hundred Rapanui to Tahiti to work for his backers. In 1871 the missionaries, having fallen out with Dutrou-Bornier, evacuated all but 171 Rapanui to the Gambier islands.[33] Those who remained were mostly older men. Six years later, only 111 people lived on Easter Island, and only 36 of them had any offspring.[34] From that point on the island's population slowly recovered. But with over 97% of the population dead or gone in less than a decade, much of the island's cultural knowledge had been lost.\\r\\nAlexander Salmon, Jr., a son of an English Jewish merchant and a Pmare Dynasty princess, eventually worked to repatriate workers from his inherited copra plantation. He eventually bought up all lands on the island with the exception of the mission, and was its sole employer. He worked to develop tourism on the island, and was the principal informant for the British and German archaeological expeditions for the island. He sent several pieces of genuine Rongorongo to his niece's husband, the German consul in Valparaso, Chile. Salmon sold the Brander Easter Island holdings to the Chilean government in 1888 January 2 and signed as a witness to the cession of the island. He returned to Tahiti in December of that year. He effectively ruled the island from 1878 until his cession to Chile in 1888.\\r\\nEaster Island was annexed by Chile on 9 September 1888 by Policarpo Toro by means of the \\"Treaty of Annexation of the Island\\" (Tratado de Anexi܇n de la isla). Toro, then representing the government of Chile, signed with Atamu Tekena, designated \\"King\\" by the Roman Catholic missionaries after the paramount chief and his heir had died. The validity of this treaty is still contested by some Rapanui. Officially, Chile purchased the nearly all encompassing Mason-Brander sheep ranch, comprised from lands purchased from the descendants of Rapanui who died during the epidemics, and then claimed sovereignty over the island.\\r\\nUntil the 1960s the surviving Rapanui were confined to Hanga Roa. The rest of the island was rented to the Williamson-Balfour Company as a sheep farm until 1953.[35] The island was then managed by the Chilean Navy until 1966, at which point the island was reopened in its entirety. In 1966 the Rapanui were given Chilean citizenship.[36]\\r\\nFollowing the 1973 Chilean coup d'tat that brought Augusto Pinochet to power, Easter Island was placed under martial law. Tourism slowed down and private property was restored. During his time in power, Pinochet visited Easter Island on three occasions. The military built a number of new military facilities and a new city hall.[37]\\r\\nAfter an agreement in 1985 between Chile and United States, the runway at Mataveri International Airport was enlarged and was inaugurated in 1987. The runway was expanded 423 metres (1,388?ft) reaching 3,353 metres (11,001?ft). Pinochet is reported to have refused to attend the inauguration in protest of pressures from the United States to attend human rights cases.[38]\\r\\nFishers of Rapa Nui have shown their concern of illegal fishing on the island. Since the year 2000 we started to lose tuna, which is the basis of the fishing on the island, so then we began to take the fish from the shore to feed our families, but in less than two years we depleted all of it, Pakarati said.[39] On 30 July 2007, a constitutional reform gave Easter Island and the Juan Fernndez Islands (also known as Robinson Crusoe Island) the status of \\"special territories\\" of Chile. Pending the enactment of a special charter, the island continued to be governed as a province of the V Region of Valparaso.[40]\\r\\nA total solar eclipse visible from Easter Island occurred for the first time in over 1,300 years on 11 July 2010, at 18:15:15.[41]\\r\\nSpecies of fish were collected in Easter Island for one month in different habitats including shallow lava pools, depths of 43 meters, and deep waters. Within these habitats, two holotypes and paratypes, Antennarius randalli and Antennarius moai, were discovered. These are considered frog-fish because of their characteristics: \\"12 dorsal rays, last two or three branched; bony part of first dorsal spine slightly shorter than second dorsal spine; body without bold zebra-like markings; caudal peduncle short, but distinct; last pelvic ray divided; pectoral rays 11 or 12\\".[42]\\r\\nStarting in August 2010, members of the indigenous Hitorangi clan occupied the Hangaroa Eco Village and Spa.[43][44] The occupiers allege that the hotel was bought from the Pinochet government, in violation of a Chilean agreement with the indigenous Rapa Nui, in the 1990s.[45] The occupiers say their ancestors had been cheated into giving up the land.[46] According to a BBC report, on 3 December 2010, at least 25 people were injured when Chilean police using pellet guns attempted to evict from these buildings a group of Rapa Nui who had claimed that the land the buildings stood on had been illegally taken from their ancestors.[47]\\r\\nIn January 2011, the UN's Special Rapporteur on Indigenous People, James Anaya, expressed concern about the treatment of the indigenous Rapa Nui by the Chilean government, urging Chile to \\"make every effort to conduct a dialogue in good faith with representatives of the Rapa Nui people to solve, as soon as possible the real underlying problems that explain the current situation\\".[43]\\r\\nThe incident ended in February 2011, when up to 50 armed police broke into the hotel to remove the final five occupiers. They were arrested by the government and no injuries were reported.[43]\\r\\nEaster Island is one of the world's most isolated inhabited islands. Its closest inhabited neighbour is Pitcairn Island, 2,075?km (1,289?mi) to the west, with fewer than 100 inhabitants. The nearest continental point lies in central Chile near Concepci܇n, at 3,512 kilometres (2,182?mi). Easter Island's latitude is similar to that of Caldera, Chile, and it lies 3,510?km (2,180?mi) west of continental Chile at its nearest point (between Lota and Lebu in the Biobo Region). Isla Salas y G܇mez, 415?km (258?mi) to the east, is closer but is uninhabited. Archipelago Tristan da Cunha in the southern Atlantic competes for the title of the most remote island, lying 2,430 kilometres (1,510?mi) from Saint Helena island and 2,816 kilometres (1,750?mi) from the South African coast.\\r\\nThe island is about 24.6?km (15.3?mi) long by 12.3?km (7.6?mi) at its widest point; its overall shape is triangular. It has an area of 163.6 square kilometres (63.2?sq?mi), and a maximum altitude of 507 metres (1,663?ft). There are three Rano (freshwater crater lakes), at Rano Kau, Rano Raraku and Rano Aroi, near the summit of Terevaka, but no permanent streams or rivers.\\r\\nEaster Island is a volcanic high island, consisting mainly of three extinct coalesced volcanoes: Terevaka (altitude 507 metres) forms the bulk of the island, while two other volcanoes, Poike and Rano Kau, form the eastern and southern headlands and give the island its roughly triangular shape. Lesser cones and other volcanic features include the crater Rano Raraku, the cinder cone Puna Pau and many volcanic caves including lava tubes.[48] Poike used to be a separate island until volcanic material from Terevaka united it to the larger whole. The island is dominated by hawaiite and basalt flows which are rich in iron and show affinity with igneous rocks found in the Galpagos Islands.[49]\\r\\nEaster Island and surrounding islets, such as Motu Nui and Motu Iti, form the summit of a large volcanic mountain rising over 2,000 metres (6,600?ft) from the sea bed. The mountain is part of the Sala y G܇mez Ridge, a (mostly submarine) mountain range with dozens of seamounts, formed by the Easter hotspot. The range begins with Pukao and next Moai, two seamounts to the west of Easter Island, and extends 2,700?km (1,700?mi) east to the Nazca Ridge. The ridge was formed by the Nazca Plate moving over the Easter hotspot.[50]\\r\\nLocated about 350?km east of the East Pacific Rise, Easter Island lies within the Nazca Plate, bordering the Easter Microplate. The Nazca-Pacific relative plate movement due to the seafloor spreading, amounts to about 150 mm per year. This movement over the Easter hotspot has resulted in the Easter Seamount Chain, which merges into the Nazca Ridge further to the east. Easter Island and Sala y G܇mez are surface representations of that chain. The chain has progressively younger ages to the west. The current hotspot location is speculated to be west of Easter Island, amidst the Ahu, Umu and Tupa submarine volcanic fields and the Pukao and Moai seamounts.[51]\\r\\nEaster Island lies atop the Rano Kau Ridge, and consists of three shield volcanoes with parallel geologic histories. Poike and Rano Kau exist on the east and south slopes of Terevaka, respectively. Rano Kau developed between 0.78 and 0.46 Ma from tholeiitic to alkalic basalts. This volcano possesses a clearly defined summit caldera. Benmoreitic lavas extruded about the rim from 0.35 to 0.34 Ma. Finally, between 0.24 and 0.11 Ma, a 6.5?km fissure developed along a NE-SW trend, forming monogenetic vents and rhyolitic intrusions. These include the cryptodome islets of Motu Nui and Motu Iti, the islet of Motu Kao Kao, the sheet intrusion of Te Kari Kari, the perlitic obsidian Te Manavai dome and the Maunga Orito dome.[51]\\r\\nPoike formed from tholeiitic to alkali basalts from 0.78 to 0.41 Ma. Its summit collapsed into a caldera which was subsequently filled by the Puakatiki lava cone pahoehoe flows at 0.36 Ma. Finally, the trachytic lava domes of Maunga Vai a Heva, Maunga Tea Tea, and Maunga Parehe formed along a NE-SW trending fissure.[51]\\r\\nTerevaka formed around 0.77 Ma of tholeiitic to alkali basalts, followed by the collapse of its summit into a caldera. Then at about 0.3Ma, cinder cones formed along a NNE-SSW trend on the western rim, while porphyritic benmoreitic lava filled the caldera, and pahoehoe flowed towards the northern coast, forming lava tubes, and to the southeast. Lava domes and a vent complex formed in the Maunga Puka area, while breccias formed along the vents on the western portion of Rano Aroi crater. This volcano's southern and southeastern flanks are composed of younger flows consisting of basalt, alkali basalt, hawaiite, mugearite, and benmoreite from eruptive fissures starting at 0.24 Ma. The youngest lava flow, Roiho, is dated at 0.11 Ma. The Hanga O Teo embayment is interpreted to be a 200 m high landslide scarp.[51]\\r\\nRano Raraku and Maunga Toa Toa are isolated tuff cones of about 0.21 Ma. The crater of Rano Raraku contains a freshwater lake. The stratified tuff is composed of sideromelane, slightly altered to palagonite, and somewhat lithified. The tuff contains lithic fragments of older lava flows. The northwest sector of Rano Raraku contains reddish ash.[51] According to Bandy, \\"...all of the great images of Easter Island are carved from\\" the light and porous tuff from Rano Raraku. A carving was abandoned when a large, dense and hard lithic fragment was encountered. However, these lithics became the basis for stone hammers and chisels. The Puna Pau crater contains an extremely porous pumice, from which was carved the Pukao \\"hats\\". The Maunga Orito obsidian was used to make the \\"mataa\\" spearheads.[52]\\r\\nIn the first half of the 20th century, steam reportedly came out of the Rano Kau crater wall. This was photographed by the island's manager, Mr. Edmunds.[53]\\r\\nUnder the K?ppen climate classification, the climate of Easter Island is classified as a tropical rainforest climate (Af) that borders on a humid subtropical climate. The lowest temperatures are recorded in July and August (minimum 15?C or 59?F) and the highest in February (maximum temperature 28?C or 82?F[54]), the summer season in the southern hemisphere. Winters are relatively mild. The rainiest month is May, though the island experiences year-round rainfall.[55] Easter Island's isolated location exposes it to winds which help to keep the temperature fairly cool. Precipitation averages 1,118 millimetres or 44 inches per year. Occasionally, heavy rainfall and rainstorms strike the island. These occur mostly in the winter months (JuneÿAugust). Since it is close to the South Pacific High and outside the range of the intertropical convergence zone, cyclones and hurricanes do not occur around Easter island.[56] There is significant temperature moderation due to its isolated position in the middle of the ocean.\\r\\nEaster Island, together with its closest neighbour, the tiny island of Isla Sala y G܇mez 415 kilometres (258?mi) farther east, is recognized by ecologists as a distinct ecoregion, the Rapa Nui subtropical broadleaf forests. The original subtropical moist broadleaf forests are now gone, but paleobotanical studies of fossil pollen, tree moulds left by lava flows, and root casts found in local soils indicate that the island was formerly forested, with a range of trees, shrubs, ferns, and grasses. A large extinct palm, Paschalococos disperta, related to the Chilean wine palm (Jubaea chilensis), was one of the dominant trees as attested by fossil evidence. Like its Chilean counterpart it probably took close to 100 years to reach adult height. The Polynesian rat, which the original settlers brought with them, played a very important role in the disappearance of the Rapanui palm. Although some may believe that rats played a major role in the degradation of the forest, less than 10% of palm nuts show teeth marks from rats. The remains of palm stumps in different places indicate that humans caused the trees to fall because in large areas, the stumps were cut efficiently.[60]\\r\\nThe clearance of the palms to make the settlements led to their extinction almost 350 years ago.[61] The toromiro tree (Sophora toromiro) was prehistorically present on Easter Island, but is now extinct in the wild. However the Royal Botanic Gardens, Kew and the G?teborg Botanical Garden are jointly leading a scientific program to reintroduce the toromiro to Easter Island. With the palm and the toromiro virtually gone, there was considerably less rainfall as a result of less condensation. After the island was used to feed thousands of sheep for almost a century, by the mid-1900s the island was mostly covered in grassland with nga'atu or bulrush (Schoenoplectus californicus tatora) in the crater lakes of Rano Raraku and Rano Kau. The presence of these reeds, which are called totora in the Andes, was used to support the argument of a South American origin of the statue builders, but pollen analysis of lake sediments shows these reeds have grown on the island for over 30,000 years.[citation needed] Before the arrival of humans, Easter Island had vast seabird colonies containing probably over 30 resident species, perhaps the world's richest.[62] Such colonies are no longer found on the main island. Fossil evidence indicates five species of landbirds (two rails, two parrots and a heron), all of which have become extinct.[63] Five introduced species of landbird are known to have breeding populations (see List of birds of Easter Island).\\r\\nLacks of studies resulting in poor understandings of oceanic fauna of Easter Island and waters in vicinity, however possibilities of undiscovered breeding grounds for humpback, southern blue and pygmy blue whales including Easter Island and Isla Salas y G܇mez have been considered.[64] Potential breeding area for fin whales have been detected off northeast of the island as well.[65]\\r\\nView of Easter Island from space, 2001. The Poike peninsula is on the right.\\r\\nDigital recreation of its ancient landscape, with tropical forest and palm trees\\r\\nView toward the interior of the island\\r\\nView of Rano Kau and Pacific Ocean\\r\\nThe immunosuppressant drug sirolimus was first discovered in the bacterium Streptomyces hygroscopicus in a soil sample from Easter Island. The drug is also known as rapamycin, after Rapa Nui.[66] It is now being studied for extending longevity in mice.[67]\\r\\nTrees are sparse, rarely forming natural groves, and it has been argued whether native Easter Islanders deforested the island in the process of erecting their statues,[68] and in providing sustenance for an overpopulated island.[citation needed] Experimental archaeology demonstrated that some statues certainly could have been placed on \\"Y\\" shaped wooden frames called miro manga erua and then pulled to their final destinations on ceremonial sites.[68] Other theories involve the use of \\"ladders\\" (parallel wooden rails) over which the statues could have been dragged.[69] Rapanui traditions metaphorically refer to spiritual power (mana) as the means by which the moai were \\"walked\\" from the quarry. Recent experimental recreations have proven that it is fully possible that the moai were literally walked from their quarries to their final positions by use of ropes, casting doubt on the role that their existence plays in the environmental collapse of the island.[70]\\r\\nGiven the island's southern latitude, the climatic effects of the Little Ice Age (about 1650 to 1850) may have exacerbated deforestation, although this remains speculative.[68] Many researchers[71] point to the climatic downtrend caused by the Little Ice Age as a contributing factor to resource stress and to the palm tree's disappearance. Experts, however, do not agree on when exactly the island's palms became extinct.\\r\\nJared Diamond dismisses past climate change as a dominant cause of the island's deforestation in his book Collapse which assesses the collapse of the ancient Easter Islanders.[72] Influenced by Heyerdahl's romantic interpretation of Easter's history (as he acknowledges in chapter 2 of Collapse), Diamond insists that the disappearance of the island's trees seems to coincide with a decline of its civilization around the 17th and 18th centuries. He notes that they stopped making statues at that time and started destroying the ahu. But the link is weakened because the Bird Man cult continued to thrive and survived the great impact caused by the arrival of explorers, whalers, sandalwood traders, and slave raiders.\\r\\nMidden contents show that the main source of protein was tuna and dolphin. With the loss of the trees, there was a sudden drop in the quantities of fish bones found in middens as the islanders lost the means to construct fishing vessels, coinciding with a large increase in bird bones. This was followed by a decrease in the number of bird bones as birds lost their nesting sites or became extinct. A new style of art from this period shows people with exposed ribs and distended bellies, indicative of malnutrition, and it is around this time that many islanders moved to living in fortified caves and the first signs of warfare and cannibalism appear.\\r\\nSoil erosion because of lack of trees is apparent in some places. Sediment samples document that up to half of the native plants had become extinct and that the vegetation of the island drastically altered. Polynesians were primarily farmers, not fishermen, and their diet consisted mainly of cultivated staples such as taro root, sweet potato, yams, cassava, and bananas. With no trees to protect them, sea spray led to crop failures exacerbated by a sudden reduction in fresh water flows. There is evidence that the islanders took to planting crops in caves beneath collapsed ceilings and covered the soil with rocks to reduce evaporation. Cannibalism occurred on many Polynesian islands, sometimes in times of plenty as well as famine. Its presence on Easter Island (based on human remains associated with cooking sites, especially in caves) is supported by oral histories.[citation needed]\\r\\nBenny Peiser[5] noted evidence of self-sufficiency when Europeans first arrived. The island still had smaller trees, mainly toromiro, which became extinct in the wild in the 20th century probably because of slow growth and changes in the island's ecosystem. Cornelis Bouman, Jakob Roggeveen's captain, stated in his logbook, \\"... of yams, bananas and small coconut palms we saw little and no other trees or crops.\\" According to Carl Friedrich Behrens, Roggeveen's officer, \\"The natives presented palm branches as peace offerings.\\" According to ethnographer Alfred Mtraux, the most common type of house was called \\"hare paenga\\" (and is known today as \\"boat house\\") because the roof resembled an overturned boat. The foundations of the houses were made of buried basalt slabs with holes for wooden beams to connect with each other throughout the width of the house. These were then covered with a layer of totora reed, followed by a layer of woven sugarcane leaves, and lastly a layer of woven grass. There were reports by European visitors who said they had seen \\"boles of large palm trees\\".[citation needed]\\r\\nPeiser claims that these reports indicate that large trees existed at that time, which is perhaps contradicted by the Bouman quote above. Plantations were often located farther inland, next to foothills, inside open-ceiling lava tubes, and in other places protected from the strong salt winds and salt spray affecting areas closer to the coast. It is possible many of the Europeans did not venture inland. The statue quarry, only one kilometre (0.62 miles) from the coast with an impressive cliff 100?m (330?ft) high, was not explored by Europeans until well into the 19th century.\\r\\nEaster Island has suffered from heavy soil erosion in recent centuries, perhaps aggravated by agriculture and massive deforestation. This process seems to have been gradual and may have been aggravated by sheep farming throughout most of the 20th century. Jakob Roggeveen reported that Easter Island was exceptionally fertile. \\"Fowls are the only animals they keep. They cultivate bananas, sugar cane, and above all sweet potatoes.\\" In 1786 Jean-Fran?ois de La Prouse visited Easter Island and his gardener declared that \\"three days' work a year\\" would be enough to support the population.\\r\\nRollin, a major in the Prouse expedition, wrote, \\"Instead of meeting with men exhausted by famine... I found, on the contrary, a considerable population, with more beauty and grace than I afterwards met in any other island; and a soil, which, with very little labor, furnished excellent provisions, and in an abundance more than sufficient for the consumption of the inhabitants.\\"[74]\\r\\nAccording to Diamond, the oral traditions (the veracity of which has been questioned by Routledge, Lavachery, Mtraux, Peiser and others) of the current islanders seem obsessed with cannibalism, which he offers as evidence supporting a rapid collapse. For example, he states, to severely insult an enemy one would say, \\"The flesh of your mother sticks between my teeth.\\" This, Diamond asserts, means the food supply of the people ultimately ran out.[75] Cannibalism, however, was widespread across Polynesian cultures.[76] Human bones have not been found in earth ovens other than those behind the religious platforms, indicating that cannibalism in Easter Island was a ritualistic practice. Contemporary ethnographic research has proven there is scarcely any tangible evidence for widespread cannibalism anywhere and at any time on the Island.[77] The first scientific exploration of Easter Island (1914) recorded that the indigenous population strongly rejected allegations that they or their ancestors had been cannibals.[29]\\r\\nThe most important myths are:\\r\\nThe Rapa Nui people had a Stone Age culture and made extensive use of local stone:\\r\\nThe large stone statues, or moai, for which Easter Island is famous, were carved in the period 1100ÿ1680 CE (rectified radio-carbon dates).[16] A total of 887 monolithic stone statues have been inventoried on the island and in museum collections.[78] Although often identified as \\"Easter Island heads\\", the statues have torsos, most of them ending at the top of the thighs, although a small number are complete figures that kneel on bent knees with their hands over their stomachs.[79][80] Some upright moai have become buried up to their necks by shifting soils.\\r\\nAlmost all (95%)[citation needed] moai were carved from compressed, easily worked solidified volcanic ash or tuff found at a single site on the side of the extinct volcano Rano Raraku. The native islanders who carved them used only stone hand chisels, mainly basalt toki, which lie in place all over the quarry. The stone chisels were sharpened by chipping off a new edge when dulled. While sculpting was going on, the volcanic stone was splashed with water to soften it. While many teams worked on different statues at the same time, a single moai took a team of five or six men approximately a year to complete. Each statue represented the deceased head of a lineage.\\r\\nOnly a quarter of the statues were installed. Nearly half remained in the quarry at Rano Raraku, and the rest sat elsewhere, presumably on their way to intended locations. The largest moai raised on a platform is known as \\"Paro\\". It weighs 82 tonnes (90.4 short tons), and is 9.89?m (32.4?ft) long.[81][82] Several other statues of similar weight were transported to ahu on the north and south coasts.\\r\\nPossible means by which the statues were moved include employment of a miro manga erua, a Y-shaped sledge with cross pieces, pulled with ropes made from the tough bark of the hau tree[83] and tied around the statue's neck. Anywhere from 180 to 250 men were required for pulling, depending on the size of the moai. Some 50 of the statues were re-erected in modern times. One of the first was on Ahu Ature Huke in Anakena beach in 1956.[84] It was raised using traditional methods during a Heyerdahl expedition.\\r\\nAnother method that might have been used would be to attach ropes to the statue and rock it, tugging it forward as it rocked. This would fit the legend of the Mo'ai 'walking' to their final locations.[85][86][87] This might have been managed by as few as 15 people, supported by the following evidence:\\r\\nThere is debate around the moai regarding the effects of the monument creation process on the environment. Some believe that the process of creating the moai caused widespread deforestation and ultimately a civil war over scarce resources.[88]\\r\\nIn 2011, a large moai statue was excavated from the ground.[89] During the same excavation program, some larger moai were found to have complex dorsal petroglyphs, revealed by deep excavation of the torso.[90]\\r\\nTukuturi, an unusual bearded kneeling moai\\r\\nAll fifteen standing moai at Ahu Tongariki, excavated and restored in the 1990s\\r\\nAhu Akivi, one of the few inland ahu, with the only moai facing the ocean\\r\\n\\r\\nAhu are stone platforms. Varying greatly in layout, many were reworked during or after the huri mo'ai or statue-toppling era; many became ossuaries; one was dynamited open; and Ahu Tongariki was swept inland by a tsunami. Of the 313 known ahu, 125 carried moaiusually just one, probably because of the shortness of the moai period and transportation difficulties. Ahu Tongariki, one kilometre (0.62 miles) from Rano Raraku, had the most and tallest moai, 15 in total.[91] Other notable ahu with moai are Ahu Akivi, restored in 1960 by William Mulloy, Nau Nau at Anakena and Tahai. Some moai may have been made from wood and were lost.\\r\\nThe classic elements of ahu design are:\\r\\nOn top of many ahu would have been:\\r\\nAhu evolved from the traditional Polynesian marae. In this context ahu referred to a small structure sometimes covered with a thatched roof where sacred objects, including statues, were stored. The ahu were usually adjacent to the marae or main central court where ceremonies took place, though on Easter Island ahu and moai evolved to much greater size. There the marae is the unpaved plaza before the ahu. The biggest ahu is 220 metres (720?ft) and holds 15 statues, some of which are 9 metres (30?ft) high. The filling of an ahu was sourced locally (apart from broken, old moai, fragments of which have been used in the fill).[73] Individual stones are mostly far smaller than the moai, so less work was needed to transport the raw material, but artificially levelling the terrain for the plaza and filling the ahu was laborious.\\r\\nAhu are found mostly on the coast, where they are distributed fairly evenly except on the western slopes of Mount Terevaka and the Rano Kau and Poike[92] headlands. These are the three areas with the least low-lying coastal land, and apart from Poike the furthest areas from Rano Raraku. One ahu with several moai was recorded on the cliffs at Rano Kau in the 1880s but had fallen to the beach before the Routledge expedition.[29]\\r\\nOne of the highest-quality examples of Easter Island stone masonry is the rear wall of the ahu at Vinapu. Made without mortar by shaping hard basalt rocks of up to 7 tonnes to match each other exactly, it has a superficial similarity to some Inca stone walls in South America.[93]\\r\\nTwo types of houses are known from the past: hare paenga, a house with an elliptical foundation, made with basalt slabs and covered with a thatched roof that resembled an overturned boat, and hare oka, a round stone structure. Related stone structures called Tupa look very similar to the hare oka, except that the Tupa were inhabited by astronomer-priests and located near the coast, where the movements of the stars could be easily observed. Settlements also contain hare moa (\\"chicken house\\"), oblong stone structures that housed chickens. The houses at the ceremonial village of Orongo are unique in that they are shaped like hare paenga but are made entirely of flat basalt slabs found inside Rano Kao crater. The entrances to all the houses are very low, and entry requires crawling.\\r\\nIn early times the people of Rapa Nui reportedly sent the dead out to sea in small funerary canoes, as did their Polynesian counterparts on other islands. They later started burying people in secret caves to save the bones from desecration by enemies. During the turmoil of the late 18th century, the islanders seem to have started to bury their dead in the space between the belly of a fallen moai and the front wall of the structure. During the time of the epidemics they made mass graves that were semi-pyramidal stone structures.\\r\\nPetroglyphs are pictures carved into rock, and Easter Island has one of the richest collections in all Polynesia. Around 1,000 sites with more than 4,000 petroglyphs are catalogued. Designs and images were carved out of rock for a variety of reasons: to create totems, to mark territory, or to memorialize a person or event. There are distinct variations around the island in the frequency of themes among petroglyphs, with a concentration of Birdmen at Orongo. Other subjects include sea turtles, Komari (vulvas) and Makemake, the chief god of the Tangata manu or Birdman cult.[94]\\r\\nMakemake with two birdmen, carved from red scoria\\r\\nFish petroglyph found near Ahu Tongariki\\r\\nThe island and neighbouring Motu Nui are riddled with caves, many of which show signs of past human use for planting and as fortifications, including narrowed entrances and crawl spaces with ambush points. Many caves feature in the myths and legends of the Rapa Nui.\\r\\nEaster Island once had an apparent script called rongorongo. Glyphs include pictographic and geometric shapes; the texts were incised in wood in reverse boustrophedon direction. It was first reported by a French missionary, Eugne Eyraud, in 1864. At that time, several islanders said they could understand the writing, but according to tradition, only ruling families and priests were ever literate, and none survived the slave raids and subsequent epidemics. Despite numerous attempts, the surviving texts have not been deciphered, and without decipherment it is not certain that they are actually writing. Part of the problem is the small amount that has survived: only two dozen texts, none of which remain on the island. There are also only a couple of similarities with the petroglyphs on the island.[95]\\r\\nWood was scarce on Easter Island during the 18th and 19th centuries, but a number of highly detailed and distinctive carvings have found their way to the world's museums. Particular forms include:[96]\\r\\nThe Rapanui sponsor an annual festival, the Tapati, held since 1975 around the beginning of February to celebrate Rapanui culture. The islanders also maintain a national football team and three discos in the town of Hanga Roa. Other cultural activities include a musical tradition that combines South American and Polynesian influences and woodcarving.\\r\\nThe Chilean leg of the Red Bull Cliff Diving World Series takes place on the Island of Rapa Nui.\\r\\nPopulation at the 2012 census was 5,761 (increased from 3,791 in 2002).[100] In 2002, 60% were persons of indigenous Rapa Nui origin, 39% were mainland Chileans (or their Easter Island-born descendants) of European or mestizo (mixed European and indigenous Chilean Amerindian) origin, and the remaining 1% were indigenous mainland Chilean Amerindians (or their Easter Island-born descendants).[101] Population density on Easter Island in 2012 is only 35 inhabitants per square kilometre (91/sq?mi).\\r\\nPolynesian dancing with feather costumes is on the tourist itinerary.\\r\\nHanga Roa town hall\\r\\nFishing boats\\r\\nFront view of the Catholic Church, Hanga Roa\\r\\nCatholic Church, Hanga Roa\\r\\nInterior view of the Catholic Church in Hanga Roa\\r\\nThe 1982 population was 1,936. The increase in population in the last census was partly caused by the arrival of people of European or mixed European and Native American descent from the Chilean mainland. However, most married a Rapanui spouse. Around 70% of the population were natives. Estimates of the pre-European population range from 7ÿ17,000. Easter Island's all-time low of 111 inhabitants was reported in 1877. Out of these 111 Rapanui, only 36 had descendants, but all of today's Rapanui claim descent from those 36.\\r\\nEaster Island shares with Juan Fernndez Islands the constitutional status of \\"special territory\\" of Chile, granted in 2007. As of 2011[update] a special charter for the island was under discussion in the Chilean Congress.\\r\\nAdministratively, the island is a province of the Valparaso Region and contains a single commune (comuna). Both the province and the commune are called Isla de Pascua and encompass the whole island and its surrounding islets and rocks, plus Isla Salas y G܇mez, some 380?km (236?mi) to the east. The provincial governor is appointed by the President of the Republic.[102] The municipal administration is located in Hanga Roa, led by a mayor and a six-member municipal council, all directly elected for a four-year mandate.\\r\\nEaster Island is served by Mataveri International Airport, with jet service (currently Boeing 767s and Boeing 787s) from LAN Airlines and, seasonally, subsidiaries such as LAN Peru.","input":"When were the statues on easter island built?"},{"output":"William Gilbert","context":"Electricity is the set of physical phenomena associated with the presence and motion of electric charge. Although initially considered a phenomenon separate from magnetism, since the development of Maxwell's equations, both are recognized as part of a single phenomenon: electromagnetism. Various common phenomena are related to electricity, including lightning, static electricity, electric heating, electric discharges and many others.\\r\\nThe presence of an electric charge, which can be either positive or negative, produces an electric field. On the other hand, the movement of electric charges, which is known as electric current, produces a magnetic field.\\r\\nWhen a charge is placed in a location with a non-zero electric field, a force will act on it. The magnitude of this force is given by Coulomb's law. Thus, if that charge were to move, the electric field would be doing work on the electric charge. Thus we can speak of electric potential at a certain point in space, which is equal to the work done by an external agent in carrying a unit of positive charge from an arbitrarily chosen reference point to that point without any acceleration and is typically measured in volts.\\r\\nElectricity is at the heart of many modern technologies, being used for:\\r\\nElectrical phenomena have been studied since antiquity, though progress in theoretical understanding remained slow until the seventeenth and eighteenth centuries. Even then, practical applications for electricity were few, and it would not be until the late nineteenth century that electrical engineers were able to put it to industrial and residential use. The rapid expansion in electrical technology at this time transformed industry and society, becoming a driving force for the Second Industrial Revolution. Electricity's extraordinary versatility means it can be put to an almost limitless set of applications which include transport, heating, lighting, communications, and computation. Electrical power is now the backbone of modern industrial society.[1]\\r\\n\\r\\n\\r\\nLong before any knowledge of electricity existed, people were aware of shocks from electric fish. Ancient Egyptian texts dating from 2750 BCE referred to these fish as the \\"Thunderer of the Nile\\", and described them as the \\"protectors\\" of all other fish. Electric fish were again reported millennia later by ancient Greek, Roman and Arabic naturalists and physicians.[2] Several ancient writers, such as Pliny the Elder and Scribonius Largus, attested to the numbing effect of electric shocks delivered by catfish and electric rays, and knew that such shocks could travel along conducting objects.[3] Patients suffering from ailments such as gout or headache were directed to touch electric fish in the hope that the powerful jolt might cure them.[4] Possibly the earliest and nearest approach to the discovery of the identity of lightning, and electricity from any other source, is to be attributed to the Arabs, who before the 15th century had the Arabic word for lightning raad (???) applied to the electric ray.[5]\\r\\nAncient cultures around the Mediterranean knew that certain objects, such as rods of amber, could be rubbed with cat's fur to attract light objects like feathers. Thales of Miletus made a series of observations on static electricity around 600 BCE, from which he believed that friction rendered amber magnetic, in contrast to minerals such as magnetite, which needed no rubbing.[6][7][8][9] Thales was incorrect in believing the attraction was due to a magnetic effect, but later science would prove a link between magnetism and electricity. According to a controversial theory, the Parthians may have had knowledge of electroplating, based on the 1936 discovery of the Baghdad Battery, which resembles a galvanic cell, though it is uncertain whether the artifact was electrical in nature.[10]\\r\\nElectricity would remain little more than an intellectual curiosity for millennia until 1600, when the English scientist William Gilbert made a careful study of electricity and magnetism, distinguishing the lodestone effect from static electricity produced by rubbing amber.[6] He coined the New Latin word electricus (\\"of amber\\" or \\"like amber\\", from ?ٶ, elektron, the Greek word for \\"amber\\") to refer to the property of attracting small objects after being rubbed.[11] This association gave rise to the English words \\"electric\\" and \\"electricity\\", which made their first appearance in print in Thomas Browne's Pseudodoxia Epidemica of 1646.[12]\\r\\nFurther work was conducted by Otto von Guericke, Robert Boyle, Stephen Gray and C. F. du Fay.[13] In the 18th century, Benjamin Franklin conducted extensive research in electricity, selling his possessions to fund his work. In June 1752 he is reputed to have attached a metal key to the bottom of a dampened kite string and flown the kite in a storm-threatened sky.[14] A succession of sparks jumping from the key to the back of his hand showed that lightning was indeed electrical in nature.[15] He also explained the apparently paradoxical behavior[16] of the Leyden jar as a device for storing large amounts of electrical charge in terms of electricity consisting of both positive and negative charges.[13]\\r\\nIn 1791, Luigi Galvani published his discovery of bioelectromagnetics, demonstrating that electricity was the medium by which neurons passed signals to the muscles.[17][18][13] Alessandro Volta's battery, or voltaic pile, of 1800, made from alternating layers of zinc and copper, provided scientists with a more reliable source of electrical energy than the electrostatic machines previously used.[17][18] The recognition of electromagnetism, the unity of electric and magnetic phenomena, is due to Hans Christian ?rsted and Andr-Marie Ampre in 1819ÿ1820. Michael Faraday invented the electric motor in 1821, and Georg Ohm mathematically analysed the electrical circuit in 1827.[18] Electricity and magnetism (and light) were definitively linked by James Clerk Maxwell, in particular in his \\"On Physical Lines of Force\\" in 1861 and 1862.[19]\\r\\nWhile the early 19th century had seen rapid progress in electrical science, the late 19th century would see the greatest progress in electrical engineering. Through such people as Alexander Graham Bell, Ott܇ Blthy, Thomas Edison, Galileo Ferraris, Oliver Heaviside, nyos Jedlik, William Thomson, 1st Baron Kelvin, Charles Algernon Parsons, Werner von Siemens, Joseph Swan, Reginald Fessenden, Nikola Tesla and George Westinghouse, electricity turned from a scientific curiosity into an essential tool for modern life, becoming a driving force of the Second Industrial Revolution.[20]\\r\\nIn 1887, Heinrich Hertz[21]:843ÿ844[22] discovered that electrodes illuminated with ultraviolet light create electric sparks more easily. In 1905, Albert Einstein published a paper that explained experimental data from the photoelectric effect as being the result of light energy being carried in discrete quantized packets, energising electrons. This discovery led to the quantum revolution. Einstein was awarded the Nobel Prize in Physics in 1921 for \\"his discovery of the law of the photoelectric effect\\".[23] The photoelectric effect is also employed in photocells such as can be found in solar panels and this is frequently used to make electricity commercially.\\r\\nThe first solid-state device was the \\"cat's-whisker detector\\" first used in the 1900s in radio receivers. A whisker-like wire is placed lightly in contact with a solid crystal (such as a germanium crystal) in order to detect a radio signal by the contact junction effect.[24] In a solid-state component, the current is confined to solid elements and compounds engineered specifically to switch and amplify it. Current flow can be understood in two forms: as negatively charged electrons, and as positively charged electron deficiencies called holes. These charges and holes are understood in terms of quantum physics. The building material is most often a crystalline semiconductor.[25][26]\\r\\nThe solid-state device came into its own with the invention of the transistor in 1947. Common solid-state devices include transistors, microprocessor chips, and RAM. A specialized type of RAM called flash RAM is used in USB flash drives and more recently, solid-state drives to replace mechanically rotating magnetic disc hard disk drives. Solid state devices became prevalent in the 1950s and the 1960s, during the transition from vacuum tubes to semiconductor diodes, transistors, integrated circuit (IC) and the light-emitting diode (LED).\\r\\nThe presence of charge gives rise to an electrostatic force: charges exert a force on each other, an effect that was known, though not understood, in antiquity.[21]:457 A lightweight ball suspended from a string can be charged by touching it with a glass rod that has itself been charged by rubbing with a cloth. If a similar ball is charged by the same glass rod, it is found to repel the first: the charge acts to force the two balls apart. Two balls that are charged with a rubbed amber rod also repel each other. However, if one ball is charged by the glass rod, and the other by an amber rod, the two balls are found to attract each other. These phenomena were investigated in the late eighteenth century by Charles-Augustin de Coulomb, who deduced that charge manifests itself in two opposing forms. This discovery led to the well-known axiom: like-charged objects repel and opposite-charged objects attract.[21]\\r\\nThe force acts on the charged particles themselves, hence charge has a tendency to spread itself as evenly as possible over a conducting surface. The magnitude of the electromagnetic force, whether attractive or repulsive, is given by Coulomb's law, which relates the force to the product of the charges and has an inverse-square relation to the distance between them.[27][28]:35 The electromagnetic force is very strong, second only in strength to the strong interaction,[29] but unlike that force it operates over all distances.[30] In comparison with the much weaker gravitational force, the electromagnetic force pushing two electrons apart is 1042 times that of the gravitational attraction pulling them together.[31]\\r\\nStudy has shown that the origin of charge is from certain types of subatomic particles which have the property of electric charge. Electric charge gives rise to and interacts with the electromagnetic force, one of the four fundamental forces of nature. The most familiar carriers of electrical charge are the electron and proton. Experiment has shown charge to be a conserved quantity, that is, the net charge within an isolated system will always remain constant regardless of any changes taking place within that system.[32] Within the system, charge may be transferred between bodies, either by direct contact, or by passing along a conducting material, such as a wire.[28]:2ÿ5 The informal term static electricity refers to the net presence (or 'imbalance') of charge on a body, usually caused when dissimilar materials are rubbed together, transferring charge from one to the other.\\r\\nThe charge on electrons and protons is opposite in sign, hence an amount of charge may be expressed as being either negative or positive. By convention, the charge carried by electrons is deemed negative, and that by protons positive, a custom that originated with the work of Benjamin Franklin.[33] The amount of charge is usually given the symbol Q and expressed in coulombs;[34] each electron carries the same charge of approximately ?1.6022G10?19?coulomb. The proton has a charge that is equal and opposite, and thus +1.6022G10?19? coulomb. Charge is possessed not just by matter, but also by antimatter, each antiparticle bearing an equal and opposite charge to its corresponding particle.[35]\\r\\nCharge can be measured by a number of means, an early instrument being the gold-leaf electroscope, which although still in use for classroom demonstrations, has been superseded by the electronic electrometer.[28]:2ÿ5\\r\\nThe movement of electric charge is known as an electric current, the intensity of which is usually measured in amperes. Current can consist of any moving charged particles; most commonly these are electrons, but any charge in motion constitutes a current. Electric current can flow through some things, electrical conductors, but will not flow through an electrical insulator.[36]\\r\\nBy historical convention, a positive current is defined as having the same direction of flow as any positive charge it contains, or to flow from the most positive part of a circuit to the most negative part. Current defined in this manner is called conventional current. The motion of negatively charged electrons around an electric circuit, one of the most familiar forms of current, is thus deemed positive in the opposite direction to that of the electrons.[37] However, depending on the conditions, an electric current can consist of a flow of charged particles in either direction, or even in both directions at once. The positive-to-negative convention is widely used to simplify this situation.\\r\\nThe process by which electric current passes through a material is termed electrical conduction, and its nature varies with that of the charged particles and the material through which they are travelling. Examples of electric currents include metallic conduction, where electrons flow through a conductor such as metal, and electrolysis, where ions (charged atoms) flow through liquids, or through plasmas such as electrical sparks. While the particles themselves can move quite slowly, sometimes with an average drift velocity only fractions of a millimetre per second,[28]:17 the electric field that drives them itself propagates at close to the speed of light, enabling electrical signals to pass rapidly along wires.[38]\\r\\nCurrent causes several observable effects, which historically were the means of recognising its presence. That water could be decomposed by the current from a voltaic pile was discovered by Nicholson and Carlisle in 1800, a process now known as electrolysis. Their work was greatly expanded upon by Michael Faraday in 1833. Current through a resistance causes localised heating, an effect James Prescott Joule studied mathematically in 1840.[28]:23ÿ24 One of the most important discoveries relating to current was made accidentally by Hans Christian ?rsted in 1820, when, while preparing a lecture, he witnessed the current in a wire disturbing the needle of a magnetic compass.[39] He had discovered electromagnetism, a fundamental interaction between electricity and magnetics. The level of electromagnetic emissions generated by electric arcing is high enough to produce electromagnetic interference, which can be detrimental to the workings of adjacent equipment.[40]\\r\\nIn engineering or household applications, current is often described as being either direct current (DC) or alternating current (AC). These terms refer to how the current varies in time. Direct current, as produced by example from a battery and required by most electronic devices, is a unidirectional flow from the positive part of a circuit to the negative.[41]:11 If, as is most common, this flow is carried by electrons, they will be travelling in the opposite direction. Alternating current is any current that reverses direction repeatedly; almost always this takes the form of a sine wave.[41]:206ÿ207 Alternating current thus pulses back and forth within a conductor without the charge moving any net distance over time. The time-averaged value of an alternating current is zero, but it delivers energy in first one direction, and then the reverse. Alternating current is affected by electrical properties that are not observed under steady state direct current, such as inductance and capacitance.[41]:223ÿ225 These properties however can become important when circuitry is subjected to transients, such as when first energised.\\r\\nThe concept of the electric field was introduced by Michael Faraday. An electric field is created by a charged body in the space that surrounds it, and results in a force exerted on any other charges placed within the field. The electric field acts between two charges in a similar manner to the way that the gravitational field acts between two masses, and like it, extends towards infinity and shows an inverse square relationship with distance.[30] However, there is an important difference. Gravity always acts in attraction, drawing two masses together, while the electric field can result in either attraction or repulsion. Since large bodies such as planets generally carry no net charge, the electric field at a distance is usually zero. Thus gravity is the dominant force at distance in the universe, despite being much weaker.[31]\\r\\nAn electric field generally varies in space,[42] and its strength at any one point is defined as the force (per unit charge) that would be felt by a stationary, negligible charge if placed at that point.[21]:469ÿ470 The conceptual charge, termed a 'test charge', must be vanishingly small to prevent its own electric field disturbing the main field and must also be stationary to prevent the effect of magnetic fields. As the electric field is defined in terms of force, and force is a vector, so it follows that an electric field is also a vector, having both magnitude and direction. Specifically, it is a vector field.[21]:469ÿ470\\r\\nThe study of electric fields created by stationary charges is called electrostatics. The field may be visualised by a set of imaginary lines whose direction at any point is the same as that of the field. This concept was introduced by Faraday,[43] whose term 'lines of force' still sometimes sees use. The field lines are the paths that a point positive charge would seek to make as it was forced to move within the field; they are however an imaginary concept with no physical existence, and the field permeates all the intervening space between the lines.[43] Field lines emanating from stationary charges have several key properties: first, that they originate at positive charges and terminate at negative charges; second, that they must enter any good conductor at right angles, and third, that they may never cross nor close in on themselves.[21]:479\\r\\nA hollow conducting body carries all its charge on its outer surface. The field is therefore zero at all places inside the body.[28]:88 This is the operating principal of the Faraday cage, a conducting metal shell which isolates its interior from outside electrical effects.\\r\\nThe principles of electrostatics are important when designing items of high-voltage equipment. There is a finite limit to the electric field strength that may be withstood by any medium. Beyond this point, electrical breakdown occurs and an electric arc causes flashover between the charged parts. Air, for example, tends to arc across small gaps at electric field strengths which exceed 30?kV per centimetre. Over larger gaps, its breakdown strength is weaker, perhaps 1?kV per centimetre.[44] The most visible natural occurrence of this is lightning, caused when charge becomes separated in the clouds by rising columns of air, and raises the electric field in the air to greater than it can withstand. The voltage of a large lightning cloud may be as high as 100?MV and have discharge energies as great as 250?kWh.[45]\\r\\nThe field strength is greatly affected by nearby conducting objects, and it is particularly intense when it is forced to curve around sharply pointed objects. This principle is exploited in the lightning conductor, the sharp spike of which acts to encourage the lightning stroke to develop there, rather than to the building it serves to protect[46]:155\\r\\nThe concept of electric potential is closely linked to that of the electric field. A small charge placed within an electric field experiences a force, and to have brought that charge to that point against the force requires work. The electric potential at any point is defined as the energy required to bring a unit test charge from an infinite distance slowly to that point. It is usually measured in volts, and one volt is the potential for which one joule of work must be expended to bring a charge of one coulomb from infinity.[21]:494ÿ498 This definition of potential, while formal, has little practical application, and a more useful concept is that of electric potential difference, and is the energy required to move a unit charge between two specified points. An electric field has the special property that it is conservative, which means that the path taken by the test charge is irrelevant: all paths between two specified points expend the same energy, and thus a unique value for potential difference may be stated.[21]:494ÿ498 The volt is so strongly identified as the unit of choice for measurement and description of electric potential difference that the term voltage sees greater everyday usage.\\r\\nFor practical purposes, it is useful to define a common reference point to which potentials may be expressed and compared. While this could be at infinity, a much more useful reference is the Earth itself, which is assumed to be at the same potential everywhere. This reference point naturally takes the name earth or ground. Earth is assumed to be an infinite source of equal amounts of positive and negative charge, and is therefore electrically unchargedand unchargeable.[47]\\r\\nElectric potential is a scalar quantity, that is, it has only magnitude and not direction. It may be viewed as analogous to height: just as a released object will fall through a difference in heights caused by a gravitational field, so a charge will 'fall' across the voltage caused by an electric field.[48] As relief maps show contour lines marking points of equal height, a set of lines marking points of equal potential (known as equipotentials) may be drawn around an electrostatically charged object. The equipotentials cross all lines of force at right angles. They must also lie parallel to a conductor's surface, otherwise this would produce a force that will move the charge carriers to even the potential of the surface.\\r\\nThe electric field was formally defined as the force exerted per unit charge, but the concept of potential allows for a more useful and equivalent definition: the electric field is the local gradient of the electric potential. Usually expressed in volts?per?metre, the vector direction of the field is the line of greatest slope of potential, and where the equipotentials lie closest together.[28]:60\\r\\n?rsted's discovery in 1821 that a magnetic field existed around all sides of a wire carrying an electric current indicated that there was a direct relationship between electricity and magnetism. Moreover, the interaction seemed different from gravitational and electrostatic forces, the two forces of nature then known. The force on the compass needle did not direct it to or away from the current-carrying wire, but acted at right angles to it.[39] ?rsted's slightly obscure words were that \\"the electric conflict acts in a revolving manner.\\" The force also depended on the direction of the current, for if the flow was reversed, then the force did too.[49]\\r\\n?rsted did not fully understand his discovery, but he observed the effect was reciprocal: a current exerts a force on a magnet, and a magnetic field exerts a force on a current. The phenomenon was further investigated by Ampre, who discovered that two parallel current-carrying wires exerted a force upon each other: two wires conducting currents in the same direction are attracted to each other, while wires containing currents in opposite directions are forced apart.[50] The interaction is mediated by the magnetic field each current produces and forms the basis for the international definition of the ampere.[50]\\r\\nThis relationship between magnetic fields and currents is extremely important, for it led to Michael Faraday's invention of the electric motor in 1821. Faraday's homopolar motor consisted of a permanent magnet sitting in a pool of mercury. A current was allowed through a wire suspended from a pivot above the magnet and dipped into the mercury. The magnet exerted a tangential force on the wire, making it circle around the magnet for as long as the current was maintained.[51]\\r\\nExperimentation by Faraday in 1831 revealed that a wire moving perpendicular to a magnetic field developed a potential difference between its ends. Further analysis of this process, known as electromagnetic induction, enabled him to state the principle, now known as Faraday's law of induction, that the potential difference induced in a closed circuit is proportional to the rate of change of magnetic flux through the loop. Exploitation of this discovery enabled him to invent the first electrical generator in 1831, in which he converted the mechanical energy of a rotating copper disc to electrical energy.[51] Faraday's disc was inefficient and of no use as a practical generator, but it showed the possibility of generating electric power using magnetism, a possibility that would be taken up by those that followed on from his work.\\r\\nThe ability of chemical reactions to produce electricity, and conversely the ability of electricity to drive chemical reactions has a wide array of uses.\\r\\nElectrochemistry has always been an important part of electricity. From the initial invention of the Voltaic pile, electrochemical cells have evolved into the many different types of batteries, electroplating and electrolysis cells. Aluminium is produced in vast quantities this way, and many portable devices are electrically powered using rechargeable cells.\\r\\nAn electric circuit is an interconnection of electric components such that electric charge is made to flow along a closed path (a circuit), usually to perform some useful task.\\r\\nThe components in an electric circuit can take many forms, which can include elements such as resistors, capacitors, switches, transformers and electronics. Electronic circuits contain active components, usually semiconductors, and typically exhibit non-linear behaviour, requiring complex analysis. The simplest electric components are those that are termed passive and linear: while they may temporarily store energy, they contain no sources of it, and exhibit linear responses to stimuli.[52]:15ÿ16\\r\\nThe resistor is perhaps the simplest of passive circuit elements: as its name suggests, it resists the current through it, dissipating its energy as heat. The resistance is a consequence of the motion of charge through a conductor: in metals, for example, resistance is primarily due to collisions between electrons and ions. Ohm's law is a basic law of circuit theory, stating that the current passing through a resistance is directly proportional to the potential difference across it. The resistance of most materials is relatively constant over a range of temperatures and currents; materials under these conditions are known as 'ohmic'. The ohm, the unit of resistance, was named in honour of Georg Ohm, and is symbolised by the Greek letter . 1? is the resistance that will produce a potential difference of one volt in response to a current of one amp.[52]:30ÿ35\\r\\nThe capacitor is a development of the Leyden jar and is a device that can store charge, and thereby storing electrical energy in the resulting field. It consists of two conducting plates separated by a thin insulating dielectric layer; in practice, thin metal foils are coiled together, increasing the surface area per unit volume and therefore the capacitance. The unit of capacitance is the farad, named after Michael Faraday, and given the symbol F: one farad is the capacitance that develops a potential difference of one volt when it stores a charge of one coulomb. A capacitor connected to a voltage supply initially causes a current as it accumulates charge; this current will however decay in time as the capacitor fills, eventually falling to zero. A capacitor will therefore not permit a steady state current, but instead blocks it.[52]:216ÿ220\\r\\nThe inductor is a conductor, usually a coil of wire, that stores energy in a magnetic field in response to the current through it. When the current changes, the magnetic field does too, inducing a voltage between the ends of the conductor. The induced voltage is proportional to the time rate of change of the current. The constant of proportionality is termed the inductance. The unit of inductance is the henry, named after Joseph Henry, a contemporary of Faraday. One henry is the inductance that will induce a potential difference of one volt if the current through it changes at a rate of one ampere per second. The inductor's behaviour is in some regards converse to that of the capacitor: it will freely allow an unchanging current, but opposes a rapidly changing one.[52]:226ÿ229\\r\\nElectric power is the rate at which electric energy is transferred by an electric circuit. The SI unit of power is the watt, one joule per second.\\r\\nElectric power, like mechanical power, is the rate of doing work, measured in watts, and represented by the letter P. The term wattage is used colloquially to mean \\"electric power in watts.\\" The electric power in watts produced by an electric current I consisting of a charge of Q coulombs every t seconds passing through an electric potential (voltage) difference of V is\\r\\nwhere\\r\\nElectricity generation is often done with electric generators, but can also be supplied by chemical sources such as electric batteries or by other means from a wide variety of sources of energy. Electric power is generally supplied to businesses and homes by the electric power industry. Electricity is usually sold by the kilowatt hour (3.6 MJ) which is the product of power in kilowatts multiplied by running time in hours. Electric utilities measure power using electricity meters, which keep a running total of the electric energy delivered to a customer. Unlike fossil fuels, electricity is a low entropy form of energy and can be converted into motion or many other forms of energy with high efficiency.[53]\\r\\nElectronics deals with electrical circuits that involve active electrical components such as vacuum tubes, transistors, diodes, optoelectronics, sensors and integrated circuits, and associated passive interconnection technologies. The nonlinear behaviour of active components and their ability to control electron flows makes amplification of weak signals possible and electronics is widely used in information processing, telecommunications, and signal processing. The ability of electronic devices to act as switches makes digital information processing possible. Interconnection technologies such as circuit boards, electronics packaging technology, and other varied forms of communication infrastructure complete circuit functionality and transform the mixed components into a regular working system.\\r\\nToday, most electronic devices use semiconductor components to perform electron control. The study of semiconductor devices and related technology is considered a branch of solid state physics, whereas the design and construction of electronic circuits to solve practical problems come under electronics engineering.\\r\\nFaraday's and Ampre's work showed that a time-varying magnetic field acted as a source of an electric field, and a time-varying electric field was a source of a magnetic field. Thus, when either field is changing in time, then a field of the other is necessarily induced.[21]:696ÿ700 Such a phenomenon has the properties of a wave, and is naturally referred to as an electromagnetic wave. Electromagnetic waves were analysed theoretically by James Clerk Maxwell in 1864. Maxwell developed a set of equations that could unambiguously describe the interrelationship between electric field, magnetic field, electric charge, and electric current. He could moreover prove that such a wave would necessarily travel at the speed of light, and thus light itself was a form of electromagnetic radiation. Maxwell's Laws, which unify light, fields, and charge are one of the great milestones of theoretical physics.[21]:696ÿ700\\r\\nThus, the work of many researchers enabled the use of electronics to convert signals into high frequency oscillating currents, and via suitably shaped conductors, electricity permits the transmission and reception of these signals via radio waves over very long distances.\\r\\nIn the 6th century BC, the Greek philosopher Thales of Miletus experimented with amber rods and these experiments were the first studies into the production of electrical energy. While this method, now known as the triboelectric effect, can lift light objects and generate sparks, it is extremely inefficient.[54] It was not until the invention of the voltaic pile in the eighteenth century that a viable source of electricity became available. The voltaic pile, and its modern descendant, the electrical battery, store energy chemically and make it available on demand in the form of electrical energy.[54] The battery is a versatile and very common power source which is ideally suited to many applications, but its energy storage is finite, and once discharged it must be disposed of or recharged. For large electrical demands electrical energy must be generated and transmitted continuously over conductive transmission lines.\\r\\nElectrical power is usually generated by electro-mechanical generators driven by steam produced from fossil fuel combustion, or the heat released from nuclear reactions; or from other sources such as kinetic energy extracted from wind or flowing water. The modern steam turbine invented by Sir Charles Parsons in 1884 today generates about 80 percent of the electric power in the world using a variety of heat sources. Such generators bear no resemblance to Faraday's homopolar disc generator of 1831, but they still rely on his electromagnetic principle that a conductor linking a changing magnetic field induces a potential difference across its ends.[55] The invention in the late nineteenth century of the transformer meant that electrical power could be transmitted more efficiently at a higher voltage but lower current. Efficient electrical transmission meant in turn that electricity could be generated at centralised power stations, where it benefited from economies of scale, and then be despatched relatively long distances to where it was needed.[56][57]\\r\\nSince electrical energy cannot easily be stored in quantities large enough to meet demands on a national scale, at all times exactly as much must be produced as is required.[56] This requires electricity utilities to make careful predictions of their electrical loads, and maintain constant co-ordination with their power stations. A certain amount of generation must always be held in reserve to cushion an electrical grid against inevitable disturbances and losses.\\r\\nDemand for electricity grows with great rapidity as a nation modernises and its economy develops. The United States showed a 12% increase in demand during each year of the first three decades of the twentieth century,[58] a rate of growth that is now being experienced by emerging economies such as those of India or China.[59][60] Historically, the growth rate for electricity demand has outstripped that for other forms of energy.[61]:16\\r\\nEnvironmental concerns with electricity generation have led to an increased focus on generation from renewable sources, in particular from wind and hydropower. While debate can be expected to continue over the environmental impact of different means of electricity production, its final form is relatively clean.[61]:89\\r\\nElectricity is a very convenient way to transfer energy, and it has been adapted to a huge, and growing, number of uses.[62] The invention of a practical incandescent light bulb in the 1870s led to lighting becoming one of the first publicly available applications of electrical power. Although electrification brought with it its own dangers, replacing the naked flames of gas lighting greatly reduced fire hazards within homes and factories.[63] Public utilities were set up in many cities targeting the burgeoning market for electrical lighting. In the late 20th century and in modern times, the trend has started to flow in the direction of deregulation in the electrical power sector.[64]\\r\\nThe resistive Joule heating effect employed in filament light bulbs also sees more direct use in electric heating. While this is versatile and controllable, it can be seen as wasteful, since most electrical generation has already required the production of heat at a power station.[65] A number of countries, such as Denmark, have issued legislation restricting or banning the use of resistive electric heating in new buildings.[66] Electricity is however still a highly practical energy source for heating and refrigeration,[67] with air conditioning/heat pumps representing a growing sector for electricity demand for heating and cooling, the effects of which electricity utilities are increasingly obliged to accommodate.[68]\\r\\nElectricity is used within telecommunications, and indeed the electrical telegraph, demonstrated commercially in 1837 by Cooke and Wheatstone, was one of its earliest applications. With the construction of first intercontinental, and then transatlantic, telegraph systems in the 1860s, electricity had enabled communications in minutes across the globe. Optical fibre and satellite communication have taken a share of the market for communications systems, but electricity can be expected to remain an essential part of the process.\\r\\nThe effects of electromagnetism are most visibly employed in the electric motor, which provides a clean and efficient means of motive power. A stationary motor such as a winch is easily provided with a supply of power, but a motor that moves with its application, such as an electric vehicle, is obliged to either carry along a power source such as a battery, or to collect current from a sliding contact such as a pantograph.\\r\\nElectronic devices make use of the transistor, perhaps one of the most important inventions of the twentieth century,[69] and a fundamental building block of all modern circuitry. A modern integrated circuit may contain several billion miniaturised transistors in a region only a few centimetres square.[70]\\r\\nElectricity is also used to fuel public transportation, including electric buses and trains. [71]\\r\\nA voltage applied to a human body causes an electric current through the tissues, and although the relationship is non-linear, the greater the voltage, the greater the current.[72] The threshold for perception varies with the supply frequency and with the path of the current, but is about 0.1?mA to 1?mA for mains-frequency electricity, though a current as low as a microamp can be detected as an electrovibration effect under certain conditions.[73] If the current is sufficiently high, it will cause muscle contraction, fibrillation of the heart, and tissue burns.[72] The lack of any visible sign that a conductor is electrified makes electricity a particular hazard. The pain caused by an electric shock can be intense, leading electricity at times to be employed as a method of torture. Death caused by an electric shock is referred to as electrocution. Electrocution is still the means of judicial execution in some jurisdictions, though its use has become rarer in recent times.[74]\\r\\nElectricity is not a human invention, and may be observed in several forms in nature, a prominent manifestation of which is lightning. Many interactions familiar at the macroscopic level, such as touch, friction or chemical bonding, are due to interactions between electric fields on the atomic scale. The Earth's magnetic field is thought to arise from a natural dynamo of circulating currents in the planet's core.[75] Certain crystals, such as quartz, or even sugar, generate a potential difference across their faces when subjected to external pressure.[76] This phenomenon is known as piezoelectricity, from the Greek piezein (?), meaning to press, and was discovered in 1880 by Pierre and Jacques Curie. The effect is reciprocal, and when a piezoelectric material is subjected to an electric field, a small change in physical dimensions takes place.[76]\\r\\nSome organisms, such as sharks, are able to detect and respond to changes in electric fields, an ability known as electroreception,[77] while others, termed electrogenic, are able to generate voltages themselves to serve as a predatory or defensive weapon.[3] The order Gymnotiformes, of which the best known example is the electric eel, detect or stun their prey via high voltages generated from modified muscle cells called electrocytes.[3][4] All animals transmit information along their cell membranes with voltage pulses called action potentials, whose functions include communication by the nervous system between neurons and muscles.[78] An electric shock stimulates this system, and causes muscles to contract.[79] Action potentials are also responsible for coordinating activities in certain plants.[78]\\r\\nIn 1850, William Gladstone asked the scientist Michael Faraday why electricity was valuable. Faraday answered, One day sir, you may tax it.[80]\\r\\nIn the 19th and early 20th century, electricity was not part of the everyday life of many people, even in the industrialised Western world. The popular culture of the time accordingly often depicts it as a mysterious, quasi-magical force that can slay the living, revive the dead or otherwise bend the laws of nature.[81] This attitude began with the 1771 experiments of Luigi Galvani in which the legs of dead frogs were shown to twitch on application of animal electricity. \\"Revitalization\\" or resuscitation of apparently dead or drowned persons was reported in the medical literature shortly after Galvani's work. These results were known to Mary Shelley when she authored Frankenstein (1819), although she does not name the method of revitalization of the monster. The revitalization of monsters with electricity later became a stock theme in horror films.\\r\\nAs the public familiarity with electricity as the lifeblood of the Second Industrial Revolution grew, its wielders were more often cast in a positive light,[82] such as the workers who \\"finger death at their gloves' end as they piece and repiece the living wires\\" in Rudyard Kipling's 1907 poem Sons of Martha.[82] Electrically powered vehicles of every sort featured large in adventure stories such as those of Jules Verne and the Tom Swift books.[82] The masters of electricity, whether fictional or realincluding scientists such as Thomas Edison, Charles Steinmetz or Nikola Teslawere popularly conceived of as having wizard-like powers.[82]\\r\\nWith electricity ceasing to be a novelty and becoming a necessity of everyday life in the later half of the 20th century, it required particular attention by popular culture only when it stops flowing,[82] an event that usually signals disaster.[82] The people who keep it flowing, such as the nameless hero of Jimmy Webbs song \\"Wichita Lineman\\" (1968),[82] are still often cast as heroic, wizard-like figures.[82]\\r\\n Media related to Electricity at Wikimedia Commons","input":"Who was the first person who discovered electricity?"},{"output":"2,546","context":"India has some of the world's most biodiverse regions. The political boundaries of India encompass a wide range of ecozonesadhudesert, high mountains, highlands, tropical and temperate forests, swamplands, plains, grasslands, areas surrounding rivers, as well as island archipelago. It hosts 4 biodiversity hotspots: the Western Ghats, the Himalayas, the Indo-Burma region and the Sundaland[Includes Nicobar group of Islands].[1] These hotspots have numerous endemic species.[2]\\r\\nIndia, for the most part, lies within the Indomalaya ecozone, with the upper reaches of the Himalayas forming part of the Palearctic ecozone; the contours of 2000 to 2500m are considered to be the altitudinal boundary between the Indo-Malayan and Palearctic zones. India displays significant biodiversity. One of seventeen megadiverse countries, it is home to 7.6% of all mammalian, 12.6% of all avian, 6.2% of all reptilian, 4.4% of all amphibian, 11.7% of all fish, and 6.0% of all flowering plant species.[3]\\r\\nThe region is also heavily influenced by summer monsoons that cause major seasonal changes in vegetation and habitat. India forms a large part of the Indomalayan biogeographical zone and many of the floral and faunal forms show Malayan affinities with only a few taxa being unique to the Indian region. The unique forms includes the snake family Uropeltidae found only in the Western Ghats and Sri Lanka. Fossil taxa from the Cretaceous show links to the Seychelles and Madagascar chain of islands.[4] The Cretaceous fauna include reptiles, amphibians and fishes and an extant species demonstrating this phylogeographical link is the purple frog. The separation of India and Madagascar is traditionally estimated to have taken place about 88 million years ago. However, there are suggestions that the links to Madagascar and Africa were present even at the time when the Indian subcontinent met Eurasia. India has been suggested as a ship for the movement of several African taxa into Asia. These taxa include five frog families (including the Myobatrachidae), three caecilian families, a lacertid lizard and freshwater snails of the family Potamiopsidae.[5] A thirty million year old Ologocene era fossil tooth from the Bugti Hills of central Pakistan has been identified as from a lemur-like primate, prompting controversial suggestions that the lemurs may have originated in Asia.[6][7] Lemur fossils from India in the past led to theories of a lost continent called Lemuria. This theory however was dismissed when continental drift and plate tectonics became well established.\\r\\nThe flora and fauna of India have been studied and recorded from early times in folk traditions and later by researchers following more formal scientific approaches (See Natural history in India). Game laws are reported from the third century BC.[8]\\r\\nA little under 5% of this total area is formally classified under protected areas.\\r\\nIndia is home to several well-known large mammals, including the Asian elephant, Bengal tiger, Asiatic lion, leopard and Indian rhinoceros. Some of these animals are engrained in culture, often being associated with deities. These large mammals are important for wildlife tourism in India, and several national parks and wildlife sanctuaries cater to these needs. The popularity of these charismatic animals have helped greatly in conservation efforts in India. The tiger has been particularly important, and Project Tiger, started in 1972, was a major effort to conserve the tiger and its habitats.[9] Project Elephant, though less known, started in 1992 and works for elephant protection.[10] Most of India's rhinos today survive in the Kaziranga National Park. Some other well-known large Indian mammals are: ungulates such as the water buffalo, nilgai, gaur and several species of deer and antelope. Some members of the dog family such as the Indian wolf, Bengal fox, golden jackal and the dhole or wild dogs are also widely distributed. It is also home to the striped hyaena. Many smaller animals such as macaques, langurs and mongoose species are especially well known due to their ability to live close to or inside urban areas Adhu.\\r\\n\\r\\n\\r\\nThere is insufficient information about the invertebrate and lower forms of India, with significant work having been done only in a few groups of insects, notably the butterflies, odonates, hymenoptera, the larger coleoptera and heteroptera. Few concerted attempts to document the biodiversity have been made since the publication of The Fauna of British India, Including Ceylon and Burma series.\\r\\nThere are about 2,546 species of fishes (about 11% of the world species) found in Indian waters. About 197 species of amphibians (4.4% of the world total) and more than 408 reptile species (6% of the world total) are found in India. Among these groups the highest levels of endemism are found in the amphibians.\\r\\nThere are about 1,250 species of birds from India, with some variations, depending on taxonomic treatments, accounting for about 12% of the world species.[11]\\r\\nThere are about 410 species of mammals known from India, which is about 8.86% of the world species.[12]\\r\\nIndia has the most number of cat species than any other country.[13]\\r\\nThe World Conservation Monitoring Centre gives an estimate of about 15,000 species of flowering plants in India.\\r\\nThe Western Ghats are a chain of hills that run along the western edge of peninsular India. Their proximity to the ocean and through orographic effect, they receive high rainfall. These regions have moist deciduous forest and rain forest. The region shows high species diversity as well as high levels of endemism. Nearly 77% of the amphibians and 62% of the reptile species found here are found nowhere else.[14] The region shows biogeographical affinities to the Malayan region, and the Satpura hypothesis proposed by Sunder Lal Hora suggests that the hill chains of Central India may have once formed a connection with the forests of northeastern India and into the Indo-Malayan region. Hora used torrent stream fishes to support the theory, but it was also suggested to hold for birds.[15] Later studies have suggested that Hora's original model species were a demonstration of convergent evolution rather than speciation by isolation.[14]\\r\\nMore recent phylogeographic studies have attempted to study the problem using molecular approaches.[16] There are also differences in taxa which are dependent on time of divergence and geological history.[17] Along with Sri Lanka this region also shows some fauna similarities with the Madagascan region especially in the reptiles and amphibians. Examples include the Sinophis snakes, the purple frog and Sri Lankan lizard genus Nessia which appears similar to the Madagascan genus Acontias.[18] Numerous floral links to the Madagascan region also exist.[19] An alternate hypothesis that these taxa may have originally evolved out-of-India has also been suggested.[20]\\r\\nBio geographical quirks exist with some taxa of Malayan origin occurring in Sri Lanka but absent in the Western Ghats. These include insects groups such as the plants such as those of the genus Nepenthes.\\r\\nThe Eastern Himalayas is the region encompassing Bhutan, northeastern India, and southern, central, and eastern Nepal. The region is geologically young and shows high altitudinal variation. It has nearly 163 globally threatened species including the one-horned rhinoceros (Rhinoceros unicornis), the Wild Asian water buffalo (Bubalus bubalis (Arnee)) and in all 45 mammals, 50 birds, 17 reptiles, 12 amphibians, 3 invertebrate and 36 plant species. [21][22] The relict dragonfly (Epiophlebia laidlawi) is an endangered species found here with the only other species in the genus being found in Japan. The region is also home to the Himalayan newt (Tylototriton verrucosus), the only salamander species found within Indian limits.[23]\\r\\nDuring the early Tertiary period, the Indian tableland, what is today peninsular India, was a large island. Prior to becoming an island it was connected to the African region. During the tertiary period this island was separated from the Asian mainland by a shallow sea. The Himalayan region and the greater part of Tibet lay under this sea. The movement of the Indian subcontinent into the Asian landmass created the great Himalayan ranges and raised the sea bed into what is today the plains of northern India.\\r\\nOnce connected to the Asian mainland, many species moved into India. The Himalayas were created in several upheavals. The Siwaliks were formed in the last and the largest number of fossils of the Tertiary period are found in these ranges.[24]\\r\\nThe Siwalik fossils include mastodons, hippopotamus, rhinoceros, sivatherium, a large four-horned ruminant, giraffe, horses, camels, bison, deer, antelope, gorillas, pigs, chimpanzees, orangutans, baboons, langurs, macaques, cheetahs, sabre-toothed cats, lions, tigers, sloth bear, Aurochs, leopards, wolves, dholes, porcupines, rabbits and a host of other mammals.[24]\\r\\nMany fossil tree species have been found in the intertrappean beds [25] including Grewioxylon from the Eocene and Heritieroxylon keralensis from the middle Miocene in Kerala and Heritieroxylon arunachalensis from the Mio-Pliocene of Arunachal Pradesh and at many other places. The discovery of Glossopteris fern fossils from India and Antarctica led to the discovery of Gondwanaland and led to the greater understanding of continental drift. Fossil Cycads[26] are known from India while seven Cycad species continue to survive in India.[27][28]\\r\\nTitanosaurus indicus was perhaps the first dinosaur discovered in India by Richard Lydekker in 1877 in the Narmada valley. This area has been one of the most important areas for paleontology in India. Another dinosaur known from India is Rajasaurus narmadensis,[29] a heavy-bodied and stout carnivorous abelisaurid (theropod) dinosaur that inhabited the area near present-day Narmada river. It was 9 m in length and 3 m in height and somewhat horizontal in posture with a double-crested crown on the skull.\\r\\nSome fossil snakes from the Cenozoic era are also known.[30]\\r\\nSome scientists have suggested that the Deccan lava flows and the gases produced were responsible for the global extinction of dinosaurs however these have been disputed.[31] [32]\\r\\nHimalayacetus subathuensis the oldest-known whale fossil of the family Protocetidae (Eocene), about 53.5 million years old was found in the Simla hills in the foothills of the Himalayas. This area was underwater (in the Tethys sea) during the Tertiary period (when India was an island off Asia). This whale may have been capable of living partly on land. [33] [34] Other fossil whales from India include Remingtonocetus approximately 43-46 million years old.\\r\\nSeveral small mammal fossils have been recorded in the intertrappean beds, however larger mammals are mostly unknown. The only major primate fossils have been from the nearby region of Myanmar.\\r\\nThe exploitation of land and forest resources by humans along with hunting and trapping for food and sport has led to the extinction of many species in India in recent times.[citation needed]\\r\\nProbably the first species to vanish during the time of the Indus Valley civilisation was the species of wild cattle, Bos primegenius nomadicus or the wild zebu, which vanished from its range in the Indus valley and western India, possibly due to inter-breeding with domestic cattle and resultant fragmentation of wild populations due to loss of habitat.[35]\\r\\nNotable mammals which became or are presumed extinct within the country itself include the Indian / Asiatic cheetah, Javan rhinoceros and Sumatran rhinoceros.[36] While some of these large mammal species are confirmed extinct, there have been many smaller animal and plant species whose status is harder to determine. Many species have not been seen since their description. Hubbardia heptaneuron, a species of grass that grew in the spray zone of the Jog Falls prior to the construction of the Linganamakki reservoir, was thought to be extinct but a few were rediscovered near Kolhapur.[37]\\r\\nSome species of birds have gone extinct in recent times, including the pink-headed duck (Rhodonessa caryophyllacea) and the Himalayan quail (Ophrysia superciliosa). A species of warbler, Acrocephalus orinus, known earlier from a single specimen collected by Allan Octavian Hume from near Rampur in Himachal Pradesh was rediscovered after 139 years in Thailand.[38][39] Similarly, the Jerdon's courser (Rhinoptilus bitorquatus), named after the zoologist Thomas C. Jerdon who discovered it in 1848, was rediscovered in 1986 by Bharat Bhushan, an ornithologist at the Bombay Natural History Society after being thought to be extinct.\\r\\nAn estimate of the numbers of species by group in India is given below. This is based on Alfred, 1998.[40]\\r\\nThis section provides links to lists of species of various taxa found in India.","input":"How many species of fisher found in india?"},{"output":"armies of Alexander the Great and Raja Porus","context":"The recorded history of Jhelum (Urdu: ????? ??????), a district of modern-day Pakistan, covers thousands of years. It has since its creation been dominated by Persian, Greek, Hindu, Buddhist, Muslim, Sikh and British influences to present-day Pakistan.\\r\\n\\r\\nJhelum is near the site of the famous Battle of the Hydaspes between the armies of Alexander the Great and Raja Porus. This battle took place a few miles downstream from the city centre, along the river banks. The city was founded to commemorate the death of Alexander's horse, Bucephalus, and was originally called Bucephala. Nearby there is also the historic 16th century Rohtas Fort, another historic fort since Sikh era located at the backside of main bus stand near Railway Phatak Jhelum City now being used as stores under Railway Authorities and also Tilla Jogian; a centuries-long history of the area.\\r\\n\\r\\nThe history of the district dates back to the semi-mythical period of the Mahabharata. Hindu tradition represents the Salt Range as the refuge of the five Pandava brethren during the period of their exile, and every salient point in its scenery is connected with some legend of the national heroes. Modern research has fixed the site of the conflict between Alexander and Porus as within Jhelum district, though the exact spot at which the Macedonian king effected the passage of the Jhelum (or Hydespes) has been hotly disputed.\\r\\n\\r\\nAlexander moved from ancient Taxila of Raja Ambhi, whom he subdued without fight, to Kalar Kahar. From there he moved over the Salt Range, turning left, along the western bank of River Jhelum, which he called Hydaspes. Opposite him on the other bank was a Raja Porus. They fought one of the biggest and most fierce  battle of  Alexander's whole campaign, which eventually Alexander won, after using a surprise move against the valiant Porus but with great difficulty and a heavy loss of life on Alexander's side too. Before moving further, along the river Alexander established a village on west bank of the River and ordered construction of 2000 boats. Greek Admiral Nearches was to arrange wood from nearby higher hills which would be floated down the River and hauled up at this point. He called this village as Boucephila (present-day Jhelum City). The Jhelum River passes vying with the residential areas of the city.\\r\\n\\r\\nThe mosque inside the river is a famous landmark most commuters on the Grand Trunk Road even today. Alexander's Naval Chief was assigned the task of boats building on a very large scale. Therefore, the craftsmen on a large scale were gathered, hence the modern colonies in the city were named as Machine Mohallahs (Number 1, 2 and 3), because of saw mills. Jhelum became timber market for whole of Punjab over the millenniums. It was only after construction of Mangla Dam that log wood does not float down the river and the city has lost this privilege. There is a plywood factory also, which is flourishing. Greeks left marks of their chivalry and martial spirit which mixed up well with the races and clans dwelling in the area.[1]\\r\\n\\r\\nIn 997 CE, Sultan Mahmud Ghaznavi, took over the Ghaznavid dynasty empire established by his father, Sultan Sebuktegin, In 1005 he conquered the Shahis in Kabul in 1005, and followed it by the conquests of Punjab region in including the Jhelum District. The Delhi Sultanate and later Mughal Empire ruled the region. The Punjab region became predominantly Muslim due to missionary Sufi saints whose dargahs dot the landscape of Punjab region.\\r\\n\\r\\nThe Janjuas and Jats, who now hold the Salt Range and its northern plateau respectively, appear to have been the earliest inhabitants.[2]\\r\\n\\r\\nThe Gakhars, who appear to represent an early wave of conquest from the west, and who still inhabit a large tract in the east of the District; while the Awans, who now cluster in the western plain, are apparently later invaders, the Gakhars were the dominant race during the early Muslim era and they long continued to retain their independence, both in Jhelum itself and in the neighbouring District of Rawalpindi.[2]\\r\\n\\r\\nDuring the flourishing period of the Mughal dynasty, the Gakhar chieftains were among the most prosperous and loyal vassals of the house of Babar.The heirs of Mughal tribes spread with the bank of river Jhelum and the main locations of Mughal tribes started to live in Chak Nazar, Khardiyala and Mong Rasool, chotala, Motagarbi, shamasAbad, Pandoori, chak Mughlan, Qazi Chak, and else where. These Mughal tribes belong to highest clan \\"Barlas\\" Mughal. They even lived as open declared Mughal Tribes during the hard period of British. They did not lose their identity and lived with honours. After the 1923 Flood in river Jhelum.These Mughal Families migrated to different parts of Jhelum and Gujrat. As the record shows that they were known as big land owners in Jhelum and Gujrat.One of the family of Mirza Khan Muhammad and Mirza Doust Muhammad, shifted to village Aima Afghana,  having lands denoted by the British Government.Mirza Khan Muhammad had four sons, named Mirza Sarwar Baig, Mirza Aslam Baig, Mirza Sadiq Baig and Mirza Bashir Baig.\\r\\n\\r\\nIn 1765 Gujar Singh defeated the last independent Gakhars Chief, Muqarrrab Khan, and reduced the wild mountaineers of the Salt Range and the Murree Hills to subjection. After the decline of the Mughal Empire, the Sikh invaded and occupied Multan District. The Muslims faced severe restrictions during the Sikh rule.  Gujar Singh's son succeeded to his dominions until 1810, when it fell to Ranjit Singh. Under the Lahore government the dominant classes of Jhelum suffered much from fiscal actions; and the Janjua, Gakhar and Awan families who had a  feudal and aristocratic influence in the area, gradually lost their landed estates, which passed into the hands of their Jat dependents.[2]\\r\\n\\r\\nIn 1847 Jhelum passed with the rest of the Sikh territories into the power of the British.In 1857 the 14th Native Infantry stationed at Jhelum town mutinied, and made a vigorous defence against a force sent from Rawalpindi to disarm them, but decamped on the night following the action, the main body. Being subsequently arrested by the Kashmir authorities, into whose territory they had escaped. British established administration at district level and Jhelum District, which originally was covering large area including Pindigheb and territory up to Indus river, was delimited later to include tehsils of Jhelum, Chakwal and Pind Dadan Khan, with District Headquarters shifting from Pind Dadan Khan to Jhelum. During the 20th Century, this city has a proud history of chivalry and achievements.[3]\\r\\n\\r\\nDuring British rule, Jhelum was a district of Rawalpindi Division, and was larger than the current district of Jhelum. On April 1, 1914, the tehsil of Talagang was detached from the District and incorporated with the new District of Attock. The old Jhelum district (minus Talagang) covered an area of 2,813 square miles (7285?km2) and included Chakwal tehsil - it was bounded by Shahpur and Attock to the west, and by Rawalpindi to the north - the Jhelum River separated it from Kashmir to the north-east and from Gujrat and Shahpur to the south-east and south.[2]\\r\\n\\r\\nDuring British rule, Jhelum was connected by the North-Western Railway to other cities in the Indian empire, 1,367 miles from Calcutta, 1,413 from Bombay, and 849 from Karachi. The population according to the 1901 census of India was 14,951.[4]\\r\\n\\r\\nAccording to the Imperial Gazetteer of India:\\r\\n\\r\\nDuring the Indian Rebellion of 1857, also known as the Indian Mutiny, 35 British soldiers of the Regular 24th Regiment of Foot were killed at the Battle of Jhelum by mutineers from the Honourable East India Companies 14th Bengal Native Infantry (roughly 500 of the soldiers mutinied with roughly 100 of the Sikh soldiers remaining loyal). Among the dead was Captain Francis Spring, the eldest son of Colonel William Spring.[5]. A lectern inside St. John's Church Jhelum shows the names of those 35 soldiers. St. John's Church is located in the Jhelum Cantonment, Pakistan beside the river Jhelum. It was built in 1860 and remains a landmark in the city. It was built as a Protestant church, and was in use throughout the British period. For the past forty years it has been closed to the public and in poor condition, however it has since[when?] been renovated and reopened and is now maintained.\\r\\n\\r\\nThe British soldier William Connolly won a Victoria Cross for his bravery during this battle. Mirza Dildar Baig, also known as Khaki Shah, took part in the mutiny at Jhelum and was later celebrated by Indian Nationalists. He was captured and arrested with the remaining mutineers by authorities in Kashmir and later hanged near the river Jhelum. His grave is in a shrine in Jhelum Dildarnagar, and a small town in Uttar Pradesh is also named after him.\\r\\n\\r\\nThe railway bridge on the river Jhelum was built in 1873 by the British engineer William St. John Galwey. He also made the great Empress Bridge over the river Sutlej.\\r\\n\\r\\nThe predominantly Muslim population supported both the Muslim League and the Pakistan Movement.  After the independence of Pakistan and partition from India in 1947, the minority Hindus and Sikhs were displaced to India while the Muslim refugees from India settled in the Jhelum District.\\r\\n\\r\\nJhelum has long been a key recruiting ground for the Armed Forces and has a history of providing large number of soldiers in particular. It has sent men to serve first in the Honourable East India Company Army then the British Army and more recently to the Pakistan Armed Forces.  As a result it is known locally as city of soldiers or land of martyrs and warriors.[6] During the First World War, Jhelum was notable for providing a significant number of recruits to the Indian Expeditionary Force and, as a result, became a strong source of recruits for the British Indian Army right up to independence.\\r\\n\\r\\nThe first Victoria Cross to be awarded to a son of Jhelum (the highest Imperial, British and Commonwealth award for gallantry) was earned by Subedar Khuda Dad Khan during the First World War whilst fighting in Belgium. Later another son of Jhelum was to be awarded its equivalent; the Nishan-e-Haider of Pakistan. Major Muhammad Akram (Shaheed) received his award posthumously for his actions during the Indo-Pakistani War of 1971.\\r\\n\\r\\nIt is of note that when Pakistan declared independence in 1947, three out the four senior major generals of the new Pakistan Army were from Jhelum: Major General Muhammad Akbar, Major General Nazir Ahmed and Major General Muhammad Iftekhar. Other senior Pakistani military officers of note, who have originated from Jhelum, are; Air Commodore Muhammad Khan Janjua, General Asif Nawaz Janjua and Admiral Tariq Kamal Khan. Colonel Muhammad Khan, the author of Bajang Amad and Bazam Araian, also came from Jhelum.\\r\\n\\r\\nSoldiers, Sailors and Airmen from Jhelum have distinguished themselves in combat from the time of the British Raj through the World Wars and the more recent conflicts with India.  As a result several have won gallantry awards and accolades.[7]\\r\\n\\r\\nAnjum Sultan Shahbaz records some stories of the name Jhelum in his book Tareekh-e-Jhelum as:[8]\\r\\n\\r\\nHowever some writers says when Dara-e-Azam reached a certain place on the river bank by winning the many battles, he fixed his flag on that place and called that place Ja-e-Alam which mean Place of Flag. With the passage of time it became Jhelum from Ja-e-Alam.\\r\\n\\r\\nAccording to a traditional story, Hazrat Saeed Bin Abi Waqas, brother of Hazrat Saad Bin Abi Waqas, was sent to China for preaching Islam, during his journey he reached at city of Jhelum, he saw the shadow of city in water of the river and said ??? ????? (this is jheelum), which means City besides river, in full moon night.\\r\\n\\r\\nHere a notable point is that in English its spellings are Jhelum or Jheelum, not Jehlum.\\r\\n\\r\\nAhmed Shah Abdali also used Jheelum in place of Jhelum and Harian for Kharian in his Diary.\\r\\n\\r\\n(Shahbaz, Anjum Sultan (September 2003). Tareekh-e-Jhelum (urdu). history of jhelum (2nd ed.). Book Corner, Main Bazar, Jhelum. p.?92.?)","input":"Who fought the famous battle near jhelum river?"},{"output":"six years","context":"Majority (51)\\r\\n\\r\\nMinority  (49)\\r\\n\\r\\n\\r\\nThe United States Senate is the upper chamber of the United States Congress, which along with the United States House of Representativesthe lower chambercomprises the legislature of the United States.\\r\\n\\r\\nThe composition and powers of the Senate are established by Article One of the United States Constitution.[1]  The Senate is composed of senators, each of whom represents a single state in its entirety, with each state being equally represented by two senators, regardless of its population, serving staggered terms of six years; with 50 states currently in the Union, there are 100 U.S. Senators. From 1789 until 1913, Senators were appointed by legislatures of the states they represented; following the ratification of the Seventeenth Amendment in 1913, they are now popularly elected.  The Senate chamber is located in the north wing of the Capitol, in Washington, D.C.\\r\\n\\r\\nAs the upper house, the Senate has several powers of advice and consent which are unique to it; these include the ratification of treaties and the confirmation of Cabinet secretaries, Supreme Court justices, federal judges, other federal executive officials, flag officers, regulatory officials, ambassadors, and other federal uniformed officers. In addition to these, in cases wherein no candidate receives a majority of electors for Vice President, the duty befalls upon the Senate to elect one of the top two recipients of electors for that office. It further has the responsibility of conducting trials of those impeached by the House. The Senate is widely considered both a more deliberative[2] and more prestigious[3][4][5] body than the House of Representatives due to its longer terms, smaller size, and statewide constituencies, which historically led to a more collegial and less partisan atmosphere.[6]\\r\\n\\r\\nThe presiding officer of the Senate is the Vice President of the United States, who is President of the Senate. In the Vice President's absence, the President Pro Tempore, who is customarily the senior member of the party holding a majority of seats, presides over the Senate. In the early 20th century, the practice of majority and minority parties electing their floor leaders began, although they are not constitutional officers.\\r\\n\\r\\nThe creators of the Constitution created a bicameral Congress primarily as a compromise between those who felt that each state, since it was sovereign, should be equally represented, and those who felt the Legislature must directly represent the people, as the House of Commons did in the United Kingdom. This idea of having one chamber represent people equally, while the other gives equal representation to states regardless of population, was known as the Connecticut Compromise. There was also a desire to have two Houses that could act as an internal check on each other. One was intended to be a \\"People's House\\" directly elected by the people, and with short terms obliging the representatives to remain close to their constituents. The other was intended to represent the states to such extent as they retained their sovereignty except for the powers expressly delegated to the national government. The Senate was thus not designed to serve the people of the United States equally. The Constitution provides that the approval of both chambers is necessary for the passage of legislation.[7]\\r\\n\\r\\nFirst convened in 1789, the Senate of the United States was formed on the example of the ancient Roman Senate. The name is derived from the senatus, Latin for council of elders (from senex meaning old man in Latin).[8]\\r\\n\\r\\nJames Madison made the following comment about the Senate:\\r\\n\\r\\nIn England, at this day, if elections were open to all classes of people, the property of landed proprietors would be insecure. An agrarian law would soon take place. If these observations be just, our government ought to secure the permanent interests of the country against innovation. Landholders ought to have a share in the government, to support these invaluable interests, and to balance and check the other. They ought to be so constituted as to protect the minority of the opulent against the majority. The Senate, therefore, ought to be this body; and to answer these purposes, the people ought to have permanency and stability.[9]\\r\\n\\r\\nThe Constitution stipulates that no constitutional amendment may be created to deprive a state of its equal suffrage in the Senate without that state's consent. The District of Columbia and all other territories are not entitled to representation allowed to vote in either House of the Congress. The District of Columbia elects two \\"shadow U.S. Senators\\", but they are officials of the D.C. City Government and not members of the U.S. Senate.[10] The United States has had 50 states since 1959,[11] thus the Senate has had 100 senators since 1959.[7]\\r\\n\\r\\nThe disparity between the most and least populous states has grown since the Connecticut Compromise, which granted each state two members of the Senate and at least one member of the House of Representatives, for a total minimum of three presidential Electors, regardless of population. In 1787, Virginia had roughly ten times the population of Rhode Island, whereas today California has roughly 70 times the population of Wyoming, based on the 1790 and 2000 censuses. This means some citizens are effectively two orders of magnitude better represented in the Senate than those in other states. Seats in the House of Representatives are approximately proportionate to the population of each state, reducing the disparity of representation.\\r\\n\\r\\nBefore the adoption of the Seventeenth Amendment in 1913, Senators were elected by the individual state legislatures.[13] Problems with repeated vacant seats due to the inability of a legislature to elect senators, intrastate political struggles, and even bribery and intimidation had gradually led to a growing movement to amend the Constitution to allow for the direct election of senators.[14]\\r\\n\\r\\nArticle I, Section 3 of the Constitution sets three qualifications for senators: (1) they must be at least 30 years old; (2) they must have been citizens of the United States for the past 9 years or longer; and (3) they must be inhabitants of the states they seek to represent at the time of their election. The age and citizenship qualifications for senators are more stringent than those for representatives. In Federalist No. 62, James Madison justified this arrangement by arguing that the \\"senatorial trust\\" called for a \\"greater extent of information and stability of character.\\"\\r\\n\\r\\nThe Senate (not the judiciary) is the sole judge of a senator's qualifications. During its early years, however, the Senate did not closely scrutinize the qualifications of its members. As a result, three senators who failed to meet the age requirement were nevertheless admitted to the Senate: Henry Clay (aged 29 in 1806), Armistead Thomson Mason (aged 28 in 1816), and John Eaton (aged 28 in 1818). Such an occurrence, however, has not been repeated since.[15] In 1934, Rush D. Holt Sr. was elected to the Senate at the age of 29; he waited until he turned 30 (on the next June 19) to take the oath of office. In November 1972, Joe Biden was elected to the Senate at the age of 29, but he reached his 30th birthday before the swearing-in ceremony for incoming senators in January 1973.\\r\\n\\r\\nThe Fourteenth Amendment to the United States Constitution disqualifies from the Senate any federal or state officers who had taken the requisite oath to support the Constitution, but later engaged in rebellion or aided the enemies of the United States. This provision, which came into force soon after the end of the Civil War, was intended to prevent those who had sided with the Confederacy from serving. That Amendment, however, also provides a method to remove that disqualification: a two-thirds vote of both chambers of Congress.\\r\\n\\r\\nOriginally, senators were selected by the state legislatures, not by popular elections. By the early years of the 20th century, the legislatures of as many as 29 states had provided for popular election of senators by referendums.[16] Popular election to the Senate was standardized nationally in 1913 by the ratification of the Seventeenth Amendment.\\r\\n\\r\\nSenators serve terms of six years each; the terms are staggered so that approximately one-third of the seats are up for election every two years. This was achieved by dividing the senators of the 1st Congress into thirds (called classes), where the terms of one-third expired after two years, the terms of another third expired after four, and the terms of the last third expired after six years. This arrangement was also followed after the admission of new states into the union. The staggering of terms has been arranged such that both seats from a given state are not contested in the same general election, except when a mid-term vacancy is being filled. Current senators whose six-year terms are set to expire on January 3, 2019, belong to Class I. There is no constitutional limit to the number of terms a senator may serve.\\r\\n\\r\\nThe Constitution set the date for Congress to conveneArticle 1, Section 4, Clause 2 originally set that date for the third day of December. The Twentieth Amendment, however, changed the opening date for sessions to noon on the third day of January, unless they shall by law appoint a different day. The Twentieth Amendment also states that Congress shall assemble at least once in every year and allows Congress to determine its convening and adjournment dates and other dates and schedules as it desires. Article 1, Section 3 provides that the President has the power to convene Congress on extraordinary occasions at his discretion.\\r\\n\\r\\nA member who has been elected, but not yet seated, is called a \\"senator-elect\\"; a member who has been appointed to a seat, but not yet seated, is called a \\"senator-designate\\".\\r\\n\\r\\nElections to the Senate are held on the first Tuesday after the first Monday in November in even-numbered years, Election Day, and coincide with elections for the House of Representatives.[17] Senators are elected by their state as a whole. The Elections Clause of the United States Constitution grants each state (and Congress, if it so desires to implement a uniform law) the power to legislate a method by which senators are elected. Ballot access rules for independent and minor party candidates also vary from state to state.\\r\\n\\r\\nIn 45 states, a primary election is held first for the Republican and Democratic parties (and a select few third parties, depending on the state) with the general election following a few months later. In most of these states, the nominee may receive only a plurality, while in some states, a runoff is required if no majority was achieved. In the general election, the winner is the candidate who receives a plurality of the popular vote.\\r\\n\\r\\nHowever, in 5 states, different methods are used. In Georgia, a runoff between the top two candidates occurs if the plurality winner in the general election does not also win a majority. In Washington, California, and Louisiana, a nonpartisan blanket primary (also known as a \\"jungle primary\\" or \\"top-two primary\\") is held in which all candidates participate in a single primary regardless of party affiliation and the top two candidates in terms of votes received at the primary election advance to the general election, where the winner is the candidate with the greater number of votes. In Louisiana, the blanket primary is considered the general election and the winner of the blanket primary can win the overall election if he or she received a majority of the vote, skipping the run-off. This can lead to a potential situation in those three states in which both candidates advancing are affiliated with the same party and the seat is considered \\"won\\" by that party even though a winner has not been determined yet overall. In Maine, following two ballot initiatives in 2016 and 2018, respectively, to establish and maintain instant-runoff voting, known in that state as \\"ranked-choice voting\\", the state uses RCV to nominate and elect candidates for federal offices, including the Senate.\\r\\n\\r\\nThe Seventeenth Amendment requires that mid-term vacancies in the Senate be filled by special election. Whenever a Senator must be appointed or elected, the Secretary of the Senate mails one of three forms to the state's governor to inform them of the proper wording to certify the appointment of a new senator.[18]  If a special election for one seat happens to coincide with a general election for the state's other seat, each seat is contested separately. A senator elected in a special election takes office as soon as possible after the election and serves until the original six-year term expires (i.e. not for a full term).\\r\\n\\r\\nThe Seventeenth Amendment also allows state legislatures to give their governors the power \\"to make temporary appointments until the people fill the vacancies by election as the legislature may direct\\". The temporary appointee may run in the special election in their own right.\\r\\n\\r\\nAs of 2015, forty-five states permit their governors to make such appointments. In thirty-seven of these states, the special election to permanently fill the U.S. Senate seat is customarily held at the next general election. The other ten states require that seat remain vacant until an election can be held, often a special elections be held outside of the normal two-year election cycle. In six states, the governor must appoint someone of the same political party as the previous incumbent.[19]\\r\\nIn September 2009, Massachusetts changed its law to enable the governor to appoint a temporary replacement for the late Senator Edward Kennedy until the special election in January 2010.[20][21]\\r\\n\\r\\nIn 2004, Alaska enacted legislation and a separate ballot referendum that took effect on the same day, but that conflicted with each other. The effect of the ballot-approved law is to withhold from the governor authority to appoint a senator.[22] Because the 17th Amendment vests the power to grant that authority to the legislature?ÿ not the people or the state generally?ÿ it is unclear whether the ballot measure supplants the legislature's statute granting that authority.[22] As a result, it is uncertain whether an Alaska governor may appoint an interim senator to serve until a special election is held to fill the vacancy.\\r\\n\\r\\n \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThe Constitution requires that senators take an oath or affirmation to support the Constitution.[23] Congress has prescribed the following oath for all federal officials (except the President), including senators: \\r\\nI, ___ ___, do solemnly swear (or affirm) that I will support and defend the Constitution of the United States against all enemies, foreign and domestic; that I will bear true faith and allegiance to the same; that I take this obligation freely, without any mental reservation or purpose of evasion; and that I will well and faithfully discharge the duties of the office on which I am about to enter. So help me God.[24]\\r\\n\\r\\nThe annual salary of each senator, since 2009, is $174,000;[25] the president pro tempore and party leaders receive $193,400.[25][26] In June 2003, at least 40 of the then-senators were millionaires.[27]\\r\\n\\r\\nAlong with earning salaries, senators receive retirement and health benefits that are identical to other federal employees, and are fully vested after five years of service.[26] Senators are covered by the Federal Employees Retirement System (FERS) or Civil Service Retirement System (CSRS). As it is for federal employees, congressional retirement is funded through taxes and the participants' contributions. Under FERS, senators contribute 1.3% of their salary into the FERS retirement plan and pay 6.2% of their salary in Social Security taxes. The amount of a senator's pension depends on the years of service and the average of the highest 3 years of their salary. The starting amount of a senator's retirement annuity may not exceed 80% of their final salary. In 2006, the average annual pension for retired senators and representatives under CSRS was $60,972, while those who retired under FERS, or in combination with CSRS, was $35,952.[26]\\r\\n\\r\\nSenators are regarded as more prominent political figures than members of the House of Representatives because there are fewer of them, and because they serve for longer terms, usually represent larger constituencies (the exception being House at-large districts, which similarly cover entire states), sit on more committees, and have more staffers. Far more senators have been nominees for the presidency than representatives. Furthermore, three senators (Warren Harding, John F. Kennedy, and Barack Obama) have been elected president while serving in the Senate, while only one Representative (James Garfield) has been elected president while serving in the House, though Garfield was also a Senator-designate at the time of his election to the Presidency, having been chosen by the Ohio Legislature to fill a Senate vacancy.\\r\\n\\r\\nAccording to the convention of Senate seniority, the senator with the longer tenure in each state is known as the \\"senior senator\\"; the other is the \\"junior senator\\". This convention does not have official significance, though seniority generally is a factor in the selection of physical offices.[28] In the 115th Congress, the most-senior \\"junior senator\\" is Maria Cantwell of Washington, who was sworn in on January 3, 2001 and is currently 21st in seniority, behind Patty Murray who was sworn in on January 3, 1993 and is currently 9th in seniority. The most-junior \\"senior senator\\" is Bill Cassidy of Louisiana, who was sworn in January 3, 2015, and is currently 81st in seniority, ahead of senator John Neely Kennedy who was sworn in January 3, 2017 and is currently 98th in seniority.\\r\\n\\r\\nThe Senate may expel a senator by a two-thirds vote. Fifteen senators have been expelled in the Senate's history: William Blount, for treason, in 1797, and fourteen in 1861 and 1862 for supporting the Confederate secession. Although no senator has been expelled since 1862, many senators have chosen to resign when faced with expulsion proceedings?ÿ for example, Bob Packwood in 1995. The Senate has also censured and condemned senators; censure requires only a simple majority and does not remove a senator from office. Some senators have opted to withdraw from their re-election races rather than face certain censure or expulsion, such as Robert Torricelli in 2002.\\r\\n\\r\\nThe \\"Majority party\\" is the political party that either has a majority of seats or can form a coalition or caucus with a majority of seats; if two or more parties are tied, the vice president's affiliation determines which party is the majority party. The next-largest party is known as the minority party. The president pro tempore, committee chairs, and some other officials are generally from the majority party; they have counterparts (for instance, the \\"ranking members\\" of committees) in the minority party. Independents and members of third parties (so long as they do not caucus with or support either of the larger parties) are not considered in determining which is the majority party.\\r\\n\\r\\nAt one end of the chamber of the Senate is a dais from which the presiding officer presides. The lower tier of the dais is used by clerks and other officials. One hundred desks are arranged in the chamber in a semicircular pattern and are divided by a wide central aisle. The Democratic Party traditionally sits to the presiding officer's right, and the Republican Party traditionally sits to the presiding officer's left, regardless of which party has a majority of seats.[29] In this respect, the Senate differs from the House of Commons of the United Kingdom and other parliamentary bodies in the Commonwealth of Nations and elsewhere.\\r\\n\\r\\nEach senator chooses a desk based on seniority within the party. By custom, the leader of each party sits in the front row along the center aisle. Forty-eight of the desks date back to 1819, when the Senate chamber was reconstructed after the original contents were destroyed in the 1812 Burning of Washington. Further desks of similar design were added as new states entered the Union.[30] It is a tradition that each senator who uses a desk inscribes their name on the inside of the desk's drawer.[31]\\r\\n\\r\\nExcept for the President of the Senate, the Senate elects its own officers,[1] who maintain order and decorum, manage and schedule the legislative and executive business of the Senate, and interpret the Senate's rules, practices and precedents. Many non-member officers are also hired to run various day-to-day functions of the Senate.\\r\\n\\r\\nUnder the Constitution, the Vice President serves as President of the Senate. He or she may vote in the Senate (ex officio, for he or she is not an elected member of the Senate) in the case of a tie, but is not required to.[32] For much of the nation's history the task of presiding over Senate sessions was one of the Vice President's principal duties (the other being to receive from the states the tally of electoral ballots cast for President and Vice President and to open the certificates \\"in the Presence of the Senate and House of Representatives,\\" so that the total votes could be counted). Since the 1950s, Vice Presidents have presided over few Senate debates. Instead, they have usually presided only on ceremonial occasions, such as swearing in new senators, joint sessions, or at times to announce the result of significant legislation or nomination, or when a tie vote on an important issue is anticipated.\\r\\n\\r\\nThe Constitution authorizes the Senate to elect a president pro tempore (Latin for \\"president for a time\\") who presides over the chamber in the vice president's absence, and is, by custom, the senator of the majority party with the longest record of continuous service.[33] Like the vice president, the president pro tempore does not normally preside over the Senate, but typically delegates the responsibility of presiding to a majority-party senator who presides over the Senate, usually in blocks of one hour on a rotating basis. Frequently, freshmen senators (newly elected members) are asked to preside so that they may become accustomed to the rules and procedures of the body. It is said that, \\"in practice they are usually mere mouthpieces for the Senates parliamentarian, who whispers what they should do\\".[34]\\r\\n\\r\\nThe presiding officer sits in a chair in the front of the Senate chamber. The powers of the presiding officer of the Senate are far less extensive than those of the Speaker of the House. The presiding officer calls on senators to speak (by the rules of the Senate, the first senator who rises is recognized); ruling on points of order (objections by senators that a rule has been breached, subject to appeal to the whole chamber); and announcing the results of votes.\\r\\n\\r\\nEach party elects Senate party leaders. Floor leaders act as the party chief spokesmen. The Senate Majority Leader is responsible for controlling the agenda of the chamber by scheduling debates and votes. Each party elects an assistant leader (whip) who works to ensure that his party's senators vote as the party leadership desires.\\r\\n\\r\\nIn addition to the Vice President, the Senate has several officers who are not members. The Senate's chief administrative officer is the Secretary of the Senate, who maintains public records, disburses salaries, monitors the acquisition of stationery and supplies, and oversees clerks. The Assistant Secretary of the Senate aids the secretary's work. Another official is the Sergeant at Arms who, as the Senate's chief law enforcement officer, maintains order and security on the Senate premises. The Capitol Police handle routine police work, with the sergeant at arms primarily responsible for general oversight. Other employees include the Chaplain, who is elected by the Senate, and Pages, who are appointed.\\r\\n\\r\\nThe Senate uses Standing Rules for operation. Like the House of Representatives, the Senate meets in the United States Capitol in Washington, D.C. At one end of the chamber of the Senate is a dais from which the presiding officer presides. The lower tier of the dais is used by clerks and other officials. Sessions of the Senate are opened with a special prayer or invocation and typically convene on weekdays. Sessions of the Senate are generally open to the public and are broadcast live on television, usually by C-SPAN 2.\\r\\n\\r\\nSenate procedure depends not only on the rules, but also on a variety of customs and traditions. The Senate commonly waives some of its stricter rules by unanimous consent. Unanimous consent agreements are typically negotiated beforehand by party leaders. A senator may block such an agreement, but in practice, objections are rare. The presiding officer enforces the rules of the Senate, and may warn members who deviate from them. The presiding officer sometimes uses the gavel of the Senate to maintain order.\\r\\n\\r\\nA \\"hold\\" is placed when the leader's office is notified that a senator intends to object to a request for unanimous consent from the Senate to consider or pass a measure. A hold may be placed for any reason and can be lifted by a senator at any time. A senator may place a hold simply to review a bill, to negotiate changes to the bill, or to kill the bill. A bill can be held for as long as the senator who objects to the bill wishes to block its consideration.\\r\\n\\r\\nHolds can be overcome, but require time-consuming procedures such as filing cloture. Holds are considered private communications between a senator and the Leader, and are sometimes referred to as \\"secret holds\\". A senator may disclose that he or she has placed a hold.\\r\\n\\r\\nThe Constitution provides that a majority of the Senate constitutes a quorum to do business. Under the rules and customs of the Senate, a quorum is always assumed present unless a quorum call explicitly demonstrates otherwise. A senator may request a quorum call by \\"suggesting the absence of a quorum\\"; a clerk then calls the roll of the Senate and notes which members are present. In practice, senators rarely request quorum calls to establish the presence of a quorum. Instead, quorum calls are generally used to temporarily delay proceedings; usually such delays are used while waiting for a senator to reach the floor to speak or to give leaders time to negotiate. Once the need for a delay has ended, a senator may request unanimous consent to rescind the quorum call.\\r\\n\\r\\nDebate, like most other matters governing the internal functioning of the Senate, is governed by internal rules adopted by the Senate. During debate, senators may only speak if called upon by the presiding officer, but the presiding officer is required to recognize the first senator who rises to speak. Thus, the presiding officer has little control over the course of debate. Customarily, the Majority Leader and Minority Leader are accorded priority during debates even if another senator rises first. All speeches must be addressed to the presiding officer, who is addressed as \\"Mr. President\\" or \\"Madam President\\", and not to another member; other Members must be referred to in the third person. In most cases, senators do not refer to each other by name, but by state or position, using forms such as \\"the senior senator from Virginia\\", \\"the gentleman from California\\", or \\"my distinguished friend the Chairman of the Judiciary Committee\\". Senators address the Senate standing next to their desk.[35]\\r\\n\\r\\nApart from rules governing civility, there are few restrictions on the content of speeches; there is no requirement that speeches pertain to the matter before the Senate.\\r\\n\\r\\nThe rules of the Senate provide that no senator may make more than two speeches on a motion or bill on the same legislative day. A legislative day begins when the Senate convenes and ends with adjournment; hence, it does not necessarily coincide with the calendar day. The length of these speeches is not limited by the rules; thus, in most cases, senators may speak for as long as they please. Often, the Senate adopts unanimous consent agreements imposing time limits. In other cases (for example, for the budget process), limits are imposed by statute. However, the right to unlimited debate is generally preserved.\\r\\n\\r\\nWithin the United States, the Senate is sometimes referred to as \\"world's greatest deliberative body\\".[36][37][38]\\r\\n\\r\\nThe filibuster is a tactic used to defeat bills and motions by prolonging debate indefinitely. A filibuster may entail long speeches, dilatory motions, and an extensive series of proposed amendments. The Senate may end a filibuster by invoking cloture. In most cases, cloture requires the support of three-fifths of the Senate; however, if the matter before the Senate involves changing the rules of the body?ÿ this includes amending provisions regarding the filibuster?ÿ a two-thirds majority is required. In current practice, the threat of filibuster is more important than its use; almost any motion that does not have the support of three-fifths of the Senate effectively fails. This means that 41 senators can make a filibuster happen. Historically, cloture has rarely been invoked because bipartisan support is usually necessary to obtain the required supermajority, so a bill that already has bipartisan support is rarely subject to threats of filibuster. However, motions for cloture have increased significantly in recent years.\\r\\n\\r\\nIf the Senate invokes cloture, debate does not end immediately; instead, it is limited to 2 additional hours unless increased by another three-fifths vote. The longest filibuster speech in the Senate's history was delivered by Strom Thurmond, who spoke for over 24 hours in an unsuccessful attempt to block the passage of the Civil Rights Act of 1957.[39]\\r\\n\\r\\nUnder certain circumstances, the Congressional Budget Act of 1974 provides for a process called \\"reconciliation\\" by which Congress can pass bills related to the budget without those bills being subject to a filibuster. This is accomplished by limiting all Senate floor debate to 20 hours.[40]\\r\\n\\r\\nWhen debate concludes, the motion in question is put to a vote. The Senate often votes by voice vote. The presiding officer puts the question, and Members respond either \\"Yea/Aye\\" (in favor of the motion) or \\"Nay\\" (against the motion). The presiding officer then announces the result of the voice vote. A senator, however, may challenge the presiding officer's assessment and request a recorded vote. The request may be granted only if it is seconded by one-fifth of the senators present. In practice, however, senators second requests for recorded votes as a matter of courtesy. When a recorded vote is held, the clerk calls the roll of the Senate in alphabetical order; senators respond when their name is called. Senators who were not in the chamber when their name was called may still cast a vote so long as the voting remains open. The vote is closed at the discretion of the presiding officer, but must remain open for a minimum of 15 minutes. A majority of those voting determines whether the motion carries.[41] If the vote is tied, the vice president, if present, is entitled to cast a tie-breaking vote. If the vice president is not present, the motion fails.[42]\\r\\n\\r\\nFilibustered bills require a three-fifths majority to overcome the cloture vote (which usually means 60 votes) and get to the normal vote where a simple majority (usually 51 votes) approves the bill. This has caused some news media to confuse the 60 votes needed to overcome a filibuster with the 51 votes needed to approve a bill, with for example USA Today erroneously stating \\"The vote was 58-39 in favor of the provision establishing concealed carry permit reciprocity in the 48 states that have concealed weapons laws. That fell two votes short of the 60 needed to approve the measure\\".[41]\\r\\n\\r\\nOn occasion, the Senate may go into what is called a secret or closed session. During a closed session, the chamber doors are closed, cameras are turned off, and the galleries are completely cleared of anyone not sworn to secrecy, not instructed in the rules of the closed session, or not essential to the session. Closed sessions are rare and usually held only when the Senate is discussing sensitive subject matter such as information critical to national security, private communications from the president, or deliberations during impeachment trials. A senator may call for and force a closed session if the motion is seconded by at least one other member, but an agreement usually occurs beforehand.[43][44] If the Senate does not approve release of a secret transcript, the transcript is stored in the Office of Senate Security and ultimately sent to the national archives. The proceedings remain sealed indefinitely until the Senate votes to remove the injunction of secrecy.[45] In 1973 the House adopted a rule that all committee sessions should be open unless a majority on the committee voted for a closed session.\\r\\n\\r\\nThe Senate maintains a Senate Calendar and an Executive Calendar.[46] The former identifies bills and resolutions awaiting Senate floor actions. The latter identifies executive resolutions, treaties, and nominations reported out by Senate committee(s) and awaiting Senate floor action. Both are updated each day the Senate is in session.\\r\\n\\r\\nThe Senate uses committees (and their subcommittees) for a variety of purposes, including the review of bills and the oversight of the executive branch. Formally, the whole Senate appoints committee members. In practice, however, the choice of members is made by the political parties. Generally, each party honors the preferences of individual senators, giving priority based on seniority. Each party is allocated seats on committees in proportion to its overall strength.\\r\\n\\r\\nMost committee work is performed by 16 standing committees, each of which has jurisdiction over a field such as finance or foreign relations. Each standing committee may consider, amend, and report bills that fall under its jurisdiction. Furthermore, each standing committee considers presidential nominations to offices related to its jurisdiction. (For instance, the Judiciary Committee considers nominees for judgeships, and the Foreign Relations Committee considers nominees for positions in the Department of State.) Committees may block nominees and impede bills from reaching the floor of the Senate. Standing committees also oversee the departments and agencies of the executive branch. In discharging their duties, standing committees have the power to hold hearings and to subpoena witnesses and evidence.\\r\\n\\r\\nThe Senate also has several committees that are not considered standing committees. Such bodies are generally known as select or special committees; examples include the Select Committee on Ethics and the Special Committee on Aging. Legislation is referred to some of these committees, although the bulk of legislative work is performed by the standing committees. Committees may be established on an ad hoc basis for specific purposes; for instance, the Senate Watergate Committee was a special committee created to investigate the Watergate scandal. Such temporary committees cease to exist after fulfilling their tasks.\\r\\n\\r\\nThe Congress includes joint committees, which include members from both the Senate and the House of Representatives. Some joint committees oversee independent government bodies; for instance, the Joint Committee on the Library oversees the Library of Congress. Other joint committees serve to make advisory reports; for example, there exists a Joint Committee on Taxation. Bills and nominees are not referred to joint committees. Hence, the power of joint committees is considerably lower than those of standing committees.\\r\\n\\r\\nEach Senate committee and subcommittee is led by a chair (usually a member of the majority party). Formerly, committee chairs were determined purely by seniority; as a result, several elderly senators continued to serve as chair despite severe physical infirmity or even senility.[47] Committee chairs are elected, but, in practice, seniority is rarely bypassed. The chairs hold extensive powers: they control the committee's agenda, and so decide how much, if any, time to devote to the consideration of a bill; they act with the power of the committee in disapproving or delaying a bill or a nomination by the president; they manage on the floor of the full Senate the consideration of those bills the committee reports. This last role was particularly important in mid-century, when floor amendments were thought not to be collegial. They also have considerable influence: senators who cooperate with their committee chairs are likely to accomplish more good for their states than those who do not. The Senate rules and customs were reformed in the twentieth century, largely in the 1970s. Committee chairmen have less power and are generally more moderate and collegial in exercising it, than they were before reform.[48] The second-highest member, the spokesperson on the committee for the minority party, is known in most cases as the ranking member.[49] In the Select Committee on Intelligence and the Select Committee on Ethics, however, the senior minority member is known as the vice chair.\\r\\n\\r\\nRecent criticisms of the Senate's operations object to what the critics argue is obsolescence as a result of partisan paralysis and a preponderance of arcane rules.[50][51]\\r\\n\\r\\nBills may be introduced in either chamber of Congress. However, the Constitution's Origination Clause provides that \\"All bills for raising Revenue shall originate in the House of Representatives\\".[52] As a result, the Senate does not have the power to initiate bills imposing taxes. Furthermore, the House of Representatives holds that the Senate does not have the power to originate appropriation bills, or bills authorizing the expenditure of federal funds.[53][54][55] Historically, the Senate has disputed the interpretation advocated by the House. However, when the Senate originates an appropriations bill, the House simply refuses to consider it, thereby settling the dispute in practice. The constitutional provision barring the Senate from introducing revenue bills is based on the practice of the British Parliament, in which only the House of Commons may originate such measures.[56]\\r\\n\\r\\nAlthough the Constitution gave the House the power to initiate revenue bills, in practice the Senate is equal to the House in the respect of spending. As Woodrow Wilson wrote:\\r\\n\\r\\nThe Senate's right to amend general appropriation bills has been allowed the widest possible scope. The upper house may add to them what it pleases; may go altogether outside of their original provisions and tack to them entirely new features of legislation, altering not only the amounts but even the objects of expenditure, and making out of the materials sent them by the popular chamber measures of an almost totally new character.[57]\\r\\n\\r\\nThe approval of both houses is required for any bill, including a revenue bill, to become law. Both Houses must pass the same version of the bill; if there are differences, they may be resolved by sending amendments back and forth or by a conference committee, which includes members of both bodies.\\r\\n\\r\\nThe Constitution provides several unique functions for the Senate that form its ability to \\"check and balance\\" the powers of other elements of the Federal Government. These include the requirement that the Senate may advise and must consent to some of the president's government appointments; also the Senate must consent to all treaties with foreign governments; it tries all impeachments, and it elects the vice president in the event no person gets a majority of the electoral votes.\\r\\n\\r\\nThe president can make certain appointments only with the advice and consent of the Senate. Officials whose appointments require the Senate's approval include members of the Cabinet, heads of most federal executive agencies, ambassadors, Justices of the Supreme Court, and other federal judges. Under Article II, Section 2 of the Constitution, a large number of government appointments are subject to potential confirmation; however, Congress has passed legislation to authorize the appointment of many officials without the Senate's consent (usually, confirmation requirements are reserved for those officials with the most significant final decision-making authority). Typically, a nominee is first subject to a hearing before a Senate committee. Thereafter, the nomination is considered by the full Senate. The majority of nominees are confirmed, but in a small number of cases each year, Senate committees purposely fail to act on a nomination to block it. In addition, the president sometimes withdraws nominations when they appear unlikely to be confirmed. Because of this, outright rejections of nominees on the Senate floor are infrequent (there have been only nine Cabinet nominees rejected outright in United States history).[citation needed]\\r\\n\\r\\nThe powers of the Senate concerning nominations are, however, subject to some constraints. For instance, the Constitution provides that the president may make an appointment during a congressional recess without the Senate's advice and consent. The recess appointment remains valid only temporarily; the office becomes vacant again at the end of the next congressional session. Nevertheless, presidents have frequently used recess appointments to circumvent the possibility that the Senate may reject the nominee. Furthermore, as the Supreme Court held in Myers v. United States, although the Senate's advice and consent is required for the appointment of certain executive branch officials, it is not necessary for their removal.[58] Recess appointments have faced a significant amount of resistance and in 1960, the U.S. Senate passed a legally non-binding resolution against recess appointments.\\r\\n\\r\\nThe Senate also has a role in ratifying treaties. The Constitution provides that the president may only \\"make Treaties, provided two thirds of the Senators present concur\\" in order to benefit from the Senate's advice and consent and give each state an equal vote in the process. However, not all international agreements are considered treaties under US domestic law, even if they are considered treaties under international law. Congress has passed laws authorizing the president to conclude executive agreements without action by the Senate. Similarly, the president may make congressional-executive agreements with the approval of a simple majority in each House of Congress, rather than a two-thirds majority in the Senate. Neither executive agreements nor congressional-executive agreements are mentioned in the Constitution, leading some scholars such as Laurence Tribe and John Yoo[59] to suggest that they unconstitutionally circumvent the treaty-ratification process. However, courts have upheld the validity of such agreements.[60]\\r\\n\\r\\nThe Constitution empowers the House of Representatives to impeach federal officials for \\"Treason, Bribery, or other high Crimes and Misdemeanors\\" and empowers the Senate to try such impeachments. If the sitting President of the United States is being tried, the Chief Justice of the United States presides over the trial. During an impeachment trial, senators are constitutionally required to sit on oath or affirmation. Conviction requires a two-thirds majority of the senators present. A convicted official is automatically removed from office; in addition, the Senate may stipulate that the defendant be banned from holding office. No further punishment is permitted during the impeachment proceedings; however, the party may face criminal penalties in a normal court of law.\\r\\n\\r\\nThe House of Representatives has impeached sixteen officials, of whom seven were convicted. (One resigned before the Senate could complete the trial.)[61] Only two presidents of the United States have ever been impeached: Andrew Johnson in 1868 and Bill Clinton in 1998. Both trials ended in acquittal; in Johnson's case, the Senate fell one vote short of the two-thirds majority required for conviction.\\r\\n\\r\\nUnder the Twelfth Amendment, the Senate has the power to elect the vice president if no vice presidential candidate receives a majority of votes in the Electoral College. The Twelfth Amendment requires the Senate to choose from the two candidates with the highest numbers of electoral votes. Electoral College deadlocks are rare. The Senate has only broken a deadlock once; in 1837, it elected Richard Mentor Johnson. The House elects the president if the Electoral College deadlocks on that choice.\\r\\n\\r\\nThe party composition of the Senate during the 115th Congress:\\r\\n\\r\\nThe 115th United States Congress runs from January 3, 2017 to January 3, 2019.\\r\\n\\r\\nThe following are published by the Senate Historical Office.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nCoordinates: 385326N 77032W? / ?38.89056N 77.00889W? / 38.89056; -77.00889","input":"How long is the term for a us senator?"},{"output":"over 300 steps","context":"The Eiffel Tower (/?a?f?l/ EYE-f?l; French: tour Eiffel [tu???f?l]?(?listen)) is a wrought iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\\r\\nConstructed from 1887ÿ89 as the entrance to the 1889 World's Fair, it was initially criticized by some of France's leading artists and intellectuals for its design, but it has become a global cultural icon of France and one of the most recognisable structures in the world.[3] The Eiffel Tower is the most-visited paid monument in the world; 6.91?million people ascended it in 2015.\\r\\nThe tower is 324 metres (1,063?ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410?ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17?ft). Excluding transmitters, the Eiffel Tower is the second tallest structure in France after the Millau Viaduct.\\r\\nThe tower has three levels for visitors, with restaurants on the first and second levels. The top level's upper platform is 276?m (906?ft) above the ground ÿ the highest observation deck accessible to the public in the European Union. Tickets can be purchased to ascend by stairs or lift (elevator) to the first and second levels. The climb from ground level to the first level is over 300 steps, as is the climb from the first level to the second. Although there is a staircase to the top level, it is usually accessible only by lift.\\r\\n\\r\\n\\r\\nThe design of the Eiffel Tower was the product of Maurice Koechlin and mile Nouguier, two senior engineers working for the Compagnie des tablissements Eiffel, after discussion about a suitable centrepiece for the proposed 1889 Exposition Universelle, a world's fair to celebrate the centennial of the French Revolution. Eiffel openly acknowledged that inspiration for a tower came from the Latting Observatory built in New York City in 1853.[4] In May 1884, working at home, Koechlin made a sketch of their idea, described by him as \\"a great pylon, consisting of four lattice girders standing apart at the base and coming together at the top, joined together by metal trusses at regular intervals\\".[5] Eiffel initially showed little enthusiasm, but he did approve further study, and the two engineers then asked Stephen Sauvestre, the head of company's architectural department, to contribute to the design. Sauvestre added decorative arches to the base of the tower, a glass pavilion to the first level, and other embellishments.\\r\\nThe new version gained Eiffel's support: he bought the rights to the patent on the design which Koechlin, Nougier, and Sauvestre had taken out, and the design was exhibited at the Exhibition of Decorative Arts in the autumn of 1884 under the company name. On 30 March 1885, Eiffel presented his plans to the Socit des Ingnieurs Civils; after discussing the technical problems and emphasising the practical uses of the tower, he finished his talk by saying the tower would symbolise,\\r\\nNot only the art of the modern engineer, but also the century of Industry and Science in which we are living, and for which the way was prepared by the great scientific movement of the eighteenth century and by the Revolution of 1789, to which this monument will be built as an expression of France's gratitude.[6]\\r\\nLittle progress was made until 1886, when Jules Grvy was re-elected as president of France and douard Lockroy was appointed as minister for trade. A budget for the exposition was passed and, on 1 May, Lockroy announced an alteration to the terms of the open competition being held for a centrepiece to the exposition, which effectively made the selection of Eiffel's design a foregone conclusion, as entries had to include a study for a 300?m (980?ft) four-sided metal tower on the Champ de Mars.[6] (A 300-meter tower was then considered a herculean engineering effort). On 12 May, a commission was set up to examine Eiffel's scheme and its rivals, which, a month later, decided that all the proposals except Eiffel's were either impractical or lacking in details.\\r\\nAfter some debate about the exact location of the tower, a contract was signed on 8 January 1887. This was signed by Eiffel acting in his own capacity rather than as the representative of his company, and granted him 1.5 million francs toward the construction costs: less than a quarter of the estimated 6.5 million francs. Eiffel was to receive all income from the commercial exploitation of the tower during the exhibition and for the next 20 years. He later established a separate company to manage the tower, putting up half the necessary capital himself.[7]\\r\\nThe proposed tower had been a subject of controversy, drawing criticism from those who did not believe it was feasible and those who objected on artistic grounds. These objections were an expression of a long-standing debate in France about the relationship between architecture and engineering. It came to a head as work began at the Champ de Mars: a \\"Committee of Three Hundred\\" (one member for each metre of the tower's height) was formed, led by the prominent architect Charles Garnier and including some of the most important figures of the arts, such as Adolphe Bouguereau, Guy de Maupassant, Charles Gounod and Jules Massenet. A petition called \\"Artists against the Eiffel Tower\\" was sent to the Minister of Works and Commissioner for the Exposition, Charles Alphand, and it was published by Le Temps on 14 February 1887:\\r\\nWe, writers, painters, sculptors, architects and passionate devotees of the hitherto untouched beauty of Paris, protest with all our strength, with all our indignation in the name of slighted French taste, against the erection  of this useless and monstrous Eiffel Tower  To bring our arguments home, imagine for a moment a giddy, ridiculous tower dominating Paris like a gigantic black smokestack, crushing under its barbaric bulk Notre Dame, the Tour Saint-Jacques, the Louvre, the Dome of les Invalides, the Arc de Triomphe, all of our humiliated monuments will disappear in this ghastly dream. And for twenty years  we shall see stretching like a blot of ink the hateful shadow of the hateful column of bolted sheet metal.[8]\\r\\nGustave Eiffel responded to these criticisms by comparing his tower to the Egyptian pyramids: \\"My tower will be the tallest edifice ever erected by man. Will it not also be grandiose in its way? And why would something admirable in Egypt become hideous and ridiculous in Paris?\\"[9] These criticisms were also dealt with by douard Lockroy in a letter of support written to Alphand, ironically saying,[10] \\"Judging by the stately swell of the rhythms, the beauty of the metaphors, the elegance of its delicate and precise style, one can tell this protest is the result of collaboration of the most famous writers and poets of our time\\", and he explained that the protest was irrelevant since the project had been decided upon months before, and construction on the tower was already under way.\\r\\nIndeed, Garnier was a member of the Tower Commission that had examined the various proposals, and had raised no objection. Eiffel was similarly unworried, pointing out to a journalist that it was premature to judge the effect of the tower solely on the basis of the drawings, that the Champ de Mars was distant enough from the monuments mentioned in the protest for there to be little risk of the tower overwhelming them, and putting the aesthetic argument for the tower: \\"Do not the laws of natural forces always conform to the secret laws of harmony?\\"[11]\\r\\nSome of the protesters changed their minds when the tower was built; others remained unconvinced.[12] Guy de Maupassant supposedly ate lunch in the tower's restaurant every day because it was the one place in Paris where the tower was not visible.[13]\\r\\nBy 1918, it had become a symbol of Paris and of France after Guillaume Apollinaire wrote a nationalist poem in the shape of the tower (a calligram) to express his feelings about the war against Germany.[14] Today, it is widely considered to be a remarkable piece of structural art, and is often featured in films and literature.\\r\\nWork on the foundations started on 28 January 1887.[15] Those for the east and south legs were straightforward, with each leg resting on four 2?m (6.6?ft) concrete slabs, one for each of the principal girders of each leg. The west and north legs, being closer to the river Seine, were more complicated: each slab needed two piles installed by using compressed-air caissons 15?m (49?ft) long and 6?m (20?ft) in diameter driven to a depth of 22?m (72?ft)[16] to support the concrete slabs, which were 6?m (20?ft) thick. Each of these slabs supported a block of limestone with an inclined top to bear a supporting shoe for the ironwork.\\r\\nEach shoe was anchored to the stonework by a pair of bolts 10?cm (4?in) in diameter and 7.5?m (25?ft) long. The foundations were completed on 30 June, and the erection of the ironwork began. The visible work on-site was complemented by the enormous amount of exacting preparatory work that took place behind the scenes: the drawing office produced 1,700 general drawings and 3,629 detailed drawings of the 18,038 different parts needed.[17] The task of drawing the components was complicated by the complex angles involved in the design and the degree of precision required: the position of rivet holes was specified to within 0.1?mm (0.0039?in) and angles worked out to one second of arc. The finished components, some already riveted together into sub-assemblies, arrived on horse-drawn carts from a factory in the nearby Parisian suburb of Levallois-Perret and were first bolted together, with the bolts being replaced with rivets as construction progressed. No drilling or shaping was done on site: if any part did not fit, it was sent back to the factory for alteration. In all, 18,038 pieces were joined together using 2.5?million rivets.[15]\\r\\nAt first the legs were constructed as cantilevers, but about halfway to the first level, construction was paused in order to create a substantial timber scaffold. This renewed concerns about the structural integrity of the tower, and sensational headlines such as \\"Eiffel Suicide!\\" and \\"Gustave Eiffel Has Gone Mad: He Has Been Confined in an Asylum\\" appeared in the tabloid press.[18] At this stage, a small \\"creeper\\" crane designed to move up the tower was installed in each leg. They made use of the guides for the lifts which were to be fitted in the four legs. The critical stage of joining the legs at the first level was completed by the end of March 1888.[15] Although the metalwork had been prepared with the utmost attention to detail, provision had been made to carry out small adjustments in order to precisely align the legs; hydraulic jacks were fitted to the shoes at the base of each leg, capable of exerting a force of 800 tonnes, and the legs were intentionally constructed at a slightly steeper angle than necessary, being supported by sandboxes on the scaffold. Although construction involved 300 on-site employees,[15] only one person died thanks to Eiffel's stringent safety precautions and the use of movable gangways, guardrails and screens[citation needed].\\r\\nThe start of the erection of the metalwork.\\r\\n7 December 1887: Construction of the legs with scaffolding.\\r\\n20 March 1888: Completion of the first level.\\r\\n15 May 1888: Start of construction on the second stage.\\r\\n21 August 1888: Completion of the second level.\\r\\n26 December 1888: Construction of the upper stage.\\r\\n15 March 1889: Construction of the cupola.\\r\\nEquipping the tower with adequate and safe passenger lifts was a major concern of the government commission overseeing the Exposition. Although some visitors could be expected to climb to the first level, or even the second, lifts clearly had to be the main means of ascent.[19]\\r\\nConstructing lifts to reach the first level was relatively straightforward: the legs were wide enough at the bottom and so nearly straight that they could contain a straight track, and a contract was given to the French company Roux, Combaluzier & Lepape for two lifts to be fitted in the east and west legs.[20] Roux, Combaluzier & Lepape used a pair of endless chains with rigid, articulated links to which the car was attached. Lead weights on some links of the upper or return sections of the chains counterbalanced most of the car's weight. The car was pushed up from below, not pulled up from above: to prevent the chain buckling, it was enclosed in a conduit. At the bottom of the run, the chains passed around 3.9?m (12?ft 10?in) diameter sprockets. Smaller sprockets at the top guided the chains.[20]\\r\\nInstalling lifts to the second level was more of a challenge because a straight track was impossible. No French company wanted to undertake the work. The European branch of Otis Brothers & Company submitted a proposal but this was rejected: the fair's charter ruled out the use of any foreign material in the construction of the tower. The deadline for bids was extended but still no French companies put themselves forward, and eventually the contract was given to Otis in July 1887.[21] Otis were confident they would eventually be given the contract and had already started creating designs.\\r\\nThe car was divided into two superimposed compartments, each holding 25 passengers, with the lift operator occupying an exterior platform on the first level. Motive power was provided by an inclined hydraulic ram 12.67?m (41?ft 7?in) long and 96.5?cm (38.0?in) in diameter in the tower leg with a stroke of 10.83?m (35?ft 6?in): this moved a carriage carrying six sheaves. Five fixed sheaves were mounted higher up the leg, producing an arrangement similar to a block and tackle but acting in reverse, multiplying the stroke of the piston rather than the force generated. The hydraulic pressure in the driving cylinder was produced by a large open reservoir on the second level. After being exhausted from the cylinder, the water was pumped back up to the reservoir by two pumps in the machinery room at the base of the south leg. This reservoir also provided power to the lifts to the first level.\\r\\nThe original lifts for the journey between the second and third levels were supplied by Lon Edoux. A pair of 81?m (266?ft) hydraulic rams were mounted on the second level, reaching nearly halfway up to the third level. One lift car was mounted on top of these rams: cables ran from the top of this car up to sheaves on the third level and back down to a second car. Each car only travelled half the distance between the second and third levels and passengers were required to change lifts halfway by means of a short gangway. The 10-ton cars each held 65 passengers.[22]\\r\\nThe main structural work was completed at the end of March 1889 and, on 31 March, Eiffel celebrated by leading a group of government officials, accompanied by representatives of the press, to the top of the tower.[12] Because the lifts were not yet in operation, the ascent was made by foot, and took over an hour, with Eiffel stopping frequently to explain various features. Most of the party chose to stop at the lower levels, but a few, including the structural engineer, mile Nouguier, the head of construction, Jean Compagnon, the President of the City Council, and reporters from Le Figaro and Le Monde Illustr, completed the ascent. At 2:35?pm, Eiffel hoisted a large Tricolour to the accompaniment of a 25-gun salute fired at the first level.[23]\\r\\nThere was still work to be done, particularly on the lifts and facilities, and the tower was not opened to the public until nine days after the opening of the exposition on 6 May; even then, the lifts had not been completed. The tower was an instant success with the public, and nearly 30,000 visitors made the 1,710-step climb to the top before the lifts entered service on 26 May.[24] Tickets cost 2 francs for the first level, 3 for the second, and 5 for the top, with half-price admission on Sundays,[25] and by the end of the exhibition there had been 1,896,987 visitors.[3]\\r\\nAfter dark, the tower was lit by hundreds of gas lamps, and a beacon sent out three beams of red, white and blue light. Two searchlights mounted on a circular rail were used to illuminate various buildings of the exposition. The daily opening and closing of the exposition were announced by a cannon at the top.\\r\\nOn the second level, the French newspaper Le Figaro had an office and a printing press, where a special souvenir edition, Le Figaro de la Tour, was made. There was also a patisserie.\\r\\nAt the top, there was a post office where visitors could send letters and postcards as a memento of their visit. Graffitists were also catered for: sheets of paper were mounted on the walls each day for visitors to record their impressions of the tower. Gustave Eiffel described some of the responses as vraiment curieuse (\\"truly curious\\").[26]\\r\\nFamous visitors to the tower included the Prince of Wales, Sarah Bernhardt, \\"Buffalo Bill\\" Cody (his Wild West show was an attraction at the exposition) and Thomas Edison.[24] Eiffel invited Edison to his private apartment at the top of the tower, where Edison presented him with one of his phonographs, a new invention and one of the many highlights of the exposition.[27] Edison signed the guestbook with this message:\\r\\nTo M Eiffel the Engineer the brave builder of so gigantic and original specimen of modern Engineering from one who has the greatest respect and admiration for all Engineers including the Great Engineer the Bon Dieu, Thomas Edison.\\r\\nEiffel had a permit for the tower to stand for 20 years. It was to be dismantled in 1909, when its ownership would revert to the City of Paris. The City had planned to tear it down (part of the original contest rules for designing a tower was that it should be easy to dismantle) but as the tower proved to be valuable for communication purposes, it was allowed to remain after the expiry of the permit.\\r\\nEiffel made use of his apartment at the top of the tower to carry out meteorological observations, and also used the tower to perform experiments on the action of air resistance on falling bodies.[28]\\r\\nFor the 1900 Exposition Universelle, the lifts in the east and west legs were replaced by lifts running as far as the second level constructed by the French firm Fives-Lille. These had a compensating mechanism to keep the floor level as the angle of ascent changed at the first level, and were driven by a similar hydraulic mechanism to the Otis lifts, although this was situated at the base of the tower. Hydraulic pressure was provided by pressurised accumulators located near this mechanism.[21] At the same time the lift in the north pillar was removed and replaced by a staircase to the first level. The layout of both first and second levels was modified, with the space available for visitors on the second level. The original lift in the south pillar was removed 13 years later.\\r\\nOn 19 October 1901, Alberto Santos-Dumont, flying his No.6 airship, won a 100,000-franc prize offered by Henri Deutsch de la Meurthe for the first person to make a flight from St. Cloud to the Eiffel Tower and back in less than half an hour.[29]\\r\\nMany innovations took place at the Eiffel Tower in the early 20th century. In 1910, Father Theodor Wulf measured radiant energy at the top and bottom of the tower. He found more at the top than expected, incidentally discovering what are known today as cosmic rays.[30] Just two years later, on 4 February 1912, Austrian tailor Franz Reichelt died after jumping from the first level of the tower (a height of 57 metres) to demonstrate his parachute design.[31] In 1914, at the outbreak of World War?I, a radio transmitter located in the tower jammed German radio communications, seriously hindering their advance on Paris and contributing to the Allied victory at the First Battle of the Marne.[32] From 1925 to 1934, illuminated signs for Citro?n adorned three of the tower's sides, making it the tallest advertising space in the world at the time.[citation needed] In April 1935, the tower was used to make experimental low-resolution television transmissions, using a shortwave transmitter of 200 watts power. On 17 November, an improved 180-line transmitter was installed.[33]\\r\\nOn two separate but related occasions in 1925, the con artist Victor Lustig \\"sold\\" the tower for scrap metal.[34] A year later, in February 1926, pilot Leon Collet was killed trying to fly under the tower. His aircraft became entangled in an aerial belonging to a wireless station.[35] A bust of Gustave Eiffel by Antoine Bourdelle was unveiled at the base of the north leg on 2 May 1929.[36] In 1930, the tower lost the title of the world's tallest structure when the Chrysler Building in New York City was completed.[37] In 1938, the decorative arcade around the first level was removed.[38]\\r\\nUpon the German occupation of Paris in 1940, the lift cables were cut by the French. The tower was closed to the public during the occupation and the lifts were not repaired until 1946.[39] In 1940, German soldiers had to climb the tower to hoist a swastika-centered Reichskriegsflagge,[40] but the flag was so large it blew away just a few hours later, and was replaced by a smaller one.[41] When visiting Paris, Hitler chose to stay on the ground. When the Allies were nearing Paris in August 1944, Hitler ordered General Dietrich von Choltitz, the military governor of Paris, to demolish the tower along with the rest of the city. Von Choltitz disobeyed the order.[42] On 25 June, before the Germans had been driven out of Paris, the German flag was replaced with a Tricolour by two men from the French Naval Museum, who narrowly beat three men led by Lucien Sarniguet, who had lowered the Tricolour on 13 June 1940 when Paris fell to the Germans.[39]\\r\\nA fire started in the television transmitter on 3 January 1956, damaging the top of the tower. Repairs took a year, and in 1957, the present radio aerial was added to the top.[43] In 1964, the Eiffel Tower was officially declared to be a historical monument by the Minister of Cultural Affairs, Andr Malraux.[44] A year later, an additional lift system was installed in the north pillar.[45]\\r\\nAccording to interviews, in 1967, Montreal Mayor Jean Drapeau negotiated a secret agreement with Charles de Gaulle for the tower to be dismantled and temporarily relocated to Montreal to serve as a landmark and tourist attraction during Expo 67. The plan was allegedly vetoed by the company operating the tower out of fear that the French government could refuse permission for the tower to be restored in its original location.[46]\\r\\nIn 1982, the original lifts between the second and third levels were replaced after 97 years in service. These had been closed to the public between November and March because the water in the hydraulic drive tended to freeze. The new cars operate in pairs, with one counterbalancing the other, and perform the journey in one stage, reducing the journey time from eight minutes to less than two minutes. At the same time, two new emergency staircases were installed, replacing the original spiral staircases. In 1983, the south pillar was fitted with an electrically driven Otis lift to serve the Jules Verne restaurant.[citation needed] The Fives-Lille lifts in the east and west legs, fitted in 1899, were extensively refurbished in 1986. The cars were replaced, and a computer system was installed to completely automate the lifts. The motive power was moved from the water hydraulic system to a new electrically driven oil-filled hydraulic system, and the original water hydraulics were retained solely as a counterbalance system.[45] A service lift was added to the south pillar for moving small loads and maintenance personnel three years later.\\r\\nRobert Moriarty flew a Beechcraft Bonanza under the tower on 31 March 1984.[47] In 1987, A.J. Hackett made one of his first bungee jumps from the top of the Eiffel Tower, using a special cord he had helped develop. Hackett was arrested by the police.[48] On 27 October 1991, Thierry Devaux, along with mountain guide Herv Calvayrac, performed a series of acrobatic figures while bungee jumping from the second floor of the tower.[49] Facing the Champ de Mars, Devaux used an electric winch between figures to go back up to the second floor. When firemen arrived, he stopped after the sixth jump.[citation needed]\\r\\nFor its \\"Countdown to the Year 2000\\" celebration on 31 December 1999, flashing lights and high-powered searchlights were installed on the tower. Fireworks were set off all over it. An exhibition above a cafeteria on the first floor commemorates this event. The searchlights on top of the tower made it a beacon in Paris's night sky, and 20,000 flashing bulbs gave the tower a sparkly appearance for five minutes every hour on the hour.[50]\\r\\nThe lights sparkled blue for several nights to herald the new millennium On 31 December 2000. The sparkly lighting continued for 18 months until July 2001. The sparkling lights were turned on again on 21 June 2003, and the display was planned to last for 10 years before they needed replacing.[51]\\r\\nThe tower received its 200,000,000th guest on 28 November 2002.[52] The tower has operated at its maximum capacity of about 7?million visitors since 2003.[53] In 2004, the Eiffel Tower began hosting a seasonal ice rink on the first level.[54] A glass floor was installed on the first level during the 2014 refurbishment.[55]\\r\\nThe puddled iron (wrought iron) of the Eiffel Tower weighs 7,300 tons,[56] and the addition of lifts, shops and antennae have brought the total weight to approximately 10,100?tons.[57] As a demonstration of the economy of design, if the 7,300?tons of metal in the structure were melted down, it would fill the square base, 125 metres (410?ft) on each side, to a depth of only 6.25?cm (2.46?in) assuming the density of the metal to be 7.8?tons per cubic metre.[58] Additionally, a cubic box surrounding the tower (324?m x 125?m x 125?m) would contain 6,200?tons of air, weighing almost as much as the iron itself. Depending on the ambient temperature, the top of the tower may shift away from the sun by up to 18?cm (7?in) due to thermal expansion of the metal on the side facing the sun.[59]\\r\\nWhen it was built, many were shocked by the tower's daring form. Eiffel was accused of trying to create something artistic with no regard to the principles of engineering. However, Eiffel and his team ÿ experienced bridge builders ÿ understood the importance of wind forces, and knew that if they were going to build the tallest structure in the world, they had to be sure it could withstand them. In an interview with the newspaper Le Temps published on 14 February 1887, Eiffel said:\\r\\nIs it not true that the very conditions which give strength also conform to the hidden rules of harmony?  Now to what phenomenon did I have to give primary concern in designing the Tower? It was wind resistance. Well then! I hold that the curvature of the monument's four outer edges, which is as mathematical calculation dictated it should be  will give a great impression of strength and beauty, for it will reveal to the eyes of the observer the boldness of the design as a whole.[60]\\r\\nHe used graphical methods to determine the strength of the tower and empirical evidence to account for the effects of wind, rather than a mathematical formula. Close examination of the tower reveals a basically exponential shape.[61] All parts of the tower were over-designed to ensure maximum resistance to wind forces. The top half was even assumed to have no gaps in the latticework.[62] In the years since it was completed, engineers have put forward various mathematical hypotheses in an attempt to explain the success of the design. The most recent, devised in 2004 after letters sent by Eiffel to the French Society of Civil Engineers in 1885 were translated into English, is described as a non-linear integral equation based on counteracting the wind pressure on any point of the tower with the tension between the construction elements at that point.[61]\\r\\nThe Eiffel Tower sways by up to 9?centimetres (3.5?in) in the wind.[63]\\r\\nWhen originally built, the first level contained three restaurantsone French, one Russian and one Flemishand an \\"Anglo-American Bar\\". After the exposition closed, the Flemish restaurant was converted to a 250-seat theatre. A promenade 2.6-metre (8?ft 6?in) wide ran around the outside of the first level. At the top, there were laboratories for various experiments, and a small apartment reserved for Gustave Eiffel to entertain guests, which is now open to the public, complete with period decorations and lifelike mannequins of Eiffel and some of his notable guests.[64]\\r\\nIn May 2016, an apartment was created on the first level to accommodate four competition winners during the UEFA Euro 2016 football tournament in Paris in June. The apartment has a kitchen, two bedrooms, a lounge, and views of Paris landmarks including the Seine, the Sacre Coeur, and the Arc de Triomphe.[65]\\r\\nThe arrangement of the lifts has been changed several times during the tower's history. Given the elasticity of the cables and the time taken to align the cars with the landings, each lift, in normal service, takes an average of 8 minutes and 50 seconds to do the round trip, spending an average of 1 minute and 15 seconds at each level. The average journey time between levels is 1 minute. The original hydraulic mechanism is on public display in a small museum at the base of the east and west legs. Because the mechanism requires frequent lubrication and maintenance, public access is often restricted. The rope mechanism of the north tower can be seen as visitors exit the lift.[citation needed]\\r\\nGustave Eiffel engraved on the tower the names of 72 French scientists, engineers and mathematicians in recognition of their contributions to the building of the tower. Eiffel chose this \\"invocation of science\\" because of his concern over the artists' protest. At the beginning of the 20th century, the engravings were painted over, but they were restored in 1986ÿ87 by the Socit Nouvelle d'exploitation de la Tour Eiffel, a company operating the tower.[66]\\r\\nThe tower is painted in three shades: lighter at the top, getting progressively darker towards the bottom to complement the Parisian sky.[67] It was originally reddish brown; this changed in 1968 to a bronze colour known as \\"Eiffel Tower Brown\\".[68]\\r\\nThe only non-structural elements are the four decorative grill-work arches, added in Sauvestre's sketches, which served to make the tower look more substantial and to make a more impressive entrance to the exposition.[69]\\r\\nA pop-culture movie clich is that the view from a Parisian window always includes the tower.[70] In reality, since zoning restrictions limit the height of most buildings in Paris to seven storeys, only a small number of tall buildings have a clear view of the tower.[citation needed]\\r\\nMaintenance of the tower includes applying 60?tons of paint every seven years to prevent it from rusting. The tower has been completely repainted at least 19 times since it was built. Lead paint was still being used as recently as 2001 when the practice was stopped out of concern for the environment.[51]\\r\\nThe nearest Paris Mtro station is Bir-Hakeim and the nearest RER station is Champ de Mars-Tour Eiffel.[71] The tower itself is located at the intersection of the quai Branly and the Pont d'Ina.\\r\\nMore than 250?million people have visited the tower since it was completed in 1889.[3] In 2015, there were 6.91?million visitors.[72] The tower is one the most-visited paid monument in the world.[73] An average of 25,000 people ascend the tower every day which can result in long queues.[74]\\r\\nThe tower has two restaurants: Le 58 Tour Eiffel on the first level, and Le Jules Verne, a gourmet restaurant with its own lift on the second level. This restaurant has one star in the Michelin Red Guide. It is run by the multi-Michelin star chef Alain Ducasse[75] and owes its name to the famous science-fiction writer Jules Verne. Additionally, there is a champagne bar at the top of the Eiffel Tower.\\r\\nAs one of the most iconic landmarks in the world, the Eiffel Tower has been the inspiration for the creation of many replicas and similar towers. An early example is Blackpool Tower in England. The mayor of Blackpool, Sir John Bickerstaffe, was so impressed on seeing the Eiffel Tower at the 1889 exposition that he commissioned a similar tower to be built in his town. It opened in 1894 and is 158.1?metres (518?ft) tall.[76] Tokyo Tower in Japan, built as a communications tower in 1958, was also inspired by the Eiffel Tower.[77]\\r\\nThere are various scale models of the tower in the United States, including a half-scale version at the Paris Las Vegas, Nevada, one in Paris, Texas built in 1993, and two 1:3 scale models at Kings Island, Ohio, and Kings Dominion, Virginia, amusement parks opened in 1972 and 1975 respectively. Two 1:3 scale models can be found in China, one in Durango, Mexico that was donated by the local French community, and several across Europe.[78]\\r\\nIn 2011, the TV show Pricing the Priceless on the National Geographic Channel speculated that a full-size replica of the tower would cost approximately US$480?million to build.[79]\\r\\nThe tower has been used for making radio transmissions since the beginning of the 20th century. Until the 1950s, sets of aerial wires ran from the cupola to anchors on the Avenue de Suffren and Champ de Mars. These were connected to longwave transmitters in small bunkers. In 1909, a permanent underground radio centre was built near the south pillar, which still exists today. On 20 November 1913, the Paris Observatory, using the Eiffel Tower as an aerial, exchanged wireless signals with the United States Naval Observatory, which used an aerial in Arlington, Virginia. The object of the transmissions was to measure the difference in longitude between Paris and Washington, D.C.[80] Today, radio and digital television signals are transmitted from the Eiffel Tower.\\r\\nA television antenna was first installed on the tower in 1957, increasing its height by 18.7?m (61.4?ft). Work carried out in 2000 added a further 5.3?m (17.4?ft), giving the current height of 324?m (1,063?ft).[51] Analogue television signals from the Eiffel Tower ceased on 8 March 2011.\\r\\nThe tower and its image have long been in the public domain.[81] In June 1990 a French court ruled that a special lighting display on the tower in 1989 to mark the tower's 100th anniversary was an \\"original visual creation\\" protected by copyright. The Court of Cassation, France's judicial court of last resort, upheld the ruling in March 1992.[82] The Socit d'Exploitation de la Tour Eiffel (SETE) now considers any illumination of the tower to be a separate work of art that falls under copyright.[83] As a result, the SNTE alleges that it is illegal to publish contemporary photographs of the lit tower at night without permission in France and some other countries for commercial use.[84][85]\\r\\nThe imposition of copyright has been controversial. The Director of Documentation for what was then called the Socit Nouvelle d'exploitation de la Tour Eiffel (SNTE), Stphane Dieu, commented in 2005: \\"It is really just a way to manage commercial use of the image, so that it isn't used in ways [of which] we don't approve\\".[86] SNTE made over ?1?million from copyright fees in 2002.[87] However, it could also be used to restrict the publication of tourist photographs of the tower at night, as well as hindering non-profit and semi-commercial publication of images of the illuminated tower.[81]\\r\\nFrench doctrine and jurisprudence allows pictures incorporating a copyrighted work as long as their presence is incidental or accessory to the subject being represented,[88] a reasoning akin to the de minimis rule. Therefore, SETE may be unable to claim copyright on photographs of Paris which happen to include the lit tower.\\r\\nThe Eiffel Tower was the world's tallest structure when completed in 1889, a distinction it retained until 1929 when the Chrysler Building in New York City was topped out.[89] The tower has lost its standing both as the world's tallest structure and the world's tallest lattice tower but retains its status as the tallest freestanding (non-guyed) structure in France.","input":"How many steps to the first level of the eiffel tower?"},{"output":"the fourth episode of the fourth season","context":"\\"The Break Up\\" is the fourth episode of the fourth season of the American musical television series Glee, and the seventieth episode overall. Written by Ryan Murphy and directed by Alfonso Gomez-Rejon, it aired on Fox in the United States on October 4, 2012, and features the end of several long-established romantic relationships on the show: the couples Finn and Rachel, Kurt and Blaine, and Santana and Brittany all break up.\\r\\n\\r\\n\\r\\nIn New York City, Rachel Berry (Lea Michele) reunites with her former fianc, Finn Hudson (Cory Monteith), who has been discharged from the Army, and gives him a tour through the New York Academy of Dramatic Arts (NYADA), causing Finn to feel out of place. Meanwhile, in Lima, Blaine Anderson (Darren Criss), feeling neglected by his boyfriend, Kurt Hummel (Chris Colfer), who is busy with his work at Vogue.com, cheats on him. Finn and Blaine sing Duncan Sheik's \\"Barely Breathing\\" and Blaine, feeling guilty, decides to surprise Kurt by visiting him in New York City.\\r\\nFinn, Rachel, Kurt and Blaine attend a local bar where NYADA students meet, and where Finn runs into Brody Weston (Dean Geyer). Suspicious of his and Rachel's relationship, Finn encourages them to sing Demi Lovato's \\"Give Your Heart a Break\\" together. They are followed by Blaine, who performs a heartfelt acoustic version of Katy Perry's \\"Teenage Dream.\\" Outside, Finn and Kurt confront Rachel and Blaine, and Rachel admits to kissing Brody, while Blaine admits to cheating on Kurt, leading to them singing No Doubt's \\"Don't Speak\\" as they return to Rachel and Kurt's apartment.\\r\\nThe following day, Finn leaves without telling Rachel and returns to Lima, where he visits glee club director Will Schuester (Matthew Morrison) and breaks down in his arms. Finn is introduced to the new members of New Directions and suggests that they perform Grease for the school musical, which impresses Will. Will later tells Emma Pillsbury (Jayma Mays), that he has been accepted to the blue ribbon government panel to improve arts education nationwide, but that it requires him to move to Washington, D.C. for six months. Emma is reluctant to leave Lima for such a long time to accompany Will, and they argue, but do not break up.\\r\\nSantana Lopez (Naya Rivera) visits her girlfriend, Brittany Pierce (Heather Morris), and learns that she joined a club created by cheerleader Kitty Wilde (Becca Tobin) to prepare for the rapture. Kitty's boyfriend, Jake Puckerman (Jacob Artist), invites Marley Rose (Melissa Benoist) to one of the meetings, but becomes disappointed when Kitty uses it to play a harmful prank on one of the members. Jake eventually decides to break up with Kitty after she mistreats Marley, but also ignores Marley's romantic advances.\\r\\nSantana serenades Brittany with Taylor Swift's \\"Mine\\" and confides with Brittany that their relationship isn't working due to the long distance and her new priorities. She and Brittany break up, which leaves Brittany devastated. Blaine continuously attempts to contact Kurt, but Kurt won't communicate with him, and he becomes uncertain of where they're standing.\\r\\nRachel, having flown all the way to Lima, confronts Finn at the McKinley auditorium, where she calls him immature and a coward for hiding from her for months. She says she loves him, but states that she can't keep their current relationship up, and she breaks up with him despite Finn's claims that he was giving her freedom. She gives him a last kiss, and leaves. After she leaves, Finn performs Coldplay's \\"The Scientist\\" alone, and imagines that Rachel, Kurt, Blaine, Santana, Brittany, Will and Emma are there performing with him.\\r\\nIn a July 2012 interview with E! News, Colfer elaborated in regard to the progression of the Kurt-Blaine relationship in the show's fourth season. Colfer said, \\"I would like to do something besides say 'I love you,' and I think Darren [Criss] and I agree on that. We're ready for the next step. They've been together for a while. Let's throw some spice and drama into that.\\" Colfer quipped that he did not know what was in store for the couple, \\"I hear mixed things. I hear they're still together but then maybe they're breaking up.\\"[1] In a September 2012 interview with the same publication, on whether the couple would breakup or not in the show's fourth season, Criss stated, \\"I don't know. We still have episodes to shoot.\\" Criss ultimately echoed Colfer's sentiment, \\"We're like an old married couple now. Let's shake it up!\\"[2] Prior to the episode's debut, series co-creator Ryan Murphy dubbed it \\"the best episode we have ever done\\".[3]\\r\\nScenes from the episode were filmed on location in New York City the weekend of August 11 and 12, 2012, including the walk through the park for the song \\"Don't Speak\\".[4][5]\\r\\nRecurring characters in this episode include McKinley guidance counselor Emma Pillsbury (Mays), glee club members Joe Hart (Samuel Larsen), Wade \\"Unique\\" Adams (Alex Newell), Marley Rose (Benoist) and Jake Puckerman (Artist), cheerleader Kitty (Tobin), NYADA junior Brody Weston (Geyer)[6] and Vogue.com employee Chase Madison (Dan Domenech).\\r\\nSix songs are being released as singles, including Duncan Sheik's \\"Barely Breathing\\" performed by Criss and Monteith,[7] No Doubt's \\"Don't Speak\\" performed by Colfer, Criss, Monteith and Michele,[4][8] Coldplay's \\"The Scientist\\" performed by Monteith, Michele, Colfer, Criss, Rivera, Morris, Morrison and Mays,[9] Demi Lovato's \\"Give Your Heart a Break\\" performed by Michele and Geyer,[10] Taylor Swift's \\"Mine\\" performed by Rivera,[11][12] and an acoustic version of Katy Perry's \\"Teenage Dream\\" performed by Criss.[13]","input":"What episode do kurt and blaine break up?"},{"output":"between 44,000 and 52,000","context":"Self storage (a shorthand for \\"self-service storage\\", and also known as \\"mini storage\\") is an industry in which storage space (such as rooms, lockers, containers, and/or outdoor space), also known as \\"storage units\\" is rented to tenants, usually on a short-term basis (often month-to-month). Self-storage tenants include businesses and individuals.\\r\\nThe self-storage industry is primarily a United States-based industry. As of 2018, it's estimated that between 44,000 and 52,000 storage facilities are currently in the United States.[1]\\r\\nIndustry experts often refer to \\"4Ds of life\\" (death, divorce, downsizing and dislocation; the latter can refer to either the renter relocating to another area and needing space to store items until they can be moved to the new location, or a subsequent marriage resulting in the couple having duplicate items) when discussing why storage space is rented.[2]\\r\\n\\r\\n\\r\\nSelf-storage facilities rent space on a short-term basis (often month-to-month, though options for longer-term leases are available) to individuals (usually storing household goods; nearly all jurisdictions prohibit the space from being used as a residence) or to businesses (usually storing excess inventory or archived records).[3] Some facilities offer boxes, locks, and packaging supplies for sale to assist tenants in packing and safekeeping their goods, and may also offer truck rentals (or may allow free use of a truck for a new tenant).\\r\\nMost storage facilities offer insurance for purchase; also, the lessor may be covered by his/her own insurance policy (if such policy has coverage for items stored off the premises of the insured) or may purchase insurance to cover the items (which the facility may offer as a service through a third-party carrier, and in some cases may require the lessor to purchase as a condition of rental).\\r\\nThe rented spaces are secured by the tenant's own lock and key. Unlike in a warehouse, self-storage facility employees do not have casual access to the contents of the space (and, thus, the facility is generally not liable for theft). A self-storage facility does not take possession or control of the contents of the space unless a lien is imposed for non-payment of rent, or if the unit is not locked the facility may lock the unit until the tenant provides his/her own lock.\\r\\nAlthough there is historical evidence of publicly available storage in ancient China, modern self-storage facilities (in which the tenant has exclusive access to the storage space) did not begin to appear until the late 1960s. The first self-storage facility chains opened in Texas.[4]\\r\\nModern storage facilities grew slowly through the 90s, at which time demand outpaced supply and caused a rush of new self-storage developments. From 2000 to 2005, over 3,000 new facilities were built every year in America.[5]\\r\\nAt year-end 2017, a total of between 44,000 and 52,000 self-storage facilities have been developed in the United States on industrial and commercial land parcels. There is more than 2.3 billion square feet of available self-storage in space in U.S., or a land area equivalent to three times Manhattan Island under roof. The six largest publicly traded storage operators (four REITs, and U-Haul own or operate approximately 18% of self-storage facilities.[1] The industry is worth $38 billion in 2018.[6] More recently, in many metropolitan cities where competition among storage companies is fierce, better parcels of land near residential and commercial areas are being converted into self-storage once approved by zoning panels. Companies are becoming more adept at manufacturing these modular storage units, allowing operators to get up and running quickly. To support the need, businesses like PODS are expected to enter the modular construction effort as well.\\r\\nMailstorage or on-demand storage is where customers' items are kept together in a warehouse rather than providing each customer with a storage unit.\\r\\nSelf-storage businesses lease a variety of unit sizes to residential and business customer/tenants. Popular unit sizes (expressed in feet, with width shown first and depth shown second) include:\\r\\nThe storage units are typically window-less, walled with corrugated metal, and lockable by the renter. Each unit is usually accessed by opening a roll-up metal door, which is usually about the same size as a one-car garage door (smaller units may be accessed by a hinged metal door). A controlled access facility may employ security guards, security cameras, individual unit door alarms and some means of electronic gate access such as a keypad or proximity card. A few facilities even use biometric thumbprint or hand scanners to ensure that access is granted only to those that rent. Self-storage facility operators frequently provide 24-hour access, climate controlled storage, outdoor storage for RVs and boats, and lights or power outlets inside the storage unit as amenities to set themselves apart from competitors. Some storage facilities have open roofs i.e. a wire mesh roof which are not that secure, compared to ones that have full covered tin roofs that provide added security and privacy.\\r\\nIn rural and suburban areas most facilities contain multiple single-story buildings with mostly drive-up units which have natural ventilation but are not climate-controlled. These buildings are referred to as \\"traditional\\" storage facilities. Climate-controlled interior units are becoming more popular in suburban areas. In urban areas many facilities have multi-story buildings using elevators or freight lifts to move the goods to the upper floors. These facilities are often climate-controlled since they are comprised mostly, if not totally, of interior units. Warehouses or grocery stores are sometimes converted into self-storage facilities. Loading docks are sometimes provided on the ground floor. Also, complimentary rolling carts or moving dollies are sometimes provided to help the customers carry items to their units. Urban self-storage facilities might contain only a few floors in a much larger building; there are successful self-storage businesses co-located with manufacturing plants, office tenants and even public schools.\\r\\nOne in ten U.S. households now rent a self-storage unit.[8] The growing demand for self-storage in the U.S. is created by people moving (some 40 million people move each year according to U.S. Census data), and by various lifestyle transitions, such as marriage, divorce, retirement, a death in the family, etc. Recent surveys of self-storage companies indicate a positive trend in market demand and occupancy rate.[9]\\r\\nOver 54,000 self-storage facilities currently exist in the U.S.[10] ranging from companies with a nationwide presence to companies with regional footprints or even stand-alone independent \\"mom and pop\\" facilities.\\r\\nDemand for storage space remains stable as of Q4 2015. The supply for self-storage is also relatively stable. Often, the process to build a new storage building is onerous and can take years. Additionally, this specific asset class often gets push back from communities, due to its nature.[2]\\r\\nThe self-storage sector is highly fragmented, which is in contrast to other asset classes in the industry. 80% of self-storage facilities are owned by individuals or small investors.[citation needed]\\r\\nThere is a belief amongst investors that the self-storage industry is recession-proof. This belief is supported by the 5.1% total return the sector delivered to investors in 2008.[11]\\r\\nSelf-storage or variations on the business model are now found in many parts of the world. In 2014, FEDESSA, the Federation of European Self Storage Associations, published a report about the state of the self-storage industry in Europe. In this report, it was estimated that 975 facilities exist in the United Kingdom, 430 in France, 264 in The Netherlands, 210 in Spain, 131 in Germany, and 112 in Sweden. No other country in Europe has more than 100 facilities. Overall, the report estimates 2,391 total facilities in Europe, or about 75 million square feet of rentable storage space. This compares with over 52,000 facilities in the US (236 million square feet), and 1,100 facilities in Australia (39 million square feet).[12]\\r\\nIn the United States, self-storage facilities may hold storage auctions or lien sales to vacate non-paying tenants according to their enforcement rights that are outlined within the lien law of each jurisdiction.\\r\\nFacilities owners are generally required to first notify the tenant of the outstanding debt, commonly by certified or registered mail to the address on file with the facility. If the debt remains unpaid, the facility must then give public notice of the sale or auction, generally in a newspaper of general circulation in most states, though some states may allow public notice of sales to be done in the internet. The tenant has the right to pay their outstanding bill at any time until the moment the auction begins and thus reclaim rights to the unit and his/her items; those units would be removed from the auction (which, in some cases, may result in the entire auction being cancelled).[13]\\r\\nThe auctions/sales are open to the general public, with most bidders buying for the purpose of reselling for profit. Once the auction for a unit starts, the door to the unit is opened and potential bidders are allowed to view the contents only by looking in from the doorway; they may not step inside, touch, or move any of the contents prior to the auction. Generally, the spaces and their contents are sold \\"as is, where is\\" with no warranties or guarantees implied or provided, and the terms of sale are cash-only upon conclusion of the auction. The purchaser of a unit takes possession of its entire contents and is responsible for removing them within a set period of time. In some cases, the facility may allow the purchaser to rent the unit and/or charge a refundable deposit for cleaning of the unit once it has been emptied.\\r\\nCertain jurisdictions require facility owners to immediately confiscate controlled items such as firearms if they are in plain sight within a delinquent unit. Also, a jurisdiction may require the purchaser to turn over some items (such as family photos and tax/business records) to the facility owner.\\r\\nIn the fall of 2010, two new television programs featuring storage auctions, Storage Wars and Auction Hunters, were released. The popularity led to additional shows such as Storage Hunters, Storage Wars: Texas, and Storage Wars: New York which helped increase the visibility and interest of storage auctions. Storage Wars: Canada also debuted on the Outdoor Living Network in 2013.\\r\\nSelf Storage Associations have been created around the world in order to support the growth of the industry. These associations offer support in the way of information, education, networking, referrals, events, standardized agreements, data collection, marketing, advocacy, and publications for current and potential facility owners, managers, suppliers, and investors.","input":"How many storage facilities are there in the united states?"},{"output":"krone","context":"\\r\\n\\r\\n?Norway\\r\\n\\r\\nThe krone [?kru?n?] (sign: kr; code: NOK), plural kroner, is the currency of Norway and its dependent territories. It is subdivided into 100 ?re, which exist only electronically since 2012. The name translates into English as crown.\\r\\n\\r\\nThe krone was the thirteenth most traded currency in the world by value in April 2010, down three positions from 2007.[1]\\r\\n\\r\\nThe krone was introduced in 1875, replacing the Norwegian speciedaler/spesidaler at a rate of 4 kroner = 1 speciedaler. In doing so, Norway joined the Scandinavian Monetary Union, which had been established in 1873. The Union persisted until 1914.[citation needed] After its dissolution, Denmark, Norway, and Sweden all decided to keep the names of their respective and since then separate currencies.\\r\\n\\r\\nWithin the Scandinavian Monetary Union, the krone was on a gold standard of 2,480 kroner = 1 kilogram of pure gold (1 krone = 403.226 milligrams gold). This gold standard was restored between 1916 and 1920 and again in 1928.[citation needed] It was suspended permanently in 1931,[citation needed] when a peg to the British pound of 19.9 kroner = 1 pound was established.[citation needed] (The previous rate had been 18.16 kroner = 1 pound).[citation needed] In 1939, Norway pegged the krone temporarily to the U.S. dollar at a rate of 4.4 kroner = 1 dollar.[citation needed] Nonetheless, Norway would continue to hold the Kingdom's gold reserves.\\r\\n\\r\\nDuring the German occupation (1940ÿ1945) in the Second World War, the krone was initially pegged to the Reichsmark at a rate of 1 krone = 0.6 Reichsmark, later reduced to 0.57.[citation needed] After the war, a rate of 20 kroner = 1 pound (4.963 kroner = 1 U.S. dollar) was established.[citation needed] The rate to the pound was maintained in 1949, when the pound devalued relative to the U.S. dollar, leading to a rate of 7.142 kroner = 1 U.S. dollar.[citation needed] In December 1992, the Central Bank of Norway abandoned the fixed exchange rate in favor of a floating exchange rate (managed float) due to the heavy speculation against the Norwegian currency in the early 1990s, which lost[clarification needed] the central bank around two billion kroner in defensive purchases of the NOK through usage of foreign currency reserves for a relatively short period of time.\\r\\n\\r\\nIn 1875, coins were introduced (some dated 1874) in denominations of 10 and 50 ?re and 1 and 10 kroner. These coins also bore the denomination in the previous currency, as 3, 15, and 30 skillings and 2? specidaler. Between 1875 and 1878, the new coinage was introduced in full, in denominations of 1, 2, 5, 10, 25, and 50 ?re and 1, 2, and 10 kroner.  The 1, 2, and 5 ?re were struck in bronze; the 10, 25, and 50 ?re and 1 and 2 kroner, in silver; and the 10 and 20 kroner, in gold.\\r\\n\\r\\nThe last gold coins were issued in 1910; silver was replaced by cupro-nickel from 1920.  Between 1917 and 1921, iron temporarily replaced bronze.  1917 also saw the last issuance of 2 kroner coins. During the German occupation of Norway in the Second World War, zinc was used in place of cupro-nickel in 10, 25, and 50 ?re coins, and production of the 1 krone piece was suspended.\\r\\n\\r\\nThe obverse of a 1940 Norwegian krone.\\r\\n\\r\\nThe reverse of the 1940 krone.\\r\\n\\r\\nIn 1963, 5 kroner coins were introduced.  Production of 1 and 2 ?re coins ceased in 1972.  The following year, the size of the 5 ?re coin was reduced; production of the denomination ceased in 1982, along with minting of the 25 ?re.  Ten-kroner coins were introduced in 1983.  In 1992, the last 10 ?re coins were minted.\\r\\n\\r\\nBetween 1994 and 1998, a new coinage was introduced, consisting of 50 ?re, 1, 5, 10, and 20 kroner. These are the only coins which are currently legal tender, with the exception of the 50-?re coin which was withdrawn on 1 May 2012. It was withdrawn because it was no longer circulating as an ordinary coin used for payment.[2] However, banks in Norway will still exchange 50 ?re coins for higher values until 2022.\\r\\n\\r\\nThe 10- and 20-kroner coins carry the effigy of the current monarch. Previously the 1- and 5-kroner coins also carried the royal effigy, but now these denominations are decorated only with stylistic royal or national symbols. The royal motto of the monarch (King Harald's motto is Alt for Norge, meaning \\"Everything for Norway\\") is also inscribed on the 10-kroner coin.\\r\\n\\r\\nCoins and banknotes of the Norwegian krone are distributed by the Central Bank of Norway.\\r\\n\\r\\nUp to 25 coins of any single denomination is considered tvungent betalingsmiddela legally recognized method of payment, in which the intended recipient can not refuse payment, according to Norwegian law.[3]\\r\\n\\r\\nThe characteristics of the 10 Syrian pound (10 SYP) coin have been found to so closely resemble the 20 Norwegian kroner (20 NOK) coin that it can fool vending machines, coins-to-cash machines, arcade machines, and any other coin-operated, automated service machine in the country. Whilst they are hardly similar to the naked eye, machines are unable to tell the coins apart, owing to their almost identical weight and size.\\r\\n\\r\\nAs of mid February 2017, 10 Syrian pounds were worth 0.39 Norwegian kroner, making the 20 NOK coin 51.5 times more valuable than the 10 SYP coin. While not easy to find in Norway, the Syrian coins are still used in automated machines there with such frequency that Posten Norge, the Norwegian postal service, decided to close many of their coins-to-cash machines on 18 February 2006, with plans to develop a system able to differentiate between the two coins. In the summer of 2005, a Norwegian man was sentenced to 30 days, suspended, for having used Syrian coins in arcade machines in the municipality of B?rum.[4]\\r\\n\\r\\nIn 1877, Norges Bank introduced notes for 5, 10, 50, 100, 500 and 1000 kroner. In 1917, 1-krone notes were issued, and 2-kroner notes were issued between 1918 and 1922. Because of metal shortages, 1- and 2-kroner notes were again issued between 1940 and 1950. In 1963, 5-kroner notes were replaced by coins, with the same happening to the 10-kroner notes in 1984. 200-kroner notes were introduced in 1994.\\r\\n\\r\\nSources:[5][6][7][8][9]\\r\\n\\r\\nThe value of Norwegian krone compared to other currencies varies considerably from one year to another, mainly based on changes in oil prices and interest rates. In 2002 the Norwegian krone grew to record high levels against the United States dollar and the Euro. On 2 January 2002, 100 NOK were worth 11.14 USD (1?USD = 8.98?NOK). In July 2002, the krone hit a high at 100 NOK = 13.7 USD (1?USD = 7.36?NOK). In addition to the high level of interest, which increased further on 4 July 2002, to 7?per?cent, the price of oil was high. At the time Norway was the world's third largest oil exporter.\\r\\n\\r\\nIn 2005, oil prices reached record levels of more than 60?dollars per barrel. Although interest rates had decreased to around 2?per?cent, the Norwegian krone grew even stronger.\\r\\n\\r\\nHowever, in late 2007 and early 2008, the USD suffered a steady depreciation against all other major currencies. The Norwegian krone was gaining value at the same time; as a result, the Norwegian krone became stronger than ever compared to the USD, making the USD worth about 5 NOK in April 2008. By October 2008, the USD had recovered and was worth approximately 7 NOK. Following 2009, the NOK has once again seen strong growth, making the USD worth about 5.8 NOK as of the beginning of 2010. Since then, the USD has gone up further and as of mid 2016 is worth about 8.5 NOK.\\r\\n\\r\\nThe Norwegian krone is used in Norway including Svalbard. It is also informally accepted in many shops in Sweden and Finland that are close to the Norwegian border, and also in some shops in the Danish ferry ports of Hirtshals and Frederikshavn. Norwegians spent 14.1 billion NOK on border shopping in 2015 compared to 10.5 billion NOK spent in 2010. Border shopping is a fairly common practice amongst Norwegians, though it is seldom done on impulse. Money is spent mainly on food articles, alcohol and tobacco, in that order, usually in bulk or large quantities. This is due to considerably higher taxes and fees on tobacco and alcohol purchased domestically in Norway.[12][13]","input":"What kind of currency is used in norway?"},{"output":"Jeroboam I","context":"Jeroboam I /?d??r??bo?.?m/ (Hebrew: ?????????? Yr??m;  Greek: ??, translit.?Ierovom) was the first king of the northern Kingdom of Israel after the revolt of the ten northern Israelite tribes against Rehoboam that put an end to the United Monarchy.\\r\\n\\r\\nJeroboam reigned for 22 years. William F. Albright has dated his reign from 922 to 901 BC, while Edwin R. Thiele offers the dates 931 to 910 BC.[1]\\r\\n\\r\\nThe name Jeroboam ?????????? is commonly held to have been derived from riyb ????? and ?am ????, signifying \\"the people contend\\" or \\"he pleads the people's cause\\". It is alternatively translated to mean \\"his people are many\\" or \\"he increases the people\\" (from ???? rbb, meaning \\"to increase\\"), or even \\"he that opposes the people\\". In the Septuagint he is called Hieroboam (??).[2]\\r\\n\\r\\nJeroboam was the son of Nebat (Douay-Rheims: Nabat), a member of the Tribe of Ephraim of Zereda. His mother,[3] named Zeruah (???? \\"leprous\\") was a widow. (1 Kings 11:26) He had at least two sons, Abijah [4] and Nadab, who succeeded him on the throne.\\r\\n\\r\\nWhile still a young man, King Solomon made him superintendent over his tribesmen in the building of the fortress Millo in Jerusalem and of other public works, and he naturally became conversant with the widespread discontent caused by the extravagances which marked the reign of Solomon.[5]\\r\\n\\r\\nInfluenced by the words of the prophet Ahijah (1 Kings 11:29ÿ39), he began to form conspiracies with the view of becoming king of the ten northern tribes; but these were discovered, and he fled to Egypt, where he remained under the protection of pharaoh Shishak until the death of Solomon. After this event he returned and participated in a delegation sent to ask the new king Rehoboam to reduce taxes.[6] After Rehoboam rejected their petition, ten of the tribes withdrew their allegiance to the house of David and proclaimed Jeroboam their king, forming the northern kingdom of Israel (Samaria). Initially, only the tribes of Judah, Simeon and Benjamin remained to form the new kingdom of Judah, loyal to Rehoboam.[7]\\r\\n\\r\\nJeroboam rebuilt and fortified Shechem as the capital of the northern kingdom, and fearing that pilgrimages to the temple in Jerusalem prescribed by the Law might be an occasion for his people to go back to their old allegiance, he built two state temples [8] with golden calves, one in Bethel and the other in Dan.[5] Although criticised for his cultic activities in 1 Kings 12:25ÿ33, calf worship was not new in Israelite ritual, but a reintroduction of earlier ritual. Bethel and Dan were already established cultic sites.\\r\\n\\r\\nAccording to 1 Kings 13:1ÿ6, while Jeroboam was engaged in offering incense at Bethel, a \\"man of God\\" warned him that \\"a son named Josiah will be born to the house of David\\", who would destroy the altar (referring to King Josiah of Judah who would rule approximately three hundred years later). Attempting to arrest the prophet for his bold words of defiance, Jeroboam's hand was \\"dried up\\", and the altar before which he stood was rent asunder. At the entreaty of the man of God, his hand was restored to him again, but the miracle made no abiding impression on him.[9] Jeroboam offered hospitality to the man of God but this was declined, not out of contempt but in obedience to the command of God.[10] The prophecy is fulfilled in 2 Kings 23:15ÿ16.\\r\\n\\r\\nThis \\"man of God\\" who warned Jeroboam has been equated with a seer named Iddo.[11]\\r\\n\\r\\nIn 1 Kings 14, Jeroboam's son Abijah gets sick, and he sends his wife to the prophet Ahijah. Ahijah's message, however, is that Abijah will die, which he does.\\r\\n\\r\\nJeroboam was in \\"constant war with the house of Judah\\".[12] While the southern kingdom made no serious effort militarily to regain power over the north, there was a long-lasting boundary dispute, fighting over which lasted during the reigns of several kings on both sides before being finally settled.\\r\\n\\r\\nIn the eighteenth year of Jeroboam's reign, Abijah (also known as Abijam), Rehoboam's son, became king of Judah.[13] During his short reign of three years, Abijah went to considerable lengths to bring the Kingdom of Israel back under his control. He waged a major battle against Jeroboam in the mountains of Ephraim. According to the Book of Chronicles Abijah had a force of 400,000 and Jeroboam 800,000.[14] The Biblical sources mention that Abijah addressed the armies of Israel, urging them to submit and to let the Kingdom of Israel be whole again,[15] but his plea fell on deaf ears. Abijah then rallied his own troops with a phrase which has since become famous: \\"God is with us as our leader\\". The biblical account states that his elite warriors fended off a pincer movement to rout Jeroboam's troops, killing 500,000 of them.[16]\\r\\n\\r\\nJeroboam was crippled by this severe defeat to Abijah and posed little threat to the Kingdom of Judah for the rest of his reign.[17] He also lost the towns of Bethel, Jeshanah, and Ephron, with their surrounding villages.[18] Bethel was an important centre for Jeroboam's Golden Calf cult (which used non-Levites as priests),[19] located on Israel's southern border, which had been allocated to the Tribe of Benjamin by Joshua, as was Ephron, which is believed to be the Ophrah that was allocated to the Tribe of Benjamin by Joshua.[20]\\r\\n\\r\\nJeroboam died soon after Abijam.\\r\\n\\r\\nThe account of Jeroboam's life, like that of all his successors, ends with the formula \\"And the rest of the acts of Jeroboam, how he warred, and how he reigned, behold, they are written in the book of the chronicles of the kings of Israel\\" (1 Kings 14, 19).\\r\\n\\r\\n\\"The Chronicles of the Kings of Israel\\", likely compiled by or derived from these kings' own scribes, is likely the source for the basic facts of Jeroboam's life and reign, though the compiler(s) of the extant Book of Kings clearly made selective use of it and added hostile commentaries.  His family was eventually wiped out.\\r\\n\\r\\nThe prophecies of doom concerning the fall of both the House of Jeroboam and the northern kingdom as a whole (\\"For the Lord shall smite Israel..., and he shall root up Israel out of this good land, which he gave to their fathers, and shall scatter them beyond the river\\") might have been composed retroactively, after the events described had already come to pass (this position is a secular or non-literal approach to scripture). Alternately, the prophecy could have been a logical deduction. Judah had just been conquered and turned into a vassal of Egypt, while Israel stood between the Egyptian and Mesopotamian empires.\\r\\n\\r\\nIt is likely that the story of the golden calf in the wilderness (cf. I Kings 12:28 with Ex. 32:4) was composed as a polemic against Jeroboams cultic restoration by claiming that its origins were inconsistent with worship of YHWH.[21]","input":"Who was the first king of the northern kingdom?"},{"output":"Between 1540 and 1685","context":"British passports are passports issued by the United Kingdom to those holding any form of British nationality.  There are different types of British nationality, and different types of British passports as a result.  A British passport enables the bearer to travel worldwide and serves as proof of citizenship.  It also facilitates access to consular assistance from British embassies around the world, or if also a citizen of the European Union, any embassy of another European Union member state. Passports are issued using royal prerogative, which is exercised by Her Majesty's Government.\\r\\n\\r\\nBritish citizen passports have been issued by Her Majesty's Passport Office in the UK since 2006. British citizens can use their passport as evidence of right of abode in the United Kingdom and EU citizenship. All passports issued in the UK since 2006 have been biometric.\\r\\n\\r\\nIn 1988, the UK Government changed the colour of the passport to burgundy red, in line with most EU passports - the only exception being Croatia which is blue. The UK Government announced plans in December 2017 to return to the dark blue cover passport after Brexit.[3]\\r\\n\\r\\nOwing to the many different categories in British nationality law, there are different types of passports for each class of British nationality. All categories of British passports are issued by Her Majesty's Government under royal prerogative.[4] Since all British passports are issued in the name of the Crown, the reigning monarch does not require a passport.[5] The following table shows the number of valid British passports on the last day of 2017 and shows the different categories eligible to hold a British passport:[6]\\r\\n\\r\\nHMPO\\r\\n\\r\\nBritish citizen, British overseas citizen, British subject, British protected person and British national (overseas) passports are issued by HM Passport Office in the UK. British nationals of these categories applying for passports outside the UK can apply for their passport online from HMPO. British passports were previously issued by the Foreign and Commonwealth Office in British embassies around the world. However, in 2009, this was stopped and British citizen passports can now only be issued by the Passport Office in the UK. The FCO says: \\"In their 2006 report on consular services, the National Audit Office recommended limiting passport production to fewer locations to increase security and reduce expenditure.\\"[8]\\r\\n\\r\\nBritish citizens and British Overseas Territory citizens of Gibraltar can apply for their passport in Gibraltar, where it will be issued by the Gibraltar Civil Status and Registration Office.\\r\\n\\r\\nBritish citizens, British Overseas Territory citizens of Gibraltar and British subjects with right of abode are considered to be UK nationals for the purpose of EU law. They are therefore considered to be EU citizens, allowing them to move freely within the European Economic Area and Switzerland.\\r\\n\\r\\nOther types of British nationals are not considered to be EU citizens, but may nevertheless enjoy visa-free travel to the European Union as tourists.\\r\\n\\r\\nBritish passports in Jersey, Guernsey and the Isle of Man are issued in the name of the Lieutenant-Governor of the respective Crown Dependencies on behalf of the States of Jersey, States of Guernsey and the Government of the Isle of Man respectively. Meanwhile, in British Overseas Territories, British Overseas Territories Citizen passports are issued in the name of the respective territory's governor.\\r\\n\\r\\nDiplomatic passports are issued in the UK by HMPO. They are issued to British diplomats and high-ranking government officials to facilitate travel abroad.\\r\\n\\r\\nOfficial passports are issued to those travelling abroad on official state business.\\r\\n\\r\\nQueen's Messenger passports are issued to diplomatic couriers who transport documents on behalf of HM Government.\\r\\n\\r\\nEmergency passports are issued by British embassies across the world. Emergency passports may be issued to any person holding British nationality. Commonwealth citizens are also eligible to receive British emergency passports in countries where their country of nationality is unrepresented. Under a reciprocal agreement, British emergency passports may also be issued to EU citizens in countries where their own country does not have a diplomatic mission or is otherwise unable to assist.\\r\\n\\r\\nSafe conduct documents, usually notes signed by the monarch, were issued to foreigners as well as English subjects in medieval times. They were first mentioned in an Act of Parliament, the Safe Conducts Act in 1414. Between 1540 and 1685, the Privy Council issued passports, although they were still signed by the monarch until the reign of Charles II when the Secretary of State could sign them instead. The Secretary of State signed all passports in place of the monarch from 1794 onwards, at which time formal records started to be kept.[9]\\r\\n\\r\\nPassports were written in Latin or English until 1772, when French was used instead. From about 1855 English was used, with some sections translated into French for many years.\\r\\n\\r\\nIn 1855 passports became a standardised document issued solely to British nationals. They were a simple single-sheet paper document, and by 1914 included a photograph of the holder.\\r\\n\\r\\nThe British Nationality and Status of Aliens Act 1914 was passed on the outbreak of World War I. A new format was introduced in 1915: a single sheet folded into eight with a cardboard cover. It included a description of the holder as well as a photograph, and had to be renewed after two years.\\r\\n\\r\\nSome duplicate passports and passport records are available at the British Library; for example IOR: L/P&J/11 contain a few surviving passports of travelling ayahs for the 1930s.[10] \\r\\nA passport issued on 18 June 1641 and signed by King Charles I still exists.[11]\\r\\n\\r\\nVarious changes to the design were made over the years:[11]\\r\\n\\r\\nA 32-page passport with a dark cover, commonly known as the old blue style,[18] came into use in 1920 with the formation of the Passport Service following international agreement [19] on a standard format for passports, and remained in use until replaced by the European Union-style machine-readable passport in late 1988. As with many documents worldwide and all booklet-format documents, details were handwritten into the passport and (as of 1955) included: number, holder's name, \\"accompanied by his wife\\" and her maiden name, \\"and\\" (number) \\"children\\", national status. For both bearer and wife: profession, place and date of birth, country of residence, height, eye and hair colour, special peculiarities, signature and photograph. Names, birth dates, and sexes of children, list of countries for which valid, issue place and date, expiry date, a page for renewals and, at the back, details of the amount of foreign exchange for travel expenses (a limited amount of sterling, typically S50 but increasing with inflation, could be taken out of the country).[20] The bearer's sex was not explicitly stated, although the name was written in with title (\\"Mr John Smith\\"). Descriptive text was printed in both English and French (a practice which still[update] continues), e.g., \\"Accompanied by his wife (Maiden name)/Accompagn de sa femme (Ne)\\". Changed details were struck out and rewritten, with a rubber-stamped note confirming the change.\\r\\n\\r\\nIf details and photograph of a man's wife and details of children were entered (this was not compulsory), the passport could be used by the bearer, wife, and children under 16, if together; separate passports were required for the wife or children to travel independently.[21] The passport was valid for five years, renewable for another five, after which it had to be replaced.[22]\\r\\n\\r\\nThe passport had a printed list of countries for which it was valid, which was added to manually as validity increased. A passport of 1955 was valid for the British Commonwealth, USA, and all countries in Europe \\"including the USSR, Turkey, Algeria, Azores, Canary Islands, Iceland, and Madeira\\";[23] during its period of validity restrictions eased and it was endorsed \\"and for all other foreign countries\\".[24]\\r\\n\\r\\nA new simplified type, the British Visitor's Passport, was introduced in 1961. It was a single-page cardboard document valid for one year obtainable for many years from Employment Exchanges, as agents of the Passport Office, and then from a Post Office. It was accepted for travel by most west European countries (excluding surface travel to West Berlin), but was dropped in 1995 since it did not identify the holder's nationality or meet new security standards.\\r\\n\\r\\nOn 15 August 1988, the Glasgow passport office became the first to issue burgundy-coloured machine-readable passports. They followed a common format agreed amongst member states of the European Community, and had the words 'European Community' on the cover, changed to 'European Union' in 1997. The passport has 32 pages; a 48-page version is available with more space for stamps and visas. There are two lines of machine-readable text printed in a format agreed amongst members of the International Civil Aviation Organisation, and a section in which relevant terms (\\"surname\\", \\"date of issue\\", etc.) are translated into the official EU languages. Passports issued overseas did not all have a Machine Readable Zone but these was introduced gradually as appropriate equipment was made available overseas.\\r\\n\\r\\nIn 1998[25] the first digital image passport was introduced with photographs being replaced with images printed directly on the bio-data page which was moved from the cover to an inside page to reduce the ease of fraud. These documents were all issued with machine readable zones and had a hologram over the photograph, which was the first time that British passports had been protected by an optically variable safeguard. These documents were issued until 2006 when the biometric passport was introduced. The bio-data page is printed with a finely detailed background including a drawing of a red grouse (a native British bird), and the entire page is protected from modification by a laminate which incorporates a holographic image of the kingfisher; visa pages are numbered and printed with detailed backgrounds including drawings of other birds: a merlin, curlew, avocet, and red kite. An RFID chip and antenna are located on the obverse of the data page and hold the same visual information as is printed, including a digital copy of the photograph with biometric information for use with facial recognition systems. The Welsh and Scottish Gaelic languages were included in all British passports for the first time in 2005,[26] and appear on the titles page replacing the official languages of the EU, although the EU languages still appear faintly as part of the background design. Welsh and Scottish Gaelic precede the official EU languages in the translations section.\\r\\n\\r\\nThere was speculation regarding re-introduction of the old-style passport following completion of the United Kingdom's exit from the European Union[27] but the government denied any immediate plans.[28] Such a change was supported by some due to its symbolic value, including Brexit Secretary David Davis,[29] while others thought the undue weight put on such a trivial change raises the question of whether the government is able to prioritise its order of business ahead of Brexit.[30][non-primary source needed] On 2 April 2017, Michael Fabricant MP said that security printing and banknote manufacturer De La Rue, who hold the current S400 million contract with HM Passport Office, had stated that the crest would \\"contrast better on navy blue than it currently does on the maroon passports\\"[31] as part of their pre-tender discussions with the government.[32][33] The Sun newspaper launched a campaign in August 2016,[34] and a question was put to Home Secretary Amber Rudd in the House of Commons.[35][not in citation given][28]\\r\\n\\r\\nIn December 2017, the Immigration Minister Brandon Lewis announced that the blue passport would \\"return\\" after the United Kingdom's exit from the European Union.[3] The announcement led to controversy regarding the actual colour of the pre-1988 passport, with Scottish Conservatives leader Ruth Davidson calling the campaign \\"baffling\\" as she \\"always thought [the old passports] were black\\", and Channel 4 political journalist Michael Crick saying that \\"any witness would describe [the passport as black] in court\\".[36] The previous blue passport spotted the words British Passport above the crest, with the words United Kingdom of Great Britain and Northern Ireland below it. The Home Office mock-up does not contain the word British at all.\\r\\n\\r\\nBritish passports are, until 2019, burgundy, with the coat of arms of the United Kingdom emblazoned in the centre of the front cover.\\r\\n\\r\\nWith the sole exception of emergency passports which are printed and issued by the British diplomatic missions, all other types British passports have been printed and issued by Her Majesty's Passport Office (HMPO) in the United Kingdom since May 2015, although some British Overseas Territories, such as Bermuda, did not start forwarding the applications to HMPO until June 2016 when its own passport book stock was depleted.[37]\\r\\n\\r\\nThere are three types of covers among British passports. Passports with the generic cover are issued to British citizens not residing in the Crown dependencies and Gibraltar, and persons holding all other types of British nationality. Passports issued to residents of the Crown dependencies and Gibraltar has a slightly variated cover. Passports issued to British Overseas Territories citizens residing in certain territories has a completely different cover, albeit with the same interior design.[38]\\r\\n\\r\\nThe words \\"UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND\\" are inscribed above the coat of arms, whilst the word \\"PASSPORT\\" is inscribed below. The biometric passport symbol  appears at the bottom of the front cover under the word \\"PASSPORT\\".\\r\\n\\r\\nThe words \\"EUROPEAN UNION\\" are printed at the top of British passports issued to British nationals who are considered \\"United Kingdom nationals for European Community purposes\\"[39] (i.e. British Citizens, British Subjects with the right of abode[40] in the UK and British Overseas Territories Citizens connected with Gibraltar).[41] It is not included at the top of other British passports (i.e. passports issued to British Nationals (Overseas), British Overseas Citizens, British Protected Persons, non-Gibraltarian British Overseas Territories Citizens and British Subjects without the right of abode in the UK)\\r\\n\\r\\nGeneric British passports contain on their inside cover the following words in English only:\\r\\n\\r\\nHer Britannic Majesty's Secretary of State Requests and requires in the Name of Her Majesty all those whom it may concern to allow the bearer to pass freely without let or hindrance, and to afford the bearer such assistance and protection as may be necessary.\\r\\n\\r\\nIn older passports, more specific reference was made to \\"Her Britannic Majesty's Principal Secretary of State for Foreign Affairs\\", originally including the name of the incumbent.\\r\\n\\r\\nBritish passports issued by HM Passport Office include the following data on the information page:\\r\\n\\r\\nThe items are identified by text in English and French (e.g., \\"Date of birth/Date de naissance\\"); there is a section in which all this text is translated into all official EU languages, as well as Welsh and Scottish Gaelic.[44]\\r\\n\\r\\nAccording to the UK government, the current policy of using titles on passports requires that the applicant provides evidence that the Lord Lyon has recognised a feudal barony, or the title is included in Burke's Peerage. If accepted (and if the applicant wishes to include the title), the correct form is for the applicant to include the territorial designation as part of their surname (Surname of territorial designation e.g. Smith of Inverglen). The Observation would then show the holder's full name, followed by their feudal title e.g. The holder is John Smith, Baron of Inverglen.\\r\\n\\r\\nBesides the ordinary passports described above, special passports are issued to government officials from which diplomatic status may (diplomatic passport) or may not (official passport) be conferred by the text on the cover. A special passport is available for the Queen's Messenger. The latter passport contains the text QUEENS MESSENGER ÿ COURRIER DIPLOMATIQUE below the coat of arms, and the text \\"BRITISH PASSPORT\\" above it.[45]\\r\\n\\r\\nBritish passports issued directly by the Crown dependencies as well as the British Overseas Territory of Gibraltar are slightly different from those issued by HMPO to residents of the United Kingdom and to British nationals abroad. The words EUROPEAN UNION still appear across the front of their passports, signifying their citizenship of the EU.\\r\\n\\r\\nPassports for British citizens connected to the Crown dependencies of Jersey, Guernsey and the Isle of Man do not carry the words \\"United Kingdom of Great Britain and Northern Ireland\\" on the front cover. In their place, these passports feature the words BRITISH ISLANDS  BAILIWICK OF JERSEY or BAILIWICK OF GUERNSEY or ISLE OF MAN, as appropriate.\\r\\n\\r\\nGibraltar passport covers are virtually identical to British passports issued by Her Majesty's Passport Office, except that they feature the word GIBRALTAR directly above the coat of arms and below the words \\"United Kingdom of Great Britain and Northern Ireland.\\"\\r\\n\\r\\nIn passports issued by the Crown dependencies, the passport note request is slightly different from those issued by the UK, coming from the Lieutenant Governor of the respective island. This difference results from the Crown dependencies owing allegiance to Queen Elizabeth II rather than the Government of the United Kingdom.\\r\\n\\r\\nIn Gibraltar passports, the \\"request\\" in the passport note is made by the Governor of Gibraltar instead of \\"Her Britannic Majesty's Secretary of State\\".\\r\\n\\r\\nThe issuing of a British Passport by the authorities in the Crown Dependencies cannot be inferred from the machine readable zone as the issuing country code and citizenship code (both GBR) is identical to passports issued by the United Kingdom for British Citizens.\\r\\n\\r\\nTraditionally, British passports issued to BOTCs residing in certain British Overseas Territories (Anguilla, Bermuda, British Virgin Islands, Cayman Islands, Montserrat, St. Helena, and Turks & Caicos Islands) bear a different design, even when the HMPO assumed the responsibility of the manufacturing process of these passports in 2015.\\r\\n\\r\\nPassports issued to BOTCs of those territories do not bear the words \\"UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND\\", but instead have the words \\"BRITISH PASSPORT\\" above the royal coat of arms of Queen Elizabeth II and the name of the British Overseas Territory below it (e.g. \\"TURKS AND CAICOS ISLANDS\\"). The only exception is the design of Bermudian passports, which bears the wordings \\"GOVERNMENT OF BERMUDA\\" under the royal coat of arms.[46]\\r\\n\\r\\nThe nationality reads \\"British Overseas Territories citizen\\" regardless of the residence of the bearer. Previously, in the machine-readable zone, the three-letter ISO 3166-1 alpha-3 code of the territory is given in the field of the code of issuing state, while GBD (British Overseas Territories citizens, formerly British Dependent Territories citizens) is shown in the nationality field. Either of these features enabled automatic distinction between BOTCs related to different territories. Ever since the HMPO assumed the responsibility of the issuance of BOTC passports in 2015, however, the code of issuing state is changed to GBD for all territories, thus making it impossible to identify the holder's domicile without the aid of other features, such as the passport cover.[47]\\r\\n\\r\\nSimilar to passports issued to Crown dependencies and Gibraltar residents, the passport note request is made by the Governor of the British Overseas Territory on behalf of \\"Her Majesty's Secretary of State\\".[48]\\r\\n\\r\\nPeople who have valid reasons may be allowed to hold more than one passport booklet. This applies usually to people who travel frequently on business, and may need to have a passport booklet to travel on while the other is awaiting a visa for another country. Some Muslim-majority countries including Syria, Lebanon, Libya, Kuwait, Iran, Iraq, Pakistan, Saudi Arabia, Sudan, and Yemen do not issue visas to visitors if their passports bear a stamp or visa issued by Israel, as a result of the IsraeliÿPalestinian conflict. In that case, a person can apply for a second passport[49] to avoid travel issues. Reasons and supporting documentation (such as a letter from an employer) must be provided.[50]\\r\\n\\r\\nIn addition, a person who has dual British citizenship and British Overseas Territories citizenship are allowed to hold two British passports under different statuses at the same time. Persons who acquired their BOTC status with a connection to Gibraltar or Falkland Islands, however, are not eligible due to differences in regulations, and their BOTC passports will be cancelled when their British citizen passports are issued even when they possess both citizenships.[51]\\r\\n\\r\\nCertain British passports are issued with printed endorsements on the Official Observations page, usually in upper case (capital letters). They form part of the passport when it is issued, as distinct from immigration stamps subsequently entered in the visa pages. Some examples are:[52][51]\\r\\n\\r\\n\\"The Holder is also known as Cliff Richard\\"\\r\\n\\r\\nSurname: \\"Sutherland\\"\\r\\nGiven names: \\"Kiefer W F D G R\\"\\r\\n\\r\\n\\"The Holder is Kiefer William Frederick Dempsey George Rufus Sutherland\\"\\r\\n\\r\\nThere had been plans, under the Identity Cards Act 2006, to link passports to the Identity Cards scheme. However, in the Conservative ÿ Liberal Democrat Coalition Agreement that followed the 2010 General Election, the new government announced that they planned to scrap the ID card scheme, the National Identity Register, and the next generation of biometric passports, as part of their measures 'to reverse the substantial erosion of civil liberties under the Labour Government and roll back state intrusion.'[55][56]\\r\\n\\r\\nThe Identity Cards Act 2006 would have required any person applying for a passport to have their details entered into a centralised computer database, the National Identity Register, part of the National Identity Scheme associated with identity cards and passports. Once registered, they would also have been obliged to update any change to their address and personal details. The identity card was expected to cost up to S60 (with S30 going to the Government, and the remainder charged as processing fees by the companies that would be collecting the fingerprints and photographs).[57] In May 2005 the Government said that the cost for a combined identity card and passport would be S93 plus processing fees.[58]\\r\\n\\r\\nThe next generation of biometric passports, which would have contained chips holding facial images and fingerprints,[59] were to have been issued from 2012. Everyone applying for a passport from 2012 would have had their 10 fingerprints digitally scanned and stored on a database, although only two would have been recorded in the passport.[60]\\r\\n\\r\\nThe Queen, Elizabeth II, does not have a passport because passports are issued in her name and on her authority, thus making it superfluous for her to hold one.[61] All other members of the royal family, however, including the Queen's husband Prince Philip, Duke of Edinburgh and their son, heir apparent Charles, Prince of Wales, do have passports.[61]\\r\\n\\r\\nVisa requirements for British citizens are administrative entry restrictions by the authorities of other states placed on citizens of the United Kingdom. As of 2 July 2018, British citizens had visa-free or visa on arrival access to 186 countries and territories, ranking the British passport 4th in the world in terms of travel freedom (tied with Austrian, Dutch, Luxembourgish, Norwegian, Portuguese and United States passports) according to the Henley visa restrictions index.[62] Additionally, the World Tourism Organization also published a report on 15 January 2016 ranking the British passport 1st in the world (tied with Denmark, Finland, Germany, Italy, Luxembourg and Singapore) in terms of travel freedom, with a mobility index of 160 (out of 215 with no visa weighted by 1, visa on arrival weighted by 0.7, eVisa by 0.5, and traditional visa weighted by 0).[63]\\r\\n\\r\\nVisa requirements for other categories of British nationals, namely British Nationals (Overseas), British Overseas Citizens, British Overseas Territories Citizens, British Protected Persons, and British Subjects, are different.\\r\\n\\r\\nAccording to the Foreign travel advice provided by the British Government (unless otherwise noted) these are the numbers of British visitors to various countries per annum in 2015 (unless otherwise noted):[64]\\r\\n\\r\\nAnguilla passport\\r\\n\\r\\nBermuda passport\\r\\n\\r\\nBritish National (Overseas) passport\\r\\n\\r\\nGuernsey passport\\r\\n\\r\\nJersey passport\\r\\n\\r\\nManx passport\\r\\n\\r\\nSaint Helena passport\\r\\n\\r\\nQueen's Messenger passport\\r\\n\\r\\nTurks and Caicos Islands passport\\r\\n\\r\\nVirgin Islands passport\\r\\n\\r\\n1920s United Kingdom of Great Britain and Ireland passport\\r\\n\\r\\n1939 Mandatory Palestine passport\\r\\n\\r\\n1949 Maltese passport\\r\\n\\r\\n1949 New Zealand passport\\r\\n\\r\\n1951 Singapore passport\\r\\n\\r\\n1957 Federation of Malaya passport\\r\\n\\r\\n1958 British Hong Kong passport\\r\\n\\r\\n1959 Grenadian passport\\r\\n\\r\\nPre-1990 Hong Kong British Dependent Territories Citizen (BDTC) passports\\r\\n\\r\\n1997 Hong Kong BDTC passport\\r\\n\\r\\nBritish Indian passport\\r\\n\\r\\nCypriot passport\\r\\n\\r\\nMauritian passport\\r\\n\\r\\nTrinidad and Tobago passport\\r\\n\\r\\n1942 British consular emergency travel document issued to a refugee in Turkey during WWII\\r\\n\\r\\nCardboard identity card issued under arrangements regarding collective passports by the UK Passport Agency in 2001\\r\\n\\r\\n\\r\\n\\r\\n1 B) The Isle of Man, Jersey and Guernsey are not part of the European Union, but Manxmen and Channel Islanders are citizens of the European Union; the Isle of Man, Jersey and Guernsey, and Manxmen and Channel Islanders themselves (unless they qualify and apply for recognition of a change in status), are however excluded from the benefits of the Four Freedoms of the European Union.\\r\\n\\r\\n1 C) The Government of the United Kingdom also issue passports to British nationals who are not British citizens with the right of abode in the United Kingdom and who are also not otherwise citizens of the European Union.  \\r\\n\\r\\n2 Non-EU country that has open border with Schengen Area.\\r\\n\\r\\n3 Russia is a transcontinental country in Eastern Europe and Northern Asia. The vast majority of its population (80%) lives in European Russia, therefore Russia as a whole is included as a European country here.\\r\\n\\r\\n4 Turkey is a transcontinental country in the Middle East and Southeast Europe. Turkey has a small part of its territory (3%) in Southeast Europe called Turkish Thrace. \\r\\n\\r\\n5 Azerbaijan and Georgia (Abkhazia; South Ossetia) are transcontinental countries. Both have a small part of their territories in the European part of the Caucasus.\\r\\n\\r\\n6 Kazakhstan is a transcontinental country. Kazakhstan has a small part of its territories located west of the Urals in Eastern Europe.  \\r\\n\\r\\n7 Armenia (Artsakh) and Cyprus (Northern Cyprus) are entirely in Southwest Asia but having socio-political connections with Europe.\\r\\n\\r\\n8 Egypt is a transcontinental country in North Africa and Western Asia. Egypt has a small part of its territory in Western Asia called Sinai Peninsula. \\r\\n\\r\\n9  Partially recognized.\\r\\n\\r\\n10  Not recognized by any other state.\\r\\n\\r\\n11 Special administrative regions of China","input":"When was the first passport issued in uk?"},{"output":"Lake Itasca in northern Minnesota","context":"The Mississippi River is the chief river of the second-largest drainage system on the North American continent, second only to the Hudson Bay drainage system.[13][14] The stream is entirely within the United States (although its drainage basin reaches into Canada), its source is Lake Itasca in northern Minnesota and it flows generally south for 2,320 miles (3,730?km)[14] to the Mississippi River Delta in the Gulf of Mexico. With its many tributaries, the Mississippi's watershed drains all or parts of 31 U.S. states and two Canadian provinces between the Rocky and Appalachian Mountains. The Mississippi ranks as the fourth-longest and fifteenth-largest river in the world by discharge. The river either borders or passes through the states of Minnesota, Wisconsin, Iowa, Illinois, Missouri, Kentucky, Tennessee, Arkansas, Mississippi, and Louisiana.[15][16]\\r\\nNative Americans long lived along the Mississippi River and its tributaries. Most were hunter-gatherers, but some, such as the Mound Builders, formed prolific agricultural societies. The arrival of Europeans in the 16th century changed the native way of life as first explorers, then settlers, ventured into the basin in increasing numbers.[17] The river served first as a barrier, forming borders for New Spain, New France, and the early United States, and then as a vital transportation artery and communications link. In the 19th century, during the height of the ideology of manifest destiny, the Mississippi and several western tributaries, most notably the Missouri, formed pathways for the western expansion of the United States.\\r\\nFormed from thick layers of the river's silt deposits, the Mississippi embayment is one of the most fertile agricultural regions of the country, which resulted in the river's storied steamboat era. During the American Civil War, the Mississippi's capture by Union forces marked a turning point towards victory due to the river's importance as a route of trade and travel, not least to the Confederacy. Because of substantial growth of cities and the larger ships and barges that supplanted riverboats, the first decades of the 20th century saw the construction of massive engineering works such as levees, locks and dams, often built in combination.\\r\\nSince modern development of the basin began, the Mississippi has also seen its share of pollution and environmental problems ÿ most notably large volumes of agricultural runoff, which has led to the Gulf of Mexico dead zone off the Delta. In recent years, the river has shown a steady shift towards the Atchafalaya River channel in the Delta; a course change would be an economic disaster for the port city of New Orleans.\\r\\n\\r\\n\\r\\nThe word Mississippi itself comes from Messipi, the French rendering of the Anishinaabe (Ojibwe or Algonquin) name for the river, Misi-ziibi (Great River).\\r\\nIn the 18th century, the river was the primary western boundary of the young United States, and since the country's expansion westward, the Mississippi River has been widely considered a convenient if approximate dividing line between the Eastern, Southern, and Midwestern United States, and the Western United States. This is exemplified by the Gateway Arch in St. Louis and the phrase \\"Trans-Mississippi\\" as used in the name of the Trans-Mississippi Exposition.\\r\\nIt is common to qualify a regionally superlative landmark in relation to it, such as \\"the highest peak east of the Mississippi\\"[18] or \\"the oldest city west of the Mississippi\\".[19] The FCC also uses it as the dividing line for broadcast callsigns, which begin with W to the east and K to the west, mixing together in media markets along the river.\\r\\nThe geographical setting of the Mississippi River includes considerations of the course of the river itself, its watershed, its outflow, its prehistoric and historic course changes, and possibilities of future course changes. The New Madrid Seismic Zone along the river is also noteworthy. These various basic geographical aspects of the river in turn underlie its human history and present uses of the waterway and its adjacent lands.\\r\\nThe Mississippi River can be divided into three sections: the Upper Mississippi, the river from its headwaters to the confluence with the Missouri River; the Middle Mississippi, which is downriver from the Missouri to the Ohio River; and the Lower Mississippi, which flows from the Ohio to the Gulf of Mexico.\\r\\nThe Upper Mississippi runs from its headwaters to its confluence with the Missouri River at St. Louis, Missouri. It is divided into two sections:\\r\\nThe source of the Upper Mississippi branch is traditionally accepted as Lake Itasca, 1,475 feet (450?m) above sea level in Itasca State Park in Clearwater County, Minnesota. The name \\"Itasca\\" was chosen to designate the \\"true head\\" of the Mississippi River as a combination of the last four letters of the Latin word for truth (veritas) and the first two letters of the Latin word for head (caput).[20] However, the lake is in turn fed by a number of smaller streams.\\r\\nFrom its origin at Lake Itasca to St. Louis, Missouri, the waterway's flow is moderated by 43 dams. Fourteen of these dams are located above Minneapolis in the headwaters region and serve multiple purposes, including power generation and recreation. The remaining 29 dams, beginning in downtown Minneapolis, all contain locks and were constructed to improve commercial navigation of the upper river. Taken as a whole, these 43 dams significantly shape the geography and influence the ecology of the upper river. Beginning just below Saint Paul, Minnesota, and continuing throughout the upper and lower river, the Mississippi is further controlled by thousands of wing dikes that moderate the river's flow in order to maintain an open navigation channel and prevent the river from eroding its banks.\\r\\nThe head of navigation on the Mississippi is the Coon Rapids Dam in Coon Rapids, Minnesota. Before it was built in 1913, steamboats could occasionally go upstream as far as Saint Cloud, Minnesota, depending on river conditions.\\r\\nThe uppermost lock and dam on the Upper Mississippi River is the Upper St. Anthony Falls Lock and Dam in Minneapolis. Above the dam, the river's elevation is 799 feet (244?m). Below the dam, the river's elevation is 750 feet (230?m). This 49-foot (15?m) drop is the largest of all the Mississippi River locks and dams. The origin of the dramatic drop is a waterfall preserved adjacent to the lock under an apron of concrete. Saint Anthony Falls is the only true waterfall on the entire Mississippi River. The water elevation continues to drop steeply as it passes through the gorge carved by the waterfall.\\r\\nAfter the completion of the St. Anthony Falls Lock and Dam in 1963, the river's head of navigation moved upstream, to the Coon Rapids Dam. However, the Locks were closed in 2015 to control the spread of invasive Asian carp, making Minneapolis once again the site of the head of navigation of the river.[21]\\r\\nThe Upper Mississippi has a number of natural and artificial lakes, with its widest point being Lake Winnibigoshish, near Grand Rapids, Minnesota, over 11 miles (18?km) across. Lake Onalaska, created by Lock and Dam No. 7, near La Crosse, Wisconsin, is more than 4 miles (6.4?km) wide. Lake Pepin, a natural lake formed behind the delta of the Chippewa River of Wisconsin as it enters the Upper Mississippi, is more than 2 miles (3.2?km) wide.[22]\\r\\nBy the time the Upper Mississippi reaches Saint Paul, Minnesota, below Lock and Dam No. 1, it has dropped more than half its original elevation and is 687 feet (209?m) above sea level. From St. Paul to St. Louis, Missouri, the river elevation falls much more slowly, and is controlled and managed as a series of pools created by 26 locks and dams.[23]\\r\\nThe Upper Mississippi River is joined by the Minnesota River at Fort Snelling in the Twin Cities; the St. Croix River near Prescott, Wisconsin; the Cannon River near Red Wing, Minnesota; the Zumbro River at Wabasha, Minnesota; the Black, La Crosse, and Root rivers in La Crosse, Wisconsin; the Wisconsin River at Prairie du Chien, Wisconsin; the Rock River at the Quad Cities; the Iowa River near Wapello, Iowa; the Skunk River south of Burlington, Iowa; and the Des Moines River at Keokuk, Iowa. Other major tributaries of the Upper Mississippi include the Crow River in Minnesota, the Chippewa River in Wisconsin, the Maquoketa River and the Wapsipinicon River in Iowa, and the Illinois River in Illinois.\\r\\nThe Upper Mississippi is largely a multi-thread stream with many bars and islands. From its confluence with the St. Croix River downstream to Dubuque, Iowa, the river is entrenched, with high bedrock bluffs lying on either side. The height of these bluffs decreases to the south of Dubuque, though they are still significant through Savanna, Illinois. This topography contrasts strongly with the Lower Mississippi, which is a meandering river in a broad, flat area, only rarely flowing alongside a bluff (as at Vicksburg, Mississippi).\\r\\nThe Mississippi River is known as the Middle Mississippi from the Upper Mississippi River's confluence with the Missouri River at St. Louis, Missouri, for 190 miles (310?km) to its confluence with the Ohio River at Cairo, Illinois.[24][25]\\r\\nThe Middle Mississippi is relatively free-flowing. From St. Louis to the Ohio River confluence, the Middle Mississippi falls 220 feet (67?m) over 180 miles (290?km) for an average rate of 1.2 feet per mile (23?cm/km). At its confluence with the Ohio River, the Middle Mississippi is 315 feet (96?m) above sea level. Apart from the Missouri and Meramec rivers of Missouri and the Kaskaskia River of Illinois, no major tributaries enter the Middle Mississippi River.\\r\\nThe Mississippi River is called the Lower Mississippi River from its confluence with the Ohio River to its mouth at the Gulf of Mexico, a distance of about 1,000 miles (1,600?km). At the confluence of the Ohio and the Middle Mississippi, the long-term mean discharge of the Ohio at Cairo, Illinois is 281,500 cubic feet per second (7,970 cubic metres per second),[26] while the long-term mean discharge of the Mississippi at Thebes, Illinois (just upriver from Cairo) is 208,200?cu?ft/s (5,900?m3/s).[27] Thus, by volume, the main branch of the Mississippi River system at Cairo can be considered to be the Ohio River (and the Allegheny River further upstream), rather than the Middle Mississippi.\\r\\nIn addition to the Ohio River, the major tributaries of the Lower Mississippi River are the White River, flowing in at the White River National Wildlife Refuge in east central Arkansas; the Arkansas River, joining the Mississippi at Arkansas Post; the Big Black River in Mississippi; and the Yazoo River, meeting the Mississippi at Vicksburg, Mississippi. The widest point of the Mississippi River is in the Lower Mississippi portion where it exceeds 1 mile (1.6?km) in width in several places.\\r\\nDeliberate water diversion at the Old River Control Structure in Louisiana allows the Atchafalaya River in Louisiana to be a major distributary of the Mississippi River, with 30% of the Mississippi flowing to the Gulf of Mexico by this route, rather than continuing down the Mississippi's current channel past Baton Rouge and New Orleans on a longer route to the Gulf.[28][29][30] Although the Red River is commonly thought to be a tributary, it is actually not, because its water flows separately into the Gulf of Mexico through the Atchafalaya River.\\r\\nThe Mississippi River has the world's fourth-largest drainage basin (\\"watershed\\" or \\"catchment\\"). The basin covers more than 1,245,000 square miles (3,220,000?km2), including all or parts of 31[31] U.S. states and two Canadian provinces. The drainage basin empties into the Gulf of Mexico, part of the Atlantic Ocean. The total catchment of the Mississippi River covers nearly 40% of the landmass of the continental United States. The highest point within the watershed is also the highest point of the Rocky Mountains, Mount Elbert at 14,440 feet (4,400?m).[32]\\r\\nIn the United States, the Mississippi River drains the majority of the area between the crest of the Rocky Mountains and the crest of the Appalachian Mountains, except for various regions drained to Hudson Bay by the Red River of the North; to the Atlantic Ocean by the Great Lakes and the Saint Lawrence River; and to the Gulf of Mexico by the Rio Grande, the Alabama and Tombigbee rivers, the Chattahoochee and Appalachicola rivers, and various smaller coastal waterways along the Gulf.\\r\\nThe Mississippi River empties into the Gulf of Mexico about 100 miles (160?km) downstream from New Orleans. Measurements of the length of the Mississippi from Lake Itasca to the Gulf of Mexico vary somewhat, but the United States Geological Survey's number is 2,320 miles (3,730?km). The retention time from Lake Itasca to the Gulf is typically about 90 days.[33]\\r\\nThe Mississippi River discharges at an annual average rate of between 200 and 700 thousand cubic feet per second (7,000ÿ20,000?m3/s).[34] Although it is the fifth-largest river in the world by volume, this flow is a small fraction of the output of the Amazon, which moves nearly 7 million cubic feet per second (200,000?m3/s) during wet seasons. On average, the Mississippi has only 8% the flow of the Amazon River.[35]\\r\\nFresh river water flowing from the Mississippi into the Gulf of Mexico does not mix into the salt water immediately. The images from NASA's MODIS (to the right) show a large plume of fresh water, which appears as a dark ribbon against the lighter-blue surrounding waters. These images demonstrate that the plume did not mix with the surrounding sea water immediately. Instead, it stayed intact as it flowed through the Gulf of Mexico, into the Straits of Florida, and entered the Gulf Stream. The Mississippi River water rounded the tip of Florida and traveled up the southeast coast to the latitude of Georgia before finally mixing in so thoroughly with the ocean that it could no longer be detected by MODIS.\\r\\nBefore 1900, the Mississippi River transported an estimated 400?million metric tons of sediment per year from the interior of the United States to coastal Louisiana and the Gulf of Mexico. During the last two decades, this number was only 145?million metric tons per year. The reduction in sediment transported down the Mississippi River is the result of engineering modification of the Mississippi, Missouri, and Ohio rivers and their tributaries by dams, meander cutoffs, river-training structures, and bank revetments and soil erosion control programs in the areas drained by them.[36]\\r\\nOver geologic time, the Mississippi River has experienced numerous large and small changes to its main course, as well as additions, deletions, and other changes among its numerous tributaries, and the lower Mississippi River has used different pathways as its main channel to the Gulf of Mexico across the delta region.\\r\\nThrough a natural process known as avulsion or delta switching, the lower Mississippi River has shifted its final course to the mouth of the Gulf of Mexico every thousand years or so. This occurs because the deposits of silt and sediment begin to clog its channel, raising the river's level and causing it to eventually find a steeper, more direct route to the Gulf of Mexico. The abandoned distributaries diminish in volume and form what are known as bayous. This process has, over the past 5,000 years, caused the coastline of south Louisiana to advance toward the Gulf from 15 to 50 miles (24 to 80?km). The currently active delta lobe is called the Birdfoot Delta, after its shape, or the Balize Delta, after La Balize, Louisiana, the first French settlement at the mouth of the Mississippi.\\r\\nThe current form of the Mississippi River basin was largely shaped by the Laurentide Ice Sheet of the most recent Ice Age. The southernmost extent of this enormous glaciation extended well into the present-day United States and Mississippi basin. When the ice sheet began to recede, hundreds of feet of rich sediment were deposited, creating the flat and fertile landscape of the Mississippi Valley. During the melt, giant glacial rivers found drainage paths into the Mississippi watershed, creating such features as the Minnesota River, James River, and Milk River valleys. When the ice sheet completely retreated, many of these \\"temporary\\" rivers found paths to Hudson Bay or the Arctic Ocean, leaving the Mississippi Basin with many features \\"oversized\\" for the existing rivers to have carved in the same time period.\\r\\nIce sheets during the Illinoian Stage about 300,000 to 132,000 years before present, blocked the Mississippi near Rock Island, Illinois, diverting it to its present channel farther to the west, the current western border of Illinois. The Hennepin Canal roughly follows the ancient channel of the Mississippi downstream from Rock Island to Hennepin, Illinois. South of Hennepin, to Alton, Illinois, the current Illinois River follows the ancient channel used by the Mississippi River before the Illinoian Stage.[37][38]\\r\\nTimeline of outflow course changes[39]\\r\\nIn March 1876, the Mississippi suddenly changed course near the settlement of Reverie, Tennessee, leaving a small part of Tipton County, Tennessee, attached to Arkansas and separated from the rest of Tennessee by the new river channel. Since this event was an avulsion, rather than the effect of incremental erosion and deposition, the state line still follows the old channel.[40]\\r\\nThe town of Kaskaskia, Illinois once stood on a peninsula at the confluence of the Mississippi and Kaskaskia (Okaw) Rivers. Founded as a French colonial community, it later became the capital of the Illinois Territory and was the first state capital of Illinois until 1819. Beginning in 1844, successive flooding caused the Mississippi River to slowly encroach east. A major flood in 1881 caused it to overtake the lower 10 miles of the Kaskaskia River, forming a new Mississippi channel and cutting off the town from the rest of the state. Later flooding destroyed most of the remaining town, including the original State House. Today, the remaining 2,300 acre island and community of 14 residents is known as an enclave of Illinois and is accessible only from the Missouri side.[41]\\r\\nThe New Madrid Seismic Zone, along the Mississippi River near New Madrid, Missouri, between Memphis and St. Louis, is related to an aulacogen (failed rift) that formed at the same time as the Gulf of Mexico. This area is still quite active seismically. Four great earthquakes in 1811 and 1812, estimated at approximately 8 on the Richter magnitude scale, had tremendous local effects in the then sparsely settled area, and were felt in many other places in the midwestern and eastern U.S. These earthquakes created Reelfoot Lake in Tennessee from the altered landscape near the river.\\r\\nWhen measured from its traditional source at Lake Itasca, the Mississippi has a length of 2,320 miles (3,730 km). When measured from its longest stream source (most distant source from the sea), Brower's Spring in Montana, the source of the Missouri River, it has a length of 3,710 miles, making it the fourth longest river in the world after the Nile, Amazon, and Yangtze.[42] When measured by the largest stream source (by water volume), the Ohio River, by extension the Allegheny River, would be the source, and the Mississippi would begin in Pennsylvania.[citation needed]\\r\\nThe Mississippi River runs through or along 10 states, from Minnesota to Louisiana, and is used to define portions of these states' borders, with Wisconsin, Illinois, Kentucky, Tennessee, and Mississippi along the east side of the river, and Iowa, Missouri, and Arkansas along its west side. Substantial parts of both Minnesota and Louisiana are on either side of the river, although the Mississippi defines part of the boundary of each of these states.\\r\\nIn all of these cases, the middle of the riverbed at the time the borders were established was used as the line to define the borders between adjacent states.[43][44] In various areas, the river has since shifted, but the state borders have not changed, still following the former bed of the Mississippi River as of their establishment, leaving several small isolated areas of one state across the new river channel, contiguous with the adjacent state. Also, due to a meander in the river, a small part of western Kentucky is contiguous with Tennessee, but isolated from the rest of its state.\\r\\nMany of the communities along the Mississippi River are listed below; most have either historic significance or cultural lore connecting them to the river. They are sequenced from the source of the river to its end.\\r\\nThe road crossing highest on the Upper Mississippi is a simple steel culvert, through which the river (locally named \\"Nicolet Creek\\") flows north from Lake Nicolet under \\"Wilderness Road\\" to the West Arm of Lake Itasca, within Itasca State Park.[45]\\r\\nThe earliest bridge across the Mississippi River was built in 1855. It spanned the river in Minneapolis, Minnesota where the current Hennepin Avenue Bridge is located.[46] No highway or railroad tunnels cross under the Mississippi River.\\r\\nThe first railroad bridge across the Mississippi was built in 1856. It spanned the river between the Rock Island Arsenal in Illinois and Davenport, Iowa. Steamboat captains of the day, fearful of competition from the railroads, considered the new bridge a hazard to navigation. Two weeks after the bridge opened, the steamboat Effie Afton rammed part of the bridge, setting it on fire. Legal proceedings ensued, with Abraham Lincoln defending the railroad. The lawsuit went to the Supreme Court of the United States, which ruled in favor of the railroad.[47]\\r\\nBelow is a general overview of selected Mississippi bridges which have notable engineering or landmark significance, with their cities or locations. They are sequenced from the Upper Mississippi's source to the Lower Mississippi's mouth.\\r\\nA clear channel is needed for the barges and other vessels that make the main stem Mississippi one of the great commercial waterways of the world. The task of maintaining a navigation channel is the responsibility of the United States Army Corps of Engineers, which was established in 1802.[48] Earlier projects began as early as 1829 to remove snags, close off secondary channels and excavate rocks and sandbars.\\r\\nSteamboats entered trade in the 1820s, so the period 1830ÿ1850 became the golden age of steamboats. As there were few roads or rails in the lands of the Louisiana Purchase, river traffic was an ideal solution. Cotton, timber and food came down the river, as did Appalachian coal. The port of New Orleans boomed as it was the trans-shipment point to deep sea ocean vessels. As a result, the image of the twin stacked, wedding cake Mississippi steamer entered into American mythology. Steamers worked the entire route from the trickles of Montana, to the Ohio River; down the Missouri and Tennessee, to the main channel of the Mississippi. Only with the arrival of the railroads in the 1880s did steamboat traffic diminish. Steamboats remained a feature until the 1920s. Most have been superseded by pusher tugs. A few survive as iconsthe Delta Queen and the River Queen for instance.\\r\\nA series of 29 locks and dams on the upper Mississippi, most of which were built in the 1930s, is designed primarily to maintain a 9-foot-deep (2.7?m) channel for commercial barge traffic.[49][50] The lakes formed are also used for recreational boating and fishing. The dams make the river deeper and wider but do not stop it. No flood control is intended. During periods of high flow, the gates, some of which are submersible, are completely opened and the dams simply cease to function. Below St. Louis, the Mississippi is relatively free-flowing, although it is constrained by numerous levees and directed by numerous wing dams.\\r\\nOn the lower Mississippi, from Baton Rouge to the mouth of the Mississippi, the navigation depth is 45 feet (14?m), allowing container ships and cruise ships to dock at the Port of New Orleans and bulk cargo ships shorter than 150-foot (46?m) air draft that fit under the Huey P. Long Bridge to traverse the Mississippi to Baton Rouge.[51] There is a feasibility study to dredge this portion of the river to 50 feet (15?m) to allow New Panamax ship depths.[52]\\r\\nIn 1829, there were surveys of the two major obstacles on the upper Mississippi, the Des Moines Rapids and the Rock Island Rapids, where the river was shallow and the riverbed was rock. The Des Moines Rapids were about 11 miles (18?km) long and just above the mouth of the Des Moines River at Keokuk, Iowa. The Rock Island Rapids were between Rock Island and Moline, Illinois. Both rapids were considered virtually impassable.\\r\\nIn 1848, the Illinois and Michigan Canal was built to connect the Mississippi River to Lake Michigan via the Illinois River near Peru, Illinois. The canal allowed shipping between these important waterways. In 1900, the canal was replaced by the Chicago Sanitary and Ship Canal. The second canal, in addition to shipping, also allowed Chicago to address specific health issues (typhoid fever, cholera and other waterborne diseases) by sending its waste down the Illinois and Mississippi river systems rather than polluting its water source of Lake Michigan.\\r\\nThe Corps of Engineers recommended the excavation of a 5-foot-deep (1.5?m) channel at the Des Moines Rapids, but work did not begin until after Lieutenant Robert E. Lee endorsed the project in 1837. The Corps later also began excavating the Rock Island Rapids. By 1866, it had become evident that excavation was impractical, and it was decided to build a canal around the Des Moines Rapids. The canal opened in 1877, but the Rock Island Rapids remained an obstacle. In 1878, Congress authorized the Corps to establish a 4.5-foot-deep (1.4?m) channel to be obtained by building wing dams which direct the river to a narrow channel causing it to cut a deeper channel, by closing secondary channels and by dredging. The channel project was complete when the Moline Lock, which bypassed the Rock Island Rapids, opened in 1907.\\r\\nTo improve navigation between St. Paul, Minnesota, and Prairie du Chien, Wisconsin, the Corps constructed several dams on lakes in the headwaters area, including Lake Winnibigoshish and Lake Pokegama. The dams, which were built beginning in the 1880s, stored spring run-off which was released during low water to help maintain channel depth.\\r\\nIn 1907, Congress authorized a 6-foot-deep (1.8?m) channel project on the Mississippi, which was not complete when it was abandoned in the late 1920s in favor of the 9-foot-deep (2.7?m) channel project.\\r\\nIn 1913, construction was complete on Lock and Dam No. 19 at Keokuk, Iowa, the first dam below St. Anthony Falls. Built by a private power company (Union Electric Company of St. Louis) to generate electricity (originally for streetcars in St. Louis), the Keokuk dam was one of the largest hydro-electric plants in the world at the time. The dam also eliminated the Des Moines Rapids. Lock and Dam No. 1 was completed in Minneapolis, Minnesota in 1917. Lock and Dam No. 2, near Hastings, Minnesota, was completed in 1930.\\r\\nBefore the Great Mississippi Flood of 1927, the Corps's primary strategy was to close off as many side channels as possible to increase the flow in the main river. It was thought that the river's velocity would scour off bottom sediments, deepening the river and decreasing the possibility of flooding. The 1927 flood proved this to be so wrong that communities threatened by the flood began to create their own levee breaks to relieve the force of the rising river.\\r\\nThe Rivers and Harbors Act of 1930 authorized the 9-foot (2.7?m) channel project, which called for a navigation channel 9 feet (2.7?m) feet deep and 400 feet (120?m) wide to accommodate multiple-barge tows.[53][54] This was achieved by a series of locks and dams, and by dredging. Twenty-three new locks and dams were built on the upper Mississippi in the 1930s in addition to the three already in existence.\\r\\nUntil the 1950s, there was no dam below Lock and Dam 26 at Alton, Illinois. Chain of Rocks Lock (Lock and Dam No. 27), which consists of a low-water dam and an 8.4-mile-long (13.5?km) canal, was added in 1953, just below the confluence with the Missouri River, primarily to bypass a series of rock ledges at St. Louis. It also serves to protect the St. Louis city water intakes during times of low water.\\r\\nU.S. government scientists determined in the 1950s that the Mississippi River was starting to switch to the Atchafalaya River channel because of its much steeper path to the Gulf of Mexico. Eventually the Atchafalaya River would capture the Mississippi River and become its main channel to the Gulf of Mexico, leaving New Orleans on a side channel. As a result, the U.S. Congress authorized a project called the Old River Control Structure, which has prevented the Mississippi River from leaving its current channel that drains into the Gulf via New Orleans.[56]\\r\\nBecause the large scale of high-energy water flow threatened to damage the structure, an auxiliary flow control station was built adjacent to the standing control station. This $300?million project was completed in 1986 by the Corps of Engineers. Beginning in the 1970s, the Corps applied hydrological transport models to analyze flood flow and water quality of the Mississippi. Dam 26 at Alton, Illinois, which had structural problems, was replaced by the Mel Price Lock and Dam in 1990. The original Lock and Dam 26 was demolished.\\r\\nThe Corps now actively creates and maintains spillways and floodways to divert periodic water surges into backwater channels and lakes, as well as route part of the Mississippi's flow into the Atchafalaya Basin and from there to the Gulf of Mexico, bypassing Baton Rouge and New Orleans. The main structures are the Birds Point-New Madrid Floodway in Missouri; the Old River Control Structure and the Morganza Spillway in Louisiana, which direct excess water down the west and east sides (respectively) of the Atchafalaya River; and the Bonnet Carr Spillway, also in Louisiana, which directs floodwaters to Lake Pontchartrain (see diagram). Some experts blame urban sprawl for increases in both the risk and frequency of flooding on the Mississippi River.[57]\\r\\nSome of the pre-1927 strategy is still in use today, with the Corps actively cutting the necks of horseshoe bends, allowing the water to move faster and reducing flood heights.[58]\\r\\nThe area of the Mississippi River basin was first settled by hunting and gathering Native American peoples and is considered one of the few independent centers of plant domestication in human history.[59] Evidence of early cultivation of sunflower, a goosefoot, a marsh elder and an indigenous squash dates to the 4th millennium BCE. The lifestyle gradually became more settled after around 1000 BCE during what is now called the Woodland period, with increasing evidence of shelter construction, pottery, weaving and other practices. A network of trade routes referred to as the Hopewell interaction sphere was active along the waterways between about 200 and 500 CE, spreading common cultural practices over the entire area between the Gulf of Mexico and the Great Lakes. A period of more isolated communities followed, and agriculture introduced from Mesoamerica based on the Three Sisters (maize, beans and squash) gradually came to dominate. After around 800 CE there arose an advanced agricultural society today referred to as the Mississippian culture, with evidence of highly stratified complex chiefdoms and large population centers. The most prominent of these, now called Cahokia, was occupied between about 600 and 1400 CE[60] and at its peak numbered between 8,000 and 40,000 inhabitants, larger than London, England of that time. At the time of first contact with Europeans, Cahokia and many other Mississippian cities had dispersed, and archaeological finds attest to increased social stress.[61][62][63]\\r\\nModern American Indian nations inhabiting the Mississippi basin include Cheyenne, Sioux, Ojibwe, Potawatomi, Ho-Chunk, Fox, Kickapoo, Tamaroa, Moingwena, Quapaw and Chickasaw.\\r\\nThe word Mississippi itself comes from Messipi, the French rendering of the Anishinaabe (Ojibwe or Algonquin) name for the river, Misi-ziibi (Great River).[64][65] The Ojibwe called Lake Itasca Omashkoozo-zaaga'igan (Elk Lake) and the river flowing out of it Omashkoozo-ziibi (Elk River). After flowing into Lake Bemidji, the Ojibwe called the river Bemijigamaag-ziibi (River from the Traversing Lake). After flowing into Cass Lake, the name of the river changes to Gaa-miskwaawaakokaag-ziibi (Red Cedar River) and then out of Lake Winnibigoshish as Wiinibiigoonzhish-ziibi (Miserable Wretched Dirty Water River), Gichi-ziibi (Big River) after the confluence with the Leech Lake River, then finally as Misi-ziibi (Great River) after the confluence with the Crow Wing River.[66] After the expeditions by Giacomo Beltrami and Henry Schoolcraft, the longest stream above the juncture of the Crow Wing River and Gichi-ziibi was named \\"Mississippi River\\". The Mississippi River Band of Chippewa Indians, known as the Gichi-ziibiwininiwag, are named after the stretch of the Mississippi River known as the Gichi-ziibi. The Cheyenne, one of the earliest inhabitants of the upper Mississippi River, called it the M?xe-?ometaa?e (Big Greasy River) in the Cheyenne language. The Arapaho name for the river is Beesniice.[67] The Pawnee name is Kickatit.[68]\\r\\nThe Mississippi was spelled Mississipi or Missisipi during French Louisiana and was also known as the Rivire Saint-Louis.[69][70][71]\\r\\nOn May 8, 1541, Spanish explorer Hernando de Soto became the first recorded European to reach the Mississippi River, which he called Ro del Espritu Santo (\\"River of the Holy Spirit\\"), in the area of what is now Mississippi. In Spanish, the river is called Ro Mississippi.[72]\\r\\nFrench explorers Louis Jolliet and Jacques Marquette began exploring the Mississippi in the 17th century. Marquette traveled with a Sioux Indian who named it Ne Tongo (\\"Big river\\" in Sioux language) in 1673. Marquette proposed calling it the River of the Immaculate Conception.\\r\\nWhen Louis Jolliet explored the Mississippi Valley in the 17th century, natives guided him to a quicker way to return to French Canada via the Illinois River. When he found the Chicago Portage, he remarked that a canal of \\"only half a league\\" (less than 2 miles (3.2?km), 3?km) would join the Mississippi and the Great Lakes.[73] In 1848, the continental divide separating the waters of the Great Lakes and the Mississippi Valley was breached by the Illinois and Michigan canal via the Chicago River.[74] This both accelerated the development, and forever changed the ecology of the Mississippi Valley and the Great Lakes.\\r\\nIn 1682, Ren-Robert Cavelier, Sieur de La Salle and Henri de Tonti claimed the entire Mississippi River Valley for France, calling the river Colbert River after Jean-Baptiste Colbert and the region La Louisiane, for King Louis XIV. On March 2, 1699, Pierre Le Moyne d'Iberville rediscovered the mouth of the Mississippi, following the death of La Salle.[75] The French built the small fort of La Balise there to control passage.[76]\\r\\nIn 1718, about 100 miles (160?km) upriver, New Orleans was established along the river crescent by Jean-Baptiste Le Moyne, Sieur de Bienville, with construction patterned after the 1711 resettlement on Mobile Bay of Mobile, the capital of French Louisiana at the time.\\r\\nFollowing Britain's victory in the Seven Years War the Mississippi became the border between the British and Spanish Empires. The Treaty of Paris (1763) gave Great Britain rights to all land east of the Mississippi and Spain rights to land west of the Mississippi. Spain also ceded Florida to Britain to regain Cuba, which the British occupied during the war. Britain then divided the territory into East and West Florida.\\r\\nArticle 8 of the Treaty of Paris (1783) states, \\"The navigation of the river Mississippi, from its source to the ocean, shall forever remain free and open to the subjects of Great Britain and the citizens of the United States\\". With this treaty, which ended the American Revolutionary War, Britain also ceded West Florida back to Spain to regain the Bahamas, which Spain had occupied during the war. In 1800, under duress from Napoleon of France, Spain ceded an undefined portion of West Florida to France. When France then sold the Louisiana Territory to the U.S. in 1803, a dispute arose again between Spain and the U.S. on which parts of West Florida exactly had Spain ceded to France, which would in turn decide which parts of West Florida were now U.S. property versus Spanish property. These aspirations ended when Spain was pressured into signing Pinckney's Treaty in 1795.\\r\\nFrance reacquired 'Louisiana' from Spain in the secret Treaty of San Ildefonso in 1800. The United States then secured effective control of the river when it bought the Louisiana Territory from France in the Louisiana Purchase of 1803. The last serious European challenge to U.S. control of the river came at the conclusion of War of 1812 when British forces mounted an attack on New Orleans ÿ the attack was repulsed by an American army under the command of General Andrew Jackson.\\r\\nIn the Treaty of 1818, the U.S. and Great Britain agreed to fix the border running from the Lake of the Woods to the Rocky Mountains along the 49th parallel north. In effect, the U.S. ceded the northwestern extremity of the Mississippi basin to the British in exchange for the southern portion of the Red River basin.\\r\\nSo many settlers traveled westward through the Mississippi river basin, as well as settled in it, that Zadok Cramer wrote a guide book called The Navigator, detailing the features and dangers and navigable waterways of the area. It was so popular that he updated and expanded it through 12 editions over a period of 25 years.\\r\\nThe colonization of the area was barely slowed by the three earthquakes in 1811 and 1812, estimated at approximately 8 on the Richter magnitude scale, that were centered near New Madrid, Missouri.\\r\\nMark Twain's book, Life on the Mississippi, covered the steamboat commerce which took place from 1830 to 1870 on the river before more modern ships replaced the steamer. The book was published first in serial form in Harper's Weekly in seven parts in 1875. The full version, including a passage from the then unfinished Adventures of Huckleberry Finn and works from other authors, was published by James R. Osgood & Company in 1885.\\r\\nThe first steamboat to travel the full length of the Lower Mississippi from the Ohio River to New Orleans was the New Orleans in December 1811. Its maiden voyage occurred during the series of New Madrid earthquakes in 1811ÿ12. The Upper Mississippi was treacherous, unpredictable and to make traveling worse, the area was not properly mapped out or surveyed. Until the 1840s only two trips a year to the Twin Cities landings were made by steamboats which suggests it was not very profitable.[77]\\r\\nSteamboat transport remained a viable industry, both in terms of passengers and freight until the end of the first decade of the 20th century. Among the several Mississippi River system steamboat companies was the noted Anchor Line, which, from 1859 to 1898, operated a luxurious fleet of steamers between St. Louis and New Orleans.\\r\\nItalian explorer Giacomo Beltrami, wrote about his journey on the Virginia, which was the first steam boat to make it to Fort St. Anthony in Minnesota. He referred to his voyage as a promenade that was once a journey on the Mississippi. The steamboat era changed the economic and political life of the Mississippi, as well as the nature of travel itself. The Mississippi was completely changed by the steamboat era as it transformed into a flourishing tourists trade.[78]\\r\\nControl of the river was a strategic objective of both sides in the American Civil War. In 1862 Union forces coming down the river successfully cleared Confederate defenses at Island Number 10 and Memphis, Tennessee, while Naval forces coming upriver from the Gulf of Mexico captured New Orleans, Louisiana. The remaining major Confederate stronghold was on the heights overlooking the river at Vicksburg, Mississippi, and the Union's Vicksburg Campaign (December 1862 to July 1863), and the fall of Port Hudson, completed control of the lower Mississippi River. The Union victory ending the Siege of Vicksburg on July 4, 1863, was pivotal to the Union's final victory of the Civil War.\\r\\nThe \\"Big Freeze\\" of 1918ÿ19 blocked river traffic north of Memphis, Tennessee, preventing transportation of coal from southern Illinois. This resulted in widespread shortages, high prices, and rationing of coal in January and February.[79]\\r\\nIn the spring of 1927, the river broke out of its banks in 145 places, during the Great Mississippi Flood of 1927 and inundated 27,000?sq?mi (70,000?km2) to a depth of up to 30 feet (9.1?m).\\r\\nIn 1962 and 1963, industrial accidents spilled 3.5?million US gallons (13,000,000?L) of soybean oil into the Mississippi and Minnesota rivers. The oil covered the Mississippi River from St. Paul to Lake Pepin, creating an ecological disaster and a demand to control water pollution.[80]\\r\\nOn October 20, 1976, the automobile ferry, MV George Prince, was struck by a ship traveling upstream as the ferry attempted to cross from Destrehan, Louisiana, to Luling, Louisiana. Seventy-eight passengers and crew died; only eighteen survived the accident.\\r\\nIn 1988, the water level of the Mississippi fell to 10 feet (3.0?m) below zero on the Memphis gauge. The remains of wooden-hulled water craft were exposed in an area of 4.5 acres (18,000?m2) on the bottom of the Mississippi River at West Memphis, Arkansas. They dated to the late 19th to early 20th centuries. The State of Arkansas, the Arkansas Archeological Survey, and the Arkansas Archeological Society responded with a two-month data recovery effort. The fieldwork received national media attention as good news in the middle of a drought.[81]\\r\\nThe Great Flood of 1993 was another significant flood, primarily affecting the Mississippi above its confluence with the Ohio River at Cairo, Illinois.\\r\\nTwo portions of the Mississippi were designated as American Heritage Rivers in 1997: the lower portion around Louisiana and Tennessee, and the upper portion around Iowa, Illinois, Minnesota and Missouri. The Nature Conservancy's project called \\"America's Rivershed Initiative\\" announced a 'report card' assessment of the entire basin in October 2015 and gave the grade of D+. The assessment noted the aging navigation and flood control infrastructure along with multiple environmental problems.[82]\\r\\nIn 2002, Slovenian long-distance swimmer Martin Strel swam the entire length of the river, from Minnesota to Louisiana, over the course of 68 days. In 2005, the Source to Sea Expedition[83] paddled the Mississippi and Atchafalaya Rivers to benefit the Audubon Society's Upper Mississippi River Campaign.[84][85]\\r\\nGeologists believe that the lower Mississippi could take a new course to the Gulf. Either of two new routesthrough the Atchafalaya Basin or through Lake Pontchartrainmight become the Mississippi's main channel if flood-control structures are overtopped or heavily damaged during a severe flood.[86][87][88][89][90]\\r\\nFailure of the Old River Control Structure, the Morganza Spillway, or nearby levees would likely re-route the main channel of the Mississippi through Louisiana's Atchafalaya Basin and down the Atchafalaya River to reach the Gulf of Mexico south of Morgan City in southern Louisiana. This route provides a more direct path to the Gulf of Mexico than the present Mississippi River channel through Baton Rouge and New Orleans.[88] While the risk of such a diversion is present during any major flood event, such a change has so far been prevented by active human intervention involving the construction, maintenance, and operation of various levees, spillways, and other control structures by the U.S. Army Corps of Engineers.\\r\\nThe Old River Control Structure, between the present Mississippi River channel and the Atchafalaya Basin, sits at the normal water elevation and is ordinarily used to divert 30% of the Mississippi's flow to the Atchafalaya River. There is a steep drop here away from the Mississippi's main channel into the Atchafalaya Basin. If this facility were to fail during a major flood, there is a strong concern the water would scour and erode the river bottom enough to capture the Mississippi's main channel. The structure was nearly lost during the 1973 flood, but repairs and improvements were made after engineers studied the forces at play. In particular, the Corps of Engineers made many improvements and constructed additional facilities for routing water through the vicinity. These additional facilities give the Corps much more flexibility and potential flow capacity than they had in 1973, which further reduces the risk of a catastrophic failure in this area during other major floods, such as that of 2011.\\r\\nBecause the Morganza Spillway is slightly higher and well back from the river, it is normally dry on both sides.[91] Even if it failed at the crest during a severe flood, the flood waters would have to erode to normal water levels before the Mississippi could permanently jump channel at this location.[citation needed] During the 2011 floods, the Corps of Engineers opened the Morganza Spillway to 1/4 of its capacity to allow 150,000?ft3/sec of water to flood the Morganza and Atchafalaya floodways and continue directly to the Gulf of Mexico, bypassing Baton Rouge and New Orleans.[92] In addition to reducing the Mississippi River crest downstream, this diversion reduced the chances of a channel change by reducing stress on the other elements of the control system.[93]\\r\\nSome geologists have noted that the possibility for course change into the Atchafalaya also exists in the area immediately north of the Old River Control Structure. Army Corps of Engineers geologist Fred Smith once stated, \\"The Mississippi wants to go west. 1973 was a forty-year flood. The big one lies out there somewherewhen the structures can't release all the floodwaters and the levee is going to have to give way. That is when the river's going to jump its banks and try to break through.\\"[94]\\r\\nAnother possible course change for the Mississippi River is a diversion into Lake Pontchartrain near New Orleans. This route is controlled by the Bonnet Carr Spillway, built to reduce flooding in New Orleans. This spillway and an imperfect natural levee about 4ÿ6 meters (12 to 20 feet) high are all that prevents the Mississippi from taking a new, shorter course through Lake Pontchartrain to the Gulf of Mexico.[95] Diversion of the Mississippi's main channel through Lake Pontchartrain would have consequences similar to an Atchafalaya diversion, but to a lesser extent, since the present river channel would remain in use past Baton Rouge and into the New Orleans area.\\r\\nThe sport of water skiing was invented on the river in a wide region between Minnesota and Wisconsin known as Lake Pepin.[96] Ralph Samuelson of Lake City, Minnesota, created and refined his skiing technique in late June and early July 1922. He later performed the first water ski jump in 1925 and was pulled along at 80?mph (130?km/h) by a Curtiss flying boat later that year.[96]\\r\\nThere are seven National Park Service sites along the Mississippi River. The Mississippi National River and Recreation Area is the National Park Service site dedicated to protecting and interpreting the Mississippi River itself. The other six National Park Service sites along the river are (listed from north to south):\\r\\nThe Mississippi basin is home to a highly diverse aquatic fauna and has been called the \\"mother fauna\\" of North American fresh water.[97]\\r\\nAbout 375 fish species are known from the Mississippi basin, far exceeding other North Hemisphere river basin exclusively within temperate/subtropical regions,[97] except the Yangtze.[98] Within the Mississippi basin, streams that have their source in the Appalachian and Ozark highlands contain especially many species. Among the fish species in the basin are numerous endemics, as well as relicts such as paddlefish, sturgeon, gar and bowfin.[97]\\r\\nBecause of its size and high species diversity, the Mississippi basin is often divided into subregions. The Upper Mississippi River alone is home to about 120 fish species, including walleye, sauger, large mouth bass, small mouth bass, white bass, northern pike, bluegill, crappie, channel catfish, flathead catfish, common shiner, freshwater drum and shovelnose sturgeon.[99][100]\\r\\nIn addition to fish, several species of turtles (such as snapping, musk, mud, map, cooter, painted and softshell turtles), American alligator, aquatic amphibians (such as hellbender, mudpuppy, three-toed amphiuma and lesser siren),[101] and cambarid crayfish (such as the red swamp crayfish) are native to the Mississippi basin.[102]\\r\\nNumerous introduced species are found in the Mississippi and some of these are invasive. Among the introductions are fish such as Asian carp, including the silver carp that have become infamous for outcompeting native fish and their potentially dangerous jumping behavior. They have spread throughout much of the basin, even approaching (but not yet invading) the Great Lakes.[103] The Minnesota Department of Natural Resources has designated much of the Mississippi River in the state as infested waters by the exotic species zebra mussels and Eurasian watermilfoil.[104]","input":"What are the headwaters of the mississippi river?"},{"output":"July 28, 2008","context":"\\r\\nTaarak Mehta Ka Ooltah Chashmah (English: Taarak Mehta's Different Perspective) is India's longest running sitcom serial.[1] It is produced by Neela Tele Films Private Limited. The show went on air on July 28, 2008. It airs from Monday to Friday on SAB TV. Reruns of the show started on Sony Pal on November 2, 2015.\\r\\nThe show is based on the column Duniya Ne Undha Chashma written by columnist and journalist Taarak Mehta for Gujarati weekly magazine Chitralekha. It is one of the longest running scripted show\\r\\n\\r\\n\\r\\nGokuldham Society is a residential society in Powder Galli, Goregaon, Mumbai with three wings: A Wing, B Wing and C Wing. Although the society has more than 50 flats, the show revolves around the lives of eight families:\\r\\nThere are also other recurring characters including Sundarlal (brother of Jethalal's wife Daya, from Ahmedabad, Gujarat)and his friends. Abdul, the shopkeeper of the provisions store located outside the society entrance, reporter Rita Shrivastav from 'Kal Tak' a news channel, Inspector Chalu Pandey, Asit Kumarr Modi as himself, Jethalal's shop assistants - Natwarlal Prabhashankar Udhaiwala (Natu Kaka) and his nephew Baagheshwar Dadu Udhaiwala (Baagha), who are often bent on doing the wrong job, and Baagha's fiance Bawri Dhondulal Kanpuria.\\r\\nThe members of the society and other characters have a good psychological bond of love and sympathy for one another that makes them live like members of one family. They are often seen celebrating festivals and participating in events together. Although they are shown to live the lives of typical Indian families, the characters, more often than not Jethalal Gada, tend to find themselves in trouble, cropping up from routine activities that intensify in a comical manner.\\r\\nThe quirks of the individual characters seek to enhance the humour quotient of the show. Whatever the nature of the problem that a member of the society encounters, all the other members stand by them to extend every possible help. In an episode, the resolution of the problem that a character faces is usually followed by a moral message at the end by Taarak Mehta, which is meant for all the characters of the show as well as the viewers.\\r\\nThe Tapu Sena is a five-member group of children residing in Gokuldham Society: Tapu (the leader of Tapu Sena), Goli, Gogi, Pinku and Sonu. These children have played significant roles, providing a fun young tone to the show. Usually, the group becomes a nuisance for the other members of the society because of their mischief, while at other times, it draws praises from the members by doing something laudable. Since the beginning of the show, the Tapu Sena has, with their childlike activities, characterized the typical frolicsome Indian children. As the children grow up and mature, the stories are tailored to suit their ages.[2][3]\\r\\nThe major part of the shooting is done in Mumbai. However, some parts of the show have also been shot in places such as Gujarat, New Delhi, Goa and in foreign locations such as London, Brussels, Paris and Hong Kong.[4]\\r\\nTo celebrate Taarak Mehta Ka Ooltah Chashmah completing 1,000 episodes on 6 November 2012,[5] the director \\"decided to shoot the film on a different canvas as he does not want the audience to feel that they are watching yet another episode of the serial.\\"[6]\\r\\nIn October 2013, Joshi and Vakani participated in a promotional event held in New Jersey at the Expo Center.[7]\\r\\nIn February 2015, Joshi, Vakani, and Lodha hosted the red carpet at the 60th Britannia Filmfare awards to promote the 'Clean India' campaign.[8]\\r\\nIn 2010, the show beat Balika Vadhu to become the most watched television programme in India. The show has constantly achieved high ratings throughout its run, irrespective of the Indian Premiere League. In the first week of 2017, the show stood in fourth position with 6,004 TVT ratings. In the fourth week, the show entered the top five and stood in fifth position with 6,059 TVT ratings. In March 2017, the show remained within the top five shows urban rural metrics. In the 25th week of 2017, the show stood at the top spot with 6,092 TVT ratings. In the 26th week of 2017, the show stood at third spot with 6,049 TVT ratings. It is the longest running scripted show on Indian television.\\r\\nPolish Deputy Prime Minister and Minister of Culture and National Heritage, Piotr Glinski visited the sets of Taarak Mehta Ka Ooltah Chashmah in February 2016.","input":"When was taarak mehta ka ooltah chashmah started?"},{"output":"BD Mishra","context":"The Governor of Arunachal Pradesh is a nominal head and representative of the President of India in the state of Arunachal Pradesh. The Governor is appointed by the President for a term of 5 years. The current governor is BD Mishra.[1]\\r\\n\\r\\n\\r\\nThe Governor enjoys many different types of powers:","input":"Who is the newly appointed governor of arunachal pradesh?"},{"output":"Sutter's Mill in Coloma, California","context":"The California Gold Rush (1848ÿ1855) began on January 24, 1848, when gold was found by James W. Marshall at Sutter's Mill in Coloma, California.[1] The news of gold brought some 300,000 people to California from the rest of the United States and abroad.[2] The sudden influx of immigration and gold into the money supply reinvigorated the American economy, and California became one of the few American states to go directly to statehood without first being a territory, in the Compromise of 1850. The Gold Rush had severe effects on Native Californians and resulted in a precipitous population decline from disease, genocide and starvation. By the time it ended, California had gone from a thinly populated ex-Mexican territory, to the home state of the first presidential nominee for the new Republican Party, in 1856.\\r\\nThe effects of the Gold Rush were substantial. Whole indigenous societies were attacked and pushed off their lands by the gold-seekers, called \\"forty-niners\\" (referring to 1849). The first to hear confirmed information of the gold rush were the people in Oregon, the Sandwich Islands (Hawaii), and Latin America, and they were the first to start flocking to the state in late 1848. Of the 300,000 people who came to America during the Gold Rush, approximately half arrived by sea and half came overland on the California Trail and the Gila River trail; forty-niners often faced substantial hardships on the trip. While most of the newly arrived were Americans, the gold rush attracted tens of thousands from Latin America, Europe, Australia, and China. Agriculture and ranching expanded throughout the state to meet the needs of the settlers. San Francisco grew from a small settlement of about 200 residents in 1846 to a boomtown of about 36,000 by 1852. Roads, churches, schools and other towns were built throughout California. In 1849 a state constitution was written. The new constitution was adopted by referendum vote, and the future state's interim first governor and legislature were chosen. In September, 1850, California became a state.\\r\\nAt the beginning of the Gold Rush, there was no law regarding property rights in the goldfields and a system of \\"staking claims\\" was developed. Prospectors retrieved the gold from streams and riverbeds using simple techniques, such as panning. Although the mining caused environmental harm, more sophisticated methods of gold recovery were developed and later adopted around the world. New methods of transportation developed as steamships came into regular service. By 1869 railroads were built across the country from California to the eastern United States. At its peak, technological advances reached a point where significant financing was required, increasing the proportion of gold companies to individual miners. Gold worth tens of billions of today's dollars was recovered, which led to great wealth for a few. However, many returned home with little more than they had started with.\\r\\n\\r\\n\\r\\nThe MexicanÿAmerican War ended on February 3, 1848, although California was firmly in American hands before that. The Treaty of Guadalupe Hidalgo provided for, among other things, the formal transfer of Upper California to the United States. The California Gold Rush began at Sutter's Mill, near Coloma.[3] On January 24, 1848, James W. Marshall, a foreman working for Sacramento pioneer John Sutter, found shiny metal in the tailrace of a lumber mill Marshall was building for Sutter on the American River.[4] Marshall brought what he found to John Sutter, and the two privately tested the metal. After the tests showed that it was gold, Sutter expressed dismay: he wanted to keep the news quiet because he feared what would happen to his plans for an agricultural empire if there were a mass search for gold.[5]\\r\\nHowever, rumors soon started to spread and were confirmed in March 1848 by San Francisco newspaper publisher and merchant Samuel Brannan. The most famous quote of the California Gold Rush was by Brannan; after he had hurriedly set up a store to sell gold prospecting supplies,[6] Brannan strode through the streets of San Francisco, holding aloft a vial of gold, shouting \\"Gold! Gold! Gold from the American River!\\"[7]\\r\\nOn August 19, 1848, the New York Herald was the first major newspaper on the East Coast to report the discovery of gold. On December 5, 1848, President James Polk confirmed the discovery of gold in an address to Congress.[8] Soon, waves of immigrants from around the world, later called the \\"forty-niners,\\" invaded the Gold Country of California or \\"Mother Lode\\". As Sutter had feared, he was ruined; his workers left in search of gold, and squatters took over his land and stole his crops and cattle.[9]\\r\\nSan Francisco had been a tiny settlement before the rush began. When residents learned about the discovery, it at first became a ghost town of abandoned ships and businesses,[10] but then boomed as merchants and new people arrived. The population of San Francisco exploded from perhaps about 1,000[11] in 1848 to 25,000 full-time residents by 1850.[12] Miners lived in tents, wood shanties, or deck cabins removed from abandoned ships.[13]\\r\\nIn what has been referred to as the \\"first world-class gold rush,\\"[14] there was no easy way to get to California; forty-niners faced hardship and often death on the way. At first, most Argonauts, as they were also known, traveled by sea. From the East Coast, a sailing voyage around the tip of South America would take five to eight months,[15] and cover some 18,000 nautical miles (33,000 kilometres). An alternative was to sail to the Atlantic side of the Isthmus of Panama, take canoes and mules for a week through the jungle, and then on the Pacific side, wait for a ship sailing for San Francisco.[16] There was also a route across Mexico starting at Veracruz. Many gold-seekers took the overland route across the continental United States, particularly along the California Trail.[17] Each of these routes had its own deadly hazards, from shipwreck to typhoid fever and cholera.[18]\\r\\nTo meet the demands of the arrivals, ships bearing goods from around the world came to San Francisco as well. Ships' captains found that their crews deserted to go to the goldfields. The wharves and docks of San Francisco became a forest of masts, as hundreds of ships were abandoned. Enterprising San Franciscans turned the abandoned ships into warehouses, stores, taverns, hotels, and one into a jail.[19] Many of these ships were later destroyed and used for landfill to create more buildable land in the boomtown.[19]\\r\\nWithin a few years, there was an important but lesser-known surge of prospectors into far Northern California, specifically into present-day Siskiyou, Shasta and Trinity Counties.[20] Discovery of gold nuggets at the site of present-day Yreka in 1851 brought thousands of gold-seekers up the Siskiyou Trail[21] and throughout California's northern counties.[22]\\r\\nSettlements of the Gold Rush era, such as Portuguese Flat on the Sacramento River, sprang into existence and then faded. The Gold Rush town of Weaverville on the Trinity River today retains the oldest continuously used Taoist temple in California, a legacy of Chinese miners who came. While there are not many Gold Rush era ghost towns still in existence, the remains of the once-bustling town of Shasta have been preserved in a California State Historic Park in Northern California.[23]\\r\\nGold was also discovered in Southern California but on a much smaller scale. The first discovery of gold, at Rancho San Francisco in the mountains north of present-day Los Angeles, had been in 1842, six years before Marshall's discovery, while California was still part of Mexico.[24] However, these first deposits, and later discoveries in Southern California mountains, attracted little notice and were of limited consequence economically.[24]\\r\\nBy 1850, most of the easily accessible gold had been collected, and attention turned to extracting gold from more difficult locations. Faced with gold increasingly difficult to retrieve, Americans began to drive out foreigners to get at the most accessible gold that remained. The new California State Legislature passed a foreign miners tax of twenty dollars per month ($590 per month as of 2018), and American prospectors began organized attacks on foreign miners, particularly Latin Americans and Chinese.[25]\\r\\nIn addition, the huge numbers of newcomers were driving Native Americans out of their traditional hunting, fishing and food-gathering areas. To protect their homes and livelihood, some Native Americans responded by attacking the miners. This provoked counter-attacks on native villages. The Native Americans, out-gunned, were often slaughtered.[26] Those who escaped massacres were many times unable to survive without access to their food-gathering areas, and they starved to death. Novelist and poet Joaquin Miller vividly captured one such attack in his semi-autobiographical work, Life Amongst the Modocs.[27]\\r\\nThe first gold found in California was made on March 9, 1842. Francisco Lopez, a native California, was searching for stray horses. He stopped on the bank of a small creek in what later was known as Placerita Canyon, about 3 miles (4.8?km) east of the present-day Newhall, California, and about 35 miles (56?km) northwest of Los Angeles. While the horses grazed, Lopez dug up some wild onions and found a small gold nugget in the roots among the onion bulbs. He looked further and found more gold.[28]\\r\\nLopez took the gold to authorities who confirmed its worth. Lopez and others began to search for other steambeds with gold deposits in the area. They found several in the northeastern section of the forest, within present-day Ventura County. In 1843 he found gold in San Feliciano Canyon near his first discovery. Mexican miners from Sonora worked the placer deposits until 1846, when the Californios began to agitate for independence from Mexico, and the Bear Flag Revolt caused many Mexicans to leave California.[28]\\r\\nThe first people to rush to the goldfields, beginning in the spring of 1848, were the residents of California themselvesprimarily agriculturally oriented Americans and Europeans living in Northern California, along with Native Americans and some Californios (Spanish-speaking Californians).[29] These first miners tended to be families in which everyone helped in the effort. Women and children of all ethnicities were often found panning next to the men. Some enterprising families set up boarding houses to accommodate the influx of men; in such cases, the women often brought in steady income while their husbands searched for gold.[30]\\r\\nWord of the Gold Rush spread slowly at first. The earliest gold-seekers were people who lived near California or people who heard the news from ships on the fastest sailing routes from California. The first large group of Americans to arrive were several thousand Oregonians who came down the Siskiyou Trail.[31] Next came people from the Sandwich Islands, and several thousand Latin Americans, including people from Mexico, from Peru and from as far away as Chile,[32] both by ship and overland.[33] By the end of 1848, some 6,000 Argonauts had come to California.[33]\\r\\nOnly a small number (probably fewer than 500) traveled overland from the United States that year.[33] Some of these \\"forty-eighters\\",[34] as the earliest gold-seekers were sometimes called, were able to collect large amounts of easily accessible goldin some cases, thousands of dollars worth each day.[35][36] Even ordinary prospectors averaged daily gold finds worth 10 to 15 times the daily wage of a laborer on the East Coast. A person could work for six months in the goldfields and find the equivalent of six years' wages back home.[37] Some hoped to get rich quick and return home, and others wished to start businesses in California.\\r\\nBy the beginning of 1849, word of the Gold Rush had spread around the world, and an overwhelming number of gold-seekers and merchants began to arrive from virtually every continent. The largest group of forty-niners in 1849 were Americans, arriving by the tens of thousands overland across the continent and along various sailing routes[38] (the name \\"forty-niner\\" was derived from the year 1849). Many from the East Coast negotiated a crossing of the Appalachian Mountains, taking to riverboats in Pennsylvania, poling the keelboats to Missouri River wagon train assembly ports, and then travelling in a wagon train along the California Trail. Many others came by way of the Isthmus of Panama and the steamships of the Pacific Mail Steamship Company. Australians[39] and New Zealanders picked up the news from ships carrying Hawaiian newspapers, and thousands, infected with \\"gold fever\\", boarded ships for California.[40]\\r\\nForty-niners came from Latin America, particularly from the Mexican mining districts near Sonora and Chile.[40][41] Gold-seekers and merchants from Asia, primarily from China,[42] began arriving in 1849, at first in modest numbers to Gum San (\\"Gold Mountain\\"), the name given to California in Chinese.[43] The first immigrants from Europe, reeling from the effects of the Revolutions of 1848 and with a longer distance to travel, began arriving in late 1849, mostly from France,[44] with some Germans, Italians, and Britons.[38]\\r\\nIt is estimated that approximately 90,000 people arrived in California in 1849about half by land and half by sea.[45] Of these, perhaps 50,000 to 60,000 were Americans, and the rest were from other countries.[38] By 1855, it is estimated at least 300,000 gold-seekers, merchants, and other immigrants had arrived in California from around the world.[46] The largest group continued to be Americans, but there were tens of thousands each of Mexicans, Chinese, Britons, Australians,[47] French, and Latin Americans,[48] together with many smaller groups of miners, such as African Americans, Filipinos, Basques[49] and Turks.[50][51]\\r\\nPeople from small villages in the hills near Genova, Italy were among the first to settle permanently in the Sierra Nevada foothills; they brought with them traditional agricultural skills, developed to survive cold winters.[52] A modest number of miners of African ancestry (probably less than 4,000)[53] had come from the Southern States,[54] the Caribbean and Brazil.[55]\\r\\nA number of immigrants were from China. Several hundred Chinese arrived in California in 1849 and 1850, and in 1852 more than 20,000 landed in San Francisco.[56] Their distinctive dress and appearance was highly recognizable in the goldfields. Chinese miners suffered enormously, enduring violent racism from white miners who aimed their frustrations at foreigners. To this day, there has been no justice for known victims. Further animosity toward the Chinese led to legislation such as the Chinese Exclusion Act and Foreign Miners Tax.[57][56]\\r\\nThere were also women in the Gold Rush. However, their numbers were small. Of the 40,000 people who arrived by ship in the San Francisco harbor in 1849, only 700 were women.[58] They held various roles including prostitutes, single entrepreneurs, married women, poor and wealthy women. They were of various ethnicities including Anglo-American, African-American,[59] Hispanic, Native, European, Chinese, and Jewish. The reasons they came varied: some came with their husbands, refusing to be left behind to fend for themselves, some came because their husbands sent for them, and others came (singles and widows) for the adventure and economic opportunities.[60] On the trail many people died from accidents, cholera, fever, and myriad other causes, and many women became widows before even setting eyes on California. While in California, women became widows quite frequently due to mining accidents, disease, or mining disputes of their husbands. Life in the goldfields offered opportunities for women to break from their traditional work.[61][62]\\r\\nThe disproportionate number of men to women in San Francisco created an environment for homosexuality and gay cultures to flourish.[63] The Barbary Coast was a district where men went to gamble and pay for sex from female impersonators and women alike.[63] Described as the \\"city of bachelors\\" [63] men often went to the Barbary Coast district to pay for prostitution and pleasure with other men.[64]\\r\\nWhen the Gold Rush began, the California goldfields were peculiarly lawless places.[65] When gold was discovered at Sutter's Mill, California was still technically part of Mexico, under American military occupation as the result of the MexicanÿAmerican War. With the signing of the treaty ending the war on February 2, 1848, California became a possession of the United States, but it was not a formal \\"territory\\" and did not become a state until September 9, 1850. California existed in the unusual condition of a region under military control. There was no civil legislature, executive or judicial body for the entire region.[66] Local residents operated under a confusing and changing mixture of Mexican rules, American principles, and personal dictates. Lax enforcement of federal laws, such as the Fugitive Slave Act of 1850, encouraged the arrival of free blacks and escaped slaves.[67]\\r\\nWhile the treaty ending the MexicanÿAmerican War obliged the United States to honor Mexican land grants,[68] almost all the goldfields were outside those grants. Instead, the goldfields were primarily on \\"public land\\", meaning land formally owned by the United States government.[69] However, there were no legal rules yet in place,[65] and no practical enforcement mechanisms.[70]\\r\\nThe benefit to the forty-niners was that the gold was simply \\"free for the taking\\" at first. In the goldfields at the beginning, there was no private property, no licensing fees, and no taxes.[71][72] The miners informally adapted Mexican mining law that had existed in California.[73] For example, the rules attempted to balance the rights of early arrivers at a site with later arrivers; a \\"claim\\" could be \\"staked\\" by a prospector, but that claim was valid only as long as it was being actively worked.[65][74][75]\\r\\nMiners worked at a claim only long enough to determine its potential. If a claim was deemed as low-valueas most wereminers would abandon the site in search for a better one. In the case where a claim was abandoned or not worked upon, other miners would \\"claim-jump\\" the land. \\"Claim-jumping\\" meant that a miner began work on a previously claimed site.[74][75] Disputes were often handled personally and violently, and were sometimes addressed by groups of prospectors acting as arbitrators.[69][74][75] This often led to heightened ethnic tensions.[76] In some areas the influx of many prospectors could lead to a reduction of the existing claim size by simple pressure.[77]\\r\\nFour hundred million years ago, California lay at the bottom of a large sea; underwater volcanoes deposited lava and minerals (including gold) onto the sea floor. By tectonic forces these minerals and rocks came to the surface of the Sierra Nevada,[78] and eroded. Water carried the exposed gold downstream and deposited it in quiet gravel beds along the sides of old rivers and streams.[79][80] The forty-niners first focused their efforts on these deposits of gold.[81]\\r\\nBecause the gold in the California gravel beds was so richly concentrated, early forty-niners were able to retrieve loose gold flakes and nuggets with their hands, or simply \\"pan\\" for gold in rivers and streams.[82][83] However, panning cannot take place on a large scale, and industrious miners and groups of miners graduated to placer mining, using \\"cradles\\" and \\"rockers\\" or \\"long-toms\\"[84] to process larger volumes of gravel.[85] Miners would also engage in \\"coyoteing\\",[86] a method that involved digging a shaft 6 to 13 meters (20 to 43?ft) deep into placer deposits along a stream. Tunnels were then dug in all directions to reach the richest veins of pay dirt.\\r\\nIn the most complex placer mining, groups of prospectors would divert the water from an entire river into a sluice alongside the river, and then dig for gold in the newly exposed river bottom.[87] Modern estimates by the U.S. Geological Survey are that some 12 million ounces[88] (370?t) of gold were removed in the first five years of the Gold Rush (worth over US$16?billion at December 2010 prices).[89]\\r\\nIn the next stage, by 1853, hydraulic mining was used on ancient gold-bearing gravel beds on hillsides and bluffs in the goldfields.[90] In a modern style of hydraulic mining first developed in California, and later used around the world, a high-pressure hose directed a powerful stream or jet of water at gold-bearing gravel beds.[91] The loosened gravel and gold would then pass over sluices, with the gold settling to the bottom where it was collected. By the mid-1880s, it is estimated that 11 million ounces (340?t) of gold (worth approximately US$15?billion at December 2010 prices) had been recovered by \\"hydraulicking\\".[89]\\r\\nA byproduct of these extraction methods was that large amounts of gravel, silt, heavy metals, and other pollutants went into streams and rivers.[92] As of 1999[update] many areas still bear the scars of hydraulic mining, since the resulting exposed earth and downstream gravel deposits do not support plant life.[93]\\r\\nAfter the Gold Rush had concluded, gold recovery operations continued. The final stage to recover loose gold was to prospect for gold that had slowly washed down into the flat river bottoms and sandbars of California's Central Valley and other gold-bearing areas of California (such as Scott Valley in Siskiyou County). By the late 1890s, dredging technology (also invented in California) had become economical,[94] and it is estimated that more than 20?million ounces (620?t) were recovered by dredging (worth approximately US$28?billion at December 2010 prices).[89]\\r\\nBoth during the Gold Rush and in the decades that followed, gold-seekers also engaged in \\"hard-rock\\" mining, that is, extracting the gold directly from the rock that contained it (typically quartz), usually by digging and blasting to follow and remove veins of the gold-bearing quartz.[95] By 1851, quartz mining had become the major industry of Coloma.[96] Once the gold-bearing rocks were brought to surface, the rocks were crushed and the gold separated, either using separation in water, using its density difference from quartz sand, or by washing the sand over copper plates coated with mercury (with which gold forms an amalgam). Loss of mercury in the amalgamation process was a source of environmental contamination.[97] Eventually, hard-rock mining wound up becoming the single largest source of gold produced in the Gold Country.[89][98] The total production of gold in California from then till now is estimated at 118 million ounces (3700 t).[99]\\r\\nForty-niner panning for gold\\r\\nSluice for separation of gold from dirt with water\\r\\nExcavating a river bed after the water has been diverted\\r\\nCrushing quartz ore prior to washing out gold\\r\\nExcavating a gravel bed with jets, circa 1863\\r\\nRecent scholarship confirms that merchants made far more money than miners during the Gold Rush.[100][101] The wealthiest man in California during the early years of the rush was Samuel Brannan, a tireless self-promoter, shopkeeper and newspaper publisher.[102] Brannan opened the first supply stores in Sacramento, Coloma, and other spots in the goldfields. Just as the rush began he purchased all the prospecting supplies available in San Francisco and re-sold them at a substantial profit.[102]\\r\\nSome gold-seekers made a significant amount of money.[103] On average, half the gold-seekers made a modest profit, after taking all expenses into account; economic historians have suggested that white miners were more successful than black, Indian, or Chinese miners.[104] However, taxes such as the California foreign miners tax passed in 1851, targeted mainly Latino miners[105] and kept them from making as much money as whites, who didn't have any taxes imposed on them. In California most late arrivals made little or wound up losing money.[106] Similarly, many unlucky merchants set up in settlements which disappeared, or which succumbed to one of the calamitous fires that swept the towns that sprang up. By contrast, a businessman who went on to great success was Levi Strauss, who first began selling denim overalls in San Francisco in 1853.[107]\\r\\nOther businessmen reaped great rewards in retail, shipping, entertainment, lodging,[108] or transportation.[109] Boardinghouses, food preparation, sewing, and laundry were highly profitable businesses often run by women (married, single, or widowed) who realized men would pay well for a service done by a woman. Brothels also brought in large profits, especially when combined with saloons and gaming houses.[110]\\r\\nBy 1855, the economic climate had changed dramatically. Gold could be retrieved profitably from the goldfields only by medium to large groups of workers, either in partnerships or as employees. By the mid-1850s, it was the owners of these gold-mining companies who made the money. Also, the population and economy of California had become large and diverse enough that money could be made in a wide variety of conventional businesses.[111]\\r\\nOnce extracted, the gold itself took many paths. First, much of the gold was used locally to purchase food, supplies and lodging for the miners. It also went towards entertainment, which consisted of anything from a traveling theater to alcohol, gambling, and prostitutes. These transactions often took place using the recently recovered gold, carefully weighed out.[112][113] These merchants and vendors in turn used the gold to purchase supplies from ship captains or packers bringing goods to California.[114]\\r\\nThe gold then left California aboard ships or mules to go to the makers of the goods from around the world. A second path was the Argonauts themselves who, having personally acquired a sufficient amount, sent the gold home, or returned home taking with them their hard-earned \\"diggings\\". For example, one estimate is that some US$80?million worth of California gold was sent to France by French prospectors and merchants.[115]\\r\\nAs the Gold Rush progressed, local banks and gold dealers issued \\"banknotes\\" or \\"drafts\\"locally accepted paper currencyin exchange for gold,[116] and private mints created private gold coins.[117] With the building of the San Francisco Mint in 1854, gold bullion was turned into official United States gold coins for circulation.[118] The gold was also later sent by California banks to U.S. national banks in exchange for national paper currency to be used in the booming California economy.[119]\\r\\nThe arrival of hundreds of thousands of new people in California within a few years, compared to a population of some 15,000?Europeans and Californios beforehand,[120] had many dramatic effects.[121]\\r\\nA 2017 study attributes the record-long economic expansion of the United States in the recession-free period of 1841ÿ1856 primarily to \\"a boom in transportation-goods investment following the discovery of gold in California.\\"[122]\\r\\nThe Gold Rush propelled California from a sleepy, little-known backwater to a center of the global imagination and the destination of hundreds of thousands of people. The new immigrants often showed remarkable inventiveness and civic-mindedness. For example, in the midst of the Gold Rush, towns and cities were chartered, a state constitutional convention was convened, a state constitution written, elections held, and representatives sent to Washington, D.C. to negotiate the admission of California as a state.[123]\\r\\nLarge-scale agriculture (California's second \\"Gold Rush\\"[124]) began during this time.[125] Roads, schools, churches,[126] and civic organizations quickly came into existence.[123] The vast majority of the immigrants were Americans.[127] Pressure grew for better communications and political connections to the rest of the United States, leading to statehood for California on September 9, 1850, in the Compromise of 1850 as the 31st state of the United States.\\r\\nBetween 1847 and 1870, the population of San Francisco increased from 500 to 150,000.[128] The Gold Rush wealth and population increase led to significantly improved transportation between California and the East Coast. The Panama Railway, spanning the Isthmus of Panama, was finished in 1855.[129] Steamships, including those owned by the Pacific Mail Steamship Company, began regular service from San Francisco to Panama, where passengers, goods and mail would take the train across the Isthmus and board steamships headed to the East Coast. One ill-fated journey, that of the S.S. Central America,[130] ended in disaster as the ship sank in a hurricane off the coast of the Carolinas in 1857, with approximately three tons of California gold aboard.[131][132]\\r\\nThe human and environmental costs of the Gold Rush were substantial. Native Americans, dependent on traditional hunting, gathering and agriculture, became the victims of starvation and disease, as gravel, silt and toxic chemicals from prospecting operations killed fish and destroyed habitats.[92][93] The surge in the mining population also resulted in the disappearance of game and food gathering locales as gold camps and other settlements were built amidst them. Later farming spread to supply the settlers' camps, taking more land away from the Native Americans.[133]\\r\\nIn some areas, systematic attacks against tribespeople in or near mining districts occurred. Various conflicts were fought between natives and settlers.[134] Miners often saw Native Americans as impediments to their mining activities.[135] Ed Allen, interpretive lead for Marshall Gold Discovery State Historic Park, reported that there were times when miners would kill up to 50 or more Natives in one day.[136] Retribution attacks on solitary miners could result in larger scale attacks against Native populations, at times tribes or villages not involved in the original act.[137] During the 1852 Bridge Gulch Massacre, a group of settlers attacked a band of Wintu Indians in response to the killing of a citizen named J. R. Anderson. After his killing, the sheriff led a group of men to track down the Indians, whom the men then attacked. Only three children survived the massacre that was against a different band of Wintu than the one that had killed Anderson.[138]\\r\\nHistorian Benjamin Madley recorded the numbers of killings of California Indians between 1846 and 1873 and estimated that during this period at least 9,400 to 16,000 California Indians were killed by non-Indians, mostly occurring in more than 370 massacres (defined as the \\"intentional killing of five or more disarmed combatants or largely unarmed noncombatants, including women, children, and prisoners, whether in the context of a battle or otherwise\\").[139] According to demographer Russell Thornton, between 1849 and 1890, the Indigenous population of California fell below 20,000 ÿ primarily because of the killings.[140] According to the government of California, some 4,500 Native Americans suffered violent deaths between 1849 and 1870.[141] Furthermore, California stood in opposition of ratifying the eighteen treaties signed between tribal leaders and federal agents in 1851.[142]\\r\\nThe state government, in support of miner activities funded and supported death squads, appropriating over 1 million dollars towards the funding and operation of the paramilitary organizations.[143] Peter Burnett, California's first governor declared that California was a battleground between the races and that there were only two options towards California Indians, extermination or removal. \\"That a war of extermination will continue to be waged between the two races until the Indian race becomes extinct, must be expected. While we cannot anticipate the result with but painful regret, the inevitable destiny of the race is beyond the power and wisdom of man to avert.\\" For Burnett, like many of his contemporaries, the genocide was part of God's plan, and it was necessary for Burnett's constituency to move forward in California.[144] The Act for the Government and Protection of Indians, passed on April 22, 1850 by the California Legislature, allowed settlers to capture and use Native people as bonded workers, prohibited Native peoples' testimony against settlers, and allowed the adoption of Native children by settlers, often for labor purposes.[145]\\r\\nAfter the initial boom had ended, explicitly anti-foreign and racist attacks, laws and confiscatory taxes sought to drive out foreignersnot just Native Americansfrom the mines, especially the Chinese and Latin American immigrants mostly from Sonora, Mexico and Chile.[56][146] The toll on the American immigrants was severe as well: one in twelve forty-niners perished, as the death and crime rates during the Gold Rush were extraordinarily high, and the resulting vigilantism also took its toll.[147]\\r\\nThe Gold Rush stimulated economies around the world as well. Farmers in Chile, Australia, and Hawaii found a huge new market for their food; British manufactured goods were in high demand; clothing and even prefabricated houses arrived from China.[149] The return of large amounts of California gold to pay for these goods raised prices and stimulated investment and the creation of jobs around the world.[150] Australian prospector Edward Hargraves, noting similarities between the geography of California and his home country, returned to Australia to discover gold and spark the Australian gold rushes.[151] Preceding the Gold Rush, the United States was on a bi-metallic standard, but the sudden increase in physical gold supply increased the relative value of physical silver and drove silver money from circulation. The increase in gold supply also created a monetary supply shock.[152]\\r\\nWithin a few years after the end of the Gold Rush, in 1863, the groundbreaking ceremony for the western leg of the First Transcontinental Railroad was held in Sacramento. The line's completion, some six years later, financed in part with Gold Rush money,[153] united California with the central and eastern United States. Travel that had taken weeks or even months could now be accomplished in days.[154]\\r\\nCalifornia's name became indelibly connected with the Gold Rush, and fast success in a new world became known as the \\"California Dream.\\"[155] California was perceived as a place of new beginnings, where great wealth could reward hard work and good luck. Historian H. W. Brands noted that in the years after the Gold Rush, the California Dream spread across the nation:\\r\\nThe old American Dream?... was the dream of the Puritans, of Benjamin Franklin's \\"Poor Richard\\"...?of men and women content to accumulate their modest fortunes a little at a time, year by year by year. The new dream was the dream of instant wealth, won in a twinkling by audacity and good luck. [This] golden dream?... became a prominent part of the American psyche only after Sutter's Mill.[156]\\r\\nOvernight California gained the international reputation as the \\"golden state\\".[157] Generations of immigrants have been attracted by the California Dream. California farmers,[158] oil drillers,[159] movie makers,[160] airplane builders,[161] and \\"dot-com\\" entrepreneurs have each had their boom times in the decades after the Gold Rush.[162]\\r\\nIncluded among the modern legacies of the California Gold Rush are the California state motto, \\"Eureka\\" (\\"I have found it\\"), Gold Rush images on the California State Seal,[163] and the state nickname, \\"The Golden State\\", as well as place names, such as Placer County, Rough and Ready, Placerville (formerly named \\"Dry Diggings\\" and then \\"Hangtown\\" during rush time), Whiskeytown, Drytown, Angels Camp, Happy Camp, and Sawyers Bar. The San Francisco 49ers National Football League team, and the similarly named athletic teams of California State University, Long Beach, are named for the prospectors of the California Gold Rush.\\r\\nIn addition, the standard route shield of state highways in California is in the shape of a miner's spade to honor the California Gold Rush.[164][165] Today, aptly named State Route 49 travels through the Sierra Nevada foothills, connecting many Gold Rush-era towns such as Placerville, Auburn, Grass Valley, Nevada City, Coloma, Jackson, and Sonora.[166] This state highway also passes very near Columbia State Historic Park, a protected area encompassing the historic business district of the town of Columbia; the park has preserved many Gold Rush-era buildings, which are presently occupied by tourist-oriented businesses.\\r\\nThe literary history of the Gold Rush is reflected in the works of Mark Twain (The Celebrated Jumping Frog of Calaveras County), Bret Harte (A Millionaire of Rough-and-Ready), Joaquin Miller (Life Amongst the Modocs), and many others.[27][167]","input":"Where was the first gold found in california?"},{"output":"8 July 2000","context":"Harry Potter and the Goblet of Fire is the fourth novel in the Harry Potter series, written by British author J. K. Rowling. It follows Harry Potter, a wizard in his fourth year at Hogwarts School of Witchcraft and Wizardry and the mystery surrounding the entry of Harry's name into the Triwizard Tournament, in which he is forced to compete.\\r\\nThe book was published in the United Kingdom by Bloomsbury and in the United States by Scholastic; in both countries the release date was 8 July 2000, the first time a book in the series was published in both countries at the same time. The novel won a Hugo Award, the only Harry Potter novel to do so, in 2001. The book was made into a film, which was released worldwide on 18 November 2005, and a video game by Electronic Arts.\\r\\n\\r\\n\\r\\nThroughout the three previous novels in the Harry Potter series, the main character, Harry Potter, has struggled with the difficulties of growing up, and the added challenge of being a famed wizard: when Harry was a baby, Lord Voldemort, the most powerful Dark wizard in history, killed Harry's parents but mysteriously vanished after unsuccessfully trying to kill Harry, which left a lightning-shaped scar on Harry's forehead. This results in Harry's immediate fame and his being placed in the care of his abusive muggle, or non-magical, aunt and uncle, Aunt Petunia Dursley and Uncle Vernon Dursley, who have a son named Dudley Dursley.\\r\\nHarry learns that he is a wizard when he is 11 years old, and enrolls in Hogwarts School of Witchcraft and Wizardry. He befriends Ron Weasley and Hermione Granger, and is confronted by Lord Voldemort who is trying to regain power. In Harry's first year he has to protect the Philosopher's Stone from Voldemort and one of his faithful followers at Hogwarts. After returning to the school after summer break, students at Hogwarts are attacked by the legendary monster of the \\"Chamber of Secrets\\" after the chamber is opened. Harry ends the attacks by killing a Basilisk and defeating another attempt by Lord Voldemort to return to full strength. The following year, Harry hears that he has been targeted by escaped mass murderer Sirius Black. Despite stringent security measures at Hogwarts, Harry is confronted by Black at the end of his third year of schooling, and Harry learns that Black was framed and is actually Harry's godfather. He also learned that it was his father's old school friend Peter Pettigrew who actually betrayed his parents.\\r\\nThe book opens with Harry seeing Frank Bryce being killed by Lord Voldemort in a vision, and is awoken by his scar hurting. The Weasleys then take Harry and Hermione Granger to the Quidditch World Cup, using a Portkey, to watch Ireland versus Bulgaria, with Ireland emerging victorious. There, Harry meets Cedric Diggory, who is attending the match with his father. After the match, Voldemort's followers attack the site, destroying spectators' tents and wreaking havoc. The Dark Mark gets fired into the sky, which leads to a panic since it is the first time the sign has been seen in 13 years. Winky, Barty Crouch Senior's house elf, is falsely accused of casting the Mark after she is found holding Harry's wand, which is revealed to have been used to cast the Mark, as Harry had lost it during the chaos of the Death Eaters' attack. Hermione, angry at this injustice, forms a society to promote the rights of house elves known as S.P.E.W. (Society for the Promotion of Elvish Welfare).\\r\\nAt Hogwarts, Professor Dumbledore announces that Alastor \\"Mad-Eye\\" Moody will be the Defence Against the Dark Arts teacher for the year, and also that Hogwarts will host the Triwizard Tournament, with a prize of one thousand gold Galleons. However, only those over 17the age of majority in the wizarding worldwill be allowed to enter. It is the first time in 202 years that the Triwizard Tournament will be held. Students from Beauxbatons Academy and the Durmstrang Institute, other wizarding academies, will travel to Hogwarts, where they will stay for the year, in hopes of competing. At Halloween, the Goblet of Fire picks Fleur Delacour from Beauxbatons Academy; Viktor Krum (who is also the Seeker on Bulgaria's Quidditch team) from Durmstrang Institute; and Cedric Diggory from Hogwarts to compete in the tournament. However, it additionally gives a fourth nameHarry Potterleading to suspicion and indignation from everyone and magically binding Harry to compete. Ron is jealous that Harry is once again in the limelight and refuses to speak to Harry.\\r\\nHagrid reveals to Harry that the first task involves dragons, and since Fleur and Krum's headmasters are also aware of this, and will surely tell them in advance, Harry informs Cedric as well. At the task, Harry has to pass a Hungarian Horntail to retrieve a golden egg that contains a hint to the next task, which he does by summoning his Firebolt broomstick with the Accio spell, and finishes the task tied for first with Krum. Ron and Harry subsequently reconcile, Ron now understanding the full danger of the tournament. When Harry opens the egg, though, it merely shrieks loudly. Hermione then takes Harry and Ron to the school kitchens, where house elves work. There, they meet a distraught Winky, who is struggling to get over the loss of her sacking. They also meet Harry's old friend Dobby, who has been employed at Hogwarts to work in the kitchens; he is the only known house elf to appreciate his freedom, despite his hardworking nature.\\r\\nMeanwhile, gossipy reporter Rita Skeeter is writing scandalous articles of half-truths and outright fabrications in The Daily Prophet about those at Hogwarts, including Hermione, Harry, Hagrid, and Madame Maxime of Beauxbatons.\\r\\nWith the Yule Ball approaching, Harry must find a partner, but when he finally approaches his crush Cho Chang, Cedric has beaten him to her, so Harry and Ron ask Parvati and Padma Patil. Ron is shocked and jealous to see that Hermione is attending with Krum. Cedric gives Harry a tip on the egg, telling him to take it to the prefects' bathroom, but Harry refuses to listen, jealous over Cho.\\r\\nFinally acting on the tip, Harry takes the egg to the prefects' bathroom, where Moaning Myrtle tells him to listen to the egg underwater; there the words become understandable. Harry learns that the task is to recover something he will \\"sorely miss\\", and starts looking for spells to help him breathe where the objects will be taken: The Black Lake. By the morning of the task, Harry still hasn't found a solution, but Dobby gives him some Gillyweed to give Harry gills. Harry completes the task by rescuing Ron from under the lake. Harry then takes a risk by also rescuing Fleur's younger sister, Gabrielle, after Fleur was unable to. After the judges confer, he earns enough points to tie him with Cedric for the lead.\\r\\nOne month before the final task, Harry and Krum are talking when they encounter Crouch, who appears to have gone insane, but manages to tell Harry to get Dumbledore. Leaving Krum with Crouch, Harry fetches Dumbledore but returns to find Krum stunned and Crouch gone. Harry returns to preparing for the final task, a hedge maze. Inside the maze, Harry is forced to incapacitate Krum, who has been bewitched, to save Cedric. Working together, the two reach the cup. They agree to touch it at the same time, and doing so, discover that it is a Portkey that transports them to a graveyard. There, Peter Pettigrew kills Cedric and uses Harry's blood (along with his own hand and Tom Riddle Sr.'s bone) to resurrect Lord Voldemort.\\r\\nVoldemort summons his Death Eaters, berating them for thinking he was dead, before he reveals that he has a single \\"faithful servant\\" concealed at Hogwarts, who has been working to ensure that Harry would make it to the graveyard, and then challenges Harry to a duel. However, when he and Harry fire curses at each other, their wands connect due to their identical cores. Voldemort's wand releases the most recent spells it performed, resulting in imprints of his last victims appearing in the graveyard, including Harry's parents, who provide a distraction so that Harry can escape back to Hogwarts using the Portkey, taking Cedric's body with him.\\r\\nWhen he returns, Moody takes him to his office, and reveals himself to be Voldemort's 'faithful servant'; he was the one who put Harry's name into the Goblet of Fire, and has been guiding him through the tournament from behind the scenes to ensure that he would grab the Portkey first. Before Moody can kill Harry, Dumbledore, McGonagall and Snape intervene. They learn that Moody is in fact Barty Crouch Jr., Mr. Crouch's son, disguised by Polyjuice Potion. Crouch had sentenced Crouch Jr. to life imprisonment in Azkaban over alleged ties to the Death Eaters but smuggled him out as a last favour to his dying wife. Crouch Jr. was the one who set off the Dark Mark at the Quidditch World Cup, doing it to scare the Death Eaters he felt had abandoned Voldemort. Eventually, Voldemort had gotten in contact with Crouch Jr. and had him impersonate Moody as part of his plan. Crouch Jr. also admits to killing Crouch Sr., to prevent him telling Dumbledore about Voldemort. The real Moody is found inside Crouch Jr.'s enchanted trunk and rescued. Harry is then declared the winner of the Triwizard Tournament and given his winnings.\\r\\nMany people, including Fudge, do not believe Harry and Dumbledore about Voldemort's return, and as Fudge has the Dementor's Kiss performed, Crouch Jr. is unable to give testimony. Hermione discovers Rita Skeeter is an unregistered Animagus, who can take the form of a beetle, and blackmails her to force her to stop writing her libellous stories. Not wanting his tournament winnings, Harry gives them to Fred and George to start their joke shop and returns home with the Dursleys.\\r\\nHarry Potter and the Goblet of Fire is the fourth book in the Harry Potter series. The first, Harry Potter and the Philosopher's Stone, was published by Bloomsbury on 26 June 1997; the second, Harry Potter and the Chamber of Secrets, was published on 2 July 1998; and the third, Harry Potter and the Prisoner of Azkaban, followed on 8 July 1999.[1] Goblet of Fire is considerably longer than the first three; almost twice the size (the paperback edition was 636 pages). Rowling stated that she \\"knew from the beginning it would be the biggest of the first four\\". She said there needed to be a \\"proper run-up\\" for the conclusion and rushing the \\"complex plot\\" could confuse readers. She also stated that \\"everything is on a bigger scale\\" which was symbolic, as Harry's horizons widened both literally and metaphorically as he grew up. She also wanted to explore more of the magical world.[2]\\r\\nUntil the official title's announcement on 27 June 2000, the book was called by its working title, 'Harry Potter IV.' Previously, in April, the publisher had listed it as Harry Potter and the Doomspell Tournament. However,[3] J.?K. Rowling expressed her indecision about the title in an Entertainment Weekly interview. \\"I changed my mind twice on what [the title] was. The working title had got out? Harry Potter and the Doomspell Tournament. Then I changed Doomspell to Triwizard Tournament. Then I was teetering between Goblet of Fire and Triwizard Tournament. In the end, I preferred Goblet of Fire because it's got that kind of cup of destiny feel about it, which is the theme of the book.\\"[2]\\r\\nRowling mentioned that she originally had a Weasley relative named Malfalda, who, according to Rowling, \\"was the daughter of the 'second cousin who's a stockbroker' mentioned in Philosopher's Stone. This stockbroker had been very rude to Mr. and Mrs.?Weasley in the past, but now he and his (Muggle) wife had inconveniently produced a witch, they came back to the Weasleys asking for their help in introducing her to wizarding society before she starts at Hogwarts\\".[4] Malfalda was supposed to be a Slytherin and who was to fill in the Rita Skeeter subplot, but eventually was removed as \\"there were obvious limitations to what an eleven year old closeted at school could discover\\". Rowling considered Rita Skeeter to be \\"much more flexible\\".[4] Rowling also admitted that the fourth book was the most difficult to write at the time, because she noticed a giant plot hole halfway through writing.[2] In particular, Rowling had trouble with the ninth chapter, \\"The Dark Mark\\", which she rewrote 13?times.[5]\\r\\nJeff Jensen, who interviewed Rowling for Entertainment Weekly in 2000, pointed out that bigotry is a big theme in the Harry Potter novels and Goblet of Fire in particular. He mentioned how Voldemort and his followers are prejudiced against Muggles and how in Goblet of Fire Hermione forms a group to liberate Hogwarts' house-elves who have \\"been indentured servants so long they lack desire for anything else\\".[2] When asked why she explored this theme, Rowling replied,\\r\\nBecause bigotry is probably the thing I detest most. All forms of intolerance, the whole idea of that which is different from me is necessarily evil. I really like to explore the idea that difference is equal and good. But there's another idea that I like to explore, too. Oppressed groups are not, generally speaking, people who stand firmly together ÿ no, sadly, they kind of subdivide among themselves and fight like hell. That's human nature, so that's what you see here. This world of wizards and witches, they're already ostracized, and then within themselves, they've formed a loathsome pecking order.[2]\\r\\nShe also commented that she did not feel this was too \\"heavy\\" for children, as it was one of those things that a \\"huge number of children at that age start to think about\\".[2]\\r\\nGoblet of Fire was the first book in the Harry Potter series to be released in the United States on the same date as the United Kingdom, on 8 July 2000, strategically on a Saturday so children did not have to worry about school conflicting with buying the book.[1] It had a combined first-printing of over five million copies.[1] It was given a record-breaking print run of 3.9 million. Three million copies of the book were sold over the first weekend in the US alone.[6] FedEx dispatched more than 9,000 trucks and 100 planes to fulfill book deliveries.[7] The pressure in editing caused a mistake which shows Harry's father emerging first from Voldemort's wand; however, as confirmed in Prisoner of Azkaban, James died first, so then Harry's mother ought to have come out first.[8] This was corrected in later editions.[9]\\r\\nTo publicise the book, a special train named Hogwarts Express was organised by Bloomsbury, and run from King's Cross to Perth, carrying J.K. Rowling, a consignment of books for her to sign and sell, also representatives of Bloomsbury and the press. The book was launched on 8 July 2000, on platform?1 at King's Cross?ÿ which had been given \\"Platform ?9?3?4\\" signs for the occasion?ÿ following which the train departed. En route it called at Didcot Railway Centre, Kidderminster, the Severn Valley Railway, Crewe (overnight stop), Manchester, Bradford, York, the National Railway Museum (overnight stop), Newcastle, Edinburgh, arriving at Perth on 11 July. The locomotive was West Country class steam locomotive no.?34027 Taw Valley, which was specially repainted red for the tour; it later returned to its normal green livery (the repaints were requested and paid for by Bloomsbury). The coaches of the train included a sleeping car. A Diesel locomotive was coupled at the other end, for use when reversals were necessary, such as the first stage of the journey as far as Ferme Park, just south of Hornsey. The tour generated considerably more press interest than the launch of the film Thomas and the Magic Railroad which was premired in London the same weekend.[10][11][12]\\r\\nHarry Potter and the Goblet of Fire has received mostly positive reviews. In The New York Times Book Review, author Stephen King stated the Goblet of Fire was \\"every bit as good as Potters?1 through 3\\" and praised the humour and subplots, although he commented that \\"there's also a moderately tiresome amount of adolescent squabbling...it's a teenage thing\\".[13] Kirkus Reviews called it \\"another grand tale of magic and mystery...and clicking along so smoothly that it seems shorter than it is\\". However, they commented that it did tend to lag, especially at the end where two \\"bad guys\\" stopped the action to give extended explanations, and that the issues to be resolved in sequels would leave \\"many readers, particularly American ones, uncomfortable\\".[14] For The Horn Book Magazine, Martha V. Parravano gave a mixed review, saying \\"some will find [it] wide-ranging, compellingly written, and absorbing; others, long, rambling, and tortuously fraught with adverbs\\".[15] A Publishers Weekly review praised the book's \\"red herrings, the artful clues and tricky surprises that disarm the most attentive audience\\" and saying it \\"might be her most thrilling yet.\\"[16] Writing for The New Yorker, Joan Acocella noted that \\"where the prior volumes moved like lightning, here the pace is slower, the energy more dispersed. At the same time, the tone becomes more grim.\\"[17]\\r\\nKristin Lemmerman of CNN said that it is not great literature: 'Her prose has more in common with your typical beach-blanket fare and the beginning contained too much recap to introduce characters to new readers, although Rowling quickly gets back on track, introducing readers to a host of well-drawn new characters.'[18] Writing for Salon.com, Charles Taylor was generally positive about the change of mood and development of characters.[19] Entertainment Weekly's reviewer Kristen Baldwin gave Goblet of Fire the grade of A-, praising the development of the characters as well as the many themes presented. However, she did worry that a shocking climax may be a nightmare factory for young readers.[20]\\r\\nHarry Potter and the Goblet of Fire won several awards, including the 2001 Hugo Award for Best Novel.[21] It won the 2002 Indian Paintbrush Book Award, the third after Philosopher's Stone and Prisoner of Azkaban.[22] The novel also won an Oppenheim Toy Portfolio Platinum Award for one of the best books, who claimed it was \\"more intense than the first three books\\".[23] In addition, Entertainment Weekly listed Goblet of Fire in second place on their list of The New Classics: Books?ÿ The 100 best reads from 1983 to 2008.[24]\\r\\nHarry Potter and the Goblet of Fire was adapted into a film, released worldwide on 18 November 2005, which was directed by Mike Newell and written by Steve Kloves. The film grossed $102.7 million for the opening weekend,[25] and eventually grossed $896 million worldwide.[26] The film was also nominated for Best Art Direction at the 78th Academy Awards.[27]\\r\\nIt was also made into a video game for PC, PlayStation 2, Nintendo DS, Nintendo GameCube, Xbox, Game Boy Advance, and PlayStation Portable by Electronic Arts. It was released just before the film.\\r\\nMuch of the plot of Harry Potter and the Cursed Child involves a revisiting scenes from Goblet of Fire, with younger protagonists born long after these events travelling back in time in a misguided effort to change history and save Cedric Diggory - which only leads to them damaging events in the present and worsening the situation.","input":"When was the fourth harry potter book released?"},{"output":"Columbia River in Washington State","context":"Maverick is a 1994 American Western comedy film directed by Richard Donner and written by William Goldman, based on the 1950s television series of the same name created by Roy Huggins. The film stars Mel Gibson as Bret Maverick, a card player and con artist collecting money to enter a high-stakes poker game. He is joined in his adventure by Annabelle Bransford (Jodie Foster), another con artist, and lawman Marshall Zane Cooper (James Garner). The supporting cast features Graham Greene, James Coburn, Alfred Molina and a large number of cameo appearances by Western film actors, country music stars and other actors.\\r\\nThe film received a favorable critical reception for its light-hearted charm, and was financially successful, earning over $180 million during its cinematic run. Costume designer April Ferry was nominated for the Academy Award for Best Costume Design.\\r\\n\\r\\n\\r\\nIn the American Old West, wisecracking gambler Bret Maverick (Mel Gibson) is on his way to a major five-card draw poker tournament. Maverick wants the prize money and to prove he is the best card player of his time. Short $3,000 of the $25,000 tournament entry fee, Maverick travels to the town of Crystal River, intending to collect on debts and win money at card games. He encounters the ill-tempered gambler Angel (Alfred Molina), the young con artist Annabelle Bransford (Jodie Foster), and lawman Marshal Zane Cooper (James Garner).\\r\\nMaverick, Bransford and Cooper journey out of Crystal River together, overcoming runaway stagecoaches and aiding migrant evangelical settlers who have been waylaid by bandits. The settlers offer Maverick a percentage of the money they have collected to start a mission, but Maverick cannot bring himself to accept it. The trio are later cornered by a band of Indians led by Joseph (Graham Greene). His companions are unaware that Joseph and Maverick are good friends; Maverick \\"sacrifices\\" himself to allow his companions' escape. Joseph is indebted to Maverick; they scheme to swindle $1,000 from an Russian Archduke that Joseph owes to Maverick.\\r\\nAngel gets word that he needs to stop Maverick from reaching the tournament. He also learns that in Crystal River Maverick conned him. Angel assaults Maverick, leaving him for dead by hanging from a tree but the branch breaks under Maverick's weight, he boards the paddle steamer Lauren Belle and he makes it to the on-board tournament. Angel already is seated for the game and Cooper oversees the security. Maverick learns that Bransford is $4,000 short of the entry fee, and he, $2,000. The Archduke is on board so Maverick cons him for $6,000.\\r\\nBy the time of the tournament \\"break\\", there are four players remaining: Maverick, Bransford, Angel, and Commodore Duvall (James Coburn), the boat's owner and the tournament organizer. Maverick and Bransford have a tryst, someone chains his door shut and he makes it back from the break just before the game resumes at the 5 A.M. deadline. Bransford is eliminated from the tournament.\\r\\nMaverick protests when the dealer cold decks and is bottom dealing Angel's cards. Unable to switch dealers, Maverick agrees that Angel get a one card off-the-top deal. Duvall and Angel each bet \\"all in\\"; Maverick holds back looking at his discard replacement believing that what he needs will with his mental gift materialize. At the reveal, Angel has a straight flush, but Maverick's single card deal of an ace of spades, gives him the game-winning hand, a royal flush. Angel draws his gun and Cooper and Maverick shoot him and his stooges dead.\\r\\nWhen Maverick is presented the $500,000 grand prize, Cooper escapes the boat with it; Maverick prevents Duvall from shooting Cooper. At a nighttime meeting in the woods, Cooper and Duvall discuss their success: Angel was working for Duvall, and Cooper's job was to steal the money if anyone other than Duvall had won the tournament. Duvall betrays Cooper and prepares to shoot him, but they are interrupted by Maverick, who recovers the money back and leaves a single gun to settle between them their argument. It is unloaded; Cooper beats up Duvall just short of killing him and sets out after Maverick.\\r\\nCooper finds Maverick relaxing in a tub and threatens to shoot him but the pretense is dropped when they acknowledge they are father and son; they had all along conspired after the $500,000. As Cooper enjoys a bath of his own, Bransford enters and robs the two, having surmised the relationship from their similar mannerisms. After she escapes, Maverick tells Cooper that she only got half the money, the rest being hidden in his boots. He reluctantly admits that retrieving the money back will be fun.\\r\\nThere are multiple cameo appearances in the film from Western actors, people who have formerly worked with Donner, Gibson, Foster, or Garner, and other celebrities including Danny Glover (uncredited), Hal Ketchum and Corey Feldman as bank robbers; Read Morgan and Steve Kahan as card dealers; Dub Taylor as a room clerk at the opening game;[5] Art LaFleur and Leo Gordon as poker players at Maverick's first game; Paul Brinegar as the stagecoach driver; Denver Pyle as a cheating old gambler;[5] Robert Fuller, Doug McClure, Henry Darrow, William Smith and Charles Dierkop as riverboat poker players; Dan Hedaya as Twitchy, another Riverboat poker player; William Marshall as a riverboat poker player defeated by Angel; Dennis Fimple as Stuttering, a player beaten by the Commodore; Bert Remsen as an elderly riverboat gambler beaten by Maverick;[5] and Margot Kidder as missionary Margaret Mary in an uncredited appearance.[6]\\r\\nLeo Gordon had played a semi-regular supporting character in seasons one and two of the original Maverick TV show: gambler Big Mike McComb. Gordon also later wrote a few episodes of the show. Margot Kidder had been Garner's co-star in the short-lived western TV series Nichols. Danny Glover's cameo appearance references Donner's Lethal Weapon film series starring Glover and Gibson as cop partners. Their meeting in Maverick sees them share a moment of recognition,[7] and as he leaves, Glover says Roger Murtaugh's catchphrase: \\"I'm getting too old for this shit.\\"\\r\\nCountry singers also cameo including Carlene Carter as a waitress, Waylon Jennings and Kathy Mattea as a gambling couple with concealed guns, Reba McEntire, Clint Black as a sweet-faced gambler thrown overboard for cheating, and Vince Gill and his then-wife Janis Gill as spectators.\\r\\nThe steamboat used in the filmdubbed the Lauren Bellewas the Portland, the last remaining sternwheel tugboat in the US; at the time it belonged to the Oregon Maritime Museum in Portland. Over several weeks, the boat was decorated to alter its appearance to resemble a Mississippi-style gambling boat, including the addition of two decorative chimneys.[8] In August 1993, the production requested permission to film scenes of the riverboat along the Columbia River in Washington State. The artificial smoke released by the boat's chimney was considered to violate air-quality laws in Washington and Oregon and required approval for the scenes before their scheduled filming date in September 1993.[9] After filming concluded, the decorations were removed and the boat was returned to its original state.[8]\\r\\nIn Five Screenplays with Essays, Goldman describes an earlier version of the script, in which Maverick explains he has a magic ability to call the card he needs out of the deck. Although he is not able to do so successfully, the old hermit he attempts to demonstrate it for tells him that he really does have the magic in him.[10] This scene was shot with Linda Hunt playing the hermit but it was felt it did not work on the context of the rest of the movie and was cut.[11]\\r\\nThe film has received generally favorable reviews.[7] The film garnered a 67% approval rating from 52 critics?ÿ?an average rating of 6 out of 10?ÿ?on the review-aggregate website Rotten Tomatoes, which said, \\"It isn't terribly deep, but it's witty and undeniably charming, and the cast is obviously having fun.\\"[12]\\r\\nJames Berardinelli, from reelviews.net, gave the film three and a half stars out of four. He stated, \\"The strength of Maverick is the ease with which it switches from comedy to action, and back again....it's refreshing to find something that satisfies expectations.\\"[13] Reviewing it for the Chicago Sun-Times, Roger Ebert gave the film three stars out of a possible four, writing: \\"The first lighthearted, laugh-oriented family Western in a long time, and one of the nice things about it is, it doesn't feel the need to justify its existence. It acts like it's the most natural thing in the world to be a Western.\\"[5]\\r\\nThe film earned $101,631,272 (55.5%) in North America and $81,400,000 (44.5%) elsewhere for a worldwide total of $183,031,272.[4] This gross made it the number 12 highest-grossing film in North America and the number 15 highest-grossing film worldwide of 1994. As of 2013, the film is the number 6 highest grossing Western film in North America.[4]\\r\\nPre-release tracking showed that the film would open strongly,.[7] During its opening weekend in North America, Maverick earned $17.2 million million from 2,537 theaters ÿ an average of $6,798 per theater ÿ ranking as the number 1 film of the weekend,[4] and took a total of $41.8 million over its first two weeks of release.[7]\\r\\nThe movie was a box office success as it grossed over $183 million worldwide.[14][15]\\r\\nThe soundtrack featured three chart singles: \\"Renegades, Rebels and Rogues\\" by Tracy Lawrence,[16] \\"A Good Run of Bad Luck\\" by Clint Black (which also appeared on his album No Time to Kill),[17] and \\"Something Already Gone\\" by Carlene Carter. Also included on the album was an all-star rendition of \\"Amazing Grace\\", from which all royalties were donated to the Elizabeth Glaser Pediatric AIDS Foundation.[18]","input":"What river was the movie maverick filmed on?"},{"output":"Mayon","context":"Active volcanoes in the Philippines, as categorized by the Philippine Institute of Volcanology and Seismology (PHIVOLCS), include volcanoes in the country having erupted within historical times (within the last 600 years), with accounts of these eruptions documented by humans; or having erupted within the last 10,000 years (holocene) based on analyses of datable materials. However, there is no consensus among volcanologists on how to define an \\"active\\" volcano. As of 2012[update], PHIVOLCS lists 23 volcanoes as active in the Philippines, 21 of which have historical eruptions; one, Cabalian, which is strongly fumarolic volcano[further explanation needed]; and one, Leonard Kniaseff, which was active 1,800 years ago (C14).[1]\\r\\nThere are 50 Philippines volcanoes listed by the royal Smithsonian Institution's Global Volcanism Program (GVP) at present,[2] of which 20 are categorized as \\"historical\\" and 59 as \\"Holocene\\".[2] The GVP lists volcanoes with historical, Holocene eruptions, or possibly older if strong signs of volcanism are still evident through thermal features like fumaroles, hot springs, mud pots, etc.[3]\\r\\nMayon in Albay is the most?active volcano in the?Philippines\\r\\nTaal in Batangas\\r\\nKanlaon in Negros?island\\r\\nBulusan in Sorsogon\\r\\nSmith in Calayan\\r\\nHibok?Hibok in Camiguin\\r\\nPinatubo in Zambales\\r\\nMusuan in Bukidnon\\r\\nThe list below showing 25 active volcanoes in the Philippines was based on the PHIVOLCS list with some included from the GVP. The number is not definite and depends on someone's definition of \\"active\\" or historical timeframe. Descriptions under Eruption were based on the GVP website. The frequency of Historical Eruptions excludes questionable or Uncertain accounts based on the two sources mentioned.","input":"What are the three most active volcanoes in the philippines?"},{"output":"13 June 2003","context":"Twenty20 cricket, sometimes written Twenty-20, and often abbreviated to T20, is a short form of cricket. At the professional level, it was originally introduced by the England and Wales Cricket Board (ECB) in 2003 for the inter-county competition in England and Wales.[1] In a Twenty20 game the two teams have a single innings each, which is restricted to a maximum of 20 overs. Together with first-class and List A cricket, Twenty20 is one of the three current forms of cricket recognised by the International Cricket Council (ICC) as being at the highest international or domestic level. A typical Twenty20 game is completed in about three hours, with each innings lasting around 75ÿ90 minutes and a 10ÿ20-minute interval. This is much shorter than previously-existing forms of the game, and is closer to the timespan of other popular team sports. It was introduced to create a fast-paced form of the game which would be attractive to spectators at the ground and viewers on television.\\r\\nSince its inception the game has been very successful resulting in its spread around the cricket world. On most international tours there is at least one Twenty20 match and all Test-playing nations have a domestic cup competition. The inaugural ICC World Twenty20 was played in South Africa in 2007 with India winning by five runs against Pakistan in the final.[2] Pakistan won the second tournament in 2009,[3] and England won the title in the West Indies 2010. West Indies won in 2012, with Sri Lanka winning the 2014 tournament. West Indies are the reigning champions, winning the 2016 competition, and in doing so, became the first nation to win the tournament twice.\\r\\n\\r\\n\\r\\nWhen the Benson & Hedges Cup ended in 2002, the ECB needed another one day competition to fill its place. Cricketing authorities were looking to boost the game's popularity with the younger generation in response to dwindling crowds and reduced sponsorship. It was intended to deliver fast paced, exciting cricket accessible to thousands of fans who were put off by the longer versions of the game. Stuart Robertson, the marketing manager of the ECB, proposed a 20 over per innings game to county chairmen in 2001 and they voted 11ÿ7 in favour of adopting the new format.[4]\\r\\nThe first official Twenty20 matches were played on 13 June 2003 between the English counties in the Twenty20 Cup.[5] The first season of Twenty20 in England was a relative success, with the Surrey Lions defeating the Warwickshire Bears by 9 wickets in the final to claim the title.[6] The first Twenty20 match held at Lord's, on 15 July 2004 between Middlesex and Surrey, attracted a crowd of 27,509, the highest attendance for any county cricket game at the ground ÿ other than a one-day final ÿ since 1953.[7]\\r\\nThirteen teams from different parts of the country participated in Pakistan's inaugural competition in 2004, with Faisalabad Wolves the first winners. On 12 January 2005 Australia's first Twenty20 game was played at the WACA Ground between the Western Warriors and the Victorian Bushrangers. It drew a sell-out crowd of 20,000, which was the first time in nearly 25 years the ground had been completely sold out.[8]\\r\\nStarting 11 July 2006 19 West Indies regional teams competed in what was named the Stanford 20/20 tournament. The event was financially backed by billionaire Allen Stanford, who gave at least US$28,000,000 funding money. It was intended that the tournament would be an annual event. Guyana won the inaugural event, defeating Trinidad and Tobago by 5 wickets, securing US$1,000,000 in prize money.[9][10]\\r\\nOn 5 January 2007 Queensland Bulls played the New South Wales Blues at The Gabba, Brisbane. A crowd of 11,000 was expected based on pre-match ticket sales. However, an unexpected 16,000 turned up on the day to buy tickets, causing disruption and confusion for surprised Gabba staff as they were forced to throw open gates and grant many fans free entry. Attendance reached 27,653.[11]\\r\\nFor 1 February 2008 Twenty20 match between Australia and India, 85,824[12] people attended the match at the Melbourne Cricket Ground involving the Twenty20 World Champions against the ODI World Champions.\\r\\nThe Stanford Super Series was held in October 2008 between Middlesex and Trinidad and Tobago, the respective winners of the English and Caribbean Twenty20 competitions, and a Stanford Superstars team formed from West Indies domestic players; Trinidad and Tobago won the competition, securing US$280,000 prize money.[13][14] On 1 November, the Stanford Superstars played England in what was expected to be the first of five fixtures in as many years with the winner claiming a US$20,000,000 in each match. The Stanford Superstars won the first match,[15] however no further fixtures were held as Allen Stanford was charged with fraud in 2009.[16]\\r\\nThe first Twenty20 International match was held on 5 August 2004 between the England and New Zealand women's teams with New Zealand winning by nine runs[17]\\r\\nOn 17 February 2005 Australia defeated New Zealand in the first men's full international Twenty20 match, played at Eden Park in Auckland. The game was played in a light-hearted manner ÿ both sides turned out in kit similar to that worn in the 1980s, the New Zealand team's a direct copy of that worn by the Beige Brigade. Some of the players also sported moustaches/beards and hair styles popular in the 1980s taking part in a competition amongst themselves for best retro look, at the request of the Beige Brigade. Australia won the game comprehensively, and as the result became obvious towards the end of the NZ innings, the players and umpires took things less seriously ÿ Glenn McGrath jokingly replayed the Trevor Chappell underarm incident from a 1981 ODI between the two sides, and Billy Bowden showed him a mock red card (red cards are not normally used in cricket) in response.\\r\\nThe first Twenty20 international in England was played between England and Australia at the Rose Bowl in Hampshire on 13 June 2005, which England won by a margin of 100 runs, a record victory which lasted until 2007.[18]\\r\\nOn 9 January 2006 Australia and South Africa met in the first international Twenty20 game in Australia. In a first, each player's nickname appeared on the back of his uniform, rather than his surname. The international match drew a crowd of 38,894 people at The Gabba. Australia convincingly won the match with man of the match Damien Martyn scoring 96 runs.\\r\\nOn 16 February 2006 New Zealand defeated West Indies in a tie-breaking bowl-out 3ÿ0; 126 runs were scored apiece in the game proper. The game was the last international match played by Chris Cairns ÿ NZC handed out life-size cardboard masks of his face to patrons as they entered the ground.\\r\\nEvery two years an ICC World Twenty20 tournament is to take place, except in the event of an ICC Cricket World Cup being scheduled in the same year, in which case it will be held the year before. The first tournament was in 2007 in South Africa where India defeated Pakistan in the final. Two Associate teams had played in the first tournament, selected through the 2007 ICC World Cricket League Division One, a 50-over competition. In December 2007 it was decided to hold a qualifying tournament with a 20-over format to better prepare the teams. With six participants, two would qualify for the 2009 World Twenty20 and would each receive $250,000 in prize money.[19] The second tournament was won by Pakistan who beat Sri Lanka by 8 wickets in England on 21 June 2009. The 2010 ICC World Twenty20 tournament was held in West Indies in May 2010, where England defeated Australia by 7 wickets. The 2012 ICC World Twenty20 was won by the West-Indies, by defeating Sri Lanka at the finals. It was the first time in Cricket history when a T20 World Cup tournament took place in an Asian country. The 2014 ICC World Twenty20 was won by Sri Lanka, by defeating India at the finals, where the tournament was held in Bangladesh. The 2016 ICC World Twenty20 was won by West-Indies, by defeating England at the finals, where the tournament was held in India.\\r\\nTwenty20 cricket is claimed to have resulted in a more athletic and explosive form of cricket. Indian fitness coach Ramji Srinivasan declared in an interview with the Indian fitness website Takath.com, that Twenty20 had \\"raised the bar\\" in terms of fitness levels for all players, demanding higher levels of strength, speed, agility and reaction time from all players regardless of role in the team.[20] Matthew Hayden credited retirement from international cricket with aiding his performance in general and fitness in particular in the Indian Premier League.[21]\\r\\nIn June 2009, speaking at the annual Cowdrey Lecture at Lord's, former Australian wicketkeeper Adam Gilchrist pushed for Twenty20 to be made an Olympic sport. \\"It would,\\" he said, \\"be difficult to see a better, quicker or cheaper way of spreading the game throughout the world.\\"[22]\\r\\nTwenty20 match format is a form of limited overs cricket in that it involves two teams, each with a single innings, the key feature being that each team bats for a maximum of 20 overs. In terms of visual format, the batting team members do not arrive from and depart to traditional dressing rooms, but come and go from a bench (typically a row of chairs) visible in the playing arena, analogous to association football's technical area or a baseball dugout.[23]\\r\\nThe Laws of cricket apply to Twenty20, with some exceptions:[24]\\r\\nCurrently, if the match ends with the scores tied and there must be a winner, the tie is broken with a one over per side Eliminator[25] or Super Over:[26][27] Each team nominates three batsmen and one bowler to play a one-over per side \\"mini-match\\". The team which bats second in the match bats first in the Super Over.[28][29] In turn, each side bats one over bowled by the one nominated opposition bowler, with their innings over if they lose two wickets before the over is completed. The side with the higher score from their Super Over wins. If the super over also ends up in a tie, the team that has scored the most boundaries (4s+6s) in the 20 overs wins.\\r\\nIn the Australian domestic competition the Big Bash League the Super Over is played slightly differently, with no 2-wicket limit, and if the super over is also tied then a \\"countback\\" is used, with scores after the fifth ball for each team being used to determine the result. If it is still tied, then the countback goes to 4 balls and so on.[30] The latest Super Over to decide a match was between the Sydney Sixers winning against the Brisbane Heat on the 25th January 2017, in the Big Bash League at the Brisbane Cricket Ground, with the Sixers winning 0/22 to 0/15 in the Super Over after tying on 164.[31]\\r\\nTied Twenty20 matches were previously decided by a bowl-out.[32]\\r\\nWomen's and men's Twenty20 Internationals have been played since 2004 and 2005 respectively. To date, 20 nations have played the format, including all test playing nations. This considers only matches between teams with Twenty20 International status, which is limited by the International Cricket Council to a small number of top teams.\\r\\nIn November 2011, the ICC released the first Twenty20 International rankings for the men's game, based on the same system as the Test and ODI rankings. The rankings cover a 2 to 3-year period, with matches since the most recent 1 August weighted fully, matches in the preceding 12 months weighted two-thirds, and matches in the 12 months preceding that weighted one-third. To qualify for the rankings, teams must have played at least eight Twenty20 Internationals in the ranking period.[33][34]\\r\\nThe ICC do not maintain a separate Twenty20 ranking for the women's game, instead aggregating performance over all three forms of the game into one overall women's teams ranking.[35]\\r\\nThis is a list of the current Twenty20 domestic competitions in several of the leading cricket countries.\\r\\nI |-\\r\\nSee also: List of Twenty20 International records","input":"When was the first t20 cricket match played?"},{"output":"in the 1980s","context":"Experiments have been conducted on automating cars since at least the 1920s;[1] promising trials took place in the 1950s and work has proceeded since then. The first self-sufficient and truly autonomous cars appeared in the 1980s, with Carnegie Mellon University's Navlab[2] and ALV[3][4] projects in 1984 and Mercedes-Benz and Bundeswehr University Munich's Eureka Prometheus Project [5] in 1987. Since then, numerous major companies and research organizations have developed working prototype autonomous vehicles including Mercedes-Benz, General Motors, Continental Automotive Systems, Autoliv Inc., Bosch, Nissan, Toyota, Audi, Volvo, Vislab from University of Parma, Oxford University and Google.[5][6][7][8][9][10][11][12][13] In July 2013, Vislab demonstrated BRAiVE, a vehicle that moved autonomously on a mixed traffic route open to public traffic.[14]\\r\\nAs of 2013, four U.S. states have passed laws permitting autonomous cars: Nevada, Florida, California, and Michigan.[15][16][17][18][19] In Europe, cities in Belgium, France, Italy and the UK are planning to operate transport systems for driverless cars,[20][21][22] and Germany, the Netherlands, and Spain have allowed testing robotic cars in traffic.\\r\\n\\r\\n\\r\\nIn 1925, Houdina Radio Control demonstrated the radio-controlled \\"American Wonder\\" on New York City streets, traveling up Broadway and down Fifth Avenue through the thick of the traffic jam. The American Wonder was a 1926 Chandler that was equipped with a transmitting antennae on the tonneau and was operated by a second car that followed it and sent out radio impulses which were caught by the transmitting antennae. The antennae introduced the signals to circuit-breakers which operated small electric motors that directed every movement of the car.\\r\\nAchen Motor, a distributor of cars in Milwaukee and surrounding territory, used Francis' invention under the name \\"Phantom Auto\\" and demonstrated it in December 1926 on the streets of Milwaukee.[1] It was demonstrated again in June 1932 on the streets of Fredericksburg as a feature attraction of Bigger Bargain Day in which most of the merchants of the city were participating.[23]\\r\\nAn early representation of an automated guided car was Norman Bel Geddes's Futurama exhibit sponsored by General Motors at the 1939 World's Fair, which depicted radio-controlled electric cars that were propelled via electromagnetic fields provided by circuits embedded in the roadway.[24]\\r\\nBel Geddes later outlined his vision in his book, Magic Motorways (1940), promoting advances in highway design and transportation, foreshadowing the Interstate Highway System, and arguing that humans should be removed from the process of driving. Bel Geddes forecasted these advances to be a reality in 1960.[25][26]\\r\\nIn 1953, RCA Labs successfully built a miniature car that was guided and controlled by wires that were laid in a pattern on a laboratory floor. The system sparked the imagination of Leland M. Hancock, traffic engineer in the Nebraska Department of Roads, and of his director, L. N. Ress, state engineer. The decision was made to experiment with the system in actual highway installations.\\r\\nIn 1957, a full size system was successfully demonstrated by RCA Labs and the State of Nebraska on a 400-foot strip of public highway at the intersection of U.S. Route 77 and Nebraska Highway 2, then just outside Lincoln, Nebraska. A series of experimental detector circuits buried in the pavement were a series of lights along the edge of the road. The detector circuits were able to send impulses to guide the car and determine the presence and velocity of any metallic vehicle on its surface. A previous test installation of the system in September 1954 along U.S. Route 73 and U.S. Route 75 in Cass County, Nebraska was utilized as an experimental traffic counter. It was developed in collaboration with General Motors, who paired two standard models with equipment consisting of special radio receivers and audible and visual warning devices that were able to simulate automatic steering, accelerating and brake control.[27][28][29]\\r\\nIt was further demonstrated on 5 June 1960, at RCA Lab's headquarter in Princeton, New Jersey, where reporters were allowed to \\"drive\\" on the cars. Commercialization of the system was expected to happen by 1975.[30][31]\\r\\nAlso during the 1950s throughout the 1960s, General Motors showcased the Firebirds, a series of experimental cars that were described to have an \\"electronic guide system [that] can rush it over an automatic highway while the driver relaxes\\".\\r\\nIn 1960, Ohio State University's Communication and Control Systems Laboratory launched a project to develop driverless cars which were activated by electronic devices imbedded in the roadway. Head of the project, Dr. Robert L. Cosgriff, claimed in 1966 that the system could be ready for installation on a public road in 15 years.[32]\\r\\nIn the early 1960s, the Bureau of Public Roads considered the construction of an experimental electronically controlled highway. Four states ÿ Ohio, Massachusetts, New York and California ÿ were bidding for the construction.[33] In August 1961, Popular Science reported on the Aeromobile 35B, an air-cushion vehicle (ACV) that was invented by William Bertelsen and was envisioned to revolutionize the transportation system, with personal self-driving hovering cars that could speed up to 1,500MPH.\\r\\nDuring the 1960s, the United Kingdom's Transport and Road Research Laboratory tested a driverless Citroen DS that interacted with magnetic cables that were embedded in the road. It went through a test track at 80 miles per hour (130?km/h) without deviation of speed or direction in any weather conditions, and in a far more effective way than by human control. Research continued in the '70s with cruise control devices activated by signals in the cabling beneath the tracks. According to cost benefit analyses that were made, adoption of system on the British motorways would be repaid by end of the century, increase the road capacity by at least 50% and prevent around 40% of the accidents. Funding for these experiments was withdrawn by the mid-1970s.[34][35][36]\\r\\nAlso during the 1960s and the 1970s, Bendix Corporation developed and tested driverless cars that were powered and controlled by buried cables, with wayside communicators relaying computer messages. Stanford demonstrated its Artificial Intelligence Laboratory Cart, a small wheeled robot that once accidentally navigated onto a nearby road.\\r\\nPreliminary research into the intelligent automated logic needed for autonomous cars was conducted at the Coordinated Science Laboratory of the University of Illinois in the early to mid 1970s.[37]\\r\\nIn the 1980s, a vision-guided Mercedes-Benz robotic van, designed by Ernst Dickmanns and his team at the Bundeswehr University Munich in Munich, Germany, achieved a speed of 39 miles per hour (63?km/h) on streets without traffic.[5] Subsequently, EUREKA conducted the ?749,000,000 Prometheus Project on autonomous vehicles from 1987 to 1995.\\r\\nIn the same decade, the DARPA-funded Autonomous Land Vehicle (ALV) project in the United States made use of new technologies developed by the University of Maryland, Carnegie Mellon University, the Environmental Research Institute of Michigan, Martin Marietta and SRI International. The ALV project achieved the first road-following demonstration that used lidar, computer vision and autonomous robotic control to direct a robotic vehicle at speeds of up to 19 miles per hour (31?km/h). In 1987, HRL Laboratories (formerly Hughes Research Labs) demonstrated the first off-road map and sensor-based autonomous navigation on the ALV. The vehicle traveled over 2,000 feet (610?m) at 1.9 miles per hour (3.1?km/h) on complex terrain with steep slopes, ravines, large rocks, and vegetation. By 1989, Carnegie Mellon University had pioneered the use of neural networks to steer and otherwise control autonomous vehicles,[38] forming the basis of contemporary control strategies.\\r\\nIn 1991, the United States Congress passed the ISTEA Transportation Authorization bill, which instructed USDOT to \\"demonstrate an automated vehicle and highway system by 1997.\\" The Federal Highway Administration took on this task, first with a series of Precursor Systems Analyses and then by establishing the National Automated Highway System Consortium (NAHSC). This cost-shared project was led by FHWA and General Motors, with Caltrans, Delco, Parsons Brinkerhoff, Bechtel, UC-Berkeley, Carnegie Mellon University, and Lockheed Martin as additional partners. Extensive systems engineering work and research culminated in Demo '97 on I-15 in San Diego, California, in which about 20 automated vehicles, including cars, buses, and trucks, were demonstrated to thousands of onlookers, attracting extensive media coverage. The demonstrations involved close-headway platooning intended to operate in segregated traffic, as well as \\"free agent\\" vehicles intended to operate in mixed traffic. Other carmakers were invited to demonstrate their systems, such that Toyota and Honda also participated. While the subsequent aim was to produce a system design to aid commercialization, the program was cancelled in the late 1990s due to tightening research budgets at USDOT. Overall funding for the program was in the range of $90 million.[39]\\r\\nIn 1994, the twin robot vehicles VaMP and Vita-2 of Daimler-Benz and Ernst Dickmanns of UniBwM drove more than 620 miles (1,000?km) on a Paris three-lane highway in standard heavy traffic at speeds up to 81 miles per hour (130?km/h), albeit semi-autonomously with human interventions. They demonstrated autonomous driving in free lanes, convoy driving, and lane changes with autonomous passing of other cars.[citation needed] That same year, Lucas Industries developed parts for a semi-autonomous car in a project that was funded by Jaguar Cars, Lucas, and the UK Department of Trade and Industry.[40]\\r\\nIn 1995, Carnegie Mellon University's Navlab project completed a 3,100 miles (5,000?km) cross-country journey, of which 98.2% was autonomously controlled, dubbed \\"No Hands Across America\\".[41] This car, however, was semi-autonomous by nature: it used neural networks to control the steering wheel, but throttle and brakes were human-controlled, chiefly for safety reasons. Also in 1995, Dickmanns' re-engineered autonomous S-Class Mercedes-Benz undertook a 990 miles (1,590?km) journey from Munich in Bavaria, Germany to Copenhagen, Denmark and back, using saccadic computer vision and transputers to react in real time. The robot achieved speeds exceeding 109 miles per hour (175?km/h) on the German Autobahn, with a mean time between human interventions of 5.6 miles (9.0?km), or 95% autonomous driving. It drove in traffic, executing manoeuvres to pass other cars. Despite being a research system without emphasis on long distance reliability, it drove up to 98 miles (158?km) without human intervention.[citation needed]\\r\\nIn 1996, (now Professor) Alberto Broggi of the University of Parma launched the ARGO Project, which worked on enabling a modified Lancia Thema to follow the normal (painted) lane marks in an unmodified highway.[42] The culmination of the project was a journey of 1,200 miles (1,900?km) over six days on the motorways of northern Italy dubbed Mille Miglia in Automatico (\\"One thousand automatic miles\\"), with an average speed of 56 miles per hour (90?km/h).[43] The car operated in fully automatic mode for 94% of its journey, with the longest automatic stretch being 34 miles (55?km). The vehicle had only two black-and-white low-cost video cameras on board and used stereoscopic vision algorithms to understand its environment.\\r\\nThe ParkShuttle, billed as the worlds first driverless vehicle,[44] is an automated people mover which uses artificial reference points (magnets) embedded in the road surface to verify its position. Two pilot projects were started in the Netherlands, at Schiphol Airport (December 1997) and business park Rivium (1999). Both carried members of the general public and as such claim stake to the title to the first driverless vehicles. The vehicles are autonomous, do not feature a steering wheel or pedals, nor do they have a safety driver or steward on board. The drive at grade, on a dedicated lane which does feature intersections with pedestrians, bicyclists and cars.[45]\\r\\nThe US Government funded three military efforts known as Demo I (US Army), Demo II (DARPA), and Demo III (US Army). Demo III (2001)[46] demonstrated the ability of unmanned ground vehicles to navigate miles of difficult off-road terrain, avoiding obstacles such as rocks and trees. James Albus at the National Institute of Standards and Technology provided the Real-Time Control System which is a hierarchical control system. Not only were individual vehicles controlled (e.g. throttle, steering, and brake), but groups of vehicles had their movements automatically coordinated in response to high level goals.\\r\\nIn the first Grand Challenge held in March 2004, DARPA (the Defense Advanced Research Projects Agency) offered a $1 million prize to any team of robotic engineers which could create an autonomous car capable of finishing a 150-mile course in the Mojave Desert. No team was successful in completing the course.[47]\\r\\nIn October 2005, the second DARPA Grand Challenge was again held in a desert environment. GPS points were placed and obstacle types were located in advance.[48] This year, five vehicles completed the course.\\r\\nIn November 2007, DARPA again sponsored Grand Challenge III, but this time the Challenge was held in an urban environment. In this race, a 2007 Chevy Tahoe autonomous car from Carnegie Mellon University earned the 1st place. Prize competitions as DARPA Grand Challenges gave students and researchers an opportunity to research a project on autonomous cars to reduce the burden of transportation problems such as traffic congestion and traffic accidents that increasingly exist on many urban residents.[48]\\r\\nIn January 2006, the United Kingdom's 'Foresight' think-tank revealed a report which predicts RFID-tagged driverless cars on UK's roads by 2056 and the Royal Academy of Engineering claimed that driverless trucks could be on Britain's motorways by 2019.[49][50]\\r\\nIn 1998, Willie Jones [51] states that many automakers consider autonomous technology as part of their research yearly. He notes \\"In May 1998, Toyota became the first to introduce an Adaptive Cruise Control (ACC) system on a production vehicle when it unveiled a laser-based system for its Progres compact luxury sedan, which it sold in Japan\\".[52]\\r\\nAutonomous vehicles have also been used in mining. In December 2008, Rio Tinto Alcan began testing the Komatsu Autonomous Haulage System ÿ the world's first commercial autonomous mining haulage system ÿ in the Pilbara iron ore mine in Western Australia. Rio Tinto has reported benefits in health, safety, and productivity. In November 2011, Rio Tinto signed a deal to greatly expand its fleet of driverless trucks.[53]\\r\\nGoogle began developing its self-driving cars in 2009, but did so privately, avoiding public announcement of the program until a later time.[54]\\r\\nMany major automotive manufacturers, including General Motors, Ford, Mercedes Benz, Volkswagen, Audi, Nissan, Toyota, BMW, and Volvo, are testing driverless car systems as of 2013. BMW has been testing driverless systems since around 2005,[55][56] while in 2010, Audi sent a driverless Audi TTS to the top of Pikes Peak at close to race speeds.[7] In 2011, GM created the EN-V (short for Electric Networked Vehicle), an autonomous electric urban vehicle.[57] In 2012, Volkswagen began testing a \\"Temporary Auto Pilot\\" (TAP) system that will allow a car to drive itself at speeds of up to 80 miles per hour (130?km/h) on the highway.[58] Ford has conducted extensive research into driverless systems and vehicular communication systems.[59] In January 2013, Toyota demonstrated a partially self-driving car with numerous sensors and communication systems.[9] Other programs in the field include the 2GetThere passenger vehicles from the Netherlands and the DARPA Grand Challenge in the USA; some plans for bimodal public transport systems include autonomous cars as a component.[60]\\r\\nIn 2010, Italy's VisLab from the University of Parma, led by Professor Alberto Broggi, ran the VisLab Intercontinental Autonomous Challenge (VIAC), a 9,900-mile (15,900?km) test run which marked the first intercontinental land journey completed by autonomous vehicles. Four electric vans made a 100-day journey, leaving Parma, Italy, on 20 July 2010, and arriving at the Shanghai Expo in China on 28 October.\\r\\nThe research project is co-funded by the European Union CORDIS program.[62]\\r\\nIn 2010, the Institute of Control Engineering of the Technische Universit?t Braunschweig demonstrated the first autonomous driving on public streets in Germany with the research vehicle Leonie. It was the first car licensed for autonomous driving on the streets and highways in Germany.[63]\\r\\nIn 2011, the Freie Universit?t Berlin developed two autonomous cars to drive in the innercity traffic of Berlin in Germany. Led by the AutoNOMOS group, the two vehicles Spirit of Berlin and MadeInGermany handled intercity traffic, traffic lights and roundabouts between International Congress Centrum and Brandenburg Gate. It was financed by the German Federal Ministry of Education and Research.[64]\\r\\nOn May 1, 2012, a 22?km (14?mi) driving test was administered to a Google self-driving car by Nevada motor vehicle examiners in a test route in the city of Las Vegas, Nevada. The autonomous car passed the test, but was not tested at roundabouts, no-signal railroad crossings, or school zones.[54]\\r\\nIn 2013, on July 12, VisLab conducted another pioneering test of autonomous vehicles, during which a robotic vehicle drove in downtown Parma with no human control, successfully navigating roundabouts, traffic lights, pedestrian crossings and other common hazards.[65]\\r\\nIn August 2013, Daimler R&D with Karlsruhe Institute of Technology/FZI, made a Mercedes-Benz S-class vehicle with close-to-production stereo cameraS[66] and radars drive completely autonomously for about 100?km from Mannheim to Pforzheim, Germany, following the historic Bertha Benz Memorial Route.[67][68]\\r\\nIn August 2013 Nissan announced its plans to launch several driverless cars by 2020. The company is building in Japan a dedicated autonomous driving proving ground, to be completed in 2014. Nissan installed its autonomous car technology in a Nissan Leaf electric car for demonstration purposes. The car was demonstrated at Nissan 360 test drive event held in California in August 2013.[69][70] In September 2013, the Leaf fitted the prototype Advanced Driver Assistance System was granted a license plate that allows to drive it on Japanese public roads. The testing car will be used by Nissan engineers to evaluate how its in-house autonomous driving software performs in the real world. Time spent on public roads will help refine the cars software for fully automated driving.[71] The autonomous Leaf was demonstrated on public roads for the first time at a media event held in Japan in November 2013. The Leaf drove on the Sagami Expressway in Kanagawa prefecture, near Tokyo. Nissan vice chairman Toshiyuki Shiga and the prefectures Governor, Yuji Kuroiwa, rode in the car during the test.[72][73]\\r\\nAvailable in 2013, the 2014 Mercedes S-Class has options for autonomous steering, lane keeping, acceleration/braking, parking, accident avoidance, and driver fatigue detection, in both city traffic and highway speeds of up to 124 miles (200?km) per hour.[74][75][76][77]\\r\\nReleased in 2013, the 2014 Infiniti Q50 uses cameras, radar and other technology to deliver various lane-keeping, collision avoidance and cruise control features. One reviewer remarked, \\"With the Q50 managing its own speed and adjusting course, I could sit back and simply watch, even on mildly curving highways, for three or more miles at a stretch,\\" adding that he wasn't touching the steering wheel or pedals.[78]\\r\\nAlthough as of 2013, fully autonomous vehicles are not yet available to the public, many contemporary car models have features offering limited autonomous functionality. These include adaptive cruise control, a system that monitors distances to adjacent vehicles in the same lane, adjusting the speed with the flow of traffic; lane assist, which monitors the vehicle's position in the lane, and either warns the driver when the vehicle is leaving its lane, or, less commonly, takes corrective actions; and parking assist, which assists the driver in the task of parallel parking.[79]\\r\\nIn January 2014, Induct Technology's Navia shuttle became the first self-driving vehicle to be available for commercial sale.[80] Limited to 12.5 miles per hour (20.1?km/h), the open-air electric vehicle resembles a golf cart and seats up to eight people. It is intended to shuttle people around \\"pedestrianized city centers, large industrial sites, airports, theme parks, university campuses or hospital complexes.\\"[81]\\r\\nOn May 27, 2014, Google[82] announced plans to unveil 100 autonomous car prototypes built from scratch inside Google's secret X lab, as manifestations of years of work that began by modifying existing vehicles, along with, \\"in the next couple of years\\" according to Google in the above blog post, a pilot program similar to that which was used for the Cr-48 Chromebook back in 2010.\\r\\nIn October 2014 Tesla Motors announced its first version of AutoPilot. Model S cars equipped with this system are capable of lane control with autonomous steering, braking and speed limit adjustment based on signals image recognition. The system also provide autonomous parking and is able to receive software updates to improve skills over time.[83] As of March?2015[update], Tesla has been testing the autopilot system on the highway between San Francisco and Seattle with a driver but letting the car to drive the car almost unassisted.[84]\\r\\nIn February 2015, the UK Government announced it would oversee public trials of the LUTZ Pathfinder driverless pod in Milton Keynes.[85]\\r\\nIn March 2015 Tesla Motors announced that it will introduce its Autopilot technology by mid 2015 through a software update for the cars equipped with the systems that allow autonomous driving.[84] Some industry experts have raised questions about the legal status of autonomous driving in the U.S. and whether Model S owner would violate current state regulations when using the autopilot function. The few states that have passed laws allowing autonomous cars on the road limit their use for testing purposes, not the use by the general public. Also, there are questions about the liability for autonomous cars in case there is a mistake.[84] A Tesla spokesman said there is \\"nothing in our autopilot system that is in conflict with current regulations.\\" \\"We are not getting rid of the pilot. This is about releasing the driver from tedious tasks so they can focus and provide better input.\\" Google's director of self-driving cars at the company said he does not think there is a regulatory block as far as the self-driving vehicle met crash-test and other safety standards. A spokesman for the National Highway Traffic Safety Administration (NHTSA) said that \\"any autonomous vehicle would need to meet applicable federal motor vehicle safety standards\\" and the NHTSA \\"will have the appropriate policies and regulations in place to ensure the safety of this type of vehicles.\\" [84]\\r\\nIn mid October 2015 Tesla Motors rolled out version 7 of their software in the U.S. that included Autopilot capability.[88] On January 9, 2016, Tesla rolled out version 7.1 as an over-the-air update, adding a new \\"summon\\" feature that allows cars to self-park at parking locations without the driver in the car.[89] Tesla's autonomous driving features are ahead of production cars, and can be classified as is somewhere between level 2 and level 3 under the NHTSA five levels of vehicle automation. At this levels the car can act autonomously but requires the full attention of the driver, who must be prepared to take control at a moment's notice.[90][91][92] Autopilot should be used only on limited-access highways, and sometimes it will fail to detect lane markings and disengage itself. In urban driving the system will not read traffic signals or obey stop signs. The system also does not detect pedestrians or cyclists.[86]\\r\\nIn February 2015 Volvo Cars announced its plans to lease 100 XC90 SUVs fitted with Drive Me Level 3 automation technology to residents of Gothenburg in 2017.[87][93] The Drive Me XC90s will be equipped with Nvidias Drive PX 2 supercomputer, and will be driven autonomously in certain weather conditions and on one road that loops around the city. As part of Volvo's Drive Me project, the 100 cars in the Sweden test will have an interface called IntelliSafe Auto Pilot, a feature that will let drivers activate and deactivate the autonomous mode through specially-designed paddles on the steering wheel. The interface was developed to oversee how drivers will transfer control to a cars autonomous driving mode in future cars. Volvo considers autonomous driving systems as the tool that will help it meet the company's goal to have no one seriously injured or killed in a new Volvo by the year 2020.[94]\\r\\nIn April 2015, a car designed by Delphi Automotive became the first automated vehicle to complete a coast-to-coast journey across North America. It traveled from San Francisco to New York, under computer control for 99% of that distance.[96]\\r\\nIn July 2015, Google announced that the test vehicles in its driverless car project had been involved in 14 minor accidents since the project's inception in 2009. Chris Urmson, the project leader, said that all of the accidents were caused by humans driving other cars, and that 11 of the mishaps were rear-end collisions. \\"Our self-driving cars are being hit surprisingly often by other drivers who are distracted and not paying attention to the road. Thats a big motivator for us.\\" Over the six years of the project's existence the test vehicles had logged nearly 2 million miles on the road.[95]\\r\\nIn April 2016 Volvo announced plans to deploy 100 XC90 self-driving cars to test them in everyday driving conditions in China in 2017.[94] Also in April 2016, the carmaker announced plans to begin a trial in London in 2017 with 100 Volvo XC90 plug-in hybrids fitted with Drive Me technology. The XC90s will be leased to everyday users, and the self-driving cars will log each and every journey, passing on that data to Thatcham Research, which will conduct a thorough analysis to examine how the car behaves in everyday situations as well as understanding how other road users and the cars occupants respond to autonomous driving decisions made by the car.[97]\\r\\nThe first known fatal accident involving a vehicle being driven by itself took place in Williston, Florida on 7 May 2016 while a Tesla Model S electric car was engaged in Autopilot mode. The driver was killed in a crash with a large 18-wheel tractor-trailer. On 28 June 2016 the National Highway Traffic Safety Administration (NHTSA) opened a formal investigation into the accident working with the Florida Highway Patrol. According to the NHTSA, preliminary reports indicate the crash occurred when the tractor-trailer made a left turn in front of the Tesla at an intersection on a non-controlled access highway, and the car failed to apply the brakes. The car continued to travel after passing under the trucks trailer.[98][99][100] The NHTSA's preliminary evaluation was opened to examine the design and performance of any automated driving systems in use at the time of the crash, which involves a population of an estimated 25,000 Model S cars.[101]\\r\\nIn August 2016 Singapore launched the first self-driving taxi service, provided by nuTonomy.[102]\\r\\nStarting October 2016, all Tesla cars are built with the necessary hardware to allow full self-driving capability at a safety level (SAE Level 5). The hardware includes eight surround cameras and twelve ultrasonic sensors, in addition to the forward-facing radar with enhanced processing capabilities.[103] The system will operate in \\"shadow mode\\" (processing without taking action) and send data back to Tesla to improve its abilities until the software is ready for deployment via over-the-air upgrades.[104] Full autonomy is only likely after millions of miles of testing, and approval by authorities. Tesla Motors says it expects to enable full self-driving by the end of 2017, however, as of March 2018, this has not happened yet.[105]\\r\\nOn June 4, 2017, Audi stated that its new A8 will be fully self-driving for speeds up to 60?km/h using its Audi AI. Contrary to other cars, the driver will not have to do safety checks such as touching the steering wheel every 15 seconds to use this feature. The Audi A8 will therefore be the first production car to reach level 3 autonomous driving, meaning that the driver can safely turn their attention away from driving tasks, e.g. the driver can text or watch a movie. Audi will also be the first manufacturer to use a 3D LIDAR system in addition to cameras and ultrasonic sensors for their AI.[106][107]\\r\\nIn March 2018, a Arizona pedestrian was hit and killed by an Uber self-driving car in what was believed to be the first reported fatal crash involving a self-driving vehicle and a pedestrian in the US.[108] Later in the same month, San Francisco police issued a ticket to the passenger of a self-driving car that had failed to yield to a pedestrian in a crosswalk.[109]","input":"When did self driving cars first come out?"},{"output":"Star Trek Beyond","context":"The Star Trek film series is the cinematic branch of the Star Trek media franchise, which began in 1966 as a weekly television series on NBC, running for three seasons until it was canceled in 1969 because of poor ratings. Reruns of the series proved to be wildly successful in syndication during the 1970s, which persuaded the series' then-owner, Paramount Pictures, to expand the franchise.\\r\\nParamount originally began work on a Star Trek feature film in 1975 after lobbying by the creator of the franchise, Gene Roddenberry. The studio scrapped the project two years later in favor of creating a television series, Star Trek: Phase II, with the original cast. However, following the huge success of Star Wars and Close Encounters of the Third Kind in 1977, Paramount changed its mind again, halting production on the television series and adapting its pilot episode into a Star Trek feature film, Star Trek: The Motion Picture (1979). Five more Star Trek feature films featuring the entire original cast followed. The cast of the Star Trek sequel series Star Trek: The Next Generation (1987-1994) starred in a further four films. Upon the release of Star Trek: Nemesis on December 13, 2002, the film had grossed $67 million, a meager amount compared to the box office of previous installments. Due to the film's poor reception and box office disappointment, the series was put on a hiatus until the franchise was rebooted with a new film, directed by J. J. Abrams and released on May 8, 2009, simply titled Star Trek, serving as a reboot to the franchise with a new cast portraying younger versions of the original series' characters. A sequel to Star Trek (2009), Star Trek Into Darkness, was released in theaters on May 16, 2013. A third film, Star Trek Beyond, was released on July 22, 2016, on the franchise's 50th anniversary.\\r\\nThe Star Trek films have received 15 Academy Award nominations. Star Trek (2009) won for Best Makeup in 2010, and four of the previous films were nominated mainly in the areas of makeup, music, set design and sound design.\\r\\nThe early Star Trek films, the first to tenth film, were originally released on VHS; competitive pricing of The Wrath of Khan's videocassette helped bolster the adoption of VHS players in households.[1] Later films were also released on LaserDisc as well. For those films that did not receive an initial DVD release, Paramount released simple one-disc versions with no special features. Later, the first ten films were released in two-disc collector's versions, with The Motion Picture and The Wrath of Khan branded as \\"director's cuts\\", followed by later box set releases. All of the films are now available on Blu-ray, digital download, streaming media and video on demand.\\r\\n\\r\\n\\r\\nStar Trek creator Gene Roddenberry first suggested the idea of a Star Trek feature in 1969.[2] When the original television series was cancelled, he lobbied to continue the franchise through a film. The success of the series in syndication convinced the studio to begin work on a feature film in 1975.[3] A series of writers attempted to craft a suitably epic script, but the attempts did not satisfy Paramount, so the studio scrapped the project in 1977. Paramount instead planned on returning the franchise to its roots with a new television series, Star Trek: Phase II. The massive worldwide box office success of Star Wars in mid-1977 sent Hollywood studios to their vaults in search of similar sci-fi properties that could be adapted or re-launched to the big screen. When Columbia's Close Encounters of the Third Kind had a huge opening in late December 1977, Paramount was convinced that science fiction films other than Star Wars could do well at the box office, and production of Phase II was cancelled in favor of making a Star Trek film.\\r\\nPrincipal photography for Star Trek: The Motion Picture commenced August 7, 1978[4] with director Robert Wise helming the feature. The production encountered difficulties and slipped behind schedule,[5] with effects team Robert Abel and Associates[6] proving unable to handle the film's large amount of effects work. Douglas Trumbull was hired and given a blank check to complete the effects work in time and location;[7] the final cut of the film was completed just in time for the film's premiere. The film introduced an upgrade to the technology and starship designs, making for a dramatic visual departure from the original series. Many of the set elements created for Phase II were adapted and enhanced for use in the first feature films. It received mixed reviews from critics; while it grossed $139 million the price tag had climbed to about $35 million due to costly effects work and delays.\\r\\nThe Motion Picture's gross was considered disappointing, but it was enough for Paramount to back a sequel with a reduced budget. After Roddenberry pitched a film in which the crew of the Enterprise goes back in time to ensure the assassination of John F. Kennedy, he was \\"kicked upstairs\\" to a ceremonial role while Paramount brought in television producer Harve Bennett to craft a betterand cheaperfilm than the first.[8] After watching all the television episodes, Bennett decided that the character of Khan Noonien Singh was the perfect villain for the new film. Director Nicholas Meyer finished a complete screenplay in just twelve days, and did everything possible within budget to give The Wrath of Khan a nautical, swashbuckling feel,[9] which he described as \\"Horatio Hornblower in outer space.\\"[8] Upon release, the reception of The Wrath of Khan was highly positive;[10] Entertainment Weekly's Mark Bernadin called The Wrath of Khan, \\"the film that, by most accounts, saved Star Trek as we know it\\".[11]\\r\\nMeyer declined to return for the next film, so directing duties were given to cast member Leonard Nimoy for the third film. Paramount gave Bennett the green light to write Star Trek III the day after The Wrath of Khan opened.[12] The producer penned a resurrection story for Spock that built on threads from the previous film and the original series episode \\"Amok Time\\".[citation needed] Nimoy remained director for the next film in the series. Nimoy and Bennett wanted a film with a lighter tone that did not have a classic antagonist. They decided on a time travel story with the Enterprise crew returning to their past to retrieve something to save their presenteventually, humpback whales. After having been dissatisfied with the script written by Daniel Petrie Jr., Paramount hired Meyer to rewrite the screenplay with Bennett's help. Meyer drew upon his own time travel story Time After Time for elements[which?] of the script.[citation needed] Star William Shatner was promised his turn as director for Star Trek V, and Nicholas Meyer returned as director/co-writer for Star Trek VI.\\r\\nBoth the sixth and seventh films acted as transitions between the films featuring the original cast and those with the Next Generation cast, with the sixth focusing on the original cast and the seventh focusing on the TNG cast. The Next Generation cast made four films over a period of eight years, with the last two performing only moderately well (Insurrection) and disappointingly (Nemesis) at the box office.\\r\\nAfter the poor reception of Star Trek: Nemesis and the cancellation of the television series Star Trek: Enterprise, the franchise's executive producer Rick Berman and screenwriter Erik Jendresen began developing a new film,[13] entitled Star Trek: The Beginning, which would take place after Enterprise but before The Original Series.[14] J. J. Abrams, the producer of Cloverfield and creator of Lost, was a huge fan of Star Wars as a child and confessed that the Star Trek franchise felt \\"disconnected\\" for him.[15] In February 2007, Abrams accepted Paramount's offer to direct the new Star Trek film, having been previously attached as producer.[16] Roberto Orci and Alex Kurtzman wrote a screenplay that impressed Abrams, featuring new actors portraying younger versions of the original series' cast. The Enterprise, its interior, and the original uniforms were redesigned. While the film was ready for a December 2008 release, Paramount chose to move the film's opening to May 8, 2009.[17] The film earned over $350 million worldwide (from a solid $75.2 million opening weekend, higher than Star Trek: First Contact (1996)), and surpassed Star Trek IV: The Voyage Home as the highest-grossing film in the franchise. A sequel, Star Trek Into Darkness, was greenlighted even before the first one opened, and Paramount released the film on May 17, 2013.[18] A third film, Star Trek Beyond, was directed by Justin Lin and produced by Abrams. It was released on July 22, 2016, also to critical acclaim.\\r\\nThis revival of the franchise is often considered to be, and referred to as, a \\"reboot\\", but it is technically a continuation of the franchise (Nimoy reprises his role of Spock from the previous films) that establishes an alternate reality from the previous films. This route was taken, over a traditional reboot, to free the new films from the restrictions of established continuity without completely discarding it, which the writers felt would have been \\"disrespectful\\". This new reality was informally referred to by several names, including the \\"Abramsverse\\", \\"JJ Trek\\" and \\"NuTrek\\", before it was named the \\"Kelvin Timeline\\" (versus the \\"Prime Timeline\\" of the original series and films) by Michael and Denise Okuda for use in official Star Trek reference guides and encyclopedias. The name Kelvin comes from the USS Kelvin, a starship involved in the event that creates the new reality in Star Trek (2009). Abrams named the starship after his grandfather Henry Kelvin, whom he also pays tribute to in Into Darkness with the Kelvin Memorial Archive.[19][20]\\r\\nFans commonly considered the films to follow a \\"curse\\" that even-numbered films were better than the odd-numbered installments.[21][22] The tenth film, Nemesis, was considered the even film that defied the curse.[21][23][24] Its failure and the subsequent success of Star Trek (2009) were considered to have broken the trend.[25][26] The curse has been mentioned often in popular culture. One of the best known examples[27][28] occurred in a 1999 episode of the Channel 4 sitcom Spaced, where it was referenced by Tim Bisley, played by Simon Pegg; Pegg, quite conscious of the irony,[29] played Scotty in the eleventh and subsequent films.\\r\\nThis trend can be seen when observing overall box-office popularity.[30] The Motion Picture while critically panned, was a box-office success. It's important acknowledge its matter of relative popularity.[31] For example, on the review aggregator Rotten Tomatoes, every film up to ten, Nemesis alternates in popularity.[32]\\r\\nNon-inflation adjusted worldwide gross divided by production budget[33] Note that a large portion of box office receipts do got go to the production studio.\\r\\nA massive energy cloud advances toward Earth, leaving destruction in its wake, and the Enterprise must intercept it to determine what lies within, and what its intent might be.\\r\\nThe movie borrows many elements from \\"The Changeling\\" of the original series and \\"One of Our Planets Is Missing\\" from the animated series.\\r\\nKhan Noonien Singh (Ricardo Montalbn), whom Kirk thwarted in his attempt to seize control of the Enterprise fifteen years earlier (\\"Space Seed\\"), seeks his revenge and lays a cunning and sinister trap.\\r\\nBoth the first and second films have television versions with additional footage and alternate takes that affect the storyline. (Subsequent Trek films tended to have shorter television versions.) Especially notable in The Wrath of Khan is the footage establishing that a young crew member who acts courageously and dies during an attack on the Enterprise is Scotty's nephew.\\r\\nWhen McCoy begins acting irrationally, Kirk learns that Spock, in his final moments, transferred his katra, his living spirit, to the doctor. To save McCoy from emotional ruin, Kirk and crew steal the Enterprise and violate the quarantine of the Genesis Planet to retrieve Spock, his body regenerated by the rapidly dying planet itself, in the hope that body and soul can be rejoined. However, bent on obtaining the secret of Genesis for themselves, a rogue Klingon (Christopher Lloyd) and his crew interfere, with deadly consequences.\\r\\nThe first film to be a direct sequel to the previous Trek film.\\r\\nWhile returning to stand court-martial for their actions in rescuing Spock, Kirk and crew learn that Earth is under siege by a giant probe that is transmitting a destructive signal, attempting to communicate with the now-extinct species of humpback whales. To save the planet, the crew must time-travel back to the late 20th century to obtain a mating pair of these whales, and a marine biologist (Catherine Hicks) to care for them.\\r\\nThe second through fourth films loosely form a trilogy, with the later plots building on elements of the earlier ones. The third film picks up within several days of the conclusion of the second, the fourth three months after the third. (The fifth film takes place a month after the fourth, but is not directly connected to the plots of the preceding three films.) The third and fourth films were both directed by Leonard Nimoy (also co-writer of the fourth), best known as the actor playing Spock.\\r\\nSpock's half-brother (Laurence Luckinbill) believes he is summoned by God, and hijacks the brand-new (and problem-ridden) Enterprise-A to take it through the Great Barrier, at the center of the Milky Way, beyond which he believes his maker waits for him. Meanwhile, a young, arrogant Klingon captain (Todd Bryant), seeking glory in what he views as an opportunity to avenge his people of the deaths of their crewmen on Genesis, sets his sights on Kirk.\\r\\nThis is the only film in the franchise directed by William Shatner.\\r\\nThe film was not very well received compared to the other films but still achieved some success; while Shatner did not direct another film he was cast in two more Star Trek films.[34] Later when Nemesis was poorly received with a Trek rookie for directing TNG, but unlike The Final Frontier, halted Trek films for over half a decade.[35]\\r\\nWhen Qo'noS' moon Praxis (the Klingon Empire's chief energy source) is devastated by an explosion caused by overmining, the Klingons make peace overtures to the Federation. The Klingon Chancellor (David Warner), while en route to Earth for a summit, is assassinated by Enterprise crewmen, and Kirk is held accountable by the Chancellor's Chief of Staff (Christopher Plummer). Spock attempts to prove Kirk's innocence, but, in doing so, uncovers a massive conspiracy against the peace process with participants from both sides.\\r\\nThis film is a sendoff to the original series crew. One Next Generation cast member, Michael Dorn, appears as the grandfather of the character he plays on the later television series. It is the second and last Trek film directed by Nicholas Meyer and last script co-authored by Leonard Nimoy.\\r\\nI think it was kind of an honor they had my character be sort of the link between the two series. It was wonderful to be working with the other cast (from the original Star Trek series). It was kind of a fantasy because who would have thought when I was watching the original show that I'd be working in the movie? Beyond that, it's like professionalism takes over and you just kind of do the best you can and not make yourself look bad.\\r\\nPicard enlists the help of Kirk, who is presumed long dead but flourishes in an extradimensional realm, to prevent a renegade scientist (Malcolm McDowell) from destroying a star and its populated planetary system in an attempt to enter that realm. This film also included original crew members Scotty (played by James Doohan) and Chekov (played by Walter Koenig).\\r\\nFollowing seven seasons of Star Trek: The Next Generation, the next Star Trek film was the first to feature the crew of the Enterprise-D along with a long prologue sequence featuring three members of the original series cast.\\r\\nThis film features two Starships Enterprise, the USS Enterprise (NCC-1701-B) (Excelsior class) and the USS Enterprise (NCC-1701-D), as featured on the television series Star Trek: The Next Generation (1987-1994).\\r\\nAfter a failed attempt to assault Earth, the Borg attempt to prevent First Contact between Humans and Vulcans by interfering with Zefram Cochrane's (James Cromwell) warp test in the past. Picard must confront the demons which stem from his assimilation into the Collective (\\"The Best of Both Worlds\\") as he leads the Enterprise-E back through time to ensure the test and subsequent meeting with the Vulcans take place.\\r\\nThe first of two films directed by series actor Jonathan Frakes.\\r\\nThis marks the debut of the USS Enterprise (NCC-1701-E).\\r\\nProfoundly disturbed by what he views as a blatant violation of the Prime Directive, Picard deliberately interferes with a Starfleet admiral's (Anthony Zerbe) plan to relocate a relatively small but seemingly immortal population from a planet to gain control of the planet's natural radiation, which has been discovered to have substantial medicinal properties. However, the admiral himself is a pawn in his alien partner's (F. Murray Abraham) mission of vengeance.\\r\\nInsurrection brought in Deep Space Nine writer Michael Pillar instead of Ronald D. Moore and Brannon Braga who had written for Generations and First Contact.[37]\\r\\nA clone of Picard (Tom Hardy), created by the Romulans but eventually exiled to hard labor on Remus, assassinates the entire Romulan senate, assumes dictatorship, and lures Picard and the Enterprise to Romulus under the false pretence of a peace overture.\\r\\nThis film was a critical and commercial disappointment (released December 13, 2002 in direct competition with the James Bond film Die Another Day and The Lord of the Rings: The Two Towers) and was the final Star Trek film to feature the Next Generation cast and to be produced by Rick Berman.\\r\\nReception was very, very critical of this film which featured a Trekiverse rookie director.[38] Although it is often given as rationale for halting the TNG films, it is significantly more well reviewed than The Final Frontier which did not halt the Trek series, and like that had a new director.[39]\\r\\n A story that covered the events between Nemesis and Star Trek was released as the graphic novel Star Trek: Countdown in early 2009.\\r\\nWhen Vulcan is destroyed by Romulans from the future, Starfleet cadet Kirk (Chris Pine) and instructor Spock (Zachary Quinto) must set aside their differences to keep Earth from suffering the same fate.\\r\\nThis film acts as a reboot to the existing franchise by taking place in an \\"alternate reality\\" using the plot device of time travel to depict an altered timeline (known as the Kelvin Timeline), featuring younger versions of the original series' cast. It is the first production to feature an entirely different cast of actors playing roles previously established by other actors, with the exception of an aged Spock played by Leonard Nimoy. It was directed by J. J. Abrams (who produced it with Damon Lindelof) and written by Roberto Orci and Alex Kurtzman. According to Lindelof, this production was designed to attract a wider audience.[40] It received positive reviews[41] and a number of awards, including the film franchise's only Academy Award, for \\"makeup and hairstyling\\".\\r\\nA Starfleet special agent (Benedict Cumberbatch) coerces an officer into blowing up a secret installation in London, shoots up a subsequent meeting of Starfleet brass in San Francisco, and then flees to Qo'noS. The crew of the Enterprise attempt to bring him to justice without provoking war with the Klingon Empire, but find there is much more to the agent's mission, and the man himself, than what the Fleet Admiral (Peter Weller) has told them.\\r\\nThe Enterprise is ambushed and destroyed by countless alien microvessels; the crew abandon ship. Stranded on an unknown planet, and with no apparent means of escape or rescue, they find themselves in conflict with a new sociopathic enemy (Idris Elba) who has a well-earned hatred of the Federation and what it stands for.\\r\\nStar Trek Beyond was released on July 22, 2016, in time for the franchise's 50th anniversary celebrations. Roberto Orci had stated that Star Trek Beyond will feel more like the original series than its predecessors in the reboot series while still trying something new with the established material.[42] In December 2014, Justin Lin was confirmed as the director for the upcoming sequel,[43] marking the first reboot film not to be directed by J. J. Abrams, whose commitments to Star Wars: The Force Awakens restricted his role on the Star Trek film to that of producer.[44] In January 2015, it was confirmed that the film would be co-written by Doug Jung and Simon Pegg,[45] who revealed the film's title that May.[46] Idris Elba was cast as the villain Krall,[47][48] while Sofia Boutella was cast as Jaylah.[49] Filming began on June 25, 2015.[50] This is the last film of Anton Yelchin (Chekov), who died in an automobile accident on June 19, 2016.\\r\\nPine and Quinto have signed contracts to return as Kirk and Spock for a fourth film.[51] In July 2016, Abrams confirmed plans for a fourth film, and stated that Chris Hemsworth would return as Kirk's father, George, whom he played in the prologue of the first film.[52][53] Later that month, Paramount confirmed the return of Hemsworth as well as most of the Beyond cast, producers Abrams and Lindsey Weber, and writers J. D. Payne and Patrick McKay.[54] That same month, Abrams had said that Chekov would not be recast, after Anton Yelchin died in a motor vehicle incident.[55] In December 2017, Deadline.com reported that Quentin Tarantino is currently working on the next Star Trek theatrical installment with Abrams, with the intention being that the former will direct the film.[56] Mark L. Smith, Lindsey Beer, Megan Amram and Drew Pearce took part in the writers room before Paramount finalized a deal with Smith to write the script.[57]\\r\\nThe following table shows the cast members who played the primary characters in the film series, as additional examples of characters from the franchise or movies","input":"What is the most recent star trek movie?"},{"output":"fifteen","context":"The United Nations Security Council (UNSC) is one of the six principal organs of the United Nations,[1] charged with the maintenance of international peace and security[2] as well as accepting new members to the United Nations[3] and approving any changes to its United Nations Charter.[4] Its powers include the establishment of peacekeeping operations, the establishment of international sanctions, and the authorization of military action through Security Council resolutions; it is the only UN body with the authority to issue binding resolutions to member states. The Security Council held its first session on 17 January 1946.\\r\\nLike the UN as a whole, the Security Council was created following World War II to address the failings of a previous international organization, the League of Nations, in maintaining world peace. In its early decades, the Security Council was largely paralyzed by the Cold War division between the US and USSR and their respective allies, though it authorized interventions in the Korean War and the Congo Crisis and peacekeeping missions in the Suez Crisis, Cyprus, and West New Guinea. With the collapse of the Soviet Union, UN peacekeeping efforts increased dramatically in scale, and the Security Council authorized major military and peacekeeping missions in Kuwait, Namibia, Cambodia, Bosnia, Rwanda, Somalia, Sudan, and the Democratic Republic of Congo.\\r\\nThe Security Council consists of fifteen members.[5] The great powers that were the victors of World War IIthe Soviet Union (now represented by the Russian Federation), the United Kingdom, France, the Republic of China (now represented by the People's Republic of China), and the United Statesserve as the body's five permanent members. These permanent members can veto any substantive Security Council resolution, including those on the admission of new member states or candidates for Secretary-General. The Security Council also has 10 non-permanent members, elected on a regional basis to serve two-year terms. The body's presidency rotates monthly among its members.\\r\\nSecurity Council resolutions are typically enforced by UN peacekeepers, military forces voluntarily provided by member states and funded independently of the main UN budget. As of 2016[update], 103,510 peacekeepers and 16,471 civilians were deployed on sixteen peacekeeping operations and one special political mission.[6]\\r\\n\\r\\n\\r\\nIn the century prior to the UN's creation, several international treaty organizations and conferences had been formed to regulate conflicts between nations, such as the International Committee of the Red Cross and the Hague Conventions of 1899 and 1907.[7] Following the catastrophic loss of life in World War I, the Paris Peace Conference established the League of Nations to maintain harmony between the nations.[8] This organization successfully resolved some territorial disputes and created international structures for areas such as postal mail, aviation, and opium control, some of which would later be absorbed into the UN.[9] However, the League lacked representation for colonial peoples (then half the world's population) and significant participation from several major powers, including the US, USSR, Germany, and Japan; it failed to act against the 1931 Japanese invasion of Manchuria, the Second Italo-Ethiopian War in 1935, the 1937 Japanese occupation of China, and Nazi expansions under Adolf Hitler that escalated into World War II.[10]\\r\\nThe earliest concrete plan for a new world organization began under the aegis of the US State Department in 1939.[11] Roosevelt first coined the term United Nations to describe the Allied countries.\\"On New Years Day 1942, President Roosevelt, Prime Minister Churchill, Maxim Litvinov, of the USSR, and T. V. Soong, of China, signed a short document which later came to be known as the United Nations Declaration and the next day the representatives of twenty-two other nations added their signatures.\\"[12] The term United Nations was first officially used when 26 governments signed this Declaration. By 1 March 1945, 21 additional states had signed.[13] \\"Four Policemen\\" was coined to refer to the four major Allied countries: the United States, the United Kingdom, the Soviet Union, and China, which was emerged in Declaration by United Nations[14] and became the foundation of an executive branch of the United Nations, the Security Council.[15]\\r\\nIn mid-1944, the delegations from the Allied \\"Big Four\\", the Soviet Union, the UK, the US and China, met for the Dumbarton Oaks Conference in Washington, D.C. to negotiate the UN's structure,[16] and the composition of the UN Security Council quickly became the dominant issue. France, the Republic of China, the Soviet Union, the UK, and US were selected as permanent members of the Security Council; the US attempted to add Brazil as a sixth member, but was opposed by the heads of the Soviet and British delegations.[17] The most contentious issue at Dumbarton and in successive talks proved to be the veto rights of permanent members. The Soviet delegation argued that each nation should have an absolute veto that could block matters from even being discussed, while the British argued that nations should not be able to veto resolutions on disputes to which they were a party. At the Yalta Conference of February 1945, the American, British, and Russian delegations agreed that each of the \\"Big Five\\" could veto any action by the council, but not procedural resolutions, meaning that the permanent members could not prevent debate on a resolution.[18]\\r\\nOn 25 April 1945, the UN Conference on International Organization began in San Francisco, attended by 50?governments and a number of non-governmental organizations involved in drafting the United Nations Charter.[19] At the conference, H. V. Evatt of the Australian delegation pushed to further restrict the veto power of Security Council permanent members.[20] Due to the fear that rejecting the strong veto would cause the conference's failure, his proposal was defeated twenty votes to ten.[21]\\r\\nThe UN officially came into existence on 24 October 1945 upon ratification of the Charter by the five then-permanent members of the Security Council and by a majority of the other 46 signatories.[19] On 17 January 1946, the Security Council met for the first time at Church House, Westminster, in London, United Kingdom.[22]\\r\\nThe Security Council was largely paralysed in its early decades by the Cold War between the US and USSR and their allies, and the Council generally was only able to intervene in unrelated conflicts.[23] (A notable exception was the 1950 Security Council resolution authorizing a US-led coalition to repel the North Korean invasion of South Korea, passed in the absence of the USSR.)[19][24] In 1956, the first UN peacekeeping force was established to end the Suez Crisis;[19] however, the UN was unable to intervene against the USSR's simultaneous invasion of Hungary following that country's revolution.[25] Cold War divisions also paralysed the Security Council's Military Staff Committee, which had been formed by Articles 45ÿ47 of the UN Charter to oversee UN forces and create UN military bases. The committee continued to exist on paper but largely abandoned its work in the mid-1950s.[26][27]\\r\\nIn 1960, the UN deployed the United Nations Operation in the Congo (UNOC), the largest military force of its early decades, to restore order to the breakaway State of Katanga, restoring it to the control of the Democratic Republic of the Congo by 1964.[28] However, the Security Council found itself bypassed in favour of direct negotiations between the superpowers in some of the decade's larger conflicts, such as the Cuban missile crisis or the Vietnam War.[29] Focusing instead on smaller conflicts without an immediate Cold War connection, the Security Council deployed the United Nations Temporary Executive Authority in West New Guinea in 1962 and the United Nations Peacekeeping Force in Cyprus in 1964, the latter of which would become one of the UN's longest-running peacekeeping missions.[30][31]\\r\\nOn 25 October 1971, over US opposition but with the support of many Third World nations, the mainland, communist People's Republic of China was given the Chinese seat on the Security Council in place of Taiwan; the vote was widely seen as a sign of waning US influence in the organization.[32] With an increasing Third World presence and the failure of UN mediation in conflicts in the Middle East, Vietnam, and Kashmir, the UN increasingly shifted its attention to its ostensibly secondary goals of economic development and cultural exchange. By the 1970s, the UN budget for social and economic development was far greater than its budget for peacekeeping.[33]\\r\\nAfter the Cold War, the UN saw a radical expansion in its peacekeeping duties, taking on more missions in ten years' time than it had in its previous four decades.[34] Between 1988 and 2000, the number of adopted Security Council resolutions more than doubled, and the peacekeeping budget increased more than tenfold.[35] The UN negotiated an end to the Salvadoran Civil War, launched a successful peacekeeping mission in Namibia, and oversaw democratic elections in post-apartheid South Africa and post-Khmer Rouge Cambodia.[36] In 1991, the Security Council demonstrated its renewed vigor by condemning the Iraqi invasion of Kuwait on the same day of the attack, and later authorizing a US-led coalition that successfully repulsed the Iraqis.[37] Undersecretary-General Brian Urquhart later described the hopes raised by these successes as a \\"false renaissance\\" for the organization, given the more troubled missions that followed.[38]\\r\\nThough the UN Charter had been written primarily to prevent aggression by one nation against another, in the early 1990s, the UN faced a number of simultaneous, serious crises within nations such as Haiti, Mozambique and the former Yugoslavia.[39] , the UN mission to Bosnia faced \\"worldwide ridicule\\" for its indecisive and confused mission in the face of ethnic cleansing.[40] In 1994, the United Nations Assistance Mission for Rwanda failed to intervene in the Rwandan Genocide in the face of Security Council indecision.[41]\\r\\nIn the late 1990s, UN-authorised international interventions took a wider variety of forms. The UN mission in the 1991ÿ2002 Sierra Leone Civil War was supplemented by British Royal Marines, and the UN-authorised 2001 invasion of Afghanistan was overseen by NATO.[42] In 2003, the US invaded Iraq despite failing to pass a UN Security Council resolution for authorization, prompting a new round of questioning of the organization's effectiveness.[43] In the same decade, the Security Council intervened with peacekeepers in crises including the War in Darfur in Sudan and the Kivu conflict in the Democratic Republic of Congo. In 2013, an internal review of UN actions in the final battles of the Sri Lankan Civil War in 2009 concluded that the organization had suffered \\"systemic failure\\".[44] In November/December 2014, Egypt presented a motion proposing an expansion of the NPT (non-Proliferation Treaty), to include Israel and Iran; this proposal was due to increasing hostilities and destruction in the Middle-East connected to the Syrian Conflict as well as others. All members of the Security Council are signatory to the NPT.[45]\\r\\nThe UN's role in international collective security is defined by the UN Charter, which authorizes the Security Council to investigate any situation threatening international peace; recommend procedures for peaceful resolution of a dispute; call upon other member nations to completely or partially interrupt economic relations as well as sea, air, postal, and radio communications, or to sever diplomatic relations; and enforce its decisions militarily, or by any means necessary. The Security Council also recommends the new Secretary-General to the General Assembly and recommends new states for admission as member states of the United Nations.[46][47] The Security Council has traditionally interpreted its mandate as covering only military security, though US Ambassador Richard Holbrooke controversially persuaded the body to pass a resolution on HIV/AIDS in Africa in 2000.[48]\\r\\nUnder Chapter VI of the Charter, \\"Pacific Settlement of Disputes\\", the Security Council \\"may investigate any dispute, or any situation which might lead to international friction or give rise to a dispute\\". The Council may \\"recommend appropriate procedures or methods of adjustment\\" if it determines that the situation might endanger international peace and security.[49] These recommendations are generally considered to not be binding, as they lack an enforcement mechanism.[50] A minority of scholars, such as Stephen Zunes, have argued that resolutions made under Chapter VI are \\"still directives by the Security Council and differ only in that they do not have the same stringent enforcement options, such as the use of military force\\".[51]\\r\\nUnder Chapter VII, the Council has broader power to decide what measures are to be taken in situations involving \\"threats to the peace, breaches of the peace, or acts of aggression\\".[27] In such situations, the Council is not limited to recommendations but may take action, including the use of armed force \\"to maintain or restore international peace and security\\".[27] This was the legal basis for UN armed action in Korea in 1950 during the Korean War and the use of coalition forces in Iraq and Kuwait in 1991 and Libya in 2011.[52][53] Decisions taken under Chapter VII, such as economic sanctions, are binding on UN members; the Security Council is the only UN body with the authority to issue binding resolutions.[54][55]\\r\\nThe Rome Statute of the International Criminal Court recognizes that the Security Council has authority to refer cases to the Court in which the Court could not otherwise exercise jurisdiction.[56] The Council exercised this power for the first time in March 2005, when it referred to the Court \\"the situation prevailing in Darfur since 1 July 2002\\"; since Sudan is not a party to the Rome Statute, the Court could not otherwise have exercised jurisdiction.[57][58] The Security Council made its second such referral in February 2011 when it asked the ICC to investigate the Libyan government's violent response to the Libyan Civil War.[59]\\r\\nSecurity Council Resolution 1674, adopted on 28 April 2006, \\"reaffirms the provisions of paragraphs 138 and 139 of the 2005 World Summit Outcome Document regarding the responsibility to protect populations from genocide, war crimes, ethnic cleansing and crimes against humanity\\".[60] The Security Council reaffirmed this responsibility to protect in Resolution 1706 on 31 August of that year.[61] These resolutions commit the Security Council to take action to protect civilians in an armed conflict, including taking action against genocide, war crimes, ethnic cleansing, and crimes against humanity.[62]\\r\\nThe Security Council's five permanent members, below, have the power to veto any substantive resolution; this allows a permanent member to block adoption of a resolution, but not to prevent or end debate.[63]\\r\\nAt the UN's founding in 1945, the five permanent members of the Security Council were the Republic of China, the French Republic, the Soviet Union, the United Kingdom, and the United States. There have been two major seat changes since then. China's seat was originally held by Chiang Kai-shek's Nationalist Government, the Republic of China. However, the Nationalists were forced to retreat to the island of Taiwan in 1949, during the Chinese Civil War. The Communist government assumed control of mainland China, thenceforth known as the People's Republic of China. In 1971, General Assembly Resolution 2758 recognized the People's Republic as the rightful representative of China in the UN and gave it the seat on the Security Council that had been held by the Republic of China, which was expelled from the UN altogether with no opportunity of membership as a separate nation.[32] After the dissolution of the Soviet Union in 1991, the Russian Federation was recognized as the legal successor state of the Soviet Union and maintained the latter's position on the Security Council.[64] Additionally, France reformed its government into the French Fifth Republic in 1958, under the leadership of Charles de Gaulle. France maintained its seat as there was no change in its international status or recognition, although many of its overseas possessions eventually became independent.[65]\\r\\nThe five permanent members of the Security Council were the victorious powers in World War II[66] and have maintained the world's most powerful military forces ever since. They annually topped the list of countries with the highest military expenditures.[67] In 2013, they spent over US$1 trillion combined on defence, accounting for over 55% of global military expenditures (the US alone accounting for over 35%).[67] They are also among the world's largest arms exporters[68] and are the only nations officially recognized as \\"nuclear-weapon states\\" under the Nuclear Non-Proliferation Treaty (NPT), though there are other states known or believed to be in possession of nuclear weapons.[69]\\r\\nUnder Article 27 of the UN Charter, Security Council decisions on all substantive matters require the affirmative votes of nine members. A negative vote or \\"veto\\" by a permanent member prevents adoption of a proposal, even if it has received the required votes.[63] Abstention is not regarded as a veto in most cases, though all five permanent members must actively concur to amend the UN Charter or to recommend the admission of a new UN member state.[54] Procedural matters are not subject to a veto, so the veto cannot be used to avoid discussion of an issue. The same holds for certain decisions that directly regard permanent members.[63] A majority of vetoes are used not in critical international security situations, but for purposes such as blocking a candidate for Secretary-General or the admission of a member state.[71]\\r\\nIn the negotiations building up to the creation of the UN, the veto power was resented by many small countries, and in fact was forced on them by the veto nations ÿ US, UK, China, France and the Soviet Union ÿ through a threat that without the veto there will be no UN. Here is a description by Francis O. Wilcox, an adviser to US delegation to the 1945 conference: \\"At San Francisco, the issue was made crystal clear by the leaders of the Big Five: it was either the Charter with the veto or no Charter at all. Senator Connally [from the US delegation] dramatically tore up a copy of the Charter during one of his speeches and reminded the small states that they would be guilty of that same act if they opposed the unanimity principle. 'You may, if you wish,' he said, 'go home from this Conference and say that you have defeated the veto. But what will be your answer when you are asked: \\"Where is the Charter\\"?'\\"[72]\\r\\nAs of 2012, 269 vetoes had been cast since the Security Council's inception.[a] In this period, China (ROC/PRC) used the veto 9 times, France 18, USSR/Russia 128, the UK 32, and the US 89. Roughly two-thirds of Soviet/Russian vetoes were in the first ten years of the Security Council's existence. Between 1996 and 2012, China vetoed 5 resolutions, Russia 7, and the US 13, while France and the UK did not use the veto.[71]\\r\\nAn early veto by Soviet Commissar Andrei Vishinsky blocked a resolution on the withdrawal of French forces from the then-colonies of Syria and Lebanon in February 1946; this veto established the precedent that permanent members could use the veto on matters outside of immediate concerns of war and peace. The USSR went on to veto matters including the admission of Austria, Cambodia, Ceylon, Finland, Ireland, Italy, Japan, Laos, Libya, Portugal, South Vietnam, and Transjordan as UN member states, delaying their joining by several years. Britain and France used the veto to avoid Security Council condemnation of their actions in the 1956 Suez Crisis. The first veto by the US came in 1970, blocking General Assembly action in Southern Rhodesia. From 1985ÿ90, the US vetoed 27 resolutions, primarily to block resolutions it perceived as anti-Israel but also to protect its interests in Panama and Korea. The USSR, US, and China have all vetoed candidates for Secretary-General, with the US using the veto to block the re-election of Boutros Boutros-Ghali in 1996.[73]\\r\\nAlong with the five permanent members, the Security Council has temporary members that hold their seats on a rotating basis by geographic region. Non-permanent members may be involved in global security briefings.[74] In its first two decades, the Security Council had six non-permanent members, the first of which were Australia, Brazil, Egypt, Mexico, the Netherlands, and Poland. In 1965, the number of non-permanent members was expanded to ten.[75]\\r\\nThese ten non-permanent members are elected by the General Assembly for two-year terms starting on 1 January, with five replaced each year.[76] To be approved, a candidate must receive at least two-thirds of all votes cast for that seat, which can result in deadlock if there are two roughly evenly matched candidates. In 1979, a standoff between Cuba and Colombia only ended after three months and a record 154 rounds of voting; both eventually withdrew in favour of Mexico as a compromise candidate.[77] A retiring member is not eligible for immediate re-election.[78]\\r\\nThe African Group is represented by three members; the Latin America and the Caribbean, Asia-Pacific, and Western European and Others groups by two apiece; and the Eastern European Group by one. Traditionally, one of the seats assigned to either the Asia-Pacific Group or the African Group is filled by a nation from the Arab world.[79] Currently, elections for terms beginning in even-numbered years select two African members, and one each within Eastern Europe, Asia-Pacific, and Latin America and the Caribbean. Terms beginning in odd-numbered years consist of two Western European and Other members, and one each from Asia-Pacific, Africa, and Latin America and the Caribbean.[77]\\r\\nThe current elected members, with the regions they were elected to represent, are as follows:[76]\\r\\nThe 2017ÿ18 term will be the first time in over five decades that two members have agreed to split a term;[vague] otherwise intractable deadlocks have instead usually been resolved by the candidate countries withdrawing in favour of a third member state.\\r\\nThe role of president of the Security Council involves setting the agenda, presiding at its meetings and overseeing any crisis. The president is authorized to issue both presidential statements (subject to consensus among Council members) and notes,[82][83] which are used to make declarations of intent that the full Security Council can then pursue.[83] The presidency of the Council is held by each of the members in turn for one month, following the English alphabetical order of the Member States names.[84]\\r\\nThe list of nations that will hold the Presidency in 2018 is as follows:[85]\\r\\nUnlike the General Assembly, the Security Council meets year-round. Each Security Council member must have a representative available at UN Headquarters at all times in case an emergency meeting becomes necessary.[86]\\r\\nThe Security Council generally meets in a designated chamber in the United Nations Conference Building in New York City, U.S. The chamber was designed by the Norwegian architect Arnstein Arneberg and was a gift from Norway. The mural painted by the Norwegian artist Per Krohg depicts a phoenix rising from its ashes, symbolic of the world's rebirth after World War II.[87]\\r\\nThe Security Council has also held meetings in cities including Nairobi, Kenya; Addis Ababa, Ethiopia; Panama City, Panama; and Geneva, Switzerland.[86] In March 2010, the Security Council moved into a temporary facility in the General Assembly Building as its chamber underwent renovations as part of the UN Capital Master Plan.[88] The renovations were funded by Norway, the chamber's original donor, for a total cost of US$5 million.[89] The chamber reopened on 16 April 2013.[90]\\r\\nBecause meetings in the Security Council Chamber are covered by the international press, proceedings are highly theatrical in nature. Delegates deliver speeches to justify their positions and attack their opponents, playing to the cameras and the audience at home. Delegations also stage walkouts to express their disagreement with actions of the Security Council.[91] Due to the public scrutiny of the Security Council Chamber,[92] all of the real work of the Security Council is conducted behind closed doors in \\"informal consultations\\".[93][94]\\r\\nIn 1978, West Germany funded the construction of a conference room next to the Security Council Chamber. The room was used for \\"informal consultations\\", which soon became the primary meeting format for the Security Council. In 1994, the French ambassador complained to the Secretary-General that \\"informal consultations have become the Council's characteristic working method, while public meetings, originally the norm, are increasingly rare and increasingly devoid of content: everyone knows that when the Council goes into public meeting everything has been decided in advance\\".[95] When Russia funded the renovation of the consultation room in 2013, the Russian ambassador called it \\"quite simply, the most fascinating place in the entire diplomatic universe\\".[96]\\r\\nOnly members of the Security Council are permitted in the conference room for consultations. The press is not admitted, and other members of the United Nations cannot be invited into the consultations.[97] No formal record is kept of the informal consultations.[98][99] As a result, the delegations can negotiate with each other in secret, striking deals and compromises without having their every word transcribed into the permanent record. The privacy of the conference room also makes it possible for the delegates to deal with each other in a friendly manner. In one early consultation, a new delegate from a Communist nation began a propaganda attack on the United States, only to be told by the Soviet delegate, \\"We don't talk that way in here.\\"[94]\\r\\nA permanent member can cast a \\"pocket veto\\" during the informal consultation by declaring its opposition to a measure. Since a veto would prevent the resolution from being passed, the sponsor will usually refrain from putting the resolution to a vote. Resolutions are only vetoed if the sponsor feels so strongly about a measure that it wishes to force the permanent member to cast a formal veto.[93][100] By the time a resolution reaches the Security Council Chamber, it has already been discussed, debated, and amended in the consultations. The open meeting of the Security Council is merely a public ratification of a decision that has already been reached in private.[101][93] For example, Resolution 1373 was adopted without public debate in a meeting that lasted just five minutes.[93][102]\\r\\nThe Security Council holds far more consultations than public meetings. In 2012, the Security Council held 160 consultations, 16 private meetings, and 9 public meetings. In times of crisis, the Security Council still meets primarily in consultations, but it also holds more public meetings. After the outbreak of the Ukraine crisis in 2013, the Security Council returned to the patterns of the Cold War, as Russia and the Western countries engaged in verbal duels in front of the television cameras. In 2016, the Security Council held 150 consultations, 19 private meetings, and 68 public meetings.[103]\\r\\nArticle 29 of the Charter provides that the Security Council can establish subsidiary bodies in order to perform its functions. This authority is also reflected in Rule 28 of the Provisional Rules of Procedure. The subsidiary bodies established by the Security Council are extremely heterogenous. On the one hand, they include bodies such as the Security Council Committee on Admission of New Members. On the other hand, both the International Criminal Tribunal for the former Yugoslavia and the International Criminal Tribunal for Rwanda were also created as subsidiary bodies of the Security Council. The by now numerous Sanctions Committees (see Category:United Nations Security Council sanctions regimes) established in order to oversee implementation of the various sanctions regimes are also subsidiary bodies of the Council.\\r\\nAfter approval by the Security Council, the UN may send peacekeepers to regions where armed conflict has recently ceased or paused to enforce the terms of peace agreements and to discourage combatants from resuming hostilities. Since the UN does not maintain its own military, peacekeeping forces are voluntarily provided by member states. These soldiers are sometimes nicknamed \\"Blue Helmets\\" for their distinctive gear.[104][105] The peacekeeping force as a whole received the Nobel Peace Prize in 1988.[106]\\r\\nIn September 2013, the UN had 116,837 peacekeeping soldiers and other personnel deployed on 15 missions. The largest was the United Nations Organization Stabilization Mission in the Democratic Republic of the Congo (MONUSCO), which included 20,688 uniformed personnel. The smallest, United Nations Military Observer Group in India and Pakistan (UNMOGIP), included 42 uniformed personnel responsible for monitoring the ceasefire in Jammu and Kashmir. Peacekeepers with the United Nations Truce Supervision Organization (UNTSO) have been stationed in the Middle East since 1948, the longest-running active peacekeeping mission.[107]\\r\\nUN peacekeepers have also drawn criticism in several postings. Peacekeepers have been accused of child rape, soliciting prostitutes, or sexual abuse during various peacekeeping missions in the Democratic Republic of the Congo,[108] Haiti,[109] Liberia,[110] Sudan and what is now South Sudan,[111] Burundi and Ivory Coast.[112] Scientists cited UN peacekeepers from Nepal as the likely source of the 2010ÿ2013 Haiti cholera outbreak, which killed more than 8,000 Haitians following the 2010 Haiti earthquake.[113]\\r\\nThe budget for peacekeeping is assessed separately from the main UN organisational budget; in the 2013ÿ2014 fiscal year, peacekeeping expenditures totalled $7.54?billion.[107][114] UN peace operations are funded by assessments, using a formula derived from the regular funding scale, but including a weighted surcharge for the five permanent Security Council members. This surcharge serves to offset discounted peacekeeping assessment rates for less developed countries. In 2013, the top 10 providers of assessed financial contributions to United Nations peacekeeping operations were the US (28.38%), Japan (10.83%), France (7.22%), Germany (7.14%), the United Kingdom (6.68%), China (6.64%), Italy (4.45%), Russian Federation (3.15%), Canada (2.98%), and Spain (2.97%).[115]\\r\\nIn examining the first sixty years of the Security Council's existence, British historian Paul Kennedy concludes that \\"glaring failures had not only accompanied the UN's many achievements, they overshadowed them\\", identifying the lack of will to prevent ethnic massacres in Bosnia and Rwanda as particular failures.[116] Kennedy attributes the failures to the UN's lack of reliable military resources, writing that \\"above all, one can conclude that the practice of announcing (through a Security Council resolution) a new peacekeeping mission without ensuring that sufficient armed forces will be available has usually proven to be a recipe for humiliation and disaster\\".[117]\\r\\nA 2005 RAND Corporation study found the UN to be successful in two out of three peacekeeping efforts. It compared UN nation-building efforts to those of the United States, and found that seven out of eight UN cases are at peace.[118] Also in 2005, the Human Security Report documented a decline in the number of wars, genocides and human rights abuses since the end of the Cold War, and presented evidence, albeit circumstantial, that international activismmostly spearheaded by the UNhas been the main cause of the decline in armed conflict since the end of the Cold War.[119]\\r\\nScholar Sudhir Chella Rajan argued in 2006 that the five permanent members of the United Nations Security Council, who are all nuclear powers, have created an exclusive nuclear club that predominately addresses the strategic interests and political motives of the permanent membersfor example, protecting the oil-rich Kuwaitis in 1991 but poorly protecting resource-poor Rwandans in 1994.[120] Since three of the five permanent members are also European, and three or four are predominantly white Western nations, the Security Council has been described as a pillar of global apartheid by Titus Alexander, former Chair of Westminster United Nations Association.[121]\\r\\nThe Security Council's effectiveness and relevance is questioned by some because, in most high-profile cases, there are essentially no consequences for violating a Security Council resolution. During the Darfur crisis, Janjaweed militias, allowed by elements of the Sudanese government, committed violence against an indigenous population, killing thousands of civilians. In the Srebrenica massacre, Serbian troops committed genocide against Bosniaks, although Srebrenica had been declared a UN safe area, protected by 400 armed Dutch peacekeepers.[122]\\r\\nThe UN Charter gives all three powers of the legislative, executive, and judiciary branches to the Security Council.[123]\\r\\nIn his inaugural speech at the 16th Summit of the Non-Aligned Movement in August 2012, Ayatollah Ali Khamenei criticized the United Nations Security Council as having an \\"illogical, unjust and completely undemocratic structure and mechanism\\" and called for a complete reform of the body.[124]\\r\\nThe Security Council has been criticized for failure in resolving many conflicts, including Cyprus, Sri Lanka, Syria, Kosovo and the IsraeliÿPalestinian conflict, reflecting the wider short-comings of the UN. For example; At the 68th Session of the UN General Assembly, New Zealand Prime Minister John Key heavily criticized the UN's inaction on Syria, more than two years after the Syrian civil war began.[125]\\r\\nProposals to reform the Security Council began with the conference that wrote the UN Charter and have continued to the present day. As British historian Paul Kennedy writes, \\"Everyone agrees that the present structure is flawed. But consensus on how to fix it remains out of reach.\\"[126]\\r\\nThere has been discussion of increasing the number of permanent members. The countries who have made the strongest demands for permanent seats are Brazil, Germany, India, and Japan. Japan and Germany, the main defeated powers in WWII, are now the UN's second- and third-largest funders respectively, while Brazil and India are two of the largest contributors of troops to UN-mandated peace-keeping missions.\\r\\nItaly, the third main defeated power in WWII and now the UN's sixth-largest funder, leads a movement known as the Uniting for Consensus in opposition to the possible expansion of permanent seats. Core members of the group include Canada, South Korea, Spain, Indonesia, Mexico, Pakistan, Turkey, Argentina and Colombia. Their proposal is to create a new category of seats, still non-permanent, but elected for an extended duration (semi-permanent seats). As far as traditional categories of seats are concerned, the UfC proposal does not imply any change, but only the introduction of small and medium size states among groups eligible for regular seats. This proposal includes even the question of veto, giving a range of options that goes from abolition to limitation of the application of the veto only to Chapter VII matters.\\r\\nFormer UN Secretary-General Kofi Annan asked a team of advisers to come up with recommendations for reforming the United Nations by the end of 2004. One proposed measure is to increase the number of permanent members by five, which, in most proposals, would include Brazil, Germany, India, and Japan (known as the G4 nations), one seat from Africa (most likely between Egypt, Nigeria or South Africa), and/or one seat from the Arab League.[127] On 21 September 2004, the G4 nations issued a joint statement mutually backing each other's claim to permanent status, together with two African countries. Currently the proposal has to be accepted by two-thirds of the General Assembly (128 votes).\\r\\nThe permanent members, each holding the right of veto, announced their positions on Security Council reform reluctantly. The United States has unequivocally supported the permanent membership of Japan and lent its support to India and a small number of additional non-permanent members. The United Kingdom and France essentially supported the G4 position, with the expansion of permanent and non-permanent members and the accession of Germany, Brazil, India and Japan to permanent member status, as well as an increase in the presence by African countries on the Council. China has supported the stronger representation of developing countries and firmly opposed Japan's membership.[128]\\r\\nIn 2017, it was reported that the G4 nations were willing to temporarily forgo veto power if granted permanent UNSC seats.[129] In September 2017, U.S. Representatives Ami Bera and Frank Pallone introduced a resolution (H.Res.535) in the US House of Representatives (115th United States Congress), seeking support for India for a permanent membership of the United Nations Security Council.[130]","input":"How many members does the un security council have?"},{"output":"the left","context":"The terms left-hand traffic (LHT) and right-hand traffic (RHT) refer to regulations requiring all bidirectional traffic, unless otherwise directed, to keep to the right or to the left side of the road, respectively.[1] This is so fundamental to traffic flow that it is sometimes referred to as the rule of the road.[2]\\r\\nOne hundred and sixty-three countries and territories use RHT, with the remaining seventy-six countries and territories using LHT. Countries that use LHT account for about a sixth of the world's area and a quarter of its roads.[3] In the early 1900s some countries including Canada, Spain, and Brazil had different rules in different parts of the country. During the 1900s many countries standardised within their jurisdictions, and changed from LHT to RHT, mostly to conform with regional custom. In 1919, 104 of the world's territories were LHT and an equal number were RHT. From 1919 to 1986, 34 of the LHT territories switched to RHT.[4]\\r\\nMany of the countries with LHT are former British colonies in the Caribbean, Southern Africa, Southeast Asia, South Asia, Australia, and New Zealand. Japan, Thailand, Nepal, Bhutan, Mozambique, Suriname, East Timor, and Indonesia are among those LHT countries outside the former British Empire. In Europe, only four countries still drive on the left: the United Kingdom, Ireland, Malta, and Cyprus, all of which are on islands that have no direct road connections with countries driving on the right.\\r\\nNearly all countries use one side or the other throughout their entire territory. Most exceptions are due to historical considerations and/or involve islands with no road connection to the main part of a country. China is RHT except the Special Administrative Regions of China of Hong Kong and Macau. The United States is RHT except the United States Virgin Islands.[5] The United Kingdom is LHT, but its overseas territories of Gibraltar and British Indian Ocean Territory are RHT.\\r\\nAccording to the International Regulations for Preventing Collisions at Sea, water traffic is RHT. For aircraft the US Federal Aviation Regulations provide for passing on the right, both in the air and on water.[6]\\r\\nLight rail vehicles generally operate on the same side as road traffic in a country. Some countries use RHT for automobiles but LHT for trains, often because of the influence of the British on early railway systems.\\r\\nThere is no technical reason to prefer one side over the other.[7] In healthy populations, traffic safety is thought to be the same regardless of handedness, although some researchers have speculated that LHT may be safer for ageing populations[8] since humans are more commonly right-eye dominant than left-eye dominant.[9]\\r\\nAncient Greek, Egyptian, and Roman troops kept to the left when marching.[10] In 1998, archaeologists found a well-preserved double track leading to a Roman quarry near Swindon, in southern England. The grooves in the road on the left side (viewed facing down the track away from the quarry) were much deeper than those on the right side, suggesting LHT, at least at this location, since carts would exit the quarry heavily loaded, and enter it empty.[11]\\r\\nThe first reference in English law to an order for LHT was in 1756, with regard to London Bridge.[12]\\r\\nSome historians, such as C. Northcote Parkinson, believed that ancient travellers on horseback or on foot generally kept to the left, since most people were right handed. If two men riding on horseback were to start a fight, each would edge toward the left.[10] In the year 1300, Pope Boniface VIII directed pilgrims to keep left.[10]\\r\\nIn the late 1700s, traffic in the United States was RHT based on teamsters' use of large freight wagons pulled by several pairs of horses. The wagons had no driver's seat, so the (typically right-handed) postilion held his whip in his right hand and thus sat on the left rear horse. Seated on the left, the driver preferred that other wagons pass him on the left so that he could be sure to keep clear of the wheels of oncoming wagons.[13]\\r\\nIn France, traditionally foot traffic had kept right, while carriage traffic kept left. Following the French Revolution, all traffic kept right.[12] Following the Napoleonic Wars, the French imposed RHT on parts of Europe. During the colonial period, RHT was introduced by the French in New France, French West Africa, the Maghreb, French Indochina, the West Indies, French Guiana and the Runion, among others.\\r\\nMeanwhile, LHT traffic was introduced by the British in Atlantic Canada, Australia, New Zealand, the East Africa Protectorate, British India, Southern Rhodesia and the Cape Colony (now Zimbabwe and South Africa), British Malaya (now Malaysia, Brunei and Singapore), British Guiana, and British Hong Kong. LHT was also introduced by the Portuguese Empire in Portuguese Macau, Colonial Brazil, East Timor, Portuguese Mozambique, and Angola.\\r\\nThe first keep-right law for driving in the United States was passed in 1792 and applied to the Philadelphia and Lancaster Turnpike.[7] New York formalized RHT in 1804, New Jersey in 1813 and Massachusetts in 1821.[14]\\r\\nInfluential in Europe was the 1920 Paris Convention, which advised driving on the right-hand side of the road, in order to harmonise traffic across a continent with many borders. This was despite the fact that left-hand traffic was still widespread: in 1915 for example, LHT was introduced everywhere in the Austro-Hungarian Empire.[15] However, three years later the Empire was split up into several countries, and they all changed eventually to RHT, notably including when Nazi Germany introduced RHT with almost immediate effect in Czechoslovakia in 1938-39.[16]\\r\\nSweden was LHT from about 1734 to 1967,[17] despite having land borders with RHT countries, and approximately 90 percent of cars being left-hand drive (LHD) vehicles.[18] A referendum was held in 1955, with an overwhelming majority voting against a change to RHT. Nevertheless, some years later the government ordered a conversion, which took place at 5 am on Sunday, 3 September 1967. The accident rate dropped sharply after the change,[19] but soon rose back to near its original level.[20] The day was known as Dagen H (\\"H-Day\\"), the 'H' being for H?gertrafik or right traffic. When Iceland switched the following year, it was known as H-dagurinn, again meaning \\"H-Day\\".[21]\\r\\nIn the late 1960s, the UK Department for Transport considered switching to RHT, but declared it unsafe and too costly for such a built-up nation.[22] Road building standards, for motorways in particular, allow asymmetrically designed road junctions, where merge and diverge lanes differ in length.[23]\\r\\nChina adopted RHT in 1946. Taiwan changed to driving on the right at the same time. Hong Kong and Macau continue to be LHT.\\r\\nBoth North Korea and South Korea switched to RHT in September 1945 after liberation from Japan which was defeated and surrendered by the Allies.\\r\\nMyanmar switched to RHT in 1970.[24]\\r\\nSamoa, a former German colony, had been RHT for more than a century. It switched to LHT in 2009,[25] being the first territory in almost 30 years to switch.[26] The move was legislated in 2008 to allow Samoans to use cheaper right hand drive (RHD) vehicles imported from Australia, New Zealand or Japan, and to harmonise with other South Pacific nations. A political party, The People's Party, was formed to try to protest against the change, a protest group which launched a legal challenge,[27] and an estimated 18,000 people attending demonstrations against it.[28] The motor industry was also opposed, as 14,000 of Samoa's 18,000 vehicles are designed for RHT and the government has refused to meet the cost of conversion.[26] After months of preparation, the switch from right to left happened in an atmosphere of national celebration. There were no reported incidents.[3] At 05:50 local time, Monday 7 September, a radio announcement halted traffic, and an announcement at 6:00 ordered traffic to switch to LHT.[25] The change coincided with more restrictive enforcement of speeding and seat-belt laws.[29] That day and the following day were declared public holidays, to reduce traffic.[30] The change included a three-day ban on alcohol sales, while police mounted dozens of checkpoints, warning drivers to drive slowly.[3]\\r\\nThe Philippines was mostly LHT during its Spanish[31] and American colonial periods,[32][33] the latter despite United States switch to RHT in the 1930s (see above); as well as during the Commonwealth era.[34] During the Japanese occupation the Philippines remained LHT,[35] also because LHT had been required by the Japanese;[36] but during the Battle of Manila the liberating American forces drove their tanks to the right for easier facilitation of movement. RHT was formally finalised by Executive Order No. 34 signed by President Sergio Osme?a on 10 March 1945.[37]\\r\\nA number of non-contiguous former British colonies in West Africa originally drove LHT and switched to RHT in the early 1970s to match the surrounding countries. Sierra Leone switched to RHT in 1971, Nigeria in 1972 and Ghana in 1974. Before this period The Gambia, a country entirely contained within RHT Senegal, had officially switched to RHT in 1965.\\r\\nRwanda, a former Belgian colony in central Africa, is RHT but is considering switching to LHT, to bring the country in line with other members of the East African Community (EAC).[38] A survey, carried out in 2009, indicated that 54% of Rwandans were in favour of the switch. Reasons cited were the perceived lower costs of RHD vehicles as opposed to LHD versions of the same model, easier maintenance and the political benefit of harmonisation of traffic regulations with other EAC countries. The same survey also indicated that RHD cars are 16 to 49 per cent cheaper than their LHD equivalents.[39] In 2014 an internal report from consultants to the Ministry of Infrastructure recommended a switch to LHT.[40] In 2015, the ban on RHD vehicles was lifted; RHD trucks from neighbouring countries cost $1000 less than LHD models imported from Europe.[41][42]\\r\\nAlthough many LHT jurisdictions are on islands, there are cases where vehicles may be driven from LHT across a border into a RHT area. The Vienna Convention on Road Traffic regulates the use of foreign registered vehicles in the 72 countries that are parties to the 1968 agreement.\\r\\nAlthough the United Kingdom is separated from Continental Europe by the English Channel, the level of cross-Channel traffic is very high; the Channel Tunnel alone carries 3.5 million vehicles per year between the UK and France.\\r\\nSome countries have borders where drivers must switch from LHT to RHT and vice versa.\\r\\nLHT Thailand has three RHT neighbours: Cambodia, Laos, Myanmar. Most of its borders use a simple traffic light to do the switch, but there are also interchanges which enable the switch while keeping up a continuous flow of traffic.[43]\\r\\nThere are four road border crossing points between Hong Kong and Mainland China. In 2006, the daily average number of vehicle trips recorded at Lok Ma Chau was 31,100.[44] The next largest is Man Kam To, where there is no changeover system and the border roads on the mainland side Wenjindu intersect as one-way streets with a main road.\\r\\nThe Takutu River Bridge (which links LHT Guyana and RHT Brazil[45]) is the only border in the Americas where traffic changes sides.\\r\\nIn RHT jurisdictions, vehicles are configured with LHD, with the driver sitting on the left side. In LHT jurisdictions, the reverse is true. The driver's side, the side closest to the centre of the road, is sometimes called the offside, while the passenger side, the side closest to the side of the road, is sometimes called the nearside.[46]\\r\\nHistorically there was less consistency in the relationship of the position of the driver to the handedness of traffic. Most American cars produced before 1910 were RHD.[7] In 1908 Henry Ford standardised the Model T as LHD in RHT America,[7] arguing that with RHD and RHT, the passenger was obliged to \\"get out on the street side and walk around the car\\" and that with steering from the left, the driver \\"is able to see even the wheels of the other car and easily avoids danger.\\"[47] By 1915 other manufacturers followed Ford's lead, due to the popularity of the Model T.[7]\\r\\nIn specialised cases, the driver will sit on the nearside, or kerbside. Examples include:\\r\\nGenerally, the convention is to mount a motorcycle on the left,[49] and kickstands are usually on the left[50] which makes it more convenient to mount on the safer kerbside[50] as is the case in LHT.\\r\\nThe projection of light from low-beam headlamps is asymmetrical. The kerbside lamp projects light forwards, while the other headlamp dips the beam down and away from oncoming traffic, so as not to dazzle drivers coming in the opposite direction. In Europe, headlamps approved for use on one side of the road must be adaptable to produce adequate illumination with controlled glare for temporarily driving on the other side of the road.[51] This is done by affixing masking strips or prismatic lenses to a designated part of the lens or by moving all or part of the headlamp optic so all or part of the beam is shifted or the asymmetrical portion is occluded.[51] Some cars have a built-in adjustment to adapt the projection mechanically.[52]\\r\\nOf the 193 countries currently recognised by the United Nations, 139 use RHT and 54 use LHT. A country and its territories and dependencies is counted once.\\r\\nGibraltar is RHT (since 1929)\\r\\nA sign reminding motorists to keep left in Australia\\r\\nVehicles entering and leaving Macau cross over each other at the Lotus Bridge.\\r\\nSign reminding motorists to drive on the left in Ireland\\r\\nThe entrance to the Channel Tunnel in France.","input":"What side of the road does japan use?"},{"output":"Arabic","context":"The Middle East[note 1] is a transcontinental region centered on Western Asia and Egypt in North Africa. The corresponding adjective is Middle-Eastern and the derived noun is Middle-Easterner. The term has come into wider usage as a replacement of the term Near East (as opposed to the Far East) beginning in the early 20th century.\\r\\nArabs, Turks, Persians, Kurds, and Azeris (excluding Republic of Azerbaijan) constitute the largest ethnic groups in the region by population.[2] Minorities of the Middle East include Jews, Assyrians and other Arameans, Baloch, Berbers, Coptic Christians, Druze, Lurs, Mandaeans, Samaritans, Shabaks, Tats, and Zazas. In the Middle East, there is also a Romani community. European ethnic groups that form a diaspora in the region include Albanians, Bosniaks, Circassians, Crimean Tatars, Franco-Levantines, and Italo-Levantines. Among other migrant populations are Bengalis as well as other Indians, Chinese, Filipinos, Indonesians, Pakistanis, and Sub-Saharan Africans.\\r\\nThe history of the Middle East dates back to ancient times, with the (geopolitical) importance of the region being recognized for millennia.[3][4][5] Several major religions have their origins in the Middle East, including Judaism, Christianity, and Islam; the Baha'i faith, Mandaeism, Unitarian Druze, and numerous other belief systems were also established within the region.\\r\\nThe Middle East generally has a hot, arid climate, with several major rivers providing irrigation to support agriculture in limited areas such as the Nile Delta in Egypt, the Tigris and Euphrates watersheds of Mesopotamia, and most of what is known as the Fertile Crescent.\\r\\nMost of the countries that border the Persian Gulf have vast reserves of crude oil, with monarchs of the Arabian Peninsula in particular benefiting economically from petroleum exports.\\r\\n\\r\\n\\r\\nThe term \\"Middle East\\" may have originated in the 1850s in the British India Office.[6] However, it became more widely known when American naval strategist Alfred Thayer Mahan used the term in 1902[7] to \\"designate the area between Arabia and India\\".[8][9] During this time the British and Russian Empires were vying for influence in Central Asia, a rivalry which would become known as The Great Game. Mahan realized not only the strategic importance of the region, but also of its center, the Persian Gulf.[10][11] He labeled the area surrounding the Persian Gulf as the Middle East, and said that after Egypt's Suez Canal, it was the most important passage for Britain to control in order to keep the Russians from advancing towards British India.[12] Mahan first used the term in his article \\"The Persian Gulf and International Relations\\", published in September 1902 in the National Review, a British journal.\\r\\nThe Middle East, if I may adopt a term which I have not seen, will some day need its Malta, as well as its Gibraltar; it does not follow that either will be in the Persian Gulf. Naval force has the quality of mobility which carries with it the privilege of temporary absences; but it needs to find on every scene of operation established bases of refit, of supply, and in case of disaster, of security. The British Navy should have the facility to concentrate in force if occasion arise, about Aden, India, and the Persian Gulf.[13]\\r\\nMahan's article was reprinted in The Times and followed in October by a 20-article series entitled \\"The Middle Eastern Question,\\" written by Sir Ignatius Valentine Chirol. During this series, Sir Ignatius expanded the definition of Middle East to include \\"those regions of Asia which extend to the borders of India or command the approaches to India.\\"[14] After the series ended in 1903, The Times removed quotation marks from subsequent uses of the term.[15]\\r\\nUntil World War II, it was customary to refer to areas centered around Turkey and the eastern shore of the Mediterranean as the \\"Near East\\", while the \\"Far East\\" centered on China,[16] and the Middle East then meant the area from Mesopotamia to Burma, namely the area between the Near East and the Far East.[citation needed] In the late 1930s, the British established the Middle East Command, which was based in Cairo, for its military forces in the region. After that time, the term \\"Middle East\\" gained broader usage in Europe and the United States, with the Middle East Institute founded in Washington, D.C. in 1946, among other usage.[17]\\r\\nThe description Middle has also led to some confusion over changing definitions. Before the First World War, \\"Near East\\" was used in English to refer to the Balkans and the Ottoman Empire, while \\"Middle East\\" referred to Iran, the Caucasus, Afghanistan, Central Asia, and Turkestan. In contrast, \\"Far East\\" referred to the countries of East Asia (e.g. China, Japan, Korea, etc.)\\r\\nWith the disappearance of the Ottoman Empire in 1918, \\"Near East\\" largely fell out of common use in English, while \\"Middle East\\" came to be applied to the re-emerging countries of the Islamic world. However, the usage \\"Near East\\" was retained by a variety of academic disciplines, including archaeology and ancient history, where it describes an area identical to the term Middle East, which is not used by these disciplines (see Ancient Near East).\\r\\nThe first official use of the term \\"Middle East\\" by the United States government was in the 1957 Eisenhower Doctrine, which pertained to the Suez Crisis. Secretary of State John Foster Dulles defined the Middle East as \\"the area lying between and including Libya on the west and Pakistan on the east, Syria and Iraq on the North and the Arabian peninsula to the south, plus the Sudan and Ethiopia.\\"[16] In 1958, the State Department explained that the terms \\"Near East\\" and \\"Middle East\\" were interchangeable, and defined the region as including only Egypt, Syria, Israel, Lebanon, Jordan, Iraq, Saudi Arabia, Kuwait, Bahrain, and Qatar.[18]\\r\\nThe Associated Press Stylebook says that Near East formerly referred to the farther west countries while Middle East referred to the eastern ones, but that now they are synonymous. It instructs:\\r\\nUse Middle East unless Near East is used by a source in a story. Mideast is also acceptable, but Middle East is preferred.[19]\\r\\nThe term Middle East has also been criticised as Eurocentric (\\"based on a British Western perception\\") by Hanafi (1998).[20]\\r\\nThere are terms similar to Near East and Middle East in other European languages, but since it is a relative description, the meanings depend on the country and are different from the English terms generally. In German the term Naher Osten (Near East) is still in common use (nowadays the term Mittlerer Osten is more and more common in press texts translated from English sources, albeit having a distinct meaning) and in Russian ҳ Ҿ or Blizhniy Vostok, Bulgarian ҽ俹 ʽҾ, Polish Bliski Wsch܇d or Croatian Bliski istok (meaning Near East in all the four Slavic languages) remains as the only appropriate term for the region. However, some languages do have \\"Middle East\\" equivalents, such as the French Moyen-Orient, Swedish Mellan?stern, Spanish Oriente Medio or Medio Oriente, and the Italian Medio Oriente.[note 2]\\r\\nPerhaps because of the influence of the Western press, the Arabic equivalent of Middle East (Arabic: ????? ?????? ash-Sharq al-Awsa?), has become standard usage in the mainstream Arabic press, comprehending the same meaning as the term \\"Middle East\\" in North American and Western European usage. The designation, Mashriq, also from the Arabic root for East, also denotes a variously defined region around the Levant, the eastern part of the Arabic-speaking world (as opposed to the Maghreb, the western part).[21] Even though the term originated in the West, apart from Arabic, other languages of countries of the Middle East also use a translation of it. The Persian equivalent for Middle East is ????????? (Khvar-e miyneh), the Hebrew is ????? ?????? (hamizrach hatikhon) and the Turkish is Orta Do?u.\\r\\nTraditionally included within the Middle East are Iran (Persia), Asia Minor, Mesopotamia, the Levant, the Arabian Peninsula, and Egypt. In modern-day-country terms they are these:\\r\\nNotes: 1 Jerusalem is the proclaimed capital of Israel and the actual location of the Knesset, Israeli Supreme Court, and other governmental institutions of Israel. Ramallah is the actual location of the government of Palestine, whereas the proclaimed capital of Palestine is East Jerusalem, which is disputed.\\r\\n2 Controlled by the Houthis due to the ongoing war. Seat of government moved to Aden.\\r\\nVarious concepts are often being paralleled to Middle East, most notably Near East, Fertile Crescent and the Levant. Near East, Levant and Fertile Crescent are geographic concepts, which refer to large sections of the modern defined Middle East, with Near East being the closest to Middle East in its geographic meaning.\\r\\nThe countries of the South CaucasusArmenia, Azerbaijan, and Georgiaare occasionally included in definitions of the Middle East.[24]\\r\\nThe Greater Middle East was a political term coined by the second Bush administration in the first decade of the 21st century,[25] to denote various countries, pertaining to the Muslim world, specifically Iran, Turkey, Afghanistan and Pakistan.[26] Various Central Asian countries are sometimes also included.[27]\\r\\nThe Middle East lies at the juncture of Eurasia and Africa and of the Mediterranean Sea and the Indian Ocean. It is the birthplace and spiritual center of religions such as Christianity, Islam, Judaism, Manichaeism, Yezidi, Druze, Yarsan and Mandeanism, and in Iran, Mithraism, Zoroastrianism, Manicheanism, and the Bah' Faith. Throughout its history the Middle East has been a major center of world affairs; a strategically, economically, politically, culturally, and religiously sensitive area.\\r\\nThe world's earliest civilizations, Mesopotamia (Sumer, Akkad, Assyria and Babylonia) and ancient Egypt, originated in the Fertile Crescent and Nile Valley regions of the ancient Near East. These were followed by the Hittite, Greek and Urartian civilisations of Asia Minor, Elam in pre-Iranian Persia, as well as the civilizations of the Levant (such as Ebla, Ugarit, Canaan, Aramea, Phoenicia and Israel), Persian and Median civilizations in Iran, North Africa (Carthage/Phoenicia) and the Arabian Peninsula (Magan, Sheba, Ubar). The Near East was first largely unified under the Neo Assyrian Empire, then the Achaemenid Empire followed later by the Macedonian Empire and after this to some degree by the Iranian empires (namely the Parthian and Sassanid Empires), the Roman Empire and Byzantine Empire. However, it would be the later Arab Caliphates of the Middle Ages, or Islamic Golden Age which began with the Arab conquest of the region in the 7th century AD, that would first unify the entire Middle East as a distinct region and create the dominant Islamic ethnic identity that largely (but not exclusively) persists today. The Mongols, the Kingdom of Armenia, the Seljuks, the Safavids, the Ottoman Empire, and the British Empire also dominated the region.\\r\\nThe modern Middle East began after World War I, when the Ottoman Empire, which was allied with the Central Powers, was defeated by the British Empire and their allies and partitioned into a number of separate nations, initially under British and French Mandates. Other defining events in this transformation included the establishment of Israel in 1948 and the eventual departure of European powers, notably Britain and France by the end of the 1960s. They were supplanted in some part by the rising influence of the United States from the 1970s onwards.\\r\\nIn the 20th century, the region's significant stocks of crude oil gave it new strategic and economic importance. Mass production of oil began around 1945, with Saudi Arabia, Iran, Kuwait, Iraq, and the United Arab Emirates having large quantities of oil.[28] Estimated oil reserves, especially in Saudi Arabia and Iran, are some of the highest in the world, and the international oil cartel OPEC is dominated by Middle Eastern countries.\\r\\nDuring the Cold War, the Middle East was a theater of ideological struggle between the two superpowers and their allies: NATO and the United States on one side, and the Soviet Union and Warsaw Pact on the other, as they competed to influence regional allies. Of course, besides the political reasons there was also the \\"ideological conflict\\" between the two systems. Moreover, as Louise Fawcett argues, among many important areas of contention, or perhaps more accurately of anxiety, were, first, the desires of the superpowers to gain strategic advantage in the region, second, the fact that the region contained some two thirds of the world's oil reserves in a context where oil was becoming increasingly vital to the economy of the Western world [...][29] Within this contextual framework, the United States sought to divert the Arab world from Soviet influence. Throughout the 20th and 21st centuries, the region has experienced both periods of relative peace and tolerance and periods of conflict particularly between Sunnis and Shiites.\\r\\nArabs constitute the largest ethnic group in the Middle East, followed by Turkic people. Native ethnic groups of the region include, in addition to Arabs, Jews, Arameans, Assyrians, Baloch, Berbers, Copts, Druze, Kurds, Lurs, Mandaeans, Persians, Samaritans, Shabaks, Tats, and Zazas.\\r\\n\\"Migration has always provided an important vent for labor market pressures in the Middle East. For the period between the 1970s and 1990s, the Arab states of the PersianGulf in particular provided a rich source of employment for workers from Egypt, Yemen and the countries of the Levant, while Europe had attracted young workers from North African countries due both to proximity and the legacy of colonial ties between Franceand the majority of North African states.\\" [30] According to the International Organization for Migration, there are 13 million first-generation migrants from Arab nations in the world, of which 5.8 reside in other Arab countries. Expatriates from Arab countries contribute to the circulation of financial and human capital in the region and thus significantly promote regional development. In 2009 Arab countries received a total of 35.1 billion USD in remittance in-flows and remittances sent to Jordan, Egypt and Lebanon from other Arab countries are 40 to 190 per cent higher than trade revenues between these and other Arab countries.[31] In Somalia, the Somali Civil War has greatly increased the size of the Somali diaspora, as many of the best educated Somalis left for Europe, North America and other Middle Eastern countries.\\r\\nNon-Arab Middle Eastern countries such as Turkey, Israel and Iran are also subject to important migration dynamics.\\r\\nA fair proportion of those migrating from Arab nations are from ethnic and religious minorities facing racial and or religious persecution and are not necessarily ethnic Arabs, Iranians or Turks.[citation needed] Large numbers of Kurds, Jews, Assyrians, Greeks and Armenians as well as many Mandeans have left nations such as Iraq, Iran, Syria and Turkey for these reasons during the last century. In Iran, many religious minorities such as Christians, Baha'is and Zoroastrians have left since the Islamic Revolution of 1979.[citation needed]\\r\\nThe Middle East is very diverse when it comes to religions, many of which originated there. Islam is the largest religion in the Middle East, but other faiths that originated there, such as Judaism and Christianity, are also well represented. Christians represent 40.5% of Lebanon, where the Lebanese president, half of the cabinet, and half of the parliament follow one of the various Lebanese Christian rites. There are also important minority religions like the Bah' Faith, Yarsanism, Yazidism, Zoroastrianism, Mandaeism, Druze, and Shabakism, and in ancient times the region was home to Mesopotamian religions, Canaanite religions, Manichaeism, Mithraism and various monotheist gnostic sects.\\r\\nThe five top languages, in terms of numbers of speakers, are Arabic, Persian, Turkish, Kurdish, and Hebrew. Arabic and Hebrew represent the Afro-Asiatic language family. Persian and Kurdish belong to the Indo-European language family. Turkish belongs to Turkic language family. About 20 minority languages are also spoken in the Middle East.\\r\\nArabic, with all its dialects, are the most widely spoken languages in the Middle East, with Literary Arabic being official in all North African and in most West Asian countries. Arabic dialects are also spoken in some adjacent areas in neighbouring Middle Eastern non-Arab countries. It is a member of the Semitic branch of the Afro-Asiatic languages. Several Modern South Arabian languages such as Mehri and Soqotri are also spoken Yemen and Oman. Another Semitic language such as Aramaic and its dialects are spoken mainly by Assyrians and Mandaeans. There is also a Oasis Berber-speaking community in Egypt where the language is also known as Siwa. It is a non-Semitic Afro-Asiatic language.\\r\\nPersian is the second most spoken language. While it is primarily spoken in Iran and some border areas in neighbouring countries, the country is one of the region's largest and most populous. It belongs to the Indo-Iranian branch of the family of Indo-European languages. Other Western Iranic languages spoken in the region include Achomi, Daylami, Kurdish dialects, Semmani, Lurish, amongst many others.\\r\\nThe third-most widely spoken language, Turkish, is largely confined to Turkey, which is also one of the region's largest and most populous countries, but it is present in areas in neighboring countries. It is a member of the Turkic languages, which have their origins in Central Asia. Another Turkic language, Azerbaijani, is spoken by Azerbaijanis in Iran.\\r\\nHebrew is one of the two official languages of Israel, the other being Arabic. Hebrew is spoken and used by over 80% of Israel's population, the other 20% using Arabic.\\r\\nEnglish is commonly taught and used as a second language, especially among the middle and upper classes, in countries such as Egypt, Jordan, Iran, Kurdistan, Iraq, Qatar, Bahrain, United Arab Emirates and Kuwait.[32][33] It is also a main language in some Emirates of the United Arab Emirates.\\r\\nFrench is taught and used in many government facilities and media in Lebanon, and is taught in some primary and secondary schools of Egypt and Syria. Maltese, a Semitic language mainly spoken in Europe, is also used by the Franco-Maltese diaspora in Egypt.\\r\\nArmenian and Greek speakers are also to be found in the region. Georgian is spoken by the Georgian diaspora. Russian is spoken by a large portion of the Israeli population, because of emigration in the late 1990s. Russian today is a popular unofficial language in use in Israel; news, radio and sign boards can be found in Russian around the country after Hebrew and Arabic. Circassian is also spoken by the diaspora in the region and by almost all Circassians in Israel who speak Hebrew and English as well. The largest Romanian-speaking community in the Middle East is found in Israel, where as of 1995[update] Romanian is spoken by 5% of the population.[note 3][34][35]\\r\\nBengali, Hindi and Urdu is widely spoken by migrant communities in many Middle Eastern countries, such as Saudi Arabia (where 20ÿ25% of the population is South Asian), the United Arab Emirates (where 50ÿ55% of the population is South Asian), and Qatar, which have large numbers of Pakistani, Bangladeshi and Indian immigrants.\\r\\nMiddle Eastern economies range from being very poor (such as Gaza and Yemen) to extremely wealthy nations (such as Qatar and UAE). Overall, as of 2007[update], according to the CIA World Factbook, all nations in the Middle East are maintaining a positive rate of growth.\\r\\nAccording to the World Bank's World Development Indicators database published on July 1, 2009, the three largest Middle Eastern economies in 2008 were Turkey ($794,228,000,000), Saudi Arabia ($467,601,000,000) and Iran ($385,143,000,000) in terms of Nominal GDP.[36] Regarding nominal GDP per capita, the highest ranking countries are Qatar ($93,204), the UAE ($55,028), Kuwait ($45,920) and Cyprus ($32,745).[37] Turkey ($1,028,897,000,000), Iran ($839,438,000,000) and Saudi Arabia ($589,531,000,000) had the largest economies in terms of GDP-PPP.[38] When it comes to per capita (PPP)-based income, the highest-ranking countries are Qatar ($86,008), Kuwait ($39,915), the UAE ($38,894), Bahrain ($34,662) and Cyprus ($29,853). The lowest-ranking country in the Middle East, in terms of per capita income (PPP), is the autonomous Palestinian Authority of Gaza and the West Bank ($1,100).\\r\\nThe economic structure of Middle Eastern nations are different in the sense that while some nations are heavily dependent on export of only oil and oil-related products (such as Saudi Arabia, the UAE and Kuwait), others have a highly diverse economic base (such as Cyprus, Israel, Turkey and Egypt). Industries of the Middle Eastern region include oil and oil-related products, agriculture, cotton, cattle, dairy, textiles, leather products, surgical instruments, defence equipment (guns, ammunition, tanks, submarines, fighter jets, UAVs, and missiles). Banking is also an important sector of the economies, especially in the case of UAE and Bahrain.\\r\\nWith the exception of Cyprus, Turkey, Egypt, Lebanon and Israel, tourism has been a relatively undeveloped area of the economy, in part because of the socially conservative nature of the region as well as political turmoil in certain regions of the Middle East. In recent years, however, countries such as the UAE, Bahrain, and Jordan have begun attracting greater number of tourists because of improving tourist facilities and the relaxing of tourism-related restrictive policies.\\r\\nUnemployment is notably high in the Middle East and North Africa region, particularly among young people aged 15ÿ29, a demographic representing 30% of the region's total population. The total regional unemployment rate in 2005, according to the International Labour Organization, was 13.2%,[39] and among youth is as high as 25%,[40] up to 37% in Morocco and 73% in Syria.[41]\\r\\nAbu Dhabi - UAE\\r\\nAmman - Jordan\\r\\nAnkara - Turkey\\r\\nBaghdad - Iraq\\r\\nBeirut - Lebanon\\r\\nCairo - Egypt\\r\\nDamascus - Syria\\r\\nDoha - Qatar\\r\\nDubai - UAE\\r\\nIstanbul - Turkey\\r\\nJerusalem - Israel\\r\\nKuwait City - Kuwait\\r\\nManama - Bahrain\\r\\nMecca - Saudi Arabia\\r\\nMuscat, Oman\\r\\nRamallah - Palestine\\r\\nRiyadh - Saudi Arabia\\r\\nSana'a - Yemen\\r\\nTabriz - Iran\\r\\nTehran - Iran\\r\\nTel Aviv - Israel\\r\\n\\r\\nCoordinates: 29N 41E? / ?29N 41E? / 29; 41","input":"What is the most common language spoken in the middle east?"},{"output":"1950s","context":"This Golden Age of US Television has been marked by the production of a large number of internationally acclaimed television programs in the United States.[1][2][3][4] The period began in the late 1990s[5] or early 2000s.[6] It resulted from advances in technologies of media distribution,[7][8] as well as a large increase in the number of hours of available television, which prompted a major wave of content creation.[9]\\r\\nIts name refers to the original Golden Age of Television which occurred in the 1950s. It has also been referred to as the \\"New\\", \\"Second\\" or \\"Third Golden Age of Television\\" (\\"third\\" being used when a period in the early 1980s is considered a second Golden Age).[7][10][11][12][8][13]\\r\\nFrench scholar Alexis Pichard has argued that TV series enjoyed a Second Golden Age in the early 1990s which was a combination of three elements: first, an improvement in both visual aesthetics and storytelling; second, an overall homogeneity between cable series and networks series; and third, a tremendous popular success. Alexis Pichard contends that this Second Golden Age was the result of a revolution initiated by the traditional networks in the 1980s and carried on by the cable channels (especially HBO) in the 1990s.[14]\\r\\nBreaking Bad, Game of Thrones, The Walking Dead, Battlestar Galactica, Mad Men, The Shield, The Sopranos, Lost, The Americans, Six Feet Under, and The Wire are generally considered the basis of the so-called Golden Age of Television, i.e. the new creator-driven tragic dramas of the 2000s and 2010s.[13][15][16] The Writer's Guild of America vote for 101 Best Written TV Shows includes a complete foundation of the current Golden Age of Television. [17] Stephanie Zacharek of The Village Voice has argued that it began earlier with network shows like Buffy the Vampire Slayer, Star Trek: Deep Space Nine, and Babylon 5.[5] With the rise of instant access to content on Netflix, creator-driven television shows like Breaking Bad, Friday Night Lights, Mad Men, and The Shield gained cult followings that grew to become widely popular. The success of instant access to television shows was presaged by the popularity of DVDs, and continues to increase with the rise of digital platforms and online companies.\\r\\nThe increase in the number of shows is also cited as evidence of a Golden Age. In the five years between 2011 and 2016, the number of scripted television shows, on broadcast, cable and digital platforms increased by 71%. In 2002, 182 television shows aired, while 2016 saw 455 original scripted television shows with an additional increase projected for 2017. The number of shows are rising largely due to companies like Netflix, Amazon Video and Hulu investing heavily in original content. The number of shows aired by online service increased from only one in 2009 to over 93 in 2016. John Landgraf, the CEO of FX Networks, has stated that the United States has reached \\"peak television\\", where the amount of television series being aired could be overwhelming for the viewer to choose from, especially for critics obligated to review as many shows as possible, which results in a decreased output of television series in the future.[18][19][20][21][22]","input":"When did the golden age of tv start?"},{"output":"India","context":"The history of hospitals has stretched over 2500 years.\\r\\n\\r\\nIn ancient cultures, religion and medicine were linked. The earliest documented institutions aiming to provide cures were ancient Egyptian temples. In ancient Greece, temples dedicated to the healer-god Asclepius, known as Asclepieia (Ancient Greek: ??ϫ, sing. Asclepieion, ??), functioned as centres of medical advice, prognosis, and healing.[1] At these shrines, patients would enter a dream-like state of induced sleep known as enkoimesis (?۰?׻ҿ?) not unlike anesthesia, in which they either received guidance from the deity in a dream or were cured by surgery.[2] Asclepeia provided carefully controlled spaces conducive to healing and fulfilled several of the requirements of institutions created for healing.[3] In the Asclepieion of Epidaurus, three large marble boards dated to 350 BC preserve the names, case histories, complaints, and cures of about 70 patients who came to the temple with a problem and shed it there. Some of the surgical cures listed, such as the opening of an abdominal abscess or the removal of traumatic foreign material, are realistic enough to have taken place, but with the patient in a state of enkoimesis induced with the help of soporific substances such as opium.[2] The worship of Asclepius was adopted by the Romans. Under his Roman name ?sculapius, he was provided with a temple (291 BC) on an island in the Tiber in Rome, where similar rites were performed.[4]\\r\\n\\r\\n\\r\\nInstitutions created specifically to care for the ill also appeared early in India. Fa Xian, a Chinese Buddhist monk who travelled across India ca. 400 AD, recorded in his travelogue [5] that \\r\\nThe heads of the Vaishya [merchant] families in them [all the kingdoms of north India] establish in the cities houses for dispensing charity and medicine. All the poor and destitute in the country, orphans, widowers, and childless men, maimed people and cripples, and all who are diseased, go to those houses, and are provided with every kind of help, and doctors examine their diseases. They get the food and medicines which their cases require, and are made to feel at ease; and when they are better, they go away of themselves.\\r\\n\\r\\nThe earliest surviving encyclopaedia of medicine in Sanskrit is the Carakasamhita (Compendium of Caraka). This text, which describes the building of a hospital is dated by the medical historian Dominik Wujastyk to the period between 100 BCE and 150 CE.[6] The description by Fa Xian is one of the earliest accounts of a civic hospital system anywhere in the world and this evidence, coupled with Carakas description of how a clinic should be built and equipped, suggests that India may have been the first part of the world to have evolved an organized cosmopolitan system of institutionally-based medical provision.[7]\\r\\n\\r\\nKing Ashoka is wrongly said by many secondary sources to have founded at hospitals in ca. 230 BCE[8]\\r\\n\\r\\nAccording to the Mahavamsa, the ancient chronicle of Sinhalese royalty, written in the sixth century CE, King Pandukabhaya of Sri Lanka (reigned 437 BCE to 367 BCE) had lying-in-homes and hospitals (Sivikasotthi-Sala) built in various parts of the country. This is the earliest documentary evidence we have of institutions specifically dedicated to the care of the sick anywhere in the world.[9][10] Mihintale Hospital is the oldest in the world.[11]\\r\\n\\r\\nThe Romans constructed buildings called valetudinaria for the care of sick slaves, gladiators, and soldiers around 100 BCE, and many were identified by later archeology. While their existence is considered proven, there is some doubt as to whether they were as widespread as was once thought, as many were identified only according to the layout of building remains, and not by means of surviving records or finds of medical tools.[12]\\r\\n\\r\\nThe declaration of Christianity as an accepted religion in the Roman Empire drove an expansion of the provision of care. Following First Council of Nicaea in 325 CE construction of a hospital in every cathedral town was begun. Among the earliest were those built by the physician Saint Sampson in Constantinople and by Basil, bishop of Caesarea in modern-day Turkey. Called the \\"Basilias\\", the latter resembled a city and included housing for doctors and nurses and separate buildings for various classes of patients.[13] There was a separate section for lepers.[14] Some hospitals maintained libraries and training programs, and doctors compiled their medical and pharmacological studies in manuscripts. Thus in-patient medical care in the sense of what we today consider a hospital, was an invention driven by Christian mercy and Byzantine innovation.[15] Byzantine hospital staff included the Chief Physician (archiatroi), professional nurses (hypourgoi) and the orderlies (hyperetai). By the twelfth century, Constantinople had two well-organized hospitals, staffed by doctors who were both male and female. Facilities included systematic treatment procedures and specialized wards for various diseases.[16]\\r\\n\\r\\nA hospital and medical training centre also existed at Gundeshapur. The city of Gundeshapur was founded in 271 CE by the Sassanid king Shapur I. It was one of the major cities in Khuzestan province of the Persian empire, in Iran. A large percentage of the population were Syriacs, most of whom were Christians. Under the rule of Khusraw I, refuge was granted to Greek Nestorian Christian philosophers including the scholars of the Persian School of Edessa (Urfa) (also called the Academy of Athens), a Christian theological and medical university. These scholars made their way to Gundeshapur in 529 following the closing of the academy by Emperor Justinian. They were engaged in medical sciences and initiated the first translation projects of medical texts.[17]  The arrival of these medical practitioners from Edessa marks the beginning of the hospital and medical centre at Gundeshapur.[18] It included a medical school and hospital (bimaristan), a pharmacology laboratory, a translation house, a library and an observatory.[19] Indian doctors also contributed to the school at Gundeshapur, most notably the medical researcher Mankah. Later after Islamic invasion, the writings of Mankah and of the Indian doctor Sustura were translated into Arabic at Baghdad.[20]\\r\\n\\r\\nMedieval hospitals in Europe followed a similar pattern to the Byzantine. They were religious communities, with care provided by monks and nuns. (An old French term for hospital is h?tel-Dieu, \\"hostel of God.\\") Some were attached to monasteries; others were independent and had their own endowments, usually of property, which provided income for their support. Some hospitals were multi-functional while others were founded for specific purposes such as leper hospitals, or as refuges for the poor, or for pilgrims: not all cared for the sick. The first Spanish hospital, founded by the Catholic Visigoth bishop Masona in 580 CE at Mrida, was a xenodochium designed as an inn for travellers (mostly pilgrims to the shrine of Eulalia of Mrida) as well as a hospital for citizens and local farmers. The hospital's endowment consisted of farms to feed its patients and guests. From the account given by Paul the Deacon we learn that this hospital was supplied with physicians and nurses, whose mission included the care the sick wherever they were found, \\"slave or free, Christian or Jew.\\" [21]\\r\\nIn 650, the \\"H?tel-Dieu\\" was found in Paris[22], it is considered as the oldest worldwide hospital still operating today.[23] It was a multipurpose institution which catered for the sick and poor, offering shelter, food and medical care.\\r\\n\\r\\nDuring the late 8th and early 9th centuries, Emperor Charlemagne decreed that those hospitals that had been well conducted before his time and had fallen into decay should be restored in accordance with the needs of the time.[24] He further ordered that a hospital should be attached to each cathedral and monastery.[24]\\r\\n\\r\\nDuring the 10th century, the monasteries became a dominant factor in hospital work. The famous Benedictine Abbey of Cluny, founded in 910, set the example which was widely imitated throughout France and Germany. Besides its infirmary for the religious, each monastery had a hospital in which externs were cared for. These were in charge of the eleemosynarius, whose duties, carefully prescribed by the rule, included every sort of service that the visitor or patient could require.\\r\\n\\r\\nAs the eleemosynarius was obliged to seek out the sick and needy in the neighborhood, each monastery became a center for the relief of suffering. Among the monasteries notable in this respect were those of the Benedictines at Corbie in Picardy, Hirschau, Braunweiler, Deutz, Ilsenburg, Liesborn, Pram, and Fulda; those of the Cistercians at Arnsberg, Baumgarten, Eberbach, Himmenrode, Herrnalb, Volkenrode, and Walkenried.\\r\\n\\r\\nNo less efficient was the work done by the diocesan clergy in accordance with the disciplinary enactments of the councils of Aachen (817, 836), which prescribed that a hospital should be maintained in connection with each collegiate church. The canons were obliged to contribute towards the support of the hospital, and one of their number had charge of the inmates. As these hospitals were located in cities, more numerous demands were made upon them than upon those attached to the monasteries. In this movement the bishop naturally took the lead, hence the hospitals founded by Heribert (d. 1021) in Cologne, Godard (d. 1038) in Hildesheim, Conrad (d. 975) in Constance, and Ulrich (d. 973) in Augsburg. But similar provision was made by the other churches; thus at Trier the hospitals of Saint Maximin, Saint Matthew, Saint Simeon, and Saint James took their names from the churches to which they were attached. During the period 1207ÿ1577 no less than one hundred and fifty-five hospitals were founded in Germany.[25]\\r\\n\\r\\nThe Ospedale Maggiore, traditionally named Ca' Granda (i.e. Big House), in Milan, northern Italy, was constructed to house one of the first community hospitals, the largest such undertaking of the fifteenth century. Commissioned by Francesco Sforza in 1456 and designed by Antonio Filarete it is among the first examples of Renaissance architecture in Lombardy.\\r\\n\\r\\nThe Normans brought their hospital system along when they conquered England in 1066. By merging with traditional land-tenure and customs, the new charitable houses became popular and were distinct from both English monasteries and French hospitals.  They dispensed alms and some medicine, and were generously endowed by the nobility and gentry who counted on them for spiritual rewards after death.[26]\\r\\n\\r\\nThe first Muslim hospital was an asylum to contain leprosy, built in the early eighth century, where patients were confined but, like the blind, were given a stipend to support their families.[27] The earliest general hospital was built in 805 in Baghdad by Harun Al-Rashid.[28][29] By the tenth century, Baghdad had five more hospitals, while Damascus had six hospitals by the 15th century and C܇rdoba alone had 50 major hospitals, many exclusively for the military.[27] Many of the prominent early Islamic hospitals were founded with assistance by Christians such as Jibrael ibn Bukhtishu from Gundeshapur.[30][31] \\"Bimaristan\\" is a compound of bimar (sick or ill) and stan (place). In the medieval Islamic world, the word \\"bimaristan\\" referred to a hospital establishment where the ill were welcomed, cared for and treated by qualified staff.\\r\\n\\r\\nThe United States National Library of Medicine credits the hospital as being a product of medieval Islamic civilization. Compared to contemporaneous Christian institutions, which were poor and sick relief facilities offered by some monasteries, the Islamic hospital was a more elaborate institution with a wider range of functions. In Islam, there was a moral imperative to treat the ill regardless of financial status. Islamic hospitals tended to be large, urban structures, and were largely secular institutions, many open to all, whether male or female, civilian or military, child or adult, rich or poor, Muslim or non-Muslim. The Islamic hospital served several purposes, as a center of medical treatment, a home for patients recovering from illness or accidents, an insane asylum, and a retirement home with basic maintenance needs for the aged and infirm.[32]\\r\\n\\r\\nThe typical hospital was divided into departments such as systemic diseases, surgery and orthopedics with larger hospitals having more diverse specialties. \\"Systemic diseases\\" was the rough equivalent of today's internal medicine and was further divided into sections such as fever, infections and digestive issues. Every department had an officer-in-charge, a presiding officer and a supervising specialist. The hospitals also had lecture theaters and libraries. Hospitals staff included sanitary inspectors, who regulated cleanliness, and accountants and other administrative staff.[27] The hospital in Baghdad employed twenty-five staff physicians.[33] The hospitals were typically run by a three-man board comprising a non-medical administrator, the chief pharmacist, called the shaykh saydalani, who was equal in rank to the chief physician, who served as mutwalli (dean).[34] Medical facilities traditionally closed each night, but by the 10th century laws were passed to keep hospitals open 24 hours a day.[35]\\r\\n\\r\\nFor less serious cases, physicians staffed outpatient clinics. Cities also had first aid centers staffed by physicians for emergencies that were often located in busy public places, such as big gatherings for Friday prayers to take care of casualties. The region also had mobile units staffed by doctors and pharmacists who were supposed to meet the need of remote communities. Baghdad was also known to have a separate hospital for convicts since the early 10th century after the vizier Ali ibn Isa ibn Jarah ibn Thabit wrote to Baghdads chief medical officer that prisons must have their own doctors who should examine them every day. The first hospital built in Egypt, in Cairo's Southwestern quarter, was the first documented facility to care for mental illnesses while the first Islamic psychiatric hospital opened in Baghdad in 705.[36][27]\\r\\n\\r\\nMedical students would accompany physicians and participate in patient care. Hospitals in this era were the first to require medical diplomas to license doctors.[37] The licensing test was administered by the region's government appointed chief medical officer. The test had two steps; the first was to write a treatise, on the subject the candidate wished to obtain a certificate, of original research or commentary of existing texts, which they were encouraged to scrutinize for errors. The second step was to answer questions in an interview with the chief medical officer. Physicians worked fixed hours and medical staff salaries were fixed by law. For regulating the quality of care and arbitrating cases, it is related that if a patient dies, their family presents the doctor's prescriptions to the chief physician who would judge if the death was natural or if it was by negligence, in which case the family would be entitled to compensation from the doctor. The hospitals had male and female quarters while some hospitals only saw men and other hospitals, staffed by women physicians, only saw women.[27] While women physicians practiced medicine, many largely focused on obstetrics.[38]\\r\\n\\r\\n\\r\\nHospitals were forbidden by law to turn away patients who were unable to pay.[35] Eventually, charitable foundations called waqfs were formed to support hospitals, as well as schools.[35] Part of the state budget also went towards maintaining hospitals.[27] While the services of the hospital were free for all citizens[35] and patients were sometimes given a small stipend to support recovery upon discharge, individual physicians occasionally charged fees.[27] In a notable endowment, a 13th-century governor of Egypt Al Mansur Qalawun ordained a foundation for the Qalawun hospital that would contain a mosque and a chapel, separate wards for different diseases, a library for doctors and a pharmacy[39] and the hospital is used today for ophthalmology.[27] The Qalawun hospital was based in a former Fatimid palace which had accommodation for 8,000 people - [40] \\"it served 4,000 patients daily.\\"[41] The waqf stated, \\r\\n\\"...The hospital shall keep all patients, men and women, until they are completely recovered. All costs are to be borne by the hospital whether the people come from afar or near, whether they are residents or foreigners, strong or weak, low or high, rich or poor, employed or unemployed, blind or sighted, physically or mentally ill, learned or illiterate. There are no conditions of consideration and payment, none is objected to or even indirectly hinted at for non-payment.\\"[39]\\r\\nThe first, most well known physicians in the Medieval Islamic world were polymaths Ibn Sina, (Greek: Avicenna) and Al Rhazi (Greek: Rhazes) during the 7th century.[42]\\r\\n\\r\\nIn Europe the medieval concept of Christian care evolved during the sixteenth and seventeenth centuries into a secular one.[43] Theology was the problem.  The Protestant reformers rejected the Catholic belief that rich men could gain God's grace through good works ÿ and escape purgatory ÿ by providing endowments to charitable institutions, and that the patients themselves could gain grace through their suffering.[44]\\r\\n\\r\\nAfter the dissolution of the monasteries in 1540 by King Henry VIII the church abruptly ceased to be the supporter of hospitals, and only by direct petition from the citizens of London, were the hospitals St Bartholomew's, St Thomas's and St Mary of Bethlehem's (Bedlam) endowed directly by the crown; this was the first instance of secular support being provided for medical institutions.[45] It was at St. Bartholomew that William Harvey conducted his research on the circulatory system in the 17th century, Percivall Pott and John Abernethy developed important principles of modern surgery in the 18th century, and Mrs. Bedford Fenwich worked to advance the nursing profession in the late 19th century.[46]\\r\\n\\r\\nThere were 28 asylums in Sweden at the start of the Reformation. Gustav Vasa removed them from church control and expelled the monks and nuns, but allowed the asylums to keep their properties and to continue their activities under the auspices of local government.[47]\\r\\n\\r\\nIn much of Europe town governments operated small Holy Spirit hospitals, which had been founded in the 13th and 14th centuries. They distributed free food and clothing to the poor, provided for homeless women and children, and gave some medical and nursing care. Many were raided and closed during the Thirty Years War (1618ÿ48), which ravaged the towns and villages of Germany and neighboring areas for three decades.\\r\\n\\r\\nMeanwhile, in Catholic lands such as France, rich families continued to fund convents and monasteries that provided free health services to the poor.  French practices were influenced by a charitable imperative which considered care of the poor and the sick to be a necessary part of Catholic practice. The nursing nuns had little faith in the power of physicians and their medicines alone to cure the sick; more important was providing psychological and physical comfort, nourishment, rest, cleanliness and especially prayer.[48]\\r\\n\\r\\nIn Protestant areas the emphasis was on scientific rather than religious aspects of patient care, and this helped develop a view of nursing as a profession rather than a vocation.[49]  There was little hospital development by the main Protestant churches after 1530.[50] Some smaller groups such as the Moravians and the Pietists at Halle gave a role for hospitals, especially in missionary work.[51]\\r\\n\\r\\nIn the 18th century, under the influence of the Age of Enlightenment, the modern hospital began to appear, serving only medical needs and staffed with trained physicians and surgeons. The nurses were untrained workers. The goal was to use modern methods to cure patients. They provided more narrow medical services, and were founded by the secular authorities. A clearer distinction emerged between medicine and poor relief. Within the hospitals, acute cases were increasingly treated alone, and separate departments were set up for different categories of patient.\\r\\n\\r\\nThe voluntary hospital movement began in the early 18th century, with hospitals being founded in London by the 1710s and 20s, including Westminster Hospital (1719) promoted by the private bank C. Hoare & Co and Guy's Hospital (1724) funded from the bequest of the wealthy merchant, Thomas Guy. Other hospitals sprang up in London and other British cities over the century, many paid for by private subscriptions.  St. Bartholomew's in London was rebuilt in 1730, and the London Hospital opened in 1752.\\r\\n\\r\\nThese hospitals represented a turning point in the function of the institution; they began to evolve from being basic places of care for the sick to becoming centres of medical innovation and discovery and the principle place for the education and training of prospective practitioners. Some of the era's greatest surgeons and doctors worked and passed on their knowledge at the hospitals.[52] They also changed from being mere homes of refuge to being complex institutions for the provision of medicine and care for sick. The Charit was founded in Berlin in 1710 by King Frederick I of Prussia as a response to an outbreak of plague.\\r\\n\\r\\nThe concept of voluntary hospitals also spread to Colonial America; the Bellevue Hospital opened in 1736, Pennsylvania Hospital in 1752, New York Hospital in 1771, and Massachusetts General Hospital in 1811.  When the Vienna General Hospital opened in 1784 (instantly becoming the world's largest hospital), physicians acquired a new facility that gradually developed into one of the most important research centres.[53]\\r\\n\\r\\nAnother Enlightenment era charitable innovation was the dispensary; these would issue the poor with medicines free of charge. The London Dispensary opened its doors in 1696 as the first such clinic in the British Empire. The idea was slow to catch on until the 1770s, when many such organizations began to appear, including the Public Dispensary of Edinburgh (1776), the Metropolitan Dispensary and Charitable Fund (1779) and the Finsbury Dispensary (1780). Dispensaries were also opened in New York 1771, Philadelphia 1786, and Boston 1796.[54]\\r\\n\\r\\nAcross Europe medical schools still relied primarily on lectures and readings. In the final year, students would have limited clinical experience by following the professor through the wards. Laboratory work was uncommon, and dissections were rarely done because of legal restrictions on cadavers. Most schools were small, and only Edinburgh, Scotland, with 11,000 alumni, produced large numbers of graduates.[55][56]\\r\\n\\r\\nThe first hospital founded in the Americas was the Hospital San Nicols de Bari [Calle Hostos] in Santo Domingo, Distrito Nacional Dominican Republic. Fray Nicols de Ovando, Spanish governor and colonial administrator from 1502ÿ1509, authorized its construction on December 29, 1503. This hospital apparently incorporated a church. The first phase of its construction was completed in 1519, and it was rebuilt in 1552.[57] Abandoned in the mid-18th century, the hospital now lies in ruins near the Cathedral in Santo Domingo.\\r\\n\\r\\nConquistador Hernn Corts founded the two earliest hospitals in North America: the Immaculate Conception Hospital and the Saint Lazarus Hospital. The oldest was the Immaculate Conception, now the Hospital de Jes~s Nazareno in Mexico City, founded in 1524 to care for the poor.[57]\\r\\n\\r\\nEnglish physician Thomas Percival (1740ÿ1804) wrote a comprehensive system of medical conduct,  'Medical Ethics, or a Code of Institutes and Precepts, Adapted to the Professional Conduct of Physicians and Surgeons (1803) that set the standard for many textbooks.[58]\\r\\n\\r\\n\\r\\nIn the mid 19th century, hospitals and the medical profession became more professionalized, with a reorganization of hospital management along more bureaucratic and administrative lines. The Apothecaries Act 1815 made it compulsory for medical students to practice for at least half a year at a hospital as part of their training.[59] An example of this professionalization was the Charing Cross Hospital, set up in 1818 as the 'West London Infirmary and Dispensary' from funds provided by Dr. Benjamin Golding. By 1821 it was treating nearly 10,000 patients a year, and it was relocated to larger quarters near Charing Cross in the heart of London. Its Charing Cross Hospital Medical School opened in 1822.  It expanded several times and 1866 added a professional nursing staff.[60]\\r\\nFlorence Nightingale pioneered the modern profession of nursing during the Crimean War when she set an example of compassion, commitment to patient care and diligent and thoughtful hospital administration. The first official nurses training programme, the Nightingale School for Nurses, was opened in 1860, with the mission of training nurses to work in hospitals, to work with the poor and to teach.[61]\\r\\n\\r\\nNightingale was instrumental in reforming the nature of the hospital, by improving sanitation standards and changing the image of the hospital from a place the sick would go to die, to an institution devoted to recuperation and healing. She also emphasized the importance of statistical measurement for determining the success rate of a given intervention and pushed for administrative reform at hospitals.[62]\\r\\n\\r\\nDuring the middle of the 19th century, the Second Viennese Medical School emerged with the contributions of physicians such as Carl Freiherr von Rokitansky, Josef ?koda, Ferdinand Ritter von Hebra, and Ignaz Philipp Semmelweis. Basic medical science expanded and specialization advanced. Furthermore, the first dermatology, eye, as well as ear, nose, and throat clinics in the world were founded in Vienna.[63]\\r\\n\\r\\nBy the late 19th century, the modern hospital was beginning to take shape with a proliferation of a variety of public and private hospital systems. By the 1870s, hospitals had more than tripled their original average intake of 3,000 patients. In continental Europe the new hospitals generally were built and run from public funds. Nursing was professionalized in France by the turn of the 20th century. At that time, the country's 1,500 hospitals were operated by 15,000 nuns representing over 200 religious orders. Government policy after 1900 was to secularize public institutions, and diminish the role the Catholic Church. This political goal came in conflict with the need to maintain better quality of medical care in antiquated facilities. New government-operated nursing schools turned out nonreligous nurses who were slated for supervisory roles. During the First World War, an outpouring of patriotic volunteers brought large numbers of untrained middle-class women into the military hospitals. They left when the war ended but the long-term effect was to heighten the prestige of nursing. In 1922 the government issued a national diploma for nursing.[64]\\r\\n\\r\\nIn the U.S., the number of hospitals reached 4400 in 1910, when they provided 420,000 beds.[65] These were operated by city, state and federal agencies, by churches, by stand-alone non-profits, and by for-profit enterprises. All the major denominations built hospitals; the 541 Catholic ones (in 1915) were staffed primarily by unpaid nuns. The others sometimes had a small cadre of deaconesses as staff.[66] Non-profit hospitals were supplemented by large public hospitals in major cities and research hospitals often affiliated with a medical school. The largest public hospital system in America is the New York City Health and Hospitals Corporation, which includes Bellevue Hospital, the oldest U.S. hospital, affiliated with New York University Medical School.[67]\\r\\n\\r\\nThe National Health Service, the principal provider of health care in Britain, was founded in 1948, and took control of nearly all the hospitals.[68]\\r\\n\\r\\nAt the turn of the 19th century, Paris medicine played a significant role in shaping clinical medicine. New emphasis on physically examining the body led to methods such as percussion, inspection, palpation, auscultation, and autopsy.[69] The situation in Paris was particularly unique due to the fact that there was a very large concentration of medical professionals in a very small setting allowing for a large flow of ideas and the spread of innovation.[69] One of the innovations to come out of the Paris hospital setting was Laennec's stethoscope. Weiner states that the widespread acceptance of the stethoscope would likely not have happened in any other setting, and the setting allowed for Laennec to pass on this technology to the eager medical community that had gathered there. This invention also brought even more attention to the Paris scene.[69]\\r\\n\\r\\nBefore the start of the 19th century, there were many problems existing within the French medical system. These problems were outlined by many seeking to reform hospitals including a contemporary surgeon Jacques Tenon in his book Memoirs on Paris Hospitals. Some of the problems Tenon drew attention to were the lack of space, the inability to separate patients based on the type of illness (including those that were contagious), and general sanitation problems.[70] Additionally, the secular revolution led to the nationalization of hospitals previously owned by the Catholic Church and led to a call for a hospital reform which actually pushed for the deinstitutionalization of medicine.[71] This contributed to the state of disarray Paris hospitals soon fell into which ultimately called for the establishment of a new hospital system outlined in the law of 1794. The law of 1794 played a significant part in revolutionizing Paris Medicine because it aimed to address some of the problems facing Paris Hospitals of the time.\\r\\n\\r\\nFirst, the law of 1794 created three new schools in Paris, Montpellier, and Strasbour due to the lack of medical professionals available to treat a growing French army. It also gave physicians and surgeons equal status in the hospital environment, whereas previously physicians were regarded as intellectually superior.[71] This led to the integration of surgery into traditional medical  education contributing to a new breed of doctors that focused on pathology, anatomy and diagnosis. The new focus on anatomy was further facilitated by this law because it ensured that medical students had enough bodies to dissect.[71] Additionally, pathological education was furthered by the increased use of autopsies to determine a patient's cause of death.[69] Lastly, the law of 1794 allocated funds for full-time salaried teachers in hospitals, as well as creating scholarships for medical students.[71] Overall, the law of 1794 contributed to the shift of medical teaching away from theory and towards practice and experience, all within a hospital setting. Hospitals became a center for learning and development of medical techniques, which was a departure from the previous notion of a hospital as an area that accepted people who needed help of any kind, ill or not.[72] This shift was consistent with much of the philosophy of the time, particularly the ideas of John Locke who preached that observation using ones senses was the best way to analyze and understand a phenomenon.[71] Foucalt, however, criticized this shift in his book The Birth of the Clinic, stating that this shift took attention away from the patient and objectified patients, ultimately resulting in a loss of the patient's narrative. He argued that from this point forward, in the eyes of doctors, patients lost their humanity and became more like objects for inspection and examination.[73]\\r\\n\\r\\nThe next advancement in Paris medicine came with the creation of an examination system, that after 1803, was required for the licensing of all medical professions creating a uniform and centralized system of licensing.[71] This law also created another class of health professionals, mostly for those living outside of cities, who did not have to go through the licensing pricess but instead went through a simpler and shorter training process.[71]\\r\\n\\r\\nAnother area influenced by Paris hospitals was the development of specialties. The structure of a Paris hospital allowed physicians more freedom to pursue interests as well as providing the necessary resources.[69] An example of a physician who used this flexibility to conduct research is Phillipe Pinel who conducted a four-year study on the hospitalization and treatment of mentally-ill women within the Salptrire hospital. This was the first study ever done of this magnitude by a physician, and the Pinel was the first to realize that patients dealing with similar illnesses could be group together, compared, and classified.[69]\\r\\n\\r\\nThe Protestant churches reentered the health field in the 19th century, especially with the establishment of orders of women, called deaconesses who dedicated themselves to nursing services. This movement began in Germany in 1836 when Theodor Fliedner and his wife opened the first deaconess motherhouse in Kaiserswerth on the Rhine. It became a model, and within half a century there were over 5,000 deaconesses in Europe. The Church of England named its first deaconess in 1862. The North London Deaconess Institution trained deaconesses for other dioceses and some served overseas.[74]\\r\\n\\r\\nWilliam Passavant in 1849 brought the first four deaconesses to Pittsburgh, in the United States, after visiting Kaiserswerth. They worked at the Pittsburgh Infirmary (now Passavant Hospital).[75]\\r\\n\\r\\nThe American Methodists made medical services a priority from the 1850s. They began opening charitable institutions such as orphanages and old people's homes. In the 1880s,  Methodists began opening hospitals in the United States, which served people of all religious beliefs. By 1895, 13 hospitals were in operation in major cities.[76]\\r\\n\\r\\nIn Quebec, Catholics operated hospitals continuously from the 1640s; they attracted nuns from the provincial elite. Jeanne Mance (1606ÿ73) founded Montreal's city's first hospital, the H?tel-Dieu de Montral, in 1645. In 1657 she recruited three sisters of the Religious Hospitallers of St. Joseph, and continued to direct operations of the hospital. The project, begun by the niece of Cardinal de Richelieu was granted a royal charter by King Louis XIII and staffed by a colonial physician, Robert Giffard de Moncel.[77]  The General Hospital in Quebec City opened in 1692.  They often handled malaria, dysentery, and respiratory sickness.[78]\\r\\n\\r\\nIn the 1840sÿ1880s era, Catholics in Philadelphia founded two hospitals, for the Irish and German Catholics. They depended on revenues from the paying sick, and became important health and welfare institutions in the Catholic community.[79]  By 1900 the Catholics had set up hospitals in most major cities. In New York the Dominicans, Franciscans, Sisters of Charity, and other orders set up hospitals to care primarily for their own ethnic group. By the 1920s they were serving everyone in the neighborhood.[80]  In smaller cities too the Catholics set up hospitals, such as St. Patrick Hospital in Missoula, Montana. The Sisters of Providence opened it in 1873. It was in part funded by the county contract to care for the poor, and also operated a day school and a boarding school. The nuns provided nursing care especially for infectious diseases and traumatic injuries among the young, heavily male clientele. They also proselytized the patients to attract converts and restore lapsed Catholics back into the Church. They built a larger hospital in 1890.[81] Catholic hospitals were largely staffed by Catholic orders of nuns, and nursing students, until the population of nuns dropped sharply after the 1960s.  The Catholic Hospital Association formed in 1915.[82][83]","input":"Where was the first hospital built in the world?"},{"output":"July 2017","context":"\\r\\n\\r\\n\\r\\nSeptember?19, 2014; 3 years ago?(2014-09-19) (16, 64 and 128GB models)\\r\\n\\r\\nThe iPhone 6 and iPhone 6 Plus are smartphones designed and marketed by Apple Inc. The devices are part of the iPhone series and were announced on September 9, 2014, and released on September 19, 2014.[17] The iPhone 6 and iPhone 6 Plus jointly serve as successors to the iPhone 5S and were themselves replaced as flagship devices of the iPhone series by the iPhone 6S and iPhone 6S Plus on September 9, 2015. The iPhone 6 and 6 Plus include larger 4.7 and 5.5 inches (120 and 140?mm) displays, a faster processor, upgraded cameras, improved LTE and Wi-Fi connectivity and support for a near field communications-based mobile payments offering.[18][19]\\r\\n\\r\\nThe iPhone 6 and 6 Plus received positive reviews, with critics regarding their improved design, specifications, camera, and battery life as being improvements over previous iPhone models. However, aspects of the design of iPhone 6 were also panned, including plastic strips on the rear of the device for its antenna that disrupted the otherwise metal exterior, and the screen resolution of the standard-sized iPhone 6 being lower than other devices in its class. Pre-orders of the iPhone 6 and iPhone 6 Plus exceeded four million within its first 24 hours of availabilityan Apple record.[20] More than ten million iPhone 6 and iPhone 6 Plus devices were sold in the first three days, another Apple record.[21] During its lifespan, the iPhone 6 and 6 Plus sold 220 million in total, making them the best selling iPhone models, so far, and one of the most successful phones to date.\\r\\n\\r\\nDespite their positive reception, the iPhone 6 and 6 Plus have been the subject of several hardware issues, including most prominently, being susceptible to bending under pressure, such as in a pocket. The iPhone 6s and 6s Plus were made with 7000 series aluminum (a design flaw nicknamed \\"Bendgate\\"), and as a byproduct of this lack of rigidity, the touchscreen's internal hardware being susceptible to losing its connection to the phone's logic board (nicknamed \\"Touch Disease\\"). The iPhone 6 Plus was also the subject of camera issues, including some devices with malfunctioning optical image stabilization or otherwise defects on rear cameras.\\r\\n\\r\\nThe iPhone 6 and 6 Plus were moved to the midrange spot in Apple's iPhone lineup when the iPhone 6S and 6S Plus were released in September 2015.  The iPhone 6 and 6 Plus were discontinued in most countries on September 7, 2016 when Apple announced the iPhone 7 and iPhone 7 Plus. Their spot as the entry-level iPhone was replaced by the iPhone SE, which was released earlier on March 31, 2016. The iPhone 6 was relaunched with 32?GB of storage in Asian markets in February 2017 as a midrange/budget iPhone. It was later expanded to Europe,[3][22] before hitting the US markets in May 2017,[23] and Canada in July 2017.[24]\\r\\n\\r\\nFrom the launch of the original iPhone to the iPhone 4S, iPhones used 3.5-inch displayswhich are smaller than screens used by flagship phones from competitors. The iPhone 5 and its immediate successors featured a display that was taller, but the same width as prior models, measuring at 4 inches diagonally. Following Apple's loss in smartphone market share to companies producing phones with larger displays, reports as early as January 2014 suggested that Apple was preparing to launch new iPhone models with larger, 4.7-inch and 5.5-inch displays.[25][26][27] Reports prior to its unveiling also speculated that Apple might use a new iPhone model to introduce a mobile payments platform using near-field communicationsa technology that has been incorporated into many Android phones, but has experienced a low adoption rate among users.[28]\\r\\n\\r\\nThe iPhone 6 and iPhone 6 Plus were officially unveiled during a press event at the Flint Center for Performing Arts in Cupertino, California on September 9, 2014 and released on September 19, 2014; pre-orders began on September 12, 2014, with the iPhone 6 starting at US$649 and the iPhone 6 Plus starting at US$749.[29] In China, where the iPhone 5c and 5s were the first models in the iPhone series to be released in the country on the same day as their international launch, Apple notified local wireless carriers that it would be unable to release the iPhone 6 and iPhone 6 Plus on the 19th because there were \\"details which are not ready\\"; local media reported that the devices had not yet been approved by the Ministry of Industry and Information Technology, and earlier in the year, a news report by state broadcaster China Central Television alleged that iPhone devices were a threat to national security because iOS 7's \\"frequent locations\\" function could expose \\"state secrets.\\"[30][31]\\r\\n\\r\\nIn August 2015, Apple admitted that some iPhone 6 Plus may have faulty cameras that could be causing photos to look blurry and initiated a replacement program.[32][33][34]\\r\\n\\r\\nOn September 9, 2015, with the release of the iPhone 6S and iPhone 6S Plus, the iPhone 6 and 6 Plus were moved to the mid-range of the iPhone lineup. The 128?GB versions of the iPhone 6 and iPhone 6 Plus was discontinued along with the gold version of both phones, but the 16?GB and 64?GB versions of the iPhone 6 and iPhone 6 Plus in silver and space gray remain available for sale at a reduced price.[35]\\r\\n\\r\\nIn June 2016, Apple faced a potential sales ban in China, as Shenzhen Baili, a Chinese device maker, alleged that the iPhone 6 and iPhone 6 Plus infringed on its design patent.[36]\\r\\n\\r\\nThe iPhone 6 and 6 Plus were discontinued on September 7, 2016, when Apple announced the iPhone 7 and iPhone 7 Plus, and the iPhone 6 and 6 Plus's spot as the entry-level iPhone has since been taken by the iPhone SE.  As the iPhone SE has more powerful internal hardware than the midrange iPhone 6 (largely the same as the 6S) and had been released earlier on March 31, 2016, this created an unusual situation when it was sold alongside the iPhone 6 and 6 Plus until September 7 despite being marketed as a lower-tier iPhone.\\r\\n\\r\\nIn February 2017, the iPhone 6 was quietly relaunched in carrier stores and online, this time the storage has been changed to 32?GB. In India it was sold on Amazon's website in Space Grey. In Taiwan, it was sold through Taiwan Mobile on March 10 in gold colour. In mid-March, it was released in the EU to Belarus via the i-Store web shop. It also makes an appearance in North America with Sprint based US prepaid carriers Boost Mobile and Virgin Mobile, along with AT&T GoPhone. These are not being distributed by Apple on their website or their retail stores.\\r\\n\\r\\nThe design of the iPhone 6 and iPhone 6 Plus is influenced by that of the iPad Air with a glass front that is curved around the edges of the display, and an aluminum rear that contains two plastic strips for the antenna.[37] Both models come in gold, silver, and \\"space gray\\" finishes. The iPhone 6 has a thickness of 6.9 millimetres (0.27?in), while the iPhone 6 Plus is 7.1?mm (0.28?in) in thickness; both are thinner than the iPhone 5c and iPhone 5s, with the iPhone 6 being Apple's thinnest phone to date. The most significant changes to the iPhone 6 and iPhone 6 Plus are its displays; both branded as \\"Retina HD Display\\" and \\"ion-strengthened\\", the iPhone 6 display is 4.7 inches in size with a 16:9 resolution of 1334x750 (326?ppi, minus one row of pixels), while the iPhone 6 Plus includes a 5.5-inch 1920x1080 (1080p) display (401?PPI). The displays use a multiple-domain LCD panel, dubbed \\"dual-domain pixels\\"; the RGB pixels themselves are skewed in pattern, so that every pixel is seen from a different angle. This technique helps improve the viewing angles of the display.[38]\\r\\n\\r\\nTo accommodate the larger physical size of the iPhone 6 and iPhone 6 Plus, the power button was moved to the side of the phone instead of the top to improve its accessibility.[18][19] The iPhone 6 features a 6.91?Wh (1810?mAh) battery, while the iPhone 6 Plus features an 11.1?Wh (2915?mAh) battery. Unlike the previous model, the rear-facing camera is not flush with the rear of the device, but instead protrudes slightly.[39]\\r\\n\\r\\nBoth models include an Apple A8 system-on-chip, and an M8 motion co-processoran update of the M7 chip from the iPhone 5s. The primary difference between the M8 and the original M7 coprocessor is that the M8 also includes a barometer to measure altitude changes. Phil Schiller touted that the A8 chip would provide, in comparison to the 5s, a 25% increase in CPU performance, a 50% increase in graphics performance, and less heat output. Early hands-on reports suggested that the A8's GPU performance might indeed break away from previous generations doubling of performance at each yearly release, scoring 21204.26 in Base mark X compared to 20253.80, 10973.36 and 5034.75 on respectively the 5s, 5 and 4s.[40]\\r\\n\\r\\nThe expanded LTE connectivity on the iPhone 6 and iPhone 6 Plus is improved to LTE Advanced, with support for over 20 LTE bands (7 more than the iPhone 5s),[41] for up to 150?Mbit/s download speed, and VoLTE support. Wi-Fi performance has been improved with support for 802.11ac specifications, providing speeds up to 433.0581?Mbit/swhich is up to 3 times faster than 802.11n,[41] along with Wi-Fi Calling support where available. The iPhone 6 and iPhone 6 Plus add support for near-field communications (NFC). It is initially used exclusively for Apple Paya new mobile payments system which allows users to store their credit cards in Passbook for use with online payments and retail purchases over NFC.[42][43] iOS 11 will provide support for uses of near-field communications besides Apple Pay.[44]\\r\\n\\r\\nThe iPhone 6's rear-facing camera now has the ability to shoot 1080p video at either 30 or 60 frames per second and slow-motion video at either 120 or 240 frames per second. The camera also includes phase detection autofocus.[45] It can also record . The iPhone 6 Plus camera is nearly identical, but also includes optical image stabilization.[18][19] The front-facing camera was also updated with a new sensor and f/2.2 aperture, along with support for burst and HDR modes.[18][19]\\r\\n\\r\\nWhen first released, the iPhone 6 and iPhone 6 Plus were supplied pre-loaded with iOS 8, while the iPhone 5S was supplied pre-loaded with iOS 7. Apps are able to take advantage of the increased screen size in the iPhone 6 and 6 Plus to display more information on-screen; for example, the Mail app uses a dual-pane layout similar to its iPad version when the device is in landscape mode on the iPhone 6 Plus. As it uses an identical aspect ratio, apps designed for the iPhone 5, iPhone 5C, and 5S can be upscaled for use on the iPhone 6 and 6 Plus. To improve the usability of the devices' larger screens, an additional \\"Reachability\\" gesture was added; double-tapping the Home button will slide the top half of the screen's contents down to the bottom half of the screen. This function allows users to reach buttons located near the top of the screen, such as a \\"Back\\" button in the top-left corner.[18][19]\\r\\n\\r\\nBoth iPhone 6 models received generally positive reviews. Re/code called it \\"the best smartphone you can buy\\".[46] TechRadar praised the iPhone 6's \\"brilliant\\" design, improved battery life over the 5s, iOS 8 for being \\"smarter and more intuitive than ever\\", along with the quality of its camera. However, the plastic antenna strips on the rear of the phone were criticized for resulting in poor aesthetics, the display for having lower resolution and pixel density in comparison to other recent smartphones ÿ including those with the same physical screen size as the iPhone 6, such as the HTC One, and for not having a sufficient justification for its significantly higher price in comparison to similar devices running Android or Windows Phone.[47] The Verge considered the iPhone 6 to be \\"simply and cleanly designed\\" in comparison to the 5s, noting that the phone still felt usable despite its larger size, but criticized the antenna plastic, the protruding camera lens (which prevents the device from sitting flat without a case), and the lack of additional optimization in the operating system for the bigger screen. Improvements such as performance, battery life, VoLTE support, and other tweaks were also noted. In conclusion, the iPhone 6 was considered \\"good, even great, but theres little about it thats truly ambitious or truly moving the needle. Its just a refinement of a lot of existing ideas into a much more pleasant package\\".[37]\\r\\n\\r\\nIn regards to the 6 Plus, Engadget panned its design for being uncomfortable to hold and harder to grip in comparison to other devices such as the Galaxy Note 3 and LG G3, but praised its inclusion of optical image stabilization and slightly better battery life than the 6.[45]\\r\\n\\r\\nThe iPhone 6 and 6 Plus were affected by a number of notable hardware-related issues, including but not limited to concerns surrounding their rigidity (which led to incidents surrounding chassis bending, as well as degradation or outright loss of touchscreen functionality), performance issues on models with larger storage capacity, camera problems on the 6 Plus model, as well as an initially undocumented \\"error 53\\" that appeared under certain circumstances.\\r\\n\\r\\nShortly after its public release, it was reported that the iPhone 6 and iPhone 6 Plus chassis was susceptible to bending under pressure, such as when carried tightly in a user's pocket. While such issues are not exclusive to the iPhone 6 and 6 Plus, the design flaw came to be known among users and the media as \\"Bendgate\\".[48][49]\\r\\n\\r\\nApple responded to the bending allegations, stating that they had only received nine complaints of bent devices, and that the damage occurring due to regular use is \\"extremely rare.\\" The company maintained that the iPhone 6 and 6 Plus went through durability testing to ensure they would stand up to daily use.[50] The company offered to replace phones that were bent, if it is determined that the bending was unintentional.[48]\\r\\n\\r\\nOn October 1, 2014, it was reported by Axel Telzerow, editor-in-chief of the German technology magazine Computer Bild, that following the posting of a video where a presenter was able to bend an iPhone 6 Plus, an Apple Germany representative informed the publication that it had been banned from future Apple events and that it would no longer receive devices directly from Apple for testing. Telzerow responded by saying that \\"we congratulate you to your fine new generation of iPhones, even if one of them has a minor weakness with its casing. But we are deeply disappointed about the lack of respect of your company.\\"[51]\\r\\n\\r\\nOn October 3, 2014 9to5Mac released a post claiming that certain iPhone 6\\r\\nand iPhone 6 Plus users complained on social networking sites that the phone ripped off their hair when they held the phone close to their ears when making phone calls.[52] Twitter users claimed that the seam between the glass screen and aluminum back of the iPhone 6 is to blame, with hair becoming caught within it.[53][54]\\r\\n\\r\\nSome users reported that 64 and 128?GB iPhone 6 models had experienced performance issues, and that some 128?GB iPhone 6 Plus models would, in rare cases, randomly crash and reboot. Business Korea reported that the issues were connected to the triple-layer cell NAND storage of the affected models. Triple-layer cells can store three bits of data per cell of flash, and are cheaper than dual-layer cell solutions, but at the cost of performance. It was reported that Apple had planned to switch the affected model lines back to multi-layer cell flash, and address the performance issues on existing devices in a future iOS update.[55][56][57]\\r\\n\\r\\nIt was reported that the optical image stabilization systems on some iPhone 6 Plus models were faulty, failing to properly stabilize when the phone is being held perfectly still, leading to blurry photos and \\"wavy\\"-looking videos.[58] The optical image stabilization system was also found to have been affected by accessories that use magnets, such as third-party lens attachments; Apple issued advisories to users and its licensed accessory makers, warning that magnetic or metallic accessories can cause the OIS to malfunction.[59]\\r\\n\\r\\nOn August 21, 2015, Apple instituted a repair program for iPhone 6 Plus models released between September 2014 and January 2015, citing that faulty rear cameras on affected models may produce blurry pictures.[32][33][34]\\r\\n\\r\\nSome iPhone 6 and iPhone 6 Plus models have an issue where the front facing camera is somehow \\"shifted\\", or out of place. Apple stated that they would replace most affected iPhone 6 models with this issue, free of charge. Despite numerous complaints regarding this issue, it does not seem to actually affect the camera itself. It is said that the camera is not what has shifted, but a piece of protective foam around the camera module itself that has gone out of place.[60]\\r\\n\\r\\nIf the iPhone 6 home button is repaired or modified by a third-party, the device will fail security checks related to Touch ID as the components had not been \\"re-validated\\" for security reasonsa process which can only be performed by an authorized Apple outlet. Failing these checks disables all features related to Touch ID. Such effects have sometimes happened as a result of damage as well.[61][62]\\r\\n\\r\\nIt was reported these same hardware integrity checks would trigger an unrecoverable loop into \\"Recovery Mode\\" if iOS is updated or restored, with attempts to restore the device via iTunes software resulting in an \\"error 53\\" message. Beyond the explanation that this is related to hardware integrity errors regarding Touch ID components, Apple provided no official explanation of what specifically triggers error 53 or how it can be fixed without replacing the entire device.[61][62]\\r\\n\\r\\nOn February 18, 2016, Apple released an iOS 9.2.1 patch through iTunes which addresses this issue, and admitted that error 53 was actually related to a diagnostic check for inspecting the Touch ID hardware before an iPhone is shipped from its factories.[63]\\r\\n\\r\\nTouchscreen control components on iPhone 6 logic boards have insufficient support, including a lack of underfillwhich strengthens and stabilizes integrated circuits, and a lack of rigid metal shielding on the logic board unlike previous iPhone models; the touchscreen controller is instead shielded by a flexible \\"sticker\\". Normal use of the device can cause the logic board to flex internally, which strains the touchscreen IC connectors and leads to a degradation or outright loss of touchscreen functionality. A symptom that has been associated with this type of failure is a flickering grey bar near the top of the display.[64][65] iFixit reported that this issue, nicknamed \\"touch disease\\",[64][66][67] was a byproduct of the previous \\"Bendgate\\" design flaw because of the device's demonstrated lack of rigidity. As such, the larger iPhone 6 Plus is more susceptible to the flaw, but it has also been reported on a small percentage of iPhone 6 models.[67][68][69] The devices' successor, the iPhone 6S, is not afflicted by this flaw due to changes to their internal design, which included the strengthening of \\"key points\\" in the rear casing, and the re-location of the touchscreen controllers to the display assembly from the logic board.[68]\\r\\n\\r\\nInitially, Apple did not officially acknowledge this issue. The issue was widely discussed on Apple's support forumwhere posts discussing the issue have been subject to censorship.[65] The touchscreen can be repaired via microsoldering: Apple Stores are not equipped with the tools needed to perform the logic board repair, which had led to affected users sending their devices to unofficial, third-party repair services. An Apple Store employee interviewed by Apple Insider reported that six months after they first started noticing the problem, Apple had issued guidance instructing them to tell affected users that this was a hardware issue which could not be repaired, and that their iPhone had to be replaced. However, some in-stock units have also been afflicted with this issue out of the box, leading to an employee stating that they were \\"tired of pulling service stock out of the box, and seeing the exact same problem that the customer has on the replacement\\".[69][70] The issue received mainstream attention in August 2016 when it was reported upon by iFixit.[64][67][69] On August 26, 2016, Apple Insider reported that based on data from four \\"high-traffic\\" Apple Store locations, there was a spike in the number of iPhone 6 devices brought into them for repairs following mainstream reports of the \\"touch disease\\" problem.[70]\\r\\n\\r\\nOn August 30, 2016, a group of three iPhone 6 owners sued Apple Inc. in the United States District Court for the Northern District of California and filed for a proposed class action lawsuit, alleging that Apple was engaging in unfair business practices by having \\"long been aware\\" of the defective design, yet actively refusing to acknowledge or repair it.[66][71][72]\\r\\n\\r\\nOn November 17, 2016, Apple officially acknowledged the issue and announced a paid repair program for affected iPhone 6 Plus models, stating that \\"some iPhone 6 Plus devices may exhibit display flickering or Multi-Touch issues after being dropped multiple times on a hard surface and then incurring further stress on the device\\".[73]\\r\\n\\r\\nApple Inc. announced that, within 24 hours of availability, over 4 million pre-orders of the iPhone 6 and 6 Plus were made, exceeding the supply available.[74] More than 10 million iPhone 6 and iPhone 6 Plus devices were sold in the first three days.[75]","input":"When was the iphone 6 released in canada?"},{"output":"June 17, 1775","context":" United Colonies\\r\\n William Prescott\\r\\n Israel Putnam\\r\\n Joseph Warren??\\r\\n William Howe\\r\\n Thomas Gage\\r\\n Sir Robert Pigot\\r\\n James Abercrombie??\\r\\n Henry Clinton\\r\\n Samuel Graves\\r\\nThe Battle of Bunker Hill was fought on June 17, 1775, during the Siege of Boston in the early stages of the American Revolutionary War. The battle is named after Bunker Hill in Charlestown, Massachusetts, which was peripherally involved in the battle. It was the original objective of both the colonial and British troops, though the majority of combat took place on the adjacent hill which later became known as Breed's Hill.[7][8]\\r\\nOn June 13, 1775, the leaders of the colonial forces besieging Boston learned that the British were planning to send troops out from the city to fortify the unoccupied hills surrounding the city, which would give them control of Boston Harbor. In response, 1,200 colonial troops under the command of William Prescott stealthily occupied Bunker Hill and Breed's Hill. During the night, the colonists constructed a strong redoubt on Breed's Hill, as well as smaller fortified lines across the Charlestown Peninsula.[9]\\r\\nBy daybreak of June 17, the British became aware of the presence of colonial forces on the Peninsula and mounted an attack against them that day. Two assaults on the colonial positions were repulsed with significant British casualties; the third and final attack carried the redoubt after the defenders ran out of ammunition. The colonists retreated to Cambridge over Bunker Hill, leaving the British in control of the Peninsula.[10]\\r\\nThe battle was a tactical, though somewhat Pyrrhic victory for the British, as it proved to be a sobering experience for them, involving many more casualties than the Americans had incurred, including a large number of officers. The battle had demonstrated that inexperienced militia were able to stand up to regular army troops in battle. Subsequently, the battle discouraged the British from any further frontal attacks against well defended front lines. American casualties were comparatively much fewer, although their losses included General Joseph Warren and Major Andrew McClary, the final casualty of the battle.[11]\\r\\nThe battle led the British to adopt a more cautious planning and maneuver execution in future engagements, which was evident in the subsequent New York and New Jersey campaign, and arguably helped rather than hindered the American forces. Their new approach to battle was actually giving the Americans greater opportunity to retreat if defeat was imminent. The costly engagement also convinced the British of the need to hire substantial numbers of foreign mercenaries to bolster their strength in the face of the new and formidable Continental Army.\\r\\n\\r\\n\\r\\nBoston, situated on a peninsula,[12] was largely protected from close approach by the expanses of water surrounding it, which were dominated by British warships. In the aftermath of the battles of Lexington and Concord on April 19, 1775, the colonial militia, a force of about 15,000 men[13] had surrounded the town, and effectively besieged it. Under the command of Artemas Ward, they controlled the only land access to Boston itself (the Roxbury Neck), but, lacking a navy, were unable to even contest British domination of the waters of the harbor. The British troops, a force of about 6,000 under the command of General Thomas Gage, occupied the city, and were able to be resupplied and reinforced by sea.[14] In theory, they were thus able to remain in Boston indefinitely.\\r\\nHowever, the land across the water from Boston contained a number of hills, which could be used to advantage.[15] If the militia could obtain enough artillery pieces, these could be placed on the hills and used to bombard the city until the occupying army evacuated it or surrendered. It was with this in mind that the Knox Expedition, led by Henry Knox, later transported cannon from Fort Ticonderoga to the Boston area.[16]\\r\\nThe Charlestown Peninsula, lying to the north of Boston, started from a short, narrow isthmus (known as the Charlestown Neck) at its northwest and extended about 1 mile (1.6?km) southeastward into Boston Harbor. Bunker Hill, with an elevation of 110 feet (34?m), lay at the northern end of the peninsula. Breed's Hill, at a height of 62 feet (19?m), was more southerly and nearer to Boston.[17] The town of Charlestown occupied flats at the southern end of the peninsula. At its closest approach, less than 1,000 feet (305?m) separated the Charlestown Peninsula from the Boston Peninsula, where Copp's Hill was at about the same height as Breed's Hill. While the British retreat from Concord had ended in Charlestown, General Gage, rather than immediately fortifying the hills on the peninsula, had withdrawn those troops to Boston the day after that battle, turning the entire Charlestown Peninsula into a no man's land.[18]\\r\\nThroughout May, in response to orders from Gage requesting support, the British received reinforcements, until they reached a strength of about 6,000 men. On May 25, three generals arrived on HMS?Cerberus: William Howe, John Burgoyne, and Henry Clinton. Gage began planning with them to break out of the city,[19] finalizing a plan on June 12.[20] This plan began with the taking of the Dorchester Neck, fortifying the Dorchester Heights, and then marching on the colonial forces stationed in Roxbury. Once the southern flank had been secured, the Charlestown heights would be taken, and the forces in Cambridge driven away. The attack was set for June 18.[21]\\r\\nOn June 13, the Massachusetts Provincial Congress was notified, by express messenger from the Committee of Safety in Exeter, New Hampshire, that a New Hampshire gentleman \\"of undoubted veracity\\" had, while visiting Boston, overheard the British commanders making plans to capture Dorchester and Charlestown.[22] On June 15, the Massachusetts Committee of Safety decided that additional defenses needed to be erected.[23] General Ward directed General Israel Putnam to set up defenses on the Charlestown Peninsula, specifically on Bunker Hill.[24][25]\\r\\nOn the night of June 16, colonial Colonel William Prescott led about 1,200 men onto the peninsula in order to set up positions from which artillery fire could be directed into Boston.[26] This force was made up of men from the regiments of Prescott, Putnam (the unit was commanded by Thomas Knowlton), James Frye, and Ebenezer Bridge.[27] At first, Putnam, Prescott, and their engineer, Captain Richard Gridley, disagreed as to where they should locate their defense. Some work was performed on Bunker Hill, but Breed's Hill was closer to Boston and viewed as being more defensible. Arguably against orders, they decided to build their primary redoubt there.[28] Prescott and his men, using Gridley's outline, began digging a square fortification about 130 feet (40?m) on a side with ditches and earthen walls. The walls of the redoubt were about 6 feet (1.8?m) high, with a wooden platform inside on which men could stand and fire over the walls.[29][30]\\r\\nThe works on Breed's Hill did not go unnoticed by the British. General Clinton, out on reconnaissance that night, was aware of them, and tried to convince Gage and Howe that they needed to prepare to attack the position at daylight. British sentries were also aware of the activity, but most apparently did not think it cause for alarm.[31] Then, in the early predawn, around 4?a.m., a sentry on board HMS?Lively spotted the new fortification, and notified her captain. Lively opened fire, temporarily halting the colonists' work. Aboard his flagship HMS?Somerset, Admiral Samuel Graves awoke, irritated by the gunfire that he had not ordered.[32] He stopped it, only to have General Gage countermand his decision when he became fully aware of the situation in the morning. He ordered all 128 guns in the harbor, as well as batteries atop Copp's Hill in Boston, to fire on the colonial position, which had relatively little effect.[33] The rising sun also alerted Prescott to a significant problem with the location of the redoubt ÿ it could easily be flanked on either side.[31] He promptly ordered his men to begin constructing a breastwork running down the hill to the east, deciding he did not have the manpower to also build additional defenses to the west of the redoubt.[34]\\r\\nWhen the British generals met to discuss their options, General Clinton, who had urged an attack as early as possible, preferred an attack beginning from the Charlestown Neck that would cut off the colonists' retreat, reducing the process of capturing the new redoubt to one of starving out its occupants. However, he was outvoted by the other three generals. Howe, who was the senior officer present and would lead the assault, was of the opinion that the hill was \\"open and easy of ascent and in short would be easily carried.\\"[35] General Burgoyne concurred, arguing that the \\"untrained rabble\\" would be no match for their \\"trained troops\\".[36] Orders were then issued to prepare the expedition.[37]\\r\\nWhen General Gage surveyed the works from Boston with his staff, Loyalist Abijah Willard recognized his brother-in-law Colonel Prescott. \\"Will he fight?\\" asked Gage. \\"[A]s to his men, I cannot answer for them;\\" replied Willard, \\"but Colonel Prescott will fight you to the gates of hell.\\"[38] Prescott lived up to Willard's word, but his men were not so resolute. When the colonists suffered their first casualty, Asa Pollard of Billerica,[39] a young private killed by cannon fire, Prescott gave orders to bury the man quickly and quietly, but a large group of men gave him a solemn funeral instead, with several deserting shortly thereafter.[38]\\r\\nIt took six hours for the British to organize an infantry force and to gather up and inspect the men on parade. General Howe was to lead the major assault, drive around the colonial left flank, and take them from the rear. Brigadier General Robert Pigot on the British left flank would lead the direct assault on the redoubt, and Major John Pitcairn led the flank or reserve force. It took several trips in longboats to transport Howe's initial forces (consisting of about 1,500 men) to the eastern corner of the peninsula, known as Moulton's Point.[40][41] By 2?p.m., Howe's chosen force had landed.[40] However, while crossing the river, Howe noted the large number of colonial troops on top of Bunker Hill. Believing these to be reinforcements, he immediately sent a message to Gage, requesting additional troops. He then ordered some of the light infantry to take a forward position along the eastern side of the peninsula, alerting the colonists to his intended course of action. The troops then sat down to eat while they waited for the reinforcements.[41]\\r\\nPrescott, seeing the British preparations, called for reinforcements. Among the reinforcements were Joseph Warren, the popular young leader of the Massachusetts Committee of Safety, and Seth Pomeroy, an aging Massachusetts militia leader. Both of these men held commissions of rank, but chose to serve as infantry.[40] Prescott ordered the Connecticut men under Captain Knowlton to defend the left flank, where they used a crude dirt wall as a breastwork, and topped it with fence rails and hay. They also constructed three small v-shaped trenches between this dirt wall and Prescott's breastwork. Troops that arrived to reinforce this flank position included about 200 men from the 1st and 3rd New Hampshire regiments, under Colonels John Stark and James Reed. Stark's men, who did not arrive until after Howe landed his forces (and thus filled a gap in the defense that Howe could have taken advantage of, had he pressed his attack sooner),[42] took positions along the breastwork on the northern end of the colonial position. When low tide opened a gap along the Mystic River to the north, they quickly extended the fence with a short stone wall to the water's edge.[42][43] Colonel Stark placed a stake about 100 feet (30?m) in front of the fence and ordered that no one fire until the regulars passed it.[44] Just prior to the action, further reinforcements arrived, including portions of Massachusetts regiments of Colonels Brewer, Nixon, Woodbridge, Little, and Major Moore, as well as Callender's company of artillery.[45]\\r\\nBehind the colonial lines, confusion reigned. Many units sent toward the action stopped before crossing the Charlestown Neck from Cambridge, which was under constant fire from gun batteries to the south. Others reached Bunker Hill, but then, uncertain about where to go from there, milled around. One commentator wrote of the scene that \\"it appears to me there never was more confusion and less command.\\"[46] While General Putnam was on the scene attempting to direct affairs, unit commanders often misunderstood or disobeyed orders.[46][47]\\r\\nBy 3?p.m., the British reinforcements, which included the 47th Foot and the 1st Marines, had arrived, and the British were ready to march.[48] Brigadier General Pigot's force, gathering just south of Charlestown village, were taking casualties from sniper fire, and Howe asked Admiral Graves for assistance in clearing out the snipers. Graves, who had planned for such a possibility, ordered incendiary shot fired into the village, and then sent a landing party to set fire to the town.[49] The smoke billowing from Charlestown lent an almost surreal backdrop to the fighting, as the winds were such that the smoke was kept from the field of battle.[50]\\r\\nPigot, commanding the 5th, 38th, 43rd, 47th, and 52nd regiments, as well as Major Pitcairn's Marines, were to feint an assault on the redoubt. However, they continued to be harried by snipers in Charlestown, and Pigot, when he saw what happened to Howe's advance, ordered a retreat.[51]\\r\\nGeneral Howe led the light infantry companies and grenadiers in the assault on the American left flank, expecting an easy effort against Stark's recently arrived troops.[52] His light infantry were set along the narrow beach, in column, in order to turn the far left flank of the colonial position.[53] The grenadiers were deployed in the middle. They lined up four deep and several hundred across. As the regulars closed, John Simpson, a New Hampshire man, prematurely fired, drawing an ineffective volley of return fire from the regulars.[citation needed] When the regulars finally closed within range, both sides opened fire. The colonists inflicted heavy casualties on the regulars, using the fence to steady and aim their muskets, and benefit from a modicum of cover. With this devastating barrage of musket fire, the regulars retreated in disarray, and the militia held their ground.[54]\\r\\nThe regulars reformed on the field and marched out again. This time, Pigot was not to feint; he was to assault the redoubt, possibly without the assistance of Howe's force. Howe, instead of marching against Stark's position along the beach, marched instead against Knowlton's position along the rail fence. The outcome of the second attack was much the same as the first. One British observer wrote, \\"Most of our Grenadiers and Light-infantry, the moment of presenting themselves lost three-fourths, and many nine-tenths, of their men. Some had only eight or nine men a company left ...\\"[55] Pigot did not fare any better in his attack on the redoubt, and again ordered a retreat.[56] Meanwhile, in the rear of the colonial forces, confusion continued to reign. General Putnam tried, with only limited success, to send additional troops from Bunker Hill to Breed's Hill to support the men in the redoubt and along the defensive lines.[57][58]\\r\\nThe British rear was also in some disarray. Wounded soldiers that were mobile had made their way to the landing areas, and were being ferried back to Boston, and the wounded lying on the field of battle were the source of moans and cries of pain.[59] General Howe, deciding that he would try again, sent word to General Clinton in Boston for additional troops. Clinton, who had watched the first two attacks, sent about 400 men from the 2nd Marines and the 63rd Foot, and then followed himself to help rally the troops. In addition to the new reserves, he also convinced about 200 of the wounded to form up for the third attack.[60] During the interval between the second and third assaults, General Putnam continued trying to direct troops toward the action. Some companies, and leaderless groups of men, moved toward the action; others retreated.[61] John Chester, a Connecticut captain, seeing an entire company in retreat, ordered his company to aim muskets at that company to halt its retreat; they turned about and headed back to the battlefield.[62]\\r\\nThe third assault, concentrated on the redoubt (with only a feint on the colonists' flank), was successful, although the colonists again poured musket fire into the British ranks, and it cost the life of Major Pitcairn.[63] The defenders had run out of ammunition, reducing the battle to close combat. The British had the advantage once they entered the redoubt, as their troops were equipped with bayonets on their muskets while most of the colonists were not. Colonel Prescott, one of the last colonists to leave the redoubt, parried bayonet thrusts with his normally ceremonial sabre.[64] It is during the retreat from the redoubt that Joseph Warren was killed.[65]\\r\\nThe retreat of much of the colonial forces from the peninsula was made possible in part by the controlled retreat of the forces along the rail fence, led by John Stark and Thomas Knowlton, which prevented the encirclement of the hill. Their disciplined retreat, described by Burgoyne as \\"no flight; it was even covered with bravery and military skill\\", was so effective that most of the wounded were saved;[66] most of the prisoners taken by the British were mortally wounded.[66] General Putnam attempted to reform the troops on Bunker Hill; however the flight of the colonial forces was so rapid that artillery pieces and entrenching tools had to be abandoned. The colonists suffered most of their casualties during the retreat on Bunker Hill. By 5?p.m., the colonists had retreated over the Charlestown Neck to fortified positions in Cambridge, and the British were in control of the peninsula.[67]\\r\\nThe British had taken the ground but at a great loss; they had suffered 1,054 casualties (226 dead and 828 wounded), with a disproportionate number of these officers. The casualty count was the highest suffered by the British in any single encounter during the entire war.[68] General Clinton, echoing Pyrrhus of Epirus, remarked in his diary that \\"A few more such victories would have shortly put an end to British dominion in America.\\"[1] British dead and wounded included 100 commissioned officers, a significant portion of the British officer corps in North America.[69] Much of General Howe's field staff was among the casualties.[70] Major Pitcairn had been killed, and Lieutenant Colonel James Abercrombie fatally wounded. General Gage, in his report after the battle, reported the following officer casualties (listing lieutenants and above by name):[71]\\r\\nThe colonial losses were about 450, of whom 140 were killed. Most of the colonial losses came during the withdrawal. Major Andrew McClary was technically the highest ranking colonial officer to die in the battle; he was hit by cannon fire on Charlestown Neck, the last person to be killed in the battle. He was later commemorated by the dedication of Fort McClary in Kittery, Maine.[72] A serious loss to the Patriot cause, however, was the death of Dr. Joseph Warren. He was the President of Massachusetts' Provincial Congress, and he had been appointed a Major General on June 14. His commission had not yet taken effect when he served as a volunteer private three days later at Bunker Hill.[73] Only thirty men were captured by the British, most of them with grievous wounds; twenty died while held prisoner. The colonials also lost numerous shovels and other entrenching tools, as well as five out of the six cannon they had brought to the peninsula.[74][75]\\r\\nWhen news of the battle spread through the colonies, it was reported as a colonial loss, as the ground had been taken by the enemy, and significant casualties were incurred. George Washington, who was on his way to Boston as the new commander of the Continental Army, received news of the battle while in New York City. The report, which included casualty figures that were somewhat inaccurate, gave Washington hope that his army might prevail in the conflict.[76]\\r\\nA British officer in Boston, after the battle\\r\\nThe Massachusetts Committee of Safety, seeking to repeat the sort of propaganda victory it won following the battles at Lexington and Concord, commissioned a report of the battle to send to England. Their report, however, did not reach England before Gage's official account arrived on July 20. His report unsurprisingly caused friction and argument between the Tories and the Whigs, but the casualty counts alarmed the military establishment, and forced many to rethink their views of colonial military capability.[78] King George's attitude toward the colonies hardened, and the news may have contributed to his rejection of the Continental Congress' Olive Branch Petition, the last substantive political attempt at reconciliation. Sir James Adolphus Oughton, part of the Tory majority, wrote to Lord Dartmouth of the colonies, \\"the sooner they are made to Taste Distress the sooner will [Crown control over them] be produced, and the Effusion of Blood be put a stop to.\\"[79] About a month after receiving Gage's report the Proclamation of Rebellion would be issued in response; this hardening of the British position would also lead to a hardening of previously weak support for the rebellion, especially in the southern colonies, in favor of independence.[79]\\r\\nGage's report had a more direct effect on his own career. His dismissal from office was decided just three days after his report was received, although General Howe did not replace him until October 1775.[80] Gage wrote another report to the British Cabinet, in which he repeated earlier warnings that \\"a large army must at length be employed to reduce these people\\", that would require \\"the hiring of foreign troops\\".[81]\\r\\nMuch has been written in the wake of this battle over how it was conducted. Both sides made strategic and tactical missteps which could have altered the outcome of the battle. While hindsight often gives a biased view, some things seem to be apparent after the battle that might reasonably have been within the reach of the command of the day.\\r\\nYears after the battle, and after Israel Putnam was dead, General Dearborn published an account of the battle in Port Folio magazine, accusing General Putnam of inaction, cowardly leadership and failing to supply reinforcements during the battle, which subsequently sparked a long lasting and major controversy among veterans of the war, various friends, family members and historians.[82][a] People were shocked by the rancor of the attack, and this prompted a forceful response from defenders of Putnam, including such notables as John and Abigail Adams. Historian Harold Murdock wrote that Dearborn's account \\"abounds in absurd misstatements and amazing flights of imagination.\\" The Dearborn attack received considerable attention because at the time he was in the middle of considerable controversy himself. He had been relieved of one of the top commands in the War of 1812 due to his mistakes. He had also been nominated to serve as Secretary of War by President Monroe, but was rejected by the United States Senate (which was the first time that the Senate had voted against confirming a presidential cabinet choice).[83][84][85][86]\\r\\nThe colonial forces, while nominally under the overall command of General Ward, with General Putnam and Colonel Prescott leading in the field, often acted quite independently.[87] This was evident in the opening stages of the battle, when a tactical decision was made that had strategic implications. After deliberating with General Putnam and Colonel Gridley, Colonel Prescott and his staff, apparently in contravention of orders, decided to fortify Breed's Hill rather than Bunker Hill.[88] The fortification of Breed's Hill was more provocative; it would have put offensive artillery closer to Boston.[89] It also exposed the forces there to the possibility of being trapped, as they probably could not properly defend against attempts by the British to land troops and take control of Charlestown Neck. If the British had taken that step, they might have had a victory with many fewer casualties.[90]\\r\\nWhile the front lines of the colonial forces were generally well managed, the scene behind them, especially once the action began, was significantly disorganized, due at least in part to a poor chain of command. Only some of the militias operated directly under Ward's and Putnam's authority,[91] and some commanders also disobeyed orders, staying at Bunker Hill rather than joining in the defense on the third British assault. Several officers were subjected to court martial and cashiered.[92] Colonel Prescott was of the opinion that the third assault would have been repulsed, had his forces in the redoubt been reinforced with either more men, or more supplies of ammunition and powder.[93]\\r\\nThe British leadership, for its part, acted slowly once the works on Breed's Hill were spotted. It was 2?p.m. when the troops were ready for the assault, roughly ten hours after the Lively first opened fire. This leisurely pace gave the colonial forces time to reinforce the flanking positions that had been poorly defended.[94] Gage and Howe decided that a frontal assault on the works would be a simple matter, when an encircling move (gaining control of Charlestown Neck), would have given them a more resounding victory.[90] (This move would not have been without risks of its own, as the colonists could have made holding the Neck expensive with fire from the high ground in Cambridge.) But the British leadership was excessively optimistic, believing that \\"two regiments were sufficient to beat the strength of the province\\".[95]\\r\\nOnce in the field, Howe, rather than focusing on the redoubt, opted (twice) to dilute the force attacking the redoubt with a flanking maneuver against the colonial left. It was only with the third attack, when the flank attack was merely a feint,[96] and the main force (now also reinforced with additional reserves) squarely targeted the redoubt, that the attack succeeded.[97]\\r\\nFollowing the taking of the peninsula, the British arguably had a tactical advantage that they could have used to press into Cambridge. General Clinton proposed this to Howe; having just led three assaults with grievous casualties, he declined the idea.[98] The colonial military leaders eventually recognized Howe as a tentative decision-maker, to his detriment; in the aftermath of the Battle of Long Island (1776), he again had tactical advantages that might have delivered Washington's army into his hands, but again refused to act.[99]\\r\\nHistorian John Ferling maintains that had General Gage used the Royal Navy to secure the narrow neck to the Charleston peninsula, cutting the Americans off from the mainland, he could have achieved a far less costly victory, but he was motivated by revenge over patriot resistance at the Battles of Lexington and Concord and relatively heavy British losses, and also felt that the colonial militia were completely untrained and could be overtaken with little effort, opting for a frontal assault.[100]\\r\\nThe famous order \\"Don't fire until you see the whites of their eyes\\" was popularized in stories about the battle of Bunker Hill. It is uncertain as to who said it there, since various histories, including eyewitness accounts,[101] attribute it to Putnam, Stark, Prescott, or Gridley, and it may have been said first by one, and repeated by the others.[102] It was also not an original statement. The idea dates originally to the general-king Gustavus Adolphus (1594ÿ1632) who gave standing orders to his musketeers: \\"never to give fire, till they could see their own image in the pupil of their enemy's eye\\".[103] Gustavus Adolphus's military teachings were widely admired and imitated and caused this saying to be often repeated. It was used by General James Wolfe on the Plains of Abraham, when his troops defeated Montcalm's army on September 13, 1759.[104] The earliest similar quote came from the Battle of Dettingen on June 27, 1743, where Lieutenant-Colonel Sir Andrew Agnew of Lochnaw warned his Regiment, the Royal Scots Fusiliers, not to fire until they could \\"see the white of their e'en.\\"[105] The phrase was also used by Prince Charles of Prussia in 1745, and repeated in 1755 by Frederick the Great, and may have been mentioned in histories the colonial military leaders were familiar with.[106] Whether or not it was actually said in this battle, it was clear that the colonial military leadership were regularly reminding their troops to hold their fire until the moment when it would have the greatest effect, especially in situations where their ammunition would be limited.[107]\\r\\nA significant number of notable people fought in this battle. Henry Dearborn and William Eustis, for example, went on to distinguished military and political careers; both served in Congress, the Cabinet, and in diplomatic posts. Others, like John Brooks, Henry Burbeck, Christian Febiger, Thomas Knowlton, and John Stark, became well known for later actions in the war.[108][109] Stark became known as the \\"Hero of Bennington\\" for his role in the 1777 Battle of Bennington. Free African-Americans also fought in the battle; notable examples include Barzillai Lew, Salem Poor, and Peter Salem.[110][111] Another notable participant was Daniel Shays, who later became famous for his army of protest in Shays' Rebellion.[112] Israel Potter was immortalized in Israel Potter: His Fifty Years of Exile, a novel by Herman Melville.[113][114] Colonel John Paterson commanded the Massachusetts First Militia, served in Shays' Rebellion, and became a congressman from New York.[115] Lt. Col. Seth Read, who served under John Paterson at Bunker Hill, went on to settle Geneva, New York and Erie, Pennsylvania, and was said to have been instrumental in the phrase E pluribus unum being added to U.S. coins.[116][117][118][119] George Claghorn of the Massachusetts militia was shot in the knee at Bunker Hill and went on after the war to become the master builder of the USS Constitution, a.k.a. \\"Old Ironsides\\", which is the oldest naval vessel in the world that is still commissioned and afloat.[120][121]\\r\\nJohn Trumbull's painting, The Death of General Warren at the Battle of Bunker Hill (displayed in lede), was created as an allegorical depiction of the battle and Warren's death, not as an actual pictorial recording of the event. The painting shows a number of participants in the battle including a British officer, John Small, among those who stormed the redoubt, yet came to be the one holding the mortally wounded Warren and preventing a fellow redcoat from bayoneting him. He was friends of Putnam and Trumbull. Other central figures include Andrew McClary who was the last man to fall in the battle.[122]\\r\\nThe Bunker Hill Monument is an obelisk that stands 221 feet (67?m) high on Breed's Hill. On June 17, 1825, the fiftieth anniversary of the battle, the cornerstone of the monument was laid by the Marquis de Lafayette and an address delivered by Daniel Webster.[123] (When Lafayette died, he was buried next to his wife at the Cimetire de Picpus under soil from Bunker Hill, which his son Georges sprinkled over him.)[124] The Leonard P. Zakim Bunker Hill Memorial Bridge was specifically designed to evoke this monument.[125] There is also a statue of William Prescott showing him calming his men down.\\r\\nThe National Park Service operates a museum dedicated to the battle near the monument, which is part of the Boston National Historical Park.[126] A cyclorama of the battle was added in 2007 when the museum was renovated.[127]\\r\\nIn nearby Cambridge, a small granite monument just north of Harvard Yard bears this inscription: \\"Here assembled on the night of June 16, 1775, 1200 Continental troops under command of Colonel Prescott. After prayer by President Langdon, they marched to Bunker Hill.\\" See footnote for picture.[128] (Samuel Langdon, a Congregational minister, was Harvard's 11th president.)[129] Another small monument nearby marks the location of the Committee of Safety, which had become the Patriots' provisional government as Tories left Cambridge.[130] These monuments are on the lawn to the west of Harvard's Littaeur Center, which is itself the west of Harvard's huge Science Center. See footnote for map.[131]\\r\\nBunker Hill Day, observed every June 17, is a legal holiday in Suffolk County, Massachusetts (which includes the city of Boston), as well as Somerville in Middlesex County. Prospect Hill, site of colonial fortifications overlooking the Charlestown Neck, is now located in Somerville, which was previously part of Charlestown.[132][133] State institutions in Massachusetts (such as public institutions of higher education) located in Boston also celebrate the holiday.[134][135] However, the state's FY2011 budget requires that all state and municipal offices in Suffolk County be open on Bunker Hill Day and Evacuation Day.[136]\\r\\nOn June 16 and 17, 1875, the centennial of the battle was celebrated with a military parade and a reception featuring notable speakers, among them General William Tecumseh Sherman and Vice President Henry Wilson. It was attended by dignitaries from across the country.[137] Celebratory events also marked the sesquicentennial (150th anniversary) in 1925 and the bicentennial in 1975.[138][139]\\r\\nOver the years the Battle of Bunker Hill has been commemorated on four U.S. Postage stamps.[140]\\r\\nMajor sources Most of the information about the battle itself in this article comes from the following sources.\\r\\nMinor sources Specific facts not necessarily covered by the major sources come from the following sources.\\r\\nCommemorations Various commemorations of the battle are described in the following sources.\\r\\nAbout the battle\\r\\nAbout people in the battle","input":"When did the battle of bunker hill happen?"},{"output":"1 January 1999","context":"The euro came into existence on 1 January 1999, although it had been a goal of the European Union (EU) and its predecessors since the 1960s. After tough negotiations, particularly due to opposition from the United Kingdom, the Maastricht Treaty entered into force in 1993 with the goal of creating an economic and monetary union by 1999 for all EU states except the UK and Denmark (even though Denmark has a fixed exchange rate policy with the euro).\\r\\nIn 1999 the currency was born virtually and in 2002 notes and coins began to circulate. It rapidly took over from the former national currencies and slowly expanded behind the rest of the EU. In 2009 the Lisbon Treaty finalised its political authority, the Eurogroup, alongside the European Central Bank.\\r\\n\\r\\n\\r\\nFirst ideas of an economic and monetary union in Europe were raised well before establishing the European Communities. For example, already in the League of Nations, Gustav Stresemann asked in 1929 for a European currency[1] against the background of an increased economic division due to a number of new nation states in Europe after World War I. At this time memories of the Latin Monetary Union[2] involving principally France, Italy, Belgium and Switzerland and which, for practical purposes, had disintegrated following the First World War, figured prominently in the minds of policy makers.\\r\\nA first attempt to create an economic and monetary union between the members of the European Economic Community goes back to an initiative by the European Commission in 1969, which set out the need for \\"greater co-ordination of economic policies and monetary cooperation.\\"[3] This was followed up at a meeting of the European Council at The Hague in December 1969. The European Council tasked Pierre Werner, Prime Minister of Luxembourg, with finding a way to reduce currency exchange rate volatility. His report was published in October 1970 and recommended centralisation of the national macroeconomic policies entailing \\"the total and irreversible fixing of parity rates and the complete liberation of movements of capital.\\" But he did not propose a single currency or central bank.[4] An attempt to limit the fluctuations of European currencies, using a snake in the tunnel, failed.\\r\\nIn 1971, US President Richard Nixon removed the gold backing from the US dollar, causing a collapse in the Bretton Woods system that managed to affect all of the world's major currencies. The widespread currency floats and devaluations set back aspirations for European monetary union.[4] However, in March 1979 the European Monetary System (EMS) was created, fixing exchange rates onto the European Currency Unit (ECU), an accounting currency, to stabilise exchange rates and counter inflation. It also created the European Monetary Cooperation Fund (EMCF).[4]\\r\\nIn February 1986 the Single European Act formalised political co-operation within the Community including competency in monetary policy.[4] European Council summit in Hannover on 14 June 1988 began to outline monetary co-operation. France, Italy and European Commission backed a fully monetary union with a central bank, which British Prime Minister Margaret Thatcher opposed.[5][6]\\r\\nThe Hannover European Council asked Commission President Jacques Delors to chair an ad hoc committee of central bank governors to propose a new timetable with clear, practical and realistic steps for creating an economic and monetary union.[7] This way of working was derived from the Spaak method.\\r\\nFrance and the UK were opposed to German reunification, and attempted to influence the Soviet Union to stop it.[8] However, in late 1989 France extracted German commitment to the Monetary Union in return for support for German reunification.[9]\\r\\nThe Delors report[10] of 1989 set out a plan to introduce the EMU in three stages and it included the creation of institutions such as the European System of Central Banks (ESCB), which would become responsible for formulating and implementing monetary policy. It laid out monetary union being accomplished in three steps. Beginning the first of these steps, on 1 July 1990, exchange controls were abolished, thus capital movements were completely liberalised in the European Economic Community. Leaders reached agreement on currency union with the Maastricht Treaty, signed on 7 February 1992. It agreed to create a single currency, although without the participation of the United Kingdom, by January 1999.[4]\\r\\nGaining approval for the treaty was a challenge. Germany was cautious about giving up its stable currency, i.e., the German Mark,[11] France approved the treaty by a narrow margin[12] and Denmark refused to ratify until they got an opt out from monetary union as the United Kingdom, an opt-out which they maintain as of 2011.[13] On 16 September 1992, known in the UK as Black Wednesday, the British pound sterling was forced to withdraw from the fixed exchange rate system due to a rapid fall in the value of the pound.[14]\\r\\nDelors' second stage began in 1994 with creation of the European Monetary Institute, succeeding the EMCF, under Maastricht. It was created as the forerunner to the European Central Bank. It met for the first time on 12 January under its first president, Alexandre Lamfalussy.[4] After much disagreement, in December 1995 the name euro was adopted for the new currency (replacing the name Ecu used for the previous accounting currency),[4] on the suggestion of then-German finance minister Theo Waigel. They also agreed on the date 1 January 1999 for its launch.[4]\\r\\nOn 17 June 1997 the European Council decided in Amsterdam to adopt the Stability and Growth Pact, designed to ensure budgetary discipline after creation of the euro, and a new exchange rate mechanism (ERM II) was set up to provide stability above the euro and the national currencies of countries that hadn't yet entered the eurozone. Then, on 3 May 1998, at the European Council in Brussels, the 11 initial countries that would participate in the third stage from 1 January 1999 were selected. To participate in the new currency, member states had to meet strict criteria such as a budget deficit of less than 3% of their GDP, a debt ratio of less than 60% of GDP, low inflation, and interest rates close to the EU average. Greece failed to meet the criteria and was excluded from participating on 1 January 1999.\\r\\nOn 1 June 1998 the European Central Bank succeeded the European Monetary Institute. However it wouldn't take on its full powers until the euro was created on 1 January 1999. The bank's first President was Wim Duisenberg, former head of the EMI and the Dutch central bank.[4] The conversion rates between the 11 participating national currencies and the euro were then established. The rates were determined by the Council of the European Union, based on a recommendation from the European Commission based on the market rates on 31 December 1998, so that one ECU would equal one euro. These rates were set by Council Regulation 2866/98 (EC), of 31 December 1998. They could not be set earlier, because the ECU depended on the closing exchange rate of the non-euro currencies (principally the pound sterling) that day. Due to differences in national conventions for rounding and significant digits, all conversion between the national currencies had to be carried out using the process of triangulation via the euro.\\r\\nThe currency was introduced in non-physical form (traveller's cheques, electronic transfers, banking, etc.) at midnight on 1 January 1999, when the national currencies of participating countries (the eurozone) ceased to exist independently in that their exchange rates were locked at fixed rates against each other, effectively making them mere non-decimal subdivisions of the euro. The euro thus became the successor to the European Currency Unit (ECU). The notes and coins for the old currencies, however, continued to be used as legal tender until new notes and coins were introduced on 1 January 2002 (having been distributed in small amounts in the previous December). Beginning on 1 January 1999, all bonds and other forms of government debt by eurozone nations were denominated in euros.\\r\\nThe value of the euro, which started at USD 1.1686 on 31 December 1998, rose during its first day of trading, Monday, 4 January 1999, closing at approximately USD 1.18.[15] It was rapidly taken up and dealers were surprised by the speed at which it replaced the national currencies. Trading in the Deutsche Mark was expected to continue in parallel but vanished as soon as the markets opened.[16] However, by the end of 1999 the euro had dropped to parity with the dollar[4] leading to emergency action from the G7 to support the euro in 2001.[17]\\r\\nLater in 2000, Denmark held a referendum on whether to abandon their opt-out from the euro. The referendum resulted in a decision to retain the krone, and also set back plans for a referendum in the UK as a result.[18] The procedure used to fix the irrevocable conversion rate of 340.750 between the Greek drachma and the euro was different, since the euro by then was already two years old. While the conversion rates for the initial eleven currencies were determined only hours before the euro was introduced as a virtual currency, the conversion rate for the Greek drachma was fixed several months beforehand, in Council Regulation 1478/2000 (EC),[19] of 19 June 2000.\\r\\nThe designs for the new coins and notes were announced between 1996 and 1998, and production began at the various mints and printers on 11 May 1998.[20] The task was large, and would require the full three years and a half. In all, 7.4 billion notes and 38.2 billion coins would be available for issuance to consumers and businesses on 1 January 2002.[21] In 7 nations, the new coins, struck in the run-up to 1 January 2002, would bear a 2002 date. In Belgium, Finland, France, the Netherlands, and Spain, the new coins would bear the date of striking, so those 5 countries would be the only ones to strike euro coins dated 1999, 2000, and 2001. Small numbers of coins from Monaco, Vatican City, and San Marino were also struck. These immediately became popular collector's items, commanding premiums well above face value. New issues continue to do so to this day.\\r\\nMeanwhile, a parallel task was to educate the European public about the new coins. Posters were issued showing the designs, which were used on items ranging from playing cards to T-shirts. As a final step, on 15 December 2001, banks began exchanging \\"euro starter kits\\", plastic pouches with a selection of the new coins in each country (generally, between 10 and 20 euros worththough Finland's contained one of each coin, totalling ?3.88). They would not be usable in commerce until 1 January, when notes would be made available as well. Larger starter kits, containing a roll of each denomination, were available as well in some nations.\\r\\nRetailers and government agencies had a considerable task as well. For items to be sold to the public, dual pricing was commonly utilised. Postage stamps for governments (as well as stamps issued by the United Nations Postal Administration for the UN offices in Vienna) often bore denominations both in the legacy currency and euros, assuring continued utility beyond 2001. Banks bore a huge task, not only in preparation for the change of the notes and coins, but also in the back office. Beginning in 1999, all deposits and loans were technically in euros, but deposits and withdrawals continued in the legacy currency. Statements would bear balances in both currencies beginning no later than 1 July 2001, and earlier if required by the customer's needs.\\r\\nBeginning on 1 December 2001, coins and notes were distributed from secure storage, first to large retailers, and then to smaller ones. It was widely expected that there would be massive problems on and after 1 January. Such a changeover, across twelve populous countries, had never been attempted before.\\r\\nThe new coins and notes were first valid on the French island of Runion in the Indian Ocean.[22] The first official purchase using euro coins and notes took place there, for one kilogram of lychees.[23] The coming of midnight in Frankfurt at the ECB offices, though, symbolised the transition.\\r\\nIn Finland, the Central Bank had opened for an hour at midnight to allow citizens to exchange currency, while a huge euro pyramid had decorated Syntagma Square in Athens. Other countries noted the coming of the euro as wellParis's Pont Neuf was decorated in EU colours, while in the northern German town of Gifhorn a sombre, symbolic funeral for the Deutsche Mark took place.\\r\\nExcept for Germany, the plan for introduction of the new currency was basically the same. Banks would accept the exchange of legacy currencies, begin to dispense euros from ATMs, and only euros would be available as withdrawals were made, beginning on 1 January. Merchants would accept legacy currency, but give change only in euros. In Germany, the Deutsche Mark would no longer be a legal tender on 1 January, but would have to be exchanged at the banks.\\r\\nDespite the massive amounts of euros available, chaos was feared. In France, these fears were accentuated by a threatened postal workers' strike.[24] The strike, however, was settled. Similarly, workers at the French bank BNP Paribas threatened to disrupt the introduction of euro currency with a strike. That was also settled.[25]\\r\\nIn practice, the roll-out was smooth, with few problems. By 2 January, all ATMs in 7 countries and at least 90 percent in 4 others were issuing euros rather than legacy currency, with Italy, the worst offender, having only 85% of ATMs dispensing euros.[27] The unexpected tendency of consumers to spend their legacy currency, rather than exchange it at banks, led to temporary shortages of euro small change, with some consumers being given change in legacy currency.[28]\\r\\nSome businesses did take advantage of the currency exchange to raise prices. According to a study by the Deutsche Bundesbank, there was a price rise, but consumers refused to buy as much. A coffee bar in Italy that took advantage of the transition to raise coffee prices by a third was ordered to pay compensation to customers.[29]\\r\\nNations were allowed to keep legacy currency in circulation as legal tender for two months, until 28 February 2002. The official date on which the national currencies ceased to be legal tender varied from member state to member state. The earliest date was in Germany; the Mark officially ceased to be legal tender after 31 December 2001. Most member states, though, permitted their legacy currency to remain in circulation the full two months. The legacy currency was exchangeable at commercial banks in the currency's nation for a further period, generally until 30 June 2002.\\r\\nHowever, even after the official dates, they continued to be accepted for exchange by national central banks for varying periodsand indefinitely in Austria, Germany, Ireland, and Spain. Coins from those four countries, Italy, and Finland remain exchangeable. The earliest coins to become non-convertible were the Portuguese escudos, which ceased to have monetary value after 31 December 2002, although banknotes remain exchangeable until 2022. All banknotes current on 1 January 2002 would remain valid until at least 2012.[30]\\r\\nIn Germany, Deutsche Telekom modified 50,000 pay phones to take Deutsche Mark coins in 2005, at least on a temporary basis.[31] Callers were allowed to use DM coins, at least initially, with the Mark pegged to equal one euro, almost twice the usual rate.[32]\\r\\nIn France, receipts still indicate the value of products in the legacy currency along with the euro value, as do receipts in Slovenia. In other eurozone countries this has long been considered unnecessary. In June 2008, The New York Times reported that many merchants in the French town of Collobrires, in Provence, choose to accept exchangeable franc notes.[33]\\r\\nAfter dropping to an interday low of $0.8296 on 26 October 2001, and a brief crash to $0.8115 on 15 January 2002, the euro soon recovered from its early slump. Its value last closed below $1.00 on 6 November 2002 ($0.9971), and increased rapidly from there. It peaked at $1.35 in 2004, and reached its highest value versus the U.S. dollar at $1.5916 on 14 July 2008.[34] As its values increased against the pound sterling in the late-2000s, peaking at 97.73p on 31 December 2008, its international usage grew rapidly.[35] The euro grew in importance steadily, with its share of foreign exchange reserves rising from nearly 18% in 1999 to 25% in 2003 - while the dollar share fell by an equivalent margin.[36] Alan Greenspan in 2007 said the eurozone had profited from the euro's rise and claimed it was perfectly conceivable that it could trade equally or become more important than the US dollar in the future.[37]\\r\\nPublic support for the euro in each state between 2001 to 2006[38]\\r\\nAs a result of the global financial crisis that began in 2007/2008, the eurozone entered its first official recession in the third quarter of 2008, official figures confirmed in January 2009.[39] The EU was in negative growth for the second, third and fourth quarters of 2008 and the first quarter of 2009 before returning to positive growth (for the eurozone as a whole).[40] Despite the recession, Estonia acceded to the eurozone and Iceland put in an EU application to join the euro, seeing it at the time as a safe haven.\\r\\nIn 2009, the Lisbon Treaty formalised the Eurogroup, the meeting of euro finance ministers, with an official president. Jean-Claude Juncker served as president before and after formalisation and has been an advocate of strengthening the group, economic co-operation and common representation. Appetite for stronger economic co-operation grew due to the recession and the potential failure of some weaker eurozone members.[41] However Germany had opposed previous moves to strengthen the Eurogroup, such as French President Nicolas Sarkozy's attempts at Eurogroup summits, due to fears of undermining the ECB's independence. Jean-Claude Trichet, who succeeded Duisenberg as ECB president in 2003, fended off numerous attacks from Sarkozy at the start of the recession. Before that formalisation of the Eurogroup, eurozone leaders held an extraordinary summit in reaction to the financial crisis on 11 October 2008 in Paris. Rather than the Eurogroup meeting as finance ministers, they met as head of states or government (similar to the European Council) to define a joint action plan for the eurozone and the European Central Bank to stabilise the European economy. These such meetings would be where many euro governance reforms would be agreed.\\r\\nThe leaders hammered out a plan to confront the financial crisis which will involve hundreds of billions of euros of new initiatives to head off a feared meltdown. They agreed a bank rescue plan: governments would buy into banks to boost their finances and guarantee interbank lending. Coordination against the crisis is considered vital to prevent the actions of one country harming another and exacerbating the bank solvency and credit shortage problems.[citation needed]\\r\\nDespite initial fears by speculators in early 2009 that the stress of such a large recession could lead to the break-up of the eurozone, the euro's position actually strengthened as the year progressed. Far from the poorer performing economies moving further away and becoming a default risk, bond yield spreads between Germany and the weakest economies decreased easing the strain on these economies. Much of the credit for the turn around in fortunes has been attributed to the ECB, which injected ?500bn into the banks in June.[42] Indeed, the euro came to be seen as a safe haven, as countries outside it such as Iceland fared worse than those with the euro. Iceland subsequently applied to the EU to get the benefit of using a larger currency with the support of the ECB.[43]\\r\\nHowever, with the risk of a default in Greece and other members in late 2009ÿ10, eurozone leaders agreed to agree provisions for bailing out member states who could not raise funds (triggered for Greece in April 2010).[44][45] This was a u-turn on the EU treaties which rule out any bail out of a euro member to encourage them to manage their finances better. Yet with Greece struggling to restore its finances, other member states also at risk and the repercussions this would have on the rest of the eurozone economy; a temporary bail out mechanism was agreed and devised in the form of a special purpose vehicle (SPV) named \\"European Financial Stability Facility\\" (complemented by the European Financial Stabilisation Mechanism and funds form the International Monetary Fund), aiming at preserving financial stability in Europe by providing financial assistance to eurozone states in difficulty. The crisis also spurred consensus for further economic integration and a range of proposals such as a \\"European Monetary Fund\\" or federal treasury.[46][47][48]\\r\\nHowever, in June 2010, broad agreement was finally reached on a controversial proposal for member states to peer review each other's budgets prior to their presentation to national parliaments. Although showing the entire budget to each other was opposed by Germany, Sweden and the UK, each government would present to their peers and the Commission their estimates for growth, inflation, revenue and expenditure levels six months before they go to national parliaments. If a country was to run a deficit, they would have to justify it to the rest of the EU while countries with a debt more than 60% of GDP would face greater scrutiny.[49] The plans would apply to all EU members, not just the eurozone, and have to be approved by EU leaders along with proposals for states to face sanctions before they reach the 3% limit in the Stability and Growth Pact. Poland has criticised the idea of withholding regional funding for those who break the deficit limits, as that would only impact the poorer states.[49] In June 2010 France agreed to back Germany's plan for suspending the voting rights of members who breach the rules.[50]\\r\\nIn late 2010/early 2011 it was agreed to replace the European Financial Stability Facility and European Financial Stability Mechanism with a larger and permanent European Stability Mechanism (ESM). The ESM required a treaty amendment to allow it and a separate treaty to establish it but, if ratified successfully, would be established in time to take over when the old facilities expire in 2013. Meanwhile, to support Italy and prevent it having to ask for a bail-out later, the ECB controversially started buying Italian bonds, as it had done with Greece.\\r\\nIn March 2011 was initiated a new reform of the Stability and Growth Pact aiming at straightening the rules by adopting an automatic procedure for imposing of penalties in case of breaches of either the deficit or the debt rules.[51][52] The Euro Plus Pact sets out a wide range of reforms to take place in the eurozone to ensure and the French and German governments further agreed to push for a 'true economic government' that would involve twice-yearly eurozone leader summits and a financial transactions tax.[53]\\r\\nThe European Fiscal Union is a proposal for a treaty about fiscal integration described in a decision adopted on 9 December 2011 by the European Council. The participants are the eurozone member states and all other EU members without the United Kingdom and the Czech Republic. The treaty entered into force on 1 January 2013 for the 16 states which completed ratification prior of this date[54] and on 1 April 2014 entered into force for all 25 signatories.\\r\\nDespite speculation that the crisis in Greece could spread and that the euro might fail, some newer EU states from the 2004 enlargement joined the currency during the recession. Slovenia, Malta and Cyprus all acceded within the first two years of the recession, closely followed by Slovakia in 2009. The three Baltic states of Estonia, Latvia and Lithuania joined in 2011, 2014 and 2015 respectively.\\r\\nSlovenia was the first country to join the eurozone after the launch of the coins and banknotes. Participation in ERM II began on 28 June 2004[55] and on 11 July 2006 the Council of EU adopted a decision allowing Slovenia to join the euro area as from 1 January 2007.[56] The euro replaced the Slovenian tolar on 1 January 2007. The exchange rate between the euro and tolar had been set on 11 July 2006 at 239.640?SIT, but unlike the previous launches, cash and non-cash transactions were introduced simultaneously.\\r\\nCyprus replaced the Cypriot pound with the euro on 1 January 2008.[57]\\r\\nA formal letter of application to join the eurozone was submitted on 13 February 2007.[58] On 16 May 2007 the European Commission, backed by the European Central Bank, gave its go-ahead for the introduction in January 2008.[59][60]\\r\\nThe campaign to inform the citizens of Cyprus about the euro officially began in Cypriot media on 9 March 2007. On 15 March 2007, the Cypriot House of Representatives passed the necessary laws for the introduction of the euro on 1 January 2008. The European Commissioner for Economic & Financial Affairs Joaqun Almunia, on 16 May 2007, recommended that Cyprus adopt the euro as scheduled and the European Parliament concurred on 21 June 2007, the date was confirmed by the EU leaders. The final decision was taken by the EU finance ministers (Ecofin) on 10 July 2007 and the conversion rate was fixed at 0.585274 CYP.[61] On 23 October 2007, the coin designs were officially published in the Official Journal of the European Union.[62]\\r\\nOn 1 January 2008 the euro replaced the Cypriot pound as the official currency.[63] The euro is only used in the government-controlled areas of the Republic, the Sovereign Base Areas of Akrotiri and Dhekelia (under UK jurisdiction, outside the EU) and in the United Nations Buffer Zone in Cyprus.[64] The de facto Turkish Republic of Northern Cyprus continues to use the new Turkish lira as its primary currency and the euro as its secondary currency.[65]\\r\\nMalta replaced the Maltese lira with the euro on 1 January 2008.[57] The aims were officially confirmed on 26 February 2007.[66] On 16 May 2007, the Commissioner for Economic & Financial Affairs of the EU, Joaqun Almunia, recommended that Malta adopt the euro as scheduled, a decision later confirmed by the Council of Finance Ministers of 10 July 2007. On the same day, dual displaying became mandatory and the first Maltese euro coins were struck at Monnaie de Paris. The first Maltese euro coins were available for the public on 1 December 2007, as business starter packs worth ?131 each started being available for small businesses to fill up their cash registers with sufficient amount of euro coins before the ?-day (Jum ?). Mini-kits each worth ?11.65 were available for the general public on 10 December 2007.[67] Maltese coins which were current at the time of the euro transition may be exchanged through 1 February 2010.[30]\\r\\nMaltese citizens could obtain euro information directly from their town or village between December 2007 and January 2008. From the Euro Centres (?entru l-ewro) which opened during the day. People trained specifically on matters related to the changeover to the euro were available to provide council at euro centres along with information materials.[68]\\r\\nIn December 2007, as part of the euro changeover celebrations, streets of Valletta were covered with carpets depicting euro coins. Celebrations reached climax on New Year's Eve with a firework display near the Grand Harbour area, several other activities had to be moved indoors because of the stormy weather that struck the island on that night.\\r\\nSlovakia adopted the euro on 1 January 2009. The koruna was part of ERM II from 28 November 2005, requiring that it trade within 15% of an agreed central rate; this rate was changed on 17 March 2007 and again on 28 May 2008. The rate of 30.126?SKK from May 2008 was finally confirmed on 8 July 2008.[69]\\r\\nTo assist the process of conversion to the euro, on 1 April 2008, the National Bank of Slovakia (NBS) announced their plan for withdrawal of the Slovak koruna notes and coins.[70] A few days later, on 5 April 2008, Slovakia officially applied to enter the eurozone.[71] On 7 May 2008, the European Commission approved the application and asked member states to endorse the bid during the EU finance ministers' meeting in July 2008.[72][73][74]\\r\\nSlovakia fulfilled the euro convergence criteria. At 2.2%, Slovakia's twelve-month inflation was well below the 3.2% threshold. However, for March 2008 annual inflation was 3.6%. Fiscal deficit was 2.2% versus the reference value of 3.0%. And finally, the government debt ratio was 29.4% of GDP in 2007, well below the maximum ratio of 60.0%.[75] Public opinion supported the switch, with 58% in favour and 35% opposed, but 65% worried about the inflationary impacts of the adoption.[76] Three months after the adoption of the currency 83 percent of Slovaks consider Slovakia's decision to adopt the euro to have been right.[77]\\r\\nPublicity for the transition from the koruna to the euro on 1 January 2009 included an \\"euromobile\\", with a professional actor driving around the countryside holding impromptu quiz shows about the euro. Winners received euro T-shirts, euro conversion calculators, and chocolate euro coins.[78] Euro starter kits, available for 500 koruna, were a popular Christmas gift in 2008. The coins therein, however, were not valid as legal tender in the eurozone until 1 January 2009, with koruna exchanged through 17 January 2009, though redeemable at the central bank in Bratislava until a date to be determined. Anyone using Slovakian euro coins before 1 January could have been fined. Businesses using the transition to raise prices also were subject to penalty.[78]\\r\\nIn 2010 Estonia gained the support of the European Commission, Central Bank and Parliament for accession on 1 January 2011 with Estonia adopting the currency on that date.[79][80] In 2013 Latvia gained the support of the European Commission, Central Bank and Parliament for accession on 1 January 2014 with Latvia adopting the currency on that date.[81][82] On 23 July 2014 Lithuania became the last Baltic state to gain permission to join the euro, which was adopted on 1 January 2015.[83]\\r\\nThe chart below provides a full summary of all applying exchange-rate regimes for EU members, since the European Monetary System with its Exchange Rate Mechanism and the related new common currency ECU was born on 13 March 1979. The euro replaced the ECU 1:1 at the exchange rate markets, on 1 January 1999. During 1979-1999, the D-Mark functioned as a de facto anchor for the ECU, meaning there was only a minor difference between pegging a currency against ECU and pegging it against the D-mark.\\r\\nSources: EC convergence reports 1996-2014, Italian lira[dead link], Spanish peseta, Portuguese escudo, Finish markka, Greek drachma, UK pound\\r\\nThe eurozone was born with its first 11 Member States on 1 January 1999. The first enlargement of the eurozone, to Greece, took place on 1 January 2001, one year before the euro had physically entered into circulation. The next enlargements were to states which joined the EU in 2004, and then joined the eurozone on 1 January in the mentioned year: Slovenia (2007), Cyprus (2008), Malta (2008), Slovakia (2009), Estonia (2011), Latvia (2014), and Lithuania (2015).\\r\\nAll new EU members having joined the bloc after the signing of the Maastricht treaty in 1992, are obliged to adopt the euro under the terms of their accession treaties. However, the last of the five economic convergence criteria which needs first to be complied with in order to qualify for euro adoption, is the exchange rate stability criterion, which requires having been an ERM-member for a minimum of two years without the presence of \\"severe tensions\\" for the currency exchange rate.\\r\\nIn September 2011, a diplomatic source close to the euro adoption preparation talks between the seven remaining new Member States from Eastern Europe who had yet to adopt the euro (Bulgaria, Czech Republic, Hungary, Latvia, Lithuania, Poland and Romania), claimed that the monetary union (eurozone) they had thought they were going to join upon their signing of the accession treaty may very well end up being a very different union entailing much closer fiscal, economic and political convergence. This changed legal status of the eurozone could potentially cause them to conclude that the conditions for their promise to join were no longer valid, which \\"could force them to stage new referendums\\" on euro adoption.[84]\\r\\nThe following lists the percentage of respondents supporting the euro in each country, according to the Standard Eurobarometer. The date reflects the month the field work was conducted in.[38]","input":"When did the euro became the european currency?"},{"output":"April 6, 1917","context":"","input":"When did the us join world war one?"},{"output":"Truffula","context":"The Lorax is a children's book written by Dr. Seuss and first published in 1971.[1] It chronicles the plight of the environment and the Lorax, who speaks for the trees against the Once-ler. As in most Dr. Seuss works, most of the creatures mentioned are original to the book.\\r\\nThe book is commonly recognized as a fable concerning the danger corporate greed poses to nature, using the literary element of personification to give life to industry as the Once-ler and the environment as The Lorax.\\r\\nThe Lorax was Dr. Seuss' personal favorite of his books. He was able to create a story addressing economic and environmental issues without it being dull. \\"The Lorax,\\" he once explained, \\"came out of me being angry. In The Lorax I was out to attack what I think are evil things and let the chips fall where they might.\\"[2]\\r\\n\\r\\n\\r\\nA boy living in a polluted area visits a strange isolated man called the Once-ler on the Street of the Lifted Lorax. The boy pays the Once-ler fifteen cents, a nail, and the shell of a great-great-great grandfather snail to hear the legend of how the Lorax was lifted away.\\r\\nThe Once-ler tells the boy of his arrival in a beautiful valley containing a forest of Truffula trees and a range of animals. The Once-ler, having long searched for such a tree as the Truffula, chops one down and uses its silk-like foliage to knit a Thneed, an impossibly versatile garment. The Lorax, who \\"speaks for the trees\\" as they have no tongues, emerges from the stump of the Truffula and voices his disapproval both of the sacrifice of the tree and of the Thneed itself. However, the first other person to happen by purchases the Thneed for $3.98, so the Once-ler is encouraged and starts a business making and selling Thneeds.\\r\\nThe Once-ler's small shop soon grows into a factory. The Once-ler's relatives all come to work for him and new vehicles and equipment are brought in to log the Truffula forest and ship out Thneeds. The Lorax appears again to report that the small bear-like Bar-ba-loots, who eat Truffula fruits, are short of food and must be sent away to find more. The Lorax later returns to complain that the factory has polluted the air and the water, forcing the Swomee-Swans and Humming-Fish to migrate as well. The Once-ler is unrepentant and defiantly tells the Lorax that he will keep on \\"biggering\\" his business, but at that moment one of his machines fells the very last Truffula tree.\\r\\nWithout raw materials, the factory shuts down and the Once-ler's relatives leave. The Lorax says nothing but with one sad backward glance and the Once-ler helps him into the air (\\"by the seat of his pants\\") and disappears behind the smoggy clouds. Where he last stood is a small monument engraved with a single word: \\"UNLESS\\". The Once-ler ponders the message for years, in solitude and self-imposed exile.\\r\\nIn the present, his buildings falling apart around him, the Once-ler at last realizes out loud what the Lorax meant: \\"unless someone like you cares a whole awful lot, nothing is going to get better. It's not.\\" He then gives the boy the last Truffula seed and urges him to grow a forest from it, saying that if the trees can be protected from logging then the Lorax and all of his friends may come back.\\r\\nBased on a 2007 online poll, the National Education Association named The Lorax one of its \\"Teachers' Top 100 Books for Children\\".[3] In 2012 it was ranked number 33 among the \\"Top 100 Picture Books\\" in a survey published by School Library Journal ÿ the second of five Dr. Seuss books on the list.[1]\\r\\nIn a retrospective critique written in the journal Nature in 2011 upon the 40th anniversary of the book's publication, Emma Marris described the Lorax character as a \\"parody of a misanthropic ecologist\\". She called the book \\"gloomy\\" and expressed skepticism that its message would resonate with small children in the manner intended. Nevertheless, she praised the book as effective in conveying the consequences of ecological destruction in a way that young children will understand.[4]\\r\\nIn 1988, a small school district in California kept the book on a reading list for second graders, though some in the town claimed the book was unfair to the logging industry.[5][6]\\r\\nTerri Birkett, a member of a family-owned hardwood flooring factory, authored The Truax,[7] offering a logging-friendly perspective to an anthropomorphic tree known as the Guardbark. This book was published by the National Oak Flooring Manufacturers' Association (NOFMA). Just as in The Lorax, the book consists of a disagreement between two people. The logging industry representative states that they have efficiency and re-seeding efforts. The Guardbark, a personification of the environmentalist movement much as the Once-ler is for big business, refuses to listen and lashes out. But in the end, he is convinced by the logger's arguments. However, this story was criticized for what were viewed as skewed arguments and clear self-interest, particularly a \\"casual attitude toward endangered species\\" that answered the Guardbark's concern for them. In addition, the book's approach as a more blatant argument, rather than one worked into a storyline, was also noted.[8][9][10]\\r\\nThe line \\"I hear things are just as bad up in Lake Erie\\" was removed more than fourteen years after the story was published, after two research associates from the Ohio Sea Grant Program wrote to Seuss about the clean-up of Lake Erie.[11] The line remains in the home video releases of the television special.\\r\\nThe book was adapted as an animated musical television special produced by DePatie-Freleng Enterprises, directed by Hawley Pratt and starring the voices of Eddie Albert and Bob Holt. It was first aired by CBS on February 14, 1972. A reference to pollution of Lake Erie was spoken by one of the Humming-Fish as they depart; it remains in DVD releases of the show, although later removed from the book. The special also shows the Once-ler arguing with himself, and asking the Lorax whether shutting down his factory (thus putting hundreds of people out of work) is practical. An abridged version of the special is used in the 1994 TV movie In Search of Dr. Seuss, with Kathy Najimy's reporter character hearing the Once-ler's story.\\r\\nOn March 2, 2012, Universal Studios and Illumination Entertainment released a 3-D CGI film based upon the book. The release coincided with the 108th birthday of Seuss, who died at 87 in 1991. The cast includes Danny DeVito as the Lorax, Zac Efron as Ted (the boy in the book), and Ed Helms as the Once-ler. The film includes several new characters: Rob Riggle as villain Aloysius O'Hare, Betty White as Ted's Grammy Norma, and Taylor Swift as Audrey, Ted's romantic interest. The film debuted in the #1 spot at the box office, making $70 million, though it received mixed reviews. The film eventually grossed a domestic total of $214,030,500.[12]\\r\\nTwo audio readings have been released on CD, one narrated by Ted Danson in the United States (Listening Library, ISBN?978-0-8072-1873-0) and one narrated by Rik Mayall in the United Kingdom (HarperCollins, ISBN?978-0-00-715705-1).\\r\\nA musical adaptation of The Lorax was originally included in script for the Broadway musical Seussical, but was cut before the show opened.[13]\\r\\nFrom 2 December 2015 to 16 January 2016, a musical version of the book ran at the Old Vic theatre in London. With former Noah And The Whale frontman, Charlie Fink, who wrote the music for the production.[14]","input":"What are the trees from the lorax called?"},{"output":"Jeff Hanna","context":"The Nitty Gritty Dirt Band, an American country rock band, has existed in various forms since its founding in Long Beach, California in 1966. The group's membership has had at least a dozen changes over the years, including a period from 1976 to 1981 when the band performed and recorded as the Dirt Band. Constant members since the early times are singer-guitarist Jeff Hanna and drummer Jimmie Fadden. Multi-instrumentalist John McEuen was with the band from 1966 to 1986 and returned during 2001 departing once again in November 2017. Keyboardist Bob Carpenter joined the band in 1977. The band is often cited as instrumental to the progression of contemporary country and roots music.\\r\\n\\r\\nThe band's successes include a cover version of Jerry Jeff Walker's \\"Mr. Bojangles\\". Albums include 1972's Will the Circle be Unbroken, featuring such traditional country artists as Mother Maybelle Carter, Earl Scruggs, Roy Acuff, Doc Watson, Merle Travis, and Jimmy Martin. A follow-up album based on the same concept, Will the Circle Be Unbroken: Volume Two was released in 1989, was certified gold, won two Grammys, and was named Album of the Year at the Country Music Association Awards.\\r\\n\\r\\nThe Nitty Gritty Dirt Band was founded around 1966 in Long Beach, California by singer-guitarist Jeff Hanna and singer-songwriter guitarist Bruce Kunkel who had performed as the New Coast Two and later the Illegitimate Jug Band. Trying, in the words of the band's website, to \\"figure out how not to have to work for a living,\\" Hanna and Kunkel joined informal jam sessions at McCabe's Guitar Shop in Long Beach.[citation needed] There they met a few other musicians: guitarist/washtub bassist Ralph Barr, guitarist-clarinetist Les Thompson, harmonicist and jug player Jimmie Fadden, and guitarist-vocalist Jackson Browne. As Nitty Gritty Dirt Band, the six men started as a jug band and adopted the burgeoning southern California folk rock musical style, playing in local clubs while wearing pinstripe suits and cowboy boots. Their first paying performance was at the Golden Bear in Huntington Beach, California.[1]\\r\\n\\r\\nBrowne was in the band for only a few months before he left to concentrate on a solo career as a singer-songwriter. He was replaced by John McEuen on banjo, fiddle, mandolin, and steel guitar. McEuen's older brother, William, was the group's manager, and he helped the band get signed with Liberty Records, which released the group's debut album, The Nitty Gritty Dirt Band during 1967. The band's first single, \\"Buy for Me the Rain,\\" was a Top 40 success, and the band gained exposure on The Tonight Show Starring Johnny Carson, as well as concerts with such disparate artists as Jack Benny and The Doors.\\r\\n\\r\\nA second album, Ricochet, was released later during the year and was less successful than their first. Kunkel wanted the band to \\"go electric\\", and include more original material. Bruce left the group to form WordSalad and Of The People. He was replaced by multi-instrumentalist Chris Darrow.\\r\\n\\r\\nBy 1968, the band adopted electrical instruments anyway, and added drums. The first electric album, Rare Junk, was a commercial failure, as was their next, Alive.\\r\\n\\r\\nThe band continued to gain publicity, mainly as a novelty act, making an appearance in the 1968 film, For Singles Only, and a cameo appearance in the 1969 musical western film, Paint Your Wagon, performing \\"Hand Me Down That Can o' Beans\\". The band also played Carnegie Hall as an opening act for Bill Cosby and played in a jam session with Dizzy Gillespie.\\r\\n\\r\\nThe group was inactive for a 6-month period after Paint Your Wagon, then reformed with Jimmy Ibbotson replacing Chris Darrow. With William McEuen as producer and a renegotiated contract that gave the band more artistic freedom, the band recorded and released Uncle Charlie & His Dog Teddy, issued in 1970. Embracing a straight, traditional country and bluegrass sound, the album included the group's best-known singles; a cover version of Jerry Jeff Walker's \\"Mr. Bojangles\\", Michael Nesmith's \\"Some of Shelley's Blues\\", and four Kenny Loggins songs including \\"House at Pooh Corner\\", the first recordings of Loggins's songs. Their version of \\"Mr. Bojangles\\" became the group's first hit, peaking at #9 on Billboard's all genre Hot 100 chart, with an unusual 36 weeks on the charts.\\r\\n\\r\\nThe next album, All The Good Times, released during early 1972, had a similar style.\\r\\n\\r\\nNitty Gritty Dirt Band next sought to solidify its reputation as a country band when band member John McEuen asked Earl Scruggs if he would record with the group. Earl's \\"yes\\" was followed the next week when John asked Doc Watson the same question, receiving the same answer of 'yes'. This set in motion the further addition of other artists, and with the help of Earl and Louise Scruggs, they set to traveling to Nashville, Tennessee, and recording what was to become a triple album, Will the Circle Be Unbroken with Nashville stalwarts Roy Acuff, Earl Scruggs, and Jimmy Martin, country pioneer Mother Maybelle Carter, folk-blues guitarist Doc Watson, Merle Travis, Norman Blake, and others. The title is from the song, \\"Will the Circle Be Unbroken (By and By)\\", as adapted by A. P. Carter, and reflects the album's theme of trying to tie together three generations of musicians: long-haired boys from California and older veterans of the middle American establishment. The track \\"I Saw the Light\\" with Acuff singing, was a success, and the album received two nominations for Grammy Award. Veteran fiddler Vassar Clements was introduced to a wider audience by the album and gave him a new career. The band also toured Japan twice soon after this period.\\r\\n\\r\\nAfter the next album Les Thompson left the group, making the band a foursome. Stars & Stripes Forever was a live album that mixed old successes such as \\"Buy for Me the Rain\\" and \\"Mr. Bojangles\\" with Circle collaborations (fiddler Vassar Clements was a guest performer) and long storytelling spoken-word monologues. A studio album, Dream, was also released.\\r\\n\\r\\nDuring July 1974, the band was among the headline acts at the Ozark Music Festival at the Missouri State Fairgrounds in Sedalia, Missouri. Some estimates put the crowd at 350,000 people, which would make this one of the largest music events in history. At another concert, the band opened for the rock band Aerosmith.\\r\\n\\r\\nJimmy Ibbotson left the band at the end of 1976, leaving Fadden, Hanna, and McEuen to add John Cable and Jackie Clark, brought in on guitar and bass. In May 1977 the Nitty Gritty Dirt Band became the first American group allowed to tour Russia, Armenia, Georgia and Latvia - the Soviet Union. Playing 28 sold out concerts, and a televised appearance that is estimated to have been watched by 145 million people. In 1977, the Nitty Gritty Dirt Band first appeared on the second season of the PBS music program Austin City Limits.\\r\\n\\r\\nAfter returning from Russia, the band released its first 'greatest successes' compilation, another now rare triple album Dirt, Silver & Gold, in 1978.\\r\\nAfter that release, the band shortened its name to The Dirt Band, and the group's sound became more pop and rock oriented. Saxophonist Al Garth, drummer Merel Bregante, and bassist Richard Hathaway were also added to the lineup in 1978 and Jeff Hanna became the group's producer for a few albums.\\r\\n\\r\\nKeyboardist Bob Carpenter (who would occasionally sit in with the band from 1975 on) contributed to their 1978 album The Dirt Band and joined the band permanently in 1979.\\r\\n\\r\\nAlbums during this period included The Dirt Band and An American Dream. The single \\"American Dream\\" with Linda Ronstadt reached No.?13 on the popular music charts. The band also appeared on Saturday Night Live in their own slot (performing the instrumental penned by John, \\"White Russia'), and separately, billed as The Toot Uncommons, provided backing for Steve Martin on his million-selling novelty tune, \\"King Tut.\\" They also played on that hit recorded in Aspen earlier that year.\\r\\n\\r\\nIn 1980, Bregante left the group and drummer Mike Gardner replaced Bregante on stage with the group on tour, only to be succeeded by Vic Mastrianni in 1981. Al Garth moved on to Pure Prairie League and later the Eagles.\\r\\n\\r\\nThe albums Make a Little Magic and Jealousy were released in 1980 and 1981, with the single \\"Make a Little Magic\\" featuring Nicolette Larson reaching the Top 25 on the pop chart. The group also performed the song on a 1980 Steve Martin television special, All Commercials, with an added comic element in which Martin lip-synced the Larson vocal for the last segment of the song.\\r\\n\\r\\nThe band returned to its original name and its country roots in 1982 with the lineup paring down to Hanna, Fadden, McEuen and Jimmy Ibbotson rejoining for recording sessions in Nashville, Tennessee for the album Let's Go, which yielded the success \\"Dance Little Jean\\" which was a Top 10 country hit. Carpenter rejoined the band in 1983 and the next album, 1984's Plain Dirt Fashion had the band's first No.?1 success, \\"Long Hard Road (The Sharecropper's Dream)\\".\\r\\n\\r\\nThere were two more country No.?1's: \\"Modern Day Romance\\" (1985) and \\"Fishin' in the Dark\\" (1987), the latter of which became the band's biggest-selling single, eventually being certified platinum in 2014 despite never reaching the Hot 100. Other successful songs were \\"Dance Little Jean\\" (1983); \\"I Love Only You\\" (1984); \\"High Horse\\" (1985); \\"Home Again in My Heart,\\" \\"Partners, Brothers and Friends\\" and \\"Stand a Little Rain\\" (1986); \\"Fire in the Sky,\\" \\"Baby's Got a Hold on Me\\" and \\"Oh What a Love\\" (1987); \\"Workin' Man (Nowhere to Go)\\" and \\"I've Been Lookin'\\" (1988); and \\"Down That Road Tonight\\" and \\"When it's Gone\\" (1989).\\r\\n\\r\\nPerformances included the 1984 Los Angeles Olympic Games and the inaugural Farm Aid concert in Champaign, Illinois. A 20-year anniversary concert at McNichols Sports Arena in Denver, Colorado featured such guests as Ricky Skaggs, Emmylou Harris, Doc Watson, and John Prine.\\r\\n\\r\\nJohn McEuen left the band at the end of 1986, replaced by Bernie Leadon, formerly of the Eagles. He was with the Nitty Gritty Dirt Band in 1987 and 1988. The band's 19th album, Hold On featured the No.?1 singles \\"Fishin' in the Dark\\" and \\"Baby's Got a Hold on Me.\\" The band appeared on the Today Show and The Tonight Show in the same week, and toured Europe.\\r\\n\\r\\nDuring 1989, Nitty Gritty Dirt Band again returned to Nashville, to record Will the Circle Be Unbroken: Volume Two. Returnees from the first Circle included Earl Scruggs, Vassar Clements, and Roy Acuff. Johnny Cash and the Carter Family, Emmylou Harris, and Ricky Skaggs joined the sessions, as did John Prine, Levon Helm, John Denver, John Hiatt, Bruce Hornsby, and former Byrds Roger McGuinn and Chris Hillman. This album won two Grammy Awards[2] and was named Album of the Year at the Country Music Association Awards for Best Country Vocal Performance (duo or group) and the Country Music Association's Album of the Year Award in 1989.\\r\\n\\r\\nAs a foursome of Hanna, Fadden, Ibbotson and Carpenter, the band again toured the former Soviet Union, as well as Canada, Europe, and Japan. A 25th anniversary concert was recorded on Live Two Five in Red Deer, Alberta, produced by T-Bone Burnett.\\r\\n\\r\\nDuring 1992, the band collaborated with Irish folk music's The Chieftains for the Grammy Award-winning Another Country. Other efforts included the album Acoustic, spotlighting their \\"wooden\\" sound, a duet with Karla Bonoff, \\"You Believed in Me\\" for the MCA Olympic compilation, One Voice, and a cover version of Buddy Holly's \\"Maybe Baby\\" for the Decca tribute album, Not Fade Away. The Christmas Album was released in 1997, followed by Bang! Bang! Bang! in 1999.\\r\\n\\r\\nDuring April 1992, they were the unwitting subject of one of George H. W. Bush's malapropisms when he referred to the group as the \\"Nitty Ditty Nitty Gritty Great Bird\\" at a country music awards ceremony in Nashville:\\r\\n\\r\\nThis unusual phrasing was repeatedly used as an example of Bush's garbled syntax (notably, in Dave Barry's book Dave Barry Hits Below the Beltway and in Barry's only non-audiobook album, A Totally Random Evening with Dave Barry), which in turn helped publicize the band.[citation needed]\\r\\n\\r\\nJohn McEuen rejoined the band in 2001. During 2002, Nitty Gritty Dirt Band celebrated the 30th anniversary of their landmark Will the Circle Be Unbroken with a remastered CD reissue of the 1972 album and a new compilation, Will the Circle Be Unbroken: Volume III. An album of all-new material, Welcome to Woody Creek, was released in 2004. Jimmy Ibbotson again left the band a few years later.\\r\\n\\r\\nAlso during 2004, country group Rascal Flatts released a cover of \\"Bless the Broken Road,\\" which the Nitty Gritty Dirt Band had recorded on Acoustic, from 1994. Songwriters Jeff Hanna, Marcus Hummon, and Bobby Boyd won a Grammy for Best Country Song for this work in 2005.\\r\\n\\r\\nDuring 2005 the band donated use of the song \\"Soldier's Joy\\" for the benefit album, Too Many Years to benefit Clear Path International's work with landmine survivors. Also in 2005, the band was recognized by the International Entertainment Buyers Association for 40 years of contributions to the music industry.\\r\\n\\r\\nIn 2009 the band released a new album, Speed of Life. Produced by George Massenburg and Jon Randall Stewart, Speed of Life is composed of a series of live, freewheeling studio recordings that purposefully avoid overproduction and demonstrate the band's collaborative spirit and spontaneity. Of the 13 tracks on Speed of Life, 11 are new songs penned by the band, and two are classic covers: Canned Heat's Woodstock hit \\"Going Up the Country\\" and Stealers Wheel's \\"Stuck in the Middle\\".\\r\\n\\r\\nIn September 2015, Nitty Gritty Dirt Band commemorated their 50th anniversary with a sold out show at the Ryman Theater.  Taped for a PBS special which debuted in March 2016, the concert included guests John Prine, Sam Bush, Vince Gill, Jerry Jeff Walker, Alison Krauss, Rodney Crowell, Byron House, Jerry Douglas and Jackson Browne in addition to former member Ibbotson. On September 30, 2016,  Circlin Back: Celebrating 50 Years,  a live CD and DVD was released.  In a 2016 review, the Los Angeles Times wrote that the original release  \\"helped knock down barriers then separating the traditional country and rock music communities, setting the stage for the eventual emergence of what came to be known as Americana music.\\"[4] John McEuen announced his departure from the band in December 2017 at the conclusion of their 50th anniversary tour.  John currently performs as a solo artist.\\r\\n\\r\\nJeff Hanna and John McEuen's sons, Jaime Hanna and Jonathan McEuen, recorded for DreamWorks Records in 2005 as Hanna-McEuen.[5]","input":"Who are the current members of the nitty gritty dirt band?"},{"output":"the 1980s","context":"The social model of disability is a reaction to the dominant medical model of disability which in itself is a functional analysis of the body as machine to be fixed in order to conform with normative values.[1] The social model of disability identifies systemic barriers, negative attitudes and exclusion by society (purposely or inadvertently) that mean society is the main contributory factor in disabling people. While physical, sensory, intellectual, or psychological variations may cause individual functional limitation or impairments, these do not have to lead to disability unless society fails to take account of and include people regardless of their individual differences. The origins of the approach can be traced to the 1960s; the specific term emerged from the United Kingdom in the 1980s.\\r\\n\\r\\n\\r\\nIn 1975, the UK organization Union of the Physically Impaired Against Segregation (UPIAS) claimed: \\"In our view it is society which disables physically impaired people. Disability is something imposed on top of our impairments by the way we are unnecessarily isolated and excluded from full participation in society.\\"[2][3]\\r\\nIn 1983, the disabled academic Mike Oliver coined the phrase \\"social model of disability\\" in reference to these ideological developments.[4] Oliver focused on the idea of an individual model (of which the medical was a part) versus a social model, derived from the distinction originally made between impairment and disability by the UPIAS.[5]\\r\\nThe \\"social model\\" was extended and developed by academics and activists in Australia, the UK, US and other countries, and extended to include all disabled people, including those who have learning difficulties / learning disabilities / or who are mentally handicapped, or people with emotional, mental health or behavioural problems.[6][7]\\r\\nOliver did not intend the \\"social model of disability\\" to be an all encompassing theory of disability, rather a starting point in reframing how society views disability.[8]\\r\\nA fundamental aspect of the social model concerns equality. The struggle for equality is often compared to the struggles of other socially marginalized groups. Equal rights are said to give empowerment and the \\"ability\\" to make decisions and the opportunity to live life to the fullest. A related phrase often used by disability rights campaigners, as with other social activism, is \\"Nothing About Us Without Us.\\"[9]\\r\\nThe social model of disability focuses on changes required in society. These might be in terms of:\\r\\nThe social model of disability implies that attempts to change, \\"fix\\" or \\"cure\\" individuals, especially when used against the wishes of the patient, can be discriminatory and prejudiced. This attitude, which may be seen as stemming from a medical model and a subjective value system, can harm the self-esteem and social inclusion of those constantly subjected to it (e.g. being told they are not as good or valuable, in an overall and core sense, as others). Some communities have actively resisted \\"treatments\\", while, for example, defending a unique culture or set of abilities. In the deaf community, sign language is valued even if most people do not know it and some parents argue against cochlear implants for deaf infants who cannot consent to them.[11] People diagnosed as being on the autism spectrum may argue against efforts to change them to be more like others. They argue instead for acceptance of neurodiversity and accommodation to different needs and goals.[12] Some people diagnosed with a mental disorder argue that they are just different and don't necessarily conform. The biopsychosocial model of disease/disability is a holistic attempt by practitioners to address this.[13]\\r\\nThe social model implies that practices such as eugenics are founded on social values and a prejudiced understanding of the potential and value of those labeled disabled. \\"Over 200,000 disabled people were the first victims of the Holocaust.\\"[14]\\r\\nA 1986 article stated: \\"It is important that we do not allow ourselves to be dismissed as if we all come under this one great metaphysical category 'the disabled'. The effect of this is a depersonalization, a sweeping dismissal of our individuality, and a denial of our right to be seen as people with our own uniqueness, rather than as the anonymous constituents of a category or group. These words that lump us all together -'the disabled', 'spina bifida', 'tetraplegic', 'muscular dystrophy, - are nothing more than terminological rubbish bins into which all the important things about us as people get thrown away.\\"[15]\\r\\nThe social model of disability is based on a distinction between the terms \\"impairment\\" and \\"disability.\\" Impairment is used to refer to the actual attributes (or lack of attributes), the abnormality, of a person, whether in terms of limbs, organs or mechanisms, including psychological. Disability is used to refer to the restrictions caused by society when it does not give equivalent attention and accommodation to the needs of individuals with impairments.[16]\\r\\nThe social model also relates to economics. It proposes that people can be disabled by a lack of resources to meet their needs. It addresses issues such as the under-estimation of the potential of people to contribute to society and add economic value to society, if given equal rights and equally suitable facilities and opportunities as others. Economic research on companies that attempt to accommodate disability in their workforce suggest they outperform competitors.[17]\\r\\nIn Autumn 2001, the UK Office for National Statistics identified that approximately one fifth of the working age population was disabled - 7.1 million disabled people as opposed to 29.8 million able people - and in this analysis also provided insight into some of the reasons why disabled people were unwilling to enter the labour market, such as that the reduction in disability benefits in entering the labour market would not make it worthwhile to enter into employment. A three-pronged approach was suggested: \\"incentives to work via the tax and benefit system, for example through the Disabled Persons Tax Credit; helping people back into work, for example via the New Deal for Disabled People; and tackling discrimination in the workplace via anti-discrimination policy. Underpinning this are the Disability Discrimination Act (DDA) 1995 and the Disability Rights Commission.\\"[18]\\r\\nIn the United Kingdom, the Disability Discrimination Act defines disability using the medical model - disabled people are defined as people with certain conditions, or certain limitations on their ability to carry out \\"normal day-to-day activities.\\" But the requirement of employers and service providers to make \\"reasonable adjustments\\" to their policies or practices, or physical aspects of their premises, follows the social model.[19] By making adjustments, employers and service providers are removing the barriers that disable - according to the social model, they are effectively removing the person's disability. In 2006, amendments to the act called for local authorities and others to actively promote disability equality. This enforcement came in the shape of the Disability Equality Duty in December 2006.[20] In 2010, The Disability Discrimination Act (1995) was amalgamated into the Equality Act 2010 along with other pertinent discrimination legislation. It extends the law on discrimination to indirect discrimination. For example, if a carer of a person with a disability is discriminated against, this is now also unlawful.[21] Since October 2010, when it came into effect, employers may not legally ask questions about illness or disability at interview for a job or for a referee to comment on such in a reference, except where there is a need to make reasonable adjustments for an interview to proceed. Following an offer of a job, an employer can lawfully ask such questions.[22]\\r\\nIn the United States, the Americans with Disabilities Act of 1990 (ADA), revision of 2008 effective in January 2009, is a wide-ranging civil rights law that prohibits discrimination based on disability.[23] It affords similar protections against discrimination to Americans with disabilities as the Civil Rights Act of 1964, which made discrimination based on race, religion, sex, national origin, and other characteristics illegal. Certain specific conditions are excluded, such as alcoholism and transsexualism.\\r\\nIn 2007, the European Court of Justice in the Chacon Navas v Eurest Colectividades SA court case, defined disability narrowly according to a medical definition that excluded temporary illness, when considering the Directive establishing a general framework for equal treatment in employment and occupation (Council Directive 2000/78/EC). The directive did not provide for any definition of disability, despite discourse in policy documents previously in the EU about endorsing the social model of disability. This allowed the Court of Justice to take a narrow medical definition.[citation needed]","input":"When was the social model of disability introduced?"},{"output":"presidential representative democratic republic","context":"The Politics of Indonesia take place in a framework of a presidential representative democratic republic, whereby the President of Indonesia is both head of state and head of government, and of a multi-party system. Executive power is exercised by the government. Legislative power is vested in both the government and the two People's Representative Councils. The judiciary is independent of the executive and the legislature.[1]\\r\\nThe 1945 constitution provided for a limited separation of executive, legislative and judicial power. The governmental system has been described as \\"presidential with parliamentary characteristics.\\"[2] Following the Indonesian riots of May 1998 and the resignation of President Suharto, several political reforms were set in motion via amendments to the Constitution of Indonesia, which resulted in changes to all branches of government. The Economist Intelligence Unit has rated Indonesia as \\"flawed democracy\\" in 2016.[3]\\r\\n\\r\\n\\r\\nAn era of Liberal Democracy (Indonesian: Demokrasi Liberal) in Indonesia began on August 17, 1950 following the dissolution of the federal United States of Indonesia less than a year after its formation, and ended with the imposition of martial law and President Sukarno's decree regarding the introduction of Guided Democracy on July 5, 1959. It saw a number of important events, including the 1955 Bandung Conference, Indonesia's first general and Constitutional Assembly elections, and an extended period of political instability, with no cabinet lasting as long as two years.\\r\\nGuided Democracy (Indonesian: Demokrasi Terpimpin) was the political system in place in Indonesia from 1957 until the New Order began in 1966. It was the brainchild of President Sukarno, and was an attempt to bring about political stability. Sukarno believed that Western-style democracy was inappropriate for Indonesia's situation. Instead, he sought a system based on the traditional village system of discussion and consensus, which occurred under the guidance of village elders.\\r\\nIndonesia's transition to the \\"New Order\\" in the mid-1960s, ousted the country's first president, Sukarno, after 22 years in the position. One of the most tumultuous periods in the country's modern history, it was the commencement of Suharto's 31-year presidency.\\r\\nDescribed as the great dhalang (\\"puppet master\\"), Sukarno drew power from balancing the opposing and increasingly antagonistic forces of the army and Indonesian Communist Party (PKI). By 1965, the PKI extensively penetrated all levels of government and gained influence at the expense of the army.[4]\\r\\nOn 30 September 1965, six of the military's most senior officers were killed in an action (generally labelled an \\"attempted coup\\") by the so-called 30 September Movement, a group from within the armed forces. Within a few hours, Major General Suharto mobilised forces under his command and took control of Jakarta. Anti-communists, initially following the army's lead, went on a violent purge of communists throughout the country, killing an estimated half million people and destroying the PKI, which was officially blamed for the crisis.[5][6]\\r\\nThe politically weakened Sukarno was forced to transfer key political and military powers to General Suharto, who had become head of the armed forces. In March 1967, the Indonesian parliament (MPRS) named General Suharto acting president. He was formally appointed president one year later. Sukarno lived under virtual house arrest until his death in 1970. In contrast to the stormy nationalism, revolutionary rhetoric, and economic failure that characterised the early 1960s under the left-leaning Sukarno, Suharto's pro-Western \\"New Order\\" stabilized the economy but continued the policies of Pancasila.\\r\\nThe New Order (Indonesian: Orde Baru) is the term coined by the second Indonesian President Suharto to characterise his regime as he came to power in 1966. Suharto used this term to contrast his rule with that of his predecessor, Sukarno (dubbed the \\"Old Order,\\" or Orde Lama). The term \\"New Order\\" in more recent times has become synonymous with the Suharto years (1966ÿ1998).\\r\\nImmediately following the attempted coup in 1965, the political situation was uncertain, but the Suharto's New Order found much popular support from groups wanting a separation from Indonesia's problems since its independence. The 'generation of 66' (Angkatan 66) epitomised talk of a new group of young leaders and new intellectual thought. Following Indonesia's communal and political conflicts, and its economic collapse and social breakdown of the late 1950s through to the mid-1960s, the \\"New Order\\" was committed to achieving and maintaining political order, economic development, and the removal of mass participation in the political process. The features of the \\"New Order\\" established from the late 1960s were thus a strong political role for the military, the bureaucratisation and corporatisation of political and societal organisations, and selective but effective repression of opponents. Strident anti-communism remained a hallmark of the regime for its subsequent 32 years.\\r\\nWithin a few years, however, many of its original allies had become indifferent or averse to the New Order, which comprised a military faction supported by a narrow civilian group. Among much of the pro-democracy movement which forced Suharto to resign in the 1998 Indonesian Revolution and then gained power, the term \\"New Order\\" has come to be used pejoratively. It is frequently employed to describe figures who were either tied to the Suharto period, or who upheld the practises of his authoritarian regime, such as corruption, collusion and nepotism (widely known by the acronym KKN: korupsi, kolusi, nepotisme).[7]\\r\\nThe Post-Suharto era in Indonesia began with the fall of Suharto in 1998 during which Indonesia has been in a period of transition, an era known in Indonesia as Reformasi (English: Reform[8][9][10]). A more open and liberal political-social environment ensued following the resignation of authoritarian President Suharto, ending the three decades of the New Order period.\\r\\nA constitutional reform process lasted from 1999 to 2002, with four constitutional amendments producing important changes.[11]\\r\\nAmong these are term limits of up to 2 five-year terms for the President and Vice-President, and measures to institute checks and balances. The highest state institution is the People's Consultative Assembly (MPR), whose functions previously included electing the president and vice-president (since 2004 the president has been elected directly by the people), establishing broad guidelines of state policy, and amending the constitution. The 695-member MPR includes all 550 members of the People's Representative Council (DPR) (the House of Representatives) plus 130 \\"regional representatives\\" elected by the twenty-six provincial parliaments and sixty-five appointed members from societal groups[12]\\r\\nThe DPR, which is the premier legislative institution, originally included 462 members elected through a mixed proportional/district representational system and thirty-eight appointed members of the armed forces (TNI) and police (POLRI). TNI/POLRI representation in the DPR and MPR ended in 2004. Societal group representation in the MPR was eliminated in 2004 through further constitutional change.[13][14]\\r\\nHaving served as rubberstamp bodies in the past, the DPR and MPR have gained considerable power and are increasingly assertive in oversight of the executive branch. Under constitutional changes in 2004, the MPR became a bicameral legislature, with the creation of the Dewan Perwakilan Daerah (DPD), in which each province is represented by four members, although its legislative powers are more limited than those of the DPR. Through his appointed cabinet, the president retains the authority to conduct the administration of the government.[15]\\r\\nA general election in June 1999 produced the first freely elected national, provincial and regional parliaments in over forty years. In October 1999 the MPR elected a compromise candidate, Abdurrahman Wahid, as the country's fourth president, and Megawati Sukarnoputri  a daughter of Sukarno, the country's first president  as the vice-president. Megawati's PDI-P party had won the largest share of the vote (34%) in the general election, while Golkar, the dominant party during the Soeharto era, came in second (22%). Several other, mostly Islamic parties won shares large enough to be seated in the DPR. Further democratic elections took place in 2004 and 2009.\\r\\nThe president and vice-president are selected by vote of the citizens for five-year terms. Prior to 2004, they were chosen by People's Consultative Assembly. The last election was held 9 July 2014. The president heads the Kabinet Kerja which means the cabinet of work. The President of Indonesia is directly elected for a maximum of two five-year terms, and is the head of state, commander-in-chief of Indonesian armed forces and responsible for domestic governance and policy-making and foreign affairs. The president appoints a cabinet, who do not have to be elected members of the legislature.[16]\\r\\nThe People's Consultative Assembly (Indonesian: Majelis Permusyawaratan Rakyat, MPR) is the legislative branch in Indonesia's political system. Following elections in 2004, the MPR became a bicameral parliament, with the creation of the DPD as its second chamber in an effort to increase regional representation.[17]\\r\\nThe Regional Representatives Council (Indonesian: Dewan Perwakilan Daerah, DPD) is the upper house of The People's Consultative Assembly. The lower house is The People's Representative Council (Indonesian: Dewan Perwakilan Rakyat, DPR), sometimes referred to as the House of Representatives, which has 560 members, elected for a five-year term by proportional representation in multi-member constituencies.\\r\\nThe General Elections Commission (Indonesian: Komisi Pemilihan Umum, KPU ) is the body responsible for running both parliamentary and presidential elections in Indonesia. Article 22E(5) of the Constitution rules that the Commission is national, permanent, and independent. Prior to the General Election of 2004, KPU was made up of members who were also members of political parties. However, members of KPU must now be non-partisan.\\r\\nNote: 1. Results are pending to appeals made in the Constitutional Court.\\r\\n2. Aceh local parties only contested for the regional legislative assemblies, not the DPR. Results are included here for completeness. The remainder of the votes were won by national parties.\\r\\nThe Indonesian Supreme Court (Indonesian: Mahkamah Agung) is the highest level of the judicial branch. Its judges are appointed by the president. The Constitutional Court (Indonesian: Mahkamah Konstitusi) rules on constitutional and political matters , while a Judicial Commission (Indonesian: Komisi Yudisial) oversees the judges.[24]\\r\\nDuring the regime of president Suharto, Indonesia built strong relations with the United States and had difficult relations with the People's Republic of China owing to Indonesia's anti-communist policies and domestic tensions with the Chinese community. It received international denunciation for its annexation of East Timor in 1978. Indonesia is a founding member of the Association of South East Asian Nations, and thereby a member of both ASEAN+3 and the East Asia Summit.\\r\\nSince the 1980s, Indonesia has worked to develop close political and economic ties between South East Asian nations, and is also influential in the Organisation of Islamic Cooperation. Indonesia was heavily criticised between 1975 and 1999 for allegedly suppressing human rights in East Timor, and for supporting violence against the East Timorese following the latter's secession and independence in 1999. Since 2001, the government of Indonesia has co-operated with the US in cracking down on Islamic fundamentalism and terrorist groups.","input":"What is the system of government in indonesia?"},{"output":"much less stable","context":"A minority government, or minority cabinet or minority parliament, is a cabinet formed in a parliamentary system when a political party or coalition of parties does not have a majority of overall seats in the parliament. It is sworn into office, with or without the formal support of other parties, to enable a government to be formed. Under such a government, legislation can only be passed with the support of enough other members of the legislature to provide a majority, encouraging multi-partisanship. In bicameral parliaments, the term relates to the situation in chamber whose confidence is considered most crucial to the continuance in office of the government.\\r\\nA minority government tends to be much less stable than a majority government because, if they can unite for the purpose, opposing parliamentary members have the numbers to vote against legislation, or even bring down the government with a vote of no confidence.\\r\\n\\r\\n\\r\\nTo deal with situations in parliamentary systems where no clear majority to support a government exists, two or more parties may establish a formal coalition government, commanding a clear majority of the parliamentary members, or a party might enter into less formal alliances or agreements with other parties, or individual members, to allow the minority government to stay in office.\\r\\nA common situation is governance with \\"jumping majorities\\": the cabinet stays as long as it can negotiate support from a majority in the parliament, even though that majority may be differently formed from issue to issue or from bill to bill. On occasion the legislature may permit a minority cabinet to continue in office despite having been defeated on a given vote, and a minority government might even bring on a confidence vote and threaten to resign should the legislature vote against it.\\r\\nAn alternative arrangement is a looser alliance of parties, exemplified by Sweden. There the long-governing Social Democrats have ruled with more or less formal support from other parties ÿ in the mid-20th century from Agrarians, after 1968 from Communists, and more recently from Greens and ex-Communists ÿ and have thus been able to retain executive power and (in practice) legislative initiative. This is also common in Canada, where nine elections from 1921 to 2005 effectively produced minority federal governments. The parties can rarely cooperate enough to establish a formal coalition, but operate under a loose agreement instead.\\r\\nOccasionally a confidence and supply agreement may be formed. This is a more formal pact which still falls short of creating a coalition government. In the Canadian province of Ontario, the Liberal Party formed a minority government from 1985 to 1987 on the basis of a formal accord with the New Democratic Party (NDP): the NDP agreed to support the Liberals for two years on all confidence motions and budgetary legislation, in exchange for the passage of certain legislative measures proposed by the NDP. This was not a formal coalition, because the NDP remained an opposition party and was not given seats in the cabinet. In this case the Liberals did not even have a plurality of seats: the Progressive Conservatives were the largest single party with 52 seats, but the Liberals had 48 and the NDP had 25.\\r\\nNew Zealand's 48th Parliament operated with both a coalition and a looser agreement: the government was a coalition between the Labour Party and the Progressives, while United Future and New Zealand First had an agreement to support the government on confidence matters, while the Green Party abstained.\\r\\nIn most Westminster system nations, each constituency elects one member of parliament by simple plurality voting. This system heavily biases the vote towards increasing the number of seats of the top two parties and reducing the seats of smaller parties, a principle known in political science as Duverger's law, and thus minority governments are relatively uncommon. Advocates of this system see this as one of its advantages. A party with less than 40% of the popular vote can often win an outright majority of the seats. (For instance, in the 2005 UK General Election, the governing Labour party won by a majority of 66 seats in the House of Commons with only 35.2% of the popular vote.) If support for some parties is regionally concentrated, however, then Duverger's law applies separately to each region, and so it is quite possible for no party to be sufficiently dominant in each region so as to receive a majority of the seats. This was the situation in Canada in the 2004, 2006, and 2008 federal elections, with no party obtaining a majority due in part to the dominance of the Bloc Qubcois in the province of Quebec.\\r\\nIn Westminster systems, in minority situations, the incumbent government usually has the first opportunity to attempt to win the confidence of the House. This is so even if the incumbents have fewer seats ÿ the incumbent prime minister still holds his or her commission for the duration of the writ period and immediately following an election. If (s)he cannot form a government that commands the confidence of the House then it is expected that (s)he will resign that commission voluntarily ÿ it is not considered acceptable for the Sovereign (or her representative) to revoke said commission unless the prime minister was acting in serious breach of constitutional protocol. Nevertheless, usually an incumbent government that loses its plurality in the House simply resigns, especially if the main opposition party is only a few seats short of having a majority or if it feels it has no chance of winning the support of enough members of smaller parties to win an initial confidence vote.\\r\\nNevertheless, the now-common practice of the party with the most seats forming the government has led to a widespread misconception among voters that a convention exists whereby the party with the most seats always gets to form the government. In fact, the most compelling reason for this practice is that the party with the most seats can survive confidence votes so long as the smaller party (or parties) simply abstain from confidence votes, whereas a governing party without a plurality in the House needs at least one other party to vote with it at all times (assuming the largest party will always vote no confidence, but that is almost certain to occur when they are denied the opportunity to govern). This means that in most situations, the party with the most seats has the best chance and the least complicated route to winning a confidence vote, regardless of its place on the political spectrum. At the Canadian federal level, in the four most recent of the five occasions a governing party lost the plurality without another winning a majority (1957, 1963, 1979, and 2006) the incumbent governments resigned rather than attempt to stay in power.\\r\\nWhatever party forms the government must either form a coalition with one or more other parties, or they must win some form of support from the other parties or independents so as to avoid no-confidence motions. Because of no-confidence motions, minority governments are frequently short-lived or fall before their term is expired. The leader of a minority government will also often call an election in hopes of winning a stronger mandate from the electorate. In Canada, for instance, federal minority governments last an average of 18 months.\\r\\nThere have been few occasions since 1900 when a single party has not commanded a parliamentary majority. The 2010-2015 Conservative/Liberal Democrat coalition government was the first of its type in Britain since the National Government between 1931 and 1945.\\r\\nThe Labour Party, led by Harold Wilson, formed a minority government for seven months after the General Election of February 1974. That situation lasted until the prime minister called another election in October that year, following which the Labour Government obtained a tiny majority of three.[1]\\r\\nThe following administration also became a minority government after the collapse of the LibÿLab pact in 1977, and the then British Prime Minister James Callaghan's Government fell in March 1979 as the result of a vote of no confidence which was carried by a single vote.\\r\\nA minority Government held power in the UK between December 1996 and the general election in May 1997. The Conservative Party, led by John Major, had won the 1992 General Election with an absolute majority of 21 seats over all other parties. That majority was progressively whittled away through defections and by-elections defeats, the most notable of the latter including those in Newbury, South East Staffordshire and Wirral South, resulting in the eventual loss of the Major government's majority in Parliament.\\r\\nWestminster and the British media tend to perceive minority governments as unstable and ineffective, possibly because recent examples of minority governments (Callaghan and Major) occurred as the result of governments in decline.[2]\\r\\nIn the 2010 General Election, the Conservatives won the most seats and votes, but only a minority of seats in parliament. There was some discussion after the election of the possibility of creating a Conservative minority government and, because the then Prime Minister Gordon Brown had the first opportunity to form a government, there were also talks about creating some sort of alliance between the Labour Party, the Liberal Democrats and other smaller parties. However Brown waived his right, acknowledging that because the Conservative Party had won the largest number of seats in the House of Commons, it should have the first opportunity to form a government. Further discussions then led to the establishment of a formal coalition between the Conservatives and the Liberal Democrats, which enabled the formation of a majority government, because it was thought that would ensure more stability.\\r\\nIn the 2017 General Election, the Conservatives won the most seats and votes, but lost their majority in the House of Commons. The Conservative Party, led by Theresa May, formed a minority government, with 317 seats, on 9 June 2017. On 10 June, the Prime Minister's Office announced a deal with the Democratic Unionist Party which would see the DUP support the Conservative government on a confidence and supply arrangement.[3] However, the DUP later announced that no such deal had been reached.[4] This remained the case until 26 June 2017, when a deal was agreed and announced between the two parties.[5]\\r\\nAfter the 2007 parliamentary elections, the Scottish National Party led by Alex Salmond constituted a minority government in the Scottish Parliament. This was because the SNP gained 47 seats out of 129 in the election, which was some way short of achieving an absolute majority of seats in the Scottish Parliament, but more than any other single party gained. The SNP were unable to negotiate a majority coalition government with any other party, but as no other combination of parties were able to agree a deal, the SNP chose to form a one-party minority government, with confidence and supply support from the Scottish Green Party and the Scottish Conservative Party.\\r\\nAfter the 2007 Assembly elections, the Welsh Labour Party led by Rhodri Morgan initially formed a minority government in the Welsh Assembly. This was because they gained 26 seats in the election, which was short of an absolute majority of seats in the Assembly. Whilst Labour were initially unable to form a coalition with the Liberal Democrats, a 'Rainbow Coalition' of the Conservative Party (UK), Liberal Democrats and Plaid Cymru failed to come to fruition. However, on 6 July 2007, Welsh Labour Party members voted for a coalition with Plaid, which was followed by a similar result from Plaid Cymru members the next day. As a result, the Welsh Assembly was controlled by the Labour-Plaid alliance with Rhodri Morgan as First Minister (up until his retirement in 2009 and subsequent replacement by Carwyn Jones as First Minister) and Plaid Leader Ieuan Wyn Jones as his deputy. After the 2011 Welsh General Election, Welsh Labour won 30 seats and entered into a new government, with a minority of 0. In 2016 Welsh Labour returned with 29 seats out of 30 and formed a minority government of 0 with the one remaining Liberal Democrat AM.\\r\\nDuring the history of Canadian politics there have been twelve minority governments on the federal level, in eleven separate minority parliaments (there were two minority governments during the life of 15th Parliament). One of these minorities, the 14th Parliament, was only a minority for half of its duration owing to floor-crossings and by-elections. The tenth and eleventh were elected twice in Canadian federal elections of 2005/2006 and again in the 2008 election. There have also been numerous minority governments in provincial legislatures, particularly in provinces such as Ontario where there are strong third parties.\\r\\nAt the federal level, the party which has won the most seats in a general election has formed the government in all but the 15th Parliament.[6] There have also been instances of parties which did not win a plurality forming the government at the provincial level (notably under David Peterson). For information about minority governments at both the federal and provincial levels see Minority governments in Canada.\\r\\nCoalitions in the Netherlands are formed with the support from parliamentary parties, elected by proportional representation. Although very rare, minority governments can be formed during the formation period of a Dutch cabinet, if an election result makes a majority coalition impossible. More often, a minority government is formed when one of the cabinet's coalition partners withdraws its support, or when all ministers of a given parliamentary party resign. In these cases, the Prime Minister offers the full cabinet's resignation to the Dutch Monarch.\\r\\nAt this point, the Monarch may choose to dissolve Parliament and hold a general election. The cabinet continues to serve as demissionary. A demissionary cabinet is not a minority government but a form of caretaker government, enjoying only limited powers until the new Parliament assembles.\\r\\nIf the Monarch does not dissolve Parliament, the remaining cabinet continues as a minority cabinet, in full possession of its powers. It can finish any legislation already before underpreparation, if Parliament passes it by majority vote; this necessitates the support of parties outside the government. Theoretically, early general elections need not be held, but they are often necessary in practice, since the coalition agreement no longer has parliamentary support.\\r\\nA third option is available to the Monarch: the formation of a new cabinet of different Parliamentary parties (which may include the defecting coalition partner). Elections are then held as scheduled at the end of the parliamentary term, since the Monarch does not dissolve parliament if an informateur has been able to negotiate a new coalition agreement.\\r\\nThe Netherlands had a minority government in 2010-2012: the First Rutte cabinet. The Second Rutte cabinet (2012-) consists of the conservative liberal VVD and the social-democratic PvdA and has a clear majority in the House of Representatives, but none in the Senate. On 11 October 2013, the cabinet reached a budgetary agreement with the social-liberal D66 and the smaller Christian parties ChristenUnie and SGP. This provides the VVD/PvdA cabinet a single-seat majority in the Senate (see also: Purple (government)).\\r\\nThe Irish parliamentary system broadly works on a simple majority system, where the Taoiseach is elected by the Dil when they achieve 50% + 1 of the votes in favour of their nomination. The Taoiseach then appoints his or her own cabinet. Until the 1980s, Irish politics was dominated by two parties, either of whom could achieve a simple majority of seats in the Dil and therefore elect their party leader as Taoiseach. Since the 1980s, the popularity of other parties has increased such that coalition governments are now typical and expected, with one of the two major parties being the \\"Senior\\" partner, and with one or more \\"Junior\\" partners ensuring that the coalition retains a majority in the Dil.\\r\\nA minority government is formed when a party (or a coalition) secures agreement from one or more other parties or independents to support their nomination for Taoiseach and achieve majority support, but without any formal coalition agreement with the parties who supported the nomination. Support for bills and other items requiring a Dil majority vote is then negotiated on a bill-by-bill basis.\\r\\nIn the event that no agreement can be reached to nominate an individual to lead a minority government, the previous Taoiseach (acting in a caretaker capacity) can then seek dissolution of the Dil and call a new general election. However, this scenario has not yet occurred.\\r\\nThe last Dil with a single-party simple majority government was in 1977. Minority governments have been relatively common in the short history of the Dil, making up 14 of the 32 governments (44%) formed since the Dil was founded.\\r\\nThe period of 1987-2016 (29 years) is the longest that there has not been a minority government in charge.","input":"What is the difference between minority and majority government?"},{"output":"Jersey Shore","context":"\\r\\n\\r\\nGeordie Shore is a British reality television series broadcast on MTV and based in Newcastle upon Tyne, England. It was first broadcast on 24 May 2011, and is the British version of the American show Jersey Shore.[1][2][3]\\r\\n\\r\\nThe show follows the daily lives of 8-12 housemates, depending on the series, as they live together for a number of weeks.[4] In the first series, the house was located in Jesmond, a suburb of Newcastle. Since the second series, the show has used a house in the Ocean Business Park in Wallsend.[5]\\r\\n\\r\\nThe first series of the show began airing on 24 May 2011 and concluded on 28 June 2011, consisting of six  episodes. It was then followed by a reunion show hosted by Russell Kane where the cast discussed the series in front of an audience. This episode aired on 5 July 2011, and was followed by a Best Bits special which counted down the best moments from the first series in an episode airing 12 July 2011. The series included the turbulent relationship of Holly (who entered the house three days late) and Dan coming to an end,[6] the beginning of Gaz and Charlotte's ongoing love/hate relationship, and Jay and Vicky's rocky relationship.[7] In June 2011, two summer specials based in Magaluf were announced.[8][9][10] These episodes aired from 23 August 2011 to 30 August 2011. This was the only series to feature Greg Lake.[11]\\r\\n\\r\\nThe second series of the show began airing on 31 January 2012 and concluded on 20 March 2012, consisting of eight episodes.[12] Like the first series, this series included a reunion special and a Best Bits special episode. The series was confirmed on 15 August 2011 when Geordie Shore was recommissioned for a second series with an extended eight-episode run.[13] After the Magaluf specials, Greg Lake announced he leaving the show. Rebecca Walker and Ricci Guarnaccio were cast as replacements. The series featured Sophie and Joel's rocky relationship coming to an end, Vicky being torn between her boyfriend Dan and new cast member Ricci,[14] Charlotte admitting she'd finally had enough of seeing Gaz with other girls,[15] and the beginning of Holly and James.[16] For series two the cast moved from their home in Jesmond to a new house in a converted warehouse on the outskirts of the city.\\r\\n\\r\\nThe third series of the show began airing on 26 June 2012 and concluded on 14 August 2012, consisting of eight episodes. After the run of episodes, two Best Bits episodes aired counting down the series' top 10 moments.[17] Series 3 began filming in early March and aired on MTV in June, it was later confirmed by cast member Gary Beadle via Twitter.[18] The series is therefore also known as Chaos in Cancun. This is the last series to include cast members Rebecca Walker and Jay Gardner, who both departed during the final episode. This series featured Vicky and Ricci's relationship on the rocks before they finally got engaged,[19] Holly and James growing closer when James broke his leg,[20][21] and more bickering and flirting between Gaz and Charlotte.\\r\\n\\r\\nThe fourth series of the show began airing on 6 November 2012 and concluded on 18 December 2012, consisting of eight episodes. For the first time this series there was no special episodes counting down the best bits. This was the first series to feature new cast members Daniel Thomas-Tuck and Scott Timlin.[22][23][24] The series included Vicky and Ricci's ongoing arguments continuing to the point of the engagement being temporarily called off,[25][26] James leaving Holly distraught by the announcement of him having a girlfriend,[27][28] and a huge bust-up between Vicky and Sophie which had the whole house divided.[29] During the series, on 11 November 2012, the cast made guest appearances during the 2012 MTV Europe Music Awards where they presented the award for Best Male, which Justin Bieber won.[30]\\r\\n\\r\\nThe fifth series of the show began airing on 19 February 2013 and concluded on 16 April 2013, consisting of eight episodes. The series was followed by another Best Bits episode airing 16 April 2013. The series was confirmed on 10 January 2013 when MTV announced that the fifth series of Geordie Shore would follow the cast in several locations across Europe including Amsterdam, Barcelona, Prague and Tignes.[31] Filming for Series 5 began on 14 November 2012, as confirmed by several cast members on Twitter,[32][33][34][35] and concluded in December. This was the final series to include cast members Daniel Thomas-Tuck and Ricci.\\r\\n\\r\\nThe sixth series of the show began airing on 9 July 2013 and concluded on 27 August 2013, consisting of eight episodes. The series was officially announced on 25 February 2013 when it was revealed the series would be located in Sydney and would air in summer 2013.[36][37] Filming for this series began on 2 April as confirmed by cast member Gaz on Twitter.[38] However, Charlotte was absent from the beginning of filming and joined the remaining cast on 7 April.[39][40][41] The series featured a one off return of former cast member Jay Gardner. During the series, Charlotte entered the Celebrity Big Brother house to compete in the twelfth series of the show and eventually won on 14 September 2013.\\r\\n\\r\\nThe seventh series of the show began airing on 17 September 2013 and concluded on 22 October 2013, consisting of six episodes. Shooting was suspended when Holly and Vicky were both arrested on a night out for assault during filming.[42] On 12 July 2013, Sophie was axed from the show after exhibiting offensive behaviour on the night when Holly and Vicky were arrested.[43] Holly Hagan was cleared on 21 August 2013.[44] Marnie Simpson, the cousin of Sophie, joined the show for this season. Jay Gardner also made another one off return during this series. After the series, on 15 December 2013, in a bid to reach Christmas number one, Gaz released his debut single which features vocals from The Risk, who previously featured in the eighth series of The X Factor.[45]\\r\\n\\r\\nThe eighth series of the show began airing on 22 July 2014 and concluded on 9 September 2014, consisting of eight episodes. The series was confirmed on 22 October 2013 when Holly indicated that Series 7 was not the last and that another series would be filmed.[46][47] Filming began for the series on 25 March 2014,[48][49][50] and featured two new cast members, Aaron Chalmers and Kyle Christie.[51] During the series, Ricci entered the Celebrity Big Brother house to participate in the fourteenth series. He followed in the footsteps of fellow cast member Charlotte who won the series in 2013. However he was evicted in a double eviction just two days before the final on 10 September. Ahead of the series, in 2014, Charlotte landed her own TV series, which aired on TLC.[52] It was also revealed that had Vicky joined the cast of Ex on the Beach. She was later joined by fellow Geordie Shore cast member Ricci as well as Australian fling Dan Conn who briefly appeared in the sixth series of the show.[53]\\r\\n\\r\\nThe ninth series of the show began airing on 28 October 2014 and concluded on 16 December 2014, consisting of eight episodes. On 15 May 2014, Gaz confirmed that the ninth series would be filmed in July/August 2014 and hinted at it being abroad.[54] However the series remained in Newcastle. A new trailer confirmed that Vicky would be in charge, taking the role of 'Queen V' upon its return. On 28 October 2014, ahead of the Series 9 premiere, Vicky announced that this series would be her last.[55]\\r\\n\\r\\nThe tenth series of the show began airing on 7 April 2015 and concluded on 26 May 2015, consisting of eight episodes. The series of the show was also confirmed on 1 November 2014 when it was revealed by Gary Beadle that filming had commenced. On 17 November 2014, MTV announced the tenth series would be James' last series.[56] The tenth series added two new cast members, Chloe Ferry and Nathan Henry.[57]\\r\\n\\r\\nThe eleventh series was announced on 23 May 2015 when MTV renewed the series for a further three series.[58] The show began on 20 October 2015 and concluded on 22 December 2015. This was the first series not to include original cast member James Tindale after he departed at the start of the previous series. \\r\\n\\r\\nSeries 11 was shot in Greece.[59] At 10 episodes, it was the longest season to date. Cast member Kyle Christie departed the series after four seasons. The cast had traveled to Zante, Malia, Ios, Santorini, Mykonos, and Athens for the series.[60]\\r\\n\\r\\nSeries 12 was filmed in October and November 2015 and began airing on 15 March 2016.[61] It was the first series to include new cast members Chantelle Connelly and Marty McKenna, who had previously appeared on the third series of Ex on the Beach.[62] Marnie Simpson would also rejoin for the twelfth series having left at the end of the previous series.\\r\\n\\r\\nOn 12 February 2016, MTV announced that cast members, past and present, would be reuniting for a mini-series to celebrate five years of the show.[63] The series would be a six-part special and would begin on 10 May 2016. All of the current cast members would return, as well as former cast members Daniel Thomas-Tuck, James Tindale, Jay Gardner, Kyle Christie, Ricci Guarnaccio, and Sophie Kasaei. The series also featured the show's 100th episode. \\r\\n\\r\\nOn 1 June 2016, original cast member Charlotte Crosby quit the show, making the Birthday Battle her final series.[64]\\r\\n\\r\\nSeries 13 was shot in June and July 2016 and began on 25 October 2016. This series featured the return of former cast members Sophie Kasaei and Kyle Christie, who previously made a brief return during the Big Birthday Battle anniversary series.[65] This series was filmed on various party islands including Kavos, Ibiza and Magaluf.[66] On 24 June 2016, it was reported that Chantelle Connelly had quit the show halfway through filming, resulting in this series being her final one.[67] On 27 September 2016, the previous reports were confirmed with the announcement that Chantelle Connelly had quit the show mid-series. It was also later announced that this would be Holly Hagan's last series after she quit in the series finale, along with Kyle Christie.[68]\\r\\n\\r\\nThe fourteenth series was confirmed on 31 October 2016 when Scotty T announced that he would be taking a break from the series to focus on other commitments. The series was filmed in November 2016, and began airing on 28 March 2017. Ahead of the series, it was also confirmed that original cast member Holly had quit the show, following her exit in the previous series.[69][70]\\r\\n\\r\\nEight new cast members joined for this series: Zahida Allen, Chelsea Barber, Sam Bentham, Sarah Goodhart, Abbie Holborn, Elettra Lamborghini, Billy Phillips and Eve Shannon.[71] Goodhart and Allen both previously appeared on Ex on the Beach, with the former appearing on the third series of the show as the ex-girlfriend of current cast member Marty (before he joined the cast). Lamborghini has also appeared on Super Shore and participated in the fifth season of Gran Hermano VIP, the Spanish version of Celebrity Big Brother.\\r\\n\\r\\nThe fifteenth series was confirmed on 8 August 2017 when a teaser video was released. The series began on 29 August 2017,[72] and concluded after nine episodes on 17 October 2017.[73] This was the final series to include Scotty T and Marty McKenna after they were both axed from the show,[74] as well as original cast member Gaz Beadle following his decision to quit.[75] The series also featured the brief return of Elettra Lamborghini, when the cast jetted off to Rome.[76] It also features Aaron taking part in his debut MMA fight in Birmingham.[77] Former cast member James Tindale made a one-off return during the eighth episode of the series.[78]\\r\\n\\r\\nThe sixteenth series was filmed in September 2017 and began on 9 January 2018,[79] and concluded after ten episodes on 13 March 2018. This is the first series not to include original cast member Gaz Beadle after he quit the show for personal reasons.[80] New cast members for this series include Sam Gowland,[81] who had previously appeared on the third series of Love Island, as well as Steph Snowdon.[82] However it was later revealed that Steph had been axed from the show and would therefore not return for the seventeenth series.[83] During this series, cast members Aaron Chalmers and Marnie Simpson both announced that they'd quit the show - therefore this was their final series.[84][85]\\r\\n\\r\\nThe seventeenth series of the show was filmed in February 2018 and began on 15 May 2018.[86] The series was filmed in Australia rather than Newcastle, making this the second series to be filmed here following the sixth series in 2013.[87] Former cast member Holly Hagan returned to the show in this series. \\r\\n\\r\\nSix new cast members joined the series: Grant Molloy, Adam Guthrie, and four Australians: Alexander MacPherson, Nick Murdoch, Dee Nguyen, and Chrysten Zenoni.[88][89]\\r\\n\\r\\nThe eighteenth series of the show was filmed in July 2018 and is expected to begin later in the year.[90] This will be the first series to include new cast member Faith Mullen.[91] Original cast member James Tindale is reportedly returning to the series.[92]\\r\\n\\r\\nIn a column for Metro, Christopher Hooton described the show as \\"a gaudy kaleidoscope of six packs, shots, fights, simulated fellatio and exposed breasts,\\" but said that criticism of the show was futile given its intent, noting that \\"being shocked by the lasciviousness of Geordie Shore is like being shocked by the lack of nutrition in a Pot Noodle.\\"[93] Newcastle Central MP Chi Onwurah has described the show as \\"bordering on pornographic\\", and announced she will be raising questions in Parliament about the issues raised by the programme.[94] Newcastle has also benefited from the show by increased tourism. Hotels and travel agents have attributed increased bookings, up by as much as three of four times in 2012 from 2011, to the popularity of the program.[95]\\r\\n\\r\\nSeries 12 features the most watched episode to date, watched by 1,367,000, the show's peak viewership.[96] Series 12 was the most watched series on average with 1,237,000 viewers per week.\\r\\n\\r\\nSeries 15 has the lowest average viewers to date, averaging at 553,000 with the series finale being watched by just 371,000.[97]\\r\\n\\r\\nIn December 2013, Gaz released his debut single \\"Party Like a Rockstar (Up Your Game)\\" in a bid to reach Christmas number one. Vocals from the track come from Australian recording artist Emily Williams and The X Factor series eight finalists The Risk.[98] Vicky also appears in the music video.[45]\\r\\n\\r\\nIn August 2014, Holly released her debut single, a cover version of Milkshake, which was previously released in 2003 by Kelis and charted at number 2 in the UK.[99]\\r\\n\\r\\nIn February 2018, Elettra Lamborghini who was featured in series 14 & 15, released her debut single Pem Pem.[100]\\r\\n\\r\\nThe uncensored episodes are available to buy on the UK iTunes Store the day after episodes are aired.[101]\\r\\n\\r\\nGeordie Shore premiered in Canada in 2011 on MTV Canada.[102] In Australia the programme began airing in 2011 on MTV Australia.[103] In September 2011, the show was bought by Network Ten and now broadcasts the series on its digital channel Eleven also in Australia, this concluded in 2013. In 2012 it began airing in New Zealand on MTV (New Zealand). The United States premiere was in 2012 on MTV.[104]","input":"What was first jersey shore or geordie shore?"},{"output":"Alejandro Javier Garca Padilla","context":"Alejandro Javier Garca Padilla (Spanish:?[ale?xand?o ?ar?si.a]; born August 3, 1971) is a Puerto Rican politician and attorney who served as the 11th Governor of Puerto Rico from 2013 to 2017. Prior to this position, Garca Padilla held various roles in the political landscape of Puerto Rico; first as Secretary of Consumer Affairs, and then as a member of the 24th Senate of Puerto Rico and as president of the Popular Democratic Party.[1] Locally, he is a staunch advocate for maintaining the current political status of Puerto Rico as that of an unincorporated territory of the United States with self-government, while at the national level he is allied with the Democratic Party.[2]\\r\\nAs governor, Garca Padilla shared his legislative powers with the 25th Senate and 29th House of Representatives, both controlled by his party.[3] Regardless of this, he was not able to persuade several members of his own party to support his proposals. This failure, in addition to his low popularity, ultimately led him to not seek re-election thus becoming the second governor in Puerto Rican history to not do so after his first term.[a]\\r\\n\\r\\n\\r\\nGarca Padilla was born on 3 August 1971 in Coamo, Puerto Rico to Luis Gerardo Garca Snchez (1927-2005) and Mara de los ngeles Padilla Passalacqua and is the youngest of six brothers including Juan Carlos and Antonio.[4] His father Luis, a World War II veteran, held various jobs throughout his life to support his family, including machinery operator, and returned from the war to become a general manager of a manufacturing company. His mother has been a dedicated homemaker.[1] He is of paternal Asturian descent with his grandfather Carlos Garcia Cadorniga born 1890 in Navia, Asturias, Spain who settled in Ponce.[5][6][7] He also has Corsican lineage from his maternal great-great grandfather.[8]\\r\\nGarca Padilla was raised in Barrio Cuy܇n in his hometown. He attended the Colegio Valvanera High School. After graduating, he obtained his bachelor's degree in Political Science and Economics from the University of Puerto Rico, and a juris doctor from the Interamerican University of Puerto Rico School of Law.[9] Garca Padilla is the first and only governor to be entirely educated in Puerto Rico, and the first and only governor who has resided only in Puerto Rico during his entire life.[b] He is also the first and only governor born in a rural municipality.[b]\\r\\nGarca Padilla began his law career working at Puerto Rico's Court of Appeals as a law clerk. He then worked as an attorney, specializing in Property, Estates, Contracts, and Administrative Law. He also worked as a law professor at the Interamerican University.[9] He later served as a legislative aide for the committees on Internal Affairs, Women's Affairs, and Agriculture, among others. He was a member of the board of the Puerto Rico Bar Association.[11]\\r\\nIn January 2005, Garca Padilla was confirmed as Secretary of the Puerto Rico Department of Consumer Affairs under the administration of Anbal Acevedo Vil. During his tenure at the agency, he was known for his credibility, accessibility and aggressive fiscalization.[12][13] In 2007, Garca Padilla resigned his position as Secretary and announced that he would run for Senator.\\r\\nIn the 2008 general elections, he received the highest number of votes among all senatorial candidates.[14] After the election, he was selected by Jos Dalmau Santiago, Senate Minority Leader, to serve as the ranking member on several committees, including Governmental Affairs, Public Safety, and Judicial Affairs.\\r\\nOn 6 March 2011, Garca Padilla announced his plans to run for Governor of Puerto Rico in 2012.[15] He also announced his candidacy for President of the Popular Democratic Party, running unopposed, and took office on 4 April 2011.[16] On 26 October 2011 he named Rafael Cox Alomar as his running mate for Resident Commissioner (who went on to lose the election by a 1.28% margin),[17] replacing Hctor Ferrer Ros, who withdrew from the congressional race in order to run as the PPD's candidate for Mayor of San Juan.[18]\\r\\nAfter the 2012 gubernatorial elections of 6 November 2012, Garca Padilla was elected as the next Governor of Puerto Rico, by a narrow (0.6%) margin, defeating incumbent Luis Fortu?o 47.73% to 47.13%.[19][20]\\r\\nPuerto Rican law requires that a formal process is followed when the government must transition from one Governor to another. As such, Garca Padilla formed the 2012 Incoming Committee on Government Transition composed of aides and advisors who would eventually become part of his Cabinet.\\r\\nGarca Padilla was officially inaugurated as the 11th Governor of Puerto Rico on 2 January 2013 by Federico Hernndez Denton, Chief Justice of the Supreme Court of Puerto Rico, at an event held in the Puerto Rico Capitol.[21] He will serve as governor concurrently with the 16th Cabinet of Puerto Rico and in parallel with the 17th Legislative Assembly of Puerto Rico, the 25th Senate of Puerto Rico, and the 29th House of Representatives of Puerto Rico.\\r\\nGarca Padilla formed a cabinet composed of former aides and members of the private sector to form the 16th Cabinet of Puerto Rico. He holds office in parallel with the 17th Legislative Assembly of Puerto Rico, the 25th Senate of Puerto Rico, and the 29th House of Representatives of Puerto Rico. His primary challenge will be taking a government with a large indebtness and high deficit.[22] His first executive orders were proclaimed on 3 January 2013, one day after being sworn in.[23] One of them activated the Puerto Rico National Guard to monitor Puerto Rico's coasts and ports in order to reduce illegal immigration and the flow of illegal goods into the island, while another established that the Puerto Rico Chief of Staff must be consulted before making any appointments to empty seats, issuing contracts or amending existing contracts.[23] The third executive order was proclaimed to control spending in agencies with credit cards, phones, escorts, official cars, overseas travel, and cell phones and personal digital assistants.[23]\\r\\nOn 30 June 2013, Garca Padilla signed the Redistribution and Tax Charge Adjustment Act of 2013 (Act No. 40 of 2013) reducing the portion of the Puerto Rico Sales and Use Tax that municipalities charge from a 1.5% to 1.0%effectively lowering the total sales tax from 7.0% to 6.5%. However, this change has not yet been reflected, and the sales tax rate of 7.0% remains. The Act also expanded the use tax to include more services, including business-to-business sales and services like consulting.[24] Under his administration, a new tax of 4 cents per liter was imposed on gasoline.[25]\\r\\nAs part of his economic policies, Garca Padilla launched an austerity programme, raising taxes by 1.1% of the gross national product (GNP) and making public employees pension schemes less generous.[c] These measures are expected to trim the government deficit from $2.2 billion to $800 million.[c] This, according to The Economist, has made 62% of Puerto Ricans disapprove of Garca Padilla.[c]\\r\\nOn June 28, 2014, Governor Garca Padilla signed into law the Puerto Rico Public Corporation Debt Enforcement and Recovery Act, which sought to allow corporations owned by the Commonwealth, such as the Puerto Rico Electric Power Authority, the Puerto Rico Aqueducts and Sewers Authority, and the Puerto Rico Highways and Transportation Authority to declare bankruptcy.[27] However, in February 2015, U.S. District Judge Francisco Besosa found the Act was void because it was preempted by the U.S. Bankruptcy Code.[28] In July 2015, that ruling was affirmed by the United States Court of Appeals for the First Circuit, with Judge Juan R. Torruella concurring only in the judgment.[29] The following June, in Puerto Rico v. Franklin California Tax-Free Trust (2016), that ruling was additionally affirmed by a U.S. Supreme Court in a vote of 5-2, with Justice Sonia Sotomayor dissenting.[30]\\r\\nFacing the Puerto Rican government-debt crisis, in June 2015, Governor Garca Padilla announced the Commonwealth was in a \\"death spiral\\" and \\"the debt is not payable.\\"[31]\\r\\nOn June 30, 2016, President Barack Obama signed the PROMESA into law, which empowered him to appoint a seven-member Financial Oversight and Management Board that has ultimate control over the Commonwealth's budget.[32]\\r\\nIn June 2013, Garca Padilla traveled to Spain where he met with representatives of the pharmaceutical and medical devices industry of Spain to showcase Puerto Rico as an attractive investment destination.[33]\\r\\nIn July 2013, Garca Padilla's administration established a trade agreement between Colombia and Puerto Rico whereby Colombia will import medicine from Puerto Rico and provide knowledge transfer in several industries.[34][35] Puerto Rico on the other hand will co-manufacture products together with Colombia, so that Colombia can benefit from Puerto Rico's lack of tariffs when exporting to the United States.\\r\\nOn 4 August 2013, protesters marched in Old San Juan to express their discontent with new taxes imposed by his administration and the way the government has been handling its finances.[36]\\r\\nOn 6 November 2013, El Nuevo Da released poll results published a year after his election that indicated that 57% of poll participants rated Garca-Padilla's administration with a \\"D\\" or an \\"F\\" grade and 62% disapproved of his performance as governor.[37][38]\\r\\nHe has also been accused of nepotism, because of his having five relatives working in the government, three of them as political appointees. Most of the criticism was focused on the appointment of his cousin, Ricardo Colon Padilla, as director of the commonwealth's Medicaid program, as Colon been previously convicted of providing the FBI and IRS with false testimony during an investigation.[39]\\r\\nGarcia Padilla has been criticized by some Puerto Ricans for his poor command of the English language, marked by stammering, poor vocabulary, a strong accent, and difficulty in understanding the language.[40][41][42] He has tried to shake off criticism of his language skills by appealing to populism, stating that he is proud of his rural origins, and that his English reflects said origin, and that he also \\"speaks better English than a mainlander speaks Spanish.\\"[43]\\r\\nOn 14 December 2015 after weeks of speculation and due to opposition from his own party, Garca Padilla announced he wouldn't seek re-election.[d]\\r\\nGarca Padilla has been married to Wilma Pastrana, a CPA, since 7 April 2001. They have three children: Ana, Juan Pablo, and Diego.[45][46] Among his older brothers, Antonio served as President of the University of Puerto Rico and Juan Carlos serves as mayor of Coamo. Another of his brothers, Luis Gerardo, was a government employee with the Puerto Rico Telephone Company.[47][relevant? ÿ discuss]","input":"Who is the present governor of puerto rico?"},{"output":"In 1944","context":"Consumption, phthisis, scrofula[non sequitur], Pott's disease[non sequitur], and the White Plague are all terms used to refer to tuberculosis throughout history. It is generally accepted that Mycobacterium tuberculosis originated from other, more primitive organisms of the same genus Mycobacterium. In 2014, results of a new DNA study of a tuberculosis genome reconstructed from remains in southern Peru suggest that human tuberculosis is less than 6,000 years old. Even if researchers theorize that humans first acquired it in Africa about 5,000 years ago,[1] there is evidence that the first tuberculosis infection happened about 9,000 years ago.[2] It spread to other humans along trade routes. It also spread to domesticated animals in Africa, such as goats and cows. Seals and sea lions that bred on African beaches are believed to have acquired the disease and carried it across the Atlantic to South America. Hunters would have been the first humans to contract the disease there.[1]\\r\\n\\r\\n\\r\\nScientific work investigating the evolutionary origins of the Mycobacterium tuberculosis complex has concluded that the most recent common ancestor of the complex was a human-specific pathogen, which underwent a population bottleneck. Analysis of mycobacterial interspersed repetitive units has allowed dating of the bottleneck to approximately 40,000 years ago, which corresponds to the period subsequent to the expansion of Homo sapiens sapiens out of Africa. This analysis of mycobacterial interspersed repetitive units also dated the Mycobacterium bovis lineage as dispersing approximately 6,000 years ago, which may be linked to animal domestication and early farming.[3]\\r\\nHuman bones from the Neolithic show a presence of the bacteria. There have also been a claim of evidence of lesions characteristic of tuberculosis in a 500,000 years old Homo erectus fossile, although this finding is controversial.[4]\\r\\nResults of a genome study reported in 2014 suggest that tuberculosis is newer than previously thought. Scientists were able to recreate the genome of the bacteria from remains of 1,000-year-old skeletons in southern Peru. In dating the DNA, they found it was less than 6,000 years old. They also found it related most closely to a tuberculosis strain in seals, and have theorized that these animals were the mode of transmission from Africa to South America.[1] The team from University of Tubingen believe that humans acquired the disease in Africa about 5,000 years ago.[1] Their domesticated animals, such as goats and cows, contracted it from them. Seals acquired it when coming up on African beaches for breeding, and carried it across the Atlantic. In addition, TB spread via humans on the trade routes of the Old World. Other researchers have argued there is other evidence that suggests the tuberculosis bacteria is older than 6,000 years.[1] This TB strain found in Peru is different from that prevalent today in the Americas, which is more closely related to a later Eurasian strain likely brought by European colonists.[5] However, this result is criticised by other experts from the field,[1] for instance because there is evidence of the presence of Mycobacterium tuberculosis in 9000 year old skeletal remains.[2]\\r\\nAlthough relatively little is known about its frequency before the 19th century, its incidence is thought to have peaked between the end of the 18th century and the end of the 19th century. Over time, the various cultures of the world gave the illness different names: phthisis (Greek), consumptione (Latin), yaksma (India), and chaky oncay (Incan), each of which make reference to the \\"drying\\" or \\"consuming\\" affect of the illness, cachexia.\\r\\nIn the 19th century, TB's high mortality rate among young and middle-aged adults and the surge of Romanticism, which stressed feeling over reason, caused many to refer to the disease as the \\"romantic disease\\".\\r\\nIn 2008, evidence for tuberculosis infection was discovered in human remains from the Neolithic era dating from 9,000 years ago, in Atlit Yam, a settlement in the eastern Mediterranean.[6] This finding was confirmed by morphological and molecular methods; to date it is the oldest evidence of tuberculosis infection in humans.\\r\\nEvidence of the infection in humans was also found in a cemetery near Heidelberg, in the Neolithic bone remains that show evidence of the type of angulation often seen with spinal tuberculosis.[7] Some authors call tuberculosis the first disease known to mankind.\\r\\nSigns of the disease have also been found in Egyptian mummies dated between 3000 and 2400 BC.[8] The most convincing case was found in the mummy of priest Nesperehen, discovered by Grebart in 1881, which featured evidence of spinal tuberculosis with the characteristic psoas abscesses.[9] Similar features were discovered on other mummies like that of the priest Philoc and throughout the cemeteries of Thebes. It appears likely that Akhenaten and his wife Nefertiti both died from tuberculosis, and evidence indicates that hospitals for tuberculosis existed in Egypt as early as 1500 BC.[10]\\r\\nThe Ebers papyrus, an important Egyptian medical treatise from around 1550 BC, describes a pulmonary consumption associated with the cervical lymph nodes. It recommended that it be treated with the surgical lancing of the cyst and the application of a ground mixture of acacia seyal, peas, fruits, animal blood, insect blood, honey and salt.\\r\\nThe Old Testament mentions a consumptive illness that would affect the Jewish people if they stray from God. It is listed in the section of curses given before they enter the land of Canaan.[11]\\r\\nThe first references to tuberculosis in non-European civilization is found in the Vedas. The oldest of them (Rigveda, 1500 BC) calls the disease yaksma.[12] The Atharvaveda calls it balasa. It is in the Atharvaveda that the first description of scrofula is given.[13] The Sushruta Samhita, written around 600 BC, recommends that the disease be treated with breast milk, various meats, alcohol and rest.[14] The Yajurveda advises sufferers to move to higher altitudes.[14]\\r\\nThe Classical Chinese word ao  \\"consumption; tuberculosis\\" was the common name in traditional Chinese medicine and fijih  (lit. \\"lung knot kernel\\") \\"pulmonary tuberculosis\\" is the modern medical term. Lao is compounded in names like xulao ? with \\"empty; void\\", lobng ô with \\"sickness\\", lozhi  with \\"[archaic] sickness\\", and feilao  with \\"lungs\\". Zhang and Unschuld explain that the medical term xulao ? \\"depletion exhaustion\\" includes infectious and consumptive pathologies, such as laozhai  \\"exhaustion with consumption\\" or laozhaichong  \\"exhaustion consumption bugs/worms\\".[15] They retrospectively identify feilao  \\"lung exhaustion\\" and infectious feilao chuanshi ?A? \\"lung exhaustion by corpse [evil] transmission as \\"consumption/tuberculosis\\".[16] Describing foreign loanwords in early medical terminology, Zhang and Unschuld note the phonetic similarity between Chinese feixiao m (from Old Chinese **p?ot-ssew) \\"lung consumption\\" and ancient Greek phthisis \\"pulmonary tuberculosis\\".[17]\\r\\nThe (c. 400 BCE ÿ 260 CE) Huangdi Neijing classic Chinese medical text, traditionally attributed to the mythical Yellow Emperor, describes a disease believed to be tuberculosis, called xulao bing (?ô \\"weak consumptive disease\\"), characterized by persistent cough, abnormal appearance, fever, a weak and fast pulse, chest obstructions, and shortness of breath.[18][verification needed]\\r\\nThe Huangdi Neijing describes an incurable disease called huaifu ?d? \\"bad palace\\", which commentators interpret as tuberculous. \\"As for a string which is cut, its sound is hoarse. As for wood which has become old, its leaves are shed. As for a disease which is in the depth [of the body], the sound it [generates] is hiccup. When a man has these three [states], this is called 'destroyed palace'. Toxic drugs do not bring a cure; short needles cannot seize [the disease].[19] Wang Bing's commentary explains that fu  \\"palace\\" stands for xiong  \\"chest\\", and huai \\"destroy\\" implies \\"injure the palace and seize the disease\\". The Huangdi Neijing compiler Yang Shangshan notes, \\"The [disease] proposed here very much resembles tuberculosis ... Hence [the text] states: poisonous drugs bring no cure; it cannot be seized with short needles.\\"[20]\\r\\nThe (c. 200ÿ250 CE) Shennong Bencaojing pharmacopeia, attributed to the legendary inventor of agriculture Shennong \\"Divine Farmer\\", also refers to tuberculosis[21]\\r\\nThe Zhouhou beiji fang YġԴ \\"Handbook of Prescriptions for Emergencies\\", attributed to the Daoist scholar Ge Hong (263-420), uses the name of shizhu ֒ \\"corpse disease; tuberculosis\\" and describes the symptoms and contagion: \\"This disease has many changing symptoms varying from thirty-six to ninety-nine different kinds. Generally it gives rise to a high fever, sweating, asthenia, unlocalised pains, making all positions difficult. Gradually, after months and years of suffering, this lingering disease brings about death to the sufferer. Afterwards it is transferred to others until the whole family is wiped out.\\"[22]\\r\\nSong dynasty (920ÿ1279) Daoist priest-doctors first recorded that tuberculosis, called shؐzhi  (lit. \\"corpse disease\\") \\"disease which changes a living being into a corpse\\",[23] was caused by a specific parasite or pathogen, centuries earlier than their contemporaries in other countries. The Duanchu shizhai pin ?? \\"On the Extermination of the Corpse Disease\\" is the 23rd chapter in Daoist collection Wushang xuanyuan santian Yutang dafa ?of\\\\??ޔΗ \\"Great Rites of the Jade Hall of the Three Heavens of the Supreme Mysterious Origins\\" (Daozang number 103). The text has a preface dated 1126, written by the Song dynasty Zhengyi Dao master Lu Shizhong ?r, who founded the Yutang dafa ޔΗ tradition, but internal evidence reveals that the text could not have been written before 1158.[24]\\r\\nThe disaster of the contagious disease, which changes a living being into a corpse, is caused by the infectious [nature] of the nine [kinds of] parasites (ch'ung ). It is also caused by overworking one's mind and exhausting one's energy, injuring one's ch'i and loosening one's spermall of which happen to common folk. When the original vitality is being [gradually] exhausted, the evil aura begins to be transmitted through the affected vital ch'i [of the sick body]. ... The aspects of the illness vary, and the causes of contamination are different. Rooms and food are capable of gradual contamination, and the clothes worn by the indisposed are twined easily with the infectious ch'i and these two become inseparable. ... The symptoms of the disease: When it begins, the sufferer coughs and pants; he spits blood [pulmonary hemorrhage]; he is emaciated and skinny; cold and fever affect him intermittently, and his dreams are morbid. This is the evidence that this person is suffering from the disease which is also known as wu-ch'uan ?? [contagious disease contracted from a sick-room]. ... The disease may be contracted by a healthy person who happens to have slept in the same bed with the patient, or worn his clothes. After the death of the sufferer, the clothes, curtains, bed or couch, vessels and utensils used by him are known to have been contaminated by and saturated with the polluted ch'i in which the noxious ku  [parasites or germs] take their abode. Stingy people wish to keep them for further use, and the poorer families cannot afford to get rid of them and buy everything anew. Isn't this lamentable, since it creates the cause of the great misfortune yet to come![25]\\r\\nThis passage refers to the cause of TB in ancient medical terminology of jiuchong  \\"Nine Worms\\" and gu  \\"supernatural agents causing disease\\", and qi. The Nine Worms generically meant \\"bodily parasites; intestinal worms\\" and were associated with the sanshi ?? \\"Three Corpses\\" or sanchong ?? \\"Three Worms\\", which were believed to be biospiritual parasites that live in the human body and seek to hasten their host's death. Daoist medical texts give different lists and descriptions of the Nine Worms. The Boji fang ??Դ \\"Prescriptions for Universal Dispensation\\", collected by Wang Gunt? (fl. 1041), calls the supposed TB pathogen laochong  \\"tuberculosis worms\\".[26]\\r\\nThis Duanchu shizhai pin chapter (23/7b-8b) explains that the present Nine Worms does not refer to the intestinal weichong  \\"stomach worms\\", huichong x \\"coiling worm; roundworm\\", or cun baichong Ɇ \\"inch-long white worm; nematode\\", and says the supposed six TB worms are \\"six kinds\\" of parasites, but the next chapter (24/20a-21b) says they are \\"six stages/generations\\" of reproduction.[27] Daoist priests allegedly cured tuberculosis through drugs, acupuncture, and burning fulu \\"supernatural talismans/charms\\". Burning magic talismans would cause the TB patient to cough, which was considered an effective treatment.\\r\\nTo cure the disease, it is necessary to produce a spout of smoke by burning off thirty-six charms, and instruct the patient to inhale and to swallow up its fumes, whether he likes it or not. By the time all charms are used up, the smoke should also be dispersed. It may be difficult for the patient to bear the odour of the smoke at first, but once he gets used to such a smell, it does not really matter. Whenever the patient feels that there is phlegm in his throat, he is advised to cough and spit it out. If the patient is greatly affected by the symptoms, it will be good if his spittle is thick and if he can spit it out. When the patient is less affected by the wicked ch'i, he does not have much phlegm to eject, but if he is deeply affected, he tends to vomit and to expectorate heavily until everything is cleared up, and then his illness is cured. When the wicked element is rooted out, it does not need to be fumigated any more [with charms].[28]\\r\\nIn addition, Daoist healers would burn talismans in order to fumigate the clothes and belongings of the deceased, and would warn the family of the tuberculosis victim's family to throw away everything into a changliu shui ˪i \\"everflowing stream\\". According to Liu Ts'un-yan,[29] \\"This proves that the priests of the time actually wanted to destroy all the belongings of the deceased, using charms as a camouflage.\\"\\r\\nThe first classical text to mention the disease is Herodotus' Histories in which he relates how a Persian general, Pharnouches, abandoned Xerxes' campaign against the Spartans due to consumption.[30]\\r\\nHippocrates, in Book 1 of his Of the Epidemics, describes the characteristics of the disease: fever, colorless urine, cough resulting in a thick sputa, and loss of thirst and appetite. He notes that most of the sufferers became delirious before they succumbed to the disease.[31] Hippocrates and many other at the time believed phthisis to be hereditary in nature.[32] Aristotle disagreed, believing the disease was contagious.\\r\\nPliny the Younger wrote a letter to Priscus in which he details the symptoms of phthisis as he saw them in Fannia:\\r\\nThe attacks of fever stick to her, her cough grows upon her, she is in the highest degree emaciated and enfeebled.\\r\\nGalen proposed a series of therapeutic treatments for the disease, including: opium as a sleeping agent and painkiller; blood letting; a diet of barley water, fish, and fruit. He also described the phyma (tumor) of the lungs, which is thought to correspond to the tubercles that form on the lung as a result of the disease.[33]\\r\\nVitruvius noted that \\"cold in the windpipe, cough, plurisy, phthisis, [and] spitting blood\\", were common diseases in regions where the wind blew from north to northwest, and advised that walls be so built as to shelter individuals from the winds.[34]\\r\\nAretaeus was the first person to rigorously describe the symptoms of the disease in his text De causis et signis diuturnorum morborum:[35]\\r\\nVoice hoarse; neck slightly bent, tender, not flexible, somewhat extended; fingers slender, but joints thick; of the bones alone the figure remains, for the fleshy parts are wasted; the nails of the fingers crooked, their pulps are shrivelled and flat...Nose sharp, slender; cheeks prominent and red; eyes hollow, brilliant and glittering; swollen, pale or livid in countenance; the slender parts of the jaws rest on the teeth as, as if smiling; otherwise of cadaverous aspect...\\r\\nIn his other book De curatione diuturnorum morborum, he recommends that sufferers travel to high altitudes, travel by sea, eat a good diet and drink plenty of milk.[36]\\r\\nIn South America, reports of a study in August 2014 revealed that TB had likely been spread via seals that contracted it on beaches of Africa, from humans via domesticated animals, and carried it across the Atlantic. A team at the University of Tubingen analyzed tuberculosis DNA in 1,000-year-old skeletons of the Chiribaya culture in southern Peru; so much genetic material was recovered that they could reconstruct the genome. They learned that this TB strain was related most closely to a form found only in seals.[1] In South America, it was likely contracted first by hunters who handled contaminated meat. This TB is a different strain from that prevalent today in the Americas, which is more closely related to a later Eurasian strain.[5][37]\\r\\nPrior to this study, the first evidence of the disease in South America was found in remains of the Arawak culture around 1050 BC.[38] The most significant finding belongs to the mummy of an 8 to 10-year-old Nascan child from Hacienda Agua Sala, dated to 700 AD. Scientists were able to isolate evidence of the bacillus.[38]\\r\\nDuring the Middle Ages, no significant advances were made regarding tuberculosis. Avicenna and Rhazes continued to consider to believe the disease was both contagious and difficult to treat. Arnaldus de Villa Nova described etiopathogenic theory directly related to that of Hippocrates, in which a cold humor dripped from the head into the lungs.\\r\\nIn Medieval Hungary, the Inquisition recorded the trials of pagans. A document from the 12th century recorded an explanation of the cause of illness. The pagans said that tuberculosis was produced when a dog-shaped demon occupied the person's body and started to eat his lungs. When the possessed person coughed, then the demon was barking, and getting close to his objective, which was to kill the victim.[39]\\r\\nWith the spread of Christianity, monarchs were seen as religious figures with magical or curative powers. It was believed that royal touch, the touch of the sovereign of England or France, could cure diseases due to the divine right of sovereigns.[40] King Henry IV of France usually performed the rite once a week, after taking communion.[41] So common was this practice of royal healing in France, that scrofula became known as the \\"mal du roi\\" or the \\"King's Evil\\".\\r\\nInitially, the touching ceremony was an informal process. Sickly individuals could petition the court for a royal touch and the touch would be performed at the King's earliest convenience. At times, the King of France would touch afflicted subjects during his royal walkabout. The rapid spread of tuberculosis across France and England, however, necessitated a more formal and efficient touching process. By the time of Louis XIV of France, placards indicating the days and times the King would be available for royal touches were posted regularly; sums of money were doled out as charitable support.[41][42] In England, the process was extremely formal and efficient. As late as 1633, the Book of Common Prayer of the Anglican Church contained a Royal Touch ceremony.[43] The monarch (king or queen), sitting upon a canopied throne, touched the afflicted individual, and presented that individual with a coin ÿ usually an Angel, a gold coin the value of which varied from about 6 shillings to about 10 shillings ÿ by pressing it against the afflicted's neck.[41]\\r\\nAlthough the ceremony was of no medical value, members of the royal courts often propagandized that those receiving the royal touch were miraculously healed. Andr du Laurens, the senior physician of Henry IV, publicized findings that at least half of those that received the royal touch were cured within a few days.[44] The royal touch remained popular into the 18th century. Parish registers from Oxfordshire, England include not only records of baptisms, marriages, and deaths, but also records of those eligible for the royal touch.[40]\\r\\nGirolamo Fracastoro became the first person to propose, in his work De contagione, that phthisis was transmitted by an invisible virus. Among his assertions were that the virus could survive between two or three years on the clothes of those suffering from the disease and that it was usually transmitted through direct contact or the discharged fluids of the infected, what he called fomes. He noted that phthisis could be contracted without either direct contact or fomes, but was unsure of the process by which the disease propagated across distances.[45]\\r\\nParacelsus advanced the belief that tuberculosis was caused by a failure of an internal organ to accomplish its alchemical duties. When this occurred in the lungs, stony precipitates would develop causing tuberculosis in what he called the tartaric process.[46]\\r\\nFranciscus Sylvius began differentiating between the various forms of tuberculosis (pulmonary, ganglion). He was the first person to recognize that the skin ulcers caused by scrofula resembled tubercles seen in phthisis,[47] noting that \\"phthisis is the scrofula of the lung\\" in his book Opera Medica, published posthumously in 1679. Around the same time, Thomas Willis concluded that all diseases of the chest must ultimately lead to consumption.[48] Willis did not know the exact cause of the disease but he blamed it on sugar[49] or an acidity of the blood.[47] Richard Morton published Phthisiologia, seu exercitationes de Phthisi tribus libris comprehensae in 1689, in which he emphasized the tubercle as the true cause of the disease. So common was the disease at the time that Morton is quoted as saying \\"I cannot sufficiently admire that anyone, at least after he comes to the flower of his youth, can [sic] dye without a touch of consumption.\\"[50]\\r\\nIn 1720, Benjamin Marten proposed in A New Theory of Consumptions more Especially of Phthisis or Consumption of the Lungs that the cause of tuberculosis was some type of animalculamicroscopic living beings that are able to survive in a new body (similar to the ones described by Anton van Leeuwenhoek in 1695).[51] The theory was roundly rejected and it took another 162 years before Robert Koch demonstrated it to be true.\\r\\nIn 1768, Robert Whytt gave the first clinical description of tuberculosis meningitis[52] and in 1779, Percivall Pott, an English surgeon, described the vertebral lesions that carry his name.[42] In 1761, Leopold Auenbrugger, an Austrian physician, developed the percussion method of diagnosing tuberculosis,[53] a method rediscovered some years later in 1797 by Jean-Nicolas Corvisart of France. After finding it useful, Corvisart made it readily available to the academic community by translating it into French.[54]\\r\\nWilliam Stark proposed that ordinary lung tubercles could eventually evolve into ulcers and cavities, believing that the different forms of tuberculosis were simply different manifestations of the same disease. Unfortunately, Stark died at the age of thirty (while studying scurvy) and his observations were discounted.[55] In his Systematik de speziellen Pathologie und Therapie, J. L. Sch?nlein, Professor of Medicine in Zurich, proposed that the word \\"tuberculosis\\" be used to describe the affliction of tubercles.[56][57]\\r\\nThe incidence of tuberculosis grew progressively during the Middle Ages and Renaissance, displacing leprosy, peaking between the 18th and 19th century as field workers moved to the cities looking for work.[42] When he released his study in 1808, William Woolcombe was astonished at the prevalence of tuberculosis in 18th-century England.[58] Of the 1,571 deaths in the English city of Bristol between 1790 and 1796, 683 were due to tuberculosis.[59] Remote towns, initially isolated from the disease, slowly succumbed. The consumption deaths in the village of Holycross in Shropshire between 1750 and 1759 were one in six (1:6); ten years later, 1:3. In the metropolis of London, 1:7 died from consumption at the dawn of the 18th century, by 1750 that proportion grew to 1:5.25 and surged to 1:4.2 by around the start of the 19th century.[60] The Industrial Revolution coupled with poverty and squalor created the optimal environment for the propagation of the disease.\\r\\n\\"Chopin coughs with infinite grace.\\"\\r\\nIt was during this century that tuberculosis was dubbed the White Plague,[61] mal de vivre, and mal du sicle. It was seen as a \\"romantic disease\\". Suffering from tuberculosis was thought to bestow upon the sufferer heightened sensitivity. The slow progress of the disease allowed for a \\"good death\\" as sufferers could arrange their affairs.[62] The disease began to represent spiritual purity and temporal wealth, leading many young, upper-class women to purposefully pale their skin to achieve the consumptive appearance. British poet Lord Byron wrote, \\"I should like to die from consumption\\", helping to popularize the disease as the disease of artists.[63] George Sand doted on her phthisic lover, Frdric Chopin, calling him her \\"poor melancholy angel\\".[64]\\r\\nIn France, at least five novels were published expressing the ideals of tuberculosis: Dumas's La Dame aux camlias, Murger's Scnes de la vie de Bohme, Hugo's Les Misrables, the Goncourt brothers' Madame Gervaisais and Germinie Lacerteux, and Rostand's L'Aiglon. The portrayals by Dumas and Murger in turn inspired operatic depictions of consumption in Verdi's La traviata and Puccini's La bohme. Even after medical knowledge of the disease had accumulated, the redemptive-spiritual perspective of the disease has remained popular[65] (as seen in the 2001 film Moulin Rouge based in part on La traviata and the musical adaptations of Les Misrables).\\r\\nIn large cities the poor had high rates of tuberculosis. Public-health physicians and politicians typically blamed both the poor themselves and their ramshackle tenement houses (conventillos) for the spread of the dreaded disease. People ignored public-health campaigns to limit the spread of contagious diseases, such as the prohibition of spitting on the streets, the strict guidelines to care for infants and young children, and quarantines that separated families from ill loved ones.[66]\\r\\nThough removed from the cultural movement, the scientific understanding advanced considerably. By the end of the 19th century, several major breakthroughs gave hope that a cause and cure might be found.\\r\\nOne of the most important physicians dedicated to the study of phthisiology was Ren Laennec, who died from the disease at the age of 45, after contracting tuberculosis while studying contagious patients and infected bodies.[67] Laennec invented the stethoscope[53] which he used to corroborate his auscultatory findings and prove the correspondence between the pulmonary lesions found on the lungs of autopsied tuberculosis patients and the respiratory symptoms seen in living patients. His most important work was Trait de lAuscultaci܇n Mediate which detailed his discoveries on the utility of pulmonary auscultation in diagnosing tuberculosis. This book was promptly translated into English by John Forbes in 1821; it represents the beginning of the modern scientific understanding of tuberculosis.[64] Laennec was named professional chair of H?pital Necker in September 1816 and today he is considered the greatest French clinician.[68][69]\\r\\nLaennec's work put him in contact with the vanguard of the French medical establishment, including Pierre Charles Alexandre Louis. Louis would go on to use statistical methods to evaluate the different aspects of the disease's progression, the efficacy of various therapies and individuals' susceptibility, publishing an article in the Annales d'hygine publique entitled \\"Note on the Relative Frequency of Phthisis in the Two Sexes\\".[70] Another good friend and co-worker of Laennec, Gaspard Laurent Bayle, published an article in 1810 entitled Recherches sur la Pthisie Pulmonaire, in which he divided pthisis into six types: tubercular phthisis, glandular phthisis, ulcerous phthisis, phthisis with melanosis, calculous phthisis, and cancerous phthisis. He based his findings on more than 900 autopsies.[61][71]\\r\\nIn 1869, Jean Antoine Villemin demonstrated that the disease was indeed contagious, conducting an experiment in which tuberculous matter from human cadavers was injected into laboratory rabbits, which then became infected.[72]\\r\\nOn 24 March 1882, Robert Koch revealed the disease was caused by an infectious agent.[64] In 1895, Wilhelm Roentgen discovered the X-ray, which allowed physicians to diagnose and track the progression of the disease,[73] and although an effective medical treatment would not come for another fifty years, the incidence and mortality of tuberculosis began to decline.[74]\\r\\nVillemin's experiments had confirmed the contagious nature of the disease and had forced the medical community to accept that tuberculosis was indeed an infectious disease, transmitted by some etiological agent of unknown origin. In 1882, Prussian physician Robert Koch utilized a new staining method and applied it to the sputum of tuberculosis patients, revealing for the first time the causal agent of the disease: Mycobacterium tuberculosis, or Koch's bacillus.[76]\\r\\nWhen he began his investigation, Koch knew of the work of Villemin and others who had continued his experiments like Julius Conheim and Carl Salmosen. He also had access to the \\"pthisis ward\\" at the Berlin Charit Hospital.[77] Before he confronted the problem of tuberculosis, he worked with the disease caused by anthrax and had discovered the causal agent to be Bacillus anthracis. During this investigation he became friends with Ferdinand Cohn, the director of the Institute of Vegetable Physiology. Together they worked to develop methods of culturing tissue samples. 18 August 1881, while staining tuberculous material with methylene blue, he noticed oblong structures, though he was not able to ascertain whether it was just a result of the coloring. To improve the contrast, he decide to add Bismarck Brown, after which the oblong structures were rendered bright and transparent. He improved the technique by varying the concentration of alkali in the staining solution until the ideal viewing conditions for the bacilli was achieved.\\r\\nAfter numerous attempts he was able to incubate the bacteria in coagulated blood serum at 37 degrees Celsius. He then inoculated laboratory rabbits with the bacteria and observed that they died while exhibiting symptoms of tuberculosis, proving that the bacillus, which he named tuberculosis bacillus, was in fact the cause of tuberculosis.[78]\\r\\nHe made his result public at the Physiological Society of Berlin on 24 March 1882, in a famous lecture entitled ber Tuberculose, which was published three weeks later. Since 1882, 24 March has been known as World Tuberculosis Day.[79]\\r\\nOn 20 April 1882, Koch presented an article entitled Die ?tiologie der Tuberculose in which he demonstrated that Mycobacterium was the single cause of tuberculosis in all of its forms.[78]\\r\\nIn 1890 Koch developed tuberculin, a purified protein derivative of the bacteria.[80] It proved to be an ineffective means of immunization but in 1908, Charles Mantoux found it was an effective intradermic test for diagnosing tuberculosis.[81]\\r\\nIf the importance of a disease for mankind is measured from the number of fatalities which are due to it, then tuberculosis must be considered much more important than those most feared infectious diseases, plague, cholera, and the like. Statistics have shown that 1/7 of all humans die of tuberculosis.\\r\\nThe advancement of scientific understanding of tuberculosis, and its contagious nature created the need for institutions to house sufferers.\\r\\nThe first proposal for a tuberculosis facility was made in paper by George Bodington entitled An essay on the treatment and cure of pulmonary consumption, on principles natural, rational and successful in 1840. In this paper, he proposed a dietary, rest, and medical care program for a hospital he planned to found in Maney.[82] Attacks from numerous medical experts, especially articles in The Lancet, disheartened Bodington and he turned to plans for housing the insane.[83]\\r\\nAround the same time in the United States, in late October and early November 1842, Dr. John Croghan, the owner of Mammoth Cave, brought 15 tuberculosis sufferers into the cave in the hope of curing the disease with the constant temperature and purity of the cave air.[84] Patients were lodged in stone huts, and each was supplied with a slave to bring meals.[85] One patient, A. H. P. Anderson, wrote glowing reviews of the cave experience:[86]\\r\\n[S]ome of the invalids eat at their pavillions while others in better health attend regularly the table d'hote which is very good indeed, having a considerable variety and being almost daily (I've noted but 2-3 omissions) graced with a saddle of venison or other game.\\r\\nBy late January, early February 1843, two patients were dead and the rest had left. Departing patients died anywhere from three days to three weeks after resurfacing; John Croghan died of tuberculosis at his Louisville residence in 1849.[87]\\r\\nHermann Brehmer, a German physician, was convinced that tuberculosis arose from the difficulty of the heart to correctly irrigate the lungs. He therefore proposed that regions well above sea level, where the atmospheric pressure was less, would help the heart function more effectively. With the encouragement of explorer Alexander von Humboldt and his teacher J. L. Sch?nlein, the first anti-tuberculosis sanatorium was established in 1854, 650 meters above sea level, at G?rbersdorf.[88] Three years later he published his findings in a paper Die chronische Lungenschwindsucht und Tuberkulose der Lunge: Ihre Ursache und ihre Heilung.\\r\\nBrehmer and one of his patients, Peter Dettweiler, became proponents for the sanatorium movement, and by 1877, sanatoriums began to spread beyond Germany and throughout Europe. Dr. Edward Livingston Trudeau subsequently founded the Adirondack Cottage Sanitorium in Saranac Lake, New York in 1884. One of Trudeau's early patients was author Robert Louis Stevenson; his fame helped establish Saranac Lake as a center for the treatment of tuberculosis. In 1894, after a fire destroyed Trudeau's small home laboratory, he organized the Saranac Laboratory for the Study of Tuberculosis; renamed the Trudeau Institute, the laboratory continues to study infectious diseases.[89]\\r\\nPeter Dettweiler went on to found his own sanatorium at Falkenstein in 1877 and in 1886 published findings claiming that 132 of his 1022 patients had been completely cured after staying at his institution.[90] Eventually, sanatoriums began to appear near large cities and at low altitudes, like the Sharon Sanatorium in 1890 near Boston.[91]\\r\\nSanatoriums were not the only treatment facilities. Specialized tuberculosis clinics began to develop in major metropolitan areas. Sir Robert Philip established the Royal Victoria Dispensary for Consumption in Edinburgh in 1887. Dispensaries acted as special sanatoriums for early tuberculosis cases and were opened to lower income individuals. The use of dispensaries to treat middle and lower-class individuals in major metropolitan areas and the coordination between various levels of health services programs like hospitals, sanatoriums, and tuberculosis colonies became known as the \\"Edinburgh Anti-tuberculosis Scheme\\".[92]\\r\\nAt the beginning of the 20th century, tuberculosis was one of the UK's most urgent health problems. A royal commission was set up in 1901, The Royal Commission Appointed to Inquire into the Relations of Human and Animal Tuberculosis. Its remit was to find out whether tuberculosis in animals and humans was the same disease, and whether animals and humans could infect each other. By 1919, the Commission had evolved into the UK's Medical Research Council.\\r\\nIn 1902, the International Conference on Tuberculosis convened in Berlin. Among various other acts, the conference proposed the Cross of Lorraine be the international symbol of the fight against tuberculosis. National campaigns spread across Europe and the United States to tamp down on the continued prevalence of tuberculosis.\\r\\nAfter the establishment in the 1880s that the disease was contagious, TB was made a notifiable disease in Britain; there were campaigns to stop spitting in public places, and the infected poor were pressured to enter sanatoria that resembled prisons; the sanatoria for the middle and upper classes offered excellent care and constant medical attention.[93] Whatever the purported benefits of the fresh air and labor in the sanatoria, even under the best conditions, 50% of those who entered were dead within five years (1916).[93]\\r\\nThe promotion of Christmas Seals began in Denmark during 1904 as a way to raise money for tuberculosis programs. It expanded to the United States and Canada in 1907ÿ1908 to help the National Tuberculosis Association (later called the American Lung Association).\\r\\nIn the United States, concern about the spread of tuberculosis played a role in the movement to prohibit public spitting except into spittoons.\\r\\nThe first genuine success in immunizing against tuberculosis was developed from attenuated bovine-strain tuberculosis by Albert Calmette and Camille Gurin in 1906. It was called \\"BCG\\" (Bacille Calmette-Gurin). The BCG vaccine was first used on humans in 1921 in France,[94] but it was not until after World War II that BCG received widespread acceptance in Great Britain, and Germany.[95] In the early days of the British National Health Service X-ray examination for TB increased dramatically but rates of vaccination were initially very low. In 1953 it was agreed that secondary school pupils should be vaccinated, but by the end of 1954 only 250,000 people had been vaccinated. By 1956 this had risen to 600,000, about half being school children.[96]\\r\\nAs the century progressed, some surgical interventions, including the pneumothorax or plombage techniquecollapsing an infected lung to \\"rest\\" it and allow the lesions to healwere used to treat tuberculosis.[97] Pneumothorax was not a new technique by any means. In 1696, Giorgio Baglivi reported a general improvement in tuberculosis sufferers after they received sword wounds to the chest. F.H. Ramadge induced the first successful therapeutic pneumothorax in 1834, and reported subsequently the patient was cured. It was in the 20th century, however, that scientists sought to rigorously investigate the effectiveness of such procedures. In 1939, the British Journal of Tuberculosis published a study by Oli Hjaltested and Kjeld T?rning on 191 patients undergoing the procedure between 1925 and 1931; in 1951, Roger Mitchell published several articles on the therapeutic outcomes of 557 patients treated between 1930 and 1939 at Trudeau Sanatorium in Saranac Lake.[98] The search for a medicinal cure, however, continued in earnest.\\r\\nDuring the Nazi occupation of Poland, SS-Obergruppenfhrer Wilhelm Koppe organized the execution of more than 30,000 Polish patients suffering from tuberculosis - little knowing or caring that a cure was nearly at hand.\\r\\nIn 1944 Albert Schatz, Elizabeth Bugie, and Selman Waksman isolated streptomycin produced by a bacterial strain Streptomyces griseus. Streptomycin was the first effective antibiotic against M. tuberculosis.[99] This discovery is generally considered the beginning of the modern era of tuberculosis, although the true revolution began some years later, in 1952, with the development of isoniazid, the first oral mycobactericidal drug.[99] The advent of rifampin in the 1970s hastened recovery times, and significantly reduced the number of tuberculosis cases until the 1980s.\\r\\nThe British epidemiologist Thomas McKeown had shown that 'treatment by streptomycin reduced the number of deaths since it was introduced (1948-71) by 51 per cent...'.[100] However, he also showed that the mortality from TB in England and Wales had already declined by 90 to 95% before streptomycin and BCG-vaccination were widely available, and that the contribution of antibiotics to the decline of mortality from TB was actually very small: '...for the total period since cause of death was first recorded (1848ÿ71) the reduction was 3.2 per cent'.[100]:82 These figures have since been confirmed for all western countries (see for example the decline in TB mortality in the USA) and for all then known infectious diseases. McKeown explained the decline in mortality from infectious diseases by an improved standard of living, particularly by better nutrition, and by better hygiene, and less by medical intervention. McKeown, who is considered as the father of social medicine,[101] has advocated for many years, that with drugs and vaccines we may win the battle but will lose the war against Diseases of Poverty.[102] Thereto, efforts and resources should be primarily directed toward improving the standard of living of people in low resource countries, and toward improving their environment by providing clean water, sanitation, better housing, education, safety and justice, and access to medical care. Particularly the work of Noble laureates Robert W. Fogel (1993)[103][104][105][106] and Angus Deaton (2015)[101] have greatly contributed to the recent reappreciation of the McKeown thesis. A negative confirmation of the McKeown thesis was that increased pressure on wages by IMF loans to post-communist Eastern European were strongly associated with a rise in TB incidence, prevalence and mortality.[107]\\r\\nHopes that the disease could be completely eliminated were dashed in the 1980s with the rise of drug-resistant strains. Tuberculosis cases in Britain, numbering around 117,000 in 1913, had fallen to around 5,000 in 1987, but cases rose again, reaching 6,300 in 2000 and 7,600 cases in 2005.[108] Due to the elimination of public health facilities in New York and the emergence of HIV, there was a resurgence of TB in the late 1980s.[109] The number of patients failing to complete their course of drugs is high. New York had to cope with more than 20,000 TB patients with multidrug-resistant strains (resistant to, at least, both rifampin and isoniazid).\\r\\nIn response to the resurgence of tuberculosis, the World Health Organization issued a declaration of a global health emergency in 1993.[110] Every year, nearly half a million new cases of multidrug-resistant tuberculosis (MDR-TB) are estimated to occur worldwide.[111]","input":"When was the first cure for tuberculosis found?"},{"output":"military occupational specialty","context":"A United States military occupation code, or a military occupational specialty code (MOS code), is a nine-character code used in the United States Army and United States Marines to identify a specific job. In the United States Air Force, a system of Air Force Specialty Codes (AFSC) is used. In the United States Navy, a system of naval ratings and designators was used along with the Navy Enlisted Classification (NEC) system: however, on September 29, 2016, the United States Navy discontinued enlisted ratings after two hundred and forty-one years of use. Naval service members thereafter were to be referred to solely by their rank and would hold a Navy Operations Specialty (NOS) instead of a rate.\\r\\nSince an individual can obtain multiple job specialties, a duty military occupational specialty (DMOS) is used to identify what their primary job function is at any given time. An individual must complete and pass all required training for their military occupational specialty qualification (MOSQ).\\r\\n\\r\\n\\r\\nOriginally, the MOS system had three to five digits. The first four-digit code number indicated the soldier's job; the first two digits were the field code, the third digit was the sub-specialty and the fourth code number (separated by a period) was the job title. A fifth code digit was for the soldier's special qualification identifier (SQI), which indicated what specialized training the soldier had. If the soldier did not have an SQI, the digit was listed as \\"0\\" or was omitted.\\r\\nOne-one is the field code for infantry, 1.1 is the sub-specialty of light weapons, and seven is the SQI for airborne training. Therefore, 111.10 is the MOS for an infantryman and 111.17 is for an airborne-qualified paratrooper. Nine-one was the old field code for the medical field, 912.0 is the MOS for medical NCO and 912.00 is a generalist medical NCO with no SQI.\\r\\nIn 1965 the system was revamped. There were completely different codes for enlisted / non-commissioned officers, warrant officers, and commissioned officers.\\r\\nEnlisted and NCO personnel had a five-symbol code. The first four code symbols were made up of a two-digit code for the career field, a letter code for the field specialty, and a number code (1 to 5) indicating level of instruction in their field specialty. The fifth code symbol was an SQI code letter indicating training in a special skill (the letter \\"O\\" indicating that the soldier had no SQI).\\r\\nWarrant officers also had a five-symbol code but it was different. The first three numbers were the career field, then a letter code for the field specialty, and ended in the SQI code letter.\\r\\nOfficers had a four-digit code number for their career field and specialty. Officers with a special qualification also had an SQI code number prefix to their MOS rather than a code letter suffix. Officers without a special qualification had no prefix number.\\r\\nIn 1983, there was a reform of this system. Some of the field code numbers were changed and the MOS codes were streamlined.\\r\\nWarrant officers and officers received the same career field codes as enlisted and NCO personnel and ended in the same SQI letter codes. Warrant officers received a five-symbol MOS consisting of a four-symbol field specialty code consisting of the two-digit field code, a one-digit sub-field code number (usually \\"0\\"), the field specialty code letter, and followed by the SQI code letter. Officers now had a four-symbol alphanumeric MOS. It consisted of the three-symbol field specialty code of two numbers and a specialty code letter and ended in the SQI letter code.\\r\\nThe field code \\"18\\" was created for US Army Special Forces, which are now considered part of the regular US Army. Previously they had been considered a layer between the intelligence services and the army. The 18A was for special forces officers and 180A was for special forces warrant officers. The 18X was for special forces candidates who had not yet passed the \\"Q\\" course. The \\"A\\" team leaders had to be captains instead of lieutenants and were rotated to conventional postings.\\r\\nCertain field specialty code letters were reserved. The \\"X\\" was for recruits or candidates who have pre-selected a career field but had not graduated from AIT. The \\"Z\\" is for senior NCOs of E8 or E9 grade. The \\"A\\" is for officers and warrant officers in a general capacity. Specialist officers and warrant officers have other field code letters reserved for them.\\r\\nThe current list of army military occupational specialty codes is published on the United States Army Human Resources Command (HRC) PAMXXI website.[1]\\r\\nThe MOS code (MOSC), consisting of nine characters, provides more information than a soldier's MOS. It is used by automated management systems and reports. The MOSC is used with active and reserve records, reports, authorization documents, and other personnel management systems.\\r\\nThe elements of the MOSC are as follows:\\r\\nWhen an enlisted soldier is promoted from sergeant first class to master sergeant in most career types, that soldier will be reclassified administratively to the \\"senior sergeant\\" of their career management field. For example, a combat engineer (MOS 12B, part of CMF 12) is promoted from sergeant first class to master sergeant. That soldier is reclassified administratively from MOS 12B to MOS 12Z \\"senior engineer sergeant\\"). An example of when this conversion occurs at the MSG to SGM level is the 68 (formerly the 91) CMF. In this case, the soldier becomes a 68Z at the SGM level, not the MSG level. When promoted from master sergeant or first sergeant or sergeant major to command sergeant major, that soldier will be reclassified administratively from their previous \\"senior sergeant\\" MOS to the MOS 00Z (zero-zero-zulu), \\"command sergeant major\\".\\r\\nWarrant officers are sometimes specialized technicians and systems managers, and were not originally assigned to traditional arms or services of the Army. Approximately 50% of warrant officers are aviators[4] (aircraft pilots, rotary wing and fixed wing), and can be appointed directly from civilian life[5] or within the service, regardless of previous enlisted MOS. The remaining 50% are technicians appointed from experienced enlisted soldiers and NCOs in a \\"feeder\\"[6] MOS directly related to the warrant officer MOS.[7]\\r\\nDuring 2004, all army warrant officers began wearing the insignia of their specialty's proponent branch rather than the 83-year-old \\"Eagle Rising\\" distinctive warrant officer insignia.[8] The following year, a revision of commissioned officer professional development and career management[9] integrated warrant officer career development with the officer career development model. In practice, warrant officer MOSC are very similar to enlisted codes except they begin with three digits instead of two before the first letter, and do not have a \\"skill level\\" identifier. They are then followed by the SQI, ASI, and SLI as an enlisted MOS would be.\\r\\nCommissioned officers' occupational codes are structured somewhat differently. A newly commissioned army officer first receives a \\"career branch\\". This is similar to the career management field of the enlisted personnel. Career branch numbers range from 11 to 92. For example: 13 for field artillery, 19 for armor/armored cavalry and 92 for quartermaster. Within each occupational field, there are usually several codes available. Within armor (branch 19) there are three specialties available: 19A (armor, general), 19B (armor), and 19C (cavalry). After an officer's fifth or sixth year of service, he or she may receive a \\"functional area\\" designation. More specific than a career branch, this is a specific skill set in which the officer is proficient. For example, an artillery officer who has had schooling in communications and public speaking could end up with a functional area in public affairs (FA46).\\r\\nThe U.S. Marine Corps begins by separating all jobs into \\"occupational fields\\" (OccFld), in which no distinction is made between officers and enlisted marines. The fields are numbered from 01 to 99 and include general categories (intelligence, infantry, logistics, public affairs, ordnance, etc.) under which specific jobs fall.\\r\\nEach field contains multiple MOSes, each designated by a four-digit numerical indicator and a job title. For example, the infantry field (03) has ten enlisted classifications: rifleman (MOS 0311), riverine assault craft Marine (MOS 0312), light armored vehicle Marine (MOS 0313), scout sniper (MOS 0317), reconnaissance Marine (MOS 0321), machine gunner (MOS 0331), mortarman (MOS 0341), infantry assault Marine (MOS 0351), antitank missile gunner (MOS 0352), and infantry unit leader (MOS 0369).\\r\\nEach of the jobs have authorized ranks associated with them. For example, anyone ranking from private to sergeant can be a rifleman (0311), but only marines ranking from staff sergeant to master gunnery sergeant can be an infantry unit leader (0369).\\r\\nDuties and tasks are identified by rank because the marine corps MOS system is designed around the belief that increased duties and tasks accompany promotions. The first two digits designate the field and, the last two digits identify the promotional channel and specialty.\\r\\nFor example, the MOS 0311 indicates that it is in occupational field 03 (infantry) and designates the \\"rifleman\\" (11) MOS. For warrant officers, the MOS 2305 indicates that it is in occupational field 23 (ammunition and explosive ordnance disposal) and designates the \\"explosive ordnance disposal officer\\" (05) MOS. For officers, the MOS 0802 indicates that it is in occupational field 08 (field artillery) and designates the \\"field artillery officer\\" (02) MOS.\\r\\nOn September 29, 2016, the Navy announced it will \\"modernize\\" all rating titles for Sailors with a new classification system that will move towards occupational specialty codes similar to how the other services operate. The fleet at large did not respond to this favorably.\\r\\nFormer Master Chief Petty Officer of the Navy Michael Stevens led the controversial review earlier this year for the Secretary of the Navy on behalf of Chief of Naval Operations, Admiral John Richardson.\\r\\nThe current Master Chief Petty Officer of the Navy, Steven S. Giordano, said:\\r\\n\\"Sailors would no longer be called, 'Yeoman Second Class' or YN2, for example,\\" he said. \\"Instead they will be 'Second Class Petty Officer, or 'Petty Officer.' However, Sailors' rates will not change: an E-7 will remain a Chief Petty Officer and an E-3 will remain a Seaman. Additionally, there will no longer be a distinction between 'airman, fireman and seaman.'\\"\\r\\nApparently, sailors will be able to hold more than one NOS, which might give them a broader range of professional experience and expertise and will be grouped under career fields that will enable flexibility to move between occupational specialties within the fields and will be tied to training and qualifications. The plan is not complete, however.\\r\\nThe transformation will occur in phases over a multi-year period and the chief of naval personnel will lead the implementation efforts\\r\\nThe United States Navy has not released it's NOS details yet and has not changed \\"designators\\" for officers.\\r\\nThe Navy indicates its \\"ratings\\" by a two or three character code based on the actual name of the rating. These range from ABE (aviation boatswain's mate - equipment) to YN (Yeoman). Each sailor and Chief Petty Officer wears a rating badge indicating their rating as part of their rate (rank) insignia on full dress and service dress uniforms.\\r\\nThe navy officer \\"designator\\" is similar to an MOS but is less complicated and has fewer categories. For example, a surface warfare officer with a regular commission has a designator of 1110; a reserve officer has an 1115 designator. A reserve surface warfare officer specializing in nuclear training (i.e., engineer on a carrier) has a designator of 1165N. Navy officers also have one or more three-character additional qualification designators (AQD) that reflect completion of requirements qualifying them in a specific warfare area or other specialization. In some senses this functions more like the MOS in other services. An officer with the naval aviator designator of 1310 might have an AQD of DV3, SH-60F carrier anti-submarine warfare helicopter pilot, or DB4, F-14 fighter pilot. An officer designated 2100, medical corps officer (physician) may hold an AQD of 6CM, trauma surgeon, or 6AE, flight surgeon who is also a naval aviator. Some AQDs may be possessed by officers in any designator, such as BT2, freefall parachutist, or BS1, shipboard Tomahawk strike officer. Navy officer designators and AQD codes may be found in NAVPERS 15839I, The Manual of Navy Officer Manpower and Personnel Classification.\\r\\nThe United States Coast Guard does not use the military occupational specialty concept either, instead dividing their occupational specialties into groups such as aviation, administrative and scientific, deck and weapons, and engineering and hull. Their rating system is very similar to the Navy's (e.g. BM, boatswain's mate).\\r\\nThe Coast Guard indicates its \\"ratings\\" by a two or three character code based on the actual name of the rating. These range from AMT (aviation maintenance technician) to YN (yeoman). Coast Guardsmen wear a rating badge indicating their rating as part of their rate (rank) insignia on full dress and service dress uniforms.\\r\\nThe air force utilizes a similar system, but titled \\"air force specialty code\\". Enlisted airmen have a five digit code, and officers have a four digit code.","input":"What is the meaning of m o s?"},{"output":"greater range for hunting bison and trading","context":"The Native American Trade refers to historic trade between Europeans and their North American descendants and the Indigenous people of North America (today known as Native Americans in the United States, and First Nations in Canada, but formerly as \\"Indians\\"), beginning before the colonial period and continuing through the 19th century, although declining it around 1937.\\r\\nThe term Indian Trade describes the people involved in the trade. The products involved varied by region and era. In most of Canada the term is synonymous with the fur trade, since fur for making beaver hats was by far the most valuable product of the trade, from the European point of view. Demand for other products resulted in trade in those items: Europeans asked for deerskin in the Southeast coast of the United States, and for buffalo skins and meat, and pemmican on the Great Plains. In turn, Native American demand influenced the trade goods brought by Europeans.\\r\\nEconomic contact between Native Americans and European colonists began in the 16th century and lasted until the late 19th century. Although the relationship between Europeans and Indians was often marred by conflicts, many tribes established peaceful trade relations with the new colonists during the early stages of European settlement. From the 17th to the 19th century, the English and French mainly traded for animal pelts and fur with Native Americans.[1] On the other hand, trading between the Spanish and Native Americans was sporadic and lasted only for a couple of decades.[2] Eventually, wars, the dwindling of Native American populations and the westward expansion of the United States led to the confinement of tribes to reservations and the end of this kind of economic relations between Indians and European Americans.\\r\\nOther economic relations continued, especially in the alcohol trade around many reservations, and for Native arts and crafts. Today, many Native Americans satisfy a different kind of demand with the associated trades of their gaming casinos on sovereign land. These have been developed as entertainment and conference resorts, serving a wide market of customers, and generating substantial revenues for tribes to use for economic development, as well as welfare and education of their people.\\r\\n\\r\\nThe first explorers to conduct trade with Native Americans were Giovanni da Verrazano and Jacques Cartier in the 1520s-1540s. Verrazano noted in his book, If we wanted to trade with them for some of their things, they would come to the seashore on some rocks where the breakers were most violent while we remained on the little boat, and they sent us what they wanted to give on a rope, continually shouting to us not to approach the land. [3] As visits from Europeans became more frequent and some Europeans began to settle in North America, Indians began to establish regular trade relations with these new colonists. The ideal locations for fur trading were near harbors where ships could come in.\\r\\n\\r\\n\\r\\nPlymouth and Jamestown\\r\\nIn order to set up a thriving colony, settlers in the New World needed the five factors of production that contribute to the creation of wealth: land (natural resources), labor, capital, entrepreneurship and knowledge. Often, trading with Native Americans resulted in colonists gaining needed knowledge and natural resources. Examples of this can be seen in the English settlements of Plymouth Bay and Jamestown. Chief Massasoit, a Wampanoag, and Squanto, a Patuxet Indian, helped the Pilgrims of Plymouth Bay establish their colony by teaching them skills in cultivating this land and hunting.[4] In return for weapons and tools, these Native Americans provided the colonists with important natural resources, including food.[5] In 1621 Chief Massasoit established one of the earliest trading pacts between Europeans and Indians by signing a treaty with Plymouth Colony to engage in peaceful trade.[6] As the number of English colonists in the New England area began to grow, the Wampanoag became uneasy of losing their land to these new settlers. Gradually, tensions escalated, leading to King Philip's War, an armed conflict between the Pilgrims and the Native Americans in the area. The war ended with the defeat of the Indian tribe, causing a serious fracture amongst relations between the Pilgrims and Native Americans.[7]\\r\\nRelations between settlers in the Jamestown area and Native Americans ended similarly. Initially, the Powahatan aided the English settlers with food and clothing, helping them survive the early difficult years. However, relations between the two groups deteriorated after three years, resulting in a war.\\r\\nFur trading posts\\r\\nFur trading was one of the main economic activities in Northern America from the late 16th century to the mid-19th century. At the time, demand for fur was surging in Europe as it was used to make cloth and fancy hats. Data collected from England in the 18th century highlights that the years from 1746 to 1763 saw an increase of 12 shillings per pelt. It has been calculated that over 20 million beaver hats were exported from England alone from 1700 to 1770.[8] Both trading partners, Native Americans and Europeans, provided the other a comparative advantage in the fur trade industry. The opportunity cost of hunting beavers in Europe was extremely high: by the seventeenth and eighteenth centuries, the Eurasian beaver was near extinction in England and France.[9] On the other hand, traders and trappers thought the wildlife in the New World was essentially limitless. Native Americans made use of the trade goods received, particularly knives, axes, and guns. The fur trade provided a stable source of income for many Native Americans until the mid-19th century, when changing fashion trends in Europe and a decline in the beaver population in North America brought about a collapse in demand for fur.[10]\\r\\nTrade with the Spanish Trading between Spanish settlers and Native Americans was rare and occurred in parts of New Mexico and California. The Spanish mainly intended to spread the Christian faith to Indians and to use them as slaves for work. The most significant effect of trading with the Spanish was the introduction of the horse to the Ute in New Mexico. Gradually, horses bred and their use was adopted across the Great Plains, dramatically altering the lifestyles and customs of many Native American tribes. Many Indians switched from a hunter- gatherer economy to a nomadic lifestyle after they began using horses for transportation. They had a greater range for hunting bison and trading with other tribes.[11]\\r\\nRelationship between Europeans and Indians It took time for Europeans and Native Americans to learn the customs of the other side. When Europeans first encountered a tribe, they would often be offered fur, food or other items as gifts. The Europeans did not understand they were supposed to take on an alliance with the natives, including helping them against their enemies. Native American tribes regularly practice gift giving as part of their social relations. Because the Europeans did not (or most of them), they were considered to be rude and crude.\\r\\nAfter observing that Europeans wanted to trade goods for the skins and other items, Native Americans entered into that. Both sides became involved in the conflicts of the other. In New France, in Carolina, Virginia, and New England and in New Netherland, the Europeans became drawn into the endemic warfare of their trading partners. As Native Americans were pressed into alliances by the Europeans for Queen Anne's War, the Seven Years' War, the Nine Years' War, and other standing competitions among the European powers: France, Great Britain and Spain, with whom they were dealing in North America, they felt drawn into the Europeans' endemic warfare.\\r\\nAfter the United States became independent, it enacted legislation to regulate trading with the Indians/Native Americans, under the Trade and Intercourse Act, first passed on July 22, 1790. Later the Indian Office, which was then part of the War Department, issued licenses to traders in the Indian Territory. Under removal, the largest tribes from the Southeast and north of the Ohio were moved west of the Mississippi river. By 1834 Indian Territory had been designated as what was then most of the United States west of the Mississippi, primarily what became Arkansas, Kansas and Oklahoma. Territories of the upper West were still occupied by native tribes as well. Mountain men and traders from Mexico freely operated there independently of the US.\\r\\nAfter the formation of the United States, the commerce clause of the constitution gave Congress the power to regulate Commerce with foreign Nations, and among the several States, and with the Indian tribes. In the 19th century, the American government passed legislation to support relocation of tribes to reservations in order to extinguish their title to lands that could be sold to European Americans. The Indian Removal Act of 1830 forced tribes such as the Cherokee and the Choctaw to move out of their homelands.[12] Resistance by Native Americans to relocate resulted in conflicts such as the Second Seminole War, that caused the deaths of 3000 Native Americans. Forcing tribes to relocate and to adjust to isolated reservations often unsuitable for the subsistence farming they were encouraged to undertake, made many of them dependent on the U.S. government for annuities and supplies. They had difficulty trying to develop economic systems of their own.[13]\\r\\nAs outlined by Kalt and Cornell in their book, What Can Tribes Do? Strategies and Institutions in American Indian Economic Development, on reservations, tribes lacked access to capital, were assigned to areas with poor natural resources (or had their resources stolen or kept from their control), and did not possess skilled labor.\\r\\nToday, many programs, such as the Harvard Project on American Indian Economic Development, exist to foster conditions that will help reservations become independent and financially stable communities. Since the late 20th century, many tribes have established gaming casinos. The most successful ones use part of the revenues for economic development of their nations, as well as for welfare and education for all their tribal members.\\r\\nN.p.: W.W. Norton &, 2011. Print.","input":"What was the first valuable use of horses for settlers in the new world?"},{"output":"philtrum","context":"The philtrum (Latin: philtrum, Greek: ? philtron, lit. \\"love charm\\"[2]), or medial cleft, is a vertical groove in the middle area of the upper lip, common to many mammals, extending in humans from the nasal septum to the tubercle of the upper lip. Together with a glandular rhinarium and slit-like nostrils, it is believed[by whom?] to constitute the primitive condition for mammals in general.\\r\\n\\r\\n\\r\\nIn most mammals, the philtrum is a narrow groove that may carry dissolved odorants from the rhinarium or nose pad to the vomeronasal organ via ducts inside the mouth.[3]\\r\\nFor humans and most primates, the philtrum survives only as a vestigial medial depression between the nose and upper lip.[4]\\r\\nThe human philtrum, bordered by ridges, also is known as the infranasal depression, but has no apparent function. That may be because most higher primates rely more on vision than on smell.[3] Strepsirrhine primates, such as lemurs, still retain the philtrum and the rhinarium, unlike monkeys and apes.[5]\\r\\nIn humans, the philtrum is formed where the nasomedial and maxillary processes meet during embryonic development. When these processes fail to fuse fully, a cleft lip may result.\\r\\nA flattened or smooth philtrum may be a symptom of fetal alcohol syndrome or PraderÿWilli syndrome.[6][7]\\r\\nA study of boys diagnosed with autism spectrum disorders found that a broader than average philtrum is one of a cluster of physical abnormalities associated with autism.[8]\\r\\nIn Jewish mythology, each embryo has an angel teaching them all of the wisdom in the world while they are in utero. The Angel lightly taps an infant's upper lip before birth, to silence the infant from telling all the secrets in the universe to the humans who reside in it; the infant then somewhat forgets the Torah they have been taught.[9] Some believers of the myth speculate that this is the cause of the philtrum, but it does not have a basis in traditional Jewish texts.[10]\\r\\nIn Philippine mythology the enchanted creature diwata (or encantado) has smooth skin, with no wrinkles even at the joints, and no philtrum.[11]\\r\\nIn Key Largo (1948), Frank McCloud (Humphrey Bogart) tells a fairy tale to a child, saying that, before birth, the soul knows all the secrets of heaven, but at birth an angel presses a fingertip just above one's lip, which seals us to silence.[12]\\r\\nIn the movie Mr. Nobody, unborn infants are said to have knowledge of all past and future events. As an unborn infant is about to be sent to its mother, the \\"Angels of Oblivion\\" lightly tap its upper lip, whereupon the unborn infant forgets everything it knows. The movie follows the life story of one infant, whose lip hadn't been tapped.[13]\\r\\nIn the movie The Prophecy, the Archangel Gabriel (Christopher Walken) asks Thomas Dagget, \\"Do you know how you got that dent in your top lip? Way back, before you were born, I told you a secret, then I put my finger there and I said 'Shhhhh!'\\"\\r\\nIn Action Comics #719 the Joker says a clue is right under Batman's nose. This leads him to a Dr. Philip Drum.[14]\\r\\nIn the book Prince Ombra by Roderick MacLeish, the \\"cleft on our upper lips\\" is attributed to being hushed by a \\"cavern angel\\" just before we are born.[15]","input":"What is the area above the lip called?"},{"output":"Star Wars: The Force Awakens","context":"Rey is a fictional character in the Star Wars franchise, portrayed by English actress Daisy Ridley. First appearing as the main character in Star Wars: The Force Awakens,[1][7][8][9] Rey is a scavenger who was left behind on the planet Jakku when she was a child, and later becomes involved with the Resistance's conflict with the First Order when her solitary life is interrupted by BB-8, the droid of ace Resistance pilot Poe Dameron, and a runaway Stormtrooper named Finn.\\r\\nScreenwriter Michael Arndt said that he found Lucasfilm President Kathleen Kennedy's offer to write the Star Wars sequel trilogy daunting in mid-2012, but he became interested when it was explained to him that the tale was about the origin story of a female Jedi and he met with George Lucas.[10] The character was a young woman known as Kira in the early stages of production, and Arndt described her as a \\"loner, hothead, gear-head, badass\\".[11] Arndt said that he struggled with introducing the young woman as the main character in his story while keeping her from being overshadowed after her early meeting with the Luke Skywalker character.[10] Ridley recalled that director and writer J. J. Abrams originally intended to name the character \\"Keera\\", however during filming in Abu Dhabi, Abrams revealed to Ridley that he was thinking of going with \\"Rey\\".[12]\\r\\nOn creating a female lead for the new trilogy, Abrams stated that from his initial discussions with writer Lawrence Kasdan, he was excited at the concept of having a woman at the center of the story. He said that \\"We always wanted to write Rey as the central character\\" and that other female representation in the story was also important.[1] Kennedy stated that, \\"Rey is the new generation's Luke Skywalker.\\"[13] Rey's background as a scavenger was part of the developers attempting to portray her as \\"the ultimate outsider and the ultimate disenfranchised person\\", due to their belief that a person of that nature would likely experience a prolonged journey compared to other types of people.[14]\\r\\nDaisy Ridley was largely unknown before being cast for the role of Rey. Ridley said that she auditioned many times for the role over the course of seven months and had to keep her casting a secret for three months.[15] She was announced as part of the cast at the end of April 2014. She only had experience with small parts in TV shows. Her inexperience and lack of exposure were a crucial part of what convinced Abrams to give Ridley the role, as the previous installments had featured relatively unknown talent that would not experience heightened degrees of scrutiny.[16] Abrams stated that Ridley \\"was so funny and had a great spark\\", as well as having her act out an emotional scene, proclaiming that \\"she nailed it on the first take.\\" Abrams would go on to praise Ridley, stating \\"She was born with this gift to be in a moment and make it her own. She simultaneously works from the inside out and the outside in.\\"[17] Kennedy proclaimed \\"Daisy had a physicality and a self-confidence that was so important to the character we were looking for. She epitomizes that optimism where anything is possible.\\"[17] Director Dusan Lazarevic, who was present at the casting of Ridley for a role in British drama series Silent Witness, in addition to praising her acting range, stated \\"She showed a combination of vulnerability and strength which gave her a complexity, and there was an intelligence in her eyes that was an indicator she could play quite a complicated part.\\"[16] Cailey Fleming was additionally cast to portray a young Rey.[2]\\r\\nAlthough Ridley expressed that she was \\"riddled with doubts and insecurities\\", she stated that Rey's hopefulness is what she related to most in Rey, going on to say it \\"was something driving me through the auditionseven though it felt so insanely out of anything that I could've imagined.\\"[18] Ridley recalled her shooting experience as starting off bumpy, with Abrams telling her that her first few takes were \\"wooden\\".[19] However, Ridley and Abrams had an \\"incredibly collaborative\\" process with creating Rey; Ridley recalled that the character \\"changed from when we first began, she became softer. And I think that's probably me, because Americans tend not to understand me, so it helped, slowing down the speech and everything just made it softer than I am.\\"[18] On her character, Ridley has stated that Rey will have \\"some impact in a girl power-y way\\", adding that the character \\"doesn't have to be one thing to embody a woman in a film. It just so happens she's a woman but she transcends gender. She's going to speak to men and women.\\"[20] In an interview with Elle, Ridley would continue describing her character, \\"She's so strong. She's cool and smart and she can look after herself,\\" adding \\"Young girls can look at her and know that they can wear trousers if they want to. That they don't have to show off their bodies.\\"[17]\\r\\nComposer John Williams said that he immediately loved Ridley in the film and that he found composing Rey's theme an interesting challenge. He said that her theme doesn't suggest a love theme, but rather a strong female adventurer character infused with the Force for a mature, thoughtful theme.[21] Williams expressed that the \\"musical grammar\\" of Rey's theme is not heroic, but instead conveys an adventurous tone that needs to illustrate empathy.\\"[22]\\r\\nRey is introduced as a 19-year-old woman in The Force Awakens.[23] Rey is stubborn, headstrong, brave, optimistic, and maintains fierce loyalty to her friends. In comparison to Luke, Matthew Yglesias of Vox said that \\"Rey is considerably less callow than Luke\\".[24][25]\\r\\nMegan Garber of The Atlantic argued that Rey \\"proves herself to be, in extremely short order, extremely adept as a fighter\\".[26] Rey is highly Force-sensitive, which is revealed when she is presented with the lightsaber first owned by Anakin Skywalker, then his son Luke Skywalker.[27] Without training, she is able to use advanced Force abilities and even defeat Kylo Ren in a duel, though he was already injured and using his power of the Dark side to fight being weakened by his pain.[28]\\r\\nRey lives alone on the planet Jakku, scraping a living through scavenging parts from ships while awaiting the return of the family that she was separated from as a child. She rescues the astromech droid BB-8 and encounters the runaway stormtrooper Finn. Attacked by First Order troops, Rey steals and pilots the Millennium Falcon to evade them and escape Jakku. The smuggler Han Solo and his partner Chewbacca capture the Falcon in their freighter ship. When dangerous gangs confront Han on the freighter, Rey mistakenly unleashes Han's vicious cargo. She saves Finn and they escape the freighter in the Falcon. Impressed with Rey, Han offers her a job on the Falcon; however, Rey declines his offer, feeling that she has to return to Jakku.\\r\\nAfter they convene at Maz Kanata's castle on the planet Takodana to return BB-8 to the Resistance, the First Order is alerted to their presence. Rey is drawn to the castle's basement vault in which Maz has stored a lightsaber that belonged to Luke Skywalker and his father before him. Upon touching it, she experiences a terrifying vision: she sees a battle led by Kylo Ren, a flashback of her younger self being left behind on Jakku, and a vision of Luke, the last Jedi Master in the galaxy, who has been missing for several years. Maz argues that whoever abandoned her will never return to Jakku, and her only option is to seek out strength in the Force. Feeling overwhelmed, Rey rejects the lightsaber and flees into the forest.\\r\\nThe First Order attacks Maz's castle, and Ren captures Rey when the Resistance arrives. Ren takes her to Starkiller Base, where he probes her mind for the map piece that BB-8 showed her. Ren uses the Force to read Rey's mind, revealing Rey feels that Han is like the father she never had. Rey then resists him and reads Ren's emotions, exposing his fear that he will never be as powerful as Darth Vader. Ren reports to his master, Supreme Leader Snoke, who commands that Rey be brought before him. Left alone with a stormtrooper guarding her, Rey uses a Jedi mind trick to get him to help free her. After sneaking around inside the base looking for a way to escape, she is elated to find Finn, Han, and Chewbacca have come for her. They watch in horror as Ren kills his own father, Han.\\r\\nAs they try to escape the base through the forest, Ren challenges Rey and Finn, using his lightsaber. After Ren seriously injures Finn and disarms him of Luke's lightsaber, Rey uses the Force to retrieve the weapon and battles the already wounded Ren. Initially overpowered, Rey rejects Ren's offer to train her and uses the Force with the lightsaber to defeat him. After escaping the destroyed planet in the Millennium Falcon with Chewbacca and the wounded Finn, she returns to the Resistance base. While the Resistance celebrates the victory, Rey mourns Han's death with Leia Organa and visits Finn, who is still unconscious. She decides to seek out Luke's location, using information provided by BB-8 and the re-activated R2-D2. Rey, Chewbacca, and R2 travel in the Falcon to the oceanic planet of Ahch-To; upon finding Luke, Rey presents him with his lost lightsaber.\\r\\nRey is featured in Star Wars: Before the Awakening (2015) by Greg Rucka, an anthology book for young readers that focuses on the lives of Poe, Rey and Finn before the events of The Force Awakens.[29] Rey's Survival Guide (2015) by Jason Fry is a first-person account from Rey's perspective about herself and her home planet of Jakku.[30] Rey is also a point of view character in the 2015 novelization of The Force Awakens by Alan Dean Foster.[31]\\r\\nFans noticed a lack of tie-in toys featuring Rey.[32] Hasbro released a version of Monopoly based on The Force Awakens that excluded the Rey character. After receiving criticism, Hasbro stated that they did not include Rey to avoid revealing spoilers, and would be including Rey in future toy releases.[33] Paul Southern, the head of Lucasfilm licensing, said that they wanted to protect the secrets that \\"the Force awakens in Rey\\" and that her character carries a lightsaber.[34] He said that demand for Rey products was underestimated.[35][36] Abrams said, \\"I will say that it seems preposterous and wrong that the main character of the movie is not well represented in what is clearly a huge piece of the Star Wars world in terms of merchandising.\\"[8] Regarding Rey's relative absence in Star Wars merchandising, CBBC presenter and voice actor Christopher Johnson stated: \\"It still baffles me to this day that some toy manufacturers don't think that girls want to play with 'superhero' toys and that boys aren't interested in female characters.\\"[37]\\r\\nRey is one of the central characters of The Last Jedi. Picking up directly where The Force Awakens left off, Rey presents Luke with his lightsaber, but Luke passively throws it aside and ignores Rey. She tells him that she has come on behalf of Leia and the Resistance to bring him home and end the fight against the First Order. Luke rejects this, and asks Rey why she personally came to Ahch-To. She confides in him her experiences with the Force, and tells him that she is afraid of her own abilities and potential. Luke eventually agrees to give Rey three lessons of the ways of the Force. Through these lessons, Rey demonstrates immense raw strength and a clear temptation toward the dark side of the Force that reminds Luke of Kylo Ren, who was once his nephew and student, Ben Solo. All the while, Rey feels a connection through the Force with Ren, who tells her that Luke tried to kill him while he was the Jedi masters student. (Luke later tells her that he was tempted to kill Ben after seeing a vision of the pain and suffering he would cause, but relented.) In one of their conversations, Rey and Ren touch hands, and through this Rey swears that she is able to feel conflict within Ren, and becomes determined to turn him back to the light side. Rey asks Luke once more to come with her and rejoin the Resistance, but when he refuses, Rey, Chewbacca, and R2-D2 leave without him.\\r\\nRen takes Rey prisoner and brings her before Snoke. Snoke tells her that he created the Force connection between her and Ren as a trap to reach Luke. Snoke tortures and taunts Rey, showing her the attack on the Resistance transports, and eventually orders Ren to kill her. Ren instead kills Snoke, and he and Rey fight Snoke's guards side by side. The duel won, Ren asks Rey to join him and create a new order separate from the legacies of Snoke and Luke, but Rey refuses. In an attempt to get her to turn, Ren reveals that Rey's parents were two-bit junk dealers who sold her off for drinking money, and are long dead. Despite the revelation, Rey refuses to join him and uses the Force to summon Luke's lightsaber, but Ren does so too, resulting in a standoff that ultimately tears the lightsaber in two. Shortly afterwards, Resistance leader Vice Admiral Holdo rams her cruiser into Snoke's ship, separating Rey from Ren.\\r\\nRey is later revealed to have made her way back to the Millennium Falcon, manning the guns as Chewbacca pilots, aiding the Resistance in fighting the First Orders troops. Despite their best efforts, the battle turns out to be a loss for the Resistance, and Rey focuses her efforts on finding the surviving Resistance fighters to help evacuate them. Eventually she finds the Resistance fighters behind a dead end, and uses the Force to move the rocky barrier aside, clearing the path for them to board the Falcon. Rey reunites with Finn and Leia, and meets Poe Dameron for the first time aboard the Falcon. Rey feels Lukes death through the Force, and reassures Leia that he met his end with \\"peace and purpose\\". Rey asks Leia how they can rebuild the Resistance from what remains, and Leia, gesturing towards Rey, says that they now have all they need. Unknown to Leia, that includes the fact that Rey stole ancient Jedi books from Luke before he decided to burn them, thus enabling her to learn the ways of the order by herself.\\r\\nRey stars in the micro-series Star Wars Forces of Destiny, voiced by Daisy Ridley.[3]\\r\\nThe character of Rey appears in the video games Disney Infinity 3.0 and Lego Star Wars: The Force Awakens, both voiced by Ridley,[38] as well as the strategy video game Star Wars: Force Arena.[39]\\r\\nThe character and Ridley's performance have received critical acclaim. Joe Morgenstern of The Wall Street Journal proclaimed that Rey is \\"a woman warrior with the stylish ferocity of a kung-fu star\\", praising \\"the verve [Ridley] must have been born with plus the skill she must have acquired as a young actress coming up in England\\", later adding \\"It's hard to imagine what the movieand the sequels to comemight have been if they'd cast the wrong person, but here Daisy Ridley is in all her unassuming glory, and all's right with the galaxy\\".[40] Adam Howard of MSNBC stated that \\"one of the most pleasant surprises of the film has been the strength of its lead female character\\", adding that some have likened Rey to a \\"new feminist icon\\".[41] Relatedly, Emily Rome of HitFix argued that Rey is \\"everything we wanted in a Star Wars female character\\", praising her for being a character that is \\"independent, skilled, scrappy, tough, and doesn't need saving\\".[42] In a personal essay, Nicole Sperling of Entertainment Weekly wrote about her daughters feeling empowered after viewing the film, stating, \\"They never commented on how pretty Rey is. They never had to flinch because Rey was a sexual object to some man in power. They just felt strong. Equal\\".[43]\\r\\nSome fans expressed opinions that Rey is too skilled, despite her inexperience during The Force Awakens, making her a \\"Mary Sue\\"-type character.[44] Rome wrote that \\"the speed with which Rey mastered Jedi mind tricks and lightsaber fighting with zero training is the stuff of fan fiction. Rey is geek feminist wish-fulfillment\\".[42] Tasha Robinson of The Verge said that Rey \\"keeps falling into standard-issue damsel-in-distress situations, then capably rescuing herself\\".[45] Robinson conceded, \\"let's face it, Rey is kind of a Mary Sue character\\". However, Robinson went on write: \\"She's a fantasy wish-fulfillment character with outsized skills, an inhuman reaction time, and a clever answer to every questionbut so are the other major Star Wars heroes.\\"[45] Other outlets have argued that the term Mary Sue carries an inherent gender bias,[46] and that categorizing Rey as one holds her to a double standard as the male characters from the original trilogy did not face comparable criticism.[47] Caroline Framke of Vox wrote \\"While my kneejerk reaction to criticism of Rey was that it's absolutely in the wrong, I have to admit that questioning her merits isn't inherently misogynistic. The real problem is that there's an undeniable false equivalence at play\\".[46]\\r\\nRey's unique hairstyle attracted attention before and after The Force Awakens was released,[48] being compared to Leia's hairdo during the original trilogy with debate over whether it would become as popular.[49]\\r\\nRichard Roeper described Ridley's portrayal of Rey as \\"a breakout performance\\", continuing by calling the character \\"tough and resourceful and smart and brave\\".[50] Ridley was nominated for a 2016 Saturn Award for Best Actress for her portrayal.[51] The first Reel Women in Technology Award for a fictional character was awarded to the character Rey.[52]\\r\\nThe question of Rey's parentage has been a significant point of discussion for the series, and has spawned numerous fan theories.[53][54] The most popular theories are that she is the daughter of Luke Skywalker or Han Solo, or is Obi-Wan Kenobi's granddaughter (because of a scene where Rey hears Kenobi's echoed voice following a vision in The Force Awakens).[53][55][56] The view that she is Luke's daughter is especially prominent, with fans and critics highlighting their story arc similarities, Star Wars being a Skywalker saga, Rey having a strong attachment to Luke's lightsaber, and being exceptionally strong with the Force without any training.[55][56][57] Some fan theories about Rey's parentage pointed to \\"Rey's Theme\\" featured in John Williams' score of The Force Awakens, as the theme shared similarities with the themes for Darth Vader and Luke.[58]\\r\\nAbrams stated that he intentionally withheld Rey's last name and background in The Force Awakens.[59] He said that he felt that the origin of Kylo Ren was the only thing that could be revealed in his film and that he knows \\"quite a bit\\" about Rey's origin but would give courtesy to Star Wars: The Last Jedi director Rian Johnson by not saying any more.[10][60] Former Star Wars: Episode IX director Colin Trevorrow stated that the answer of Rey's origin will be \\"deeply and profoundly satisfying\\" and that Rey is \\"important in this universe, not just in the context of The Force Awakens, but in the entire galaxy. She deserves it.\\"[61] Ridley said that she knows who Rey's parents are.[15]\\r\\nIn The Last Jedi, Kylo Ren tells Rey that her parents were nobodies that sold Rey for drink money and that she had always known this deep down.[62] Todd VanDerWerff of Vox equated this scene with Luke finding out that Darth Vader is his father, which was his greatest nightmare.[62] To VanDerWerff, \\"Rey's greatest nightmare is being no one.\\" He added that Kylo Ren \\"has every reason to be lying\\" in this instance because \\"he's trying to get Rey to let the pastJedi, Sith, Rebellion, Empire, First Order, etc., etc., etc.crumble to dust,\\" but that \\"in a weird way, it's a kind of meta-commentary on a franchise that is seeking a new future, while still being indebted enough to its past that it continually recycles itself.\\" He said that it \\"is great\\" that \\"Rey is the child of nobody of particular importance to the story so far.\\"[62] Josh Spiegel of The Hollywood Reporter stated that although some fans may be disappointed by the reveal that Rey's parents are nobodies, \\"it fits in perfectly with the message Rian Johnson sends all the way to the very last scene\\" which is that \\"knowing that Rey is both exceptionally gifted in the Force and also not a Skywalker or someone along those bloodlines emphasizes\\" that \\"the spirit of the Jedi extends beyond those like Luke, to anyone with a gift and the power to believe.\\"[63]\\r\\nConversely, although Casey Cipriani of Bustle recognized that Kylo Ren might be right about Rey's parents, she opined that he is \\"unreliable\\" and that \\"we have to take what he says with a grain of salt and look elsewhere [within the story] for hints of Rey's lineage.\\"[57]","input":"When did rey first appear in star wars?"},{"output":"Karen Horney","context":"Feminist psychology is a form of psychology centered on social structures and gender. Feminist psychology critiques historical psychological research as done from a male perspective with the view that males are the norm.[1] Feminist psychology is oriented on the values and principles of feminism.\\r\\nGender issues can include the way people identify their gender (male, female, genderqueer; transgender or cisgender), how they have been affected by societal structures related to gender (gender hierarchy), the role of gender in the individual's life (such as stereotypical gender roles), and any other gender related issues. The objective behind this field of study is to understand the individual within the larger social and political aspects of society.[2] Feminist psychology puts a strong emphasis on women's rights. Psychoanalysis took shape as a clinical or therapeutic method, feminism as a political strategy (Buhle, 1998).\\r\\n\\r\\n\\r\\nThe term feminist psychology was originally coined by Karen Horney. In her book, Feminine Psychology, which is a collection of articles Horney wrote on the subject from 1922ÿ1937, she addresses previously held beliefs about women, relationships, and the effect of society on female psychology.\\r\\nThe beginning of psychology research presents very little in the way of female psychology. Many women did not fight against oppression because they did not realize they were oppressed in the first place (Ruck, 2015). Once the functionalist movement came about in the United States, academic psychology's study of sex difference and a prototypic psychology of woman were developed.[3]\\r\\nIn 1942 Edward Strecker made \\"mom-ism\\" an official pathological syndrome under the APA. He believed that the country was under threat because mothers weren't emotionally disconnecting from their children at a young enough age, and the matriarchy was making young men weak and losing their \\"man power\\". This fueled that anti-feminist movement; women were in need of psychotherapy to aid their mental illness and further prevent the spread of maternalism. The psychological damage on the family would be severe if a woman chose a career to satisfy her needs as opposed to her feminine domestic role assigned by society ÿ a woman's happiness was not important, she must follow her role. The effect of women having independent thoughts and a thirst for exploring her options was a huge threat to gender, as it resulted in masculinized women and feminized men, apparently confounding the nation's youth and dooming their future. Constantinople and Bem both agreed that men and women possess masculinity and femininity, and that having both is being psychologically androgynous and a cause to be psychologically fixed or evaluated.\\r\\nEsther Greenglass states that in 1972, the field of psychology was still male-dominated, women were totally excluded. The use of the word women in conjunction with psychology was forbidden, men refused to be excluded from the narrative. In her experience of teaching class, or being assistant professors, they had to phrase it in the interest of human beings or gender. Unger's paper \\"Toward a Redefinition of Sex and Gender\\" said that the use of gender showed the separation of biological and psychological sex. Psychology of women is feminist because it says women are different from men and that women's behavior cannot be understood outside of context. Feminists in turn compelled psychoanalysts to consider the implications of one of Freud's own, most uncompromising propositions: \\"that human beings consist of men and women and that this distinction is the most significant one that exists\\" (Buhl, 1998). In Liberating Minds: Consciousness-Raising as a Bridge Between Feminism and Psychology in 1970s Canada, Nora Ruck leads with, \\"U.S. radical feminist Irene Peslikis warned that equating women's liberating with individual therapy prevented women from truly understanding and fighting the roots of their oppression\\". Canada was one of the few countries with an academic category within psychology for feminism. They relied on CR (consciousness raising) groups to build their movement. Ruck describes the process of these CR groups by \\"bridging the tensions\\" between the personal and political. The development of CR as a political method in its own right is widely attributed to the New York-based radical feminist collective \\"Redstockings\\" (Echols, 1989). CR is also closely tied with radical feminism, which aims to weed out discrimination and segregation based on sex, and through a grassroots movement like socialist feminism, maintains that women's oppression is not a by-product of capitalist oppression but a \\"primary cause\\" (Koedt, 1968).\\r\\nWomen were excluded from Freud's definition of mental health (the ability to love and to work) because women wanting jobs was attributed to a masculinity complex or envy of men. Between 1970 and 1980 the percentage of women working outside the home had risen from 43 to 51, in the United States. Although women reported having difficulty juggling the roles of mother and provider, they found a way to be fulfilled void of childbearing (Buhle, 1998). Women continue to be a large percentage of the workforce in psychological positions. In 2005, 58.2 percent of the psychological positions in the United States of America were held by women, and as of 2013 it is now 68.3 percent (APA, 2013). This resulted in 2.1 women in the workforce for every 1 man, a drastic shift from Freuds previous school of thought on women in the workforce (APA, 2013). The workforce does consider semi-retired psychologists as well; however, women still overtake men when comparing active psychologists, and have less percentage than men for semi-retired and retired psychologists (APA, 2013). The Committee on Women in Psychology (CWP), was founded in 1973. It was founded with the mission of  to advance psychology as a science and a profession  by ensuring that women in all their diversity achieve equality within the psychological community and in the larger society (APA, 2017). There are also journals that focus on women in psychology, such as SAGE, which is recognized by the APA (SAGE, 2017). SAGE journal publishes articles about the mental health of women in the workforce, and what it is like for single mothers in the country, all of which are common topics in feminism as it is (SAGE, 2017). These movements that have occurred over time show a clear shift in culture from Freuds original philosophy on mental health, where women are not only included, but are also part of every aspect of the workforce of psychology. The APA Leadership Institute for Women in Psychology emerged to support and empower women in psychological fields. Women such as Cynthia de las Fuentes are not only pushing for feminist psychology to be a more popular topic, but also do research in why some might be moving away from feminism, and by extension, feminism psychology (APA, 2006).\\r\\n\\r\\nThe Association for Women in Psychology (AWP) was created in 1969 in response to the American Psychological Association's apparent lack of involvement in the Women's Liberation Movement.[4] The organization formed with the purpose of fighting for and raising awareness of feminist issues within the field of psychology. The association focused its efforts toward feminist representation in the APA and finally succeeded in 1973 with the establishment of APA Division 35 (the Society for the Psychology of Women).\\r\\nAPA Division 35, the Society for the Psychology of Women,[4] was established in 1973.[5] It was created to provide a place for all people interested in the psychology of women to access information and resources in the field. SWP works to incorporate feminist concerns into the teaching and practice of psychology. Div 35 also runs a number of committees, projects, and programs.\\r\\nThe Canadian Psychological Association (CPA) has a section on Women and Psychology (SWAP), which is meant \\"to advance the status of women in psychology, promote quity for women in general, and to educate psychologists and the public on topics relevant to women and girls.\\"[6] SWAP supports projects such as Psychology's Feminist Voices.[7] The Journal of Diversity in Higher Education expresses that female psychologists are often considered to be inefficient due to their low contribution in scientific productivity. Hence, women tend to dominate in low level positions than their male counterparts even if they acquire their doctoral degrees.[8] \\"They did not show any acknowledgement or appreciation that there was a difference and that there was a need for it, and that was around the time that we were giving a course here interdisciplinary, not in psychology. I still didn't have a course here because they wouldn't let me do it. And the men pretty well called the shots when they told you, you can't do it, you just, you don't do it.\\" (Greenglass, 2005).\\r\\nThe Psychology of Women Section (BPS),[9] of the British Psychological Society was created in 1988 to draw together everyone with an interest in the psychology of women, to provide a forum to support research, teaching and professional practice, and to raise an awareness of gender issues and gender inequality in psychology as profession and as practice. POWS is open to all members of the British Psychological Society.\\r\\nA major topic of study within feminist psychology is that of gender differences in emotion. In general, feminist psychologists view emotion as culturally controlled and state that the differences lie in the expression of emotion rather than the actual experience.[10] The way a person shows his or her emotions is defined by socially enforced display rules which guide the acceptable forms of expression for particular people and feelings.[10]\\r\\nStereotypes of emotion view women as the more emotional sex. However, feminist psychologists point out that women are only viewed as experiencing passive emotions such as sadness, happiness, fear, and surprise more strongly. Conversely, men are viewed as more likely to express emotions of a more dominant nature, such as anger.[11] Feminist psychologists believe that men and women are socialized throughout their lifetimes to view and express emotions differently. From infancy mothers use more facial expression when speaking to female babies and use more emotion words in conversation with them as they get older.[11]\\r\\nGirls and boys are further socialized by peers where girls are rewarded for being sensitive and emotional and boys are rewarded for dominance and lack of most emotional expression.[11] Psychologists have also found that women, overall, are more skilled at decoding emotion using non-verbal cues. These signals include facial expression, tone of voice, and posture.[12] Studies have shown gender differences in decoding ability beginning as early as age ?3?1?2.[11] The book Man and Woman, Boy and Girl looks at intersex patients in explaining why social factors are more important than biological factors in gender identity and gender roles and brought nature vs nurture issues back into the spotlight (Money & Ehrhardt, 1972).\\r\\nSocial scientists in many disciplines study aspects of the \\"glass ceiling effect\\", the invisible yet powerful barriers that prevent many women from moving beyond a certain level in the workplace and other public institutions.[13] According to the U.S. Department of Labor, women in the United States comprised 47% of the workforce in 2010.[14] However, there are only a small number of women with high held positions in corporations. Women constitute only 5% of Fortune 500 CEOs (in 2014)[15] and 19% of board members of S&P500 companies (in 2014),[16] and 26% of college presidents.[17] In 2017 U.S. government bodies, women comprise 19.1% of U.S. Representatives, 21% of U.S. Senators, 8% of state governors, and similarly low percentages of state elected officials.[18] Women of color have lower representation than white women.[19] The U.S. lags behind other countries in gender parity in government representation; according to the Global Gender Gap Report of 2014, the U.S. ranked 33 out of 49 so-called \\"high-income\\" countries, and 83rd out of the 137 countries surveyed.[20][21] \\"Women affiliated with the American Academy of Psychoanalysis were among the first to pursue such subjects as women's fear of success and inclinations toward neurotic dependency. They acknowledged the cultural forces inhibiting women's progress in nondomestic realms, particularly the pressures inherent in a male-dominated society\\" (Buhl, 1998). Much scholarship focuses on structural features inhibiting women's progress in public spheres, rather than locating the source of the issue on women themselves.\\r\\nIn addition, women experience a \\"sticky floor effect\\". The sticky floor effect happens when women have no job path or ladder to higher positions. When women have children they experience a roadblock called the maternal wall. The maternal wall is when women receive fewer desirable assignments and fewer opportunities for advancement after they have a child. The patriarchy labels women as \\"nourishing facilitators\\" making them not mentally strong enough to take part in the aggressive male-dominated workforce without taking psychological and emotional hits (Buhl, 1998). When women begin working at a company, their advancement can be limited by not having a senior level employee taking an active role in the development and career planning of junior employees. There are a lack of female mentors to assist new female employees because there are fewer women than men in higher level company positions. A woman with a male mentor could experience difficulty in gaining bonding and advice from out of work experiences. This is because men play basketball or golf and typically exclude women from these endeavors. Other factors limiting leadership for women are cultural differences, stereotypes, and perceived threats. If women show a small amount of sensitivity, they are stereotyped as being overly emotional. Generally, employers do not accept sensitive, soft people as being able to tackle tough decisions or handle leadership roles. However, if a woman displays male traits she is portrayed as mean, butch, and aggressive. Women are viewed as less competent when they showcase non-\\"feminine\\" traits and are not taken seriously. These women don't brag about their accomplishments and feel guilty for being able to go beyond stereotypes of feminine emotion and thought in order to become masculine in their jobs, just to be successful or try and be equal to men. Career women, whose professional status depends on the appropriation of masculine traits, frequently suffer from depression (Buhl, 1998). Recent research has connected the concept of stereotype threat with girls' motivations to avoid success as an individual difference, girls might avoid participation in certain male-dominated fields due to real and perceived obstacles to success in those fields, although there is little that can be proven (e.g., Spencer et al. 1999).\\r\\nAnother factor leading to discrimination and stress are cultural differences between managers and workers. For example, if a manager is white and has an employee of color, stress may be created if they do not understand or respect each other. Without trust and respect, advancement is unlikely. Our depiction of gender identity is white and middle class. White women are described as intelligent, manipulative, and privileged by Black women, who are described as strong, determined, and having attitude (Burack, 2002). \\"There it is, White fear of Black anger\\", was written in Ladies Home Journal (Edwards 1998: 77). Regarding perceived threats at work, it is not a matter of sexual harassment or harassment in general. The threat is the fact that women could possibly take over. The more women working in a place of employment, the increased threat a man feels over job security. In a study of 126 male managers, when asked to estimate the number of women working at their place of employment and whether or not they felt men were disadvantaged. Men who believed there were many women felt threatened about the security of their job (Beaton et al., 1996). Alice Eagly and Blair Johnson (1990) discovered that men and women have different small differences in their styles of leadership. Women in power were seen as interpersonal and more democratic, whereas men were seen as task-oriented and more autocratic. In reality, men and women are equally effective in their styles of leadership. A study by Alice Eagly (Eagly, Karau, & Makhijani, 1995) found no overall differences in the effectiveness of male and female leaders in facilitating accomplishment of their group goals.[22][23][24][25]\\r\\nHerman (1996) has shown that feminists relied on the psychological notion of \\"trauma\\" to criticize institutions like the family, to protect the children, to argue for revised policies, and to fight against male violence against women and children. Feminists argue that gender-based violence occurs frequently in the forms of domestic violence, sexual harassment, childhood sexual abuse, sexual assault, and rape. Violence towards women can be physical or psychological and is not limited by race, economic status, age, ethnicity, or location. Women can be abused by strangers but often the abuser is someone the woman knows. Violence can have both short- and long-term effects on women, and they react to the abuse in various ways. Some women express emotions such as fear, anxiety, and anger. Others choose to deny it occurred and conceal their feelings. Often, women blame themselves for what happened and try to justify that they somehow deserved it. Among victims of violence, psychological disorders such as post traumatic stress disorder and depression are common. In addition to the psychological ramifications, many women also sustain physical injuries from the violence that require medical attention.[26][27][28]\\r\\nRelational-cultural theory is based on the work of Jean Baker Miller, whose book Toward a New Psychology of Women proposes that \\"growth-fostering relationships are a central human necessity and that disconnections are the source of psychological problems.\\"[29] Inspired by Betty Friedan's Feminine Mystique, and other feminist classics from the 1960s, relational-cultural theory proposes that \\"isolation is one of the most damaging human experiences and is best treated by reconnecting with other people\\", and that therapists should \\"foster an atmosphere of empathy and acceptance for the patient, even at the cost of the therapist's neutrality\\".[30] The theory is based on clinical observations and sought to prove that \\"there was nothing wrong with women, but rather with the way modern culture viewed them\\".[31]\\r\\nFeminist therapy is a type of therapy based on viewing individuals within their sociocultural context. The main idea behind this therapy is that the psychological problems of women and minorities are often a symptom of larger problems in the social structure in which they live. There is a general agreement that women are more frequently diagnosed with internalizing disorders such as depression, anxiety, and eating disorders than men.[1] Feminist therapists dispute earlier theories that this is a result of psychological weakness in women and instead view it as a result of encountering more stress because of sexist practices in our culture.[1] A common misconception is that feminist therapists are only concerned with the mental health of women. While this is certainly a central component of feminist theory, feminist therapists are also sensitive to the impact of gender roles on individuals regardless of sex. Goldman found the connection between psychoanalysis and feminism as the recognition of sexuality as preeminent in the makeup of women as well as men. Freud found that men's ideology was forced onto women in order to sexually repress them, connecting the public and private spheres for the subjugation of women (Buhle, 1998). The goal of feminist therapy is the empowerment of the client. Generally, therapists avoid giving specific diagnoses or labels and instead focus on problems within the context of living in a sexist culture. Clients are sometimes trained to be more assertive and encouraged to understand their problems with the intent of changing or challenging their circumstances.[11] Feminist therapists view lack of power as a major issue in the psychology of women and minorities. Accordingly, the client-therapist relationship is meant to be as egalitarian as possible with both sides communicating on equal ground and sharing experiences.[12]\\r\\nFeminist therapy is different than other types of therapy in that it goes beyond the idea that men and women should be treated equally in the therapeutic relationship. Feminist therapy incorporates political values to a greater extent than many other types of therapy. Also, feminist therapy encourages social change as well as personal change in order to improve the psychological state of the client and society.[1]\\r\\nMany traditional therapies assume that women should follow sex-roles in order to be mentally healthy. They believe gender differences are biologically based and encourage female clients to be submissive, expressive, and nurturant in order to achieve fulfillment (Worell & Remer, 1992). Psychotherapy is a male-dominated practice and supports women's adjustment to stereotypical gender roles instead of women's liberation (Kim & Rutherford, 2015). This may be done unconsciously by the therapist ÿ for example, they may encourage a female to be a nurse, when they would have encouraged a male client of the same abilities to be a doctor, but there is the risk that the goals and outcomes of therapy will be evaluated differently in accordance with the therapist's beliefs and values. Inequality between the sexes and restrictions on sex roles are perpetuated by evolutionary psychology, but we could understand the role of gender in scientific communities by using feminist research strategies and admitting to gender bias (Fehr, 2012).\\r\\nTraditional therapies are based on the assumption that being male is the norm. Male traits are seen as the default, and stereotypically male traits are seen as more highly valued (Worell & Remer, 1992; Hegarty & Buechel, 2006). Men are considered the standard of comparison when comparing gender differences, with feminine traits viewed as a deviation from the norm and a deficiency on the part of women (Hegarty & Buechel, 2006).) Psychological theories of female development were written by men who are completely uninformed by women's actual experiences and the conditions under which they lived (Kim & Rutherford, 2015).\\r\\nTraditional therapies place little emphasis on sociopolitical influences, focusing instead on the client's internal functioning. This can lead therapists to blame clients for their symptoms, even if the client may in fact be coping admirably in a difficult and oppressive situation (Worell & Remer, 1992). Another possible issue can arise if therapists pathologize normal responses to oppressive environments (Goodman & Epstein, 2007).\\r\\nThis principle stems from the belief that psychological symptoms are caused by the environment. The goal of the therapist is to separate the external from the internal so the client can become aware of the socialization and oppression they have experienced, and attribute their problems to the appropriate causes (Worrel & Remer, 1992).). Feminist stance is largely marginalized and seen as standing outside of mainstream psychiatry, and there is the power-based distribution of knowledge, which gives therapists the ability to label women's disorders without knowing their lived experiences (Sawicki, 1991).\\r\\nTherapists do not view their client's cognitions or behaviors as maladaptive ÿ indeed, symptoms of depression or PTSD are often considered to be the normal, rational response to oppression and discrimination (Goodman & Epstein, 2007). Traditional therapies place little emphasis on sociopolitical influences, focusing instead on the client's internal functioning. This can lead therapists to blame clients for their symptoms, even if the client may in fact be coping admirably in a difficult and oppressive situation (Worell & Remer, 1992). Another possible issue can arise if therapists pathologize normal responses to oppressive environments (Goodman & Epstein, 2007).\\r\\nFeminist therapists consider power inequalities to be a major contributing factor to the struggles of women, and as such criticize the traditional therapist role as an authority figure. Feminist therapists believe interpersonal relationships should be based in equality, and view the client as the \\"expert\\" in their own experiences. Therapists emphasize collaboration, and use techniques such as self-disclosure to reduce the power differential (Worrel & Remer, 1992).\\r\\nThe goal of feminist therapy is to re-value feminine characteristics and perspectives. Often, women are criticized for breaking gender norms while simultaneously being devalued for acting feminine. In order to break this double bind, therapists encourage women to value the female perspective and self-define themselves and their roles. In doing so, clients can value their own characteristics, bond with other women, and embrace traits that had previously been discouraged (Worrel & Remer, 1992).\\r\\nOne component of feminist therapy involves a critique of cultural conditioning that produces and maintains socially biased structures (Ballou & Gabalac, 1985). From birth, women are taught which behaviors are appropriate, and face sanctions if they fail to conform. These gender stereotypes are taught explicitly or implicitly by the family, media, school, and the workplace, and lead to gender-related belief systems and self-imposed expectations (Worell & Remer, 1992).\\r\\nBefore women can be free of these expectations, they need to gain an understanding of the social systems that molded and encouraged these gender stereotypes, and how this system impacted their mental health. First, women work to identify the gendered messages they've received, as well as the consequences. Then, women explore how these messages have been internalized, and decide which rules they would like to follow and which behaviors they would prefer to change (Worrel & Remer, 1992).\\r\\nPower systems are organized groups that have legitimized status, that are sanctioned by custom or law, that have the power to set the standards for society. In Western society, women are expected to conform to the power systems that place them as submissive and inferior to men (Ballou & Gabalac, 1985). Types of power include the legal, physical, financial, and institutional ability to exert change. Often, men control direct power via concrete resources, while women are left to use indirect means and interpersonal resources. Also, sex-roles and institutionalized sexism play a role in limiting the power women have (Worrel & Remer, 1992).\\r\\nPower analysis is the technique used to examine the power differential between women and men, and to empower women to challenge the interpersonal and institutional inequalities they face (Worrel & Remer, 1992).\\r\\nTraditionally, assertiveness is a masculine trait, so frequently women struggle with learning to stand up for their rights. Feminist therapists work to help women distinguish assertive behaviors from passive or aggressive ones, overcome beliefs that tell women they cannot be assertive, and help women rehearse assertiveness skills through role play (Worrel & Remer, 1992).\\r\\nThe biggest feminist critique of cognitive-behavioral therapy is that the theory fails to focus on how behaviors are learned from society (NetCE, 2014). Often, the focus is on encouraging women to change their \\"maladaptive\\" responses and conform to normative standards. By putting the onus on the woman to change her thoughts and behaviors, instead of changing the environmental factors that give rise to the problems, the theory fails to question the social norms that condone the oppression of women (Brown & Ballou, 1992). Despite this, feminist therapists do use cognitive-behavioral techniques to help women change their beliefs and behaviors, in particular using techniques such as sex-role analysis or assertiveness training (Brown & Ballou, 1993; NetCE, 2014).\\r\\nMany psychoanalytic concepts are considered by feminist therapists to be sexist and culturally-bound (NetCE, 2014). However, feminist psychoanalysis adapts many of the ideas of traditional psychotherapy, including the focus on early childhood experiences and the idea of transference. Specifically, therapists serve as a mother figure and help clients connect emotionally with others while maintaining an individuated sense of self (NetCE, 2014).\\r\\nThe main critique of family systems therapy is the endorsement of power imbalances and traditional gender roles. For example, family systems therapists often respond to men and women differently, for example placing more importance on the man's career or placing the responsibility for childcare and housework on the mother (Braverman, 1988).\\r\\nFeminist therapists strive to make the discussion of gender roles explicit in therapy, as well as focusing on the needs of and empowering the woman in her relationship (Braverman, 1988). Therapists help couples examine how gender role beliefs and power dynamics lead to conflict. The focus is on encouraging more egalitarian relationships and affirming the women's experiences (NetCE, 2014).\\r\\nA feminist approach to dealing with rape or domestic abuse is focused on empowerment. Therapists help clients analyze societal messages about rape or domestic abuse that encourage a victim-blaming attitude, and try to help clients get past shame, guilt, and self-blame. Often, women do not know the true definitions of abuse or rape, and don't immediately identify themselves as victims (Worrel & Remer, 1992).\\r\\nSurvivors often face negative reactions from others that lead to re-victimization when trying to seek help, so therapists can help the woman navigate the medical and legal services if she wishes. At all times, although safety is the main concern, the therapist empowers the woman to explore her options and make her own decisions (for example, to leave the relationship or stay following an attack) (Worrel & Remer, 1992).\\r\\nIt is emphasized that any symptoms are in fact normal responses to the traumatic effect, and the women is not pathologized. Both rape and domestic violence are not viewed as something one can recover from, but are instead viewed as experiences that one can integrate into one's life story as one restructures one's self-esteem and self-confidence (Worrel & Remer, 1992).\\r\\nOccupational choice is a main theme in feminist counseling. Women are more likely to earn less than men, and are overrepresented in lower-status occupations (Worrel & Remer, 1992). Several factors influence this career trajectory, including gender-role stereotyping of which jobs are appropriate for men and women. Women are often pointed towards nurturing jobs, while leadership jobs are reserved for men (Worrel & Remer, 1992).\\r\\nInstitutionalized sexism in the educational system often encourages girls to study traditionally feminine subjects while discouraging them from studying math and science. Discriminatory hiring practices also reflect the attitude that men should be the breadwinner and women are a riskier choice because their work will be disrupted once they have children (Worrel & Remer, 1992).\\r\\nThese societal messages often lead to internalized negative messages, including lower self-confidence and self-esteem, lower levels of assertiveness and willingness to negotiate, and the imposter syndrome, where women believe they do not deserve success and are merely lucky (Worrel & Remer, 1992).\\r\\nWhen women do seek nontraditional employment, they are placed in a double bind, where they are expected to be competent at their job while simultaneously being feminine. Especially for women in male-dominated fields, trying to be competent and successful as a woman is difficult (Howard, 1986).\\r\\nFeminist therapists work with women in search of counseling, as well as men, for help in alleviating a variety of mental health concerns. Feminist therapists have an interest in gender and how multiple social identities can impact an individual's functioning. Psychologists or therapists who identify with the feminism, the belief that women and men are equals, and/or feminist psychological theory may call themselves feminist therapists. Currently, there are not many postdoctoral training programs in feminist psychology, but models for this training are being developed and modified for institutions to start offering them.[32] Most of this training is modeled around gender-fair counseling techniques.[2]","input":"Who is often considered the first feminist psychologist?"},{"output":"Forged from the Love of Liberty","context":"\\"Forged from the Love of Liberty\\" is the national anthem of the Republic of Trinidad and Tobago. Originally composed as the national anthem for the short-lived West Indies Federation (1958ÿ1962), this song was edited and adopted by Trinidad and Tobago when it became independent in 1962.[1]\\r\\nPatrick S. Castagne composed the words and music of the National Anthem in 1962.[2] Mr Castagne, a renowned West Indian songwriter, was employed at the Trinidad and Tobago Commission in London.[1] One of his compositions, called \\"A Song for the Islands\\"[2] or A Song for Federation,[1] was submitted to the West Indies Federation as a possible anthem.[2]\\r\\nWhen the Federation collapsed, he changed some of the lines and resubmitted the song to Trinidad and Tobago[2] for the competition to choose the National Anthem. In total, the competition received 834 word only entries, 33 music only entries and 306 word and music entries. Mr. Castagne's submission came out on top and he won the price of $5,000.00 in Government Bonds and a gold medal inscribed with the Coat of Arms of Trinidad and Tobago.[1]\\r\\nCastagne's alteration of A Song for Federation was deemed to be most suitable for a twin-island state that consisted of \\"islands of the blue Caribbean Sea\\" standing \\"side by side\\" in promoting the values of \\"every creed and race\\" finding \\"an equal place\\" in the multi-racial, multi-religious and multi-cultural society of Trinidad and Tobago as it existed in 1962.[1] It was considered to have reflected the nature and the strength of the people of Trinidad and Tobago and their courage as one nation working towards living in unity despite the existing diversity.[2] According to an excerpt from the editorial in the Sunday Guardian of 19 August 1962: \\"In its solemn declaration of brotherhood and unity, it very neatly includes Tobago with Trinidad without mentioning the name of either (\\"Side by side we stand, islands of the blue Caribbean Sea\\"); and as an added impulse to unity it goes on to describe them together as \\"our native land,\\" ending with the petition, \\"And may God bless our nation.\\"[1]\\r\\nWords and music by Patrick Castagne (1916ÿ2000).[3]\\r\\nCastagnes A Song For Federation provided the musical inspiration that could have matched the foundation of a strong federation had it survived. The close resemblance between the National Anthem of Trinidad and Tobago and A Song For Federation can seen from the lyrics of the latter as follows:[1]","input":"What is the national anthem of trinidad and tobago?"},{"output":"develop from one zygote","context":"Twins are two offspring produced by the same pregnancy.[1] Twins can be either monozygotic (\\"identical\\"), meaning that they develop from one zygote, which splits and forms two embryos, or dizygotic (\\"fraternal\\"), meaning that they develop from two different eggs. In fraternal twins, each twin is fertilized by its own sperm cell.[2]\\r\\nIn contrast, a fetus that develops alone in the womb is called a singleton, and the general term for one offspring of a multiple birth is multiple.[3] Non-related look-alikes whose resemblance parallels that of twins are referred to as doppelgangers.[4]\\r\\nThe human twin birth rate in the United States, rose 76% from 1980 through 2009, from 18.9 to 33.3 per 1,000 births (about 80%)[5]\\r\\nThe Yoruba peoples have the highest rate of twinning in the world, at 45ÿ50 twin sets (or 90ÿ100 twins) per 1,000 live births,[6][7][8] possibly because of high consumption of a specific type of yam containing a natural phytoestrogen which may stimulate the ovaries to release an egg from each side.[9][10]\\r\\nIn Central Africa there are 18ÿ30 twin sets (or 36ÿ60 twins) per 1,000 live births.[11] In Latin America, South Asia, and Southeast Asia, the lowest rates are found; only 6 to 9 twin sets per 1,000 live births. North America and Europe have intermediate rates of 9 to 16 twin sets per 1,000 live births.[11]\\r\\nMultiple pregnancies are much less likely to carry to full term than single births, with twin pregnancies lasting on average 37 weeks, three weeks less than full term.[12]\\r\\nWomen who have a family history of fraternal twins have a higher chance of producing fraternal twins themselves, as there is a genetically linked tendency to hyper-ovulate. There is no known genetic link for identical twinning.[13] Other factors that increase the odds of having fraternal twins include maternal age, fertility drugs and other fertility treatments, nutrition, and prior births.[14]\\r\\nThe vast majority of twins are either dizygotic (fraternal) or monozygotic (identical). Less common variants are discussed further down the article.\\r\\nTwins can be:\\r\\nAmong non-twin births, male singletons are slightly (about five percent) more common than female singletons. The rates for singletons vary slightly by country. For example, the sex ratio of birth in the US is 1.05 males/female,[15] while it is 1.07 males/female in Italy.[16] However, males are also more susceptible than females to die in utero, and since the death rate in utero is higher for twins, it leads to female twins being more common than male twins.\\r\\nZygosity is the degree of identity in the genome of twins.\\r\\nDizygotic (DZ) or fraternal twins (also referred to as \\"non-identical twins\\", \\"dissimilar twins\\", \\"biovular twins\\", and, informally in the case of females, \\"sororal twins\\") usually occur when two fertilized eggs are implanted in the uterus wall at the same time. When two eggs are independently fertilized by two different sperm cells, fraternal twins result. The two eggs, or ova, form two zygotes, hence the terms dizygotic and biovular. Fraternal twins are, essentially, two ordinary siblings who happen to be born at the same time, since they arise from two separate eggs fertilized by two separate sperm, just like ordinary siblings.\\r\\nThis is the most common type of twin.[17]\\r\\nDizygotic twins, like any other siblings, have an extremely small chance of having the same chromosome profile. Even if they happen to have the same chromosome profile, they will always have different genetic material on each chromosome, due to chromosomal crossover during meiosis. Like any other siblings, dizygotic twins may look similar, particularly given that they are the same age. However, dizygotic twins may also look very different from each other.\\r\\nStudies show that there is a genetic proclivity for dizygotic twinning. However, it is only the mother who has any effect on the chances of having such twins; there is no known mechanism for a father to cause the release of more than one ovum. Dizygotic twinning ranges from six per thousand births in Japan (similar to the rate of monozygotic twins) to 14 and more per thousand in some African countries.[18]\\r\\nDizygotic twins are also more common for older mothers, with twinning rates doubling in mothers over the age of 35.[19] With the advent of technologies and techniques to assist women in getting pregnant, the rate of fraternals has increased markedly.\\r\\nMonozygotic (MZ) or identical twins occur when a single egg is fertilized to form one zygote (hence, \\"monozygotic\\") which then divides into two separate embryos.\\r\\nRegarding spontaneous or natural monozygotic twinning, a recent theory proposes that monozygotic twins are formed after a blastocyst essentially collapses, splitting the progenitor cells (those that contain the body's fundamental genetic material) in half, leaving the same genetic material divided in two on opposite sides of the embryo. Eventually, two separate fetuses develop.[20] Spontaneous division of the zygote into two embryos is not considered to be a hereditary trait, but rather a spontaneous and random event.[19]\\r\\nMonozygotic twins may also be created artificially by embryo splitting. It can be used as an expansion of in vitro fertilization (IVF) to increase the number of available embryos for embryo transfer.[21]\\r\\nMonozygotic twinning occurs in birthing at a rate of about 3 in every 1000 deliveries worldwide.[22] (about 0.3% of the world population).\\r\\nThe likelihood of a single fertilization resulting in monozygotic twins is uniformly distributed in all populations around the world.[19] This is in marked contrast to dizygotic twinning, which ranges from about six per thousand births in Japan (almost similar to the rate of identical twins, which is around 4ÿ5) to 15 and more per thousand in some parts of India[23] and up to over 20 in some Central African countries.[11] The exact cause for the splitting of a zygote or embryo is unknown.\\r\\nIVF techniques are more likely to create dizygotic twins. For IVF deliveries, there are nearly 21 pairs of twins for every 1,000.[24]\\r\\nMonozygotic twins are genetically nearly identical and they are always the same sex unless there has been a mutation during development. The children of monozygotic twins test genetically as half-siblings (or full siblings, if a pair of monozygotic twins reproduces with another pair or with the same person), rather than first cousins. Identical twins do not have the same fingerprints, because even in the confines of the womb, the fetuses touch different parts of this environment, which gives small variations in the same fingerprint, making them unique.[25]\\r\\nMonozygotic twins always have different phenotypes. Normally due to an environmental factor or the deactivation of different X chromosomes in female monozygotic twins, and in some extremely rare cases, due to aneuploidy, twins may express different sexual phenotypes, normally from an XXY Klinefelter syndrome zygote splitting unevenly.[26][27][28]\\r\\nMonozygotic twins, although genetically very similar, are not genetically exactly the same. The DNA in white blood cells of 66 pairs of monozygotic twins was analyzed for 506,786 single nucleotide polymorphisms known to occur in human populations. Polymorphisms appeared in 2 of the 33 million comparisons, leading the researchers to extrapolate that the blood cells of monozygotic twins may have on the order of one DNA-sequence difference for every 1.2 x 107 nucleotides, which would imply hundreds of differences across the entire genome.[29] The mutations producing the differences detected in this study would have occurred during embryonic cell-division (after the point of fertilization). If they occur early in fetal development, they will be present in a very large proportion of body cells.\\r\\nAnother cause of difference between monozygotic twins is epigenetic modification, caused by differing environmental influences throughout their lives. Epigenetics refers to the level of activity of any particular gene. A gene may become switched on, switched off, or could become partially switched on or off in an individual. This epigenetic modification is triggered by environmental events. Monozygotic twins can have markedly different epigenetic profiles. A study of 80 pairs of monozygotic twins ranging in age from three to 74 showed that the youngest twins have relatively few epigenetic differences. The number of epigenetic differences increases with age. Fifty-year-old twins had over three times the epigenetic difference of three-year-old twins. Twins who had spent their lives apart (such as those adopted by two different sets of parents at birth) had the greatest difference.[30] However, certain characteristics become more alike as twins age, such as IQ and personality.[31][32][33]\\r\\nA 1981 study of a deceased triploid XXX twin fetus without a heart showed that although its fetal development suggested that it was an identical twin, as it shared a placenta with its healthy twin, tests revealed that it was probably a polar body twin. The authors were unable to predict whether a healthy fetus could result from a polar body twinning.[34]\\r\\nIn 2003, a study argued that many cases of triploidity arise from semi-identical twinning.[35]\\r\\nIn 2007, a study reported a case of a pair of living twins, one intersex and one a phenotypical male. The twins were both found to be chimeras and to share all of their maternal DNA but only half of their father's DNA. The exact mechanism of fertilization could not be determined but the study stated that it was unlikely to be a case of polar body twinning.[36] \\r\\n\\r\\nThe degree of separation of the twins in utero depends on if and when they split into two zygotes. Dizygotic twins were always two zygotes. Monozygotic twins split into two zygotes at some time very early in the pregnancy. The timing of this separation determines the chorionicity (the number of placentae) and amniocity (the number of sacs) of the pregnancy. Dichorionic twins either never divided (i.e.: were dizygotic) or they divided within the first 4 days. Monoamnionic twins divide after the first week.\\r\\nIn very rare cases, twins become conjoined twins. Non-conjoined monozygotic twins form up to day 14 of embryonic development, but when twinning occurs after 14 days, the twins will likely be conjoined.[37] Furthermore, there can be various degrees of shared environment of twins in the womb, potentially leading to pregnancy complications.\\r\\nIt is a common misconception that two placentas means twins are dizygotic. But if monozygotic twins separate early enough, the arrangement of sacs and placentas in utero is indistinguishable from dizygotic twins.\\r\\nDiDi twins have the lowest mortality risk at about 9 percent, although that is still significantly higher than that of singletons.[40]\\r\\nMonochorionic twins generally have two amniotic sacs (called Monochorionic-Diamniotic \\"MoDi\\"), which occurs in 60ÿ70% of the pregnancies with monozygotic twins,[39] and in 0.3% of all pregnancies.[41] Monochorionic-Diamniotic twins are almost always monozygotic, with a few exceptions where the blastocysts have fused.[38]\\r\\nMonochorionic twins share the same placenta, and thus have a risk of twin-to-twin transfusion syndrome.\\r\\nMonoamniotic twins are always monozygotic.[42]\\r\\nThe survival rate for monoamniotic twins is somewhere between 50%[42] to 60%.[43]\\r\\nMonoamniotic twins, as with diamniotic monochorionic twins, have a risk of twin-to-twin transfusion syndrome. Also, the two umbilical cords have an increased chance of being tangled around the babies. Because of this, there is an increased chance that the newborns may be miscarried or suffer from cerebral palsy due to lack of oxygen.\\r\\nWhen the division of the developing zygote into 2 embryos occurs, 99% of the time it is within 8 days of fertilization.\\r\\nMortality is highest for conjoined twins due to the many complications resulting from shared organs.\\r\\nDichorionic-diamniotic twins at 8 weeks and 5 days since co-incubation as part of IVF. The twin at left in the image is shown in the sagittal plane with the head pointing towards upper left. The twin at right in the image is shown in the coronal plane with the head pointing rightwards.\\r\\nAbdominal ultrasonography of monoamniotic twins at a gestational age of 15 weeks. There is no sign of any membrane between the fetuses. A coronal plane is shown of the twin at left, and a sagittal plane of parts of the upper thorax and head is shown of the twin at right.\\r\\nA 2006 study has found that insulin-like growth factor present in dairy products may increase the chance of dizygotic twinning. Specifically, the study found that vegan mothers (who exclude dairy from their diets) are one-fifth as likely to have twins as vegetarian or omnivore mothers, and concluded that \\"Genotypes favoring elevated IGF and diets including dairy products, especially in areas where growth hormone is given to cattle, appear to enhance the chances of multiple pregnancies due to ovarian stimulation.\\"[44]\\r\\nFrom 1980 to 1997, the number of twin births in the United States rose 52%.[45] This rise can at least partly be attributed to the increasing popularity of fertility drugs and procedures such as IVF, which result in multiple births more frequently than unassisted fertilizations do. It may also be linked to the increase of growth hormones in food.[44]\\r\\nAbout 1 in 90 human births (1.1%) results from a twin pregnancy.[46] The rate of dizygotic twinning varies greatly among ethnic groups, ranging as high as about 45 per 1000 births (4.5%) for the Yoruba to 10% for Linha S?o Pedro, a tiny Brazilian settlement which belongs to the city of Candido God܇i.[47] In Candido God܇i, one in five pregnancies has resulted in twins.[48] The Argentine historian Jorge Camarasa has put forward a theory that experiments of the Nazi doctor Josef Mengele could be responsible for the high ratio of twins in the area.[49] His theory was rejected by Brazilian scientists who had studied twins living in Linha S?o Pedro; they suggested genetic factors within that community as a more likely explanation.[50] A high twinning rate has also been observed in other places of the world, including:\\r\\nThe widespread use of fertility drugs causing hyperovulation (stimulated release of multiple eggs by the mother) has caused what some call an \\"epidemic of multiple births\\". In 2001, for the first time ever in the US, the twinning rate exceeded 3% of all births. Nevertheless, the rate of monozygotic twins remains at about 1 in 333 across the globe.\\r\\nIn a study on the maternity records of 5750 Hausa women living in the Savannah zone of Nigeria, there were 40 twins and 2 triplets per 1000 births. Twenty-six percent of twins were monozygotic. The incidence of multiple births, which was about five times higher than that observed in any western population, was significantly lower than that of other ethnic groups, who live in the hot and humid climate of the southern part of the country. The incidence of multiple births was related to maternal age but did not bear any association to the climate or prevalence of malaria.[56][57]\\r\\nThe predisposing factors of monozygotic twinning are unknown.\\r\\nDizygotic twin pregnancies are slightly more likely when the following factors are present in the woman:\\r\\nWomen undergoing certain fertility treatments may have a greater chance of dizygotic multiple births. In the United States it has been estimated that by 2011 36% of twin births resulted from conception by assisted reproductive technology.[58]\\r\\nThe risk of twin birth can vary depending on what types of fertility treatments are used. With in vitro fertilisation (IVF), this is primarily due to the insertion of multiple embryos into the uterus. Ovarian hyperstimulation without IVF has a very high risk of multiple birth. Reversal of anovulation with clomifene (trade names including Clomid) has a relatively less but yet significant risk of multiple pregnancy.\\r\\nA 15-year German study[59] of 8,220 vaginally delivered twins (that is, 4,110 pregnancies) in Hesse yielded a mean delivery time interval of 13.5 minutes.[60] The delivery interval between the twins was measured as follows:\\r\\nThe study stated that the occurrence of complications \\"was found to be more likely with increasing twin-to-twin delivery time interval\\" and suggested that the interval be kept short, though it noted that the study did not examine causes of complications and did not control for factors such as the level of experience of the obstetrician, the wish of the women giving birth, or the \\"management strategies\\" of the procedure of delivering the second twin.\\r\\nResearchers suspect that as many as 1 in 8 pregnancies start out as multiples, but only a single fetus is brought to full term, because the other fetus has died very early in the pregnancy and has not been detected or recorded.[61] Early obstetric ultrasonography exams sometimes reveal an \\"extra\\" fetus, which fails to develop and instead disintegrates and vanishes in the uterus. There are several reasons for the \\"vanishing\\" fetus, including it being embodied or absorbed by the other fetus, placenta or the mother. This is known as vanishing twin syndrome. Also, in an unknown proportion of cases, two zygotes may fuse soon after fertilization, resulting in a single chimeric embryo, and, later, fetus.\\r\\nConjoined twins (or the once-commonly used term \\"siamese\\") are monozygotic twins whose bodies are joined together during pregnancy. This occurs when the zygote starts to split after day 12[38] following fertilization and fails to separate completely. This condition occurs in about 1 in 50,000 human pregnancies. Most conjoined twins are now evaluated for surgery to attempt to separate them into separate functional bodies. The degree of difficulty rises if a vital organ or structure is shared between twins, such as the brain, heart or liver.\\r\\nA chimera is an ordinary person or animal except that some of their parts actually came from their twin or from the mother. A chimera may arise either from monozygotic twin fetuses (where it would be impossible to detect), or from dizygotic fetuses, which can be identified by chromosomal comparisons from various parts of the body. The number of cells derived from each fetus can vary from one part of the body to another, and often leads to characteristic mosaicism skin coloration in human chimeras. A chimera may be intersex, composed of cells from a male twin and a female twin. In one case DNA tests determined that a woman, mystifyingly, was not the mother of two of her three children; she was found to be a chimera, and the two children were conceived from eggs derived from cells of their mother's twin.[62]\\r\\nSometimes one twin fetus will fail to develop completely and continue to cause problems for its surviving twin. One fetus acts as a parasite towards the other. Sometimes the parasitic twin becomes an almost indistinguishable part of the other, and sometimes this needs to be treated medically.\\r\\nA very rare type of parasitic twinning is one where a single viable twin is endangered when the other zygote becomes cancerous, or molar. This means that the molar zygote's cellular division continues unchecked, resulting in a cancerous growth that overtakes the viable fetus. Typically, this results when one twin has either triploidy or complete paternal uniparental disomy, resulting in little or no fetus and a cancerous, overgrown placenta, resembling a bunch of grapes.\\r\\nOccasionally, a woman will suffer a miscarriage early in pregnancy, yet the pregnancy will continue; one twin was miscarried but the other was able to be carried to term. This occurrence is similar to the vanishing twin syndrome, but typically occurs later, as the twin is not reabsorbed.\\r\\nIt is very common for twins to be born at a low birth weight. More than half of twins are born weighing less than 5.5 pounds (2.5?kg), while the average birth weight of a healthy baby should be around 6ÿ8 pounds (3ÿ4?kg).[63] This is largely due to the fact that twins are typically born premature. Premature birth and low birth weights, especially when under 3.5 pounds (1.6?kg), can increase the risk of several health-related issues, such as vision and hearing loss, mental disabilities, and cerebral palsy.[64] There is an increased possibility of potential complications as the birth weight of the baby decreases.\\r\\nMonozygotic twins who share a placenta can develop twin-to-twin transfusion syndrome. This condition means that blood from one twin is being diverted into the other twin. One twin, the 'donor' twin, is small and anemic, the other, the 'recipient' twin, is large and polycythemic. The lives of both twins are endangered by this condition.\\r\\nStillbirths occurs when a fetus dies after 20 weeks of gestation. There are two types of stillbirth, including intrauterine death and intrapartum death. Intrauterine death occurs when a baby dies during late pregnancy. Intrapartum death, which is more common, occurs when a baby dies while the mother is giving birth. The cause of stillbirth is often unknown, but the rate of babies who are stillborn is higher in twins and multiple births. Caesareans or inductions are advised after 38 weeks of pregnancy for twins, because the risk of stillbirth increases after this time.[65]\\r\\nFor otherwise healthy twin pregnancies where both twins are head down a trial of vaginal delivery is recommended at between 37 and 38 weeks.[66][67] Vaginal delivery in this case does not worsen the outcome for the infant as compared with Caesarean section.[66] There is controversy on the best method of delivery where the first twin is head first and the second is not.[66] When the first twin is not head down a caesarean section is often recommended.[66] It is estimated that 75% of twin pregnancies in the United States were delivered by caesarean section in 2008.[68] In comparison, the rate of caesarean section for all pregnancies in the general population varies between 14% and 40%.[69] In twins that share the same placenta delivery may be considered at 36 weeks.[70]\\r\\nTwin studies are utilized in an attempt to determine how much of a particular trait is attributable to either genetics or environmental influence. These studies compare monozygotic and dizygotic twins for medical, genetic, or psychological characteristics to try to isolate genetic influence from epigenetic and environmental influence. Twins that have been separated early in life and raised in separate households are especially sought-after for these studies, which have been used widely in the exploration of human nature. Classical twin studies are now being supplemented with molecular genetic studies which identify individual genes.\\r\\nAmong dizygotic twins, in rare cases, the eggs are fertilized at different times with two or more acts of sexual intercourse, either within one menstrual cycle (superfecundation) or, even more rarely, later on in the pregnancy (superfetation). This can lead to the possibility of a woman carrying fraternal twins with different fathers (that is, half-siblings). This phenomenon is known as heteropaternal superfecundation. One 1992 study estimates that the frequency of heteropaternal superfecundation among dizygotic twins, whose parents were involved in paternity suits, was approximately 2.4%; see the references section, below, for more details.\\r\\nDizygotic twins from biracial couples can sometimes be mixed twins, which exhibit differing ethnic and racial features. One such pairing was born in Germany in 2008 to a white father from Germany and a black mother from Ghana.[71][72]\\r\\nHeterotopic pregnancy is an exceedingly rare type of dizygotic twinning in which one twin implants in the uterus as normal and the other remains in the fallopian tube as an ectopic pregnancy. Ectopic pregnancies must be resolved because they can be life-threatening to the mother. However, in most cases, the intrauterine pregnancy can be salvaged.[citation needed]\\r\\nAmong monozygotic twins, in extremely rare cases, twins have been born with different sexes (one male, one female).[73] When monozygotic twins are born with different sexes it is because of chromosomal defects. There can be monozygotic boy/girl twins if the sex gene of the embryo has an extra x chromosome (the fertilized egg would be an xxy) then when the egg splits, one can have xx (girl) genes and one can have xy (boy) genes. This is rare, but possible. Records show there are only 10 known cases of these type twins.[citation needed] The probability of this is so small that multiples having different sexes is universally accepted as a sound basis for in utero clinical determination that the multiples are not monozygotic. Another abnormality that can result in monozygotic twins of different genders is if the egg is fertilized by a male sperm but during cell division only the X chromosome is duplicated. This results in one normal male (XY) and one female with Turner syndrome (45,X).[74] In these cases, although the twins did form from the same fertilized egg, it is incorrect to refer to them as genetically identical, since they have different karyotypes.\\r\\nMonozygotic twins can develop differently, due to different genes being activated.[75] More unusual are \\"semi-identical twins\\". These \\"half-identical twins\\" are hypothesized to occur when an unfertilized egg cleaves into two identical attached ova and which are viable for fertilization. Both cloned ova are then fertilized by different sperm and the coalesced eggs undergo further cell duplications developing as a chimeric blastomere. If this blastomere then undergoes a twinning event, two embryos will be formed, each of which have different paternal genes and identical maternal genes.\\r\\nThis results in a set of twins with identical genes from the mother's side, but different genes from the father's side. Cells in each fetus carry genes from either sperm, resulting in chimeras. This form had been speculated until only recently being recorded in western medicine.[76][77][78]\\r\\nMirror image twins result when a fertilized egg splits later in the embryonic stage than normal timing, around day 9ÿ12. This type of twinning could exhibit characteristics with reversed asymmetry, such as opposite dominant handedness, dental structure, or even organs (situs inversus).[79] If the split occurs later than this time period, the twins risk being conjoined. There is no DNA-based zygosity test that can determine if twins are indeed mirror image.[80]\\r\\nThere have been many studies highlighting the development of language in twins compared to single-born children. These studies have converged on the notion that there is a greater rate of delay in language development in twins compared to their single-born counterparts.[81] The reasons for this phenomenon are still in question; however, cryptophasia was thought to be the major cause.[82] Idioglossia is defined as a private language that is usually invented by young children, specifically twins. Another term to describe what some people call \\"twin talk\\" is cryptophasia where a language is developed by twins that only they can understand. The increased focused communication between two twins may isolate them from the social environment surrounding them. Idioglossia has been found to be a rare occurrence and the attention of scientists has shifted away from this idea. However, there are researchers and scientists that say cryptophasia or idioglossia is not a rare phenomenon. Current research is looking into the impacts of a richer social environment for these twins to stimulate their development of language.[83]\\r\\nTwins are common in many animal species, including cats, sheep, ferrets, giant pandas, dogs, deer, marmosets, and tamarins. The incidence of twinning among cattle is about 1ÿ4%, and research is under way to improve the odds of twinning, which can be more profitable for the breeder if complications can be sidestepped or managed. A female calf that is the twin of a bull becomes partially masculinized and is known as a freemartin.","input":"When would monozygotic (identical) twins be produced?"},{"output":"Giant Forest","context":"General Sherman is a giant sequoia (Sequoiadendron giganteum) tree located in the Giant Forest of Sequoia National Park in Tulare County, in the U.S. state of California. By volume, it is the largest known living single stem tree on Earth.[1]\\r\\nWhile the General Sherman is the largest currently living tree, it is not the largest historically-recorded tree. The Crannell Creek Giant, a coast redwood (Sequoia sempervirens) near Trinidad, California, is estimated to have been 15 to 25% larger than the General Sherman tree by volume. That tree was cut down in the mid-1940s. Another larger coast redwood, near 90,000 cubic feet, the Lindsey Creek tree, was reported in a 1905 Humboldt Times Standard article.[2][3]\\r\\n\\r\\n\\r\\nThe General Sherman was named after the American Civil War general William Tecumseh Sherman, in 1879 by naturalist James Wolverton, who had served as a lieutenant in the 9th Indiana Cavalry under Sherman. In 1931, following comparisons with the nearby General Grant tree, General Sherman was identified as the largest tree in the world. One result of this process was that wood volume became widely accepted as the standard for establishing and comparing the size of different trees.[1][4]\\r\\nIn January 2006 the largest branch on the tree (seen most commonly, in older photos, as an \\"L\\" or golf-club shape, protruding from about a quarter of the way down the trunk) broke off. There were no witnesses to the incident, and the branch  larger than most tree trunks; diameter over 2?m (6.6?ft) and length over 30?m (98?ft)  smashed part of the perimeter fence and cratered the pavement of the surrounding walkway. The breakage is not believed to be indicative of any abnormalities in the tree's health, and may even be a natural defense mechanism against adverse weather conditions.[5]\\r\\nWhile it is the largest tree known, the General Sherman Tree is neither the tallest known living tree on Earth (that distinction belongs to the Hyperion tree, a Coast redwood),[6] nor is it the widest (both the largest cypress and largest baobab have a greater diameter), nor is it the oldest known living tree on Earth (that distinction belongs to a Great Basin bristlecone pine).[7] With a height of 83.8 meters (275?ft), a diameter of 7.7?m (25?ft), an estimated bole volume of 1,487?m3 (52,513?cu?ft), and an estimated age of 2,300ÿ2,700 years,[8][9][10] it is nevertheless among the tallest, widest, and longest-lived of all trees on the planet.\\r\\nCoordinates: 363454N 1184505.5W? / ?36.58167N 118.751528W? / 36.58167; -118.751528","input":"Where are the largest trees in sequoia national park?"},{"output":"Roger Williams","context":"The history of Rhode Island includes the history of Rhode Island and Providence Plantations since pre-colonial times.\\r\\n\\r\\n\\r\\nIndian inhabitants occupied most of the area now known as Rhode Island, including the Wampanoag, Narragansett, and Niantic tribes.[1] Many Indians were killed by diseases, possibly contracted through contact with European settlers and explorers (though no definitive source has been proven), and through warfare with other tribes and with European settlers. The Narragansett language died out for many years but was partially preserved in Roger Williams's A Key into the Languages of America (1643).[2]\\r\\nIn 1636, Roger Williams settled on land granted to him by the Narragansett tribe at the tip of Narragansett Bay after being banished from the Massachusetts Bay Colony for his religious views. He called the site \\"Providence Plantations\\" and declared it a place of religious freedom.\\r\\nIn 1638, Anne Hutchinson, William Coddington, John Clarke, Philip Sherman, and other religious dissidents settled on Rhode Island after conferring with Williams,[3] forming the settlement of Portsmouth which was governed by the Portsmouth Compact. The southern part of the island became the separate settlement of Newport after disagreements among the founders.\\r\\nDissident Samuel Gorton purchased Indian lands at Shawomet in 1642, precipitating a dispute with the Massachusetts Bay Colony. In 1644, Providence, Portsmouth, and Newport united for their common independence as the Colony of Rhode Island and Providence Plantations, governed by an elected council and president. Gorton received a separate charter for his settlement in 1648, which he named Warwick after his patron.[4] The union of these four towns was strengthened by the Royal Charter of 1663. Critics at the time sometimes referred to the Colony as \\"Rogue's Island\\",[5] and Cotton Mather called it \\"the sewer of New England\\" because of the Colony's willingness to accept people who had been banished from Massachusetts Bay.[6]\\r\\nIn 1686, King James II ordered Rhode Island to submit to the Dominion of New England and its appointed governor Edmund Andros. This suspended the Colony's charter, but Rhode Island still managed to retain possession of it until Andros was deposed and the Dominion was dissolved.[7] William of Orange became King after the Glorious Revolution of 1688, and Rhode Island's independent government resumed under the 1663 charter, which was used as the state constitution until 1842.[8]\\r\\nIn 1693, William III and Mary II issued a patent extending Rhode Island's territory to three miles \\"east and northeast\\" of Narragansett Bay, conflicting with the claims of Plymouth Colony.[9] This resulted in several later transfers of territory between Rhode Island and Massachusetts.\\r\\nThe early relationship between New Englanders and Indians was mostly peaceable. The largest tribes that lived near Rhode Island were the Wampanoags, Pequots, Narragansetts, and Nipmucks. Squanto was a member of the Wampanoag tribe who stayed with the Pilgrims in Plymouth Colony and taught them many valuable skills needed to survive in the area.\\r\\nRoger Williams won the respect of his Colonial neighbors for his skill in keeping the powerful Narragansetts on friendly terms with the Colonists. In 1637, the Narragansetts formed an alliance with Rhode Island during the Pequot War. However, this peace did not last long, as the most traumatic event in 17th century Rhode Island was King Philip's War (1675ÿ76). Metacomet, the chief of the Wampanoag Indians, was known as King Philip by the settlers of Portsmouth who had purchased their land from his father Massasoit. He led attacks around Narragansett Bay, despite Rhode Island's continued neutrality, and later these spread throughout New England. A force of Massachusetts, Connecticut, and Plymouth militia under General Josiah Winslow invaded and destroyed the fortified Narragansett Indian village in the Great Swamp in southern Rhode Island on December 19, 1675.[10] The Narragansetts also invaded and burned down several of the Rhode Island settlements, including Providence, although they allowed the population to leave first. In one of the final actions of the war, troops from Connecticut led by Captain Benjamin Church hunted down and killed King Philip at Mount Hope.\\r\\nRhode Island was the first British colony in America to formally declare its independence, doing so on May 4, 1776, a full two months before the national Declaration of Independence.[11] Previously, Rhode Islanders attacked the British warship HMS Gaspee in 1772 as one of the first overt acts of rebellion in America. British naval forces under Captain James Wallace controlled Narragansett Bay for much of the Revolution, periodically raiding the islands and the mainland. The British raided Prudence Island for livestock and engaged in a skirmish with American forces, losing approximately a dozen soldiers. Newport remained a hotbed for Tory or Loyalist sympathizers who assisted the British forces. The state appointed General William West of Scituate to root out Tories in the winter of 1775ÿ76. British forces eventually occupied Newport from 1777 to 1778, causing the colonial forces to flee to Bristol.\\r\\nThe Battle of Rhode Island was fought during the summer of 1778 and was an unsuccessful attempt to expel the British from Narragansett Bay, although few colonial casualties occurred. The Marquis de Lafayette called the action the \\"best fought\\" of the war. The following year, the British wanted to concentrate their forces in New York and consequently abandoned Newport.\\r\\nIn 1780, the French under Rochambeau landed in Newport and, for the rest of the war, Newport was the base of the French forces in the United States. The French soldiers behaved themselves so well that, in gratitude, the Rhode Island General Assembly repealed an old law banning Catholics from living in Rhode Island. The first Catholic mass in Rhode Island was said in Newport during this time.\\r\\nRhode Island was the last of the original 13 states to ratify the United States Constitution (May 29, 1790), only doing so after being threatened with having its exports taxed as a foreign nation. Rural resistance to the Constitution was strong in Rhode Island, and the anti-federalist Country Party controlled the General Assembly from 1786 to 1790. In 1788, anti-federalist politician and revolutionary general William West led an armed force of 1,000 men to Providence to oppose a July 4 celebration of the state ratifying the Constitution.[12] Civil war was narrowly averted by a compromise limiting the Fourth of July celebration.\\r\\nRhode Island was heavily involved in the slave trade during the post-Revolution era, prior to industrialization. In 1652, Rhode Island passed the first abolition law in the thirteen colonies, banning African slavery,[13] but the law was not enforced by the end of the 17th century. By 1774, the slave population of RI was 6.3%, nearly twice as high as any other New England colony. In the late 18th century, several Rhode Island merchant families began actively engaging in the triangle slave trade, most notably the Browns, for whom Brown University is named. In the years after the Revolution, Rhode Island merchants controlled between 60 and 90 percent of the American trade in African slaves.[14] In the 18th century, Rhode Island's economy depended largely upon the triangle trade, where Rhode Islanders distilled rum from molasses, sent the rum to Africa to trade for slaves, and then traded the slaves in the West Indies for more molasses.\\r\\nStephen Hopkins introduced a bill while serving in the Rhode Island Assembly in 1774 that prohibited the importation of slaves into the colony. This became one of the first anti-slavery laws in the United States. In February 1784, the Rhode Island Legislature passed a compromise measure for gradual emancipation of slaves within Rhode Island. All children of slaves born after March 1 were to be \\"apprentices,\\" the girls to become free at 18, the boys at 21. By 1840, the census reported only five African Americans enslaved in Rhode Island.[14]\\r\\nDespite the antislavery laws of 1774, 1784, and 1787, an international slave trade continued. In 1789, an Abolition Society was organized to secure enforcement of existing laws against the trade. Leading merchants continued to engage in the trade even after it became illegal, especially John Brown and George DeWolf. After 1770, slaving was never more than a minor aspect of Rhode Island's overall maritime trade.[15]\\r\\nRhode Island manufactured numerous textiles throughout the early 19th century using southern cotton cultivated with slave laboras did all other American textile manufacturers of the time.[16] By the mid-19th century, many Rhode Islanders were active in the abolitionist movement, particularly Quakers in Newport and Providence such as Moses Brown.[17]\\r\\nIn 1790, English immigrant Samuel Slater founded the first textile mill in the United States in Pawtucket, Rhode Island (Slater Mill) and became known as the father of the American industrial revolution. During the 19th century, Rhode Island became one of the most industrialized states in the United States with large numbers of textile factories. The state also had significant machine tool, silverware, and costume jewelry industries.[18]\\r\\nThe Industrial Revolution moved large numbers of workers into cities and attracted large numbers of immigrants from Ireland, and a permanently landlessand therefore votelessclass developed. By 1829, 60% of the state's white men were ineligible to vote. All efforts at reform failed in the face of rural control of the political system. In 1842, Thomas Dorr drafted a liberal constitution which he tried to ratify by popular referendum. However, conservative Governor Samuel Ward King opposed the constitution, leading to the Dorr Rebellion. The Rebellion gained little support and failed, and Dorr went to prison. The conservative elements relented, however, and allowed most American-born men to vote, but the conservative rural towns remained in control of the legislature.[19]\\r\\nDuring the American Civil War, Rhode Island furnished 25,236 fighting men to the Union armies, of which 1,685 died. These comprised 12 infantry regiments, three cavalry regiments, and an assortment of artillery and miscellaneous outfits. Rhode Island used its industrial capacity to supply the Union Army with the materials needed to win the war, along with the other northern states. Rhode Island's continued growth and modernization led to the creation of an urban mass transit system and improved health and sanitation programs. In 1866, Rhode Island abolished racial segregation throughout the state.[20] Governor William Sprague IV fought at the First Battle of Bull Run while a sitting governor, and Rhode Island general Ambrose Burnside emerged as one of the major heroes of the war.\\r\\nThe fifty or so years following the Civil War were a time of prosperity and affluence that author William G. McLoughlin called \\"Rhode Island's halcyon era.\\"[21] Rhode Island was a center of the Gilded Age and provided a home (or summer home) to the many of the country's most prominent robber barons.[21] This was a time of incredible growth in textile mills and manufacturing, and saw a huge influx of immigrants to fill those jobs.[21] The state saw increased population growth and urbanization, even as the state denied the growing urban masses access to political power.[21] In politics, the state was dominated by Republicans allied with their mouthpiece newspaper, The Providence Journal.[21] The Journal's editor Henry B. Anthony and his later protege Nelson Aldrich, along with war hero Ambrose Burnside, all Republicans, dominated politics during this time. Aldrich, as US Senator, became known as the \\"General Manager of the United States,\\" for his ability to set high tariffs to protect Rhode Island  and American  goods from foreign competition.[21]\\r\\nIn Newport, New York's wealthiest industrialists created a summer haven to socialize and build ostentatious grand mansions.[21] In Providence, Pawtucket, Central Falls, and Woonsocket, thousands of French-Canadian, Italian, Irish, and Portuguese immigrants arrived to fill jobs in the textile and manufacturing mills.[21] In response, the Know Nothing party, allied with the Republicans and the Providence Journal, sought to exclude these newcomers from the political process.[21] The constitution of 1843 denied the vote to the landless poor, and ensured that urban centers were disproportionately underrepresented in the state legislature.[21]\\r\\nAround the start of the 20th century, Rhode Island had a booming economy, which fed the demand for immigration. During World War I, Rhode Island furnished 28,817 troops, of whom 612 died. After the war, the state was hit hard by the Spanish Influenza.[22]\\r\\nIn the 1920s and 30s, rural Rhode Island saw a surge in Ku Klux Klan membership, largely among the native-born white population, in reaction to the large waves of immigrants moving to the state. The Klan is believed to be responsible for burning the Watchman Industrial School in Scituate, Rhode Island, which was a school for African American children.[23]\\r\\nIn 1935, Governor Theodore Francis Green and Democratic majorities in the state House and Senate replaced a Republican dominance that had existed since the middle of the 19th century in what is termed the \\"Bloodless Revolution.\\" The Rhode Island Democratic Party has dominated state politics ever since.[24][25] Since then, the Speaker of the House has always been a Democrat and one of the most powerful figures in government.\\r\\nThe Democratic Party presents itself as a coalition of labor unions, working class immigrants, intellectuals, college students, and the rising ethnic middle class. The Republican Party has been dominant in rural and suburban parts of the state, and has nominated occasional reform candidates who criticize the state's high taxes and excesses of Democratic domination. Cranston Mayors Edward D. DiPrete and Stephen Laffey, Governor Donald Carcieri of East Greenwich, and former Mayor Vincent A. \\"Buddy\\" Cianci of Providence ran as Republican reform candidates.\\r\\nThe state income tax was first enacted in 1971 as a temporary measure. Prior to 1971, there was no income tax in the state, but the temporary income tax soon became permanent. The tax burden in Rhode Island remains among the five highest in the United States, including sales, gasoline, property, cigarette, corporate, and capital gains taxes.[26][27]\\r\\nRhode Islanders have overwhelmingly supported and re-elected Democrats to positions of authority, where issues are promoted involving education, health care, and liberal causes. As of 2014[update] Rhode Island has heavily Democrat-controlled legislatures; both U.S. Senators and Congressmen, and all statewide offices are held by Democrats. The state has been carried by Democrat presidential candidates in every election since 1988.[28]","input":"Who was in charge of rhode island colony?"},{"output":"anatomical feature of the infant human skull comprising any of the soft membranous gaps (sutures) between the cranial bones that make up the calvaria of a fetus or an infant","context":"A fontanelle (or fontanel) (colloquially, soft spot) is an anatomical feature of the infant human skull comprising any of the soft membranous gaps (sutures) between the cranial bones that make up the calvaria of a fetus or an infant.[1] Fontanelles allow for rapid stretching and deformation of the neurocranium as the brain expands faster than the surrounding bone can grow.[2] Premature complete ossification of the sutures is called craniosynostosis.\\r\\nAfter infancy, the anterior fontanelle is known as the bregma.\\r\\n\\r\\n\\r\\nThe skull of a baby consists of five main bones: two frontal bones, two parietal bones, and one occipital bone. These are joined by fibrous sutures, which allow movement that facilitates childbirth and brain growth.\\r\\nDuring birth, fontanelles enable the bony plates of the skull to flex, allowing the child's head to pass through the birth canal. The ossification of the bones of the skull causes the anterior fontanelle to close over by 9 to 18 months.[3] The sphenoidal and posterior fontanelles close during the first few months of life. The closures eventually form the sutures of the neurocranium. Other than the anterior and posterior fontanelles, the mastoid fontanelle and the sphenoidal fontanelle are also significant.\\r\\nIn humans, the sequence of fontanelle closure is as follows:[2][4]\\r\\nThe fontanelle may pulsate, and although the precise cause of this is not known, it is perfectly normal and seems to echo the heartbeat, perhaps via the arterial pulse within the brain vasculature, or in the meninges. This pulsating action is how the soft spot got its name ÿ fontanelle is borrowed from the old French word fontenele, which is a diminutive of fontaine, meaning \\"spring\\". It is assumed that the term spring is used because of the analogy of the dent in a rock or earth where a spring arises.[5]\\r\\nParents may worry that their infant may be more prone to injury at the fontanelles. In fact, although they may colloquially be called \\"soft-spots\\", the membrane covering the fontanelles is extremely tough and difficult to penetrate.[6]\\r\\nFontanelles allow the infant brain to be imaged using ultrasonography. Once they are closed, most of the brain is inaccessible to ultrasound imaging, because the bony skull presents an acoustic barrier.[6]\\r\\nA very tense or bulging anterior fontanelle indicates raised intracranial pressure. Increased cranial pressure in infants may cause the fontanelles to bulge or the head to begin to enlarge abnormally.[7] It can occur due to:[4]\\r\\nA sunken (also called \\"depressed\\") fontanelle indicates dehydration or malnutrition.[8]\\r\\nThe fontanelles may be enlarged, may be slow to close or may never close most commonly due to causes like:[9]\\r\\nRarer causes include:[9]\\r\\nIn apes the fontanelles fuse soon after birth. In chimpanzees the anterior fontanelle is fully closed by 3 months of age.[2]\\r\\nOne of the more serious problems that can affect canines is known as an \\"open fontanelle,\\" which occurs when the skull bones at the top of the head fail to close. The problem is often found in conjunction with hydrocephalus, which is a condition in which too much fluid is found within and around the brain, placing pressure on the brain and surrounding tissues. Often the head will appear dome-shaped, and the open fontanelle is noticeable as a \\"soft spot\\" on the top of the dog's head. The fluid-filled spaces within the brain, known as ventricles, also become swollen. The increased pressure damages or prevents the development of brain tissue.[10]\\r\\nNot all open fontanelles are connected with hydrocephalus. In many young dogs the skull bones are not fused at birth, but instead will close slowly over a three- to six-month period. Occasionally these bones fail to close, but the dog is still healthy. In these cases, however, the dog's owners need to be very careful, since any injury or bumps to the animal's head could cause significant brain damage, as well as conditions like epilepsy.\\r\\nFontanelle.\\r\\nAnterior fontanelle.\\r\\nCranial sutures shown from top of head.","input":"What are the fontanels and why are they important?"},{"output":"Maldivian","context":"\\r\\n\\r\\n??????, dhivehi\\r\\n\\r\\nThe Maldives\\r\\n\\r\\nMaldivian,[1] also known as Dhivehi[2] or Divehi[3][4] (??????, dhivehi or ??????????, dhivehi-bas), is an Indo-Aryan language spoken in the South Asian island country of Maldives; it is the language of Maldivians, an Indo-Aryan ethnic group native to the country. It is also the first language of nearly 10,000 people on the island of Minicoy in the Union territory of Lakshadweep, India, where the Mahl dialect of the Maldivian language is spoken.\\r\\n\\r\\nMaldivian is closely related to the Sinhalese language of Sri Lanka.\\r\\n\\r\\nThe ethnic autonym for the language, Divehi, is occasionally found in English as Dhivehi (spelled according to the locally used Mal Latin for romanization of the Maldivian language), which is the official spelling as well as the common usage in the Maldives. Maldivian is written in the Thaana script.\\r\\n\\r\\nThe major dialects of Maldivian are Mal, Huvadhu, Mulaku, Addu, Haddhunmathee, and Maliku. The standard form of Maldivian is Mal, which is spoken in the Maldivian capital of the same name. The Maliku dialect spoken in Minicoy is officially referred to as Mahl by the Lakshadweep administration. This has been adopted by many authors when referring to Maldivian spoken in Minicoy.[5][6][7]\\r\\n\\r\\nMaldivian is a descendent of Elu Prakrit and is closely related to the Sinhalese language, but not mutually intelligible with it. Many languages have influenced the development of the Maldivian language through the ages, most importantly Arabic. Others include French, Persian, Portuguese, Hindustani, and English. The English words atoll (a ring of coral islands or reefs) and dhoni (a vessel for inter-atoll navigation) are anglicised forms of the Maldivian words ato?u and dni.\\r\\n\\r\\nThe origin of the word \\"Divehi\\" is Div+vehi meaning \\"Islanders\\" (from Sanskrit Dvؐpa). Bas means \\"language\\" (from Sanskrit Bh?), so Divehi-bas means \\"Islanders' language\\". Harry Charles Purvis Bell, one of the first Dhivehi linguists, called it Divehi. This was consistent with Maldives, the name of the country, for the -dives of Maldives and the word Divehi have the same root, Old Indo-Aryan dvؐpa \\"island\\".\\r\\n\\r\\nWilhelm Geiger, a German linguist who undertook the first research on Maldivian linguistics in the early 20th century, also called the language Divehi. An h was added to the name of the language \\"Dhivehi\\" in 1976, when the semi-official transliteration called Mal Latin was developed. Today the spelling with an h is both common and official usage in the Maldives.\\r\\n\\r\\nMaldivian is an Indo-Aryan language closely related to the Sinhalese language of Sri Lanka. Maldivian represents the southernmost Indo-Aryan language. Together with Sinhala, Maldivian represents a subgroup within the Modern Indo-Aryan languages which is called Insular Indo-Aryan. However, Sinhala and Maldivian are not mutually intelligible.[8]\\r\\n\\r\\nMaldivian is descended from the Maharashtri Prakrit[citation needed] of ancient and medieval India. These Prakrits were originally derived from Old Indo-Aryan vernaculars related to Vedic Sanskrit.\\r\\n\\r\\nWhereas earlier it was believed that Maldivian was a descendant of the Sinhalese language, in 1969 Sinhalese philologist M. W. S. de Silva for the first time proposed that Maldivian and Sinhalese have branched off from a common mother language.[9]\\r\\n\\r\\nMaldivian has a continuous written history of about eight hundred years. The earliest writings were on the lmfnu (copper-plate grants) of the 12th and 13th centuries. Early inscriptions on coral stone have also been found. The oldest inscription found to date is an inscription on a coral stone, which is estimated to be from around the 7th or 8th century.\\r\\n\\r\\nMaldivian is an Indo-Aryan language of the Sinhalese-Maldivian subfamily.[10] It developed in relative isolation from other languages until the 12th century. Since the 16th century, Maldivian has been written in a unique script called Thaana which is written from right to left, like those of Aramaic and Arabic (with which it shares several common diacritics for vowel sounds).\\r\\n\\r\\nThe foundation of the historical linguistic analysis of both Maldivian and Sinhalese was laid by Wilhelm Geiger (1856ÿ1943). In Geiger's comparative study of Maldivian and Sinhalese, he assumes that Maldivian is a dialectal offspring of Sinhalese and therefore is a \\"daughter language\\" of Sinhalese. However, the material he collected was not sufficient to judge the \\"degree of relationship\\" of Maldivian and Sinhalese.\\r\\n\\r\\nGeiger concludes that Maldivian must have split from Sinhalese not earlier that the 10th century CE. However, there is nothing in the history of these islands or Sinhalese chronicles, even in legendary form, that alludes to a migration of Sinhalese people which results such a connection.\\r\\n\\r\\nVitharana suggests that Maldivian did not evolve as a separate language to Sinhalese until the 12th century CE.[11] But Reynolds and others[who?] have suggested that Maldivian started showing indications of divergence as early as the 4th century CE.[citation needed]\\r\\n\\r\\nDe Silva proposes that Maldivian and Sinhalese must have branched off from a common mother language. He says that \\"the earliest Indic element in Maldivian is not so much a result of branching off from Sinhalese as a result of a simultaneous separation with Sinhalese from the Indic languages of the mainland of India\\", referring to Dravidian influences seen in the Maldivian language, such as in old place names.\\r\\n\\r\\nDe Silva's theory is supported by the legend of Prince Vijaya as told in the Mahavamsa, because if this legend is to be believed, the migration of Indo-Aryan colonists to the Minicoy, Maldives and Sri Lanka from the mainland (India) must have taken place simultaneously. This means that Maldivian and Sinhalese must be \\"sister languages\\" that developed from a common Prakrit.[citation needed]\\r\\n\\r\\nWhatever the origin of Maldivian, linguists agree that Maldivian is an Indo-Aryan language which also has older Indic elements in it.\\r\\n\\r\\nA rare Maliku Thaana primer written in Maldivian published by Lakshadweep's administration during the time of Rajiv Gandhi's rule was reprinted by Spanish researcher Xavier Romero-Frias in 2003.[12]\\r\\n\\r\\nMost speakers of Maldivian live in the Maldives, where it is the national language of the island-nation. Maldivian is also spoken in Minicoy Island in the Union Territory of Lakshadweep, India, while a few have migrated to Thiruvananthapuram, Kochi and elsewhere in the state of Kerala.[citation needed]\\r\\n\\r\\nMaldivian is the official language of Maldives and a semi-official language in the Union Territory of Lakshadweep, India.\\r\\n\\r\\nDue to the wide distribution of the islands, differences in pronunciation and vocabulary have developed during the centuries. The mainstream form of Maldivian is known as Mal Bas and is based on the dialect spoken in the capital of the Maldives.\\r\\n\\r\\nThe most divergent dialects of the language are to be found in the southern atolls, namely Huvadhu, Fuvahmulah and Addu. Slighter variants are spoken in Haddhunmathi and in Minicoy (Maliku) where Haddhunmathee Bas and Maliku Bas (Mahl) are spoken respectively. The dialect spoken in Minicoy has fewer differences from the standard Maldivian than other dialects. Among the dialects, Mal Bas and Maliku Bas are most similar. The other variants show much difference including the dialects spoken in a few islands in Kolhumadulu, which are hardly recognised and known.\\r\\n\\r\\nMulaku Bas is a dialect of Maldivian spoken by the people of Fuvahmulah. Mulaku Bas has word-final 'l' (laamu sukun ??), which is absent from the other dialects of Maldivian. Another characteristic is the 'o' sound at the end of words, instead of the final 'u' common in all other forms of Maldivian; e.g. 'fanno' instead of 'fannu'. Regarding pronunciation, the retroflex '?' (IPA [?]), which has almost a slight 'r' sound in mainstream Maldivian, becomes '?' (IPA [?]) in Mulaku Bas, sounding like Arabic: ?? shؐn. One of the most unusual features of Mulaku Bas is that, unlike other dialects, it distinguishes gender. Also, there are many remarkable differences in the dialect in place of the Sukun system as well as the vowel or diacritical system following a distinctive set of rules.\\r\\n\\r\\nHuvadhu Bas, spoken by the inhabitants of the large atoll of Huvadhu, is another distinctive form of Maldivian. Because of the isolation from the Northern Atolls, and the capital of Mal, Huvadhu Bas compared to other variants makes more use of the retroflex /?/ (IPA [?]). Huvadhu Bas also retains old Sinhala words and is sometimes considered to be linguistically closer to Sinhala than the other dialects of Maldivian.\\r\\n\\r\\nAddu Bas is also quite different from the official form of the Maldivian language and has some affinities with Mulaku Bas. In the past, Addu Atoll being a centre of Education, the islanders from the three atolls of the south who acquired education from the atoll used the Addu Bas as their lingua franca. Hence, when for example one of these islanders of any of the Huvadhu islands met with someone from Fuvahmulah, they would use Addu Bas to talk to each other. Addu Bas is the most widespread of the dialects of Maldivian. However, the secessionist government of the Suvadives (1959ÿ1963) used Mal Bas in its official correspondence.\\r\\n\\r\\nThe lesser known dialect in the Madifushi island of Kolhumadulu locally known as Madifushi Bas has some similarities with Huvadhu Bas. Word-final 'a' is often replaced with 'e' or 'o', and some final consonants also differ.\\r\\n\\r\\nThe letter ?aviyani ? (different from the letter ?aviyani), which represented the retroflex n sound common to many Indic languages (Gujarati, Hindi, etc.), was abolished from official documents in 1950 by Muhammad Amin, the ruler of Maldives. It is not known why this particular letter representing a retroflex sound was abolished while others, like ?aviyani, ?aviyani, and ?aviyani, were not.[13] ?aviyani's former position in the Thaana alphabet, between the letters Gaafu and Seenu, is today occupied by the palatal nasal ? or ?yaviyani ?. It is still seen in reprints of traditional old books like the Bodu Tarutheebu and official documents like Rdava?i. It is also used by people of southern atolls when writing songs or poetry in their language variant.\\r\\n\\r\\nAccording to Sonja Fritz, \\"the dialects of Maldivian represent different diachronial stages in the development of the language. Especially in the field of morphology, the amount of archaic features steadily increase from the north to the south. Within the three southernmost atolls (of the Maldives), the dialect of the Addu islands which form the southern tip of the whole archipelago is characterized by the highest degree of archaicity\\".[14]\\r\\n\\r\\nFritz puts forward this theory based on research into the dialects of Addu and Fuvahmulah. She is yet to do research on the dialect of Huvadhu Atoll, and has to do more research on both Addu and Fuvahmulah dialect.[who?][when?] Only then can she determine whether the dialects Fuvahmulah and Huvadhu or that of Addu is more archaic. However, from Mal (Maldives) to the south up to Huvadhu Atoll (Maldives) the amount of archaic features increase but from Huvadhu Atoll the amount of archaic features decrease towards south. And the dialect of Huvadhu is characterized by the highest degree of archaicity.\\r\\n\\r\\nFritz also adds that \\"the different classes of verb conjugation and nominal inflection are best preserved there, morphological simplifications and, as a consequence increasing from atoll to atoll towards north (in the Maldives)\\".\\r\\n\\r\\nMaldivian presents another aspect with which English speakers are not too familiar: the distinction between what is spoken and what is written. Every language that has a written idiom has this distinction to a greater or lesser degree. But Asian languages such as Maldivian seem to exhibit major differences between the two varieties of language. Mal Bas and Maliku Bas are the only dialects commonly used in writing.\\r\\n\\r\\nSpoken Maldivian, for instance, has twenty seven consonants. In contrast, written or literary Maldivian contains these sounds and some Arabic sounds as well. Though these sounds are also used in speaking, their phonetics are not strictly observed. This results in pronouncing it as close as possible to the Maldivian sounds when speaking.\\r\\n\\r\\nTo make things simpler it may be said that every sentence in written Maldivian ends with the addition of ve, which is never used to end a sentence in spoken Maldivian. In using ve a strict word-order also has to be maintained. But in spoken Maldivian word-order is not considered to be very rigid.\\r\\n\\r\\nOne of the very important things one has to take into account in written Maldivian which is not so important in spoken Maldivian is the sukun on the letters alif and shaviyani. Sukun in general is a mark to indicate an abrupt stop on the sound of the letter on which it is placed. However, if it comes within the word, the letter is repeated; if it comes on a shaviyani or alif at the end of a word, it signifies the sound h; if it comes on a thaa, the sound is replaced by iy.\\r\\n\\r\\nThe Maldivian language has had its own script since very ancient times, most likely over two millennia, when Maldivian Buddhist monks translated and copied the Buddhist scriptures.\\r\\n\\r\\nIt used to be written in the earlier form (Evla) of the Dhives Akuru (\\"Dhivehi/Maldivian letters\\") which are written from left to right. Dhives Akuru were used in all of the islands between the conversion to Islam and until the 18th century. These ancient Maldivian letters were also used in official correspondence with Addu Atoll until the early 20th century. Perhaps they were used in some isolated islands and rural communities until the 1960s, but the last remaining native user died in the 1990s. Today Maldivians rarely learn the Dhives Akuru alphabet, for Arabic is being favoured as second script.[15]\\r\\n\\r\\nMaldivian is now written using a different script, called Taana or Thaana, written from right to left. This script is relatively recent.\\r\\n\\r\\nThe literacy rate of the Maldives is very high (98%) compared to other South Asian countries. Since the 1960s English has become the medium of education in most schools although they still have Maldivian language classes, but Maldivian is still the language used for the overall administration.\\r\\n\\r\\nMaldivian uses mainly the Thaana script for writing. It is an alphabet, with obligatory vowels derived from the vowel diacritics of the Arabic abjad.  It is a largely phonemic script: With a few minor exceptions, spelling can be predicted from pronunciation, and pronunciation from spelling.\\r\\n\\r\\nThe origins of Thaana are unique among the world's alphabets: The first nine letters (hÿv) are derived from the Arabic numerals, whereas the next nine (mÿd) were the local Indic numerals. (See Hindu-Arabic numerals.) The remaining letters for loanwords (tÿz) and Arabic transliteration are derived from phonetically similar native consonants by means of diacritics, with the exception of y, which is of unknown origin. This means that Thaana is one of the few alphabets not derived graphically from the original Semitic alphabet ÿ unless the Indic numerals were (see Brahmi numerals). The Thaana alphabet (h, shaviyani, nnu, r, b, ...) does not follow the ancient order of the other Indic scripts (like Sinhala or Tamil) or the order of the Arabic alphabet.\\r\\n\\r\\nThaana, like Hebrew and Arabic, is written right to left.  It indicates vowels with diacritic marks derived from Arabic. Each letter must carry either a vowel or a sukun, which indicates \\"no vowel\\". The only exception to this rule is noonu which, when written without a diacritic, indicates prenasalisation of a following stop.\\r\\n\\r\\nThe vowels are written with diacritical signs called fili. There are five fili for short vowels (a, i, u, e, o), where the first three look identical to the Arabic vowel signs (fatha, kasra and damma). Long vowels (aa, ee, oo, ey, oa) are denoted by doubled fili (except oa, which is a modification of the short obofili).\\r\\n\\r\\nThe letter alifu has no sound value of its own and is used for three different purposes:\\r\\nIt can act as a carrier for a vowel with no preceding consonant, that is, a word-initial vowel or the second part of a diphthong; when it carries a sukun, it indicates gemination (lengthening) of the following consonant; and if alifu+sukun occurs at the end of a word, it indicates that the word ends in /eh/. Gemination of nasals, however, is indicated by noonu+sukun preceding the nasal to be geminated.\\r\\n\\r\\nMaldivian is also written in Roman script and Devangarؐ script.\\r\\n\\r\\nTowards the mid-1970s, during President Ibrahim Nasir's tenure, the Maldivian government introduced telex machines in the local administration. This was viewed as great progress, but the local Thaana script was deemed to be an obstacle because messages on the telex machines could only be written in the Latin script.\\r\\n\\r\\nFollowing this, in 1976 the government approved a new official Latin transliteration, Dhivehi Latin, which was quickly implemented by the administration. Booklets were printed and dispatched to all Atoll and Island Offices, as well as schools and merchant liners. This was seen by many as the effective demise of the Thaana script.\\r\\nClarence Maloney, an American anthropologist who was in the Maldives at the time of the change, lamented the inconsistencies of the \\"Dhivehi Latin\\" which ignored all previous linguistic research on the Maldivian language done by H.C.P. Bell and Wilhelm Geiger. He wondered why the modern Standard Indic transliteration had not been considered. Standard Indic is a consistent script system that is well adapted to writing practically all languages of South Asia.[16]\\r\\n\\r\\nThe government reinstated the Thaana script shortly after President Maumoon took power in 1978. There was widespread relief in certain places, especially rural areas, where the introduction of Latin had been regarded with suspicion. However, the substandard Latin transcription of 1976 continues to be widely used.\\r\\n\\r\\nThe 412-page hard-back English-Maldivian dictionary, A Maldivian Dictionary, written by Christopher Hanby Baillie Reynolds, was published on 22 July 2003 by Routledge and contains about 5000 individual entries.\\r\\n\\r\\nThe sound system of Maldivian is similar to that of south Indian languages. Like other modern Indo-Aryan languages the Maldivian phonemic inventory shows an opposition of long and short vowels, of dental and retroflex consonants, and of single and geminate consonants.\\r\\n\\r\\n1  Abafili is the vowel sign  denoting a.\\r\\n\\r\\n2. Ibifili is the vowel sign denoting i.\\r\\n\\r\\n3. Ubufili is the vowel sign  denoting u.\\r\\n\\r\\n4. Sukun is the signdenoting absence of a vowel.\\r\\n\\r\\nMaldivian, like English, has intonation, but its patterns are very different from those of English. In Maldivian, the general tendency is to stress the first syllable of a word.\\r\\n\\r\\nMaldivian has geminate consonants. For example, the two 's' sounds in vissaara (rain) fall into adjoining syllables: vis-saa-ra. Similarly feth-thun (to swim), dhek-kun (to show).\\r\\n\\r\\nNative Maldivian (mabbas) words do not allow initial consonant clusters; the maximum syllabic structure is CVC (i.e. one vowel flanked by a consonant on each side). Many speakers of Maldivian restrict their phonology to this pattern, even when using loan words, thus iskl (VC.CVC) for skl (CCVC) \\"school\\".\\r\\n\\r\\nThe old sequence of letters used to be:\\r\\n\\r\\n? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\\r\\n\\r\\nThe letters are now ordered:\\r\\n\\r\\n? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\\r\\n\\r\\nThe letter ? was replaced by ?, and the letter ? was regarded as a letter from the set of thikijehi-Thaana (pointed Thaana) during the rule of Mohamed Ameen Didi.\\r\\n\\r\\nNouns in Maldivian inflect for definiteness, number and case. Definiteness may be one of definite, indefinite or unspecified. Number may be singular or plural. Case may be one of nominative, dative, ablative, genitive, locative, instrumental or emphatic.\\r\\n\\r\\nThe nominal system of Maldivian comprises nouns, pronouns, adjectives and numerals as parts of speech.\\r\\n\\r\\nMaldivian uses two numeral systems. Both of them are identical up to 30. After 30, however, one system places the unit numeral stem before the decade, for example, eh-thirees '31' (lit. \\"one and thirty\\") while the other combines the stem of the decade with the unit numeral, for example, thirees-ekeh '31' (\\"thirty + one\\"). The latter system also has numerals multiplied by ten for decades 70, 80 and 90. The decade fas dholhas '60' (\\"five twelves\\"), comes from a much older duodecimal, or dozen-based, system which has nearly disappeared.\\r\\n\\r\\nThe Maldivian verbal system is characterised by a derivational relationship between active, causative and involitive/intransitive verb forms.\\r\\n\\r\\nThe word order in Maldivian is not as rigid as in English, though changes in the order of words in a sentence may convey subtle differences in meaning. To ask for some fish in a market, one uses the following words: mashah (to me) mas (fish) vikkaa (sell), which may be put in any of the following orders without a change in meaning:\\r\\n\\r\\nThe word mashah (to me) may be dropped wherever the context makes it obvious.\\r\\n\\r\\nSpeakers of Maldivian use a great many loan words from many languages in their everyday conversation (see  Vocabulary). The extent to which loan words  are used varies between speakers, depending on their contacts with that language. Thus, those who have had an English education will tend to use a larger number of English words, while an average speaker with little or no contact with English will tend to use just a few. Some of these adopted words have now become so much part of the Maldivian language that there seem to be no other words that could replace them.\\r\\n\\r\\nThere are different ways by which loan words are naturalised in Maldivian. This depends on whether the loan word refers to a person, a thing, or some kind of action.\\r\\n\\r\\nIf the loan word refers to a person, the following suffixes can be used: \\r\\n\\r\\nAmong some of the most common words of this kind are the following:\\r\\n\\r\\nactor (ektaru), \\r\\nagent (ejentu), \\r\\nambassador (embesedaru), \\r\\narchitect (aakitektu), \\r\\nbodyguard (bodeegaadu),\\r\\ncashier (keyshiyaru),\\r\\ndirector (direktaru, dairektaru), \\r\\ndoctor (daktaru), \\r\\ndriver (duraivaru), \\r\\nguard (gaadu), \\r\\ninspector (inispektaru), \\r\\nmanager (meneyjaru), \\r\\nminister (ministaru), \\r\\noperator (opareytaru), \\r\\nproducer (purodiusaru), \\r\\nsergeant (saajentu),\\r\\nservant (saaventu)\\r\\n\\r\\nIf the loan word refers to a thing, the suffixes are\\r\\n\\r\\nSome of the most commonly used words of this kind are the following:\\r\\n\\r\\nbicycle (baisikalu), \\r\\nbill (bilu), \\r\\ncable (keybalu), \\r\\ncake (keyku), \\r\\ncoat (koatu), \\r\\ncounter (kauntaru), \\r\\nparcel (paarisalu/paarusalu), \\r\\nticket (tiketu)\\r\\n\\r\\nIf the loan word refers to some kind of action, the Maldivian word 'kure' (present), kuranee (present continuous), koffi (present perfect), \\"kuri\\" (past) or kuraane (future) is added after it, if it is done intentionally, and 've' (present),vanee (present continuous), vejje (present perfect), 'vi' (past) and vaane (future) is added after it, if it happens to be unintentional or passive. For example, using 'kensal' \\"cancel\\":\\r\\n\\r\\nSome examples:\\r\\n\\r\\nInherent in the Maldivian language is a form of elaborate class distinction expressed through three levels: The first level, the enme maaiy goiy (known colloquially as reethi bas), is used to address members of the upper class and of royal blood, but is now more often used on national radio and TV. To show respect for elders, officials and strangers the second level, maaiy goiy is used. People use the more informal third level aadhaige goiy in everyday life and to talk about themselves. Even a nobleman or a high official does not use the high level to talk about himself.\\r\\n\\r\\nRegarding salutations, there is no direct translation of the English \\"hello\\" or \\"good-bye\\" in Maldivian. Instead, islanders greet each other with a smile or the raising of the eyebrow and just ask \\"where are you going?\\", followed by \\"what for?\\". Goodbyes were not traditionally expressed, except in highly formal speech or in poetry\\r\\n\\r\\nMaldivian contains many loan words from other languages.\\r\\n\\r\\nAfter the arrival of Islam in South Asia, Persian and Arabic made a significant impact on Maldivian. It borrowed extensively from both languages, especially terms related to Islam and the judiciary. Some examples follow:\\r\\n\\r\\nPortuguese influence in the language can be seen from the period of Portuguese colonial power in the region. Some examples follow:\\r\\n\\r\\nMaldivian has also borrowed words from Urdu, Hindi and more recently, English (in particular many scientific and technological terms).\\r\\n\\r\\nEnglish words are also commonly used in the spoken language, for example \\"phone\\", \\"note\\", \\"radio\\", and soat (\\"shorts\\").\\r\\n\\r\\nThe following is a sample text in Maldivian,  Article 1 of the Universal Declaration of Human Rights (by the United Nations):\\r\\n\\r\\nTransliteration (SAMT):\\r\\n\\r\\nGloss (word-for-word):\\r\\n\\r\\nTranslation (grammatical):\\r\\n\\r\\nFounded in 1984, the Mahal Unit Press at Minicoy prints texts in Maldivian, among other languages. The press also publishes the Lakshadweep Times in three languages on a regular basis: Maldivian, English and Malayalam. This unit is based in the main building, constructed in 1998. For the first time in the history of Lakshadweep, Maldivian was brought into the field of typography.\\r\\n\\r\\nActivities:\\r\\n\\r\\nFreely downloadable open-source Unicode typefaces featuring Thaana letters include FreeSerif and MPH 2B Damase.\\r\\n\\r\\nFthaana, Universal Word, Accent Express, Accent Special Edition are the most common word processors used. However now most of the people use MS Word to write Maldivian.","input":"What language do they speak in the maldives?"},{"output":"a safety device mounted on some oil-filled power transformers and reactors","context":"In the field of electric power distribution and transmission, a Buchholz relay is a safety device mounted on some oil-filled power transformers and reactors, equipped with an external overhead oil reservoir called a \\"conservator\\". The Buchholz relay is used as a protective device sensitive to the effects of dielectric failure inside the equipment. A generic designation for this type of device is \\"gas detector relay\\".\\r\\n\\r\\n\\r\\nBuchholz relays have been applied on oil-filled power and distribution transformers at least since the 1940s. The relay is connected to the oil piping between the conservator and oil tank of a transformer. The piping between the main tank and conservator is arranged so that any gas evolved in the main tank tends to flow upward toward the conservator and gas detector relay. [1]\\r\\nDepending on the model, the relay has multiple methods to detect a failing transformer. On a slow accumulation of gas, due perhaps to slight overload, gas produced by decomposition of insulating oil accumulates in the top of the relay and forces the oil level down. A float switch in the relay is used to initiate an alarm signal. Depending on design, a second float may also serve to detect slow oil leaks.\\r\\nIf an electrical arc forms, gas accumulation is rapid, and oil flows rapidly into the conservator. This flow of oil operates a switch attached to a vane located in the path of the moving oil. This switch normally will operate a circuit breaker to isolate the apparatus before the fault causes additional damage. Buchholz relays have a test port to allow the accumulated gas to be withdrawn for testing. Flammable gas found in the relay indicates some internal fault such as overheating or arcing, whereas air found in the relay may only indicate low oil level or a leak. [2]\\r\\nThrough a connected gas sampling device the control can also be made from the ground. Depending on the requirements, the Buchholz relay has a flange or threaded connection. The classic Buchholz relay has to comply with the requirements of the DIN EN 50216-2 standard. Depending on the requirements, it is equipped with up to four (2 per float) switches or change-over switches, which can either send a light signal or switch off the transformer.[3]\\r\\nThe relay was first developed by Max Buchholz (1875ÿ1956) in 1921. Names like \\"beechwood relay\\" or \\"beech relay\\" are an indication of incorrectly translated German language manuals of the \\"Buchholz relay \\"","input":"What is buchholz relay what is it used for?"},{"output":"A dispute over succession to Muhammad as a caliph of the Islamic community","context":"","input":"What caused the split between sunni and shiite?"},{"output":"July 1, 1874","context":"The Philadelphia Zoo, located in the Centennial District of Philadelphia, Pennsylvania, on the west bank of the Schuylkill River, was the first true zoo in the United States. Chartered by the Commonwealth of Pennsylvania on March 21, 1859, its opening was delayed by the American Civil War until July 1, 1874. It opened with 1,000 animals and an admission price of 25 cents.[2] For a brief time, the zoo also housed animals brought over from safari on behalf of the Smithsonian Institution, which had not yet built the National Zoo.[3]\\r\\nThe Philadelphia Zoo is one of the premier zoos in the world for breeding animals that have been found difficult to breed in captivity.[4] The zoo also works with many groups around the world to protect the natural habitats of the animals in their care.\\r\\nThe zoo is 42 acres (17?ha) and is home to more than 1,300 animals, many of which are rare and endangered. The zoo features a children's zoo, a paddleboat lake, a rainforest themed carousel, and many interactive and educational exhibits.\\r\\n\\r\\n\\r\\nThe zoo was once served by the Zoological Garden station on 34th Street and Girard Avenue until 1902.[5]\\r\\nWhen the Philadelphia Zoological Garden first opened its Victorian gates on July 1, 1874 to over 3,000 visitors, it was the only institution of its kind in the New World. It began as a full-fledged zoo with varied exhibits: 200 mammals, 67 birds and 15 reptiles. 10-11 acres were enclosed with a cedar picket fence as exhibition space for buffalo, deer, wolves, foxes, bears, monkeys, birds, reptiles, etc. There were goat cart rides. Reptiles and small mammals were housed in The Solitude. There was a Carriage House at the entrance for horses that had transported visitors to the Zoo. Landscaping and architecture created a Victorian garden atmosphere that still is represented on the grounds today. The managers stressed the need for the very best facilities, affording optimum husbandry and in-depth scientific observations, including necropsies.\\r\\nThe 1876 Centennial Exhibition was held in Fairmount Park, a few blocks from the 33-acre Zoo. The U. S. President, Ulysses S. Grant, had officiated at the Exhibition and visited the Zoo on April 23. Zoo attendance that year increased as a result of the Centennial Exhibition: the nearly 680,000 attendance, a 36% increase over the preceding year, set a record that would remain unmatched until 1951, with an attendance of 857,901 visitors.\\r\\nThe Penrose Research Laboratory was established in 1901.[6] The first of its kind in any zoo, contributions of the Penrose Research Lab, have included gains in freedom from disease, increased vigor, longevity and understanding of species across the animal kingdom. In 1901 the lab began performing necropsies on every Zoo animal that became ill and died. The lab's history of preventative medicine reflected the foresight of Dr. Charles B. Penrose and Dr. Cortland Y. White, professors at the Medical School of the University of Pennsylvania.\\r\\nOver the course of the Zoo's history, the organization has developed a distinguished breeding program and is credited with many \\"firsts\\"[7] including: the first successful birth of an orangutan in a U.S. zoo in 1928, the first successful birth of a chimpanzee in a U.S. zoo in 1928, the first cheetahs born in a zoo in 1956, the first successful birth of an echidna in North America in 1983 and first recorded parent-reared Micronesian Kingfisher was bred at Philadelphia Zoo in 1985.\\r\\nPhiladelphia Zoo also pioneered the first captive management of flamingos under the direction of Curator Emeritus John A. Griswold. Through innovative feeding techniques, the Zoo was the first to gain the beautiful pink and red pigmentation of these birds. The Zoo was the first to successfully breed Chilean and greater flamingos in captivity.[8]\\r\\nThe Zoo played an important role in the 1979 film, Rocky II the second installment of the Rocky film franchise.[9] Several romantic scenes were filmed at the Zoo including Rocky Balboa's proposal to Adrian in front of the Carnivore House.\\r\\nThe brown tree snake was introduced to the island of Guam in the 1940s, and as a result, bird species endemic to the island were driven to extinction in the wild by the invasive serpent.[10] In 1983, the Guam Bird Rescue Project was spearheaded by the Philadelphia Zoo in an attempt to save the Micronesian kingfisher and the Guam rail, two native species still present in large enough numbers to benefit from intervention.[11] The rescue plan called for the capture of all kingfishers and rails on Guam and a captive management protocol was formulated. The captive breeding was carried out in U.S. zoos in an effort to save this species from extinction until reintroduction became feasible. In 1985 the first recorded parent-reared Micronesian kingfisher was bred at Philadelphia Zoo.\\r\\nIn the early morning of December 24, 1995, a fire in the World of Primates building killed 23 animals, including a family group of six lowland gorillas, a family group of three orangutans, four white-handed gibbons, and ten lemurs (two ruffed lemurs, six ring-tailed lemurs, and two mongoose lemurs).[12][13] All were members of endangered species. The animals died in their sleep from smoke inhalation (carbon monoxide poisoning); none were burned. Ten primates housed in an adjoining building, the Discovery House, survived. At the time of the fire, detection equipment existed in only 20% of the zoo buildings; the primates building, which had been constructed in 1985, was not one of them. In the ten months following the fire, the zoo installed fire detection equipment in all animal buildings.[14]\\r\\nOn July 1, 1999, the zoo opened a new primate exhibit, the PECO Primate Reserve. It features 2.5 acres (10,000?m2) of indoor and outdoor exhibits with ten species of primates, including Sumatran orangutans, Western lowland gorillas, lemurs, langurs, and gibbons.[15]\\r\\nIn 2006, the zoo opened a new, $20-million big cat exhibit, First Niagara Big Cat Falls. Showcasing the animals in scenes reminiscent of their natural habitats, this exhibit allows visitors to get very close to the cats, sometimes separated only by a pane of glass. Visitors can see 12 endangered big cats from around the world, including three new snow leopard cubs, three new cougar kittens, and a new black jaguar cub.\\r\\nOn May 25, 2007, three Amur tiger cubs were born at the Philadelphia Zoo to mother Kira and father Dmitri (also spelled \\"Dimitri\\").[16]\\r\\nOn March 21, 2009, the zoo opened its 150th Anniversary Year-Long Celebrations.\\r\\nOn May 30, 2009, the zoo opened the McNeil Avian Center, a renovation of its classic bird house. It features two birds that are extinct in the wild: the Guam rail and the Guam kingfisher. A theatre presents a fourteen-minute, 4D-movie about avian migration, following the migration of an animated oriole named Otis.\\r\\nOn October 2, 2009, the zoo welcomed a baby Sumatran orangutan, subsequently named \\"Batu\\". Batu, a female, is the first-born child to 15-year-old father Sugi and 18-year-old mother Tua. She is also the first baby orangutan to be born in the PECO Primate Reserve, which opened in 1999. The zoo, however, does have a history of successfully breeding orangutans, being the first zoo in the nation to have a successful birth in 1928.\\r\\nOn April 10, 2010, the zoo's seasonal \\"Creatures of Habitat\\" opened, a unique exhibit featuring 9 animal stations throughout the zoo, each featuring an endangered animal, and each consisting of statue(s) made completely out of Lego bricks. Each statue was created by Sean Kenney, the first of only nine Lego-certified artists in the world.[17]\\r\\nOn July 17, 2010, the zoo welcomed a new female baby giraffe to first-time parents Stella, 7, and Gus, 4, after a gestation period of over 15 months. This is the first giraffe birth at the Philadelphia Zoo in over a decade.\\r\\nPhiladelphia Zoo opened Treetop Trail in 2011, the first component of its Zoo360 animal exploration trail system, a campus-wide network of see-through mesh trails that allows animals to leave their traditional enclosures and explore more of the campus. Since then, the Great Ape Trail, Big Cat Crossing, and Gorilla Treeway have been added to the system, with additional trails planned for the future.\\r\\nOn April 13, 2013, the zoo opened KidZooU on the site of the old Pachyderm House. Also known as the Hamilton Family Children's Zoo and Faris Family Education Center, it is one of the largest projects undertaken by the zoo and replaces the old Children's Zoo open for over 50 years prior. It is notable for many ecologically conscious features, such as rain gardens and cisterns, geothermal wells, and green roofs, making it the first LEED-certified exhibit at the zoo.[18]\\r\\nOn June 25 and 26, 2014, African lion Tajiri gave birth to four cubs, the first lion cubs born at the zoo since 1996.\\r\\nOn December 29, 2016, Zenda, the oldest African lion in U.S. zoo population, was euthanized, following a sudden loss of appetite and failing health. Zenda was born at the Johannesburg Zoo in South Africa, and came to Philadelphia in 1993. She and her family were part of the Zoo360 trail. Zenda was 25.[19]\\r\\nThe zoo's welcome sign\\r\\nA flock of flamingos\\r\\nA cheetah in his enclosure\\r\\nA pygmy marmoset at the Small Mammals exhibit\\r\\nPolar bear inside her enclosure\\r\\nRed-shanked douc","input":"When was the first zoo opened in the us?"},{"output":"on the Las Vegas Strip","context":"American Ninja Warrior (sometimes abbreviated as ANW) is an American sports entertainment competition that is a spin-off of the Japanese television series Sasuke. It features hundreds of competitors attempting to complete a series of obstacle courses of increasing difficulty in various cities across the United States, in hopes of advancing to the national finals on the Las Vegas Strip, in hopes of becoming an \\"American Ninja Warrior\\".\\r\\n\\r\\nTo date only two competitors, rock-climbers Isaac Caldiero and Geoff Britten, have finished the course and achieved \\"Total Victory\\". Caldiero is the only competitor to win the cash prize. The series premiered on December 12, 2009 on the now-defunct cable channel G4 and now airs on NBC with encore episodes airing on USA Network and NBCSN.\\r\\n\\r\\nAmerican Ninja Warrior succeeded G4's American Ninja Challenge as the qualifying route for Americans to enter Sasuke. Beginning with the fourth season in 2012, regional finalists and wild card competitors competed on a nearly identical Mount Midoriyama course in Las Vegas, Nevada, rather than traveling to Japan to compete on Sasuke.\\r\\n\\r\\nAmerican Ninja Warrior was originally hosted by G4's American television personality Blair Herter, and actress and former television correspondent Alison Haislip. In the second season, American actor, comedian, and television host Matt Iseman joined the show, replacing Herter.[8] Additionally, Jimmy Smith was brought in as a co-host, while Haislip was the sideline reporter. The panel remained the same throughout season three.\\r\\n\\r\\nFor season four, skier Jonny Moseley was brought in as the new co-host, replacing Smith.[9] American journalist, sportscaster, and documentary filmmaker Angela Sun replaced Haislip.\\r\\n\\r\\nFor season five, two newcomers were added. Sports analyst and former NFL football player Akbar Gbaja-Biamila replaced Moseley, while ESPN sportscaster and model Jenn Brown replaced Sun as sideline reporter.[10] The season five panel remained the same through the sixth season.\\r\\n\\r\\nFor season seven, CBS Sports reporter Kristine Leahy joined the show as the new sideline reporter, replacing Brown.[11] The roster has stayed the same as of season ten, consisting of Iseman, Gbaja-Biamila, and Leahy.[12]\\r\\n\\r\\nPotential contestants go through a series of steps before possibly becoming an \\"American Ninja Warrior\\". Over 3,500 athletes have attempted to conquer Mount Midoriyama and become one since the series began in 2009.\\r\\n\\r\\nThere are some requirements contestants must meet before participating at a regional qualifier. Contestants must be legal residents of the United States and be in decent physical shape. There is no upper age limit, though participants must be at least 19 years old (21 years old during the first nine seasons). Contestants must fill out a 20-page questionnaire and make a video about themselves.[13] The required length of the video has differed over the years. Submission video length requirements have varied from 2 to 8 minutes, depending on the season.[14][15]\\r\\n\\r\\n1,000 people applied to compete in season one,[16] 5,000 people in season six,[17] 50,000 in season seven,[16] 70,000 in season eight,[18] and 77,000 in season nine.[19] Producers then select 100 contestants from the thousands of applicants to participate in each regional qualifier. They also select 20 to 30 \\"walk-ons\\" who may wait weeks camping outside to get a chance on the course.[16]\\r\\n\\r\\nIn each city qualifier course, the competitors that the producers have selected compete on an obstacle course consisting of six obstacles. Descriptions of each obstacle in each course are provided by the sideline reporter at the beginning of an episode.\\r\\n\\r\\nAt the beginning of each run, a buzzer sounds off, allowing a competitor to begin the course. A timer begins simultaneously. The first obstacle on any city qualifying course is the quintuple steps or floating steps, in which competitors must run across. This is followed by four different obstacles that test a competitors balance, upper-body strength and grip. These five obstacles are built above water. If a competitor falls into the water or touches it, their run ends immediately and the timer records their time.\\r\\n\\r\\nUntil season nine, the sixth and final obstacle was the 14'6\\" warped wall, in which competitors are given three chances to reach the top. In season ten, the  18-foot \\"Mega Wall\\" was introduced adjacent to the warped wall. Competitors have only one attempt to reach the top of the Mega Wall, and if successful, will win $10,000. However, if unsuccessful, the competitor will only get one attempt at the warped wall. Competitors are given the choice of which to climb.\\r\\n\\r\\nAt the top of both walls, there is a buzzer a competitor presses which stops the timer and records their time, ending their run on the course. The top 30 competitors who go the farthest the fastest advance to the city finals course. Since season nine, the top five women also advance to the city finals, regardless if they finished in the top 30.\\r\\n\\r\\nCity finals courses are the follow-up to each city qualifying course. They contain four new obstacles, in addition to the six obstacles featured in the city qualifying course. These four obstacles are all placed after the original six obstacles. As of season ten, two of the original six obstacles are replaced with new obstacles for the city finals course.\\r\\n\\r\\nThe top 15 competitors who go the farthest the fastest from each city finals course move on to compete on the National Finals course. As of season nine, the top two women in each city finals course also move on to compete on the National Finals course, even if they do not finish in the top 15. Small prizes ranging from $1,000 to $5,000 are awarded to first, second, and third finishers who complete the city finals course.[20]\\r\\n\\r\\nQualifying and finals courses are filmed back-to-back, usually over two nights. Obstacles are designed and produced in the five months prior to an episode taping, with 3ÿ4 new ones per city. In season eight, 18 obstacles were debuted.[21]\\r\\n\\r\\nThe National Finals takes place at \\"Mount Midoriyama\\", the final course for American Ninja Warrior. Located on the Las Vegas Strip, it consists of four stages, each containing various obstacles of increasing difficulty. Competitors must complete all of the 23 obstacles. Should they complete the first three stages, competitors will advance to Stage 4, where competitors attempt to climb the 75-foot rope climb, known as Mount Midoriyama, in 30 seconds or less.[22] Should a competitor achieve Total Victory, he or she receives a money prize of $500,000 from season four to season six, and $1,000,000 from season seven. Beginning in season eight, if multiple competitors complete stage 4, the competitors split the prize money, although in prior years the fastest competitor would receive the full amount.[20]\\r\\n\\r\\nThe first season of American Ninja Warrior was held in Los Angeles, where hundreds of competitors came to challenge themselves against the course and qualify for a shot at making it to Japan to compete in Sasuke 23 later in the year. The special premiered on December 12, 2009, on G4 TV and was hosted by G4's Blair Herter and Alison Haislip. Notable competitors this season included freerunners Levi Meeuwenberg and Brian Orosco, mixed martial artist Jason \\"Mayhem\\" Miller, and Hollywood stuntman Rich King. Along with competitors on every season, Lorin Ball, Brian Kretsch, Ryan Stratis, and David Campbell.\\r\\n\\r\\nOut of the ten Americans who qualified to compete at Mount Midori in Japan, only Rich King, Levi Meeuwenberg and Brian Orosco successfully completed Stage 1. The majority of the American Ninja Warrior competitors ran out of time or failed the obstacles. Levi Meeuwenberg was the only American competitor to complete Stage 2. The sole American competitor on Stage 3 fell on the \\"Shin-Cliffhanger\\" and his run came to an end.[23]\\r\\n\\r\\nThe second season premiered on December 8, 2010, on G4, and concluded on December 23, 2010 after 10 episodes. The city qualifiers were held near the beach in Venice, California, where 300 competitors took on the qualifiers course. 30 competitors advanced to the city finals course. The top 15 competitors in the city finals course then moved on to participate in \\"Ninja Warrior Boot Camp\\" in Simi Valley, where they competed in a series of team challenges for five days. The 10 finalists then moved on to compete in the season finale as part of Sasuke 26 in Japan. Five competitors completed Stage 1, while four competitors completed Stage 2. No competitor made it beyond Stage 3.[24] David Campbell was the Last Ninja Standing, having gone the farthest the fastest among the American competitors in Sasuke 26.[8]\\r\\n\\r\\nThe third season began airing on July 31, 2011, on G4 and concluded with the finale airing on August 22, 2011, as a two-hour primetime special on NBC.[25][26] Tryouts took place in May 2011 at Venice Beach, California. After the tryouts, the top 15 competitors competed in Ninja Warrior Boot Camp with the top 10 moving on to Japan for the finals of the competition as a part of Sasuke 27 and a chance at becoming the first American to conquer the course and win a $500,000 endorsement deal with K-Swiss. No competitors made it beyond Stage 3.\\r\\n\\r\\nThe fourth season of American Ninja Warrior began airing on May 20, 2012, on both G4 and NBC. There were six regional competitions held in three locations: Venice Beach (Southwest and Northwest), Dallas (Midwest and Midsouth), and Miami (Northeast and Southeast), that determined the 100 competitors to participate in the qualifying rounds. The winner of the ANW season four competition would receive $500,000 and the coveted \\"American Ninja Warrior\\" title. The season finale, held in Las Vegas, was the first time that Mount Midori was held on U.S. soil. Submission videos for American Ninja Warrior season 4 had been collected since January 25, 2012.[27]\\r\\n\\r\\nThe entire format was changed as well ÿ regional qualifiers in different parts of the country were aired, and the Mt. Midori course was recreated just off the Las Vegas Strip for the national finals. The regional qualifiers would narrow down its selections down to 30 contestants who finished its qualifying course in the fastest time as well as the contestants who finished the furthest the fastest. Qualifying obstacles would include common Stage 1 obstacles such as the Quintuple steps and the Warped wall, but its contents would change from city to city. The 30 contestants were then cut in half in the regional finals where the course would extend to include common Stage 2 and Stage 3 obstacles such as the Salmon Ladder, Cliffhanger and Body Prop. The 100 contestants who qualified (including wild cards) earned tickets to Las Vegas to challenge Mt. Midori. Brent Steffensen was the first American to defeat the Ultimate Cliffhanger on Stage 3, and he made it the farthest that season, falling on the Hang Climb. He was the only competitor to reach Stage 3 in this competition.\\r\\n\\r\\nThe fifth season of American Ninja Warrior premiered on June 30, 2013, on G4 with subsequent shows airing on NBC and G4.[28] Notably, the sideboard advertising along the course listed Esquire Network as the broadcaster as the fifth season was to premiere after G4's transition to Esquire on April 22, 2013. The network switch was eventually delayed to September 23, 2013, and Esquire took over Style Network's channel space instead. Because of this, additional reruns of the season aired on Saturday nights on NBC through the summer to maintain ratings momentum due to G4's lame duck status, with ANW being their only new program since they wound down all their original programming in January 2013. The success of the NBC re-airings led to the series being considered for NBC's main summer schedule for the next season.\\r\\n\\r\\nRegional competitions were held in Venice Beach, Baltimore, Miami, and Denver. Tryouts for the season began in February 2013[29] and ended with the last of the regional rounds taking place the following May.[30] The finale was once again held in Las Vegas. No one defeated Stage 3, but Brian Arnold fell on the last obstacle, the Flying Bar, making him the farthest-going American on the Mount Midori course since Kane Kosugi reached the final stage on Sasuke 8.\\r\\n\\r\\nThe sixth season of American Ninja Warrior premiered on May 26, 2014, on NBC with subsequent shows airing on Monday nights at 9:00 pm EST[31] and Tuesday nights at 8:00 pm EST on Esquire Network.[32] Regional competitions were held at Venice Beach, Dallas, St. Louis, Miami, and Denver. The season finale was again held in Las Vegas, the permanent home of the U.S. version of Mount Midori. Notable competitors this season included The Biggest Loser personal trainer Kim Lyons, U.S. Olympic gymnasts Jonathan Horton and Terin Humphrey, among others. Female competitor Kacy Catanzaro became the first female to make it up the \\"Warped Wall\\" in the Dallas Qualifiers. Later in the Dallas Finals, she became the first woman to complete that finals course, in 8 minutes, 59 seconds. Again, no competitor achieved \\"total victory\\". Kacy's run has over ten million views. Joe Moravsky, the \\"Weatherman\\", made it farther than anyone on season six, falling on the Hang Climb, where Brent Steffensen failed two years ago.\\r\\n\\r\\nThe seventh season of American Ninja Warrior premiered on NBC on May 25, 2015. This season's grand prize was increased from $500,000 to $1,000,000. Qualifying and finals courses were held in Venice Beach, Kansas City, Houston, Orlando, Pittsburgh, as well as a special military-only course in San Pedro. Stage 1 had a total of 38 finishers including Brent Steffensen and Dustin McKinney. In Stage 2, 30 of the 38 competitors failed. Only eight were remaining in Stage 3 including Drew Dreschel, Abel Gonzalez, Isaac Caldiero, Ian Dory, Jeremiah Morgan, Kevin Bull, Joe Moravsky and Geoff Britten. Only two competitors finished the course: Isaac Caldiero and Geoff Britten. It was the first time that any American had finished Stage 3. The season concluded with a victory: Geoff Britten was the first to complete Stage 4 with a second remaining; however, Isaac Caldiero achieved the Stage 4 rope climb in a faster time and was awarded the grand prize of $1,000,000 and the title of \\"American Ninja Warrior\\". Geoff Britten was the first Ninja to complete all six courses in a single season.\\r\\n\\r\\nSeason eight of American Ninja Warrior began on June 1, 2016, on NBC, with encore episodes airing the following day on Esquire Network. Regional competitions were held in Los Angeles, Atlanta, Indianapolis, Oklahoma City, and Philadelphia, with 28 new obstacles. Over 40 percent more women registered for season eight compared to the previous season. Additionally, prize money for possible Stage 4 winners would now be split equally among competitors who complete the rope climb in under 30 seconds.[20]\\r\\n\\r\\nIn Philadelphia's city finals, no competitors completed the finals course, a first in American Ninja Warrior history. In Stage 1 of the National Finals, many veterans of the show such as Geoff Britten and Brent Steffensen were eliminated early, while Jessie Graff became the first woman to complete Stage 1, placing fifth.[33] Tyler Yamauchi became the shortest person ever to complete the Jumping Spider obstacle at 5'1\\". Only 17 competitors successfully completed Stage 1, the lowest in ANW history.[33] On Stage 2, all athletes were eliminated except Drew Drechsel and Daniel Gil. During Stage 3, both Drechsel and Gil could not complete the course. Gil fell on the Ultimate Cliffhanger, while Drechsel went the farthest, but fell on the Hang Climb. Contrary to season seven's multiple winners, no season eight competitor made it past Stage 3.\\r\\n\\r\\nSeason  nine of American Ninja Warrior began on June 12, 2017, on NBC; Esquire Network ended operations fifteen days later on June 27, thus encore episodes shifted over to NBCSN on non-event nights with this season. The premiere was preceded by a special episode, \\"Celebrity Ninja Warrior\\" on May 25, 2017, the U.S. Red Nose Day, which was followed by a \\"USA vs. the World\\" special on June 4. New for season nine, the top five women in each city qualifying course qualified for the city finals course, and the top two women in each city finals qualified for national finals, regardless of their placement overall. Also this season, fans were given the opportunity to design their own obstacles through ANW Obstacle Design Challenge and seven fan-submitted obstacles have been featured on the show.\\r\\n\\r\\nIn the national finals, a record 41 competitors successfully completed Stage 1, including Allyssa Beird, the second woman to complete Stage 1. On Stage 2, all athletes were eliminated except Joe Moravsky, Sean Bryan and  Najee Richardson. During Stage 3, none of the three could complete the course. Richardson and Bryan fell on the Ultimate Cliffhanger, while Moravsky went the farthest, but failed Time Bomb. As in season eight, no competitor was able to complete Stage 3.\\r\\n\\r\\nSeason ten of American Ninja Warrior began airing on May 30, 2018, with new changes including a $10,000 bonus for clearing the new 18-foot Mega Wall and $100,000 prize money for the \\"Last Ninja Standing\\".\\r\\n\\r\\nNBC has aired a series of 5 specials in which ANW fan favorites compete in a team against teams of competitors from regions across the world, including Japan, Europe, Latin America, and most recently, Asia. The competitors race on the same course used in the ANW finals.\\r\\n\\r\\nThe first special was entitled USA vs. Japan, while the rest have been named USA vs. The World. The inaugural competition was aired on January 13, 2014, and was won by Team USA. The second special aired on September 15, 2014, and was won by Team Europe. The third special aired on January 31, 2016, and was won by Team USA. The fourth international competition was aired on June 4, 2017, and was again won by Team USA. The most recent special aired on March 11, 2018, and was won by Team Europe.\\r\\n\\r\\nAll of the specials have been hosted by Matt Iseman and Akbar Gbaja-Biamila. The first two included sideline reporter Jenn Brown. Since the 2016 special, Kristine Leahy has sideline reported.\\r\\n\\r\\nOn May 29, 2016, prior to the premiere of season eight, NBC aired a two-hour all-star special in which hosts Matt Iseman and Akbar Gbaja-Biamila chose their own all-star teams composed of three veterans, one rookie, and one woman. Teams competed on stages two, three, and four of the regular season finals course, Mt. Midoriyama, as well as competitions on a supersized course by testing their skills in competitions on the giant pegboard, 40-foot Salmon Ladder, Flying Shelf Grab, and Jump Hang, concluding with a race to the top of the \\"Mega\\" Warped Wall.[34]\\r\\n\\r\\nThe all-star winners were Team Akbar who won the team competition, beating Team Matt 5-3. Additionally, competitor Joe Moravsky completed Stage 2 in a record time of 1:08:52.[35]\\r\\n\\r\\nOn February 20, 2017, NBC aired a second two-hour all-star special. Like the previous year's competition, ANW hosts Matt Iseman and Akbar Gbaja-Biamila chose their own all-star teams, this year composed of one veteran, one breakout star, and one woman. Team Matt featured Chris Wilczewski, Najee Richardson, and Jesse \\"Flex\\" Lebreck. Team Akbar featured Grant McCartney, Neil \\"Crazy\\" Craver, and Meagan Martin. Also, sideline interviewer Kristine Leahy got to pick her own team, which consisted of Jessie Graff, Flip Rodriguez, and Nicholas Coolridge. Teams competed as a relay race to finish sections of stages one, two, and three of the regular season finals course, Mt. Midoriyama. Next, was the skills competition on a supersized course where individual contestants tested their skills in competition on the 75-feet tall Endless Invisible Ladder, the 4-story high Super Salmon Ladder, Supersonic Shelf Grab, Striding Steps, and the Mega Wall, which is now 20 feet high.\\r\\n\\r\\nThe all-star winners were Team Kristine, who won the team relay race competition, beating Team Matt and last year's champions Team Akbar. Their highlight of the night was completing Stage 3 in a record time of 5:30:62, making this the POM Wonderful Run of the Night.\\r\\n\\r\\nOn May 17, 2018, NBC aired a third two-hour all-star special. Like the last two seasons' competition, ANW hosts Matt Iseman and Akbar Gbaja-Biamila, along with Kristine Leahy, chose their own all-star teams, composed of two male veterans, and one female veteran. The reigning champs, Team Kristine (gray/pink) featured: Jessie Graff, Flip Rodriguez, and J.J. Woods. Team Matt (blue) featured: Jamie Rahn, Lance Pekus, and Jesse LaBreck. However, Team Akbar featured first-time all-stars: Allyssa Beird, Jon Alexis Jr., and Tyler Yamauchi.\\r\\n\\r\\nFor the first half of the special, the athletes competed individuality, earning \\"skills medals\\". First was the \\"Skills Competition\\", which consisted of who can make it up the Super Salmon Ladder, 4 stories high and 35 rungs in the fastest time. Winner: Sean Bryan (19.39). And a test of how far the all-star ninjas can fly on the Wicked Wingnuts obstacle. Winner: Drew Drechsel (20 feet). They tested their upper body strength by racing head-to-head on the Thunderbolt. Winner: Jamie Rahn. Then, it was a speed and balance challenge on the Striding Steps. Winner: Jake Murray (28.76) This year, ANW debuted a new obstacle, the Mega Spider Climb, where the eight women all-stars raced side-by-side 80 feet up to the top of the Stage 4 tower. Winner: Jessie Graff, who won the tournament-style Stage 4 competition in a time of 24:03, making this the POM Wonderful Run of the Night.\\r\\n\\r\\nThe second half showcased the team competition: Stage 1 featured a relay race through the obstacles course. First racer goes through Snake Run, Propeller Bar and Double Dipper. Next racer tackles the Jumping Spider, Parkour Run and the Warped Wall. And the anchor runs through the Domino Pipes, and the Flying Squirrel. The other two teams compete on Stage 2 for the other spot in the finals. Team Kristine won Stage 1 and got a bye into Stage 3. Stage 2 featured the Giant Ring Swing, Criss Cross Salmon Ladder, Wave Runner, Swing Surfer, Wingnut Alley and the Wall Flip. Team Matt won and moved onto Stage 3, which featured Floating Boards, Key Lock Hang, the Nail Clipper, Ultimate Cliffhanger, the Body Prop, Peg Cloud, the Time Bomb and the Floating Bar.\\r\\n\\r\\nThe all-star winners were once again Team Kristine, who won the team relay race competition with a time of 6:12.06, beating Team Matt by only 5 seconds (6:17.96).\\r\\n\\r\\n\\r\\n\\r\\nCelebrity Ninja Warrior  features celebrities competing on the American Ninja Warrior course while being coached by ANW favorites.[36]\\r\\n\\r\\nNBC announced a special entitled Celebrity Ninja Warrior for Red Nose Day which aired on May 25, 2017. The course featured modified obstacles: Floating Steps, Cannonball Drop, Fly Wheels, Block Run, Battering Ram, and the Warped Wall. After completing the course, Stephen Amell also completed the Salmon Ladder (which he performed in a scene on Arrow) and unsuccessfully attempted a new obstacle, the Swinging Pegboard; Amell's run was named the M&M's \\"Run of the Night.\\"\\r\\n\\r\\nFor every obstacle the celebrities completed, M&M's and The Rockefeller Foundation pledged to donate $5,000 to Red Nose Day.\\r\\n\\r\\nIn March 2018, NBC announced a second Celebrity Ninja Warrior special will aired during a three-hour U.S. Red Nose Day special on May 24, 2018.[37] On April 2, 2018, the celebrities competing were announced.[38] Like last year' competition, ANW hosts Matt Iseman and Akbar Gbaja-Biamila, who ran the course this year, were the hosts, along with special correspondent, actress Zooey Deschanel and sideline reporter Kristine Leahy. The course featured six modified obstacles: Floating Steps, Grab Bag, Spinning Bridge, Flying Shelf Grab, Doorknob Drop, and the 14 1/2-foot Warped Wall.\\r\\n\\r\\nEach obstacle a celebrity completed raised $5,000 for Red Nose Day; earning up to $30,000 for finishing the whole course. A total of $185,000 was raised, courtesy of Comcast.\\r\\n\\r\\nFollowing the inception of American Ninja Warrior, ANW competitors have also continued to enter other obstacle course competitions around the world, including Sasuke:\\r\\n\\r\\nOn October 9, 2015, Esquire Network announced a spin-off of American Ninja Warrior which would feature 24 three-person teams (two men and one woman) of popular ANW alumni, initially titled Team Ninja Warrior. The teams compete head-to-head against each other, running the course simultaneously, thus creating a new live duel dynamic (including crossing points where the two competitors can affect the other's progress.) The two teams with the fastest times advance to the finale where one team will be crowned the winners and receive a cash prize. Matt Iseman and Akbar Gbaja-Biamila host alongside actor and journalist, Alex Curry.[40][41][42] The series is Esquire Network's most-watched program in the channel's history.[43]\\r\\n\\r\\nOn May 31, 2016, Esquire Network ordered a sixteen-episode second season that also included a five-episode special college edition that had college-aged competitors go head-to-head against rival schools.[43] On March 6, 2017, it was announced that Team Ninja Warrior will be moving to sibling cable channel USA Network as Esquire Network winds down its linear channel operations and relaunches as an online only service. The show's second season premiered proper on April 18.[44] Ahead of its third season, the show was also re-titled American Ninja Warrior: Ninja vs. Ninja.\\r\\n\\r\\nOn May 2, 2018, the second spin-off of American Ninja Warrior, entitled American Ninja Warrior Junior, was announced. Set to premiere on Universal Kids on October 13, 2018, Matt Iseman and Akbar Gbaja-Biamila will reprise their roles from ANW as hosts, with Olympic 2016 gold medalist Laurie Hernandez joining as co-host, guiding competitors in head-to-head challenges. The series will feature 200 kids age 9ÿ14 competing along a course of miniature, kid-friendly ANW obstacles such as the warped wall. Similar to ANW, males and females will run along the same course. However, they will be divided into three age groups: 9ÿ10, 11ÿ12 and 13ÿ14,[45] with each category coached by fan-favorite athletes: Drew Dreschel, Kevin Bull, Natalie Duran,  Meagan Martin, Najee Richardson, and Barclay Stockett.[46]\\r\\n\\r\\nIn Australia and New Zealand, the show is broadcast on SBS2 (2013ÿ2017), 9Go! (2018), TV3 and Four. On April 25, 2016, it was announced Canadian broadcaster CTV picked up American Ninja Warrior for its 2016 summer broadcast schedule.[64] In the United Kingdom and Ireland, the show is broadcast on Challenge. In Israel, the show is broadcast on Yes Action. In 2016 Croatian RTL started broadcasting the show. The show is also shown in Finland on Sub-TV. In the Netherlands the show was first broadcast in 2017 on SBS 6, where their own Ninja Warrior NL has been broadcast.\\r\\n\\r\\nThe show is in syndication markets throughout the US and airs on local broadcast channels. As of August 18th 2018 the syndicated episodes are airing on MTV2 on Saturdays.","input":"Where is mt midoriyama located in las vegas?"},{"output":"Richard O'Brien","context":"","input":"Who wrote the rocky horror picture show play?"},{"output":"Iaan Bekker","context":"The present coat of arms of South Africa was introduced on Freedom Day 27 April 2000. It replaced the earlier national arms, which had been in use since 1910.[1] The motto ?ke e: ?xarra ~ke is written in the Khoisan language of the ?Xam people and translates literally to \\"diverse people unite\\". The previous motto, in Latin, was Ex Unitate Vires, translated as \\"From unity, strength\\".\\r\\n\\r\\n\\r\\nThe design process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas received, along with input from the Cabinet. The Government Communication and Information System then approached Design South Africa to brief ten of the top designers. Three designers were chosen to present their concepts to the Cabinet. Iaan Bekker's design was chosen.\\r\\nThe new arms were introduced on Freedom Day, 27 April 2000. The change reflected government's aim to highlight the democratic change in South Africa and a new sense of patriotism.\\r\\nThe coat of arms is a series of elements organised in distinct symmetric egg-like or oval shapes placed on top of one another. The completed structure of the coat of arms combines the lower and higher oval shape in a symbol of infinity. The path that connects the lower edge of the scroll, through the lines of the tusks, with the horizon above and the sun rising at the top, forms the shape of the cosmic egg from which the secretary bird rises. In the symbolic sense, this is the implied rebirth of the spirit of the great and heroic nation of South Africa.\\r\\nThe coat of arms is also a central part of the Seal of the Republic, traditionally considered to be the highest emblem of the State. Absolute authority is given to every document with an impression of the Seal of the Republic on it, as this means that it has been approved by the President of South Africa. Since 1997, however, the use of the Seal of the Republic has not actually been required by the Constitution, but it continues to be used.\\r\\nThe official blazon of the arms is:\\r\\nOr, representations of two San human figures of red ochre, statant respectant, the hands of the innermost arms clasped, with upper arm, inner wrist, waist and knee bands Argent, and a narrow border of red ochre; the shield ensigned of a spear and knobkierie in saltire, Sable. Thereabove a demi-secretary bird displayed Or, charged on the breast with a stylised representation of a protea flower with outer petals Vert, inner petals Or and seeded of nine triangles conjoined in three rows, the upper triangle Gules, the second row Vert, Or inverted and Vert, and the third row Vert, Or inverted, Sable, Or inverted and Vert. Above the head of the secretary bird an arc of seven rays facetted Or and Orange, the two outer rays conjoined to the elevated wings.\\r\\nUpon a riband Vert, the motto !KE E: /XARRA //KE in letters Argent. Issuant from the ends of the riband two pairs of elephant tusks curving inwards, the tips conjoined to the wings of the secretary bird, Or, therewithin and flanking the shields, two ears of wheat Brunatr.[2]\\r\\nThe first element is the motto, in a green semicircle. Completing the semicircle are two symmetrically placed pairs of elephant tusks pointing upwards. Within the oval shape formed by the tusks are two symmetrical ears of wheat, that in turn frame a centrally placed gold shield.\\r\\nThe shape of the shield makes reference to the drum, and contains two human figures from Khoisan rock art. The figures are depicted facing one another in greeting and in unity.\\r\\nAbove the shield are a spear and a knobkierie, crossed in a single unit. These elements are arranged harmoniously to give focus to the shield and complete the lower oval shape of foundation.\\r\\nImmediately above the oval shape of foundation, is the visual centre of the coat of arms, a protea. The petals of the protea are rendered in a triangular pattern reminiscent of the crafts of Africa.\\r\\nThe secretary bird is placed above the protea and the flower forms the chest of the bird. The secretary bird stands with its wings uplifted in a regal and uprising gesture. The distinctive head feathers of the secretary bird crown a strong and vigilant head. The rising sun above the horizon is placed between the wings of the secretary bird and completes the oval shape of ascendance.\\r\\nThe combination of the upper and lower oval shapes intersect to form an unbroken infinite course, and the great harmony between the basic elements result in a dynamic, elegant and thoroughly distinctive design. Yet it clearly retains the stability, gravity and immediacy that a coat of arms demands.\\r\\nThe first coat of arms was granted by King George V by Royal Warrant on 17 September 1910.[3] This was a few months after the formation of the Union of South Africa.\\r\\nIt was a combination of symbols representing the four provinces (formerly colonies) that made up the Union.\\r\\nThe motto, Ex Unitate Vires was officially translated as \\"Union is Strength\\" until 1961, and thereafter as \\"Unity is Strength\\".\\r\\nThree official renditions of the arms were used. The original rendition (1910) was the only version used until 1930, and it continued to be used as the rank badge of warrant officers in the South African Defence Force and South African National Defence Force until 2002. The second version, painted in 1930 and known as the \\"ordinary coat of arms\\", and the third version, painted in 1932 and known as the \\"embellished coat of arms\\", were both used until 2000.","input":"Who designed the south african coat of arms?"},{"output":"A Doctor of Medicine","context":"A Doctor of Medicine (MD from Latin Medicinae Doctor) is a medical degree, the meaning of which varies between different jurisdictions. In some countries, the MD denotes a first professional graduate degree awarded upon initial graduation from medical school.[1] In other countries, the MD denotes an academic research doctorate, higher doctorate, honorary doctorate or advanced clinical coursework degree restricted to medical graduates; in those countries, the equivalent first professional degree is titled differently (for example, Bachelor of Medicine, Bachelor of Surgery in countries following the tradition of the United Kingdom).[2]\\r\\n\\r\\n\\r\\nIn 1703, the University of Glasgow's first medical graduate, Samuel Benion, was issued with the academic degree of Doctor of Medicine.[3]\\r\\nUniversity medical education in England culminated with the MB qualification, and in Scotland the MD, until in the mid-19th century the public bodies who regulated medical practice at the time required practitioners in Scotland as well as England to hold the dual Bachelor of Medicine and Bachelor of Surgery degrees (MB BS/MBChB/MB BChir/BM BCh etc.). North American medical schools switched to the tradition of the ancient universities of Scotland and began granting the MoD title rather than the MB beginning in the late 18th century. The Columbia University College of Physicians and Surgeons in New York (which at the time was referred to as King's College of Medicine) was the first American university to grant the MD degree instead of the MB.[4]\\r\\nEarly medical schools in North America that granted the Doctor of Medicine degrees were Columbia, Penn, Harvard, Maryland, and McGill.[5] These first few North American medical schools that were established were (for the most part) founded by physicians and surgeons who had been trained in England and Scotland.\\r\\nA feminine form, \\"Doctress of Medicine\\" or Medicinae Doctrix, was also used by the New England Female Medical College in Boston in the 1860s.[6][7][8] In most countries having a Doctor of Medicine degree does not mean that the individual will be allowed to practice medicine. Typically a doctor must go through a residency (medicine) for at least four years and take some form of licensing examination in their jurisdiction.\\r\\nIn Afghanistan, medical education begins after high school. No pre-medicine courses or bachelor's degree is required. Eligibility is determined through the rank applicants obtain in the public university entrance exam (kankor) held every year throughout the country. Entry to medical school is competitive, and only students with the highest ranks are accepted into medical programs. The primary medical degree is completed in 7 years. According to the new medical curriculum (from 2016), during the 12th semester, medical students must complete research on a medical topic and provide a thesis as part of their training. Medical graduates are awarded a certificate in general medicine, regarded \\"MD\\" and validated by the \\"Ministry of Higher Education of Afghanistan\\". All physicians are to obtain licensing and a medical council registration number from the \\"Ministry of Public Health\\" before they officially begin to practice. They may subsequently specialize in a specific medical field at medical schools offering the necessary qualifications. After graduation, students may complete residency.\\r\\nBefore the civil wars in Afghanistan, medical education used to be taught by foreign professors or Afghan professors who studied medical education abroad. The Kabul medical institute certified the students as \\"Master of Medicine\\". After the civil wars, medical education has extremely changed, and the MD certification has been reduced to \\"Medicine Bachelor\\".\\r\\nIn the United States, MDs are awarded by medical schools as \\"Professional Doctorate\\"[9][10] (as opposed to the Doctor of Philosophy degree which requires additional studies) and are accredited by the Liaison Committee on Medical Education (LCME), an independent body sponsored by the Association of American Medical Colleges and the American Medical Association (AMA).[11][12]\\r\\nAdmission to medical schools in the United States and Canada is highly competitive, and in the United States about 17,800 out of approximately 47,000 applicants received at least one acceptance to any medical school in recent application years. Before entering medical school, students are required to complete a four-year undergraduate degree and take the Medical College Admission Test (MCAT); however, some combined undergraduate/medical programs exist. Before graduating from a medical school and achieving the Doctor of Medicine degree, students are required to take the United States Medical Licensing Examination (USMLE) Step 1 and both the clinical knowledge and clinical skills parts of Step 2. The M.D. degree is typically earned in four years. Following the awarding of the MD, physicians who wish to practice in the United States are required to complete at least one internship year (PGY-1) and pass the USMLE Step 3. In order to receive board eligible or board accredited status in a specialty of medicine such as general surgery or internal medicine, they undergo additional specialized training in the form of a residency. Those who wish to further specialize in areas such as cardiology or interventional radiology then complete a fellowship. Depending upon the physician's chosen field, residencies and fellowships involve an additional three to eight years of training after obtaining the M.D. This can be lengthened with additional research years, which can last one, two, or more years.\\r\\nIn Canada, the M.D. is the basic medical degree required to practice medicine. McGill University Faculty of Medicine is the only medical school in Canada that continues to award the M.D.,C.M. degrees (abbreviated M.D.C.M.). M.D.C.M. is from the Latin \\"Medicinae Doctorem et Chirurgiae Magistrum\\" meaning \\"doctor of medicine and master of surgery\\". Upon graduation, students enter into a residency phase of training. Prior to obtaining independent practicing license from a provincial regulatory body, students must complete the Medical Council of Canada Qualifying Examination to obtain the Licentiate of the Medical Council of Canada (LMCC) qualifications.\\r\\nEven though the M.D. is a professional degree and not a research doctorate (i.e., a Ph.D.), many holders of the M.D. degree conduct clinical and basic scientific research and publish in peer-reviewed journals during training and after graduation; an academic physician whose work emphasizes basic research is called a physician-scientist. Combined medical and research training is offered through programs granting an MD-PhD. The National Institutes of Health (NIH) through its Medical Scientist Training Program funds M.D.-Ph.D. training programs at many universities. Some M.D.s choose a research career and receive funding from the NIH as well as other sources such as the Howard Hughes Medical Institute.[13] The United States Department of Education and the National Science Foundation do not include the M.D. or other professional doctorates among the degrees that are equivalent to research doctorates.[14][15]\\r\\nThe entry-level first professional degree in these countries for the practice of medicine is that of Bachelor of Medicine and Bachelor of Surgery (MBBS, MB, MB BCh BAO, BMBS, MBBChir, or MBChB). This degree typically requires between four and six years of study and clinical training, and is equivalent to the North American MD degree. Due to the UK code for higher education, first degrees in medicine comprise an integrated programme of study and professional practice spanning several levels. These degrees may retain, for historical reasons, \\"Bachelor of Medicine, Bachelor of Surgery\\" and are abbreviated to MBChB, MBBS or BMBS.[16]\\r\\nIn the UK, Ireland and many Commonwealth countries, the MD is a postgraduate research degree in medicine. At some universities, this takes the form of a first doctorate, analogous to the Ph.D., awarded upon submission of a thesis and a successful viva. The thesis may consist of new research undertaken on a full- or part-time basis, with much less supervision (in the UK) than for a Ph.D., or a portfolio of previously published work.[17]\\r\\nIn order to be eligible to apply for an M.D. degree from a UK or Commonwealth University one must hold either a \\"Bachelor of Medicine, Bachelor of Surgery\\" (MBBS, MBChB, BMBS for example) degree, or an equivalent U.S.-M.D. degree and must usually have at least five years of postgraduate experience. Therefore, graduates from the MBBS/MBChB/BMBS degrees do not hold doctorates; however, physicians holding these degrees are referred to as \\"doctor\\" as they are fully licensed as medical practitioners. In some commonwealth nations, these interns are designated as \\"house officers\\".\\r\\nAt some other universities (especially older institutions, such as Oxford, Dublin, Cambridge and St Andrews), the M.D. is a higher doctorate (similar to a DSc) awarded upon submission of a portfolio of published work representing a substantial contribution to medical research.[18] The University of Cambridge is proposing to introduce a new degree of MedScD (more akin to the ScD degree) awarded on the basis of a career's contribution to the science or art of medicine, rather than a thesis, for which a candidate may be awarded the M.D. degree.[19]\\r\\nIn the case where the M.D. is awarded (either as a first or higher doctorate) for previously published research, the candidate is usually required to be either a graduate or a full-time member of staff, of several years' standing of the university in question.[20]\\r\\nIn Denmark, basic medical education and training is available at four universities: the University of Copenhagen, Aarhus University, the University of Southern Denmark and Aalborg University. The duration of basic medical education and training is six years and the course leads to the degree of Candidate of Medicine (rated equally to master's degree). Students are qualified as \\"medical doctor\\" (MD) after swearing the Hippocratic Oath upon graduation.[21]\\r\\nMedical school is usually followed by a year of residency called basic clinical training (Danish: Klinisk basisuddannelse or KBU) which upon completion grants the right to practice medicine without supervision.\\r\\nMedical studies in France are organised as follows:\\r\\nRight after graduating from high school with a Baccalaureat, any student can register at a university of medicine (there are about 30 of them throughout the country). At the end of first year, an internal ranking examination takes place in each of these universities in order to implement the numerus clausus. First year consists mainly of theoretical classes such as biophysics and biochemistry, anatomy, ethics or histology. Passing first year is commonly considered very challenging, requiring hard and continuous work. Each student can only try twice. For example, the Universit Ren Descartes welcomes about 2,000 students in first year and only 300 after numerus clausus.\\r\\nThe second and third year are usually mainly quite theoretical although the teachings are often accompanied by placements in the field (e.g., internships as nurses or in the emergency room, depending on the university).\\r\\nDuring fourth, fifth and sixth years, medical students get a special status called \\"externe\\" (In some universities, such as Pierre et Marie Curie, the externe status is given starting in the third year). They work as interns every morning at the hospital plus a few night shifts a month and study in the afternoon. Each internship lasts between three and four months and takes place in a different department. Med students get five weeks off a year.\\r\\nAt the end of the sixth year, they need to pass a national ranking exam, which will determine their specialty. The first student gets to choose first, then the second, et cetera. Usually, students work hard during fifth and sixth years in order to train properly for the national ranking exam. During these years, actual practice at the hospital and some theoretical courses are meant to balance the training. Such externs' average wage stands between 100 and 300 euros a month.\\r\\nAfter that ranking exams, students can start as residents in the specialty they have been able to pick. That is the point from which they also start getting paid.\\r\\nTowards the end of the medical program, French medical students are provided with more responsibilities and are required to defend a thesis; however, unlike a PhD thesis, no original research is actually necessary to write an MD thesis. At the conclusion of the thesis defense, French medical students receive a State Diploma of Doctor of Medicine (MD) or dipl?me d'Etat de docteur en mdecine. Every new doctor must then proceed to a Diploma of Specialised Studies (Dipl?me d'Etudes Spcialises or DES) to mark their specialty. Some students may also receive a Diploma of Complementary Specialized Studies (Dipl?me d'Etudes Spcialises Complmentaires or DESC).[22]\\r\\nAfter at least six years of medical school, the students graduate with a final federal medical exam [[Staatsexamen|(Dritter Abschnitt der ?rztlichen Prfung)]]. Graduates receive their license to practice medicine and the professional title of physician (Arzt). The academic degree Doctor of Medicine (Dr. med.) MD is a postgraduate research degree in medicine.[23] It is awarded if the graduate has, in addition, successfully completed a scientific study and dissertation. Many medical students opt to perform their thesis during their studies at medical school but are only allowed to finish the dissertation process after their studies.\\r\\nIn the Netherlands and Belgium, medical students receive six years of university education prior to their graduation.\\r\\nIn the Netherlands, students receive three years of preclinical training, followed by three years of clinical training (co-assistentschappen, or co-schappen) in hospitals. At one medical faculty, that of Utrecht University, clinical training already begins in the third year of medical school. After 6 years, students graduate as Basisartsen (comparable to Doctors of Medicine). As a result of the Bologna process, medical students in the Netherlands now receive a bachelor's degree after three years in medical school and a master's degree upon graduation. Prospective students can apply for medical education directly after finishing the highest level of secondary school, vwo; previous undergraduate education is not a precondition for admittance.\\r\\nThe Belgian medical education is much more based on theoretical knowledge than the Dutch system. In the first three years, which are very theoretical and lead to a university bachelor's degree, general scientific courses are taken such as chemistry, biophysics, physiology, biostatistics, anatomy, virology, etc. To enter the bachelor course in Flanders, prospective students have to pass an exam, as a result of the numerus clausus.\\r\\nAfter the bachelor courses, students are allowed to enter the 'master in medicine' courses, which consist of three years of theoretical and clinical study. In general, the first two master years are very theoretical and teach the students human pathology, diseases and pharmacology. The third year is a year full of internships in a wide range of specialities in different clinics. The seventh, final year serves as a kind of 'pre-specialization' year in which the students are specifically trained in the specialty they wish to pursue after medical school. This contrasts with the Dutch approach, in which graduates are literally 'basic doctors' (basisartsen) who have yet to decide on a specialty.\\r\\nIn South Korea, there is a Medical Doctor (MD) license.\\r\\nThe medical educations in South Korea (Republic of Korea) are 6 or 4 years in duration, 6-year courses starting right after high schools, and 4-year course starting after 4-year's university education(To start the 4-year course, the student needs a bachelor's degree). The first 2 years in the 6-year system is composed of basic sciences and liberal art courses.\\r\\nMedical education in Sweden begins with a five-and-a-half-year undergraduate university program leading to the degree \\"Master of Science in Medicine\\" (Swedish: L?karexamen). Following this, the National Board of Health and Welfare requires a minimum of 18 months of clinical internship (Swedish: Allm?ntj?nstg?ring) before granting a medical license (Swedish: L?karlegitimation) to be fully qualified as the Swedish equivalent to Medical Doctor (MD).[24]\\r\\nThis internship consists of surgery (3ÿ6 months), internal medicine (3ÿ6 months), psychiatry (three months) and family medicine (six months). Upon receiving a license to practice, a physician is able to apply for a post to start specialist training. There are currently 52 recognised medical specialties in Sweden. The specialist training has a duration of minimum five years, which upon completion grants formal qualification as a specialist.\\r\\nHistorically, Australian medical schools have followed the British tradition by conferring the degrees of Bachelor of Medicine and Bachelor of Surgery (MBBS) to its graduates whilst reserving the title of Doctor of Medicine (MD) for their research training degree, analogous to the PhD, or for their honorary doctorates. Although the majority of Australian MBBS degrees have been graduate programs since the 1990s, under the previous Australian Qualifications Framework (AQF) they remained categorized as Level 7 Bachelor's degrees together with other undergraduate programs.\\r\\nThe latest version of the AQF includes the new category of Level 9 Master's (Extended) degrees which permits the use of the term 'Doctor' in the styling of the degree title of relevant professional programs. As a result, various Australian medical schools have replaced their MBBS degrees with the MD to resolve the previous anomalous nomenclature. With the introduction of the Master's level MD, universities have also renamed their previous medical research doctorates. The University of Melbourne was the first to introduce the MD in 2011 as a basic medical degree, and has renamed its research degree to Doctor of Medical Science (DMedSc).[25][26]\\r\\nIn China, the degree system is very similar to the UK. Students can enter medical schools after graduating from high school. Lengths of the studies vary, there are 5-year Bachelor of Medicine, Bachelor of Surgery (MBBS), 6-year Bachelor of Medicine, Bachelor of Surgery (MBBS) with one year of hospital internship, 7-year (Masters of Medicine), and 8-year (Doctor of Medicine) programs. After a degree is acquired, one needs to pass the certification exam to be allowed to practice.\\r\\nIn Malaysia, M.D. are awarded by both private and public universities, mostly are trained as a 5 years course, however with the establishment of Perdana University, it became the first university in Malaysia to provide a 5-year graduate entry course. Examples of universities in Malaysia offering the M.D degree. are University Sains Malaysia, National University of Malaysia, University Putra Malaysia, UCSI University, etc..\\r\\nIn Argentina the First Degree of Physician or Physician Diplomate (Ttulo de Mdico)[27] is equivalent to the North American M.D. Degree with six years of intensive studies followed by usually three or four years of residency as a major specialty in a particular empiric field, consisting of internships, social services and sporadic research. Only by holding a Medical Title can the postgraduate student apply for the Doctor degree through a Doctorate in Medicine program approved by the National Commission for University Evaluation and Accreditation.[28]\\r\\nThe MBBS (Bachelor of Medicine/Bachelor of Surgery) degree represents the first (undergraduate) level of training required to be licensed as a physician(other degrees in alternative medicine are present like BAMS, BHMS, BSMS etc. ) and the MS or MD degree is a postgraduate degree, representative of specialty training. The equivalent training in the US or Canada would be the completion of a medical (post-graduate) degree. Eligibility for the MS or MD course is restricted to medical graduates holding the MBBS degree.\\r\\nThe MBBS course is for five and a half years, and training imparted is as follows:\\r\\nAfter three years of study and the successful completion of an examination, which includes both theoretical and practical elements, in a pre-clinical or clinical subject of a non-surgical nature [e.g. Anatomy (since the subject deals with study of anatomy through dissecting cadavers, thus given an MD degree), Physiology, Pharmacology, Internal Medicine, Pediatrics, Pathology, Microbiology, Pharmacology] the candidate receives MD degree, whereas in a clinical subject of a surgical nature (e.g. General Surgery, Orthopaedics, Obstetrics/Gynaecology, Ophthalmology), the candidate receives the equivalent degree Master of Surgery (MS).\\r\\nA second alternate qualification termed DNB [Diplomate of National Board], is considered equivalent to the MD and MS degrees. This can be obtained by passing the exam conducted by the National Board of Examinations after completing 3 years of post-MBBS residency training in teaching hospitals recognised by the board. The College of Physicians & Surgeons of Bombay, India (Established 1912) also awards higher postgraduate degrees in clinical and pre-clinical specialties, called FCPS; it involves three years of study and the successful completion of an examination, which includes both theoretical and practical elements, and a research thesis and a viva. The FCPS is representative of specialty clinical training, and equivalent to MD/MS/DNB in India, or Ph.D. or Professional Doctorates in other parts of the world. Until 2007, the Government of India and the Medical Council of India recognised the FCPS qualification - since then, this is being done by State Medical Councils.\\r\\nAfter obtaining the first postgraduate degree, that is MD/MS/FCPS/DNB, one can go for further specialisation in medical or surgical fields. This involves a highly competitive entrance examination. This course has three years of additional training and requires the submission of a dissertation (thesis). This is considered a clinical doctorate as the focus is on preapring a super-specialist with adequate clinical as well as research training. After the dissertation is approved and the exit examination (theory and practical) is cleared, the degree awarded is DM (Doctor of Medicine). Based on the specific field of training, the degree awarded is DM in Cardiology, Neurology, Nephrology, Gastroenterology, Neuroradiology, Critical Care, Pulmonology, Hematology, Medical Oncology, Cardio-anaesthesia, Clinical Pharmacology, Pediatric Critical Care, Pediatric Neurology, Neonataology, Pediatric Gastroenterology, Neuroanaesthesia, etc. For surgical superspecialities the degree awarded is MCh (Magister Chirurgiae), like MCh in Cardio-thoracic and Vascular Surgery, Endocrine Surgery, Neurosurgery, Surgical Gastroenterology, Urology, Plastic Surgery, Pediatric Surgery etc. DM and MCh are the clinical equivalent of a Doctorate degree. A third alternate qualification is DNB (superspecialties), offered by National Board of Examinations, like DNB in Cardiology, Neurology, Cardiac Surgery, Neurosurgery.\\r\\nFollowing DM or MCh, one can further go for postdoctoral fellowship programs of one-year duration in specific subspecialties like Cardiac Electrophysiology, Invasive cardiology, Pediatric cardiology, Epilepsy, stroke, electroencephalography, movement disorders, neuromuscular disorders, cerebrovascular surgery, skull base surgery, neurocritical care, pediatric cardiac surgery etc. offered by prestigious government institutes and abroad.\\r\\nIn Indonesia, the title of \\"dokter\\" (dr.) is awarded after a Medical student received their Bachelor in Medicine (Sarjana Kedokteran; S. Ked) after 3-3.5 years of study (at least) and 1.5ÿ2 years of clinical course in university hospitals. After a medical student finished those five years of study, they need to take \\"Uji Kompetensi Mahasiswa Program Profesi Dokter\\" (UKMPPD). If they pass the test, they can take Hippocrates Oath and the title of Dokter (dr.) is entitled before their name. Then they need to take a year-long internship course in primary health care clinics (also known as Puskesmas) or primary hospitals all over the country to practice as general practitioner under supervision of senior doctors. Those who wished to further their study into specialties can take graduate course of medicine of their preference and will be entitled with \\"Specialist of ...\\" after their name (e.g.: Sp.A for Spesialis Anak = Pediatrician). Graduate course of medicine is equal with residency program which is required the candidates to study for four years and hospital internship. Note that \\"dr.\\" is used for medical graduates, while Dr. (or wrongfully DR., Doktor) is used for PhD holders.\\r\\nIn Iran, Medical education begins after high school. No pre-med course or BSc degree is required. The eligibility is determined through the rank applicants obtain in the public university entrance exam being held every year throughout the country. The entry to medical school is competitive and only students with the highest rank are accepted into medical program. The primary medical degree is completed in 7-7.5 years. On the final years (last 1ÿ2 years) medical students need to do a research on a medical topic and provide thesis as part of their trainings. Medical graduates are awarded a certificate in general medicine, called \\"Professional Doctorate in Medicine\\" validated by the \\"Ministry of Health and Medical Education of Iran\\". All physicians will obtain license and medical council registration number from the \\"Medical Council of Iran\\" before they officially begin to practice. They may subsequently specialize in a specific medical field at medical schools offering the necessary qualifications.\\r\\nThere are five university medical schools in Israel, including the Technion in Haifa, Ben Gurion University in Be'er Sheva, Tel Aviv University, the Hebrew University in Jerusalem and the Medical school of the Bar-Ilan University in Safed. They all follow the European 6-year model except Bar-Ilan University, which has a four-year program similar to the US system.[29] However, as of 2009, Tel Aviv University has introduced a four-year program similar to the US system for students with a bachelor's degree in certain biological sciences. The entrance requirements of the various schools of medicine are very strict. Israeli students require a high school Baccalaureate average above 100 and psychometric examination grade over 740. The demand for medical education is strong and growing, and there is a lack of doctors in Israel.[citation needed] The Technion Medical School, Ben Gurion University, and Tel Aviv University Sackler Faculty of Medicine[30] offer 4-year MD programs for American students who have American college degrees and have taken the MCAT interested in completing rigorous medical education in Israel before returning to the US or Canada. The degree of Doctor of Medicine (MD) is legally considered to be equivalent to master's degree due to Israeli Educational System .[31]\\r\\nIn Latvia, the duration of basic medical education is six years and the course leads to the degree of Doctor of Medicine.[32]\\r\\nIn Pakistan the MD is a higher doctorate, awarded by medical universities based on successful completion of a residency program of four to six years' duration in a university hospital.\\r\\nIn the Philippines, the MD is a first professional degree in medicine.\\r\\nAt the end of the six-year medical programs from Bulgarian medical schools, medical students are awarded the academic degree Master in Medicine and the professional title Physician - Doctor of Medicine (MD).[33][34]\\r\\nRomanian medical programs last for 6 years (including clinical practice), which is the long-cycle first professional degree and concludes with a final licensing examination (licen?a), based on the dissertation of the student's original research. The degree awarded is 'Doctor-Medic' and graduates are entitled to use the title \\"Dr.\\"[35]\\r\\nIn Sri Lanka, the MD degree is a higher postgraduate degree that is awarded by the Postgraduate Institute of Medicine after completion of a postgraduate course, examinations and speciality training. The MD degree in Sri Lanka is representative of specialty training in clinical, para clinical, and preventive medicine (e.g., general medicine, cardiology, nephrology, oncology, para clinical such as microbiology, haematology and preventive such as community medicine). Entry for the MD course is open only for medical graduates holding the MBBS degree (with a duration of five and a half years), and training is obtained in medical disciplines that are non-surgical in nature (e.g., internal medicine, radiology, pathology, etc.) After three or four years of study and the successful completion of an examination with written as well as cases and via examinations, the MD degree in the respective field of study is awarded. In community medicine and medical administration, part I examination consists of a theoretical exam while the degree is conferred after completion of a thesis as a PhD. This thesis has to be completed within a period of five years. After successfully defending the academic thesis, the MD degree is conferred to the candidate. The MD degree holder is certified as a board certified specialist by the respective board of study of the Postgraduate Institute of Medicine after he or she undergoes 2ÿ4 years of local and foreign training depending on the specialty/subspecialty selected.\\r\\nIn Ayurveda, Bachelor of Ayurveda, Medicine and Surgery B.A.M.S in Unani, Bachelor of Unani Medicine and Surgery BUMS in Sidha, Bachelor of Sidha Medicine and Surgery BSMS are the basic qualification for practicing Ayurveda, Unani,&Sidha. The B.A.M.S, B.U.M.S, and B.S.M.S are 6-year degree (including internship) courses accepted by the University Grants Commission (Sri Lanka). M.D (Ayu)(Ayurveda vachaspati) can be done after B.A.M.S, as a specialty, and it takes 3 years (including submission of a thesis) to complete the course. Ayurveda M.D (Ayu) (Ayurveda vachaspati) is a master's degree accepted by University Grants Commission (Sri Lanka), after completion of MPhil can follow Ph.D. level programmes in Sri Lanka.\\r\\nIn Taiwan, the MD is a first professor awarded professional degree that goes up and beyond the limits of upper education.[36]\\r\\nThe American Duke University has a medical school based in Singapore (Duke-NUS Graduate Medical School), and follows the North-American model of styling its first professional degree \\"Doctor of Medicine\\" (\\"MD\\"), consid.[37] By contrast, the Yong Loo Lin School of Medicine at the National University of Singapore confers MB BS as the first professional degree.\\r\\nThe Thai medical education is 6 years system, consisting of 1 year in basic-science, 2 years in pre-clinical training, and 3 years for clinical training. Upon graduation, all medical students must pass national medical licensing examinations and a university-based comprehensive test. After medical school, newly graduated doctor are under contract to spend a year of internship and 2 years of tenure in rural areas before they are eligible for any other residency positions or specialized training. The students will receive Doctor of Medicine (MD) degree. However, the degree is equivalent to master's degree in Thailand. Specialty training after the MD degree requires at least 4ÿ6 years residency program in the training university hospitals and must pass the board examination. Board certified specialized degree is equivalent to doctorate degree.\\r\\nIn Tunisia, education is free for all Tunisian citizens and for foreigners who have scholarships. The oldest Medical school is a faculty of the University of Tunis. There are four medicine faculties situated in the major cities of Tunis, Sfax, Sousse and Monastir. Admission is bound to the success and score in the baccalaureate examination. Admission score threshold is very high, based on competition among all applicants throughout the nation. Medical school curriculum consists of five years. The first two years are medical theory, containing all basic sciences related to medicine, and the last three years consists of clinical issues related to all medical specialties. During these last three years, the student gets the status of \\"Externe\\". The student has to attend at the university hospital every day, rotating around all wards. Every period is followed by a clinical exam regarding the student's knowledge in that particular specialty. After those five years, there are two years on internship, in which the student is a physician but under the supervision of the chief doctor; the student rotates over the major and most essential specialties during period of four months each. After that, student has the choice of either passing the residency national exam or extending his internship for another year, after which he gains the status of family physician. The residency program consists of four to five years in the specialty he qualifies, depending on his score in the national residency examination under the rule of highest score chooses first. Whether the student chooses to be a family doctor or a specialist, he has to write a doctoral thesis, which he will be defending in front of a jury, after which he gains his degree of Doctor of Medicine (MD).\\r\\nAfter 6 years of general medical education (a foundation year + 5 years), all students will graduate with Bachelor of Medical Sciences (BMedSc) ???????????? ?????????????????????????. This degree does not allow graduates to work independently as Physician, but it is possible for those who wish to continue to master's degrees in other fields relating to medical sciences such as Public Health, Epidemiology, Biomedical Science, Nutrition...\\r\\nMedical graduates, who wish to be fully qualified as physicians or specialists must follow the rule as below:\\r\\nAll Medical graduates must complete Thesis Defense and pass the National Exit Exam ????????????????????????????????????? to become either GPs or Medical or Surgical Specialists.\\r\\nThere is also a similar advanced professional degree to the postgraduate MD: the Master of Surgery (usually ChM or MS, but MCh in Scotland, Ireland, Wales and at Oxford and MChir at Cambridge). The equivalence of these degrees, but their differing names, prevents the need for surgeons (addressed as Mr. in the UK) having to revert to the title Dr., which they once held as new MBBS graduates.\\r\\nIn Ireland, where the basic medical qualification includes a degree in obstetrics, there is a similar higher degree of Master of the Art of Obstetrics (MAO). A Master of Midwifery was formerly examined by the Worshipful Society of Apothecaries of London (hence MMSA) but fell into abeyance in the 1960s; in this case, the term Master referred not to a university degree but rather a professional rank that is common among craft guilds.\\r\\nIn East Africa, the medical schools in Kenya, Tanzania and Uganda award the degree of Master of Medicine (MMed) degree in both surgical and medical specialty disciplines following a three to six-year period of instruction.\\r\\nIn West Africa, the West African College of Physicians and the West African College of Surgeons award the Fellowship of the West African College of Physicians (FWACP) and the Fellowship of the West African College of Surgeons (FWACS) in medical and surgical disciplines respectively after a minimum of four-year residency training period.\\r\\nThe Doctor of Osteopathic Medicine or D.O. degree allows similar practice in the United States and Canada to the M.D. degree and Doctor of Osteopathic Medicine are fully licensed physicians.[44] The M.D. degree is awarded only by the 137 Medical Schools in the United States and holders of the M.D. degree must pass M.D. level board exams while D.O. can pass either D.O. or M.D. examinations. Similarly, M.D.'s must attend M.D. rated residency and fellowship programs while D.O.'s can attend either type of program.[45] On average, M.D. physicians score 31.4 on MCAT examinations while D.O. score 27.33 and pre-M.D.'s have an average GPA of 3.70 versus 3.53 for D.O. students and therefore Medical School admission is considered more difficult than Osteopathic Medical School admission (This data is directly from the AAMC and the AACOM which are the organizations for the two degrees).[46] The American M.D. degree is also recognized by most countries in the world. While the D.O. degree is getting more widely accepted in other countries as fully licensed physicians, some places still allow Osteopathic physicians to do Osteopathic Manipulative Medicine only.[47]","input":"What kind of degree does an md have?"},{"output":"Carl Linnaeus","context":"","input":"Who is the modern father of naming organism?"},{"output":"Indonesia","context":"Palm oil (also known as dend oil[citation needed], from Portuguese [?d?nde]) is an edible vegetable oil derived from the mesocarp (reddish pulp) of the fruit of the oil palms, primarily the African oil palm Elaeis guineensis,[1] and to a lesser extent from the American oil palm Elaeis oleifera and the maripa palm Attalea maripa.\\r\\nPalm oil is naturally reddish in color because of a high beta-carotene content. It is not to be confused with palm kernel oil derived from the kernel of the same fruit,[2] or coconut oil derived from the kernel of the coconut palm (Cocos nucifera). The differences are in color (raw palm kernel oil lacks carotenoids and is not red), and in saturated fat content: palm mesocarp oil is 49% saturated, while palm kernel oil and coconut oil are 81% and 86% saturated fats, respectively. However, crude red palm oil that has been refined, bleached and deodorized, a common commodity called RBD palm oil, does not contain carotenoids.[3]\\r\\nAlong with coconut oil, palm oil is one of the few highly saturated vegetable fats and is semisolid at room temperature.[4] Palm oil is a common cooking ingredient in the tropical belt of Africa, Southeast Asia and parts of Brazil. Its use in the commercial food industry in other parts of the world is widespread because of its lower cost[5] and the high oxidative stability (saturation) of the refined product when used for frying.[6][7] One source reported that humans consumed an average 17 pounds (7.7?kg) of palm oil per person in 2015.[8]\\r\\nThe use of palm oil in food products has attracted the concern of environmental activist groups; the high oil yield of the trees has encouraged wider cultivation, leading to the clearing of forests in parts of Indonesia and Malaysia to make space for oil-palm monoculture.[9] This has resulted in significant acreage losses of the natural habitat of the two surviving species of orangutan. One species in particular, the Sumatran orangutan, has been listed as critically endangered.[10] In 2004, an industry group called the Roundtable on Sustainable Palm Oil was formed to work with the palm oil industry to address these concerns.[11] Additionally, in 1992, in response to concerns about deforestation, the Government of Malaysia pledged to limit the expansion of palm oil plantations by retaining a minimum of half the nation's land as forest cover.[12][13] In March 2017, a documentary made by DW Germany revealed that palm oil is also used to make milk substitutes that are now used to make milk to feed calves in dairies in the German alps. These milk substitutes contain 30% milk powder and a remainder of raw protein which is in turn made of skimmed milk powder, whey powder and vegetable fats, mostly coconut oil and palm oil.[14]\\r\\n\\r\\n\\r\\nHumans used oil palms as far back as 5,000 years; in the late 1800s, archaeologists discovered a substance that they concluded was originally palm oil in a tomb at Abydos dating back to 3,000 BCE.[15] It is believed that traders brought the oil palm to Egypt.[16]\\r\\nPalm oil from E. guineensiss has long been recognized in West and Central African countries, and is widely used as a cooking oil. European merchants trading with West Africa occasionally purchased palm oil for use as a cooking oil in Europe.\\r\\nPalm oil became a highly sought-after commodity by British traders, for use as an industrial lubricant for machinery during Britain's Industrial Revolution.[17]\\r\\nPalm oil formed the basis of soap products, such as Lever Brothers' (now Unilever) \\"Sunlight\\" soap, and the American Palmolive brand.[18]\\r\\nBy around 1870, palm oil constituted the primary export of some West African countries, such as Ghana and Nigeria, although this was overtaken by cocoa in the 1880s.[citation needed]\\r\\nPalm oil, like all fats, is composed of fatty acids, esterified with glycerol. Palm oil has an especially high concentration of saturated fat, specifically the 16-carbon saturated fatty acid, palmitic acid, to which it gives its name. Monounsaturated oleic acid is also a major constituent of palm oil. Unrefined palm oil is a significant source of tocotrienol, part of the vitamin E family.[19][20]\\r\\nThe approximate concentration of esterified fatty acids in palm oil is:[21]\\r\\nRed palm oil is rich in carotenes, such as alpha-carotene, beta-carotene and lycopene, which give it a characteristic dark red color.[20][22] However, palm oil that has been refined, bleached and deodorized from crude palm oil (called \\"RBD palm oil\\") does not contain carotenes.[3]\\r\\nMany processed foods either contain palm oil or various ingredients derived from it.[23]\\r\\nAfter milling, various palm oil products are made using refining processes. First is fractionation, with crystallization and separation processes to obtain solid (stearin), and liquid (olein) fractions.[24] Then melting and degumming removes impurities. Then the oil is filtered and bleached. Physical refining[clarification needed] removes smells and coloration to produce \\"refined, bleached and deodorized palm oil\\" (RBDPO) and free fatty acids,[clarification needed] which are used in the manufacture of soaps, washing powder and other products. RBDPO is the basic palm oil product sold on the world's commodity markets. Many companies fractionate it further to produce palm olein for cooking oil, or process it into other products.[24]\\r\\nSince the mid-1990s, red palm oil has been cold-pressed and bottled for use as cooking oil, and blended into mayonnaise and salad oil.[3]\\r\\nThe highly saturated nature of palm oil renders it solid at room temperature in temperate regions, making it a cheap substitute for butter or trans fats in uses where solid fat is desirable, such as the making of pastry dough and baked goods. A recent rise in the use of palm oil in the food industry has partly come from changed labelling requirements that have caused a switch away from using trans fats.[25] Palm oil has been found to be a reasonable replacement for trans fats;[26] however, a small study conducted in 2009 found that palm oil may not be a good substitute for trans fats for individuals with already-elevated LDL levels.[27] The USDA agricultural research service states that palm oil is not a healthy substitute for trans fats.[28]\\r\\nPalm oil is used to produce both methyl ester and hydrodeoxygenated biodiesel.[29] Palm oil methyl ester is created through a process called transesterification. Palm oil biodiesel is often blended with other fuels to create palm oil biodiesel blends.[30] Palm oil biodiesel meets the European EN 14214 standard for biodiesels.[29] Hydrodeoxygenated biodiesel is produced by direct hydrogenolysis of the fat into alkanes and propane. The world's largest palm oil biodiesel plant is the Finnish-operated Neste Oil biodiesel plant in Singapore, which opened in 2011 and produces hydrodeoxygenated NEXBTL biodiesel.[31]\\r\\nThe organic waste matter that is produced when processing oil palm, including oil palm shells and oil palm fruit bunches, can also be used to produce energy. This waste material can be converted into pellets that can be used as a biofuel.[32] Additionally, palm oil that has been used to fry foods can be converted into methyl esters for biodiesel. The used cooking oil is chemically treated to create a biodiesel similar to petroleum diesel.[33]\\r\\nAlthough palm oil is applied to wounds for its supposed antimicrobial effects, research does not confirm its effectiveness.[34]\\r\\nIn 2012, the annual revenue received by Indonesia and Malaysia together, the top two producers of palm oil, was $40 billion.[35] Between 1962 and 1982 global exports of palm oil increased from around half a million to 2.4 million tonnes annually and in 2008 world production of palm oil and palm kernel oil amounted to 48 million tonnes. According to FAO forecasts by 2020 the global demand for palm oil will double, and triple by 2050.[36]\\r\\nIndonesia is the world's largest producer of palm oil, surpassing Malaysia in 2006, producing more than 20.9 million tonnes.[35][37] Indonesia expects to double production by the end of 2030.[11] At the end of 2010, 60 percent of the output was exported in the form of crude palm oil.[38] FAO data show production increased by over 400% between 1994 and 2004, to over 8.66 million metric tonnes.\\r\\nIn 2012, Malaysia, the world's second largest producer of palm oil,[39] produced 18.79 million tonnes of crude palm oil on roughly 5,000,000 hectares (19,000?sq?mi) of land.[40][41] Though Indonesia produces more palm oil, Malaysia is the world's largest exporter of palm oil having exported 18 million tonnes of palm oil products in 2011. China, Pakistan, the European Union, India and the United States are the primary importers of Malaysian palm oil products.[42]\\r\\nAs of 2011, Nigeria was the third-largest producer, with approximately 2.3?million hectares (5.7G10^6 acres) under cultivation. Until 1934, Nigeria had been the world's largest producer. Both small- and large-scale producers participated in the industry.[43][44]\\r\\nIn 2013, Thailand produced 2.0 million tonnes of crude palm oil on roughly 626 thousand hectares. Thailand expects to produce 11 million tonnes of fresh palm nuts in 2016, down from more than 12 million in 2015, the shortfall due to Thailand's drought.[45]\\r\\nIn the 1960s, about 18,000 hectares (69?sq?mi) were planted with palm. Colombia has now become the largest palm oil producer in the Americas, and 35% of its product is exported as biofuel. In 2006, the Colombian plantation owners' association, Fedepalma, reported that oil palm cultivation was expanding to 1,000,000 hectares (3,900?sq?mi). This expansion is being funded, in part, by the United States Agency for International Development to resettle disarmed paramilitary members on arable land, and by the Colombian government, which proposes to expand land use for exportable cash crops to 7,000,000 hectares (27,000?sq?mi) by 2020, including oil palms. Fedepalma states that its members are following sustainable guidelines.[46]\\r\\nSome Afro-Colombians claim that some of these new plantations have been expropriated from them after they had been driven away through poverty and civil war, while armed guards intimidate the remaining people to further depopulate the land, with coca production and trafficking following in their wake.[47]\\r\\nPalm is native to the wetlands of western Africa, and south Benin already hosts many palm plantations. Its 'Agricultural Revival Programme' has identified many thousands of hectares of land as suitable for new oil palm export plantations. In spite of the economic benefits, Non-governmental organisations (NGOs), such as Nature Tropicale, claim biofuels will compete with domestic food production in some existing prime agricultural sites. Other areas comprise peat land, whose drainage would have a deleterious environmental impact. They are also concerned genetically modified plants will be introduced into the region, jeopardizing the current premium paid for their non-GM crops.[48][49]\\r\\nCameroon had a production project underway initiated by Herakles Farms in the US.[50] However, the project was halted under the pressure of civil society organizations in Cameroon. Before the project was halted, Herakles left the Roundtable on Sustainable Palm Oil early in negotiations.[51] The project has been controversial due to opposition from villagers and the location of the project in a sensitive region for biodiversity.\\r\\nKenya's domestic production of edible oils covers about a third of its annual demand, estimated at around 380,000 metric tonnes. The rest is imported at a cost of around US$140 million a year, making edible oil the country's second most important import after petroleum. Since 1993 a new hybrid variety of cold-tolerant, high-yielding oil palm has been promoted by the Food and Agriculture Organization of the United Nations in western Kenya. As well as alleviating the country's deficit of edible oils while providing an important cash crop, it is claimed to have environmental benefits in the region, because it does not compete against food crops or native vegetation and it provides stabilisation for the soil.[52]\\r\\nGhana has a lot of palm nut species, which may become an important contributor to the agriculture of the region. Although Ghana has multiple palm species, ranging from local palm nuts to other species locally called agric, it was only marketed locally and to neighboring countries. Production is now expanding as major investment funds are purchasing plantations, because Ghana is considered a major growth area for palm oil.\\r\\nAccording to the Hamburg-based Oil World trade journal,[citation needed] in 2008 global production of oils and fats stood at 160 million tonnes. Palm oil and palm kernel oil were jointly the largest contributor, accounting for 48 million tonnes, or 30% of the total output. Soybean oil came in second with 37 million tonnes (23%). About 38% of the oils and fats produced in the world were shipped across oceans. Of the 60.3 million tonnes of oils and fats exported around the world, palm oil and palm kernel oil made up close to 60%; Malaysia, with 45% of the market share, dominated the palm oil trade.\\r\\nPreviously, palm oil could be listed as \\"vegetable fat\\" or \\"vegetable oil\\" on food labels in the European Union (EU). From December 2014, food packaging in the EU is no longer allowed to use the generic terms \\"vegetable fat\\" or \\"vegetable oil\\" in the ingredients list. Food producers are required to list the specific type of vegetable fat used, including palm oil. Vegetable oils and fats can be grouped together in the ingredients list under the term \\"vegetable oils\\" or \\"vegetable fats\\" but this must be followed by the type of vegetable origin (e.g. palm, sunflower or rapeseed) and the phrase \\"in varying proportions\\".[53]\\r\\nThe Roundtable on Sustainable Palm Oil (RSPO) was established in 2004[54] following concerns raised by non-governmental organizations about environmental impacts resulting from palm oil production. The organization has established international standards for sustainable palm oil production.[55] Products containing Certified Sustainable Palm Oil (CSPO) can carry the RSPO trademark.[56] Members of the RSPO include palm oil producers, environmental groups, and manufacturers who use palm oil in their products.[54][55]\\r\\nThe RSPO is applying different types of programmes to supply palm oil to producers.[57]\\r\\nGreenPalm is one of the retailers executing the book and claim supply chain and trading programme. It guarantees that the palm oil producer is certified by the RSPO. Through GreenPalm the producer can certify a specified amount with the GreenPalm logo. The buyer of the oil is allowed to use the RSPO and the GreenPalm label for sustainable palm oil on their products.[57]\\r\\nPalm oil is an important source of calories and a food staple in poor communities.[58][59][60]\\r\\nMuch of the palm oil that is consumed as food is cooking oil, to some degree oxidized rather than in the fresh state, and this oxidation appears to be responsible for the health risk associated with consuming palm oil.[61] On average globally, humans consumed 17 pounds (7.7?kg) of palm oil per person in 2015.[8]\\r\\nAccording to studies reported on by the Center for Science in the Public Interest (CSPI), excessive intake of palmitic acid, which makes up 44 percent of palm oil, increases blood cholesterol levels and may contribute to heart disease.[62] The CSPI also reported that the World Health Organization and the US National Heart, Lung and Blood Institute have encouraged consumers to limit the consumption of palmitic acid and foods high in saturated fat.[58][62] According to the World Health Organization, evidence is convincing that consumption of palmitic acid increases risk of developing cardiovascular diseases, placing it in the same evidence category as trans fatty acids.[63]\\r\\nIn response to negative reports on palm oil many food manufacturers transitioned to using hydrogenated vegetable oils in their products, which have also come under scrutiny for the impact these oils have on health.[64] A 2006 study supported by the National Institutes of Health and the USDA Agricultural Research Service concluded that palm oil is not a safe substitute for partially hydrogenated fats (trans fats) in the food industry, because palm oil results in adverse changes in the blood concentrations of LDL cholesterol and apolipoprotein B just as trans fat does.[27][65] However, according to two reports published in 2010 by the Journal of the American College of Nutrition palm oil is again an accepted replacement for hydrogenated vegetable oils[64] and a natural replacement for partially hydrogenated vegetable oils, which are a significant source of trans fats.[66]\\r\\nNot all saturated fats have equally cholesterolemic effects.[67] Studies have indicated that consumption of palm olein (which is more unsaturated) reduces blood cholesterol when compared to sources of saturated fats like coconut oil, dairy and animal fats.[67][68]\\r\\nThe palm oil industry has had both positive and negative impacts on workers, indigenous peoples and residents of palm oil-producing communities. Palm oil production provides employment opportunities, and has been shown to improve infrastructure, social services and reduce poverty.[69][70][71] However, in some cases, oil palm plantations have developed lands without consultation or compensation of the indigenous people occupying the land, resulting in social conflict.[72][73][74] The use of illegal immigrants in Malaysia has also raised concerns about working conditions within the palm oil industry.[75][76][77]\\r\\nSome social initiatives use palm oil cultivation as part of poverty alleviation strategies. Examples include the UN Food and Agriculture Organisation's hybrid oil palm project in Western Kenya, which improves incomes and diets of local populations,[78] and Malaysia's Federal Land Development Authority and Federal Land Consolidation and Rehabilitation Authority, which both support rural development.[79]\\r\\nThe use of palm oil in the production of biodiesel has led to concerns that the need for fuel is being placed ahead of the need for food, leading to malnutrition in developing nations. This is known as the food versus fuel debate. According to a 2008 report published in the Renewable and Sustainable Energy Reviews, palm oil was determined to be a sustainable source of both food and biofuel. The production of palm oil biodiesel does not pose a threat to edible palm oil supplies.[80] According to a 2009 study published in the Environmental Science and Policy journal, palm oil biodiesel might increase the demand for palm oil in the future, resulting in the expansion of palm oil production, and therefore an increased supply of food.[81]\\r\\nPalm oil cultivation has been criticized for impacts on the natural environment,[82][83] including deforestation, loss of natural habitats,[84] which has threatened critically endangered species such as the orangutan[85][86] and Sumatran tiger,[87] and increased greenhouse gas emissions.[83][88] Many palm oil plantations are built on top of existing peat bogs, and clearing the land for palm oil cultivation contributes to rising greenhouse gas emissions.[88][89]\\r\\nEfforts to portray palm oil cultivation as sustainable have been made by organizations including the Roundtable on Sustainable Palm Oil,[90] an industry group, and the Malaysian government, which has committed to preserve 50 percent of its total land area as forest.[12] According to research conducted by the Tropical Peat Research Laboratory, a group studying palm oil cultivation in support of the industry,[91] oil palm plantations act as carbon sinks, converting carbon dioxide into oxygen[92] and, according to Malaysia's Second National Communication to the United Nations Framework Convention on Climate Change, the plantations contribute to Malaysia's status as a net carbon sink.[93]\\r\\nEnvironmental groups such as Greenpeace and Friends of the Earth oppose the use of palm oil biofuels, claiming that the deforestation caused by oil palm plantations is more damaging for the climate than the benefits gained by switching to biofuel and utilizing the palms as carbon sinks.[89][94][95]\\r\\nWhile only 5 percent of the world's vegetable oil farmland is used for palm plantations, palm cultivation produces 38 percent of the world's total vegetable oil supply.[96] In terms of oil yield, a palm plantation is 10 times more productive than soya bean and rapeseed cultivation because the palm fruit and kernel both provide usable oil.[96]\\r\\nThe Roundtable on Sustainable Palm Oil (RSPO) was created in 2004[54] following concerns raised by non-governmental organizations about environmental impacts related to palm oil production. The organization has established international standards for sustainable palm oil production.[55] Products containing Certified Sustainable Palm Oil (CSPO) can carry the RSPO trademark.[56] Members of the RSPO include palm oil producers, environmental groups and manufacturers who use palm oil in their products.[54][55]\\r\\nPalm oil growers who produce Certified Sustainable Palm Oil have been critical of the organization because, though they have met RSPO standards and assumed the costs associated with certification, the market demand for certified palm oil remains low.[55][56] Low market demand has been attributed to the higher cost of Certified Sustainable Palm Oil, leading palm oil buyers to purchase cheaper non-certified palm oil. Palm oil is mostly fungible. In 2011, 12% of palm oil produced was certified \\"sustainable\\", though only half of that had the RSPO label.[97] Even with such a low proportion being certified, Greenpeace has argued that confectioners are avoiding responsibilities on sustainable palm oil, because it says that RSPO standards fall short of protecting rain forests and reducing greenhouse gases.[98]","input":"Where is most of the world's palm oil grown?"},{"output":"Epipaleolithic","context":"The names for archaeological periods in the list of archaeological periods vary enormously from region to region. This is a list of the main divisions by continent and region. Dating also varies considerably and those given are broad approximations across wide areas.\\r\\nThe three-age system has been used in many areas, referring to the prehistorical and historical periods identified by tool manufacture and use, of Stone Age, Bronze Age and Iron Age. Since these ages are distinguished by the development of technology, it is natural that the dates to which these refer vary in different parts of the world. In many regions, the term Stone Age is no longer used, as it has been replaced by more specific geological periods. For some regions, there is need for an intermediate Chalcolithic period between the Stone Age and Bronze Age. For cultures where indigenous metal tools were in less widespread use, other classifications, such as the lithic stage, archaic stage and formative stage refer to the development of other types of technology and social organisation.\\r\\nHistorical periods denotes periods of human development with the advantage of the development of writing. Written records tend to provide more socio-political insight into the dominant nations, and hence allow categorization according to the ruling empires and cultures, such as Hellenistic, Roman, Viking. Inevitably these definitions of periods only relate to the region of that empire or culture.\\r\\nThe Industrial Age or Modern era is generally taken to refer to post-1800. From this time, the industrial revolution which began in Western Europe resulted in global trade and greatly increased cultural exchange.\\r\\nEpipaleolithic\\r\\nNeolithic c. 7500 BCE\\r\\nIron Age\\r\\nRoman\\r\\nMiddle Stone Age\\r\\nLater Stone Age\\r\\nNeolithic c. 4000 BCE\\r\\nBronze Age (3500 ÿ 600 BCE)\\r\\nIron Age (550 BC ÿ 700 CE)\\r\\nClassic Middle Ages (c. 700 ÿ 1700 CE)\\r\\nBronze Age (3300 ÿ 1200 BCE)\\r\\nIron Age (1200 ÿ 586 BCE)\\r\\nHistorical periods (586 BCE ÿ present)\\r\\nJeulmun pottery period c. 8000 ÿ 1500 BCE\\r\\nMumun pottery period c. 1500 ÿ 300 BCE\\r\\nProtohistoric period c. 300 BCE ÿ 300/400 CE\\r\\nThree Kingdoms of Korea c. 300/400 ÿ 668 CE\\r\\nJmon period c. 10,000 ÿ 300 BCE\\r\\nYayoi period c. 300 BCE ÿ 250 CE\\r\\nYamato period c. 250 ÿ 710 CE\\r\\nNeolithic period c. 10,000 ÿ 2100 BCE\\r\\nAncient China c. 2100 ÿ 221 BCE\\r\\nImperial period c. 221 BCE ÿ 1911 CE\\r\\nModern period\\r\\nArchaic (c. 8000 ÿ 1000 BCE)\\r\\nWoodland (1000 BCE to 1000 CE)\\r\\nMississippian (800 CE to 1600 CE)\\r\\nArchaic (c. 8000 ÿ 1000 BCE)\\r\\nFormative (c. 1000 BCE ÿ 250 CE)\\r\\nClassic (250 ÿ 900 CE)\\r\\nPost-Classic (900 ÿ 1515)\\r\\nArchaic (c. 8200 ÿ 1000 BCE)\\r\\nFormative (c. 1000 BCE ÿ 500 CE)\\r\\nClassic (c. 500 ÿ 1200 CE)\\r\\nPost-Classic (c. 1200 ÿ 1900 CE)\\r\\nEuropean-Contact Pre-Settlement Period (1606 ÿ 1788 CE)\\r\\nSettlement / Pre-Industrial Period (1788 ÿ 1820 CE)\\r\\nIndustrial/Modern (1820s ÿ Present)\\r\\nNB Australian archaeology is often simply classified as Pre-historic before European settlement (prior to 1788), and Historic (post-1788) but this is contentious as it infers indigenous Australians had no history, despite having a strong oral tradition.\\r\\nClassic period (1350 ÿ 1800; 1650 ÿ 1800 in eastern South Island)\\r\\nNordic Bronze Age\\r\\nPre-Roman Iron Age\\r\\nRoman Iron Age in northern Europe (c. 1 CE ÿ 400 CE)\\r\\nGermanic Iron Age (c. 400 ÿ 800 CE)\\r\\nViking Age (c. 800 ÿ 1066 CE)\\r\\nMedieval period (1066 ÿ c. 1500)\\r\\nPost-medieval period (c. 1500 ÿ c. 1800)\\r\\nIndustrial/Modern\\r\\nMesolithic (c. 8800 ÿ 4900 BCE)\\r\\nNeolithic (c. 4900 ÿ 2000 BCE)\\r\\nBronze Age (c. 2000 ÿ 800 BCE)\\r\\nIron Age (c. late 11th century BCE ÿ 1 BCE)\\r\\nRoman (c. 56 BCE ÿ 400 CE)\\r\\nEarly medieval period (c. 400 ÿ 800 CE)\\r\\nMedieval period (800 ÿ c. 1500)\\r\\nPost-medieval period (c. 1500 ÿ c. 1800)\\r\\nIndustrial/Modern\\r\\nEpipaleolithic\\r\\nNeolithic\\r\\nChalcolithic\\r\\nBronze Age\\r\\nIron Age\\r\\nHellenistic\\r\\nRoman\\r\\nByzantine period\\r\\nOttoman Empire","input":"What is the period which precedes the neolithic revolution?"},{"output":"young stockbroker","context":"Wall Street is a 1987 American drama film, directed and co-written by Oliver Stone, which stars Michael Douglas, Charlie Sheen, and Daryl Hannah. The film tells the story of Bud Fox (Sheen), a young stockbroker who becomes involved with Gordon Gekko (Douglas), a wealthy, unscrupulous corporate raider.\\r\\nStone made the film as a tribute to his father, Lou Stone, a stockbroker during the Great Depression. The character of Gekko is said to be a composite of several people, including Dennis Levine, Ivan Boesky, Carl Icahn, Asher Edelman, Michael Milken, and Stone himself. The character of Sir Lawrence Wildman, meanwhile, was modeled on the prominent British financier and corporate raider Sir James Goldsmith. Originally, the studio wanted Warren Beatty to play Gekko, but he was not interested; Stone, meanwhile, wanted Richard Gere, but Gere passed on the role.\\r\\nThe film was well received among major film critics. Douglas won the Academy Award for Best Actor, and the film has come to be seen as the archetypal portrayal of 1980s success, with Douglas' character declaring that \\"greed is good.\\" It has also proven influential in inspiring people to work on Wall Street, with Sheen, Douglas, and Stone commenting over the years how people still approach them and say that they became stockbrokers because of their respective characters in the film.\\r\\nStone and Douglas reunited for a sequel titled Wall Street: Money Never Sleeps, which was released theatrically on September 24, 2010.\\r\\n\\r\\n\\r\\nIn 1985, Bud Fox (Charlie Sheen) is working as a junior stockbroker in New York City at Jackson Steinem & Co. He wants to work with his hero, Gordon Gekko (Michael Douglas), a legendary Wall Street player. After calling Gekko's office 59 days in a row trying to land an appointment, Bud visits Gekko on his birthday with a box of Gekko's favorite, contraband Cuban cigars. Impressed at his sheer boldness, Gekko grants Bud an interview. Bud pitches him stocks, but Gekko is unimpressed. Desperate, Bud provides him some inside information about Bluestar Airlines, which he has learned in a casual conversation from his father, Carl (Martin Sheen), the union leader for the company's maintenance workers. Intrigued, Gekko tells Bud he will think about it, but also that he \\"[looks] at a hundred deals a day,\\" but \\"[chooses] one.\\" A dejected Bud returns to his office. However, Gekko places an order for Bluestar stock and becomes one of Bud's clients. Gekko gives Bud some capital to manage, but the other stocks Bud selects lose money.\\r\\nGekko offers Bud another chance, and tells him to spy on British CEO Sir Lawrence Wildman (Terence Stamp) and discern Wildman's next move. Bud learns that Wildman is making a bid for a steel company. Through Bud's spying, Gekko makes big money, and Wildman is forced to buy Gekko's shares off him to complete his takeover.\\r\\nBud becomes wealthy, enjoying Gekko's promised perks, including a penthouse on Manhattan's Upper East Side and a trophy girlfriend, interior decorator Darien (Daryl Hannah). Bud is promoted to a senior stockbroker as a result of the large commission fees he is bringing in from Gekko's trading, and is given a corner office with a view. He continues to maximize inside information and use friends as straw buyers to provide more income for him and Gekko. Unknown to Bud, several of his trades attract the attention of the Securities and Exchange Commission.\\r\\nBud pitches a new idea to Gekko: buy Bluestar Airlines and expand the company, with Bud as president, using savings achieved by union concessions and the overfunded pension. Even though Bud is unable to persuade his father to support him and Gekko, he is able to get the unions to push for the deal. Soon afterward, Bud learns that Gekko plans to dissolve the company and sell off Bluestar's assets in order to access cash in the company's pension plan, leaving Carl and the entire Bluestar staff unemployed. Although this would leave Bud a very rich man, he is angered by Gekko's deceit and racked with the guilt of being an accessory to Bluestar's impending destruction, especially after his father suffers a heart attack. Bud resolves to disrupt Gekko's plans, and breaks up with Darien when she refuses to go against Gekko, her former lover.\\r\\nBud devises a plan to drive up Bluestar's stock before manipulating it back down. He and the other union presidents then secretly meet with Wildman and arrange for him to buy controlling interest in Bluestar at a significant discount. Gekko, realizing that his stock is plummeting, dumps his remaining interest in the company on Bud's advice. However, when Gekko learns on the evening news that Wildman is buying Bluestar, he realizes that Bud has engineered the entire scheme. Bud triumphantly goes back to work at Jackson Steinem the following day, only to be arrested for insider trading.\\r\\nSometime later, Bud confronts Gekko in Central Park. Gekko physically assaults Bud as he berates him for his role with Bluestar and accuses him of ingratitude for several of their illicit trades. Following the confrontation, it is revealed that Bud has turned state's evidence and was wearing a wire to record his encounter with Gekko. He turns the wire tapes over to the authorities, who suggest that he may get a lighter sentence in exchange for helping them make a case against Gekko. Later on, Bud's parents drive him down FDR Drive towards the New York State Supreme Court Building downtown to answer for the crimes he committed under Gekko's influence. Carl tells him he did right in saving the airline. The film ends with Bud going up the steps of the courthouse, knowing that while he is likely going to prison and his career is ruined, he now has a clear conscience.\\r\\nAfter the success of Platoon (1986), Stone wanted film school friend and Los Angeles screenwriter Stanley Weiser to research and write a screenplay about quiz show scandals in the 1950s.[2] During a story conference, Stone suggested making a film about Wall Street instead. The director pitched the premise of two investment partners getting involved in questionable financial dealings, using each other, and they are tailed by a prosecutor as in Crime and Punishment.[2] The director had been thinking about this kind of a movie as early as 1981[3] and was inspired by his father, Lou Stone, a broker during the Great Depression at Hayden Stone.[4]\\r\\nThe filmmaker knew a New York businessman who was making millions and working long days putting together deals all over the world. This man started making mistakes that cost him everything. Stone remembers that the \\"story frames what happens in my movie, which is basically a Pilgrims Progress of a boy who is seduced and corrupted by the allure of easy money. And in the third act, he sets out to redeem himself\\".[3] Stone asked Weiser to read Crime and Punishment, but Weiser found that its story did not mix well with their own. Stone then asked Weiser to read The Great Gatsby for material that they could use, but it was not the right fit either.[2] Weiser had no prior knowledge of the financial world and immersed himself in researching the world of stock trading, junk bonds, and corporate takeovers. He and Stone spent three weeks visiting brokerage houses and interviewing investors.[2]\\r\\nWeiser wrote the first draft, initially called Greed, with Stone writing another draft. Originally, the lead character was a young Jewish broker named Freddie Goldsmith, but Stone changed it to Bud Fox to avoid the stereotype that Wall Street was controlled by Jews.[3] Reportedly, Gordon Gekko is said to be a composite of several people: Wall Street broker Owen Morrisey, an old friend of Stone's[5] who was involved in a $20 million insider trading scandal in 1985, Dennis Levine, Ivan Boesky,[6] corporate raider Carl Icahn, art collector Asher Edelman, agent Michael Ovitz, and Stone himself.[2] For example, the \\"Greed is good\\" line was based on a speech by Boesky where he said, \\"Greed is right\\".[7]\\r\\nAccording to Edward R. Pressman, producer of the film, \\"Originally, there was no one individual who Gekko was modeled on\\", he adds, \\"But Gekko was partly Milken\\". Also, Pressman has said that the character of Sir Larry Wildman was modeled on James Goldsmith, the Anglo-French billionaire and corporate-raider.[8]\\r\\nAccording to Weiser, Gekko's style of speaking was inspired by Stone. \\"When I was writing some of the dialogue I would listen to Oliver on the phone and sometimes he talks very rapid-fire, the way Gordon Gekko does\\".[3] Stone cites as influences on his approach to business, the novels of Upton Sinclair, Sinclair Lewis and Victor Hugo, and the films of Paddy Chayefsky because they were able to make a complicated subject clear to the audience.[9] Stone set the film in 1985 because insider trading scandals culminated in 1985 and 1986.[9] This led to anachronisms in the script, including a reference to the Space Shuttle Challenger disaster, which had not yet occurred.\\r\\nStone met with Tom Cruise about playing Bud Fox, but the director had already committed to Charlie Sheen for the role.[3] Stone liked the \\"stiffness\\" of Sheen's acting style and used it to convey Bud's naivete.[10] Michael Douglas had just come off heroic roles like the one in Romancing the Stone and was looking for something dark and edgy.[3] The studio wanted Warren Beatty to play Gekko, but he was not interested. Stone initially wanted Richard Gere but the actor passed, so Stone went with Douglas despite having been advised by others in Hollywood not to cast him.[3] Stone remembers, \\"I was warned by everyone in Hollywood that Michael couldn't act, that he was a producer more than an actor and would spend all his time in his trailer on the phone\\". Nevertheless, Stone found out that \\"when he's acting he gives it his all\\".[11] Stone said that he saw \\"that villain quality\\" in Douglas and always thought he was a smart businessman.[12] Douglas remembers that when he first read the screenplay, \\"I thought it was a great part. It was a long script, and there were some incredibly long and intense monologues to open with. Id never seen a screenplay where there were two or three pages of single-spaced type for a monologue. I thought, whoa! I mean, it was unbelievable\\".[3] For research, he read profiles of corporate raiders T. Boone Pickens and Carl Icahn.[3]\\r\\nStone gave Charlie Sheen the choice of Jack Lemmon or Martin Sheen to play his father in the film, and Sheen picked his father. The elder Sheen related to the moral sense of his character.[10] Stone cast Daryl Hannah as Bud Fox's materialistic girlfriend Darien Taylor, but felt that she was never happy with the role and did not know why she accepted it. He tried to explain the character to Hannah repeatedly, and thought that the materialism of the character conflicted with Hannah's idealism.[10] Stone said later that he was aware early on that she was not right for the part. \\"Daryl Hannah was not happy doing the role and I should have let her go. All my crew wanted to get rid of her after one day of shooting. My pride was such that I kept saying I was going to make it work\\".[3] Stone also had difficulties with Sean Young, who made her opinions known that Hannah should be fired and that she should play that role instead. Young would show up to the set late and unprepared. She did not get along with Charlie Sheen, which caused further friction on the set. In retrospect, Stone felt that Young was right and he should have swapped Hannah's role with hers.[3] Stone admits that he had \\"some problems\\" with Young, but was not willing to confirm or deny rumors that she walked off with all of her costumes when she completed filming.[12]\\r\\nStone wanted to shoot the movie in New York City and that required a budget of at least $15 million, a moderate shooting budget by 1980s standards. The studio that backed Platoon felt that it was too risky a project to bankroll and passed. Stone and producer Edward R. Pressman took it to 20th Century Fox and filming began in April 1987 and ended on July 4 of the same year.[13] Parts of the film were shot in Snowbird, Utah.[14] According to Stone, he was \\"making a movie about sharks, about feeding frenzies. Bob [director of photography Robert Richardson] and I wanted the camera to become a predator. There is no letup until you get to the fixed world of Charlies father, where the stationary camera gives you a sense of immutable values\\".[3] The director saw Wall Street as a battle zone and \\"filmed it as such\\" including shooting conversations like physical confrontations and in ensemble shots had the camera circle the actors \\"in a way that makes you feel you're in a pool with sharks\\".[15]\\r\\nJeffrey \\"Mad Dog\\" Beck, a star investment banker at the time with Drexel Burnham Lambert, was one of the film's technical advisers and has a cameo appearance in the film as the man speaking at the meeting discussing the breakup of Bluestar. Kenneth Lipper, investment banker and former deputy mayor of New York for Finance and Economic Development, was also hired as chief technical adviser.[16] At first, he turned Stone down because he felt that the film would be a one-sided attack. Stone asked him to reconsider and Lipper read the script responding with a 13-page critique.[17] For example, he argued that it was unrealistic to have all the characters be \\"morally bankrupt\\".[16] Lipper advised Stone on the kind of computers used on the trading floor, the accurate proportion of women at a business meeting, and the kinds of extras that should be seated at the annual shareholders meeting where Gekko delivers his \\"Greed is good\\" speech.[16] Stone agreed with Lipper's criticism and asked him to rewrite the script. Lipper brought a balance to the film and this helped Stone get permission to shoot on the floor of the New York Stock Exchange during trading hours.[17] Lipper and Stone disagreed over the character of Lou Mannheim. Stone shot a scene showing the honest Mannheim giving in to insider trading, but Lipper argued that audiences might conclude that everyone on Wall Street is corrupt and insisted that the film needed an unimpeachable character. Stone cut the scene.[17]\\r\\nStone also consulted with Carl Icahn, Asher Edelman, convicted inside trader David Brown, several government prosecutors, and Wall Street investment bankers.[12] In addition, traders were brought in to coach actors on the set on how to hold phones, write out tickets, and talk to clients.[17] Stone asked Lipper to design a six-week course that would expose Charlie Sheen to a cross section of young Wall Street business people. The actor said, \\"I was impressed and very, very respectful of the fact that they could maintain that kind of aggressiveness and drive\\".[18]\\r\\nDouglas worked with a speech instructor on breath control in order to become better acclimatized to the fast rhythm of the film's dialogue. Early on in the shoot, Stone tested Douglas by enhancing his \\"repressed anger\\", according to the actor.[10] At one point, Stone came into Douglas' trailer and asked him if he was doing drugs because \\"you look like you haven't acted before\\".[10] This shocked Douglas, who did more research and worked on his lines again and again, pushing himself harder than he had before. All of this hard work culminated with the \\"Greed is good\\" speech.[10] Stone planned to use a Fortune magazine cover in exchange for promotional advertisements, but Forbes magazine made a similar offer. Stone stuck with Fortune, which upset Forbes publisher Malcolm Forbes, who turned down a later request to use his private yacht.[19] Stone switched from 12- to 14-hour shooting days in the last few weeks in order to finish principal photography before an impending Directors Guild of America strike and finished five days ahead of schedule.[19] Sheen remembered that Stone was always looking at the script and at his watch.[10]\\r\\nThe original score composed by Stewart Copeland was released on LP record in 1988, with the first five tracks from Copeland's score from the film Talk Radio,[20] followed by a CD version in 1993.[21]\\r\\nSide 1\\r\\nSide 2\\r\\nThe film has come to be seen as the archetypal portrayal of 1980s excess, with Douglas advocating \\"greed, for lack of a better word, is good\\".[22] Wall Street defines itself through a number of morality conflicts putting wealth and power against simplicity and honesty,[23][24] and an attack on the value system of extreme competitiveness where ethics and the law are simply irrelevant parts of the show.[25]\\r\\nCarl (Martin Sheen's character) represents the working class in the film: he is the union leader for the maintenance workers at Bluestar. He constantly attacks big business, money, mandatory drug screening, greedy manufacturers, and anything that he sees as a threat to his union. The conflict between Gekko's relentless pursuit of wealth and Carl Fox's leftward leanings form the basis of the film's subtext.[23] This subtext could be described as the concept of the two fathers battling for control over the morals of the son, a concept Stone had also used in Platoon. In Wall Street the hard-working Carl Fox and the cutthroat businessman Gordon Gekko represent the fathers. The producers of the film use Carl as their voice in the film, a voice of reason amid the creative destruction brought about by Gekko's unrestrained personal philosophy.[23]\\r\\nA significant scene in the film is a speech by Gekko to a shareholders' meeting of Teldar Paper, a company he is planning to take over. Stone uses this scene to give Gekko, and by extension, the Wall Street raiders he personifies, the chance to justify their actions, portraying himself as a liberator of the company value from the ineffective and excessively compensated executives.[23] The inspiration for the \\"Greed is good\\" speech seems to have come from two sources. The first part, where Gekko complains that the company's management owns less than three percent of its stock, and that it has too many vice presidents, is taken from similar speeches and comments made by Carl Icahn about companies he was trying to take over.[23] The defense of greed is a paraphrase of the May 18, 1986, commencement address at the UC Berkeley's School of Business Administration, delivered by arbitrageur Ivan Boesky (who himself was later convicted of insider trading charges), in which he said, \\"Greed is all right, by the way. I want you to know that. I think greed is healthy. You can be greedy and still feel good about yourself.\\"[26][27]\\r\\nWall Street is not a wholesale criticism of capitalism, but of the cynical, quick-buck culture of the 1980s.[23] The \\"good\\" characters in the film are themselves capitalists, but in a more steady, hardworking sense. In one scene, Gekko scoffs at Bud Fox's question as to the moral value of hard work, quoting the example of his (Gekko's) father, who worked hard his entire life only to die in debt. Lou Mannheim, the film's archetypal mentor, says early in the film, that \\"good things sometimes take time\\", referring to IBM and Hiltonin contrast, Gekko's \\"Greed is Good\\" credo typifies the short-term view prevalent in the 1980s.[23]\\r\\nWall Street was released on December 11, 1987, in 730 theaters and grossed $4.1 million on its opening weekend. It went on to make $43.8 million in North America.[28]\\r\\nThe film has a 78% rating on Rotten Tomatoes and a 56 metascore on Metacritic. In his review for The New York Times, Vincent Canby, while quite critical of the film overall, praised Douglas' work as \\"the funniest, canniest performance of his career\\".[29] Roger Ebert gave the film three-and-a-half stars out of four and praised it for allowing \\"all the financial wheeling and dealing to seem complicated and convincing, and yet always have it make sense. The movie can be followed by anybody, because the details of stock manipulation are all filtered through transparent layers of greed. Most of the time we know what's going on. All of the time, we know why\\".[30] Time magazine's Richard Corliss wrote, \\"This time he works up a salty sweat to end up nowhere, like a triathlete on a treadmill. But as long as he keeps his players in venal, perpetual motion, it is great scary fun to watch him work out\\".[31] In his review for the Globe and Mail, Jay Scott praised the performances of the two leads: \\"But Douglas's portrayal of Gordon Gekko is an oily triumph and as the kid Gekko thinks he has found in Fox ('Poor, smart and hungry; no feelings'), Charlie Sheen evolves persuasively from gung-ho capitalist child to wily adolescent corporate raider to morally appalled adult\\".[32] Rita Kempley in the Washington Post wrote that the film \\"is at its weakest when it preaches visually or verbally. Stone doesn't trust the time-honored story line, supplementing the obvious moral with plenty of soapboxery\\".[33]\\r\\nMichael Douglas won the Academy Award for Best Actor and thanked Oliver Stone for \\"casting me in a part that almost nobody thought I could play\\".[34] However, Daryl Hannah's performance was not as well received and earned her a Razzie for Worst Supporting Actress, thus making this the only film to date to win both an Oscar and a Razzie. The \\"quintessential financial high-roller's attire\\"[35] of Michael Douglas in the movie, designed by Alan Flusser, was emulated in the 1980s by yuppies.[36]\\r\\nWall Street enjoyed renewed interest in the film in 1990 when the cover of Newsweek magazine asked, \\"Is Greed Dead?\\" after 1980s icons like Michael Milken and Ivan Boesky ran afoul of insider trading laws.[4] Over the years, the film's screenwriter Stanley Weiser has been approached by numerous people who told him, \\"The movie changed my life. Once I saw it I knew that I wanted to get into such and such business. I wanted to be like Gordon Gekko\\".[2] In addition, both Charlie Sheen and Michael Douglas still have people come up to them and say that they became stockbrokers because of their respective characters in the film.[10] In recent years, Stone was asked how the financial market depicted in Wall Street has changed and he replied, \\"The problems that existed in the 1980s market grew and grew into a much larger phenomenon. Enron is a fiction, in a sense, in the same way that Gordon Gekko's buying and selling was a fiction ... Kenny Layhe's the new Gordon Gekko\\".[7] Entertainment Weekly magazine's Owen Gleiberman recently commented that the film, \\"reveals something now which it couldn't back then: that the Gordon Gekkos of the world weren't just getting richthey were creating an alternate reality that was going to crash down on all of us\\".[37]\\r\\nA 20th-anniversary edition was released on September 18, 2007. New extras include an on-camera introduction by Stone, extensive deleted scenes, \\"Greed is Good\\" featurettes, and interviews with Michael Douglas and Martin Sheen.[38]\\r\\nIn reviewing the film's sequel 23 years later, Variety noted that though the original film was \\"intended as a cautionary tale on the pitfalls of unchecked ambition and greed, Stone's 1987 original instead had the effect of turning Douglas' hugely charismatic (and Oscar-winning) villain into a household name and boardroom icon -- an inspiration to the very power players and Wall Street wannabes for whom he set such a terrible example\\".[39]\\r\\nThe film is recognized by American Film Institute in these lists:\\r\\nIn 2007, The New York Times reported that a sequel to Wall Street, to be subtitled Money Never Sleeps, was already in pre-production.[42] Michael Douglas would reprise his role as Gordon Gekko. The film would also focus on Gekko, recently released from prison and re-entering a much more chaotic financial world than the one he once oversaw.[42] Charlie Sheen would also reprise his character of Bud Fox, but only in a cameo role.[43] Daryl Hannah would not be involved in the sequel.[44][45]\\r\\nBut by April 2009, 20th Century Fox confirmed that the sequel was already in development and announced that Oliver Stone would direct.[46] In addition, Shia LaBeouf was cast with Josh Brolin.[47] Javier Bardem had been considered,[48] but Bardem dropped out due to scheduling conflicts.[49] The film was finally released on September 24, 2010.[50]","input":"Who is bud fox and what is his occupation?"},{"output":"same side of the carbon chain","context":"Cisÿtrans isomerism, also known as geometric isomerism or configurational isomerism, is a term used in organic chemistry. The prefixes \\"cis\\" and \\"trans\\" are from Latin. In the context of chemistry, cis indicates that the functional groups are on the same side of the carbon chain[1] while trans conveys that functional groups are on opposing sides of the carbon chain. Cis-trans isomers are stereoisomers, that is, pairs of molecules which have the same formula but whose functional groups are rotated into a different orientation in three-dimensional space. It is not to be confused with EÿZ isomerism, which is an absolute stereochemical description, and only to be used with alkenes. In general, stereoisomers contain double bonds that cannot rotate, or they may contain ring structures, where the rotation of bonds is restricted or prevented.[2] Cis and trans isomers occur both in organic molecules and in inorganic coordination complexes. Cis and trans descriptors are not used for cases of conformational isomerism where the two geometric forms easily interconvert, such as most open-chain single-bonded structures; instead, the terms \\"syn\\" and \\"anti\\" would be used.\\r\\nThe term \\"geometric isomerism\\" is considered by IUPAC to be an obsolete synonym of \\"cisÿtrans isomerism\\".[3]\\r\\n\\r\\n\\r\\nWhen the substituent groups are oriented in the same direction, the diastereomer is referred to as cis, whereas, when the substituents are oriented in opposing directions, the diastereomer is referred to as trans. An example of a small hydrocarbon displaying cisÿtrans isomerism is but-2-ene.\\r\\nAlicyclic compounds can also display cisÿtrans isomerism. As an example of a geometric isomer due to a ring structure, consider 1,2-dichlorocyclohexane:\\r\\nCis and trans isomers often have different physical properties. Differences between isomers, in general, arise from the differences in the shape of the molecule or the overall dipole moment.\\r\\nThese differences can be very small, as in the case of the boiling point of straight-chain alkenes, such as pent-2-ene, which is 37?C in the cis isomer and 36?C in the trans isomer.[4] The differences between cis and trans isomers can be larger if polar bonds are present, as in the 1,2-dichloroethenes. The cis isomer in this case has a boiling point of 60.3?C, while the trans isomer has a boiling point of 47.5?C.[5] In the cis isomer the two polar C-Cl bond dipole moments combine to give an overall molecular dipole, so that there are intermolecular dipoleÿdipole forces (or Keesom forces), which add to the London dispersion forces and raise the boiling point. In the trans isomer on the other hand, this does not occur because the two C?Cl bond moments cancel and the molecule has a net zero dipole (it does however have a non-zero quadrupole).\\r\\nThe two isomers of butenedioic acid have such large differences in properties and reactivities that they were actually given completely different names. The cis isomer is called maleic acid and the trans isomer fumaric acid. Polarity is key in determining relative boiling point as it causes increased intermolecular forces, thereby raising the boiling point. In the same manner, symmetry is key in determining relative melting point as it allows for better packing in the solid state, even if it does not alter the polarity of the molecule. One example of this is the relationship between oleic acid and elaidic acid; oleic acid, the cis isomer, has a melting point of 13.4?C, making it a liquid at room temperature, while the trans isomer, elaidic acid, has the much higher melting point of 43?C, due to the straighter trans isomer being able to pack more tightly, and is solid at room temperature.\\r\\nThus, trans alkenes, which are less polar and more symmetrical, have lower boiling points and higher melting points, and cis alkenes, which are generally more polar and less symmetrical, have higher boiling points and lower melting points.\\r\\nIn the case of geometric isomers that are a consequence of double bonds, and, in particular, when both substituents are the same, some general trends usually hold. These trends can be attributed to the fact that the dipoles of the substituents in a cis isomer will add up to give an overall molecular dipole. In a trans isomer, the dipoles of the substituents will cancel out[citation needed] due to being on opposite sides of the molecule. Trans isomers also tend to have lower densities than their cis counterparts.[citation needed]\\r\\nAs a general trend, trans alkenes tend to have higher melting points and lower solubility in inert solvents, as trans alkenes, in general, are more symmetrical than cis alkenes.[6]\\r\\nVicinal coupling constants (3JHH), measured by NMR spectroscopy, are larger for trans (range: 12ÿ18?Hz; typical: 15?Hz) than for cis (range: 0ÿ12?Hz; typical: 8?Hz) isomers.[7]\\r\\nUsually for acyclic systems trans isomers are more stable than cis isomers. This is typically due to the increased unfavourable steric interaction of the substituents in the cis isomer. Therefore, trans isomers have a less exothermic heat of combustion, indicating higher thermochemical stability.[6] In the Benson heat of formation group additivity dataset, cis isomers suffer a 1.10?kcal/mol stability penalty. Exceptions to this rule exist, such as 1,2-difluoroethylene, 1,2-difluorodiazene (FN=NF), and several other halogen- and oxygen-substituted ethylenes. In these cases, the cis isomer is more stable than the trans isomer.[8] This phenomenon is called the cis effect.[9]\\r\\nThe cisÿtrans system for naming alkene isomers should generally only be used when there are only two different substituents on the double bond, so there is no confusion about which substituents are being described relative to each other. For more complex cases, the cis/trans designation is generally based on the longest carbon chain as reflected in the root name of the molecule (i.e. an extension of standard organic nomenclature for the parent structure). The IUPAC standard designations EÿZ are unambiguous in all cases, and therefore are especially useful for tri- and tetrasubstituted alkenes to avoid any confusion about which groups are being identified as cis or trans to each other.\\r\\nZ (from the German zusammen) means \\"together\\". E (from the German entgegen) means \\"opposed\\" in the sense of \\"opposite\\". That is, Z has the higher-priority groups cis to each other and E has the higher-priority groups trans to each other. Whether a molecular configuration is designated E or Z is determined by the Cahn-Ingold-Prelog priority rules; higher atomic numbers are given higher priority. For each of the two atoms in the double bond, it is necessary to determine the priority of each substituent. If both the higher-priority substituents are on the same side, the arrangement is Z; if on opposite sides, the arrangement is E.\\r\\nBecause the cis/trans and EÿZ systems compare different groups on the alkene, it is not strictly true that Z corresponds to cis and E corresponds to trans. For example, trans-2-chlorobut-2-ene (the two methyl groups, C1 and C4, on the but-2-ene backbone are trans to each other) is (Z)-2-chlorobut-2-ene (the chlorine and C4 are together because C1 and C4 are opposite).\\r\\nCisÿtrans isomerism can also occur in inorganic compounds, most notably in diazenes and coordination compounds.\\r\\nDiazenes (and the related diphosphenes) can also exhibit cis/trans isomerism. As with organic compounds, the cis isomer is generally the more reactive of the two, being the only isomer that can reduce alkenes and alkynes to alkanes, but for a different reason: the trans isomer cannot line its hydrogens up suitably to reduce the alkene, but the cis isomer, being shaped differently, can.\\r\\nIn inorganic coordination complexes with octahedral or square planar geometries, there are also cis isomers in which similar ligands are closer together and trans isomers in which they are further apart.\\r\\nFor example, there are two isomers of square planar Pt(NH3)2Cl2, as explained by Alfred Werner in 1893. The cis isomer, whose full name is cis-diamminedichloroplatinum(II), was shown in 1969 by Barnett Rosenberg to have antitumor activity, and is now a chemotherapy drug known by the short name cisplatin. In contrast, the trans isomer (transplatin) has no useful anticancer activity. Each isomer can be synthesized using the trans effect to control which isomer is produced.\\r\\nFor octahedral complexes of formula MX4Y2, two isomers also exist. (Here M is a metal atom, and X and Y are two different types of ligands.) In the cis isomer, the two Y ligands are adjacent to each other at 90, as is true for the two chlorine atoms shown in green in cis-[Co(NH3)4Cl2]+, at left. In the trans isomer shown at right, the two Cl atoms are on opposite sides of the central Co atom.\\r\\nA related type of isomerism in octahedral MX3Y3 complexes is facialÿmeridional (or fac/mer) isomerism, in which different numbers of ligands are cis or trans to each other. Metal carbonyl compounds can be characterized as \\"fac\\" or \\"mer\\" using infrared spectroscopy.","input":"What is the difference between cis and trans molecules?"},{"output":"July 8, 2011","context":"Michael Nelson Trout (born August 7, 1991) is an American professional baseball center fielder for the Los Angeles Angels of Major League Baseball (MLB). Trout is a six-time MLB All-Star, and received the American League (AL) Most Valuable Player (MVP) award in 2014 and 2016 (finishing second in the 2012, 2013 and 2015 votes).\\r\\nTrout was a first-round pick by the Angels in the 2009 MLB draft and made a brief major league appearance in 2011 as a teenager. He became a regular player for the Angels the subsequent season and won the 2012 AL Rookie of the Year Award unanimously. He is under contract with the Angels through 2020.\\r\\nNicknamed \\"The Millville Meteor\\", Trout's MLB performances have received praise from both the mainstream media and sabermetricians. He is regarded as one of the most outstanding young players in the history of baseball, as well as one of the best current players in all of MLB.[1][2][3][4] Trout has led the American League in wins above replacement (WAR) in each of his first five full seasons (according to Fangraphs and Baseball-Reference.com).\\r\\n\\r\\n\\r\\nBorn in Vineland, New Jersey, to Jeff and Debbie Trout, he has two older siblings, sister Teal and brother Tyler. His father, Jeff (born January 7, 1961), played baseball at the University of Delaware [5][6] and was a fifth-round draft pick as a second baseman by the Minnesota Twins in 1983.[7] Jeff played four years of minor league baseball before a torn plantar fascia and knee injuries ended his career.[8] Mike grew up a die-hard Philadelphia Phillies fan and attended their World Series parade in 2008.[9][10]\\r\\nTrout began playing baseball in Cal Ripken Baseball, A Division of Babe Ruth League.[11] His main position as a youth baseball player was the shortstop position. He wore #2 in honor of his childhood hero, New York Yankees shortstop Derek Jeter. He would switch to #1 in high school.[12] Mike attended Lakeside Middle School and is a 2009 graduate of Millville Senior High School.[13]\\r\\nTrout attended Millville Senior High School in Millville, New Jersey where he played both baseball and basketball,[14] earning five letters (three in baseball and two in basketball).[6] In his junior year, he threw a no-hitter against Egg Harbor Township High School. The Thunderbolts made it to the state playoffs and were defeated by Cherry Hill High School East.[12] He started as a pitcher and shortstop, and was shifted to the outfield during his senior year.[15] That year, he hit 18 home runs, a New Jersey high school record.[16] Trout had committed to play baseball at East Carolina University prior to the 2009 MLB Draft.[6] Millville initially planned to retire Trout's jersey number, but instead began awarding it to the team captain, starting in 2012.[17]\\r\\nTrout played travel ball with Tri-State Arsenal, one of the premier travel programs in the Northeast. He began working with the coaches at Arsenal at age 14.[18] Trout played in various tournaments with Tri-State Arsenal, including the Perfect Game WWBA Championships in Jupiter, Florida in 2007 and 2008.[19]\\r\\nIn the summer before his senior year, Trout attended the Area Code Games in southern California, where he went 6-for-11 against some of the best players in the country.[20] Angels scout Greg Morhardt, who had played in the minor leagues with Trout's father, claimed Mike was the fastest and strongest 17-year-old he had ever seen.[7]\\r\\nTrout was drafted by the Angels, using their compensation pick from the New York Yankees for their signing of Mark Teixeira, 25th overall in the 2009 MLB draft.[21]\\r\\nHe started his professional career in 2009 playing for the Arizona Angels of the rookie-level Arizona League, hitting .360 with a .418 OBP and .506 SLG with one home run, 25 runs batted in (RBIs), and 13 stolen bases in 187 plate appearances over 39 games. He was beaten out in being named AZL Most Valuable Player by Cody Decker.[22][23] He finished the season playing for the Cedar Rapids Kernels of the Class A Midwest League, hitting .267 over 20 plate appearances in five games.[citation needed]\\r\\nBefore the 2010 season, Trout was considered the Angels' third-best prospect and the 85th-best in all of baseball by Baseball America.[24][25] He started the season playing for Cedar Rapids, where he hit .362 with a .454 on-base percentage (OBP) and a .526 slugging percentage (SLG) with six home runs, 39 RBIs, and 45 stolen bases in 82 games. He was selected to play in the All-Star Futures Game.[16] In July, Baseball America named Trout the second-best overall baseball prospect.[26] After the Futures game, he was promoted to the Rancho Cucamonga Quakes of the Class A-Advanced California League.[27]\\r\\nAfter the 2010 season, Trout was named 2010 J.G. Taylor Spink Award as the Topps Minor League Player of the Year. At just 19 years and two months, he was the youngest player to win this award.[28] He was also named a Baseball America All-Star as well as a Topps Class A All-Star.[29]\\r\\nPrior to the 2011 season, Trout was ranked number one by ESPN's Keith Law in his 2011 top 100 prospects list[30] and by MLB's Jonathan Mayo.[31] Trout started the 2011 season with the Arkansas Travelers of the Class AA Texas League. He hit .324 with nine home runs, 27 RBIs, and 28 stolen bases in his first 75 games.[32]\\r\\nThe Los Angeles Angels promoted Trout on July 8, 2011, to replace the injured Peter Bourjos in center field. He made his major league debut that night, going 0-for-3.[32] In his next game, Trout recorded his first career major league hit, an infield single against Seattle Mariners pitcher Michael Pineda in the bottom of the third inning.[33] He hit his first major league home run against Baltimore Orioles pitcher Mark Worrell on July 24.[34] Trout was sent back to Double-A Arkansas on August 1, 2011 after hitting .163 with one home run and six runs batted in 12 starts for the Angels.[35]\\r\\nAfter spending time back in Double-A Arkansas, Trout was recalled by the Angels on August 19, 2011. That night, he went 1-for-4 with a home run, his first at Angel Stadium.[36] On August 30, Trout became the youngest Angel to hit two home runs in one game, homering off of Mariners pitcher Anthony Vazquez in the top of the second inning and again in the top of the fourth inning.[37][38] In his 40-game rookie big league stint in 2011, Trout's batting average was .220, while his on-base percentage was .281 and his slugging percentage .390.[39]\\r\\nFor the 2011 season, of the 13 votes cast for the USA Today Minor League Player of the Year Award, Trout received the 2 votes allocated to the fan poll.[40] He was named Baseball America Minor League Player of the Year[41][42] after hitting .326/.414/.544 with 11 home runs, 38 RBIs, 82 runs scored, and 33 stolen bases in 91 games. He was again named an outfielder on Baseball America's 2011 Minor League All Star team.[43]\\r\\nTrout began the 2012 season with the Salt Lake Bees of the Triple-A Pacific Coast League. On April 28, he was again brought up from the minors, this time to replace Bobby Abreu (who was batting .208 in 24 at-bats). At that time, Trout had a .403 batting average, a .467 on-base percentage, and a .623 slugging percentage in 20 games with Salt Lake.[44]\\r\\nTrout recorded his first career four-hit game on June 4 (and his second 15 days later). In the process, he scored all four times and two of his four hits went for doubles. Trout, along with Angels right fielder Torii Hunter, was named American League co-Player of the Week from June 4ÿ10. During that stretch, Trout went 13-for-25 for a .520 batting average to go along with 10 runs scored and four stolen bases.[45] On June 27 against the Baltimore Orioles, Trout had his third career four-hit game in the same month. In the same game, he showed off his defensive skills when he robbed Orioles shortstop J. J. Hardy of a home run as he leaped up in the center field wall to make a spectacular catch in the bottom of the first inning.[46]\\r\\nTrout broke both an Angels' franchise and American League rookie record when he crossed home plate in 14 consecutive games after scoring a run in a game on July 22.[47] Trout's 26 stolen bases tied Jerry Remy for the team's rookie record for most stolen bases by the All-Star Break.[48] Playing in his first All-Star Game, Trout singled off of New York Mets pitcher R.A. Dickey in the bottom of the 6th inning and drew a base on balls against Cincinnati Reds pitcher Aroldis Chapman in the bottom of the 7th.[49] In the month of June, Trout batted .372 with three home runs and 16 RBI and was named AL Player of the Month and AL Rookie of the Month. Angels manager Mike Scioscia explained Trout's impact by saying, \\"It's a pleasant surprise only with the fact that you see very few guys come up and do this much. Is it surprising that Mike Trout's talent is able to produce what's happening on the field? No, that's not a surprise. He's an extraordinary talent.\\"[50] Trout's 34 runs scored in July tied the Major League rookie record with Cleveland Indians first baseman Hal Trosky in 1934. He had a .392 batting average, 10 home runs, and 23 runs batted in. In addition, Trout continued to show his speed by stealing nine bases and scoring 32 runs in July.[51] Trout also became the first rookie to drive in at least 55 runs and score 80 runs in 81 games since Joe DiMaggio in 1936.\\"[52]\\r\\nAgainst the Chicago White Sox on August 4, Trout made another highlight catch, robbing second baseman Gordon Beckham of a home run in the second inning. White Sox catcher A. J. Pierzynski told reporters after the game that Trout \\"makes those catches in the outfield look so good.\\".[53]\\r\\nOn August 21, Trout went 2-for-4 in a victory over the Boston Red Sox, raising his batting average to .344.[54] With the .344 average, Trout set the rookie record for batting average through 100 games.[52] Trout finished the month of August with a .284 batting average, seven home runs, 19 runs batted in, 11 stolen bases, and an .866 OPS. Trout was again named AL Rookie of the Month for August, his fourth time winning the honor. In winning the award for the fourth time, Trout became the first American League rookie since Ichiro Suzuki in 2001 to win Rookie of the Month four times during a single season.[55]\\r\\nTrout became the youngest player ever to hit at least 20 home runs and steal at least 40 bases in a season. Houston Astros center fielder Csar Cede?o had been the youngest player to accomplish the feat, doing so in 1972.[56] He also became the youngest hitter ever to hit at least 20 home runs and steal at least 30 bases in a season.[57] Trout scored his 100th run of the season on August 26, becoming the second Angels rookie to score at least 100 runs in a season after Devon White.[58] Trout set a new Angels record for runs scored in a rookie season, passing White. Trout scored three runs that day, the tenth time in the 2012 season where he scored three or more runs in one game, the most since Sammy Sosa's 11 games in 2001.[59]\\r\\nOn September 9, in a game against the Detroit Tigers, Trout became the first player in baseball history under the age of 22 to hit a leadoff home run in back-to-back games.[60] On September 21, Trout became the first rookie to score 120 or more runs since Ichiro Suzuki and the fourth rookie to accomplish that feat since 1964.[61] On September 30, Trout became the youngest player in Major League Baseball history to join the 30ÿ30 club when he belted a 7th-inning home run off of Texas Rangers pitcher Yu Darvish, helping the Angels win the game by a score of 5ÿ4.[62]\\r\\nTrout became the first player in MLB history to hit 30 home runs, steal 45 bases, and score 125 runs in one season.[63] Trout set the Angels' club record for most runs scored in a season, surpassing Vladimir Guerrero. He also set the Angels rookie record for most hits in a season with 173, passing Wally Joyner.[64] Trout became the first rookie ever to hit 30 home runs and steal 40 bases in the same season. In addition, Trout finished second in the AL in batting average (.326), third in slugging percentage (.564), third in on-base percentage (.399), second in OPS (.963), 9th in hits (182), and first in OPS+ (171).[65] He became the first Angels player to lead the league in stolen bases since Chone Figgins did so in 2005 with 49 stolen bases.[66] According to Baseball-Reference.com, Trout finished with a wins above replacement (WAR) value of 10.9, 2.4 better than second-place finisher Robinson Can܇ of the Yankees.[67] Trout was the first position player to have a WAR above 10.0 since Barry Bonds for the San Francisco Giants in 2004.[68]\\r\\nTrout led the Angels in batting average, runs scored, hits (182), triples, stolen bases, total bases (315), base on balls, batting average, on-base percentage, slugging percentage, and on-base plus slugging despite playing in just 139 games. He was tied with Pujols for second place on the team in home runs behind Mark Trumbo and was fourth in runs batted in.[69]\\r\\nOn November 12, 2012, Trout won the BBWAA Jackie Robinson Rookie of the Year Award, receiving 28 of 28 first place votes, becoming the first Angels player to win the award since Tim Salmon won it in 1993 and the youngest player to win the AL Rookie of the Year Award. Trout became just the 18th Rookie of the Year winner to win the award unanimously.[70] On November 13, Trout won the Heart and Hustle Award, given to the player who \\"demonstrates a passion for the game of baseball and best embodies the values, spirit and traditions of the game.\\"[71][72] Trout was one of three outfielders in the American League to win the Silver Slugger for being the best offensive players at their position; the others were then-Ranger Josh Hamilton and Josh Willingham of the Minnesota Twins.[73] He also won a Fielding Bible Award as the best fielding center fielder in MLB.[74]\\r\\nTrout's high WAR value led many to support his candidacy for American League Most Valuable Player.[75][76][77][78] Trout's main competition for the award was Miguel Cabrera, who became the first player since Carl Yastrzemski in 1967 to win the triple crown by leading the AL in batting average, home runs, and runs batted in.[77] The race between Trout and Cabrera created controversy amongst baseball fans and writers, and was described by many as a clash between new-age sabermetrics and supporters of more \\"traditional\\" statistics.[79] In supporting Trout's case, Jayson Stark wrote, \\"We just understand that Trout's insane 10.5 WAR are one more clear indication that he's a better baseball player than even one of the greatest hitters of our lifetimes. ... If you want to toss in his slash line, his 62 extra-base hits, his 92.3 percent stolen-base success rate or any other item on his stat sheet, you'll find that no player in the history of baseball has combined this much excellence in so many areas in the same season.\\"[78] Meanwhile, Scott Miller of CBS Sports wrote, \\"Nobody combined overall statistics, badass lineup presence and value to his team more than Triple Crown winner Miguel Cabrera.\\"[80] On November 15, Cabrera won the MVP decisively, winning twenty-two of twenty-eight first place votes to Trout's six.[81]\\r\\nTrout began the 2013 season as a left fielder, in order to accommodate for Peter Bourjos in center field.[82] Trout started the 2013 season slowly, hitting .261 with two home runs and 16 RBIs in April.[83] During a game on April 20 against the Detroit Tigers, Trout hit his first career grand slam off pitcher Rick Porcello, capping a 10-run inning for the Angels, their highest-scoring inning in almost 18 years.[84]\\r\\nOn April 30, Bourjos injured his hamstring, and Trout was moved back to center field.[85] In May, Trout regained his rookie-year form, batting .327 with 8 home runs, 21 RBIs, and 27 runs scored.[83] Trout stated that he had struggled early in the season because he was chasing pitches out of the strike zone and pressing too much on himself.[86] On May 21, 2013 Trout became the youngest player to hit for the cycle in American League history and sixth youngest in Major League history, doing so at home against the Seattle Mariners.[87] On May 30, Angels manager Mike Scioscia announced that Trout would return to left field after Bourjos returned from the disabled list. This decision caused some controversy, as some believed that Trout's successful May was a direct result of his move back to center field.[82] Scioscia, however, believed that Trout's numbers as a center fielder had to do with his batting-order position and hype subsiding.[88]\\r\\nOn June 8, with shortstop Erick Aybar struggling at the leadoff spot, Trout began batting leadoff, marking his first time hitting in the leadoff spot since April 14.[89] In his first game batting leadoff since mid-April, Trout went 3 for 5, with two doubles, a run batted in, scored two runs, had a base on balls, and stole a base, helping the Angels win the game over the Boston Red Sox in the first game of a double-header.[90]\\r\\nTrout indeed moved back to left field after Bourjos returned to the Angels' lineup on June 10.[91] In his 249th career game, he scored his 200th career run, becoming the fastest player to accomplish this since Ted Williams (225 games) and Barney McCosky (236 games) did it in 1940.[92]\\r\\nTrout represented the Angels in the 2013 Major League Baseball All-Star Game. He was the leading vote-getter among all AL outfielders and the first Angels position player to start in the All-Star Game since Vladimir Guerrero in 2007.[93] In the month of July, Trout led all of baseball with an on-base percentage of .475 and OPS of 1.108.[83] In addition, he was the only player in the American League to reach base in every game of the month and became the first Angels player to have two consecutive streaks of reaching base in at least 33 games.[94] Trout continued his strong play in August, batting .337 with 6 home runs and an on-base percentage of .500.[83] As in 2012, Trout's play declined somewhat in September, as he batted .281 with 4 home runs and 4 stolen bases.[83]\\r\\nAccording to Baseball-Reference, Trout finished the 2013 season with 9.2 WAR, again the highest in baseball.[95] Notably, Trout's walk rate increased from 10.5% in 2012 to 15.4% in 2013.[83] Trout's 110 bases on balls led the American League.[95] Echoing the 2012 season, Miguel Cabrera won the 2013 AL MVP with twenty-three first-place votes, while Trout finished second with five.[96]\\r\\nRumors of a contract extension surfaced in February 2014, as news outlets reported that the Angels were considering offering Trout a six-year $150 million contract. Instead, he signed a one-year, $1 million contract. That figure is the highest ever for a player not yet eligible for salary arbitration.[97] On March 28, 2014, the Angels announced they had signed Trout to a 6-year, $144.5 million extension.[98]\\r\\nOn April 19, 2014, Trout went 0-4 with four consecutive strikeouts against Max Scherzer, giving him his first golden sombrero after playing in 353 games.[99] On May 15, Trout hit his first career walk-off home run in a 6-5 victory over the Tampa Bay Rays.[100] On July 15, Trout appeared in his third All-Star Game at Target Field in Minnesota. He went 2 for 3, with a double, a triple, and two RBIs. He was named the Most Valuable Player of the game, making him the second-youngest All-Star Game MVP behind Ken Griffey Jr. in 1992.[101][102] On June 27, Trout hit the longest home run of the 2014 season, according to ESPN.com's Home Run Tracker.[103] The ball was hit 489 feet into left-center field at Kauffman Stadium, Kansas City, Missouri.[104]\\r\\nPlaying in 157 games in 2014, Trout batted .287 with 36 home runs, 39 doubles, nine triples, an AL-leading 111 RBIs, 16 stolen bases and an MLB-leading 115 runs scored. He also struck out a league-high 184 times. In an interview with Ken Rosenthal, Trout attributed his increased strikeouts to a \\"golf-swing.\\" Nevertheless, Trout added he is working with staff to fix correct the strikeout tendency, and what may have been the only significant flaw of his all-around game.[citation needed]\\r\\nIn Game 3 of the 2014 American League Division Series against the Kansas City Royals, Trout hit his first career postseason home run in the first inning off of James Shields.[105] Later on in the ninth inning, Trout was the final batter of the Angels to strike out as the team lost to the Royals in a three-game sweep of the series.[105]\\r\\nOn November 13, 2014, the Baseball Writers' Association of America announced that Trout was unanimously selected as the AL MVP, becoming the sixth player in MLB history to win both the regular season MVP and the All-Star Game MVP in the same season. Further, at the time, he was the fifth-youngest MVP ever, the 17th to win unanimously, and the fifth in Angels' franchise history, following Vladimir Guerrero in 2004.[106]\\r\\nOn April 17, 2015, Trout became the youngest player in MLB history to reach 100 home runs and 100 stolen bases.[107] He was 23 years and 253 days old when he reached the milestone, passing the previous record-holder, Alex Rodriguez, who had achieved it at the age of 23 years and 309 days in 1999.[107] Trout led off the 2015 MLB All-Star Game with a home run, becoming the fourth player in All-Star Game history to do so.[108] For the second year in a row, Trout won the All-Star Game MVP Award, becoming the first player ever to win it in consecutive years.[109] On September 22, Trout hit his 40th home run, becoming only the second Angels player to hit 40 home runs in a season.[110] Trout led the AL in WAR for the fourth straight year.[111]\\r\\nTrout finished the season with 41 home runs and 90 RBIs. He also led all American League players in slugging percentage, and OPS with a slashline of .299/.402/.590/.991. For his offensive performance, Trout would go on to win his fourth Silver Slugger Award in as many seasons. In doing so, he became only the second player since Mike Piazza to win four straight Silver Slugger Awards to start off a career.[112] He also won the Best Major League Baseball Player ESPY Award.[113]\\r\\nOn November 10, it was announced that Trout, along with Royals outfielder Lorenzo Cain and Blue Jays third baseman Josh Donaldson, were finalists for the AL MVP. Trout became the first player since Barry Bonds to be among the top three in MVP voting in four straight seasons.\\r\\nOn November 19, Trout finished second to MVP winner Josh Donaldson, making it the third time he finished second in MVP voting in his four big league seasons.[114]\\r\\nIn June 2016, Sporting News named Trout \\"baseball's best player\\" for the season.[115] According to Fangraphs, he had accumulated more WAR through his age-24 season (on August 12, 2016) than any other player since 1913, with 45. Mickey Mantle was second with 41.1, followed by Mel Ott, Jimmie Foxx, and Ted Williams. A close contemporary of Trout's, Alex Rodriguez, was seventh.[116] In 159 games of 2016, Trout led the MLB with walks (116), runs scored (123), and on-base percentage (.441). He also had a .315 batting average, 29 home runs, 30 stolen bases, and 100 RBI.\\r\\nOn November 17, Trout was announced as the 2016 AL MVP, winning the award for the second time in his career.[117] Trout also joined Barry Bonds as the only other player in MLB history to finish top 2 for the MVP in five straight seasons.[118] He was the 2016 Esurance MLB/This Year in Baseball Award winner for Best Major Leaguer.[119] At the conclusion of the 2016 season, Trout was 12th among active position players in Total Wins Above Replacement through just five full seasons. [120]\\r\\nOn May 28, 2017, Trout left the game after spraining his left thumb. Two days later, an MRI revealed that the thumb had a torn ulnar collateral ligament, and was placed on the disabled list for the first time in his major league career. The injury required surgery, and he was ruled out for six to eight weeks.[121] Prior to the injury, Trout was batting .337 and had led the Angels with 16 home runs.[122] On May 31, he underwent successful thumb surgery.[123] He was voted to be a starting outfielder for the American League in the All-Star Game, but did not participate due to his thumb injury.[124] Trout was activated from the disabled list on July 14 after missing 39 games.[122] On August 7, the date of his 26th birthday, he doubled down the third-base line for his 1,000th career hit.[125] In his next at-bat, he hit a home run for his 1001st hit. It marked the fourth time in six seasons that Trout had homered on his birthday.\\r\\nOn September 6, 2017, versus the Oakland Athletics, Trout drew a walk in his 14th consecutive contest to pass Albie Pearson for the franchise record of 13 set in 1961.[126][127] He hit his 200th career home run versus Marco Gonzales of the Seattle Mariners on September 29, 2017. Trout became the seventh player in history to reach 200 or more home runs before the end of his age-25 season, following Foxx, Matthews, Mantle, Ott, Robinson, Rodriguez, and Pujols.[128]\\r\\nNotes: Through 2016 season. Per Baseball-Reference.com.\\r\\nTrout's exceptional performance at an early age has drawn comparisons with Ted Williams,[129] and Trout's combination of power and speed has been compared to the skillset of Hall of Fame center fielder Mickey Mantle.[130]\\r\\nBetween 2012 and 2016, Trout was second in on-base plus slugging, and was MLB's most productive batter per plate appearance when adjusted for park factors (among all batters who had 1000 or more plate appearances).[131] During this period Trout combined a high average (.310, fifth among 340 players), high isolated power (.255, sixth) and high walk rate (13.7%, twelfth).[131]\\r\\nTrout is particularly able to hit pitches that are low in the strike zone,[132][133] but in 2015 acknowledged a vulnerability against high pitches.[134] However, Trout later appeared to fix this vulnerability, greatly improving his contact rate and slugging percentage against high fastballs.[135][136]\\r\\nIn 2014, Trout recorded the most strikeouts ever during an MVP season, and later expressed a wish to reduce his strikeout rate.[134][137] After having MLB's 14th highest strikeout rate in 2014, Trout improved to 26th in 2015, and 59th in 2016.[138][139][140]\\r\\nTrout has been graded as a roughly average defender across the outfield positions (according to ultimate zone rating) and he is also a valuable baserunner, stealing 142 bases between 2012 and 2016 at a success rate of 83 percent.[141]\\r\\nTrout's nicknames include \\"Prince Fish\\", \\"God's Gift\\" and \\"King Fish 2.0\\", in reference to retired Angel Tim Salmon.[142] He adopted the nickname \\"Millville Meteor\\" after a prankster edited his Wikipedia article[143] and the name caught on.[65][144][145]\\r\\nIn February 2014, President Barack Obama used Trout as an analogy for the 2014 U.S. Farm Bill. To emphasize the versatility and utility of the bill, Obama remarked that it was \\"like Mike Trout, for those of you who know baseball...somebody who's got a lot of tools.\\"[146]\\r\\n\\"Who is Mike Trout?\\" was an answer on a February 2013 episode of the quiz show Jeopardy! during the show's teen tournament.[147]\\r\\nTrout is a season ticket holder of the Philadelphia Eagles of the National Football League.[148]\\r\\nTrout has been a partner and investor in Bodyarmor SuperDrink, a sports drink, since 2012.[149] He has sponsorship agreements with Subway[150] and SuperPretzel[151] and in 2014, Nike began selling Mike Trout branded shoes.[152][153]","input":"When did mike trout come into the league?"},{"output":"the Latin ducti (\\"A breeding, a bringing up, a rearing\\") from duc (\\"I educate, I train\\")","context":"Education is the process of facilitating learning, or the acquisition of knowledge, skills, values, beliefs, and habits. Educational methods include storytelling, discussion, teaching, training, and directed research. Education frequently takes place under the guidance of educators, but learners may also educate themselves.[1] Education can take place in formal or informal settings and any experience that has a formative effect on the way one thinks, feels, or acts may be considered educational. The methodology of teaching is called pedagogy.\\r\\nEducation is commonly divided formally into such stages as preschool or kindergarten, primary school, secondary school and then college, university, or apprenticeship.\\r\\nA right to education has been recognized by some governments and the United Nations.[2] In most regions, education is compulsory up to a certain age.\\r\\n\\r\\n\\r\\nEtymologically, the word \\"education\\" is derived from the Latin ducti (\\"A breeding, a bringing up, a rearing\\") from duc (\\"I educate, I train\\") which is related to the homonym dc (\\"I lead forth, I take out; I raise up, I erect\\") from - (\\"from, out of\\") and dc (\\"I lead, I conduct\\").[3]\\r\\nEducation began in prehistory, as adults trained the young in the knowledge and skills deemed necessary in their society. In pre-literate societies, this was achieved orally and through imitation. Story-telling passed knowledge, values, and skills from one generation to the next. As cultures began to extend their knowledge beyond skills that could be readily learned through imitation, formal education developed. Schools existed in Egypt at the time of the Middle Kingdom.[4]\\r\\nPlato founded the Academy in Athens, the first institution of higher learning in Europe.[5] The city of Alexandria in Egypt, established in 330 BCE, became the successor to Athens as the intellectual cradle of Ancient Greece. There, the great Library of Alexandria was built in the 3rd century BCE. European civilizations suffered a collapse of literacy and organization following the fall of Rome in CE 476.[6]\\r\\nIn China, Confucius (551ÿ479 BCE), of the State of Lu, was the country's most influential ancient philosopher, whose educational outlook continues to influence the societies of China and neighbours like Korea, Japan, and Vietnam. Confucius gathered disciples and searched in vain for a ruler who would adopt his ideals for good governance, but his Analects were written down by followers and have continued to influence education in East Asia into the modern era.[citation needed]\\r\\nAfter the Fall of Rome, the Catholic Church became the sole preserver of literate scholarship in Western Europe. The church established cathedral schools in the Early Middle Ages as centres of advanced education. Some of these establishments ultimately evolved into medieval universities and forebears of many of Europe's modern universities.[6] During the High Middle Ages, Chartres Cathedral operated the famous and influential Chartres Cathedral School. The medieval universities of Western Christendom were well-integrated across all of Western Europe, encouraged freedom of inquiry, and produced a great variety of fine scholars and natural philosophers, including Thomas Aquinas of the University of Naples, Robert Grosseteste of the University of Oxford, an early expositor of a systematic method of scientific experimentation,[7] and Saint Albert the Great, a pioneer of biological field research.[8] Founded in 1088, the University of Bologne is considered the first, and the oldest continually operating university.[9]\\r\\nElsewhere during the Middle Ages, Islamic science and mathematics flourished under the Islamic caliphate which was established across the Middle East, extending from the Iberian Peninsula in the west to the Indus in the east and to the Almoravid Dynasty and Mali Empire in the south.\\r\\nThe Renaissance in Europe ushered in a new age of scientific and intellectual inquiry and appreciation of ancient Greek and Roman civilizations. Around 1450, Johannes Gutenberg developed a printing press, which allowed works of literature to spread more quickly. The European Age of Empires saw European ideas of education in philosophy, religion, arts and sciences spread out across the globe. Missionaries and scholars also brought back new ideas from other civilizations?ÿ as with the Jesuit China missions who played a significant role in the transmission of knowledge, science, and culture between China and Europe, translating works from Europe like Euclid's Elements for Chinese scholars and the thoughts of Confucius for European audiences. The Enlightenment saw the emergence of a more secular educational outlook in Europe.\\r\\nIn most countries today, full-time education, whether at school or otherwise, is compulsory for all children up to a certain age. Due to this the proliferation of compulsory education, combined with population growth, UNESCO has calculated that in the next 30?years more people will receive formal education than in all of human history thus far.[10]\\r\\nFormal education occurs in a structured environment whose explicit purpose is teaching students. Usually, formal education takes place in a school environment with classrooms of multiple students learning together with a trained, certified teacher of the subject. Most school systems are designed around a set of values or ideals that govern all educational choices in that system. Such choices include curriculum, organizational models, design of the physical learning spaces (e.g. classrooms), student-teacher interactions, methods of assessment, class size, educational activities, and more.[11][12]\\r\\nPreschools provide education from ages approximately three to seven, depending on the country when children enter primary education. These are also known as nursery schools and as kindergarten, except in the US, where kindergarten is a term used for primary education.[citation needed] Kindergarten \\"provide[s] a child-centred, preschool curriculum for three- to seven-year-old children that aim[s] at unfolding the child's physical, intellectual, and moral nature with balanced emphasis on each of them.\\"[13]\\r\\nPrimary (or elementary) education consists of the first five to seven years of formal, structured education. In general, primary education consists of six to eight years of schooling starting at the age of five or six, although this varies between, and sometimes within, countries. Globally, around 89% of children aged six to twelve are enrolled in primary education, and this proportion is rising.[14] Under the Education For All programs driven by UNESCO, most countries have committed to achieving universal enrollment in primary education by 2015, and in many countries, it is compulsory. The division between primary and secondary education is somewhat arbitrary, but it generally occurs at about eleven or twelve years of age. Some education systems have separate middle schools, with the transition to the final stage of secondary education taking place at around the age of fourteen. Schools that provide primary education, are mostly referred to as primary schools or elementary schools. Primary schools are often subdivided into infant schools and junior school.\\r\\nIn India, for example, compulsory education spans over twelve years, with eight years of elementary education, five years of primary schooling and three years of upper primary schooling. Various states in the republic of India provide 12 years of compulsory school education based on a national curriculum framework designed by the National Council of Educational Research and Training.\\r\\nIn most contemporary educational systems of the world, secondary education comprises the formal education that occurs during adolescence. It is characterized by transition from the typically compulsory, comprehensive primary education for minors, to the optional, selective tertiary, \\"postsecondary\\", or \\"higher\\" education (e.g. university, vocational school) for adults. Depending on the system, schools for this period, or a part of it, may be called secondary or high schools, gymnasiums, lyceums, middle schools, colleges, or vocational schools. The exact meaning of any of these terms varies from one system to another. The exact boundary between primary and secondary education also varies from country to country and even within them but is generally around the seventh to the tenth year of schooling. Secondary education occurs mainly during the teenage years. In the United States, Canada, and Australia, primary and secondary education together are sometimes referred to as K-12 education, and in New Zealand Year 1ÿ13 is used. The purpose of secondary education can be to give common knowledge, to prepare for higher education, or to train directly in a profession.\\r\\nSecondary education in the United States did not emerge until 1910, with the rise of large corporations and advancing technology in factories, which required skilled workers. In order to meet this new job demand, high schools were created, with a curriculum focused on practical job skills that would better prepare students for white collar or skilled blue collar work. This proved beneficial for both employers and employees, since the improved human capital lowered costs for the employer, while skilled employees received higher wages.\\r\\nSecondary education has a longer history in Europe, where grammar schools or academies date from as early as the 16th century, in the form of public schools, fee-paying schools, or charitable educational foundations, which themselves date even further back.\\r\\nCommunity colleges offer another option at this transitional stage of education. They provide nonresidential junior college courses to people living in a particular area.\\r\\nHigher education, also called tertiary, third stage, or postsecondary education, is the non-compulsory educational level that follows the completion of a school such as a high school or secondary school. Tertiary education is normally taken to include undergraduate and postgraduate education, as well as vocational education and training. Colleges and universities mainly provide tertiary education. Collectively, these are sometimes known as tertiary institutions. Individuals who complete tertiary education generally receive certificates, diplomas, or academic degrees.\\r\\nHigher education typically involves work towards a degree-level or foundation degree qualification. In most developed countries, a high proportion of the population (up to 50%) now enter higher education at some time in their lives. Higher education is therefore very important to national economies, both as a significant industry in its own right and as a source of trained and educated personnel for the rest of the economy.\\r\\nUniversity education includes teaching, research, and social services activities, and it includes both the undergraduate level (sometimes referred to as tertiary education) and the graduate (or postgraduate) level (sometimes referred to as graduate school). Universities are generally composed of several colleges. In the United States, universities can be private and independent like Yale University; public and state-governed like the Pennsylvania State System of Higher Education; or independent but state-funded like the University of Virginia. A number of career specific courses are now available to students through the Internet.\\r\\nOne type of university education is a liberal arts education, which can be defined as a \\"college or university curriculum aimed at imparting broad general knowledge and developing general intellectual capacities, in contrast to a professional, vocational, or technical curriculum.\\"[15] Although what is known today as liberal arts education began in Europe,[16] the term \\"liberal arts college\\" is more commonly associated with institutions in the United States.[17]\\r\\nVocational education is a form of education focused on direct and practical training for a specific trade or craft. Vocational education may come in the form of an apprenticeship or internship as well as institutions teaching courses such as carpentry, agriculture, engineering, medicine, architecture and the arts.\\r\\nIn the past, those who were disabled were often not eligible for public education. Children with disabilities were repeatedly denied an education by physicians or special tutors. These early physicians (people like Itard, Seguin, Howe, Gallaudet) set the foundation for special education today. They focused on individualized instruction and functional skills. In its early years, special education was only provided to people with severe disabilities, but more recently it has been opened to anyone who has experienced difficulty learning.[18]\\r\\nWhile considered \\"alternative\\" today, most alternative systems have existed since ancient times. After the public school system was widely developed beginning in the 19th century, some parents found reasons to be discontented with the new system. Alternative education developed in part as a reaction to perceived limitations and failings of traditional education. A broad range of educational approaches emerged, including alternative schools, self learning, homeschooling, and unschooling. Example alternative schools include Montessori schools, Waldorf schools (or Steiner schools), Friends schools, Sands School, Summerhill School, Walden's Path, The Peepal Grove School, Sudbury Valley School, Krishnamurti schools, and open classroom schools. Charter schools are another example of alternative education, which have in the recent years grown in numbers in the US and gained greater importance in its public education system.[19][20]\\r\\nIn time, some ideas from these experiments and paradigm challenges may be adopted as the norm in education, just as Friedrich Fr?bel's approach to early childhood education in 19th-century Germany has been incorporated into contemporary kindergarten classrooms. Other influential writers and thinkers have included the Swiss humanitarian Johann Heinrich Pestalozzi; the American transcendentalists Amos Bronson Alcott, Ralph Waldo Emerson, and Henry David Thoreau; the founders of progressive education, John Dewey and Francis Parker; and educational pioneers such as Maria Montessori and Rudolf Steiner, and more recently John Caldwell Holt, Paul Goodman, Frederick Mayer, George Dennison, and Ivan Illich.\\r\\nIndigenous education refers to the inclusion of indigenous knowledge, models, methods, and content within formal and non-formal educational systems. Often in a post-colonial context, the growing recognition and use of indigenous education methods can be a response to the erosion and loss of indigenous knowledge and language through the processes of colonialism. Furthermore, it can enable indigenous communities to \\"reclaim and revalue their languages and cultures, and in so doing, improve the educational success of indigenous students.\\"[21]\\r\\nInformal learning is one of three forms of learning defined by the Organisation for Economic Co-operation and Development (OECD). Informal learning occurs in a variety of places, such as at home, work, and through daily interactions and shared relationships among members of society. For many learners, this includes language acquisition, cultural norms, and manners.\\r\\nIn informal learning, there is often a reference person, a peer or expert, to guide the learner. If learners have a personal interest in what they are informally being taught, learners tend to expand their existing knowledge and conceive new ideas about the topic being learned.[22] For example, a museum is traditionally considered an informal learning environment, as there is room for free choice, a diverse and potentially non-standardized range of topics, flexible structures, socially rich interaction, and no externally imposed assessments.[23]\\r\\nWhile informal learning often takes place outside educational establishments and does not follow a specified curriculum, it can also occur within educational settings and even during formal learning situations. Educators can structure their lessons to directly utilize their students informal learning skills within the education setting.[22]\\r\\nIn the late 19th century, education through play began to be recognized as making an important contribution to child development.[24] In the early 20th century, the concept was broadened to include young adults but the emphasis was on physical activities.[25] L.P. Jacks, also an early proponent of lifelong learning, described education through recreation: \\"A master in the art of living draws no sharp distinction between his work and his play, his labour and his leisure, his mind and his body, his education and his recreation. He hardly knows which is which. He simply pursues his vision of excellence through whatever he is doing and leaves others to determine whether he is working or playing. To himself, he always seems to be doing both. Enough for him that he does it well.\\"[26] Education through recreation is the opportunity to learn in a seamless fashion through all of life's activities.[27] The concept has been revived by the University of Western Ontario to teach anatomy to medical students.[27]\\r\\nAutodidacticism (also autodidactism) is a term used to describe self-directed learning. One may become an autodidact at nearly any point in one's life. Notable autodidacts include Abraham Lincoln (U.S. president), Srinivasa Ramanujan (mathematician), Michael Faraday (chemist and physicist), Charles Darwin (naturalist), Thomas Alva Edison (inventor), Tadao Ando (architect), George Bernard Shaw (playwright), Frank Zappa (composer, recording engineer, film director), and Leonardo da Vinci (engineer, scientist, mathematician).\\r\\nIn 2012, the modern use of electronic educational technology (also called e-learning) had grown at 14 times the rate of traditional learning.[clarification needed][28] Open education is fast growing to become the dominant form of education, for many reasons such as its efficiency and results compared to traditional methods.[29] Cost of education has been an issue throughout history, and a major political issue in most countries today. Online courses often can be more expensive than face-to-face classes. Out of 182 colleges surveyed in 2009 nearly half said tuition for online courses was higher than for campus-based ones.[30] Many large university institutions are now starting to offer free or almost free full courses such as Harvard, MIT and Berkeley teaming up to form edX. Other universities offering open education are Stanford, Princeton, Duke, Johns Hopkins, Edinburgh, U. Penn, U. Michigan, U. Virginia, U. Washington, and Caltech. It has been called the biggest change in the way we learn since the printing press.[31] Despite favourable studies on effectiveness, many people may still desire to choose traditional campus education for social and cultural reasons.[32]\\r\\nThe conventional merit-system degree is currently not as common in open education as it is in campus universities, although some open universities do already offer conventional degrees such as the Open University in the United Kingdom. Presently, many of the major open education sources offer their own form of certificate. Due to the popularity of open education, these new kind of academic certificates are gaining more respect and equal \\"academic value\\" to traditional degrees.[33] Many open universities are working to have the ability to offer students standardized testing and traditional degrees and credentials.[34]\\r\\nA culture is beginning to form around distance learning for people who are looking to social connections enjoyed on traditional campuses. For example, students may create study groups, meetups, and movements such as UnCollege.\\r\\nThe education sector or education system is a group of institutions (ministries of education, local educational authorities, teacher training institutions, schools, universities, etc.) whose primary purpose is to provide education to children and young people in educational settings. It involves a wide range of people (curriculum developers, inspectors, school principals, teachers, school nurses, students, etc.). These institutions can vary according to different contexts.[35]\\r\\nSchools deliver education, with support from the rest of the education system through various elements such as education policies and guidelines ÿ to which school policies can refer ÿ curricula and learning materials, as well as pre- and in-service teacher training programmes. The school environment ÿ both physical (infrastructures) and psychological (school climate) ÿ is also guided by school policies that should ensure the well-being of students when they are in school.[35] The Organisation for Economic Co-operation and Development has found that schools tend to perform best when principals have full authority and responsibility for ensuring that students are proficient in core subjects upon graduation. They must also seek feedback from students for quality-assurance and improvement. Governments should limit themselves to monitoring student proficiency.[36]\\r\\nThe education sector is fully integrated into society, through interactions with a large number of stakeholders and other sectors. These include parents, local communities, religious leaders, NGOs, stakeholders involved in health, child protection, justice and law enforcement (police), media and political leadership.[35]\\r\\nThe 2030 Agenda for Sustainable Development, adopted by the United Nations (UN) General Assembly in September 2015, calls for a new vision to address the environmental, social and economic concerns facing the world today. The Agenda includes 17 Sustainable Development Goals (SDGs), including SDG 4 on education.[37][38]\\r\\nSince 1909, the ratio of children in the developing world attending school has increased. Before then, a small minority of boys attended school. By the start of the 21st century, the majority of all children in most regions of the world attended school.\\r\\nUniversal Primary Education is one of the eight international Millennium Development Goals, towards which progress has been made in the past decade, though barriers still remain.[39] Securing charitable funding from prospective donors is one particularly persistent problem. Researchers at the Overseas Development Institute have indicated that the main obstacles to funding for education include conflicting donor priorities, an immature aid architecture, and a lack of evidence and advocacy for the issue.[39] Additionally, Transparency International has identified corruption in the education sector as a major stumbling block to achieving Universal Primary Education in Africa.[40] Furthermore, demand in the developing world for improved educational access is not as high as foreigners have expected. Indigenous governments are reluctant to take on the ongoing costs involved. There is also economic pressure from some parents, who prefer their children to earn money in the short term rather than work towards the long-term benefits of education.[citation needed]\\r\\nA study conducted by the UNESCO International Institute for Educational Planning indicates that stronger capacities in educational planning and management may have an important spill-over effect on the system as a whole.[41] Sustainable capacity development requires complex interventions at the institutional, organizational and individual levels that could be based on some foundational principles:\\r\\nNearly every country now has Universal Primary Education.\\r\\nSimilarities ÿ in systems or even in ideas ÿ that schools share internationally have led to an increase in international student exchanges. The European Socrates-Erasmus Program[42] facilitates exchanges across European universities. The Soros Foundation[43] provides many opportunities for students from central Asia and eastern Europe. Programs such as the International Baccalaureate have contributed to the internationalization of education. The global campus online, led by American universities, allows free access to class materials and lecture files recorded during the actual classes.\\r\\nThe Programme for International Student Assessment and the International Association for the Evaluation of Educational Achievement objectively monitor and compare the proficiency of students from a wide range of different nations.\\r\\nTechnology plays an increasingly significant role in improving access to education for people living in impoverished areas and developing countries. Charities like One Laptop per Child are dedicated to providing infrastructures through which the disadvantaged may access educational materials.\\r\\nThe OLPC foundation, a group out of MIT Media Lab and supported by several major corporations, has a stated mission to develop a $100 laptop for delivering educational software. The laptops were widely available as of 2008. They are sold at cost or given away based on donations.\\r\\nIn Africa, the New Partnership for Africa's Development (NEPAD) has launched an \\"e-school program\\" to provide all 600,000 primary and high schools with computer equipment, learning materials and internet access within 10 years.[44] An International Development Agency project called nabuur.com,[45] started with the support of former American President Bill Clinton, uses the Internet to allow co-operation by individuals on issues of social development.\\r\\nIndia is developing technologies that will bypass land-based telephone and Internet infrastructure to deliver distance learning directly to its students. In 2004, the Indian Space Research Organisation launched EDUSAT, a communications satellite providing access to educational materials that can reach more of the country's population at a greatly reduced cost.[46]\\r\\nResearch into LCPS (low-cost private schools) found that over 5 years to July 2013, debate around LCPSs to achieving Education for All (EFA) objectives was polarized and finding growing coverage in international policy.[47] The polarization was due to disputes around whether the schools are affordable for the poor, reach disadvantaged groups, provide quality education, support or undermine equality, and are financially sustainable. The report examined the main challenges encountered by development organizations which support LCPSs.[47] Surveys suggest these types of schools are expanding across Africa and Asia. This success is attributed to excess demand. These surveys found concern for:\\r\\nThe report showed some cases of successful voucher and subsidy programmes; evaluations of international support to the sector are not widespread.[47] Addressing regulatory ineffectiveness is a key challenge. Emerging approaches stress the importance of understanding the political economy of the market for LCPS, specifically how relationships of power and accountability between users, government, and private providers can produce better education outcomes for the poor.\\r\\nEducational psychology is the study of how humans learn in educational settings, the effectiveness of educational interventions, the psychology of teaching, and the social psychology of schools as organizations. Although the terms \\"educational psychology\\" and \\"school psychology\\" are often used interchangeably, researchers and theorists are likely to be identified as educational psychologists, whereas practitioners in schools or school-related settings are identified as school psychologists. Educational psychology is concerned with the processes of educational attainment in the general population and in sub-populations such as gifted children and those with specific disabilities.\\r\\nEducational psychology can in part be understood through its relationship with other disciplines. It is informed primarily by psychology, bearing a relationship to that discipline analogous to the relationship between medicine and biology. Educational psychology, in turn, informs a wide range of specialties within educational studies, including instructional design, educational technology, curriculum development, organizational learning, special education and classroom management. Educational psychology both draws from and contributes to cognitive science and the learning sciences. In universities, departments of educational psychology are usually housed within faculties of education, possibly accounting for the lack of representation of educational psychology content in introductory psychology textbooks (Lucas, Blazek, & Raley, 2006).\\r\\nIntelligence is an important factor in how the individual responds to education. Those who have higher intelligence tend to perform better at school and go on to higher levels of education.[49] This effect is also observable in the opposite direction, in that education increases measurable intelligence.[50] Studies have shown that while educational attainment is important in predicting intelligence in later life, intelligence at 53 is more closely correlated to intelligence at 8 years old than to educational attainment.[51]\\r\\nThere has been much interest in learning modalities and styles over the last two decades. The most commonly employed learning modalities are:[52]\\r\\nOther commonly employed modalities include musical, interpersonal, verbal, logical, and intrapersonal.\\r\\nDunn and Dunn[53] focused on identifying relevant stimuli that may influence learning and manipulating the school environment, at about the same time as Joseph Renzulli[54] recommended varying teaching strategies. Howard Gardner[55] identified a wide range of modalities in his Multiple Intelligences theories. The Myers-Briggs Type Indicator and Keirsey Temperament Sorter, based on the works of Jung,[56] focus on understanding how people's personality affects the way they interact personally, and how this affects the way individuals respond to each other within the learning environment. The work of David Kolb and Anthony Gregorc's Type Delineator[57] follows a similar but more simplified approach.\\r\\nSome theories propose that all individuals benefit from a variety of learning modalities, while others suggest that individuals may have preferred learning styles, learning more easily through visual or kinesthetic experiences.[58] A consequence of the latter theory is that effective teaching should present a variety of teaching methods which cover all three learning modalities so that different students have equal opportunities to learn in a way that is effective for them.[59] Guy Claxton has questioned the extent that learning styles such as Visual, Auditory and Kinesthetic(VAK) are helpful, particularly as they can have a tendency to label children and therefore restrict learning.[60][61] Recent research has argued, \\"there is no adequate evidence base to justify incorporating learning styles assessments into general educational practice.\\"[62]\\r\\nEducational neuroscience is an emerging scientific field that brings together researchers in cognitive neuroscience, developmental cognitive neuroscience, educational psychology, educational technology, education theory and other related disciplines to explore the interactions between biological processes and education.[63][64][65][66] Researchers in educational neuroscience investigate the neural mechanisms of reading,[65] numerical cognition,[67] attention, and their attendant difficulties including dyslexia,[68][69] dyscalculia,[70] and ADHD as they relate to education. Several academic institutions around the world are beginning to devote resources to the establishment of educational neuroscience research.\\r\\nAs an academic field, philosophy of education is \\"the philosophical study of education and its problems?(...) its central subject matter is education, and its methods are those of philosophy\\".[71] \\"The philosophy of education may be either the philosophy of the process of education or the philosophy of the discipline of education. That is, it may be part of the discipline in the sense of being concerned with the aims, forms, methods, or results of the process of educating or being educated; or it may be metadisciplinary in the sense of being concerned with the concepts, aims, and methods of the discipline.\\"[72] As such, it is both part of the field of education and a field of applied philosophy, drawing from fields of metaphysics, epistemology, axiology and the philosophical approaches (speculative, prescriptive or analytic) to address questions in and about pedagogy, education policy, and curriculum, as well as the process of learning, to name a few.[73] For example, it might study what constitutes upbringing and education, the values and norms revealed through upbringing and educational practices, the limits and legitimization of education as an academic discipline, and the relation between education theory and practice.\\r\\nThere is no broad consensus as to what education's chief aim or aims are or should be. Some authors stress its value to the individual, emphasizing its potential for positively influencing students' personal development, promoting autonomy, forming a cultural identity or establishing a career or occupation. Other authors emphasize education's contributions to societal purposes, including good citizenship, shaping students into productive members of society, thereby promoting society's general economic development, and preserving cultural values.[74]\\r\\nIn formal education, a curriculum is the set of courses and their content offered at a school or university. As an idea, curriculum stems from the Latin word for race course, referring to the course of deeds and experiences through which children grow to become mature adults. A curriculum is prescriptive and is based on a more general syllabus which merely specifies what topics must be understood and to what level to achieve a particular grade or standard.\\r\\nAn academic discipline is a branch of knowledge which is formally taught, either at the universityÿor via some other such method. Each discipline usually has several sub-disciplines or branches, and distinguishing lines are often both arbitrary and ambiguous. Examples of broad areas of academic disciplines include the natural sciences, mathematics, computer science, social sciences, humanities and applied sciences.[75]\\r\\nEducational institutions may incorporate fine arts as part of K-12 grade curricula or within majors at colleges and universities as electives. The various types of fine arts are music, dance, and theatre.[76]\\r\\nInstruction is the facilitation of another's learning. Instructors in primary and secondary institutions are often called teachers, and they direct the education of students and might draw on many subjects like reading, writing, mathematics, science and history. Instructors in post-secondary institutions might be called teachers, instructors, or professors, depending on the type of institution; and they primarily teach only their specific discipline. Studies from the United States suggest that the quality of teachers is the single most important factor affecting student performance, and that countries which score highly on international tests have multiple policies in place to ensure that the teachers they employ are as effective as possible.[77][78] With the passing of NCLB in the United States (No Child Left Behind), teachers must be highly qualified. A popular way to gauge teaching performance is to use student evaluations of teachers (SETS), but these evaluations have been criticized for being counterproductive to learning and inaccurate due to student bias.[79]\\r\\nCollege basketball coach John Wooden the Wizard of Westwood would teach through quick \\"This not That\\" technique. He would show (a) the correct way to perform an action, (b) the incorrect way the player performed it, and again (c) the correct way to perform an action. This helped him to be a responsive teacher and fix errors on the fly. Also, less communication from him meant more time that the player could practice.[80]\\r\\nIt has been argued that high rates of education are essential for countries to be able to achieve high levels of economic growth.[81] Empirical analyses tend to support the theoretical prediction that poor countries should grow faster than rich countries because they can adopt cutting edge technologies already tried and tested by rich countries. However, technology transfer requires knowledgeable managers and engineers who are able to operate new machines or production practices borrowed from the leader in order to close the gap through imitation. Therefore, a country's ability to learn from the leader is a function of its stock of \\"human capital\\". Recent study of the determinants of aggregate economic growth have stressed the importance of fundamental economic institutions[82] and the role of cognitive skills.[83]\\r\\nAt the level of the individual, there is a large literature, generally related to the work of Jacob Mincer,[84] on how earnings are related to the schooling and other human capital. This work has motivated a large number of studies, but is also controversial. The chief controversies revolve around how to interpret the impact of schooling.[85][86] Some students who have indicated a high potential for learning, by testing with a high intelligence quotient, may not achieve their full academic potential, due to financial difficulties.[citation needed]\\r\\nEconomists Samuel Bowles and Herbert Gintis argued in 1976 that there was a fundamental conflict in American schooling between the egalitarian goal of democratic participation and the inequalities implied by the continued profitability of capitalist production.[87]\\r\\nMany countries are now drastically changing the way they educate their citizens. The world is changing at an ever quickening rate, which means that a lot of knowledge becomes obsolete and inaccurate more quickly. The emphasis is therefore shifting to teaching the skills of learning: to picking up new knowledge quickly and in as agile a way as possible. Finnish schools have even begun to move away from the regular subject-focused curricula, introducing instead developments like phenomenon-based learning, where students study concepts like climate change instead.[88]\\r\\nEducation is also becoming a commodity no longer reserved for children. Adults need it too.[89] Some governmental bodies, like the Finnish Innovation Fund Sitra in Finland, have even proposed compulsory life-long education.[90]\\r\\nThis article incorporates text from a free content work. Licensed under CC-BY-SA IGO 3.0 Licence statement: Out in the Open: Education sector responses to violence based on sexual orientation and gender identity/expression, 54, UNESCO.\\r\\nTo learn how to add freely licensed text to Wikipedia articles, please see the terms of use.\\r\\nThis article incorporates text from a free content work. Licence statement: Cracking the code: girls' and women's education in science, technology, engineering and mathematics (STEM), UNESCO.\\r\\nTo learn how to add freely licensed text to Wikipedia articles, please see the terms of use.","input":"What is the origin of the word education?"},{"output":"a rapid response throughout the body in stress situations","context":"The adrenal glands (also known as suprarenal glands) are endocrine glands that produce a variety of hormones including adrenaline and the steroids aldosterone and cortisol.[1][2] They are found above the kidneys. Each gland has an outer cortex which produces steroid hormones and an inner medulla. The adrenal cortex itself is divided into three zones: zona glomerulosa, the zona fasciculata and the zona reticularis.[3]\\r\\nThe adrenal cortex produces three main types of steroid hormones: mineralocorticoids, glucocorticoids, and androgens. Mineralocorticoids (such as aldosterone) produced in the zona glomerulosa help in the regulation of blood pressure and electrolyte balance. The glucocorticoids cortisol and corticosterone are synthesized in the zona fasciculata; their functions include the regulation of metabolism and immune system suppression. The innermost layer of the cortex, the zona reticularis, produces androgens that are converted to fully functional sex hormones in the gonads and other target organs.[4] The production of steroid hormones is called steroidogenesis, and involves a number of reactions and processes that take place in cortical cells.[5] The medulla produces the catecholamines adrenaline and noradrenaline, which function to produce a rapid response throughout the body in stress situations.[4]\\r\\nA number of endocrine diseases involve dysfunctions of the adrenal gland. Overproduction of cortisol leads to Cushing's syndrome, whereas insufficient production is associated with Addison's disease. Congenital adrenal hyperplasia is a genetic disease produced by dysregulation of endocrine control mechanisms.[4][6] A variety of tumors can arise from adrenal tissue and are commonly found in medical imaging when searching for other diseases.[7]\\r\\nThe adrenal glands are located on both sides of the body in the retroperitoneum, above and slightly medial to the kidneys. In humans, the right adrenal gland is pyramidal in shape, whereas the left is semilunar or crescent shaped and somewhat larger.[8] The adrenal glands measure approximately 3.0?cm in width, 5.0?cm in length, and up to 1.0?cm in thickness.[9] Their combined weight in an adult human ranges from 7 to 10?grams.[10] The glands are yellowish in colour.[8]\\r\\nThe adrenal glands are surrounded by a fatty capsule and lie within the renal fascia, which also surrounds the kidneys. A weak septum (wall) of connective tissue separates the glands from the kidneys.[11] The adrenal glands are directly below the diaphragm, and are attached to the crura of the diaphragm by the renal fascia.[11]\\r\\nEach adrenal gland has two distinct parts, each with a unique function, the outer adrenal cortex and the inner medulla, both of which produce hormones.[12]\\r\\nThe adrenal cortex is the outermost layer of the adrenal gland. Within the cortex are three layers, called \\"zones\\". When viewed under a microscope each layer has a distinct appearance, and each has a different function.[13] The adrenal cortex is devoted to production of hormones, namely aldosterone, cortisol, and androgens.[14]\\r\\nThe outermost zone of the adrenal cortex is the zona glomerulosa. It lies immediately under the fibrous capsule of the gland. Cells in this layer form oval groups, separated by thin strands of connective tissue from the fibrous capsule of the gland and carry wide capillaries.[15]\\r\\nThis layer is the main site for production of aldosterone, a mineralocorticoid, by the action of the enzyme aldosterone synthase.[16][17] Aldosterone plays an important role in the long-term regulation of blood pressure.[18]\\r\\nThe zona fasciculata is situated between the zona glomerulosa and zona reticularis. Cells in this layer are responsible for producing glucocorticoids such as cortisol.[19] It is the largest of the three layers, accounting for nearly 80% of the volume of the cortex.[3] In the zona fasciculata, cells are arranged in columns radially oriented towards the medulla. Cells contain numerous lipid droplets, abundant mitochondria and a complex smooth endoplasmic reticulum.[15]\\r\\nThe innermost cortical layer, the zona reticularis, lies directly adjacent to the medulla. It produces androgens, mainly dehydroepiandrosterone (DHEA), DHEA sulfate (DHEA-S), and androstenedione (the precursor to testosterone) in humans.[19] Its small cells form irregular cords and clusters, separated by capillaries and connective tissue. The cells contain relatively small quantities of cytoplasm and lipid droplets, and sometimes display brown lipofuscin pigment.[15]\\r\\nThe adrenal medulla is at the centre of each adrenal gland, and is surrounded by the adrenal cortex. The chromaffin cells of the medulla are the body's main source of the catecholamines adrenaline and noradrenaline, released by the medulla. Approximately 20% noradrenaline (norepinephrine) and 80% adrenaline (epinephrine) are secreted here.[19]\\r\\nThe adrenal medulla is driven by the sympathetic nervous system via preganglionic fibers originating in the thoracic spinal cord, from vertebrae T5ÿT11.[20] Because it is innervated by preganglionic nerve fibers, the adrenal medulla can be considered as a specialized sympathetic ganglion.[20] Unlike other sympathetic ganglia, however, the adrenal medulla lacks distinct synapses and releases its secretions directly into the blood.\\r\\nThe adrenal glands have one of the greatest blood supply rates per gram of tissue of any organ: up to 60 small arteries may enter each gland.[21] Three arteries usually supply each adrenal gland:[8]\\r\\nThese blood vessels supply a network of small arteries within the capsule of the adrenal glands. Thin strands of the capsule enter the glands, carrying blood to them.[8]\\r\\nVenous blood is drained from the glands by the suprarenal veins, usually one for each gland:[8]\\r\\nThe central adrenomedullary vein, in the adrenal medulla, is an unusual type of blood vessel. Its structure is different from the other veins in that the smooth muscle in its tunica media (the middle layer of the vessel) is arranged in conspicuous, longitudinally oriented bundles.[3]\\r\\nThe adrenal glands may not develop at all, or may be fused in the midline behind the aorta.[12] These are associated with other congenital abnormalities, such as failure of the kidneys to develop, or fused kidneys.[12] The gland may develop with a partial or complete absence of the cortex, or may develop in an unusual location.[12]\\r\\nThe adrenal gland secretes a number of different hormones which are metabolised by enzymes either within the gland or in other parts of the body. These hormones are involved in a number of essential biological functions.[23]\\r\\nCorticosteroids are a group of steroid hormones produced from the cortex of the adrenal gland, from which they are named.[24] Corticosteroids are named according to their actions:\\r\\nThe adrenal gland produces aldosterone, a mineralocorticoid, which is important in the regulation of salt (\\"mineral\\") balance and blood volume. In the kidneys, aldosterone acts on the distal convoluted tubules and the collecting ducts by increasing the reabsorption of sodium and the excretion of both potassium and hydrogen ions.[18] Aldosterone is responsible for the reabsorption of about 2% of filtered glomerular filtration rates.[27] Sodium retention is also a response of the distal colon and sweat glands to aldosterone receptor stimulation. Angiotensin II and extracellular potassium are the two main regulators of aldosterone production.[19] The amount of sodium present in the body affects the extracellular volume, which in turn influences blood pressure. Therefore, the effects of aldosterone in sodium retention are important for the regulation of blood pressure.[28]\\r\\nCortisol is the main glucocorticoid in humans. In species that do not create cortisol, this role is played by corticosterone instead. Glucocorticoids have many effects on metabolism. As their name suggests, they increase the circulating level of glucose. This is the result of an increase in the mobilization of amino acids from protein and the stimulation of synthesis of glucose from these amino acids in the liver. In addition, they increase the levels of free fatty acids, which cells can use as an alternative to glucose to obtain energy. Glucocorticoids also have effects unrelated to the regulation of blood sugar levels, including the suppression of the immune system and a potent anti-inflammatory effect. Cortisol reduces the capacity of osteoblasts to produce new bone tissue and decreases the absorption of calcium in the gastrointestinal tract.[28]\\r\\nThe adrenal gland secretes a basal level of cortisol but can also produce bursts of the hormone in response to adrenocorticotropic hormone (ACTH) from the anterior pituitary. Cortisol is not evenly released during the day ÿ its concentrations in the blood are highest in the early morning and lowest in the evening as a result of the circadian rhythm of ACTH secretion.[28] Cortisone is an inactive product of the action of the enzyme 11-HSD on cortisol. The reaction catalyzed by 11-HSD is reversible, which means that it can turn administered cortisone into cortisol, the biologically active hormone.[28]\\r\\nAll corticosteroid hormones share cholesterol as a common precursor. Therefore, the first step in steroidogenesis is cholesterol uptake or synthesis. Cells that produce steroid hormones can acquire cholesterol through two paths. The main source is through dietary cholesterol transported via the blood as cholesterol esters within low density lipoproteins (LDL). LDL enters the cells through receptor-mediated endocytosis. The other source of cholesterol is synthesis in the cell's endoplasmic reticulum. Synthesis can compensate when LDL levels are abnormally low.[4] In the lysosome, cholesterol esters are converted to free cholesterol, which is then used for steroidogenesis or stored in the cell.[29]\\r\\nThe initial part of conversion of cholesterol into steroid hormones involves a number of enzymes of the cytochrome P450 family that are located in the inner membrane of mitochondria. Transport of cholesterol from the outer to the inner membrane is facilitated by steroidogenic acute regulatory protein and is the rate-limiting step of steroid synthesis.[29]\\r\\nThe layers of the adrenal gland differ by function, with each layer having distinct enzymes that produce different hormones from a common precursor.[4] The first enzymatic step in the production of all steroid hormones is cleavage of the cholesterol side chain, a reaction that forms pregnenolone as a product and is catalyzed by the enzyme P450scc, also known as cholesterol desmolase. After the production of pregnenolone, specific enzymes of each cortical layer further modify it. Enzymes involved in this process include both mitochondrial and microsomal P450s and hydroxysteroid dehydrogenases. Usually a number of intermediate steps in which pregnenolone is modified several times are required to form the functional hormones.[5] Enzymes that catalyze reactions in these metabolic pathways are involved in a number of endocrine diseases. For example, the most common form of congenital adrenal hyperplasia develops as a result of deficiency of 21-hydroxylase, an enzyme involved in an intermediate step of cortisol production.[30]\\r\\nGlucocorticoids are under the regulatory influence of the hypothalamus-pituitary-adrenal (HPA) axis. Glucocorticoid synthesis is stimulated by adrenocorticotropic hormone (ACTH), a hormone released into the bloodstream by the anterior pituitary. In turn, production of ACTH is stimulated by the presence of corticotropin-releasing hormone (CRH), which is released by neurons of the hypothalamus. ACTH acts on the adrenal cells first by increasing the levels of StAR within the cells, and then of all steroidogenic P450 enzymes. The HPA axis is an example of a negative feedback system, in which cortisol itself acts as a direct inhibitor of both CRH and ACTH synthesis. The HPA axis also interacts with the immune system through increased secretion of ACTH at the presence of certain molecules of the inflammatory response.[4]\\r\\nMineralocorticoid secretion is regulated mainly by the reninÿangiotensinÿaldosterone system (RAAS), the concentration of potassium, and to a lesser extent the concentration of ACTH.[4] Sensors of blood pressure in the juxtaglomerular apparatus of the kidneys release the enzyme renin into the blood, which starts a cascade of reactions that lead to formation of angiotensin II. Angiotensin receptors in cells of the zona glomerulosa recognize the substance, and upon binding they stimulate the release of aldosterone.[31]\\r\\nPrimarily referred to in the United States as Epinephrine and norepinephrine, Adrenaline and noradrenaline are catecholamines, water-soluble compounds that have a structure made of a catechol group and an amine group. The adrenal glands are responsible for most of the adrenaline that circulates in the body, but only for a small amount of circulating noradrenaline.[23] These hormones are released by the adrenal medulla, which contains a dense network of blood vessels. Adrenaline and noradrenaline act at adrenoreceptors throughout the body, with effects that include an increase in blood pressure and heart rate.[23] The actions of adrenaline and noradrenaline are responsible for the fight or flight response, characterised by a quickening of breathing and heart rate, an increase in blood pressure, and constriction of blood vessels in many parts of the body.[32]\\r\\nCatecholamines are produced in chromaffin cells in the medulla of the adrenal gland, from tyrosine, a non-essential amino acid derived from food or produced from phenylalanine in the liver. The enzyme tyrosine hydroxylase converts tyrosine to L-DOPA in the first step of catecholamine synthesis. L-DOPA is then converted to dopamine before it can be turned into noradrenaline. In the cytosol, noradrenaline is converted to epinephrine by the enzyme phenylethanolamine N-methyltransferase (PNMT) and stored in granules. Glucocorticoids produced in the adrenal cortex stimulate the synthesis of catecholamines by increasing the levels of tyrosine hydroxylase and PNMT.[4][13]\\r\\nCatecholamine release is stimulated by the activation of the sympathetic nervous system. Splanchnic nerves of the sympathetic nervous system innervate the medulla of the adrenal gland. When activated, it evokes the release of catecholamines from the storage granules by stimulating the opening of calcium channels in the cell membrane.[33]\\r\\nCells in zona reticularis of the adrenal glands produce male sex hormones, or androgens, the most important of which is DHEA. In general, these hormones do not have an overall effect in the male body, and are converted to more potent androgens such as testosterone and DHT or to estrogens (female sex hormones) in the gonads, acting in this way as a metabolic intermediate.[34]\\r\\nThe?human genome?includes approximately 20,000 protein coding genes and 70% of these?genes are expressed?in the normal, adult adrenal glands.[35][36]?Only some 250 genes are more specifically expressed in the adrenal glands compared to other organs and tissues.?The adrenal gland specific genes with highest level of expression include members of the cytochrome P450 superfamily of enzymes. Corresponding proteins are expressed in the different compartments of the adrenal gland, such as CYP11A1, HSD3B2 and FDX1 involved in steroid hormone synthesis and expressed in cortical cell layers, and PNMT and DBH involved in noradrenalin and adrenalin synthesis and expressed in the medulla.[37]\\r\\nThe adrenal glands are composed of two heterogenous types of tissue. In the center is the adrenal medulla, which produces adrenaline and noradrenaline and releases them into the bloodstream, as part of the sympathetic nervous system. Surrounding the medulla is the cortex, which produces a variety of steroid hormones. These tissues come from different embryological precursors and have distinct prenatal development paths. The cortex of the adrenal gland is derived from mesoderm, whereas the medulla is derived from the neural crest, which is of ectodermal origin.[12]\\r\\nThe adrenal glands in a newborn baby are much larger as a proportion of the body size than in an adult.[38] For example, at age three months the glands are four times the size of the kidneys. The size of the glands decreases relatively after birth, mainly because of shrinkage of the cortex. The cortex, which almost completely disappears by age 1, develops again from age 4ÿ5. The glands weigh about 1 g at birth[12] and develop to an adult weight of about 4 grams each.[28] In a fetus the glands are first detectable after the sixth week of development.[12]\\r\\nAdrenal cortex tissue is derived from the intermediate mesoderm. It first appears 33 days after fertilisation, shows steroid hormone production capabilities by the eighth week and undergoes rapid growth during the first trimester of pregnancy. The fetal adrenal cortex is different from its adult counterpart, as it is composed of two distinct zones: the inner \\"fetal\\" zone, which carries most of the hormone-producing activity, and the outer \\"definitive\\" zone, which is in a proliferative phase. The fetal zone produces large amounts of adrenal androgens (male sex hormones) that are used by the placenta for estrogen biosynthesis.[39] Cortical development of the adrenal gland is regulated mostly by ACTH, a hormone produced by the pituitary gland that stimulates cortisol synthesis.[40] During midgestation, the fetal zone occupies most of the cortical volume and produces 100ÿ200?mg/day of DHEA-S, an androgen and precursor of both androgens and estrogens (female sex hormones).[41] Adrenal hormones, especially glucocorticoids such as cortisol, are essential for prenatal development of organs, particularly for the maturation of the lungs. The adrenal gland decreases in size after birth because of the rapid disappearance of the fetal zone, with a corresponding decrease in androgen secretion.[39]\\r\\nDuring early childhood androgen synthesis and secretion remain low, but several years before puberty (from 6ÿ8 years of age) changes occur in both anatomical and functional aspects of cortical androgen production that lead to increased secretion of the steroids DHEA and DHEA-S. These changes are part of a process called adrenarche, which has only been described in humans and some other primates. Adrenarche is independent of ACTH or gonadotropins and correlates with a progressive thickening of the zona reticularis layer of the cortex. Functionally, adrenarche provides a source of androgens for the development of axillary and pubic hair before the beginning of puberty.[42][43]\\r\\nThe adrenal medulla is derived from neural crest cells, which come from the ectoderm layer of the embryo. These cells migrate from their initial position and aggregate in the vicinity of the dorsal aorta, a primitive blood vessel, which activates the differentiation of these cells through the release of proteins known as BMPs. These cells then undergo a second migration from the dorsal aorta to form the adrenal medulla and other organs of the sympathetic nervous system.[44] Cells of the adrenal medulla are called chromaffin cells because they contain granules that stain with chromium salts, a characteristic not present in all sympathetic organs. Glucocorticoids produced in the adrenal cortex were once thought to be responsible for the differentiation of chromaffin cells. More recent research suggests that BMP-4 secreted in adrenal tissue is the main responsible for this, and that glucocorticoids only play a role in the subsequent development of the cells.[45]\\r\\nThe normal function of the adrenal gland may be impaired by conditions such as infections, tumors, genetic disorders and autoimmune diseases, or as a side effect of medical therapy. These disorders affect the gland either directly (as with infections or autoimmune diseases) or as a result of the dysregulation of hormone production (as in some types of Cushing's syndrome) leading to an excess or insufficiency of adrenal hormones and the related symptoms.\\r\\nCushing's syndrome is the manifestation of glucocorticoid excess. It can be the result of a prolonged treatment with glucocorticoids or be caused by an underlying disease which produces alterations in the HPA axis or the production of cortisol. Causes can be further classified into ACTH-dependent or ACTH-independent. The most common cause of endogenous Cushing's syndrome is a pituitary adenoma which causes an excessive production of ACTH. The disease produces a wide variety of signs and symptoms which include obesity, diabetes, increased blood pressure, excessive body hair (hirsutism), osteoporosis, depression, and most distinctively, stretch marks in the skin, caused by its progressive thinning.[4][6]\\r\\nWhen the zona glomerulosa produces excess aldosterone, the result is primary aldosteronism. Causes for this condition are bilateral hyperplasia (excessive tissue growth) of the glands, or aldosterone-producing adenomas (a condition called Conn's syndrome). Primary aldosteronism produces hypertension and electrolyte imbalance, increasing potassium depletion and sodium retention.[6]\\r\\nAdrenal insufficiency (the deficiency of glucocorticoids) occurs in about 5 in 10,000 in the general population.[6] Diseases classified as primary adrenal insufficiency (including Addison's disease and genetic causes) directly affect the adrenal cortex. If a problem that affects the hypothalamic-pituitary-adrenal axis arises outside the gland, it is a secondary adrenal insufficiency.\\r\\nAddison's disease refers to primary hypoadrenalism, which is a deficiency in glucocorticoid and mineralocorticoid production by the adrenal gland. In the Western world, Addison's disease is most commonly an autoimmune condition, in which the body produces antibodies against cells of the adrenal cortex. Worldwide, the disease is more frequently caused by infection, especially from tuberculosis. A distinctive feature of Addison's disease is hyperpigmentation of the skin, which presents with other nonspecific symptoms such as fatigue.[4]\\r\\nA complication seen in untreated Addison's disease and other types of primary adrenal insufficiency is the adrenal crisis, a medical emergency in which low glucocorticoid and mineralocorticoid levels result in hypovolemic shock and symptoms such as vomiting and fever. An adrenal crisis can progressively lead to stupor and coma.[4] The management of adrenal crises includes the application of hydrocortisone injections.[46]\\r\\nIn secondary adrenal insufficiency, a dysfunction of the hypothalamic-pituitary-adrenal axis leads to decreased stimulation of the adrenal cortex. Apart from suppression of the axis by glucocorticoid therapy, the most common cause of secondary adrenal insufficiency are tumors that affect the production of adrenocorticotropic hormone (ACTH) by the pituitary gland.[6] This type of adrenal insufficiency usually does not affect the production of mineralocorticoids, which are under regulation of the reninÿangiotensin system instead.[4]\\r\\nCongenital adrenal hyperplasia is a congenital disease in which mutations of enzymes that produce steroid hormones result in a glucocorticoid deficiency and malfunction of the negative feedback loop of the HPA axis. In the HPA axis, cortisol (a glucocorticoid) inhibits the release of CRH and ACTH, hormones that in turn stimulate corticosteroid synthesis. As cortisol cannot be synthesized, these hormones are released in high quantities and stimulate production of other adrenal steroids instead. The most common form of congenital adrenal hyperplasia is due to 21-hydroxylase deficiency. 21-hydroxylase is necessary for production of both mineralocorticoids and glucocorticoids, but not androgens. Therefore, ACTH stimulation of the adrenal cortex induces the release of excessive amounts of adrenal androgens, which can lead to the development of ambiguous genitalia and secondary sex characteristics.[30]\\r\\nAdrenal tumors are commonly found as incidentalomas, unexpected asymptomatic tumors found during medical imaging. They are seen in around 3.4% of CT scans,[7] and in most cases they are benign adenomas.[47] Adrenal carcinomas are very rare, with an incidence of 1 case per million per year.[4]\\r\\nPheochromocytomas are tumors of the adrenal medulla that arise from chromaffin cells. They can produce a variety of nonspecific symptoms, which include headaches, sweating, anxiety and palpitations. Common signs include hypertension and tachycardia. Surgery, especially adrenal laparoscopy, is the most common treatment for small pheochromocytomas.[48]\\r\\nBartolomeo Eustachi, an Italian anatomist, is credited with the first description of the adrenal glands in 1563-4.[49][50] However, these publications were part of the papal library and did not receive public attention, which was first received with Caspar Bartholin the Elder's illustrations in 1611.[50]\\r\\nThe adrenal glands are named for their location relative to the kidneys. The term \\"adrenal\\" comes from ad- (Latin, \\"near\\") and renes (Latin, \\"kidney\\").[51] Similarly, \\"suprarenal\\", as termed by Jean Riolan the Younger in 1629, is derived from the Latin supra (Latin: \\"above\\") and renes (Latin: kidney). The suprarenal nature of the glands was not truly accepted until the 19th century, as anatomists clarified the ductless nature of the glands and their likely secretory role ÿ prior to this, there was some debate as to whether the glands were indeed suprarenal or part of the kidney.[50]\\r\\nOne of the most recognized works on the adrenal glands came in 1855 with the publication of On the Constitutional and Local Effects of Disease of the Suprarenal Capsule, by the English physician Thomas Addison. In his monography, Addison described what the French physician George Trousseau would later name Addison's disease, an eponym still used today for a condition of adrenal insufficiency and its related clinical manifestations.[52] In 1894, English physiologists George Oliver and Edward Schafer studied the action of adrenal extracts and observed their pressor effects. In the following decades several physicians experimented with extracts from the adrenal cortex to treat Addison's disease.[49] Edward Calvin Kendall, Philip Hench and Tadeusz Reichstein were then awarded the 1950 Nobel Prize in Physiology or Medicine for their discoveries on the structure and effects of the adrenal hormones.[53]","input":"What general effects do hormones secreted by the adrenal medulla produce?"},{"output":"Emperor Nicholas II","context":"The Russian Revolution was a pair of revolutions in Russia in 1917 which dismantled the Tsarist autocracy and led to the rise of the Soviet Union. The Russian Empire collapsed with the abdication of Emperor Nicholas II and the old regime was replaced by a provisional government during the first revolution of February 1917 (March in the Gregorian calendar; the older Julian calendar was in use in Russia at the time). Alongside it arose grassroots community assemblies (called 'soviets') which contended for authority. In the second revolution that October, the Provisional Government was toppled and all power was given to the soviets.\\r\\nThe February Revolution (March 1917) was a revolution focused around Petrograd (now Saint Petersburg), the capital of Russia at that time. In the chaos, members of the Imperial parliament (the Duma) assumed control of the country, forming the Russian Provisional Government which was heavily dominated by the interests of large capitalists and the noble aristocracy. The army leadership felt they did not have the means to suppress the revolution, resulting in Nicholas's abdication. The soviets, which were dominated by soldiers and the urban industrial working class, initially permitted the Provisional Government to rule, but insisted on a prerogative to influence the government and control various militias. The February Revolution took place in the context of heavy military setbacks during the First World War (1914ÿ18), which left much of the Russian Army in a state of mutiny.\\r\\nA period of dual power ensued, during which the Provisional Government held state power while the national network of soviets, led by socialists, had the allegiance of the lower classes and, increasingly, the left-leaning urban middle class. During this chaotic period there were frequent mutinies, protests and many strikes. Many socialist political organizations were engaged in daily struggle and vied for influence within the Duma and the soviets, central among which were the Bolsheviks (\\"Ones of the Majority\\") led by Vladimir Lenin who campaigned for an immediate end to the war, land to the peasants, and bread to the workers. When the Provisional Government chose to continue fighting the war with Germany, the Bolsheviks and other socialist factions were able to exploit virtually universal disdain towards the war effort as justification to advance the revolution further. The Bolsheviks turned workers' militias under their control into the Red Guards (later the Red Army) over which they exerted substantial control.[1]\\r\\nIn the October Revolution (November in the Gregorian calendar), the Bolsheviks led an armed insurrection by workers and soldiers in Petrograd that successfully overthrew the Provisional Government, transferring all its authority to the soviets with the capital being relocated to Moscow shortly thereafter. The Bolsheviks had secured a strong base of support within the soviets and, as the now supreme governing party, established a federal government dedicated to reorganizing the former empire into the world's first socialist republic, practicing soviet democracy on a national and international scale. The promise to end Russias participation in the First World War was honored promptly with the Bolshevik leaders signing the Treaty of Brest-Litovsk with Germany in March 1918. To further secure the new state, the Cheka was established which functioned as a revolutionary security service that sought to weed out and punish those considered to be \\"enemies of the people\\" in campaigns consciously modeled on similar events during the French Revolution.\\r\\nSoon after, civil war erupted among the \\"Reds\\" (Bolsheviks), the \\"Whites\\" (counter-revolutionaries), the independence movements and the non-Bolshevik socialists. It continued for several years, during which the Bolsheviks defeated both the Whites and all rival socialists and thereafter reconstituted themselves as the Communist Party. In this way, the Revolution paved the way for the creation of the Union of Soviet Socialist Republics (USSR) in 1922. While many notable historical events occurred in Moscow and Petrograd, there was also a visible movement in cities throughout the state, among national minorities throughout the empire and in the rural areas, where peasants took over and redistributed land.\\r\\n\\r\\n\\r\\nThe Russian Revolution of 1905 was said to be a major factor contributing to the cause of the Revolutions of 1917. The events of Bloody Sunday triggered nationwide protests and soldier mutinies. A council of workers called the St. Petersburg Soviet was created in this chaos. [2] While the 1905 Revolution was ultimately crushed, and the leaders of the St. Petersburg Soviet were arrested, this laid the groundwork for the later Petrograd Soviet and other revolutionary movements during the leadup to 1917. The 1905 Revolution also lead to the creation of a Duma (parliament), that would later form the Provisional Government following February 1917. [3]\\r\\nThe outbreak World War I prompted general outcry directed at Tsar Nicholas II and the Romanov family. While the nation was initially caught up in a wave of nationalism, increasing numbers of defeats and poor conditions soon made the opposite true. The Tsar attempted to remedy the situation by taking personal control of the army in 1915. This proved disastrous, as the Tsar was now held personally responsible for Russia's continuing defeats and losses. In addition, the Tsarina Alexandra, left to rule in while the Tsar was commanding at the front, was German born, leading to suspicion of collusion, only exacerbated by rumors relating to her relationship with the controversial mystic Rasputin. Rasputin's influence lead to disastrous ministerial appointments and corruption, resulting in a worsening of conditions within Russia. This lead to general dissatisfaction with the Romanov family, and was a major factor contributing to the retaliation of the Russian Communists against the royal family. [3]\\r\\nAfter the entry of the Ottoman Empire on the side of the Central Powers in October 1914, Russia was deprived of a major trade route through the Dardanelles, which further contributed to the economic crisis, in which Russia became incapable of providing munitions to their army in the years leading to 1917. However, the problems were primarily administrative, and not industrial, as Germany was producing great amounts of munitions whilst constantly fighting on two major battlefronts.[4]\\r\\nThe conditions during the war resulted in devastating loss of morale within the Russian army, as well as the general population. This was particularly apparent in the cities, owing to a lack of food in response to the disruption of agriculture. Food scarcity had become a considerable problem in Russia, but the cause of this did not lie in any failure of the harvests, which had not been significantly altered during wartime. The indirect reason was that the government, in order to finance the war, had been printing millions of ruble notes, and by 1917 inflation had made prices increase up to four times what they had been in 1914. Farmers were consequently faced with a higher cost of living, but little increase in income. As a result, they tended to hoard their grain and to revert to subsistence farming. Thus the cities were constantly short of food. At the same time, rising prices led to demands for higher wages in the factories, and in January and February 1916 revolutionary propaganda, in part aided by German funds, led to widespread strikes. This resulted in a growing criticism of the government, including an increased participation of workers in revolutionary parties.\\r\\nLiberal parties too had an increased platform to voice their complaints, as the initial fervor of the war had resulted in the Tsarist government creating a variety of political organizations. In July 1915, a Central War Industries Committee was established under the chairmanship of a prominent Octobrist, Alexander Guchkov (1862-1936), including ten workers' representatives. The Petrograd Mensheviks agreed to join despite the objections of their leaders abroad. All this activity gave renewed encouragement to political ambitions, and, in September 1915, a combination of Octobrists and Kadets in the Duma demanded the forming of a responsible government. The Tsar rejected these proposals.[5]\\r\\nAll these factors had given rise to a sharp loss of confidence in the regime, even within the ruling class, growing throughout the war. Early in 1916, Guchkov discussed with senior army officers and members of the Central War Industries Committee about a possible coup to force the abdication of the Tsar. In December, a small group of nobles assassinated Rasputin, and in January 1917 the Tsar's uncle, Grand Duke Nicholas, was asked indirectly by Prince Lvov whether he would be prepared to take over the throne from his nephew, Tsar Nicholas II. None of these incidents were in themselves the immediate cause of the February Revolution, but they do help to explain why the monarchy survived only a few days after it had broken out.[5]\\r\\nMeanwhile, Socialist Revolutionary leaders in exile, many of them living in Switzerland, had been the glum spectators of the collapse of international socialist solidarity. French and German Social Democrats had voted in favour of their respective governments' war efforts. Georgi Plekhanov in Paris had adopted a violently anti-German stand, while Parvus supported the German war effort as the best means of ensuring a revolution in Russia. The Mensheviks largely maintained that Russia had the right to defend herself against Germany, although Martov (a prominent Menshevik), now on the left of his group, demanded an end to the war and a settlement on the basis of national self-determination, with no annexations or indemnities.[5]\\r\\nIt was these views of Martov that predominated in a manifesto drawn up by Leon Trotsky (at the time a Menshevik) at a conference in Zimmerwald, attended by 35 Socialist leaders in September 1915. Inevitably Vladimir Lenin, supported by Zinoviev and Radek, strongly contested them. Their attitudes became known as the Zimmerwald Left. Lenin rejected both the defence of Russia and the cry for peace. Since the autumn of 1914, he had insisted that \\"from the standpoint of the working class and of the labouring masses from the lesser evil would be the defeat of the Tsarist Monarchy\\"; the war must be turned into a civil war of the proletarian soldiers against their own governments, and if a proletarian victory should emerge from this in Russia, then their duty would be to wage a revolutionary war for the liberation of the masses throughout Europe.[6]\\r\\nAn elementary theory of property, believed by many peasants, was that land should belong to those who work on it. At the same time, peasant life and culture was changing constantly. Change was facilitated by the physical movement of growing numbers of peasant villagers who migrated to and from industrial and urban environments, but also by the introduction of city culture into the village through material goods, the press, and word of mouth.[nb 1]\\r\\nWorkers also had good reasons for discontent: overcrowded housing with often deplorable sanitary conditions, long hours at work (on the eve of the war a 10-hour workday six days a week was the average and many were working 11ÿ12 hours a day by 1916), constant risk of injury and death from poor safety and sanitary conditions, harsh discipline (not only rules and fines, but foremen's fists), and inadequate wages (made worse after 1914 by steep wartime increases in the cost of living). At the same time, urban industrial life was full of benefits, though these could be just as dangerous, from the point of view of social and political stability, as the hardships. There were many encouragements to expect more from life. Acquiring new skills gave many workers a sense of self-respect and confidence, heightening expectations and desires. Living in cities, workers encountered material goods such as they had never seen in villages. Most important, living in cities, they were exposed to new ideas about the social and political order.[nb 2]\\r\\nThe social causes of the Russian Revolution mainly came from centuries of oppression of the lower classes by the Tsarist regime, and Nicholas's failures in World War I. While rural agrarian peasants had been emancipated from serfdom in 1861, they still resented paying redemption payments to the state, and demanded communal tender of the land they worked. The problem was further compounded by the failure of Sergei Witte's land reforms of the early 20th century. Increasing peasant disturbances and sometimes actual revolts occurred, with the goal of securing ownership of the land they worked. Russia consisted mainly of poor farming peasants, with 1.5% of the population owning 25% of the land.[citation needed]\\r\\nThe rapid industrialization of Russia also resulted in urban overcrowding and poor conditions for urban industrial workers (as mentioned above). Between 1890 and 1910, the population of the capital, Saint Petersburg, swelled from 1,033,600 to 1,905,600, with Moscow experiencing similar growth. This created a new 'proletariat' which, due to being crowded together in the cities, was much more likely to protest and go on strike than the peasantry had been in previous times. In one 1904 survey, it was found that an average of sixteen people shared each apartment in Saint Petersburg, with six people per room. There was also no running water, and piles of human waste were a threat to the health of the workers. The poor conditions only aggravated the situation, with the number of strikes and incidents of public disorder rapidly increasing in the years shortly before World War I. Because of late industrialization, Russia's workers were highly concentrated. By 1914, 40% of Russian workers were employed in factories of 1,000+ workers (32% in 1901). 42% worked in 100ÿ1,000 worker enterprises, 18% in 1ÿ100 worker businesses (in the USA, 1914, the figures were 18, 47 and 35 respectively).[7]\\r\\nWorld War I added to the chaos. Conscription swept up the unwilling across Russia. The vast demand for factory production of war supplies and workers caused many more labor riots and strikes. Conscription stripped skilled workers from the cities, who had to be replaced with unskilled peasants, and then, when famine began to hit due to the poor railway system, workers abandoned the cities in droves seeking food. Finally, the soldiers themselves, who suffered from a lack of equipment and protection from the elements, began to turn against the Tsar. This was mainly because, as the war progressed, many of the officers who were loyal to the Tsar were killed, and were replaced by discontented conscripts from the major cities, who had little loyalty to the Tsar.\\r\\nMany sections of the country had reason to be dissatisfied with the existing autocracy. Nicholas II was a deeply conservative ruler and maintained a strict authoritarian system. Individuals and society in general were expected to show self-restraint, devotion to community, deference to the social hierarchy and a sense of duty to the country. Religious faith helped bind all of these tenets together as a source of comfort and reassurance in the face of difficult conditions and as a means of political authority exercised through the clergy. Perhaps more than any other modern monarch, Nicholas II attached his fate and the future of his dynasty to the notion of the ruler as a saintly and infallible father to his people.[nb 3]\\r\\nThis idealized vision of the Romanov monarchy blinded him to the actual state of his country. With a firm belief that his power to rule was granted by Divine Right, Nicholas assumed that the Russian people were devoted to him with unquestioning loyalty. This ironclad belief rendered Nicholas unwilling to allow the progressive reforms that might have alleviated the suffering of the Russian people. Even after the 1905 revolution spurred the Tsar to decree limited civil rights and democratic representation, he worked to limit even these liberties in order to preserve the ultimate authority of the crown.[nb 3]\\r\\nDespite constant oppression, the desire of the people for democratic participation in government decisions was strong. Since the Age of Enlightenment, Russian intellectuals had promoted Enlightenment ideals such as the dignity of the individual and the rectitude of democratic representation. These ideals were championed most vociferously by Russias liberals, although populists, Marxists, and anarchists also claimed to support democratic reforms. A growing opposition movement had begun to challenge the Romanov monarchy openly well before the turmoil of World War I.\\r\\nDissatisfaction with Russian autocracy culminated in the huge national upheaval that followed the Bloody Sunday massacre of January 1905, in which hundreds of unarmed protesters were shot by the Tsar's troops. Workers responded to the massacre with a crippling general strike, forcing Nicholas to put forth the October Manifesto, which established a democratically elected parliament (the State Duma). The Tsar undermined this promise of reform but a year later with Article 87 of the 1906 Fundamental State Laws, and subsequently dismissed the first two Dumas when they proved uncooperative. Unfulfilled hopes of democracy fueled revolutionary ideas and violent outbursts targeted at the monarchy.\\r\\nOne of the Tsars principal rationales for risking war in 1914 was his desire to restore the prestige that Russia had lost amid the debacles of the Russo-Japanese war. Nicholas also sought to foster a greater sense of national unity with a war against a common and ancient enemy. The Russian Empire was an agglomeration of diverse ethnicities that had shown significant signs of disunity in the years before the First World War. Nicholas believed in part that the shared peril and tribulation of a foreign war would mitigate the social unrest over the persistent issues of poverty, inequality, and inhuman working conditions. Instead of restoring Russia's political and military standing, World War I led to the horrifying slaughter of Russian troops and military defeats that undermined both the monarchy and society in general to the point of collapse.\\r\\nThe outbreak of war in August 1914 initially served to quiet the prevalent social and political protests, focusing hostilities against a common external enemy, but this patriotic unity did not last long. As the war dragged on inconclusively, war-weariness gradually took its toll. More important, though, was a deeper fragility: although many ordinary Russians joined anti-German demonstrations in the first few weeks of the war, the most widespread reaction appears to have been skepticism and fatalism. Hostility toward the Kaiser and the desire to defend their land and their lives did not necessarily translate into enthusiasm for the Tsar or the government.[9][10][11]\\r\\nRussia's first major battle of the war was a disaster: in the 1914 Battle of Tannenberg, over 30,000 Russian troops were killed or wounded and 90,000 captured, while Germany suffered just 12,000 casualties. However, Austro-Hungarian forces allied to Germany were driven back deep into the Galicia region by the end of the year. In the autumn of 1915, Nicholas had taken direct command of the army, personally overseeing Russia's main theatre of war and leaving his ambitious but incapable wife Alexandra in charge of the government. Reports of corruption and incompetence in the Imperial government began to emerge, and the growing influence of Grigori Rasputin in the Imperial family was widely resented. In the eyes of Michael Lynch, a revisionist historian (member of the School of Historical Studies at the University of Leicester) who focuses on the role of the people, Rasputin was a \\"fatal disease\\" to the Tsarist regime.\\r\\nIn 1915, things took a critical turn for the worse when Germany shifted its focus of attack to the Eastern front. The superior German army?ÿ better led, better trained and better supplied?ÿ was terrifyingly effective against the ill-equipped Russian forces, driving the Russians out of Galicia, as well as Russian Poland, during the GorliceÿTarn܇w Offensive campaign. By the end of October 1916, Russia had lost between 1,600,000 and 1,800,000 soldiers, with an additional 2,000,000 prisoners of war and 1,000,000 missing, all making up a total of nearly 5,000,000 men.\\r\\nThese staggering losses played a definite role in the mutinies and revolts that began to occur. In 1916, reports of fraternizing with the enemy started to circulate. Soldiers went hungry, and lacked shoes, munitions, and even weapons. Rampant discontent lowered morale, which was further undermined by a series of military defeats.\\r\\nCasualty rates were the most vivid sign of this disaster. Already, by the end of 1914, only five months into the war, around 390,000 Russian men had lost their lives and nearly 1,000,000 were injured. Far sooner than expected, barely trained recruits had to be called up for active duty, a process repeated throughout the war as staggering losses continued to mount. The officer class also saw remarkable changes, especially within the lower echelons, which were quickly filled with soldiers rising up through the ranks. These men, usually of peasant or working-class backgrounds, were to play a large role in the politicization of the troops in 1917.\\r\\nThe huge losses on the battlefields were not limited to men. The army quickly ran short of rifles and ammunition (as well as uniforms and food), and, by mid-1915, men were being sent to the front bearing no arms. It was hoped that they could equip themselves with the arms that they recovered from fallen soldiers, of both sides, on the battlefields. The soldiers did not feel that they were being treated as human beings, or even as valuable soldiers, but rather as raw materials to be squandered for the purposes of the rich and powerful.\\r\\nBy the spring of 1915, the army was in steady retreat, which was not always orderly; desertion, plunder and chaotic flight were not uncommon. By 1916, however, the situation had improved in many respects. Russian troops stopped retreating, and there were even some modest successes in the offensives that were staged that year, albeit at great loss of life. Also, the problem of shortages was largely solved by a major effort to increase domestic production. Nevertheless, by the end of 1916, morale among soldiers was even worse than it had been during the great retreat of 1915. The fortunes of war may have improved, but the fact of the war, still draining away strength and lives from the country and its many individuals and families, remained an oppressive inevitability. The crisis in morale (as was argued by Allan Wildman, a leading historian of the Russian army in war and revolution) \\"was rooted fundamentally in the feeling of utter despair that the slaughter would ever end and that anything resembling victory could be achieved.\\"[12]\\r\\nThe war devastated not only soldiers. By the end of 1915, there were manifold signs that the economy was breaking down under the heightened strain of wartime demand. The main problems were food shortages and rising prices. Inflation dragged incomes down at an alarmingly rapid rate, and shortages made it difficult to buy even what one could afford. These shortages were a problem especially in the capital, St. Petersburg, where distance from supplies and poor transportation networks made matters particularly bad. Shops closed early or entirely for lack of bread, sugar, meat and other provisions, and lines lengthened massively for what remained. It became increasingly difficult both to afford and actually buy food.\\r\\nNot surprisingly, strikes increased steadily from the middle of 1915, and so did crime; but, for the most part, people suffered and endured, scouring the city for food. Working class women in St. Petersburg reportedly spent about forty hours a week in food lines, begging, turning to prostitution or crime, tearing down wooden fences to keep stoves heated for warmth, grumbling about the rich, and wondering when and how this would all come to an end.\\r\\nGovernment officials responsible for public order worried about how long people's patience would last. A report by the St. Petersburg branch of the security police, the Okhrana, in October 1916, warned bluntly of \\"the possibility in the near future of riots by the lower classes of the empire enraged by the burdens of daily existence.\\"[13]\\r\\nNicholas was blamed for all of these crises, and what little support he had left began to crumble. As discontent grew, the State Duma issued a warning to Nicholas in November 1916. It stated that, inevitably, a terrible disaster would grip the country unless a constitutional form of government was put in place. Nicholas ignored these warnings and Russia's Tsarist regime collapsed a few months later during the February Revolution of 1917. One year later, the Tsar and his entire family were executed.\\r\\nAt the beginning of February, Petrograd workers began several strikes and demonstrations.[citation needed] On 7 March [O.S. 22 February], workers at Putilov, Petrograd's largest industrial plant, announced a strike.[14]\\r\\nThe next day, a series of meetings and rallies were held for International Women's Day, which gradually turned into economic and political gatherings. Demonstrations were organised to demand bread, and these were supported by the industrial working force who considered them a reason for continuing the strikes. The women workers marched to nearby factories bringing out over 50,000 workers on strike.[15] By 10 March [O.S. 25 February], virtually every industrial enterprise in Petrograd had been shut down, together with many commercial and service enterprises. Students, white-collar workers and teachers joined the workers in the streets and at public meetings.[citation needed]\\r\\nTo quell the riots, the Tsar looked to the army. At least 180,000 troops were available in the capital, but most were either untrained or injured. Historian Ian Beckett suggests around 12,000 could be regarded as reliable, but even these proved reluctant to move in on the crowd, since it included so many women. It was for this reason that when, on 11 March [O.S. 26 February], the Tsar ordered the army to suppress the rioting by force, troops began to mutiny.[16] Although few actively joined the rioting, many officers were either shot or went into hiding; the ability of the garrison to hold back the protests was all but nullified, symbols of the Tsarist regime were rapidly torn down around the city, and governmental authority in the capital collapsed ÿ not helped by the fact that Nicholas had prorogued the Duma that morning, leaving it with no legal authority to act. The response of the Duma, urged on by the liberal bloc, was to establish a Temporary Committee to restore law and order; meanwhile, the socialist parties establish the Petrograd Soviet to represent workers and soldiers. The remaining loyal units switched allegiance the next day.[17]\\r\\nThe Tsar directed the royal train back towards Petrograd, which was stopped 14 March [O.S. 1 March],[16] by a group of revolutionaries at Malaya Vishera. When the Tsar finally arrived at in Pskov, the Army Chief Nikolai Ruzsky, and the Duma deputees Guchkov and Vasily Shulgin suggested in unison that he abdicate the throne. He did so on 15 March [O.S. 2 March], on behalf of himself, and then, having taken advice, on behalf of his son, the Tsarevich.[16] Nicholas nominated his brother, the Grand Duke Michael Alexandrovich, to succeed him. But the Grand Duke realised that he would have little support as ruler, so he declined the crown on 16 March [O.S. 3 March],[16] stating that he would take it only if that was the consensus of democratic action.[18] Six days later, Nicholas, no longer Tsar and addressed with contempt by the sentries as \\"Nicholas Romanov\\", was reunited with his family at the Alexander Palace at Tsarskoye Selo.[19] He was placed under house arrest with his family by the Provisional Government.\\r\\nThe immediate effect of the February Revolution was a widespread atmosphere of elation and excitement in Petrograd.[20] On 16 March [O.S. 3 March], a provisional government was announced. The center-left was well represented, and the government was initially chaired by a liberal aristocrat, Prince Georgy Yevgenievich Lvov, a member of the Constitutional Democratic party (KD).[21] The socialists had formed their rival body, the Petrograd Soviet (or workers' council) four days earlier. The Petrograd Soviet and the Provisional Government competed for power over Russia.\\r\\n\\r\\nThe effective power of the Provisional Government was challenged by the authority of an institution that claimed to represent the will of workers and soldiers and could, in fact, mobilize and control these groups during the early months of the revolution?ÿ the Petrograd Soviet [Council] of Workers' Deputies. The model for the soviet were workers' councils that had been established in scores of Russian cities during the 1905 Revolution. In February 1917, striking workers elected deputies to represent them and socialist activists began organizing a citywide council to unite these deputies with representatives of the socialist parties. On 27 February, socialist Duma deputies, mainly Mensheviks and Socialist Revolutionaries, took the lead in organizing a citywide council. The Petrograd Soviet met in the Tauride Palace, the same building where the new government was taking shape.\\r\\nThe leaders of the Petrograd Soviet believed that they represented particular classes of the population, not the whole nation. They also believed Russia was not ready for socialism. So they saw their role as limited to pressuring hesitant \\"bourgeoisie\\" to rule and to introduce extensive democratic reforms in Russia (the replacement of the monarchy by a republic, guaranteed civil rights, a democratic police and army, abolition of religious and ethnic discrimination, preparation of elections to a constituent assembly, and so on).[22] They met in the same building as the emerging Provisional Government not to compete with the Duma Committee for state power but to best exert pressure on the new government, to act, in other words, as a popular democratic lobby.\\r\\nThe relationship between these two major powers was complex from the beginning and would shape the politics of 1917. The representatives of the Provisional Government agreed to \\"take into account the opinions of the Soviet of Workers' Deputies\\", though they were also determined to prevent \\"interference in the actions of the government\\", which would create \\"an unacceptable situation of dual power.\\"[23] In fact, this was precisely what was being created, though this \\"dual power\\" (dvoevlastie) was the result less of the actions or attitudes of the leaders of these two institutions than of actions outside their control, especially the ongoing social movement taking place on the streets of Russias cities, in factories and shops, in barracks and in the trenches, and in the villages.\\r\\nA series of political crises?ÿ see the chronology below?ÿ in the relationship between population and government and between the Provisional Government and the soviets (which developed into a nationwide movement with a national leadership, The All-Russian Central Executive Committee of Soviets (VTsIK)) undermined the authority of the Provisional Government but also of the moderate socialist leaders of the Soviet. Although the Soviet leadership initially refused to participate in the \\"bourgeois\\" Provisional Government, Alexander Kerensky, a young and popular lawyer and a member of the Socialist Revolutionary Party (SRP), agreed to join the new cabinet, and became an increasingly central figure in the government, eventually taking leadership of the Provisional Government. As minister of war and later Prime Minister, Kerensky promoted freedom of speech, released thousands of political prisoners, did his very best to continue the war effort and even organised another offensive (which, however, was no more successful than its predecessors). Nevertheless, Kerensky still faced several great challenges, highlighted by the soldiers, urban workers and peasants, who claimed that they had gained nothing by the revolution:\\r\\nThe political group that proved most troublesome for Kerensky, and would eventually overthrow him, was the Bolshevik Party, led by Vladimir Lenin. Lenin had been living in exile in neutral Switzerland and, due to democratization of politics after the February Revolution, which legalized formerly banned political parties, he perceived the opportunity for his Marxist revolution. Although return to Russia had become a possibility, the war made it logistically difficult. Eventually, German officials arranged for Lenin to pass through their territory, hoping that his activities would weaken Russia or even?ÿ if the Bolsheviks came to power?ÿ lead to Russia's withdrawal from the war. Lenin and his associates, however, had to agree to travel to Russia in a sealed train: Germany would not take the chance that he would foment revolution in Germany. After passing through the front, he arrived in Petrograd in April 1917.\\r\\nWith Lenin's arrival, the popularity of the Bolsheviks increased steadily. Over the course of the spring, public dissatisfaction with the Provisional Government and the war, in particular among workers, soldiers and peasants, pushed these groups to radical parties. Despite growing support for the Bolsheviks, buoyed by maxims that called most famously for \\"all power to the Soviets,\\" the party held very little real power in the moderate-dominated Petrograd Soviet. In fact, historians such as Sheila Fitzpatrick have asserted that Lenin's exhortations for the Soviet Council to take power were intended to arouse indignation both with the Provisional Government, whose policies were viewed as conservative, and the Soviet itself, which was viewed as subservient to the conservative government. By some historians' accounts, Lenin and his followers were unprepared for how their groundswell of support, especially among influential worker and soldier groups, would translate into real power in the summer of 1917.\\r\\nOn 18 June, the Provisional Government launched an attack against Germany that failed miserably. Soon after, the government ordered soldiers to go to the front, reneging on a promise. The soldiers refused to follow the new orders. The arrival of radical Kronstadt sailors?ÿ who had tried and executed many officers, including one admiral?ÿ further fueled the growing revolutionary atmosphere. The sailors and soldiers, along with Petrograd workers, took to the streets in violent protest, calling for \\"all power to the Soviets.\\" The revolt, however, was disowned by Lenin[24] and the Bolshevik leaders and dissipated within a few days. In the aftermath, Lenin fled to Finland under threat of arrest while Trotsky, among other prominent Bolsheviks, was arrested. The July Days confirmed the popularity of the anti-war, radical Bolsheviks, but their unpreparedness at the moment of revolt was an embarrassing gaffe that lost them support among their main constituent groups: soldiers and workers.\\r\\nThe Bolshevik failure in the July Days proved temporary. The Bolsheviks had undergone a spectacular growth in membership. Whereas, in February 1917, the Bolsheviks were limited to only 24,000 members, by September 1917 there were 200,000 members of the Bolshevik faction.[25] Previously, the Bolsheviks had been in the minority in the two leading cities of RussiaSt. Petersburg and Moscow behind the Mensheviks and the Socialist Revolutionaries, by September the Bolsheviks were in the majority in both cities.[26] Furthermore, the Bolshevik-controlled Moscow Regional Bureau of the Party also controlled the Party organizations of the thirteen (13) provinces around Moscow. These thirteen provinces held 37% of Russia's population and 20% of the membership of the Bolshevik faction.[26]\\r\\nIn August, poor or misleading communication led General Lavr Kornilov, the recently appointed Supreme Commander of Russian military forces, to believe that the Petrograd government had already been captured by radicals, or was in serious danger thereof. In response, he ordered troops to Petrograd to pacify the city. To secure his position, Kerensky had to ask for Bolshevik assistance. He also sought help from the Petrograd Soviet, which called upon armed Red Guards to \\"defend the revolution\\". The Kornilov Affair failed largely due to the efforts of the Bolsheviks, whose influence over railroad and telegraph workers proved vital in stopping the movement of troops. With his coup failing, Kornilov surrendered and was relieved of his position. The Bolsheviks' role in stopping the attempted coup further strengthened their position.\\r\\nIn early September, the Petrograd Soviet freed all jailed Bolsheviks and Trotsky became chairman of the Petrograd Soviet. Growing numbers of socialists and lower-class Russians viewed the government less and less as a force in support of their needs and interests. The Bolsheviks benefited as the only major organized opposition party that had refused to compromise with the Provisional Government, and they benefited from growing frustration and even disgust with other parties, such as the Mensheviks and Socialist Revolutionaries, who stubbornly refused to break with the idea of national unity across all classes.\\r\\nIn Finland, Lenin had worked on his book State and Revolution[27] and continued to lead his party, writing newspaper articles and policy decrees. By October, he returned to Petrograd (St. Petersburg), aware that the increasingly radical city presented him no legal danger and a second opportunity for revolution. Recognising the strength of the Bolsheviks, Lenin began pressing for the immediate overthrow of the Kerensky government by the Bolsheviks. Lenin was of the opinion that taking power should occur in both St. Petersburg and Moscow simultaneously, parenthetically stating that it made no difference which city rose up first, but expressing his opinion that Moscow may well rise up first.[28] The Bolshevik Central Committee drafted a resolution, calling for the dissolution of the Provisional Government in favor of the Petrograd Soviet. The resolution was passed 10ÿ2 (Lev Kamenev and Grigory Zinoviev prominently dissenting) and the October Revolution began.\\r\\nThe October Revolution was led by Vladimir Lenin and was based upon Lenin's writing on the ideas of Karl Marx, a political ideology often known as MarxismÿLeninism. It marked the beginning of the spread of communism in the 20th century. It was far less sporadic than the revolution of February and came about as the result of deliberate planning and coordinated activity to that end.\\r\\nThough Lenin was the leader of the Bolshevik Party, it has been argued that since Lenin was not present during the actual takeover of the Winter Palace, it was really Trotsky's organization and direction that led the revolution, merely spurred by the motivation Lenin instigated within his party.[29] Critics on the Right have long argued that the financial and logistical assistance of German intelligence via their key agent, Alexander Parvus was a key component as well, though historians are divided, since there is little evidence supporting that claim.\\r\\nOn 7 November 1917, Bolshevik leader Vladimir Lenin led his leftist revolutionaries in a revolt against the ineffective Provisional Government (Russia was still using the Julian calendar at the time, so period references show a 25 October date). The October revolution ended the phase of the revolution instigated in February, replacing Russia's short-lived provisional parliamentary government with government by soviets, local councils elected by bodies of workers and peasants. Liberal and monarchist forces, loosely organized into the White Army, immediately went to war against the Bolsheviks' Red Army, in a series of battles that would become known as the Russian Civil War.\\r\\nSoviet membership was initially freely elected, but many members of the Socialist Revolutionary Party, anarchists, and other leftists created opposition to the Bolsheviks through the soviets themselves. When it became clear that the Bolsheviks had little support outside of the industrialized areas of Saint Petersburg and Moscow, they simply barred non-Bolsheviks from membership in the soviets.[citation needed] Not surprisingly, this caused mass domestic tension with many individuals who called for another series of political reform, revolting, and calling for \\"a third Russian revolution,\\" a movement that received a significant amount of support. The most notable instances of this anti-Bolshevik mentality were expressed in the Tambov rebellion, 1919ÿ1921, and the Kronstadt rebellion in March 1921. These movements, which made a wide range of demands and lacked effective coordination, were eventually defeated along with the White Army during the Civil War.\\r\\nThe Russian Civil War, which broke out in 1918 shortly after the revolution, brought death and suffering to millions of people regardless of their political orientation. The war was fought mainly between the Red Army (\\"Reds\\"), consisting of the uprising majority led by the Bolshevik minority, and the \\"Whites\\"?ÿ army officers and cossacks, the \\"bourgeoisie\\", and political groups ranging from the far Right to the Socialist Revolutionaries who opposed the drastic restructuring championed by the Bolsheviks following the collapse of the Provisional Government to the soviets (under clear Bolshevik dominance).[30][31] The Whites had backing from nations such as Great Britain, France, USA and Japan, while the Reds possessed internal support which proved to be much more effective. Though the Allied nations, using external interference, provided substantial military aid to the loosely knit anti-Bolshevik forces, they were ultimately defeated.[30]\\r\\nThe Bolsheviks firstly assumed power in Petrograd, expanding their rule outwards. They eventually reached the Easterly Siberian Russian coast in Vladivostok, 4 years after the war began, an occupation that is believed to have ended all significant military campaigns in the nation. Less than one year later the last area controlled by the White Army, the Ayano-Maysky District, directly to the north of the Krai containing Vladivostok, was given up when General Anatoly Pepelyayev capitulated in 1923.\\r\\nSeveral revolts were initiated against the Bolsheviks and their army near the end of the war, notably the Kronstadt Rebellion. This was a naval mutiny engineered by Soviet Baltic sailors, former Red Army soldiers, and the people of Kronstadt. This armed uprising was fought against the antagonizing Bolshevik economic policies that farmers were subjected to, including seizures of grain crops by the Communists.[32] This all amounted to large-scale discontent. When delegates representing the Kronstadt sailors arrived at Petrograd for negotiations, they raised 15 demands primarily pertaining to the Russian right to freedom.[33] The Government firmly denounced the rebellions and labelled the requests as a reminder of the Social Revolutionaries, a political party that was popular among Soviets before Lenin, but refused to cooperate with the Bolshevik Army. The Government then responded with an armed suppression of these revolts and suffered 10 thousand casualties before entering the city of Kronstadt.[34] This ended the rebellions fairly quickly, causing many of the rebels to flee to political exile.[35]\\r\\nDuring the Civil War, Nestor Makhno led a Ukrainian anarchist movement, the Black Army allied to the Bolsheviks thrice, one of the powers ending the alliance each time. However, a Bolshevik force under Mikhail Frunze destroyed the Makhnovist movement, when the Makhnovists refused to merge into the Red Army. In addition, the so-called \\"Green Army\\" (peasants defending their property against the opposing forces) played a secondary role in the war, mainly in the Ukraine.\\r\\nThe Bolsheviks executed the tsar and his family on 16 July 1918.[36] In early March, the Provisional Government placed Nicholas and his family under house arrest in the Alexander Palace at Tsarskoye Selo, 24 kilometres (15?mi) south of Petrograd. In August 1917 the Kerensky government evacuated the Romanovs to Tobolsk in the Urals, to protect them from the rising tide of revolution during the Red Terror. After the Bolsheviks came to power in October 1917, the conditions of their imprisonment grew stricter and talk of putting Nicholas on trial increased. As the counter revolutionary White movement gathered force, leading to full-scale civil war by the summer, the Romanovs were moved during April and May 1918 to Yekaterinburg, a militant Bolshevik stronghold.\\r\\nDuring the early morning of 16 July, Nicholas, Alexandra, their children, their physician, and several servants were taken into the basement and shot. According to Edvard Radzinsky and Dmitrii Volkogonov, the order came directly from Lenin and Sverdlov in Moscow. That the order came from the top has long been believed, although there is a lack of hard evidence. The execution may have been carried out on the initiative of local Bolshevik officials, or it may have been an option pre-approved in Moscow should White troops approach Yekaterinburg. Radzinsky noted that Lenin's bodyguard personally delivered the telegram ordering the execution and that he was ordered to destroy the evidence.[37][38]\\r\\nLeon Trotsky said that the goal of socialism in Russia would not be realized without the success of the world revolution. Indeed, a revolutionary wave caused by the Russian Revolution lasted until 1923. Despite initial hopes for success in the German Revolution of 1918ÿ19, in the short-lived Hungarian Soviet Republic and others like it, no other Marxist movement at the time succeeded in keeping power in its hands.\\r\\nThis issue is subject to conflicting views on the communist history by various Marxist groups and parties. Joseph Stalin later rejected this idea, stating that socialism was possible in one country.\\r\\nThe confusion regarding Stalin's position on the issue stems from the fact that he, after Lenin's death in 1924, successfully used Lenin's argument?ÿ the argument that socialism's success needs the workers of other countries in order to happen?ÿ to defeat his competitors within the party by accusing them of betraying Lenin and, therefore, the ideals of the October Revolution.\\r\\nFew events in historical research have been as conditioned by political influences as the October Revolution. The historiography of the Revolution generally divides into three camps: the Soviet-Marxist view, the Western-Totalitarian view, and the Revisionist view.[39] Since the fall of Communism in Russia in 1991, the Western-Totalitarian view has again become dominant and the Soviet-Marxist view has practically vanished.[40]\\r\\nLenin's biographer Robert Service, says he, \\"laid the foundations of dictatorship and lawlessness. Lenin had consolidated the principle of state penetration of the whole society, its economy and its culture. Lenin had practised terror and advocated revolutionary amoralism.\\"[41]\\r\\nDates are correct for the Julian calendar, which was used in Russia until 1918. It was twelve days behind the Gregorian calendar during the 19th century and thirteen days behind it during the 20th century.\\r\\nGeorge Orwell's classic novella Animal Farm is an allegory of the Russian Revolution and its aftermath. It describes the dictator Stalin as a big Berkshire boar named, \\"Napoleon.\\" Trotsky is represented by a pig called Snowball who is a brilliant talker and makes magnificent speeches. However, Napoleon overthrows Snowball as Stalin overthrew Trotsky and Napoleon takes over the farm the animals live on. Napoleon becomes a tyrant and uses force and propaganda to oppress the animals.[42]\\r\\nThe Russian Revolution has been portrayed in or served as backdrop for many films. Among them, in order of release date:","input":"What russian leader was overthrown in the revolution of 1917?"},{"output":"Herbert Paul Brooks Jr.","context":"Herbert Paul Brooks Jr. (August 5, 1937 ÿ August 11, 2003) was an American ice hockey player and coach. His most notable achievement came in 1980 as head coach of the gold medal-winning U.S. Olympic hockey team at Lake Placid. At the games, Brooks' US team upset the heavily favored Soviet team in a match that came to be known as the 'Miracle on Ice'. Brooks would go on to coach multiple NHL teams, as well as the French hockey team at the 1998 Winter Olympics, and ultimately returned to coach the US men's team to a silver medal at the 2002 games in Salt Lake City. Brooks was killed in a 2003 car accident. At the time of his death, Brooks was the Pittsburgh Penguins' director of player personnel.\\r\\n\\r\\n\\r\\nHerb Brooks was born in Saint Paul, Minnesota, to Pauline and Herbert Brooks Sr. He attended Johnson High School, where his team won the 1955 state hockey championship.[1]\\r\\nBrooks continued his hockey career with the University of Minnesota Gophers from 1955 to 1959.[2] He was a member of the 1960 Olympic team, only to become the last cut the week before the Games started. Three weeks later, Brooks sat at home with his father and watched the team he almost made win gold. Afterwards, Brooks \\"went up to the coach Jack Riley and said, 'Well, you must have made the right decisionyou won.'\\"; this humbling moment served as motivation for an already self-driven person.[3]\\r\\nFrom 1960 to 1970, Brooks set a record by playing on a total of eight US National and Olympic teams, including the 1964 and 1968 Olympic squads.[4]\\r\\nAfter retiring as a player, he became a coach, notably leading his alma mater, the Minnesota Golden Gophers, to three NCAA championship titles in 1974, 1976, and 1979. Brooks finished his collegiate coaching with a record of 175 wins, 101 losses and 20 ties.\\r\\nSoon after Minnesota won their third college championship, he was hired to coach the Olympic team. Hand-picking his team, he named several of his Minnesota players to the team as well as several from their rival, Boston University. To compete with the Soviet Union team specifically, Herb Brooks developed a hybrid of American and Canadian style and the faster European style, which emphasized creativity and teamwork, a difficult thing to do with a tough rivalry between the University of Minnesota and Boston University. He also stressed peak conditioning, believing that one of the reasons the Soviet team had dominated international competition was that many of their opponents were exhausted by the third period.\\r\\nAfter his Olympic gold medal win, Brooks moved to Switzerland for a year to coach HC Davos in the National League A. From 1981 to 1985, he coached in the National Hockey League for the New York Rangers, where he became the first American-born coach in Rangers' team history to win 100 games. After a brief stop at then-NCAA Division III St. Cloud State University, he returned to the NHL to coach the Minnesota North Stars (from 1987 to 1988), New Jersey Devils (1992ÿ93), and Pittsburgh Penguins (1999ÿ2000). He was a long-time scout for the Penguins from the mid-1990s, and held the role of Director of Player Personnel from 2002 to the day of his death. His hiring by the North Stars in 1987 would be the last time a college coach was selected to coach an NHL team until North Dakota coach Dave Hakstol was tapped to coach the Philadelphia Flyers in May 2015.\\r\\nBrooks also coached two more Olympic team squads: Team France at the 1998 in Nagano, and the U.S. hockey team again at the 2002 Winter Olympics in Salt Lake City. The 2002 team defeated the Russians in the semi-finals en route to a silver, losing in the gold medal game to Canada. The U.S. win over Russia came exactly 22 years to the day after the famous 'Miracle on Ice' game.[5][6]\\r\\nBrooks was inducted into the United States Hockey Hall of Fame in 1990,[7] and the International Hockey Hall of Fame in 1999. He was honored posthumously with the Wayne Gretzky International Award in 2004, and inducted into the Hockey Hall of Fame.[7][8]\\r\\nAt the age of 66, Brooks died in a single-car accident on the afternoon of August 11, 2003, near Forest Lake, Minnesota, on Interstate 35.[9] It is believed that he fell asleep behind the wheel before the accident after driving all night, and neither drugs nor alcohol was responsible. Brooks was not wearing his seatbelt at the time of the crash, and according to the Minnesota State Patrol it is likely he would have survived the crash if he had been.[10]\\r\\nDisney released a film about the 1980 Olympic team in 2004 called Miracle featuring Kurt Russell playing the part of Brooks. (Karl Malden had previously played Brooks in a 1981 television film called Miracle on Ice). Brooks served as a consultant during principal photography, which was completed shortly before his death. At the end of the movie there is a dedication to Brooks. It states, \\"He never saw it. He lived it.\\"\\r\\nUpon the 25th anniversary of the Miracle on Ice, the Olympic ice arena in Lake Placid, New York, where the United States won the gold medal, was renamed Herb Brooks Arena. A statue of Brooks depicting his reaction to the victory in the 'Miracle' game was erected at the entrance to the RiverCentre in Saint Paul, Minnesota, in 2003.\\r\\nThe Herb Brooks Award is awarded at the conclusion of the Minnesota State High School League's state hockey tournament to \\"the most qualified hockey player in the state tournament who strongly represents the values, characteristics, and traits that defined Herb Brooks.\\"[11]\\r\\nThe Herb Brooks Training Center is located at Blaine, Minnesota.\\r\\nThe National Hockey Center at St. Cloud State University in Minnesota was renamed for Brooks in April 2013.[12]\\r\\nIn 2006, Brooks was posthumously inducted into the Hockey Hall of Fame in the Builders' category. The inscription reads: \\"A man of passion and dedication, Herb Brooks inspired a generation of Americans to pursue any and all dreams.\\"[7]\\r\\nBrooks was married to his wife Patti since 1965, and they had two children, Danny and Kelly.[13]\\r\\nBrooks' original expressions were known by his players as \\"Brooksisms.\\" According to Olympians John Harrington, Dave Silk, and Mike Eruzione, these are a few.[14]\\r\\n??????National champion?? ??????Postseason invitational champion??\\r\\n??????Conference regular season champion?? ??????Conference regular season and conference tournament champion\\r\\n??????Division regular season champion ??????Division regular season and conference tournament champion\\r\\n??????Conference tournament champion\\r\\n?Minnesota played jointly in the Big Ten and WCHA from 1959 to 1981\\r\\nNote: GC = Games coached, W = Wins, L = Losses, T = Ties, Pts = Points, Pct = Winning percentage\\r\\nNote: GC = Games coached, W = Wins, L = Losses, T = Ties, OL = Overtime loss, Pts = Points, Pct = Winning percentage","input":"Who was the coach of the 1980 usa olympic hockey team?"},{"output":"Dfc, Dwc, Dsc, Dfd and Dwd in the K?ppen climate classification scheme","context":"Taiga (/?ta??/; Russian: ?, IPA:?[t?j?a]; from Turkic[1]), also known as boreal forest or snow forest, is a biome characterized by coniferous forests consisting mostly of pines, spruces and larches.\\r\\nThe taiga is the world's largest biome apart from the oceans. In North America it covers most of inland Canada and Alaska as well as parts of the extreme northern continental United States (northern Minnesota through the Upper Peninsula of Michigan to Upstate New York and northern New England), where it is known as the Northwoods or \\"North woods\\".[2] In Eurasia, it covers most of Sweden, Finland, much of Norway, some of the Scottish Highlands, some lowland/coastal areas of Iceland, much of Russia from Karelia in the west to the Pacific Ocean (including much of Siberia), and areas of northern Kazakhstan, northern Mongolia, and northern Japan (on the island of Hokkaid). However, the main tree species, the length of the growing season and summer temperatures vary. For example, the taiga of North America mostly consists of spruces; Scandinavian and Finnish taiga consists of a mix of spruce, pines and birch; Russian taiga has spruces, pines and larches depending on the region, while the Eastern Siberian taiga is a vast larch forest.\\r\\nA different use of the term taiga is often encountered in the English language, with \\"boreal forest\\" used in the United States and Canada to refer to only the more southerly part of the biome, while \\"taiga\\" is used to describe the more barren areas of the northernmost part of the biome approaching the tree line and the tundra biome. Hoffman (1958) discusses the origin of this differential use in North America and why it is an inappropriate differentiation of the Russian term. Although at high elevations taiga grades into alpine tundra through Krummholz, it is not exclusively an alpine biome; and unlike subalpine forest, much of taiga is lowlands.\\r\\n\\r\\n\\r\\nTaiga is the world's largest land biome, making up 29% of the world's forest cover.[3] The largest areas are located in Russia and Canada. The taiga is the terrestrial biome with the lowest annual average temperatures after the tundra and permanent ice caps. Extreme winter minimums in the northern taiga are typically lower than those of the tundra. The lowest reliably recorded temperatures in the Northern Hemisphere were recorded in the taiga of northeastern Russia. The taiga or boreal forest has a subarctic climate with very large temperature range between seasons, but the long and cold winter is the dominant feature. This climate is classified as Dfc, Dwc, Dsc, Dfd and Dwd in the K?ppen climate classification scheme,[4] meaning that the short summer (24?h average 10?C (50?F) or more) lasts 1ÿ3 months and always less than 4 months. In Siberian taiga the average temperature of the coldest month is between ?6?C (21?F) and ?50?C (?58?F).[5] There are also some much smaller areas grading towards the oceanic Cfc climate with milder winters, whilst the extreme south and (in Eurasia) west of the taiga reaches into humid continental climates (Dfb, Dwb) with longer summers. The mean annual temperature generally varies from -5?C to 5?C (23?F to 41?F),[6] but there are taiga areas in eastern Siberia and interior Alaska-Yukon where the mean annual reaches down to -10?C (14?F).[7][8] According to some sources, the boreal forest grades into a temperate mixed forest when mean annual temperature reaches about 3?C (37?F).[9] Discontinuous permafrost is found in areas with mean annual temperature below 0?C, whilst in the Dfd and Dwd climate zones continuous permafrost occurs and restricts growth to very shallow-rooted trees like Siberian larch. The winters, with average temperatures below freezing, last five to seven months. Temperatures vary from ?54?C to 30?C (-65?F to 86?F) throughout the whole year. The summers, while short, are generally warm and humid. In much of the taiga, -20?C (-4?F) would be a typical winter day temperature and 18?C (64?F) an average summer day.\\r\\nThe growing season, when the vegetation in the taiga comes alive, is usually slightly longer than the climatic definition of summer as the plants of the boreal biome have a lower threshold to trigger growth. In Canada, Scandinavia and Finland, the growing season is often estimated by using the period of the year when the 24-hour average temperature is +5?C (41?F) or more.[10] For the Taiga Plains in Canada, growing season varies from 80 to 150 days, and in the Taiga Shield from 100 to 140 days.[11] Some sources claim 130 days growing season as typical for the taiga.[12] Other sources mention that 50ÿ100 frost-free days are characteristic.[13] Data for locations in southwest Yukon gives 80ÿ120 frost-free days.[14] The closed canopy boreal forest in Kenozersky National Park near Plesetsk, Arkhangelsk Province, Russia, on average has 108 frost-free days.[15] The longest growing season is found in the smaller areas with oceanic influences; in coastal areas of Scandinavia and Finland, the growing season of the closed boreal forest can be 145ÿ180 days.[16] The shortest growing season is found at the northern taigaÿtundra ecotone, where the northern taiga forest no longer can grow and the tundra dominates the landscape when the growing season is down to 50ÿ70 days,[17][18] and the 24-hr average of the warmest month of the year usually is 10?C (50?F) or less.[19] High latitudes mean that the sun does not rise far above the horizon, and less solar energy is received than further south. But the high latitude also ensures very long summer days, as the sun stays above the horizon nearly 20 hours each day, with only around 6 hours of daylight occurring in the dark winters, depending on latitude. The areas of the taiga inside the Arctic Circle have midnight sun in mid-summer and polar night in mid-winter.\\r\\nThe taiga experiences relatively low precipitation throughout the year (generally 200ÿ750?mm annually, 1,000?mm in some areas), primarily as rain during the summer months, but also as fog and snow. This fog, especially predominant in low-lying areas during and after the thawing of frozen Arctic seas, means that sunshine is not abundant in the taiga even during the long summer days. As evaporation is consequently low for most of the year, precipitation exceeds evaporation, and is sufficient to sustain the dense vegetation growth. Snow may remain on the ground for as long as nine months in the northernmost extensions of the taiga ecozone.[22]\\r\\nIn general, taiga grows to the south of the 10?C July isotherm, but occasionally as far north as the 9?C (48?F) July isotherm.[23] Rich in spruces, Scots pines in the western Siberian plain, the taiga is dominated by larch in Eastern Siberia, before returning to its original floristic richness on the Pacific shores. Two deciduous trees mingle throughout southern Siberia: birch and Populus tremula.[5]\\r\\nThe southern limit is more variable, depending on rainfall; taiga may be replaced by forest steppe south of the 15?C (59?F) July isotherm where rainfall is very low, but more typically extends south to the 18?C (64?F) July isotherm, and locally where rainfall is higher (notably in eastern Siberia and adjacent Outer Manchuria) south to the 20?C (68?F) July isotherm. In these warmer areas the taiga has higher species diversity, with more warmth-loving species such as Korean pine, Jezo spruce, and Manchurian fir, and merges gradually into mixed temperate forest or, more locally (on the Pacific Ocean coasts of North America and Asia), into coniferous temperate rainforests where oak and hornbeam appear and join the conifers, birch and Populus tremula.\\r\\nThe area currently classified as taiga in Europe and North America (except Alaska) was recently glaciated. As the glaciers receded they left depressions in the topography that have since filled with water, creating lakes and bogs (especially muskeg soil) found throughout the taiga.\\r\\nIn Sweden the taiga is associated with the Norrland terrain.[24]\\r\\nTaiga soil tends to be young and poor in nutrients. It lacks the deep, organically enriched profile present in temperate deciduous forests.[25] The thinness of the soil is due largely to the cold, which hinders the development of soil and the ease with which plants can use its nutrients.[25] Fallen leaves and moss can remain on the forest floor for a long time in the cool, moist climate, which limits their organic contribution to the soil; acids from evergreen needles further leach the soil, creating spodosol, also known as podzol.[26] Since the soil is acidic due to the falling pine needles, the forest floor has only lichens and some mosses growing on it. In clearings in the forest and in areas with more boreal deciduous trees, there are more herbs and berries growing. Diversity of soil organisms in the boreal forest is high, comparable to the tropical rainforest.[27]\\r\\nSince North America and Asia used to be connected by the Bering land bridge, a number of animal and plant species (more animals than plants) were able to colonize both continents and are distributed throughout the taiga biome (see Circumboreal Region). Others differ regionally, typically with each genus having several distinct species, each occupying different regions of the taiga. Taigas also have some small-leaved deciduous trees like birch, alder, willow, and poplar; mostly in areas escaping the most extreme winter cold. However, the Dahurian larch tolerates the coldest winters in the Northern Hemisphere in eastern Siberia. The very southernmost parts of the taiga may have trees such as oak, maple, elm and lime scattered among the conifers, and there is usually a gradual transition into a temperate mixed forest, such as the eastern forest-boreal transition of eastern Canada. In the interior of the continents with the driest climate, the boreal forests might grade into temperate grassland.\\r\\nThere are two major types of taiga. The southern part is the closed canopy forest, consisting of many closely spaced trees with mossy ground cover. In clearings in the forest, shrubs and wildflowers are common, such as the fireweed. The other type is the lichen woodland or sparse taiga, with trees that are farther-spaced and lichen ground cover; the latter is common in the northernmost taiga.[28] In the northernmost taiga the forest cover is not only more sparse, but often stunted in growth form; moreover, ice pruned asymmetric black spruce (in North America) are often seen, with diminished foliage on the windward side.[29] In Canada, Scandinavia and Finland, the boreal forest is usually divided into three subzones: The high boreal (north boreal) or taiga zone; the middle boreal (closed forest); and the southern boreal, a closed canopy boreal forest with some scattered temperate deciduous trees among the conifers,[30] such as maple, elm and oak. This southern boreal forest experiences the longest and warmest growing season of the biome, and in some regions (including Scandinavia, Finland and western Russia) this subzone is commonly used for agricultural purposes. The boreal forest is home to many types of berries; some are confined to the southern and middle closed boreal forest (such as wild strawberry and partridgeberry); others grow in most areas of the taiga (such as cranberry and cloudberry), and some can grow in both the taiga and the low arctic (southern part of) tundra (such as bilberry, bunchberry and lingonberry).\\r\\nThe forests of the taiga are largely coniferous, dominated by larch, spruce, fir and pine. The woodland mix varies according to geography and climate so for example the Eastern Canadian forests ecoregion of the higher elevations of the Laurentian Mountains and the northern Appalachian Mountains in Canada is dominated by balsam fir Abies balsamea, while further north the Eastern Canadian Shield taiga of northern Quebec and Labrador is notably black spruce Picea mariana and tamarack larch Larix laricina.\\r\\nEvergreen species in the taiga (spruce, fir, and pine) have a number of adaptations specifically for survival in harsh taiga winters, although larch, the most cold-tolerant of all trees,[citation needed] is deciduous. Taiga trees tend to have shallow roots to take advantage of the thin soils, while many of them seasonally alter their biochemistry to make them more resistant to freezing, called \\"hardening\\".[31] The narrow conical shape of northern conifers, and their downward-drooping limbs, also help them shed snow.[31]\\r\\nBecause the sun is low in the horizon for most of the year, it is difficult for plants to generate energy from photosynthesis. Pine, spruce and fir do not lose their leaves seasonally and are able to photosynthesize with their older leaves in late winter and spring when light is good but temperatures are still too low for new growth to commence. The adaptation of evergreen needles limits the water lost due to transpiration and their dark green color increases their absorption of sunlight. Although precipitation is not a limiting factor, the ground freezes during the winter months and plant roots are unable to absorb water, so desiccation can be a severe problem in late winter for evergreens.\\r\\nAlthough the taiga is dominated by coniferous forests, some broadleaf trees also occur, notably birch, aspen, willow, and rowan. Many smaller herbaceous plants, such as ferns and occasionally ramps grow closer to the ground. Periodic stand-replacing wildfires (with return times of between 20ÿ200 years) clear out the tree canopies, allowing sunlight to invigorate new growth on the forest floor. For some species, wildfires are a necessary part of the life cycle in the taiga; some, e.g. jack pine have cones which only open to release their seed after a fire, dispersing their seeds onto the newly cleared ground; certain species of fungi (such as morels) are also known to do this. Grasses grow wherever they can find a patch of sun, and mosses and lichens thrive on the damp ground and on the sides of tree trunks. In comparison with other biomes, however, the taiga has low biological diversity.\\r\\nConiferous trees are the dominant plants of the taiga biome. A very few species in four main genera are found: the evergreen spruce, fir and pine, and the deciduous larch. In North America, one or two species of fir and one or two species of spruce are dominant. Across Scandinavia and western Russia, the Scots pine is a common component of the taiga, while taiga of the Russian Far East and Mongolia is dominated by larch.\\r\\nThe boreal forest, or taiga, supports a relatively small range of animals due to the harshness of the climate. Canada's boreal forest includes 85 species of mammals, 130 species of fish, and an estimated 32,000 species of insects.[32] Insects play a critical role as pollinators, decomposers, and as a part of the food web. Many nesting birds rely on them for food in the summer months. The cold winters and short summers make the taiga a challenging biome for reptiles and amphibians, which depend on environmental conditions to regulate their body temperatures, and there are only a few species in the boreal forest including red-sided garter snake, common European adder, blue-spotted salamander, northern two-lined salamander, Siberian salamander, wood frog, northern leopard frog, boreal chorus frog, American toad, and Canadian toad. Most hibernate underground in winter. Fish of the taiga must be able to withstand cold water conditions and be able to adapt to life under ice-covered water. Species in the taiga include Alaska blackfish, northern pike, walleye, longnose sucker, white sucker, various species of cisco, lake whitefish, round whitefish, pygmy whitefish, Arctic lamprey, various grayling species, brook trout (including sea-run brook trout in the Hudson Bay area), chum salmon, Siberian taimen, lenok and lake chub.\\r\\nThe taiga is home to a number of large herbivorous mammals, such as moose and reindeer/caribou. Some areas of the more southern closed boreal forest also have populations of other deer species such as the elk (wapiti) and roe deer.[33][34] The largest animal in the taiga is the wood bison, found in northern Canada, Alaska and has been newly introduced into the Russian far-east.[35] Small mammals of the Taiga biome include rodent species including beaver, squirrel, North American porcupine and vole, as well as a small number of lagomorph species such as snowshoe hare and mountain hare. These species have adapted to survive the harsh winters in their native ranges. Some larger mammals, such as bears, eat heartily during the summer in order to gain weight, and then go into hibernation during the winter. Other animals have adapted layers of fur or feathers to insulate them from the cold. Predatory mammals of the taiga must be adapted to travel long distances in search of scattered prey or be able to supplement their diet with vegetation or other forms of food (such as raccoons). Mammalian predators of the taiga include Canada lynx, Eurasian lynx, stoat, Siberian weasel, least weasel, sable, American marten, North American river otter, European otter, American mink, wolverine, Asian badger, fisher, gray wolf, coyote, red fox, brown bear, American black bear, Asiatic black bear, polar bear (only small areas at the taiga - tundra ecotone) and Siberian tiger.\\r\\nMore than 300 species of birds have their nesting grounds in the taiga.[36] Siberian thrush, white-throated sparrow, and black-throated green warbler migrate to this habitat to take advantage of the long summer days and abundance of insects found around the numerous bogs and lakes. Of the 300 species of birds that summer in the taiga only 30 stay for the winter.[37] These are either carrion-feeding or large raptors that can take live mammal prey, including golden eagle, rough-legged buzzard (also known as the rough-legged hawk), and raven, or else seed-eating birds, including several species of grouse and crossbills.\\r\\nFire has been one of the most important factors shaping the composition and development of boreal forest stands (Rowe 1955);[38] it is the dominant stand-renewing disturbance through much of the Canadian boreal forest (Amiro et al. 2001).[39] The fire history that characterizes an ecosystem is its fire regime, which has 3 elements: (1) fire type and intensity (e.g., crown fires, severe surface fires, and light surface fires), (2) size of typical fires of significance, and (3) frequency or return intervals for specific land units (Heinselman 1981).[40] The average time within a fire regime to burn an area equivalent to the total area of an ecosystem is its fire rotation (Heinselman 1973)[41] or fire cycle (Van Wagner 1978).[42] However, as Heinselman (1981)[40] noted, each physiographic site tends to have its own return interval, so that some areas are skipped for long periods, while others might burn two-times or more often during a nominal fire rotation.\\r\\nThe dominant fire regime in the boreal forest is high-intensity crown fires or severe surface fires of very large size, often more than 10,000 ha, and sometimes more than 400,000 ha (Heinselman 1981).[40] Such fires kill entire stands. Fire rotations in the drier regions of western Canada and Alaska average 50ÿ100 years, shorter than in the moister climates of eastern Canada, where they may average 200 years or more. Fire cycles also tend to be long near the tree line in the subarctic spruce-lichen woodlands. The longest cycles, possibly 300 years, probably occur in the western boreal in floodplain white spruce (Heinselman 1981).[40]\\r\\nAmiro et al. (2001)[39] calculated the mean fire cycle for the period 1980 to 1999 in the Canadian boreal forest (including taiga) at 126 years. Increased fire activity has been predicted for western Canada, but parts of eastern Canada may experience less fire in future because of greater precipitation in a warmer climate (Flannigan et al. 1998).[43]\\r\\nThe mature boreal forest pattern in the south shows balsam fir dominant on well-drained sites in eastern Canada changing centrally and westward to a prominence of white spruce, with black spruce and tamarack forming the forests on peats, and with jack pine usually present on dry sites except in the extreme east, where it is absent (Rowe and Scotter 1973).[44] The effects of fires are inextricably woven into the patterns of vegetation on the landscape, which in the east favour black spruce, paper birch, and jack pine over balsam fir, and in the west give the advantage to aspen, jack pine, black spruce, and birch over white spruce. Many investigators have reported the ubiquity of charcoal under the forest floor and in the upper soil profile, e.g., La Roi (1967).[45] Charcoal in soils provided Bryson et al. (1965)[46] with clues about the forest history of an area 280?km north of the then current tree line at Ennadai Lake, District Keewatin, Northwest Territories.\\r\\nTwo lines of evidence support the thesis that fire has always been an integral factor in the boreal forest: (1) direct, eye-witness accounts and forest-fire statistics, and (2) indirect, circumstantial evidence based on the effects of fire, as well as on persisting indicators (Rowe and Scotter 1973).[44] The patchwork mosaic of forest stands in the boreal forest, typically with abrupt, irregular boundaries circumscribing homogenous stands, is indirect but compelling testimony to the role of fire in shaping the forest. The fact is that most boreal forest stands are less than 100 years old, and only in the rather few areas that have escaped burning are there stands of white spruce older than 250 years (Rowe and Scotter 1973).[44] The prevalence of fire-adaptive morphologic and reproductive characteristics of many boreal plant species is further evidence pointing to a long and intimate association with fire. Seven of the ten most common trees in the boreal forestjack pine, lodgepole pine, aspen, balsam poplar (Populus balsamifera), paper birch, tamarack, black sprucecan be classed as pioneers in their adaptations for rapid invasion of open areas. White spruce shows some pioneering abilities, too, but is less able than black spruce and the pines to disperse seed at all seasons. Only balsam fir and alpine fir seem to be poorly adapted to reproduce after fire, as their cones disintegrate at maturity, leaving no seed in the crowns.\\r\\nThe oldest forests in the northwest boreal region, some older than 300 years, are of white spruce occurring as pure stands on moist floodplains (Rowe 1970).[47] Here, the frequency of fire is much less than on adjacent uplands dominated by pine, black spruce and aspen. In contrast, in the Cordilleran region, fire is most frequent in the valley bottoms, decreasing upward, as shown by a mosaic of young pioneer pine and broadleaf stands below, and older spruceÿfir on the slopes above (Rowe and Scotter 1973).[44] Without fire, the boreal forest would become more and more homogeneous, with the long-lived white spruce gradually replacing pine, aspen, balsam poplar, and birch, and perhaps even black spruce, except on the peatlands (Raup and Denny 1950).[48]\\r\\nLarge areas of Siberia's taiga have been harvested for lumber since the collapse of the Soviet Union. Previously, the forest was protected by the restrictions of the Soviet Forest Ministry, but with the collapse of the Union, the restrictions regarding trade with Western nations have vanished. Trees are easy to harvest and sell well, so loggers have begun harvesting Russian taiga evergreen trees for sale to nations previously forbidden by Soviet law.[49]\\r\\nIn Canada, eight percent of the taiga is protected from development, the provincial government allows forest management to occur on Crown land under rigorous constraints.\\r\\nThe main forestry practice in the boreal forest of Canada is clearcutting, which involves cutting down most of the trees in a given area, then replanting the forest as a monocrop (one species of tree) the following season.\\r\\nSome of the products from logged boreal forests include toilet paper, copy paper, newsprint, and lumber. More than 90% of boreal forest products from Canada are exported for consumption and processing in the United States.\\r\\nSome of the larger cities situated in this biome are Murmansk,[50] Arkhangelsk, Yakutsk, Anchorage,[51] Yellowknife, Troms?, Lule?, and Oulu.\\r\\nMost companies that harvest in Canadian forests are certified by an independent third party agency such as the Forest Stewardship Council (FSC), Sustainable Forests Initiative (SFI), or the Canadian Standards Association (CSA). While the certification process differs between these groups, all of them include forest stewardship, respect for aboriginal peoples, compliance with local, provincial or national environmental laws, forest worker safety, education and training, and other environmental, business, and social requirements. The prompt renewal of all harvest sites by planting or natural renewal is also required.\\r\\nDuring the last quarter of the twentieth century, the zone of latitude occupied by the boreal forest experienced some of the greatest temperature increases on Earth. Winter temperatures have increased more than summer temperatures. The number of days with extremely cold temperatures (e.g., ?20 to ?40?C (-4 to -40?F) has decreased irregularly but systematically in nearly all the boreal region, allowing better survival for tree-damaging insects. In summer, the daily low temperature has increased more than the daily high temperature.[52] In Fairbanks, Alaska, the length of the frost-free season has increased from 60ÿ90 days in the early twentieth century to about 120 days a century later. Summer warming has been shown to increase water stress and reduce tree growth in dry areas of the southern boreal forest in central Alaska, western Canada and portions of far eastern Russia. Precipitation is relatively abundant in Scandinavia, Finland, northwest Russia and eastern Canada, where a longer growth season (i.e. the period when sap flow is not impeded by frozen water) accelerate tree growth. As a consequence of this warming trend, the warmer parts of the boreal forests are susceptible to replacement by grassland, parkland or temperate forest.[53]\\r\\nIn Siberia, the taiga is converting from predominantly needle-shedding larch trees to evergreen conifers in response to a warming climate. This is likely to further accelerate warming, as the evergreen trees will absorb more of the sun's rays. Given the vast size of the area, such a change has the potential to affect areas well outside of the region.[54] In much of the boreal forest in Alaska, the growth of white spruce trees are stunted by unusually warm summers, while trees on some of the coldest fringes of the forest are experiencing faster growth than previously.[55]\\r\\nLack of moisture in the warmer summers are also stressing the birch trees of central Alaska.[56]\\r\\nRecent years have seen outbreaks of insect pests in forest-destroying plagues: the spruce-bark beetle (Dendroctonus rufipennis) in Yukon and Alaska;[57] the mountain pine beetle in British Columbia; the aspen-leaf miner; the larch sawfly; the spruce budworm (Choristoneura fumiferana);[58] the spruce coneworm.[59]\\r\\nThe effect of sulphur dioxide on woody boreal forest species was investigated by Addison et al. (1984),[60] who exposed plants growing on native soils and tailings to 15.2 mol/m3 (0.34 ppm) of SO2 on CO2 assimilation rate (NAR). The Canadian maximum acceptable limit for atmospheric SO2 is 0.34 ppm. Fumigation with SO2 significantly reduced NAR in all species and produced visible symptoms of injury in 2ÿ20 days. The decrease in NAR of deciduous species (trembling aspen [Populus tremuloides], willow [Salix], green alder [Alnus viridis], and white birch [Betula papyrifera]) was significantly more rapid than of conifers (white spruce, black spruce [Picea mariana], and jack pine [Pinus banksiana]) or an evergreen angiosperm (Labrador tea) growing on a fertilized Brunisol. These metabolic and visible injury responses seemed to be related to the differences in S uptake owing in part to higher gas exchange rates for deciduous species than for conifers. Conifers growing in oil sands tailings responded to SO2 with a significantly more rapid decrease in NAR compared with those growing in the Brunisol, perhaps because of predisposing toxic material in the tailings. However, sulphur uptake and visible symptom development did not differ between conifers growing on the 2 substrates.\\r\\nAcidification of precipitation by anthropogenic, acid-forming emissions has been associated with damage to vegetation and reduced forest productivity, but 2-year-old white spruce that were subjected to simulated acid rain (at pH 4.6, 3.6, and 2.6) applied weekly for 7 weeks incurred no statistically significant (P 0.05) reduction in growth during the experiment compared with the background control (pH 5.6) (Abouguendia and Baschak 1987).[61] However, symptoms of injury were observed in all treatments, the number of plants and the number of needles affected increased with increasing rain acidity and with time. Scherbatskoy and Klein (1983)[62] found no significant effect of chlorophyll concentration in white spruce at pH 4.3 and 2.8, but Abouguendia and Baschak (1987)[61] found a significant reduction in white spruce at pH 2.6, while the foliar sulphur content significantly greater at pH 2.6 than any of the other treatments.\\r\\nMany nations are taking direct steps to protect the ecology of the taiga by prohibiting logging, mining, oil and gas production, and other forms of development. In February 2010 the Canadian government established protection for 13,000 square kilometres of boreal forest by creating a new 10,700-square-kilometre park reserve in the Mealy Mountains area of eastern Canada and a 3,000-square-kilometre waterway provincial park that follows alongside the Eagle River from headwaters to sea.[63]\\r\\nTwo Canadian provincial governments, Ontario and Quebec, introduced measures in 2008 that would protect at least half of their northern boreal forest.[64][65] Although both provinces admitted it will take years to plan, work with Aboriginal and local communities and ultimately map out precise boundaries of the areas off-limits to development, the measures are expected to create some of the largest protected areas networks in the world once completed. Both announcements came the following year after a letter signed by 1,500 scientists called on political leaders to protect at least half of the boreal forest.[66]\\r\\nThe taiga stores enormous quantities of carbon, more than the world's temperate and tropical forests combined, much of it in wetlands and peatland.[67] In fact, current estimates place boreal forests as storing twice as much carbon per unit area as tropical forests.[68]\\r\\nOne of the biggest areas of research and a topic still full of unsolved questions is the recurring disturbance of fire and the role it plays in propagating the lichen woodland.[69] The phenomenon of wildfire by lightning strike is the primary determinant of understory vegetation and because of this, it is considered to be the predominant force behind community and ecosystem properties in the lichen woodland.[70] The significance of fire is clearly evident when one considers that understory vegetation influences tree seedling germination in the short term and decomposition of biomass and nutrient availability in the long term.[70] The recurrent cycle of large, damaging fire occurs approximately every 70 to 100 years.[71] Understanding the dynamics of this ecosystem is entangled with discovering the successional paths that the vegetation exhibits after a fire. Trees, shrubs, and lichens all recover from fire-induced damage through vegetative reproduction as well as invasion by propagules.[72] Seeds that have fallen and become buried provide little help in re-establishment of a species. The reappearance of lichens is reasoned to occur because of varying conditions and light/nutrient availability in each different microstate.[72] Several different studies have been done that have led to the formation of the theory that post-fire development can be propagated by any of four pathways: self replacement, species-dominance relay, species replacement, or gap-phase self replacement.[69] Self replacement is simply the re-establishment of the pre-fire dominant species. Species-dominance relay is a sequential attempt of tree species to establish dominance in the canopy. Species replacement is when fires occur in sufficient frequency to interrupt species dominance relay. Gap-Phase Self-Replacement is the least common and so far has only been documented in Western Canada. It is a self replacement of the surviving species into the canopy gaps after a fire kills another species. The particular pathway taken after a fire disturbance depends on how the landscape is able to support trees as well as fire frequency.[73] Fire frequency has a large role in shaping the original inception of the lower forest line of the lichen woodland taiga.\\r\\nIt has been hypothesized by Serge Payette that the spruce-moss forest ecosystem was changed into the lichen woodland biome due to the initiation of two compounded strong disturbances: large fire and the appearance and attack of the spruce budworm.[74] The spruce budworm is a deadly insect to the spruce populations in the southern regions of the taiga. J.P. Jasinski confirmed this theory five years later stating Their [lichen woodlands] persistence, along with their previous moss forest histories and current occurrence adjacent to closed moss forests, indicate that they are an alternative stable state to the spruceÿmoss forests.[75]","input":"What climate type is associated with a coniferous or boreal forest biome?"},{"output":"second-generation American soldiers of Japanese ancestry","context":"The 442nd Infantry Regiment is an infantry regiment of the United States Army and is the only infantry formation in the Army Reserve. The regiment is best known for its history as a fighting unit composed almost entirely of second-generation American soldiers of Japanese ancestry who fought in World War II. Beginning in 1944, the regiment fought primarily in Europe during World War II,[3] in particular Italy, southern France, and Germany.\\r\\nThe 442nd Regiment is the most decorated unit in the history of American warfare.[4] The 4,000 men who initially made up the unit in April 1943 had to be replaced nearly two times. In total, about 14,000 men served, earning 9,486 Purple Hearts. The unit was awarded eight Presidential Unit Citations (five earned in one month).[5]:201 Twenty-one of its members were awarded Medals of Honor.[3] Its motto was \\"Go for Broke\\".\\r\\nInactivated in 1946, the unit was reactivated as a reserve unit in 1947 and garrisoned at Fort Shafter, Hawaii. Mobilized for duty in Vietnam and Iraq, its current members carry on the honors and traditions of the historical unit. Currently,[when?] the regiment has units aligned under the 25th Infantry Division.\\r\\n\\r\\n\\r\\nMost Japanese Americans who fought in World War II were Nisei, born in the United States to immigrant parents. Shortly after the Japanese attack on Pearl Harbor on 7 December 1941, Japanese-American men were initially categorized as 4C (enemy alien) and therefore not subject to the draft. On 19 February 1942, President Franklin D. Roosevelt signed Executive Order 9066, authorizing military authorities\\r\\nto prescribe military areas in such places and of such extent as he or the appropriate Military Commander may determine, from which any or all persons may be excluded, and with respect to which, the right of any person to enter, remain in, or leave shall be subject to whatever restrictions the Secretary of War or the appropriate Military Commander may impose in his discretion.\\r\\nAlthough the order did not refer specifically to people of Japanese ancestry, it was targeted largely for the internment of people of Japanese ancestry from the West Coast. In March 1942, Lieutenant General John L. DeWitt, head of the Western Defense Command and Fourth Army, issued the first of 108 military proclamations that resulted in the forced relocation from their residences to guarded relocation camps of more than 110,000 people of Japanese ancestry from the West Coast, the great majority of the ethnic community. Two thirds were born in the United States.\\r\\nIn Hawaii, the military imposed martial law, complete with curfews and blackouts. As a large portion of the population was of Japanese ancestry (150,000 out of 400,000 people in 1937), internment was deemed not practical; it was strongly opposed by the island's business community, which was heavily dependent on the labor force of those of Japanese ancestry, unlike businesses on the mainland. There, business interests competed with those of Japanese Americans, and many bought up Japanese American properties that had to be surrendered. It was accurately believed that an internment of Japanese Americans and Japanese immigrants in Hawaii would have had catastrophic results for the Hawaiian economy; intelligence reports at the time noted that \\"the Japanese, through a concentration of effort in select industries, had achieved a virtual stranglehold on several key sectors of the economy in Hawaii.\\"[6] In addition, other reports indicated that those of Japanese descent in Hawaii \\"had access to virtually all jobs in the economy, including high-status, high-paying jobs (e.g., professional and managerial jobs),\\" suggesting that a mass internment of people of Japanese descent in Hawaii would have negatively impacted every sector of the Hawaiian economy.[7] When the War Department called for the removal of all soldiers of Japanese ancestry from active service in early 1942, General Delos C. Emmons, commander of the U.S. Army in Hawaii, decided to discharge those in the Hawaii Territorial Guard, which was composed mainly of ROTC students from the University of Hawaii. However, he permitted the more than 1,300 Japanese-American soldiers of the 298th and 299th Infantry Regiment regiments of the Hawaii National Guard to remain in service. The discharged members of the Hawaii Territorial Guard petitioned General Emmons to allow them to assist in the war effort. The petition was granted and they formed a group called the Varsity Victory Volunteers, which performed various military construction jobs. General Emmons, worried about the loyalty of Japanese-American soldiers in the event of a Japanese invasion, recommended to the War Department that those in the 298th and 299th regiments be organized into a \\"Hawaiian Provisional Battalion\\" and sent to the mainland. The move was authorized, and on 5 June 1942, the Hawaiian Provisional Battalion set sail for training. They landed at Oakland, California on 10 June 1942 and two days later were sent to Camp McCoy, Wisconsin. On 15 June 1942, the battalion was designated the 100th Infantry Battalion (Separate)the \\"One Puka Puka\\".\\r\\nDue in part to the actions of the 100th and the Varsity Victory Volunteers, the War Department directed that a Japanese-American Combat Team should be activated comprising the 442d Infantry Regiment, the 522d Field Artillery Battalion, and the 232d Engineer Combat Company.\\r\\nThe order dated January 22, 1943 directed that, \\"All cadre men must be American citizens of Japanese ancestry who have resided in the United States since birth,\\" and that \\"Officers of field grade and captains furnished under the provisions of subparagraphs a, b and c above, will be white American citizens. Other officers will be of Japanese ancestry insofar as practicable.\\"[8]\\r\\nIn accordance with these orders the 442d Combat Team was activated February 1, 1943, by General Orders, Headquarters Third Army. Colonel Charles W. Pence took command, with Lieutenant Colonel Merritt B. Booth as executive officer. Lieutenant Colonel Keith K. Tatom commanded the 1st Battalion, Lieutenant Colonel James M. Hanley the 2d Battalion, and Lieutenant Colonel Sherwood Dixon the 3d Battalion. Lieutenant Colonel Baya M. Harrison commanded the 522d Field Artillery, and Captain Pershing Nakada commanded the 232d Engineers.[9]\\r\\nColonel Charles W. Pence, a World War I veteran and military science professor, commanded the regiment until he was wounded during the rescue of the \\"Lost Battalion\\" in October 1944. He was then replaced by Lieutenant Colonel Virgil R. Miller.[10]\\r\\nThe U.S. government required that all internees answer a loyalty questionnaire, which was used to register the Nisei for the draft. Question 27 of the questionnaire asked eligible males, \\"Are you willing to serve in the armed forces of the United States on combat duty, wherever ordered?\\" and question 28 asked, \\"Will you swear unqualified allegiance to the United States of America and faithfully defend the United States from any or all attack by foreign or domestic forces, and forswear any form of allegiance or obedience to the Japanese emperor, or any other foreign government, power or organization?\\"\\r\\nNearly a quarter of the Nisei males answered with a no or a qualified answer to both questions in protest, resenting the implication they ever had allegiance to Japan; some left them blank. Qualified answers included those who said, yes, but criticized the internment of the Japanese or racism. Many who responded that way were imprisoned for evading the draft. Such refusal is the subject of the postwar novel No-No Boy. But more than 75% indicated that they were willing to enlist and swear allegiance to the U.S. The U.S. Army called for 1,500 volunteers from Hawaii and 3,000 from the mainland. An overwhelming 10,000 men from Hawaii volunteered. The announcement was met with less enthusiasm on the mainland, where the vast majority of draft-age men of Japanese ancestry and their families were held in internment camps. The Army revised the quota, calling for 2,900 men from Hawaii, and 1,500 from the mainland. Only 1,256 volunteered from the mainland during this initial call for volunteers. As a result, around 3,000 men from Hawaii and 800 men from the mainland were inducted. President Roosevelt announced the formation of the 442nd Infantry Regimental Combat Team, saying, \\"Americanism is not, and never was, a matter of race or ancestry.\\"[11] Ultimately, the draft was instated to obtain more Japanese Americans from the mainland and these made up a large part of the 14,000 men who eventually served in the 442nd Regiment.[citation needed]\\r\\nThe 100th Infantry Battalion relocated to Camp Shelby in Mississippi. Eventually, the 100th was joined by 3,000 volunteers from Hawaii and 800 from the mainland camps. As a regimental combat team (RCT), the 442nd RCT was a self-sufficient fighting formation of three infantry battalions (originally 1st, 2nd, and 3rd Battalions, 442nd Infantry, and later the 100th Infantry Battalion in place of the 1st), the 522nd Field Artillery Battalion, the 232nd Engineer Company, an anti-tank company, cannon company, service company, medical detachment, headquarters companies, and the 206th Army Band.\\r\\nAlthough they were permitted to volunteer to fight, Americans of Japanese ancestry were generally forbidden to fight in combat in the Pacific Theater. No such limitations were placed on Americans of German or Italian ancestry, who were assigned to units fighting against the Axis Powers in the European Theater. There were many more German and Italian Americans than Japanese Americans, and their political and economic power reduced the restrictions against them. Many men deemed proficient enough in the Japanese language were approached, or sometimes ordered, to join the Military Intelligence Service (MIS) to serve as translators/interpreters and spies in the Pacific, as well as in the China Burma India Theater. These men were sent to the MIS Language School at Camp Savage, Minnesota to develop their language skills and receive training in military intelligence. While the 442nd trained in Mississippi, the 100th departed for Oran in North Africa to join the forces destined to invade Italy.\\r\\nThe 442nd Combat Team, less its 1st Battalion, which had remained in the U.S. to train Nisei replacements after many of its members were levied as replacements for the 100th, sailed from Hampton Roads, Virginia, on 1 May 1944 and landed at Anzio on 28 May. The 442nd would join the 100th Battalion in Civitavecchia north of Rome on 11 June 1944, attached to the 34th Infantry Division. The 100th was placed under the command of the 442nd on 15 June 1944 but on 14 August 1944, the 100th Battalion was officially assigned to the 442nd as its 1st battalion, but was allowed to keep its unit designation in recognition of its distinguished fighting record. The 1st Battalion, 442nd Infantry at Camp Shelby was then redesignated the 171st Infantry Battalion (Separate) on 5 September 1944. The 100th Battalion's high casualty rate at Anzio and Monte Cassino earned it the unofficial nickname \\"Purple Heart Battalion.\\"[12]\\r\\nThe newly formed Nisei unit went into battle together on 26 June 1944 at the village of Belvedere in Suvereto, Tuscany. Although the 100th was attached to the 442nd, their actions earned them a separate Presidential Unit Citation. Second and Third Battalions were the first to engage the enemy, in a fierce firefight. F Company bore the worst fighting. A, B, and C Companies of the 100th were called into combat and advanced east using a covered route to reach the high ground northeast of Belvedere.[9]:34 The enemy did not know that the 100th was flanking the German exit, trapping them in Belvedere. C Company blocked the town's entrance while A Company blocked the exit. As this was occurring the 442nd's 2nd Battalion was receiving a heavy barrage by the Germans from inside Belvedere, and the Germans remained unaware of their situation. B Company stayed on the high ground and conducted a surprise attack on the German battalion's exposed east flank, forcing the Germans to flee and run into C Company, which then drove the Germans to A Company.[13]\\r\\nAll three companies went into action boldly facing murderous fire from all types of weapons and tanks and at times fighting without artillery support... The stubborn desire of the men to close with a numerically superior enemy and the rapidity with which they fought enabled the 100th Infantry Battalion to destroy completely the right flank positions of a German Army... The fortitude and intrepidity displayed by the officers and men of the 100th Infantry Battalion reflects the finest traditions of the Army of the United States.[14]:149 Presidential Unit Citation Review\\r\\nThe 442nd, along with its first battalion, the 100th, kept driving the enemy north, engaging in multiple skirmishes until they had passed Sassetta. The battle of Belvedere showed that the 442nd could hold their own and showed them the kind of fighting the 100th Battalion had gone through in the prior months. After only a few days of rest, the united 442nd again entered into combat on 1 July, taking Cecina and moving towards the Arno River. On 2 July, as the 442nd approached the Arno, 5th Battalion engaged in a hard-fought battle to take Hill 140, while on 7 July the 100th fought for the town of Castellina Marittima.[15]\\r\\nFor the first three weeks of July the 442nd and its 1st Battalion, the 100th, were constantly attacking German forces, leading to 1,100 enemy killed and 331 captured.[citation needed]\\r\\nHill 140 was the main line of enemy resistance. A single German battalion held the hill and, along with the help of artillery, had completely wiped out a machine-gun squad of L Company of the 3rd Battalion and G Company of 2nd Battalion except for its commander.[9]:36 A constant barrage of artillery shells were launched against the 2nd and 3rd Battalions as they dug in at the hill's base. The 442nd gained very little ground in the coming days only improving their position slightly. The 232nd Engineers aided the 442nd by defusing landmines that lay in the 442nd's path. The entire 34th Division front encountered heavy resistance. \\"All along the 34th Infantry Division Front the Germans held more doggedly than at any time since the breakthrough at Cassino and Anzio.\\"[9]:37 Hill 140 had been dubbed \\"Little Cassino\\" as the resistance by the Germans was so fierce. \\"Hill 140, when the medics were just overrun with all the casualties; casualties you couldn't think to talk about.\\"[16] The 2nd Battalion moved to the eastern front of Hill 140 and 3rd Battalion moved to the western front, both converging on the German flanks. It wasn't until 7 July when the last German resistance was taken down that the hill came under the 34th Division's control.\\r\\nOn the day Hill 140 fell, the battle for the town of Castellina Marittima began. The 100th began its assault on the northwestern side of the town taking the high ground. Just before dawn, 2nd Platoon C Company moved into town, encountering heavy resistance and multiple counterattacks by German forces but held them off. In the meantime Company B moved north into Castellina, encountering heavy resistance as well. First they helped defend 2nd and 3rd Battalions in the taking of Hill 140. Then with the help of the 522nd Field Artillery, they lay down a heavy barrage and forced the Germans to retreat by 1800 hours on 7 July.[9]:38 The 100th dug in and waited for relief to arrive after spending an entire day securing the town.\\r\\nUntil 25 July, the 442nd encountered heavy resistance from each town when they reached the Arno River, ending the Rome-Arno Campaign. The 100/442 lost 1,272 men (17 missing, 44 non-combat injuries, 972 wounded, and 239 killed) in the process, a distance of only 40 miles (64?km).[17] They rested from 25 July to 15 August, when the 442nd moved to patrol the Arno. Crossing the Arno on 31 August was relatively uneventful, as they were guarded the north side of the river in order for bridges to be built. On 11 September the 442nd was detached from the Fifth Army and then attached to the 36th Infantry Division of the Seventh Army.[citation needed]\\r\\nOn 15 July the Antitank Company was pulled from the frontlines and placed with the 517th Parachute Infantry Regiment, 1st Airborne Task Force. They had trained at an airfield south of Rome to prepare for the invasion of Southern France which took place on 15 August, landing near Le Muy, France. They trained for a few weeks to get used to, prepare, properly load, and fly gliders. These gliders were 48 feet (15?m) long and 15 feet (4.6?m) high, and could hold a jeep and a trailer filled with ammunition, or a British six-pounder antitank gun.[17][dead link] The Southern France Campaign, 15 August to 14 September, led the 442nd to its second Presidential Unit Citation for invading in gliders and the Combat Infantryman Badge for fighting with the infantrymen of the 7th Army. The soldiers of Antitank Company received the Glider Badge.[18]:56ÿ57 After many rough landings by the gliders, hitting trees or enemy flak, they held their positions for a few days until relieved by Allied troops coming in by sea. For the next two months the Antitank Company guarded the exposed right flank of the Seventh Army and protected the 517th Parachute Infantry. The unit also cleared mines, captured Germans, and guarded roads and tunnels.[19] In mid-to-late October, the Antitank Company rejoined the 442nd during the battle to find the \\"Lost Battalion.\\"[20]\\r\\nAfter leaving Naples, the 442nd landed in Marseille on 30 September and for the next few weeks they traveled 500 miles (800?km) through the Rhone Valley, by walking and by boxcar, until 13 October. On 14 October 1944 the 442nd began moving into position in the late afternoon preparing the assault on Hills A, B, C, and D of Bruyres. Each hill was heavily guarded, as each hill was key in order to take and secure the city. Hill A was located Northwest of Bruyres, Hill B to the North, Hill C Northeast, and Hill D to the East. The 442nd had experienced mainly prairie in Italy, but the Vosges Mountains provided a very different terrain. The unit faced dense fog, mud, heavy rain, large trees, hills, and heavy enemy gunfire and artillery while moving through the Vosges. Hitler had ordered the German frontline to fight at all costs as this was the last barrier between the Allied forces and Germany. On 15 October 1944 the 442nd began its attack on Bruyres. The 100th Battalion moved on Hill A, which was held by the SS Polizei Regiment 19, as 2nd Battalion moved in on Hill B. Third Battalion was left to take Bruyres.[citation needed]\\r\\nAfter heavy fighting dealing with enemy machine guns and snipers and a continuous artillery barrage placed onto the Germans, the 100th Battalion was eventually able to take Hill A by 3 a.m. on 18 October. 2nd Battalion took Hill B in a similar fashion only hours later. Once Hill A and B were secured, 3rd Battalion along with the 36th Infantry's 142nd Regiment began its assault from the south. After the 232nd broke through the concrete barriers around town hall of Bruyres, the 442nd captured 134 Wehrmacht members including Poles, Yugoslavs, Somalis, East Indians of the Regiment \\"Freies Indien\\", 2nd and 3rd Company of Fusilier Battalion 198, Grenadier Regiment 736, and Panzer Grenadier Regiment 192.[21]:43 After three days of fighting Bruyres fell but was not yet secured. Germans on Hill C and D used that high-ground to launch artillery barrages on the town; Hills C and D needed to be taken to secure Bruyres.[18]:60\\r\\nThe 442nd initially took Hills C and D but did not secure them and they fell back into German hands. By noon of 19 October, Hill D was taken by 2nd and 3rd Battalions, who then were ordered to take a railroad embankment leaving Hill D unsecure. As the 100th began moving on Hill C on 20 October, German forces retook Hill D during the night.[9]:57 The 100th Battalion was ordered back to Bruyres into reserve, allowing a German force onto Hill C, surprising another American division arriving into position. Retaking Hill C cost another 100 casualties.[18]:62 Hill D fell back into Allied hands after a short time, finally securing the town. The 232nd Engineers had to dismantle roadblocks, clear away trees and clear mine fields all in the midst of the battle.[9]:51,54 The 100th rested, then was called to the battle for Biffontaine.\\r\\nThe 100th was ordered to take the high-ground but was eventually ordered to move into the town, leading to a bitter fight after the 100th were encircled by German forces: cut off from the 442nd, outside radio contact, and outside artillery support. The 100th were in constant battle from 22 October until dusk of 23 October, engaging in house to house fighting and defending against multiple counterattacks. 3rd Battalion of the 442nd reached the 100th and helped drive out the remaining German forces, handing Biffontaine to the 36th.[14]:182,183 On 24 October the 143rd Infantry of the 36th Division relieved the 100th and 3rd Battalion who were sent to Belmont, another small town to the north, for some short-lived rest.[22]:139 Nine days of constant fighting continued as they were then ordered to save T-Patchers, the 141st Regiment of the 36th Infantry, the \\"Lost Battalion.\\"\\r\\nAfter less than two days in reserve, the 442nd was ordered to attempt the rescue of the \\"Lost Battalion\\" two miles east of Biffontaine.[22]:139 On 23 October Colonel Lundquist's 141st Regiment, soon to be known as the \\"Alamo\\" Regiment, began its attack on the German line that ran from Rambervillers to Biffontaine. Tuesday morning, 24 October, the left flank of the 141st, commanded by Technical Sergeant Charles H. Coolidge, ran into heavy action, fending off numerous German attacks throughout the days of 25 and 26 October. The right flank command post was overrun and 275 men of Lieutenant Colonel William Bird's 1st Battalion Companies A, B, C, and a platoon from Company D were cut off 2 kilometres (1.2?mi) behind enemy lines.[21]:61ÿ62 The \\"Lost Battalion\\" was cut off by German troops and was forced to dig in until help arrived. It was nearly a week before they saw friendly soldiers.\\r\\nAt 4 a.m. on Friday 27 October, General John E. Dahlquist ordered the 442nd to move out and rescue the cut-off battalion. The 442nd had the support of the 522nd and 133rd Field Artillery units but at first made little headway against German General Richter's infantry and artillery front line.[21]:66 For the next few days the 442nd engaged in the heaviest fighting it had seen in the war, as the elements combined with the Germans to slow their advance. Dense fog and very dark nights prevented the men from seeing even twenty feet. Many men had to hang onto the man in front of him just to know where to go. Rainfall, snow, cold, mud, fatigue, trench foot, and even exploding trees plagued them as they moved deeper into the Vosges and closer to the German frontlines.[14]:185,187 The 141st continued fightingin all directions.\\r\\nWhen we realized we were cut off, we dug a circle at the top of the ridge. I had two heavy, water-cooled machine guns with us at this time, and about nine or ten men to handle them. I put one gun on the right front with about half of my men, and the other gun to the left. We cut down small trees to cover our holes and then piled as much dirt on top as we could. We were real low on supplies, so we pooled all of our food.\\r\\nAirdrops with ammo and food for the 141st were called off by dense fog or landed in German hands. Many Germans did not know that they had cut off an American unit. \\"We didn't know that we had surrounded the Americans until they were being supplied by air. One of the supply containers, dropped by parachute, landed near us. The packages were divided up amongst us.\\"[21]:83 Only on 29 October was the 442nd told why they were being forced to attack the German front lines so intensely.\\r\\nThe fighting was intense for the Germans as well. Gebirgsjager Battalion 202 from Salzburg was cut off from Gebirgsjager Battalion 201 from Garmisch.[21]:72 Both sides eventually rescued their cut-off battalions.\\r\\nAs the men of the 442nd went deeper and deeper they became more hesitant, until reaching the point where they would not move from behind a tree or come out of a foxhole. However, this all changed in an instant. The men of Companies I and K of 3rd Battalion had their backs against the wall, but as each one saw another rise to attack, then another also rose. Then every Nisei charged the Germans screaming, and many screaming \\"Banzai!\\"[18]:83 Through gunfire, artillery shells, and fragments from trees, and Nisei going down one after another, they charged.\\r\\nColonel Rolin's grenadiers put up a desperate fight, but nothing could stop the Nisei rushing up the steep slopes, shouting, firing from the hip, and lobbing hand grenades into dugouts. Finally the German defenses broke and the surviving grenadiers fled in disarray. That afternoon the American aid stations were crowded with casualties. The 2nd platoon of Company I had only two men left, and the 1st platoon was down to twenty.\\"[21]:89 On the afternoon of 30 October, 3rd Battalion broke through and reached the 141st, rescuing 211 T-Patchers at the cost of 800 men in five days. However, the fighting continued for the 442nd as they moved past the 141st. The drive continued until they reached Saint-Die on 17 November when they were finally pulled back. The 100th fielded 1,432 men a year earlier, but was now down to 239 infantrymen and 21 officers. Second Battalion was down to 316 riflemen and 17 officers, while not a single company in 3rd Battalion had over 100 riflemen; the entire 100th/442nd Regimental Combat Team was down to less than 800 soldiers. Earlier (on 13 October) when attached to the 36th Infantry, the unit was at 2,943 rifleman and officers, thus in only three weeks 140 were killed and a further 1,800 had been wounded, while 43 were missing.[18]:83,85\\r\\nGeneral Dahlquist's dubious command of the 442nd received mixed reviews, chiefly from the unit's officers rather than the enlisted soldiers, who believed that Dahlquist considered his Nisei soldiers expendable cannon fodder. Despite examples of ostensibly courageous behavior, his decisions were undermined by the failure to tally victories without considerable costs to his men. A particular example was when his aide Lieutenant Wells Lewis, the eldest son of novelist Sinclair Lewis, was killed while Dahlquist was issuing orders standing in the open during a battle.[18]:82 When Dahlquist ordered his men to take Biffontaine, it was despite the sparsely populated farming town being militarily insignificant, out of the range of artillery and radio contact. In another example, Lieutenant Allan M. Ohata was ordered to charge with his men up a hill toward the enemy, who were dug in and well supplied. Ohata considered the order a certain suicide mission. Despite the threat of court-martial and demotion he refused, insisting that the men would be better off attacking the position \\"their own way.\\"[14]:190 Lt. Ohata's Distinguished Service Cross, for his actions in Italy as an enlisted Staff Sergeant, was ultimately upgraded to the Medal of Honor.\\r\\nOn 12 November, General Dahlquist ordered the entire 442nd to stand in formation for a recognition and award ceremony. Of the 400 men originally assigned to K Company only eighteen turned out, joined by eight survivors from I Company. Upon reviewing the meager assemblage Dahlquist became irritated, ignorant of the sacrifices that the unit had made in serving his orders. He demanded of Colonel Virgil R. Miller, \\"I want all your men to stand for this formation.\\" Miller responded simply, \\"That's all of K company left, sir.\\"[18]:95\\r\\nSome time later, while the former commander of the 1st Battalion, Lieutenant Colonel Gordon Singles was filling the role of brigadier general at Fort Bragg (North Carolina), General Dahlquist arrived as part of a review. When he recognized Colonel Singles he approached him and offered the colonel his hand saying, \\"Let bygones be bygones. It's all water under the bridge, isn't it?\\" In the presence of the entire III Corps, Colonel Singles continued to salute General Dahlquist but refused to take Dahlquist's hand.[18]:91[23][24]\\r\\nDuring and after the war, the 442nd was repeatedly commemorated for their efforts in the Vosges Mountains. A commissioned painting now hangs in The Pentagon depicting their fight to reach the \\"Lost Battalion.\\"[18]:89 A memorial was erected in Biffontaine by Gerard Henry, later the town's mayor. A monument was established in Bruyeres to mark the liberation of that city. At first a narrow road led to the monument, but the road was later widened to accommodate four tour buses and is now named \\"The Avenue of the 442nd Infantry Regiment\\" in honor of those brave soldiers.[14]:201\\r\\nFollowing the tough battle through the Vosges Mountains, the 442nd was sent to the Maritime Alps and the French Riviera. It was a walk in the park compared to what they had experienced in October. Little to no action occurred in the next four months as they rested.[25] The 442nd guarded and patrolled a twelve to fourteen-mile front line segment of the French-Italian border. This part of the 442nd's journey gained the name \\"Champagne Campaign\\" because of the available wine, women, and merry times.[26] The 442nd experienced additional losses as patrols sometimes ran into enemy patrols, or sometimes soldiers stepped on enemy and allied land mines. Occasionally, soldiers of the 442nd captured spies and saboteurs.\\r\\nThe 442nd also captured an enemy submarine. A Nisei soldier noticed what looked like an animal in the water but upon closer look it was actually a one-man German midget submarine. The German and the submarine were captured and handed over to the U.S. Navy.[15] On 23 March 1945, the 442nd Regimental Combat Team sailed back to Italy and returned to the Gothic Line.[25]\\r\\nFrom 20 to 22 March, the 442 and the 232 shipped off to Italy from France but the 522nd Field Artillery Battalion was sent to another part of Europe. They traveled northwards some 600 miles (970?km) through the Rhone Valley and stopped at Kleinblittersdorf on the east bank of the Saar River. The 522nd aided the 63rd Division on the Siegfried Line defenses south of St. Ingbert from 12ÿ21 March.[9]:99 The 522nd became a roving battalion, supporting nearly two dozen army units along the front traveling a total of 1,100 miles (1,800?km) across Germany and accomplishing every objective of their fifty-two assignments.[14]:239 The 522nd was the only Nisei unit to fight in Germany. On 29 April scouts of the 522nd located a satellite camp of the infamous Dachau concentration camp next to the small Bavarian town of Lager Lechfeld, adjacent to Hurlach. Scouts from the 522nd were among the first Allied troops to release prisoners from the Kaufering IV Hurlach satellite camp, one of nearly 170 such camps, where more than 3,000 prisoners were held.[27]\\r\\nAs we came around the way, there were a lot of Jewish inmates coming out of the camp, and I heard that the gate was opened by our advanced scouts. They took a rifle and shot it. I think it was a fellow from Hawaii that did that. I think it was a Captain Taylor, Company B was one of them, but another person from Hawaii, he passed away. They opened the gate and all these German, I mean, Jewish victims were coming out of the camp.[28]\\r\\nThen, when we finally opened the Dachau camp, got in, oh those people were so afraid of us, I guess. You could see the fear in their face. But eventually, they realized that we were there to liberate them and help them.[29]\\r\\nThe only thing the Nisei could really do was give them clothing and keep them warm. Nisei soldiers began to give the Jewish inmates food from their rations but were ordered to stop because the food could overwhelm the digestive systems of the starved inmates and kill them.[31] As they continued past the subcamp, they discovered the eastward path along which Jewish inmates were approaching Waakirchen,[32] as the concentration camp survivors had been driven on a death march to another camp from Dachau starting there on 24 April, headed south through Eurasburg, then eastwards for a total distance of nearly sixty kilometers (37 miles),[33] originally numbering some 15,000 prisoners.[34]\\r\\nNo, my first encounter was these lumps in snow, and then I didn't know what they were, and so I went and investigated them and discovered that they were people, you know. Most of them were skeletons or people who had been beaten to death or just died of starvation or overworked or whatever. Most of them I think died from exposure because it was cold.[35]\\r\\nThey discovered more subcamps and former inmates wandering the countryside. Following the German surrender, from May to November, the 522nd was assigned to security around Donauw?rth, which consisted of setting up roadblocks and sentry posts to apprehend Nazis who were trying to disappear. The 522nd returned to the United States in November 1945.[9]:99 A memorial to the rescue by the 522nd on May 2, 1945 exists at 47466.15N 113855.30E? / ?47.7683750N 11.6486944E? / 47.7683750; 11.6486944, just under two kilometers west of the Waakirchen town centre.[36]\\r\\nOn 23 March 1945 the 100/442 shipped out from Marseille and traveled to Leghorn, Italy, attached to the 92nd Division. The Fifth Army had been stalemated at the Gothic Line for the prior five months. The 442nd faced extremely tough terrain, where the saw-toothed Apennines rose up from the Ligurian Sea. Starting from the northeast, the peaks hugged the east coast of Italy and stretched diagonally southward across the Italian boot. To the west, on the other side of the mountains, was the wide flat Po River Valley that led to the Austrian Alpsthe last barrier to Germany. For nine months German Field Marshal Albert Kesselring directed the construction of the Gothic Line along the top of the Apennines. The Todt Organization (known for its fortifications at Monte Cassino) used 15,000 Italian slave laborers. They drilled into solid rock to make gun pits and trenches, which they reinforced with concrete. They built 2,376 machine gun nests with interlocking fire.[18]:105ÿ7\\r\\nOn the Italian front, the 442nd had contact with the only segregated African-American active combat unit of the U.S. Army in Europe, the 92nd Infantry Division, as well as troops of the British and French colonial empires (West and East Africans, Moroccans, Algerians, Indians, Gurkhas, Jews from the Palestine mandate)[37] and the non-segregated Brazilian Expeditionary Force[38] which had in its ranks ethnic Japanese.\\r\\nGeneral Mark W. Clark welcomed the 442 and presented his plan to break the Gothic Line. General Clark had a disagreement with Supreme Commander Eisenhower. Clark had to negotiate for the return of the 100th and 442nd because Eisenhower wanted them for the Battle of the Bulge and General Devers, commander of the Sixth Army Group, needed fresh troops.[9]:249ÿ50 General Clark got his wish. The 442nd and 100th, minus the 522nd, along with the 92nd Division, mounted a surprise diversionary attack on the left flank. They intended to shift enemy attention to it from the interior, allowing the Eighth Army to cross the Senio River on the right flank and then the Fifth Army on the left.[18]:107[22]:145\\r\\nIn front of the 442nd lay mountains code-named Georgia, Florida, Ohio 1, Ohio 2, Ohio 3, Monte Cerreta, Monte Folgorito, Monte Belvedere, Monte Carchio, and Monte Altissimo. These objectives hinged on surprising the Germans. The 100th went after Georgia Hill and the 3rd Battalion attacked Mount Folgorita. On 3 April the 442nd moved into position under the cover of nightfall to hide from the Germans who had good sight lines from their location on the mountains. The next day the 442nd waited. At 0500 the following morning they were ready to strike. A little over 30 minutes later objectives Georgia and Mount Folgorita were taken, cracking the Gothic Line. They achieved surprise and forced the enemy to retreat. After counterattacking, the Germans were defeated. During this time, 2nd Battalion was moving into position at Mount Belvedere, which overlooked Massa and the Frigido River.[citation needed]\\r\\nThe 442nd made a continuous push against the German Army and objectives began to fall: Ohio 1, 2, and 3, Mount Belvedere on 6 April by 2nd Battalion, Montignoso 8 April by 3rd Battalion, Mount Brugiana on 11 April by 2nd Battalion, Carrara by 3rd Battalion on 11 April, and Ortonovo by the 100th on 15 April. The 442 turned a surprise diversionary attack into an all-out offensive. The advance came so quickly that supply units had a hard time keeping up.[citation needed]\\r\\nThe Nisei drove so hard that beginning on 17 April the Germans decided to destroy their fortifications and pull back to make a final stand at Aulla. The last German defense in Italy was Monte Nebbione, directly south of Aulla. San Terenzo lay East of Mount Nobbione and became the launching point for the Aulla assault. The final drive of the 442nd began on 19 April and lasted until 23 April, when the 3rd Battalion finally took Mount Nebbione and Mount Carbolo. Following the fall of San Terenzo, 2nd Battalion hooked right around the mountains and Task Force Fukuda (consisting of Companies B and F from 2nd Battalion) flanked left from Mount Carbolo creating a pincer move onto Aulla.[18]:117 On 25 April Aulla fell and the German retreat was cut off. In the days that followed, Germans began to surrender in the hundreds and thousands to the Fifth and Eighth Armies. This was 442nd's final World War II action.[citation needed] On 2 May the war ended in Italy followed six days later by Victory in Europe.\\r\\nThe 442nd Regimental Combat Team was the most decorated unit for its size and length of service in the history of American warfare.[4] The 4,000 men who initially came in April 1943 had to be replaced nearly 2.5 times. In total, about 14,000 men served, earning 9,486 Purple Hearts. The unit was awarded eight Presidential Unit Citations (5 earned in one month).[5]:201 Twenty-one of its members were awarded Medals of Honor.[3] Members of the 442nd received 18,143 awards, including:\\r\\nOn 5 October 2010, the Congressional Gold Medal was awarded to the 442nd Regimental Combat Team, the 100th Infantry Battalion, and Nisei serving in the Military Intelligence Service.[41]\\r\\nIn 2012, the surviving members of the 442nd RCT were made chevaliers of the French Lgion d'Honneur for their actions contributing to the liberation of France during World War II and their heroic rescue of the Lost Battalion outside of Biffontaine.[42][43][44][45]\\r\\nOriginal fight song of the 442nd Battalion Hawai'i Go For Broke Lyrics by Martin Kida -KIA, Score by T.Y.[46][47]\\r\\nREMEMBER PEARL HARBOR.\\r\\nHistory in every century\\r\\nWe recall an act that lives forevermore\\r\\nWe recall as into night they fall\\r\\nThe things that happened on Hawaii shore\\r\\n\\r\\nLet's remember Pearl Harbor\\r\\nAs we go to meet the foe\\r\\nLet's remember Pearl Harbor\\r\\nAs we did the Alamo\\r\\nWe will always remember\\r\\nHow they died for liberty\\r\\nLet's remember Pearl Harbor\\r\\nAnd go on to victory\\r\\n\\r\\nGO FOR BROKE\\r\\nFour Forty-Second Infantry\\r\\nWe are the boys of Hawaii Nei\\r\\nWe will fight for you\\r\\nAnd the red white and blue\\r\\nAnd will go the front\\r\\nAnd back to Honolulu-lu-lu\\r\\nFighting for dear old Uncle Sam\\r\\nGo for broke we don't give a damn\\r\\nWe will round up the Huns\\r\\nAt the point of a gun\\r\\nAnd victory will be ours\\r\\nGo for broke! Four Four Two!\\r\\nGo for broke! Four Four Two!\\r\\nAnd victory will be ours.\\r\\n\\r\\nAll hail our company.\\r\\nThe record of the Japanese Americans serving in the 442nd and in the Military Intelligence Service (U.S. Pacific Theater forces in World War II) helped change the minds of anti-Japanese American critics in the U.S. and resulted in easing of restrictions and the eventual release of the 120,000 strong community well before the end of World War II.\\r\\nHowever, the unit's exemplary service and many decorations did not change the attitudes of the general U.S. population to people of Japanese ancestry after World War II. Veterans were welcomed home by signs that read \\"No Japs Allowed\\" and \\"No Japs Wanted\\", denied service in shops and restaurants, and had their homes and property vandalized.\\r\\nAnti-Japanese sentiment remained strong into the 1960s, but faded along with other once-common prejudices, even while remaining strong in certain circles. Conversely, the story of the 442nd provided a leading example of what was to become the controversial model minority stereotype.[48]\\r\\nAccording to author and historian Tom Coffman, men of the 442nd dreaded returning home as second-class citizens. In Hawaii these men became involved in a peaceful movement. It has been described as the 442nd returning from the battles in Europe to the battle at home. The non-violent revolution was successful and put veterans in public office in what became known as the Revolution of 1954.\\r\\nOne notable effect of 442nd's service was to help convince Congress to end its opposition towards Hawaii's statehood petition. Twice before 1959, residents of Hawaii asked to be admitted to the U.S. as the 49th state.[citation needed] The exemplary record of the Japanese-Americans serving in the 442nd and the loyalty showed by the rest of Hawaii's population during World War II allowed Hawaii to be admitted as the 50th state (Alaska was granted statehood just prior).\\r\\nIn post-war American popular slang, the phrase \\"going for broke\\" was adopted from the 442nd's unit motto \\"Go for Broke\\", which was derived from the Hawaiian pidgin phrase used by craps shooters risking all their money on one roll of the dice.[5]:69\\r\\nThe 442nd RCT was inactivated in Honolulu in 1946, but reactivated in 1947 in the U.S. Army Reserve. It was mobilized in 1968 to refill the Strategic Reserve during the Vietnam War, and carries on the honors and traditions of the unit. Today, the 100th Battalion, 442nd Infantry, is the only ground combat unit of the Army Reserve.[49] The battalion headquarters is at Fort Shafter, Hawaii, with subordinate units based in Hilo, American Samoa, Saipan, and Guam. The only military presence in American Samoa consists of the battalion's B and C companies.[3]\\r\\nIn August 2004, the battalion was mobilized for duty in Iraq.[50] Stationed at Logistics Support Area Anaconda in the city of Balad, which is located about 50 miles northwest of Baghdad.[51] Lt. Colonel Colbert Low assumed command of the battalion only a few weeks after the battalion arrived at Logistical Support Area Anaconda.[52] In early 2006, the 100th had returned home.[53] One soldier was killed by an improvised explosive device attack.[54] Four members of the battalion were killed in action, and several dozen injured, before the battalion returned home.[49][55] During the year-long deployment, one of Charlie Company's attached platoons, discovered over 50 weapons caches.[56] Unlike the soldiers of World War II who were predominantly Japanese Americans, these soldiers came from as far away as Miami, Florida, Tennessee, Alaska and included soldiers from Hawaii, Philippines, Samoa and Palau. For their actions in Iraq the unit received the Meritorious Unit Commendation.[57]\\r\\nCalifornia has given three state highway segments honorary designations for Japanese American soldiers:\\r\\nA nationwide campaign to urge the U.S. Postal Service to issue a commemorative postage stamp to honor the contributions of the Japanese American soldiers of World War II was begun in 2006 in California.[58]\\r\\nThe unit was once again deployed in 2009.[56] The unit was called up alongside the 3rd brigade, 25th Infantry Division;[59] and was assigned as an element of the 29th Infantry Brigade Combat Team.[60] Nominally deployed to Kuwait, it conducted patrols into Iraq, leading to two fatalities;[61] those patrols consisted of more than a million miles of driving conducting convoy duty.[62] During the units deployment, several dozen of the units American Samoan servicemembers were naturalized in Kuwait.[63]","input":"What kind of soldiers compromised the highly decorated 442nd regimental combat team?"},{"output":"an independent central bank","context":"","input":"What type of agency is the federal reserve board?"},{"output":"Raja Raja Chola I","context":"Brihadishvara Temple, also called Rajarajesvaram or Peruvudaiyar Kovil, is a Hindu temple dedicated to Shiva located in Thanjavur, Tamil Nadu, India.[1][3] It is one of the largest South Indian temple and an exemplary example of a fully realized Tamil architecture.[4] It is called as Dhakshina Meru of south. Built by Raja Raja Chola I between 1003 and 1010 AD, the temple is a part of the UNESCO World Heritage Site known as the \\"Great Living Chola Temples\\", along with the Chola dynasty era Gangaikonda Cholapuram temple and Airavatesvara temple that are about 70 kilometres (43?mi) and 40 kilometres (25?mi) to its northeast respectively.[5]\\r\\nThe original monuments of this 11th century temple were built around a moat. It included gopura, the main temple, its massive tower, inscriptions, frescoes and sculptures predominantly related to Shaivism, but also of Vaishnvaism and Shaktism traditions of Hinduism. The temple was damaged in its history and some artwork is now missing. Additional mandapam and monuments were added in centuries that followed. The temple now stands amidst fortified walls that were added after the 16th century.[6][7]\\r\\nBuilt out of granite, the vimana tower above the sanctum is one of the tallest in South India.[3] The temple has a massive colonnaded prakara (corridor) and one of the largest Shiva lingas in India.[3][5][8] It is also famed for the quality of its sculpture, as well as being the location that commissioned the brass Nataraja ÿ Shiva as the lord of dance, in 11th century. The complex includes shrines for Nandi, Parvati, Kartikeya, Ganesha, Sabhapati, Dakshinamurti, Chandeshvara, Varahi and others.[9][10] The temple is one of the most visited tourist attractions in Tamil Nadu.[11]\\r\\n\\r\\n\\r\\nBrihadishvara (IAST: B?ihdؐ?vara) is a Sanskrit composite word composed of Brihat which means \\"big, great, lofty, vast\\",[12] and Ishvara means \\"lord, Shiva, supreme being, supreme atman (soul)\\".[13][14] The name means the \\"great lord, big Shiva\\" temple. Locally, the temple is called the big temple, while in historic inscriptions it is also referred to as the Rajarajeswaram and Peruvudaiyar temple.[15]\\r\\nThe Brihadeeswarar Temple is located in the city of Thanjavur, about 350 kilometres (220?mi) southwest of Chennai. The city is connected daily to other major cities by the network of Indian Railways, Tamil Nadu bus services and the National Highways 67, 45C, 226 and 226 Extn.[16][17] The nearest airport with regular services is Tiruchirappalli International Airport (IATA: TRZ), about 55 kilometres (34?mi) away.[18]\\r\\nThe city and the temple though inland, are at the start of the Cauveri River delta, thus with access to the Bay of Bengal and through it to the Indian Ocean. Along with the temples, the Tamil people completed the first major irrigation network in the 11th century for agriculture, for movement of goods and to control the water flow through the urban center.[19]\\r\\nA spectrum of Hindu temple styles continued to develop from the 5th to the 9th century over the Chalukya era rule as evidenced in Aihole, Badami and Pattadakal, and then with the Pallava era as witnessed at Mamallapuram and other monuments. Thereafter, between 850 and 1280 CE, Cholas emerged as the dominant dynasty.[2][20] The early Chola period saw a greater emphasis on securing their geopolitical boundaries and less emphasis on architecture. In the 10th century, within the Chola empire emerged features such as the multifaceted columns with projecting square capitals. This, states George Michell, signaled the start of the new Chola style.[2][note 1] This South Indian style is most fully realized both in scale and detail in the Brihadeshvara temple built between 1003 and 1010 by the Chola king Rajaraja.[1][2] The architect and engineer of the temple was Kunjara Mallan Raja Raja Rama Perunthachan as stated in inscriptions found at the temple.[citation needed]\\r\\nThe main temple along with its gopurams are from the early 11th century. The temple also saw additions, renovations, and repairs over the next 1,000 years. The raids and wars, particularly between Muslim Sultans who controlled Madurai and Hindu kings who controlled Thanjavur caused damage.[7][note 2] These were repaired by Hindu dynasties that regained control. In some cases, the rulers attempted to renovate the temple with faded paintings, by ordering new murals on top of the older ones. In other cases, they sponsored addition of shrines. The significant shrines of Kartikeya (Murugan), Parvati (Amman) and Nandi are from the 16th and 17th-century Nayaka era.[7][24] Similarly the Dakshinamurti shrine was built later. According to an inscription dated 1801, the Marathas made elaborate repairs to the shrines of Ganesha, Kartikeya, Parvati, Sabhapati which houses the Nataraja bronze, Dakshinamurti, Chandeshvara, mandapas and the prakara walls. They also rebuilt the temple kitchen and put in a new floor in the courtyard.[24]\\r\\nThe Brihadeshvara temple plan and development utilizes the axial and symmetrical geometry rules.[25] The temple complex is a rectangle that is almost two stacked squares, covering 240.79 metres (790.0?ft) east to west, and 121.92 metres (400.0?ft) north to south. In this space are five main sections: the sanctum with the towering superstructure (sri vimana), the Nandi hall in front (Nandi-mandapam) and in between these the main community hall (mukhamandapam), the great gathering hall (mahamandapam) and the pavilion that connects the great hall with the sanctum (ardhamandapam).[26]\\r\\nThe temple complex integrates a large pillared and covered veranda (prakara) in its spacious courtyard, with a perimeter of about 450 metres (1,480?ft) for circumambulation. Outside this pillared veranda there are two walls of enclosure, the outer one being defensive and added in 1777 CE by the French colonial forces with gun-holes with the temple serving as an arsenal. They made the outer wall high, isolating the temple complex area. On its east end is the original main gopuram or gateway that is barrel vaulted. It is less than half the size of the main temple's vimana. Additional structures were added to the original temple after the 11th century, such as a mandapa in its northeast corner and additional gopurams (gateways) on its perimeters to allow people to enter and leave from multiple locations.[26][27] Some of the shrines and structures were added during the Pandya, Nayaka, Vijayanagara and Maratha era, before the colonial era started, and these builders respected the original plans and symmetry rules. Inside the original temple courtyard, along with the main sanctum and Nandi-mandapam are two major shrines, one for Kartikeya and for Parvati. The complex has additional smaller shrines.[26][28][29]\\r\\nThe Brihadisvara temple continued the Hindu temple traditions of South India by adopting architectural and decorative elements, but its scale significantly exceeded the temples constructed before the 11th century. The Chola era architects and artisans innovated the expertise to scale up and build, particularly with heavy stone and to accomplish the 63.4 metres (208?ft) high towering vimana.[28][26]\\r\\nThe temple faces east, and once had a water moat around it. This has been filled up. The fortified wall now runs around this moat. The two walls have ornate gateways called the gopurams. These are made from stone and display entablature. The main gateways are on the east side. The first one is called the Keralantakan tiruvasal, which means the \\"sacred gate of the Keralantakan\\". The word Keralantakan was the surname of king Rajaraja who built it. About a 100 metres (330?ft) ahead is the inner courtyard gopuram called the Rajarajan tiruvasal. This is more decorated than the Keralantakan tiruvasal, such as with its adhishthanam relief work narrating scenes from the Puranas and other Hindu texts.[26] The inner eastern gopuram leads to a vast courtyard, in which the shrines are all signed to east-west and north-west cardinal directions. The complex can be entered either on one axis through a five-story gopuram or with a second access directly to the huge main quadrangle through a smaller free-standing gopuram. The gopuram of the main entrance is 30 m high, smaller than the vimana.[10]\\r\\nThe main temple-related monuments and the great tower is in the middle of this courtyard.[26] Around the main temple that is dedicated to Shiva, are smaller shrines, most of which are aligned axially. These are dedicated to his consort Parvati, his sons Subrahmanya and Ganesha, Nandi, Varahi, Karuvur deva (the guru of Rajaraja Chola), Chandeshvara and Nataraja.[10] The Nandi mandapam has a monolithic seated bull facing the sanctum. In between them are stairs leading to a columned porch and community gathering hall, then an inner mandapa connecting to the pradakshina patha, or circumambulation path. The Nandi (bull) facing the mukh-mandapam weighs about 25 tonnes.[30] It is made of a single stone and is about 2 m in height, 6 m in length and 2.5 m in width. The image of Nandi is a monolithic one and is one of the largest in the country.[31]\\r\\nThe sanctum is at the center of the western square. It is surrounded by massive walls that are divided into levels by sharply cut sculptures and pilasters providing deep bays and recesses. Each side of the sanctuary has a bay with iconography.[32][25] The interior of the sanctum sanctorum hosts an image of the primary deity, Shiva, in the form of a huge stone linga. It is called Karuvarai, a Tamil word that means \\"womb chamber\\". This space is called garbha griha in other parts of India. Only priests are allowed to enter this inner-most chamber.[33]\\r\\nIn the Dravida style, the sanctum takes the form of a miniature vimana. It has the inner wall together with the outer wall creating a path around the sanctum for circumambulation (pradakshina). The entrance is highly decorated. The inside chamber is the sanctum sanctorum, which houses the brihad linga.[2]\\r\\nThe main Vimana (Shikhara) is a massive 16 storeys tower of which 13 are tapering squares. It dominates the main quadrangle. It sits above a 30.18 metres (99.0?ft) sided square.[32] The tower is elaborately articulated with Pilaster, piers(a raised structure), and attached columns which are placed rhythmically covering every surface of the vimana.[34]\\r\\nThe temple is dedicated to Shiva in the form of linga, his abstract aniconic representation. It is 8.7?m (29?ft) high, occupying two storeys of the sanctum.[3][8] It is one of the largest monolithic linga sculptures in India.[31]\\r\\nThe Shaivism temple celebrates all major Hindu traditions by including the primary deities of the Vaishnavism and Shaktism tradition in the great mandapa of the main temple. The distribution of the deities is generally symmetric, except for the east entrance side which provide for the door and walkway. In addition to the main deities, each side provides for dvarapalas (guardians), and various other sculptures. The vestibule has three stone sculptures that is intricately carved, and mural paintings.[36] The ground floor level sanctum walls have the following sculptures:[36]\\r\\nOn the second floor, Shiva's Tripurantaka form in different postures is depicted corresponding to these sculptures. Above these floors, the sri-vimana towers above in thirteen storeys (talas). Above these storeys is a single square block of granite weight eighty tons and 7.77 metres (25.5?ft) side. On top of this block, at its corners are Nandi pairs each about 1.98 metres (6?ft 6?in) by 1.68 metres (5?ft 6?in) in dimension. Above the center of this granite block rises the griva, the sikhara and the finial (stupi) of Tamil Hindu temple architecture. This stupi is 3.81 metres (12.5?ft) in height, and was originally covered with gold (no longer). The sikhara at the top is cupola-shaped and weighs 25 tons.[36] Each storey of this tower is decorated with kutas and salas. The shrinking squares tower architecture of this temple differs from the tower at the Chola temple at Gangaikondasolisvaram, because this is straight in contrast to the latter which is curvilinear. The temple's sri-vimana magnitude has made it a towering landmark for the city.[36]\\r\\nThe upper storey corridor wall of the aditala is carved with 81 of the 108 dance karanas ÿ postures of Natya Sastra. This text is the basis of the Bharathanatyam, the classical dance of Tamil Nadu. The 27 unrepresented karanas are blank blocks of stone, and it is unclear why these were not carved. The 81 postures carved suggest the significance of this classical Indian dance form by early 11th century.[8]\\r\\nThe garbhagriha is square and sits on a plinth. This is moulded and 0.5 metres (1?ft 8?in) thick. It consists of upapitham and adhishthanam, respectively 140 cm and 360 cm think.[8]\\r\\nThe two mandapa, namely maha-mandapa and mukha-mandapa, are square plan structures axially aligned between the sanctum and the Nandi mandapa. The maha-mandapa has six pillars on each side.[37] This too has artwork. The Vitankar and Rajaraja I bronze are here, but these were added much later. The maha-mandapa is flanked by two giant stone dvarapalas. It is linked to the mukha-mandapa by stairs. The entrance of the mukha-mandapa also has dvarapalas. With the mandapa are eight small shrines for dikpalas, or guardian deities of each direction such as Agni, Indra, Varuna, Kubera and others. These were installed during the rule of Chola king Rajendra I.[37]\\r\\nInscriptions indicate that this area also had other iconography from major Hindu traditions during the Chola era, but these are now missing. The original eight shrines included those for Surya (the sun god), Saptamatrikas (seven mothers), Ganesha, Kartikeya, Jyeshtha, Chandra (the moon god), Chandeshvara and Bhairava.[37] Similarly, in the western wall cella was a massive granite Ganesha built during Rajaraja I era, but who is now found in the tiruch-churru-maligai (southern veranda). Of the Shaktism tradition's seven mothers, only Varahi survives in a broken form. Her remnants are now found in a small modern era brick \\"Varahi shrine\\" in the southern side of the courtyard. The original version of the others along with their original Chola shrines are missing.[37]\\r\\nThe temple has an underneath layer of Chola frescoes on the sanctum walls along the circumambulatory pathway. These frescoes which cover floor to ceiling, were discovered in 1931 by S. K. Govindasami of the Anamalai University.[38] The painters used natural pigments and infused it into the wet limestone layer as it was setting in. The Chola frescoes were largely of Shaivism themes. These were restored in the 2000s.[39] The total Chola fresco area is about 670 square metres (7,200?sq?ft), of which about 112 square metres (1,210?sq?ft) had been uncovered as of 2010 in a method that preserves both paintings, a technique developed by Archaeological Survey of India.[38] The frescoes narrate Hindu mythology.[38][40] According to Balasubrahmanyam, most frescoes are related to Shiva, but the 11th century Chola frescoes also show Vishnu, Durga and others, as well as scenes of Chola royalty, courtly and common life.[40]\\r\\nThe later constructions, additions and modifications to the temple curtailed the amount of natural light inside the temple. The frescoes were thus photographed in a limited way and interpreted. According to Sriraman, a complete imaging with better photographic equipment suggests that these historic interpretations were incorrect.[38] For example, a fresco that was previously interpreted as Dakshinamurti Shiva is actually a secular scene of a royal guru meditating under a banyan tree. On the tree are shown peacocks, birds, monkeys, squirrels and owls, plus a cobra. The animals and birds are shown as worried of the cobra, the one's closer to the snake are shown to be more worried.[38] Other parts of the panel similarly show a court listening to a saint. Other show women in different dresses in different dance mudra.[38]\\r\\nSome of the paintings in the sanctum sanctorum and the walls in the passage had been damaged because of the soot that had deposited on them once upon a time. Owing to the continuous exposure to smoke and soot from the lamps and burning of camphor in the sanctum sanctorum over a period of centuries certain parts of the Chola paintings on the circumambulatory passage walls had been badly damaged.[39] The Archaeological Survey of India, for the first time in the world, used its unique de-stucco process to restore 16 Nayak paintings, which were superimposed on 1000-year-old Chola frescoes.[39] These 400-year-old paintings have been mounted on fibre glass boards, displayed at a separate pavilion.[39]\\r\\nThe temple walls have numerous inscriptions in Tamil and Grantha scripts. Many of these begin with customary Sanskrit and Tamil language historical introduction to the king who authorized it, and predominant number of them discuss gifts to the temple or temple personnel, in some cases residents of the city.[41][42]\\r\\nAn inscription on the north wall of enclosure, dated 1011 CE, gives a detailed accounts of people employed and supported by the temple. The inscription gives their wages, roles and names. It includes over 600 names including those of priests, lamp lighters, washermen, tailors, jewelers, potters, carpenters, sacred parasol bearers, dance gurus, dancing girls, singers, male and female musicians, superintendents of performance artists, accountants among others. Their wages was in parcels of land, so their temple employment was likely part time.[43][42]\\r\\nThe temple employed devadasis who were dancers and singers of devotional hymns. Among its numerous inscriptions are frequent gifts that state, \\"to provide for worship, for food to assembly of sannyasis (monks or ascetics) and for repairs\\". According to George Michell, the Thanjavur temple was a major charity institution in its history. It provides free meal for pilgrims, devotees and wayfarers on a daily basis. On days of Hindu festivals, these meals were elaborate and when brahmins were particularly invited and fed.[43][42]\\r\\nBuilt in the year 1010 CE by Raja Raja Chola in Thanjavur, the temple popularly known as the Big Temple. It turned 1000 years old in September 2010. To celebrate the 1000th year of the grand structure, the state government and the town held many cultural events. It was to recall the 275th day of his 25th regal year (1010 CE) when Raja Raja Chola (985ÿ1014 CE) handed over a gold-plated kalasam (copper pot or finial) for the final consecration to crown the vimana, the 59.82-metre tall tower above the sanctum.[44][45][46]\\r\\nTo mark the occasion, the state government organised a Bharathanatyam Yajna, classical dance show under noted dancer Padma Subramaniam. It was jointly organised by the Association of Bharatanatyam Artistes of India (ABHAI) and the Brhan Natyanjali Trust, Thanjavur. To mark the 1000th year anniversary of the building, 1000 dancers from New Delhi, Mumbai, Pune, Tamil Nadu, Andhra Pradesh, Karnataka, Kerala, Singapore, Malaysia and the US danced in concert to the recorded 11 verses of divine music Thiruvisaippa (ninth volume of Thirumurai) composed by Karuvur deva (the guru of Raja Raja Chola). The small town turned into a cultural hub for two days beginning 26 September 2010 as street performers and dancers performed throughout the town.[47][48]\\r\\nOn 26 September 2010 (Big Temple's fifth day of millennium celebrations), as a recognition of Big Temple's contribution to the country's cultural, architectural, epigraphical history, a special ? 5 postage stamp featuring the 216-feet tall giant Raja Gopuram was released by India Post.\\r\\nThe Reserve Bank of India commemorated the event by releasing a ? 5 coin with the model of temple embossed on it.[49][50] A Raja, Cabinet Minister of Communications and Information Technology released the esteemed Brihadeeswarar temple special stamp, the first of which was received by G K Vasan, Cabinet Minister of Shipping.\\r\\nMumbai Mint issued Rs 1000 Commemorative Coin with the same picture as on the Rs 5 coin. It was the first 1000 Rupees coin to be released in the Republic of India coinage. This coin was a Non Circulative Legal Tender (NCLT).[51]\\r\\nOn 1 April 1954, the Reserve Bank of India released a ? 1000 currency note featuring a panoramic view of the Brihadeeswar temple marking its cultural heritage and significance. In 1975, the then government led by Prime Minister Indira Gandhi demonetised all ? 1,000 currency notes in an effort to curtail black money. These notes are now popular among collectors.[52]\\r\\nIn 2010, the then Tamil Nadu chief minister, M Karunanidhi renamed Semmai Rice, a type of high productivity paddy variant, as Raja Rajan-1000 to mark the millennial year of the constructor of the temple, Rajaraja Chola].[53]\\r\\nThe temple \\"testifies the brilliant achievements of the Chola in architecture, sculpture, painting and bronze casting.\\"[54] The temple finds mention in many of the contemporary works of the period like Muvar Ula and Kalingathuparani. According to Chatterjee, the Dravidian architecture attained its supreme form of expression in the temple and it successor, the Brihadeeswarar Temple, Gangaikonda Cholapuram.[55] The temple has been declared as a heritage monument by the Government of India and administered by the Archaeological Survey of India as a protected monument. The temple is one of the most visited tourist attractions in Tamil Nadu.[11]\\r\\nThe temple was declared as a World Heritage Site by UNESCO, along with the Brihadeeswara Temple at Gangaikondacholapuram and Airavatesvara temple at Darasuram that are referred as the Great Living Chola Temples.[5] These three temples have similarities, but each has unique design and sculptural elements.[56] All of the three temples were built by the Cholas between the 10th and 12th centuries CE and they have continued to be supported and used by Hindus. The temples are classified as \\"Great Living\\" as the temples are active in cultural, pilgrimage and worship practises in modern times.[57]\\r\\nThe Brihadishvara temple at Thanjavur is the site of annual dance festivals around February, around the Mahashivratri. Major classical Indian dance form artists, as well as regional teams, perform their repertoire at this Brahan Natyanjali festival over 10 days.[58]\\r\\nThe Temple car was rolled out on its trial run from opposite to Sri Ramar temple on 20 April 2015 witnessed by a large number of people.[59] Nine days later, the maiden procession of the temple car was held. This was the first such procession in this temple held in the past hundred years, according to news reports.[60]\\r\\nKalki Krishnamurthy, a renowned Tamil novelist, has written a historical novel named Ponniyin Selvan, based on the life of Raja Raja Chola I.[61] Balakumaran, another Tamil author has written a novel named Udaiyar themed on the life of Raja Raja Chola I and the construction of the temple.[62]\\r\\nThe temple is currently administered and managed by Babaji Bhonsle, the head of the Thanjavur Maratha royal family. He serves as the hereditary trustee of the palace Devasthanam which continues to manage 88 Chola temples including the Brihadeeswara temple. Tamil groups have been unsuccessfully petitioning the Tamil Nadu government to revoke these rights as he does not belong to the erstwhile Chola royal family.[63]\\r\\nThe temple features many sculptures, reliefs and murals:[64]\\r\\nShiva with a begging bowl as a saddhu (monk, Bhikshatana)\\r\\nArdhanarishvara (half Shiva, half Parvati) symbolizing that the male and female principles are inseparable.[65]\\r\\nGanesha is depicted both in the main temple and a separate shrine.\\r\\nSeparate Ganesha shrine with temple corridor in the back.\\r\\nSubrahmanyar shrine in the north part of the courtyard. Also called Murugan, Kartikeya or Skanda.\\r\\nChandeshvara shrine. On right is the wall of main temple, in back the eastern gopuram. Chandeshvara is a meditating yogi and Nayanmar Bhakti movement saint.\\r\\nNarasimha avatar of Vishnu killing the demon who persecutes people for their religious beliefs.\\r\\nLakshmi statue, a Vaishnava sculpture reverentially displayed.\\r\\nGaja-lakshmi mural, another Vaishnavism themed artwork.\\r\\nVishnu sculpture at the Shaivism temple.\\r\\nA yoga and meditation relief; the temple portrays numerous secular and saint scenes.\\r\\nKalpavrisksha mythology with kama depiction (gopuram).\\r\\nNandi shrine\\r\\nSculpture\\r\\nSculpture\\r\\nVimana outer wall detail\\r\\nReliefs adorning the stairs\\r\\nRelief detail\\r\\nRelief detail\\r\\nVimana opening flanked by Dvarapalakas\\r\\nEntrance\\r\\nVimana view\\r\\nFront view with Nandi shrine in foreground\\r\\nFront view with Nandi shrine in foreground\\r\\nLeft profile view","input":"Who was the chola king under whose region the brihadeeswara temple of tanjore was constructed?"},{"output":"Charles E. Rushmore (December 2, 1857 ÿ October 31, 1931) was an American businessman and attorney","context":"Charles E. Rushmore (December 2, 1857 ÿ October 31, 1931) was an American businessman and attorney for whom Mount Rushmore is named. Born in New York City, he was the son of Edward Carmen Rushmore and Mary Eliza (ne Dunn) Rushmore, of Tuxedo Park, NY. He was married to the former Jeanette E. Carpenter.[1]\\r\\nIn 1883, a tin mine, the Etta, was opened, which caused excitement among Eastern investors.[2] In 1885 Rushmore was in the Black Hills of South Dakota to check the titles to properties for an eastern mining company owned by James Wilson. Although an Easterner, Rushmore quickly made friends among the miners and prospectors. One day he was returning to headquarters of the Harney Peak Consolidated Tin Co., Ltd., located at Pine Camp, which was north of the great granite peak soon to bear his name. With him were a local business man, and William W. Challis, a prospector and guide. As they neared the mountain, Rushmore turned to Challis and asked its name. Challis jestingly replied: \\"Never had any but it has now - we'll call the thing Rushmore.\\"\\r\\nAccording to rancher Jerry Urbanek, Rushmore returned to the Black Hills annually to hunt big game. One day, while accompanied by Ted Brockett of Keystone, South Dakota, Rushmore asked the name of the mountain and was told that it was Slaughterhouse Rock. Rushmore joked that his annual treks to the Hills had earned him the right to have the mountain named after himself. \\"So just for the hell of it,\\" Urbanek claimed, the locals started calling the hill Mount Rushmore.[3]\\r\\nWhatever the precise story, the United States Board of Geographic Names officially recognized the name \\"Mount Rushmore\\" in June 1930. Forty years after the initial 1885 naming, Rushmore donated $5000 towards Gutzon Borglum's sculpture of the four presidents' heads on the mountain - the largest single contribution. The Memorial was dedicated by President Coolidge on August 10, 1927.\\r\\nRushmore was also a member of the Phi Gamma Delta Fraternity. Mr. Rushmore was also a member of Kane Lodge No. 454, F&AM (NYC).","input":"How did mt. rushmore get its name?"},{"output":"Jodi Marie Marzorati Benson","context":"Jodi Marie Marzorati Benson (born October 10, 1961)[1] is an American actress, voice actress and soprano singer. She is best known for providing both the speaking and the singing voice of Disney's Princess Ariel in The Little Mermaid and its sequel, prequel, and television series spinoff. Benson voiced the character Barbie in the 1999 movie Toy Story 2 and its 2010 Academy Award-winning sequel Toy Story 3. She also voiced Barbie in the Toy Story toon Hawaiian Vacation. For her contributions to the Disney company, Benson was named a Disney Legend in 2011.[2]\\r\\nBenson was the original voice of Ariel in the Academy Award-winning Walt Disney Pictures animated feature film The Little Mermaid and continues to perform Ariel and the bubbly voice of \\"Barbie\\" in Disney/Pixar's Best Picture Golden Globe winner Toy Story 2 and Academy Award winner Toy Story 3. She also gave voice to the spirited \\"Weebo\\" in Disney's live action Flubber, starring Robin Williams. For Warner Bros., she created the voice of Thumbelina in 1994, a Don Bluth animated feature film with songs by Barry Manilow.[3] Jodi's other projects include Tinkerbell: Secret of the Wings, The Little Mermaid: Ariel's Beginning, The Little Mermaid II: Return to the Sea, Lady and the Tramp II: Scamp's Adventure, 101 Dalmatians II: Patch's London Adventure, Balto II: Wolf Quest, and Balto III: Wings of Change. She appeared as Patrick Dempsey's assistant Sam, in Disneys live-action feature film Enchanted. While being a Disney Legend, she also voiced Jane Doe and Patsy Smiles in Cartoon Network's Camp Lazlo. She also voiced the character Tula in Fox's \\"Pirates of Dark water\\" series.\\r\\n\\r\\n\\r\\nBenson's debut on Broadway was in the 1983 Kenny Ortega-directed \\"Marilyn: An American Fable\\". Other Broadway credits include a starring role in the Broadway musical Smile, where she introduced a song called \\"Disneyland\\". Howard Ashman, the lyricist of Smile, would go on to write the lyrics for The Little Mermaid. She describes the song \\"Disneyland\\" at the \\"Smile\\" Reunion concert held on Sept. 22, 2014, \\"This is the first piece of the puzzle of my life, the first step of the journey, so to speak\\".[citation needed] Benson also sings \\"Disneyland\\" on a compilation CD called Unsung Musicals. In 1989, Benson appeared in the Broadway musical, Welcome to the Club, alongside Samuel E. Wright, who performed the voice for Sebastian the Crab in The Little Mermaid.\\r\\nIn 1992, Benson received a Tony Award nomination for Best Actress in a Musical for her role as Polly Baker in Crazy For You. She played the narrator in Joseph And The Amazing Technicolor Dreamcoat in 1998.\\r\\nBenson also played the Queen in a one-night concert version of Rodgers & Hammerstein's Cinderella at the Nashville Symphony Orchestra in May 2010.[4]\\r\\nShe was at the 2012 SYTA conference singing her signature song Part of Your World on Monday, August 27, 2012.\\r\\nBenson has been the guest artist for the Candlelight Processional for 5 years at Walt Disney World including December 10ÿ13, 2012.[5]\\r\\nShe joined the \\"2013 Spring Pops\\" on May 14ÿ15, 2013 as a guest soloist with the Boston Pops.\\r\\nBenson can be heard on over a dozen recordings and has a six-part DVD series entitled Baby Faith from the creators of Baby Einstein. Her animated TV series include the Emmy Award-winning Camp Lazlo for the Cartoon Network, The Little Mermaid, Batman Beyond, The Grim Adventures of Billy and Mandy, The Wild Thornberrys, Barbie, Hercules: Zero to Hero, P. J. Sparkles, and the series Sofia the First for Disney as well as many others.\\r\\nOn the concert stage, Benson has performed as a concert soloist with symphonies all over the world, including The Boston Pops, The Philly Pops (conductor: Peter Nero), The Hollywood Bowl Orchestra (conductor: John Mauceri), The National Symphony (conductor: Marvin Hamlisch), Cleveland, Dallas, Tokyo, San Francisco and Chicago Symphonies, to name a few. She starred in the Kennedy Center Honors for Ginger Rogers, and in Disney's Premiere in Central Park with Pocahontas, The Walt Disney World 25th Anniversary Spectacular and Disney's 100 Years of Magic. Benson is the resident guest soloist for the Walt Disney Company/Disney Cruise Line and ambassador for feature animation.\\r\\nOn June 6, 2016, Benson performed the role of Ariel at the Hollywood Bowl's concert performance of The Little Mermaid.[6]\\r\\nIn late 1986, Benson first heard of the audition for The Little Mermaid through lyricist and playwright Howard Ashman. The two had just worked together in the Broadway show Smile until its run ended early. He knew she would be the perfect fit for the role.[7][8] After hearing the demo for \\"Part of Your World\\", she sang a small part of it on tape where it was later sent to Disney executives. Before her audition for The Little Mermaid, she was primarily a stage actress. It was Ashman's first Disney project. In early 1988, Benson won the role of Ariel.[7][9]\\r\\nBenson was born and raised in a Catholic environment[10], graduating from Boylan Central Catholic High School in Rockford, IL.[11] She married actor/singer Ray Benson in 1984.[12] They have two children, McKinley and Delaney.[13]","input":"Who is the voice of the little mermaid?"},{"output":"January 1962","context":"","input":"When was the first navy seal team formed?"},{"output":"the period between 1603 and 1868 in the history of Japan, when Japanese society was under the rule of the Tokugawa shogunate","context":"The Edo period (??ry, Edo jidai) or Tokugawa period (?ܤ?ry, Tokugawa jidai) is the period between 1603 and 1868 in the history of Japan, when Japanese society was under the rule of the Tokugawa shogunate and the country's 300 regional daimy. The period was characterized by economic growth, strict social order, isolationist foreign policies, a stable population, \\"no more wars\\", and popular enjoyment of arts and culture. The shogunate was officially established in Edo on March 24, 1603, by Tokugawa Ieyasu. The period came to an end with the Meiji Restoration on May 3, 1868, after the fall of Edo.\\r\\n\\r\\n\\r\\nA revolution took place from the time of the Kamakura shogunate, which existed with the Tenn's court, to the Tokugawa, when the samurai became the unchallenged rulers in what historian Edwin O. Reischauer called a \\"centralized feudal\\" form of shogunate. Instrumental in the rise of the new-existing bakufu was Tokugawa Ieyasu, the main beneficiary of the achievements of Oda Nobunaga and Toyotomi Hideyoshi. Already powerful, Ieyasu profited by his transfer to the rich Kant area. He maintained two million koku of land, a new headquarters at Edo, a strategically situated castle town (the future Tokyo), and also had an additional two million koku of land and thirty-eight vassals under his control. After Hideyoshi's death, Ieyasu moved quickly to seize control from the Toyotomi family.\\r\\nIeyasu's victory over the western daimys at the Battle of Sekigahara (October 21, 1600, or in the Japanese calendar on the 15th day of the ninth month of the fifth year of the Keich era) gave him control of all Japan. He rapidly abolished numerous enemy daimy houses, reduced others, such as that of the Toyotomi, and redistributed the spoils of war to his family and allies. Ieyasu still failed to achieve complete control of the western daimys, but his assumption of the title of shgun helped consolidate the alliance system. After further strengthening his power base, Ieyasu installed his son Hidetada (1579ÿ1632) as shgun and himself as retired shgun in 1605. The Toyotomi were still a significant threat, and Ieyasu devoted the next decade to their eradication. In 1615, the Tokugawa army destroyed the Toyotomi stronghold at Osaka.\\r\\nThe Tokugawa (or Edo) period brought 250 years of stability to Japan. The political system evolved into what historians call bakuhan, a combination of the terms bakufu and han (domains) to describe the government and society of the period.[1] In the bakuhan, the shgun had national authority and the daimys had regional authority. This represented a new unity in the feudal structure, which featured an increasingly large bureaucracy to administer the mixture of centralized and decentralized authorities. The Tokugawa became more powerful during their first century of rule: land redistribution gave them nearly seven million koku, control of the most important cities, and a land assessment system reaping great revenues.\\r\\nThe feudal hierarchy was completed by the various classes of daimy. Closest to the Tokugawa house were the shinpan, or \\"related houses\\". They were twenty-three daimys on the borders of Tokugawa lands, all directly related to Ieyasu. The shinpan held mostly honorary titles and advisory posts in the bakufu. The second class of the hierarchy were the fudai, or \\"house daimys\\", rewarded with lands close to the Tokugawa holdings for their faithful service. By the 18th century, 145 fudai controlled such smaller han, the greatest assessed at 250,000 koku. Members of the fudai class staffed most of the major bakufu offices. Ninety-seven han formed the third group, the tozama (outside vassals), former opponents or new allies. The tozama were located mostly on the peripheries of the archipelago and collectively controlled nearly ten million koku of productive land. Because the tozama were least trusted of the daimys, they were the most cautiously managed and generously treated, although they were excluded from central government positions.\\r\\nThe Tokugawa shogunate not only consolidated their control over a reunified Japan, they also had unprecedented power over the emperor, the court, all daimys and the religious orders. The emperor was held up as the ultimate source of political sanction for the shgun, who ostensibly was the vassal of the imperial family. The Tokugawa helped the imperial family recapture its old glory by rebuilding its palaces and granting it new lands. To ensure a close tie between the imperial clan and the Tokugawa family, Ieyasu's granddaughter was made an imperial consort in 1619.\\r\\nA code of laws was established to regulate the daimy houses. The code encompassed private conduct, marriage, dress, types of weapons and numbers of troops allowed; required feudal lords to reside in Edo every other year (the sankin-ktai system); prohibited the construction of ocean-going ships; proscribed Christianity; restricted castles to one per domain (han) and stipulated that bakufu regulations were the national law. Although the daimys were not taxed per se, they were regularly levied for contributions for military and logistical support and for such public works projects as castles, roads, bridges and palaces. The various regulations and levies not only strengthened the Tokugawa but also depleted the wealth of the daimys, thus weakening their threat to the central administration. The han, once military-centered domains, became mere local administrative units. The daimys did have full administrative control over their territory and their complex systems of retainers, bureaucrats and commoners. Loyalty was exacted from religious foundations, already greatly weakened by Nobunaga and Hideyoshi, through a variety of control mechanisms.\\r\\nLike Hideyoshi, Ieyasu encouraged foreign trade but also was suspicious of outsiders. He wanted to make Edo a major port, but once he learned that the Europeans favored ports in Kysh and that China had rejected his plans for official trade, he moved to control existing trade and allowed only certain ports to handle specific kinds of commodities.\\r\\nThe beginning of the Edo period coincides with the last decades of the Nanban trade period during which intense interaction with European powers, on the economic and religious plane, took place. It is at the beginning of the Edo period that Japan built its first ocean-going Western-style warships, such as the San Juan Bautista, a 500-ton galleon-type ship that transported a Japanese embassy headed by Hasekura Tsunenaga to the Americas and then to Europe. Also during that period, the bakufu commissioned around 720 Red Seal Ships, three-masted and armed trade ships, for intra-Asian commerce. Japanese adventurers, such as Yamada Nagamasa, used those ships throughout Asia.\\r\\nThe \\"Christian problem\\" was, in effect, a problem of controlling both the Christian daimys in Kysh and their trade with the Europeans. By 1612, the shgun's retainers and residents of Tokugawa lands had been ordered to forswear Christianity. More restrictions came in 1616 (the restriction of foreign trade to Nagasaki and Hirado, an island northwest of Kysh), 1622 (the execution of 120 missionaries and converts), 1624 (the expulsion of the Spanish), and 1629 (the execution of thousands of Christians). Finally, the Closed Country Edict of 1635 prohibited any Japanese from traveling outside Japan or, if someone left, from ever returning. In 1636 the Dutch were restricted to Dejima, a small artificial islandand thus, not true Japanese soilin Nagasaki's harbor.\\r\\nThe shogunate perceived Catholic Christianity to be an extremely destabilizing factor, and so decided to persecute it. The Shimabara Rebellion of 1637ÿ38, in which discontented Catholic Christian samurai and peasants rebelled against the bakufuand Edo called in Dutch ships to bombard the rebel strongholdmarked the end of the Christian movement, although some Catholic Christians survived by going underground, the so-called Kakure Kirishitan. Soon thereafter, the Portuguese were permanently expelled, members of the Portuguese diplomatic mission were executed, all subjects were ordered to register at a Buddhist or Shinto temple, and the Dutch and Chinese were restricted, respectively, to Dejima and to a special quarter in Nagasaki. Besides small trade of some outer daimys with Korea and the Ryukyu Islands, to the southwest of Japan's main islands, by 1641, foreign contacts were limited by the policy of sakoku to Nagasaki.\\r\\nThe last Jesuit was either killed or reconverted by 1644[2] and by the 1660s, Christianity was almost completely eradicated, and its external political, economic, and religious influence on Japan became quite limited.[3] Only China, the Dutch East India Company, and for a short period, the English, enjoyed the right to visit Japan during this period, for commercial purposes only, and they were restricted to the Dejima port in Nagasaki. Other Europeans who landed on Japanese shores were put to death without trial.\\r\\nEdo society had an elaborate social structure, in which everyone knew their place and level of prestige. At the top were the Emperor and the court nobility, invincible in prestige but weak in power. Next came the shgun, daimys and layers of feudal lords whose rank was indicated by their closeness to the Tokugawa. They had power. The daimys comprised about 250 local lords of local \\"han\\" with annual outputs of 50,000 or more bushels of rice. The upper strata was much given to elaborate and expensive rituals, including elegant architecture, landscaped gardens, Noh drama, patronage of the arts, and the tea ceremony.[4]\\r\\nAfter a long period of inner conflict, the first goal of the newly established Tokugawa government was to pacify the country. It created a balance of power that remained (fairly) stable for the next 250 years, influenced by Confucian principles of social order. Most samurai lost their direct possession of the land: the daimys took over their land. The samurai had a choice: give up their sword and become peasants, or move to the city of their feudal lord and become a paid retainer. Only a few land samurai remained in the border provinces of the north, or as direct vassals of the shgun, the 5,000 so-called hatamoto. The daimys were put under tight control of the shogunate. Their families had to reside in Edo; the daimys themselves had to reside in Edo for one year and in their province (han) for the next. This system was called sankin-ktai.\\r\\nThe individual had no legal rights in Tokugawa Japan. The family was the smallest legal entity, and the maintenance of family status and privileges was of great importance at all levels of society. The 1711 Gotke reij was compiled from over 600 statutes promulgated between 1597 and 1696.[5]\\r\\nDuring the Tokugawa period, the social order, based on inherited position rather than personal merits, was rigid and highly formalized. At the top were the emperor and court nobles (kuge), together with the shgun and daimys. Below them the population was divided into four classes in a system known as mibunsei (㶇): the samurai on top (about 5% of the population) and the peasants (more than 80% of the population) on the second level. Below the peasants were the craftsmen, and even below them, on the fourth level, were the merchants.[6] Only the peasants lived in the rural areas. Samurai, craftsmen and merchants lived in the cities that were built around the daimys' castles, each restricted to their own quarter.\\r\\nOutside the four classes were the so-called eta and hinin, those whose professions broke the taboos of Buddhism. Eta were butchers, tanners and undertakers. Hinin served as town guards, street cleaners, and executioners. Other outsiders included the beggars, entertainers, and prostitutes. The word eta literally translates to \\"filthy\\" and hinin to \\"non-humans\\", a thorough reflection of the attitude held by other classes that the eta and hinin were not even people.[7] Hinin were only allowed inside a special quarter of the city. Other persecution of the hinin included disallowing them from wearing robes longer than knee-length and the wearing of hats.[7] Sometimes eta villages were not even printed on official maps. A sub-class of hinin who were born into their social class had no option of mobility to a different social class whereas the other class of hinin who had lost their previous class status could be reinstated in Japanese society.[7] In the 19th century the umbrella term burakumin was coined to name the eta and hinin because both classes were forced to live in separate village neighborhoods.[8] The eta, hinin and burakumin classes were officially abolished in 1871.[7] However, their cultural and societal impact, including some forms of discrimination, continued into modern times.[8]\\r\\nThe Edo period bequeathed a vital commercial sector to be in burgeoning urban centers, a relatively well-educated elite, a sophisticated government bureaucracy, productive agriculture, a closely unified nation with highly developed financial and marketing systems, and a national infrastructure of roads.\\r\\nEconomic development during the Tokugawa period included urbanization, increased shipping of commodities, a significant expansion of domestic and, initially, foreign commerce, and a diffusion of trade and handicraft industries. The construction trades flourished, along with banking facilities and merchant associations. Increasingly, han authorities oversaw the rising agricultural production and the spread of rural handicrafts.\\r\\nBy the mid-18th century, Edo had a population of more than one million, and Osaka and Kyoto each had more than 400,000 inhabitants. Many other castle towns grew as well. Japan had almost zero population growth between the 1720s and 1820s, often attributed to lower birth rates in response to widespread famine, but some historians have presented different theories, such as a high rate of infanticide artificially controlling population.[9] Osaka and Kyoto became busy trading and handicraft production centers, while Edo was the center for the supply of food and essential urban consumer goods.\\r\\nRice was the base of the economy. About 80% of the people were rice farmers.[10] Rice production increased steadily, but population remained stable, so prosperity increased. Rice paddies grew from 1.6 million ch in 1600 to 3 million by 1720.[11] Improved technology helped farmers control the all-important flow of irrigation to their paddies. The daimys operated several hundred castle towns, which became loci of domestic trade. Large-scale rice markets developed, centered on Edo and saka.[12] In the cities and towns, guilds of merchants and artisans met the growing demand for goods and services. The merchants, while low in status, prospered, especially those with official patronage. Merchants invented credit instruments to transfer money, currency came into common use, and the strengthening credit market encouraged entrepreneurship.[13] The daimys collected the taxes from the peasants in the form of rice. Taxes were high, about 40% of the harvest. The rice was sold at the fudasashi market in Edo. To raise money, the daimys used forward contracts to sell rice that was not even harvested yet. These contracts were similar to modern futures trading.\\r\\nIt was during the Edo period that Japan developed an advanced forest management policy. Increased demand for timber resources for construction, shipbuilding and fuel had led to widespread deforestation, which resulted in forest fires, floods and soil erosion. In response the shgun, beginning around 1666, instituted a policy to reduce logging and increase the planting of trees. The policy mandated that only the shgun and daimys could authorize the use of wood. By the 18th century, Japan had developed detailed scientific knowledge about silviculture and plantation forestry.[14]\\r\\nDuring the period, Japan studied Western sciences and techniques (called rangaku, \\"Dutch studies\\") through the information and books received through the Dutch traders in Dejima. The main areas that were studied included geography, medicine, natural sciences, astronomy, art, languages, physical sciences such as the study of electrical phenomena, and mechanical sciences as exemplified by the development of Japanese clockwatches, or wadokei, inspired by Western techniques.\\r\\nThe flourishing of Neo-Confucianism was the major intellectual development of the Tokugawa period. Confucian studies had long been kept active in Japan by Buddhist clerics, but during the Tokugawa period, Confucianism emerged from Buddhist religious control. This system of thought increased attention to a secular view of man and society. The ethical humanism, rationalism, and historical perspective of neo-Confucian doctrine appealed to the official class. By the mid-17th century, neo-Confucianism was Japan's dominant legal philosophy and contributed directly to the development of the kokugaku (national learning) school of thought.\\r\\nAdvanced studies and growing applications of neo-Confucianism contributed to the transition of the social and political order from feudal norms to class- and large-group-oriented practices. The rule of the people or Confucian man was gradually replaced by the rule of law. New laws were developed, and new administrative devices were instituted. A new theory of government and a new vision of society emerged as a means of justifying more comprehensive governance by the bakufu. Each person had a distinct place in society and was expected to work to fulfill his or her mission in life. The people were to be ruled with benevolence by those whose assigned duty it was to rule. Government was all-powerful but responsible and humane. Although the class system was influenced by neo-Confucianism, it was not identical to it. Whereas soldiers and clergy were at the bottom of the hierarchy in the Chinese model, in Japan, some members of these classes constituted the ruling elite.\\r\\nMembers of the samurai class adhered to bushi traditions with a renewed interest in Japanese history and in cultivation of the ways of Confucian scholar-administrators. Another special way of lifechnindalso emerged. Chnind (\\"the way of the townspeople\\") was a distinct culture that arose in cities such as Osaka, Kyoto, and Edo. It encouraged aspiration to bushido qualitiesdiligence, honesty, honor, loyalty, and frugalitywhile blending Shinto, neo-Confucian, and Buddhist beliefs. Study of mathematics, astronomy, cartography, engineering, and medicine were also encouraged. Emphasis was placed on quality of workmanship, especially in the arts.\\r\\nFor the first time, urban populations had the means and leisure time to support a new mass culture. Their search for enjoyment became known as ukiyo (the floating world), an ideal world of fashion, popular entertainment, and the discovery of aesthetic qualities in objects and actions of everyday life. This increasing interest in pursuing recreational activities helped to develop an array of new industries, many of which could be found in an area known as Yoshiwara. The region was better known for being the center of Edos developing sense of elegance and refinement. This place of pleasure and luxury became a destination for the elite and wealthy merchants who wished to flaunt their fortune.[15] Their economy relied primarily on the patronage of such individuals in order to sustain itself. For many of those who inhabited and worked in this region maintaining the illusion of grandeur was the only way of supporting their business.\\r\\nYoshiwara was home to mostly women who, due to unfortunate circumstances, found themselves working in this secluded environment. Combining factors such as rent, value of their employment contract, cost of clothing, make-up, gift giving, and other expenses ensured that many would spend their entire lives working to pay off their debts. These females were expected to perform dances, sing, play an instrument, gossip or provide companionship so that their guests would come again. As a result, the region developed its own culture which, in turn, determined what would be popular in the rest of the country. This was particularly true for fashion because a woman's identity was determined by her clothing, specifically it clarified what her profession and status was within that field. The quality of her attire ensured that she stood out from the rest of her competition. It was her only means of establishing a reputation and helped to market her talents. However, Yoshiwara also possessed a seedier side. Much of the business conducted here incorporated the use of prostitution as a means to deal with the women's cost of living. As a result, since its establishment was first authorised by Toyotomi Hideyoshi in 1589,[16] this area became the country's government sanctioned red-light district. This designation lasted for about 250 years.\\r\\nProfessional female entertainers (geisha), music, popular stories, Kabuki and bunraku (puppet theater), poetry, a rich literature, and art, exemplified by beautiful woodblock prints (known as ukiyo-e), were all part of this flowering of culture. Literature also flourished with the talented examples of the playwright Chikamatsu Monzaemon (1653ÿ1724) and the poet, essayist, and travel writer Matsuo Bash (1644ÿ94).\\r\\nMatsumura Keibun is one of the most significant painters of this period. His works commonly included realistic depictions of birds, flowers and animals.[17]\\r\\nUkiyo-e is a genre of painting and printmaking that developed in the late 17th century, at first depicting the entertainments of the pleasure districts of Edo, such as courtesans and kabuki actors. Harunobu produced the first full-colour nishiki-e prints in 1765, a form that has become synonymous to most with ukiyo-e. The genre reached a peak in technique towards the end of the century with the works of such artists as Kiyonaga and Utamaro. As the Edo period came to an end a great diversity of genres proliferated: warriors, nature, folklore, and the landscapes of Hokusai and Hiroshige. The genre declined throughout the rest of the century in the face of modernization that saw ukiyo-e as both old-fashioned and laborious to produce compared to Western technologies. Ukiyo-e was a primary part of the wave of Japonism that swept Western art in the late 19th century.\\r\\nBuddhism and Shinto were both still important in Tokugawa Japan. Buddhism, together with neo-Confucianism, provided standards of social behavior. Although Buddhism was not as politically powerful as it had been in the past, Buddhism continued to be espoused by the upper classes. Proscriptions against Christianity benefited Buddhism in 1640 when the bakufu ordered everyone to register at a temple. The rigid separation of Tokugawa society into han, villages, wards, and households helped reaffirm local Shinto attachments. Shinto provided spiritual support to the political order and was an important tie between the individual and the community. Shinto also helped preserve a sense of national identity.\\r\\nShinto eventually assumed an intellectual form as shaped by neo-Confucian rationalism and materialism. The kokugaku movement emerged from the interactions of these two belief systems. Kokugaku contributed to the emperor-centered nationalism of modern Japan and the revival of Shinto as a national creed in the 18th and 19th centuries. The Kojiki, Nihon Shoki, and Man'ysh were all studied anew in the search for the Japanese spirit. Some purists in the kokugaku movement, such as Motoori Norinaga, even criticized the Confucian and Buddhist influencesin effect, foreign influencesfor contaminating Japan's ancient ways. Japan was the land of the kami and, as such, had a special destiny.[18]\\r\\nThe Edo period was characterized by an unprecedented series of economic developments (despite termination of contact with the outside world) and cultural maturation, especially in terms of theater, music, and other entertainment. For example, a poetic meter for music called kinsei kouta-ch was invented during this time[19] and is still used today in folk songs. Music and theater were influenced by the social gap between the noble and commoner classes, and different arts became more defined as this gap widened. Several different types of kabuki (puppet acting) emerged. Some, such as shibaraku, were only available at a certain time of year, while some companies only performed for nobles. Fashion trends, satirization of local news stories, and advertisements were often part of kabuki theater, as well.[20]\\r\\nThe end of this period is specifically called the late Tokugawa shogunate. The cause for the end of this period is controversial but is recounted as the forcing of Japan's opening to the world by Commodore Matthew Perry of the US Navy, whose armada (known by Japanese as \\"the black ships\\") fired weapons from Edo Bay. Several artificial land masses were created to block the range of the armada, and this land remains in what is presently called the Odaiba district.\\r\\nThe Tokugawa did not eventually collapse simply because of intrinsic failures. Foreign intrusions helped to precipitate a complex political struggle between the bakufu and a coalition of its critics. The continuity of the anti-bakufu movement in the mid-19th century would finally bring down the Tokugawa. Historians consider that a major contributing factor to the decline of the Tokugawa was \\"poor management of the central government by the shgun, which caused the social classes in Japan to fall apart\\".[attribution needed][21] From the outset, the Tokugawa attempted to restrict families' accumulation of wealth and fostered a \\"back to the soil\\" policy, in which the farmer, the ultimate producer, was the ideal person in society.\\r\\nDespite these efforts to restrict wealth and partly because of the extraordinary period of peace, the standard of living for urban and rural dwellers alike grew significantly during the Tokugawa period. Better means of crop production, transport, housing, food, and entertainment were all available, as was more leisure time, at least for urban dwellers. The literacy rate was high for a preindustrial society (by some estimates the literacy rate in the city of Edo was 80 percent), and cultural values were redefined and widely imparted throughout the samurai and chnin classes. Despite the reappearance of guilds, economic activities went well beyond the restrictive nature of the guilds, and commerce spread and a money economy developed. Although government heavily restricted the merchants and viewed them as unproductive and usurious members of society, the samurai, who gradually became separated from their rural ties, depended greatly on the merchants and artisans for consumer goods, artistic interests, and loans. In this way, a subtle subversion of the warrior class by the chnin took place.\\r\\nA struggle arose in the face of political limitations that the shgun imposed on the entrepreneurial class. The government ideal of an agrarian society failed to square with the reality of commercial distribution. A huge government bureaucracy had evolved, which now stagnated because of its discrepancy with a new and evolving social order. Compounding the situation, the population increased significantly during the first half of the Tokugawa period. Although the magnitude and growth rates are uncertain, there were at least 26 million commoners and about four million members of samurai families and their attendants when the first nationwide census was taken in 1721. Drought, followed by crop shortages and starvation, resulted in twenty great famines between 1675 and 1837. During the Tokugawa period, there were 154 famines, of which 21 were widespread and serious.[22] Peasant unrest grew, and by the late 18th century, mass protests over taxes and food shortages had become commonplace. Newly landless families became tenant farmers, while the displaced rural poor moved into the cities. As the fortunes of previously well-to-do families declined, others moved in to accumulate land, and a new, wealthy farming class emerged. Those people who benefited were able to diversify production and to hire laborers, while others were left discontented. Many samurai fell on hard times and were forced into handicraft production and wage jobs for merchants.\\r\\nAlthough Japan was able to acquire and refine a wide variety of scientific knowledge, the rapid industrialization of the West during the 18th century created a material gap in terms of technologies and armament between Japan and the West, forcing it to abandon its policy of seclusion and contributing to the end of the Tokugawa regime.\\r\\nWestern intrusions were on the increase in the early 19th century. Russian warships and traders encroached on Karafuto (called Sakhalin under Russian and Soviet control) and on the Kuril Islands, the southernmost of which are considered by the Japanese as the northern islands of Hokkaid. A British warship entered Nagasaki harbour searching for enemy Dutch ships in 1808, and other warships and whalers were seen in Japanese waters with increasing frequency in the 1810s and 1820s. Whalers and trading ships from the United States also arrived on Japan's shores. Although the Japanese made some minor concessions and allowed some landings, they largely attempted to keep all foreigners out, sometimes using force. Rangaku became crucial not only in understanding the foreign \\"barbarians\\" but also in using the knowledge gained from the West to fend them off.\\r\\nBy the 1830s, there was a general sense of crisis. Famines and natural disasters hit hard, and unrest led to a peasant uprising against officials and merchants in Osaka in 1837. Although it lasted only a day, the uprising made a dramatic impression. Remedies came in the form of traditional solutions that sought to reform moral decay rather than address institutional problems. The shgun's advisers pushed for a return to the martial spirit, more restrictions on foreign trade and contacts, suppression of rangaku, censorship of literature, and elimination of \\"luxury\\" in the government and samurai class. Others sought the overthrow of the Tokugawa and espoused the political doctrine of sonn ji (revere the emperor, expel the barbarians), which called for unity under imperial rule and opposed foreign intrusions. The bakufu persevered for the time being amidst growing concerns over Western successes in establishing colonial enclaves in China following the First Opium War of 1839ÿ1842. More reforms were ordered, especially in the economic sector, to strengthen Japan against the Western threat.\\r\\nJapan turned down a demand from the United States, which was greatly expanding its own presence in the Asia-Pacific region, to establish diplomatic relations when Commodore James Biddle appeared in Edo Bay with two warships in July 1846.\\r\\nWhen Commodore Matthew C. Perry's four-ship squadron appeared in Edo Bay in July 1853, the bakufu was thrown into turmoil. The chairman of the senior councillors, Abe Masahiro (1819ÿ1857), was responsible for dealing with the Americans. Having no precedent to manage this threat to national security, Abe tried to balance the desires of the senior councillors to compromise with the foreigners, of the emperor who wanted to keep the foreigners out, and of the daimys who wanted to go to war. Lacking consensus, Abe decided to compromise by accepting Perry's demands for opening Japan to foreign trade while also making military preparations. In March 1854, the Treaty of Peace and Amity (or Treaty of Kanagawa) opened two ports to American ships seeking provisions, guaranteed good treatment to shipwrecked American sailors, and allowed a United States consul to take up residence in Shimoda, a seaport on the Izu Peninsula, southwest of Edo. The Treaty of Amity and Commerce Between the U.S. and Japan (Harris Treaty), opening still more areas to American trade, was forced on the bakufu five years later.\\r\\nThe resulting damage to the bakufu was significant. The devalued price for gold in Japan was one immediate, enormous effect.[23] The European and American traders purchased gold for its original price on the world market and then sold it to the Chinese for triple the price.[23] Along with this, cheap goods from these developed nations, like finished cotton, flooded the market forcing many Japanese out of business.[23] Debate over government policy was unusual and had engendered public criticism of the bakufu. In the hope of enlisting the support of new allies, Abe, to the consternation of the fudai, had consulted with the shinpan and tozama daimys, further undermining the already weakened bakufu. In the Ansei Reform (1854ÿ1856), Abe then tried to strengthen the regime by ordering Dutch warships and armaments from the Netherlands and building new port defenses. In 1855, a naval training school with Dutch instructors was set up at Nagasaki, and a Western-style military school was established at Edo; by the next year, the government was translating Western books. Opposition to Abe increased within fudai circles, which opposed opening bakufu councils to tozama daimys, and he was replaced in 1855 as chairman of the senior councilors by Hotta Masayoshi (1810ÿ1864).\\r\\nAt the head of the dissident faction was Tokugawa Nariaki, who had long embraced a militant loyalty to the emperor along with anti-foreign sentiments, and who had been put in charge of national defense in 1854. The Mito schoolbased on neo-Confucian and Shinto principleshad as its goal the restoration of the imperial institution, the turning back of the West, and the founding of a world empire under the divine Yamato dynasty.\\r\\nIn the final years of the Tokugawas, foreign contacts increased as more concessions were granted. The new treaty with the United States in 1859 allowed more ports to be opened to diplomatic representatives, unsupervised trade at four additional ports, and foreign residences in Osaka and Edo. It also embodied the concept of extraterritoriality (foreigners were subject to the laws of their own countries but not to Japanese law). Hotta lost the support of key daimys, and when Tokugawa Nariaki opposed the new treaty, Hotta sought imperial sanction. The court officials, perceiving the weakness of the bakufu, rejected Hotta's request and thus suddenly embroiled Kyoto and the emperor in Japan's internal politics for the first time in many centuries. When the shgun died without an heir, Nariaki appealed to the court for support of his own son, Tokugawa Yoshinobu (or Keiki), for shgun, a candidate favored by the shinpan and tozama daimys. The fudai won the power struggle, however, installing Tokugawa Yoshitomi, arresting Nariaki and Keiki, executing Yoshida Shin (1830ÿ1859), a leading sonn-ji intellectual who had opposed the American treaty and plotted a revolution against the bakufu), and signing treaties with the United States and five other nations, thus ending more than 200 years of exclusion.\\r\\nRecently[when?] some scholars[who?] have suggested that there were more events that spurred this opening of Japan. From 1716 to 1745 Yoshimune (eighth Tokugawa shgun from 1716ÿ1745) started the first Kyh reforms in an attempt to gain more revenue for the government.[24] In 1767 to 1786 Tanuma Okitsugu also initiated some unorthodox economic reforms to expand government income.[24] This led his conservative opponents to attack him and take his position as he was forced from government in disgrace.[24] Similarly, Matsudaira Sadanobu launched the Kansei Reforms in 1787ÿ1793 to stabilize rice prices, cut government costs, and increase revenues.[24] The final economic reform of the Tenp era of 1841ÿ1843 had similar objectives. Most were ineffective and only worked in some areas. These economic failings would also have been a force in the opening of Japan, as Japanese businessmen desired larger markets. Some scholars also point to internal activism for political change. The Mito school had long been an active force in demanding political changes, such as restoring the powers of the Emperor. This anger can also be seen in the poetry of Matsuo Taseko (a woman who farmed silk worms in the Ina Valley) from Hirata Atsutane's School of National Learning:\\r\\n\\"It is disgusting\\r\\nthe agitation over thread\\r\\nIn today's world\\r\\nEver since the ships\\r\\nfrom foreign countries\\r\\ncame for the jeweled\\r\\nsilkworm cocoons\\r\\nto the land of the gods and the Emperor\\r\\nPeoples hearts\\r\\nawesome though they are,\\r\\nare being pulled apart\\r\\nand consumed by rage.\\"\\r\\n[25] This inspired many anti-Tokugawa activists as they blamed the Bakufu for impoverishing the people and dishonoring the emperor.[25]\\r\\nDuring the last years of the bakufu, or bakumatsu, the bakufu took strong measures to try to reassert its dominance, although its involvement with modernization and foreign powers was to make it a target of anti-Western sentiment throughout the country.\\r\\nThe army and the navy were modernized. A naval training school was established in Nagasaki in 1855. Naval students were sent to study in Western naval schools for several years, starting a tradition of foreign-educated future leaders, such as Admiral Enomoto. French naval engineers were hired to build naval arsenals, such as Yokosuka and Nagasaki. By the end of the Tokugawa shogunate in 1867, the Japanese navy of the shgun already possessed eight Western-style steam warships around the flagship Kaiy Maru, which were used against pro-imperial forces during the Boshin War under the command of Admiral Enomoto. A French military mission was established to help modernize the armies of the bakufu.\\r\\nRevering the emperor as a symbol of unity, extremists wrought violence and death against the Bakufu and Han authorities and foreigners. Foreign naval retaliation in the Anglo-Satsuma War led to still another concessionary commercial treaty in 1865, but Yoshitomi was unable to enforce the Western treaties. A bakufu army was defeated when it was sent to crush dissent in the Satsuma and Chsh Domains in 1866. Finally, in 1867, Emperor Kmei died and was succeeded by his underaged son Emperor Meiji.\\r\\nTokugawa Yoshinobu reluctantly became head of the Tokugawa house and shgun. He tried to reorganize the government under the emperor while preserving the shgun's leadership role. Fearing the growing power of the Satsuma and Chsh daimys, other daimys called for returning the shgun's political power to the emperor and a council of daimys chaired by the former Tokugawa shgun. Yoshinobu accepted the plan in late 1867 and resigned, announcing an \\"imperial restoration\\". The Satsuma, Chsh, and other han leaders and radical courtiers, however, rebelled, seized the imperial palace, and announced their own restoration on January 3, 1868.\\r\\nFollowing the Boshin War (1868ÿ1869), the bakufu was abolished, and Yoshinobu was reduced to the ranks of the common daimys. Resistance continued in the North throughout 1868, and the bakufu naval forces under Admiral Enomoto Takeaki continued to hold out for another six months in Hokkaid, where they founded the short-lived Republic of Ezo.\\r\\nThe Edo period is the setting of many works of popular culture. These include novels, comics, stageplays, films, television shows, animated works, and manga.\\r\\n?This article incorporates?public domain material from the Library of Congress Country Studies website http://lcweb2.loc.gov/frd/cs/. Japan","input":"Why was the tokugawa period given its name?"},{"output":"Dinesh Karthik","context":"T20I kit\\r\\nThe Kolkata Knight Riders (also known by the acronym KKR) are a franchise cricket team representing the city of Kolkata in the Indian Premier League. The franchise is owned by Bollywood actor Shahrukh Khan, actress Juhi Chawla and her spouse Jay Mehta. The team is coached by Jacques Kallis. The home of the Knight Riders is Eden Gardens, the largest cricket stadium in India and the second largest in the world by seating capacity.[2]\\r\\nAlthough the team has gained immense popularity due to its association with celebrity owners, it was surrounded with controversy and poor on-field performance through the first three years of the tournament.[3] The team's performance, however, improved from the fourth season as it qualified for the IPL playoffs as well as the now defunct Champions League Twenty20. They eventually became the IPL champions for the first time in 2012, by defeating Chennai Super Kings in the final and repeated the feat in 2014, defeating Kings XI Punjab.[4] The Knight Riders hold the record for the longest winning streak by any Indian team in T20s (14).[5]\\r\\nThe leading run-scorer of the side is Gautam Gambhir,[6] while the leading wicket-taker is Sunil Narine.[7] The official theme of the team is Korbo, Lorbo, Jeetbo Re (we will perform, fight and win!) and the official colours are purple and gold. The brand value of the Knight Riders was estimated at $99 million in 2017, second highest among IPL franchises.[3].\\r\\n\\r\\n\\r\\nIn 2007, the Board of Control for Cricket in India (BCCI) created the cricket tournament Indian Premier League based on the Twenty20 form of the game.[8] Eight teams would participate in the inaugural tournament held in April ÿ June of the same year. The teams representing the eight different cities of India were put up on auction in Mumbai on 20 February. The team representing Kolkata was eventually bought by Bollywood superstar Shah Rukh Khan's company Red Chillies Entertainment in partnership with actress Juhi Chawla and her husband Jay Mehta for a price of $75.09 million, equal to approximately ?2.98 billion at that time.[9] Sourav Ganguly, former captain of the Indian national team and a native of West Bengal, was named the Icon Player for the team. The name of the team is a reference to the popular 1980s American television series Knight Rider.[10]\\r\\nIn June 2015, they bought a stake in the Caribbean Premier League cricket team Trinidad and Tobago Red Steel[11] and later in 2016, renamed it Trinbago Knight Riders.[12] In July 2017, they bought Cape Town Knight Riders in the newly formed T20 Global League.[13]\\r\\nInitially, when Kolkata Knight Riders were first introduced in 2008, the logo of the team consisted of a blazing golden Viking helmet against a black background with the name of the team written in gold next to it. However, the black background was changed to purple in the fourth season. It was in 2012 that the current logo, which has a blazing purple Corinthian helmet trimmed with gold, with Kolkata Knight Riders written within a shield was introduced.[14]\\r\\nThe tagline of the team was \\"All the King's Men\\" during the first four seasons.[15] However, in the fifth it was replaced by \\"New Dawn, New Knights\\". The team's official colours were black and gold during the first two seasons. At the time, Khan said that \\"golden symbolizes spirit of life and black presents the Goddess Kali.\\"[15] It was later changed to purple and gold during the third season and was kept so. The jersey was created by Bollywood fashion designer Manish Malhotra.[15]\\r\\nThe main theme of the team Korbo, Lorbo, Jeetbo Re (we will act, fight and win!) was scored by Vishal-Shekhar duo.[15] A Knight Riders album featuring several singers and music composers including Usha Uthup and Bappi Lahiri was also created.[16][17]\\r\\nThe home venue of the Knight Riders is the iconic Eden Gardens (with the two ends of the crease called the High Court End and the Club House End). Owned by the Cricket Association of Bengal, it is the largest cricket stadium in India and had a seating capacity of over 90,000.[18] In 2011, the stadium was renovated to meet the standards set by the ICC for the 2011 Cricket World Cup; reducing its capacity to around 68,000. The renovated stadium includes a new clubhouse and players' facilities, upgrading the exterior wall, cladding the existing roof structure with a new metal skin, and general infrastructure improvements.[19] In 2013, two of the team's home matches were hosted by the JSCA International Cricket Stadium in Ranchi.\\r\\nMultinational communications corporation Nokia was the official founding sponsor of the Kolkata Knight Riders and remained their principal sponsor until 2014.[20][21][3] In 2015, Chinese mobile phone manufacturer Gionee took over as their principal sponsor and signed a three-year deal worth ?540 million (US$8.0?million).[22] In 2018, Nokia returned as the main sponsor of the Knight Riders, signing a two-year deal.[23] Star Plus, Reebok, HDIL, Kit Kat, Sprite, SB Nation, Doublemint, SAP AG, Red FM 93.5, Seiko, U.S. Polo Assn., Uber, Dish TV, Sansui, Ola Cabs, Pepsi and Sony Music India have all formerly been either their co-sponsors or partners.\\r\\nAs of 2018, they have co-sponsorship deals with Jio, Lux Cozi, SRMB Steel, Exide, Royal Stag, JBL, The Telegraph, Fever 104 FM, Greenply and Kingfisher Premium along with several others.[24]\\r\\nSourav Ganguly, the former captain of the Indian cricket team was the icon player and led the franchise in the 2008 and 2010 seasons. Brendon McCullum lead the team in the intervening period. Both captains were released before the 2011 season. The former team included all-rounders Chris Gayle, David Hussey, Laxmi Ratan Shukla, Angelo Mathews, batsman Ricky Ponting and wicket keeper Wriddhiman Saha. The main bowlers were Umar Gul, Ishant Sharma, Ashok Dinda, Ajit Agarkar and Murali Karthik. Australian batsman Brad Hodge and bowlers Ajantha Mendis and Charl Langeveldt were bought outside the IPL auction in late 2008.\\r\\nAt the 2009 auction the team bought Bangladeshi all-rounder Mashrafe Mortaza at a whopping price of $600,000 dollars. Due to the unavailability of Pakistani players starting 2009, KKR had to suspend the contract of Umar Gul, who was a key performer from the 2008 season.[25][26] On 26 April 2009, KKR administration sent back two of its players Akash Chopra and Sanjay Bangar on the premises of poor performance.[27] Shane Bond was acquired after releasing Ricky Ponting, Morne van Wyk and the Pakistani players Umar Gul, Salman Butt, Mohammad Hafeez and Shoaib Akhtar before the third season. Moises Henriques was traded to Delhi in return for Owais Shah and Manoj Tiwary. Thus, their overseas roster for the 2010 season consisted of Shane Bond, Mashrafe Mortaza, Brendon McCullum, Charl Langeveldt, Ajantha Mendis, Angelo Mathews, Brad Hodge, David Hussey, Owais Shah and Chris Gayle.\\r\\nIn the 2011 season, KKR drastically revamped their squad. Former captain and icon player Sourav Ganguly was not purchased in the January auction. This led to protest rallies, signature campaigns throughout the country and abroad along with stadium protests by various fan groups, such as No Dada No KKR,[28] which received both national and international press attention.[29][30][31] The team appointed Gautam Gambhir, who was bought for a record-breaking $2.4 million as skipper.[32] Yusuf Pathan was also picked up for a whopping $2.1 million.[32] Other international names who were added include Shakib Al Hasan, Brad Haddin, Jacques Kallis, Brett Lee, Ryan ten Doeschate, Eoin Morgan and James Pattinson. Haddin was replaced by Mark Boucher mid-season due to injury.[32]\\r\\nIn the 2012 auction, KKR bought back their former captain, Brendon McCullum. They also acquired West Indian spinner Sunil Narine and South African fast bowler Marchant de Lange.\\r\\nThe team later added four domestic players to their squad, including Debabrata Das and Iresh Saxena from Bengal, Saurashtra's Chirag Jani and Sanju Samson from Kerala.[33] However, in November 2012, KKR released the latter three from their team along with Jaydev Unadkat, a key performer from the previous seasons. In the 2013 auction, the team acquired only two overseas players, Sachithra Senanayake and Ryan McLaren.\\r\\nBefore the February 2014 auction, the team had only retained their key performers Gautam Gambhir and Sunil Narine. From the auctions that took place, the team brought back Jacques Kallis and Yusuf Pathan with their right-to-match (RTM) card. Also keeping their place in the squad was Ryan ten Doeschate and Shakib Al Hasan. New international players were Morne Morkel, Patrick Cummins and Chris Lynn. Prominent Indian players bought included Robin Uthappa, Umesh Yadav, Manish Pandey, Suryakumar Yadav and Piyush Chawla.\\r\\nKKR's impressive additions in the 2015 auction were veteran Australian bowler Brad Hogg and wicket-keeper Sheldon Jackson. Before the auction in February 2016, they released Ryan ten Doeschate who was a part of their team for five consecutive seasons along with pace bowler Pat Cummins. The Knight Riders were particularly noted for their change in approach from the previous auctions where they had concentrated on spinners. For the 2016 edition, however, they acquired as many as six pacers in the form of all-rounders John Hastings, Colin Munro, Jason Holder and Rajagopal Sathish as well as bowlers Ankit Rajpoot and Jaydev Unadkat, with the latter being a former player of the squad. They signed one spinner in Manan Sharma.[34] Before the 2017 auctions, they released Morne Morkel, Brad Hogg, Jason Holder, Colin Munro, John Hastings, Jaydev Unadkat, Rajagopal Sathish, Manan Sharma and replacement signing Shaun Tait. From the 2017 Indian Premier League auction, they signed Trent Boult, English all-rounder Chris Woakes, Australian Nathan Coulter-Nile, West Indian Darren Bravo and Jamaican Rovman Powell. The domestic players signed were Rishi Dhawan, Ishank Jaggi, Sayan Ghosh and R Sanjay Yadav. At the time, Andre Russell was banned for one year for doping; he was replaced by Colin de Grandhomme for the season. In January 2018, they only retained West Indian cricketers Sunil Narine and Andre Russell. Their two-time title winning captain Gautam Gambhir was released. At the auction, they retained Robin Uthappa, Piyush Chawla and Kuldeep Yadav using RTM (Right-To-Match) card. KKR also bought back their impressive opener Chris Lynn and uncapped Indian batsman Ishank Jaggi. Other uncapped batsmen bought were Nitish Rana, Shubman Gill, Cameron Delport, Rinku Singh and Apoorv Wankhade. They also bought West Indian uncapped all-rounder Javon Searles and uncapped Indian all-rounders Kamlesh Nagarkoti and Shivam Mavi. Other signings were veteran Indian wicket-keeper Dinesh Karthik, Australian pace bowlers Mitchell Starc and Mitchell Johnson and former Knight Riders player Vinay Kumar.\\r\\nOn 4 March 2018, Dinesh Karthik was appointed as the captain of KKR for IPL 2018 and Robin Uthappa was named vice-captain.[35] Mitchell Starc was ruled out before the season due to injury and Tom Curran was announced as his replacement.\\r\\nThe Knight Riders qualified for the Champions League Twenty20 in 2011, 2012 and 2014. The latter was the last edition of the tournament before it being permanently called off. The team was eliminated in the group stage in 2011 and 2012, but finished as runners-up in the ultimate season.","input":"Who is the captain of kolkata knight riders?"},{"output":"eight","context":"","input":"How many times cowboys been to super bowl?"},{"output":"19 May 2006","context":"Conor Paul Maynard (born 21 November 1992) is an English singer-songwriter, record producer[3] and actor from Brighton who is signed to Warner Music Group subsidiary, Parlophone.[2]. Maynard rose to success in 2012 when he was nominated for, and subsequently won, MTV's Brand New for 2012 award.[4] His debut single, \\"Can't Say No\\", was released in the United Kingdom on 15 April 2012.\\r\\n\\r\\n\\r\\nConor Maynard was born in Brighton, England, to Gary and Helen Maynard, a builder and office worker, respectively. He has a younger brother, Jack who is a YouTuber and briefly appeared on the 2017 series of I'm a Celebrity...Get Me Out of Here!. Maynard has his own Youtube Channel as well. His younger sister Anna has appeared in some of his covers on YouTube, including \\"Run\\" and \\"If I Were A Boy\\".[5][6] He attended Cardinal Newman Catholic School in Hove. On 19 May 2006, he signed up to the online video-sharing website YouTube and uploaded his very first video of him singing \\"Breathe\\", by fellow British musician Lee Carr.[7]\\r\\nIn 2006, Maynard starred as a young Casper Rose in the Sky 1 television series Dream Team.[8]\\r\\nSince 2009, Maynard has uploaded cover versions of songs with rapper and close friend, Anthony \\"Anth\\" Melo, who resides in Virginia. Together they have covered a variety of songs, including: Taio Cruz (\\"Dynamite\\"), Rihanna (\\"Only Girl (In the World)\\"). Maynard came to label attention when American singer/songwriter Ne-Yo watched a cover version of his track \\"Beautiful Monster\\" ÿ who contacted the musician soon afterwards, and Ne-Yo became Maynard's mentor.[9] He signed to EMI/Parlophone and Turn First management.[10]\\r\\nTurn First were responsible for developing the artist.[10] CEO Sarah Stennett told HitQuarters that rather than telling him what songs to sing, they guided him through the songwriting process, finding what music he was listening to and what was inspiring him, and then matched him up with producers The Invisible Men and songwriter Sophie Stern.[10] These sessions eventually resulted in first single \\"Can't Say No\\". Stennett described the song as \\"a tastemaker track. It sounded like something he was listening to, which was urban radio.\\"[10]\\r\\nIn November 2011, Maynard received a nomination for MTV's Brand New for 2012 award, competing alongside Delilah, Michael Kiwanuka, Lana Del Rey and Lianne La Havas.[11] It was announced on 31 January 2012 that Maynard had been crowned winner of the award, having received approximately 48% of the public vote.[4] February 2012 saw the reveal that Maynard had been signed to label EMI subsidiary, Parlophone in late 2011 and that work would begin in the coming months on his debut studio album, Contrast.[2] He released the music video for his debut single \\"Can't Say No\\" on 1 March 2012,[12] which by September 2012 had already surpassed fourteen million views.\\r\\nThe single was met with positive reviews, with Lewis Corner (of Digital Spy) describing it as \\"playful, fun and immediately leaves you wanting another go\\",[13] while others compared Maynard to Canadian singer Justin Bieber. Maynard largely disputed this comparison, stating \\"I'm not like Justin Bieber\\", but allowed that both gained popularity from being young and from being found through YouTube.[14]\\r\\nMaynard's debut single, \\"Can't Say No\\", was released in the United Kingdom on 15 April 2012 ÿ debuting at number two on the UK Singles Chart for the week ending 28 April with 74,792 copies sold.[15] The track also saw chart success in Ireland, where it peaked at number thirteen.[16] On 1 May, Maynard released the album track \\"Drowning\\" as a free download for any fans who pre-ordered the upcoming studio album, Contrast.[17] On 5 May, he performed \\"Can't Say No\\" at the 7th annual edition of the TRL Awards in Italy.[18] On 9 June 2012, Maynard performed \\"Can't Say No\\" at the Capital Summertime Ball[19] in front of an 80,000 strong crowd.\\r\\nMaynard released his second single, \\"Vegas Girl\\", on 21 July 2012 in the UK ÿ it debuted and peaked at number 4 on the UK Singles Chart. On 30 July, he released Contrast, which debuted at number 1 on the UK Album Chart on 11 August 2012. The album sold only 17,000 copies in its debut week. He released the third single from the album \\"Turn Around\\", featuring Ne-Yo. It peaked at number 8 on the UK singles chart.[citation needed]\\r\\nIt was revealed in June 2013 that Maynard would release a book offering fans an insight into his rise to fame, entitled Take Off; it was released in October 2013.[20] Maynard is currently preparing for the release of his second studio album. He has promised a new sound for the album[21] and has confirmed that he has worked with Labrinth and Travie McCoy on the album.[22]\\r\\nOn 23 August, Maynard confirmed that his new single would be called \\"R U Crazy\\", which was produced by Labrinth.[23] The song premiered on radio on 25 August, as well as the music video appearing on 27 August.[24]\\r\\nIn March 2014, Maynard took part in recording England's 2014 World Cup song. He collaborated with the likes of fellow pop stars Melanie C, Eliza Doolittle, Emma Bunton, Katy B, Kimberley Walsh and Pixie Lott, on \\"Greatest Day\\", a track originally performed by British band, Take That. The track was produced by Gary Barlow and recorded at Sarm Studios in London. The track also featured past footballers such as Gary Lineker, Michael Owen, Geoff Hurst, David Seaman, Peter Shilton, Glenn Hoddle and Dion Dublin on backing vocals.[25]\\r\\nOn 1 March 2015 Conor released his new single \\"Talking About\\", the second single from the upcoming album. The single debuted at number 44 on the UK Singles Chart, becoming not only Maynard's first single to miss the top-ten, but also his first to miss the top-forty altogether.[26] Within a month Conor released his third single called \\"Royalty\\". The single is extracted from his second upcoming album, which is predicted to be released at the beginning of 2016.\\r\\nOn 22 January 2016, the single \\"I'm Famous\\" by Marcus Butler was released featuring Maynard. It peaked at number 85 on the UK Singles Chart top 100, failing to reach the top 40.[27] The single spent only one week on the chart. Maynard was also featured alongside Butler in the music video for the same song.\\r\\nConor performed at the Hertfordshire Summer Ball on 13 May 2016, along with other acts such as Becky Hill.\\r\\nIn July 2016, due to the success of his covers on YouTube, Conor announced he would be releasing an album of covers with one original track. A few of the covers included \\"Pillowtalk\\", \\"One Dance\\", \\"Hello\\" and \\"Stitches\\". The original was called \\"This Is My Version\\" and was written about a relationship he had previously been in. The album was released on 5 August 2016.\\r\\nMaynard featured on a dance track called \\"Dancing in the Headlights\\" by DJ Antoine. Maynard also featured on a track called \\"Catch Me Here\\" by Drumsound and Bassline Smith which Conor had already written for 2 years. On 23 December 2016 he released the single \\"Are You Sure?\\" with Kris Kross Amsterdam featuring vocals from Ty Dolla Sign.","input":"When did jack maynard start his youtube channel?"},{"output":"587 BCE","context":"According to the Hebrew Bible, Solomon's Temple, also known as the First Temple, was the Holy Temple (Hebrew: ???????????????????: Beit HaMikdash) in ancient Jerusalem before its destruction by Nebuchadnezzar II after the Siege of Jerusalem of 587 BCE and its subsequent replacement with the Second Temple in the 6th century BCE.\\r\\nThe Hebrew Bible states that the temple was constructed under Solomon, king of the United Kingdom of Israel and Judah and that during the Kingdom of Judah, the temple was dedicated to Yahweh, and is said to have housed the Ark of the Covenant. Jewish historian Josephus says that \\"the temple was burnt four hundred and seventy years, six months, and ten days after it was built\\",[1] although rabbinic sources state that the First Temple stood for 410 years and, based on the 2nd-century work Seder Olam Rabbah, place construction in 832 BCE and destruction in 422 BCE, 165 years later than secular estimates.\\r\\nBecause of the religious sensitivities involved, and the politically volatile situation in Jerusalem, only limited archaeological surveys of the Temple Mount have been conducted. No archaeological excavations have been allowed on the Temple Mount during modern times. Therefore, there are very few pieces of archaeological evidence for the existence of Solomon's Temple.[2] An Ivory pomegranate which mentions priests in the house \\"of ---h\\", and an inscription recording the Temple's restoration under Jehoash have both appeared on the antiquities market, but their authenticity has been challenged and they are the subject of controversy.\\r\\n\\r\\n\\r\\nThe only source of information on the First Temple is the Tanakh.[3] According to the biblical sources, the temple was constructed under Solomon, during the united monarchy of Israel and Judah. The Bible describes Hiram I of Tyre who furnished architects, workmen and cedar timbers for the temple of his ally Solomon at Jerusalem. He also co-operated with Solomon in mounting an expedition on the Red Sea. 1 Kings 6:1 puts the date of the beginning of building the temple \\"in the fourth year of Solomon's reign over Israel\\". The conventional dates of Solomon's reign are circa 970 to 931 BCE. This puts the date of its construction in the mid-10th century BCE.[4] Schmid and Rupprecht are of the view that the site of the temple used to be a Jebusite shrine which Solomon chose in an attempt to unify the Jebusites and Israelites.[5] 1 Kings 9:10 says that it took Solomon 20 years altogether to build the Temple and his royal palace. The Temple itself finished being built after 7 years.[6] During the united monarchy the Temple was dedicated to Yahweh, the God of Israel, and housed the Ark of the Covenant.[7] Rabbinic sources[8] state that the First Temple stood for 410 years and, based on the 2nd-century work Seder Olam Rabbah, place construction in 832 BCE and destruction in 422 BCE (3338 AM), 165 years later than secular estimates.[9]\\r\\nThe exact location of the Temple is unknown: it is believed to have been situated upon the hill which forms the site of the 1st century Second Temple and present-day Temple Mount, where the Dome of the Rock is situated.[citation needed]\\r\\nAccording to the Tanakh, the Temple was plundered by the Neo-Babylonian Empire king Nebuchadnezzar II when the Babylonians attacked Jerusalem during the brief reign of Jehoiachin c. 598 BCE (2 Kings 24:13). A decade later, Nebuchadnezzar again besieged Jerusalem and after 30 months finally breached the city walls in 587 BCE, subsequently burning the Temple, along with most of the city (2 Kings 25). According to Jewish tradition, the Temple was destroyed on Tisha B'Av, the 9th day of Av (Hebrew calendar).[10]\\r\\nThe Temple of Solomon is considered to be built according to Phoenician design, and its description is considered the best description of what a Phoenician temple looked like.[11] The detailed descriptions provided in the Tanakh are the sources for reconstructions of its appearance. Technical details are lacking, since the scribes who wrote the books were not architects or engineers.[12] Nevertheless, the descriptions have inspired modern replicas of the temple and influenced later structures around the world.\\r\\nReconstructions differ; the following is largely based on Easton's Bible Dictionary and the Jewish Encyclopedia:[citation needed]\\r\\nThe Holy of Holies, or Kodesh haKodashim in Hebrew, (1 Kings 6:19; 8:6), also called the \\"Inner House\\" (6:27), (Heb. 9:3) was 20 cubits in length, breadth, and height. The usual explanation for the discrepancy between its height and the 30-cubit height of the temple is that its floor was elevated, like the cella of other ancient temples.[12] It was floored and wainscotted with cedar of Lebanon (1 Kings 6:16), and its walls and floor were overlaid with gold (6:20, 21, 30) amounting to 600 talents (2 Chr. 3:8) or roughly 20 metric tons. It contained two cherubim of olive-wood, each 10 cubits high (1 Kings 6:16, 20, 21, 23ÿ28) and each having outspread wings of 10 cubits span, so that, since they stood side by side, the wings touched the wall on either side and met in the center of the room. There was a two-leaved door between it and the Holy Place overlaid with gold (2 Chr. 4:22); also a veil of tekhelet (blue), purple, and crimson and fine linen (2 Chronicles 3:14; compare Exodus 26:33). It had no windows (1 Kings 8:12) and was considered the dwelling-place of the \\"name\\" of God.\\r\\nThe Kodesh haKodashim (the Holy of Holies) was prepared to receive and house the Ark (1 Kings 6:19); and when the Temple was dedicated, the Ark, containing the original tablets of the Ten Commandments, was placed beneath the cherubim (1 Kings 8:6).\\r\\nThe Hekhal, or Holy Place, (1 Kings 8:8ÿ10), is also called the \\"greater house\\" (2 Chr. 3:5) and the \\"temple\\" (1 Kings 6:17); the word also means \\"palace\\",[12] was of the same width and height as the Holy of Holies, but 40 cubits in length. Its walls were lined with cedar, on which were carved figures of cherubim, palm-trees, and open flowers, which were overlaid with gold. Chains of gold further marked it off from the Holy of Holies. The floor of the Temple was of fir-wood overlaid with gold. The door-posts, of olive-wood, supported folding-doors of fir. The doors of the Holy of Holies were of olive-wood. On both sets of doors were carved cherubim, palm-trees, and flowers, all being overlaid with gold (1 Kings 6:15 et seq.)\\r\\nThe Hebrew noun hekhal (Hebrew ????) in Classical Hebrew means \\"a large building\\". This can be either the main building of the Temple in Jerusalem (that is the nave, or sanctuary, of the Temple), or a palace such as the \\"palace\\" of Ahab, king of Samaria, or the \\"palace\\" of the King of Babylon.\\r\\nHekhal is used 80 times in the Masoretic Text of the Hebrew Bible. Of these, 70 refer to the House of the LORD (in Hebrew Bible ????? ?????? beit Yahweh), the other 10 are references to palaces. There is no reference to any part of the tabernacle using this term in the Hebrew Bible.\\r\\n\\"In the year that king Uzziah died. I saw the LORD sitting upon a throne high and lifted up, and His train filled the hekhal (sanctuary).\\" Isaiah 6:1.\\r\\nIn older English versions of the Bible, including the King James Version, the term \\"temple\\" is used to translate hekhal. In modern versions more reflective of archaeological research, the distinction is made of different sections of the whole Temple. Scholars and archaeologists generally agree on the structure of Solomon's Temple as described in 1 Kings 6:3ÿ5, with the main building, the hekhal, in English now sometimes called \\"the sanctuary\\", the devir, the inner sanctuary, and finally the Holy of Holies.[13]\\r\\nThis main building was between the outer altar, where most sacrifices were performed, and inside at the far end was the entry to the Holy of Holies, originally containing the Ark of the Covenant. The main hekhal contained a number of sacred ritual objects including the seven branched candlestick, the inner altar for incense offerings (also called the \\"Golden Altar\\"), and the table of the showbread.\\r\\nThe same architectural layout of the temple was adopted in synagogues leading to the hekhal being applied in Sephardi usage to the Ashkenazi Torah ark, the equivalent of the nave.[14]\\r\\nThe Ulam, or porch, acted as an entrance before the Temple on the east (1 Kings 6:3; 2 Chr. 3:4; 9:7). This was 20 cubits long (corresponding to the width of the Temple) and 10 cubits deep (1 Kings 6:3). (ESV 2 Chr. 3:4) notes that this porch was 120 cubits high. The description does not specify whether a wall separated it from the next chamber. In the porch stood the two pillars Jachin and Boaz (1 Kings 7:21; 2 Kings 11:14; 23:3), which were 18 cubits in height.\\r\\nChambers were built around the Temple on the southern, western and northern sides (1 Kings 6:5ÿ10). These formed a part of the building and were used for storage. They were probably one story high at first; two more may have been added later.[12]\\r\\nAccording to the Bible, two courts surrounded the Temple. The Inner Court (1 Kings 6:36), or Court of the Priests (2 Chr. 4:9), was separated from the space beyond by a wall of three courses of hewn stone, surmounted by cedar beams (1 Kings 6:36). It contained the Altar of burnt-offering (2 Chr. 15:8), the Brazen Sea laver (4:2ÿ5, 10) and ten other lavers (1 Kings 7:38, 39). A brazen altar stood before the Temple (2 Kings 16:14), its dimensions 20 cubits square and 10 cubits high (2 Chr. 4:1). The Great Court surrounded the whole Temple (2 Chr. 4:9). It was here that people assembled to worship. (Jeremiah 19:14; 26:2).\\r\\nAccording to the Hebrew Bible, the Molten Sea or Brazen Sea (?? ???? \\"cast metal sea\\") was a large basin in the Temple for ablution of the priests. It is described in 1 Kings 7:23-26 and 2 Chronicles 4:2-5. It stood in the south-eastern corner of the inner court. According to the Bible it was five cubits high, ten cubits in diameter from brim to brim, and thirty cubits in circumference. The brim was \\"like the calyx of a lily\\" and turned outward \\"about an hand breadth\\"; or about four inches. It was placed on the backs of twelve oxen, standing with their faces outward. The Book of Kings states that it contains 2,000 baths (90 cubic meters), while Chronicles (2 Chr. 4:5ÿ6) states it can hold up to 3,000 baths (136 cubic meters) and states that its purpose was to afford opportunity for the purification by immersion of the bodies of the priests.\\r\\nThe fact that it was a wash basin which was too large to enter from above lends to the idea that water would likely have flowed from it down into a subcontainer beneath. The water was originally supplied by the Gibeonites, but was afterwards brought by a conduit from Solomon's Pools. The molten sea was made of brass or bronze, which Solomon had taken from the captured cities of Hadarezer, the king of Zobah (1 Chronicles 18:8). Ahaz later removed this laver from the oxen, and placed it on a stone pavement (2 Kings 16:17). It was destroyed by the Chaldeans (2 Kings 25:13).\\r\\nThe lavers, each of which held \\"forty baths\\" (1 Kings 7:38), rested on portable holders made of bronze, provided with wheels, and ornamented with figures of lions, cherubim, and palm-trees. The author of the books of the Kings describes their minute details with great interest (1 Kings 7:27ÿ37). Josephus reported that the vessels in the Temple were composed of orichalcum in Antiquities of the Jews. According to 1 Kings 7:48 there stood before the Holy of Holies a golden Altar of Incense and a table for showbread. This table was of gold, as were also the five candlesticks on each side of it. The implements for the care of the candlesÿtongs, basins, snuffers, and fire-pansÿwere of gold; and so were the hinges of the doors.\\r\\n1 Kings 8:10-66 and 2 Chronicles 6:1-42 recount the events of the temple's dedication. When the priests emerged from the holy of holies after placing the Ark there, the Temple was filled with an overpowering cloud which interrupted the dedication ceremony,[15] \\"for the glory of the Lord had filled the house of the Lord\\" (1 Kings 8:10ÿ11; 2 Chronicles 5:13, 14). Solomon interpreted the cloud as \\"[proof] that his pious work was accepted\\":[15]\\r\\nThe allusion is to Leviticus 16:2:\\r\\nSolomon then led the whole assembly of Israel in prayer, noting that the construction on the temple represented a fulfilment of God's promise to David, dedicating the temple as a place of prayer and reconciliation for the people of Israel and for foreigners living in Israel, and highlighting the paradox that God who lives in the heavens cannot really be contained within a single building. The dedication was concluded with sacrifices said to have included \\"twenty-two thousand bulls and one hundred and twenty thousand sheep\\".[16]\\r\\nBecause of the religious and political sensitivities involved, no archaeological excavations and only limited surface surveys of the Temple Mount have been conducted since Charles Warren's expedition of 1867ÿ70.[17][18][19] There is no archaeological evidence for the existence of Solomon's Temple, and the building is not mentioned in surviving extra-biblical accounts.[20] Israel Finkelstein and Neil Asher Silberman argue that the first Jewish temple in Jerusalem was not built until the end of the 7th century BCE, around three hundred years after Solomon.[20] They believe the temple should not really be assigned to Solomon, who they see as little more than a small-time hill country chieftain, and argue that it was most likely built by Josiah, who governed Judah from 639 to 609 BCE.[20]\\r\\nThere is archaeological and written evidence of three Israelite temples, either contemporary or of very close date, dedicated to Yahweh (Elephantine temple, probably Arad too), either in the Land of Israel or in Egypt. Two of them have the same general outline as given by the Bible for the Jerusalem Temple.\\r\\nRituals in Freemasonry refer to King Solomon and the building of his Temple.[34] Masonic buildings, where Lodge members meet, are sometimes called 'temples'; an allegoric reference to King Solomon's Temple.[35]\\r\\nKabbalah views the design of the Temple of Solomon as representative of the metaphysical world and the descending light of the creator through Sephirot of the Tree of Life. The levels of the outer, inner and priest's courts represent three lower worlds of Kabbalah. The Boaz and Jachin pillars at the entrance of the temple represent the active and passive elements of the world of Atziluth. The original menorah and its seven branches represent the seven lower Sephirot of the Tree of Life. The veil of the Holy of Holies and the inner part of the temple represent the Veil of the Abyss on the Tree of Life, behind which the Shekhina or Divine presence hovers.[36]\\r\\nThe Temple in Jerusalem is mentioned in verse 7 of the surah Al-Isra in the Quran; commentators of Quran such as Muhammad al-Tahir ibn Ashur [37] postulate that this verse refers specifically to the Temple of Solomon.\\r\\nSolomon's Temple appears in Solomon and Sheba (1959) and in the novel King Solomon's Mines (1885). It also appears in the video game Assassin's Creed where the main character Alta?r Ibn-La'Ahad deal with Robert de Sabl.[38][39] It appears too on Assassin's Creed Unity (2014) where the Knight Templar Jacques de Molay is burned and died.[40][41]","input":"What year was the first temple of jerusalem destroyed?"},{"output":"Sinhalese","context":"Several languages are spoken in Sri Lanka within the Indo-European, Dravidian and Austronesian families. Sri Lanka accords official status to Sinhalese and Tamil. The languages spoken on the island nation are deeply influenced by the languages of neighbouring India, the Maldives and Malaysia. Arab settlers and the colonial powers of Portugal, the Netherlands and Britain have also influenced the development of modern languages in Sri Lanka.\\r\\n\\r\\nEthnicity in Sri Lanka (2016)[1]\\r\\n\\r\\nAs per 2016, the Sinhala language is mostly spoken by the Sinhalese people, who constitute approximately 74.9% of the national population and total about 16.6 million. It uses the Sinhala abugida script, which is derived from the ancient Brahmi script. The Rodiya language, a dialect of Sinhala, is spoken by the low-caste  community of chamodi veddhas. The Veddah people, totaling barely 2,500 in 2002,[2] are thought to have once spoken a distinct language, possibly a creolized form of an earlier indigenous language. The Tamil language is spoken by Sri Lankan Tamils, as well as by Tamil migrants from the neighboring Indian state of Tamil Nadu and by most Sri Lankan Moors. Tamil speakers number around 4.7 million. There are more than 50,000 speakers of the Sri Lankan Creole Malay language, which is strongly influenced by the Malay language. \\r\\n\\r\\nEnglish in Sri Lanka is fluently spoken by approximately 10%[3] of the population, and widely used for official and commercial purposes. It is the native language of approximately 74,000 people, mainly in urban areas. A handful of the 3,400 people of Portuguese descent speak Sri Lankan Portuguese creole.[4] The Muslim community in Sri Lanka widely uses Arabic for religious purposes. Seldom used nowadays is Arwi, a written register of Tamil that uses the Arabic script and has extensive lexical influences from Arabic.","input":"What is the main language of sri lanka?"},{"output":"5,600 years B.P.","context":"","input":"When did the woolly mammoth species become extinct?"},{"output":"Kimberlee Green","context":"\\r\\n\\r\\nGiants Netball (stylised as GIANTS Netball) is an Australian netball team in Sydney which competes in the premier Australian league, Suncorp Super Netball.[1] The team represents the Greater Western Sydney region of New South Wales, as well as Canberra in the Australian Capital Territory. The team was formed in 2016, during the disbanding of the ANZ Championship. Giants Netball is owned by Netball NSW and is allied with the elite Australian Football League club, the Greater Western Sydney Giants. Home games are played at the State Sports Centre, Qudos Bank Arena and the AIS Arena in Canberra.\\r\\n\\r\\nFollowing the dissolving of the trans-Tasman ANZ Championship competition in 2016, Netball Australia announced the creation of a new national Netball league, which would feature the five original Australian teams and three additional teams. In May 2016, Netball Australia confirmed that Netball NSW (in a strategic alliance with the Greater Western Sydney Giants AFL club) was one of three preferred license holders for the new teams.[2][3]\\r\\n\\r\\nGiants Netball made their first stride as a professional sporting club when they announced former assistant coach of the Australia national team Julie Fitzgerald as the inaugural head coach of the team.[4] The club then began assembling a strong squad over the coming months, a process which culminated in the appointment of Kimberlee Green as captain, a player with 72 national team caps.[5]\\r\\n\\r\\nThe 2017 Suncorp Super Netball season saw the debut of Giants Netball. The club was struck with a season-ending injury to captain Kimberlee Green in the early part of the season. Green was later replaced by Sarah Wall.[6] Despite this setback, the Giants would finish third (out of eight teams) at the end of the regular season, winning ten of their fourteen games and defeating each of the other seven teams in the competition.[7] They then defeated Collingwood and Melbourne Vixens in successive finals before falling well short in the Grand Final to Sunshine Coast Lightning.[8][9] The following season the Giants finished first on the regular season ladder and won the minor premiership, though they crashed out the finals series in straight sets. Serena Guthrie, Rebecca Bulley and Susan Pettitt (three starting players) all departed the club at the end of the season, with Bulley and Pettitt retiring from the game and Guthrie returning to play in England.[10]\\r\\n\\r\\n\\r\\n\\r\\nThe team owns a reserves team, known as the Canberra Giants, based in both the cities of Canberra and in Sydney, which play in the second-tier Australian Netball League, partially acting as a development squad beneath the senior team.[11] The team was established in 2017 and replaced the Canberra Darters which were the region's former ANL team.[12] The squad comprises a mixture of Giants Netball training partners and elite netball talent based in the Australian Capital Territory.[13]","input":"Who is the captain of the giants netball team?"},{"output":"socialist-oriented market economy","context":"$223 billion (2018, nominal)[1]\\r\\n$2,459 (2018, nominal)[1]\\r\\n 54.9% of GDP (2016)[9]\\r\\nThe socialist-oriented market economy of the Socialist Republic of Vietnam is the 47th-largest economy in the world measured by nominal gross domestic product (GDP) and 35th-largest in the world measured by purchasing power parity (PPP). The country is a member of APEC, ASEAN and the WTO.\\r\\nSince the mid-1980s, through the Doi Moi reform period, Vietnam has made a shift from a highly centralized command economy to a mixed economy that uses both directive and indicative planning through five-year plans. Over that period, the economy has experienced rapid growth. In the twenty-first century, Vietnam is in a period of being integrated into the global economy. Almost all Vietnamese enterprises are small and medium enterprises (SMEs). Vietnam has become a leading agricultural exporter and served as an attractive destination for foreign investment in Southeast Asia. In a similar fashion to other Communist countries after the end of the Cold War, the planned economy of Vietnam lost the momentum for productivity and sustainable growth. In the current period[when?] Vietnam's economy relies largely on foreign direct investment to attract the capital from overseas to support its continual economic rigorousness.[12] Foreign investment on the luxury hotel and sector and resorts will rise to support high-end tourist industry.[13]\\r\\nAccording to a forecast by PricewaterhouseCoopers in February 2017, Vietnam may be the fastest-growing of the world's economies, with a potential annual GDP growth rate of about 5.1%, which would make its economy the 20th-largest in the world by 2050.[14]\\r\\nVietnam has been named among the Next Eleven and CIVETS countries. Despite economic achievement following Doi Moi, there exist issues that cause many analysts and researchers to remain worried about the economic slowdown in the country in recent years.[when?][15][16]\\r\\n\\r\\n\\r\\nCivilization in Vietnam had been built on agriculture. The feudal dynasties always considered agriculture as the main economic base, and their economic thoughts have been predicated on physiocracy. Land ownership was regulated, and such large-scale works as dykes were constructed in the Red River Delta to facilitate wet rice cultivation. In peaceful times, soldiers were sent home to do farm work. Furthermore, the court prohibited slaughtering water buffalo and cattle and held many agriculture-related ceremonies. Handicrafts and art were valued, but commerce was deprecated, and businessmen were called by the derogatory term con bu?n. The national economy was self-sufficient.\\r\\nFrom the 16th century, Confucianism was losing its influence on Vietnamese society and a monetary economy began to develop. Early commercial ports, such as H?i An, were constrained, and foreign countries with their different cultures and their invasion ambitions were seen as a threat. This policy of closure led to a degree of stagnation in the Vietnamese economy, and contributed to Vietnam becoming a French colony.[citation needed]\\r\\nUntil the French colonization in the mid-19th century, Vietnam's economy had been mostly agrarian, subsistence-based and village-oriented. French colonizers, however, deliberately developed the regions differently as the French needed raw materials and a market for French manufactured goods, designating the South for agricultural production as it was better suited for agriculture, and the North for manufacturing as it was naturally wealthy in mineral resources. Though the plan exaggerated regional divisions, the development of exports  coal from the North, rice from the South  and the importation of French manufactured goods stimulated domestic commerce.[17] The separation distorted the basic Vietnamese economy by overly stressing regional economic differences. In the South, while irrigated rice remained the principal subsistence crop, the French introduced plantation agriculture with products such as tea, cotton, and tobacco. The colonial government also developed some extractive industries, such as the mining of coal, iron, and nonferrous metals. A shipbuilding industry was begun in Hanoi; railroads, roads, power stations, and hydraulics works were constructed. In the South, agricultural development concentrated on rice cultivation, and, nationally, rice and rubber were the main items of export. Domestic and foreign trade were centered around the Saigon-Cholon area. Industry in the South consisted mostly of food-processing plants and factories producing consumer goods.[18]\\r\\nWhen the North and South were divided politically in 1954, they also adopted different economic ideologies: communism in the North and capitalism in the South. Destruction caused by the Second Indochina War from 1954 to 1975 seriously strained the economy. The situation was worsened by the country's 1.5 million military and civilian deaths, and the subsequent exodus of 1 million refugees, including tens of thousands of professionals, intellectuals, technicians and skilled workers.[17]\\r\\nThe government's Second Five-Year Plan (1976ÿ1981) aimed for extraordinarily high[clarification needed] annual growth rates in industrial and agricultural sectors and national income and sought to integrate the North and the South, but the goals were not attained. The economy remained dominated by small-scale production, low labor productivity, unemployment, material and technological shortfalls, and insufficient food and consumer goods.[17] The more modest[clarification needed] goals of the Third Five-Year Plan (1981ÿ85) were a compromise between ideological and pragmatic factions; they emphasized the development of agriculture and industry. Efforts were also made to decentralize planning and improve the managerial skills of government officials.[17]\\r\\nAfter reunification in 1975, the economy of Vietnam was plagued by enormous difficulties in production, imbalances in supply and demand, inefficiencies in distribution and circulation, soaring inflation rates, and rising debt problems. Vietnam is one of the few countries in modern history to experience a sharp economic deterioration in a postwar reconstruction period. Its peacetime economy was one of the poorest in the world and had shown a negative to very slow growth in total national output as well as in agricultural and industrial production. Vietnam's gross domestic product ( GDP) in 1984 was valued at US$18.1 billion with a per capita income estimated to be between US$200 and US$300 per year. Reasons for this mediocre economic performance have included severe climatic conditions that afflicted agricultural crops, bureaucratic mismanagement, elimination of private ownership, extinction of entrepreneurial classes in the South, and military occupation of Cambodia (which resulted in a cutoff of much-needed international aid for reconstruction).[19]\\r\\nFrom the late 1970s until the early 1990s, Vietnam was a member of the Comecon, and therefore was heavily dependent on trade with the Soviet Union and its allies. Following the dissolution of the Comecon and the loss of its traditional trading partners, Vietnam was forced to liberalize trade, devalue its exchange rate to increase exports, and embark on a policy of economic development.[20]\\r\\nIn 1986, Vietnam launched a political and economic renewal campaign (??i M?i) that introduced reforms to facilitate the transition from a centralized economy to a \\"socialist-oriented market economy\\". ??i M?i combined government planning with free-market incentives and encouraged the establishment of private businesses and foreign investment, including foreign-owned enterprises. Furthermore, the Vietnam government stressed the necessity to lower birth rates when developing the economic and social rights of the population by implementing a policy that restricted the number of children per household to two, called the two-child policy.[21] By the late 1990s, the success of the business and agricultural reforms ushered in under ??i M?i was evident. More than 30,000 private businesses had been created, the economy was growing at an annual rate of more than 7%, and poverty was nearly halved.[20]\\r\\nThroughout the 1990s, exports increased by as much as 20% to 30% in some years. In 1999, exports accounted for 40% of GDP, an impressive performance in the midst of the economic crisis that hit other countries in Asia. Vietnam became a member of the World Trade Organization (WTO) in 2007, which freed Vietnam from textile quotas enacted worldwide as part of the Multi Fibre Arrangement (MFA) in 1974.[22] The MFA placed restrictions on the import by industrialized countries of textiles from developing countries. For China and other WTO members, however, textile quotas under the MFA expired at the end of 2004 as agreed in the Uruguay Round of trade negotiations in 1994.[20]\\r\\nVietnam's economic policy following the 1997 Asian Financial Crisis has been a cautious one, emphasizing macroeconomic stability rather than growth. While the country shifted toward a more market-oriented economy, the Vietnamese government still continues to hold a tight reign over major state sectors, such as the banking system, state-owned enterprises and foreign trade.[23] GDP growth fell to 6% in 1998 and 5% in 1999.\\r\\nThe signing of the Bilateral Trade Agreement (BTA) between the United States and Vietnam on July 13, 2000, was a significant milestone. The BTA provided for \\"normal trade relations\\" (NTR) status of Vietnamese goods in the U.S. market. It was expected that access to the U.S. market would allow Vietnam to hasten its transformation into a manufacturing-based, export-oriented economy. Furthermore, it would attract foreign investment, not only from the U.S., but also from Europe, Asia and other regions.\\r\\nIn 2001, the ruling Communist Party of Vietnam approved a 10-year economic plan that enhanced the role of the private sector, while reaffirming the primacy of the state.[20] Growth then rose to 6% to 7% between 2000 and 2002 even in the midst of the global recession, making it the world's second fastest-growing economy. At the same time, investment grew threefold and domestic savings quintupled.\\r\\nIn 2003, the private sector accounted for more than one-quarter of all industrial output.[20] However, between 2003 and 2005, Vietnam fell dramatically in the World Economic Forum's global competitiveness report rankings, largely due to negative perceptions of the effectiveness of government institutions.[20] Official corruption is endemic, and Vietnam lags in property rights, efficient regulation of markets, and labor and financial market reforms.[20]\\r\\nVietnam had an average GDP growth of 7.1% a year from 2000 to 2004. The GDP growth was 8.4% in 2005, the second-largest in Asia, trailing only China's. The government estimated that GDP grew in 2006 by 8.17%. According to the Minister of Planning and Investment, the government targeted a GDP growth of around 8.5% in 2007.[24]\\r\\nOn November 7, 2006, the General Council at the World Trade Organization (WTO) approved Vietnam's accession package. On January 11, 2007, Vietnam officially became the WTO's 149th member, after 11 years of preparation, including eight years of negotiation.[22] The country's access to the WTO was intended to provide an important boost to the economy, as it ensured that the liberalizing reforms continue and created options for trade expansion. However, the WTO accession also brought serious challenges, requiring the economy to open up to increasing foreign competition.\\r\\nVietnams economy continues to expand at an annual rate in excess of 7%, one of the fastest-growing in the world, but it grew from an extremely low base, as it suffered the crippling effect of the Vietnam War from the 1950s to the 1970s, as well as the austerity measures introduced in its aftermath.[20] In 2012, the communist party was forced to apologise about the mismanagement of the economy after large numbers of SOEs went bankrupt and inflation rose. The main danger has been over the bad debt in the banks totalling to 15% and forecast growth is 5.2% for 2012 but this is also due to the global economic crisis.[25] The government has launched schemes to reform the economy, however, such as lifting foreign ownership cap from 49% and partially privatizing the country's state-owned companies that have been responsible for the recent economic downturn. By the end of 2013, the government is expected to privatize 25ÿ50% of SOEs, only maintaining control on public services and military. The recent reforms have created a major boom in the Vietnamese stock market as confidence in the Vietnamese economy is returning.\\r\\nOver the last 2 decades, Vietnam has experienced a rapid construction booming that contributed to economic growth but also caused \\"bubble\\" to the economy. Skyscrapers ballooned in big cities. According to Skyscrapercity, in 2013, the top three tallest buildings in Vietnam were the Hanoi Landmark 72 (336m), the Hanoi Lotte Center (267m), and the Saigon Bitexco Financial Tower (263m).\\r\\nVietnam's current economic turmoil has given rise to question of a new period of changing political economy, however.[26]\\r\\nIn 2003, Vietnam produced an estimated 30.7 million cubic meters of wood. Production of sawn wood was a more modest 2,950 cubic meters. In 1992, in response to dwindling forests, Vietnam imposed a ban on the export of logs and raw timber. In 1997, the ban was extended to all timber products except wooden artifacts. During the 1990s, Vietnam began to reclaim land for forests with a tree-planting program.[20]\\r\\nVietnams fishing industry, which has abundant resources given the countrys long coastline and extensive network of rivers and lakes, has generally experienced moderate growth. In 2003, the total catch was about 2.6 million tons. However, seafood exports increased fourfold between 1990 and 2002 to more than US$2 billion, driven in part by shrimp farms in the South and \\"catfish\\", which are a different species from their American counterparts, but are marketed in the United States under the same name. By selling vast quantities of shrimp and catfish to the U.S., Vietnam triggered antidumping complaints by the U.S., which imposed tariffs in the case of catfish and was considering doing the same for shrimp. In 2005, the seafood industry began to focus on domestic demand to compensate for declining exports.[20]\\r\\nVietnam is one of the top rice exporting countries in the world, but the limited sophistication of small-scale Vietnamese farmers causes quality to suffer.[27]\\r\\nVietnam is the world's second largest exporter of coffee.[28]\\r\\nPetroleum is the main source of energy, followed by coal, which contributes about 25% of the countrys energy (excluding biomass). Vietnams oil reserves are in the range of 270ÿ500 million tons. Oil production rose rapidly to 403,300 barrels per day (64,120?m3/d) in 2004, but output is believed to have peaked and is expected to decline gradually.\\r\\nIn 2003, mining and quarrying accounted for 9.4% of GDP, and the sector employed 0.7% of the workforce. Petroleum and coal are the main mineral exports. Also mined are antimony, bauxite, chromium, gold, iron, natural phosphates, tin, and zinc.[20]\\r\\nCrude oil was Vietnams leading export until the late 2000s, when high-tech electrical manufactures emerged to become the biggest export market (by 2014, crude oil comprised only 5% of Vietnamese exports, compared to 20% of all exports in 1996). This is in part because Vietnam crude oil peaked in 2004, when crude oil represented 22% of all export earnings.[29] Petroleum exports are in the form of crude petroleum because Vietnam has a very limited refining capacity. Vietnams only operational refinery, a facility at Cat Hai near Ho Chi Minh City, has a capacity of only 800 barrels per day (130?m3/d). Refined petroleum accounted for 10.2% of total imports in 2002. As of 2012, Vietnam had only one refinery, the Dung Quat refinery, but a second one, the Nghi Son Refinery was planned and was scheduled for construction in May 2013.[20][30]\\r\\nVietnams anthracite coal reserves are estimated at 3.7 billion tons. Coal production was almost 19 million tons in 2003, compared with 9.6 million tons in 1999. Vietnams potential natural gas reserves are 1.3 trillion cubic meters. In 2002, Vietnam brought ashore 2.26 billion cubic meters of natural gas. Hydroelectric power is another source of energy. In 2004, Vietnam confirmed plans to build a nuclear power plant with Russian assistance,[20] and a second by a Japanese group.\\r\\nAlthough the industrial sector contributed 40.1% of GDP in 2004, it employed only 12.9% of the workforce. In 2000, 22.4% of industrial production was attributable to non-state activities. From 1994 to 2004, the industrial sector grew at an average annual rate of 10.3%. Manufacturing contributed 20.3% of GDP in 2004, while employing 10.2% of the workforce. From 1994 to 2004, manufacturing GDP grew at an average annual rate of 11.2%. The top manufacturing sectors  food processing, cigarettes and tobacco, textiles, chemicals, and electrical goods  experienced rapid growth. Benefits from its proximity to China with lower labor cost, Vietnam is becoming a new manufacturing hub in Asia, especially for Japanese and Korean firms. For instance, Samsung produces about 40% of its phones in Vietnam.\\r\\nIn 2004, services accounted for 38.2% of gross domestic product (GDP). From 1994 to 2004, GDP attributable to the service sector grew at an average annual rate of 6.0%.[20]\\r\\nIn 2012, Vietnam welcomed 6.8 millions international visitors and the number is expected to be more than 7 millions in 2013. Vietnam keeps emerging as an attractive destination. In Tripadvisor's list of top 25 destinations Asia 2013 by travellers' choice, there are four cities of Vietnam, namely Hanoi, Ho Chi Minh City, Hoian and Halong.\\r\\n2016 is the first year ever which Vietnam welcomed over 10 million international visitors.[31]\\r\\nMost efficient and reliable banks are the largest (also state-owned) ones: VietinBank, BIDV, and Vietcombank. The banking sector is dominated by the three institutions. There is also a trend of foreign investment into profitable banks. For example, VietinBank is currently owned by Bank of Tokyo Mitsubishi UFJ (20%) and International Finance Corporation (10%) while Vietcombank is owned by Mizuho (15%).\\r\\n(NOTE: Exchange rates as of 30 December 2016. Source: tradingeconomics.com. 1 USD = 22,769 VND)\\r\\nVietnam has two stock trading centers, the Ho Chi Minh City Securities Trading Center and the Hanoi Securities Trading Center, which run the Ho Chi Minh Stock Exchange (HOSE) and the Hanoi Stock Exchange (HNX), respectively.\\r\\nVietnam's currency is the Vietnamese ??ng.\\r\\nThe exchange rate between the U.S. dollar and the Vietnamese ??ng is important because the dong, although not freely convertible, is loosely pegged to the dollar through an arrangement known as a \\"crawling peg\\". This mechanism allows the dollarÿdong exchange rate to adjust gradually to changing market conditions.[20] As of January 1, 2017, a US dollar is worth 22,769 Vietnamese ??ng.\\r\\nGold still maintains its position as a physical currency to a certain extent, although it has seen its economic role declining in recent years.[32]\\r\\nLatest foreign exchange rates can be found at VietinBank.vn.[33]\\r\\nVietnam's economy experienced a hyperinflation period in its early years of the extensive reform program, especially from 1987 to 1992.[34]\\r\\nIn 2008, inflation was tracking at 20.3% for the first half of the year,[35] higher than the 3.4% in 2000, but down significantly from 160% in 1988.[20]\\r\\nIn 2010, inflation stood at 11.5%, and 18.58% in 2011.[36]\\r\\nAt the end of 2012, inflation stood at 7.5%, a substantial decrease from 2011.[37]\\r\\nIn 2013, inflation stood at 6%,[38] and 4.09% in 2014.[39]\\r\\nWith 1,120 inbound deals with a cumulated value of almost 15 bil. USD, there is a tremendous interest by foreign companies to get access to the Vietnamese market or continue the expansion using mergers and acquisitions. From 1991 to February 2018, Vietnamese companies were involved as either an acquiror or an acquired company in 4,000 mergers and acquisitions with a total value of 40.6 bil. USD. The mergers and acquisitions activities faced many obstacles, lowering the rate of success of the transaction. Common obstacles come from culture, transparency and legal aspects.[40] The Institute for Mergers, Acquisitions and Alliances that has been active in Vietnam since 2006 and its M&A expert Christopher Kummer think that after the peak in 2016 and 2017 the trend will decrease in 2018.[41][42][43] Among the largest and most prominent transactions since 2000 are:\\r\\nIt is noticable, that all of the top 10 deals, are inbound into Vietnam and none outbound.[44]\\r\\nEconomic relations with the United States are improving, but are not without challenges. Although the United States and Vietnam reached a landmark bilateral agreement in December 2001, which helped increase Vietnams exports to the United States, disagreements over textile and catfish exports are hindering full implementation of the agreement. Further disrupting the economic relations between the two countries were efforts in Congress to link non-humanitarian aid to Vietnam's human rights record. Barriers to trade and intellectual property are also within the purview of bilateral discussions.[20]\\r\\nGiven neighboring China's rapid economic ascendancy, Vietnam highly values its economic relationship with China. Following the resolution of most territorial disputes, trade with China is growing rapidly, and in 2004, Vietnam imported more products from China than from any other country. In November 2004, the Association of Southeast Asian Nations (ASEAN), of which Vietnam is a member, and China announced plans to establish the worlds largest free-trade area by 2010.[20]\\r\\nVietnam became a member of the World Trade Organization (WTO) on January 11, 2007.[20]\\r\\nIn December 2015, Vietnam joined the ASEAN Economic Community along with the 9 other ASEAN members. The community's goal is to integrate the 10 members of ASEAN and bring a freer flow of labor, investment and trade to the region.[45]\\r\\nSince ??i M?i in 1986, Vietnam has increased trading, growing both exports and imports in double digits ever since. More recently, alarms on trade account deficits have been raised domestically, especially after joining the WTO in 2007. Throughout the next five years after 2007, Vietnam ran a trade deficit with the rest of the world in the tens of billions of dollars, with the record trade deficit in 2008 of US$18 billion.[35]\\r\\nThe account deficit has since decreased. In 2012, Vietnam recorded a trade surplus of US$780 million, the first trade surplus since 1993. Total trade reached US$228.13 billion, an increase of 12.1% from 2011.[46] In 2013, Vietnam recorded the second year of trade surplus of US$863 million. In 2014, Vietnam recorded the third year of trade surplus of US$2.14 billion, the largest trade surplus ever in history.[47]\\r\\nIn 2004, Vietnams exports of merchandise were valued at US$26.5 billion, and, were growing rapidly along with imports. Vietnams principal exports were crude oil (22.1%), textiles and garments (17.1%), footwear (10.5%), fisheries products (9.4%) and electronics (4.1%). The main destinations of Vietnam's exports were the United States (18.8%), Japan (13.2%), China (10.3%), Australia (6.9%), Singapore (5.2%), Germany (4.0%), and the United Kingdom (3.8%).[20]\\r\\nIn 2012, export rose 18.2%, valued at US$114.57 billion.[46] Vietnam's main export market included the EU with US$20 billion, United States with US$19 billion, ASEAN with $US 17.8 billion, Japan with US$13.9 billion, China with US$14.2 billion, and South Korea with US$7 billion.[51]\\r\\nIn 2013, exports rose 15.4%, valued at US$132.17 billion, of which export of electronics now comprised 24.5% of total export, compared with a 4.4% in 2008. Textiles and garments are still an important part in Vietnam's export, valued about US$17.9 billion in 2013.\\r\\nIn 2014, exports rose 13.6%, reaching US$150.1 billion. Electronics and electronics parts, textiles and garments, computers and computer parts are the three main export groups of Vietnam. The United States continued to be Vietnam's largest export market, with US$28.5 billion. The EU is second with US$27.9 billion, ASEAN is third, China is fourth and Japan is the fifth largest export market of Vietnam.\\r\\nIn 2004 Vietnams merchandise imports were valued at US$31.5 billion, and growing rapidly. Vietnams principal imports were machinery (17.5%), refined petroleum (11.5%), steel (8.3%), material for the textile industry (7.2%), and cloth (6.0%). The main origins of Vietnams imports were China (13.9%), Taiwan (11.6%), Singapore (11.3%), Japan (11.1%), South Korea (10.4%), Thailand (5.8%), and Malaysia (3.8%).[20]\\r\\nVietnam import rose 6.6% in 2012, valued at US$113.79 billion.[46] Major import countries were China US$29.2 billion, ASEAN with US$22.3 billion, South Korea with US$16.2 billion, Japan with US$13.7 billion, EU with US$10 billion, and United States with US$6.3 billion.[51]\\r\\nIn 2014, imports rose 12.1%, reaching US$148 billion, most of which are materials and machinery needed for export. China continued to be Vietnam's largest import partner, with US$43.7 billion. The ASEAN is second with US$23.1 billion, South Korea is third, Japan is fourth and the EU is the fifth largest import partner of Vietnam.\\r\\nIn 2004, external debt amounted to US$16.6 billion, or 37% of GDP.[52][20]\\r\\nFrom 1988 to December 2004, cumulative foreign direct investment (FDI) commitments totaled US$46 billion. By December 2004, about 58% had been dispersed. About half of FDI has been directed at the two major cities (and environs) of Ho Chi Minh City and Hanoi. In 2003 new foreign direct investment commitments were US$1.5 billion. The largest sector by far for licensed FDI is industry and construction. Other sectors attracting FDI are oil and gas, fisheries, construction, agriculture and forestry, transportation and communications, and hotels and tourism. From 2006 to 2010, Vietnam hoped to receive US$18 billion of FDI to support a targeted growth rate in excess of 7%. Despite rising investments, foreign investors still regard Vietnam as a risky destination, as confirmed by recent survey by the Japan External Trade Organization of Japanese companies operating in Vietnam. Many of the respondents complained about high costs of utilities, office rentals and skilled labor. Corruption, bureaucracy, lack of transparent regulations and the failure to enforce investor rights are additional obstacles to investment, according to the U.S. State Department. Vietnam tied with several nations for the 102nd place in Transparencies International's Corruption Perceptions Index in 2004.[20]\\r\\nThe World Bank's assistance program for Vietnam has three objectives: to support Vietnams transition to a market economy, to enhance equitable and sustainable development and to promote good governance. From 1993 through 2004, Vietnam received pledges of US$29 billion of official development assistance (ODA), of which about US$14 billion, or 49%, has been disbursed. In 2004, international donors pledged ODA of US$2.25 billion, of which US$1.65 billion actually was disbursed. Three donors accounted for 80% of disbursements in 2004: Japan, the World Bank, and the Asian Development Bank. From 2006 to 2010, Vietnam hopes to receive US$14 billion to US$15 billion of ODA.[20]\\r\\nPledged foreign direct investment US$21.3 billion for 2007 and a record US$31.6 billion for the first half of 2008.[35] Mergers and acquisitions have gradually become an important channel of investments in the economy, especially after 2005.\\r\\nVietnam's major economic regions include Ho Chi Minh city and Hanoi.","input":"What kind of economy does vietnam have today?"},{"output":"About two weeks","context":"About 26, including:\\r\\nTent caterpillars are moderately sized caterpillars, or moth larvae, belonging to the genus Malacosoma in the family Lasiocampidae. Twenty-six species have been described, six of which occur in North America and the rest in Eurasia. Some species are considered to have subspecies as well. They are often considered pests due to their habit of defoliating trees. They are among the most social of all caterpillars and exhibit many noteworthy behaviors.\\r\\nTent caterpillars are readily recognized because they are social, colorful, diurnal and build conspicuous silk tents in the branches of host trees. Some species, such as the eastern tent caterpillar, Malacosoma americanum, build a single large tent which is typically occupied through the whole of the larval stage, while others build a series of small tents that are sequentially abandoned. Whereas tent caterpillars make their tents in the nodes and branches of a tree's limbs, webworms enclose leaves and small branches at the ends of the limbs.\\r\\nThe following description of the tent caterpillar life cycle is based on that of the eastern tent caterpillar, the best known species. The details of the life histories of other species vary to a small extent.\\r\\nTent caterpillars hatch from their eggs in the early spring at the time the leaves of their host trees are just unfolding. The caterpillars establish their tent soon after they eclose. The tent is constructed at a site that intercepts the early morning sun. The position of the tent is critical because the caterpillars must bask in the sun to elevate their temperatures above the cool ambient temperatures that occur in the early spring. Studies have shown that when the body temperature of a caterpillar is less than about 15?C (59?F), digestion cannot occur. The tent consists of discrete layers of silk separated by gaps and the temperature in these compartments varies markedly. Caterpillars can adjust their body temperatures by moving from one compartment to another. On cool mornings they typically rest in a tight aggregate just under a sunlit surface of the tent. It is not uncommon to find that the temperature of the aggregate is as much as 30C (54F) warmer than the surrounding air temperature on cold but sunny spring mornings. Later on in the spring, temperatures may become excessive at midday and the caterpillars may retreat to the shaded outside surface of the tent to cool down.\\r\\nThe digestive physiology of tent caterpillars is tuned to young leaves, and their need to complete their larval development before the leaves of the host trees become too aged for them to eat compels them to feed several times each day. At the onset of a bout of foraging, caterpillars leave the tent en masse, moving to distant feeding sites. Immediately after feeding the caterpillars return to the tent and aggregate in sunlight to facilitate the digestive process. Thus, eastern tent caterpillars are central place foragers. In contrast, the forest tent caterpillar is a nomadic forager that establishes a series of temporary resting sites during the course of its larval development.\\r\\nStudies have shown that eastern tent caterpillars recruit their tent mates to go on food finds. Caterpillars move from the tent in search of food, laying down an exploratory pheromone trail as they pass over the branches of the host tree. These chemical exploratory trails allow caterpillars to find their way back to the tent. If a caterpillar finds food and feeds to repletion, it returns to the tent, laying down a recruitment trail that serves to recruit hungry tent mates to its food find. The chemical nature of the pheromone has been determined, but it is unclear how exploratory and recruitment trails differ. The chemical recruitment trail of the eastern tent caterpillar is remarkably similar to the pheromone trails that are used by ants and termites to alert nest mates to the discovery of food.\\r\\nLeaves consist largely of nondigestible components, and it has been estimated that tent caterpillars void as fecal pellets nearly half of the energy they ingest. As a consequence, a colony of caterpillars produces large quantities of fecal pellets. This is particularly noticeable during outbreaks of the forest tent caterpillar. Fecal pellets dropping from treetops in which the caterpillars are feeding create the auditory illusion of rainfall. Tent caterpillars typically have five to six larval instars. It is estimated that the last instar consumes about 80% of all the food taken in by a larva during the whole of its life cycle. Consequently, it is not uncommon for populations of forest tent caterpillars to go unnoticed until the last instar, when their feeding causes extensive defoliation of trees.\\r\\nCaterpillars grow rapidly and typically complete their larval development in seven to eight weeks. When fully grown, the caterpillars leave the natal tree and seek protected places on the ground or under the eaves of buildings to spin their cocoons. About two weeks later, they emerge as adults. Shortly after eclosing from the cocoon, the female moth secretes a pheromone which draws males to her. Mating typically occurs in the early evening and the mated female, already fully laden with eggs, typically oviposits the full complement later that same evening. The eggs are placed around the circumference of a branch and covered with a frothy material called spumaline. Spumaline is hydrophilic and prevents the eggs from drying out. It also serves as a protective covering which limits the ability of small wasps to parasitize the eggs. Although the male moth may live for a week or more, the female dies soon after laying her eggs. Thus, the whole of the female's adult life may take place in fewer than 24 hours.\\r\\nShortly after the egg mass is deposited, embryogenesis begins. Within three weeks or so, small larvae can be found within each egg mass. These pharate larvae lie sequestered within the shells of the eggs until the following spring. Henceforth, these encased larvae are the most durable of the insect's life stages. In northern areas, the pharate larvae are highly freeze-tolerant and can withstand midwinter temperatures of ?40?C (?40?F) or lower.\\r\\nTent caterpillars exhibit boom-or-bust population dynamics. The most notorious of the outbreak species is the forest tent caterpillar. During outbreaks, the caterpillars can become so abundant that they are capable of completely defoliating tens of thousands of acres of forest. Even though these outbreaks do not follow true cycles in the sense that they occur at regular intervals, some particularly prone regions have recorded outbreaks every ten years or so. Caterpillars rarely remain in outbreak numbers for more than two to three years. Factors which bring outbreaks to a close include parasitoids and disease. In some cases populations collapse because caterpillars starve to death either because trees are completely defoliated before the caterpillars are fully grown or because the quality of host leaves declines to the point where they are no longer palatable. Defoliated trees typically refoliate after caterpillar attacks and experience no lasting damage. In some cases, however, trees or parts of trees may be killed after several seasons of repeated defoliation. This has occurred when forest tent caterpillars defoliated sugar maples that were already stressed due to drought.","input":"How long do eastern tent caterpillars stay in their cocoons?"},{"output":"Genesis","context":"Outline of Bible-related topics\\r\\n\\r\\nThe Old Testament (abbreviated OT) is the first part of Christian Bibles, based primarily upon the Hebrew Bible (or Tanakh), a collection of ancient religious writings by the Israelites[1] believed by most Christians and religious Jews to be the sacred Word of God.[2] The second part of the Christian Bible is the New Testament.\\r\\n\\r\\nThe books that comprise the Old Testament canon, as well as their order and names, differ between Christian denominations. The Catholic canon comprises 46 books, and the canons of the Eastern Orthodox and Oriental Orthodox Churches comprise up to 51 books[3] and the most common Protestant canon comprises 39 books. The 39 books in common to all the Christian canons correspond to the 24 books of the Tanakh, with some differences of order, and there are some differences in text. The additional number reflects the splitting of several texts (Kings, Samuel and Chronicles, EzraÿNehemiah and the minor prophets) into separate books in Christian bibles. The books which are part of a Christian Old Testament but which are not part of the Hebrew canon are sometimes described as deuterocanonical. In general, Protestant Bibles do not include the deuterocanonical books in their canon, but some versions of Anglican and Lutheran bibles place such books in a separate section called Apocrypha. These extra books are ultimately derived from the earlier Greek Septuagint collection of the Hebrew scriptures and are also Jewish in origin. Some are also contained in the Dead Sea Scrolls.\\r\\n\\r\\nThe Old Testament consists of many distinct books by various authors produced over a period of centuries.[4] Christians traditionally divide the Old Testament into four sections: (1) the first five books or Pentateuch (Torah); (2) the history books telling the history of the Israelites, from their conquest of Canaan to their defeat and exile in Babylon; (3) the poetic and \\"Wisdom books\\" dealing, in various forms, with questions of good and evil in the world; and (4) the books of the biblical prophets, warning of the consequences of turning away from God.\\r\\n\\r\\nThe Old Testament contains 39 (Protestant), 46 (Catholic), or more (Orthodox and other) books, divided, very broadly, into the Pentateuch (Torah), the historical books, the \\"wisdom\\" books and the prophets.[5]\\r\\n\\r\\nThe table uses the spellings and names present in modern editions of the Christian Bible, such as the Catholic New American Bible Revised Edition and the Protestant Revised Standard Version and English Standard Version. The spelling and names in both the 1609ÿ10 Douay Old Testament (and in the 1582 Rheims New Testament) and the 1749 revision by Bishop Challoner (the edition currently in print used by many Catholics, and the source of traditional Catholic spellings in English) and in the Septuagint differ from those spellings and names used in modern editions which are derived from the Hebrew Masoretic text.[a]\\r\\n\\r\\nFor the Orthodox canon, Septuagint titles are provided in parentheses when these differ from those editions. For the Catholic canon, the Douaic titles are provided in parentheses when these differ from those editions. Likewise, the King James Version references some of these books by the traditional spelling when referring to them in the New Testament, such as \\"Esaias\\" (for Isaiah).\\r\\n\\r\\nIn the spirit of ecumenism more recent Catholic translations (e.g. the New American Bible, Jerusalem Bible, and ecumenical translations used by Catholics, such as the Revised Standard Version Catholic Edition) use the same \\"standardized\\" (King James Version) spellings and names as Protestant Bibles (e.g. 1 Chronicles as opposed to the Douaic 1 Paralipomenon, 1ÿ2 Samuel and 1ÿ2 Kings instead of 1ÿ4 Kings) in those books which are universally considered canonical, the protocanonicals.\\r\\n\\r\\nThe Talmud (the Jewish commentary on the scriptures) in Bava Batra 14b gives a different order for the books in Nevi'im and Ketuvim. This order is also cited in Mishneh Torah Hilchot Sefer Torah 7:15. The order of the books of the Torah is universal through all denominations of Judaism and Christianity.\\r\\n\\r\\nThe disputed books, included in one canon but not in others, are often called the Biblical apocrypha, a term that is sometimes used specifically to describe the books in the Catholic and Orthodox canons that are absent from the Jewish Masoretic Text and most modern Protestant Bibles. Catholics, following the Canon of Trent (1546), describe these books as deuterocanonical, while Greek Orthodox Christians, following the Synod of Jerusalem (1672), use the traditional name of anagignoskomena, meaning \\"that which is to be read.\\" They are present in a few historic Protestant versions; the German Luther Bible included such books, as did the English 1611 King James Version.[b]\\r\\n\\r\\nEmpty table cells indicate that a book is absent from that canon.\\r\\n\\r\\nSeveral of the books in the Eastern Orthodox canon are also found in the appendix to the Latin Vulgate, formerly the official bible of the Roman Catholic Church.\\r\\n\\r\\nThe first five books ÿ Genesis, Exodus, Leviticus, book of Numbers and Deuteronomy ÿ reached their present form in the Persian period (538ÿ332 BC), and their authors were the elite of exilic returnees who controlled the Temple at that time.[8] The books of Joshua, Judges, Samuel and Kings follow, forming a history of Israel from the Conquest of Canaan to the Siege of Jerusalem c. 587 BC. There is a broad consensus among scholars that these originated as a single work (the so-called \\"Deuteronomistic history\\") during the Babylonian exile of the 6th century BC.[9] \\r\\nThe two Books of Chronicles cover much the same material as the Pentateuch and Deuteronomistic history and probably date from the 4th century BC.[10] Chronicles, and EzraÿNehemiah, were probably finished during the 3rd century BC.[11]  Catholic and Orthodox Old Testaments contain two (Catholic Old Testament) to four (Orthodox) Books of Maccabees, written in the 2nd and 1st centuries BC.\\r\\n\\r\\nThese history books make up around half the total content of the Old Testament. Of the remainder, the books of the various prophets ÿ Isaiah, Jeremiah, Ezekiel, Daniel and the twelve \\"minor prophets\\" ÿ were written between the 8th and 6th centuries BC, with the exceptions of Jonah and Daniel, which were written much later.[12] The \\"wisdom\\" books ÿ Job, Proverbs, Ecclesiastes, Psalms, Song of Solomon ÿ have various dates:  Proverbs possibly was completed by the Hellenistic time (332-198 BC), though containing much older material as well; Job completed by the 6th century BC; Ecclesiastes by the 3rd century BC.[13]\\r\\n\\r\\nGod is consistently depicted as the one who created the world. Although the God of the Old Testament is not consistently presented as the only God who exists, he is always depicted as the only God whom Israel is to worship, or the one \\"true God\\", that only Yahweh is Almighty, and both Jews and Christians have always interpreted the Bible (both the \\"Old\\" and \\"New\\" Testaments) as an affirmation of the oneness of Almighty God.[14]\\r\\n\\r\\nThe Old Testament stresses the special relationship between God and his chosen people, Israel, but includes instructions for proselytes as well. This relationship is expressed in the biblical covenant (contract) between the two, received by Moses. The law codes in books such as Exodus and especially Deuteronomy are the terms of the contract: Israel swears faithfulness to God, and God swears to be Israel's special protector and supporter.[14]\\r\\n\\r\\nFurther themes in the Old Testament include salvation, redemption, divine judgment, obedience and disobedience, faith and faithfulness, among others. Throughout there is a strong emphasis on ethics and ritual purity, both of which God demands, although some of the prophets and wisdom writers seem to question this, arguing that God demands social justice above purity, and perhaps does not even care about purity at all. The Old Testament's moral code enjoins fairness, intervention on behalf of the vulnerable, and the duty of those in power to administer justice righteously. It forbids murder, bribery and corruption, deceitful trading, and many sexual misdemeanors. All morality is traced back to God, who is the source of all goodness.[15]\\r\\n\\r\\nThe problem of evil plays a large part in the Old Testament. The problem the Old Testament authors faced was that a good God must have had just reason for bringing disaster (meaning notably, but not only, the Babylonian exile) upon his people. The theme is played out, with many variations, in books as different as the histories of Kings and Chronicles, the prophets like Ezekiel and Jeremiah, and in the wisdom books like Job and Ecclesiastes.[15]\\r\\n\\r\\nThe process by which scriptures became canons and Bibles was a long one, and its complexities account for the many different Old Testaments which exist today. Timothy H. Lim, a professor of Hebrew Bible and Second Temple Judaism at the University of Edinburgh, identifies the Old Testament as \\"a collection of authoritative texts of apparently divine origin that went through a human process of writing and editing.\\"[4] He states that it is not a magical book, nor was it literally written by God and passed to mankind. By about the 5th century BC Jews saw the five books of the Torah (the Old Testament Pentateuch) as having authoritative status; by the 2nd century BC the Prophets had a similar status, although without quite the same level of respect as the Torah; beyond that, the Jewish scriptures were fluid, with different groups seeing authority in different books.[16]\\r\\n\\r\\nHebrew texts commenced to be translated into Greek in Alexandria in about 280 and continued until about 130 BC.[17]  These early Greek translations ÿ supposedly commissioned by Ptolemy Philadelphus ÿ were called the Septuagint (Latin: \\"Seventy\\") from the supposed number of translators involved (hence its abbreviation \\"LXX\\"). This Septuagint remains the basis of the Old Testament in the Eastern Orthodox Church.[18]\\r\\n\\r\\nIt varies in many places from the Masoretic Text and includes numerous books no longer considered canonical in some traditions: 1 and 2 Esdras, Judith, Tobit, 3 and 4 Maccabees, the Book of Wisdom, Sirach, and Baruch.[19]  Early modern Biblical criticism typically explained these variations as intentional or ignorant corruptions by the Alexandrian scholars, but most recent scholarship holds it is simply based on early source texts differing from those later used by the Masoretes in their work.\\r\\n\\r\\nThe Septuagint was originally used by Hellenized Jews whose knowledge of Greek was better than Hebrew. But the texts came to be used predominantly by gentile converts to Christianity and by the early Church as its scripture, Greek being the lingua franca of the early Church. The three most acclaimed early interpreters were Aquila of Sinope, Symmachus the Ebionite, and Theodotion; in his Hexapla, Origen placed his edition of the Hebrew text beside its transcription in Greek letters and four parallel translations: Aquila's, Symmachus's, the Septuagint's, and Theodotion's. The so-called \\"fifth\\" and \\"sixth editions\\" were two other Greek translations supposedly miraculously discovered by students outside the towns of Jericho and Nicopolis: these were added to Origen's Octapla.[20]\\r\\n\\r\\nIn 331, Constantine I commissioned Eusebius to deliver fifty Bibles for the Church of Constantinople. Athanasius[21] recorded Alexandrian scribes around 340 preparing Bibles for Constans. Little else is known, though there is plenty of speculation. For example, it is speculated that this may have provided motivation for canon lists, and that Codex Vaticanus and Codex Sinaiticus are examples of these Bibles. Together with the Peshitta and Codex Alexandrinus, these are the earliest extant Christian Bibles.[22]  There is no evidence among the canons of the First Council of Nicaea of any determination on the canon, however, Jerome (347ÿ420), in his Prologue to Judith, makes the claim that the Book of Judith was \\"found by the Nicene Council to have been counted among the number of the Sacred Scriptures\\".[23]\\r\\n\\r\\nIn Western Christianity or Christianity in the Western half of the Roman Empire, Latin had displaced Greek as the common language of the early Christians, and in 382 AD Pope Damasus I commissioned Jerome, the leading scholar of the day, to produce an updated Latin bible to replace the Vetus Latina, which was a Latin translation of the Septuagint. Jerome's work, called the Vulgate, was a direct translation from Hebrew, since he argued for the superiority of the Hebrew texts in correcting the Septuagint on both philological and theological grounds.[24] His Vulgate Old Testament became the standard bible used in the Western Church, specifically as the Sixto-Clementine Vulgate, while the Churches in the East continued, and still continue, to use the Septuagint.[25]\\r\\n\\r\\nJerome, however, in the Vulgate's prologues describes some portions of books in the Septuagint not found in the Hebrew Bible as being non-canonical (he called them apocrypha);[26] for Baruch, he mentions by name in his Prologue to Jeremiah and notes that it is neither read nor held among the Hebrews, but does not explicitly call it apocryphal or \\"not in the canon\\".[27] The Synod of Hippo (in 393), followed by the Council of Carthage (397) and the Council of Carthage (419), may be the first council that explicitly accepted the first canon which includes the books that did not appear in the Hebrew Bible;[28] the councils were under significant influence of Augustine of Hippo, who regarded the canon as already closed.[29]\\r\\n\\r\\nIn the 16th century, the Protestant reformers sided with Jerome; yet although most Protestant Bibles now have only those books that appear in the Hebrew Bible, they have them in the order of the Greek Bible.[30]\\r\\n\\r\\nRome then officially adopted a canon, the Canon of Trent, which is seen as following Augustine's Carthaginian Councils[31] or the Council of Rome,[32][33] and includes most, but not all, of the Septuagint (3 Ezra and 3 and 4 Maccabees are excluded);[34] the Anglicans after the English Civil War adopted a compromise position, restoring the 39 Articles and keeping the extra books that were excluded by the Westminster Confession of Faith, but only for private study and for reading in churches, while Lutherans kept them for private study, gathered in an appendix as Biblical Apocrypha.[30]\\r\\n\\r\\nWhile the Hebrew, Greek and Latin versions of the Hebrew Bible are the best known Old Testaments, there were others. At much the same time as the Septuagint was being produced, translations were being made into Aramaic, the language of Jews living in Palestine and the Near East and likely the language of Jesus: these are called the Aramaic Targums, from a word meaning \\"translation\\", and were used to help Jewish congregations understand their scriptures.[35]\\r\\n\\r\\nFor Aramaic Christians there was a Syriac translation of the Hebrew Bible called the Peshitta, as well as versions in Coptic (the everyday language of Egypt in the first Christian centuries, descended from ancient Egyptian), Ethiopic (for use in the Ethiopian church, one of the oldest Christian churches), Armenian (Armenia was the first to adopt Christianity as its official religion), and Arabic.[35]\\r\\n\\r\\nChristianity is based on the belief that the historical Jesus is also the Christ, as in the Confession of Peter. This belief is in turn based on Jewish understandings of the meaning of the Hebrew term messiah, which, like the Greek \\"Christ\\", means \\"anointed\\". In the Hebrew Scriptures it describes a king anointed with oil on his accession to the throne: he becomes \\"The LORD's anointed\\" or Yahweh's Anointed. By the time of Jesus, some Jews expected that a flesh and blood descendant of David (the \\"Son of David\\") would come to establish a real Jewish kingdom in Jerusalem, instead of the Roman province.[36]\\r\\n\\r\\nOthers stressed the Son of Man, a distinctly other-worldly figure who would appear as a judge at the end of time; and some harmonised the two by expecting a this-worldly messianic kingdom which would last for a set period and be followed by the other-worldly age or World to Come. Some thought the Messiah was already present, but unrecognised due to Israel's sins; some thought that the Messiah would be announced by a fore-runner, probably Elijah (as promised by the prophet Malachi, whose book now ends the Old Testament and precedes Mark's account of John the Baptist). None predicted a Messiah who suffers and dies for the sins of all the people.[36]  The story of Jesus' death therefore involved a profound shift in meaning from the tradition of the Old Testament.[37]\\r\\n\\r\\nThe name \\"Old Testament\\" reflects Christianity's understanding of itself as the fulfillment of Jeremiah's prophecy of a New Covenant (which is similar to \\"testament\\" and often conflated) to replace the existing covenant between God and Israel (Jeremiah 31:31).[1]  The emphasis, however, has shifted from Judaism's understanding of the covenant as a racially or tribally-based contract between God and Jews to one between God and any person of faith who is \\"in Christ\\".[38]","input":"What is the first story in the old testament?"},{"output":"(828,000 square miles or 2.14 million km2)","context":"The Louisiana Purchase (French: Vente de la Louisiane \\"Sale of Louisiana\\") was the acquisition of the Louisiana territory (828,000 square miles or 2.14 million km2) by the United States from France in 1803. The U.S. paid fifty million francs ($11,250,000) and a cancellation of debts worth eighteen million francs ($3,750,000) for a total of sixty-eight million francs ($15 million, equivalent to $300?million in 2016). The Louisiana territory included land from fifteen present U.S. states and two Canadian provinces. The territory contained land that forms Arkansas, Missouri, Iowa, Oklahoma, Kansas, and Nebraska; the portion of Minnesota west of the Mississippi River; a large portion of North Dakota; a large portion of South Dakota; the northeastern section of New Mexico; the northern portion of Texas; the area of Montana, Wyoming, and Colorado east of the Continental Divide; Louisiana west of the Mississippi River (plus New Orleans); and small portions of land within the present Canadian provinces of Alberta and Saskatchewan. Its non-native population was around 60,000 inhabitants, of whom half were African slaves.[1]\\r\\nThe Kingdom of France controlled the Louisiana territory from 1699 until it was ceded to Spain in 1762. In 1800, Napoleon, then the First Consul of the French Republic, hoping to re-establish an empire in North America, regained ownership of Louisiana. However, France's failure to put down the revolt in Saint-Domingue, coupled with the prospect of renewed warfare with the United Kingdom, prompted Napoleon to sell Louisiana to the United States to fund his military. The Americans originally sought to purchase only the port city of New Orleans and its adjacent coastal lands, but quickly accepted the bargain. The Louisiana Purchase occurred during the term of the third President of the United States, Thomas Jefferson. Before the purchase was finalized, the decision faced Federalist Party opposition; they argued that it was unconstitutional to acquire any territory. Jefferson agreed that the U.S. Constitution did not contain explicit provisions for acquiring territory, but he asserted that his constitutional power to negotiate treaties was sufficient.\\r\\n\\r\\n\\r\\nThroughout the second half of the 18th century, Louisiana was a pawn on the chessboard of European politics.[2] It was controlled by the French, who had a few small settlements along the Mississippi and other main rivers. France ceded the territory to Spain in the secret Treaty of Fontainebleau (1762). Following French defeat in the Seven Years' War, Spain gained control of the territory west of the Mississippi and the British the territory to the east of the river.[3]\\r\\nFollowing the establishment of the United States, the Americans controlled the area east of the Mississippi and north of New Orleans. The main issue for the Americans was free transit of the Mississippi to the sea. As the lands were being gradually settled by a few American migrants, many Americans, including Jefferson, assumed that the territory would be acquired \\"piece by piece.\\" The risk of another power taking it from a weakened Spain made a \\"profound reconsideration\\" of this policy necessary.[2] New Orleans was already important for shipping agricultural goods to and from the areas of the United States west of the Appalachian Mountains. Pinckney's Treaty, signed with Spain on October 27, 1795, gave American merchants \\"right of deposit\\" in New Orleans, granting them use of the port to store goods for export. Americans used this right to transport products such as flour, tobacco, pork, bacon, lard, feathers, cider, butter, and cheese. The treaty also recognized American rights to navigate the entire Mississippi, which had become vital to the growing trade of the western territories.[3]\\r\\nIn 1798, Spain revoked the treaty allowing American use of New Orleans, greatly upsetting Americans. In 1801, Spanish Governor Don Juan Manuel de Salcedo took over from the Marquess of Casa Calvo, and restored the American right to deposit goods. However, in 1800 Spain had ceded the Louisiana territory back to France as part of Napoleon's secret Third Treaty of San Ildefonso.[4] The territory nominally remained under Spanish control, until a transfer of power to France on November 30, 1803, just three weeks before the formal cession of the territory to the United States on December 20, 1803.[5] A further ceremony was held in St. Louis, Upper Louisiana regarding the New Orleans formalities. The March 9ÿ10, 1804 event is remembered as Three Flags Day.[6][7]\\r\\nJames Monroe and Robert R. Livingston had traveled to Paris to negotiate the purchase of New Orleans in January 1803. Their instructions were to negotiate or purchase control of New Orleans and its environs; they did not anticipate the much larger acquisition which would follow.[8]\\r\\nThe Louisiana Purchase was by far the largest territorial gain in U.S. history. Stretching from the Mississippi River to the Rocky Mountains, the purchase doubled the size of the United States. Before 1803, Louisiana had been under Spanish control for forty years. Although Spain aided the rebels in the American Revolutionary War, the Spanish didn't want the Americans to settle in their territory.[9]\\r\\nAlthough the purchase was thought of by some as unjust and unconstitutional, Jefferson determined that his constitutional power to negotiate treaties allowed the purchase of what became fifteen states. In hindsight, the Louisiana Purchase could be considered one of his greatest contributions to the United States.[10] On April 18, 1802, Jefferson penned a letter to United States Ambassador to France Robert Livingston. It was an intentional exhortation to make this supposedly mild diplomat strongly warn the French of their perilous course. The letter began:\\r\\nThe cession of Louisiana and the Floridas by Spain to France works most sorely on the U.S. On this subject the Secretary of State has written to you fully. Yet I cannot forbear recurring to it personally, so deep is the impression it makes in my mind. It completely reverses all the political relations of the U.S. and will form a new epoch in our political course. Of all nations of any consideration France is the one which hitherto has offered the fewest points on which we could have any conflict of right, and the most points of a communion of interests. From these causes we have ever looked to her as our natural friend, as one with which we never could have an occasion of difference. Her growth therefore we viewed as our own, her misfortunes ours. There is on the globe one single spot, the possessor of which is our natural and habitual enemy. It is New Orleans, through which the produce of three-eighths of our territory must pass to market, and from its fertility it will ere long yield more than half of our whole produce and contain more than half our inhabitants. France placing herself in that door assumes to us the attitude of defiance. Spain might have retained it quietly for years. Her pacific dispositions, her feeble state, would induce her to increase our facilities there, so that her possession of the place would be hardly felt by us, and it would not perhaps be very long before some circumstance might arise which might make the cession of it to us the price of something of more worth to her. Not so can it ever be in the hands of France. The impetuosity of her temper, the energy and restlessness of her character, placed in a point of eternal friction with us...\\r\\nJefferson's letter went on with the same heat to a much quoted passage about \\"the day that France takes possession of New Orleans.\\" Not only did he say that day would be a low point in France's history, for it would seal America's marriage with the British fleet and nation, but he added, astonishingly, that it would start a massive shipbuilding program.[11]\\r\\nWhile the transfer of the territory by Spain back to France in 1800 went largely unnoticed, fear of an eventual French invasion spread nationwide when, in 1801, Napoleon sent a military force to secure New Orleans. Southerners feared that Napoleon would free all the slaves in Louisiana, which could trigger slave uprisings elsewhere.[12] Though Jefferson urged moderation, Federalists sought to use this against Jefferson and called for hostilities against France. Undercutting them, Jefferson took up the banner and threatened an alliance with the United Kingdom, although relations were uneasy in that direction.[12] In 1801 Jefferson supported France in its plan to take back Saint-Domingue (present-day Haiti), which was then under control of Toussaint Louverture after a slave rebellion.\\r\\nJefferson sent Livingston to Paris in 1801[13] after discovering the transfer of Louisiana from Spain to France under the Third Treaty of San Ildefonso. Livingston was authorized to purchase New Orleans.\\r\\nIn January 1802, France sent General Charles Leclerc to Saint-Domingue (present-day Haiti) to re-establish slavery, which had been abolished by the constitution of the French Republic of 1795, as well as to reduce the rights of free people of color and take back control of the island from Toussaint Louverture. Louverture had fended off invasions of St. Domingue by the Spanish and British empires, but had also begun to consolidate power for himself on the island. Before the Revolution, France had derived enormous wealth from St. Domingue at the cost of the lives and freedom of the slaves. Napoleon wanted its revenues and productivity for France restored. Alarmed over the French actions and its intention to re-establish an empire in North America, Jefferson declared neutrality in relation to the Caribbean, refusing credit and other assistance to the French, but allowing war contraband to get through to the rebels to prevent France from regaining a foothold.[14]\\r\\nIn November 1803, France withdrew its 7,000 surviving troops from Saint-Domingue (more than two-thirds of its troops died there) and gave up its ambitions in the Western Hemisphere.[15] In 1804 Haiti declared its independence; but, fearing a slave revolt at home, Jefferson and Congress refused to recognize the new republic, the second in the Western Hemisphere, and imposed a trade embargo against it. This, together with later claims by France to reconquer Haiti, encouraged by the United Kingdom, made it more difficult for Haiti to recover after ten years of wars.[16]\\r\\nIn 1803, Pierre Samuel du Pont de Nemours, a French nobleman, began to help negotiate with France at the request of Jefferson. Du Pont was living in the United States at the time and had close ties to Jefferson as well as the prominent politicians in France. He engaged in back-channel diplomacy with Napoleon on Jefferson's behalf during a visit to France and originated the idea of the much larger Louisiana Purchase as a way to defuse potential conflict between the United States and Napoleon over North America.[17]\\r\\nJefferson disliked the idea of purchasing Louisiana from France, as that could imply that France had a right to be in Louisiana. Jefferson had concerns that a U.S. president did not have the constitutional authority to make such a deal. He also thought that to do so would erode states' rights by increasing federal executive power. On the other hand, he was aware of the potential threat that France could be in that region and was prepared to go to war to prevent a strong French presence there.[citation needed]\\r\\nThroughout this time, Jefferson had up-to-date intelligence on Napoleon's military activities and intentions in North America. Part of his evolving strategy involved giving du Pont some information that was withheld from Livingston. He also gave intentionally conflicting instructions to the two.[citation needed] Desperate to avoid possible war with France, Jefferson sent James Monroe to Paris in 1803 to negotiate a settlement, with instructions to go to London to negotiate an alliance if the talks in Paris failed. Spain procrastinated until late 1802 in executing the treaty to transfer Louisiana to France, which allowed American hostility to build. Also, Spain's refusal to cede Florida to France meant that Louisiana would be indefensible. Monroe had been formally expelled from France on his last diplomatic mission, and the choice to send him again conveyed a sense of seriousness.\\r\\nNapoleon needed peace with the United Kingdom to implement the Treaty of San Ildefonso and take possession of Louisiana. Otherwise, Louisiana would be an easy prey for the UK or even for the United States. But in early 1803, continuing war between France and the UK seemed unavoidable. On March 11, 1803, Napoleon began preparing to invade the UK.\\r\\nAs Napoleon had failed to re-enslave the emancipated population of Haiti, he abandoned his plans to rebuild France's New World empire. Without sufficient revenues from sugar colonies in the Caribbean, Louisiana had little value to him. Spain had not yet completed the transfer of Louisiana to France, and war between France and the UK was imminent. Out of anger towards Spain and the unique opportunity to sell something that was useless and not truly his yet, Napoleon decided to sell the entire territory.[18]\\r\\nAlthough the foreign minister Talleyrand opposed the plan, on April 10, 1803, Napoleon told the Treasury Minister Fran?ois de Barb-Marbois that he was considering selling the entire Louisiana Territory to the United States. On April 11, 1803, just days before Monroe's arrival, Barb-Marbois offered Livingston all of Louisiana for $15 million,[19] (equivalent to about $300?million in 2016 dollars,[20]) which averages to less than three cents per acre (7?S/ha).[21][22]\\r\\nThe American representatives were prepared to pay up to $10 million for New Orleans and its environs, but were dumbfounded when the vastly larger territory was offered for $15 million. Jefferson had authorized Livingston only to purchase New Orleans. However, Livingston was certain that the United States would accept the offer.[23]\\r\\nThe Americans thought that Napoleon might withdraw the offer at any time, preventing the United States from acquiring New Orleans, so they agreed and signed the Louisiana Purchase Treaty on April 30, 1803.[24] On July 4, 1803, the treaty was announced,[25] but the documents did not arrive in Washington, D.C. until July 14.[26] The Louisiana Territory was vast, stretching from the Gulf of Mexico in the south to Rupert's Land in the north, and from the Mississippi River in the east to the Rocky Mountains in the west. Acquiring the territory would double the size of the United States, at a sum of less than 3 cents per acre.\\r\\nHenry Adams and other historians have argued that Jefferson acted hypocritically with the Louisiana Purchase, due to his position as a strict constructionist regarding the Constitution since he stretched the intent of that document to justify his purchase.[27] This argument goes as follows:\\r\\nThe American purchase of the Louisiana territory was not accomplished without domestic opposition. Jefferson's philosophical consistency was in question because of his strict interpretation of the Constitution. Many people believed that he and others, including James Madison, were doing something they surely would have argued against with Alexander Hamilton. The Federalists strongly opposed the purchase, favoring close relations with Britain over closer ties to Napoleon, and were concerned that the United States had paid a large sum of money just to declare war on Spain.[citation needed]\\r\\nBoth Federalists and Jeffersonians were concerned over the purchase's constitutionality. Many members of the House of Representatives opposed the purchase. Majority Leader John Randolph led the opposition. The House called for a vote to deny the request for the purchase, but it failed by two votes, 59ÿ57. The Federalists even tried to prove the land belonged to Spain, not France, but available records proved otherwise.[28]\\r\\nThe Federalists also feared that the power of the Atlantic seaboard states would be threatened by the new citizens in the West, whose political and economic priorities were bound to conflict with those of the merchants and bankers of New England. There was also concern that an increase in the number of slave-holding states created out of the new territory would exacerbate divisions between North and South as well. A group of Northern Federalists led by Senator Timothy Pickering of Massachusetts went so far as to explore the idea of a separate northern confederacy.\\r\\nAnother concern was whether it was proper to grant citizenship to the French, Spanish, and free black people living in New Orleans, as the treaty would dictate. Critics in Congress worried whether these \\"foreigners\\", unacquainted with democracy, could or should become citizens.[29]\\r\\nSpain protested the transfer on two grounds: First, France had previously promised in a note not to alienate Louisiana to a third party and second, France had not fulfilled the Third Treaty of San Ildefonso by having the King of Etruria recognized by all European powers. The French government replied that these objections were baseless since the promise not to alienate Louisiana was not in the treaty of San Ildefonso itself and therefore had no legal force, and the Spanish government had ordered Louisiana to be transferred in October 1802 despite knowing for months that Britain had not recognized the King of Etruria in the Treaty of Amiens.[30]\\r\\nHenry Adams claimed \\"The sale of Louisiana to the United States was trebly invalid; if it were French property, Bonaparte could not constitutionally alienate it without the consent of the French Chambers; if it were Spanish property, he could not alienate it at all; if Spain had a right of reclamation, his sale was worthless.\\"[31] The sale of course was not \\"worthless\\"the U.S. actually did take possession. Furthermore, the Spanish prime minister had authorized the U.S. to negotiate with the French government \\"the acquisition of territories which may suit their interests.\\" Spain turned the territory over to France in a ceremony in New Orleans on November 30, a month before France turned it over to American officials.[32]\\r\\nOther historians counter the above arguments regarding Jefferson's alleged hypocrisy by asserting that countries change their borders in two ways: (1) conquest, or (2) an agreement between nations, otherwise known as a treaty. The Louisiana Purchase was the latter, a treaty. The Constitution specifically grants the president the power to negotiate treaties (Art. II, Sec. 2), which is just what Jefferson did.[33]\\r\\nJefferson's Secretary of State, James Madison (the \\"Father of the Constitution\\"), assured Jefferson that the Louisiana Purchase was well within even the strictest interpretation of the Constitution. Treasury Secretary Albert Gallatin added that since the power to negotiate treaties was specifically granted to the president, the only way extending the country's territory by treaty could not be a presidential power would be if it were specifically excluded by the Constitution (which it was not). Jefferson, as a strict constructionist, was right to be concerned about staying within the bounds of the Constitution, but felt the power of these arguments and was willing to \\"acquiesce with satisfaction\\" if the Congress approved the treaty.[34]\\r\\nThe Senate quickly ratified the treaty, and the House, with equal alacrity, authorized the required funding, as the Constitution specifies.[35][36]\\r\\nThe opposition of New England Federalists to the Louisiana Purchase was primarily economic self-interest, not any legitimate concern over constitutionality or whether France indeed owned Louisiana or was required to sell it back to Spain should it desire to dispose of the territory. The Northerners were not enthusiastic about Western farmers gaining another outlet for their crops that did not require the use of New England ports. Also, many Federalists were speculators in lands in upstate New York and New England and were hoping to sell these lands to farmers, who might go west instead, if the Louisiana Purchase went through. They also feared that this would lead to Western states being formed, which would likely be Republican, and dilute the political power of New England Federalists.[35][37]\\r\\nWhen Spain later objected to the United States purchasing Louisiana from France, Madison responded that America had first approached Spain about purchasing the property, but had been told by Spain itself that America would have to treat with France for the territory.[38]\\r\\nThe Louisiana Purchase Treaty was signed on April 30 by Robert Livingston, James Monroe, and Barb Marbois in Paris. Jefferson announced the treaty to the American people on July 4. After the signing of the Louisiana Purchase agreement in 1803, Livingston made this famous statement, \\"We have lived long, but this is the noblest work of our whole lives... From this day the United States take their place among the powers of the first rank.\\"[39]\\r\\nThe United States Senate advised and consented to ratification of the treaty with a vote of twenty-four to seven on October 20. The Senators who voted against the treaty were: Simeon Olcott and William Plumer of New Hampshire, William Wells and Samuel White of Delaware, James Hillhouse and Uriah Tracy of Connecticut, and Timothy Pickering of Massachusetts.\\r\\nOn the following day, October 21, 1803, the Senate authorized Jefferson to take possession of the territory and establish a temporary military government. In legislation enacted on October 31, Congress made temporary provisions for local civil government to continue as it had under French and Spanish rule and authorized the President to use military forces to maintain order. Plans were also set forth for several missions to explore and chart the territory, the most famous being the Lewis and Clark Expedition.[40]\\r\\nA timeline of legislation can be found at the Library of Congress: American Memory:The Louisiana Purchase Legislative Timeline--1803-1804.[41]\\r\\nFrance turned over New Orleans, the historic colonial capital, on December 20, 1803, at the Cabildo, with a flag-raising ceremony in the Plaza de Armas, now Jackson Square. Just three weeks earlier, on November 30, 1803, Spanish officials had formally conveyed the colonial lands and their administration to France.\\r\\nOn March 9 and 10, 1804, another ceremony, commemorated as Three Flags Day, was conducted in St. Louis, to transfer ownership of Upper Louisiana from Spain to the French First Republic, and then from France to the United States. From March 10 to September 30, 1804, Upper Louisiana was supervised as a military district, under Commandant Amos Stoddard.[citation needed]\\r\\nEffective October 1, 1804, the purchased territory was organized into the Territory of Orleans (most of which would become the state of Louisiana) and the District of Louisiana, which was temporarily under control of the governor and judicial system of the Indiana Territory. The following year, the District of Louisiana was renamed the Territory of Louisiana, aka Louisiana Territory (1805ÿ1812).[citation needed]\\r\\nNew Orleans was the administrative capital of the Orleans Territory, and St. Louis was the capital of the Louisiana Territory.[citation needed]\\r\\nA dispute soon arose between Spain and the United States regarding the extent of Louisiana. The territory's boundaries had not been defined in the 1762 Treaty of Fontainebleau that ceded it from France to Spain, nor in the 1801 Third Treaty of San Ildefonso ceding it back to France, nor the 1803 Louisiana Purchase agreement ceding it to the United States.[42]\\r\\nThe United States claimed Louisiana included the entire western portion of the Mississippi River drainage basin to the crest of the Rocky Mountains and land extending southeast to the Rio Grande and West Florida.[43] Spain insisted that Louisiana comprised no more than the western bank of the Mississippi River and the cities of New Orleans and St. Louis.[44] The dispute was ultimately resolved by the AdamsÿOns Treaty of 1819, with the United States gaining most of what it had claimed in the west.[citation needed]\\r\\nThe relatively narrow Louisiana of New Spain had been a special province under the jurisdiction of the Captaincy General of Cuba while the vast region to the west was in 1803 still considered part of the Commandancy General of the Provincias Internas. Louisiana had never been considered one of New Spain's internal provinces.[45]\\r\\nIf the territory included all the tributaries of the Mississippi on its western bank, the northern reaches of the Purchase extended into the equally ill-defined British possessionRupert's Land of British North America, now part of Canada. The Purchase originally extended just beyond the 50th parallel. However, the territory north of the 49th parallel (including the Milk River and Poplar River watersheds) was ceded to the UK in exchange for parts of the Red River Basin south of 49th parallel in the Anglo-American Convention of 1818.[citation needed]\\r\\nThe eastern boundary of the Louisiana purchase was the Mississippi River, from its source to the 31st parallel, though the source of the Mississippi was, at the time, unknown. The eastern boundary below the 31st parallel was unclear. The U.S. claimed the land as far as the Perdido River, and Spain claimed that the border of its Florida Colony remained the Mississippi River. In early 1804, Congress passed the Mobile Act, which recognized West Florida as part of the United States. The AdamsÿOns Treaty with Spain (1819) resolved the issue upon ratification in 1821. Today, the 31st parallel is the northern boundary of the western half of the Florida Panhandle, and the Perdido is the western boundary of Florida.[citation needed]\\r\\nBecause the western boundary was contested at the time of the Purchase, President Jefferson immediately began to organize three missions to explore and map the new territory. All three started from the Mississippi River. The Lewis and Clark Expedition (1804) traveled up the Missouri River; the Red River Expedition (1806) explored the Red River basin; the Pike Expedition (1806) also started up the Missouri, but turned south to explore the Arkansas River watershed. The maps and journals of the explorers helped to define the boundaries during the negotiations leading to the AdamsÿOns Treaty, which set the western boundary as follows: north up the Sabine River from the Gulf of Mexico to its intersection with the 32nd parallel, due north to the Red River, up the Red River to the 100th meridian, north to the Arkansas River, up the Arkansas River to its headwaters, due north to the 42nd parallel and due west to its previous boundary.\\r\\nGoverning the Louisiana Territory was more difficult than acquiring it. Its European peoples, of ethnic French, Spanish and Mexican descent, were largely Catholic; in addition, there was a large population of enslaved Africans made up of a high proportion of recent arrivals, as Spain had continued the international slave trade. This was particularly true in the area of the present-day state of Louisiana, which also contained a large number of free people of color. Both present-day Arkansas and Missouri already had some slaveholders in the early 19th century.\\r\\nDuring this period, south Louisiana received an influx of French-speaking refugee planters, who were permitted to bring their slaves with them, and other refugees fleeing the large slave revolt in Saint-Domingue, today's Haiti. Many Southern slaveholders feared that acquisition of the new territory might inspire American-held slaves to follow the example of those in Saint-Domingue and revolt. They wanted the US government to establish laws allowing slavery in the newly acquired territory so they could be supported in taking their slaves there to undertake new agricultural enterprises, as well as to reduce the threat of future slave rebellions.[46]\\r\\nThe Louisiana Territory was broken into smaller portions for administration, and the territories passed slavery laws similar to those in the southern states but incorporating provisions from the preceding French and Spanish rule (for instance, Spain had prohibited slavery of Native Americans in 1769, but some slaves of mixed African-Native American descent were still being held in St. Louis in Upper Louisiana when the U.S. took over).[47] In a freedom suit that went from Missouri to the US Supreme Court, slavery of Native Americans was finally ended in 1836.[47] The institutionalization of slavery under U.S. law in the Louisiana Territory contributed to the American Civil War a half century later.[46] As states organized within the territory, the status of slavery in each state became a matter of contention in Congress, as southern states wanted slavery extended to the west, and northern states just as strongly opposed new states being admitted as \\"slave states.\\"\\r\\nThe Missouri Compromise of 1820 was a temporary solution.[citation needed]\\r\\nAfter the early explorations, the U.S. government sought to establish control of the region, since trade along the Mississippi and Missouri rivers was still dominated by British and French traders from Canada and allied Indians, especially the Sauk and Fox. The U.S. adapted the former Spanish facility at Fort Bellefontaine as a fur trading post near St. Louis in 1804 for business with the Sauk and Fox.[48] In 1808 two military forts with trading factories were built, Fort Osage along the Missouri River in western present-day Missouri and Fort Madison along the Upper Mississippi River in eastern present-day Iowa.[49] With tensions increasing with Great Britain, in 1809 Fort Bellefontaine was converted to a U.S. military fort, and was used for that purpose until 1826.\\r\\nDuring the War of 1812, Great Britain and allied Indians defeated U.S. forces in the Upper Mississippi; the U.S. abandoned Forts Osage and Madison, as well as several other U.S. forts built during the war, including Fort Johnson and Fort Shelby. After U.S. ownership of the region was confirmed in the Treaty of Ghent (1814), the U.S. built or expanded forts along the Mississippi and Missouri rivers, including adding to Fort Bellefontaine, and constructing Fort Armstrong (1816) and Fort Edwards (1816) in Illinois, Fort Crawford (1816) in Prairie du Chien Wisconsin, Fort Snelling (1819) in Minnesota, and Fort Atkinson (1819) in Nebraska.[49]\\r\\nThe American government used $3 million in gold as a down payment, and issued bonds for the balance to pay France for the purchase. Earlier that year, Francis Baring and Company of London had become the U.S. government's official banking agent in London. Because of this favored position, the U.S. asked the Baring firm to handle the transaction. Francis Baring's son Alexander was in Paris at the time and helped in the negotiations.[50] Another Baring advantage was a close relationship with Hope and Company of Amsterdam. The two banking houses worked together to facilitate and underwrite the Purchase.\\r\\nBecause Napoleon wanted to receive his money as quickly as possible, the two firms received the American bonds and shipped the gold to France.[50] Napoleon used the money to finance his planned invasion of England, which never took place.[51]","input":"How much land did the united states buy from france?"},{"output":"Alaska","context":"In the United States, the use and possession of cannabis is illegal under federal law for any purpose, by way of the Controlled Substances Act of 1970. Under the CSA, cannabis is classified as a Schedule I substance, determined to have a high potential for abuse and no accepted medical use ÿ thereby prohibiting even medical use of the drug.[1] At the state level, however, policies regarding the medical and recreational use of cannabis vary greatly, and in many states conflict significantly with federal law.\\r\\nThe medical use of cannabis is legal (with a doctor's recommendation) in 29 states, the District of Columbia, and the territories of Guam and Puerto Rico.[2] Seventeen other states have laws that limit THC content, for the purpose of allowing access to products that are rich in cannabidiol (CBD), a non-psychoactive component of cannabis.[2] Although cannabis remains a Schedule I drug, the RohrabacherÿFarr amendment prohibits federal prosecution of individuals complying with state medical cannabis laws.[3]\\r\\nThe recreational use of cannabis is legal in 9 states (Alaska, California, Colorado, Maine, Massachusetts, Nevada, Oregon, Vermont, and Washington) plus the District of Columbia, and decriminalized in another 13 states plus the U.S. Virgin Islands.[4] Commercial distribution of cannabis is allowed in all jurisdictions where cannabis has been legalized, except Vermont and the District of Columbia. Prior to January 2018, the Cole Memorandum provided some protection against the enforcement of federal law in states that have legalized, but it was rescinded by Attorney General Jeff Sessions.[5]\\r\\nThere are currently three cannabinoid drugs (Marinol, Syndros, and Cesamet) that can be prescribed in accordance with federal law. The drug cannabidiol cannot legally be prescribed (as with whole-plant cannabis), due to the fact that the Drug Enforcement Administration considers it a Schedule I drug.[6] Despite this classification, a number of online retailers sell CBD products to all 50 states, claiming such products are derived from industrial hemp plants and therefore legal.[7] The federal government has so far not taken action against these retailers.[8]\\r\\nFirst-time may be punished as a misdemeanor, but further possession, or intent to sell, can result in felony charges.\\r\\nLegalized by Measure 2 on November 4, 2014.[11]\\r\\nNovember 2010: medical marijuana legalized when Proposition 203 passed with 50.13% of the vote.[12][13][14]\\r\\nPossession under three ounces a misdemeanor; Cities of Fayetteville and Eureka Springs labeled cannabis their lowest law enforcement priority. November 8, 2016: medical marijuana legalized when Issue 6 passed by 53%.[15]\\r\\nJuly 1975: Senate Bill 95 reduced the penalty for possession of one ounce (28.5 grams) or less of cannabis to a citable misdemeanor.[16]\\r\\nNovember 1996: first state to legalize medical marijuana when Proposition 215 passed by 56%.[17]\\r\\nNovember 2016: Proposition 64 passed by 57% to 43%, legalizing sale and distribution, effective January 1, 2018.\\r\\nColorado Amendment 64 legalized the sale and possession of marijuana for non-medical use on November 6, 2012, including cultivation of up to six plants with up to three mature.[19][20] Second state to legalize recreational marijuana (Dec 10, 2012, by 4 days).\\r\\nPossession less than a half-ounce by those 21 or over, results in graduated fines, and confiscation. Under 21 face more sanctions, with temporary loss of drivers license.[21]\\r\\nFebruary 10, 2012: Governor Markell suspended medical marijuana after a Justice Department letter threatened federal prosecution. On August 31, 2016, Gov. Markell signed House Bill 400, expanding medical cannabis programs for those with a terminal illness.[22][23]\\r\\nNovember 8, 2016: medical marijuana legalized as of July 1, 2017 when voters passed Amendment 2 by 71%.[24]\\r\\nPossession, sale, or cultivation results in suspension of driver's license. First-time offense eligible for discharge with payment of fine and community service. April 16, 2015: CBD oil legalized for medical use.[25]\\r\\nJune 15, 2000: Governor Benjamin Cayetano signed bill legalizing medical marijuana. First state legislature to do so.[26][27] July 14, 2015: Governor David Ige signed bill allowing medical cannabis dispensaries.[28] July 14, 2016: Governor Ige signed law expanding medical cannabis programs.[29]\\r\\nPossession of 3 ounces or less a misdemeanor up to 1 year prison or fine up to $1,000 or both. More than 3 ounces but less than 1 pound a felony up to 5 years prison or fine up to $10,000 or both.[30]\\r\\nCannabis Control Act of 1978 allowed for medical marijuana but was never implemented.[31][32]\\r\\nAugust 1, 2013: Gov. Pat Quinn signed bill legalizing medical marijuana effective January 1, 2014.[33]\\r\\nMarch 22, 2017: lawmakers proposed legalizing recreational marijuana[34] allowing possession up to 28 g and five plants.\\r\\nApril 14, 2014: SB 364 decriminalized possession of 10 grams or less punishable by $100 fine for first offense, $250 fine for second offense, and $500 fine plus possible drug treatment for third offense. HB 881 legalized medical cannabis. Both laws effective October 1, 2014.[40][41]\\r\\nPossession 60 grams or less up to 6 months in prison and fine of $100ÿ$500. Second offense up to 3 years in prison or fine up to $1,000 or both. More than 60 grams a felony up to 5 years in prison or fine up to $50,000 or both. Intent to distribute a felony up to 20 years in prison or fine up to $50,000 or both.[49]\\r\\nPossession up to one ounce fined up to $300 for first offense, with potential mandatory drug education. Second offense fine up to $500 and up to five days' jail, third offense up to $500 fine and maximum one week jail.[50]\\r\\nNovember 7, 2000: medical marijuana legalized with 65% vote on Question 9.[51][52]\\r\\nNovember 8, 2016: recreational marijuana legalized when Question 2 passed by 54%.[53] Home cultivation allowed if 25 miles away from store.[54]\\r\\nJuly 23, 2013: medical marijuana legalized when Governor Maggie Hassan signed HB 573.[55][56] July 11, 2015: Governor Hassan expanded medical marijuana law.[57] July 18, 2017: Governor Chris Sununu signed bill decriminalizing up to three-quarters of an ounce.\\r\\nJanuary 18, 2010: medical marijuana law signed by Governor Jon Corzine. Maximum 1 year in prison and 1,000 dollar fine for possession of up to 50 grams.[58][59] September 19, 2016: Governor Chris Christie signed Assembly Bill 457 adding PTSD as qualifying condition for medical marijuana, effective immediately.[60]\\r\\nApril 2007: medical marijuana legalized when Governor Bill Richardson signed Senate Bill 523.[62][63]\\r\\nJuly 14, 2014: medical marijuana legalized when Governor Andrew Cuomo signed legislation allowing edibles, oils, pills, and vaporization, but not smoking.[65][66][67]\\r\\nNovember 8, 2016: legalized medical marijuana when voters passed Measure 5 by 64%.[68]\\r\\nJune 8, 2016: Governor John Kasich signed legislation legalizing medical marijuana.[69]\\r\\nVoter approved Measure 91 November 4, 2014 provides for possession and sale of set amounts of cannabis.[72][73] Cannabis sentencing reform signed July 1, 2015 by Governor Kate Brown.[74][75] More medical cannabis reforms signed July 28, 2015 by Governor Brown effective October 1, 2015.[76][77] Governor Brown signed 25% cannabis sales tax.[78]\\r\\nMedical use law signed by Governor Wolf April 17, 2016. Possession of 30g or less up to 30 days in jail and fine up to $500. More than 30g a misdemeanor up to a year in jail and $5000 fine.[79]\\r\\nPossession of an ounce $150 fine, three violations within 18 months a misdemeanor with larger fines or prison or both.[80]\\r\\nPersonal use of 2 oz or less a Class 1 misdemeanor punishable by maximum 1 year in prison and maximum fine $2,000.[83]\\r\\nFirst-time possession one year supervised probation instead of one year in prison; *Possession of 1/2 ounce or more for resale a felony. CBD oil possession allowed as of May 4, 2015, if suffering seizures or epilepsy with recommendation of doctor.[84]\\r\\nDec. 2014: \\"possession of up to two ounces of marijuana can result in a jail sentence of up to six months and fine of up to $2,000.\\"[85] June 1, 2015: governor Greg Abbott signed a bill legalizing CBD oil for medical use.[86]\\r\\nHB 105 signed in 2014 allows use of low-THC cannabis oil for patients with epilepsy.[87] HB 195 signed in March 2018 allows cannabis for certain terminally ill patients.[88]\\r\\nPossession up to an ounce 6-months prison and maximum fine $1,000. Over 10 ounces $10,000 fine. Selling any amount a felony with 5 years in prison and $5,000 fine.[89]\\r\\nMay 19, 2004: medical marijuana legalized when Senate Bill 76 passed,[90] expanded in June 2007 by SB 7.[91]\\r\\nJune 6, 2013: Governor Peter Shumlin signed HB200 decriminalizing one ounce.[92] January 2018: HB511 passed, [93][94][95] legalizing one ounce and two plants,[96] taking effect on July 1, 2018.[97][98][99] First state legislature to legalize recreational marijuana.[100]\\r\\nFirst offense- Unclassified Misdemeanor up to 30 days jail and $500 fine or both, and loss of driving privilege. 2nd offense Class 1 misdemeanor up to 12 months prison and $2,500 fine or both, plus loss of driving privileges. First offense qualifies for deferred disposition & dismissal with drug assessment, classes, community service, and loss of driving privileges for six months, but does not qualify for expungement, remaining on record permanently.[101]\\r\\nLegalized by Washington Initiative 502 in 2012, the law permits anyone over 21 to carry one ounce, and it requires licensed sellers, distributors and growers. Home growing is not allowed except for medical use.[102]First state to legalize recreational marijuana (Dec 6, 2012, by 4 days).[103]\\r\\n\\"Compassionate Use Act for Medical Cannabis; providing for protections for the medical use of cannabis...\\"[104]\\r\\nFirst possession a misdemeanor fine up to $1,000 or imprisonment up to 6 months, or both. Second offense a Class I felony fine up to $10,000 or imprisonment up to 3.5 years, or both.\\r\\nBeing under the influence of marijuana is a misdemeanor up to 90 days in prison and fine up to $100. Possession three ounces or less a misdemeanor up to 1 year in prison and fine up to $1000.[106]\\r\\n?District of Columbia\\r\\nIn 1999, the Territory established a 5-year mandatory minimum sentence for possession of any amount of any illegal drug, to explicitly include marijuana, even when medically prescribed in another jurisdiction.[109]\\r\\nResidents passed a ballot measure on November 4, 2014 that allows cannabis for medical use only.[110]\\r\\nIn 2010, the CNMI House of Representatives approved a legalization bill to regulate and tax marijuana,[111] but the measure ultimately failed.[why?]\\r\\nOn May 4, 2015, the governor of Puerto Rico signed an executive order legalizing medicinal marijuana in the U.S territory.[112]","input":"What places in the us is weed legal?"},{"output":"typical Antarctic tundra","context":"The Antarctic Peninsula is the northernmost part of the mainland of Antarctica, located at the base of the Southern Hemisphere.\\r\\nAt the surface, it is the biggest, most prominent peninsula in Antarctica as it extends 1,300?km (810 miles) from a line between Cape Adams (Weddell Sea) and a point on the mainland south of Eklund Islands. Beneath the ice sheet which covers it, the Antarctic Peninsula consists of a string of bedrock islands; these are separated by deep channels whose bottoms lie at depths considerably below current sea level. They are joined together by a grounded ice sheet. Tierra del Fuego, the southernmost tip of South America, lies only about 1,000?km (620 miles) away across the Drake Passage.[1]\\r\\nThe Antarctic Peninsula is currently dotted with numerous research stations and nations have made multiple claims of sovereignty. The peninsula is part of disputed and overlapping claims by Argentina, Chile and the United Kingdom. None of these claims have international recognition and, under the Antarctic Treaty System, the respective countries do not attempt to enforce their claims. The British claim is recognised though by Australia, France, New Zealand and Norway. Argentina has the most bases and personnel stationed on the peninsula.\\r\\n\\r\\n\\r\\nThe first sighting of the Antarctic Peninsula is disputed but apparently occurred in 1820. The most likely first sighting of the Antarctic Peninsula, and also of the whole Antarctic mainland, was probably on 27 January 1820 by an expedition of the Russian Imperial Navy led by Fabian Gottlieb von Bellingshausen. But the party did not recognize as the mainland what they thought was an icefield covered by small hillocks.\\r\\nThree days later on 30 January 1820, Edward Bransfield and William Smith, with a British expedition, were the first to chart part of the Antarctic Peninsula. This area was later to be called Trinity Peninsula and is the extreme northeast portion of the peninsula. The next confirmed sighting was in 1832 by John Biscoe, a British explorer, who named the northern part of the Antarctic Peninsula as Graham Land.[1][2]\\r\\nThe first European to land on the continent is also disputed. A 19th-century seal hunter, John Davis, was almost certainly the first. But, sealers were secretive about their movements and their logbooks were deliberately unreliable, to protect any new sealing grounds from competition.[1]\\r\\nBetween 1901 and 1904, Otto Nordenski?ld led the Swedish Antarctic Expedition, one of the first expeditions to explore parts of Antarctica. They landed on the Antarctic Peninsula in February 1902, aboard the Antarctic, which later sank not far from the peninsula. All crew were saved. They were later rescued by an Argentine ship. The British Graham Land Expedition between 1934 and 1937 carried out aerial surveys and concluded that Graham Land was not an archipelago but a peninsula.[1][2]\\r\\nAgreement on the name Antarctic Peninsula by the US-ACAN and UK-APC in 1964 resolved a long-standing difference over the use of the United States' name \\"Palmer Peninsula\\" or the British name \\"Graham Land\\" for this geographic feature. This dispute was resolved by making Graham Land the part of the Antarctic Peninsula northward of a line between Cape Jeremy and Cape Agassiz; and Palmer Land the part southward of that line. Palmer Land is named for the United States seal hunter Nathaniel Palmer. In Chile, the peninsula is officially named O'Higgins Land, after Bernardo O'Higgins, the Chilean patriot and Antarctic visionary. Other Spanish-speaking countries call it \\"Pennsula Antrtica\\", among them Argentina. It officially also refers to this as Tierra de San Martn, and Argentina has more bases and personnel there than any other nation.[1]\\r\\nOther portions of the peninsula named by and after the various expeditions discovered them include Bowman Coast, Black Coast, Danco Coast, Davis Coast, English Coast, Fallieres Coast, Loubet Land, Nordenskjold Coast and the Wilkins Coast.[1]\\r\\nThe first Antarctic research stations were established during World War II by a British military operation, Operation Tabarin.[3]\\r\\nThe 1950s saw a marked increase in the number of research bases as Britain, Chile and Argentina competed to make claims over the same area.[4] Meteorology and geology were the primary research subjects.\\r\\nSince the peninsula has the mildest climate in Antarctica, the highest concentration of research stations on the continent can be found there, or on the many nearby islands, and it is the part of Antarctica most often visited by tour vessels and yachts. Occupied bases include Base General Bernardo O'Higgins Riquelme, Bellingshausen Station, Comandante Ferraz Brazilian Antarctic Base, Rothera Research Station and San Martn Base. Today, on the Antarctic Peninsula there are many abandoned scientific and military bases. Ice core and sediment samples from the peninsula are valuable because events such as the Little Ice Age can be verified with samples from other continents. Argentina's Esperanza Base was the birthplace of Emilio Marcos Palma, the first person to be born in Antarctica.[citation needed]\\r\\nTourism to the Antarctic Peninsula began in the 1950s. Most ship-based tourists depart for the peninsula from Ushuaia in Argentina.\\r\\nThe grounding of the Argentine ship Baha Paraso and subsequent 170,000?US?gal (640,000?l; 140,000?imp?gal) oil spill occurred near the Antarctic Peninsula in 1989.[5][6] In 2005, Lewis Gordon Pugh broke the farthest-south long distance swim record by undertaking a 1?km (0.62?mi) swim at Petermann Island off the Antarctic Peninsula. In November 2007, the MV Explorer rammed submerged sea ice and then sank after water from a fist sized hole could not be pumped out quickly enough. All passengers and crew were safely evacuated and rescued.[7]\\r\\nThe peninsula is highly mountainous, its highest peaks rising to about 2,800?m (9,200?ft). Notable peaks on the peninsula include Mount Castro, Mount Coman, Mount Gilbert, Mount Jackson, Mount Hope, which is the highest point at 3,239?m (10,627?ft),[8] Mount William, Mount Owen and Mount Scott. These mountains are considered to be a continuation of the Andes of South America, with a submarine spine or ridge connecting the two.[9] This is the basis for the position advanced by Chile and Argentina for their territorial claims. The Scotia Arc is the island arc system that links the mountains of the Antarctic Peninsula to those of Tierra del Fuego.\\r\\nThe landscape of the peninsula is typical Antarctic tundra. The peninsula has a sharp elevation gradient, with glaciers flowing into the Larsen Ice Shelf, which experienced significant breakup in 2002. Other ice shelves on the peninsula include George VI Ice Shelf, Wilkins Ice Shelf, Wordie Ice Shelf and the Bach Ice Shelf. The Filchner-Ronne Ice Shelf lies to the east of the peninsula.\\r\\nIslands along the peninsula are mostly ice-covered and connected to the land by pack ice.[10] Separating the peninsula from nearby islands are the Antarctic Sound, Erebus and Terror Gulf, George VI Sound, Gerlache Strait and the Lemaire Channel. The Lemaire Channel is a popular destination for tourist cruise ships that visit Antarctica. Further to the west lies the Bellingshausen Sea and in the north is the Scotia Sea. The Antarctic Peninsula and Cape Horn create a funneling effect, which channels the winds into the relatively narrow Drake Passage.[citation needed]\\r\\nHope Bay, at 6323S 05700W? / ?63.383S 57.000W? / -63.383; -57.000, is near the northern extremity of the peninsula, Prime Head, at 6313S. Near the tip at Hope Bay is Sheppard Point. The part of the peninsula extending northeastwards from a line connecting Cape Kater to Cape Longing is called the Trinity Peninsula. Brown Bluff is a rare tuya and Sheppard Nunatak is found here also. The Airy, Seller, Fleming and Prospect Glaciers form the Forster Ice Piedmont along the west coast of the peninsula. Charlotte Bay, Hughes Bay and Marguerite Bay are all on the west coast as well.\\r\\nOn the east coast is the Athene Glacier; the Arctowski and Akerlundh Nunataks are both just off the east coast. A number of smaller peninsulas extend from the main Antarctic Peninsula including Hollick-Kenyon Peninsula and Prehn Peninsula at the base of the Antarctic Peninsula. Also located here are the Scaife Mountains. The Eternity Range is found in the middle of the peninsula. Other geographical features include Avery Plateau, the twin towers of Una's Peaks.\\r\\nBecause the Antarctic Peninsula, which reaches north of the Antarctic Circle, is the most northerly part of Antarctica, it has the mildest climates within this continent. Its temperatures are warmest in January, averaging 1 to 2?C (34 to 36?F), and coldest in June, averages from ?15 to ?20?C (5 to ?4?F). Its west coast from the tip of the Antarctic Peninsula south to 68S, which has a maritime Antarctic climate, is the mildest part of the Antarctic Peninsula. Within this part of the Antarctic Peninsula, temperatures exceed 0?C (32?F) for 3 or 4 months during the summer, and rarely fall below ?10?C (14?F) during the winter. Farther south along the west coast and the northeast coast of the peninsula, mean monthly temperatures exceed 0?C (32?F) for only 1 or 2 months of summer and average around ?15?C (5?F) in winter. The east coast of the Antarctic Peninsula south of 63S is generally much colder, with mean temperatures exceeding 0?C (32?F) for only 0 or 1 month of summer, and winter mean temperatures ranging from ?5 to ?25?C (23 to ?13?F). The colder temperatures of the southeast, Weddell Sea side, of the Antarctic Peninsula are reflected in the persistence of ice shelves that cling to the eastern side.[11][12]\\r\\nPrecipitation varies greatly within the Antarctic Peninsula. From the tip of the Antarctic Peninsula south to 68 degrees South, precipitation averages 35ÿ50?cm (14ÿ20?in) per year. A good portion of this precipitation falls as rain during the summer, on two-thirds of the days of the year, and with little seasonal variation in amounts. Between about 68S and 63S on the west coast of the Antarctic Peninsula and along its northeast coast, precipitation is 35?cm (14?in) or less with occasional rain. Along the east coast of the Antarctic Peninsula south of 63S, precipitation ranges from 10 to 15?cm (3.9 to 5.9?in). In comparison, the subantarctic islands have precipitation of 100ÿ200?cm (39ÿ79?in) per year and the dry interior of Antarctica is a virtual desert with only 10?cm (3.9?in) precipitation per year.[12]\\r\\nBecause of issues concerning global climate change, the Antarctic Peninsula and adjacent parts of the Weddell Sea and its Pacific continental shelf have been the subject of intensive geologic, paleontologic, and paleoclimatic research by interdisciplinary and multinational groups over the last several decades. The combined study of the glaciology of its ice sheet and the paleontology, sedimentology, stratigraphy, structural geology, and volcanology of glacial and nonglacial deposits of the Antarctic Peninsula has allowed the reconstruction of the paleoclimatology and prehistoric ice sheet fluctuation of it for over the last 100 million years. This research shows the dramatic changes in climate, which have occurred within this region after it reached its approximate position within the Antarctic Circle during the Cretaceous Period.[13][14][15][16][17]\\r\\nThe Fossil Bluff Group, which outcrops within Alexander Island, provides a detailed record, which includes paleosols and fossil plants, of Middle Cretaceous (Albian) terrestrial climates. The sediments that form the Fossil Bluff Group accumulated within a volcanic island arc, which now forms the bedrock backbone of the Antarctic Peninsula, in prehistoric floodplains and deltas and offshore as submarine fans and other marine sediments. As reflected in the plant fossils, paleosols, and climate models, the climate was warm, humid, and seasonally dry. According to climate models, the summers were dry and winters were wet. The rivers were perennial and subject to intermittent flooding as the result of heavy rainfall.[15][18]\\r\\nWarm high-latitude climates reached a peak during the mid-Late Cretaceous Cretaceous Thermal Maximum. Plant fossils found within the Late Cretaceous (Coniacian and Santonian-early Campanian) strata of the Hidden Lake and Santa Maria formations, which outcrop within James Ross, Seymour, and adjacent islands, indicate that this emergent volcanic island arc enjoyed warm temperate or subtropical climates with adequate moisture for growth and without extended periods of below freezing winter temperatures.[15][19]\\r\\nAfter the peak warmth of the Cretaceous thermal maximum the climate, both regionally and globally, appears to have cooled as seen in the Antarctic fossil wood record. Later, warm high-latitude climates returned to the Antarctic Peninsula region during the Paleocene and early Eocene as reflected in fossil plants. Abundant plant and marine fossils from Paleogene marine sediments that outcrop on Seymour Island indicate the presence of cool and moist, high-latitudes environment during the early Eocene.[13][15]\\r\\nDetailed studies of the paleontology, sedimentology, and stratigraphy of glacial and nonglacial deposits within the Antarctic Peninsula and adjacent parts of the Weddell Sea and its Pacific continental shelf have found that it has become progressively glaciated as the climate of Antarctica dramatically and progressively cooled during the last 37 million years. This progressive cooling was contemporaneous with a reduction in atmospheric CO2 concentrations. During this climatic cooling, the Antarctic Peninsula was probably the last region of Antarctica to have been fully glaciated. Within the Antarctic Peninsula, mountain glaciation was initiated during the latest Eocene, about 37ÿ34?Ma. The transition from temperate, alpine glaciation to a dynamic ice sheet occurred about 12.8?Ma. At this time, the Antarctic Peninsula formed as the bedrock islands underlying it were overridden and joined together by an ice sheet in the early Pliocene about 5.3ÿ3.6?Ma. During the Quaternary period, the size of the West Antarctic Ice Sheet has fluctuated in response to glacialÿinterglacial cycles. During glacial epochs, this ice sheet was significantly thicker than it is currently and extended to the edge of the continental shelves. During interglacial epochs, the West Antarctica Ice Sheet was thinner than during glacial epochs and its margins lay significantly inland of the continental margins.[13][14][15]\\r\\nDuring the Last Glacial Maximum, about 20,000 to 18,000 years ago, the ice sheet covering the Antarctic Peninsula was significantly thicker than it is now. Except for a few isolated nunataks, the Antarctic Peninsula and its associated islands were completely buried by the ice sheet. In addition, the ice sheet extended past the present shoreline onto the Pacific outer continental shelf and completely filled the Weddell Sea up to the continental margin with grounded ice.[13][16][17][20]\\r\\nThe deglaciation of the Antarctic Peninsula largely occurred between 18,000 and 6,000 years ago as an interglacial climate was established in the region. It initially started about 18,000 to 14,000 years ago with retreat of the ice sheet from the Pacific outer continental shelf and the continental margin within the Weddell Sea. Within the Weddell Sea, the transition from grounded ice to a floating ice shelf occurred about 10,000 years ago. The deglaciation of some locations within the Antarctic Peninsula continued until 4,000 to 3,000 years ago. Within the Antarctic Peninsula, an interglacial climatic optimum occurred about 3,000 to 5,000 years ago. After the climate optimum, a distinct climate cooling, which lasted until historic times, occurred.[16][17][20][21]\\r\\nThe Antarctic Peninsula is a part of the world that is experiencing extraordinary warming.[22] Each decade for the last five, average temperatures in the Antarctic Peninsula have risen by 0.5?C (0.90?F).[23] Ice mass loss on the peninsula occurred at a rate of 60 billion tons / year in 2006,[24] with the greatest change occurring in the northern tip of the peninsula.[25] Seven ice shelves along the Antarctic Peninsula have retreated or disintegrated in the last two decades.[22] Research by the United States Geological Survey has revealed that every ice front on the southern half of the peninsula experienced a retreat between 1947 and 2009.[26] According to a study by the British Antarctic Survey, glaciers on the peninsula are not only retreating but also increasing their flow rate as a result of increased buoyancy in the lower parts of the glaciers.[27] Professor David Vaughan has described the disintegration of the Wilkins Ice Shelf as the latest evidence of rapid warming in the area.[28] The Intergovernmental Panel on Climate Change has been unable to determine the greatest potential effect on sea level rise that glaciers in the region may cause.[27]\\r\\nThe coasts of the peninsula have the mildest climate in Antarctica and moss and lichen-covered rocks are free of snow during the summer months, although the weather is still intensely cold and the growing season very short. The plant life today is mainly mosses, lichens and algae adapted to this harsh environment, with lichens preferring the wetter areas of the rocky landscape. The most common lichens are Usnea and Bryoria species. Antarctica's two flowering plant species, the Antarctic hair grass (Deschampsia antarctica) and Antarctic pearlwort (Colobanthus quitensis) are found on the northern and western parts of the Antarctic Peninsula, including offshore islands, where the climate is relatively mild. Lagotellerie Island in Marguerite Bay is an example of this habitat.[11][12][29]\\r\\nAntarctic krill are found in the seas surrounding the peninsula and the rest of the continent. The crabeater seal spends most of its life in the same waters feeding on krill. Bald notothen is a cryopelagic fish that lives in sub-zero water temperatures around the peninsula. Vocalizations of the sei whale can be heard emanating from the waters surrounding the Antarctic Peninsula.[11]\\r\\nThe animals of Antarctica live on food they find in the seanot on landand include seabirds, seals and penguins. The seals include: leopard seal (Hydrurga leptonyx), Weddell seal (Leptonychotes weddellii), the huge southern elephant seal (Mirounga leonina), and crabeater seal (Lobodon carcinophagus).[11]\\r\\nPenguin species found on the peninsula, especially near the tip and surrounding islands, include the chinstrap penguin, emperor penguin, gentoo penguin and the Adelie penguin. Petermann Island is the world's southernmost colony of gentoo penguins. The exposed rocks on the island is one of many locations on the peninsula that provides a good habitat for rookeries. The penguins return each year and may reach populations of more than ten thousand. Of these the most common on the Antarctic Peninsula are the chinstrap and gentoo, with the only breeding colony of emperor penguins in West Antarctica an isolated population on the Dion Islands, in Marguerite Bay on the west coast of the peninsula. Most emperor penguins breed in East Antarctica.[11][12][29]\\r\\nSeabirds of the Southern Ocean and West Antarctica found on the peninsula include: southern fulmar (Fulmarus glacialoides), the scavenging southern giant petrel (Macronectes giganteus), Cape petrel (Daption capense), snow petrel (Pagodroma nivea), the small Wilson's storm-petrel (Oceanites oceanicus), imperial shag (Phalacrocorax atriceps), snowy sheathbill (Chionis alba), the large south polar skua (Catharacta maccormicki), brown skua (Catharacta l?nnbergi), kelp gull (Larus dominicanus), and Antarctic tern (Sterna vittata). The imperial shag is a cormorant which is native to many sub-Antarctic islands, the Antarctic Peninsula and southern South America.[11][12]\\r\\nAlthough this very remote part of the world has never been inhabited and is protected by the Antarctic Treaty System, which bans industrial development, waste disposal and nuclear testing, there is still a threat to these fragile ecosystems from increasing tourism, primarily on cruises across the Southern Ocean from the port of Ushuaia, Argentina.\\r\\nA rich record of fossil leaves, wood, pollen, and flowers demonstrates that flowering plants thrived in subtropical climates within the volcanic island arcs that occupied the Antarctic Peninsula region during the Cretaceous and very early Paleogene periods. The analysis of fossil leaves and flowers indicate that semitropical woodlands, which were composed of ancestors of plants that live in the tropics today, thrived within this region during a global thermal maximum with summer temperatures that averaged 20?C (68?F). The oldest fossil plants come from the middle Cretaceous (Albian) Fossil Bluff Group, which outcrop along the edge of Alexander Island. These fossils reveal that at this time the forests consisted of large conifers, with mosses and ferns in the undergrowth. The paleosols, in which trees are rooted, have physical characteristics indicative of modern soils that form under seasonally dry climates periodic high rainfall.[18] Younger Cretaceous strata, which outcrop within James Ross, Seymour, and adjacent islands, contain plants fossil of Late Cretaceous angiosperms with leaf morphotypes that are similar to those of living families such as Sterculiaceae, Lauraceae, Winteraceae, Cunoniaceae, and Myrtaceae. They indicate that the emergent parts of the volcanic island arc, the eroded roots of which now formed the central part of the Antarctic Peninsula, were covered by either warm temperate or subtropical forests.[19] These fossil plants are indicative of tropical and subtropical forest at high paleolatitudes during the Middle and Late Cretaceous, which grew in climates without extended periods of below freezing winter temperatures and with adequate moisture for growth.[15] The Cretaceous strata of James Ross Island also yielded the dinosaur genera Antarctopelta, which was the first dinosaur fossil to be found on Antarctica.[30]\\r\\nPaleogene and Early Eocene marine sediments that outcrop on Seymour Island contains plant-rich horizons. The fossil plants are dominated by permineralized branches of conifers and compressions of angiosperm leaves, and found within carbonate concretions. These fossils, which date to about 51.5ÿ49.5?Ma, are dominated by leaves, cone scales, and leafy branches of Araucarian conifers, very similar in all respects to living Araucaria araucana (monkey puzzle) from Chile. They suggest that the adjacent parts of the prehistoric Antarctic Peninsula were covered by forests that grew in a cool and moist, high-latitude environment during the early Eocene.[15]\\r\\nDuring the Cenozoic climatic cooling, the Antarctic Peninsula was the last region of Antarctica to have been fully glaciated according to current research. As a result, this region was probably the last refugium for plants and animals that had inhabited Antarctica after it separated from the Gondwanaland supercontinent. Analysis of paleontologic, stratigraphic, and sedimentologic data acquired from the study of drill core and seismic acquired during the Shallow Drilling on the Antarctic Continental Shelf (SHALDRIL) and other projects and from fossil collections from and rock outcrops within Alexander, James Ross, King George, Seymour, and South Shetland Islands has yielded a record of the changes in terrestrial vegetation that occurred within the Antarctic Peninsula over the course of the past 37 million years.[14][15]\\r\\nThis research found that vegetation within the Antarctic Peninsula changed in response to a progressive climatic cooling that started with the initiation of mountain glaciation in the latest Eocene, about 37ÿ34?Ma. The cooling was contemporaneous with glaciation elsewhere in Antarctica and a reduction in atmospheric CO2 concentrations. Initially, during the Eocene, this climate cooling resulted in a decrease in diversity of the angiosperm-dominated vegetation that inhabited the northern Antarctic Peninsula. During the Oligocene, about 34ÿ23?Ma, these woodlands were replaced by a mosaic of southern beech (Nothofagus) and conifer-dominated woodlands and tundra as the climate continued to cool. By middle Miocene, 16ÿ11.6?Ma, a tundra landscape completely replaced any remaining woodlands. At this time, woodlands became completely extirpated from the Antarctic Peninsula and all of Antarctica. A tundra landscape probably persisted until about 12.8?Ma when the transition from a temperate, alpine glaciation to a dynamic ice sheet occurred. Eventually, the Antarctic Peninsula was overridden by an ice sheet, which has persisted without any interruption to this day, in the early Pliocene, about 5.3ÿ3.6?Ma.[14][15]\\r\\nCoordinates: 6930S 6500W? / ?69.500S 65.000W? / -69.500; -65.000","input":"What kind of habitat is the antarctic peninsula?"},{"output":"SunTrust Park in Cumberland, Georgia, home of the Atlanta Braves","context":"The following is a list of Major League Baseball stadiums, their locations, their first year of usage and home teams.\\r\\nThe newest Major League Baseball (MLB) ballpark is SunTrust Park in Cumberland, Georgia, home of the Atlanta Braves, which opened for the 2017 season. Fenway Park in Boston, home of the Boston Red Sox, is the oldest, having opened in 1912.\\r\\nTen MLB stadiums do not have corporate naming rights deals: Angel Stadium, Dodger Stadium, Fenway Park, Kauffman Stadium, Marlins Park, Nationals Park, OaklandÿAlameda County Coliseum, Oriole Park at Camden Yards, Wrigley Field, and Yankee Stadium. Wrigley Field is named for former Chicago Cubs owner William Wrigley Jr. and not the Wrigley Company; Kauffman Stadium is named for original Kansas City Royals owner Ewing Kauffman, who brought baseball back to Kansas City; and Fenway Park is named for the FenwayÿKenmore neighborhood of Boston where it is located.","input":"What is the newest major league baseball stadium?"},{"output":"Berkeley Preparatory School in Tampa, Florida","context":"Nelson Efamehule Agholor (born May 24, 1993) is an American football wide receiver for the Philadelphia Eagles of the National Football League (NFL). He played college football at USC. He was the 20th overall pick in the 2015 NFL Draft. With the Eagles, he won Super Bowl LII over the New England Patriots.\\r\\n\\r\\n\\r\\nBorn in Lagos, Nigeria, Agholor moved to the United States when he was five years old.[1] He attended Berkeley Preparatory School in Tampa, Florida where he played running back, wide receiver, and defensive back for the Berkeley Buccaneers. He was rated by Rivals.com as a five-star recruit and was ranked as the third best wide receiver in his class.[2] He committed to the University of Southern California in January 2012 over Notre Dame, Oklahoma, Florida, Florida State, and Alabama.[3]\\r\\nAs a true freshman in 2012, Agholor played in all 13 games as a backup wide receiver and recorded 19 receptions for 340 yards and two touchdowns.\\r\\nAs a sophomore in 2013, he became a starter.[4] Agholor started all 14 games, totaling 56 receptions, 918 yards, and six touchdowns as a receiver. Along with being the leading receiver, Agholor returned punts and kicks for the Trojans. He returned 18 punts for 343 yards and two touchdowns, and 10 kickoffs for 175 yards. Agholor was recognized as a second-team All-American by numerous sports outlets for his punt returning. Agholor returned as a starter his junior season in 2014. He led the team with 104 receptions for 1,313 yards and 12 touchdowns.\\r\\nAfter his junior season, Agholor decided to forego his senior season and entered the 2015 NFL Draft.[5][6]\\r\\n[7][8]\\r\\nAgholor was selected by the Philadelphia Eagles in the first round with the 20th overall pick of the 2015 NFL Draft. He signed a four-year contract on May 7, 2015, worth around $9.4 million with a signing bonus of $5.1 million.[9]\\r\\nOn December 13, 2015, Agholor scored his first NFL career touchdown, a 53-yard reception from quarterback Sam Bradford, in a matchup against the Buffalo Bills.[10] During his rookie season in 2015, Agholor played 13 games with 283 receiving yards and a touchdown. During his second season in 2016, Agholor played 15 games with 365 receiving yards and two touchdowns.[11]\\r\\nOn March 13, 2017, it was reported that Agholor would switch from the #17, which he wore in his first two seasons, to the #13. He opted to give the #17 to newly acquired free agent wide receiver Alshon Jeffery.[12]\\r\\nDuring the 2017 season, Agholor found more success when he was switched to a slot receiver role. On September 10, 2017, in the season opening 30ÿ17 victory over the Washington Redskins, Agholor had a 58-yard receiving touchdown from quarterback Carson Wentz in the first quarter. He finished the game with six receptions for 86 yards.[13] On September 17, in a Week 2 27ÿ20 loss to the Kansas City Chiefs, he recorded his second touchdown of the season late in the fourth quarter to cut into the Chiefs' lead.[14] He would end the 2017 regular season with his best season yet, getting more receiving yards and touchdowns then his previous two seasons combined.\\r\\nDuring Super Bowl LII against the New England Patriots, Agholor finished with 84 receiving yards as the Eagles won 41-33, giving them their first Super Bowl championship in franchise history.[15]\\r\\nIn June 2016, Agholor was accused of sexually assaulting a dancer at Cheerleaders Gentlemans Club.[16] Agholor was at the club located nearby the teams off-season practice site with two Eagles teammates.[16]\\r\\nOn July 15, 2016, it was announced that Agholor would not face charges in the investigation.[17]","input":"Where did nelson agholor go to high school?"},{"output":"June 12, 2015","context":"","input":"When did net neutrality first come into effect?"},{"output":"Urmila","context":"Urmila is a character in the Hindu epic Ramayana. She was daughter of King Janaka of Janakpur and his wife Queen Sunaina and also a younger sister of Sita. She was wife of Lakshmana, younger brother of Rama. They had two sons - Angada and Chandraketu.[1] When Lakshman went to exile along with Ram and Sita, Urmila was ready to accompany him but he hesitated and asked her to stay back in Ayodhya to take care of his aging parents. Urmila is notable for her unparalleled sacrifice called Urmila Nidra.[2]\\r\\nIn Bharatpur district of Rajasthan, there is a temple dedicated to Lakshman and Urmila. The temple was built in 1870 AD by the then ruler Balwant Singh of Bharatpur and is considered as a royal temple by the royal family of Bharatpur State.[3]\\r\\nWhen Rama was exiled to the forest for fourteen years on Kaikeyi's insistence, Urmila tried to persuade Lakshmana to permit her to following him into exile but to no avail. Lakshmana reasoned that he will have no time for her in his day and night steadfast service to his brother and that Urmila's welfare was in staying back. He persuaded Urmila that her welfare would be a concern in the forest and could hinder his services to his brother. After much persuasion, Urmila reluctantly agreed to stay back contemplating,if she could serve her husband any way possible.\\r\\nAs the night fell on the first day of the exile, Lakshmana stood guard over Ram and Sita with a strong resolve not to sleep until the exile ended. As Lakshmana stood guard over his brother's dwelling, a resplendent goddess called Nidra Devi manifested before Lakshmana. On Lakshmana's enquiry, she introduced herself as the Goddess of Sleep and informed him that not sleeping for fourteen years is an act of defiance against nature. Lakshmana requested Nidra Devi for a way out so that he could carry out his Dharma towards his brother. Impressed by Lakshmana's devotion towards his brother, Nidra Devi put forth a workaround that if someone bears the burden of Lakshmana's share of sleep for fourteen years, he could have the exemption for fourteen years. Lakshmana requested Nidra Devi to approach his wife, Urmila, to help him.\\r\\nIn South India, Urmila Nidra is a term used to refer to deep sleep by a person who cannot be woken easily.","input":"Who is the wife of lakshmana in ramayana?"},{"output":"April 2, 1978","context":"","input":"When did the tv show dallas first air?"},{"output":"American football","context":"","input":"Which is the most popular sport in america?"},{"output":"Indians","context":"Mission San Francisco Solano was the 21st, last and northernmost mission in Alta California.[7] It was the only mission built in Alta California after Mexico gained independence from Spain. The difficulty of its beginning demonstrates the confusion resulting from that change in governance. The California Governor wanted a robust Mexican presence north of the San Francisco Bay to keep the Russians who had established Fort Ross on the Pacific coast from moving further inland. A young Franciscan friar from Mission San Francisco de Asis wanted to move to a location with a better climate and access to a larger number of potential converts.[8]\\r\\nThe Mission was successful given its short eleven year life but was smaller in number of converts and with lower productivity and diversity of industries than the older California missions.[9]\\r\\nThe mission building is now part of the Sonoma State Historic Park and is located in the city of Sonoma, California.\\r\\n\\r\\n\\r\\nFr. Jos Altimira age 33, arrived from Barcelona, Spain to serve at Mission San Francisco de Ass. The mission was not thriving because of its climate and had established a medical asistencia (\\"sub-mission\\") in San Rafael to help the missions ill neophytes (baptized Native Americans) recover their health. California Governor Luis Argello was interested in blocking the Russians at Bodega Bay and Fort Ross from moving further inland. Together they developed and presented to the party church authorities and the territory (legislature) a plan for moving Mission San Francisco de Ass and the San Rafael asistencia to a new location north of the Bay. The legislature approved but the church authorities did not respond (they had forwarded the plan to their superiors in Mexico).[10] Under the old Spanish regime, founding a new mission required the approval of both New Spain's Bishop and the Kings Viceroy.[11]\\r\\nBeginning in 1823, while waiting for a response from the church authorities, Fr. Altimira, with military escorts, began exploring north of the Bay for a suitable mission site. On July 4, 1823, the soldiers placed a large redwood cross on the place in the Sonoma Valley where they expected the new Mission San Francisco de Assis to be established. Then they celebrated Mass to consecrate the location. They then returned south to begin gathering men and materials to begin construction.[12]\\r\\nThe area around the selected site was not empty. It was near the northeast corner of the territory of the Coast Miwok,[13] Southern Pomo to the northwest, Wappo to the northeast, Suisunes and Ptwin peoples to the east.[14][15] A detachment of soldiers from the Presidio of San Francisco would be provided to protect the Mission and guard the neophytes.[16]\\r\\nAltimira with soldiers and neophytes primarily from Mission San Francisco de Ass returned to the Sonoma area near the end of August. Altimira decided there was a better place to build on the other side of the valley. Just after starting he received a letter from Father-President Sarria who refused Altimira permission to continue building. Fr. Altimira obeyed and the month of September saw continuing negotiations between Californias civil and religious leaders. On September 30 an agreement was reached: a new mission could be built and Fr. Altimira would be its minister, but Mission San Francisco de Ass would not be closed and the San Rafael asistencia had already been designated as a full mission (Mission San Rafael Arcngel).[17]\\r\\nBeginning in October 1823 Fr. Altimira had the opportunity to build his new mission at the location he chose but since Mission San Francisco de Ass would remain open this Mission needed a different patron saint. Altimira chose San Francisco Solano, a 17th-century Franciscan missionary to South America.[18] His company of soldiers and neophytes set about building all the facilities needed in a California mission. His annual report for 1823 listed no baptisms, one marriage, one funeral, a population of 482 Indians (all transferred from other missions) and 1341 animals.[19] The work had started too late in the year for anything to be planted and harvested.\\r\\nOn April 4, 1824, Passion Sunday, Father Altimira proudly dedicated his church. It was a crude, temporary structure but it symbolized development at the Mission. The church was built of whitewashed boards but was well furnished and decorated. Many of the articles were gifts from the Russians at Fort Ross. It also held a canvas painting of San Francisco Solano which had been donated by the Father-President. Furthermore, the Mission had been promised a relic of the patron saint to put in the altar.[20]\\r\\nThe Mission continued to develop until an argument arose about the sharing of the bountiful 1826 harvest Indians, not living at the Mission, were unhappy with the amount allocated for their work and burned some of the wooden buildings in protest. Fr. Altimira with a few faithful neophytes fled to Mission San Rafael Arcngel.[21]\\r\\nFr. Buenaventura Fortuni, an aging Spanish Franciscan who had been working at Mission San Jos, was assigned to replace Altimira.[22] Fr. Fortuni quickly reestablished order and morale and the work of building the mission restarted. He arranged the main buildings to form a large, square enclosure.\\r\\nIn 1830 Fr. Fortuni, having labored alone at this mission for 3 1/2 years, felt the need to transfer to another mission where the work load could be shared.[23] He was 58 years old when he was replaced by Fr. Jos Gutirrez, a Franciscan friar from South America. The Mexican government had in 1826 required that all the Spanish friars who would not pledge loyalty to Mexico leave. Fr. Fortuni had been exempted from this rule but all new churchmen would be required to take the pledge.[22]\\r\\nFr. Gutierrez continued to build and increased the agricultural effort.[24] By 1832 the mission had 27 rooms in the convento or priest's quarters, with a great adobe church at the east end, and a wooden storehouse (the original mission chapel) at the west end. Completing this enclosure were workshops where the Indians were taught to be craftsmen and created the items needed to help the mission be self-sufficient. Along the back of the courtyard were the living quarters and workrooms for the young Indian girls. In addition to the quadrangle, there were orchards, gardens, vineyards, fields of grain, a gristmill, houses for the soldiers and Indian families, a jail, a cemetery and an infirmary.[25]\\r\\nThe most successful year of this mission's short life span (11 years) was 1832. In his annual report for that year, Fr. Gutierrez recorded the following: 127 baptisms, 34 marriages, and 70 deaths; a total of 996 neophytes (coming from 35 area villages[26]); the livestock inventory included 6,000 sheep and goats, 900 horses, 13 mules, 50 pigs and 3,500 head of cattle. Crops were measured in fanegas, or Spanish bushels, a variable measure of volume generally between 50 and 60 liters. In 1832 the mission produced 800 fanegas of wheat, 1025 fanegas of barley, 52 fanegas of peas, 300 fanegas of corn, 32 fanegas of beans, and 2 fanegas of garbanzos.[27]\\r\\nIn 1833 the Mexican Congress decided to close all of the missions in Alta California with the passage of the Mexican secularization act of 1833. Governor Figueroa issued a regulation (Reglamento Provisional para la secularization de las Misiones) on August 9, 1834, outlining the requirements for the distribution of property (land, cattle, and equipment) to each missions neophytes.[28] Among the provisions were that \\"5. To each head of a family and to all over 20 years old, will be given from the Mission lands a lot not over 400 nor less than 100 varas square\\" (28 to 7 acres). Plus \\"6. ...pro rata...one-half of the livestock\\" and \\"7. ... half or less of the existing chattels, tools, and seed...\\".[29]\\r\\nMission San Francisco Solano officially ceased to exist on November 3, 1834, when it was designated a First Class Parish. The Spanish missionaries were to be replaced by parish priests - the first was Fr. Lorenzo Quijas who had earlier been assigned to Sonoma and San Rafael.[30]In,\\r\\nLieutenant (teniente) Mariano Vallejo, Commandant of the Presidio of San Francisco, was named administrator (comisionado) to oversee the closing of the Mission under the Reglamento.[31] Fr. Quijas moved back to San Rafael in July, 1835, after many disputes with Guadalupe Antonio Ortega, Vallejo's majordomo, to whom Vallejo had delegated the work of secularization. Ortega (sometimes call Sergeant Ortega[32]) was uneducated, coarse and licentious\\".[33] Right after returning to San Rafael, Padre Quijas wrote a letter to Commissary Perfect Garcia Diego, his superior, complaining about the situation in Sonoma and specifically the \\"...abominable deeds of Ortega....\\" Quijas then gives names of witnesses to be called against Ortega.[34] Upon receipt of the letter Fr. Diego forward it to Governor Jos Figueroa demanding some action against Ortega. The Governor was critically ill and died at the end of the following month. No action was taken.[35] It wasn't until the summer of 1837, because of new scandals and unsatisfactory accounts, that Ortega was removed.[36]\\r\\nAfter Fr. Quijas left, the neophyte population decreased rapidly (most returning to their home villages - taking their movable property with them, or moving to ranchos {including Vallejo's Petaluma Adobe} to work, or staying in Sonoma as servants).[37] Some former Mission Indians reportedly received their allotted land and cattle from the Mission (none of these small plots of land were permanently recorded.)[38] In August 1839, the government sent William Edward Petty Hartnell as Visitador General de Misiones to check compliance with the Reglamento but Vallejo avoided responding - claiming he did not have time because of military affairs. No effective review of the secularization of the Sonoma mission was even completed.[39]\\r\\nThe mission buildings rapidly fell into disrepair. The town of Sonoma was growing and building materials were in great demand. Roof tiles, timbers, and adobe bricks were salvaged from the mission buildings. After the settlers had cannibalized the old buildings, nature began recycling the remnants.[14]\\r\\nIn 1841, Mariano Vallejo ordered a small adobe chapel to be built on the location of the first wooden mission chapel. It became the church of the parish and replaced the large mission church which was rapidly deteriorating. It stood on the west end of the Convento so is often thought to be the church of the old mission.[40]\\r\\nDuring 1863 President Abraham Lincoln transferred ownership of all the mission churches in California to the Roman Catholic Church. In 1881, the Sonoma church property was sold to a local businessman and a new parish church was built across town. At one time, the old adobe chapel was used as a warehouse. The Convento may have been used as a winery.[14]\\r\\nIn 1903, the two remaining mission buildings were purchased by California Historic Landmarks League and became part of the California Park System in 1906. By 1913, both had been reconstructed. After the 1940s, the former church and Convento were remodeled along more authentic lines suited to exhibits devoted exclusively to mission history.[14]\\r\\nDedicated in 1999, the Sonoma Mission Indian Memorial honors the more than 800 native people (including over 200 children) who died while living and working at the Mission between 1824 and 1839. Their Christian names, as recorded by the priests in the Missions records, are inscribed on this granite memorial.[41] European diseases such as measles and smallpox, for which Native Americans had no inherited resistance, with the overcrowded and unhealthful living conditions at all California missions (especially for women and children) contributed to the high death rate.[42]\\r\\nOn June 1, 1932, Mission San Francisco Solano was designated California Historical Landmark #3.\\r\\nInterior of Vallejo's Chapel\\r\\nIndian Memorial\\r\\nMission Solano State Landmark Plaque","input":"Who lived at the san francisco solano mission?"},{"output":"August 16, 1977","context":"\\"Way Down\\" is a song recorded by Elvis Presley. Recorded in October 1976, it was his last single released before his death on August 16, 1977. The song was written by Layng Martine, Jr. and was later covered by Status Quo and Cliffhanger. Presley recorded the song at his home studio in Graceland on 29 October 1976.\\r\\nReleased as a single (with \\"Pledging My Love\\" on the B-side) on June 6, 1977, it was his single at the time of his death. It initially peaked at No. 31 on the Billboard Hot 100 chart dated August 6, 1977 and had fallen to No. 53 on the chart for the week ending August 27, 1977. Thereafter, it reversed direction and reached an even higher peak at No. 18 on 24 September ÿ 1 October 1977. \\"Way Down\\" reached No. 1 on the American Country chart the week he died.[1] Overseas, the song hit the number one in the UK Singles Chart week ending 3 September for five weeks, [2] just over seven years after his previous 16th UK number one single, \\"The Wonder of You\\", in August 1970. His previous single, \\"Moody Blue\\", had been a number one hit on the US Country Charts earlier in 1977. \\"Way Down\\" was reissued in April 2005 and reached No. 2 on the UK Singles Chart.[3]\\r\\nThe recording also featured J.D. Sumner singing the words \\"way on down\\" at the end of each chorus down to the note low C (C2). At the end of the song, this phrase is octaved, reaching a double low C (C1, three octaves below middle C).[4] This note was first accomplished by Sumner in a 1966 recording of the hymn \\"Blessed Assurance.\\"","input":"When was way down by elvis presley released?"},{"output":"state and territorial legislatures","context":"Coordinates: 28370N 771230E? / ?28.61667N 77.20833E? / 28.61667; 77.20833\\r\\n245\\r\\nGovernment coalition (87)\\r\\nNational Democratic Alliance (87)\\r\\nOpposition Parties (158)\\r\\nUnited Progressive Alliance (57)\\r\\nJanata Parivar Parties (7)\\r\\nUnaligned Parties (79)\\r\\nOthers (15)\\r\\nThe Rajya Sabha or Council of States is the upper house of the Parliament of India. Membership of Rajya Sabha is limited by the Constitution to a maximum of 250 members, and current laws have provision for 245 members. Most of the members of the House are indirectly elected by state and territorial legislatures using single transferable votes, while the President can appoint 12 members for their contributions to art, literature, science, and social services. Members sit for staggered six-year terms, with one third of the members retiring every two years.[5]\\r\\nThe Rajya Sabha meets in continuous sessions, and unlike the Lok Sabha, the lower house of Parliament, is not subject to dissolution. However, the Rajya Sabha, like the Lok Sabha can be prorogued by the President. The Rajya Sabha has equal footing in all areas of legislation with Lok Sabha, except in the area of supply, where the Lok Sabha has overriding powers. In the case of conflicting legislation, a joint sitting of the two houses can be held. However, since the Lok Sabha has twice as many members as the Rajya Sabha, the former would normally hold the greater power. Joint sittings of the Houses of Parliament of India are rare, and in the history of the Republic, only three such joint-sessions have been held; the latest one for the passage of the 2002 Prevention of Terrorism Act.\\r\\nThe Vice President of India (currently, Venkaiah Naidu) is the ex-officio Chairman of the Rajya Sabha, who presides over its sessions. The Deputy Chairman, who is elected from amongst the house's members, takes care of the day-to-day matters of the house in the absence of the Chairman. The Rajya Sabha held its first sitting on 13 May 1952.[6] The salary and other benefits for a member of Rajya Sabha are same as for a member of Lok Sabha.\\r\\nRajya Sabha members are elected by state legislatures rather than directly through the electorate by single transferable vote method.\\r\\n\\r\\n\\r\\nArticle 84 of the Constitution lays down the qualifications for membership of Parliament. A member of the Rajya Sabha must:[7]\\r\\nIn addition, twelve members are nominated by the President of India having special knowledge in various areas like arts and science. However, they are not entitled to vote in Presidential elections as per Article 55 of the Constitution.\\r\\nThe Constitution of India places some restrictions on Rajya Sabha which makes Lok Sabha more powerful in certain areas in comparison.\\r\\nThe definition of a money bill is given in article 110 of constitution of India. A money bill can be introduced only in the Lok Sabha by a minister and only on recommendation of President of India. When the Lok Sabha passes a money bill then the Lok Sabha sends money bill to the Rajya Sabha council of states for 14 days during which it can make recommendations. Even if Rajya Sabha fails to return the money bill in 14 days to the Lok Sabha, that bill is deemed to have passed by both the Houses. Also, if the Lok Sabha rejects any (or all) of the amendments proposed by the Rajya Sabha, the bill is deemed to have been passed by both Houses of Parliament of India in the form the Lok Sabha finally passes it. This is because the Lok Sabha has largest number of representatives of peoples of India and so the Lok Sabha lower house also called house of the peoples is more powerful in comparison with Rajya Sabha council of states upper house. Hence, Rajya Sabha can only give recommendations for a money bill but Rajya Sabha cannot amend a money bill this is to ensure that Rajya Sabha must not add any non money matters in money bill. Lok Sabha can reject all the recommendations of Rajya Sabha or can accept some or all of the recommendations. Decisions of the speaker of the Lok Sabha are final. There is no joint sitting of both houses with respect to money bills, because all final decisions are taken by the Lok Sabha.[9]\\r\\nArticle 108 provides for a joint sitting of the two Houses of Parliament in certain cases. A joint sitting can be convened by the President of India when one house has either rejected a bill passed by the other house, has not taken any action on a bill transmitted to it by the other house for six months, or has disagreed to the amendments proposed by the Lok Sabha on a bill passed by it. Considering that the numerical strength of Lok Sabha is more than twice that of Rajya Sabha, Lok Sabha tends to have a greater influence in a joint sitting of Parliament. A joint session is chaired by the Speaker of Lok Sabha. Also, because the joint session is convened by the President on advice of the government, which already has a majority in Lok Sabha, the joint session is usually convened to get bills passed through a Rajya Sabha in which the government has a minority.\\r\\nJoint sessions of Parliament are a rarity, and have been convened three times in last 69 years, for the purpose of passage of a specific legislative act, the latest time being in 2002:\\r\\nUnlike the Lok Sabha, a member of the Rajya Sabha cannot bring to the house a no-confidence motion against the government.\\r\\nIn Indian federal structure, Rajya Sabha is a representative of the States in the Union legislature (Hence the name, Council of States). Hence, Rajya Sabha is granted powers that protect the rights of States against the Union.\\r\\nThe Constitution empowers Parliament of India to make laws on the matters reserved for States (States List). However, this can only be done if Rajya Sabha first passes a resolution by two-thirds special majority granting such a power to the Union Parliament. The union government cannot make a law on a matter reserved for states without any authorisation from Rajya Sabha.\\r\\nRajya Sabha, by a two-thirds super majority can pass a resolution empowering the Government of India to create more All-India Services common to both Union and States, including a judicial service.\\r\\nSeats are allotted in proportion to the population of people of each state or union territory in such a manner that smaller states have slight advantage over more populous states.[10] As the members are elected by the state legislature, smaller Union Territories which are not States and do not have legislatures cannot have representation in Rajya Sabha. Hence, Andaman & Nicobar Islands, Lakshadweep, Chandigarh, Daman & Diu and Dadra & Nagar Haveli do not send any representatives to Rajya Sabha. 12 members are nominated by the President.[11][12]\\r\\nAs per the Fourth Schedule to the Constitution of India on 26 January 1950, the Rajya Sabha was to consist of 216 members of which 12 members were to be nominated by the President and the remaining 204 elected to represent the States.[12] The present strength, however, is 245 members of whom 233 are representatives of the states and union territories and 12 are nominated by the President.[12] The twelve nominated members of the Rajya Sabha are persons who are eminent in particular fields, and are well known contributors in the particular field. A few examples of such nominated persons are cricketing icon Sachin Tendulkar, former RBI Governor Bimal Jalan and famous lyricist and poet Javed Akhtar. As of March 2014, each state or union territory specified in the first column of the following table, there shall be allotted the number of seats specified in the second column thereof opposite to that State or that union territory, as the case may be:[13]\\r\\nRajya Sabha Secretariat (As of 9 April 2018):[15]\\r\\nBesides the Chairman (Vice-President of India) and the Deputy Chairman, there is also a position called Leader of the House. This is a cabinet minister ÿ the prime minister if he is a member of the House, or another nominated minister. The Leader has a seat next to the Chairman, in the front row.\\r\\nBesides the Leader of the House, who is leading the majority, there is also a Leader of the Opposition (LOP) ÿ leading the opposition parties. The function was only recognized in the Salary and Allowances of Leaders of the Opposition in Parliament Act 1977. This is commonly the leader of the largest non-government party, and is recognized as such by the Chairman.\\r\\nThe following people have been the Leader of the Opposition in the Rajya Sabha:\\r\\nThe Secretariat of Rajya Sabha was set up pursuant to the provisions contained in Article 98 of the Constitution. The said Article, which provides for a separate secretarial staff for each House of Parliament, reads as follows:- 98. Secretariat of Parliament ÿ Each House of Parliament shall have a separate secretarial staff: Provided that nothing in this clause shall be construed as preventing the creation of posts common to both Houses of Parliament. (2) Parliament may by law regulate the recruitment and the conditions of service of persons appointed to the secretarial staff of either House of Parliament.\\r\\nThe Rajya Sabha Secretariat functions under the overall guidance and control of the Chairman. The main activities of the Secretariat inter alia include the following?:\\r\\n(i) providing secretarial assistance and support to the effective functioning of the Council of States (Rajya Sabha) possible to Members of Rajya Sabha; (iv) servicing the various Parliamentary Committees; (v) preparing research and reference material and bringing out various publications; (vi) recruitment of manpower in the Sabha Secretariat and attending to personnel matters; and (vii) preparing and publishing a record of the day-to-day proceedings of the Rajya Sabha and bringing out such other publications, as may be required concerning the functioning of the Rajya Sabha and its Committees. In the discharge of his constitutional and statutory responsibilities, the Chairman, Rajya Sabha is assisted by the Secretary-General, who holds the rank equivalent[16] to the Cabinet Secretary to the Government of India. The Secretary-General, in turn, is assisted by senior functionaries at the level of Secretary, Additional Secretary, Joint Secretary and other officers and staff of the Secretariat.\\r\\nRajya Sabha Television (RSTV) is a 24-hour a day, seven day a week parliamentary TV channel fully owned and operated by the Rajya Sabha. The channel is aimed at providing in-depth coverage and analysis of parliamentary affairs especially the functioning of and developments related to Rajya Sabha. During sessions of Parliament, apart from telecasting live coverage of the proceedings of Rajya Sabha, RSTV presents incisive analysis of the proceedings of the House as well as other day-to-day parliamentary events and developments.[16]","input":"Who elect the members of the rajya sabha?"},{"output":"Mobile Telecommunications Limited","context":"Mobile Telecommunications Limited (MTC) is a mobile telecommunications company in Namibia providing cellular access. It is the largest mobile operator in Namibia with over two million active subscribers.[1] MTC was established in 1994 and was the only cellular provider in Namibia at that time. Today its competitors in Namibia are TN Mobile and Telecom.\\r\\nBefore Cell One and Telecom Switch entered the market, MTC had the monopoly on mobile telecommunications and 3G Internet access. MTC is still the most recognised mobile telecommunication company in Namibia. Its competitors are Telecom Namibia's TN Mobile and Paratus Telecom.\\r\\nMTC was established as a joint venture between the Namibian government, Namibia Post and Telecommunications Holdings (NPTH), and Telia and Swedfund. During May 2004, NPTH concluded a deal that saw it hold 100% of the shares in MTC by acquiring the 49% held by Telia Overseas AB and Swedfund International AB. During 2006 the sale of 34% of MTC shares to Portugal Telecom was concluded for N$1.34 billion while the Namibian government retains the remainder of the stake through NPTH.[2]\\r\\nMTC launched Netman 3G on 23 June 2010 and on 16 May 2012, the company launched Netman 4G/LTE, making it the second mobile operator to provide 4G services in Africa. MTC Netman 4G provides download speeds of up to 100 Mbit/s.[3] The company's 3G HSDPA+ Network allows for a download speed of up 7.2 Mbit/s in Namibia's major towns. It further runs two modern mobile switching centres in Windhoek and Oshakati with capacity to accommodate rapidly rising number of customers of over 2 million active users.\\r\\nMTC also operates the only full service customer contact centre in Namibia dealing with service queries ranging from telephony, sms, fax, GPRS, data, voicemail and 3G/HSDPA. A staff of 421 persons serves a diverse market of both pre- and postpaid subscribers.","input":"What is the first mobile operate in namibia?"},{"output":"dates from the 13th to the 10th centuries BC","context":"\\r\\n\\r\\nThe Epic of Gilgamesh (/??l?m??/)[1] is an epic poem from ancient Mesopotamia that is often regarded as the earliest surviving great work of literature. The literary history of Gilgamesh begins with five Sumerian poems about Bilgamesh (Sumerian for \\"Gilgamesh\\"), king of Uruk, dating from the Third Dynasty of Ur (c.?2100 BC). These independent stories were later used as source material for a combined epic. The first surviving version of this combined epic, known as the \\"Old Babylonian\\" version, dates to the 18th century BC and is titled after its incipit, Shtur eli sharrؐ (\\"Surpassing All Other Kings\\"). Only a few tablets of it have survived. The later \\"standard\\" version dates from the 13th to the 10th centuries BC and bears the incipit Sha naqba ؐmuru (\\"He who Saw the Abyss\\", in modern terms: \\"He who Sees the Unknown\\"). Approximately two thirds of this longer, twelve-tablet version have been recovered. Some of the best copies were discovered in the library ruins of the 7th-century BC Assyrian king Ashurbanipal.\\r\\n\\r\\nThe first half of the story discusses Gilgamesh, king of Uruk, and Enkidu, a wild man created by the gods to stop Gilgamesh from oppressing the people of Uruk. After Enkidu becomes civilized through sexual initiation with a prostitute, he travels to Uruk, where he challenges Gilgamesh to a test of strength. Gilgamesh wins the contest; nonetheless, the two become friends. Together, they make a six-day journey to the legendary Cedar Forest, where they plan to slay the Guardian, Humbaba the Terrible, and cut down the sacred Cedar.[2] The goddess Ishtar sends the Bull of Heaven to punish Gilgamesh for spurning her advances.  Gilgamesh and Enkidu kill the Bull of Heaven after which the gods decide to sentence Enkidu to death and kill him.\\r\\n\\r\\nIn the second half of the epic, distress over Enkidu's death causes Gilgamesh to undertake a long and perilous journey to discover the secret of eternal life. He eventually learns that \\"Life, which you look for, you will never find. For when the gods created man, they let death be his share, and life withheld in their own hands\\".[3][4] However, because of his great building projects, his account of Siduri's advice, and what the immortal man Utnapishtim told him about the Great Flood, Gilgamesh's fame survived well after his death with expanding interest in the Gilgamesh story which has been translated into many languages and is featured in works of popular fiction.\\r\\n\\r\\nDistinct sources exist from over a 2000-year timeframe. The earliest Sumerian poems are now generally considered to be distinct stories, rather than parts of a single epic.[5]:45 They date from as early as the Third Dynasty of Ur (c.?2100 BC).[5]:41ÿ42 The Old Babylonian tablets (c.?1800 BC),[5]:45 are the earliest surviving tablets for a single Epic of Gilgamesh narrative.[6] The older Old Babylonian tablets and later Akkadian version are important sources for modern translations, with the earlier texts mainly used to fill in gaps (lacunae) in the later texts. Although several revised versions based on new discoveries have been published, the epic remains incomplete.[7] Analysis of the Old Babylonian text has been used to reconstruct possible earlier forms of the Epic of Gilgamesh.[8] The most recent Akkadian version (c.?1200 BC), also referred to as the standard version, consisting of twelve tablets, was edited by Sin-liqe-unninni[9] and was found in the Library of Ashurbanipal in Nineveh.[10]\\r\\n\\r\\nThe New York Times, front page, 1872[11]\\r\\n\\r\\nThe Epic of Gilgamesh was discovered by Austen Henry Layard, Hormuzd Rassam, and W. K. Loftus in 1853.[12] The central character of Gilgamesh was initially reintroduced to the world as \\"Izdubar\\", before the cuneiform logographs in his name could be pronounced accurately. The first modern translation was published in the early 1870s by George Smith.[13] Smith then made further discoveries of texts on his later expeditions, which culminated in his final translation which is given in his book The Chaldaean Account of Genesis (1880).\\r\\n\\r\\nThe most definitive modern translation is a two-volume critical work by Andrew George, published by Oxford University Press in 2003. A book review by the Cambridge scholar, Eleanor Robson, claims that George's is the most significant critical work on Gilgamesh in the last 70 years.[14] George discusses the state of the surviving material, and provides a tablet-by-tablet exegesis, with a dual language side-by-side translation.  In 2004, Stephen Mitchell supplied a controversial version that takes many liberties with the text and includes modernized allusions and commentary relating to the Iraq War of 2003.[15][16]\\r\\n\\r\\nThe first direct Arabic translation from the original tablets was made in the 1960s by the Iraqi archaeologist Taha Baqir.[citation needed]\\r\\n\\r\\nThe discovery of artifacts (c.?2600 BC) associated with Enmebaragesi of Kish, mentioned in the legends as the father of one of Gilgamesh's adversaries, has lent credibility to the historical existence of Gilgamesh.[5]:40ÿ41\\r\\n\\r\\nFrom the diverse sources found, two main versions of the epic have been partially reconstructed: the standard Akkadian version, or He who saw the deep, and the Old Babylonian version, or Surpassing all other kings. Five earlier Sumerian poems about Gilgamesh have been partially recovered, some with primitive versions of specific episodes in the Akkadian version, others with unrelated stories.\\r\\n\\r\\nThe standard version was discovered by Hormuzd Rassam in the library of Ashurbanipal in Nineveh in 1853. It was written in a dialect of Akkadian that was used for literary purposes. This version was compiled by Sin-liqe-unninni sometime between 1300 and 1000 BC from earlier texts.\\r\\n\\r\\nThe standard Akkadian version has different opening words, or incipit, from the older version. The older version begins with the words \\"Surpassing all other kings\\", while the standard version has \\"He who saw the deep\\" (?a nagba ؐmuru), \\"deep\\" referring to the mysteries of the information brought back by Gilgamesh from his meeting with Uta-Napishti (Utnapishtim) about Ea, the fountain of wisdom.[7] Gilgamesh was given knowledge of how to worship the gods, why death was ordained for human beings, what makes a good king, and how to live a good life. The story of Utnapishtim, the hero of the flood myth, can also be found in the Babylonian Epic of Atrahasis.\\r\\n\\r\\nThe 12th tablet is a sequel to the original 11, and was probably added at a later date. It bears little relation to the well-crafted 11-tablet epic; the lines at the beginning of the first tablet are quoted at the end of the 11th tablet, giving it circularity and finality. Tablet 12 is a near copy of an earlier Sumerian tale, a prequel, in which Gilgamesh sends Enkidu to retrieve some objects of his from the Underworld, and he returns in the form of a spirit to relate the nature of the Underworld to Gilgamesh.\\r\\n\\r\\nThis summary is based on Andrew George's translation.[7]\\r\\n\\r\\nThe story introduces Gilgamesh, king of Uruk. Gilgamesh, two-thirds god and one-third man, is oppressing his people, who cry out to the gods for help. For the young women of Uruk this oppression takes the form of a droit du seigneur, or \\"lord's right\\", to sleep with brides on their wedding night. For the young men (the tablet is damaged at this point) it is conjectured that Gilgamesh exhausts them through games, tests of strength, or perhaps forced labour on building projects. The gods respond to the people's pleas by creating an equal to Gilgamesh who will be able to stop his oppression. This is the primitive man, Enkidu, who is covered in hair and lives in the wild with the animals. He is spotted by a trapper, whose livelihood is being ruined because Enkidu is uprooting his traps. The trapper tells the sun-god Shamash about the man, and it is arranged for Enkidu to be seduced by Shamhat, a temple prostitute, his first step towards being tamed. After six days and seven nights (or two weeks, according to more recent scholarship[17]) of lovemaking and teaching Enkidu about the ways of civilization, she takes Enkidu to a shepherd's camp to learn how to be civilized. Gilgamesh, meanwhile, has been having dreams about the imminent arrival of a beloved new companion and asks his mother, Ninsun, to help interpret these dreams.\\r\\n\\r\\nShamhat brings Enkidu to the shepherds' camp, where he is introduced to a human diet and becomes the night watchman. Learning from a passing stranger about Gilgamesh's treatment of new brides, Enkidu is incensed and travels to Uruk to intervene at a wedding. When Gilgamesh attempts to visit the wedding chamber, Enkidu blocks his way, and they fight. After a fierce battle, Enkidu acknowledges Gilgamesh's superior strength and they become friends. Gilgamesh proposes a journey to the Cedar Forest to slay the monstrous demi-god Humbaba in order to gain fame and renown. Despite warnings from Enkidu and the council of elders, Gilgamesh is not deterred.\\r\\n\\r\\nThe elders give Gilgamesh advice for his journey. Gilgamesh visits his mother, the goddess Ninsun, who seeks the support and protection of the sun-god Shamash for their adventure. Ninsun adopts Enkidu as her son, and Gilgamesh leaves instructions for the governance of Uruk in his absence.\\r\\n\\r\\nGilgamesh and Enkidu journey to the Cedar Forest. Every few days they camp on a mountain, and perform a dream ritual. Gilgamesh has five terrifying dreams about falling mountains, thunderstorms, wild bulls, and a thunderbird that breathes fire. Despite similarities between his dream figures and earlier descriptions of Humbaba, Enkidu interprets these dreams as good omens, and denies that the frightening images represent the forest guardian. As they approach the cedar mountain, they hear Humbaba bellowing, and have to encourage each other not to be afraid.\\r\\n\\r\\nThe heroes enter the cedar forest. Humbaba, the guardian of the Cedar Forest, insults and threatens them. He accuses Enkidu of betrayal, and vows to disembowel Gilgamesh and feed his flesh to the birds. Gilgamesh is afraid, but with some encouraging words from Enkidu the battle commences. The mountains quake with the tumult and the sky turns black. The god Shamash sends 13 winds to bind Humbaba, and he is captured. Humbaba pleads for his life, and Gilgamesh pities him. He offers to make Gilgamesh king of the forest, to cut the trees for him, and to be his slave. Enkidu, however, argues that Gilgamesh should kill Humbaba to establish his reputation forever. Humbaba curses them both and Gilgamesh dispatches him with a blow to the neck, as well as killing his seven sons.[18] The two heroes cut down many cedars, including a gigantic tree that Enkidu plans to fashion into a gate for the temple of Enlil. They build a raft and return home along the Euphrates with the giant tree and (possibly) the head of Humbaba.\\r\\n\\r\\nGilgamesh rejects the advances of the goddess Ishtar because of her mistreatment of previous lovers like Dumuzi. Ishtar asks her father Anu to send Gugalanna, the Bull of Heaven, to avenge her. When Anu rejects her complaints, Ishtar threatens to raise the dead who will \\"outnumber the living\\" and \\"devour them\\". Anu becomes frightened, and gives in to her. Ishtar leads Gugalanna to Uruk, and it causes widespread devastation. It lowers the level of the Euphrates river, and dries up the marshes. It opens up huge pits that swallow 300 men. Without any divine assistance, Enkidu and Gilgamesh attack and slay it, and offer up its heart to Shamash. When Ishtar cries out, Enkidu hurls one of the hindquarters of the bull at her. The city of Uruk celebrates, but Enkidu has an ominous dream about his future failure.\\r\\n\\r\\nIn Enkidu's dream, the gods decide that one of the heroes must die because they killed Humbaba and Gugalanna. Despite the protestations of Shamash, Enkidu is marked for death. Enkidu curses the great door he has fashioned for Enlil's temple. He also curses the trapper and Shamhat for removing him from the wild. Shamash reminds Enkidu of how Shamhat fed and clothed him, and introduced him to Gilgamesh. Shamash tells him that Gilgamesh will bestow great honors upon him at his funeral, and will wander into the wild consumed with grief. Enkidu regrets his curses and blesses Shamhat instead. In a second dream, however, he sees himself being taken captive to the Netherworld by a terrifying Angel of Death. The underworld is a \\"house of dust\\" and darkness whose inhabitants eat clay, and are clothed in bird feathers, supervised by terrifying beings. For 12?days, Enkidu's condition worsens. Finally, after a lament that he could not meet a heroic death in battle, he dies. In a famous line from the epic Gilgamesh clings to Enkidu's body and denies that he has died until a maggot drops from the corpse's nose.\\r\\n\\r\\nGilgamesh delivers a lament for Enkidu, in which he calls upon mountains, forests, fields, rivers, wild animals, and all of Uruk to mourn for his friend. Recalling their adventures together, Gilgamesh tears at his hair and clothes in grief. He commissions a funerary statue, and provides grave gifts from his treasury to ensure that Enkidu has a favourable reception in the realm of the dead. A great banquet is held where the treasures are offered to the gods of the Netherworld. Just before a break in the text there is a suggestion that a river is being dammed, indicating a burial in a river bed, as in the corresponding Sumerian poem, The Death of Gilgamesh.\\r\\n\\r\\nTablet nine opens with Gilgamesh roaming the wild wearing animal skins, grieving for Enkidu. Having now become fearful of his own death, he decides to seek Utnapishtim (\\"the Faraway\\"), and learn the secret of eternal life. Among the few survivors of the Great Flood, Utnapishtim and his wife are the only humans to have been granted immortality by the gods. Gilgamesh crosses a mountain pass at night and encounters a pride of lions. Before sleeping he prays for protection to the moon god Sin. Then, waking from an encouraging dream, he kills the lions and uses their skins for clothing. After a long and perilous journey, Gilgamesh arrives at the twin peaks of Mount Mashu at the end of the earth. He comes across a tunnel, which no man has ever entered, guarded by two scorpion monsters, who appear to be a married couple. The husband tries to dissuade Gilgamesh from passing, but the wife intervenes, expresses sympathy for Gilgamesh, and (according to the poem's editor Benjamin Foster) allows his passage. He passes under the mountains along the Road of the Sun. In complete darkness he follows the road for 12 \\"double hours\\", managing to complete the trip before the Sun catches up with him. He arrives at the Garden of the gods, a paradise full of jewel-laden trees.\\r\\n\\r\\nGilgamesh meets alewife Siduri, who assumes that he is a murderer or thief because of his disheveled appearance. Gilgamesh tells her about the purpose of his journey. She attempts to dissuade him from his quest, but sends him to Urshanabi the ferryman, who will help him cross the sea to Utnapishtim. Gilgamesh, out of spontaneous rage, destroys the stone charms that Urshanabi keeps with him. He tells him his story, but when he asks for his help, Urshanabi informs him that he has just destroyed the objects that can help them cross the Waters of Death, which are deadly to the touch. Urshanabi instructs Gilgamesh to cut down 120 trees and fashion them into punting poles. When they reach the island where Utnapishtim lives, Gilgamesh recounts his story, asking him for his help. Utnapishtim reprimands him, declaring that fighting the common fate of humans is futile and diminishes life's joys.\\r\\n\\r\\nGilgamesh observes that Utnapishtim seems no different from himself, and asks him how he obtained his immortality. Utnapishtim explains that the gods decided to send a great flood. To save Utnapishtim the god Ea told him to build a boat. He gave him precise dimensions, and it was sealed with pitch and bitumen. His entire family went aboard together with his craftsmen and \\"all the animals of the field\\". A violent storm then arose which caused the terrified gods to retreat to the heavens. Ishtar lamented the wholesale destruction of humanity, and the other gods wept beside her. The storm lasted six days and nights, after which \\"all the human beings turned to clay\\". Utnapishtim weeps when he sees the destruction. His boat lodges on a mountain, and he releases a dove, a swallow, and a raven. When the raven fails to return, he opens the ark and frees its inhabitants. Utnapishtim offers a sacrifice to the gods, who smell the sweet savor and gather around. Ishtar vows that just as she will never forget the brilliant necklace that hangs around her neck, she will always remember this time. When Enlil arrives, angry that there are survivors, she condemns him for instigating the flood. Ea also castigates him for sending a disproportionate punishment. Enlil blesses Utnapishtim and his wife, and rewards them with eternal life. This account matches the flood story that concludes the Epic of Atra-Hasis (see also Gilgamesh flood myth).\\r\\n\\r\\nThe main point seems to be that when Enlil granted eternal life it was a unique gift. As if to demonstrate this point, Utnapishtim challenges Gilgamesh to stay awake for six days and seven nights. Gilgamesh falls asleep, and Utnapishtim instructs his wife to bake a loaf of bread on each of the days he is asleep, so that he cannot deny his failure to keep awake. Gilgamesh, who is seeking to overcome death, cannot even conquer sleep. After instructing Urshanabi the ferryman to wash Gilgamesh, and clothe him in royal robes, they depart for Uruk.\\r\\n\\r\\nAs they are leaving, Utnapishtim's wife asks her husband to offer a parting gift. Utnapishtim tells Gilgamesh that at the bottom of the sea there lives a boxthorn-like plant that will make him young again. Gilgamesh, by binding stones to his feet so he can walk on the bottom, manages to obtain the plant. Gilgamesh proposes to investigate if the plant has the hypothesized rejuvenation ability by testing it on an old man once he returns to Uruk.\\r\\n\\r\\n There is a plant that looks like a box-thorn, it has prickles like a dogrose, and will prick one who plucks it. But if you can possess this plant, you'll be again as you were in your youth\\r\\n\\r\\nThis plant, Ur-shanabi, is the \\"Plant of Heartbeat\\", with it a man can regain his vigour. To Uruk-the-sheepfold I will take it, to an ancient I will feed some and put the plant to the test![7]:98\\r\\n\\r\\nUnfortunately, when Gilgamesh stops to bathe, it is stolen by a serpent, who sheds its skin as it departs. Gilgamesh weeps at the futility of his efforts, because he has now lost all chance of immortality. He returns to Uruk, where the sight of its massive walls prompts him to praise this enduring work to Urshanabi.\\r\\n\\r\\nThis tablet is mainly an Akkadian translation of an earlier Sumerian poem, Gilgamesh and the Netherworld (also known as \\"Gilgamesh, Enkidu, and the Netherworld\\" and variants), although it has been suggested that it is derived from an unknown version of that story.[5]:42 The contents of this last tablet are inconsistent with previous ones: Enkidu is still alive, despite having died earlier in the epic. Because of this, its lack of integration with the other tablets, and the fact that it is almost a copy of an earlier version, it has been referred to as an 'inorganic appendage' to the epic.[19] Alternatively, it has been suggested that \\"its purpose, though crudely handled, is to explain to Gilgamesh (and the reader) the various fates of the dead in the Afterlife\\" and in \\"an awkward attempt to bring closure\\",[20] it both connects the Gilgamesh of the epic with the Gilgamesh who is the King of the Netherworld,[21] and is \\"a dramatic capstone whereby the twelve-tablet epic ends on one and the same theme, that of \\"seeing\\" (= understanding, discovery, etc.), with which it began.\\"[22]\\r\\n\\r\\nGilgamesh complains to Enkidu that various of his possessions (the tablet is unclear exactly what? different translations include a drum and a ball) have fallen into the underworld. Enkidu offers to bring them back. Delighted, Gilgamesh tells Enkidu what he must and must not do in the underworld if he is to return. Enkidu does everything which he was told not to do. The underworld keeps him. Gilgamesh prays to the gods to give him back his friend. Enlil and Suen don't reply, but Ea and Shamash decide to help. Shamash makes a crack in the earth, and Enkidu's ghost jumps out of it. The tablet ends with Gilgamesh questioning Enkidu about what he has seen in the underworld.\\r\\n\\r\\nThis version of the epic, called in some fragments Surpassing all other kings, is composed of tablets and fragments from diverse origins and states of conservation.[7]:101ÿ26 It remains incomplete in its majority, with several tablets missing and big lacunae in those found. They are named after their current location or the place where they were found.\\r\\n\\r\\nSurpassing all other kings Tablet II, greatly correlates with tablets I-II of the standard version.\\r\\nGilgamesh tells his mother Ninsun about two dreams he had. His mother explains that they mean that a new companion will soon arrive at Uruk. In the meanwhile the wild Enkidu and the priestess (here called Shamkatum) are making love. She tames him in company of the shepherds by offering him bread and beer. Enkidu helps the shepherds by guarding the sheep. They travel to Uruk to confront Gilgamesh and stop his abuses. Enkidu and Gilgamesh battle but Gilgamesh breaks off the fight. Enkidu praises Gilgamesh.\\r\\n\\r\\nSurpassing all other kings Tablet III, partially matches tablets II-III of the standard version.\\r\\nFor reasons unknown (the tablet is partially broken) Enkidu is in a sad mood. In order to cheer him up Gilgamesh suggests going to the Pine Forest to cut down trees and kill Humbaba (known here as Huwawa). Enkidu protests, as he knows Huwawa and is aware of his power. Gilgamesh talks Enkidu into it with some words of encouragement, but Enkidu remains reluctant. They prepare, and call for the elders. The elders also protest, but after Gilgamesh talks to them, they agree to let him go. After Gilgamesh asks his god (Shamash) for protection, and both he and Enkidu equip themselves, they leave with the elder's blessing and counsel.\\r\\n\\r\\nPossibly another version of the contents of the Yale Tablet, practically irrecoverable.\\r\\n\\r\\nIn the journey to the cedar forest and Huwawa, Enkidu interprets one of Gilgamesh's dreams.\\r\\n\\r\\nFragments from two different versions/tablets tell how Enkidu interprets one of Gilgamesh's dreams on the way to the Forest of Cedar, and their conversation when entering the forest.\\r\\n\\r\\nAfter defeating Huwawa, Gilgamesh refrains from slaying him, and urges Enkidu to hunt Huwawa's \\"seven auras\\". Enkidu convinces him to smite their enemy. After killing Huwawa and the auras, they chop down part of the forest and discover the gods' secret abode. The rest of the tablet is broken.\\r\\n\\r\\nThe auras are not referred to in the standard version, but are in one of the Sumerian poems.\\r\\n\\r\\nPartially overlapping the felling of the trees from the Ishchali tablet.\\r\\n\\r\\nPartially overlapping the standard version tablets IXÿX.\\r\\nGilgamesh mourns the death of Enkidu wandering in his quest for immortality. Gilgamesh argues with Shamash about the futility of his quest. After a lacuna, Gilgamesh talks to Siduri about his quest and his journey to meet Utnapishtim (here called Uta-na'ishtim). Siduri attempts to dissuade Gilgamesh in his quest for immortality, urging him to be content with the simple pleasures of life.[3] After one more lacuna, Gilgamesh smashes the \\"stone ones\\" and talks to the ferryman Urshanabi (here called Sur-sunabu). After a short discussion, Sur-sunabu asks him to carve 300 oars so that they may cross the waters of death without needing the \\"stone ones\\". The rest of the tablet is missing.\\r\\n\\r\\nThe text on the Old Babylonian Meissner fragment (the larger surviving fragment of the Sippar tablet) has been used to reconstruct possible earlier forms of the Epic of Gilgamesh, and it has been suggested that a \\"prior form of the story ÿ earlier even than that preserved on the Old Babylonian fragment ÿ may well have ended with Siduri sending Gilgamesh back to Uruk...\\" and \\"Utnapistim was not originally part of the tale.\\"[23]\\r\\n\\r\\nThere are five extant Gilgamesh stories in the form of older poems in Sumerian.[7]:141ÿ208 These probably circulated independently, rather than being in the form of a unified epic. Some of the names of the main characters in these poems differ slightly from later Akkadian names; for example, \\"Bilgamesh\\" is written instead of \\"Gilgamesh\\", and there are some differences in the underlying stories such as the fact that Enkidu is Gilgamesh's servant in the Sumerian version:\\r\\n\\r\\nVarious themes, plot elements, and characters in the Epic of Gilgamesh have counterparts in the Hebrew Biblenotably, the accounts of the Garden of Eden, the advice from Ecclesiastes, and the Genesis flood narrative.\\r\\n\\r\\nThe parallels between the stories of Enkidu/Shamhat and Adam/Eve have been long recognized by scholars.[25][26] In both, a man is created from the soil by a god, and lives in a natural setting amongst the animals. He is introduced to a woman who tempts him. In both stories the man accepts food from the woman, covers his nakedness, and must leave his former realm, unable to return. The presence of a snake that steals a plant of immortality from the hero later in the epic is another point of similarity.\\r\\n\\r\\nSeveral scholars suggest direct borrowing of Siduri's advice by the author of Ecclesiastes.[27]\\r\\n\\r\\nA rare proverb about the strength of a triple-stranded rope, \\"a triple-stranded rope is not easily broken\\", is common to both books.\\r\\n\\r\\nAndrew George submits that the Genesis flood narrative matches that in Gilgamesh so closely that \\"few doubt\\" that it derives from a Mesopotamian account.[28] What is particularly noticeable is the way the Genesis flood story follows the Gilgamesh flood tale \\"point by point and in the same order\\", even when the story permits other alternatives.[29] In a 2001 Torah commentary released on behalf of the Conservative Movement of Judaism, rabbinic scholar Robert Wexler stated: \\"The most likely assumption we can make is that both Genesis and Gilgamesh drew their material from a common tradition about the flood that existed in Mesopotamia. These stories then diverged in the retelling.\\"[30] Ziusudra, Utnapishtim and Noah are the respective heroes of the Sumerian, Akkadian and biblical flood legends of the ancient Near East.\\r\\n\\r\\nMatthias Henze suggests that Nebuchadnezzar's madness in the biblical Book of Daniel draws on the Epic of Gilgamesh. He claims that the author uses elements from the description of Enkidu to paint a sarcastic and mocking portrait of the king of Babylon.[31]\\r\\n\\r\\nMany characters in the Epic have mythical biblical parallels, most notably Ninti, the Sumerian goddess of life, was created from Enki's rib to heal him after he had eaten forbidden flowers. It is suggested that this story served as the basis for the story of Eve created from Adam's rib in the Book of Genesis.[32]\\r\\nEsther J. Hamori, in Echoes of Gilgamesh in the Jacob Story, also claims that the myth of Jacob and Esau is paralleled with the wrestling match between Gilgamesh and Enkidu.[33]\\r\\n\\r\\nNumerous scholars have drawn attention to various themes, episodes, and verses, indicating that the Epic of Gilgamesh had a substantial influence on both of the epic poems ascribed to Homer. These influences are detailed by Martin Litchfield West in The East Face of Helicon: West Asiatic Elements in Greek Poetry and Myth.[34] According to Tzvi Abusch of Brandeis University, the poem \\"combines the power and tragedy of the Iliad with the wanderings and marvels of the Odyssey. It is a work of adventure, but is no less a meditation on some fundamental issues of human existence.\\"[35]\\r\\n\\r\\nThe Epic of Gilgamesh has inspired many works of literature, art, and music, as Theodore Ziolkowski points out in his book Gilgamesh Among Us: Modern Encounters With the Ancient Epic (2011).[36][37] It was only after the First World War that the Gilgamesh epic reached a modern audience, and only after the Second World War that it began to feature in a variety of genres.[37]","input":"When was the most complete version of gilgamesh compiled?"},{"output":"University of Iowa","context":"Alexander \\"Alex\\" Michael Karev,[1] M.D. is a fictional character on the ABC television series Grey's Anatomy, portrayed by actor Justin Chambers.[2] Introduced as a surgical intern at the fictional Seattle Grace Hospital, Karev eventually obtained the position of resident, later becoming a pediatric surgical fellow. His relationships with colleagues Meredith Grey (Ellen Pompeo), Cristina Yang (Sandra Oh), Izzie Stevens (Katherine Heigl), and George O'Malley (T. R. Knight) formed a focal point of the series.\\r\\nThe character is initially disliked by his fellow interns, and is often accused of being brusque[2] and dismissive with his patients and co-workers. As a resident, Karev's negative attitude, temper and rudeness has occasionally earned the ire of the attendings, with former neonatal surgeon Addison Montgomery requesting him on her service as punishment for his rudeness to her and neurosurgeon Derek Shepherd, amongst others, throwing him out of their service for his inappropriate comments about patients. He demonstrates profound skill for the specialty which prompts praise from Montgomery and contributes to Karev's interest in pediatric surgery for the rest of the series. As the character developed, he displayed more empathy for patients and is shown to have a gift for connecting with young children, despite his repeated claims to dislike them.\\r\\nAlthough Karev and Stevens had an on-off romantic history in previous seasons, it was not until the fifth season that the two formed a lasting relationship. Despite Stevens' advanced skin cancer, the two marry. Justin Chambers commented on his character's inability to tell Stevens that he loves her in the beginning of their relationship, saying that Karev has difficulty expressing himself.[3] Though Stevens departs in season 6, series creator Shonda Rhimes has said that she would like the chance to create closure for both Karev and Stevens.[4] Rhimes later retracted her comments and stated that she has no plans to ever re-approach Izzie's storyline again. In the ninth season, Karev befriends intern Jo Wilson. They begin a relationship in the tenth season until their break-up in the twelfth season.\\r\\n\\r\\n\\r\\nHis mother had a mental illness, and his father was often absent, as well as often becoming violent towards Alex and his mother. Alex began wrestling in high school,[5] and eventually physically confronted his father - after this, his father did not return. Alex has a younger brother, Aaron, and a younger sister, Amber; they were all placed in foster care for 5 years. Though Aaron and Amber only had a few foster families, Alex went through 17 foster families in 5 years before he reunited with his siblings. It is revealed in later seasons that Aaron was diagnosed with schizophrenia and tried to kill Amber. Alex was present when Aaron had to be committed to a psychiatric ward.\\r\\nAlex secured a position in the surgical residency program at Seattle Grace Hospital after graduating from the University of Iowa. He initially makes a poor impression on his fellow interns meeting fellow interns Meredith Grey (Ellen Pompeo), Cristina Yang (Sandra Oh), George O'Malley (T.R. Knight), and Izzie Stevens (Katherine Heigl) whom he later taunts when he discovers she used to be a lingerie model. After initial disagreements, Alex reveals to Izzie that his father was a heroin addict who used to beat his mother. He became a wrestler so he could defend his mother, and attended university on a wrestling scholarship. He and Izzie begin a friendship. At the end of the first season, George contracts syphilis from Alex through nurse Olivia Harper, causing animosity between the two.\\r\\nAlex asks Izzie out on a date, but he is thrown by the news that he has failed his medical board exams. Izzie is offended since he pays no attention to her during their date and so informs him that she no longer wants to go out with him. He later freezes during an emergency operation, needing George to take over from him. Alex's relationship with Izzie is damaged when he experiences erectile dysfunction with her. He goes on to sleep with Olivia again, and is caught by Izzie and they break up. After retaking his exams, Alex manages a pass, and reunites with Izzie after a bomb scare in the hospital. They break up again, however, when Izzie falls for cardiothoracic patient Denny Duquette.\\r\\nAlex helps Izzie recover from Denny's death and advances Izzie but Izzie backs away since she is still in the process of getting over her loss and they remain friends. Alex spends a period of time working under neonatal surgeon Dr. Addison Montgomery (Kate Walsh), and though he is later released to work for plastic surgeon Dr. Mark Sloan (Eric Dane), he finds his interest returning to Addison's firm. Addison is attracted to Alex, and the two share a kiss and later sleep together. In the aftermath of a ferry accident, Alex rescues a pregnant woman (Elizabeth Reaser) who awakes with amnesia, and grows close to Alex as he helps her forging an identity for herself, picking out the name Ava. After she gives birth to her daughter, Ava's memory eventually returns, although she tries to hide it from Alex as she had recently left a bad marriage. He convinces her to tell him her true identity, and she reveals herself to be Rebecca Pope. Alex turns her down after realizing she's married, feeling that he is not good enough for her.\\r\\nRebecca returns and she and Alex sleep together before she goes back to her husband. Alex has a brief relationship with intern Lexie Grey (Chyler Leigh), but chooses to be with Rebecca when she returns and tells him she is pregnant. After Rebecca attempted suicide, Izzie convinces Alex to admit her for psychiatric help due to Rebecca's hallucinations of her pregnancy. Alex later breaks down in Izzie's arms, and the two kiss.\\r\\nLater in their relationship, Izzie begins hallucinating about Denny, and uncovers the fact she has metastatic melanoma (Stage IV) with an estimated chance of 5% survival. It is revealed that Izzie's hallucinations of Denny are, in fact, caused by her tumor. Alex is shocked by the news, but finds the strength to stay by her side. Izzie plans a wedding for Meredith and Derek, but when Derek finds Izzie has another inoperable tumor in her brain, they give the wedding to Izzie and Alex, who marry in front of all their friends. Izzie debates whether or not she should undergo a risky surgery to remove her tumor and Alex supports her, but eventually insists that she should have the surgery. Alex performs CPR on Izzie after she flatlines.\\r\\nIzzie regains a heartbeat but is soon fired leaving Alex a Dear John letter and no clue as to her whereabouts. She later returns to the hospital and says to Alex, thinking he had a hand in getting her fired, that she could not forgive him for talking to the Chief. Alex says he could not forgive her either for not giving him the benefit of the doubt and leaving without talking to him first. Alex re-kindles an old flame with Lexie. Alex seems to have recently found that his calling is actually Peds and not Plastics as he had decided in the earlier seasons. Seeing Alex's ability to handle child patients, Dr. Arizona Robbins shows an interest in mentoring him for that specialization. Alex's brother Aaron comes to Seattle Grace for surgery, and lots of painful memories resurface because of this. Meredith discovers Alex, along with Aaron and their sister Amber, had been in foster care for five years when their mother could not take care of them. Alex is also served with divorce papers from Izzie. Alex is shot in the hospital by a deceased patient's husband, but survives with the help of Lexie and Mark. While undergoing treatment, he mistakes Lexie for Izzie.\\r\\nFollowing the shooting, Lexie has a mental breakdown in front of Alex and he walks away. Dr. Bailey bars Alex from surgery until he has the bullet removed, which he later allows her to do. Alex realizes that his passion lies in Pediatric Surgery. He is further shown to be excellent with children, comforting with a young patient while growing her a new trachea. He immediately gets on the wrong side of new Pediatric attending Stark while Arizona is on leave. Alex then attempts to sleep with virgin April Kepner after visiting his mom in Iowa when his brother was diagnosed schizophrenia. Alex and Meredith perform an emergent surgery on a young boy by themselves during the night shift, dealing with the angry fallout from Stark (who would not answer his pager) but gaining the wordless approval of the Chief. Alex is thrilled when Arizona returns from Africa and hopes she will come to work for the hospital again. In the meantime, Alex falls for the new OBGYN attending, Lucy Fields, and they start a relationship after she kisses him. Alex finds out about Meredith sabotaging her Alzheimer's clinical trial and rats her out in attempt to get Chief Resident.\\r\\nThe adoption counselor takes away Zola, the child Meredith wanted to adopt. Realizing his mistake, Alex apologizes to Meredith who forgives him shortly after. As the end of the fifth year of residency is near, the surgical residents, including Alex, prepare for their board exams for the different fellowships they plan on joining. Though Alex is late for his exam because he had to treat a patient, he ends up passing. Dr. Webber tells him that Johns Hopkins Hospital, which has the top program in the country, has been very impressed with him and has decided to create a position in pediatrics surgery for him and accepts the position. After finding out his decision, his current boss, Dr. Arizona Robbins, yells at him and takes his place on a plane that later crashes.\\r\\nFollowing the rescue of his colleagues, Robbins' health deteriorates and amputates her leg. He extends his stay at Seattle Grace until a replacement for Robbins is found, but when he learns that the replacement will send the exchange program to UCLA, he decides not to leave. Karev buys Meredith's old house from her, and Cristina becomes his roommate. Karev forms a friendship with new intern, Jo Wilson that eventually develops into romantic feelings towards each other. Alex admits his love for Jo, and the two kiss and become a couple.\\r\\nAlex's estranged father, Jimmy, who he hasn't seen in 18 years, is admitted to the ER as a patient. After being discharged, Jimmy plays with his band at a bar, and Alex spends several nights watching his father perform onstage. Unknowing that Alex is his son, Jimmy confides in Alex that he had another family that he hasn't seen in years. This made Alex upset and he punched Jimmy at the bar. Once returning home, Alex unleashes his hurt and anger on Jo for having encouraged him to reconnect with his father. His father returns suffering from symptoms of withdrawal and hallucinations of the past where more is revealed about Alex's childhood. Jimmy tells Alex he knows that he is his son and Alex yells at his dad stating that \\"I WAS THE DAD\\". His dad later goes into cardiac arrest and is brought into surgery, fate unknown. Alex kisses Jo at April's wedding wanting to start a family with her. That night his dad died, due to a mistake by intern, Shane Ross, and Alex is upset. He punches Ross and is later comforted by Meredith.\\r\\nUpon the completion of his fellowship in Pediatric Surgery, Alex is given an offer to work at Dr. Oliver Lebackes' private practice office, claiming that he will have more flexible hours and \\"a big fat paycheck\\". Alex takes this offer happily. Robbins is initially angered by this decision and thinks that Alex is choosing money over substance. Eventually she realizes that he has become a wonderful surgeon and that she is happy to see him go. He later discovers that he isn't happy working at the private practice and expresses a desire to return full-time to Grey Sloan. When Cristina leaves for Switzerland, she leaves Alex her share of the board, including her seat.\\r\\nAlex is fired by Dr. Lebackes when Maggie Pierce accidentally reveals to him that Karev was thinking about leaving the job. Webber recommended Bailey to fill Yang's board seat after she left, so Bailey and Alex fight over the chair. They both make presentations to the board and eventually Bailey wins, with a unanimous vote in her favor. He is hired back as an attending Peds surgeon and takes over full-time as Arizona pursues a fellowship with Dr. Herman. Alex continues to date Jo and his friendship with Meredith grows stronger than ever, with him taking on the role of her new person. When Derek dies and Meredith runs away, Alex is upset by her leaving without telling him where she went and calls her everyday. Eventually she calls him, tells him she is okay, and to stop calling. When she goes into labor and gives birth to Ellis Shepherd, Alex goes to see her since he is her emergency contact. He brings Meredith and her kids back to her house. She asks to move back in with him in her old house. Alex sells Meredith back the house and he and Jo rent a loft.\\r\\nAlex and Jo continue to struggle with their relationship. Alex wants to settle down, marry Jo, and have kids. However, Jo continues to resist. When Karev proposes to her, Jo tells him she can't marry him, so he breaks up with her. Later, Alex realizes that he misses Jo and gets her back. They seem to be doing well for some time, until Alex brings up marriage again and the two fight, as Jo still continues to argue that she cannot marry him. Alex storms out, leaving their relationship uncertain. During Owen and Amelia's wedding, Alex realizes that even though she won't marry him, he loves Jo and goes back to her again. However, when he arrives at their loft, he finds Jo highly intoxicated, wearing nothing but her bra and underwear, and surgical intern, Andrew Deluca lying on top of her. Alex assumes that Deluca was attempting to take advantage of Jo while she was inebriated and is filled with rage. He beats Deluca to a pulp with his bare hands.\\r\\nAndrew is badly injured, with his face bruised beyond recognition. He is unconscious and on the verge of dying. Alex realizes what he's done and quickly rushes Deluca to the hospital. There, the doctors call the police as they struggle to save Andrew and discover who did this to him. Alex lies to everyone and says that he found Andrew in this state and brought him to Grey Sloan. However, Ben Warren is suspicious of Karev. Meredith also quickly realizes that Alex was in fact the one who beat Deluca. She covers for him and the two continue to lie to everyone in the hospital about Alex's actions. Soon, Karev learns that Andrew wasn't doing anything wrong and that he had beaten up a good guy. Meredith decides that even though she loves Alex, she needs to turn him in. She goes to Bailey and tells her the truth. But, when the two rush to the police they find Alex being arrested for aggravated assault, as he had turned himself in. He is taken to jail and Meredith bails him out. While they wait for a trial, Bailey suspends Alex as an attending and makes him work in the clinic. Eventually, Jo finally tells Alex that the reason she couldn't marry Alex is because she is already married. Her husband is abusive and so she ran away and changed her name to Jo Wilson so that he wouldn't find her. Alex realizes that when Jo is called to the stand as a witness in the trial, this information about her past and lack of records under the name Jo Wilson may be revealed, and when the information goes public, her husband may find her. To keep her safe, he decides to take the plea deal without a trial, ensuring that he goes to jail for 2 years. However, when Alex tells Meredith this, she begs him not to and tells him that she can't lose him too because she's already lost everyone else important in her life. Alex struggles to decide whether or not to take the plea deal.\\r\\nMeredith searches for Alex's case online, to find that the trial had been put off indefinitely. She assumes that he took the plea, and began calling and visiting various local jails to find him. After a full day of searching without finding him, she goes home to sleep, and discovers him sleeping in her bed. He explains he slept there all day. He explains that during his meeting with the D.A. Deluca came in and dropped all charges. Alex was then free to continue being Alex.\\r\\nThe American Broadcasting Company (ABC) characterized Karev as \\"honest\\", \\"always tells it like it is\\", while also citing his mouth, his punctuality and him being a \\"smart-ass\\" as his weaknesses.[6] Shonda Rhimes said of Karev: \\"I love that we have a character who can do something wonderful but still be a selfish cranky ass about it. Alex gets to be complex in ways most characters don't because even though hes got a moral code, his moral code is totally twisted and dark. But he's essentially good ÿ deep down inside.\\"[7] Carolina Paiz, one of the writers of the series, wrote: \\"He has so much going on inside... you think you've got him figured out but then he just reveals this whole other side to him.\\"[8]\\r\\n\\"He is superficial sleazeball who turns out to be a nice guy and a talented doctor with an amazing bedside manner, as well as the budding love interest of Katherine Heigl's character Isobel.\\"[9] DVD Verdict wrote of the character's development in the fourth season: \\"Love him, hate him, or both, Karev speaks his mind, rough edges and all. But ultimately his cold heart seems to be softened by his blossoming relationship with Jane Doe/Ava/Rebecca.\\"[10] Rhimes felt that the 100th episode during which Karev marries Stevens showed how he had grown up: \\"Look at him. Standing at the altar and saying those vows like a man. (...) He's become a man who can step up. And I love him for it.\\"[11]\\r\\nAnalyzing Alex Karev, Rachel Simon called him \\"underrated;\\" she pointed out that Alexs personal growth never seems to get acknowledged, as \\"Alex begins Greys as an arrogant, obnoxious intern who pushes away anyone who tries to care about him. He breaks Izzies heart 1,000 times, and then acts surprised when she falls for someone else. He sleeps with any girl who will have him, insults everyone who doesnt, and generally enjoys being the hospital asshole. Yet, over the course of 10 seasons Alex has evolved, slowly and realistically, into a genuinely good person whose faults dont miraculously disappear, but take a backseat to much better qualities.\\"\\r\\nFormer television columnist for The Star-Ledger Alan Sepinwall disapproved of Karev's flirt with Addison as \\"he should take interest in a woman's speciality and respect his boss without getting in her pants.\\"[12] Reviewing the fifth season, Chris Monfette of IGN wrote: \\"Alex, who'd become simply the cast's angry outcast, was uplifted as his relationship with Izzie became more and more substantial, and his bedside scenes with her toward the end were some of his character's best material yet.\\"[13]\\r\\nOn his career path as a Pediatric Surgeon Examiner wrote, \\"Despite his rough exterior, Alex has a certain child-like innocence and need for acceptance. He is keen in recognizing these traits in kids, as well. He reaches out to kids on many levels.\\" and added, \\"Alex has major trust issues. Maybe it was the constant beatings from his father. Or, his mothers mental illness. Or, being shuffled through 17 foster homes over a 5 year period. Who wouldnt have issues with a childhood like that?\\"\\r\\nSpecific\\r\\nGeneral","input":"Where did alex karev go to medical school?"},{"output":"the first emperor of China, Qin Shi Huang","context":"","input":"Who was responsible for building the great wall?"},{"output":"Depeche Mode","context":"\\r\\n\\r\\n\\"Personal Jesus\\" is a song by the English electronic band Depeche Mode, released on 28 August 1989 as the lead single from their seventh album, Violator (1990). It reached No. 13 on the UK Singles Chart[4] and No. 28 on the Billboard Hot 100.[5] The single was their first to make the US Top 40 since 1984's \\"People Are People\\", and was their first gold-certified single in the US (quickly followed by its successor, \\"Enjoy the Silence\\").[6]\\r\\n\\r\\nIn Germany, \\"Personal Jesus\\" is one of the band's longest-charting songs, staying on the singles chart for 23 weeks.[7]\\r\\n\\r\\nIn 2004, \\"Personal Jesus\\" was ranked No. 368 in Rolling Stone's list of \\"The 500 Greatest Songs of All Time\\",[8] and in September 2006 it was voted as one of the \\"100 Greatest Songs Ever\\" in Q magazine.\\r\\n\\r\\n\\"Personal Jesus\\" was rereleased as a single on 30 May 2011 for the Depeche Mode remix album Remixes 2: 81ÿ11, with the leading remix by the production team Stargate.\\r\\n\\r\\nThe song has been covered by numerous artists, including Johnny Cash, Marilyn Manson and Sammy Hagar. \\"I was never a huge fan of synth music in the eighties,\\" Hagar remarked, \\"but that song has a badass groove and a cool lyric.\\"[9]\\r\\n\\r\\nThe song was inspired by the book Elvis and Me by Priscilla Presley. According to songwriter Martin Gore:\\r\\n\\r\\nIt's a song about being a Jesus for somebody else, someone to give you hope and care. It's about how Elvis Presley was her man and her mentor and how often that happens in love relationships; how everybody's heart is like a god in some way, and that's not a very balanced view of someone, is it?[10]\\r\\n\\r\\n\\"Personal Jesus\\" is written in the key of F? minor with a tempo of 130 beats per minute in 128 time.[11][12]\\r\\n\\r\\nIn mid-1989, the band began recording in Milan with record producer Flood. The result of this session was the single \\"Personal Jesus\\", which featured a catchy bluesy riff and drum-based sound, radically different from anything the band had released thus far. The song became a big hit across the world, and is one of Depeche Mode's most successful songs, along with the single \\"Enjoy the Silence\\". Although not the first Depeche Mode song to feature guitar parts (\\"Behind the Wheel\\" and their cover of \\"Route 66\\" featured a guitar; \\"Love, in Itself\\" and \\"And Then...\\" from Construction Time Again and \\"Here is the House\\" from \\"Black Celebration\\" featured an acoustic guitar), it was the first time a guitar was used as a dominant instrument in a Depeche Mode song.\\r\\n\\r\\nPrior to its release, advertisements were placed in the personal columns of regional newspapers in the UK with the words \\"Your own personal Jesus.\\" Later, the ads included a phone number one could dial to hear the song.[13] The ensuing controversy helped propel the single to No. 13 on the UK charts, becoming one of Depeche Modes biggest sellers. The single was particularly successful commercially thanks to the fact that it was released six months prior to the album it would later appear on. Up to that point, it was the best selling 12\\" single in Warner Brothers history.[14]\\r\\n\\r\\n\\"Personal Jesus\\" had a plethora of remixes, almost unprecedented for Depeche Mode at the time. While most other Depeche Mode singles prior to \\"Personal Jesus\\" usually had band-made extended mixes, Depeche Mode started to invite more DJs and mixers to the fold, which would become the mainstay for all future Depeche Mode singles. Fran?ois Kevorkian (who did the mixing for the Violator album, in general) mixed the single version, the \\"Holier Than Thou Approach\\", the \\"Pump Mix\\", and the lesser-known \\"Kazan Cathedral Mix\\" (which was not available on any of the singles), while producer Flood mixed the \\"Acoustic\\" version and the \\"Telephone Stomp Mix\\" as well as the single version and \\"Sensual Mix\\" of the single's B-side \\"Dangerous\\", a more disco-electronic track. The \\"Hazchemix\\" and \\"Hazchemix Edit\\" of \\"Dangerous\\" were mixed by Daniel Miller.\\r\\n\\r\\nThe back-cover of \\"Personal Jesus\\" features one of the band members and the back-side of a naked woman. The band member she is with depends on whether it is the 7\\" Vinyl (Martin Gore), the 12\\" Vinyl (Dave Gahan), the Cassette (Andy Fletcher), or the original CD (Alan Wilder). On some copies she does not appear at all, such as the 2004 CD re-release, and on promo copies. On some limited releases, like the GBong17, all four photos are available plus one photo of the full group (Martin is hugging the woman).\\r\\n\\r\\nThe Anton Corbijn-directed music video for \\"Personal Jesus\\" is his first Depeche Mode video in colour, and features the band in a ranch (suggested to appear as a brothel), placed in the Tabernas Desert of Almera, in Spain. MTV edited out some suggestive mouth movements of Martin Gore during the bridge and replaced it with some other footage from the video.\\r\\n\\r\\nAll songs written by Martin Gore.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nFrancois Kevorkian\\r\\n\\r\\nFlood\\r\\n\\r\\nDaniel Miller\\r\\n\\r\\n\\r\\n\\r\\n*sales figures based on certification alone^shipments figures based on certification alone\\r\\n\\r\\n\\r\\n\\r\\n\\"Personal Jesus 2011\\" is the remixed version of the single, released on 30 May 2011. The digital single was released in the UK on 18 April 2011. It was released a day later in the US.\\r\\n\\r\\nCD (Bong43)\\r\\n\\r\\n12\\" vinyl\\r\\n\\r\\nDigital Download\\r\\n\\r\\nBeatport Exclusive Digital Download\\r\\n\\r\\nPromo CD (PCDBong43)\\r\\n\\r\\niTunes Store\\r\\n\\r\\nIn 2002, American country singer Johnny Cash covered \\"Personal Jesus\\" for his album American IV: The Man Comes Around.[47] The idea to cover the song was suggested by record producer Rick Rubin.[48] Cash called it \\"probably the most evangelical gospel song I ever recorded\\".[48]\\r\\n\\r\\nMarilyn Manson released their cover version of the track as the only previously unreleased recording included on their 2004 greatest hits album Lest We Forget: The Best Of.[51] The band's eponymous vocalist explained to MTV that he decided to cover \\"Personal Jesus\\" as: \\"I thought if I had to write a song, [the lyrics of 'Personal Jesus' are] exactly what I would say. ... I think it takes a little more of an ironic tone when you put it in context with what's going on today.\\"[52] He additionally described the original song and Depeche Mode's music in general as hypnotic, sexy and inspirational.[53] Its music video was directed by Manson and Nathan Cox.[54] The song won an award in the 'pop' category of the 2005 BMI Awards,[55] while its music video received two nominations at the 2005 Music Video Production Awards.[56]\\r\\n\\r\\n1Felix da Housecat mix","input":"Who was the original singer of personal jesus?"},{"output":"chocolate Tootsie Roll","context":"Tootsie Pops[1] are hard candy lollipops filled with chocolate-flavored chewy Tootsie Roll. They were invented in 1931 by Lukas R. \\"Luke\\" Weisgram, an employee of The Sweets Company of America. The company changed its name to Tootsie Roll Industries in 1969.\\r\\nThe candy debuted in 1931. In addition to chocolate (the original flavor), Tootsie Pops come in cherry, orange, caramel, grape, raspberry, strawberry, watermelon, blue raspberry, candy cane (seasonal), and now, pomegranate, banana, blueberry, lemon, and green apple flavors. Another release of Tootsie Roll Pops, named Tropical Stormz, features six swirl-textured flavors: orange , lemon lime, strawberry banana, apple blueberry, citrus punch, and berry punch. All flavors apply only to the hard candy surrounding the core; the soft core is always chocolate Tootsie Roll material.\\r\\nIn 2002, 60 million Tootsie Rolls and twenty million Tootsie Pops were produced every day.[2]\\r\\n\\r\\n\\r\\nTootsie Pops are known for the catch phrase \\"How many licks does it take to get to the center of a Tootsie Pop?\\". The phrase was first introduced in an animated commercial which debuted on U.S. television in 1969.[3] In the original television ad, a questioning boy poses the question to a cow, a fox, a turtle and an owl. Each one of the first three animals tells the boy to ask someone else, explaining that they'd bite a Tootsie Pop every time they lick one. Eventually, he asks the owl, who starts licking it, but bites into the lollipop after only three licks, much to the chagrin of the boy, who gets the empty stick back. The commercial ends the same way, with various flavored Tootsie Pops unwrapped and being \\"licked away\\" until being crunched in the center.[4]\\r\\nWhile the original commercial is 60 seconds long, an edited 30-second version and 15-second version of this commercial are the ones that have aired innumerable times over the years. The dialogue to the 60-second version is as follows:\\r\\nIn the shorter 30-second ad, Mr. Owl returns the spent candy stick, and the boy's final line is replaced with a reaction shot and a beat of silence.[5][6] The 30-second commercial dialogue is as follows:\\r\\nThe 15-second commercial (which still airs today) only shows the boy with Mr. Owl and a different narrator (Frank Leslie) speaks the same above line, but without the scene showing the Tootsie Roll pops slowly disappearing with a different tune playing in the background. The question still stands unanswered.[7] The dialogue is as follows:\\r\\nAfter the commercial, Mr. Oliver Owl became the mascot for Tootsie Roll Pops, appearing in marketing campaigns and on the packaging.\\r\\nIn the 1990s, a new commercial was made featuring a boy asking a robot and a dragon how many licks it takes to get to the center, with the Tootsie Pops known for the catch phrase \\"How many licks to the center of a Tootsie Pop?\\", rather than \\"How many licks does it take to get to the Tootsie Roll center of a Tootsie Pop?\\".[8]\\r\\nIn the early 1970s, Tootsie Pops were the initial lollipop of choice of the titular character in the TV series Kojak, and are seen prominently beginning in the December 12, 1973 episode \\"Dark Sunday\\" when Lt. Theo Kojak decides to favor them instead of cigarettes.\\r\\nAt some point, a rumor began that the lollipop wrappers which bore three unbroken circles were redeemable for free candy or even free items like shirts and other items. The rumor was untrue, but some shops have honored the wrapper offer over the years, allowing people to \\"win\\" a free pop.\\r\\nSome say it takes 1 million licks to get to the center of a tootsie pop.\\r\\nSome stores redeemed lollipop wrappers with the \\"shooting star\\" (bearing an image of a child dressed as a Native American aiming a bow and arrow at a star) for a free sucker. This was clearly up to the store owner and not driven by the lollipop manufacturer.[9] One convenience store in Iowa City, Iowa, for example, gave candy away when the children asked. Also, in Cedar Rapids, Iowa, Osco Drug used to give children free suckers for star wrappers. In 1994, the owner of Dans Shortstop told a reporter that when he first opened children came by often, but after a while, he said he had to stop giving things away. Giveaways also occurred in Chico, California, where a 7-Eleven store manager in the Pleasant Valley area, said she had to stop because it had become too expensive.[10] Since 1982, Tootsie Roll Industries has been distributing a short story, The Legend of the Indian Wrapper, to children who mail in their Indian star wrappers as a \\"consolation prize\\".[11]\\r\\nA student study at the University of Cambridge concluded that it takes 3,481 licks to get to the center of a Tootsie Pop.[12] Another study by Purdue University concluded that it takes an average of 364 licks to get to the center of a Tootsie Pop using a \\"licking machine\\", while it takes an average of 252 licks when tried by 20 volunteers.[citation needed] Yet another study by the University of Michigan concluded that it takes 411 licks to get to the center of a Tootsie Pop. A 1996 study by undergraduate students at Swarthmore College concluded that it takes a median of 144 licks (range 70ÿ222) to get to the center of a Tootsie Pop.[13] Nolan Walker personally found that it takes 1,139 licks as documented in a home experiment on December, 1997.[14] Harvard Grad students created a rotating mechanical tongue and concluded it took 2255 licks.[citation needed] It took 2256 licks on one attempt for a normal raspberry Tootsie Pop to get the center showing. YouTube star Ryan Higa found out that it took 700 licks to get to the center of the Tootsie Pop.[15]\\r\\nIn 2014, the Tribology Laboratory at the University of Florida published a study examining the coupled effects of biology, corrosion, and mechanical agitation on the wear of Tootsie Roll Pops. Self reported wear data from 58 participants was used in conjunction with statistical analysis of actual lollipop cross-sectional information in a numerical simulation to compute the average number of licks required to reach the Tootsie Roll center of a Tootsie Roll Pop. The number of licks required to reach the center, based on equatorial cross-section data, was found to be nearly independent of the licking style with the one-sided approach requiring 195I18 licks and the full-surface approach requiring 184I33. Detailed examination of the lollipops indicates that the minimum candy shell thickness is rarely (if ever) located along the equator. Using the global minimum distance resulted in a calculated 130I29 licks to reach the center, independent of licking style.[16]\\r\\nAll assortment flavors can also be purchased in single-flavor bulk. In 2004, and again in 2011 with different flavors, Tootsie Pops would have a random, rotating sixth flavor.\\r\\nNon-standard flavors can be now purchased in single-flavor bulk.\\r\\nAdditional flavors: Strawberry-Vanilla, Cherry (Valentine's Day), Tangerine, Pineapple, Tropical Punch, Wild Blackberry and Strawberry Watermelon.\\r\\nThe \\"Sweet & Sour Bunch\\" flavors came in a package of 8 Assortment pops, at .50 oz. / 14.8 grams each.","input":"What is the center of a tootsie pop?"},{"output":"Hyderabad","context":"^? The Andhra Pradesh Reorganisation Act, 2014 states that Hyderabad is joint capital of both Telangana and Andhra Pradesh states for a period of time not exceeding 10 years. A new capital is planned to be developed between Guntur and Vijaywada.\\r\\nAndhra Pradesh (/??ndr? pr??d??/) (?pronunciation?(help{info)) is one of the 29 states of India, situated on the southeastern coast of the country. The state is the seventh-largest state in India covering an area of 162,970?km2 (62,920?sq?mi).[4] As per 2011 Census of India, the state is tenth-largest by population with 49,386,799 inhabitants.\\r\\nOn 2 June 2014, the north-western portion of the state was bifurcated to form a new state of Telangana. Andhra Pradesh's longtime capital, Hyderabad, was transferred to Telangana as part of the division. However, in accordance with the Andhra Pradesh Reorganisation Act, 2014, Hyderabad will remain the de jure capital of both Andhra Pradesh and Telangana states for a period of time not exceeding 10 years.[5] The new riverfront proposed capital in Guntur district is Amaravati, which is under the jurisdiction of APCRDA.[6] The Gross State Domestic Product (GSDP) of the state in the 2016ÿ2017 financial year at current prices stood at ?6,800.3 billion (US$110?billion).[7]\\r\\nThe state has a coastline of 974?km (605?mi) with jurisdiction over nearly 15,000?km2 territorial waters, the second longest among all the states of India after Gujarat.[4][8] It is bordered by Telangana in the north-west, Odisha in the north-east, Karnataka in the west, Tamil Nadu in the south and the water body of Bay of Bengal in the east. A small enclave of 30?km2 (12?sq?mi) of Yanam, a district of Puducherry, lies south of Kakinada in the Godavari delta to the east of the state.[9]\\r\\nAndhra Pradesh is composed of two regions: Coastal Andhra, located along the Bay of Bengal, and Rayalaseema, in the inland southwestern part of the state.[10] These two regions comprise 13 districts, with 9 in Coastal Andhra and 4 in Rayalaseema. Visakhapatnam, located on the Bay of Bengal in North Coastal Andhra is the largest city and commercial hub of the state with a GDP of $43.5 billion, followed in population and GDP by Vijayawada, which is located on the Krishna River and which has a GDP of $3 billion as of 2010.[11][12]\\r\\nAndhra Pradesh hosted 121.8 million visitors in 2015, a 30% growth in tourist arrivals over the previous year.[13] The Tirumala Venkateswara Temple in Tirupati is one of the world's most visited religious sites, with 18.25 million visitors per year.[14] Other pilgrimage centers in Andhra Pradesh include the Ameen Peer Dargah in Kadapa, the Mahachaitya at Amaravathi, and the Kanaka Durga Temple in Vijayawada, while the state's natural attractions include the beaches of Visakhapatnam, hill stations such as the Araku Valley and Horsley Hills, and the island of Konaseema in the Godavari River delta.\\r\\n\\r\\n\\r\\nA tribe named Andhra was mentioned in Sanskrit texts such as Aitareya Brahmana (800-500 BCE). According to Aitareya Brahmana of the Rig Veda, the Andhras left north India and settled in south India.[15][16][17] The Satavahanas have been mentioned by the names Andhra, Andhrara-jatiya and Andhrabhrtya in the Puranic literature.[18][19] They did not refer themselves as Andhra in any of their coins or inscriptions; it is possible that they were termed as Andhras because of their ethnicity or because their territory included the Andhra region.[20]\\r\\nArchaeological evidence from places such as Amaravati, Dharanikota and Vaddamanu suggests that the Andhra region was part of the Mauryan Empire. Amaravati might have been a regional centre for Mauryan rule. After the death of Emperor Ashoka, Mauryan rule weakened around 200 BCE, and was replaced by several smaller kingdoms in the Andhra region.[21]\\r\\nThe Satavahana dynasty dominated the Deccan region from the 1st century BC to the 3rd century.[22] The later Satavahanas made Dharanikota and Amaravathi their capital, which according to the Buddhists is the place where Nagarjuna, the philosopher of Mahayana lived in the 2nd and 3rd centuries.[23] The Andhra Ikshvakus, with their capital at Vijayapuri, succeeded the Satavahanas in the Krishna River valley in the later half of the 2nd century.[24] Pallavas, who were originally executive officers under the Satavahana kings, were not a recognised political power before the 2nd century AD and were swept away by the Western Chalukyan invasion, led by Pulakesin II in the first quarter of the 7th century CE.[25] After the downfall of the Ikshvakus, the Vishnukundinas were the first great dynasty in the 5th and 6th centuries, and held sway over the entire Andhra country, including Kalinga and parts of Telangana. They played an important role in the history of Deccan during the 5th and 6th century CE, with Eluru, Amaravathi and Puranisangam.[26]\\r\\nThe Salankayanas were an ancient dynasty that ruled the Andhra region between Godavari and Krishna with their capital at Vengi (modern Pedavegi) from 300 to 440 CE.[27] The Eastern Chalukyas of Vengi, whose dynasty lasted for around 500 years from the 7th century until 1130 C.E., eventually merged with the Chola empire. They continued to rule under the protection of the Chola empire until 1189 C.E., when the kingdom succumbed to the Hoysalas and the Yadavas.[28] The roots of the Telugu language have been seen on inscriptions found near the Guntur district and from others dating to the rule of Renati Cholas in the fifth century CE.[29][30]\\r\\nKakatiyas ruled Andhra Pradesh state for nearly 200 years. They constructed several forts here. Their legacy was carried forward by their family members the Musunuri Nayaks.\\r\\nMusunuri Nayaks, the south Indian empire who are the first kings in India to win against Delhi sultanates ruled the present day Andhra Pradesh State. Musunuri Nayaks are family members belonging to same Vamsha of Kakatiyas which made them to be Nayak leaders of group of Nayaks against rebellion against Turks. Musunuri Nayaks were assisted by 75 Nayaks in the revolt against Delhi sultanates. Musunuri Prolaa Naidu is the first king of Modern day Andhra Pradesh state after the fall of Kakatiyas and the first Indian king who won against Delhi sultanates. He is succeeded by his cousin Musunuri Kaapaa Naidu who assumed titles \\"Andhradesadeswara\\" and \\"Andhra Suratrana\\" and ruled for nearly 40 years[31].\\r\\nThe Reddy dynasty (1325ÿ1448 CE) was established by Prolaya Vema Reddi in the early 14th century, who ruled from present day Kondaveedu. Prolaya Vema Reddi was part of the confederation of states that started a movement against the invading Turkic Muslim armies of the Delhi Sultanate in 1323 CE and succeeded in repulsing them from Warangal.[32] They constructed Kondaveedu Fort which they ruled between 1328ÿ1428, before it was taken over by the Gajpathis of Orissa, and later ravaged by the Muslim rulers of the Bahmani kingdom in 1458. The Vijayanagara emperor Krishnadevaraya captured it in 1516. The Golconda Sultans fought for the fort in 1531, 1536 and 1579, and Sultan Quli Qutb Shah captured it in 1579, renaming it Murtuzanagar. Again it was reconquered by Vijayanagarans who overthrew sultunate rule across the entirety of modern day Andhra Pradesh (excluding Telangana). After this rebellion, the Bahmani sultans launched no further military compaigns outside their kingdoms, because the Marathas soon emerged as the strongest power in India.[33][34][35] Efforts are in progress to classify Kondaveedu Fort as a UNESCO World Heritage Site.[36][37]\\r\\nPemmasani Nayaks, the greatest kings during Vijayanagara times ruled parts of Andhra Pradesh state with Gandikota as capital for nearly 300 years[38].\\r\\nThe Vijayanagara Empire originated in the Deccan Plateau region in the early 14th century. It was established in 1336 by Harihara Raya I and his brother Bukka Raya I of the Sangama Dynasty.[39][40][41] The empire's patronage enabled fine arts and literature to reach new heights in Kannada, Telugu, Tamil and Sanskrit, while Carnatic music evolved into its current form.[42]\\r\\nHarihara and Bukka, who served as treasury officers of the Kakatiyas of Warangal, founded the [Vijayanagara Empire]].[43] In 1347 CE, an independent Muslim state, the Bahmani Sultanate, was established in south India by Ala-ud-Din Bahman Shah in a revolt against the Delhi Sultanate. The Qutb Shahi dynasty held sway over the Andhra country for about two hundred years from the early part of the sixteenth century to the end of the seventeenth century.[44]\\r\\nIn the early nineteenth century Northern Circars was ceded to the British East India Company and became part of the Madras Presidency. Eventually this region emerged as the Coastal Andhra region. Later the Nizam rulers of Hyderabad ceded five territories to the British that eventually became the Rayalaseema region. The Nizams retained control of the interior provinces as the princely state of Hyderabad, acknowledging British rule in return for local autonomy. However, Komaram Bheem, a tribal leader, started his fight against the erstwhile Asaf Jahi Dynasty for the liberation of Hyderabad State.[45] Meanwhile, the French occupied Yanam, in the Godavari delta, and (save for periods of British control) would hold it until 1954. In 1947 Vizianagaram was the largest Hindu princely state in Andhra Pradesh.\\r\\nIndia became independent from the United Kingdom in 1947. The Nizam wanted to retain the independence of the Princely Hyderabad State from India, but the people of the region launched a movement to join the Indian Union. The state of Hyderabad was forcibly joined to the Republic of India with Operation Polo in 1948.[46]\\r\\nIn an effort to gain an independent state based on linguistic identity, and to protect the interests of the Telugu-speaking people of Madras State, Potti Sreeramulu fasted to death in 1952. As Madras became a bone of contention, in 1949 a JVP committee report stated \\"Andhra Province could be formed provided the Andhras give up their claim on the city of Madras (now Chennai)\\". After Potti Sreeramulu's death, the Telugu-speaking area of Andhra State was carved out of Madras State on 1 October 1953, with Kurnool as its capital city.[47] On the basis of a gentlemen's agreement of 1 November 1956, the States Reorganisation Act formed Andhra Pradesh by merging Andhra State with the Telugu-speaking areas of the already existing Hyderabad State.[48] Hyderabad was made the capital of the new state. The Marathi-speaking areas of Hyderabad State merged with Bombay State and the Kannada-speaking areas were merged with Mysore state.\\r\\nIn February 2014, the Andhra Pradesh Reorganisation Act, 2014 bill was passed by the Parliament of India for the formation of Telangana state comprising ten districts. Hyderabad will remain as a joint capital for not exceeding ten years.[5] The new state of Telangana came into existence on 2 June 2014 after approval from the President of India.[49]\\r\\nThe state has varied topography ranging from the hills of Eastern Ghats and Nallamala Hills to the shores of Bay of Bengal that supports varied ecosystems, rich diversity of flora and fauna. There are two main rivers namely, Krishna and Godavari, that flow through the state. The seacoast of the state extends along the Bay of Bengal from Srikakulam to Nellore district.[50] The plains to the east of Eastern Ghats form the Eastern coastal plains. The coastal plains are for the most part of delta regions formed by the Godavari, Krishna, and Penner Rivers. The Eastern Ghats are discontinuous and individual sections have local names. The Eastern Ghats are a major dividing line in the state's geography. The Kadapa Basin[51][better?source?needed] formed by two arching branches of the Eastern Ghats is a mineral-rich area. The Ghats become more pronounced towards the south and extreme north of the coast. Most of the coastal plains are put to intense agricultural use. The Rayalaseema region has semi-arid conditions.\\r\\nAndhra Pradesh Forest Department deals with protection, conservation and management of forests. The total forest cover of the state after the bifurcation is left with an area of 22,862?km2.[52] The forest in the state can be broadly divided into four major biotic provinces.[53] They are:\\r\\nEastern Ghats region is home to dense tropical forests, while the vegetation becomes sparse as the Ghats give way to the Deccan Plateau, where shrub vegetation is more common. The vegetation found in the state is largely of dry deciduous types with a mixture of teak, Terminalia, Dalbergia, Pterocarpus, Anogeissus, etc.\\r\\nThe state has many Sanctuaries, National Parks and Zoological Parks such as, Coringa, Krishna Wildlife Sanctuary, Nagarjunsagar-Srisailam Tiger Reserve, Kambalakonda Wildlife Sanctuary, Sri Venkateswara Zoological Park, Indira Gandhi Zoological Park etc. Atapaka Bird Sanctuary, Nelapattu Bird Sanctuary and Pulicat Lake Bird Sanctuary attracts many migratory birds.[54] The state possesses some rare and endemic plants like Cycas beddomei, Pterocarpus santalinus, Terminalia pallida, Syzygium alternifolium, Shorea talura, Shorea tumburgia, Psilotum nudum, etc.[53] The diversity of fauna includes tigers, panthers, hyenas, black bucks, cheetals, sambars, sea turtles and a number of birds and reptiles. The estuaries of river Godavari and Krishna support rich mangrove forests with fishing cats and otters as keystone species.[53]\\r\\nThe climate of Andhra Pradesh varies considerably, depending on the geographical region. Summers last from March to June. In the coastal plain, the summer temperatures are generally higher than the rest of the state, with temperature ranging between 20?C and 41?C. July to September is the season for tropical rains. About one third of the total rainfall is brought by the northeast monsoon. October and November see low-pressure systems and tropical cyclones form in the Bay of Bengal which, along with the northeast monsoon, bring rains to the southern and coastal regions of the state.\\r\\nNovember, December, January, and February are the winter months in Andhra Pradesh. Since the state has a long coastal belt the winters are not very cold. The range of winter temperature is generally 12?C to 30?C. Lambasingi in Visakhapatnam district is the only place in South India which receives snowfall because of its location as at 1,000?m (3,300?ft) above the sea level. It is also nicknamed as the Kashmir of Andhra Pradesh and the temperature ranges from 0?C to 10?C.[55][56]\\r\\nAs of 2011[update] Census of India, the state had a population of 49,386,799 with a population density of 308/km2 (800/sq?mi).\\r\\nAccording to Polavaram ordinance bill 2014 , 7 mandals of Khammam district in Telangana state merged with Andhra Pradesh to facilitate polavaram project, due to which population of 2,47,515 added to Andhra Pradesh. Thus final population of Andhra Pradesh in the year 2014 ,as per census 2011 is 4,96,34,314?; with a density of 304.5/sqkm .\\r\\nThe total population constitute, 70.4% of rural population with 34,776,389 inhabitants and 29.6% of urban population with 14,610,410 inhabitants. Children in the age group of 0ÿ6 years are 5,222,384, constituting 10.6% of the total population, among them 2,686,453 are boys and 2,535,931 are girls. Visakhapatnam district has the largest urban population of 47.5% and Srikakulam district with 83.8%, has the largest rural population, among others districts in the state. The overall population of the state comprises 17.1% of Scheduled Caste and 5.3% of Scheduled Tribe population.[4]\\r\\nThere are 24,738,068 male and 24,648,731 female citizensa sex ratio of 996 females per 1000 males, higher than the national average of 926 per 1000. The literacy rate of the state stands at 67.41%. West Godavari district has the highest literacy rate of 74.6% and Vizianagaram district has the least with 58.9%.[3][57]\\r\\nAndhra Pradesh ranks tenth of all Indian States in the Human Development Index scores[59] with a score of 0.416. The National Council of Applied Economic Research district analysis in 2001 reveals that Krishna, West Godavari and Chittoor are the three districts in rural AP with the highest Human Development Index scores in ascending order.\\r\\nThe official language of Andhra Pradesh is Telugu.[60][61] The Minister of Tourism and Culture has issued a declaration of the Telugu language as a Classical Language.[62]\\r\\nMajority of the people in Andhra Pradesh are Hindus while Muslims constitute a sizeable minority. According to the 2011 census, the major religious groups in the state are Hindus (90.87%), Muslims (7.32%) and Christians (1.38%). Buddhists, Sikhs, Jains and the people who declined to state their religion make up the remaining portion of population.[58]\\r\\nAndhra Pradesh is home to Shankaracharya of Pushpagiri Peetham. Other Hindu saints include Sadasiva Brahmendra, Bhaktha Kannappa, Yogi Vemana, Yogi Sri Potuluri Virabrahmendra Swami.[63]\\r\\nBuddhism spread to Andhra Pradesh early in its history. The Krishna River valley was \\"a site of extraordinary Buddhist activity for almost a thousand years.\\"[64] The ancient Buddhist sites in the lower Krishna Valley, including Amaravati, Nagarjunakonda and Jaggayyapeta \\"can be traced to at least the third century BCE, if not earlier.\\"[65]\\r\\nThe region played a central role in the development of Mahayana-buddhism, along with the Magadha-area in northeastern India.[66][67] A.K. Warder holds that \\"the Mahyna originated in the south of India and almost certainly in the Andhra country.\\"[68] According to Xing, \\"Several scholars have suggested that the Prajnaparamita probably developed among the Mahasamghikas in Southern India probably in the Andhra country, on the Krishna River.\\"[69] The Praj?pramit Sutras belong to the earliest Mahayana Sutras.[70][71]\\r\\nRegions:\\r\\nHitherto, it comprised two regions: Northern Circars and Ceded districts. Now, the state comprises two regions:\\r\\nDistricts:\\r\\nIt has a total of 13 districts, nine in Kosta and four in Rayalaseema.\\r\\nRevenue divisions:\\r\\nThese 13 districts are further divided into 50 revenue divisions There are as many as 7 revenue divisions in East Godavari district and only 2 in Vizianagaram district.[4][73]\\r\\nMandals:\\r\\nThe 50 revenue divisions are in turn divided into 670 mandals. Chittoor district has the most number of mandals with 66 and Vizianagaram district has the least with 34.[74]\\r\\nCities:\\r\\nThere are a total of 31 cities which include, 16 municipal corporations and 14 municipalities. There are two million plus cities namely, Visakhapatnam and Vijayawada.\\r\\nLegislative Assembly of Andhra Pradesh is the lower house of the state and legislative council of andhra pradesh is the upper house. with 58 members. In the Parliament of India, Andhra Pradesh has 11 seats in the Rajya Sabha, and 25 seats in the Lok Sabha.[75] There are a total of 175 Assembly constituencies in the state. East Godavari district has the most number of constituencies with 19 and Vizianagaram district has the least with 9 assembly seats.[76] Whereas, the legislative council of the state has 58 seats, which is one-third of total assembly seats.[77]\\r\\nUntil 1962, the CPI, along with socialist parties namely Praja Socialist Party and Krishi Lok Party played an important role in the 1950s. In the 1967 state assembly elections, all socialist parties were eliminated and CPI lost opposition party status. The first Chief Minister of Andhra Pradesh was Neelam Sanjiva Reddy who later served as President of India.[78][79]\\r\\nIn 1983, the Telugu Desam Party (TDP) won the state elections and N.T. Rama Rao became the chief minister of the state for the first time. This broke the long time single party monopoly enjoyed by the INC from 1956 until 1982. Nandamuri Taraka Rama Rao is the founder of Telugu Desam party and served as the first chief minister from the party. The 1989 elections ended the rule of NTR, with the INC party returning to power with Marri Chenna Reddy at the helm. He was replaced by Janardhan Reddy in 1990, who was replaced by Kotla Vijaya Bhaskara Reddy in 1992.\\r\\nN. Chandrababu Naidu held the record for the longest serving chief minister (1995 to 2004).[80] In 1994, Andhra Pradesh gave a mandate to the Telugu Desam Party again, and NTR became the chief minister again. Nara Chandrababu Naidu, the son-in-law of NTR, came to power with the backing of a majority of the MLAs. The Telugu Desam Party won both the assembly and Lok Sabha election in 1999 under the leadership of Chandrababu Naidu.\\r\\nIn what would be the last elections held in the unified state, Telugu Desam Party got a mandate in their favour in the residuary (new)state. Nara Chandrababu Naidu, the chief of Telugu Desam Party became Chief Minister on 8 June 2014, for the new state of Andhra Pradesh.[81]\\r\\nAndhra Pradesh was ranked eighth among other Indian states in terms of GSDP for the financial year 2014ÿ2015. The GSDP at current prices was  5200.3 billion and at constant prices was  2645.21 billion.[82] The domestic product of agriculture sector accounts for ?545.99 billion (US$8.5?billion) and Industrial sector for ?507.45 billion (US$7.9?billion). The service sector of the state accounts more percentage of the GSDP with a total of ?1,305.87 billion (US$20?billion).[83] In the 2010 list by Forbes magazine, there were several from Andhra Pradesh among the top 100 richest Indians.[84]\\r\\nAndhra Pradesh economy is mainly based on agriculture and livestock. Four important rivers of India, the Godavari, Krishna, Penna, and Thungabhadra flow through the state and provide irrigation. 60 percent of population is engaged in agriculture and related activities. Rice is the major food crop and staple food of the state. It is an exporter of many agricultural products and is also known as \\"Rice Bowl of India\\".[85][86] The state has three Agricultural Economic Zones in Chittoor district for mango pulp and vegetables, Krishna district for mangoes, Guntur district for chilies.[87]\\r\\nBesides rice, farmers also grow jowar, bajra, maize, minor millet, coarse grain, many varieties of pulses, oil seeds, sugarcane, cotton, chili pepper, mango nuts and tobacco. Crops used for vegetable oil production such as sunflower and peanuts are popular. There are many multi-state irrigation projects under development, including Godavari River Basin Irrigation Projects and Nagarjuna Sagar Dam.[88]\\r\\nLivestock and poultry is also another profitable business, which involves rearing cattle in enclosed areas for commercial purposes. The state is also a largest producer of eggs in the country and hence, it is nicknamed as \\"Egg Bowl of Asia\\".[89][90]\\r\\nFisheries contribute 10% of total fish and over 70% of the shrimp production[91] of India. The geographical location of the state allows marine fishing as well as inland fish production. The most exported marine exports include Vannamei shrimp[92] and are expected to cross $1 billion in 2013ÿ2014.[93]\\r\\nThe industrial sector of the state includes some of the key sectors like Pharma, Automobile, Textiles etc. Sricity located in Chittoor district is an integrated business city which is home to many renowned firms like PepsiCo, Isuzu Motors, Cadbury India, Kellogg's, Colgate-Palmolive, Kobelco etc.[94] The PepsiCo firm has its largest plant in India at Sri City.[95]\\r\\nThe state is also emerging in information technology and biotechnology. The IT/ITES revenues of Visakhapatnam is at ?14.45 billion (US$230?million) in 2012ÿ2013. The development of IT in Tier-II and Tier-III cities like Vijayawada, Kakinada and Tirupati is also improving. In the fiscal year 2012ÿ2013, Vijayawada's IT/ITeS revenues were ?1,153 million (US$18?million) crore. Tirupati with ?693 million (US$11?million) and Kakinada with ?615 million (US$9.6?million) stand next.[96] For the benefit of state i.e., After separating Telangana from andhra, people of andhra protested for special status during the month of January in 2017\\r\\nAndhra Pradesh is one of the storehouses of mineral resources in India. Andhra Pradesh with varied geological formations, contain rich and variety of industrial minerals and building stones.[97]\\r\\nAndhra Pradesh is listed top in the deposit and production of mica in India. Minerals found in the state include limestone, reserves of oil and natural gas, manganese, asbestos, iron ore, ball clay, fire clay, gold diamonds, graphite, dolomite, quartz, tungsten, steatitic, feldspar, silica sand. It has about one third of India's limestone reserves and is known for large exclusive deposits of barytes and galaxy granite in the international market.[97]\\r\\nMining\\r\\nMining is identified as one of the growth engines for the overall development of industry and infrastructure. The Tummalapalle Uranium mine in Andhra has confirmed 49,000 tonnes of ore and there are indications that it could hold reserves totalling three times its current size. 700 million tonnes of metal grade Bauxite deposits in proximity to Visakhapatnam Port.\\r\\nReliance Industries Limited struck nine trillion cubic feet of gas reserves in the KG basin, 150?km (93?mi) off the Andhra Pradesh coast near Kakinada. Discovery of large quantity of natural gas in KG Basin is expected to provide rapid economic growth.[98] During the year 2016, nearly 134 trillion cubic feet of methane hydrate deposits were explored in KG basin whose extraction is adequate to impart energy security for many decades to India.[99]\\r\\nPower plants\\r\\nThe state is a pioneer nationwide in solar power generation. APGENCO is the power generating company owned by the state.[100] The state has become power surplus with excess power generation being exported to other states.[101]\\r\\nThermal (natural gas and coal based) and renewable power plants totalling to 21,000 MW were installed in the state by the year 2015. Local power plants of 9,600?MW capacity only are supplying electricity in the state which includes Simhadri Super Thermal Power Plant (2000 MW) of NTPC, Vizag Thermal Power Station (1040 MW), Rayalaseema Thermal Power Station (1050 MW), Sri Damodaram Sanjeevaiah Thermal Power Station (1600 MW), Vijayawada Thermal Power Plant (1760 MW), etc. Hydel power plants are having a capacity of 1671 MW.[102]\\r\\nAndhra Pradesh has rich culture and heritage.[103] Kuchipudi, the state dance originated in the village of Kuchipudi in Krishna district, had entered the Guinness World Records for performing Mahabrinda Natyam with a total of 6,117 dancers in Vijayawada.[104] It had thirteen geographical indications in categories of agricultural handicrafts, foodstuff and textiles as per Geographical Indications of Goods (Registration and Protection) Act, 1999.[105] It increased to fifteen with the addition of Banaganapalle Mangoes[106] and Bandar laddu.[107] The other GI tagged goods are, Bobbili Veena, Budithi Bell and Brass Craft, Dharmavaram Handloom Pattu Sarees and Paavadas, Guntur Sannam, Kondapalli Toys, Machilipatnam Kalamkari, Mangalagiri Sarees and Fabrics, Srikalahasti Kalamkari, Tirupati Laddu, Uppada Jamdani Sari and Venkatagiri Sari.[105]\\r\\nMachilipatnam and Srikalahasti Kalamkari are the two unique textile art forms practised in India.[108] There are also other notable handicrafts present in the state, like the soft limestone idol carvings of Durgi.[109] Etikoppaka in Visakhapatnam district is notable for its Lac industry, producing lacquered wooden.[110][111]\\r\\nThe state has many museums, which features a varied collection of ancient sculptures, paintings, idols, weapons, cutlery and inscriptions, and religious artifacts such as the Amaravati Archaeological Museum,[112] Visakha Museum and Telugu Cultural Museum in Visakhapatnam displays the history of the pre-Independence and the Victoria Jubilee Museum in Vijayawada with large collection of artifacts.\\r\\nNannayya, Tikkana and Yerrapragada form the trinity who translated the Sanskrit epic Mahabharata into Telugu language. Nannayya wrote the first treatise on Telugu grammar called Andhra Shabda Chintamani in Sanskrit, as there was no grammatical work in Telugu prior to that.[113] Pothana is the poet who composed the classic Srimad Maha Bhagavatamu, a Telugu translation of Sri Bhagavatam. Vemana is notable for his philosophical poems. The Vijayanagara emperor Krishnadevaraya wrote Amuktamalyada. Telugu literature after Kandukuri Veeresalingam is termed as Adhunika Sahityam. He is known as Gadya Tikkana and was the author of Telugu social novel, Satyavati Charitam. Jnanpith Award winners include Sri Viswanatha Satya Narayana. The Andhra Pradesh native and revolutionary poet Sri Sri brought new forms of expressionism into Telugu literature.[114]\\r\\nMany composers of Carnatic music like Annamacharya, Kshetrayya, and Bhadrachala Ramadas were of Telugu descent. Modern Carnatic music composers and singers like Ghantasala, Sujatha Puligella and M. Balamuralikrishna are also of Telugu descent. The Telugu film industry hosts many music composers and playback singers such as S. P. Balasubrahmanyam, P. Susheela, S. Janaki, P B Srinivas. Folk songs are popular in the many rural areas of the state. Forms such as the Burra katha and Poli are still performed today.[115] Harikathaa Kalakshepam (or Harikatha) involves the narration of a story, intermingled with various songs relating to the story. Harikatha was originated in Andhra.[116] Burra katha is an oral storytelling technique with the topic be either a Hindu mythological story or a contemporary social issue.[117] Rangasthalam is an Indian theatre in the Telugu language, based predominantly in Andhra Pradesh.[118] Gurazada Apparao wrote the play, Kanyasulkam in 1892, which is often considered the greatest play in the Telugu language.[119] C. Pullaiah is cited as the father of Telugu theatre movement.[120][121]\\r\\nThe Telugu film industry had largely shifted from Chennai to Hyderabad. The Telugu film culture (or, \\"Tollywood\\") is the second -largest film industry in India next to Bollywood Film Industry.[122] Prolific film producer from the state, D. Ramanaidu holds a Guinness Record for the most number of films produced by a person.[123] In the years 2005, 2006 and 2008 the Telugu film industry produced the largest number of films in India, exceeding the number of films produced in Bollywood.[124][125] The industry holds the Guinness World Record for the largest film production facility in the world.[126]\\r\\nTelugu people's adorable traditional sweet Pootharekulu originated from Atryapuram village, Andhra Pradesh.\\r\\nTourism\\r\\nThe state has several beaches in its coastal districts such as, Rushikonda, Mypadu, Suryalanka etc.;[127] caves such as, Borra Caves,[128] Indian rock-cut architecture depicting Undavalli caves[129] and the country's second longest caves named as Belum Caves.[130] The valleys and hills include, Araku Valley, Horsley Hills, Papi Hills etc[131] Arma Konda peak located in Visakhapatnam district is the highest peak in Eastern Ghats.\\r\\nThe state is home to various religious pilgrim destinations such as, Tirumala Temple, Simhachalam Temple, Annavaram, Srisailam temple, Kanaka Durga Temple, Amaravati, Srikalahasti temple,[132] Shahi jamia masjid in Adoni, Gunadala Church in Vijayawada, Buddhist centres at Amaravati, Nagarjuna Konda etc.,[133] and many more as well.\\r\\nThe state is well connected to other states through road and rail networks. It is also connected to other countries by means of airways and seaports as well. With a long seacoast along the Bay of Bengal, it also has many ports for sea trade. The state has one of the largest railway junctions at Vijayawada and one of the largest seaports at Visakhapatnam.\\r\\nRoads in Andhra Pradesh consist of National Highways and state highways with district roads as well. NH 5, with a highway network of around 1,000?km (620?mi) in the state, is a part of Golden Quadrilateral Project undertaken by National Highways Development Project. It also forms part of AH 45 which comes under the Asian Highway Network.\\r\\nThe Andhra Pradesh State Road Transport Corporation (APSRTC) is the major public bus transport owned by the state government which runs thousands of buses connecting different parts of the state. Pandit Nehru Bus Station (PNBS) in Vijayawada is one of the largest bus terminals in Asia.[134]\\r\\nAndhra Pradesh has a railway network of 4,403?km (2,736?mi). One of the highest broad gauge tracks in the world is in Eastern Ghats route that runs from Visakhapatnam to Anantagiri.[135] Most of Andhra Pradesh falls under Guntur, Vijayawada, Guntakal (South Central Railway zone and Waltair (East Coast Railway zone) divisions.\\r\\nWaltair Railway Division under ECoR zone is fourth-largest revenue earning division in India.[136] Vijayawada railway station is the highest grosser in the SCR zone and one of busiest railway junctions in India.\\r\\nVisakhapatnam Airport, is the only airport in the state with international connectivity. The state has five domestic airports, Vijayawada Airport at Gannavaram, Rajahmundry Airport at Madhurapudi, Tirupati Airport at Renigunta, Cuddapah Airport and a privately owned, public use airport at Puttaparthi. There are also 16 small air strips located in the state.[137]\\r\\nAndhra Pradesh has one of the country's largest port at Visakhapatnam in terms of cargo handling.[138] The other famous ports are Krishnapatnam Port (Nellore), Gangavaram Port and Kakinada Port. Gangavaram Port is a deep seaport which can accommodate ocean liners up to 200,000ÿ250,000 DWT.[139] There are 14 notified non-major ports at Bheemunipatnam, S.Yanam, Machilipatnam, Nizampatnam, Vadarevu etc.[140]\\r\\nAndhra Pradesh has an overall literacy rate of 67.41% as per the 2011 Indian census.[3] The primary and secondary school education is imparted by government, aided and private schools, under the administration of School Education Department of the state.[142][143] These schools include, Municipal, Andhra Pradesh Residential, Andhra Pradesh Social Welfare Residential, Zilla Parishad, aided and unaided private schools.[144][145] There a total of 6,864,201 students[146] enrolled in 61,529 schools in the state.[147] The mediums of instruction followed by the schools are Telugu, English, Urdu, Hindi, Kannada, Odia and Tamil.[148] The Directorate of Government Examinations of the state administers the conduct of Secondary School Certificate examination.[149] 652,374 candidates took the 2016 Secondary School Certificate exam and recorded a pass percentage of 94.52% for regular and 55.47% by private candidates.[150]\\r\\nThe higher education in the state is administered by the Department of Higher Education.[151] The central universities in the state are, All India Institute of Medical Sciences, IIM Visakhapatnam, IIT Tirupati, NIT Tadepalligudem and IIITDM Kurnool,[152] Indian Institute of Petroleum and Energy.[153] The Government of Andhra Pradesh has established Rajiv Gandhi University of Knowledge Technologies (RGUKT) in 2008 to cater to the educational needs of the rural youth of Andhra Pradesh.[154] As per the University Grants Commission, GITAM, K L University and Vignan University are the Deemed Universities in the state.[155] There are eighteen state universities in different districts providing higher education in the fields of horticulture, law, medical, techonology, vedic and veterinary.[156] Andhra University is the oldest of all the universities in the state, established in 1926.[157][158]\\r\\nResearch\\r\\nResearch institutes have been set up by the central government in the state. NSTL Naval Science & Technological Laboratory, NIO National Institute of Oceanography, Visakhapatnam, School of Planning and Architecture at Vijayawada is an autonomous research institute under Ministry of Human Resource Development of Government of India, National Atmospheric Research Laboratory carry out fundamental and applied research in Atmospheric and Space Sciences,[159] Indian Institute of Science Education and Research, Tirupati,[160] Society For Applied Microwave Electronics Engineering and Research, Visakhapatnam Central Tobacco Research Institute, Rajahmundry under control of ICAR (Indian Council of Agriculture Research) conducts fundamental and applied research on Tobacco for the benefit of the farming community,[161] Indian Institute of Oil Palm Research (IIOPR) at Pedavegi near Eluru in West Godavari district serves as a centre for conducting and co-ordinating research on all aspects of oil palm conservation, improvement, production, protection, post-harvest technology and transfer of technology,[162] CCRH Regional Research Institute at Gudivada, Clinical Research Institute at Tirupati and National Institute of Oceanography[163] at Visakhapatnam are some of them.[164]\\r\\nSpace research organisation\\r\\nIndian Space Research Organisation (or Sriharikota Range (SHAR)) at barrier island of Sriharikota in Nellore district of Andhra Pradesh is a satellite launching station.[165] It is India's primary orbital launch site. India's lunar orbiter Chandrayaan-1 was launched from the centre at 6:22 AM IST on 22 October 2008.[166]\\r\\nThe Sports Authority of Andhra Pradesh, is the governing body which looks after the infrastructure development in cricket, field hockey, association football, Olympic weightlifting, chess, water sports, tennis, badminton, table tennis, cycling, etc.[167]\\r\\nCricket is one of the most popular sports in the state. The ACA-VDCA Stadium in Visakhapatnam is the home to Andhra Pradesh cricket team. The venue regularly hosts international as well as domestic matches. Notable cricketers from Andhra Pradesh, include Maharajkumar of Vizianagram, M. V. Narasimha Rao, M. S. K. Prasad, V.V.S. Laxman, Tirumalasetti Suman, Arshad Ayub, Ambati Rayudu, Venkatapathy Raju, Sravanthi Naidu, Yalaka Venugopal Rao etc. Humpy Koneru, from Gudivada of Krishna district of the state, is an Indian chess Grandmaster.\\r\\nKarnam Malleswari, the first female Indian to win an Olympic medal, hails from Srikakulam district of Andhra Pradesh. She won the bronze medal on 19 September 2000, in the 69?kg category with a lift of 240?kg.[168]\\r\\nPullela Gopichand, is a former Indian badminton player. He won the All England Open Badminton Championships (2001), to becoming the second Indian to achieve it after Prakash Padukone.[169][170][171]\\r\\nCherukuri Lenin 1985 or 1986 ÿ 24 October 2010) was an Indian archer and coach who won a silver medal at the Asian Grand Prix in Malaysia, and was a National Archery Coach.","input":"What is the capital of andhra pradesh and telangana?"},{"output":"adapt to new or revised routed protocols","context":"Protocol-dependent modules (PDMs) are used by the routing protocol EIGRP to make decisions about adding routes learned from other sources; for example other routers or routing protocols to the routing table. In fact EIGRP has the capability for routing several different protocols including IPv4 and IPv6 using protocol-dependent modules (PDMs). The PDM is also capable of carrying information from the routing table to the topology table. EIGRP offers support for various routed protocols (e.g. Internet Protocol Version 6 (IPv6), IP, IPX, AppleTalk), and has added support for Service Routing (SAF) PDMs. The only other routing protocol that comes with support for multiple network layer protocols is Intermediate System-to-Intermediate System (IS-IS).\\r\\n\\"In theory, EIGRP can add PDMs to easily adapt to new or revised routed protocols such as IPv6. Each PDM is responsible for all functions related to its specific routed protocol. The IP-EIGRP module is responsible for the following functions:\\r\\nWhen a newly discovered neighbor is learned, the address and interface of the neighbor are recorded, and this information is held in the neighbor table, stored in RAM. There is one neighbor table per each protocol-dependent module.[2]","input":"What is the purpose of the eigrp pdm?"},{"output":"\\"The Star-Spangled Banner\\" by Marvin Gaye","context":"\\r\\n\\r\\nVH1 (originally an initialism of Video Hits One) is an American pay television network based in New York City owned by Viacom. It was originally created by Warner-Amex Satellite Entertainment, at the time a division of Warner Communications and the original owner of MTV, and launched on January 1, 1985, in the former space of Turner Broadcasting System's short-lived Cable Music Channel. \\r\\n\\r\\nThe original purpose of the channel was to build upon the success of MTV by playing music videos, but targeting a slightly older demographic than its sister channel, focusing on the lighter, softer side of popular music. More recently, much like MTV, VH1 has been in the area of reality television programming, such as Behind the Music, the I Love series and the Celebreality block of programming, as part of the channel's current focus on programming primarily aimed towards women.\\r\\n\\r\\nAs of January 2016, approximately 90.2 million US households receive VH1.[1]\\r\\n\\r\\nVH1's aim was to focus on the lighter, softer side of popular music,[2] including such musicians as Olivia Newton-John, Kenny Rogers, Carly Simon, Tina Turner, Elton John, Billy Joel, Eric Clapton, Sting, Donna Summer, Rod Stewart, Kenny G, Michael Bolton, Anita Baker, Chicago and Fleetwood Mac, in hopes of appealing to people aged 18 to 35, and possibly older. Also frequently featured in the network's early years were \\"videos\\" for Motown and other 60s oldies consisting of newsreel and concert footage. It was introduced on January 1, 1985, with the video performance of \\"The Star-Spangled Banner\\" by Marvin Gaye.[2]\\r\\n\\r\\nFrom the start, Video Hits One was branded as an urban version of its sister/parent channel. It played more jazz and R&B artists than MTV and had a higher rotation of urban-contemporary performers. Its early on-camera personalities were New York radio veterans Don Imus (then of WNBC), Frankie Crocker (then program director and DJ for WBLS), Scott Shannon (of WHTZ), Jon Bauman (\\"Bowzer\\" from Sha Na Na), Bobby Rivers, and Rita Coolidge.\\r\\n\\r\\nLater VJs included Tim Byrd of WPIX-FM (the current day FM rebroadcast of WFAN), a station whose eclectic ballad-and-R&B oriented format mirrored that of VH-1, and Alison Steele (\\"The Nightbird\\" of WNEW-FM). Rosie O'Donnell later joined the outlet's veejay lineup. O'Donnell would also host a comedy show featuring various comedians each episode. As an added touch to make the network more like a televised radio station, the early years of the network featured jingles in their bumpers produced by JAM Creative Productions in Dallas, who had previously made jingles for radio stations worldwide.\\r\\n\\r\\nThe format left room for occasional ad-libs by the VJ, a godsend for emcees such as Imus and O'Donnell. In true Imus style, he used a 1985 segment of his VH-1 show to jokingly call smooth-jazz icon Sade Adu a \\"grape\\" for her oval-shaped head.\\r\\n\\r\\nTypical of VH1's very early programming was New Visions, a series which featured videos and in-studio performances by smooth jazz and classical and new-age bands and performers, including Spyro Gyra, Andy Narell, Mark Isham, Philip Glass,[3] and Yanni. At first many different musicians guest-hosted the program, but eventually musician/songwriter Ben Sidran became the permanent host.\\r\\n\\r\\nNew Age music videos continued to play on the channel into the 1990s. They would be seen on the Sunday morning two-hour music video block titled Sunday Brunch.\\r\\n\\r\\nOnce VH1 established itself a few years later, they catered to Top 40, adult contemporary, classic rock, and 1980s mainstream pop.[4] For a time, even country music videos aired in a one-hour block during the afternoons. They started out using MTV's famous Kabel typeface font for their music video credit tags. It was later replaced in 1991 by a larger font, with the year the video was made added to the lower column that identified the label on which the album was released. In 1993, the name of the videos' director was included at the bottom of the credits.\\r\\n\\r\\nDuring this time, they also had some non-music programming, such as a comedy hour hosted by Rosie O'Donnell with various amateur and veteran comedians, called Stand Up Spotlight,[5] an in-depth look at current movies called Flix,[6] and reports on good civilians and volunteers in the community, called Good News People.[7]\\r\\n\\r\\nEvery week, the Top 21 Video Countdown usually had a different guest host.[8] Occasionally, they had themed countdowns as well, such as Elvira hosting scary videos for Halloween in 1991.[9]\\r\\n\\r\\nLong blocks of music videos by a particular artist or band, theme, or years were also very popular in this era. One popular weekend program was called Video Rewind, in which blocks of 1980s videos from one particular year would play for an hour.[10] There was also a short-lived hour-long program called By Request in which viewers could call a 1ÿ900 hotline number to request their videos.\\r\\n\\r\\nAlso in 1991, a popular morning program was introduced called Hits News & Weather that ran from 7 AM to 9 AM ET.[11] (It later expanded to 10 AM ET.) It consisted of music videos both past and present along with a 90-second update of the day's news & weather provided by All News Channel. The updates were typically shown twice an hour during the program. A box displaying the minutes past the hour was shown below the logo during the period. It was discontinued a week before the channel was re-branded in the Spring of 1994. During the week prior, classic music videos from forgotten artists/bands aired, titled Whatever Happened To...?\\r\\n\\r\\nThe channel's playlist was gradually expanding, and, by 1994, included contemporary musicians such as Ace of Base, Melissa Etheridge, Sheryl Crow, Lisa Loeb, Amy Grant, Seal, and other slightly heavier, or more alternative rock-influenced music than what it had originally played, although favorites such as Whitney Houston, Mariah Carey, Rod Stewart, Cher, Elton John, Madonna, Phil Collins, Janet Jackson, and Cline Dion still continued to receive heavy play for several more years as well. VH1 to One was a program in the Video Hits One days that was very similar to Behind The Music. It profiled artists such as Phil Colins, Michael Bolton and Paul McCartney. Plus other various artists of interest at the time that were playing the network's chosen style of music at the time and their music careers\\r\\n\\r\\nIn order to reach a wider and younger audience, VH1 announced in late 1989 that in 1990 they would be holding a contest where the grand prize was a collection of 36 Chevrolet Corvettes, one for every model year from its introduction year of 1953, to the then current model year of 1989 (there is no model for 1983), all going to a single grand winner. All cars were to be certified as roadworthy and in \\"good\\" to \\"excellent\\" condition. The collection at the time had an estimated worth of over US$1 million. Contestants entered by calling a 900 number and registering, at $2 per call. VH1 received over 4 million call-in entries. The winner was a man from Long Island, New York, who immediately sold the entire collection to artist Peter Max for $500,000. Max intended to use the cars for an art project, but it never got started and the entire collection was left in an underground parking lot in New York City for over 20 years, and deteriorated into poor condition.[12][13][14][15][16]\\r\\n\\r\\n In May 1994, VH1 re-branded itself as VH1: Music First,[17] following a slight ratings decline in the early 1990s.[2] They began airing \\"History of Music Videos A to Z\\" during the July 4 weekend from 1994 to 1998 where they would show a large percentage of their library of music videos, which would include mini-marathons of videos by artists with a large number of videos. The success of A to Z led to a weeknight 11 p.m. hour-long broadcast of Madonna videos, titled The Madonna Show. The videos were aired without introduction by a VJ and the program was soon shortened to thirty minutes, and then scrapped altogether. By 1996, VH1 was heading down the same path as its sister channel, MTV, choosing to focus more on music-related shows than on music videos. Additionally, the network began to expand its playlist of music videos to include more rock music.[2] Old episodes of American Bandstand could regularly be seen on the channel. By that time, the channel's ratings were beginning to fall.\\r\\n\\r\\nAs part of VH-1's re-branding as \\"VH1: Music First\\" in 1994, the channel launched a new series, the VH1 Top 10 Countdown, that counted down the top ten music videos played on VH1 each week. A combination of record sales, radio airplay, video spins, message board posts, and conventional mail would decide the order of the countdown. A rotating cast of VJs picked up hosting duties for the show over the years. The series expanded from ten to twenty music videos, becoming the VH1 Top 20 Video Countdown, in 2001. The show was renamed The 20 in early 2015, and ended later that year.\\r\\n\\r\\nIn the fall of 1996, VH1 premiered Pop-Up Video, in which music videos were accompanied by \\"pop-ups\\" (also known as \\"bubbles\\" or \\"info nuggets\\")small enclosed areas of the screen containing facts about the band artists, and videos such as career highlights, discography, biographical details, quotes, and anecdotes.\\r\\n\\r\\nIn February 1996, VH1 again hit it big with the premiere of the first of the network's flagship shows, VH1 Storytellers. The show started with a broadcast of Ray Davies, during his \\"Storyteller\\" tour, and took its name from this first show. In each hourlong episode, artists appear in front of a (mostly small and intimate) live audience, interspersing musical performances with anecdotes related to the songs' meaning, the songwriting process, audience reaction, etc. Along with Davies, the series has featured a widely diverse list of artists, including Culture Club, Willie Nelson and Johnny Cash, Kanye West, Tom Waits, and Def Leppard. Meat Loaf enjoyed the show's format so much that he bought the stage decorations from VH-1 and went on to do a \\"Storytellers\\" tour in 1998/1999.[18]\\r\\n\\r\\nVH1 scored another hit in August 1997 with the debut of Behind the Music. The hourlong show features interviews and biographies of some of popular music's biggest stars qualified to be profiled on the series. The premiere episode featured Milli Vanilli. Episodes have ranged from Aaliyah to Stryper to Queen, as well as others such as, Meat Loaf, Tori Amos, MC Hammer, Cher, Oasis, Steppenwolf, Fleetwood Mac, TLC, \\"Weird Al\\" Yankovic, Megadeth, Britney Spears, Selena, Petra, Pantera, and Eminem, with more episodes being produced periodically. By the late 1990s, the show began to run out of artists to profile, leading to the short-lived BTM2 program, half-hour looks into bands and artists whose popularity was rising, but not yet at its peak.\\r\\n\\r\\nShortly after, VH1 created a companion series, Legends (originally sponsored by AT&T), profiling artists who have made a more significant contribution to music history to qualify as \\"Legends\\" (that is, those artists who have gone beyond the category of Behind the Music biographies). The artists profiled so far have included Aerosmith; the Bee Gees; David Bowie; Johnny Cash; Eric Clapton; The Clash; George Clinton; Sam Cooke; Crosby, Stills, Nash & Young; The Doors; John Fogerty; Aretha Franklin; Marvin Gaye; The Grateful Dead; Guns N' Roses; Jimi Hendrix; Michael Jackson; Eminem; Elton John; Janis Joplin; B. B. King; Led Zeppelin; John Lennon; Curtis Mayfield; Nirvana; Pink Floyd; The Pretenders; Red Hot Chili Peppers; Queen; Bruce Springsteen; Tina Turner; U2; Stevie Ray Vaughan; The Who, and Neil Young.[19]\\r\\n\\r\\nThe VH1 Save The Music Foundation is a nonprofit organization dedicated to restoring instrumental music education programs in America's public schools, and raising awareness about the importance of music as part of each child's complete education. Founded in 1997, VH1 Save The Music was the first organization in existence dedicated to restoring music programs in America's schools. For nearly 20 years, the foundation has donated over $53 million worth of new musical instruments to 2,024 public schools in 247 school districts around the country to dateimpacting the lives of more than three?million public school students. Learn about the foundation's Play it Forward campaign in celebration of its 20th anniversary here: on.vh1.com/playitforward\\r\\n\\r\\nVH1 Save The Music Foundation's 2012 Ambassador class includes Gavin Rossdale, Jordin Sparks, Vanessa Carlton, Lupe Fiasco, Katy Perry, Chris Daughtry, Matthew Morrison, and AJ Mclean, joining Alumni Ambassadors including: Kelly Clarkson, John Mayer, Natasha Bedingfield, John Legend, The Fray, Colbie Caillat, Tamia, Ne-Yo, and Nick Lachey, among many other musicians, singers, athletes and celebrities dedicated to the cause.[20] VH1 Save The Music Ambassadors help raise awareness and deliver key messages about the importance of music education in a young person's life, as well as help raise funds to further the Foundation's mission to restore instrumental music education programs in U.S. public elementary and middle schools. It won a Peabody Award in 1999.[21]\\r\\n\\r\\nIn 1998, VH1 debuted the first annual VH1 Divas concert and featured the \\"divas\\" Aretha Franklin, Mariah Carey, Shania Twain, Gloria Estefan, and Celine Dion, and the \\"special guest\\" Carole King.[22] The second installment of these \\"diva\\" shows was produced in 1999 featuring Whitney Houston, Tina Turner, Cher, LeAnn Rimes, Mary J. Blige, Faith Hill, Chaka Khan, Brandy, and special \\"divo\\" Elton John.[23] It became a huge success and was featured in the following years starring Diana Ross, Donna Summer, Destiny's Child, Kelly Clarkson, Jordin Sparks, Miley Cyrus, Jennifer Hudson, Shakira, Deborah Harry, Anastacia, Dixie Chicks, Gladys Knight, Patti LaBelle, and Jessica Simpson. Also in 1999, Donna Summer who was asked to do the \\"diva\\" concert, was given her own concert special by VH1 \\"Donna Summer Live and More: Encore\\". Some artists such as Whitney Houston, Mariah Carey, Aretha Franklin, Mary J. Blige, Celine Dion, Cher, Chaka Khan, and Faith Hill were featured in two or more VH1 divas concerts, with Cyndi Lauper appearing the most times, having been featured in four concerts.\\r\\n\\r\\nIn 1999, VH1 aired its first original movie, a bio-pic on Sweetwater. Their third original movie (which aired in 2000), Two of Us, focused on a fictional meeting between John Lennon and Paul McCartney. Over the next three years, they made over a dozen movies, including bio-pics on Jim Morrison and The Doors, Ricky Nelson, MC Hammer, The Monkees, Meat Loaf, and Def Leppard.\\r\\n\\r\\nVH1 continues to air \\"Movies That Rock\\" on a regular basis, expanding to include movies not produced by VH1. The subject matter remains mostly focused on music and musicians.\\r\\n\\r\\nIn the late 1990s, VH1 continued to get more diverse and teen-based with its music selection, and with that, the network updated its 1994 \\"Big 1\\" logo. Various late-night rock shows have been shown on VH1, featuring alternative rock and metal videos from the 1980s and 1990s. VH1 eventually warmed up to harder rock acts such as the Red Hot Chili Peppers, the Foo Fighters, the Stone Temple Pilots, and Metallica. Their new videos began being added into VH1's playlist right away.\\r\\n\\r\\nAround late 2002, VH1 even began to play mainstream rap musicians.[2] The latest videos by Eminem, Nelly, Jay-Z, Snoop Dogg, Busta Rhymes, Missy Elliott, and Eve began to be shown in VH1's rotation and even started to crop up on VH1's top 20 countdown. VH1 also plays music from Latin artists such as Ricky Martin, Marc Anthony, Enrique Iglesias, Thala, and Shakira.\\r\\n\\r\\nrockDocs was the title under which VH1 aired various music documentaries, both those produced by VH1 and those produced by third parties. Such documentary series produced by VH1 include \\"And Ya' Don't Stop\\", a five-part series on the history of hip-hop and rap,[24] a four-part series on the history of heavy metal, Heavy: The Story of Metal, and The Drug Years, which tells the story of various drug cultures that changed America. Films produced by other studios have also been aired as rockDocs, including Woodstock, Madonna: Truth or Dare, Tupac: Resurrection, Metal: A Headbanger's Journey, Awesome; I Fuckin' Shot That!, a documentary on the Beastie Boys, and most recently Last Days of Left Eye which documented the last month of Lisa Lopes's life from the band TLC, and N.W.A.: The World's Most Dangerous Group, featuring the narration of comedian Chris Rock, which chronicled the rise and fall of N.W.A.\\r\\n\\r\\nVH1 endured criticism for Music Behind Bars, which mainly focuses on musicians in custody. Critics have claimed prisoners, mainly those convicted of murder, should not be entitled to any exposure, especially nationally.[25]\\r\\n\\r\\nThe channel aired Where Are They Now? from 1999 to 2002. It featured former celebrities and their current professional and personal status. Each episode was dedicated to a specific genre, ranging from past child stars to Aaron Spelling's notable productions, to controversial news figures.\\r\\n\\r\\nVH1 also aired a series of spots in 2003, featuring animated kittens from the online animation website Rathergood, lipsyncing popular songs such as Joan Jett's \\"I Love Rock n' Roll\\", Culture Club's \\"Karma Chameleon\\" and Guns N' Roses' \\"Welcome to the Jungle\\". These spots were done by British animator Joel Veitch.\\r\\n\\r\\nIn August 2003, the network changed its focus again, dropping \\"Music First\\" from its name, and introducing a box logo. As of January 5, 2013, the network has a new logo that closely resembles the first VH1 logo. The logo has a \\"plus\\" sign in it to represent VH1's era saying how they are about reality television, plus that they still also show some music videos in the early morning. Having saturated its Behind The Music series (and spinoff BTM2, a 30-minute version that told the stories of current chart-toppers), gotten past the point of showing music videos on a regular basis, the network began to target the pop culture nostalgia market just like its sister MTV.[2][26] The network primarily broadcasts reality television series. On the first quarter of 2016, VH1 announced it has shown the network's highest ratings in six years and it is now the fastest-growing subscription channel in that same time period. Thanks to the success of shows like Love & Hip Hop, Stevie J & Joseline Go Hollywood, K. Michelle: My Life, and Mob Wives, the channel has moved ahead as a Top Five network for adults.[27]\\r\\n\\r\\nIn 2002, VH1 broadcast a ten-part series entitled I Love the '80s. The series was adapted from a BBC series, first broadcast in 2000,[28] in which current entertainers and pop-culture figures offered their take on the trends, events, and personalities of another decade. The success of VH1's I Love the '80s, coupled with the growing nostalgia for ever-more-recent times, led the network to create a parade of similarly themed programs. These ranged from 2003's I Love the '70s, to further variants like I Love the '80s Strikes Back, I Love the '90s, and I Love the '90s: Part Deux. More recently, VH1 premiered I Love the '80s 3-D and I Love the '70s: Volume 2. So eager was the network to capitalize on the trend while it was hot, that it devoted a series to the 2000s, despite the fact that the decade had not yet ended (I Love the New Millennium, broadcast in 2008, covered only the years 2000ÿ2007). This was thought to be the final installment of the series until 2014, when I Love the 2000s continued the format.\\r\\n\\r\\nThe concept was broadened to include non-decade based installments, I Love the Holidays and I Love Toys.\\r\\n\\r\\nThe format of these shows has been repeated for the weekly program Best Week Ever. In a sketch on Fox's MADtv envisioning the, at the time, fictitious \\"I Love the 00s\\" show, VH1 was referred to as \\"the bitter comics ragging on real celebrities\\" network. On 22 June 2008, VH1 premiered I Love the New Millennium, focusing on the years 2000ÿ2007.\\r\\n\\r\\nVH1 also produces its The Greatest series in which a similar format is used to countdown lists like \\"100 Greatest Artists of Rock and Roll\\", \\"The 50 Sexiest Video Moments\\", \\"100 Greatest Songs of Rock 'N' Roll\\", \\"100 Greatest Songs from the Past 25 Years\\", \\"100 Greatest One-hit Wonders\\", and \\"100 Greatest Kid Stars\\". In 2001, Mark McGrath hosted VH1's miniseries \\"100 Most Shocking Moments in Rock 'N' Roll\\", which compiled a list of the moments in music history that changed its course and shook its foundations.[29] Recently in late December 2009, an updated series titled \\"100 Most Shocking Music Moments\\" aired on VH1.[30][31] In 2008 and early 2009, the channel premiered the \\"100 Greatest Hip-Hop Songs\\", \\"100 Greatest Hard Rock Songs\\", \\"100 Greatest Songs of the 90s\\", and \\"100 Greatest Songs of the 80s\\".\\r\\n\\r\\nIn 2004, VH1 began this mini-series category with \\"50 Most Awesomely Bad Songs...Ever\\". Additional series in this group include \\"40 Most Awesomely Bad Dirrty Songs...Ever\\",[32] \\"40 Most Awesomely Bad Break-up Songs...Ever\\",[33] \\"40 Most Awesomely Bad #1 Songs...Ever\\",[34] \\"40 Most Awesomely Bad Metal Songs...Ever\\",[35] and \\"40 Most Awesomely Bad Love Songs\\".[36]\\r\\n\\r\\nIn January 2005 VH1 launched its Celebreality programming block of reality shows featuring celebrities, anchored by The Surreal Life, which mimics MTV's The Real World, instead placing celebrities from the past into a living environment.[37]\\r\\nThe word \\"celebreality\\" is a portmanteau combining the words \\"celebrity\\" and \\"reality\\" and is generally used to describe reality TV shows in which celebrities participate as subjects. The term appears to have been coined by Michael Gross, writing for The Toronto Star on May 12, 1991. In his article, entitled \\"Celebrity's New Face,\\" Mr. Gross used a hyphenated form of the word (\\"celeb-reality\\") to describe the tendency of certain contemporary celebrities to downplay the traditional trappings of Hollywood glamour. \\"You could see the new celeb-reality on display at this year's Oscars,\\" wrote Gross. \\"It is Kathy Bates and Whoopi Goldberg, not Kim Basinger and Michelle Pfeiffer. It is Jeremy Irons in black tie and the sneakers he says keep his feet on the ground. It is Kevin Costner, fighting small, important battles, winning big, but reacting with modesty and going off to party privately. The new celebrities are human first, famous second.\\"\\r\\n\\r\\nThe next known citation of the word is by Joyce Millman, writing for The New York Times on January 5, 2003. In an article entitled, \\"Celebreality: The 'Stars' Are Elbowing Their Way In,\\" Ms. Millman wrote: \\"Celebreality, the junk genre du jour, turns the notion of reality TV upside down. Instead of real people acting like celebrities on shows like \\"Survivor\\", \\"Big Brother\\" and \\"The Bachelor\\", celebreality gives us celebrities acting like real people on shows like \\"The Osbournes\\", \\"The Anna Nicole Show\\" and \\"Celebrity Boot Camp.\\" I'm using the term \\"celebrity\\" loosely herewe're not talking about Russell Crowe, Julia Roberts and Dame Judi Dench eating bugs and scrubbing latrines. No, the celebrities of celebreality are a motlier crew, like, well, M?tley Cre's Vince Neil, the former rap superstar M. C. Hammer and the wee ex-Michael Jackson ornament Emmanuel (\\"Webster\\") Lewis. Those three will be setting up housekeeping together on Thursday in \\"The Surreal Life\\" on WB, a celebreality spin on MTV's \\"Real World.\\" Not to be outdone, ABC sends a Baldwin brother (Stephen), a supermodel (Frederique) and a former \\"L.A. Law\\" star (Corbin Bernsen) to Hawaii for \\"Celebrity Mole Hawaii\\", beginning Wednesday.\\"\\r\\n\\r\\nThe VH1 Celebreality block has also aired shows such as:\\r\\n\\r\\nFollowing the controversy over the murder-suicide of a contestant from Megan Wants a Millionaire, the channel toned down its reality programming.[38][39]\\r\\n\\r\\nSince 2004, VH1 has showed their appreciation for hip-hop and rock music by honoring pioneers and movements. Hip-hop musicians honored include Eazy-E, LL Cool J, The Notorious B.I.G., 2Pac, and Public Enemy. All of the shows have been taped in the Hammerstein Ballroom in New York City. On May 25, 2006, Queen, Judas Priest, Def Leppard, and Kiss were the inaugural inductees into the VH1 Rock Honors in Las Vegas. The ceremony aired on VH1 six days later. In 2007, ZZ Top, Heart, Genesis, and Ozzy Osbourne were inducted into the VH1 Rock Honors. 2008's sole Rock Honors inductees were The Who.\\r\\n\\r\\nFor What It's Worth premiered on February 21, 2013, and only lasted the length of one season. The show featured hosts Gary Dell'Abate and Jon Hein appraising music and pop-culture memorabilia.[40] The first episode featured musician Jack White at Third Man Records in Nashville, Tennessee, discussing a format of vinyl record he invented called the \\"Triple Decker Record\\".[41] The show also chose Gary Sohmers, an appraiser from Antiques Roadshow, to be an expert appraiser on all six episodes.[42]\\r\\n\\r\\nStarting in 2011, VH1 has broadcast Big Morning Buzz Live, a daily morning news and pop culture talk show hosted by Carrie Keagan, Jason Dundas and VH1 music expert Jim Shearer and, later, Nick Lachey.[43][44] The show features entertainment news, celebrity interviews and musical performances.[43][44] On June 3, 2013, VH1 premiered The Gossip Table, another live daily entertainment news program featuring five entertainment columnists presenting entertainment news and gossip.[43][44] Both shows have since been cancelled.\\r\\n\\r\\nOn July 1, 2007, VH1 and MHD, the high-definition music channel of MTV (now called MTV Live), simulcast live the entire Concert for Diana from London, England, on the birthday of Princess Diana, Princess of Wales.[45]\\r\\n\\r\\nAlthough VH1 has drastically reduced its emphasis on music, it does continue to play music videos (just like its sister network, MTV) from 3 a.m. until 11 a.m. ET. The overnight block was called Insomniac Music Theater until August 2005, when it was renamed Nocturnal State. As of the beginning of October 2008, Nocturnal State has been cut down to one hour, and Fresh: New Music has been supplanted by additional hours of Jump Start, thus meaning that VH1 now plays 7 hours of music daily. In 2010, VH1 retired Nocturnal State.\\r\\n\\r\\nMusic Videos continued to be branded under Jump Start until January 5, 2013 when a new logo was introduced. The name then changed to VH1 + Music and videos are primarily played between 6 a.m. to 9 a.m. Monday through Friday. Music videos continued to be branded \\"Nocturnal State\\" and videos are primarily played between 3 a.m. to 6 a.m. Monday through Sunday. However at the start of 2016, VH1 + Music was dropped for blocks of older 1990sÿ2000s sitcoms, and presently the channel only carries music video programming in continuity form between shows.\\r\\n\\r\\nFrom April 28 to May 2, 2011, from Tampa to Cozumel music fans could experience non-stop music performances from headliners Train, Lifehouse, Colbie Caillat, and The Script. Other bands include Alpha Rev, Civil Twilight, Mat Kearney, One eskimO, SafetySuit, Thriving Ivory, Trailer Park Ninjas, and Ryan Star. The cruise is on The Carnival Cruise Line ship Carnival Inspiration.\\r\\n\\r\\nVH1 HD (launched in 2005) is a 1080i high definition simulcast of VH1, with all major providers (with the exceptions of Suddenlink and Cable One, which do not carry any Viacom networks) carrying the network; as of 2016 this feed is downgraded at a provider's headend to provide the network's standard definition channel on systems.\\r\\n\\r\\nLike MTV and Nickelodeon before them, VH1 also launched spinoff digital networks as part of The Suite From MTV. Initially, four VH1 spinoff networks were formed, with another being made later on. However, as of August 2016, VH1 no longer has any spinoff networks, as all of the networks were rebranded as MTV, BET, or CMT spinoff networks, or became different networks entirely. VH1 formerly ran these channels:\\r\\n\\r\\nVH1's website, launched in the late 1990s. In 2003, MTV Networks VSPOT, a broadband video channel that followed the model of MTV Overdrive, containing the shows aired by VH1 and music videos. Like Overdrive, it was coolly received due to a heavy reliance on broadband and advanced web technologies. VH1 returned to a traditional-style website in late 2007.\\r\\n\\r\\nAs with other MTV channels, MTV Networks broadcasts international versions of VH1:","input":"What was the first music video on vh1?"},{"output":"Puritan Separatists","context":"","input":"What was the main religion of the plymouth colony?"},{"output":"Sunrise, Florida","context":"Red, Blue, Flat Gold[1][2][3]\\r\\nThe Florida Panthers are a professional ice hockey team based in the Miami metropolitan area. They are members of the Atlantic Division of the Eastern Conference of the National Hockey League (NHL). The team's local broadcasting rights has been held by Fox Sports Florida (formerly SportsChannel Florida) since 1996. The team initially played their home games at Miami Arena, before moving to the BB&T Center in 1998. Located in Sunrise, Florida, the Panthers are the southernmost team in the NHL.\\r\\nThe Panthers began playing in the 1993ÿ94 NHL season. The team has made one appearance in the Stanley Cup Finals, in 1996, the only season in which the Panthers have ever won a playoff series, eventually losing the Finals to the Colorado Avalanche. The team advanced to the Stanley Cup playoffs for the second time in 12 years in 2012,[5] but were eliminated in seven games in the Eastern Conference quarterfinals by the New Jersey Devils, who eventually won the Eastern Conference championship that season.[6]\\r\\nThe club is affiliated with one minor league team, the Springfield Thunderbirds of the American Hockey League.\\r\\n\\r\\n\\r\\nBlockbuster Video magnate Wayne Huizenga was awarded an NHL franchise for Miami on December 10, 1992,[7] the same day The Walt Disney Company earned the rights to start a team in Anaheim that would become the Mighty Ducks. At the time, Huizenga owned both the newly founded Florida Marlins of Major League Baseball and a share of the National Football League's Miami Dolphins. The entry fee was $50?million, but despite fellow Florida team Tampa Bay Lightning starting play the year before, the NHL did not consider it to be a case of territory infringement. Huizenga announced the team would play at the Miami Arena, sharing the building with the National Basketball Association's Miami Heat, until a new arena was built.[8] Offices for the team were only established in June 1993, while Vice President of Business Operations Dean Jordan conceded that \\"none of the business people, myself included, knew anything about hockey.\\"[9]\\r\\nOn April 20, 1993, a press conference in Fort Lauderdale announced that the team would be named Florida Panthers, with former New York Islanders general manager Bill Torrey as president and Bobby Clarke as general manager. The team is named for the Florida panther, an endangered species of large cat endemic to the nearby Everglades region.[10] Once the logos and uniforms were unveiled on June 15, the team also announced its financial commitment to the panther preservation cause.[11] Huizenga held the Panthers trademark since 1991, when he purchased it from a group of Tampa investors who sought to create an MLB team in the Tampa Bay area.[12]\\r\\nThe new franchise would join the NHL for participation in the 1993ÿ94 season, along with the Mighty Ducks of Anaheim. The Panthers' and Ducks' roster was filled up in both the expansion draft and the 1993 NHL Entry Draft in June 1993, hosted by Quebec City;[13][14] that draft produced ten players who would eventually be a part of the 1996 Eastern Conference-winning team.[15]\\r\\nThe Panthers' first major stars were New York Rangers goaltender castoff John Vanbiesbrouck, rookie Rob Niedermayer and forward Scott Mellanby, who scored 30 goals in Florida's inaugural season.[16] Their first game was a 4ÿ4 tie on the road against the Chicago Blackhawks, while their first win was a 2ÿ0 shutout of the Tampa Bay Lightning in the Thunderdome before a then-NHL record crowd of 27,227. The Panthers had one of the most successful first seasons of any expansion team, finishing just two points below .500 and narrowly missing out on the final 1994 playoff spot in the East.[17] Their first-year success was attributed mainly to the \\"trap defense\\" that first-year coach Roger Neilson implemented. This conservative style was widely criticized by NHL teams; some even suggested that the Panthers were ruining the game at the time.[18] While the team executives expected the audience to consist of mostly \\"snowbird\\" Canadians living in Florida, the Floridians soon embraced the Panthers.[16] Helped by Miami's other teams having middling performances, the club averaged 94% capacity at the 14,500-seat Miami Arena, and managed to sell 8,500 season tickets in 100 days.[16]\\r\\nIn August 1994, General Manager Clarke left to work for the Philadelphia Flyers, while Bryan Murray was brought in from the Detroit Red Wings as his replacement.[19] After another close brush with the playoffs, finishing the lockout-shortened 1994ÿ95 season again in ninth,[20] Neilson was fired following an argument with Murray regarding Ed Jovanovski, whom the Panthers chose as the number one overall pick at the 1994 NHL Entry Draft.[21] Doug MacLean, who had been the team's player development director, was promoted to coach.[22] The team then acquired Ray Sheppard from the San Jose Sharks at the NHL trade deadline and looked toward the playoffs for the first time.\\r\\nA very unusual goal celebration developed in Miami during the 1995ÿ96 season. On the night of the Panthers' 1995ÿ96 home opener, a rat scurried across the team's locker room. Scott Mellanby reacted by \\"one-timing\\" the rat against the wall, killing it. That night, he scored two goals, which Vanbiesbrouck quipped was \\"a rat trick.\\" Two nights later, as the story found its way into the world, a few fans threw rubber rats on the ice in celebration of a goal. The rubber rat count went from 16 for the third home game to over 2,000 during the playoffs.[15]\\r\\nIn the 1996 playoffs, as the fourth seed in the East, the Panthers faced the Boston Bruins in the first round and won in five games. Bill Lindsay's famous series-clinching goal is still a trademark image for the incredible run the third-year franchise went on. The Panthers went on to upset the top-seeded Philadelphia Flyers in six games followed by the second-seeded Pittsburgh Penguins in seven (with Tom Fitzgerald scoring what would end up being the game-winning goal) to reach the Stanley Cup Finals against the Colorado Avalanche, another team making its first Finals appearance.[15] The Avalanche, however, swept the Panthers in four-straight games.[23] For his team's surprising success, Bryan Murray was honored as NHL Executive of the Year.[24]\\r\\nThe Panthers would begin the next season with a 12ÿgame unbeaten streak but faded in the second half of the season after trading second line center Stu Barnes. They lost in the first round of the playoffs to the Wayne Gretzky-led New York Rangers in five games. The team would plummet in the 1997ÿ98 season. After a 7ÿ12ÿ4 start, the Panthers fired Doug MacLean, replacing him for the season with General Manager Bryan Murray. The change did not aid matters, however, as Florida posted a franchise-worst 24ÿ43ÿ15 record, including a 15ÿgame winless streak. This season would also mark the end of goaltender John Vanbiesbrouck's time in Florida; in the midst of that streak, he was shelled by the Chicago Blackhawks and never played another game for the Panthers. He would later sign with the Flyers that off-season as a free agent.\\r\\nThe Panthers moved into the brand new National Car Rental Center (later Office Depot and BankAtlantic Center, now known as BB&T Center) in 1998. In 1998ÿ99, they acquired Pavel Bure (the \\"Russian Rocket\\"), in a blockbuster trade with the Vancouver Canucks. They then reached the playoffs again in 1999ÿ2000, losing in a first-round sweep to the eventual Stanley Cup champion New Jersey Devils. The team slumped in 2000ÿ01. Afterward, Huizenga sold the Panthers to an ownership group led by Alan Cohen.[25] The following season, 2001ÿ02, the Panthers had their worst record ever. Bure struggled despite being reunited with his brother Valeri, and was traded to the Rangers at the 2002 trade deadline.\\r\\nThe Panthers then began eyeing defenceman Jay Bouwmeester, who was widely tipped to be picked first overall pick at the 2002 Draft. However, then-General Manager Rick Dudley sent Florida's first pick to the Columbus Blue Jackets, who selected winger Rick Nash, and in return the Panthers received the right to trade first round selections with the Blue Jackets in the 2003 Draft,[26] a right which was not exercised when the Panthers received the first overall selection in 2003 as well. The Atlanta Thrashers, after picking goaltender Kari Lehtonen second overall, announced that the Panthers had given them two draft picks to guarantee that Bouwmeester would still be available for Florida's selection. Bouwmeester was selected third overall by the Panthers. Said then-Head Coach Mike Keenan, \\"We shouldn't have done that?... Jay would have been number-one if we'd kept that pick.\\"[27]\\r\\nIn 2003, the Panthers hosted the NHL All-Star Weekend in which the Western Conference earned a 6ÿ5 victory after the first overtime shootout in All-Star history. The West overcame a four-goal outburst by Thrashers winger Dany Heatley, who took home MVP honors in his first All-Star appearance.\\r\\nOn June 23, 2006, the Panthers were again involved in a blockbuster trade with Vancouver, sending Roberto Luongo, Lukas Krajicek and a sixth-round draft pick (Sergei Shirokov) in exchange for Todd Bertuzzi, Alex Auld and Bryan Allen. This trade has been regarded by some as one of the worst trades in professional sports history ÿ Luongo, who was at the prime of his career, was one of the League's top goaltenders, while Bertuzzi played just a handful of games for Florida before getting injured. He would later be traded to Detroit Red Wings at the trade deadline for Shawn Matthias. Additionally, Auld ended up a poor replacement for Luongo, and was ultimately let go after one season with the team.\\r\\nOn June 22, 2007, the Panthers were involved in yet another draft day deal involving a goaltender. The team acquired Tomas Vokoun from the Nashville Predators in exchange for three draft picks ÿ a first-round pick in 2008, a second-round pick in 2008 and a conditional second round pick that can be used in 2007 or 2008. The move would eventually pay off when Vokoun was selected to the Eastern Conference All-Star Team. On July 28, 2007, Florida unveiled their new jerseys to over 11,000 fans at the BankAtlantic Center during the first intermission of the Panthers' 1996 Reunion game. Star forwards Nathan Horton and Stephen Weiss were both in full gear to help showcase the sweater changes.\\r\\nIn June 2008, the Panthers traded their captain Olli Jokinen to the Phoenix Coyotes for a second-round draft pick and defensemen Keith Ballard and Nick Boynton. The Panthers finished the 2008ÿ09 season with a strong 41ÿ30ÿ11 record and 93 points, their second-highest finish in franchise history. Despite this, however, the Panthers missed the playoffs for an eighth-straight season, the then-longest streak in the NHL.\\r\\nIn November 2009, Cliff Viner and Stu Siegel became the new majority owners.[28] On November 23, 2009 the Panthers made their third jersey, ridding red from the alternate jersey, replacing it with powder blue. The Panthers missed the playoffs for the ninth consecutive time in the 2009ÿ10 season, making them the first team in NHL history to do so in one city.\\r\\nPanthers management hired Dale Tallon as the team's new general manager on May 17, 2010. Tallon rebuilt the team with 2010 draft picks Erik Gudbranson, Nick Bjugstad and Quinton Howden, as well as the acquisition of players, including Steve Bernier, Michael Grabner, Marty Reasoner, Ryan Carter and Sergei Samsonov. All of the above-mentioned players, however, were traded at the 2011 trade deadline or released during the 2011 off-season, save for Gudbranson, Bjugstad and Howden. At the end of the 2010ÿ11 season, just Stephen Weiss and David Booth remained from the pre-lockout era Panthers roster.\\r\\nOn June 1, 2011, Kevin Dineen, head coach of the American Hockey League (AHL)'s Portland Pirates, was named to be the 11th head coach of the Panthers. The team also rebranded their image, releasing a new home jersey, predominantly red with navy blue sleeves, and eliminating the navy blue piping on the road jersey; this new jersey replaced the navy blue one as the main home jersey. The 2011 off-season saw the acquisitions of Scottie Upshall, Tomas Fleischmann, Sean Bergenheim, Marcel Goc, Matt Bradley, Ed Jovanovski, Jose Theodore, Kris Versteeg, Tomas Kopecky and Brian Campbell.\\r\\nAfter several more trades and over 300-man-games lost to injury throughout the season, the Panthers were able to finish first in the Southeast Division, marking the end of their record-setting decade-long post-season drought. The Panthers won the first-ever division title in franchise history with a 4ÿ1 victory over the Carolina Hurricanes on April 7, 2012. However, the Panthers were eliminated in the first round of the playoffs by the eventual Eastern Conference champion New Jersey Devils, losing at home in double overtime of Game 7.\\r\\nIn the lockout-shortened 2013 season, the Panthers had an abysmal season. Unable to regain their form from last season, the Panthers suffered key injuries and fell back down into the basement with the worst record in the League. In the 2013ÿ14 season, the Panthers failed to gain any momentum and finished 29th out of 30 teams. The team then fired head coach Kevin Dineen and replaced him with Peter Horachek. At the trade deadline, the Panthers reacquired Roberto Luongo from Vancouver. The Panthers would relieve Horachek of his duties at the end of the season, replacing him with former Columbus Blue Jackets head coach Gerard Gallant. The team also received the first overall pick in the 2014 NHL Entry Draft, using it to select Barrie Colts defenseman Aaron Ekblad.\\r\\nThe Panthers' 2014ÿ15 home opener on October 12, 2014, set a team record for the lowest attendance at a home opener, with only 11,419 spectators in attendance. The team's next game against the Ottawa Senators marked the team's lowest attendance ever, with only 7,311 in attendance.[29] Despite finishing with a record of 38ÿ29ÿ15, the Panthers missed the 2015 playoffs by seven points. On December 8, 2015, the Panthers announced that they signed a 13-year lease, and an $86 million funding agreement with Broward County and would have a new logo and uniforms after the 2015ÿ16 season. Their original logo had remained almost unchanged since their first season in 1993.[30][31]\\r\\nIn the 2015ÿ16 season, the team set a franchise record with a 12-game win streak. They also set a franchise record for most wins in a regular season with 47 wins and won their division for the second time in their existence. However, the Panthers lost to the New York Islanders in six games in the first round of the playoffs. Head coach Gerard Gallant was nominated as a finalist for the Jack Adams Award for NHL's coach of the year.\\r\\nThe 2016ÿ17 season season began with the promotion of General Manager Dale Tallon to an executive position within the organization and assistant GM Tom Rowe was promoted to general manager.[32] After an 11ÿ10ÿ1 start to the season, the Panthers fired head coach Gerard Gallant and GM Tom Rowe took over as interim head coach.[33] At the end of the season, Rowe was relieved of his duties as both coach and GM and was named special advisor to Tallon, who returned to positions of team president and general manager.[34] On June 12, 2017, the Panthers named Bob Boughner as their new head coach.[35]\\r\\nThis is a partial list of the last five seasons completed by the Panthers. For the full season-by-season history, see List of Florida Panthers seasons.\\r\\nNote: GP = Games played, W = Wins, L = Losses, T = Ties, OTL = Overtime Losses, Pts = Points, GF = Goals for, GA = Goals against\\r\\nRecords as of the end of the 2010ÿ11 season.\\r\\nUpdated February 25, 2018[36][37]\\r\\n\\r\\nSee List of Florida Panthers head coaches.\\r\\nSee List of Florida Panthers general managers.\\r\\nThese are the top-ten-point-scorers in franchise history. Figures are updated after each completed NHL regular season.\\r\\nNote: Pos = Position; GP = Games Played; G = Goals; A = Assists; Pts = Points; P/G = Points per game\\r\\nPrince of Wales Trophy\\r\\nMaurice \\"Rocket\\" Richard Trophy\\r\\nLady Byng Memorial Trophy\\r\\nCalder Memorial Trophy\\r\\nBill Masterton Memorial Trophy","input":"Where is the florida panthers hockey team located?"},{"output":"David Shulkin","context":"The United States Secretary of Veterans Affairs is the head of the U.S. Department of Veterans Affairs, the department concerned with veterans' benefits, health care, and national veterans' memorials and cemeteries. The Secretary is a member of the Cabinet and second to last at sixteenth in the line of succession to the presidency (the position was last until the addition of the United States Department of Homeland Security in 2006[2]). Until the appointment of David Shulkin in 2017, all appointees and acting appointees to the post were United States military veterans, but that is not a requirement to fill the position.\\r\\nWhen the post of Secretary is vacant, the United States Deputy Secretary of Veterans Affairs[3] or any other person designated by the President serves as Acting Secretary[3] until the President nominates and the United States Senate confirms a new Secretary.\\r\\n\\r\\n\\r\\n\\r\\n??No party (2) ??Democratic (2) ??Republican (5)\\r\\n1 Anthony Principi served as acting secretary in his capacity as Deputy Secretary of Veterans Affairs September 26, 1992January 20, 1993.\\r\\n2 Hershel W. Gober served as acting secretary in his capacity as Deputy Secretary of Veterans Affairs July 1, 1997January 2, 1998 and July 25, 2000January 20, 2001.[4]\\r\\n3 West served as acting Secretary from January 2, 1998[5] to May 5, 1998.[6]\\r\\n4 Gordon H. Mansfield served as acting secretary in his capacity as Deputy Secretary of Veterans Affairs October 1December 20, 2007.[7]\\r\\nAs of October 2017, there are six living former Secretaries of Veterans Affairs, the oldest being Jim Nicholson (served 2005-2007, born 1938). The most recent Secretary of Veterans Affairs to die was Ed Derwinski (served 1989-1992, born 1926), on January 15, 2012. The most recently serving Secretary to die was Jesse Brown (served 1993-1997, born 1944) on August 15, 2002.","input":"Who is the head of the veterans administration?"},{"output":"\\"Scream\\"","context":"This page lists the most expensive music videos ever made, with costs of US$500,000 or more. David Bowie's video for the 1980 single \\"Ashes to Ashes\\" was the first music video to exceed this sum. Janet Jackson leads with six videos on the list, while Michael Jackson, Britney Spears, and Ayumi Hamasaki have five each. Ayumi Hamasaki, T-ara, 2NE1 and B.A.P are also the only Asian artists to appear on this list. Madonna has made three appearances in the top 5, and four total, making her the artist with the most expensive videos of all time put together. Mylne Farmer has made 3 appearances. TLC, Kanye West, Busta Rhymes, Guns N' Roses, and MC Hammer appear on the list twice. Joseph Kahn has directed four videos on this list while Hype Williams, Cha Eun Taek, and Wataru Takeishi have directed three videos on the list. Nigel Dick, Mark Romanek and John Landis appear twice on this list, the latter with videos both directed for Michael Jackson. This list only includes music videos with an announced or reported budget.\\r\\nMark Romanek, the director of Michael and Janet Jackson's \\"Scream\\", which is claimed to be the most expensive music video ever made, has since denied this claim saying that there were two other music videos from the same era which cost \\"millions more\\" than the video for \\"Scream\\".[1] In a 2017 interview, Mick Garris a writer for Michael Jackson's Ghosts stated that after several years of production development for the Ghosts short film \\"it became the most expensive music video ever made...it ended up coming in at about $15 million dollars, all of it out of Michaels pocket\\".[2]","input":"What was the most expensive music video of all time?"},{"output":"late nineteenth century","context":"The idea of the Panama canal dates back to the 1513 discovery of the isthmus by Vasco N~?ez de Balboa. The narrow land bridge between North and South America houses the Panama Canal, a water passage between the Atlantic and Pacific Oceans. The earliest European colonists recognized this potential, and several proposals for a canal were made.[1]\\r\\nBy the late nineteenth century, technological advances and commercial pressure allowed construction to begin in earnest. Noted canal engineer Ferdinand de Lesseps led an initial attempt by France to build a sea-level canal. Beset by cost overruns due to the severe underestimation of the difficulties in excavating the rugged Panama land, heavy personnel losses in Panama due to tropical diseases, and political corruption in France surrounding the financing of the massive project, the project succeeded in only partially completing the canal.\\r\\nInterest in a U.S.-led canal effort picked up as soon as France abandoned the project. Initially, the Panama site was politically unfavorable in the U.S. for a variety of reasons, including the taint of the failed French efforts and the Colombian government's unfriendly attitude towards the U.S. continuing the project. The U.S. first sought to construct a completely new canal through Nicaragua instead.\\r\\nFrench engineer and financier Philippe-Jean Bunau-Varilla played a key role in changing U.S. attitudes. Bunau-Varilla had a large stake in the failed French canal company, and stood to make money on his investment only if the Panama Canal was completed. Extensive lobbying of U.S. lawmakers coupled with his support of a nascent independence movement among the Panamanian people led to a simultaneous revolution in Panama and the negotiation of the HayÿBunau-Varilla Treaty which secured both independence for Panama and the right for the U.S. to lead a renewed effort to construct the canal. Colombia's response to the Panamanian independence movement was tempered by U.S. military presence; the move is often cited as a classic example of the era of gunboat diplomacy.\\r\\nU.S. success hinged on two factors. First was converting the original French sea-level plan to a more realistic lock-controlled canal. The second was controlling disease which decimated workers and management alike under the original French attempt. Initial chief engineer John Frank Stevens built much of the infrastructure necessary for later construction; slow progress on the canal itself led to his replacement by George Washington Goethals. Goethals oversaw the bulk of the excavation of the canal, including appointing Major David du Bose Gaillard to oversee the most daunting project, the Culebra Cut through the roughest terrain on the route. Almost as important as the engineering advances was the healthcare advances made during the construction, led by William C. Gorgas, an expert in controlling tropical diseases such as yellow fever and malaria. Gorgas was one of the first to recognize the role of mosquitoes in the spread of these diseases, and by focusing on controlling the mosquitoes greatly improved worker conditions.\\r\\nOn 7 January 1914 the French crane boat Alexandre La Valley became the first to make the traverse, and on 1 April 1914 the construction was officially completed with the hand-over of the project from the construction company to the Canal Zone government. The outbreak of World War I caused the cancellation of any official \\"grand opening\\" celebration, and the canal officially opened to commercial traffic on 15 August 1914 with the transit of the SS Ancon.\\r\\nDuring World War II, the canal proved a vital part of the U.S. military strategy, allowing ships to transfer easily between the Atlantic and Pacific. Politically, the Canal remained a territory of the United States until 1977, when the TorrijosÿCarter Treaties began the process of transferring territorial control of the Panama Canal Zone to Panama, a process completed on 31 December 1999.\\r\\nThe Panama Canal continues to be a viable commercial venture and a vital link in world shipping, and continues to be periodically updated and maintained. The Panama Canal expansion project started construction in 2007 and began commercial operation on 26 June 2016. The new locks allow transit of larger Post-Panamax and New Panamax ships, which have a greater cargo capacity than the original locks could accommodate.[2]\\r\\n\\r\\n\\r\\nThe idea of a canal across Central America was revived during the early 19th century. In 1819, the Spanish government authorized the construction of a canal and the creation of a company to build it.\\r\\nAlthough the project stalled for some time, a number of surveys were made between 1850 and 1875. They indicated that the two most-favorable routes were across Panama (then part of Colombia) and Nicaragua, with a third route across the Isthmus of Tehuantepec in Mexico another option. The Nicaraguan route was surveyed.\\r\\nAfter the 1869 completion of the Suez Canal, France thought that an apparently-similar project to connect the Atlantic and Pacific Oceans could be carried out with little difficulty. In 1876 an international company, La Socit internationale du Canal interocanique, was created to undertake its construction; two years later, it obtained a concession from the Colombian government (since Panama was a Colombian province) to dig a canal across the isthmus.\\r\\nFerdinand de Lesseps, who was in charge of the Suez Canal construction, headed the project. His enthusiastic leadership and his reputation as the man who had built the Suez Canal persuaded speculators and ordinary citizens to invest nearly $400?million in the project.\\r\\nHowever, despite his previous success de Lesseps was not an engineer. The Suez Canal, essentially a ditch dug through a flat, sandy desert, presented few challenges. Although Central America's mountainous spine has a low point in Panama, it is still 110 meters (360.9?ft) above sea level at its lowest crossing point. The sea-level canal proposed by de Lesseps would require a great deal of excavation through a variety of rock, rather than Suez' sand.\\r\\nLess-obvious barriers were the rivers crossing the canal, particularly the Chagres (which flows strongly during the rainy season). Since the water would be a hazard to shipping if it drained into the canal, a sea-level canal would require the river's diversion.\\r\\nThe most serious problem was tropical disease, particularly malaria and yellow fever, whose methods of transmission were unknown at the time. The legs of hospital beds were placed in cans of water to keep insects from crawling up them, but the stagnant water was an ideal breeding place for mosquitoes (carriers of the diseases).\\r\\nThe project was plagued by a lack of engineering expertise. In May 1879, an international engineering congress led by de Lesseps convened in Paris. Of its 136 delegates, only 42 were engineers; the others were speculators, politicians and friends of de Lesseps.\\r\\nHe was convinced that a sea-level canal, dug through the mountainous spine of Central America, could be completed at least as easily as the Suez Canal. The engineering congress estimated the project's cost at $214 million; on February 14, 1880, an engineering commission revised the estimate to $168.6 million. De Lesseps reduced this estimate twice, with no apparent justification: on February 20 to $131.6 million and on March 1 to $120 million. The congress estimated seven or eight years as the time required to complete the canal; de Lesseps reduced this estimate to six years (the Suez Canal required ten).\\r\\nThe proposed sea-level canal would have a uniform depth of 9 meters (29.5?ft), a bottom width of 22 meters (72.2?ft) and a width at water level of about 27.5 meters (90.2?ft); the excavation estimate was 120,000,000?m3 (157,000,000?cu?yd). A dam was proposed at Gamboa to control flooding of the Chagres River, with channels to drain water away from the canal. However, the Gamboa dam was later found impracticable and the Chagres River problem was left unsolved.\\r\\nConstruction of the canal began on January 1, 1881, with digging at Culebra beginning on January 22.[1] A large labor force was assembled, numbering about 40,000 in 1888 (nine-tenths of whom were afro-Caribbean workers from the West Indies). Although the project attracted good, well-paid French engineers, retaining them was difficult due to disease. The death toll from 1881 to 1889 was estimated at over 22,000, of whom as many as 5,000 were French citizens.[3]\\r\\nBy 1885 it had become clear to many that a sea-level canal was impractical, and an elevated canal with locks was preferable; de Lesseps resisted, and a lock canal plan was not adopted until October 1887. By this time increasing mortality rates, as well as financial and engineering problems coupled with frequent floods and mudslides, indicated that the project was in serious trouble. Work continued under the new plan until May 15, 1889, when the company went bankrupt and the project was suspended. After eight years the canal was about two-fifths completed, and about $234.8 million had been spent.\\r\\nThe company's collapse was a scandal in France, and the antisemitic Edouard Drumont exploited the role of two Jewish speculators in the affair. One hundred four legislators were found to have been involved in the corruption, and Jean Jaurs was commissioned by the French parliament to conduct an inquiry which was completed in 1893.[2]\\r\\nIt soon became clear that the only way to recoup expenses for the stockholders was to continue the project. A new concession was obtained from Colombia, and in 1894 the Compagnie Nouvelle du Canal de Panama was created to finish the canal. To comply with the terms of the contract, work began immediately on the Culebra excavation while a team of engineers began a comprehensive study of the project. They eventually settled on a plan for a two-level, lock-based canal.\\r\\nThe new effort never gained traction, mainly because of US speculation that a canal through Nicaragua would render one through Panama useless. The most men employed on the new project was 3,600 (in 1896), primarily to comply with the terms of the concession and to maintain the existing excavation and equipment in saleable condition. The company had already begun looking for a buyer, with an asking price of $109 million.\\r\\nIn the US, a congressional Isthmian Canal Commission was established in 1899 to examine possibilities for a Central American canal and recommend a route. In November 1901, the commission reported that a US canal should be built through Nicaragua unless the French were willing to sell their holdings for $40 million. The recommendation became law on June 28, 1902, and the New Panama Canal Company was compelled to sell at that price.[3]\\r\\nAlthough the French effort was, to a large extent, doomed to failure from the beginning due to disease and a lack of understanding of the engineering difficulties, it was not entirely futile. The old and new companies excavated 59,747,638?m3 (78,146,960?cu?yd) of material, of which 14,255,890?m3 (18,646,000?cu?yd) was taken from the Culebra Cut. The old company dredged a channel from Panama Bay to the port at Balboa, and the channel dredged on the Atlantic side (known as the French canal) was useful for bringing in sand and stone for the locks and spillway concrete at Gat~n.\\r\\nDetailed surveys and studies (particularly those carried out by the new canal company) and machinery, including railroad equipment and vehicles, aided the later American effort. The French lowered the summit of the Culebra Cut along the canal route by five meters (17?ft), from 64 to 59 metres (210 to 194?ft). An estimated 22,713,396?m3 (29,708,000?cu?yd) of excavation, valued at about $25.4 million, and equipment and surveys valued at about $17.4 million were usable by the Americans.[citation needed]\\r\\nThe 1848 discovery of gold in California and the rush of would-be miners stimulated US interest in building a canal between the oceans. In 1887, a United States Army Corps of Engineers regiment surveyed canal possibilities in Nicaragua. Two years later, the Maritime Canal Company was asked to begin a canal in the area and chose Nicaragua. The company lost money in the panic of 1893, and its work in Nicaragua ceased. In 1897 and 1899, the United States Congress charged a canal commission with researching possible construction; Nicaragua was chosen as the location both times.\\r\\nAlthough the Nicaraguan canal proposal was made redundant by the American takeover of the French Panama Canal project, increases in shipping volume and ship sizes have revived interest in the project. A canal across Nicaragua accommodating post-Panamax ships or a rail link carrying containers between ports on either coast have been proposed.[citation needed]\\r\\nTheodore Roosevelt believed that a US-controlled canal across Central America was a vital strategic interest of the country. This idea gained wide circulation after the destruction of the USS Maine in Cuba on February 15, 1898. Reversing a Walker Commission decision in favor of a Nicaraguan canal, Roosevelt encouraged the acquisition of the French Panama Canal effort. George S. Morison was the only commission member who argued for the Panama location. The purchase of the French-held land for $40?million was authorized by the June 28, 1902 Spooner Act. Since Panama was then part of Colombia, Roosevelt began negotiating with that country to obtain the necessary rights. In early 1903 the HayÿHerrn Treaty was signed by both nations, but the Senate of Colombia failed to ratify the treaty.\\r\\nRoosevelt implied to Panamanian rebels that if they revolted, the US Navy would assist their fight for independence. Panama declared its independence on November 3, 1903, and the USS Nashville impeded Colombian interference. The victorious Panamanians gave the United States control of the Panama Canal Zone on February 23, 1904, for $10?million in accordance with the November 18, 1903 HayÿBunau-Varilla Treaty.\\r\\nThe United States took control of the French property connected to the canal on May 4, 1904, when Lieutenant Jatara Oneel of the United States Army was presented with the keys during a small ceremony.[citation needed] The new Panama Canal Zone Control was overseen by the Isthmian Canal Commission (ICC) during construction.\\r\\nThe first step taken by the US government was to place all the canal workers under the new administration. The operation was maintained at minimum strength to comply with the canal concession and keep the machinery in working order. The US inherited a small workforce and an assortment of buildings, infrastructure and equipment, much of which had been neglected for fifteen years in the humid jungle environment. There were no facilities in place for a large workforce, and the infrastructure was crumbling.\\r\\nCataloguing assets was a large job; it took many weeks to card-index available equipment. About 2,150 buildings had been acquired,[4] many of which were uninhabitable; housing was an early problem, and the Panama Railway was in a state of decay. However, much equipment (such as locomotives, dredges and other floating equipment) was still serviceable.\\r\\nAlthough chief engineer John Findley Wallace was pressured to resume construction, red tape from Washington stifled his efforts to obtain heavy equipment and caused friction between Wallace and the ICC. He and chief sanitary officer William C. Gorgas were frustrated by delay, and Wallace resigned in 1905. He was replaced by John Frank Stevens, who arrived on July 26, 1905. Stevens quickly realized that serious investment in infrastructure was necessary and determined to upgrade the railway, improve sanitation in Panama City and Col܇n, renovate the old French buildings and build hundreds of new ones for housing. He then began the difficult task of recruiting the large labor force required for construction. Stevens' approach was to press ahead first and obtain approval later. He improved drilling and dirt-removal equipment at the Culebra Cut for greater efficiency, revising the inadequate provisions in place for soil disposal.\\r\\nNo decision had been made about whether the canal should be a lock or a sea-level one; the ongoing excavation would be useful in either case. In late 1905, President Roosevelt sent a team of engineers to Panama to investigate the relative merits of both types in cost and time. Although the engineers voted eight to five in favor of a sea-level canal, Stevens and the ICC opposed the plan; Stevens' report to Roosevelt was instrumental in convincing the president of the merits of a lock canal and Congress concurred. In November 1906 Roosevelt visited Panama to inspect the canal's progress, the first trip outside the United States by a sitting president.\\r\\nWhether contract employees or government workers would build the canal was controversial. Bids for the canal's construction were opened in January 1907, and Knoxville, Tennessee-based contractor William J. Oliver was the low bidder. Stevens disliked Oliver, and vehemently opposed his choice. Although Roosevelt initially favored the use of a contractor, he eventually decided that army engineers should carry out the work[4] and appointed Major George Washington Goethals as chief engineer (under Stevens' direction) in February 1907. Stevens, frustrated by government inaction and the army involvement, resigned and was replaced by Goethals.[5]\\r\\nThe US relied on a stratified workforce to build the canal. High-level engineering jobs, clerical positions, skilled labor and jobs in supporting industries were generally reserved for white Americans, with manual labor primarily by cheap immigrant labor. These jobs were initially filled by Europeans, primarily from Spain, Italy and Greece, many of whom were radical and militant due to political turmoil in Europe. The US then decided to recruit primarily from the British and French West Indies, and these workers provided most of the manual labor on the canal.[6]\\r\\nThe Canal Zone originally had minimal facilities for entertainment and relaxation for the canal workers apart from saloons; as a result, alcohol abuse was a great problem. The inhospitable conditions resulted in many American workers returning home each year.\\r\\nA program of improvements was implemented. Clubhouses were built, managed by the YMCA, with billiard, assembly and reading rooms, bowling alleys, darkrooms for camera clubs, gymnastic equipment, ice cream parlors, soda fountains and a circulating library. Member dues were ten dollars a year, with the remaining upkeep (about $7,000 at the larger clubhouses) paid by the ICC. The commission built baseball fields and arranged rail transportation to games; a competitive league soon developed. Semimonthly Saturday-night dances were held at the Hotel Tivoli, which had a spacious ballroom.\\r\\nThese measures influenced life in the Canal Zone; alcohol abuse fell, with saloon business declining by 60 percent.[citation needed] The number of workers leaving the project each year dropped significantly.\\r\\nThe work done thus far was preparation, rather than construction. By the time Goethals took over, the construction infrastructure had been created or overhauled and expanded from the French effort and he was soon able to begin construction in earnest.\\r\\nGoethals divided the project into three divisions: Atlantic, Central and Pacific. The Atlantic Division, under Major William L. Sibert, was responsible for construction of the breakwater at the entrance to Limon Bay, the Gat~n locks and their 5.6?km (3.5?mi) approach channel, and the Gatun Dam. The Pacific Division (under Sydney B. Williamson, the only civilian division head) was responsible for the Pacific entrance to the canal, including a 4.8?km (3.0?mi) breakwater in Panama Bay, the approach channel, and the Miraflores and Pedro Miguel locks and their associated dams. The Central Division, under Major David du Bose Gaillard, was responsible for everything in between. It had arguably the project's greatest challenge: excavating the Culebra Cut (known as the Gaillard Cut from 1915 to 2000), which involved cutting 8 miles (13?km) through the continental divide down to 12 meters (40?ft) above sea level.\\r\\nBy August 1907, 765,000 m3 (1,000,000 cubic yards) per month was being excavated; this set a record for the rainy season; soon afterwards this doubled, before increasing again. At the peak of production, 2,300,000 m3 (3,000,000 cubic yards) were being excavated per month (the equivalent of digging a Channel Tunnel every 3? months).[citation needed]\\r\\nOne of the greatest barriers to a canal was the continental divide, which originally rose to 110 metres (360.9?ft) above sea level at its highest point. The effort to cut through this barrier of rock was one of the greatest challenges faced by the project.\\r\\nGoethals arrived at the canal with Major David du Bose Gaillard of the US Army Corps of Engineers. Gaillard was placed in charge of the canal's Central Division, which stretched from the Pedro Miguel locks to the Gatun Dam, and dedicated himself to getting the Culebra Cut (as it was then known) excavated.\\r\\nThe scale of the work was massive. Six thousand men worked in the cut, drilling holes in which a total of 27,000?t (60,000,000?lb) of dynamite were placed to break up the rock (which was then removed by as many as 160 trains per day). Landslides were frequent, due to the oxidation and weakening of the rock's underlying iron strata. Although the scale of the job and the frequent, unpredictable slides generated chaos, Gaillard provided quiet, clear-sighted leadership.\\r\\nOn May 20, 1913, Bucyrus steam shovels made a passage through the Culebra Cut at the level of the canal bottom. The French effort had reduced the summit to 59 metres (193.6?ft) over a relatively narrow width; the Americans had lowered this to 12 metres (39.4?ft) above sea level over a greater width, and had excavated over 76,000,000?m3 (99,000,000?cu?yd) of material. About 23,000,000?m3 (30,000,000?cu?yd) of this material in addition to the planned excavation, in the form of landslides. Dry excavation ended on September 10, 1913; a January slide had added 1,500,000?m3 (2,000,000?cu?yd) of earth, but it was decided that this loose material would be removed by dredging when the cut was flooded.\\r\\nTwo artificial lakes are key parts of the canal: Gatun and Miraflores Lakes. Four dams were constructed to create them. Two small dams at Miraflores impound Miraflores Lake, and a dam at Pedro Miguel encloses the south end of the Culebra Cut (essentially an arm of Lake Gatun). The Gatun Dam is the main dam blocking the original course of the Chagres River, creating Gatun Lake.\\r\\nThe Miraflores dams are an 825-metre (2,707?ft) earth dam connecting the Miraflores Locks in the west and a 150-metre (492?ft) concrete spillway dam east of the locks. The concrete dam has eight floodgates, similar to those on the Gatun spillway. The earthen, 430-metre (1,411?ft) Pedro Miguel dam extends from a hill in the west to the lock. Its face is protected by rock riprap at the water level. The largest and most challenging of the dams is the Gatun Dam. This earthen dam, 640 metres (2,100?ft) thick at the base and 2,300 metres (7,546?ft) long along the top, was the largest of its kind in the world when the canal opened.[citation needed]\\r\\nBuilding the locks began with the first concrete laid at Gatun on August 24, 1909. The Gatun locks are built into a cutting into a hill bordering the lake, requiring the excavation of 3,800,000?m3 (4,970,212?cu?yd) of material (mostly rock). The locks were made of 1,564,400?m3 (2,046,158?cu?yd) of concrete, with an extensive system of electric railways and cable cars transporting concrete to the lock-construction sites.\\r\\nThe Pacific-side locks were finished first: the single flight at Pedro Miguel in 1911, and Miraflores in May 1913. The seagoing tugboat Gatun, an Atlantic-entrance tug used to haul barges, traversed the Gatun locks on September 26, 1913. The trip was successful, although the valves were controlled manually; the central control board was not yet ready.\\r\\nOn October 10, 1913, the dike at Gamboa which had kept the Culebra Cut isolated from Gatun Lake was demolished; the detonation was made telegraphically by President Woodrow Wilson in Washington. On January 7, 1914, the Alexandre La Valley, an old French crane boat, became the first ship to make a complete transit of the Panama Canal under its own steam after working its way across during the final stages of construction.\\r\\nAs construction wound down, the canal team began to disperse. Thousands of workers were laid off, and entire towns were disassembled or demolished. Chief sanitary officer William C. Gorgas, who left to fight pneumonia in the South African gold mines, became surgeon general of the Army. On April 1, 1914 the Isthmian Canal Commission disbanded, and the zone was governed by a Canal Zone Governor; the first governor was George Washington Goethals.\\r\\nAlthough a large celebration was planned for the canal's opening, the outbreak of World War I forced the cancellation of the main festivities and it became a modest local affair. The Panama Railway steamship SS?Ancon, piloted by Captain John A. Constantine (the canal's first pilot), made the first official transit on August 15, 1914. With no international dignitaries in attendance, Goethals followed the Ancon's progress by railroad.\\r\\nThe canal was a technological marvel and an important strategic and economic asset to the US. It changed world shipping patterns, removing the need for ships to navigate the Drake Passage and Cape Horn. The canal saves a total of about 7,800 miles (12,600?km) on a sea trip from New York to San Francisco.\\r\\nIts anticipated military significance of the canal was proven during World War II, when the canal helped restore the devastated United States Pacific Fleet.[7] Some of the largest ships the United States had to send through the canal were aircraft carriers, particularly Essex class; they were so large that although the locks could accommodate them, the lampposts along the canal had to be removed.\\r\\nThe Panama Canal cost the United States about $375 million, including $10 million paid to Panama and $40 million paid to the French company. Although it was the most expensive construction project in US history to that time, it cost about $23 million less than the 1907 estimate despite landslides and an increase in the canal's width. An additional $12 million was spent on fortifications.\\r\\nA total of over 75,000 people worked on the project; at the peak of construction, there were 40,000 workers. According to hospital records, 5,609 workers died from disease and accidents during the American construction era.[citation needed]\\r\\nA total of 182,610,550?m3 (238,845,582?cu?yd) of material was excavated in the American effort, including the approach channels at the canal ends. Adding the work by the French, the total excavation was about 204,900,000?m3 (268,000,000?cu?yd) (over 25 times the volume excavated in the Channel Tunnel project).[citation needed]\\r\\nOf the three presidents whose terms spanned the construction period, Theodore Roosevelt is most associated with the canal and Woodrow Wilson presided over its opening. However, William Howard Taft may have given the canal its greatest impetus for the longest time. Taft visited Panama five times as Roosevelt's secretary of war and twice as president. He hired John Stevens and later recommended Goethals as Stevens' replacement. Taft became president in 1909, when the canal was half finished, and was in office for most of the remainder of the work. However, Goethals later wrote: \\"The real builder of the Panama Canal was Theodore Roosevelt\\".[citation needed]\\r\\nThe following words by Roosevelt are displayed in the rotunda of the canal's administration building in Balboa:[citation needed]\\r\\nIt is not the critic who counts, not the man who points out how the strong man stumbled, or where the doer of deeds could have done them better. The credit belongs to the man who is actually in the arena; whose face is marred by dust and sweat and blood; who strives valiantly, who errs and comes short again and again; who knows the great enthusiasms, the great devotions, and spends himself in a worthy cause; who, at the best, knows in the end the triumph of high achievement; and who, at the worst, if he fails, at least fails while daring greatly, so that his place shall never be with those cold and timid souls who know neither victory nor defeat.\\r\\nDavid du Bose Gaillard died of a brain tumor in Baltimore on December 5, 1913, at age 54. Promoted to colonel only a month earlier, Gaillard never saw the opening of the canal whose creation he directed. The Culebra Cut (as it was originally known) was renamed the Gaillard Cut on April 27, 1915, in his honor. A plaque commemorating Gaillard's work stood over the cut for many years; in 1998 it was moved to the administration building, near a memorial to Goethals.\\r\\nAs the situation in Europe deteriorated during the late 1930s, the US again became concerned about its ability to move warships between the oceans. The largest US battleships already had problems with the canal locks, and there were concerns about the locks being incapacitated by bombing.[8][9]\\r\\nThese concerns led Congress to pass a resolution on May 1, 1936, authorizing a study of improving the canal's defenses against attack and expanding its capacity to handle large vessels. A special engineering section was created on July 3, 1937, to carry out the study. The section reported to Congress on February 24, 1939, recommending work to protect the existing locks and the construction of a new set of locks capable of carrying larger vessels than the existing locks could accommodate. On August 11, Congress authorized the work.\\r\\nThree new locks were planned, at Gat~n, Pedro Miguel and Miraflores, parallel to the existing locks with new approach channels. The new locks would add a traffic lane to the canal, with each chamber 1,200?ft (365.76?m) long, 140?ft (42.67?m) wide and 45?ft (13.72?m) deep. They would be 1?2?mi (805?m) east of the existing Gat~n locks and 1?4?mi (402?m) west of the Pedro Miguel and Miraflores locks.\\r\\nThe first excavations for the new approach channels at Miraflores began on July 1, 1940, following the passage by Congress of an appropriations bill on June 24, 1940. The first dry excavation at Gat~n began on February 19, 1941. Considerable material was excavated before the project was abandoned, and the approach channels can still be seen paralleling the original channels at Gat~n and Miraflores.\\r\\nIn 2006, the Autoridad del Canal de Panam (the Panama Canal Authority, or ACP) proposed a plan creating a third lane of locks using part of the abandoned 1940s approach canals. Following a referendum, work began in 2007 and the expanded canal began commercial operations on June 26, 2016. After a two-year delay, the new locks allow the transit of Panamax ships (which have a greater cargo capacity than the original locks can handle). The first ship to cross the canal through the third set of locks was a Panamax container ship, the Chinese-owned Cosco Shipping Panama. The cost of the expansion was estimated at $5.25 billion.[2]\\r\\nAfter construction, the canal and the Canal Zone surrounding it were administered by the United States. On September 7, 1977, US President Jimmy Carter signed the Torrijos-Carter Treaty setting in motion the process of transferring control of the canal to Panama. The treaty became effective on October 1, 1979, providing for a 20-year period in which Panama would have increasing responsibility for canal operations before complete US withdrawal on December 31, 1999. Since then, the canal has been administered by the Panama Canal Authority (Autoridad de Canal de Panama, or ACP).\\r\\nThe treaty was controversial in the US, and its passage was difficult. The controversy was largely generated by contracts to manage two ports, at either end of the canal, which were awarded by Panama to Hong Kong-based conglomerate Hutchison Whampoa. According to US Republicans, the company has close ties to the Chinese government and the Chinese military.[10] However, the United States Department of State said that it found no evidence of connections between Hutchison Whampoa and Beijing.[11] Some Americans were wary of placing the strategic waterway under the protection of Panamanian security forces.[12]\\r\\nAlthough concerns existed in the US and the shipping industry about the canal after the transfer, Panama has exercised good stewardship.[13] According to ACP figures, canal income increased from $769?million in 2000 (the first year under Panamanian control) to $1.4?billion in 2006.[citation needed] Traffic through the canal increased from 230 million tons in 2000 to nearly 300?million tons in 2006. The number of accidents has decreased from an average of 28 per year in the late 1990s to 12 in 2005. Transit time through the canal averages about 30 hours, about the same as during the late 1990s. Canal expenses have increased less than revenue, from $427?million in 2000 to $497?million in 2006. On October 22, 2006, Panamanian citizens approved a referendum to expand the canal.\\r\\nFormer US Ambassador to Panama Linda Watt, who served from 2002 to 2005, said that the canal operation in Panamanian hands has been \\"outstanding\\". \\"The international shipping community is quite pleased\\", Watt added.[14]\\r\\nEarly proposal","input":"When did america start building the panama canal?"},{"output":"Aditya Puri","context":"\\r\\nAditya Puri is the Managing Director of HDFC Bank, India's largest private sector bank.[1][2] He assumed this position in September 1994, making him the longest-serving head of any private bank in the country.[3] India Today magazine ranked him #24th in India's 50 Most Powerful People of 2017 list.[4]\\r\\n\\r\\nAditya Puri was born in Gurdaspur District (Punjab) and studied at Punjab University, Chandigarh, gaining a bachelor's degree in Commerce. He qualified as a Chartered Accountant with the Institute of Chartered Accountants of India.\\r\\n\\r\\nHe has worked in the banking sector for 40 years, in India and other countries, and became CEO of Citibank, Malaysia in 1992. In September 1994 he returned to India as Managing Director of HDFC Bank.[1][5]\\r\\n\\r\\nHe presided over HDFC's acquisitions of Times Bank Limited in 2000 and of Centurion Bank of Punjab in 2008.[1][6]\\r\\n\\r\\nHe is the father of actress Amrita Puri.[12]","input":"Who is the managing director of hdfc bank?"},{"output":"November 11, 2011","context":"The Miami Marlins are an American professional baseball team based in Miami, Florida. The Marlins compete in Major League Baseball (MLB) as a member club of the National League (NL) East division. Their home park is Marlins Park. Though one of only two MLB franchises to have never won a division title (the other is the Colorado Rockies), the Marlins have won two World Series championships as a wild card team.\\r\\nThe team began play as an expansion team in the 1993 season as the Florida Marlins and played home games from their inaugural season to the 2011 season at Joe Robbie Stadium, which they shared with the Miami Dolphins of the National Football League (NFL). The stadium was later called Pro Player Park, Pro Player Stadium, Dolphin Stadium, Dolphins Stadium, Land Shark Stadium, and Sun Life Stadium during their tenancy. Since the 2012 season, they have played at Marlins Park in downtown Miami, on the site of the former Orange Bowl in Miami, Florida. The new park, unlike Sun Life Stadium (which was criticized in its baseball configuration for poor sight lines in some locations), was designed foremost as a baseball park. The new park's name is a temporary one until naming rights are purchased.[4][5] Per an agreement with the city and Miami-Dade County (which owns the park), the Marlins officially changed their name to the \\"Miami Marlins\\" on November 11, 2011.[6] They also adopted a new logo, color scheme, and uniforms.\\r\\nThe Marlins have the distinction of winning a World Series championship in both seasons they qualified for the postseason, doing so in 1997 and 2003? both times as the National League wild card team. They defeated the American League (AL) champion Cleveland Indians in the 1997 World Series, which was notable for shortstop dgar Rentera driving in second baseman Craig Counsell for the series-clinching run in the 11th inning of the seventh and deciding game. The 2003 season was notable for the firing of manager Jeff Torborg after 38 games. The Marlins were in last place in the NL East with a 16ÿ22 record at the time. Torborg's successor, 72-year-old Jack McKeon, led them to the NL wild card berth in the postseason; they defeated the New York Yankees four games to two in the 2003 World Series.\\r\\n\\r\\n\\r\\nWayne Huizenga, CEO of Blockbuster Entertainment Corporation, was awarded an expansion franchise in the National League (NL) for a $95?million expansion fee and the team began operations in 1993 as the Florida Marlins.\\r\\nThe Marlins would qualify for the postseason and win the World Series in both 1997 and 2003, though both titles were followed by controversial periods where the team sold off all the high priced players and rebuilt.\\r\\nThe Marlins moved into their new ballpark, Marlins Park in 2012, which coincided with a change in the team colors/uniforms and name to the Miami Marlins.\\r\\nPitchers\\r\\nCatchers\\r\\nInfielders\\r\\nOutfielders\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nManager\\r\\nCoaches\\r\\n\\r\\n\\r\\n 7- or 10-day disabled list\\r\\n Suspended list\\r\\n# Personal leave\\r\\nRoster and coaches updated October 26, 2017\\r\\nTransactions ? Depth chart\\r\\nFrom 1993 until 2011, the Marlins had retired the number 5 in honor of Carl Barger, the first president of the Florida Marlins who died prior to the team's inaugural season. Barger's favorite player was Joe DiMaggio, thus the selection of number 5. With the move to the new ballpark, the team opted to honor Barger with a plaque. Logan Morrison, a Kansas City native and fan of Royals Hall-of-Famer George Brett (who wore that number with the Royals), became the first Marlin to wear the number.[9]\\r\\nAfter Jos Fernndez' death as a result of a boating accident on September 25, 2016, the Miami Marlins announced plans to build a memorial at Marlins Park in his honor. However, Fernndez' number 16 has yet to be officially retired.[10]\\r\\nAndre Dawson\\r\\nTony Prez1\\r\\nMike Piazza\\r\\nTim Raines\\r\\nIvn Rodrguez\\r\\nFelo Ramrez\\r\\nDave Van Horne\\r\\nThe Marlins began construction of a new, state-of-the-art stadium at the Miami Orange Bowl site on July 18, 2009. The now approved stadium was the subject of a protracted legal battle. A lawsuit by local automobile franchise mogul and former Philadelphia Eagles owner Norman Braman contested the legality of the deal with Miami-Dade County and the City of Miami. However, Miami-Dade County Judge Beth Cohen dismissed all the charges in Braman's lawsuit.\\r\\nThe seating capacity for Marlins Park is 36,742, making it the third smallest stadium (in capacity) in the MLB. Its first regular season game was April 4, 2012, against the St. Louis Cardinals, the ballpark became only the sixth MLB stadium to have a retractable roof, joining Rogers Centre in Toronto (1989), Chase Field in Phoenix (1998), Safeco Field in Seattle (1999), Minute Maid Park in Houston (2000), and Miller Park in Milwaukee (2001).\\r\\nAs part of the new stadium agreement, the team renamed itself the Miami Marlins on November 11, 2011 along with the unveiling of new uniforms and team logo in time for the move to the new stadium in 2012.\\r\\nUntil a naming-rights deal is reached, the park will be known as Marlins Park.\\r\\nThe Marlins' flagship radio station from their inception in 1993 through 2007 was WQAM 560?AM. Although the Marlins had plans to leave WQAM after 2006, they ultimately remained with WQAM for the 2007 season. On October 11, 2007, it was announced that the Marlins had entered into a partnership with WAXY 790?AM to broadcast all games for the 2008 season. Longtime Montreal Expo and current Marlins play-by-play radio announcer Dave Van Horne won the Hall of Fame's Ford C. Frick Award for excellence in baseball broadcasting in 2010.[11] He shares the play-by-play duties with Glenn Geffner.\\r\\nGames are also broadcast in Spanish on Radio Mambi 710?AM. Felo Ramrez, who calls play-by-play on that station along with Luis Quintana, won the Ford C. Frick Award from the National Baseball Hall of Fame in 2005.\\r\\nMarlins games are televised by Fox Sports Florida. FS Florida's slogan in 2008 was \\"You Gotta Be Here.\\" For the 2009 season the new slogan is \\"It's where you wanna be.\\" There are no games available over-the-air, with the exception of games broadcast on Fox Saturday Baseball; the last \\"free TV\\" broadcast of a game was on WPXM-TV in 2005. Rich Waltz is the play-by-play announcer.\\r\\nIn 1989, Back to the Future Part II had a reference to the Chicago Cubs defeating a baseball team from Miami in the 2015 World Series, ending the longest championship drought in all four of the major North American professional sports leagues.[12]\\r\\nThe Marlins were the first team in Major League Baseball to have a dance/cheer team.[citation needed] Debuting in 2003, the \\"Marlins Mermaids\\" influenced other MLB teams to develop their own cheer/dance squads; this was inspired in part by similar squads from the NFL and NBA.[citation needed] In 2008, the Florida Marlins debuted \\"The Marlins Manatees\\", Major League Baseball's first all-male dance/energy squad, to star alongside the Mermaids.[citation needed] As of 2012, the Marlins have abandoned the \\"Mermaids\\" and \\"Manatees\\" for in-game entertainment instead using an \\"energy squad\\", a co-ed group of dancers.[13]\\r\\nIn 2016, the Miami New Times reported that the team was involved in contract dispute lawsuits with both season ticket holders and vendors.[14]\\r\\nThe following are the five best seasons in Marlins' history:\\r\\nThe following are the five worst seasons in Marlins' history:\\r\\nOther than their first few years as a franchise in the 1990s, the Marlins have consistently ranked as one of lowest attendance teams in the league, coming in last place (30th) several of the past 20 years. Even when Marlins Park was completed for the 2012 season, attendance was only average for the first year, dropping down to second to last by 2013.\\r\\n[17][18]\\r\\nOpening Day payrolls for 25-man roster (since 1993):[19][20]\\r\\nThe annual financial records of the Marlins according to Forbes since 2001.[21]","input":"When did the marlins became the miami marlins?"},{"output":"in 79 AD","context":"\\r\\n\\r\\nMount Vesuvius, a stratovolcano in modern-day Italy, erupted in 79 AD in one of the most catastrophic volcanic eruptions in European history. Historians have learned about the eruption from the eyewitness account of Pliny the Younger, a Roman administrator and poet.[1] The event is the namesake for the Vesuvian type of volcanic eruptions.\\r\\n\\r\\nMount Vesuvius violently spewed forth a deadly cloud of super-heated tephra and gases to a height of 33?km (21?mi), ejecting molten rock, pulverized pumice and hot ash at a massive rate of 1.5 million tons per second, ultimately releasing 100,000 times the thermal energy of the Hiroshima-Nagasaki bombings.[2] Several Roman settlements were obliterated and buried underneath massive pyroclastic surges and ashfall deposits, the best known being Pompeii and Herculaneum.[1][2]\\r\\n\\r\\nThe total inhabitants of both cities were 16,000ÿ20,000; the remains of over 1,500 people have been found at Pompeii and Herculaneum, but the overall death toll is still unclear.\\r\\n\\r\\nThe AD 79 eruption was preceded by a powerful earthquake seventeen years before on February 5, AD 62, which caused widespread destruction around the Bay of Naples, and particularly to Pompeii.[3] Some of the damage had still not been repaired when the volcano erupted.[4] The deaths of 600 sheep from \\"tainted air\\" in the vicinity of Pompeii, reported by Seneca the Younger, leads volcanologist Haraldur Sigurdsson to compare them to similar deaths of sheep in Iceland from pools of volcanic carbon dioxide and to speculate that the earthquake of AD 62 was related to new activity by Mount Vesuvius.[5]\\r\\n\\r\\nAnother smaller earthquake took place in AD 64; it was recorded by Suetonius in his biography of Nero,[6] and by Tacitus in Annales because it took place while Nero was in Naples performing for the first time in a public theatre.[7] Suetonius recorded that the emperor continued singing through the earthquake until he had finished his song, while Tacitus wrote that the theatre collapsed shortly after being evacuated.\\r\\n\\r\\nThe Romans grew accustomed to minor earth tremors in the region; the writer Pliny the Younger wrote that they \\"were not particularly alarming because they are frequent in Campania\\". Small earthquakes started taking place on 20 August 79,[4] becoming more frequent over the next four days, but the warnings were not recognized.[8]\\r\\n\\r\\nReconstructions of the eruption and its effects vary considerably in the details but have the same overall features. The eruption lasted for two days. The morning of the first day, August 22, was perceived as normal by the only eyewitness to leave a surviving document, Pliny the Younger, who at that point was staying at Misenum, on the other side of the Bay of Naples about 30 kilometres (19?mi) from the volcano, which may have prevented him from noticing the early signs of the eruption. He was not to have any opportunity, during the next two days, to talk to people who had witnessed the eruption from Pompeii or Herculaneum (indeed he never mentions Pompeii in his letter), so he would not have noticed early, smaller fissures and releases of ash and smoke on the mountain, if such had occurred earlier in the morning. Around 1:00 P.M., Mount Vesuvius violently erupted, spewing up a high-altitude column from which ash and pumice began to fall, blanketing the area. Rescues and escapes occurred during this time. At some time in the night or early the next day, August 23, pyroclastic flows in the close vicinity of the volcano began. Lights seen on the mountain were interpreted as fires. People as far away as Misenum fled for their lives. The flows were rapid-moving, dense, and very hot, knocking down wholly or partly all structures in their path, incinerating or suffocating all population remaining there and altering the landscape, including the coastline. These were accompanied by additional light tremors and a mild tsunami in the Bay of Naples. By evening of the second day, the eruption was over, leaving only haze in the atmosphere through which the sun shone weakly.\\r\\n\\r\\nPliny the Younger wrote an account of the eruption:\\r\\n\\r\\nBroad sheets of flame were lighting up many parts of Vesuvius; their light and brightness were the more vivid for the darkness of the night... it was daylight now elsewhere in the world, but there the darkness was darker and thicker than any night.[9]\\r\\nAccording to a stratigraphic study (a study of the layers of ash) by Sigurdsson, Cashdollar, and Sparks, published in 1982, and now a standard reference, the eruption of Vesuvius of AD 79 unfolded in two phases:[10] a Vesuvian eruption that lasted eighteen to twenty hours and produced a fall of pumice and ashes southward of the volcano that accumulated up to depths of 2.8?m (9.2?ft) at Pompeii, followed by pyroclastic surges or nues ardentes in the second Pelan phase that reached as far as Misenum but was concentrated to the west and northwest. Two pyroclastic surges engulfed Pompeii, burning and asphyxiating any living beings who had remained behind. Herculaneum and Oplontis received the brunt of the surges and were buried in fine pyroclastic deposits, pulverized pumice and lava fragments.\\r\\n\\r\\nIn an article published in 2002, Sigurdsson and Casey elaborate on the stratigraphic evidence based on excavations and surveys up until then. In this interpretation, the quasi-initial explosion (not quite initial) produced a column of ash and pumice ranging between 15?km (9.3?mi) and 30?km (19?mi) high, which, due to northwest winds, rained on Pompeii to the southeast but not on Herculaneum upwind. The eruption is viewed as primarily phreatomagmatic; that is, the chief energy supporting the blast column came from the escape of steam generated by the magma, created from seawater seeping over time into the deep-seated faults of the region, that came into interaction with magma and heat.\\r\\n\\r\\nSubsequently, the cloud collapsed as the gases densified and lost their capability to support their solid contents, releasing it as a pyroclastic surge, which first reached Herculaneum, not Pompeii. Additional explosions reinstituted the column. The eruption alternated between Vesuvian and Pelan six times. Surges 4 and 5 are believed by the authors to have destroyed and buried Pompeii.[11] Surges are identified in the deposits by dune and cross-bedding formations, which are not produced by fallout.\\r\\n\\r\\nThe authors suggest that the first ash falls are to be interpreted as early-morning, low-volume explosions not seen from Misenum, causing Rectina to send her messenger on a ride of several hours around the Bay of Naples, then passable, providing an answer to the paradox of how the messenger might miraculously appear at Pliny's villa so shortly after a distant eruption that would have prevented him.\\r\\n\\r\\nA 2006 study by Zanella, Gurioli, Pareschi, and Lanza used the magnetic characteristics of over 200?samples of lithic, roof-tile, and plaster fragments collected from pyroclastic deposits in and around Pompeii to estimate the equilibrium temperatures of the deposits.[12] The deposits were placed by pyroclastic density currents (PDCs) resulting from the collapses of the Plinian column. The authors argue that fragments over 2ÿ5?cm (0.8ÿ2?in) were not in the current long enough to acquire its temperature, which would have been much higher, and therefore they distinguish between the depositional temperatures, which they estimated, and the emplacement temperatures, which in some cases based on the cooling characteristics of some types and fragment sizes of rocks they believed they also could estimate. Final figures are considered to be those of the rocks in the current just before deposition.[13]\\r\\n\\r\\nAll crustal rock contains some iron or iron compounds, rendering it ferromagnetic, as do Roman roof tiles and plaster. These materials may acquire a residual field from a number of sources. When individual molecules, which are magnetic dipoles, are held in alignment by being bound in a crystalline structure, the small fields reinforce each other to form the rock's residual field.[14] Heating the material adds internal energy to it. At the Curie temperature, the vibration of the molecules is sufficient to disrupt the alignment; the material loses its residual magnetism and assumes whatever magnetic field might be applied to it only for the duration of the application. The authors term this phenomenon unblocking. Residual magnetism is considered to \\"block out\\" non-residual fields.\\r\\n\\r\\nA rock is a mixture of minerals, each with its own Curie temperature; the authors therefore looked for a spectrum of temperatures rather than a single temperature. In the ideal sample, the PDC did not raise the temperature of the fragment beyond the highest blocking temperature. Some constituent material retained the magnetism imposed by the Earth's field when the item was formed. The temperature was raised above the lowest blocking temperature and therefore some minerals on recooling acquired the magnetism of the Earth as it was in AD 79. The overall field of the sample was the vector sum of the fields of the high-blocking material and the low-blocking material.\\r\\n\\r\\nThis type of sample made possible estimation of the low unblocking temperature. Using special equipment that measured field direction and strength at various temperatures, the experimenters raised the temperature of the sample in increments of 40?C (70?F) from 100?C (210?F) until it reached the low unblocking temperature.[15] Deprived of one of its components, the overall field changed direction. A plot of direction at each increment identified the increment at which the sample's resultant magnetism had formed.[16] That was considered to be the equilibrium temperature of the deposit. Considering the data for all the deposits of the surge arrived at a surge deposit estimate. The authors discovered that the city, Pompeii, was a relatively cool spot within a much hotter field, which they attributed to interaction of the surge with the \\"fabric\\" of the city.[17]\\r\\n\\r\\nThe investigators reconstruct the sequence of volcanic events as follows. On the first day of the eruption a fall of white pumice containing clastic fragments of up to 3 centimetres (1?in) fell for several hours.[18] It heated the roof tiles to 120ÿ140?C (250ÿ280?F).[19] This period would have been the last opportunity to escape. Subsequently, a second column deposited a grey pumice with clastics up to 10?cm (4?in), temperature unsampled, but presumed to be higher, for 18 hours. These two falls were the Plinian phase. The collapse of the edges of these clouds generated the first dilute PDCs, which must have been devastating to Herculaneum, but did not enter Pompeii.\\r\\n\\r\\nEarly in the morning of the second day the grey cloud began to collapse to a greater degree. Two major surges struck and destroyed Pompeii. Herculaneum and all its population no longer existed. The emplacement temperature range of the first surge was 180ÿ220?C (360ÿ430?F), minimum temperatures; of the second, 220ÿ260?C (430ÿ500?F). The depositional temperature of the first was 140ÿ300?C (280ÿ570?F). Upstream and downstream of the flow it was 300ÿ360?C (570ÿ680?F).[20]\\r\\n\\r\\nThe variable temperature of the first surge was due to interaction with the buildings. Any population remaining in structural refuges could not have escaped, as the city was surrounded by gases of incinerating temperatures. The lowest temperatures were in rooms under collapsed roofs. These were as low as 100?C (210?F), the boiling point of water.[21] The authors suggest that elements of the bottom of the flow were decoupled from the main flow by topographic irregularities and were made cooler by the introduction of ambient turbulent air. In the second surge the irregularities were gone and the city was as hot as the surrounding environment.\\r\\n\\r\\nDuring the last surge, which was very dilute, one meter more of deposits fell over the region.[22]\\r\\n\\r\\nThe only surviving eyewitness account of the event consists of two letters by Pliny the Younger, who was 17 at the time of the eruption,[23] to the historian, Tacitus.[24] Observing the first volcanic activity from Misenum across the Bay of Naples from the volcano, approximately 35 kilometres (22?mi) away, the elder Pliny launched a rescue fleet and went himself to the rescue of a personal friend. His nephew declined to join the party. One of the nephew's letters relates what he could discover from witnesses of his uncle's experiences.[25] In a second letter the younger Pliny details his own observations after the departure of his uncle.[26]\\r\\n\\r\\nThe two men saw an extraordinarily dense cloud rising rapidly above the mountain:[25]\\r\\nI cannot give you a more exact description of its appearance than by comparing to a pine tree; for it shot up to a great height in the form of a tall trunk, which spread out at the top as though into branches. [...] Occasionally it was brighter, occasionally darker and spotted, as it was either more or less filled with earth and cinders.\\r\\n\\r\\nThese events and a request by messenger for an evacuation by sea prompted the elder Pliny to order rescue operations in which he sailed away to participate. His nephew attempted to resume a normal life, continuing to study, and bathing, but that night a tremor awoke him and his mother, prompting them to abandon the house for the courtyard. At another tremor near dawn the population abandoned the village. After still a third \\"the sea seemed to roll back upon itself, and to be driven from its banks\\", which is evidence for a tsunami. There is, however, no evidence of extensive damage from wave action.\\r\\n\\r\\nThe early light was obscured by a black cloud through which shone flashes, which Pliny likens to sheet lightning, but more extensive. The cloud obscured Point Misenum near at hand and the island of Capraia (Capri) across the bay. Fearing for their lives the population began to call to each other and move back from the coast along the road. Pliny's mother requested him to abandon her and save his own life, as she was too corpulent and aged to go further, but seizing her hand he led her away as best he could. A rain of ash fell. Pliny found it necessary to shake off the ash periodically to avoid being buried. Later that same day the ash stopped falling and the sun shone weakly through the cloud, encouraging Pliny and his mother to return to their home and wait for news of Pliny the Elder. The letter compares the ash to a blanket of snow. Evidently the earthquake and tsunami damage at that location were not severe enough to prevent continued use of the home.\\r\\n\\r\\nPliny's uncle Pliny the Elder was in command of the Roman fleet at Misenum, and had meanwhile decided to investigate the phenomenon at close hand in a light vessel. As the ship was preparing to leave the area, a messenger came from his friend Rectina (wife of Tascius) living on the coast near the foot of the volcano, explaining that her party could only get away by sea and asking for rescue.[27] Pliny ordered the immediate launching of the fleet galleys to the evacuation of the coast. He continued in his light ship to the rescue of Rectina's party.[27]\\r\\n\\r\\nHe set off across the bay but in the shallows on the other side encountered thick showers of hot cinders, lumps of pumice, and pieces of rock. Advised by the helmsman to turn back he stated \\"Fortune favors the brave\\" and ordered him to continue on to Stabiae (about 4.5?km or 2.8?mi from Pompeii), where Pomponianus was.[27] Pomponianus had already loaded a ship with possessions and was preparing to leave, but the same onshore wind that brought Pliny's ship to the location had prevented anyone from leaving.[27]\\r\\n\\r\\nPliny and his party saw flames coming from several parts of the mountain, which Pliny and his friends attributed to burning villages. After staying overnight, the party was driven from the building by an accumulation of material which threatened to block all egress.[27] They woke Pliny, who had been napping and emitting loud snoring. They elected to take to the fields with pillows tied to their heads to protect them from rockfall. They approached the beach again but the wind had not changed. Pliny sat down on a sail that had been spread for him and could not rise even with assistance when his friends departed, escaping ultimately by land.[28] Very likely, he had collapsed and died, which is the most popular explanation of why his friends abandoned him, although Suetonius offers an alternative story of his ordering a slave to kill him to avoid the pain of incineration. How the slave would have escaped to tell the tale remains a mystery. There is no mention of such an event in his nephew's letters.\\r\\n\\r\\nIn the first letter to Tacitus his nephew suggested that his death was due to the reaction of his weak lungs to a cloud of poisonous, sulphurous gas that wafted over the group.[27] However, Stabiae was 16?km (9.9?mi) from the vent (roughly where the modern town of Castellammare di Stabia is situated) and his companions were apparently unaffected by the fumes, and so it is more likely that the corpulent Pliny died from some other cause, such as a stroke or heart attack.[29] An asthmatic attack is also not out of the question. His body was found with no apparent injuries on the next day, after dispersal of the plume.\\r\\n\\r\\nAlong with Pliny the Elder, the only other notable casualties of the eruption to be known by name were Agrippa (a son of the Jewish princess Drusilla and the procurator Antonius Felix) and his wife.[30]\\r\\n\\r\\nBy 2003 around 1,044?casts made from impressions of bodies in the ash deposits had been recovered in and around Pompeii, with the scattered bones of another 100.[31] The remains of about 332 bodies have been found at Herculaneum (300 in arched vaults discovered in 1980).[32] What percentage these numbers are of the total dead or the percentage of the dead to the total number at risk remain completely unknown.\\r\\n\\r\\nThirty-eight percent of the 1,044 were found in the ash fall deposits, the majority inside buildings. These are thought to have been killed mainly by roof collapses, with the smaller number of victims found outside buildings probably killed by falling roof slates or by larger rocks thrown out by the volcano. This differs from modern experience, since over the last four hundred years only around 4% of victims have been killed by ash falls during explosive eruptions. The remaining 62% of remains found at Pompeii were in the pyroclastic surge deposits,[31] and thus were probably killed by them. It was initially believed that due to the state of the bodies found at Pompeii and the outline of clothes on the bodies it was unlikely that high temperatures were a significant cause. But in 2010, studies indicated that during the fourth pyroclastic surge ÿ the first surge to reach Pompeii ÿ temperatures reached 300?C (572?F). Volcanologist Giuseppe Mastrolorenzo, who led the study, noted that \\"(It was) enough to kill hundreds of people in a fraction of a second\\". In reference as to why the bodies were frozen in suspended action, \\"The contorted postures are not the effects of a long agony, but of the cadaveric spasm, a consequence of heat shock on corpses.\\"[33]\\r\\n\\r\\nHerculaneum, which was much closer to the crater, was saved from tephra falls by the wind direction, but was buried under 23 metres (75?ft) of material deposited by pyroclastic surges. It is likely that most, or all, of the known victims in this town were killed by the surges, particularly given evidence of high temperatures found on the skeletons of the victims found in the arched vaults, and the existence of carbonised wood in many of the buildings.\\r\\n\\r\\nThese people were all caught on the former seashore by the first surge and died of thermal shock but not of carbonization, although some were partly carbonized by later and hotter surges. The arched vaults were most likely boathouses, as the crossbeams in the overhead were probably for the suspension of boats. No boats have been found, indicating they may have been used for the earlier escape of some of the population. The rest were concentrated in the chambers at a density of as high as 3 persons per square meter. As only 85 metres (279?ft) of the coast have been excavated, the casualties waiting to be excavated may well be as high as the thousands.[34]\\r\\n\\r\\nThe year of the eruption is pinned to AD 79 by references in contemporary Roman writers, a number of them apart from Pliny the Younger, and has never been seriously questioned. It is determined by the well-known events of the reign of Titus. Vespasian died that year. When Titus visited Pompeii to give orders for the relief of the displaced population, he was the sole ruler. In the year after the eruption, AD 80, he faced another disaster, a great fire at Rome.\\r\\n\\r\\nThe time of year is stated once in one historical document, the first letter of Pliny the Younger to Tacitus,[25] where it appears as \\"nonum kal. Septembres\\". This seems to be an abbreviation of a standard date, to be interpreted as \\"the ninth day before the Kalends of September\\", which in the Julian calendar, in general use by then, would have been eight days before September 1, that is August 24 (the Romans counted September 1 as one of the nine).\\r\\n\\r\\nAugust 24 is not necessarily the date given by Pliny. It represents an editorial collusion to use the manuscript text of Pliny's letters in the Medicean Laurentian Library, which also appears in the edition printed by Aldus Manutius (1508) and in all recensions since then, even though the numerous other Pliny manuscripts, as well as the works of other authors, offer many alternative dates.[35]","input":"When did mt vesuvius erupt and destroy pompeii?"},{"output":"The Roanoke Colony","context":"The Roanoke Colony (/?ro???no?k/), also known as the Lost Colony, was established in 1585 on Roanoke Island in what is today's Dare County, North Carolina. It was a late 16th-century attempt by Queen Elizabeth I to establish a permanent English settlement in North America. The colony was founded by Sir Walter Raleigh.\\r\\nThe colonists disappeared during the Anglo-Spanish War, three years after the last shipment of supplies from England. Their disappearance gave rise to the nickname \\"The Lost Colony\\". There is no conclusive evidence as to what happened to the colonists.\\r\\n\\r\\n\\r\\nThe enterprise was originally financed and organized by Sir Humphrey Gilbert, who drowned in 1583 returning from a voyage to the fishing settlement at St. John's, Newfoundland. Sir Humphrey Gilbert's half-brother Sir Walter Raleigh later gained his brother's charter from the Queen and subsequently executed the details of the charter through his delegates Ralph Lane and Richard Grenville, Raleigh's distant cousin.[1]\\r\\nOn March 25, 1584, Queen Elizabeth I granted Raleigh a charter for the colonization of the area of North America. This charter specified that Raleigh needed to establish a colony in North America, or lose his right to colonization.[2]:9\\r\\nThe Queen and Raleigh intended that the venture should provide riches from the New World. The queen's charter said that Raleigh was supposed to \\"discover, search, find out, and view such remote heathen and barbarous Lands, Countries, and territories ... to have, hold, occupy, and enjoy\\".[3]\\r\\nThe queen's charter also said that Raleigh was supposed to establish a base from which to send privateers on raids against the treasure fleets of Spain.[4]:135 The purpose of these raids was to tell Spain that England was ready for war. The original charter basically told Raleigh to establish a military base to counteract the activities of the Spaniards.[5] Raleigh himself never visited North America, although he led expeditions in 1595 and 1617 to South America's Orinoco River basin in search of the legendary golden city of El Dorado.\\r\\nOn April 27, 1584, Raleigh dispatched an expedition led by Philip Amadas and Arthur Barlowe to explore the eastern coast of North America. They arrived on Roanoke Island on July 4[2]:32 and soon established relations with the local natives, the Secotans and Croatans. Barlowe returned to England with two Croatans named Manteo and Wanchese, who were able to describe the politics and geography of the area to Raleigh.[2]:44ÿ45 Based on the information given, Raleigh organized a second expedition, to be led by Sir Richard Grenville.\\r\\nGrenville's fleet departed Plymouth on April 9, 1585, with five main ships: Tiger (Grenville's), Roebuck, Red Lion, Elizabeth, and Dorothy. A severe storm off the coast of Portugal separated Tiger from the rest of the fleet.[2]:57 The captains had a contingency plan if they were separated, which was to meet up again in Puerto Rico, and Tiger arrived in the \\"Baye of Muskito\\"[6] (Guayanilla Bay) on May 11.\\r\\nWhile waiting for the other ships, Grenville established relations with the resident Spanish while simultaneously engaging in some privateering against them.[2]:62 He also built a fort. Elizabeth arrived soon after the fort's construction.[7]:91 Grenville eventually tired of waiting for the remaining ships and departed on June 7. The fort was abandoned, and its location remains unknown.\\r\\nTiger sailed through Ocracoke Inlet on June 26, but it struck a shoal, ruining most of the food supplies.[2]:63 The expedition succeeded in repairing the ship and, in early July, reunited with Roebuck and Dorothy, which had arrived in the Outer Banks with Red Lion some weeks previous. Red Lion had dropped off its passengers and left for Newfoundland for privateering.[2]:64\\r\\nDuring the initial exploration of the mainland coast and the native settlements, the Europeans blamed the natives of the village of Aquascogoc for stealing a silver cup. As retaliation, the settlers sacked and burned the village.[2]:72 English writer and courtier Richard Hakluyt's contemporaneous reports also describe this incident. (Hakluyt's reports of the first voyage to Roanoke were compiled from accounts by various financial backers, including Sir Walter Raleigh. Hakluyt himself never traveled to the New World.)[8]\\r\\nDespite this incident and a lack of food, Grenville decided to leave Ralph Lane and 107 men to establish a colony at the north end of Roanoke Island, promising to return in April 1586 with more men and fresh supplies. The group disembarked on August 17, 1585,[9] and built a small fort on the island. There are no surviving renderings of the Roanoke fort, but it was likely similar in structure to the one in Guayanilla Bay. Grenville in the Tiger on only his seventh day of sail captured (after a three-day battle) a rich Spanish galleon, Santa Maria de San Vicente off Bermuda which he took with him as a prize back to England.[10]\\r\\nAs April 1586 passed, there was no sign of Grenville's relief fleet. Meanwhile, in June, bad blood resulted from the destruction of the village, and this spurred an attack on the fort by the local Native Americans, which the colonists were able to repel.[11]:5 Soon after the attack, Sir Francis Drake was on his way home from a successful raid in the Caribbean, and he stopped at the colony and offered to take the colonists back to England. Several accepted, including metallurgist Joachim Gans. On this return voyage, the Roanoke colonists introduced tobacco, maize, and potatoes to England.[11]:5 The relief fleet arrived shortly after Drake's departure with the colonists. Finding the colony abandoned, Grenville returned to England with the bulk of his force, leaving behind a small detachment of fifteen men both to maintain an English presence and to protect Raleigh's claim to Roanoke Island.[12]:127\\r\\nIn 1587, Raleigh dispatched a new group of 115 colonists to establish a colony on Chesapeake Bay. They were led by John White, an artist and friend of Raleigh who had accompanied the previous expedition to Roanoke, and was appointed governor of the 1587 colony. White and Raleigh named 12 assistants to aid in the settlement. They were ordered to stop at Roanoke to pick up the small contingent left there by Grenville the previous year, but when they arrived on July 22, 1587, they found nothing except a skeleton that may have been the remains of one of the English garrison.[8]\\r\\nWhen they could find no one,[8] the master pilot Simon Fernandez refused to let the colonists return to the ships, insisting that they establish the new colony on Roanoke.[7]:215 His motives remain unclear, however, and new evidence offered by author Brandon Fullam indicates not only that Fernandez had good reason for his actions, but that the decision to alter the Chesapeake Bay destination had already been agreed to prior to their arrival at Roanoke.[13]\\r\\nWhite re-established relations with the Croatan and other local tribes, but those with whom Lane had fought previously refused to meet with him. Shortly thereafter, colonist George Howe was killed by a native while searching alone for crabs in Albemarle Sound.[14]:120ÿ23\\r\\nThe colonists persuaded Governor White to return to England to explain the colony's desperate situation and ask for help.[14]:120ÿ23 Left behind were about 115 colonists?ÿ the remaining men and women who had made the Atlantic crossing plus White's newly born granddaughter Virginia Dare, the first English child born in the Americas.[12]:19\\r\\nWhite sailed for England in late 1587, although crossing the Atlantic at that time of year was a considerable risk.[15] Plans for a relief fleet were delayed first by the captain's refusal to return during the winter, and then the attack on England of the Spanish Armada and the subsequent Anglo-Spanish War. Every able English ship joined the fight, leaving White without a means to return to Roanoke at the time.[4]:125ÿ26 In the spring of 1588, White managed to acquire two small vessels and sailed for Roanoke; however, his attempt to return was thwarted when the captains of the ships attempted to capture several Spanish ships on the outward-bound voyage (in order to improve their profits). They themselves were captured and their cargo seized. With nothing left to deliver to the colonists, the ships returned to England.[4]:125ÿ26\\r\\nBecause of the continuing war with Spain, White was unable to mount another resupply attempt for an additional three years. He finally gained passage on a privateering expedition organised by John Watts and Walter Raleigh. They agreed to stop off at Roanoke on the way back after raiding the Spanish in the Caribbean. White landed on August 18, 1590, on his granddaughter's third birthday, but found the settlement deserted. His men could not find any trace of the 90 men, 17 women, and 11 children, nor was there any sign of a struggle or battle.[4]:130ÿ33\\r\\nThe only clue was the word \\"CROATOAN\\" carved into a post of the fence around the village, and the letters C-R-O carved into a nearby tree. All the houses and fortifications had been dismantled, which meant that their departure had not been hurried. Before he had left the colony, White instructed the colonists that, if anything happened to them, they should carve a Maltese cross on a tree nearby, indicating that their absence had been forced. There was no cross, and White took this to mean that they had moved to Croatoan Island (now known as Hatteras Island), but he was unable to conduct a search. A massive storm was forming and his men refused to go any farther; the next day, they left.[4]:130ÿ33\\r\\nBorn in 1560, Thomas Harriot entered Raleigh's employment in the early 1580s, after graduating from the University of Oxford. Harriot may have been among the men of Arthur Barlowe's 1584 expedition of the colony. He trained the members of Raleigh's first Roanoke expedition in navigational skills and eventually sailed to Roanoke with the second group of settlers, where his skills as a naturalist became particularly important along with those of painter and settlement leader John White.[16]\\r\\nBetween their arrival in Roanoke in April 1585 and the July 1586 departure, Harriot and White both conducted detailed studies of the Roanoke area, with Harriot compiling his samples and notes into several notebooks that did not survive the colony's disappearance. Harriot also wrote descriptions of the surrounding flora and fauna of the area, which survive in his work A Brief and True Report of the New Founde Land of Virginia, written as a report on the colony's progress to the English government on the request of Raleigh. Viewed by modern historians as propaganda for the colony, this work has become vastly important to Roanoke's history due to Harriot's observations on wildlife as well as his depictions of Indian activities at the time of the colony's disappearance.[16]\\r\\nHarriot reports that relations between the Roanoke Indians and the English settlers were mutually calm and prosperous, contradicting other historical evidence that catalogs the bloody struggles between the Roanoke Indians and both of Raleigh's commanders, Sir Richard Grenville and his successor, Ralph Lane. Harriot recounts little to none of these accounts in his report to England and does not mention the disorderly state of the colony under either Grenville's or Lane's tenure, correctly assuming these facts would prevent Roanoke from gaining more settlers. Harriot's text did not reach England, or the English press, until 1588, by which time the fate of the \\"Lost Colony\\" was sealed in all but name.[16]\\r\\nTwelve years went by before Raleigh decided to find out what happened to his colony. Led by Samuel Mace, this 1602 expedition differed from previous voyages in that Raleigh bought his own ship and guaranteed the sailors' wages so that they would not be distracted by privateering. However, Raleigh still hoped to make money from the trip, and Mace's ship landed in the Outer Banks to gather aromatic woods or plants such as sassafras that would generate a decent profit back in England. By the time they could turn their attention to the colonists, the weather had turned bad and they were forced to return without even making it to Roanoke Island. By this time, having been arrested for treason, Raleigh was unable to send any further missions.[4]:134ÿ35\\r\\nThere was one final expedition in 1603 led by Bartholomew Gilbert with the intention of finding Roanoke colonists. Their intended destination was Chesapeake Bay, but bad weather forced them to land in an unspecified location near there. The landing team, including Gilbert himself, was killed by a group of Native Americans for unknown reasons on July 29. The remaining crew were forced to return to England empty-handed.[17]\\r\\nMeanwhile, the Spanish had different reasons for wanting to find the colony. Knowing of Raleigh's plans to use Roanoke as a base for privateering, they were hoping to destroy it. Moreover, they had been getting mostly inaccurate reports of activities there, and they imagined the colony to be far more successful than it actually was.[4]:135ÿ37\\r\\nIn 1590, they found the remnants of the colony purely by accident, but assumed it was only an outlying base of the main settlement, which they believed was in the Chesapeake Bay area (John White's intended location). But just as the Anglo-Spanish War prevented White from returning in a timely manner, Spanish authorities in the New World could not muster enough support back home for such a venture.[4]:135ÿ37\\r\\nOnce the Jamestown settlement was established in 1607, efforts were undertaken by the English to acquire information from the Powhatan tribe about Roanoke. The first definitive information concerning the fate of the Lost Colony came from Captain John Smith, leader of the Jamestown Colony from 1608 to 1609. According to chronicler Samuel Purchas, Smith learned from Chief Powhatan that he had personally conducted the slaughter of the Roanoke colonists just prior to the arrival of the Jamestown settlers because they were living with the Chesepians, a tribe living in the eastern portion of the present-day South Hampton Roads sub-region who were related to the Pamlico tribe in Carolina and who refused to merge with the Powhatans.[18]:21ÿ24 This shocking information was reported to England and by the spring of 1609, King James and the Royal Council were convinced that Chief Powhatan was responsible for the slaughter of the Lost Colony.\\r\\nThe second source of Chief Powhatans involvement was William Strachey, Secretary of the Jamestown colony in 1610ÿ11. Stracheys The Historie of Travaile Into Virginia Britannia seemed to confirm Smiths report and provided additional information: the colonists had been living peacefully among a group of natives beyond Powhatans domain for more than twenty years when they were massacred. Furthermore, Powhatan himself seemed to have directed the slaughter because of prophecies by his priests that he would be overthrown by people from that area,[19]:101 and he reportedly produced several English-made iron implements to back his claim.[20]\\r\\nThe information from these two sources, John Smith and William Strachey, provides the basis for the traditional view that the Lost Colony was slaughtered by Chief Powhatan, and versions of the Powhatan-Lost Colony-slaughter scenario have persisted for more than 400 years. However, no bodies were found and no archaeological evidence has been found to support this claim.[21]\\r\\nFurthermore, recent re-examination of the Smith and Strachey sources advanced by author and researcher Brandon Fullam has suggested that the massacre described by Powhatan was actually of the 15 people left behind by the first Roanoke expedition, leaving the fate of the second colony still unknown.[20][22]\\r\\n\\r\\nAs per Smith's and Strachey's reports, Dr. David Beers Quinn theorized that the colonists moved north to integrate with the Chesepians that Chief Powhatan claimed to have killed. To make the journey northward, Quinn believed that they used the pinnace and other small boats to transport themselves and their belongings. Naturally, if that were the mode of transportation, the colonists could have gone to live in other locations as well.[21]\\r\\nIn her 2000 book Roanoke: Solving the Mystery of the Lost Colony, historian Lee Miller postulated that some of the Lost Colony survivors sought shelter with the Chowanoke, who were attacked by another tribe, identified by the Jamestown Colony as the \\"Mandoag\\" (an Algonquian name commonly given to enemy nations). The Mandoag are believed to be either the Tuscarora, an Iroquois-speaking tribe,[23]:45 or the Eno, also known as the Wainoke.[12]:255ÿ56\\r\\nThe so-called \\"Zuniga Map\\" (named for Pedro de Z~?iga, the Spanish ambassador to England, who had secured a copy and passed it on to Philip III of Spain[24]:112), drawn about 1607 by the Jamestown settler Francis Nelson, also gives credence to this claim. The map states \\"four men clothed that came from roonock\\" were living in an Iroquois site on the Neuse. William Strachey wrote that, at the Indian settlements of Peccarecanick and Ochanahoen, there were reportedly two-story houses with stone walls. The Indians supposedly had learned how to build them from the Roanoke settlers.[25]:222 In both cases, as stated above, it is equally possible that these were survivors of Chief Powhatan's attack on the first Jamestown colonists.[20]\\r\\nThere were also reported sightings of European captives at various Indian settlements during the same time period.[12]:250 Strachey wrote in 1612 that four English men, two boys and one girl had been sighted at the Eno settlement of Ritanoc, under the protection of a chief called Eyanoco. Strachey reported that the captives were forced to beat copper and that they had escaped the attack on the other colonists and fled up the Chaonoke river, the present-day Chowan River in Bertie County, North Carolina.[12]:242[25]:222[26]\\r\\nJohn Lawson wrote in his 1709 work A New Voyage to Carolina that the Croatans living on Hatteras Island used to live on Roanoke Island and claimed to have white ancestors:\\r\\nA farther Confirmation of this we have from the Hatteras Indians, who either then lived on Ronoak-Island, or much frequented it. These tell us, that several of their Ancestors were white People, and could talk in a Book, as we do; the Truth of which is confirm'd by gray Eyes being found frequently amongst these Indians, and no others. They value themselves extremely for their Affinity to the English, and are ready to do them all friendly Offices. It is probable, that this Settlement miscarry'd for want of timely Supplies from England; or thro' the Treachery of the Natives, for we may reasonably suppose that the English were forced to cohabit with them, for Relief and Conversation; and that in process of Time, they conform'd themselves to the Manners of their Indian Relations.[27]\\r\\nFrom the early 17th century to the middle 18th century, European colonists reported encounters with gray-eyed American Indians who claimed descent from the colonists[12]:257, 263 (although at least one, a story of a Welsh priest who met a Doeg warrior who spoke the Welsh language, is likely to be a hoax).[28]:76 Records from French Huguenots who settled along the Tar River in 1696 tell of meeting Tuscaroras with blond hair and blue eyes not long after their arrival. As Jamestown was the nearest English settlement, and they had no record of being attacked by Tuscarora, the likelihood that the origin of those fair-skinned natives was the Lost Colony is high.[23]:28\\r\\nFred Willard and Phillip MacMullan believe that the colonists along with the Croatans relocated to villages along the Alligator River in an area known as \\"Beechland\\", slightly inland from Roanoke Island. Archeological remains of settlements have been discovered in the area, including coffins with Christian markings on them where there had been no previous record of a grave site, but their hypothesis is mostly based on oral histories and also lacks any definitive evidence.[21]\\r\\nIn the late 1880s, North Carolina state legislator Hamilton McMillan discovered that his \\"redbones\\" (those of Indian blood) neighbors in Robeson County claimed to have been descended from the Roanoke settlers. He also noticed that many of the words in their language had striking similarities to obsolete English words. Furthermore, many of the family names were identical to those listed in Hakluyt's account of the colony. Thus on February 10, 1885, convinced that these were the descendants of the Lost Colony, he helped to pass the \\"Croatan bill\\", that officially designated the population around Robeson county as Croatan.[25]:231ÿ33 Two days later on February 12, 1885, the Fayetteville Observer published an article regarding the Robeson people's origins. This article states:\\r\\nThey say that their traditions say that the people we call the Croatan Indians (though they do not recognize that name as that of a tribe, but only a village, and that they were Tuscaroras), were always friendly to the whites; and finding them destitute and despairing of ever receiving aid from England, persuaded them to leave [Roanoke Island], and go to the mainland... They gradually drifted away from their original seats, and at length settled in Robeson, about the center of the county...[29]\\r\\nHowever, the case was far from settled. A similar legend claims that the now extinct Saponi of Person County, North Carolina, are descended from the English colonists of Roanoke Island. However, no documented evidence exists to link the Saponi to the Roanoke colonists.\\r\\nOther tribes claiming partial descent from surviving Roanoke colonists include the Catawba (who absorbed the Shakori and Eno people), and the Coree and the people who call themselves the Lumbee. Samuel A'Court Ashe was convinced that the colonists had relocated westward to the banks of the Chowan River in Bertie County, and Conway Whittle Sams claimed that after being attacked by Wanchese and Powhatan, the colonists scattered to multiple locations: the Chowan River, and south to the Pamlico and Neuse Rivers.[25]:233\\r\\nAnother theory is that the Spanish destroyed the colony. Earlier in the century, the Spanish did destroy evidence of the French colony of Fort Charles in coastal South Carolina and then massacred the inhabitants of Fort Caroline, a French colony near present-day Jacksonville, Florida. However, a Spanish attack is unlikely, as the Spanish were still looking for the location of England's failed colony as late as 1600, ten years after White discovered that the colony was missing.[4]:137\\r\\nFrom 1937 to 1941, a series of inscribed stones were discovered that were claimed to have been written by Eleanor Dare, mother of Virginia Dare. They told of the travelings of the colonists and their ultimate deaths. Most historians believe that they are a fraud, but there are some today who still believe at least one of the stones to be genuine.[30]\\r\\nIn May 2011, Brent Lane of the First Colony Foundation was studying the Virginia Pars Map, which was made by John White during his 1585 visit to Roanoke Island, and noticed two patches where the map had been corrected. The patches are made of paper contemporaneous with that of the map. Lane asked researchers at the British Museum in London, where the map has been kept since 1866, what might be under the patches, sparking a research investigation. On May 3, 2012, at Wilson Library of the University of North Carolina at Chapel Hill, members of the Foundation and representatives of the museum announced the discovery of \\"a large, square-shaped symbol with oddly shaped corners.\\" This symbol, presumed to represent a fort, is visible when the map is viewed on a light box.[31] Some scholars speculate that the colonists relocated to that location, on what is now called Salmon Creek in the Bertie County community of Merry Hill. The Scotch Hall Preserve golf course community was planned on the site, but it has not been fully developed.[32]\\r\\nThe discovery of new information on the map led to more study of artifacts previously found, as well as additional digs in 2012 and 2014.[33]\\r\\nIn 1993, Hurricane Emily caused numerous relics to appear, and David Phelps of East Carolina University later began digging in the area and found evidence the settlers lived with the native people.[34]\\r\\nIn 1998, East Carolina University organized \\"The Croatoan Project\\", an archaeological investigation into the events at Roanoke. The excavation team sent to Hatteras Island uncovered what they believed to be a 10 karat (42%) gold 16th-century English signet ring, gun flints, and two copper farthings (produced sometime in the 1670s) at the site of the ancient Croatan capital, 50 miles (80?km) from the old Roanoke Colony. Genealogists were able to trace the lion crest on the signet ring to the Kendall coat of arms, and concluded that the ring most likely belonged to one Master Kendall who is recorded as having lived in the Roanoke Colony from 1585 to 1586. If this is the case, the ring represents the first material connection between the Roanoke colonists and the Native Americans on Hatteras Island.[35][36][37][38] However, archaeologist David Phelps did not have the ring tested, and Charles Ewen, who continued Phelps' work after Phelps retired, had the ring tested and found the ring was brass. Ewen announced his findings in April 2017. Mark Horton of the University of Bristol said he was not convinced that this news proved the ring did not date to the 16th century.[39]\\r\\nIt is also believed that the reason for the extreme deficiency in archaeological evidence is due to shoreline erosion. Since all that was found was a rustic looking fort on the north shore, and this location is well-documented and backed up, it is believed that the settlement must have been nearby. The northern shore, between 1851 and 1970, lost 928 feet (283 m) because of erosion. If in the years leading up to and following the brief life of the settlement at Roanoke, shoreline erosion was following the same trend, it is likely the site of the dwellings is underwater, along with any artifacts or signs of life.[40] Archaeological investigations continue to find tantalizing clues and funding is being sought to continue recent excavations.[41]\\r\\nIn 1998, a team led by climatologist David W. Stahle, of the University of Arkansas and archaeologist Dennis B. Blanton of the College of William and Mary used tree ring cores from 800-year-old bald cypresses taken from the Roanoke Island area of North Carolina and the Jamestown area of Virginia to reconstruct precipitation and temperature chronologies.\\r\\nThe researchers concluded that the settlers of the Lost Colony landed at Roanoke Island in the summer of the worst growing-season drought in 800 years. \\"This drought persisted for 3 years, from 1587 to 1589, and is the driest 3-year episode in the entire 800-year reconstruction,\\" the team reported in the journal Science. A map shows that \\"the Lost Colony drought affected the entire southeastern United States but was particularly severe in the Tidewater region near Roanoke [Island].\\" The authors suggested that the Croatan who were shot and killed by the colonists may have been scavenging the abandoned village for food as a result of the drought.[42][43]\\r\\nThe Lost Colony of Roanoke DNA Project was founded in 2007 by a group led by Roberta Estes, who owns a private DNA-testing company, in order to solve the mystery of the Lost Colony using historical records, migration patterns, oral histories and DNA testing. The project used Y chromosome, Mitochondrial DNA and Autosomal DNA.[44] As of 2016[update], they have not yet been able to positively identify any descendants of the colony.\\r\\nCoordinates: 355542N 754215W? / ?35.928259N 75.704098W? / 35.928259; -75.704098","input":"What is the lost colony in north carolina?"},{"output":"Alaska","context":"The Pacific States form one of the nine geographic divisions within the United States that are officially recognized by that country's census bureau.[11] There are five states in this division ÿ Alaska, California, Hawaii, Oregon, Washington ÿ and, as its name suggests, they all have coastlines on the Pacific Ocean (and are the only American states that border that ocean). The Pacific States division is one of two divisions that are located within the United States Census Bureau's Western region; the other Western division is the Mountain States.\\r\\nDespite being slotted into the same region by the Census Bureau, the Pacific and Mountain divisions are vastly different from one another in many vital respects, most notably in the arena of politics; while nearly all of the Mountain states are regarded as being conservative \\"red states\\", four out of five of the Pacific states (all except Alaska) are clearly counted among the liberal \\"blue states.\\"","input":"What are two states that border the pacific ocean?"},{"output":"October 22, 2014","context":"\\r\\n\\r\\nBluetooth 4.2\\r\\n\\r\\nThe iPad Air 2 is the second-generation iPad Air tablet computer designed, developed, and marketed by Apple Inc. It was announced on October 16, 2014 alongside the iPad Mini 3, both of which were released on October 22, 2014. The iPad Air 2 is thinner and faster than its predecessor, the iPad Air, and features Touch ID with the height and screen size the same as the iPad Air.\\r\\n\\r\\nThe iPad Air 2 was discontinued on March 21, 2017. Its successor, the 2017 iPad, was announced on the same day.[5]\\r\\n\\r\\nThe iPad Air 2 was announced during a keynote on October 16, 2014, and was the first iPad to feature Touch ID. The theme of the keynote was \\"it's been way too long\\".[6] The Air 2 began arriving in retail stores on October 22, 2014. The slogan for the device was Change Is in the Air. With the release of the new iPad Pro, the slogan for the device was changed to Light. Heavyweight.\\r\\n\\r\\nThe iPad Air 2 ships with the iOS 10 (formerly iOS 8, later iOS 9) operating system pre-installed and includes a version of Apple Pay with the in-store NFC functionality removed. The included Touch ID sensor allows the user to pay for items online without needing to enter the user's card details.\\r\\n\\r\\niOS 10 comes with several built-in applications, which are Camera, Photos, Messages, FaceTime, Mail, Music, Safari, Maps, Siri, Calendar, iTunes Store, App Store, Notes, Contacts, iBooks, Home, Reminders, Clock, Videos, News, Photo Booth and Podcasts. The Apple App Store, a digital application distribution platform for iOS, allows users to browse and download applications made by various developers from the iTunes Store. Additional apps made by Apple itself are available for free download, which are iMovie, GarageBand, iTunes U, Find My iPhone, Find My Friends, Apple Store, Trailers, Remote, and the iWork apps (Pages, Keynote, and Numbers).[7] Like all iOS devices, the iPad Air 2 can also sync content and other data with a Mac or PC using iTunes. Although the tablet is not designed to make phone calls over a cellular network, it can place and receive phone calls through an iPhone's cellular connection, using Apple's Continuity feature[8] (supported on iOS 8 and later versions of iOS, and OS X Yosemite and later versions of macOS), or using a VoIP application, such as Skype.\\r\\n\\r\\nOn June 8, 2015, it was announced at the WWDC that the iPad Air 2 would support all of iOS 9's new features when it is released in Q3 2015.[9] Air 2 users with iOS 9 will be able to use Slide Over, Picture in Picture and Split View. Slide Over allows a user to \\"slide\\" a second app in from the side of the screen in a smaller window, and have it display information alongside the initial app. Picture in Picture allows a user to watch video in a small, resizable, moveable window while remaining in another app. Split View allows a user to run two apps simultaneously in a 50/50 view.[10]\\r\\n\\r\\niPad Air 2 is 6.1mm compared to the iPad Air 7.5mm design\\r\\n\\r\\nThe iPad Air 2 inherits hardware that is similar to that which is in both the iPhone 6 and iPhone 6 Plus. One major change is its processor, the Apple A8X which is the high-end 3-core variant of the Apple A8. The iPad Air 2 has 2 GB RAM (making the iPad Air 2 the first iOS device to have more than 1 GB RAM) and the PowerVR GPU has 8 cores.[11] It also uses the Apple M8 motion co-processor which has a barometer and is the first generation of the iPad to inherit the fingerprint Touch ID sensor from the iPhone. In addition, compared to the iPad Air, it includes an improved 8-megapixel (3264G2448) rear-facing camera with 10 fps burst mode and slow motion video at 120 fps, similar to the iPhone 5S camera capabilities. The front-facing FaceTime HD camera has also been improved with a larger ?/2.2 aperture, which allows 81% more light in the image.[12] Apple added a gold option to the existing silver and space gray color choices for the iPad Air 2, the previous existing colors were used on the preceding iPad Air.\\r\\n\\r\\nUnlike its iPad predecessors, the mute/orientation lock switch has been removed to accommodate the reduced depth. Instead, the user must use the Control Center to access these functions. \\r\\n\\r\\nIt has a slightly smaller battery compared to the iPad Air but Apple claims the same 10-hour battery life as before. The iPad Air 2 is available in 16, 32, 64 or 128?GB storage options with no storage expansion options. Apple has released a \\"camera connection kit\\" with an SD card reader, but it can only be used to transfer photos and videos to an iPad.[13]\\r\\n\\r\\nThe Verge called the Air 2 \\"the best tablet ever made,\\" giving it a score of 9.3 out of 10 while noting that it offered only \\"iterative improvement\\" and that there were \\"missed opportunities\\" in its design.[14]","input":"When was the apple ipad air 2 released?"},{"output":"United States","context":"The Virgin Islands are the western island group of the Leeward Islands, which are the northern part of the Lesser Antilles, and form the border between the Caribbean Sea and the Atlantic Ocean. The archipelago is separated from the Renaissance Islands by the Anegada Passage and from the main island of Puerto Rico by the Virgin Passage.\\r\\nThe islands fall into three different political jurisdictions:\\r\\n\\r\\n\\r\\nChristopher Columbus named the islands after Saint Ursula and the 11,000 Virgins (Spanish: Santa ~rsula y las Once Mil Vrgenes), shortened to the Virgins (las Vrgenes). The official name of the British territory is the Virgin Islands, and the official name of the U.S. territory is the Virgin Islands of the United States. In practice, the two island groups are almost universally referred to as the British Virgin Islands and the U.S. Virgin Islands.\\r\\nThe Virgin Islands were originally inhabited by the Arawak, Carib, and Cermic, almost all of whom are thought to have perished during the colonial period due to enslavement, foreign disease, and mass extermination brought about by European colonists, as is the case in the rest of the Caribbean.[1]\\r\\nEuropean colonists later settled here and established sugar plantations, at least one tobacco plantation, and purchased slaves acquired from Africa. The plantations are gone, but the descendants of the slaves remain the bulk of the population, sharing a common African-Caribbean heritage with the rest of the English-speaking Caribbean.\\r\\nIn 1916 and 1917, Denmark and the U.S., respectively, ratified a treaty in which Denmark sold the Danish West Indies to the United States of America for $25 million in gold.\\r\\nIn the 1990s, a Puerto Rican tourism campaign renamed the Passage Islands as the Spanish Virgin Islands,[citation needed] though they are seldom[clarification needed] identified as such on maps and atlases.[citation needed] They are part of the Commonwealth of Puerto Rico, located east of the main island of Puerto Rico. They are closer to St. Thomas than St. Thomas is to St. Croix.\\r\\nMotor vehicles are driven on the left-hand side of the road in both the British and the U.S. Virgin Islands, although the steering wheels on most cars are located on the left side (as is the norm for drive-on-the-right localities). In the Spanish Virgin Islands, vehicles are driven on the right-hand side of the road.\\r\\nCoordinates: 18537N 644949W? / ?18.09361N 64.83028W? / 18.09361; -64.83028","input":"What two countries claim the virgin islands in the caribbean sea?"},{"output":"viruses","context":"In biology, cell theory is the historic scientific theory, now universally accepted, that living organisms are made up of cells, that they are the basic structural/organizational unit of all organisms, and that all cells come from pre-existing cells. Cells are the basic unit of structure in all organisms and also the basic unit of reproduction. With continual improvements made to microscopes over time, magnification technology advanced enough to discover cells in the 17th century. This discovery is largely attributed to Robert Hooke, and began the scientific study of cells, also known as cell biology. Over a century later, many debates about cells began amongst scientists. Most of these debates involved the nature of cellular regeneration, and the idea of cells as a fundamental unit of life. Cell theory was eventually formulated in 1839. This is usually credited to Matthias Schleiden and Theodor Schwann. However, many other scientists like Rudolf Virchow contributed to the theory. It was an important step in the movement away from spontaneous generation.\\r\\nThe three tenets to the cell theory are as described below:\\r\\nThe first of these tenets is disputed, as non-cellular entities such as viruses are sometimes considered life-forms.[1]\\r\\n\\r\\n\\r\\nThe discovery of the cell was made possible through the invention of the microscope. In the first century BC, Romans were able to make glass, discovering that objects appeared to be larger under the glass. In Italy during the 12th century, Salvino DArmate made a piece of glass fit over one eye, allowing for a magnification effect to that eye. The expanded use of lenses in eyeglasses in the 13th century probably led to wider spread use of simple microscopes (magnifying glasses) with limited magnification.[3] Compound microscope, which combine an objective lens with an eyepiece to view a real image achieving much higher magnification, first appeared in Europe around 1620[4][5] In 1665, Robert Hooke used a microscope about six inches long with two convex lenses inside and examined specimens under reflected light for the observations in his book Micrographia. Hooke also used a simpler microscope with a single lens for examining specimens with directly transmitted light, because this allowed for a clearer image.[6]\\r\\nExtensive microscopic study was done by Anton van Leeuwenhoek, a draper who took the interest in microscopes after seeing one while on an apprenticeship in Amsterdam in 1648. At some point in his life before 1668, he was able to learn how to grind lenses. This eventually led to Leeuwenhoek making his own unique microscope. His were a single lens simple microscope, rather than a compound microscope. This was because he was able to use a single lens that was a small glass sphere but allowed for a magnification of 270x. This was a large progression since the magnification before was only a maximum of 50x. After Leeuwenhoek, there was not much progress for the microscopes until the 1850s, two hundred years later. Carl Zeiss, a German engineer who manufactured microscopes, began to make changes to the lenses used. But the optical quality did not improve until the 1880s when he hired Otto Schott and eventually Ernst Abbe.[7]\\r\\nOptical microscopes can focus on objects the size of a wavelength or larger, giving restrictions still to advancement in discoveries with objects smaller than the wavelengths of visible light. Later in the 1920s, the electron microscope was developed, making it possible to view objects that are smaller than optical wavelengths, once again, changing the possibilities in science.[7]\\r\\nThe cell was first discovered by Robert Hooke in 1665, which can be found to be described in his book Micrographia. In this book, he gave 60 observations in detail of various objects under a coarse, compound microscope.[6] One observation was from very thin slices of bottle cork. Hooke discovered a multitude of tiny pores that he named \\"cells\\". This came from the Latin word Cella, meaning a small room like monks lived in and also Cellulae, which meant the six sided cell of a honeycomb. However, Hooke did not know their real structure or function.[8] What Hooke had thought were cells, were actually empty cell walls of plant tissues. With microscopes during this time having a low magnification, Hooke was unable to see that there were other internal components to the cells he was observing. Therefore, he did not think the \\"cellulae\\" were alive.[9] His cell observations gave no indication of the nucleus and other organelles found in most living cells. In Micrographia, Hooke also observed mould, bluish in color, found on leather. After studying it under his microscope, he was unable to observe seeds that would have indicated how the mould was multiplying in quantity. This led to Hooke suggesting that spontaneous generation, from either natural or artificial heat, was the cause. Since this was an old Aristotelian theory still accepted at the time, others did not reject it and was not disproved until Leeuwenhoek later discovers generation is achieved otherwise.[6]\\r\\nAnton van Leeuwenhoek is another scientist who saw these cells soon after Hooke did. He made use of a microscope containing improved lenses that could magnify objects almost 300-fold, or 270x.[9] Under these microscopes, Leeuwenhoek found motile objects. In a letter to The Royal Society on October 9, 1676, he states that motility is a quality of life therefore these were living organisms. Over time, he wrote many more papers in which described many specific forms of microorganisms. Leeuwenhoek named these animalcules, which included protozoa and other unicellular organisms, like bacteria.[7] Though he did not have much formal education, he was able to identify the first accurate description of red blood cells and discovered bacteria after gaining interest in the sense of taste that resulted in Leeuwenhoek to observe the tongue of an ox, then leading him to study \\"pepper water\\" in 1676. He also found for the first time the sperm cells of animals and humans. Once discovering these types of cells, Leeuwenhoek saw that the fertilization process requires the sperm cell to enter the egg cell. This put an end to the previous theory of spontaneous generation. After reading letters by Leeuwenhoek, Hooke was the first to confirm his observations that were thought to be unlikely by other contemporaries.[6]\\r\\nThe cells in animal tissues were observed after plants were because the tissues were so fragile and susceptible to tearing, it was difficult for such thin slices to be prepared for studying. Biologists believed that there was a fundamental unit to life, but were unsure what this was. It would not be until over a hundred years later that this fundamental unit was connected to cellular structure and existence of cells in animals or plants.[10] This conclusion was not made until Henri Dutrochet. Besides stating the cell is the fundamental element of organization,[11] Dutrochet also claimed that cells were not just a structural unit, but also a physiological unit.\\r\\nIn 1804, Karl Rudolphi and J.H.F. Link were awarded the prize for \\"solving the problem of the nature of cells\\", meaning they were the first to prove that cells had independent cell walls by the K?nigliche Societ?t der Wissenschaft (Royal Society of Science), G?ttingen.[12] Before, it had been thought that cells shared walls and the fluid passed between them this way.\\r\\nCredit for developing cell theory is usually given to two scientists: Theodor Schwann and Matthias Jakob Schleiden.[13] While Rudolf Virchow contributed to the theory, he is not as credited for his attributions toward it. In 1839, Schleiden suggested that every structural part of a plant was made up of cells or the result of cells. He also suggested that cells were made by a crystallization process either within other cells or from the outside.[14] However, this was not an original idea of Schleiden. He claimed this theory as his own, though Barthelemy Dumortier had stated it years before him. This crystallization process is no longer accepted with modern cell theory. In 1839, Theodor Schwann states that along with plants, animals are composed of cells or the product of cells in their structures.[15] This was a major advancement in the field of biology since little was known about animal structure up to this point compared to plants. From these conclusions about plants and animals, two of the three tenets of cell theory were postulated.[10]\\r\\n1. All living organisms are composed of one or more cells\\r\\n2. The cell is the most basic unit of life\\r\\nSchleiden's theory of free cell formation through crystallization was refuted in the 1850s by Robert Remak, Rudolf Virchow, and Albert Kolliker.[7] In 1855, Rudolf Virchow added the third tenet to cell theory. In Latin, this tenet states Omnis cellula e cellula.[10] This translated to:\\r\\n3. All cells arise only from pre-existing cells\\r\\nHowever, the idea that all cells come from pre-existing cells had in fact already been proposed by Robert Remak; it has been suggested that Virchow plagiarized Remak and did not give him credit.[16] Remak published observations in 1852 on cell division, claiming Schleiden and Schawnn were incorrect about generation schemes. He instead said that binary fission, which was first introduced by Dumortier, was how reproduction of new animal cells were made. Once this tenet was added, the classical cell theory was complete.\\r\\nThe generally accepted parts of modern cell theory include:\\r\\nThe modern version of the cell theory includes the ideas that:\\r\\nThe cell was first discovered by Robert Hooke in 1665 using a microscope. The first cell theory is credited to the work of Theodor Schwann and Matthias Jakob Schleiden in the 1830s. In this theory the internal contents of cells were called protoplasm and described as a jelly-like substance, sometimes called living jelly. At about the same time, colloidal chemistry began its development, and the concepts of bound water emerged. A colloid being something between a solution and a suspension, where Brownian motion is sufficient to prevent sedimentation. The idea of a semipermeable membrane, a barrier that is permeable to solvent but impermeable to solute molecules was developed at about the same time. The term osmosis originated in 1827 and its importance to physiological phenomena realized, but it wasnt until 1877, when the botanist Pfeffer proposed the membrane theory of cell physiology. In this view, the cell was seen to be enclosed by a thin surface, the plasma membrane, and cell water and solutes such as a potassium ion existed in a physical state like that of a dilute solution. In 1889 Hamburger used hemolysis of erythrocytes to determine the permeability of various solutes. By measuring the time required for the cells to swell past their elastic limit, the rate at which solutes entered the cells could be estimated by the accompanying change in cell volume. He also found that there was an apparent nonsolvent volume of about 50% in red blood cells and later showed that this includes water of hydration in addition to the protein and other nonsolvent components of the cells.\\r\\nTwo opposing concepts developed within the context of studies on osmosis, permeability, and electrical properties of cells.[21] The first held that these properties all belonged to the plasma membrane whereas the other predominant view was that the protoplasm was responsible for these properties. The membrane theory developed as a succession of ad-hoc additions and changes to the theory to overcome experimental hurdles. Overton (a distant cousin of Charles Darwin) first proposed the concept of a lipid (oil) plasma membrane in 1899. The major weakness of the lipid membrane was the lack of an explanation of the high permeability to water, so Nathansohn (1904) proposed the mosaic theory. In this view, the membrane is not a pure lipid layer, but a mosaic of areas with lipid and areas with semipermeable gel. Ruhland refined the mosaic theory to include pores to allow additional passage of small molecules. Since membranes are generally less permeable to anions, Leonor Michaelis concluded that ions are adsorbed to the walls of the pores, changing the permeability of the pores to ions by electrostatic repulsion. Michaelis demonstrated the membrane potential (1926) and proposed that it was related to the distribution of ions across the membrane.[22] Harvey and Danielli (1939) proposed a lipid bilayer membrane covered on each side with a layer of protein to account for measurements of surface tension. In 1941 Boyle & Conway showed that the membrane of frog muscle was permeable to both K+ and Cl?, but apparently not to Na+, so the idea of electrical charges in the pores was unnecessary since a single critical pore size would explain the permeability to K+, H+, and Cl? as well as the impermeability to Na+, Ca+, and Mg2+. Over the same time period, it was shown (Procter & Wilson, 1916) that gels, which do not have a semipermeable membrane, would swell in dilute solutions. Loeb (1920) also studied gelatin extensively, with and without a membrane, showing that more of the properties attributed to the plasma membrane could be duplicated in gels without a membrane. In particular, he found that an electrical potential difference between the gelatin and the outside medium could be developed, based on the H+ concentration. Some criticisms of the membrane theory developed in the 1930s, based on observations such as the ability of some cells to swell and increase their surface area by a factor of 1000. A lipid layer cannot stretch to that extent without becoming a patchwork (thereby losing its barrier properties. Such criticisms stimulated continued studies on protoplasm as the principal agent determining cell permeability properties. In 1938, Fischer and Suer proposed that water in the protoplasm is not free but in a chemically combined formthe protoplasm represents a combination of protein, salt and waterand demonstrated the basic similarity between swelling in living tissues and the swelling of gelatin and fibrin gels. Dimitri Nasonov (1944) viewed proteins as the central components responsible for many properties of the cell, including electrical properties. By the 1940s, the bulk phase theories were not as well developed as the membrane theories. In 1941, Brooks & Brooks published a monograph, \\"The Permeability of Living Cells\\", which rejects the bulk phase theories.\\r\\nWith the development of radioactive tracers, it was shown that cells are not impermeable to Na+. This was difficult to explain with the membrane barrier theory, so the sodium pump was proposed to continually remove Na+ as it permeates cells. This drove the concept that cells are in a state of dynamic equilibrium, constantly using energy to maintain ion gradients. In 1935, Karl Lohmann discovered ATP and its role as a source of energy for cells, so the concept of a metabolically-driven sodium pump was proposed. The tremendous success of Hodgkin, Huxley, and Katz in the development of the membrane theory of cellular membrane potentials, with differential equations that modeled the phenomena correctly, provided even more support for the membrane pump hypothesis.\\r\\nThe modern view of the plasma membrane is of a fluid lipid bilayer that has protein components embedded within it. The structure of the membrane is now known in great detail, including 3D models of many of the hundreds of different proteins that are bound to the membrane. These major developments in cell physiology placed the membrane theory in a position of dominance and stimulated the imagination of most physiologists, who now apparently accept the theory as factthere are, however, a few dissenters.[citation needed]\\r\\nIn 1956, Afanasy S. Troshin published a book, The Problems of Cell Permeability, in Russian (1958 in German, 1961 in Chinese, 1966 in English) in which he found that permeability was of secondary importance in determination of the patterns of equilibrium between the cell and its environment. Troshin showed that cell water decreased in solutions of galactose or urea although these compounds did slowly permeate cells. Since the membrane theory requires an impermanent solute to sustain cell shrinkage, these experiments cast doubt on the theory. Others questioned whether the cell has enough energy to sustain the sodium/potassium pump. Such questions became even more urgent as dozens of new metabolic pumps were added as new chemical gradients were discovered.\\r\\nIn 1962, Gilbert Ling became the champion of the bulk phase theories and proposed his association-induction hypothesis of living cells.\\r\\nCells can be subdivided into the following subcategories:\\r\\nAnimals have evolved a greater diversity of cell types in a multicellular body (100ÿ150 different cell types), compared with 10ÿ20 in plants, fungi, and protoctista.[25]","input":"What is one exception to the cell theory?"},{"output":"Master Sergeant","context":"The chart below represents the current enlisted rank insignia of the United States Air Force.\\r\\n\\r\\nWhile all Air Force military personnel are referred to as Airmen, it can specifically refer to the pay grades of E-1 through E-4 which are below the level of non-commissioned officers (NCOs).[1]  Above the pay grade of E-4 (E-5 through E-9) all ranks fall into the category of NCO and are further subdivided into NCOs (E-5 & E-6) and Senior NCOs (E-7 through E-9); the term Junior NCO is sometimes used to refer to staff sergeants and technical sergeants (E-5 & E-6).[1]\\r\\n\\r\\nThe Air Force is the only one of the five branches of the United States military where NCO status is now only achieved at the grade of E-5.  Formerly, the grade of Sergeant was obtained after a time as a Senior Airman and successful completion of the Air Force NCO School. In all other branches, NCO status can be achieved at the grade of E-4 (a Corporal in the Army and Marine Corps, Petty Officer Third Class in the Navy and Coast Guard). However, E-4s in the Army with the rank of Specialist are not NCOs.  The Air Force mirrored the Army from 1976 to 2 May 1991 with an E-4 being either a Senior Airman wearing three stripes without a star or a Sergeant (informally referred to as \\"Buck Sergeant\\") which was noted by the presence of the central star and considered an NCO.[2]  Despite not being an NCO, a Senior Airman who has completed Airman Leadership School can be a supervisor.[1]\\r\\n\\r\\nAlthough the Air Force became an independent service with the National Security Act of 1947, it retained the Army Air Force rank structure and corresponding insignia of years past.  This rank structure provided for seven enlisted ranks: Private, Private First Class, Corporal/Technician Fifth Grade, Sergeant/Technician Fourth Grade, Staff Sergeant/Technician Third Grade, Technical Sergeant and Master Sergeant/First Sergeant.  Additionally, Air Force personnel were still referred to as soldiers.[2] During the Second World War, many USAAF NCOs wore the Army Air Corps branch insignia of the winged propeller underneath their chevrons.[3]\\r\\n\\r\\nChanges to the rank structure were proposed almost immediately but did not start occurring until the next year.  Sometime during late 1947 and early 1948, new chevron designs were tested at Bolling Air Force Base.  The style preferred was the one used today, the inverted chevron.  Air Force Chief of Staff General Hoyt Vandenberg approved the new chevron on 9 March 1948.[2] A new Air Force \\"Uxbridge Blue\\" uniform and black leather replaced the US Army Air Corps Olive Drab uniform and russet leather in 1949. Air Force personnel were allowed to wear their old Army World War Two pattern uniforms and rank insignia until July, 1952. Recolored \\"hash marks\\" and Overseas Service Bars were worn on the uniform until 1957. \\r\\n\\r\\nAlthough the new chevrons were approved, the titles did not change.  Two years would pass (February 1950) before General Vandenberg ordered all enlisted personnel in the Air Force be referred to as \\"airman\\" (singular) and \\"airmen\\" (plural) rather than \\"soldier.\\".  A further two years would go by while the enlisted rank structure was studied and changes proposed.  The end results finally became effective on 24 April 1952 with the release of a revised Air Force Regulation (AFR) 39-36.  This revision changed the names of the enlisted ranks to Basic Airman, Airman Third Class, Airman Second Class, Airman First Class (with resultant loss of NCO status that was not restored until 1967), Staff Sergeant, Technical Sergeant and Master Sergeant.[2]\\r\\n\\r\\nWith the new titles came a proposal for new rank insignia for Airman Third Class through Airman First Class.  The proposed insignia would have horizontal stripes for Airman Third Class through Airman First Class while NCOs keep their inverted chevrons. The purpose of the two different types of insignia was to more readily differentiate the airman and NCO tiers while increasing the prestige of the latter.  These were not approved at the time of the release of the revised regulation.  When they were finally approved by General Vandenberg in December 1952, procurement of these stripes was deferred until approximately June 1955.  This change would eventually be reversed, on 12 March 1956, by General Vandenberg's successor, General Twining.[2]\\r\\n\\r\\nDuring his tenure, General Twining also approved the diamond insignia for First Sergeants.  This became available on 21 September 1955.[2]  With this approval, the foundations of the first seven ranks and insignia the Air Force uses today were in place.\\r\\n\\r\\nThe next major change came with the Military Pay Act of 1958.  This established the pay grades of E-8 and E-9 but without corresponding rank titles.  The titles of Senior Master Sergeant and Chief Master Sergeant were chosen between July and December 1958 after comments were solicited from the major Air Force commands of the day.  After much discussion, the insignia for these two ranks were designed by simply adding one and two chevrons to the top of the Master Sergeant insignia (for E-8 and E-9 respectively), each stripe pointing up.[2]\\r\\n\\r\\nThe rank of Basic Airman was renamed Airman Basic on 5 February 1959, still with no insignia attached.[2]\\r\\n\\r\\nThe next series of changes to Air Force enlisted ranks did not occur for almost eight years.  In January 1967 the position of Chief Master Sergeant of the Air Force was created.  This position gained its own special insignia, the Chief Master Sergeant chevrons with a wreath encircling the center star.  On 1 August 1967 the lower enlisted rank names changed (revised AFR 39-36 on 19 October 1967) renamed Airman Third Class, Airman Second Class and Airman First Class to Airman, Airman First Class and Sergeant (known unofficially as \\"Buck Sergeant\\" by the NCO ranks at the time) respectively.  This returned Sergeant to the rank structure as the first step in the NCO tier as a retention move but required achievement of a 5-skill Air Force Specialty Code (AFSC) level.  No changes to the respective insignias were made.[2] Footnote: On 1 July 1969 the Air Force Serial Number was changed to the member's Social Security Number (SSAN). This change was for all grades and the three major US military forces including guard and reserve components. The commandant of the USMC did not adopt the serial number change to his forces. \\r\\n\\r\\nIn a 30 December 1975 directive the grade of Sergeant was split into two separate ranks while retaining the grade of E-4.  Senior Airman would be the last junior enlisted tier rank while Sergeant would remain the first rank in the NCO tier.  The impetus behind this was to laterally promote senior E-4 airmen who were ready for NCO responsibilities but not prepared to take on the role of a Staff Sergeant. This permitted airmen who had not yet reached the AFSC 5-skill level to achieve the pay grade of E-4, while according those who had NCO status. To differentiate the two ranks, the directive changed the silver star in the center of Airman, Airman First Class and Senior Airman changed to blue while the star on Sergeant chevrons remained silver.  Having two ranks within one grade mirrored the Army's Specialist/Corporal division of E-4.  This dual role would last until March 1991 when then Chief of Staff General McPeak terminated the rank of Sergeant effective 2 May 1991.  This termination was due in part to the manning reductions that occurred in the postÿCold War drawdowns of the early 1990s.  The last of the \\"Buck Sergeants\\" would have either been promoted or discharged under High Year Tenure by December 1998.[2]\\r\\n\\r\\nThe year 1991 also saw the last major change to the enlisted rank insignia.  In October 1991 General McPeak and Chief Master Sergeant of the Air Force Pfingston announced that the senior NCO tier would have new chevron layouts and that all chevrons would have a white star in the center.  The change in senior NCO chevrons was the first since chevrons came into being in 1948.  Until that time, Master Sergeant had been composed of six inverted chevrons (six down) with none pointing up, Senior Master Sergeant six down with one up and Chief Master Sergeant six down with two up.  The new layout changed the insignia to the current layout (see chart above).  The second change, changing the star color to white, was actually two changes in one.  It added a star to the Airman through Senior Airman rank insignias where there had been none since 1975 (the blue star carried by these chevrons was the same color as the blue in the stripes giving the impression that the star was not there) and changing the silver star on the NCO and senior NCO chevrons to white.[2]\\r\\n\\r\\nIn November 1998, the duty position of Senior Enlisted Advisor was changed to Command Chief Master Sergeant.  Along with the change, the addition of a star in the empty blue area between the chevrons was added to denote those holding this position.\\r\\n\\r\\nIn November 2004, the Chief Master Sergeant of the Air Force insignia was updated to include the Great Seal of the United States with a white star on either side.  These additions were placed in the empty blue area between the chevrons.","input":"What is an e7 in the air force?"},{"output":"1 October 2007","context":"The Equality and Human Rights Commission (EHRC) is a non-departmental public body in England and Wales, established by the Equality Act 2006 with effect from 1 October 2007. The Commission has responsibility for the promotion and enforcement of equality and non-discrimination laws in England, Scotland and Wales. It took over the responsibilities of the Commission for Racial Equality, the Equal Opportunities Commission and the Disability Rights Commission. It also has responsibility for other aspects of equality law: age, sexual orientation and religion or belief. A national human rights institution, it seeks to promote and protect human rights in England and Wales.\\r\\nThe EHRC has offices in Manchester, London, Glasgow and Cardiff. It is a non-departmental public body (NDPB) sponsored by the Government Equalities Office, part of the Department for Education (DfE). It is separate from and independent from Government but accountable for its use of public funds. The Chairman of the Commission is David Isaac.[1]\\r\\nThe EHRC's functions do not extend to Northern Ireland, where there is a separate Equality Commission (ECNI) and a Human Rights Commission (NIHRC), each established under the terms of the Belfast Agreement.\\r\\n\\r\\n\\r\\nThe EHRC derives its powers from the Equality Act 2006, which resulted from the government white paper, Fairness for All: A New Commission for Equality and Human Rights.[2] Section 3 states the EHRC has a general duty to work towards the development of a society where equality and rights are rooted. This is taken to mean,\\r\\n(a) people's ability to achieve their potential is not limited by prejudice or discrimination,\\r\\n(b) there is respect for and protection of each individual's human rights (including respect for the dignity and worth of each individual),\\r\\n(c) each person has an equal opportunity to participate in society, and\\r\\n(d) there is mutual respect between communities based on understanding and valuing of diversity and on shared respect for equality and human rights.\\r\\nSection 30 strengthens the EHRC's ability to apply for judicial review and to intervene in court proceedings, through giving explicit statutory provision for such action. Sections 31ÿ2 gives the EHRC a new power to assess public authorities' compliance with their positive equality duties. It can issue \\"compliance notices\\" if it finds a public authority is failing in its duties. Public authorities, importantly, are bound under the Human Rights Act 1998 to act in a way compatible with the European Convention on Human Rights (s.6 HRA). The EHRC's role is therefore one of catching matters before they lead to the courts. So if you work for a public sector employer (like a local council or the civil service) there are more avenues to enforce equality standards in your favour. This may seem somewhat odd, considering that public sector employers are consistently shown to have excellent workplace practices.[3] Section 30(3) of the Equality Act 2006 allows the EHRC to bring judicial review proceedings under the HRA against public authorities. This is a stronger tool than usual, because the EHRC is not subject to the normal requirement of being a \\"victim\\" of a Human Rights violation.[4]\\r\\nUnder section 24, the EHRC can enter into binding agreements with employers. So for instance, it can agree that an employer will commit to equality best practice audits or avoid discriminatory practices that it may identify, in return for not investigating (a bad thing for employers' publicity). It can enforce these agreements through injunctions. Previously only the Disability Rights Commission had such powers, the CRE and the EOC were more limited. For instance, the EOC used only to have the power to get injunctions against bodies with a bad track record of discrimination.[5]\\r\\nSection 20 gives the EHRC the power to carry out investigations when it has the \\"suspicion\\" of unlawful discrimination taking place. Before this had been limited to a requirement of \\"reasonable suspicion\\" which in effect led the predecessors to be much more cautious. In legal terms this is the difference between an irrationality test and a reasonable man test. In other words, a court could not declare an investigation unlawful unless it considered that the EHRC was carrying out an investigation where no reasonable person could have come to the same conclusion. Before a court could declare an investigation unlawful if it thought that the proverbial \\"man on the Clapham Omnibus\\" would not regard an employer as being a suspect \\"discriminator\\".\\r\\nThere are some complications in relation to the Human Rights Act 1998 with the EHRC's powers. If it is going to be a \\"named investigation\\" (i.e. the employer will probably get shamed by the publication of its name during an investigation), the EHRC cannot start an investigation into a public authority for breaches under the HRA. Also, it cannot support individual cases in tribunals and courts where the issue would concern matters that fall only under the HRA and not under some pre-existing British equality legislation (like the Sex Discrimination Act 1975). Practically this will be problematic, not least because if a claim did exist under the HRA, British legislation which did not cover such problems would usually be updated to comply with European Convention rights (these are the ones that the HRA implements). Also, the line between what is in the European Convention, what is actually covered by domestic legislation, is difficult to draw. At any rate, section 28 gives the Minister the power to give authorisation for a discrimination case to be fought if a domestic legislation issue has dropped away, but a purely human rights issue remains.\\r\\nAs a successor body, the EHRC's new powers are not dramatic. Some people have called for the changes to go further, for instance, to allow the EHRC to bring proceedings against employers in its own name on any issue (not just human rights ones).[6] The American, Australian, Belgian, Canadian and New Zealand counterparts can.\\r\\nAlthough it operates at sub-national level, the EHRC was in 2009 recognised as a member of the worldwide network of national human rights institutions, securing \\"A status\\" accreditation from the International Co-ordinating Committee of NHRIs (ICC). This gives the Commission enhanced access to the Human Rights Council, treaty bodies and other United Nations human rights bodies. The EHRC was the second NHRI in the UK, following the creation of the Northern Ireland Human Rights Commission (NIHRC) in 1999, and the Scottish Human Rights Commission (SHRC) became the third to gain ICC accreditation in 2010. The three bodies share representation and voting rights in the ICC and its regional network, the European Group of NHRIs.\\r\\nThe EHRC has since 2008 engaged in parallel reporting (\\"shadow reporting\\") at examinations of the UK under the UN and Council of Europe human rights treaties, and in the Universal Periodic Review. It was designated in 2008 as part of the United Kingdom's independent mechanism for promoting, monitoring and protecting implementation in the state of the United Nations Convention on the Rights of Persons with Disabilities (CRPD). (It shares that role with the other two NHRIs in the UK ÿ the NIHRC and SHRC ÿ and the Equality Commission for Northern Ireland.) The EHRC chairs the CRPD Working Group of the European Group of NHRIs.\\r\\nWorking Better The Working Better Initiative was launched with a remit of coming up with innovative ways to meet the needs of modern workforce, with a particular focus on flexibility and family life. The Home Front survey[7] formed part of the initial consultation process.\\r\\nGood Relations The Commission aims to provide research and resources and advice to Local Authorities and to enable greater understanding between communities.\\r\\nCare and Support A report[8] produced by the Commission highlighted the need to shift from a \\"safety net\\" approach to care to a \\"springboard\\". The report suggested ways that individuals could be given greater autonomy over their lives and encouraged to engage in society and make social and economic contributions.\\r\\nFollowing the election of 2 MEPs from the British National Party (BNP), a potential issue of public funding was raised by the commission as the BNP constitution states that recruitment is only open to members who are \\"indigenous Caucasian and defined ethnic groups emanating from that Race\\"[9] The Commission's legal director John Wadham has stated that\\r\\n\\"The legal advice we have received indicates that the British National party's constitution and membership criteria, employment practices and provision of services to constituents and the public may breach discrimination laws which all political parties are legally obliged to uphold\\"[10]\\r\\nThis relates to the Race Relations Act 1976,[10] which outlaws the refusal or deliberate omission to offer employment on the basis of non-membership of an organisation. The commission sent a letter to the BNP giving them until 20 July to provide written undertakings that there will not be discrimination in its recruitment procedures.[10] The BNP responded to the letter by stating that it \\"intends to clarify the word 'white' on its website\\".[11] However, because the commission believes the BNP will continue to discriminate against potential or actual members on racial grounds, on 24 August 2009 the commission announced that they had issued county court proceedings against the BNP.[11][12] In a statement the commission reduced the grounds on which it was taking action against the BNP, stating\\r\\n\\"The Commission believes the BNP's constitution and membership criteria are discriminatory and, further, that the continued publication of them on the BNP website is unlawful. It has therefore issued county court proceedings against party leader Nick Griffin and two other officials. The Commission has decided not to take action on two further grounds set out in its letter before action in the light of the BNP's commitment to comply with the law.\\"[11]\\r\\nThe Commission is made up of 10 commissioners with backgrounds in various fields of equality and human rights. As of August 2016[update] they are:[13]\\r\\nSome of the first set of Commissioners resigned towards the end of their first term, while others did not seek a second term. The Commissioners included Morag Alexander, Kay Allen, Baroness Campbell of Surbiton, Jeannie Drake CBE, Joel Edwards, Mike Smith, Professor Kay Hampton, Francesca Klug, Sir Bert Massie CBE, Ziauddin Sardar, Ben Summerskill and Dr Neil Wooding. Nicola Brewer, the first chief executive (and ex officio Commissioner), returned to the diplomatic service.\\r\\nSix staff were sacked by email on 9 February 2017 and given a day to clear their desks. Since then another two staff have been dismissed and two Directors are serving their notice. Another member of staff is still at risk of dismisal. Those sacked on 9 February had payment in lieu of notice (PILON) which workers did not agree to because it closes off the opportunity to seek redeployment at the Commission or elsewhere in the civil service. In a letter the union stated: By imposing PILON you are cutting off this option and effectively consigning BME, disabled, women and trade union members to unemployment. There should only be PILON in cases where the individual concerned has agreed to it. Commenting on the cases, PCS general secretary Mark Serwotka said: Its absolutely reprehensible that dedicated staff have been sacked and told to clear their desks with a days notice. That this has happened at the government body charged with upholding human rights and fair treatment in our society is an absolute scandal and we will continue to fight it.[15]\\r\\nThe EHRC has four offices: in London (in Salisbury Square, EC4), in Manchester (in the Arndale Centre), in Cardiff (in Gabalfa), and in Glasgow (on West George Street).[16]","input":"When was the equality and human rights commission established?"},{"output":"Harry Burnett \\"H. B.\\" Reese","context":"Harry Burnett \\"H. B.\\" Reese (May 24, 1879 ÿ May 16, 1956) was an American inventor and businessman known for creating the No. 1 selling candy brand in the United States, Reese's Peanut Butter Cups[1] and founding the H.B. Reese Candy Company.[2] In 2009, he was posthumously inducted into the Candy Hall of Fame.[3]\\r\\n\\r\\nH.B. Reese was born on May 24, 1879 on the Frosty Hill Farm, an agricultural and dairy farm located near the Muddy Creek Forks Historic District in York County, Pennsylvania.[2] He was the only child of Annie Belinda Manifold (1854ÿ1935) and Aquilla Asbury Reese Jr. (1845ÿ1914). When it came to earning money as a young man, Reese was creative. He farmed the land, but also milked cows because doing so was a quick way to earn cash. He even built a pond where he raised frogs that he sold to restaurants in the Baltimore area. By 1898, Reese was an accomplished French horn player who performed with local area bands.[4]\\r\\n\\r\\nOn August 1, 1900 Reese married Blanche Edna Hyson (1882ÿ1968), the daughter of Mary Elizabeth Markey (1857ÿ1952) and Robert Bortner Hyson (1853ÿ1930). Together they had 16 children, 8 daughters and 8 sons (13 of whom survived to adulthood).[5]\\r\\n\\r\\nA true family man, Reese's mother Annie Belinda Manifold (1854ÿ1935) as well as her two sisters, Elizabeth Turner Manifold (1846-1910) and Mary Collins Manifold (1847-1933), lived with him for the rest of their lives. At least 20 family members were present during a typical Reese family supper and sometimes more than 40 people were present when friends and relatives were invited to join them.[4]\\r\\n\\r\\nBy 1903, Reese was managing the fishing operations of his father-in-laws cannery business located in Ditchley, Virginia. In 1912 he managed a dairy farm in Woodbine, Pennsylvania, but took a factory job in New Freedom, Pennsylvania in 1915 to support his growing family.[6]\\r\\n\\r\\nIn 1916, Reese read an employment ad in the York Daily Record by Milton S. Hershey seeking to hire people to manage and operate his numerous dairy farms that were located in the Hershey, Pennsylvania area. In 1917, Hershey hired Reese to work as a dairyman at Farm 28-A. In 1918, Hershey asked Reese to manage a dairy farm called the Round Barn. Milton Hershey visited the Round Barn every two weeks because it was an experimental dairy farm that used new milking machines (more efficient than milking cows by hand) as he sought new approaches to animal treatment and milk production. However by 1919, Hershey found the Round Barn too expensive to operate and closed it down.[6]\\r\\n\\r\\nJobless in 1919, Reese formed a new business called the R&R Candy Company that he operated from an old canning factory located in Hummelstown, Pennsylvania where he manufactured milk chocolate covered almonds and raisins, selling them to local stores.[7]\\r\\n\\r\\nReese knew he needed high-quality manufacturing equipment in order to boost the potential of his Hummelstown, Pennsylvania candy business. So in January, 1920 he reorganized the R&R Candy Company as the Superior Chocolate and Confectionery Company and proceeded to raise today's equivalent of $290,000 by issuing stock in the newly formed company. A State charter for the new company was issued on May 14, 1920 with the following company officers:[8]\\r\\n\\r\\nNonetheless, the business ultimately failed.[9]\\r\\n\\r\\nUnder pressure to support his 10-children with yet another baby on the way, Reese took a paper mill job in Spring Grove, Pennsylvania where he worked a second job as a butcher and also a third job canning vegetables.[7]\\r\\n\\r\\nIn 1921, Reese's father-in-law purchased a home at 18 E. Areba Avenue in Hershey, Pennsylvania for his son-in-law's growing family. With his return to Hershey, Reese began working at The Hershey Company factory in the shipping department and was soon promoted to foreman.[9]\\r\\n\\r\\nOn the side, working from the basement of his Areba Avenue home, he made a variety of confectionery products including hard candy, chocolate covered nut (fruit) and raisins, mint (candy) as well as two popular milk chocolate covered caramel-coconut candy bars that he invented:[10]\\r\\n\\r\\nThe ingredients for both bars included fresh grated coconut, caramel, molasses, cocoa butter and honey. The main difference between the two bars was that the Johnny Bar had Nut (fruit) as an ingredient. From the very beginning, Reese used chocolate manufactured by The Hershey Company for his chocolate coatings.[11]\\r\\n\\r\\nReese enjoyed enough success to finally quit his factory job at The Hershey Company and set out on his own to \\"make a living\\" manufacturing candy.[6]\\r\\n\\r\\nReese incorporated the H.B. Reese Candy Company in 1923. Selling a large assortment of candies on consignment, his employees coated by hand each piece of candy on marble slabs, some coated with milk chocolate and others with dark chocolate that were placed in two-pound and five-pound boxes that were sold in department store candy displays. To promote sales, Reese set up special coating tables in the front display windows of large, downtown department stores and had his employees coat candies in full view of shoppers passing by while other employees handed out freshly made samples.[12]\\r\\n\\r\\nHere's a brief list of the candy initially manufactured by the H.B. Reese Candy Company. They were made with ingredients such as real cocoa butter, fresh cream, fresh grated coconut and freshly roasted peanuts:[4]\\r\\n\\r\\nNote: *These 12-candies were sold in five-pound boxes during the holiday season.[4]\\r\\n\\r\\nBorrowing money from a York County, Pennsylvania bank in 1926, Reese built a large home and a new factory that were  located next to each other at 203-205 W Caracas Ave in Hershey, Pennsylvania. By 1935, he had 62 employees as well as his 6 sons working for him and was so successful that he was able to pay off all his mortgages.[13]\\r\\n\\r\\nBy 1928, H.B. (Poppy Reese) and Blanche (Mommy Reese) had sixteen children. That same year, H.B. Reese invented Reese's Peanut Butter Cups which became part of his assorted chocolate line.[9]\\r\\n\\r\\n\\"In late 1927, H.B. was delivering some of his candy to a store in Harrisburg, Pennsylvania, the Bluebird Candy Shop. The owner of the shop was having problems with another supplier who could not keep him supplied with a candy made of peanut butter covered with chocolate. He asked H.B. if he could supply him with something like that. H.B. saw an opportunity and with considerable persistence, seized it. H.B. originally rolled the peanut butter into a small ball and dipped it into chocolate; the peanut butter manufacturing process was easy to automate, and the cup was used to help that process, since it provided a small compartment for each item. The candy was quickly added to the assortment box in 1928.\\"[4]\\r\\n\\r\\nSoon the company was packaging 120 individually wrapped pieces per box that sold for a penny per cup. The penny peanut butter cup was the candy that helped Reese pay off the mortgages on both his house and factory by 1935. This was especially noteworthy since the United States was still in the grip of the Great Depression and chocolate was considered a luxury.[4]\\r\\n\\r\\nDuring World War II, economic constraints and scarcity of materials led him to discontinue his other candies and concentrate solely on his Peanut butter cup, his most popular offering.[citation needed]\\r\\n\\r\\nThroughout the war, Reese built his company based on the success of a single product, Reese's Peanut Butter Cups. And instead of selling the product by weight, peanut butter cups were packaged for retail sale with each candy wrapper prominently displaying the slogan: \\"Made in Chocolate Town, So They Must Be Good\\". Additionally in 1943, the five-cent cup was introduced and as packaging machine and plant automation were placed into production, the sales of Reese's Peanut Butter Cups doubled every four years.[14]\\r\\n\\r\\nBefore H.B. Reese died in 1956, he began construction of a second plant located at 925 Reese Avenue, Hershey, Pennsylvania. Completed on November 30, 1957, this new modern plant contained 100,000 square feet of state-of-the-art manufacturing technology built at a cost equivalent of $6.9 million at a time when the sales of Reese's Peanut Butter Cups were equivalent to $125 million.[15]\\r\\n\\r\\nAfter a short illness, H.B. Reese died of a Myocardial infarction[16] on May 16, 1956 at the St. Mary's Medical Center located in West Palm Beach, Florida (where Reese had been vacationing). His residence at the time of his death was located at 630 Linden Road, Hershey, PA.\\r\\n\\r\\nOn July 2, 1963 (seven years after the death of H.B. Reese), when the sales of Reese's Peanut Butter Cups were equivalent to $243 million, his sons Robert, John, Ed, Ralph, Harry and Charles Richard Reese, merged the H.B. Reese Candy Company with The Hershey Company in a tax free stock-for-stock merger. In 2018 after 55 years of stock splits, the Reese brothers' original 666,316 shares of Hershey common stock represent 16 million Hershey shares valued at over $1.8 billion that pay annual cash dividends of $42 million.[17] At the time of its 1963 merger, the H.B. Reese Candy Company was celebrating its 40th Anniversary and had just added 200,000 square feet of new state-of-the-art manufacturing capacity to its 925 Reese Avenue, Hershey, PA plant.[8] In 1969, only 6 years after the Reese/Hershey merger, Reese's Peanut Butter Cups became the best-selling product of The Hershey Company.[9]\\r\\n\\r\\nAs of September 20, 2012, Reese's Peanut Butter Cups were the No. 1 selling candy brand in the United States with sales of $2.603 billion.[1] Furthermore back in 1973, the non-union H.B. Reese Candy Company plant added yet another 200,000 square feet of manufacturing space in order to begin production of the Kit Kat for sale in the United States[8] which had 2012 U.S. sales of $948 million, making Kit Kat the No. 4 selling candy brand in the United States.[1]","input":"Who invented the reese's peanut butter cup?"},{"output":"29 March and Saturday 30 March 1901","context":"Edmund Barton\\r\\nProtectionist\\r\\nFederal elections for the inaugural Parliament of Australia were held in Australia on Friday 29 March and Saturday 30 March 1901 following Federation and the establishment of the Commonwealth of Australia. All 75 seats in the Australian House of Representatives, six of which were uncontested, as well as all 36 seats in the Australian Senate, were up for election.\\r\\nAfter the initial confusion of the Hopetoun Blunder, the first Prime Minister of Australia, Edmund Barton, went into the inaugural 1901 federal election as the appointed head of a Protectionist Party caretaker government. While the Protectionists came first on votes and seats, they fell short of a majority. The incumbent minority government remained in office with the parliamentary support of the Labour Party who held the balance of power, with the Free Trade Party forming the opposition. A few months prior to the 1903 election, Alfred Deakin replaced Barton who resigned to become a founding justice of the High Court of Australia.\\r\\n\\r\\n\\r\\nIndependents: Alexander Paterson (Capricornia, Qld), James Wilkinson (Moreton, Qld)\\r\\n\\r\\nThe federation of the colonies of New South Wales, Queensland, South Australia, Tasmania, Victoria and Western Australia came into effect on 1 January 1901 to form the Commonwealth of Australia. An election was held on Friday 29 March in Western Australia, Victoria, New South Wales and Tasmania, and on Saturday 30 March 1901 in South Australia and Queensland, to elect the inaugural members of federal parliament. Floods in Queensland delayed polling in parts of the state until April.\\r\\nThe 1901 election was the only one of two occasions in Australia's history that the entire country did not go to the polls on the same day in a general election, the second occasion being the 1993 \\"supplementary election\\" in the Division of Dickson. This election was also the only time that an election or any part thereof was held on a day other than a Saturday.\\r\\nIn what would later be known as the Hopetoun Blunder, in December 1900 the Governor-General, the 7th Earl of Hopetoun commissioned William Lyne, the Premier of the senior state, New South Wales, to form the first Commonwealth Government from 1 January 1901. The government was to conduct itself on a caretaker basis in the absence of a parliament. Lyne was unpopular and was unable to gain support, so he returned his commission. Edmund Barton was then called upon to form the interim government. Barton was sworn in as the inaugural Prime Minister, and his cabinet contested the poll as the incumbent government.\\r\\nSome candidates were still sitting members of a state parliament. William Lyne was a minister in Barton's interim government and was a candidate for the Division of Hume while still Premier of New South Wales, and used his official Premier's car during the campaign, resigning on 27 March.\\r\\nVoting franchise was according to each state's specific electoral laws. South Australian and Western Australian women were enfranchised, but in the other states they could not vote. Tasmania retained a small property qualification for voting, but in the other states all males over 21 were eligible to vote. Only in South Australia and Tasmania, however, were indigenous Australians even theoretically entitled to vote. A few may have done so in South Australia.\\r\\nVoting was voluntary throughout Australia and candidates were elected by a \\"first past the post\\" voting system. In South Australia, voters were required to mark the box opposite their preferred candidates, while in other states voters were required to cross out the names of non-preferred candidates.\\r\\nAll seats were to be filled ? 75 in the House of Representatives and 36 in the Senate. Six House seats were uncontested.\\r\\nThere were 75 House of Representative seats to be filled. The initial number of seats for each state were set out in the Australian Constitution. New South Wales was allocated 26, Victoria 23, Queensland 9, South Australia 7, Western Australia 5 and Tasmania 5. The South Australian and Tasmanian colonial parliaments had not legislated for single member electorates, so their House of Representative members were elected from a single statewide electorate. In South Australia, each elector cast seven votes, while in Tasmania, each elector cast one vote.\\r\\nEach state elected six Senators, in accordance with the Constitution. Senators in each state were elected on a statewide electorate basis by bloc voting rather than the current proportional representation or single transferable vote system.\\r\\nThe parties contesting the election were the Protectionist Party, led by Prime Minister of Australia Edmund Barton, and the Free Trade Party, unofficially led by former New South Wales Premier George Reid. There would not be a federal Labour Party until two months after the election, but in five of the six states local Labour parties contested the elections - in Tasmania, where there was no Labour party, King O'Malley was elected as an independent labour candidate. There were also a number of independents of various political leanings and a New South Wales Senate ticket called the \\"Socialist Six\\", comprising Labour members in conflict with the official party.\\r\\nThe Protectionists advocated the protection of local industries through the imposition of tariffs on imported goods, the construction of a transcontinental railway, a uniform railway gauge, uniform suffrage, aged pensions and defending the Australian constitution from radicals. The party used the colour red throughout the campaign. In addition to Barton, Protectionist candidates included many of the leading political figures from colonial Australia, including Charles Kingston, Sir John Forrest, and future Prime Minister Alfred Deakin.\\r\\nThe Free Traders (their official title was \\"Australian Free Trade and Liberal Association\\") advocated the dismantling of the tariff system, a transcontinental railway, and believed that aged pensions should be left to the states. As many of the policies of the Protectionists and Free Traders were similar, the Free Traders campaigned heavily on tariffs, with Reid stating that he wanted the election to be a plebiscite on tariffs. The party used the colour blue throughout the campaign. In addition to Reid, who believed he should have been appointed Prime Minister[1] instead of Barton as he considered himself the bigger political figure, Free Trade candidates included Reid's unofficial deputy Paddy Glynn, William Irvine, and former state Labour leader and future Commonwealth Liberal Party Prime Minister Joseph Cook.\\r\\nLabour advocated old age pensions, electoral reform, a national army, compulsory arbitration of industrial disputes and a national referendum to decide issues that would otherwise lead to a double dissolution of parliament. Senior Labour candidates included future Prime Ministers Chris Watson, Andrew Fisher and Billy Hughes. Labour candidates were elected as individual state-based candidates - they met before the first sitting of Parliament on 8 May 1901 and agreed to form a federal Labour Party. Chris Watson, a Sydney printer and former member of the New South Wales Parliament, was elected the first leader of the Party.\\r\\nAll parties were in support of a White Australia as was the norm at the time, with only a single parliamentarian, Free Trader Bruce Smith, fully opposing the legislation.[2]\\r\\nThe campaign period officially commenced on 17 January 1901, although some candidates, particularly Reid, had been unofficially campaigning since December the previous year. The campaign was delayed due to the death of Queen Victoria on 22 January, but soon got into full swing again as candidates travelled widely to address lively public meetings. Reid drew the biggest crowds, including 8,000 to a rally in Newcastle and he campaigned widely, travelling to Victoria, Queensland and Tasmania, while Paddy Glynn organised the Free Trade campaign in South Australia.[1]\\r\\nThe Protectionists were forced to modify their immigration policy following an outcry from Queensland Protectionist candidates who feared that a White Australia policy would impinge on the importation of Kanakas to work on Queensland sugar plantations. Their policy was revised to read that Kanakas would be only be sent back to their country of origin when they were no longer of any use to the sugar industry. On the whole, however, a white Australia was extremely popular with the electorate and most candidates outdid themselves to prove how much they supported it. It was left to Free Trade candidate for Parkes, Bruce Smith (a leading representative of the employers), to oppose anti-immigration measures. Andrew Fisher argued that any Kanaka who had converted to Christianity and married should be allowed to remain in Australia. Both were elected comfortably.\\r\\nThe Free Traders also had to modify part of their election platform when they realised that to advocate for the removal of all tariffs protecting Australian industries would be political suicide. Many employees in these industries considered the removal of tariffs as likely to mean the end of their jobs.\\r\\nThe Protectionists enjoyed the support of the powerful Australian Natives' Association (ANA) throughout the campaign as well as the endorsements of The Age and The Sydney Bulletin, while Free Trade received support from business interests and the endorsements of The Sydney Morning Herald, The Daily Telegraph, The Brisbane Courier, Melbourne's The Argus and The Adelaide Register. Labour could only rely on union-owned newspapers, although some of these enjoyed a great level of influence in some electorates (the Gympie Truth for example is considered to have played an important role in the election of its part-owner, Andrew Fisher, in Wide Bay).\\r\\nThere were only two cars used in the 1901 election campaign; William Lyne, who was a candidate for the Division of Hume while still Premier of New South Wales, used his official Premier's car to great advantage; the shipping magnate and candidate for Melbourne Sir Malcolm McEacharn, enjoyed the use of his car while travelling around his electorate.\\r\\nComplaints were received by polling officials about the earlier than advertised closing of polling booths in some electorates, the poor quality pencils supplied to fill in ballot papers (they apparently blunted easily, leaving many votes incomprehensible to officials) and the Senate ballot paper in New South Wales which listed 50 candidates, confusing many voters and leading to a significant number of informal votes.[3]\\r\\nThese complaints aside, the administering of the first federal election was seen as a great success and a credit to the polling officials who, in some cases, were responsible for electorates larger than some European countries.\\r\\nThe Free Traders won most of the seats in New South Wales, apart from the border areas where the Protectionists were strong. The Protectionists won most of the seats in their stronghold, Victoria. Labour won some inner urban seats but most of their members represented pastoral and mining areas. In the smaller states many members had no fixed party loyalty and saw themselves as representing the interests of their states. Seven Prime Ministers of Australia (Barton, Deakin, Watson, Reid, Fisher, Joseph Cook and Hughes) were elected at this election, as were a number of influential former state Premiers (Sir John Forrest, Lyne, George Turner, Anderson Dawson, Philip Fysh and Charles Kingston among them).\\r\\nWith no past to live down, Barton's Protectionist ministry had all the advantages of incumbency with none of the problems, which meant that a Protectionist victory was almost a certainty, and Barton had been confident of obtaining a comfortable majority in parliament.[4] However, while Barton and his ministry were returned, they had to rely on Labour support to pass legislation. Although the Protectionists remained in government, however, many observers saw the result as a moral victory for Free Trade (who won more seats than the Protectionists in the three smallest states of South Australia, Tasmania and Western Australia). Labour also performed better than expected, particularly after the post-election recruitment of O'Malley. Labour was the smallest of the three parties in the House but held the balance of power. Chris Watson pursued the same policy as Labour had done in the colonial parliaments. He kept the Protectionist governments of Edmund Barton and Alfred Deakin in office, in exchange for legislative concessions including the immensely popular White Australia policy. Such was the overwhelming support for a White Australia by the electorate and the three political parties that the Immigration Restriction Act 1901 was the seventeenth piece of legislation passed by the nascent parliament.[5][6]\\r\\nThe average national voting turnout was 60% of enrolled voters, with the Division of Newcastle gaining the highest turnout on 97%, while the Division of Fremantle recorded the lowest turnout on 30%.\\r\\nOf the two elected independents, both were from Queensland. James Wilkinson, elected to the seat of Moreton, was a former member of the Labour Party, and rejoined the party in 1903. Alexander Paterson, representing Capricornia, had no political affiliation, and retired in 1903.\\r\\nSouth Australia and Tasmania went to the election as single multi-member constituencies. South Australia elected seven members, each elector casting seven votes: four Free Traders (Paddy Glynn, 59.5%; Frederick Holder, 59.5%; Alexander Poynton, 41.1%; and Vaiben Louis Solomon, 43.0%), two Protectionists (Charles Kingston, 65.9%; Langdon Bonython, 62.7%) and one Labour member (Lee Batchelor, 50.3%). Tasmania elected five members, each elector casting one vote: three Free Traders (Edward Braddon, 26.2%; Norman Cameron, 11.6%; Frederick Piesse, 10.1%), one Protectionist (Philip Fysh, 9.9%) and one Labour member (King O'Malley, 21.9%).","input":"Where was australia's first federal government formed?"},{"output":"Minnesota","context":"The Minnesota State Capitol is the seat of government for the U.S. state of Minnesota, in its capital city of Saint Paul.  It houses the Minnesota Senate, Minnesota House of Representatives, the office of the Attorney General and the office of the Governor. The building also includes a chamber for the Minnesota Supreme Court, although court activities usually take place in the neighboring Minnesota Judicial Center.\\r\\n\\r\\nThe building is set in a landscaped campus.  Various monuments are to its sides and front.  Behind, a bridge spans University Avenue, and in front others were later added over the sunken roadway of Interstate 94, thus preserving the sight lines. Set near the crest of a hill, from the Capitol steps a panoramic view of downtown Saint Paul is presented.\\r\\n\\r\\nThe building was built by Butler-Ryan Construction and designed by Cass Gilbert and modeled after Saint Peter's Basilica in Romethe unsupported marble dome is the second largest in the world, after Saint Peter's. However, like all capitols with domes in the US it is also inspired by the idea of domed capitols originating with the United States Capitol dome. Work began on the capitol in 1896, its corner-stone laid July 27, 1898, and construction was completed in 1905. It is the third building to serve this purpose: the first capitol was destroyed by fire in 1881, and the second was completed in 1883, but was considered to be too small almost immediately.\\r\\n\\r\\nAbove the southern entrance to the building is a gilded quadriga called The Progress of the State which was sculpted by Daniel Chester French and Edward Clark Potter. It was completed and raised to the roof of the capitol in 1906. The four horses represent the power of nature: earth, wind, fire and water. The women leading the horses symbolize civilization, and the man on the chariot represents prosperity.[2] In 1994 and 1995, the statues underwent a restoration procedure which included replacing the gold leaf on the figures. A sphere perched above the capitol dome had similar treatment.\\r\\n\\r\\nAny classical dome built since Michelangelo's must expect to be compared to it, and Gilbert's dome is a frank homage, with interesting differences. His drawings show that he originally planned a wider drum and, correspondingly, a more massive dome. The smaller dome as built is smaller than St. Peter's and has a simplified design: single columns round the upper lantern instead of double ones, for instance. The ribs on the capitol dome are less pronounced than those on St. Peter's, but they are still visually apparent. Gilbert knew that St. Peter's dome was on the edge of being unstable: it had cracked and had to be reinforced. His engineer for this project, Gunvald Aus, bound the brick dome in reinforcing steel bands, and Gilbert crowned the paired columns round the drum (which act as buttresses to counter the dome's weight) with additional stone. Other than St. Peter's, additional buildings with marble domes include the Taj Mahal in India, and the Rhode Island State House in the city of Providence.\\r\\n\\r\\nThe central block under the dome needed three entrances, and Gilbert avoided creating visual references to a triumphal arch, which would have been inappropriate in its position. Equally, he managed to avoid any reference to a palace block that would have been offensive to Minnesotans. However, Gilbert drew ire for choosing stone from Georgia rather than native Minnesota stone. A compromise was eventually made where the base of the building and interior spaces used varieties of native stone, including Kasota stone, and the rare Minnesota Pipestone used by Native Americans for their peace pipes. Upon completion, the exterior and interior of the building drew praise, leading to requests for Gilbert to design capitol buildings for other states such as West Virginia and Arkansas and other notable structures.\\r\\n\\r\\nThe capitol cost US$4.5 million at the beginning of the 20th century. It opened its doors to the public for the first time on January 2, 1905. A hundred years later, the building's estimated value was $400 million.\\r\\n\\r\\nMost days of the week the building is open for individual visits, and organized tours are frequently given, including a stair climb to the roof behind the Quadriga. Upon entering the building by the south door, one is below the central dome. A large star, symbolizing Minnesota's motto, \\"The Star of the North\\", is directly beneath the apex. Various portraits of state governors, and flags captured by Minnesota's regiments during the American Civil War, are on display. Paintings showing some of the related battles can be seen in the governor's outer office. Much of the building is open to the public, although one interesting sight is only rarely accessible. This is the cloak room behind the House of Representatives chamber. The walls are painted to simulate a north woods forest, but in one corner is a tiny four leaf clover. This was added by an Irish artist to remember his home island.\\r\\n\\r\\nThe structure was added to the National Register of Historic Places in 1972.\\r\\n\\r\\nThe Minnesota State Capitol underwent a comprehensive restoration project from 2013 to 2017, the first major renovation since the building first opened.[3] Work began in 2013, with the project estimated at that time to cost $241 million, funded via a series of appropriations made by the Minnesota legislature.[4] The project repaired and modernized deteriorating building systems, restored the building to Cass Gilbert's original architectural vision, increased public meeting space (including a new classroom for the Minnesota Historical Society to host school groups and provide information about the building), updated life safety systems and improved accessibility for people with disabilities.[5]\\r\\n\\r\\nDuring renovation, more than 30,000 pieces of marble were restored or replaced.[6] The amount of public space in the building was doubled to nearly 40,000 square feet, with a number of new public spaces opened to the public for reservation and use year round.[7]\\r\\n\\r\\nThe project also included a restoration of the capitol's many works of fine art, which prompted discussions over some paintings in the building that feature controversial depictions of American Indians. A series of public input meetings were held around the state to gather feedback and consider options for new policies regarding art in the renovated building.[8] When the building reopened, two of these paintings were relocated to a public space in the building, while others remained in place.[9]\\r\\n\\r\\nThe renovation forced the House and Senate to hold a special session in the nearby State Office Building in 2015. During the regular 2016 session, the Senate met in the newly completed Senate Office Building, with the capitol open for only limited access to the House chamber during the session.[10]\\r\\n\\r\\nBy the time of its completion in 2017, the total cost of the renovation project reached about $310 million.[11] The bulk of construction was completed by the start of the 2017 legislative session in January.[12] The project was officially completed in August 2017, at which point all of the building's newly renovated spaces opened to the public.[13]\\r\\n\\r\\nA three-day grand opening celebration took place on August 11, 12, and 13, 2017.[14][15] The grand opening celebration featured a ribbon cutting ceremony with state and local leaders, panel conversations with notable Minnesotans (including former U.S. Vice President Walter Mondale and Minnesota Lynx Head Coach Cheryl Reeve), a beer tasting event with more than 25 Minnesota craft brewers, and musical performances from Minnesota bands Poli?a and Cloud Cult.[16]\\r\\n\\r\\nThe Capitol at night\\r\\n\\r\\nMarble dome\\r\\n\\r\\nGolden quadriga above the south entrance\\r\\n\\r\\nClose up of the quadriga\\r\\n\\r\\nInside the dome\\r\\n\\r\\nRotunda\\r\\n\\r\\nMural depicting the North Star. Below the Star are the French words \\"L'toile du nord\\", which translates as \\"The Star of the North\\", which is also the state's motto.\\r\\n\\r\\nHouse of Representatives chamber\\r\\n\\r\\nAbove the House of Representatives chamber is Lady Minnesota with two pioneers to her left. To her right are a Native American chief and Sacagawea in honor of the people who lived in Minnesota before the pioneers. On the book that she holds in her left hand are both the dates of Minnesota's founding as a territory and state.\\r\\n\\r\\nWilliam J. Colvill Memorial\\r\\n\\r\\nJames Shields Memorial\\r\\n\\r\\nJohn B. Sanborn Memorial\\r\\n\\r\\nAlexander Wilkin Memorial\\r\\n\\r\\nKnute Nelson Memorial\\r\\n\\r\\nJohn Albert Johnson Memorial\\r\\n\\r\\nFloyd B. Olson Memorial\\r\\n\\r\\nCharles Lindbergh Memorial\\r\\n\\r\\nMinnesota Vietnam Veteran's Memorial\\r\\n\\r\\nMinnesota Korean War Memorial\\r\\n\\r\\nPeace Officers Memorial\\r\\n\\r\\nRoy Wilkins Memorial\\r\\n\\r\\nWomen's Suffrage Memorial Garden\\r\\n\\r\\nChristopher Columbus Monument\\r\\n\\r\\nLeif Ericsson Monument\\r\\n\\r\\nMonument to the Living","input":"What state is st paul the capitol of?"},{"output":"seven","context":"In association football, a substitute is a player who is brought on to the pitch during a match in exchange for an existing player. Substitutions are generally made to replace a player who has become tired or injured, or who is performing poorly, or for tactical reasons (such as bringing a striker on in place of a defender). Unlike some sports (such as American football or ice hockey or Kabaddi), a player who has been substituted during a match may take no further part in it.\\r\\nMost competitions only allow each team to make a maximum of three substitutions during a game, although more substitutions are often permitted in non-competitive fixtures such as friendlies. Allowing a fourth substitution in extra time is currently being trialed at several tournaments, including the 2016 Summer Olympic Games, the 2017 FIFA Confederations Cup and the 2017 CONCACAF Gold Cup final.[1][2][3][4][5] A fourth substitute in extra time has been approved for use in the knockout rounds at the 2018 FIFA World Cup and the UEFA Champions League.[6][7] Each team nominates a number of players (typically between five and seven, depending on the competition) who may be used as substitutes; these players typically sit in the technical area with the coaches, and are said to be \\"on the bench\\". When the substitute enters the field of play it is said they have come on or have been brought on, while the player they are substituting is coming off or being brought off.\\r\\nA player who is noted for frequently making appearances, or scoring important goals, as a substitute is often informally known as a \\"super sub\\".\\r\\n\\r\\n\\r\\nThe origin of football substitutes goes back to at least the early 1860s as part of English public school football games. The original use of the term \\"substitute\\" in football was to describe the replacement of players who failed to turn up for matches. For example, in 1863, a match reports states: \\"The Charterhouse eleven played a match in cloisters against some old Carthusians but in consequence of the non-appearance of some of those who were expected it was necessary to provide three substitutes.[8]\\" The substitution of absent players happened as early as the 1850s, for example from Eton College where the term \\"emergencies\\" is used.[9] Numerous references to players acting as a \\"substitute\\" occur in matches in the mid-1860s[10] where it is not indicated whether these were replacements of absent players or of players injured during the match.\\r\\nThe first use of a substitute in international football was on 15 April 1889, in the match between Wales and Scotland at Wrexham. Wales's original goalkeeper, Jim Trainer, failed to arrive; local amateur player Alf Pugh started the match and played for some 20 minutes until the arrival of Sam Gillam, who took over from him.[11]\\r\\nSubstitution during games was first permitted in 1958.[12] (Although as early as the qualifying phase for the 1954 World Cup, Horst Eckel of Germany is recorded as having been replaced by Richard Gottinger in their match with the Saarland on 11 October 1953.)[13] The use of substitutes in World Cup Finals matches was not allowed until the 1970 tournament.[14]\\r\\nThe number of substitutes usable in a competitive match has increased from zeromeaning teams were reduced if players' injuries could not allow them to play onto one (plus another for an injured goalkeeper) in 1958; to two out of a possible five in 1988. With the later increases in substitutions allowed, the number of potential substitute players increased to seven.[15] The number of substitutes increased to two plus one (injured goalkeeper) in 1994,[16] to three in 1995;[17][18] and most recently to a fourth substitute in certain competitions in extra time.[19]\\r\\nSubstitutions during matches in the English Football League were first permitted in the 1965ÿ66 season. During the first two seasons after the law was introduced, each side was permitted only one substitution during a game. Moreover, the substitute could only replace an injured player. From the 1967ÿ68 season, this rule was relaxed to allow substitutions for tactical reasons.[20]\\r\\nOn 21 August 1965, Keith Peacock of Charlton Athletic became the first substitute used in the Football League when he replaced injured goalkeeper Mike Rose eleven minutes into their away match against Bolton Wanderers.[21] On the same day, Bobby Knox became the first ever substitute to score a goal when he scored for Barrow against Wrexham.[22]\\r\\nArchie Gemmill of St Mirren was the first substitute to come on in a Scottish first-class match, on 13 August 1966 in a League Cup tie against Clyde when he replaced Jim Clunie after 23 minutes.[20]\\r\\nThe first official substitute in a Scottish League match was Paul Conn for Queen's Park vs Albion Rovers in a Division 2 match on 24 August 1966. Previously, on 20 January 1917, a player called Morgan came on for the injured Morrison of Partick Thistle after 5 minutes against Rangers at Firhill, but this was an isolated case and the Scottish League did not authorise substitutes until 1966.[20]\\r\\nIn later years, the number of substitutes permitted in Football League matches has gradually increased; at present each team is permitted to name either five or seven substitutes depending on the country and competition, of which a maximum of three may be used. In England, the Premier League increased the number of players on the bench to five in 1996, and it was announced that the number available on the bench would be seven for the 2008ÿ09 season.[23]\\r\\nAccording to the Laws of the Game (2014/15):[24]\\r\\nA player may only be substituted during a stoppage in play and with the permission of the referee. The player to be substituted (outgoing player) must have left the field of play before the substitute (incoming player) may enter the field of play; at that point the substitute becomes a player and the person substituted ceases to be a player. The incoming player may only enter the field at the half-way line. Failure to comply with these provisions may be punished by a caution (yellow card).\\r\\nA player who has been substituted may take no further part in a match.\\r\\nUnused substitutes still on the bench, as well as players who have been already substituted, remain under the authority of the referee. These are liable for misconduct, though cannot be said to have committed a foul. For example, in the 2002 FIFA World Cup, Claudio Caniggia was shown the red card for cursing at the referee from the bench.\\r\\nUnder the Laws, the referee has no specific power to force a player to be substituted, even if the team manager or captain has ordered their player to be substituted. If a player refuses to be substituted play may simply resume with that player on the field. However, in some situations players may still be liable to punishment with a caution (yellow card) for time wasting or unsporting behaviour.\\r\\nA player who has been sent off (red card) may not be substituted; the team will have to make do with the remaining players. In the case of a goalkeeper who is sent off, such as in the 2006 UEFA Champions League Final, when Arsenal midfielder Robert Pirs was replaced by second-choice goalkeeper Manuel Almunia to replace Jens Lehmann, who received a red card less than 20 minutes into the match, the coach will usually (but is not required to) substitute an outfield player so that the backup goalkeeper can enter the game. If all substitutions have been used, or if no goalkeeper is available, an outfield player will take up the role of the goalkeeper. A famous example of this is when Chelsea goalkeepers Petr ?ech and Carlo Cudicini were both injured in the same game, which led to defender John Terry spending the remainder of the match in goal wearing third-choice goalkeeper Hilrio's shirt.[25]\\r\\nAccording to the Laws of the Game, \\"up to a maximum of three substitutes may be used in any match played in an official competition organised under the auspices of FIFA, the confederations or the member associations.\\" Also:\\r\\nThe term \\"super-sub\\" refers to a substitution made by the manager that subsequently saves the game, generally by scoring a late equalising or winning goal. Players regarded as \\"super-subs\\" include Tup?zinho and Dinei for Corinthians, Azar Karadas for Brann, Santiago Solari for Real Madrid, Nwankwo Kanu for Arsenal, David Fairclough for Liverpool,[26] Adam Le Fondre for Reading,[27] Ole Gunnar Solskj?r and Javier Hernndez for Manchester United,[28][29] Mikael Forssell for Chelsea,[30] Leon Clarke for Wigan Athletic,[31] Brendon Santalab for Western Sydney Wanderers[32] Henrique for Brisbane Roar,[33] Stevie Kirk for Motherwell,[34], Archie Thompson, Joshua Kennedy and Tim Cahill for Australia.[35][36][37][38][39][40][41]","input":"How many players are on the bench in football?"},{"output":"Bourbon Street","context":"Bourbon Street (French: Rue Bourbon, Spanish: Calle Bourbon) is a street in the heart of New Orleans' oldest neighborhood, the French Quarter, in New Orleans, Louisiana. It extends 13 blocks from Canal to Esplanade Avenue.[1] Known for its bars and strip clubs, Bourbon Street's history provides a rich insight into New Orleans' past.[2]\\r\\n\\r\\nThe French claimed Louisiana as a colony in the 1690s. Jean Baptiste Le Moyne de Bienville was appointed as Director General in charge of developing a colony in the territory. He founded New Orleans in 1718. In 1721, the royal engineer, Adrien de Pauger, designed the city's street layout. He named the streets after French royal houses and Catholic saints. Bourbon Street paid homage to France's ruling family, the House of Bourbon.[3]\\r\\n\\r\\nNew Orleans was given to the Spanish in 1763 following the Seven Years' War. The Great New Orleans Fire of 1788 destroyed 80% of the city's building. The Spanish rebuilt many of the damaged structures, which are still standing today. For this reason, Bourbon Street and the French Quarter display more Spanish than French influence.[4]\\r\\n\\r\\nThe Americans gained control of the colony following the 1803 Louisiana Purchase.[5] They translated the French street names into English, with Rue Bourbon becoming Bourbon Street.[4]\\r\\n\\r\\nNew Orleans in the 19th century was both similar to and different from other Southern cities. It was similar in that its economy was based on selling cash crops such as sugar and tobacco. By 1840, newcomers whose wealth came from these enterprises turned New Orleans into the third largest metropolis in the country.[6] The city's port was the nation's second largest, with New York City being the largest.[7]\\r\\n\\r\\nThe main difference between New Orleans and other Southern cities was its unique cultural heritage as a result of formerly having been a French and Spanish possession.  This cultural legacy in the form of its architecture, cuisine and traditions was emphasized by promoters to attract tourists.[6]\\r\\n\\r\\nThe French Quarter was central to this image and became the best-known part of the city. Recent arrivals in New Orleans criticized the perceived loose morals of the Creoles, a perception which persisted as many travelers came to New Orleans to drink, gamble and have sexual encounters in the citys brothels, beginning in the 1880s.[6]\\r\\n\\r\\nBourbon Street was a premier residential area prior to 1900.[4] This changed in the late 1800s and early 1900s, when the Storyville red-light district was constructed on Basin Street adjacent to the French Quarter. The area became known for prostitution, gambling and vaudeville acts.[8] Jazz is said to have developed here, with artists such as King Oliver and Jelly Roll Morton providing musical entertainment at the brothels.\\r\\n\\r\\nThis was also the era when some of New Orleans' most eminent restaurants were founded, including Galatoire's, located at 209 Bourbon Street.[9] It was established by Jean Galatoire in 1905. Known for years by its characteristic line snaking down Bourbon Street, patrons waited for hours just to get a table  especially on Fridays.[9]\\r\\n\\r\\nBefore World War II, the French Quarter was emerging as a major asset to the citys economy. While there was an interest in historic districts at the time, developers pressured to modernize the city. Simultaneously, with the wartime influx of people, property owners opened adult-centered nightclubs to capitalize on the citys risqu image. This led to Bourbon Street becoming the new Storyville in terms of reputation.[6] By the 1940s and 1950s, nightclubs lined Bourbon Street. Over 50 different burlesque shows, striptease acts and exotic dancers could be found.[6]\\r\\n\\r\\nThere was a move in the 1960s under District Attorney Jim Garrison to clean up Bourbon Street. In August 1962, two months after he was elected, Garrison began raiding adult entertainment establishments on Bourbon. His efforts mirrored those of his predecessors, which had been largely unsuccessful, but he had more success. He forced closure on a dozen nightclubs convicted of prostitution and selling overpriced alcohol. Following this campaign, Bourbon Street was populated by peep shows and sidewalk beer stands.[10]\\r\\n\\r\\nWhen Mayor Moon Landrieu came into office in 1970, he focused his efforts on stimulating tourism. He did so by making Bourbon Street a pedestrian mall, making it more inviting.[6] The 1980s and 1990s were characterized by a Disneyfication of Bourbon Street. Critics of the proliferation of souvenir shops and corporate ventures said that Bourbon Street had become Creole Disneyland. They also argued that the streets authenticity had been lost in this process.[11]\\r\\n\\r\\nOn April 5, 2018 a giant saxophone of 3m30 high is inaugurated in the street. It was offered by the city of Namur (Belgium) to recall that the inventor of the instrument Adolphe Sax is from the region of Namur, specifically Dinant.[12]\\r\\n\\r\\nGiven Bourbon Street's high-ground location in the French Quarter, it was mostly intact following 2005's Hurricane Katrina. A major tourist attraction, Bourbon Street renovation was given high priority after the storm. However, New Orleans was still experiencing a dearth of visitors.[13] In 2004, the year before Katrina, the city had 10.1 million visitors. The year after the storm, that number was 3.7 million.[14]\\r\\n\\r\\nEfforts to draw visitors back to the city were initiated by the New Orleans Tourism Marketing Corporation, featuring celebrities such as Emeril Lagasse and Patricia Clarkson with the slogan, \\"Come fall In love with Louisiana all over again.\\" (One third of the city's operating budget, approximately $6 billion, came from visitors and conventions; officials saw the tourist draw as vital for post-disaster economic recovery.)[13] Travelers heard mixed messages in the media. Advertising campaigns gave the impression that New Orleans was thriving, while city leaders asked for increased Federal financial assistance and National Guard troops to help control municipal crime waves.[13]\\r\\n\\r\\nNew Orleans has been working its way back to pre-Katrina tourist numbers, as it attracted 9.5 million visitors in 2014 and 10.5 million visitors in 2016.[15] The 2016 record was the highest since 2004.[16]\\r\\n\\r\\nIn April 2017, the 100 block of Bourbon Street was closed off for reconstruction of the street and its underground utilities as part of the city's $6 million French Quarter infrastructure project.[17]\\r\\n\\r\\nLargely quiet during the day, Bourbon Street comes alive at night, particularly during the French Quarter's many festivals.  Most famous of these is the annual Mardi Gras celebration, when the streets teem with thousands of people.  Local open container laws allow drinking alcoholic beverages on the Quarter's streets. Popular drinks include the hurricane cocktail, the resurrection cocktail, the hand grenade and the profanely named \\"huge-ass beers\\" ÿ a large plastic cup of draft beer marketed to tourists at a low price.\\r\\n\\r\\nThe most heavily visited section of Bourbon Street is \\"upper Bourbon Street\\" toward Canal Street, an eight-block section of visitor attractions[18] including bars, restaurants, souvenir shops, and strip clubs. In the 21st century Bourbon Street is the home of New Orleans Musical Legends Park, a free, outdoor venue for live jazz performances, with sculptures and other tributes to the city's legendary music personalities. \\r\\n\\r\\nMost of the bars are located in the central section of Bourbon. Popular spots include Pat O'Brien's, Johnny White's, the Famous Door, Spirits on Bourbon, Channing Tatum's Saints and Sinners, Razzoo and The Cat's Meow.[19] Marie Laveau's House of Voodoo is located on the corner of St. Ann Street.\\r\\n\\r\\nThe most renowned restaurant on Bourbon Street is Galatoire's; it represents traditional New Orleans dining and has a dress code. Lafitte's Blacksmith Shop and the Old Absinthe House are two of the many casual eateries.[1]\\r\\n\\r\\n\\"Lower Bourbon Street\\" (lower being a reference to downriver, or downstream Mississippi River), from the intersection of St. Ann Street, caters to New Orleans' thriving gay community, featuring such establishments as Oz and the city's largest gay nightclub, the Bourbon Pub. St. Ann Street has been referred to as \\"the Velvet Line\\"[20] or \\"the Lavender Line,\\" the edge or approximate boundary of the French Quarter's gay community. Cafe-Lafitte-in-Exile is the oldest gay bar in the nation. The intersection of Bourbon and St. Ann Streets is also the center of the Labor Day weekend event Southern Decadence, commonly referred to as the Gay Mardi Gras, which attracts upwards of 100,000 participants.[21]\\r\\n\\r\\nHistorically, noise violations were the responsibility of the individual making the noise.[22] This changed in 1996 with Yokum v. 615 Bourbon Street. The case ruled that the property owner, not the noise-maker is responsible for noise violations. A 2010 city ordinance stipulates that no music may be played in the French Quarter between 8?pm and 9?am. Enforcement has been inconsistent, and critics claim its goals are vague. Some even state that the local law is unconstitutional.[23] Besides being difficult to enforce, music aficionados claim that noise ordinances threaten the city's notable music culture. Local jazz bands, such as the To Be Continued Brass Band, who play in the streets, would be prohibited from doing so under such ordinances.[23]\\r\\n\\r\\nAggressive-solicitation bans are a more recent issue on Bourbon Street. In 2011, an ordinance[24] was passed which prohibited individuals and groups from \\"disseminating any social, political or religious message\\" at night. The ordinance did not explain the justification for the rule.[25]  On September 21, 2012, the ACLU of Louisiana won[26] a temporary restraining order against the ban, on behalf of Kelsey McCauley (Bohn), a woman who converted to Christianity through a religious group's activities on Bourbon Street. The group had several of its members arrested, some of whom were cited on September 14, 2012, for violating the anti-solicitation ordinance.  A hearing was set for October 1, 2012.\\r\\n\\r\\nOn July 25, 2013, the New Orleans City Council voted 6-0[27] to amend the law and exempt Bourbon Street from the ban, with legal language found acceptable by the participating attorneys.\\r\\n\\r\\nRoute map:","input":"What's the famous street in new orleans?"},{"output":"United States","context":"\\r\\n\\r\\nGross domestic product (GDP) is the market value of all final goods and services from a nation in a given year.[2] Countries are sorted by nominal GDP estimates from financial and statistical institutions, which are calculated at market or government official exchange rates. Nominal GDP does not take into account differences in the cost of living in different countries, and the results can vary greatly from one year to another based on fluctuations in the exchange rates of the country's currency.[3] Such fluctuations may change a country's ranking from one year to the next, even though they often make little or no difference in the standard of living of its population.[4]\\r\\n\\r\\nComparisons of national wealth are also frequently made on the basis of purchasing power parity (PPP), to adjust for differences in the cost of living in different countries. PPP largely removes the exchange rate problem, but has its own drawbacks; it does not reflect the value of economic output in international trade, and it also requires more estimation than nominal GDP.[5] On the whole, PPP per capita figures are less spread than nominal GDP per capita figures.[6]\\r\\n\\r\\nThe United States is the world's largest economy with a GDP of approximately $19.39 trillion, notably due to high average incomes, a large population,[7] capital investment, moderate unemployment,[8] high consumer spending,[9] a relatively young population,[10] and technological innovation.[11] Tuvalu is the world's smallest national economy, with a GDP of about $32 million, because of its very small population, a lack of natural resources, reliance on foreign aid, negligible capital investment, demographic problems, and low average incomes.[12]\\r\\n\\r\\nAlthough the rankings of national economies have changed considerably over time, the United States has maintained its top position since the Gilded Age, a time period in which its economy saw rapid expansion, surpassing the British Empire and Qing dynasty in aggregate output.[13][14] Since China's transition to a market-based economy through privatisation and deregulation,[15][16] the country has seen its ranking increase from ninth in 1978 to second to only the United States in 2016 as economic growth accelerated and its share of global nominal GDP surged from 2% in 1980 to 15% in 2016.[14][1] India has also experienced a similar economic boom since the implementation of economic liberalisation in the early 1990s.[17] When supranational entities are included, the European Union is the second largest economy in the world. It was the largest from 2004, when ten countries joined the union,[18] to 2014, after which it was surpassed by the United States.[19]\\r\\n\\r\\nThe first list includes estimates compiled by the International Monetary Fund's World Economic Outlook, the second list shows the World Bank's data, and the third list includes data compiled by the United Nations Statistics Division. The IMF  definitive data for the past year and estimates for the current year are published twice a year in April and October. Several economies which are not considered to be countries (the world, the European Union, and some dependent territories) are included in the lists because they appear in the sources as distinct economies. These economies are italicized and not ranked in the charts, but are listed where applicable.","input":"What country has the highest gross domestic product?"},{"output":"June 12, 2009","context":"\\r\\nThe DTV (an abbreviation of digital television, also called digital broadcast) transition in the United States was the switchover from analog (the traditional method of transmitting television signals) to exclusively digital broadcasting of free over-the-air television programming. According to David Rehr, then president and CEO of the National Association of Broadcasters, this transition represented \\"the most significant advancement of television technology since color TV was introduced.\\"[1] For full-power TV stations, the transition went into effect on June 12, 2009, with stations ending regular programming on their analog signals no later than 11:59pm local time that day.[2]\\r\\n\\r\\nUnder the Digital Transition and Public Safety Act of 2005, full-power broadcasting of analog television in the United States was initially planned to have ceased after February 17, 2009. To help U.S. consumers through the conversion, the Act also established a federally sponsored DTV Converter Box Coupon Program.\\r\\n\\r\\nThe DTV Delay Act changed the mandatory analog cutoff date to June 12, although stations were permitted to cease analog transmissions before the new mandatory cutoff date. The legislation was enacted on February 4, 2009, and on February 11, 2009, President Barack Obama signed it into law.[3][4] The purpose of the extension was to help the millions of households who had not been able to get their coupons for converters because demand for coupons exceeded the funding provided for in the initial bill, leaving millions on a waiting list to receive coupons. Funding for extra coupons was provided by the American Recovery and Reinvestment Act of 2009. By midnight on the original cut-off date of February 17, 2009, 641 stations representing 36 percent of U.S. full-power broadcasters were transmitting exclusively in digital.[5]\\r\\n\\r\\nAnalog broadcasting did not cease entirely following the June 12 deadline: under the provisions of the Short-term Analog Flash and Emergency Readiness Act, approximately 120 full-power stations briefly maintained analog \\"nightlight\\" service, ending no later than July 12.[6] In a separate category, low power television stations were permitted to continue analog broadcasts for several more years.\\r\\n\\r\\nOn July 15, 2011, the FCC posted the required transition deadlines for low power television. Stations broadcasting on channels 52 to 69 were required to vacate those channels by December 31, 2011, and all analog television transmitters (primarily low-powered (LP), and Class-A low-powered (-CA) stations, and also broadcast translator (TX) translator/repeaters in rural communities) were required to shut down by September 1, 2015.[7] On April 24, 2015, it was announced that the conversion date for standard LPTVs and translators still broadcasting in analog had been suspended until further notice, due to economic problems that may arise from the then-upcoming spectrum auction; however, Class A low-powered stations were still required to convert by the original deadline date of September 1, 2015.[8] After the auction's completion in 2017, the FCC announced on May 17 of that year that all analog low-power stations and transmitters must convert by July 13, 2021.[9]\\r\\n\\r\\nThe Congressional deadline to transition to digital broadcasts was pushed back several times. Congress passed the Telecommunications Act of 1996 with the original transition date of December 31, 2006.  However, the transition to digital television was set back three times: first to December 31, 2008, then to February 17, 2009, and then finally to June 12, 2009.[10]\\r\\n\\r\\nAll U.S. full-power analog TV broadcasts were required by law to end on June 12, 2009.[11] Since March 1, 2007, all new television devices that receive signals over-the-air, including pocket-sized portable televisions, personal computer video capture card tuners, and DVD recorders, have been required to include digital ATSC tuners.[12] Prior to this, the requirement was phased-in starting with larger screen sizes. Until the transition was completed, most U.S. broadcasters transmitted their signals in both analog and digital formats, though a few were already digital-only. Digital stations transmitted on another channel, which was assigned to each full-power broadcaster in a three-round digital channel election.\\r\\n\\r\\nThe transition from the analog NTSC format to the digital ATSC format was originally required to be completed on February 17, 2009, as set by Congress in the Digital Transition and Public Safety Act of 2005.[13] Following the analog switch-off, the FCC reallocated channels 52 through 69 (the 700?MHz band) for other communications traffic,[14] completing the reallocation of broadcast channels 52ÿ69 that began in the late 1990s. These channels were auctioned off in early 2008, with the winning bidders taking possession of them in June 2009. Four channels from this portion of the broadcast spectrum (60, 61, 68, and 69) were held for reallocation to public safety communications (such as police, fire, and emergency rescue). Some of the remaining freed up frequencies will be used for advanced commercial wireless services for consumers, such as Qualcomm's planned use of former UHF channel 55 for its MediaFLO service.[13][15]\\r\\n\\r\\nFor U.S. cable television, the FCC voted 5ÿ0 on September 12, 2007 to require operators to make local broadcasts available to their users in analog. This requirement lasts until 2012, when the FCC will review the case again.[needs update] This was necessary since many cable companies, including major ones like Comcast, have been taking analog channels away from customers.[16]\\r\\n\\r\\nIn 2007, a bill in the U.S. Congress called the DTV Border Fix Act was introduced. It would have allowed all television stations within 80 kilometers (50 miles) of the Mexican border, in areas such as San Diego and the Rio Grande Valley, to keep their analog signals active for another five years. The bill passed the Senate but did not pass the House.[17]\\r\\n\\r\\nThe SAFER Act was passed by Congress and signed by President Bush in December 2008.[18] The act has been called the \\"analog nightlight\\" act, and allows analog stations on channels that did not conflict with post-transition digital stations the option of leaving their analog transmitters on for an additional 30 days, but only to provide disaster information and information regarding the digital transition.\\r\\n\\r\\nDue to a lack of Commerce Department funds to provide for additional converter box coupons, and on account of other potential problems, the Barack Obama transition team asked Congress in a January 8, 2009, letter to delay the end of analog TV.  Gene Kimmelman of Consumers Union, which wanted a delay, feared older people, those outside cities and the poor needed help.[19]  Speaking to a group of area residents as part of a nationwide campaign to persuade people to upgrade, FCC chair Kevin Martin said in Raleigh, North Carolina that a delay was \\"unlikely,\\" and that it would be \\"unfair\\" to all those who made the effort to switch, and to those who bought the reallocated spectrum that was sold with the understanding analog broadcasts would end February 17, 2009.[20] The delay passed Congress despite this prediction (see Extension of transition to June 12).\\r\\n\\r\\nAs part of a test by the FCC to iron out transition and reception concerns before the nationwide shutoff, all of the major network stations in the Wilmington, North Carolina market ceased transmission of their analog signals on September 8, 2008, making it the first market in the nation to go digital-only. Wilmington was chosen as the test city in part because the area's digital channel positions would remain unchanged after the transition.[21] Wilmington was also appropriate because it had no hills to cause reception problems and all of the stations would have UHF channels.[22]\\r\\n\\r\\nThe low-power CBS affiliate WILM-LD signed on its new digital signal in time for the transition. The test excluded UNC-TV/PBS station WUNJ, which kept their analog signal on, as they were the official conduit of emergency information in the area.[23]\\r\\n\\r\\nViewers were notified of the change by months of public service announcements, town hall meetings, and local news coverage. Only 7% of viewers were affected by the loss of analog broadcasts, the remainder subscribing to cable or satellite services, but this produced 1,800 calls to the FCC for assistance. Officials were concerned by the implications of this for larger markets or those where reliance on over the air broadcasts exceeds 30%.[24]\\r\\n\\r\\nMore disturbingly, while many calls from viewers were straightforward questions about installation of antennas and converters, or the need to scan for channels before being able to watch digital television, hundreds more were from viewers who had installed converters and UHF antennas correctly but had still lost existing channels. Most affected were full-power broadcasters which had been on low-VHF channels. WECT (NBC 6 Wilmington), a signal which in its analog form reached to the edge of Myrtle Beach, could no longer be received by many who had watched the station for yearsÿ a victim of a move to UHF 44 at a different transmitter site. WECT's coverage area had been substantially reduced; for many who were on the fringes of the analog NBC 6 signal, WECT was no more.[25] However weeks before, new digital-only WMBF-TV, a new NBC affiliate, came to the air to serve Myrtle Beach with a city-grade signal; like WECT, WMBF is owned by Raycom Media.\\r\\n\\r\\nOn November 7, 2008, the FCC issued an order allowing distributed transmission systems to be constructed by stations which otherwise cannot cover their original analog footprint with their new digital channels and facilities.[26] While broadcasters may now apply for DTS facilities, this decision was made far too late to allow the extra transmitter sites to be constructed and operational before the original February 17, 2009 analog shutoff.[27]\\r\\n\\r\\nDigital TV encoding allows stations to offer higher definition video and better sound quality than analog, as well as allowing the option of programming multiple digital subchannels (multicasting). However, it provides these advantages at the cost of a severe limitation of broadcast range.\\r\\n\\r\\nDigital signals do not have 'grade b' signal areas, and are either 'in perfectly' or 'not in at all'. Further, since most stations have elected to use UHF rather than older VHF channel allocations, their actual broadcast range is far less than previously. Viewers in major metropolitan areas will likely not notice problems; however, rural TV users have generally had most and in some events all of the stations they previously received with acceptable but not 'perfect' signals fall over the digital cliff (as the loss of signal has been described).\\r\\n\\r\\nLastly, many low-power broadcasters have been temporarily permitted to transmit in analog for several years.[28]\\r\\n\\r\\nAlthough Britain spent the equivalent of more than a billion dollars educating about 60 million people, the National Telecommunications and Information Administration had received $5?million a year before the original transition date of February 17, 2009, and the FCC had received $2.5?million and was scheduled to receive $20?million more later in the year, for 300 million people. This meant voluntary education campaigns would be needed.[29] It was also noted that low-income, elderly, disabled, inner city, immigrants, and rural Americans were targeted the most, because these groups mainly watch analog antenna TV more than any other groups.[30]\\r\\n\\r\\nWhile broadcasters were forced by Federal Communications Commission regulations to devote the equivalent of more than a billion dollars worth of airtime to public service announcements regarding the digital transition, the amount of information conveyed in these short advertisements was by necessity limited. Both the on-air announcements and government-funded telephone hotlines receiving viewer inquiries directed consumers to Internet sites to seek information,[31] a problematic approach, as many of those most-affected do not use online media as a primary source of information.\\r\\n\\r\\nConsumers' old analog televisions, VCRs, DVRs, and other devices which lack a digital tuner no longer receive over-the-air television, though previously recorded content can still be replayed.[32]  The only real solution to this is to buy an external tuner (called a converter box) that receives DTV signals directly and converts them to analog for the television VCR or other analog device.\\r\\n\\r\\nUsers of analog VCRs, DVRs, or other recording devices which lack a digital tuner have a unique problem of no longer being able to record programs across multiple channels. In order to make them work with DTV the viewer must use an external tuner box and set the device to record the output from that box, typically L-1 for the line input. Some manufacturers such as Zinwell and Dish sell external converter boxes/tuners that will automatically change channels at preset times. The analog VCR or DVR may record at preset times but will continue recording the L-1 line input, which will be the same channel unless the channel is manually changed.\\r\\n\\r\\nAlternatively the user may purchase a new TV, DVR, or DVD recorder with a built-in digital tuner. However, these newer technologies have their own drawbacks, such as no way to store programs long-term (DVR) or being limited to only 1ÿ2 hours with high quality XP mode (DVD-R).[33]\\r\\n\\r\\nA major concern is that the broadcast technology used for ATSC signals called 8VSB has problems receiving signals inside buildings and in urban areas, largely due to multipath reception issues which cause ghosting and fading on analog images, but can lead to intermittent signal or no reception at all on ATSC programs.[34] DTV broadcasts exhibit a digital cliff effect, by which viewers will receive either a perfect signal or no signal at all with little or no middle ground. Digital transmissions do contain additional data bits to provide error correction for a finite number of bit errors; once signal quality degrades beyond that point, recovery of the original digital signal becomes impossible, and the image on the screen freezes, or blinks back and forth to totally blank black.\\r\\n\\r\\nThe maximum power for DTV broadcast classes is also substantially lower; one-fifth of the legal limits for the former full-power analog services. This is because there are only eight different states in which an 8VSB signal can be in at any one moment; thus, like all digital transmissions, very little signal is required at the receiver in order to decode it. Nonetheless, this limit is often too low for many stations to reach many rural areas, which was an alleged benefit in the FCC's choice of ATSC and 8VSB over worldwide-standard DVB-T and its COFDM modulation. Additionally, without the hierarchical modulation of DVB, signal loss is complete, and there is no switch to a lower resolution before this occurs.\\r\\n\\r\\nA hundred-kW analog station on TV channels 2 to 6 would therefore be faced with the choice of either lowering its power by 80% (to the twenty kilowatt limit of low-VHF DTV) or abandoning a frequency which it occupied since the 1950s in order to transmit more power (up to 1000?kW) on the less-crowded UHF TV band. Such stations can keep the same channel number, however, because of ATSC virtual channels. Unfortunately, the higher frequencies are challenged in areas where signals must travel great distances or encounter significant terrestrial obstacles. Most stations in the low-VHF (channels 2ÿ6) did not return to these frequencies after the transition. About 40 stations remained in the low-VHF after the transition, with the majority in smaller markets (with a few notable exceptions).[35] The FCC has long discouraged the digital allocation on low-VHF channels for several reasons: higher ambient noise, interference with FM radio (channel 6 borders FM at 88?MHz), and larger antenna size required for these channels.[36][37] After the transition, many viewers using \\"high-definition\\" antennas have reported problems receiving stations that broadcast on VHF channels.[38]  This is because some of the new antennas marketed as \\"HDTV antennas\\" from manufacturers such as Channel Master were only designed for channels 7ÿ51 and are more compact than their channel 2ÿ69 counterparts. These manufacturers did not anticipate widespread continued use of the relatively longer wavelength low-VHF channels.\\r\\n\\r\\nStations that broadcast in analog on channel 6 have had an additional benefit of having its audio feed broadcast on 87.7?MHz, which is at the very low end of the FM radio dial. As such, many stations that use channel 6 have taken advantage of this, and directly promote this feature, especially during drive time newscasts, and as a critical conduit of information in markets where severe weather (such as hurricanes) allowed a station the advantage to broadcast their audio via FM radio without having to contract with another FM operation to do so. WDSU in New Orleans, Miami's WTVJ and WECT in Wilmington, North Carolina were among the most well-known Channel 6 broadcasters which used this approach to provide emergency information during hurricanes.\\r\\n\\r\\nDigital television, however, does not have this feature, and after the transition, this additional method of reception is no longer available. WRGB, channel 6 in Albany, New York, used a separate transmitter on 87.7 that transmitted a vertically polarized analog audio signal, which would theoretically avoid interference with the horizontally polarized digital TV signal. This would allow the station to keep its audio on 87.7 FM after the transition to digital.[39] WRGB ran this transmitter for approximately 6 weeks on an experimental basis, only to find that the vertically polarized 87.7?MHz signal interfered with the digital video, while broadcast of analog signals on 87.9?MHz met with FCC objections. WITI in Milwaukee took a more direct though still experimental approach to restore their TV audio, having it restored in August 2009 to an HD Radio subchannel of WMIL-FM via a content agreement with WMIL owner Clear Channel Communications. A purchase of HD Radio equipment or having a car stereo equipped with an HD Radio receiver is required to listen to this broadcast.\\r\\n\\r\\nPlanning for DTV reception assumed \\"a properly oriented, high-gain antenna mounted 30 feet in the air outside.\\"[40] The Consumer Electronics Association set up a website called AntennaWeb to identify means to provide the correct signal reception to over-the-air viewers. Another website, TVFool provides geographic mapping and signal data to allow viewers to estimate the number of channels which will be gained or lost as a result of digital transition; while it estimated that marginally more stations would be gained than lost by viewers, this varied widely with viewers of low-VHF analog signals in distant-fringe areas among the most adversely affected. An estimated 1.8?million people were expected to lose the ability to access over-the-air TV entirely as a result of the digital transition.\\r\\n\\r\\nViewers in rural and mountainous regions were particularly prone to lose all reception after digital transition.[41]\\r\\n\\r\\nU.S. markets which have presented unique problems for digital transition include:\\r\\n\\r\\nThere are 80 media markets in which more than 100,000 households receive television signals by over-the-air broadcasts.[24]\\r\\n\\r\\nThe reclaimed channels will be used for a variety of service, including mobile phones, MediaFLO (55) and public safety (63/64 base, 68/69 mobile). Most of this mobile spectrum has been sold to existing incumbent providers, with AT&T Mobility and Verizon as the largest bidders (see United States 2008 wireless spectrum auction).\\r\\n\\r\\nThe elimination of UHF channels, rather than VHF channels as in the rest of the world, precludes the use of band III (high VHF) for Digital Audio Broadcasting as is used in a few other countries. It also makes more difficult the reassignment of channels 5 and 6 (76 to 88?MHz) to expand the FM radio broadcast band.[51] There are also no channels set aside for analog broadcasts of the Emergency Alert System, rendering most portable emergency TV sets useless. While a small number of portable ATSC sets have started to appear, these are costly.[52] A portable converter box (such as Winegard's RCDT09A) would require a bulky external battery and mobile ATSC is not yet available. Another option to people would be getting a USB-based TV tuner card for their laptop computer, which in addition to its low costs became a popular option after Microsoft released Windows 7 four months after the DTV transition ended.\\r\\n\\r\\nA Google-sponsored program called Free the Airwaves has started with the goal of using the \\"empty\\" white space within the remaining TV for unlicensed use, like for Wi-Fi.[53]\\r\\n\\r\\nIn March 2008, the FCC requested public comment on turning the bandwidth currently occupied by analog television channels 5 and 6 (76ÿ88?MHz) over to extending the FM broadcast band when the digital television transition was to be completed in February 2009 (ultimately delayed to June 2009).[54] This proposed allocation would effectively assign frequencies corresponding to the existing Japanese FM radio service (which begins at 76?MHz) for use as an extension to the existing North American FM broadcast band.\\r\\n\\r\\nOn August 22, 2011, the United States' Federal Communications Commission announced a freeze on all future applications for broadcast stations requesting to use channel 51,[55] to prevent adjacent-channel interference (ACI) to the A-Block of the 700?MHz band.  Later that year (on December 16, 2011), Industry Canada and the CRTC followed suit in placing a moratorium on future television stations using Channel 51 for broadcast use, to prevent ACI to the A-Block of the 700?MHz band.[56]\\r\\n\\r\\nNow that the switch from analog to digital broadcasts is complete, analog TVs are incapable of receiving over-the-air broadcasts without the addition of a set-top converter box. Consequently, a digital-to-analog converter, an electronic device that connects to an analog television, must be used in order to allow the television to receive digital broadcasts.[57] The box may also be called a \\"set-top\\" converter, \\"digital TV adapter\\" (DTA), or \\"digital set-top box\\" (DSTB).[58]\\r\\n\\r\\n  To assist consumers through the conversion, the Department of Commerce through its National Telecommunications and Information Administration (NTIA) division handled requests from households for up to two $40 coupons for digital-to-analog converter boxes[59] beginning January 1, 2008 via a toll free number or a website.[60][61]  The program was paid for with a small part of the $20?billion taken in from the DTV spectrum auction. However, these government coupons were limited to an initial sum of $890?million (22,250,000 coupons) with the option to grow to $1.34?billion (33,500,000 coupons),[62] which is far short of the estimated 112 million households (224?million redeemable coupons) in the United States.[63] Nevertheless, not every household took advantage of the offer, as reports indicate half of all households already had at least one digital TV.[64]  In January 2009, the NTIA began placing coupon requests on a waiting list after the program reached its maximum allowed funding. New requests for coupons were fulfilled only after unredeemed coupons expired.[65]\\r\\n\\r\\nThese coupons could be redeemed toward the purchase of a digital-to-analog converter at brick and mortar, on-line, and telephone retailers that had completed the NTIA certification process.[66] Retail prices for the boxes range from $40 to $70 (plus tax and/or shipping); after applying the coupons, the price to the consumer would be between $5 and $40 per box. Because it was actually used as a payment, despite the name \\"coupon\\", consumers paid pay state and local sales tax on the coupon amount, which in effect reduced its value by about $3 (based on 7?% tax).\\r\\n\\r\\nThere has been possible evidence that the presence of the government coupon program has inflated the prices of converter boxes by between $21 and $34 above what they would be otherwise.[67]\\r\\n\\r\\nOn January 21, 2009, Senator Jay Rockefeller introduced a bill in the Senate titled the DTV Delay Act because millions of Americans would not be ready for the cutoff on February 17 due to a shortage of converter box coupons, and planning that the transition date be moved to June 12. Rockefeller, chairman of the Committee on Commerce, Science and Transportation, and Sen. Kay Bailey Hutchison, worked together on the bill. Hutchison supported the idea because Rockefeller did not intend to ask for another postponement. On January 22, The Nielsen Company said 6.5?million Americans had not prepared for the switch. Opponents pointed out that TV stations would face extra operating expenses, and those who paid to use the spectrum to be made available would have to wait.\\r\\n\\r\\nUnder later amendments, stations could choose to end analog broadcasts before June 12 even if the bill passed, and any frequencies freed up by such action could be used by fire and police departments and other emergency services. Those whose converter box coupons had expired would be allowed to apply for new coupons. The House postponed a similar bill (by House Energy and Commerce Committee Chairman Henry Waxman), until the Senate's version was complete.[68][69]\\r\\n\\r\\nThe Senate unanimously voted on January 26, 2009 to delay the digital TV transition to June 12, 2009.[70] However, the House of Representatives voted on and defeated a similar measure on January 28.[69] Rep. Joe Barton led the movement in the House to defeat the measure, saying that \\"the DTV transition is neither stuck nor broke\\", and that any problems with the DTV transition can be fixed.[71] Barton also said, \\"I guarantee you, no matter when you set the date February 17, June 12, July the Fourth, Valentine's Day there are going to be some people that aren't ready.\\"[72][73]\\r\\n\\r\\nOn January 29, the DTV Delay Act passed in the Senate.[74][75]  On February 4, the House also approved this measure.[76][77][78]\\r\\n\\r\\nThe bill was submitted to President Obama on February 4, who did not immediately sign it into law. On February 9, President Obama posted the bill on whitehouse.gov, giving the public five days to weigh in on it. Under a midnight February 10 deadline imposed by the FCC, broadcasters disclosed whether they would still cease broadcasting analog signals on the original date of February 17, or if they would delay until June 12, should the DTV Delay Act be signed into law.[79] On February 10, the FCC published the list. 491 stations stated they intended to transition on February 17. The FCC reserved final say on which stations would be allowed to transition on February 17 and which ones would be required to continue analog broadcasts, depending on how many viewers in each market have been determined not ready for the transition[4][77][80][81]\\r\\nOwned & Operated stations of five major networks (ABC, CBS, Fox, NBC and Telemundo, plus The CW, MyNetworkTV and independent stations owned by CBS and MyNetworkTV stations owned by Fox), as well as the station groups of Gannett, Hearst-Argyle and Meredith, committed to keeping all or most of their analog signals active until the new June 12 cutoff date.[82][83] On February 11, 2009 President Obama signed the bill into law, officially moving the cutoff date to June 12, 2009.[3] In total, 191 stations already had turned off their analog transmitters for good.[80]\\r\\n\\r\\nOn February 20, 2009, the FCC released an order stating that stations that wish to go all digital before the final June 12, 2009 date must inform the FCC of that decision by March 17, 2009.[84][85]\\r\\n\\r\\nWhile 93 large-city network owned and operated stations (controlled by CBS, ABC, Fox TV and NBC) would continue analog broadcasts until June 12,[86] many small-market broadcasters were unable to justify the extra cost, with non-commercial and independent stations very adversely affected. No funding was provided to reimburse broadcasters who incurred additional costs due to the DTV Delay Act.\\r\\n\\r\\nPublic Broadcasting Service CEO Paula Kerger had estimated a $22?million cost to the nation's PBS member stations to extend simulcasting until June 12;[87] more than a hundred PBS stations ultimately elected to stick to the original deadline.[88] Some individual commercial station groups, most notably Sinclair Broadcast Group and Gray Television, shut down the vast majority of their analog signals on the original deadline. Others left the question to their individual local stations. Many local markets, ranging from Burlington, Vermont and Sioux City, Iowa[89]  to San Diego,[90] lost analog signals from most or all major U.S. stations. Some stations in coastal regions such as Fort Myers, Florida had chosen not to wait until June 12 so as to ensure transition is complete before hurricane season.[91]\\r\\n\\r\\nIn some cases, the Federal Communications Commission forced stations to continue full-power analog broadcast of at least a local newscast and information on the digital transition for an additional sixty days ÿ a costly move for individual affected broadcasters. Of 491 stations which had indicated their intention to go digital-only in February 2009,[92] 123 affiliates of four major U.S. commercial networks (ABC, CBS, Fox, NBC) were targeted by Federal Communications Commission opposition, precluding or applying additional restrictions to the shutdown of their analog signals[93] in markets where the only analog service remaining after the February 17 shutdown would have been an independent or educational broadcaster, an adjacent-market station or a low-power station.[94][95] Of approximately 1800 U.S. full-service TV stations, an additional 190 were already digital-only before February 2009; these included Hawaii (digital since January 2009) and Wilmington, North Carolina (the FCC's 2008 digital test market), as well as some new stations and a few broadcasters forced to shut down analog early due to technical problems.\\r\\n\\r\\nOn April 12, Nielsen estimated that 3.6?million households remained unready;[96] key problem markets (according to FCC and NTIA) included Albuquerque, Baltimore, Cleveland, DallasÿFort Worth, Denver, Fresno, Houston, Brownsville, Indianapolis,  Los Angeles, MinneapolisÿSt. Paul, Phoenix, Portland, Oregon, Tulsa, Sacramento, St. Louis, the San Francisco Bay Area, Salt Lake City and Seattle.\\r\\n\\r\\nOn February 11, 2009, the FCC announced it would allow 368 of the 491 applied stations to go all-digital on the original February 17 date, 100 of which will be allowed to use their analog signal to inform unprepared viewers of the new transition date, or for emergency situations such as severe weather (called \\"nightlighting\\"). The FCC concluded that the other 123 stations who applied present a \\"significant risk of substantial public harm,\\" if they go all digital on February 17. The FCC stated \\"We considered the presence of major networks and their affiliates critical to ensuring that viewers have access to local news and public affairs available over the air because the major network affiliates are the primary source of local broadcast news and public affairs programming\\". The FCC would not permit the 123 stations in \\"at-risk\\" markets to proceed unless they certify with the agency by 6?pm ET on February 13 that they comply with eight additional requirements, including ensuring that at least one station that is currently providing analog service to an area within the DMA provides DTV transition and emergency information, as well as local news and public affairs programming (\\"enhanced nightlight\\" service) for at least 60 days following February 17.[81][97][98][99]\\r\\n\\r\\nOn February 13, the FCC said 53 of the applied 106 at risk stations had qualified to go all digital on February 17. The other 43 qualified for nightlight service; 10 others could not comply with the nightlight clause. The total number stations which became digital only on February 17 was 421.[100][101]\\r\\n\\r\\nHouse Republican Joe Barton from Texas, who strongly opposed the DTV Delay Act (see above section for further details), introduced a bill that would insert $650?million in DTV transition assistance into The American Recovery and Reinvestment Act of 2009 to be used for making more converter box coupons available and for DTV education, which was strongly supported by the Obama administration.[69][102] The American Recovery and Reinvestment Act of 2009 passed with this revision in the House with a vote of 244ÿ188 on January 28, 2009,[103][104]\\r\\nand the Senate passed the bill on February 10 by a vote of 61ÿ37.[105]\\r\\n\\r\\nCongressional negotiators announced on February 11, 2009, that they had reached agreement on a $789?billion economic stimulus bill.[106] President Obama signed the final $787?billion version into law on February 17, 2009 in Denver, Colorado.[107] The final version included the DTV provisions.[108]\\r\\n\\r\\nWhile the economic stimulus bill did allow additional funds for coupons, there was also a risk that available retail stock of the converter boxes themselves could prove inadequate. The Consumer Electronics Association had estimated three to six million boxes remained in-stock at the beginning of February 2009; Nielsen Media Research reported five million households as \\"completely unready\\" for digital transition in this same time period. The average U.S. household uses 3 television screens.[109]\\r\\nHowever, the converter box coupon program only allows 2 coupons per household.\\r\\n\\r\\nThe American Recovery and Reinvestment Act of 2009 also allocated funds for expert installation services for those switching to DTV.[110]\\r\\n\\r\\nThe FCC awarded the contract to several companies to provide expert installation services.[111]\\r\\n\\r\\nOn May 1, 2009, Nielsen Media Research reported that 3.1% of Americans were still completely unprepared for the transition.[112] On June 11, 2009, one day before the analog shutoff, the National Association of Broadcasters reported that 1.75?million Americans were still not ready.[113]\\r\\n\\r\\n971 TV stations made the final switch to digital on June 12. It was believed Albuquerque, Santa Fe, Austin and Dallas would be the least prepared markets, but this turned out not to be the case, as most of the difficulties were in the Northeast, primarily with stations that changed their digital frequencies from UHF to VHF.\\r\\n\\r\\nOn June 13, 2009, the FCC said their help line, with about 4000 answering phones, received 317,450 calls on June 12. About one-third of callers still needed converter boxes, and one-fifth had reception problems. Acting FCC chair Michael Copps said, \\"Our job is far from over. This transition is not a one-day affair.\\"\\r\\n\\r\\nIn New York City, about 11,000 people called the FCC for assistance, the most of any market. The other areas from which the most calls to the FCC were made: Chicago (6526), Los Angeles (5473), Dallas-Fort Worth (5473), and Philadelphia (3749). 900,000 calls were received in all.\\r\\n\\r\\nThe National Association of Broadcasters said 278 TV stations received 35,500 calls, but most callers merely needed to rescan.\\r\\n\\r\\nThe Commerce Department said 319,900 requested converter box coupons on June 11, almost four times the average during the previous month.[114]\\r\\n\\r\\nSmithGeiger LLC said 2.2?million homes were not ready, while Nielsen said the number was 2.8?million. This included homes which had requested coupons.[115] On June 14, Nielsen said the number was 2.5?million, or 2.2 percent of homes. That number was down to 2.1?million, or 1.8 percent, by June 21,[116] and 1.7?million, or 1.5 percent, a week later.[117] One month after the transition, the number was 1.5?million, 1.3 percent,[118] and after nearly 2 months, the number was down to just over one million, or 1.1 percent.[119] As of August 30, 2009, the number was 710,000, as 572,000 had upgraded in August and 1.8?million since June 12.[120]\\r\\n\\r\\nIn some cases where digital frequencies moved, people have been advised not only to re-scan but to \\"double-scan\\", in order to clear outdated information from the digital TV or converter box memory.[114]\\r\\n\\r\\nCalls to the FCC decreased from 43,000 a day in the week ending June 15 to 21,000 the next week. Reception problems, representing nearly a third of calls at first, were down to one-fifth.[121]\\r\\n\\r\\nOn June 15, 2009, U.S. Representative Peter DeFazio, an Oregon Democrat, introduced the House version of The Digital TV Transition Fairness Act, which Senator Bernie Sanders introduced in December 2008. It would require video service providers to offer a $10 basic package to anyone who lost at least one channel to the DTV conversion (with broadcasters waiving fees), pay for outdoor antennas (including installation) and extend the converter box program beyond July 31.[122][123]  It did not pass.\\r\\n\\r\\nOne of the most common problems was the return to VHF frequencies by stations that had used them when they were analog. Over 480 stations were broadcasting digitally on the VHF spectrum after the transition, up from only 216 on the frequencies before. Many antennas marketed for digital TV are designed for UHF, which most digital stations use. VHF analog signals travel further than UHF signals, but watchable VHF digital signals appear to have a more limited range than UHF with the lower power they are assigned, and they don't penetrate buildings as well, especially in larger cities.[124][125] Mike Doback, vice president of engineering for Scripps Television, said, \\"Its only now that weve found out the planning factors were probably wrong in terms of how much power you need to replicate analog service.\\"[126] According to TV consultant Peter Putman, the problem with VHF reception is that VHF antennas must be large to be effective, and indoor antennas do not perform well enough. In addition, channels 2 through 6 are more susceptible to many types of interference.[22] Richard Mertz of Cavell, Mertz & Associates says multipath interference inside the house is also a factor. Some receivers can deal with this problem better than others, but there are no standards. And with amplified antennas or amplifiers, it is possible to overload a converter box. Amplifiers can also cause noise that is interpreted as data.[40] Raycom Media Chief Technology Officer Dave Folsom said, \\"Theres nothing inherently wrong with VHF. Its just easier to have interference, because it goes out further.\\"[126]\\r\\n\\r\\nThe FCC sent extra personnel to Chicago, Philadelphia, and New York City to deal with difficulties in those cities. WLS-TV had received 1,735 calls just by the end of the day on June 12, and an estimated 5000 calls in total by June 16. WLS-TV is just one station which may solve its problems by increasing its signal strength, but doing this required making sure no other stations are affected.[127] A low-power analog station, not required to shut down after 30 days like other nightlight stations, aired newscasts that could not be seen by a number of people after the transition, while the stations attempted to solve problems.[128]\\r\\n\\r\\nIn Philadelphia, most of the problems were with WPVI-TV, which had the area's leading news program, and public station WHYY-TV. Many people having trouble with those stations could pick up stations from Reading and Atlantic City.[129] Unlike WLS, WPVI had concerns about increasing its signal because of potential interference to other stations and to FM radio.\\r\\n\\r\\nIn New York City, many called the FCC because they lived in apartment buildings with a single roof antenna which was not suitable for digital reception. The city reported antenna shortages and numerous requests for cable service.[114]\\r\\n\\r\\nBy the end of June, four stations had received permission to increase power. Ten other stations asked for power increases as well, but these were not in major cities; instead, the markets were in rural or mountainous areas such as Montana, Virginia, and Alabama.[130] KNMD-TV in Santa Fe tried an alternate VHF channel.[131]\\r\\n\\r\\nThe FCC had two concerns about the requests for more power: some stations just wanted a competitive advantage and were not actually experiencing difficulties. Other stations wanted UHF frequencies instead because UHF worked better with mobile digital TV. However, some stations with legitimate problems have asked to return to their UHF frequencies.[130]\\r\\n\\r\\nTwo months after the transition, \\"two or three-dozen\\" stations continued to have problems.[132]  Three months after the transition, about 50 stations had applied for a power increase.[22]\\r\\n\\r\\n\\"Approximately a half-dozen stations\\" were still deciding at the end of October about what to do.[133]  In some of the cases where stations returned to UHF, interference to nearby stations prevented a power increase.\\r\\n\\r\\nIronically, KUAC-TV in Fairbanks, Alaska moved from channel 24 back to channel 9 in September 2009. The area never had UHF before DTV, so most people had VHF antennas, while few people lived in apartment buildings. The higher power needed for UHF cost too much, and channel 24 had signal problems, so the station asked to move back.[citation needed]\\r\\n\\r\\nOf 79 stations asking for a new channel, 22 wanted to go from VHF to UHF, and 10 wanted to go from UHF to VHF.[126]\\r\\n\\r\\nOn June 30, his first day as FCC Chairman, Julius Genachowski said in a speech that the transition \\"succeeded far beyond expectations. You pulled it off by working collaboratively with each other across the agency, and with the Commerce Department and other parts of government, and by thinking creatively to leverage all available resources.\\"[134]\\r\\n\\r\\nStill, the FCC planned a report on how well the transition went, and Genachowski admitted more work was needed.[121]\\r\\n\\r\\nGenachowski's predecessor Michael Copps called the process\\r\\n\\r\\nA huge transition with significant impact on consumers that was not until the last moment adequately planned for or coordinated. [It was] a transition that led to problems that were largely predictable and one that we moved measurably forward from January to June to the benefit of many consumers. But it's not a closed book. It is ongoing. There are still problems out there, lessons to be learned and a document to write.[135]\\r\\nIn September 2010, the FCC announced a proposal to set a hard deadline of 2012 for low power stations to broadcast in digital, though this deadline was not adopted.\\r\\n\\r\\nOn July 15, 2011, the Federal Communications Commission issued a final ruling regarding Broadcast translator (TX), Low-powered (LP), and Class-A low-powered (-CA) stations, requiring that analog transmitters shut down by September 1, 2015.[136]  Transmitters on channels 52 to 69 were required to vacate their channels by December 31, 2011, but may remain in analog on another channel until the September 1, 2015 deadline.  As part of the rules that were imposed, low power VHF stations on channels 2 to 6 can transmit with a maximum ERP 3?kW instead of the previously allowed maximum of 0.3?kW.\\r\\n\\r\\nOn August 13, 2009, the Community Broadcasters Association (CBA) announced in a statement that it would shut down after 20 years of representing LPTV stations. One reason given was the cost required to fight \\"restrictive regulations that kept the Class A and LPTV industry from realizing its potential,\\" including the campaign to require analog passthrough, a converter box feature that allows both digital and analog television to be viewed on older TVs. Amy Brown, former CBA executive director, said, \\"some 40% of Class A and LPTV station operators believe they will have to shut down in the next year if they are not helped through the digital transition.\\"[137] On April 24, 2015, the requirement for broadcast translator (TX) and low-powered (-LP) stations to convert by September 1 of that year was suspended, pending the then-upcoming spectrum auction.[138] After the auction's completion in 2017, on May 17 of that year the FCC announced July 13, 2021 as the new analog low-power shutoff date.[139]\\r\\n\\r\\nThe study of how to increase spectrum for wireless broadband began in 2009. Some plans called for eliminating broadcast TV entirely, but opponents of such a plan said the efforts made during the DTV transition would become pointless. By 2010, voluntary efforts were planned. Sharing channels, made possible by the first transition, was approved in 2012. A spectrum auction planned for 2014 (and delayed to 2016) became the first step in what amounted to a second digital transition.[citation needed]","input":"When did tv go from analog to digital?"},{"output":"five arms, though some species have a larger number of arms","context":"\\r\\n\\r\\n? Calliasterellidae \\r\\n? Trichasteropsida[2]\\r\\n\\r\\nStarfish or sea stars are star-shaped echinoderms belonging to the class Asteroidea. Common usage frequently finds these names being also applied to ophiuroids, which are correctly referred to as brittle stars or \\"basket stars\\". About 1,500 species of starfish occur on the seabed in all the world's oceans, from the tropics to frigid polar waters. They are found from the intertidal zone down to abyssal depths, 6,000?m (20,000?ft) below the surface.\\r\\n\\r\\nStarfish are marine invertebrates. They typically have a central disc and five arms, though some species have a larger number of arms. The aboral or upper surface may be smooth, granular or spiny, and is covered with overlapping plates. Many species are brightly coloured in various shades of red or orange, while others are blue, grey or brown. Starfish have tube feet operated by a hydraulic system and a mouth at the centre of the oral or lower surface. They are opportunistic feeders and are mostly predators on benthic invertebrates. Several species have specialized feeding behaviours including eversion of their stomachs and suspension feeding. They have complex life cycles and can reproduce both sexually and asexually. Most can regenerate damaged parts or lost arms and they can shed arms as a means of defence. The Asteroidea occupy several significant ecological roles. Starfish, such as the ochre sea star (Pisaster ochraceus) and the reef sea star (Stichaster australis), have become widely known as examples of the keystone species concept in ecology. The tropical crown-of-thorns starfish (Acanthaster planci) is a voracious predator of coral throughout the Indo-Pacific region, and the northern Pacific sea star is considered to be one of the world's 100 worst invasive species.\\r\\n\\r\\nThe fossil record for starfish is ancient, dating back to the Ordovician around 450 million years ago, but it is rather sparse, as starfish tend to disintegrate after death. Only the ossicles and spines of the animal are likely to be preserved, making remains hard to locate. With their appealing symmetrical shape, starfish have played a part in literature, legend, design and popular culture. They are sometimes collected as curios, used in design or as logos, and in some cultures, despite possible toxicity, they are eaten.\\r\\n\\r\\nMost starfish have five arms that radiate from a central disc, but the number varies with the group. Some species have six or seven arms and others have 10ÿ15 arms.[3] The Antarctic Labidiaster annulatus can have over fifty.[4] Having descended from bilateral organisms, starfish move in a bilateral fashion, with certain arms acting like the front of the animal.[3]\\r\\n\\r\\nThe body wall consists of a thin cuticle, an epidermis consisting of a single layer of cells, a thick dermis formed of connective tissue and a thin coelomic myoepithelial layer, which provides the longitudinal and circular musculature. The dermis contains an endoskeleton of calcium carbonate components known as ossicles. These are honeycombed structures composed of calcite microcrystals arranged in a lattice.[5] They vary in form, with some bearing external granules, tubercles and spines, but most are tabular plates that fit neatly together in a tessellated manner and form the main covering of the aboral surface.[6]  Some are specialised structures such as the madreporite (the entrance to the water vascular system), pedicellariae and paxillae.[5] Pedicellariae are compound ossicles with forceps-like jaws. They remove debris from the body surface and wave around on flexible stalks in response to physical or chemical stimuli while continually making biting movements. They often form clusters surrounding spines.[7][8] Paxillae are umbrella-like structures found on starfish that live buried in sediment. The edges of adjacent paxillae meet to form a false cuticle with a water cavity beneath in which the madreporite and delicate gill structures are protected. All the ossicles, including those projecting externally, are covered by the epidermal layer.[5]\\r\\n\\r\\nSeveral groups of starfish, including Valvatida and Forcipulatida, possess pedicellariae.[7] In Forcipulatida, such as Asterias and Pisaster, they occur in pompom-like tufts at the base of each spine, whereas in the Goniasteridae, such as Hippasteria phrygiana, the pedicellariae are scattered over the body surface. Some are thought to assist in defence, while others aid in feeding or in the removal of organisms attempting to settle on the starfish's surface.[9] Some species like Labidiaster annulatus, Rathbunaster californicus and Novodinia antillensis use their large pedicellariae to capture small fish and crustaceans.[10]\\r\\n\\r\\nThere may also be papulae, thin-walled protrusions of the body cavity that reach through the body wall and extend into the surrounding water. These serve a respiratory function.[11] The structures are supported by collagen fibres set at right angles to each other and arranged in a three-dimensional web with the ossicles and papulae in the interstices. This arrangement enables both easy flexion of the arms by the starfish and the rapid onset of stiffness and rigidity required for actions performed under stress.[12]\\r\\n\\r\\nThe water vascular system of the starfish is a hydraulic system made up of a network of fluid-filled canals and is concerned with locomotion, adhesion, food manipulation and gas exchange. Water enters the system through the madreporite, a porous, often conspicuous, sieve-like ossicle on the aboral surface. It is linked through a stone canal, often lined with calcareous material, to a ring canal around the mouth opening. A set of radial canals leads off this; one radial canal runs along the ambulacral groove in each arm. There are short lateral canals branching off alternately to either side of the radial canal, each ending in an ampulla. These bulb-shaped organs are joined to tube feet (podia) on the exterior of the animal by short linking canals that pass through ossicles in the ambulacral groove. There are usually two rows of tube feet but in some species, the lateral canals are alternately long and short and there appear to be four rows. The interior of the whole canal system is lined with cilia.[13]\\r\\n\\r\\nWhen longitudinal muscles in the ampullae contract, valves in the lateral canals close and water is forced into the tube feet. These extend to contact the substrate. Although the tube feet resemble suction cups in appearance, the gripping action is a function of adhesive chemicals rather than suction.[14]  Other chemicals and relaxation of the ampullae allow for release from the substrate. The tube feet latch on to surfaces and move in a wave, with one arm section attaching to the surface as another releases.[15][16] Some starfish turn up the tips of their arms while moving which gives maximum exposure of the sensory tube feet and the eyespot to external stimuli.[17]\\r\\n\\r\\nIn some situations, particularly when hunting or in danger, starfish may move in a bilateral fashion. When crawling, some arms act as the leading arms, while others trail behind.[18][8] Most starfish cannot move quickly, a typical speed being that of the leather star (Dermasterias imbricata), which can manage just 15?cm (6?in) in a minute.[19] Some burrowing species from the genera Astropecten and Luidia have points rather than suckers on their long tube feet and are capable of much more rapid motion, \\"gliding\\" across the ocean floor. The sand star (Luidia foliolata) can travel at a speed of 2.8?m (9?ft 2?in) per minute.[20] When a starfish finds itself upside down, two adjacent arms are bent backwards to provide support, the opposite arm is used to stamp the ground while the two remaining arms are raised on either side; finally the stamping arm is released as the starfish turns itself over and recovers its normal stance.[18]\\r\\n\\r\\nApart from their function in locomotion, the tube feet act as accessory gills. The water vascular system serves to transport oxygen from, and carbon dioxide to, the tube feet and also nutrients from the gut to the muscles involved in locomotion. Fluid movement is bidirectional and initiated by cilia.[13] Gas exchange also takes place through other gills known as papulae, which are thin-walled bulges on the aboral surface of the disc and arms. Oxygen is transferred from these to the coelomic fluid, which acts as the transport medium for gasses. Oxygen dissolved in the water is distributed through the body mainly by the fluid in the main body cavity; the circulatory system may also play a minor role.[21]\\r\\n\\r\\nThe gut of a starfish occupies most of the disc and extends into the arms. The mouth is located in the centre of the oral surface, where it is surrounded by a tough peristomial membrane and closed with a sphincter. The mouth opens through a short oesophagus into a stomach divided by a constriction into a larger, eversible cardiac portion and a smaller pyloric portion. The cardiac stomach is glandular and pouched, and is supported by ligaments attached to ossicles in the arms so it can be pulled back into position after it has been everted. The pyloric stomach has two extensions into each arm: the pyloric caeca. These are elongated, branched hollow tubes that are lined by a series of glands, which secrete digestive enzymes and absorb nutrients from the food. A short intestine and rectum run from the pyloric stomach to open at a small anus at the apex of the aboral surface of the disc.[22]\\r\\n\\r\\nPrimitive starfish, such as Astropecten and Luidia, swallow their prey whole, and start to digest it in their cardiac stomachs. Shell valves and other inedible materials are ejected through their mouths. The semi-digested fluid is passed into their pyloric stomachs and caeca where digestion continues and absorption ensues.[22] In more advanced species of starfish, the cardiac stomach can be everted from the organism's body to engulf and digest food. When the prey is a clam or other bivalve, the starfish pulls with its tube feet to separate the two valves slightly, and inserts a small section of its stomach, which releases enzymes to digest the prey. The stomach and the partially digested prey are later retracted into the disc. Here the food is passed on to the pyloric stomach, which always remains inside the disc.[23] The retraction and contraction of the cardiac stomach is activated by a neuropeptide known as NGFFYamide.[24]\\r\\n\\r\\nBecause of this ability to digest food outside the body, starfish can hunt prey much larger than their mouths. Their diets include clams and oysters, arthropods, small fish and gastropod molluscs. Some starfish are not pure carnivores, supplementing their diets with algae or organic detritus. Some of these species are grazers, but others trap food particles from the water in sticky mucus strands that are swept towards the mouth along ciliated grooves.[22]\\r\\n\\r\\nThe main nitrogenous waste product is ammonia. Starfish have no distinct excretory organs; waste ammonia is removed by diffusion through the tube feet and papulae.[21] The body fluid contains phagocytic cells, coelomocytes, which are also found within the hemal and water vascular systems. These cells engulf waste material, and eventually migrate to the tips of the papulae, where a portion of body wall is nipped off and ejected into the surrounding water. Some waste may also be excreted by the pyloric glands and voided with the faeces.[21]\\r\\n\\r\\nStarfish do not appear to have any mechanisms for osmoregulation, and keep their body fluids at the same salt concentration as the surrounding water. Although some species can tolerate relatively low salinity, the lack of an osmoregulation system probably explains why starfish are not found in fresh water or even in many estuarine environments.[21]\\r\\n\\r\\nAlthough starfish do not have many well-defined sense organs, they are sensitive to touch, light, temperature, orientation and the status of the water around them. The tube feet, spines and pedicellariae are sensitive to touch. The tube feet, especially those at the tips of the rays, are also sensitive to chemicals, enabling the starfish to detect odour sources such as food.[23] There are eyespots at the ends of the arms, each one made of 80ÿ200 simple ocelli. These are composed of pigmented epithelial cells that respond to light and are covered by a thick, transparent cuticle that both protects the ocelli and acts to focus light. Many starfish also possess individual photoreceptor cells in other parts of their bodies and respond to light even when their eyespots are covered. Whether they advance or retreat depends on the species.[25]\\r\\n\\r\\nWhile a starfish lacks a centralized brain, it has a complex nervous system with a nerve ring around the mouth and a radial nerve running along the ambulacral region of each arm parallel to the radial canal. The peripheral nerve system consists of two nerve nets: a sensory system in the epidermis and a motor system in the lining of the coelomic cavity. Neurons passing through the dermis connect the two.[25] The ring nerves and radial nerves have sensory and motor components and coordinate the starfish's balance and directional systems.[11] The sensory component receives input from the sensory organs while the motor nerves control the tube feet and musculature. The starfish does not have the capacity to plan its actions. If one arm detects an attractive odour, it becomes dominant and temporarily over-rides the other arms to initiate movement towards the prey. The mechanism for this is not fully understood.[25]\\r\\n\\r\\nThe body cavity contains the circulatory or haemal system. The vessels form three rings: one around the mouth (the hyponeural haemal ring), another around the digestive system (the gastric ring) and the third near the aboral surface (the genital ring). The heart beats about six times a minute and is at the apex of a vertical channel (the axial vessel) that connects the three rings. At the base of each arm are paired gonads; a lateral vessel extends from the genital ring past the gonads to the tip of the arm. This vessel has a blind end and there is no continuous circulation of the fluid within it. This liquid does not contain a pigment and has little or no respiratory function but is probably used to transport nutrients around the body.[26]\\r\\n\\r\\nStarfish produce a large number of secondary metabolites in the form of lipids, including steroidal derivatives of cholesterol, and fatty acid amides of sphingosine. The steroids are mostly saponins, known as asterosaponins, and their sulphated derivatives. They vary between species and are typically formed from up to six sugar molecules (usually glucose and galactose) connected by up to three glycosidic chains. Long-chain fatty acid amides of sphingosine occur frequently and some of them have known pharmacological activity. Various ceramides are also known from starfish and a small number of alkaloids have also been identified. The functions of these chemicals in the starfish have not been fully investigated but most have roles in defence and communication. Some are feeding deterrents used by the starfish to discourage predation. Others are antifoulants and supplement the pedicellariae to prevent other organisms from settling on the starfish's aboral surface. Some are alarm pheromones and escape-eliciting chemicals, the release of which trigger responses in conspecific starfish but often produce escape responses in potential prey.[27] Research into the efficacy of these compounds for possible pharmacological or industrial use occurs worldwide.[28]\\r\\n\\r\\nMost species of starfish are gonochorous, there being separate male and female individuals. These are usually not distinguishable externally as the gonads cannot be seen, but their sex is apparent when they spawn. Some species are simultaneous hermaphrodites, producing eggs and sperm at the same time and in a few of these, the same gonad, called an ovotestis, produces both eggs and sperm.[29] Other starfish are sequential hermaphrodites. Protandrous individuals of species like Asterina gibbosa start life as males before changing sex into females as they grow older. In some species such as Nepanthia belcheri, a large female can split in half and the resulting offspring are males. When these grow large enough they change back into females.[30]\\r\\n\\r\\nEach starfish arm contains two gonads that release gametes through openings called gonoducts, located on the central disc between the arms. Fertilization is generally external but in a few species, internal fertilization takes place. In most species, the buoyant eggs and sperm are simply released into the water (free spawning) and the resulting embryos and larvae live as part of the plankton. In others, the eggs may be stuck to the undersides of rocks.[31] In certain species of starfish, the females brood their eggs ÿ either by simply enveloping them[31] or by holding them in specialised structures. Brooding may be done in pockets on the starfish's aboral surface,[32][33] inside the pyloric stomach (Leptasterias tenera)[34] or even in the interior of the gonads themselves.[29] Those starfish that brood their eggs by \\"sitting\\" on them usually assume a humped posture with their discs raised off the substrate.[35] Pteraster militaris broods a few of its young and disperses the remaining eggs, that are too numerous to fit into its pouch.[32] In these brooding species, the eggs are relatively large, and supplied with yolk, and they generally develop directly into miniature starfish without an intervening larval stage.[29] The developing young are called lecithotrophic because they obtain their nutrition from the yolk as opposed to \\"planktotrophic\\" larvae that feed in the water column. In Parvulastra parvivipara, an intragonadal brooder, the young starfish obtain nutrients by eating other eggs and embryos in the brood pouch.[36] Brooding is especially common in polar and deep-sea species that live in environments unfavourable for larval development[33] and in smaller species that produce just a few eggs.[37][38]\\r\\n\\r\\nIn the tropics, a plentiful supply of phytoplankton is continuously available for starfish larvae to feed on. Spawning takes place at any time of year, each species having its own characteristic breeding season.[39] In temperate regions, the spring and summer brings an increase in food supplies. The first individual of a species to spawn may release a pheromone that serves to attract other starfish to aggregate and to release their gametes synchronously.[40] In other species, a male and female may come together and form a pair.[41][42] This behaviour is called pseudocopulation[43] and the male climbs on top, placing his arms between those of the female. When she releases eggs into the water, he is induced to spawn.[40] Starfish may use environmental signals to coordinate the time of spawning (day length to indicate the correct time of the year,[41] dawn or dusk to indicate the correct time of day), and chemical signals to indicate their readiness to breed. In some species, mature females produce chemicals to attract sperm in the sea water.[44]\\r\\n\\r\\nMost starfish embryos hatch at the blastula stage. The original ball of cells develops a lateral pouch, the archenteron. The entrance to this is known as the blastopore and it will later develop into the anus. Another invagination of the surface will fuse with the tip of the archenteron as the mouth while the interior section will become the gut. At the same time, a band of cilia develops on the exterior. This enlarges and extends around the surface and eventually onto two developing arm-like outgrowths. At this stage the larva is known as a bipinnaria. The cilia are used for locomotion and feeding, their rhythmic beat wafting phytoplankton towards the mouth.[7]\\r\\n\\r\\nThe next stage in development is a brachiolaria larva and involves the growth of three short, additional arms. These are  at the anterior end, surround a sucker and have adhesive cells at their tips. Both bipinnaria and brachiolaria larvae are bilaterally symmetrical. When fully developed, the brachiolaria settles on the seabed and attaches itself with a short stalk formed from the ventral arms and sucker. Metamorphosis now takes place with a radical rearrangement of tissues. The left side of the larval body becomes the oral surface of the juvenile and the right side the aboral surface. Part of the gut is retained but the mouth and anus move to new positions. Some of the body cavities degenerate but others become the water vascular system and the visceral coelom. The starfish is now pentaradially symmetrical. It casts off its stalk and becomes a free-living juvenile starfish about 1?mm (0.04?in) in diameter. Starfish of the order Paxillosida have no brachiolaria stage, with the bipinnaria larvae settling on the seabed and developing directly into juveniles.[7]\\r\\n\\r\\nSome species of starfish are able to reproduce asexually as adults either by fission of their central discs[45] or by autotomy of one or more of their arms. Which of these processes occurs depends on the genus. Among starfish that are able to regenerate their whole body from a single arm, some can do so even from fragments just 1?cm (0.4?in) long.[46] Single arms that regenerate a whole individual are called comet forms. The division of the starfish, either across its disc or at the base of the arm, is usually accompanied by a weakness in the structure that provides a fracture zone.[47]\\r\\n\\r\\nThe larvae of several species of starfish can reproduce asexually before they reach maturity.[48] They do this by autotomising some parts of their bodies or by budding.[49] When such a larva senses that food is plentiful, it takes the path of asexual reproduction rather than normal development.[50] Though this costs it time and energy and delays maturity, it allows a single larva to give rise to multiple adults when the conditions are appropriate.[49]\\r\\n\\r\\nSome species of starfish have the ability to regenerate lost arms and can regrow an entire new limb given time.[46]  A few can regrow a complete new disc from a single arm, while others need at least part of the central disc to be attached to the detached part.[21] Regrowth can take several months or years,[46] and starfish are vulnerable to infections during the early stages after the loss of an arm. A separated limb lives off stored nutrients until it regrows a disc and mouth and is able to feed again.[46] Other than fragmentation carried out for the purpose of reproduction, the division of the body may happen inadvertently due to part being detached by a predator, or part may be actively shed by the starfish in an escape response.[21] The loss of parts of the body is achieved by the rapid softening of a special type of connective tissue in response to nervous signals. This type of tissue is called catch connective tissue and is found in most echinoderms.[51] An autotomy-promoting factor has been identified which, when injected into another starfish, causes rapid shedding of arms.[52]\\r\\n\\r\\nThe lifespan of a starfish varies considerably between species, generally being longer in larger forms and in those with planktonic larvae. For example, Leptasterias hexactis broods a small number of large-yolked eggs. It has an adult weight of 20?g (0.7?oz), reaches sexual maturity in two years and lives for about ten years.[7] Pisaster ochraceus releases a large number of eggs into the sea each year and has an adult weight of up to 800?g (28?oz). It reaches maturity in five years and has a maximum recorded lifespan of 34 years.[7]\\r\\n\\r\\nEchinoderms, including starfish, maintain a delicate internal electrolyte balance that is in equilibrium with sea water. This means that it is only possible for them to live in a marine environment and they are not found in any freshwater habitats.[15] Starfish species inhabit all of the world's oceans. Habitats range from tropical coral reefs, rocky shores, tidal pools, mud, and sand to kelp forests, seagrass meadows[53] and the deep-sea floor down to at least 6,000?m (20,000?ft).[54] The greatest diversity of species occurs in coastal areas.[53]\\r\\n\\r\\nMost species are generalist predators, eating microalgae, sponges, bivalves, snails and other small animals.[23][55] The crown-of-thorns starfish consumes coral polyps,[56] while other species are detritivores, feeding on decomposing organic material and faecal matter.[55][57] A few are suspension feeders, gathering in phytoplankton; Henricia and Echinaster often occur in association with sponges, benefiting from the water current they produce.[58] Various species have been shown to be able to absorb organic nutrients from the surrounding water, and this may form a significant portion of their diet.[58]\\r\\n\\r\\nThe processes of feeding and capture may be aided by special parts; Pisaster brevispinus, the short-spined pisaster from the West Coast of America, can use a set of specialized tube feet to dig itself deep into the soft substrate to extract prey (usually clams).[59] Grasping the shellfish, the starfish slowly pries open the prey's shell by wearing out its adductor muscle, and then inserts its everted stomach into the crack to digest the soft tissues. The gap between the valves need only be a fraction of a millimetre wide for the stomach to gain entry.[15]\\r\\n\\r\\nStarfish are keystone species in their respective marine communities. Their relatively large sizes, diverse diets and ability to adapt to different environments makes them ecologically important.[60] The term \\"keystone species\\" was in fact first used by Robert Paine in 1966 to describe a starfish, Pisaster ochraceus.[61] When studying the low intertidal coasts of Washington state, Paine found that predation by P.?ochraceus was a major factor in the diversity of species. Experimental removals of this top predator from a stretch of shoreline resulted in lower species diversity and the eventual domination of Mytilus mussels, which were able to outcompete other organisms for space and resources.[62] Similar results were found in a 1971 study of Stichaster australis on the intertidal coast of the South Island of New Zealand. S.?australis was found to have removed most of a batch of transplanted mussels within two or three months of their placement, while in an area from which S.?australis had been removed, the mussels increased in number dramatically, overwhelming the area and threatening biodiversity.[63]\\r\\n\\r\\nThe feeding activity of the omnivorous starfish Oreaster reticulatus on sandy and seagrass bottoms in the Virgin Islands appears to regulate the diversity, distribution and abundance of microorganisms. These starfish engulf piles of sediment removing the surface films and algae adhering to the particles.[64]  Organisms that dislike this disturbance are replaced by others better able to rapidly recolonise \\"clean\\" sediment. In addition, foraging by these migratory starfish creates diverse patches of organic matter, which may play a role in the distribution and abundance of organisms such as fish, crabs and sea urchins that feed on the sediment.[65]\\r\\n\\r\\nStarfish sometimes have negative effects on ecosystems. Outbreaks of crown-of-thorns starfish have caused damage to coral reefs in Northeast Australia and French Polynesia.[56][66] A study in Polynesia found that coral cover declined drastically with the arrival of migratory starfish in 2006, dropping from 50% to under 5% in three years. This had an unintended effect on reef-feeding fish and the whole benthic community.[56] Asterias amurensis is one of a few echinoderm invasive species. Its larvae likely arrived in Tasmania from central Japan via water discharged from ships in the 1980s. The species has since grown in numbers to the point where they threaten commercially important bivalve populations. As such, they are considered pests,[67] and are on the Invasive Species Specialist Group's list of the world's 100 worst invasive species.[68]\\r\\n\\r\\nStarfish may be preyed on by conspecifics, other starfish species, tritons, crabs, fish, gulls and sea otters.[37][67][69][70] Their first lines of defence are the saponins present in their body walls, which have unpleasant flavours.[71] Some starfish such as Astropecten polyacanthus also include powerful toxins such as tetrodotoxin among their chemical armoury, and the slime star can ooze out large quantities of repellent mucus. They also have body armour in the form of hard plates and spines.[72] The crown-of-thorns starfish is particularly unattractive to potential predators, being heavily defended by sharp spines, laced with toxins and sometimes with bright warning colours.[73] Other species protect their vulnerable tube feet and arm tips by lining their ambulacral grooves with spines and heavily plating their extremities.[72]\\r\\n\\r\\nSeveral species sometimes suffer from a wasting condition caused by bacteria in the genus Vibrio;[69] however, a more widespread wasting disease, causing mass mortalities among starfish, appears sporadically. A paper published in November 2014 revealed the most likely cause of this disease to be a densovirus the authors named sea star-associated densovirus (SSaDV).[74]\\r\\nThe protozoan Orchitophrya stellarum is known to infect the gonads of starfish and damage tissue.[69] Starfish are vulnerable to high temperatures. Experiments have shown that the feeding and growth rates of P. ochraceus reduce greatly when their body temperatures rise above 23?C (73?F) and that they die when their temperature rises to 30?C (86?F).[75][76] This species has a unique ability to absorb seawater to keep itself cool when it is exposed to sunlight by a receding tide.[77] It also appears to rely on its arms to absorb heat, so as to protect the central disc and vital organs like the stomach.[78]\\r\\n\\r\\nStarfish and other echinoderms are sensitive to marine pollution.[79] The common starfish is considered to be a bioindicator for marine ecosystems.[80] A 2009 study found that P. ochraceus is unlikely to be affected by ocean acidification as severely as other marine animals with calcareous skeletons. In other groups, structures made of calcium carbonate are vulnerable to dissolution when the pH is lowered. Researchers found that when P. ochraceus were exposed to 21?C (70?F) and 770?ppm carbon dioxide (beyond rises expected in the next century), they were relatively unaffected. Their survival is likely due to the nodular nature of their skeletons, which are able to compensate for a shortage of carbonate by growing more fleshy tissue.[81]\\r\\n\\r\\nEchinoderms first appeared in the fossil record in the Cambrian.  The first known asterozoans were the Somasteroidea, which exhibit characteristics of both groups.[82] Starfish are infrequently found as fossils, possibly because their hard skeletal components separate as the animal decays. Despite this, there are a few places where accumulations of complete skeletal structures occur, fossilized in place in Lagerst?tten  so-called \\"starfish beds\\".[83]\\r\\n\\r\\nBy the late Paleozoic, the crinoids and blastoids were the predominant echinoderms, and some limestones from this period are made almost entirely from fragments from these groups. In the two major extinction events that occurred during the late Devonian and late Permian, the blastoids were wiped out and only a few species of crinoids survived.[82] Many starfish species also became extinct in these events, but afterwards the surviving few species diversified rapidly within about sixty million years during the Early Jurassic and the beginning of the Middle Jurassic.[84][85] A 2012 study found that speciation in starfish can occur rapidly. During the last 6,000 years, divergence in the larval development of Cryptasterina hystera and Cryptasterina pentagona has taken place, the former adopting internal fertilization and brooding and the latter remaining a broadcast spawner.[86]\\r\\n\\r\\nThe scientific name Asteroidea was given to starfish by the French zoologist de Blainville in 1830.[87] It is derived from the Greek aster, ?? (a star) and the Greek eidos, ?Ѵ? (form, likeness, appearance).[88] The class Asteroidea belongs to the phylum Echinodermata. As well as the starfish, the echinoderms include sea urchins, sand dollars, brittle and basket stars, sea cucumbers and crinoids. The larvae of echinoderms have bilateral symmetry, but during metamorphosis this is replaced with radial symmetry, typically pentameric.[11]  Adult echinoderms are characterized by having a water vascular system with external tube feet and a calcareous endoskeleton consisting of ossicles connected by a mesh of collagen fibres.[89] Starfish are included in the subphylum Asterozoa, the characteristics of which include a flattened, star-shaped body as adults consisting of a central disc and multiple radiating arms. The subphylum includes the two classes of Asteroidea, the starfish, and Ophiuroidea, the brittle stars and basket stars. Asteroids have broad-based arms with skeletal support provided by calcareous plates in the body wall[84] while ophiuroids have clearly demarcated slender arms strengthened by paired fused ossicles forming jointed \\"vertebrae\\".[90]\\r\\n\\r\\nThe starfish are a large and diverse class with about 1,500 living species. There are seven extant orders, Brisingida, Forcipulatida, Notomyotida, Paxillosida, Spinulosida, Valvatida and Velatida[1] and two extinct ones, Calliasterellidae and Trichasteropsida.[2] Living asteroids, the Neoasteroidea, are morphologically distinct from their forerunners in the Paleozoic. The taxonomy of the group is relatively stable but there is ongoing debate about the status of the Paxillosida, and the deep-water sea daisies, though clearly Asteroidea and currently included in Velatida, do not fit easily in any accepted lineage. Phylogenetic data suggests that they may be a sister group, the Concentricycloidea, to the Neoasteroidea, or that the Velatida themselves may be a sister group.[85]\\r\\n\\r\\nExtinct groups within the Asteroidea include:[2]\\r\\n\\r\\nStarfish are deuterostome animals, like the chordates. A 2014 analysis of 219 genes from all classes of echinoderms gives the following phylogenetic tree.[115] The times at which the clades diverged is shown under the labels in millions of years ago (mya).\\r\\n\\r\\nXenacoelomorpha \\r\\n\\r\\nChordata and allies \\r\\n\\r\\nHolothuroidea \\r\\n\\r\\nEchinoidea \\r\\n\\r\\nOphiuroidea \\r\\n\\r\\nAsteroidea \\r\\n\\r\\nCrinoidea \\r\\n\\r\\nEcdysozoa \\r\\n\\r\\nSpiralia \\r\\n\\r\\nThe phylogeny of the Asteroidea has been difficult to resolve, with visible (morphological) features proving inadequate, and the question of whether traditional taxa are clades in doubt.[2] The phylogeny proposed by Gale in 1987 is:[2][116]\\r\\n\\r\\n? Palaeozoic Asteroids\\r\\n\\r\\nPaxillosida\\r\\n\\r\\nValvatida, including Velatida, Spinulosida (not a clade)[2]\\r\\n\\r\\nForcipulatida, including Brisingida\\r\\n\\r\\nThe phylogeny proposed by Blake in 1987 is:[2][117]\\r\\n\\r\\n? Palaeozoic Asteroids\\r\\n\\r\\n? Calliasterellidae\\r\\n\\r\\n? Compasteridae\\r\\n\\r\\n? Trichasteropsida\\r\\n\\r\\nBrisingida\\r\\n\\r\\nForcipulatida\\r\\n\\r\\nSpinulosida\\r\\n\\r\\nVelatida\\r\\n\\r\\nNotomyotida\\r\\n\\r\\nValvatida\\r\\n\\r\\nPaxillosida\\r\\n\\r\\nLater work making use of molecular evidence, with or without the use of morphological evidence, had by 2000 failed to resolve the argument.[2] In 2011, on further molecular evidence, Janies and colleagues noted that the phylogeny of the echinoderms \\"has proven difficult\\", and that \\"the overall phylogeny of extant echinoderms remains sensitive to the choice of analytical methods\\". They presented a phylogenetic tree for the living Asteroidea only; using the traditional names of starfish orders where possible, and indicating \\"part of\\" otherwise, the phylogeny is shown below. The Solasteridae are split from the Velatida, and the old Spinulosida is broken up.[118]\\r\\n\\r\\nSolasteridae and part of Spinulosida, e.g. Stegnaster and part of Valvatida, e.g. Asterina\\r\\n\\r\\nOdontasteridae, which was a part of Valvatida\\r\\n\\r\\nPaxillosida\\r\\n\\r\\npart of Spinulosida, e.g. Echinaster, part of Valvatida, e.g. Archaster\\r\\n\\r\\nForcipulatida\\r\\n\\r\\nBrisingida with part of Velatida, e.g. Caymanostella and part of Forcipulatida, e.g. Stichaster\\r\\n\\r\\nVelatida except for Solasteridae\\r\\n\\r\\nNotomyotida (not analysed)\\r\\n\\r\\nStarfish are deuterostomes, closely related, together with all other echinoderms, to chordates, and are used in reproductive and developmental studies. Female starfishs produce large numbers of oocytes that are easily isolated; these can be stored in a pre-meiosis phase and stimulated to complete division by the use of 1-methyladenine.[119] Starfish oocytes are well suited for this research as they are large and easy to handle, transparent, simple to maintain in sea water at room temperature, and they develop rapidly.[120] Asterina pectinifera, used as a model organism for this purpose, is resilient and easy to breed and maintain in the laboratory.[121]\\r\\n\\r\\nAnother area of research is the ability of starfish to regenerate lost body parts. The stem cells of adult humans are incapable of much differentiation and understanding the regrowth, repair and cloning processes in starfish may have implications for human medicine.[122]\\r\\n\\r\\nStarfish also have an unusual ability to expel foreign objects from their bodies, which makes them difficult to tag for research tracking purposes.[123]\\r\\n\\r\\nAn aboriginal Australian fable retold by the Welsh school headmaster William Jenkyn Thomas (1870ÿ1959)[124] tells how some animals needed a canoe to cross the ocean. Whale had one but refused to lend it, so Starfish kept him busy, telling him stories and grooming him to remove parasites, while the others stole the canoe. When Whale realized the trick he beat Starfish ragged, which is how Starfish still is today.[125]\\r\\n\\r\\nIn 1900, the scholar Edward Tregear documented The Creation Song, which he describes as \\"an ancient prayer for the dedication of a high chief\\" of Hawaii. Among the \\"uncreated gods\\" described early in the song are the male Kumilipo (\\"Creation\\") and the female Poele, both born in the night, a coral insect, the earthworm, and the starfish.[126]\\r\\n\\r\\nGeorg Eberhard Rumpf's 1705 The Ambonese Curiosity Cabinet describes the tropical varieties of Stella Marina or Bintang Laut, \\"Sea Star\\", in Latin and Malay respectively, known in the waters around Ambon. He writes that the Histoire des Antilles reports that when the sea stars \\"see thunder storms approaching, [they] grab hold of many small stones with their little legs, looking to?... hold themselves down as if with anchors\\".[127]\\r\\n\\r\\nStarfish is the title of novels by Peter Watts[128] and Jennie Orbell,[129] and in 2012, Alice Addison wrote a non-fiction book titled \\"Starfish - A year in the life of bereavement and depression\\".[130] The Starfish and the Spider is a 2006 business management book by Ori Brafman and Rod Beckstrom; its title alludes to the ability of the starfish to regenerate itself because of its decentralized nervous system, and the book suggests ways that a decentralized organisation may flourish.[131]\\r\\n\\r\\nIn his 2002 book The Divine Mystery Fort, Sri Sai Kaleshwar Swami wrote, \\"An eighth type of supernatural power object is a starfish. Sometimes at the full moon time, when the moon is really dazzling and hitting on the ocean, a starfish jumps out of the water and falls down. If you can get that you can suck unbelievable cosmic energy. You can use it as your own power object. It has to be only on the full moon day when it comes up.\\"\\r\\n\\r\\nIn the Nickelodeon animated television series SpongeBob SquarePants, the eponymous character's best friend is a dim-witted starfish, Patrick Star.[132]\\r\\n\\r\\nStarfish are widespread in the oceans, but are only occasionally used as food. There may be good reason for this: the bodies of numerous species are dominated by bony ossicles, and the body wall of many species contains saponins, which have an unpleasant taste,[71] and others contain tetrodotoxins which are poisonous.[133] Some species that prey on bivalve molluscs can transmit paralytic shellfish poisoning.[134] Georg Eberhard Rumpf found few starfish being used for food in the Indonesian archipelago, other than as bait in fish traps, but on the island of \\"Huamobel\\"  [sic] the people cut them up, squeeze out the \\"black blood\\" and cook them with sour tamarind leaves; after resting the pieces for a day or two, they remove the outer skin and cook them in coconut milk.[127] Starfish are sometimes eaten in China,[135] Japan[136][137] and in Micronesia.[138]\\r\\n\\r\\nStarfish are in some cases taken from their habitat and sold to tourists as souvenirs, ornaments, curios or for display in aquariums. In particular, Oreaster reticulatus, with its easily accessed habitat and conspicuous coloration, is widely collected in the Caribbean. In the early to mid 20th century, this species was common along the coasts of the West Indies, but collection and trade have severely reduced its numbers. In the State of Florida, O. reticulatus is listed as endangered and its collection is illegal. Nevertheless, it is still sold throughout its range and beyond.[70] A similar phenomenon exists in the Indo-Pacific for species such as Protoreaster nodosus.[139]\\r\\n\\r\\nWith its multiple arms, the starfish provides a popular metaphor for computer networks,[140] companies[141][142] and software tools.[143] It is also the name of a seabed imaging system and company.[144]\\r\\n\\r\\nStarfish has repeatedly been chosen as a name in military history. Three ships of the Royal Navy have borne the name HMS Starfish: an A-class destroyer launched in 1894;[145] an R-class destroyer launched in 1916;[146] and an S-class submarine launched in 1933 and lost in 1940.[147] In the World War II, Starfish sites  were large-scale night-time decoys created during The Blitz to simulate burning British cities.[148] Starfish Prime was a high-altitude nuclear test conducted by the United States on 9 July 1962.[149]","input":"How many arms does a sea star have?"},{"output":"genetics","context":"","input":"What would cause hearing loss in a child?"},{"output":"Mao Zedong","context":"The history of the People's Republic of China details the history of mainland China since October 1, 1949, when, after a near complete victory by the Communist Party of China (CPC) in the Chinese Civil War, Mao Zedong proclaimed the People's Republic of China (PRC) from atop Tiananmen.  The PRC has for several decades been synonymous with China, but it is only the most recent political entity to govern mainland China, preceded by the Republic of China (ROC) and thousands of years of imperial dynasties.\\r\\n\\r\\nFollowing the Chinese Civil War and the victory of Mao Zedong's Communist forces over the Kuomintang forces of Generalissimo Chiang Kai-shek, who fled to Taiwan, Mao declared the founding of the People's Republic of China on October 1, 1949. Mao's first goal was a total overhaul of the land ownership system, and extensive land reforms. China's old system of gentry landlord ownership of farmland and tenant peasants was replaced with a distribution system in favor of poor/landless peasants which significantly reduced economic inequality. Over a million landlords were executed.[1] In Zhangzhuangcun, in the more thoroughly reformed north of the country, most \\"landlords\\" and \\"rich peasants\\" had lost all their land and often their lives or had fled. All formerly landless workers had received land, which eliminated this category altogether. As a result, \\"middling peasants,\\" who now accounted for 90 percent of the village population, owned 90.8 percent of the land.[2] Mao laid heavy theoretical emphasis on class struggle, and in 1953 began various campaigns to persecute former landlords and merchants, including the execution of more powerful landlords. Drug trafficking in the country as well as foreign investment were largely wiped out.\\r\\n\\r\\nMao believed that socialism would eventually triumph over all other ideologies, and following the First Five-Year Plan based on a Soviet-style centrally controlled economy, Mao took on the ambitious project of the Great Leap Forward in 1958, beginning an unprecedented process of collectivization in rural areas. Mao urged the use of communally organized iron smelters to increase steel production, pulling workers off of agricultural labor to the point that large amounts of crops rotted unharvested. Mao decided to continue to advocate these smelters despite a visit to a factory steel mill which proved to him that high quality steel could only be produced in a factory. He thought that ending the program would dampen peasant enthusiasm for his political mobilization, the Great Leap Forward.\\r\\n\\r\\nThe implementation of Maoist thought in China may have been responsible for over 40ÿ70 million deaths including famine during peacetime[3], with the Great Leap Forward,  Anti-Rightist Campaign of 1957ÿ1958,[4] and the Cultural Revolution. Millions died from both executions and forced labour.\\r\\nBecause of Mao's land reforms during the Great Leap Forward, which resulted in massive famines, thirty million perished between 1958 and 1961.  By the end of 1961 the birth rate was nearly cut in half because of malnutrition.[5] Active campaigns, including party purges and \\"reeducation\\" resulted in the imprisonment or execution of those deemed to hold views contrary to Maoist ideals.[6]\\r\\nMao's failure with the Leap reduced his power in government, whose administrative duties fell to Liu Shaoqi and Deng Xiaoping.\\r\\n\\r\\nTo impose socialist orthodoxy and rid China of \\"old elements\\", and at the same time serving certain political goals, Mao began the Cultural Revolution in May 1966. The campaign was far reaching into all aspects of Chinese life. Red Guards terrorized the streets as many ordinary citizens were deemed counter-revolutionaries. Education and public transportation came to a nearly complete halt. Daily life involved shouting slogans and reciting Mao quotations. Many prominent political leaders, including Liu and Deng, were purged and deemed \\"capitalist-roaders\\". The campaign would not come to a complete end until the death of Mao in 1976.\\r\\n\\r\\nSupporters of the Maoist Era claim that under Mao, China's unity and sovereignty was assured for the first time in a century, and there was development of infrastructure, industry, healthcare, education (only 20% of the population could read in 1949, compared to 65.5% thirty years later)[7], which raised standard of living for the average Chinese. They also claimed that campaigns such as the Great Leap Forward ÿ an example of the concept New Democracy ÿ and the Cultural Revolution were essential in jumpstarting China's development and \\"purifying\\" its culture. Others[8] claim that though the consequences of both these campaigns were economically and humanly disastrous, they left behind a \\"clean slate\\" on which later economic progress could be built. Supporters often also doubt statistics or accounts given for death tolls or other damages incurred by Mao's campaigns, attributing the high death toll to natural disasters, famine, or other consequences of political chaos during the rule of Chiang Kai-shek.\\r\\n\\r\\nMao Zedong's death was followed by a power struggle between the Gang of Four, Hua Guofeng, and eventually Deng Xiaoping. Deng would maneuver himself to the top of China's leadership by 1980. At the Third Plenum of the Eleventh National Party Congress Central Committee, Deng embarked China on the road to Economic Reforms and Openness (T˜ Gaige Kaifang), policies that began with the de-collectivization of the countryside, followed with industrial reforms aimed at decentralizing government controls in the industrial sector. A major document presented at the September 1979 Fourth Plenum, gave a \\"preliminary assessment\\" of the entire 30-year period of Communist rule. At the plenum, party Vice Chairman Ye Jianying declared the Cultural Revolution \\"an appalling catastrophe\\" and \\"the most severe setback to [the] socialist cause since [1949].\\"[9] The Chinese government's condemnation of the Cultural Revolution culminated in the Resolution on Certain Questions in the History of Our Party Since the Founding of the People's Republic of China, adopted by the Sixth Plenary Session of the Eleventh Central Committee of the Communist Party of China. This stated that \\"Comrade Mao Zedong was a great Marxist and a great proletarian revolutionary, strategist and theorist. It is true that he made gross mistakes during the \\"cultural revolution\\", but, if we judge his activities as a whole, his contributions to the Chinese revolution far outweigh his mistakes. His merits are primary and his errors secondary.\\"[10]\\r\\n\\r\\nOn the subject of Mao's legacy Deng coined the famous phrase \\"7 parts good, 3 parts bad\\" and avoided denouncing Mao altogether. Deng championed the idea of Special Economic Zones (SEZs), areas where foreign investment would be allowed to pour in without strict government restraint and regulations, running on a basically capitalist system. Deng laid emphasis on light industry as a stepping stone to the development of heavy industries.\\r\\n\\r\\nSupporters of the economic reforms point to the rapid development of the consumer and export sectors of the economy, the creation of an urban middle class that now constitutes 15% of the population, higher living standards (which is shown via dramatic increases in GDP per capita, consumer spending, life expectancy, literacy rate, and total grain output) and a much wider range of personal rights and freedoms for average Chinese as evidence of the success of the reforms.\\r\\n\\r\\nAlthough standards of living improved significantly in the 1980s, Deng's reforms were not without criticism. Hard-liners asserted that Deng opened China once again to various social evils, and an overall increase in materialistic thinking, while liberals attacked Deng's unrelenting stance on political reform. Liberal forces began gathering in different forms to protest against the Party's authoritarian leadership. In 1989, the death of Hu Yaobang, a liberal figure, triggered weeks of spontaneous protests in the Tiananmen Square. The government imposed martial law and sent in tanks and soldiers to suppress the demonstrations. Western countries and multilateral organizations briefly suspended their formal ties with China's government under Premier Li Peng's leadership, which was directly responsible for the military curfew and bloody crackdown.\\r\\n\\r\\nCritics of the economic reforms, both in China and abroad, claim that the reforms have caused wealth disparity, environmental pollution, rampant corruption, widespread unemployment associated with layoffs at inefficient state-owned enterprises, and has introduced often unwelcome cultural influences. Consequently, they believe that China's culture has been corrupted, the poor have been reduced to a hopeless abject underclass, and that the social stability is threatened. They are also of the opinion that various political reforms, such as moves towards popular elections, have been unfairly nipped in the bud.  Regardless of either view, today, the public perception of Mao has improved at least superficially; images of Mao and Mao related objects have become fashionable, commonly used on novelty items and even as talismans. However, the path of modernization and market-oriented economic reforms that China started since the early 1980s appears to be fundamentally unchallenged. Even critics of China's market reforms do not wish to see a backtrack of these two decades of reforms, but rather propose corrective measures to offset some of the social issues caused by existing reforms.\\r\\n\\r\\nIn 1979, the Chinese government instituted a one child policy to try to control its rapidly increasing population.  The controversial policy resulted in a dramatic decrease in child poverty. The law currently applies to about a third of mainland Chinese, with plans in place to ease it to a two-child limit.[11][12]\\r\\n\\r\\nThe achievements of Lee Kuan Yew to create an economic superpower in Singapore had a profound effect on the Communist leadership in China. They made a major effort, especially under Deng Xiaoping, to emulate his policies of economic growth, entrepreneurship, and subtle suppression of dissent. Over 22,000 Chinese officials were sent to Singapore to study its methods.[13]\\r\\n\\r\\nAfter the events at Tiananmen, Deng Xiaoping retired from public view. While keeping ultimate control, power was passed onto the third generation of leadership led by Jiang Zemin, who was hailed as its \\"core\\". Economic growth, despite foreign trade embargoes, returned to a fast pace by the mid-1990s. Jiang's macroeconomic reforms furthered Deng's vision for \\"Socialism with Chinese Characteristics\\". At the same time, Jiang's period saw a continued rise in social corruption in all areas of life.  Unemployment skyrocketed as unprofitable SOE's were closed to make way for more competitive ventures, internally and abroad. The ill-equipped social welfare system was put on a serious test. Jiang also laid heavy emphasis on scientific and technological advancement in areas such as space exploration. To sustain vast human consumption, the Three Gorges Dam was built, attracting supporters and widespread criticism. Environmental pollution became a very serious problem as Beijing was frequently hit by sandstorms as a result of desertification.\\r\\n\\r\\nThe 1990s saw two foreign colonies returned to China, Hong Kong from Britain in 1997, and Macau from Portugal in 1999. Hong Kong and Macau mostly continued their own governance, retaining independence in their economic, social, and judicial systems.\\r\\n\\r\\nJiang and President Clinton exchanged state visits, but Sino-American relations took very sour turns at the end of the decade. On May 7, 1999, during the Kosovo War, US aircraft bombed the Chinese embassy in Belgrade. The U.S. government claimed the strike was due to bad intelligence and false target identification.\\r\\n\\r\\nInside the US, the Cox Report stated that China had been stealing various top US military secrets.\\r\\n\\r\\nIn 2001, a US surveillance plane collided with a Chinese fighter jet over international waters near Hainan, inciting further outrage with the Chinese public, already dissatisfied with the US.\\r\\n\\r\\nOn the political agenda, China was once again put on the spotlight for the banning of public Falun Gong activity in 1999. Silent protesters from the spiritual movement sat outside of Zhongnanhai, asking for dialogue with China's leaders. Jiang saw it as threatening to the political situation and outlawed the group altogether, while using the mass media to denounce it as an evil cult.\\r\\n\\r\\nConversely, Premier Zhu Rongji's economic policies held China's economy strong during the Asian Financial Crisis. Economic growth averaged at 8% annually, pushed back by the 1998 Yangtze River Floods. After a decade of talks, China was finally admitted into the World Trade Organization.  Standards of living improved significantly, although a wide urban-rural wealth gap was opened, as China saw the reappearance of the middle class. Wealth disparity between East and the Western hinterlands continued to widen by the day, prompting government programs to \\"develop the West\\", taking on such ambitious projects such as the Qinghai-Tibet Railway. The burden of education was greater than ever.  Rampant corruption continued despite Premier Zhu's anti-corruption campaign that executed many officials.\\r\\n\\r\\nThe first major issue faced by China in the 21st century as a new generation of leaders led by Hu Jintao after assuming power was the public health crisis involving SARS, an illness that seemed to have originated out of Guangdong province. China's position in the war on terror drew the country closer diplomatically to the United States. The economy continues to grow in double-digit numbers as the development of rural areas became the major focus of government policy. In gradual steps to consolidate his power, Hu Jintao removed Shanghai Party Chief Chen Liangyu and other potential political opponents amidst the fight against corruption, and the ongoing struggle against once powerful Shanghai clique. The assertion of the Scientific Perspective to create a Socialist Harmonious Society is the focus of the Hu-Wen administration, as some Jiang-era excesses are slowly reversed. In the years after Hu's rise to power, respect of basic human rights in China continue to be a source of concern.\\r\\n\\r\\nThe political status and future of Taiwan remain uncertain, but steps have been taken to improving relations between the Communist Party and several of Taiwan's parties that hold a less antagonistic view towards China, notably former rival Kuomintang.\\r\\n\\r\\nThe continued economic growth of the country as well as its sporting power status gained China the right to host the 2008 Summer Olympics. However, this also put Hu's administration under intense spotlight.  While the 2008 Olympic was commonly understood to be a come-out party for People's Republic of China, in light of the March 2008 Tibet protests, the government received heavy scrutiny. The Olympic torch was met with protest en route. Within the country these reactions were met with a fervent wave of nationalism with accusations of Western bias against China.\\r\\n\\r\\nIn May 2008, a massive earthquake registering 8.0 on the Richter scale hit Sichuan province of China, exacting a death toll officially estimated at approximately 70,000.  The government responded more quickly than it did with previous events, and has allowed foreign media access to the regions that were hit the hardest.  The adequacy of the government response was generally praised, and the relief efforts extended to every corner of Chinese life.\\r\\nIn May and June 2008, heavy rains in southern China caused severe flooding in the provinces of Anhui, Hunan, Jiangxi, Fujian and Guangdong, with dozens of fatalities and over a million people forced to evacuate. As of 2009 China has increased its internet monitoring capabilities by adding hundreds of new monitoring stations.","input":"Who created the people's republic of china?"},{"output":"28 and 29 March 2015","context":"Goodluck Jonathan\\r\\nPDP\\r\\nMuhammadu Buhari\\r\\nAPC\\r\\nGeneral elections were held in Nigeria on 28 and 29 March 2015, the fifth quadrennial election to be held since the end of military rule in 1999.[4] Voters elected the President and members to the House of Representatives and the Senate. The incumbent president, Goodluck Jonathan sought his second and final term.\\r\\nThe elections were first scheduled to be held on 14 February 2015. However, the electoral commission postponed it by six weeks to 28 March, mainly due to the poor distribution of Permanent Voter Cards, and also to curb ongoing Boko Haram insurgency in certain north-eastern states.[5] The government closed its land and sea borders from midnight on 25 March until the end of the polling date.[6] The election was extended to 29 March due to delays and technical problems with the biometric card readers.[7]\\r\\nIt was the most expensive election ever to be held on the African continent.[8] Nigeria is the continent's most populous country, has its largest economy and is its leading oil producer. Opposition candidate Muhammadu Buhari won the presidential election by more than 2.5?million votes.[9] Incumbent President Goodluck Jonathan conceded defeat on 31 March, before the results from all 36 states had been announced.[10] The election marks the first time an incumbent president has lost re-election in Nigeria. The President-elect was sworn-in on 29 May 2015.\\r\\n\\r\\n\\r\\nArticle 134 (2) of the Nigerian Constitution stipulates that a presidential candidate will be duly elected after attaining both the highest number of votes cast, and having received at least a quarter of the votes at each of at least two-thirds of the 36 states and the Federal Capital Territory (FCT). If no candidate satisfies the requirement, a second election will be held between the two leading candidates within seven days from the pronouncement of the result.[11]\\r\\nIt had long been assumed that incumbent President Goodluck Jonathan would run for re-election, as despite declining approval ratings, he was still thought to be popular and had several high-profile supporters.[12] Jonathan officially confirmed his candidacy on 11 November at a rally in Abuja, announcing to cheering supporters:[13]\\r\\n\\"After seeking the face of God, and in the quiet of my family, and after listening to the clarion call of Nigerians, I have accepted to present myself to serve a second term.\\"\\r\\nJonathan ran unopposed in the People's Democratic Party (PDP) primaries on 10 December 2014, receiving the nomination of the party. However, this was against an unwritten rule that the PDP's presidential candidacy should alternate between Muslim northerners and Christian southerners, and opposition to Jonathan's candidacy had led to the defection of dozens of PDP MPs in the House of Representatives.[14]\\r\\nPrior to the elections,[when?] the All Progressives Congress was formed as an alliance of four opposition parties, the Action Congress of Nigeria, the Congress for Progressive Change, the All Nigeria Peoples Party, and the All Progressives Grand Alliance.[citation needed]\\r\\nIts primaries, also held on 10 December, were won by retired Major General Muhammadu Buhari,[14] who defeated Kano State Governor Rabiu Kwankwaso, former Vice-President Atiku Abubakar, Imo State Governor Rochas Okorocha and newspaper editor Sam Nda Isaiah.[15] On 17 December, APC chose Professor Yemi Osinbajo as the running mate of General M. Buhari.[citation needed]\\r\\nAs of February 2015, \\"Though the APC's voter base is in the north, it enjoys support all over the country, unlike the opposition in 2011.\\"[16]\\r\\nA presidential and Vice presidential Debate was conducted by the Nigerian media with majority of the candidates attending. The debate was attended by the then incumbent president Goodluck Jonathan, and his vice Namadi Sambo, while as predicted, the Presidential candidate of the All Progressives Congress, Muhammadu Buhari boycotted the debate while his vice presidential nominee attended. The debate which lasted for approximately an hour was watched by over 20 million people in Nigeria, with radios and the Internet conveying through other means.\\r\\nFourteen candidates contested the election.[17]\\r\\nThe main opposition Goodluck Jonathan faced was from Muhammadu Buhari of the APC. While inaugurating a 250-bed Orthopaedic Hospital in Wamakko, Buhari said: We will stop corruption and make the ordinary people, the weak and the vulnerable our top priority.[18]\\r\\nAfter a botched governor's election in Anambra State, there were serious concerns that the election would not go smoothly. The country's election commission had promised a better election process, hoping that combating electoral fraud would prevent the violence that had plagued previous Nigerian elections.[12] Despite this, a pre-election poll by Gallup noted that only 13% of Nigerians had confidence in the honesty of elections.[20]\\r\\nThe Socialist Party of Nigeria filed for registration as a political party to contest the election, but the Independent National Electoral Commission (INEC) refused the registration. The SPN sued the INEC at the Federal High Court, claiming that INEC had failed to respond to their petition within 30 days as prescribed by law and that thus it would have to be registered automatically.[21]\\r\\nThe presidential election was a trending topic in Nigeria on Twitter, one social media platform reflecting public opinion; although PDP/GEJ may simply have had better support on social media, which is not representative of the population as a whole. According to Impact Social, based on data from 40,000 tweets, Facebook messages, blogs, and other internet outlets that mention PDP or GEJ, 70% of public opinion toward President Jonathan is positive, but messaging on the economy has taken up 6% of election conversation and was seen as a key PDP strength. Social media support for Buhari/APC was a bit \\"noisier\\" without a single issue leveraged by the campaign to gain traction: there was general frustration that the campaign lacked consistency, content and focus on the important issues at hand.[22]\\r\\nIn January 2015, the #bringbackourgirls campaign raised alarm over plans by the Independent National Electoral Commission (INEC) to exclude Chibok and some communities currently under the control of the Boko Haram from getting the permanent voter cards (PVCs) for the February elections.[23] Jonathan's already controversial handling of the situation was exacerbated by the Twitter campaign that was launched in mid 2014, #BringBackJonathan2015, which was widely considered to be insensitive to the victims and their families. Jonathan eventually called for banners containing the hashtag to be taken down and asked for the hashtag to not be used.[24]\\r\\nOn 8 February 2015, the Independent National Electoral Commission announced that \\"presidential and national assembly elections will now hold on 28 March while the governorship and state assemblies election will take place on 11 April,[25]\\" mainly due to the poor distribution of Permanent Voter Cards, and also the security concerns related to the Boko Haram insurgency in certain north eastern states.\\r\\nThe postponement was called on the grounds of the INEC failing to deliver Permanent Voters' Cards to millions (around 34%) of voters ÿ reportedly only around 45.1mn of 68.8mn registered voters had received PVC's. Additionally, on 5 February, the National Council of State (chaired by President Jonathan) told INEC that it had just launched a major, decisive offensive against Boko Haram for six weeks. Due to the assets and resources that would go into this offensive, the military would be unable to provide security and logistics support for elections. This is a disputable claim, since election security is the primary responsibility of not the military (which should only act as support) but the police and civil defence corps. There is speculation over whether or not the postponement was motivated by politics rather than security and has raised questions over the political neutrality of the military as well as the independence of INEC.[26]\\r\\n[27] Sambo Dasuki, Nigerian national security advisor, told the commission \\"that operations against Boko Haram militants meant the military \\"will be unable to provide adequate security\\" for the 14 February vote.\\"[28] \\"Seventeen out of the 28 registered political parties\\" supported postponing the elections; 12 opposed, \\"including the leading opposition party, All Progressives Congress\\".[29] By 30 January, \\"Boko Haram was in total occupation/complete control of 13 local governments (and other swathes of land) in Borno and 2 each in Yobe and Adamawa.\\"[30] Critics of the postponement view it as a political move on behalf of GEJ/PDP rather than one made in the interest of national security. GEJ/PDP are losing traction due to gains by Boko Haram in January, economic strains from the slide in global oil price (Nigerias key export), and GEJ/PDPs slow progress on fighting corruption and improving infrastructure. According to primaries in December 2014, Buhari/APC is viewed as more equipped to fight insecurity and corruption.\\r\\nCritics have pointed out that even with the postponement, the Nigerian government is unlikely to re-establish control in all the affected areas by the date of the election. Distribution of the Permanent Voters' Card (PVC) has begun in camps for internally displaced persons (IDPs) from the three affected states. Estimates of the number of IDPs range from 868,235 to 1.5 million people, and is not yet clear how successful efforts will be to organise elections under these circumstances.[30] Key Government officials in Nigeria are publicly stating their opposition to the postponement. Senator Chris Ngige, for example, has accused the PDP of pressuring INEC to postpone the general elections.[31]\\r\\nIn addition to growing criticism within Nigeria, on 8 February Vanguard reported that \\"the United States said it was 'deeply disappointed' by the delay.\\" US Secretary of State John Kerry, who had urged that elections be held on time, \\"[warned] the Nigerian government against using 'security concerns as a pretext for impeding the democratic process.'\\"[32] Additionally, the British Foreign Secretary, Philip Hammond, has revealed that he, too, is disgruntled by the news: The security situation should not be used as a reason to deny the Nigerian people from exercising their democratic rights. It is vital that the elections are kept on track and held as soon as possible. [33] Deutsche Welle reported that \\"The postponement has been seen by critics as a ploy by President Goodluck Jonathan and the ruling People's Democratic Party (PDP) to buy time to sway support from the popular main opposition candidate and former military dictator, Muhammadu Buhari.\\"[28]\\r\\nBy 7 February 2015, threats of post-election violence from both sides remained a concern, given that hundreds of people died in the rioting that followed the 2011 Nigerian presidential election,[28] and rhetoric was running high. It was reported that \\"the Council of Imams and Ulamas in Kaduna State ... told the Niger Delta militants threatening chaos if President Goodluck Jonathan loses the presidential election that they stand to lose if there is a war.\\"[34] The GMB Volunteers, a group described as a \\"frontline voluntary organization made up of professionals, ethnic and religious groups,\\" has criticised hate advertisements directed against APC candidate General Muhammadu Buhari.[35]\\r\\nOn 9 February, although \\"Nigerian civil society\\" was \\"in uproar\\" over the postponement, the north east remained calm, and voters there appeared willing to wait.[36]\\r\\nGroups such as the Nigeria Stability and Reconciliation Programme (NSRP) have \\"advised political parties to stop making hate speeches against opponents.\\"[37]\\r\\nThe Nigeria Women Platform for Peaceful Election (NWPPE) is collaborating with United Nations Women to hold training sessions for journalists on gender-based violence and gender sensitive reporting. A \\"women situation room\\", similar to a \\"civil society situation room\\" is planned for monitoring violence against women during the elections.[38]\\r\\nSenator Abubakar Bukola Saraki, who has called the postponement \\"an obstruction of democracy\\", nonetheless released a statement saying \\"I charge Nigerians to be calm, non-violent and steadfast. We must be determined to make sure postponement does not demoralize or disenfranchise us. We must see this as a challenge for us to remain resolute in yearning for a new democratic government; one that will not see itself as above the people.\\"[39]\\r\\nOn 31 January, a concert was held in Owerri, Imo State, as part of the RSVP concert series, urging young people to RSVP ÿ Register, Select, Vote and Protect. \\"Register ÿ pick your Permanent Voters' card-PVC, Select (select your candidates), and Vote ÿ vote not Fight, and Protect ÿ protect your mandate.\\" A second RSVP concert was planned for Lagos on 8 February.[40]\\r\\nThe postponement was the topic of a Council on Foreign Relations online conference call with John Campbell on 28 February 2015.[41]\\r\\nAccording to the Nigerian Constitution, the presidential election must be held by 28 April.[36] As Section 25 of the 2010 Electoral Act states, the date is to be no later than 30 days before the expiration of the previous office holder's term of office.[42]\\r\\nBuhari was supported by The Economist \\"with a heavy heart\\" as \\"the least awful\\" option; the newspaper was scathing about the repression and economic policy of Buhari's previous regime, but praised his subsequent adherence to democratic process, anti-corruption stance, and the legitimacy he held in the Muslim North as a stronger platform with which to combat Boko Haram.[43]\\r\\nThe website of the Independent National Electoral Commission was hacked on election day by a group calling itself the Nigerian Cyber Army.[44]\\r\\nVoting was extended due to technical problems with electronic card readers.[45] The technology was introduced to prevent voter fraud, but was opposed by President Goodluck Jonathan who called it a \\"huge national embarrassment\\" when problems caused a delay. President Jonathan himself failed to be accredited by the card reader, which was shown live on national television.[46]\\r\\nBoko Haram attempted to disrupt the election by attacking voting centres, killing 41 people.[47][48] An opposition politician, Umaru Ali, was gunned down in one attack.[49][50]\\r\\nThe Jos Forum Inter-communal Dialogue Process was established to serve as a sustainable and impartial dialogue mechanism to be used by the communities to handle disputes.[51] In 2015, the Jos Peace Dialogue Forum has already served as a platform for various political parties to discuss challenges and commit to peaceful elections in 2015.[52]\\r\\nElection observer missions [EOM] were deployed from the African Union (AU), Commonwealth of Nations, Economic Community of West African States (ECOWAS) and the European Union (EU); and were led by Amos Sawyer,[53] Bakili Muluzi,[54] John Kufuor,[55] and Santiago Fisas respectively.[56]\\r\\nUN Secretary-General Ban Ki-moon congratulated the citizens and the government for conducting a peaceful and orderly election.[57] The AUEOM concluded that the elections were conducted in a \\"peaceful atmosphere\\" and met the \\"continental and regional principles of democratic elections\\".[53] ECOWAS EOM said that it met the \\"criteria of being free and transparent\\" despite \\"pockets of incidents and logistical challenges.\\"[55] The Commonwealth EOM described the conduct as \\"generally peaceful and transparent.\\"[58]","input":"When was the last election held in nigeria?"},{"output":"Bhnusi?ha","context":"Rabindranath Tagore[a] FRAS (/r??b?ndr?n?t t????r/?(?listen); Bengali:?[robind?ronat?? ??akur]), also written Ravؐndrantha ?hkura[2] (7 May 1861?ÿ 7 August 1941),[b] sobriquet Gurudev,[c] was a Bengali polymath[4][5] who reshaped Bengali literature and music, as well as Indian art with Contextual Modernism in the late 19th and early 20th centuries. Author of Gitanjali and its \\"profoundly sensitive, fresh and beautiful verse\\",[6] he became in 1913 the first non-European to win the Nobel Prize in Literature.[7] Tagore's poetic songs were viewed as spiritual and mercurial; however, his \\"elegant prose and magical poetry\\" remain largely unknown outside Bengal.[8] He is sometimes referred to as \\"the Bard of Bengal\\".[9]\\r\\nA Pirali Brahmin from Calcutta with ancestral gentry roots in Jessore, Tagore wrote poetry as an eight-year-old.[10] At the age of sixteen, he released his first substantial poems under the pseudonym Bhnusi?ha (\\"Sun Lion\\"), which were seized upon by literary authorities as long-lost classics.[11][12] By 1877 he graduated to his first short stories and dramas, published under his real name. As a humanist, universalist internationalist, and ardent anti-nationalist,[13] he denounced the British Raj and advocated independence from Britain. As an exponent of the Bengal Renaissance, he advanced a vast canon that comprised paintings, sketches and doodles, hundreds of texts, and some two thousand songs; his legacy also endures in the institution he founded, Visva-Bharati University.[14][15][16][17][18]\\r\\nTagore modernised Bengali art by spurning rigid classical forms and resisting linguistic strictures. His novels, stories, songs, dance-dramas, and essays spoke to topics political and personal. Gitanjali (Song Offerings), Gora (Fair-Faced) and Ghare-Baire (The Home and the World) are his best-known works, and his verse, short stories, and novels were acclaimedor pannedfor their lyricism, colloquialism, naturalism, and unnatural contemplation. His compositions were chosen by two nations as national anthems: India's Jana Gana Mana and Bangladesh's Amar Shonar Bangla. The Sri Lankan national anthem was inspired by his work.[19][20][21]\\r\\n\\r\\n\\r\\nThe youngest of thirteen surviving children, Tagore (nicknamed \\"Rabi\\") was born on 7 May 1861 in the Jorasanko mansion in Calcutta to Debendranath Tagore (1817ÿ1905) and Sarada Devi (1830ÿ1875).[d]\\r\\n Letter to Indira Devi.[27]\\r\\nTagore was raised mostly by servants; his mother had died in his early childhood and his father travelled widely.[28] The Tagore family was at the forefront of the Bengal renaissance. They hosted the publication of literary magazines; theatre and recitals of Bengali and Western classical music featured there regularly. Tagore's father invited several professional Dhrupad musicians to stay in the house and teach Indian classical music to the children.[29] Tagore's oldest brother Dwijendranath was a philosopher and poet. Another brother, Satyendranath, was the first Indian appointed to the elite and formerly all-European Indian Civil Service. Yet another brother, Jyotirindranath, was a musician, composer, and playwright.[30] His sister Swarnakumari became a novelist.[31] Jyotirindranath's wife Kadambari Devi, slightly older than Tagore, was a dear friend and powerful influence. Her abrupt suicide in 1884, soon after he married, left him profoundly distraught for years.[32]\\r\\nTagore largely avoided classroom schooling and preferred to roam the manor or nearby Bolpur and Panihati, which the family visited.[33][34] His brother Hemendranath tutored and physically conditioned himby having him swim the Ganges or trek through hills, by gymnastics, and by practising judo and wrestling. He learned drawing, anatomy, geography and history, literature, mathematics, Sanskrit, and Englishhis least favourite subject.[35] Tagore loathed formal educationhis scholarly travails at the local Presidency College spanned a single day. Years later he held that proper teaching does not explain things; proper teaching stokes curiosity:[36]\\r\\nAfter his upanayan (coming-of-age) rite at age eleven, Tagore and his father left Calcutta in February 1873 to tour India for several months, visiting his father's Santiniketan estate and Amritsar before reaching the Himalayan hill station of Dalhousie. There Tagore read biographies, studied history, astronomy, modern science, and Sanskrit, and examined the classical poetry of Klidsa.[37][38] During his 1-month stay at Amritsar in 1873 he was greatly influenced by melodious gurbani and nanak bani being sung at Golden Temple for which both father and son were regular visitors. He mentions about this in his 'MY REMINISCENCES (1912)\\r\\nThe golden temple of Amritsar comes back to me like a dream. Many a morning have I accompanied my father to this Gurudarbar of the Sikhs in the middle of the lake. There the sacred chanting resounds continually. My father, seated amidst the throng of worshippers, would sometimes add his voice to the hymn of praise, and finding a stranger joining in their devotions they would wax enthusiastically cordial, and we would return loaded with the sanctified offerings of sugar crystals and other sweets.[39]\\r\\nHe wrote 6 poems relating to Sikhism and a number of articles in Bengali child magazine about Sikhism.[40]\\r\\nTagore returned to Jorosanko and completed a set of major works by 1877, one of them a long poem in the Maithili style of Vidyapati. As a joke, he claimed that these were the lost works of (what he claimed was) a newly discovered 17th-century Vai??ava poet Bhnusi?ha.[41] Regional experts accepted them as the lost works of Bhnusi?ha.[e][42] He debuted in the short-story genre in Bengali with \\"Bhikharini\\" (\\"The Beggar Woman\\").[43][44] Published in the same year, Sandhya Sangit (1882) includes the poem \\"Nirjharer Swapnabhanga\\" (\\"The Rousing of the Waterfall\\").\\r\\nBecause Debendranath wanted his son to become a barrister, Tagore enrolled at a public school in Brighton, East Sussex, England in 1878.[27] He stayed for several months at a house that the Tagore family owned near Brighton and Hove, in Medina Villas; in 1877 his nephew and nieceSuren and Indira Devi, the children of Tagore's brother Satyendranathwere sent together with their mother, Tagore's sister-in-law, to live with him.[45] He briefly read law at University College London, but again left school, opting instead for independent study of Shakespeare's plays Coriolanus, and Antony and Cleopatra and the Religio Medici of Thomas Browne. Lively English, Irish, and Scottish folk tunes impressed Tagore, whose own tradition of Nidhubabu-authored kirtans and tappas and Brahmo hymnody was subdued.[27][46] In 1880 he returned to Bengal degree-less, resolving to reconcile European novelty with Brahmo traditions, taking the best from each.[47] After returning to Bengal, Tagore regularly published poems, stories, and novels. These had a profound impact within Bengal itself but received little national attention.[48] In 1883 he married 10-year-old[49] Mrinalini Devi, born Bhabatarini, 1873ÿ1902 (this was a common practice at the time). They had five children, two of whom died in childhood.[50]\\r\\nIn 1890 Tagore began managing his vast ancestral estates in Shelaidaha (today a region of Bangladesh); he was joined there by his wife and children in 1898. Tagore released his Manasi poems (1890), among his best-known work.[51] As Zamindar Babu, Tagore criss-crossed the Padma River in command of the Padma, the luxurious family barge (also known as \\"budgerow\\"). He collected mostly token rents and blessed villagers who in turn honoured him with banquetsoccasionally of dried rice and sour milk.[52] He met Gagan Harkara, through whom he became familiar with Baul Lalon Shah, whose folk songs greatly influenced Tagore.[53] Tagore worked to popularise Lalon's songs. The period 1891ÿ1895, Tagore's Sadhana period, named after one of his magazines, was his most productive;[28] in these years he wrote more than half the stories of the three-volume, 84-story Galpaguchchha.[43] Its ironic and grave tales examined the voluptuous poverty of an idealised rural Bengal.[54]\\r\\nIn 1901 Tagore moved to Santiniketan to found an ashram with a marble-floored prayer hallThe Mandiran experimental school, groves of trees, gardens, a library.[55] There his wife and two of his children died. His father died in 1905. He received monthly payments as part of his inheritance and income from the Maharaja of Tripura, sales of his family's jewellery, his seaside bungalow in Puri, and a derisory 2,000 rupees in book royalties.[56] He gained Bengali and foreign readers alike; he published Naivedya (1901) and Kheya (1906) and translated poems into free verse.\\r\\nIn November 1913, Tagore learned he had won that year's Nobel Prize in Literature: the Swedish Academy appreciated the idealisticand for Westernersaccessible nature of a small body of his translated material focused on the 1912 Gitanjali: Song Offerings.[57] He was awarded a knighthood by King George V in the 1915 Birthday Honours, but renounced it after the 1919 Jallianwala Bagh massacre.[58]\\r\\nIn 1921, Tagore and agricultural economist Leonard Elmhirst set up the \\"Institute for Rural Reconstruction\\", later renamed Shriniketan or \\"Abode of Welfare\\", in Surul, a village near the ashram. With it, Tagore sought to moderate Gandhi's Swaraj protests, which he occasionally blamed for British India's perceived mental  and thus ultimately colonial  decline.[59] He sought aid from donors, officials, and scholars worldwide to \\"free village[s] from the shackles of helplessness and ignorance\\" by \\"vitalis[ing] knowledge\\".[60][61] In the early 1930s he targeted ambient \\"abnormal caste consciousness\\" and untouchability. He lectured against these, he penned Dalit heroes for his poems and his dramas, and he campaignedsuccessfullyto open Guruvayoor Temple to Dalits.[62][63]\\r\\nDutta and Robinson describe this phase of Tagore's life as being one of a \\"peripatetic litterateur\\". It affirmed his opinion that human divisions were shallow. During a May 1932 visit to a Bedouin encampment in the Iraqi desert, the tribal chief told him that \\"Our prophet has said that a true Muslim is he by whose words and deeds not the least of his brother-men may ever come to any harm ...\\" Tagore confided in his diary: \\"I was startled into recognizing in his words the voice of essential humanity.\\"[64] To the end Tagore scrutinised orthodoxyand in 1934, he struck. That year, an earthquake hit Bihar and killed thousands. Gandhi hailed it as seismic karma, as divine retribution avenging the oppression of Dalits. Tagore rebuked him for his seemingly ignominious implications.[65] He mourned the perennial poverty of Calcutta and the socioeconomic decline of Bengal, and detailed these newly plebeian aesthetics in an unrhymed hundred-line poem whose technique of searing double-vision foreshadowed Satyajit Ray's film Apur Sansar.[66][67] Fifteen new volumes appeared, among them prose-poem works Punashcha (1932), Shes Saptak (1935), and Patraput (1936). Experimentation continued in his prose-songs and dance-dramas Chitra (1914), Shyama (1939), and Chandalika (1938) and in his novels Dui Bon (1933), Malancha (1934), and Char Adhyay (1934).[citation needed]\\r\\n?Verse 292, Stray Birds, 1916.\\r\\nTagore's remit expanded to science in his last years, as hinted in Visva-Parichay, a 1937 collection of essays. His respect for scientific laws and his exploration of biology, physics, and astronomy informed his poetry, which exhibited extensive naturalism and verisimilitude.[68] He wove the process of science, the narratives of scientists, into stories in Se (1937), Tin Sangi (1940), and Galpasalpa (1941). His last five years were marked by chronic pain and two long periods of illness. These began when Tagore lost consciousness in late 1937; he remained comatose and near death for a time. This was followed in late 1940 by a similar spell, from which he never recovered. Poetry from these valetudinary years is among his finest.[69][70] A period of prolonged agony ended with Tagore's death on 7 August 1941, aged eighty; he was in an upstairs room of the Jorasanko mansion he was raised in.[71][72] The date is still mourned.[73] A. K. Sen, brother of the first chief election commissioner, received dictation from Tagore on 30 July 1941, a day prior to a scheduled operation: his last poem.[74]\\r\\nI'm lost in the middle of my birthday. I want my friends, their touch, with the earth's last love. I will take life's final offering, I will take the human's last blessing. Today my sack is empty. I have given completely whatever I had to give. In return if I receive anythingsome love, some forgivenessthen I will take it with me when I step on the boat that crosses to the festival of the wordless end.\\r\\n Interviewed by Einstein, 14 April 1930.[75]\\r\\nBetween 1878 and 1932, Tagore set foot in more than thirty countries on five continents.[77] In 1912, he took a sheaf of his translated works to England, where they gained attention from missionary and Gandhi protg Charles F. Andrews, Irish poet William Butler Yeats, Ezra Pound, Robert Bridges, Ernest Rhys, Thomas Sturge Moore, and others.[78] Yeats wrote the preface to the English translation of Gitanjali; Andrews joined Tagore at Santiniketan. In November 1912 Tagore began touring the United States[79] and the United Kingdom, staying in Butterton, Staffordshire with Andrews's clergymen friends.[80] From May 1916 until April 1917, he lectured in Japan and the United States.[81] He denounced nationalism.[82] His essay \\"Nationalism in India\\" was scorned and praised; it was admired by Romain Rolland and other pacifists.[83]\\r\\nShortly after returning home the 63-year-old Tagore accepted an invitation from the Peruvian government. He travelled to Mexico. Each government pledged US$100,000 to his school to commemorate the visits.[84] A week after his 6 November 1924 arrival in Buenos Aires,[85] an ill Tagore shifted to the Villa Miralro at the behest of Victoria Ocampo. He left for home in January 1925. In May 1926 Tagore reached Naples; the next day he met Mussolini in Rome.[86] Their warm rapport ended when Tagore pronounced upon Il Duce's fascist finesse.[87] He had earlier enthused: \\"[w]ithout any doubt he is a great personality. There is such a massive vigour in that head that it reminds one of Michael Angelo's chisel.\\" A \\"fire-bath\\" of fascism was to have educed \\"the immortal soul of Italy ... clothed in quenchless light\\".[88]\\r\\nOn 14 July 1927 Tagore and two companions began a four-month tour of Southeast Asia. They visited Bali, Java, Kuala Lumpur, Malacca, Penang, Siam, and Singapore. The resultant travelogues compose Jatri (1929).[89] In early 1930 he left Bengal for a nearly year-long tour of Europe and the United States. Upon returning to Britainand as his paintings were exhibited in Paris and Londonhe lodged at a Birmingham Quaker settlement. He wrote his Oxford Hibbert Lectures[f] and spoke at the annual London Quaker meet.[90] There, addressing relations between the British and the Indians  a topic he would tackle repeatedly over the next two years  Tagore spoke of a \\"dark chasm of aloofness\\".[91] He visited Aga Khan III, stayed at Dartington Hall, toured Denmark, Switzerland, and Germany from June to mid-September 1930, then went on into the Soviet Union.[92] In April 1932 Tagore, intrigued by the Persian mystic Hafez, was hosted by Reza Shah Pahlavi.[93][94] In his other travels, Tagore interacted with Henri Bergson, Albert Einstein, Robert Frost, Thomas Mann, George Bernard Shaw, H.G. Wells, and Romain Rolland.[95][96] Visits to Persia and Iraq (in 1932) and Sri Lanka (in 1933) composed Tagore's final foreign tour, and his dislike of communalism and nationalism only deepened.[64] Vice-President of India M. Hamid Ansari has said that Rabindranath Tagore heralded the cultural rapprochement between communities, societies and nations much before it became the liberal norm of conduct. Tagore was a man ahead of his time. He wrote in 1932, while on a visit to Iran, that \\"each country of Asia will solve its own historical problems according to its strength, nature and needs, but the lamp they will each carry on their path to progress will converge to illuminate the common ray of knowledge.\\"[97]\\r\\nKnown mostly for his poetry, Tagore wrote novels, essays, short stories, travelogues, dramas, and thousands of songs. Of Tagore's prose, his short stories are perhaps most highly regarded; he is indeed credited with originating the Bengali-language version of the genre. His works are frequently noted for their rhythmic, optimistic, and lyrical nature. Such stories mostly borrow from deceptively simple subject matter: commoners. Tagore's non-fiction grappled with history, linguistics, and spirituality. He wrote autobiographies. His travelogues, essays, and lectures were compiled into several volumes, including Europe Jatrir Patro (Letters from Europe) and Manusher Dhormo (The Religion of Man). His brief chat with Einstein, \\"Note on the Nature of Reality\\", is included as an appendix to the latter. On the occasion of Tagore's 150th birthday an anthology (titled Kalanukromik Rabindra Rachanabali) of the total body of his works is currently being published in Bengali in chronological order. This includes all versions of each work and fills about eighty volumes.[98] In 2011, Harvard University Press collaborated with Visva-Bharati University to publish The Essential Tagore, the largest anthology of Tagore's works available in English; it was edited by Fakrul Alam and Radha Chakravarthy and marks the 150th anniversary of Tagore's birth.[99]\\r\\nTagore's experiences with drama began when he was sixteen, with his brother Jyotirindranath. He wrote his first original dramatic piece when he was twenty  Valmiki Pratibha which was shown at the Tagore's mansion. Tagore stated that his works sought to articulate \\"the play of feeling and not of action\\". In 1890 he wrote Visarjan (an adaptation of his novella Rajarshi), which has been regarded as his finest drama. In the original Bengali language, such works included intricate subplots and extended monologues. Later, Tagore's dramas used more philosophical and allegorical themes. The play Dak Ghar (The Post Office'; 1912), describes the child Amal defying his stuffy and puerile confines by ultimately \\"fall[ing] asleep\\", hinting his physical death. A story with borderless appealgleaning rave reviews in EuropeDak Ghar dealt with death as, in Tagore's words, \\"spiritual freedom\\" from \\"the world of hoarded wealth and certified creeds\\".[100][101] Another is Tagore's Chandalika (Untouchable Girl), which was modelled on an ancient Buddhist legend describing how Ananda, the Gautama Buddha's disciple, asks a tribal girl for water.[102] In Raktakarabi (\\"Red\\" or \\"Blood Oleanders\\") is an allegorical struggle against a kleptocrat king who rules over the residents of Yaksha puri.[103]\\r\\nChitrangada, Chandalika, and Shyama are other key plays that have dance-drama adaptations, which together are known as Rabindra Nritya Natya.\\r\\nTagore began his career in short stories in 1877when he was only sixteenwith \\"Bhikharini\\" (\\"The Beggar Woman\\").[104] With this, Tagore effectively invented the Bengali-language short story genre.[105] The four years from 1891 to 1895 are known as Tagore's \\"Sadhana\\" period (named for one of Tagore's magazines). This period was among Tagore's most fecund, yielding more than half the stories contained in the three-volume Galpaguchchha, which itself is a collection of eighty-four stories.[104] Such stories usually showcase Tagore's reflections upon his surroundings, on modern and fashionable ideas, and on interesting mind puzzles (which Tagore was fond of testing his intellect with). Tagore typically associated his earliest stories (such as those of the \\"Sadhana\\" period) with an exuberance of vitality and spontaneity; these characteristics were intimately connected with Tagore's life in the common villages of, among others, Patisar, Shajadpur, and Shilaida while managing the Tagore family's vast landholdings.[104] There, he beheld the lives of India's poor and common people; Tagore thereby took to examining their lives with a penetrative depth and feeling that was singular in Indian literature up to that point.[106] In particular, such stories as \\"Kabuliwala\\" (\\"The Fruitseller from Kabul\\", published in 1892), \\"Kshudita Pashan\\" (\\"The Hungry Stones\\") (August 1895), and \\"Atithi\\" (\\"The Runaway\\", 1895) typified this analytic focus on the downtrodden.[107] Many of the other Galpaguchchha stories were written in Tagore's Sabuj Patra period from 1914 to 1917, also named after one of the magazines that Tagore edited and heavily contributed to.[104]\\r\\nTagore wrote eight novels and four novellas, among them Chaturanga, Shesher Kobita, Char Odhay, and Noukadubi. Ghare Baire (The Home and the World)through the lens of the idealistic zamindar protagonist Nikhilexcoriates rising Indian nationalism, terrorism, and religious zeal in the Swadeshi movement; a frank expression of Tagore's conflicted sentiments, it emerged from a 1914 bout of depression. The novel ends in Hindu-Muslim violence and Nikhil'slikely mortalwounding.[108]\\r\\nGora raises controversial questions regarding the Indian identity. As with Ghare Baire, matters of self-identity (jti), personal freedom, and religion are developed in the context of a family story and love triangle.[109] In it an Irish boy orphaned in the Sepoy Mutiny is raised by Hindus as the titular gora\\"whitey\\". Ignorant of his foreign origins, he chastises Hindu religious backsliders out of love for the indigenous Indians and solidarity with them against his hegemon-compatriots. He falls for a Brahmo girl, compelling his worried foster father to reveal his lost past and cease his nativist zeal. As a \\"true dialectic\\" advancing \\"arguments for and against strict traditionalism\\", it tackles the colonial conundrum by \\"portray[ing] the value of all positions within a particular frame?[...] not only syncretism, not only liberal orthodoxy, but the extremest reactionary traditionalism he defends by an appeal to what humans share.\\" Among these Tagore highlights \\"identity?[...] conceived of as dharma.\\"[110]\\r\\nIn Jogajog (Relationships), the heroine Kumudinibound by the ideals of ?iva-Sati, exemplified by Dkshyaniis torn between her pity for the sinking fortunes of her progressive and compassionate elder brother and his foil: her roue of a husband. Tagore flaunts his feminist leanings; pathos depicts the plight and ultimate demise of women trapped by pregnancy, duty, and family honour; he simultaneously trucks with Bengal's putrescent landed gentry.[111] The story revolves around the underlying rivalry between two familiesthe Chatterjees, aristocrats now on the decline (Biprodas) and the Ghosals (Madhusudan), representing new money and new arrogance. Kumudini, Biprodas' sister, is caught between the two as she is married off to Madhusudan. She had risen in an observant and sheltered traditional home, as had all her female relations.\\r\\nOthers were uplifting: Shesher Kobitatranslated twice as Last Poem and Farewell Songis his most lyrical novel, with poems and rhythmic passages written by a poet protagonist. It contains elements of satire and postmodernism and has stock characters who gleefully attack the reputation of an old, outmoded, oppressively renowned poet who, incidentally, goes by a familiar name: \\"Rabindranath Tagore\\". Though his novels remain among the least-appreciated of his works, they have been given renewed attention via film adaptations by Ray and others: Chokher Bali and Ghare Baire are exemplary. In the first, Tagore inscribes Bengali society via its heroine: a rebellious widow who would live for herself alone. He pillories the custom of perpetual mourning on the part of widows, who were not allowed to remarry, who were consigned to seclusion and loneliness. Tagore wrote of it: \\"I have always regretted the ending\\".[citation needed]\\r\\nInternationally, Gitanjali (Bengali: ?????????) is Tagore's best-known collection of poetry, for which he was awarded the Nobel Prize in 1913. Tagore was the first person (excepting Roosevelt) outside Europe to get the Nobel Prize.\\r\\nBesides Gitanjali, other notable works include Manasi, Sonar Tori (\\"Golden Boat\\"), Balaka (\\"Wild Geese\\"  the title being a metaphor for migrating souls)[112]\\r\\nTagore's poetic style, which proceeds from a lineage established by 15th- and 16th-century Vaishnava poets, ranges from classical formalism to the comic, visionary, and ecstatic. He was influenced by the atavistic mysticism of Vyasa and other rishi-authors of the Upanishads, the Bhakti-Sufi mystic Kabir, and Ramprasad Sen.[113] Tagore's most innovative and mature poetry embodies his exposure to Bengali rural folk music, which included mystic Baul ballads such as those of the bard Lalon.[114][115] These, rediscovered and repopularised by Tagore, resemble 19th-century Kartbhaj hymns that emphasise inward divinity and rebellion against bourgeois bhadralok religious and social orthodoxy.[116][117] During his Shelaidaha years, his poems took on a lyrical voice of the moner manush, the Buls' \\"man within the heart\\" and Tagore's \\"life force of his deep recesses\\", or meditating upon the jeevan devatathe demiurge or the \\"living God within\\".[27] This figure connected with divinity through appeal to nature and the emotional interplay of human drama. Such tools saw use in his Bhnusi?ha poems chronicling the Radha-Krishna romance, which were repeatedly revised over the course of seventy years.[118][119]\\r\\nLater, with the development of new poetic ideas in Bengal  many originating from younger poets seeking to break with Tagore's style  Tagore absorbed new poetic concepts, which allowed him to further develop a unique identity. Examples of this include Africa and Camalia, which are among the better known of his latter poems.\\r\\nTagore was a prolific composer with around 2,230 songs to his credit.[120] His songs are known as rabindrasangit (\\"Tagore Song\\"), which merges fluidly into his literature, most of whichpoems or parts of novels, stories, or plays alikewere lyricised. Influenced by the thumri style of Hindustani music, they ran the entire gamut of human emotion, ranging from his early dirge-like Brahmo devotional hymns to quasi-erotic compositions.[121] They emulated the tonal colour of classical ragas to varying extents. Some songs mimicked a given raga's melody and rhythm faithfully; others newly blended elements of different ragas.[122] Yet about nine-tenths of his work was not bhanga gaan, the body of tunes revamped with \\"fresh value\\" from select Western, Hindustani, Bengali folk and other regional flavours \\"external\\" to Tagore's own ancestral culture.[27]\\r\\nIn 1971, Amar Shonar Bangla became the national anthem of Bangladesh. It was written  ironically  to protest the 1905 Partition of Bengal along communal lines: cutting off the Muslim-majority East Bengal from Hindu-dominated West Bengal was to avert a regional bloodbath. Tagore saw the partition as a cunning plan to stop the independence movement, and he aimed to rekindle Bengali unity and tar communalism. Jana Gana Mana was written in shadhu-bhasha, a Sanskritised form of Bengali, and is the first of five stanzas of the Brahmo hymn Bharot Bhagyo Bidhata that Tagore composed. It was first sung in 1911 at a Calcutta session of the Indian National Congress[123] and was adopted in 1950 by the Constituent Assembly of the Republic of India as its national anthem.\\r\\nThe Sri Lanka's National Anthem was inspired by his work.[19][20][21]\\r\\nFor Bengalis, the songs' appeal, stemming from the combination of emotive strength and beauty described as surpassing even Tagore's poetry, was such that the Modern Review observed that \\"[t]here is in Bengal no cultured home where Rabindranath's songs are not sung or at least attempted to be sung... Even illiterate villagers sing his songs\\".[124] Tagore influenced sitar maestro Vilayat Khan and sarodiyas Buddhadev Dasgupta and Amjad Ali Khan.[122]\\r\\nAt sixty, Tagore took up drawing and painting; successful exhibitions of his many workswhich made a debut appearance in Paris upon encouragement by artists he met in the south of France[126]were held throughout Europe. He was likely red-green colour blind, resulting in works that exhibited strange colour schemes and off-beat aesthetics. Tagore was influenced numerous styles, including scrimshaw by the Malanggan people of northern New Ireland, Papua New Guinea, Haida carvings from the Pacific Northwest region of North America, and woodcuts by the German Max Pechstein.[125] His artist's eye for his handwriting were revealed in the simple artistic and rhythmic leitmotifs embellishing the scribbles, cross-outs, and word layouts of his manuscripts. Some of Tagore's lyrics corresponded in a synesthetic sense with particular paintings.[27]\\r\\nSurrounded by several painters Rabindranath had always wanted to paint. Writing and music, playwriting and acting came to him naturally and almost without training, as it did to several others in his family, and in even greater measure. But painting eluded him. Yet he tried repeatedly to master the art and there are several references to this in his early letters and reminiscence. In 1900 for instance, when he was nearing forty and already a celebrated writer, he wrote to Jagadishchandra Bose, \\"You will be surprised to hear that I am sitting with a sketchbook drawing. Needless to say, the pictures are not intended for any salon in Paris, they cause me not the least suspicion that the national gallery of any country will suddenly decide to raise taxes to acquire them. But, just as a mother lavishes most affection on her ugliest son, so I feel secretly drawn to the very skill that comes to me least easily.\\" He also realized that he was using the eraser more than the pencil, and dissatisfied with the results he finally withdrew, deciding it was not for him to become a painter.[127]\\r\\nTagore also had an artist's eye for his own handwriting, embellishing the cross-outs and word layouts in his manuscripts with simple artistic leitmotifs.\\r\\nIndia's National Gallery of Modern Art lists 102 works by Tagore in its collections.[128][129]\\r\\nTagore opposed imperialism and supported Indian nationalists,[130][131][132] and these views were first revealed in Manast, which was mostly composed in his twenties.[51] Evidence produced during the HinduÿGerman Conspiracy Trial and latter accounts affirm his awareness of the Ghadarites, and stated that he sought the support of Japanese Prime Minister Terauchi Masatake and former Premier kuma Shigenobu.[133] Yet he lampooned the Swadeshi movement; he rebuked it in The Cult of the Charkha, an acrid 1925 essay.[134] He urged the masses to avoid victimology and instead seek self-help and education, and he saw the presence of British administration as a \\"political symptom of our social disease\\". He maintained that, even for those at the extremes of poverty, \\"there can be no question of blind revolution\\"; preferable to it was a \\"steady and purposeful education\\".[135][136]\\r\\n Sdhan: The Realisation of Life, 1916.[137]\\r\\nSuch views enraged many. He escaped assassinationand only narrowlyby Indian expatriates during his stay in a San Francisco hotel in late 1916; the plot failed when his would-be assassins fell into argument.[138] Tagore wrote songs lionising the Indian independence movement.[139] Two of Tagore's more politically charged compositions, \\"Chitto Jetha Bhayshunyo\\" (\\"Where the Mind is Without Fear\\") and \\"Ekla Chalo Re\\" (\\"If They Answer Not to Thy Call, Walk Alone\\"), gained mass appeal, with the latter favoured by Gandhi.[140] Though somewhat critical of Gandhian activism,[141] Tagore was key in resolving a GandhiÿAmbedkar dispute involving separate electorates for untouchables, thereby mooting at least one of Gandhi's fasts \\"unto death\\".[142][143]\\r\\nTagore renounced his knighthood in response to the Jallianwala Bagh massacre in 1919. In the repudiation letter to the Viceroy, Lord Chelmsford, he wrote[144]\\r\\nThe time has come when badges of honour make our shame glaring in the incongruous context of humiliation, and I for my part, wish to stand, shorn, of all special distinctions, by the side of those of my countrymen who, for their so called insignificance, are liable to suffer degradation not fit for human beings.\\r\\nTagore despised rote classroom schooling: in \\"The Parrot's Training\\", a bird is caged and force-fed textbook pagesto death.[145][146] Tagore, visiting Santa Barbara in 1917, conceived a new type of university: he sought to \\"make Santiniketan the connecting thread between India and the world [and] a world center for the study of humanity somewhere beyond the limits of nation and geography.\\"[138] The school, which he named Visva-Bharati,[g] had its foundation stone laid on 24 December 1918 and was inaugurated precisely three years later.[147] Tagore employed a brahmacharya system: gurus gave pupils personal guidanceemotional, intellectual, and spiritual. Teaching was often done under trees. He staffed the school, he contributed his Nobel Prize monies,[148] and his duties as steward-mentor at Santiniketan kept him busy: mornings he taught classes; afternoons and evenings he wrote the students' textbooks.[149] He fundraised widely for the school in Europe and the United States between 1919 and 1921.[150]\\r\\nOn 25 March 2004, Tagore's Nobel Prize was stolen from the safety vault of the Visva-Bharati University, along with several other of his belongings.[151] On 7 December 2004, the Swedish Academy decided to present two replicas of Tagore's Nobel Prize, one made of gold and the other made of bronze, to the Visva-Bharati University.[152] It inspired the fictional film Nobel Chor.\\r\\n\\"Every person is worthy of an infinite wealth of love - the beauty of his soul knows no limit.\\" -Rabindranath Tagore, Glimpses of Bengal [153]\\r\\n\\"Who are you, reader, reading my poems an hundred years hence? I cannot send you one single flower from this wealth of the spring, one single streak of gold from yonder clouds. Open your doors and look abroad. From your blossoming garden gather fragrant memories of the vanished flowers of an hundred years before. In the joy of your heart may you feel the living joy that sang one spring morning, sending its glad voice across an hundred years.\\"\\r\\n\\"Trust love even if it brings sorrow. Do not close up your heart.\\"  Rabindranath Tagore, The Gardener [154]\\r\\n\\"The roots below the earth claim no rewards for making the branches fruitful.\\"\\r\\n\\"We read the world wrong and say that it deceives us.\\"\\r\\n\\"Once we dreamt that we were strangers. We wake up to find that we were dear to each other.\\"\\r\\n~ Rabindranath Tagore, Stray Birds [155]\\r\\n(All quotes sourced from Project Gutenberg)\\r\\nEvery year, many events pay tribute to Tagore: Kabipranam, his birth anniversary, is celebrated by groups scattered across the globe; the annual Tagore Festival held in Urbana, Illinois (USA); Rabindra Path Parikrama walking pilgrimages from Kolkata to Santiniketan; and recitals of his poetry, which are held on important anniversaries.[79][156][157] Bengali culture is fraught with this legacy: from language and arts to history and politics. Amartya Sen deemed Tagore a \\"towering figure\\", a \\"deeply relevant and many-sided contemporary thinker\\".[157] Tagore's Bengali originalsthe 1939 Rabؐndra Rachanvalؐis canonised as one of his nation's greatest cultural treasures, and he was roped into a reasonably humble role: \\"the greatest poet India has produced\\".[158]\\r\\nWho are you, reader, reading my poems a hundred years hence?\\r\\nI cannot send you one single flower from this wealth of the spring, one single streak of gold from yonder clouds.\\r\\nOpen your doors and look abroad.\\r\\nFrom your blossoming garden gather fragrant memories of the vanished flowers of an hundred years before.\\r\\nIn the joy of your heart may you feel the living joy that sang one spring morning, sending its glad voice across an hundred years.\\r\\n The Gardener, 1915.[159]\\r\\nTagore was renowned throughout much of Europe, North America, and East Asia. He co-founded Dartington Hall School, a progressive coeducational institution;[160] in Japan, he influenced such figures as Nobel laureate Yasunari Kawabata.[161] Tagore's works were widely translated into English, Dutch, German, Spanish, and other European languages by Czech Indologist Vincenc Lesny,[162] French Nobel laureate Andr Gide, Russian poet Anna Akhmatova,[163] former Turkish Prime Minister Blent Ecevit,[164] and others. In the United States, Tagore's lecturing circuits, particularly those of 1916ÿ1917, were widely attended and wildly acclaimed. Some controversies[h] involving Tagore, possibly fictive, trashed his popularity and sales in Japan and North America after the late 1920s, concluding with his \\"near total eclipse\\" outside Bengal.[8] Yet a latent reverence of Tagore was discovered by an astonished Salman Rushdie during a trip to Nicaragua.[170]\\r\\nBy way of translations, Tagore influenced Chileans Pablo Neruda and Gabriela Mistral; Mexican writer Octavio Paz; and Spaniards Jos Ortega y Gasset, Zenobia Camprub, and Juan Ram܇n Jimnez. In the period 1914ÿ1922, the Jimnez-Camprub pair produced twenty-two Spanish translations of Tagore's English corpus; they heavily revised The Crescent Moon and other key titles. In these years, Jimnez developed \\"naked poetry\\".[171] Ortega y Gasset wrote that \\"Tagore's wide appeal [owes to how] he speaks of longings for perfection that we all have?[...] Tagore awakens a dormant sense of childish wonder, and he saturates the air with all kinds of enchanting promises for the reader, who?[...] pays little attention to the deeper import of Oriental mysticism\\". Tagore's works circulated in free editions around 1920alongside those of Plato, Dante, Cervantes, Goethe, and Tolstoy.\\r\\nTagore was deemed over-rated by some. Graham Greene doubted that \\"anyone but Mr. Yeats can still take his poems very seriously.\\" Several prominent Western admirersincluding Pound and, to a lesser extent, even Yeatscriticised Tagore's work. Yeats, unimpressed with his English translations, railed against that \\"Damn Tagore?[...] We got out three good books, Sturge Moore and I, and then, because he thought it more important to know English than to be a great poet, he brought out sentimental rubbish and wrecked his reputation. Tagore does not know English, no Indian knows English.\\"[8][172] William Radice, who \\"English[ed]\\" his poems, asked: \\"What is their place in world literature?\\"[173] He saw him as \\"kind of counter-cultur[al]\\", bearing \\"a new kind of classicism\\" that would heal the \\"collapsed romantic confusion and chaos of the 20th [c]entury.\\"[172][174] The translated Tagore was \\"almost nonsensical\\",[175] and subpar English offerings reduced his trans-national appeal:\\r\\nAnyone who knows Tagore's poems in their original Bengali cannot feel satisfied with any of the translations (made with or without Yeats's help). Even the translations of his prose works suffer, to some extent, from distortion. E.M. Forster noted [of] The Home and the World [that] '[t]he theme is so beautiful,' but the charms have 'vanished in translation,' or perhaps 'in an experiment that has not quite come off.'\\r\\nThere are five Tagore museums in India and Bangladesh:\\r\\nJorasanko Thakur Bari (Bengali: House of the Thakurs (anglicised to Tagore) in Jorasanko, north of Kolkata, is the ancestral home of the Tagore family. It is currently located on the Rabindra Bharati University campus at 6/4 Dwarakanath Tagore Lane[176] Jorasanko, Kolkata 700007.[177] It is the house in which Tagore was born. It is also the place where he spent most of his childhood and where he died on 7 August 1941.\\r\\nShilaidaha Kuthibadi[178][179] (Bengali: ???????) is a place in Kumarkhali Upazila of Kushtia District in Bangladesh. The place is famous for Kuthi Bari; a country house made by Dwarkanath Tagore.[180] Tagore lived a part of life here and created some of his memorable poems while living here. The museum is named 'Tagore Memorial Museum'. Many of the objects Tagore used are displayed here, such as his bed, wardrobe, iron chest, lawn mower, framed pictures and last but not the least his houseboat.[181][182]\\r\\nThe Shahzadpur Kachharibari has been converted into a museum and a memorial in his name. Many artefacts and memorabilia items are on display in the museum, including shoes, wooden sandals, a piano and a harmonium. The building itself is of interesting architectural heritage, and contains 7 rooms.\\r\\nAdditionally, there is the Rabindra Tirtha, a cultural center in Narkel Bagan, New Town, Kolkata, India, completed in 2012.\\r\\nThe SNLTR hosts the 1415 BE edition of Tagore's complete Bengali works. Tagore Web also hosts an edition of Tagore's works, including annotated songs. Translations are found at Project Gutenberg and Wikisource. More sources are below.\\r\\nBengali\\r\\nEnglish\\r\\nEnglish\\r\\nEsperanto\\r\\nNotes\\r\\nCitations\\r\\nAnthologies\\r\\nOriginals\\r\\nTranslations\\r\\nArticles\\r\\nBooks\\r\\nOther\\r\\nOriginal\\r\\nTranslated\\r\\nAnalyses\\r\\nAudiobooks\\r\\nTexts\\r\\nTalks","input":"By which pseudonym rabindranath tagore first published his poems?"}]`),I={name:"App",components:{PoemCard:C},data(){return{visibleCount:20,poemsData:M}},computed:{visiblePoems(){return this.poemsData.slice(0,this.visibleCount)},hasMorePoems(){return this.visibleCount<this.poemsData.length}},methods:{loadMore(){this.visibleCount+=20}}},x={class:"card-container"};function B(h,t,n,c,u,i){const m=p("PoemCard");return a(),o(l,null,[t[1]||(t[1]=e("section",null,[e("div",{class:"top-Banner"},[e("div",{class:"top-Banner-Title"},[e("div",{class:"top-Banner-Title-Text"},"🎉Q&A Life🥳")])])],-1)),e("section",null,[e("div",x,[(a(!0),o(l,null,g(i.visiblePoems,(r,f)=>(a(),y(m,{key:f,poem:r},null,8,["poem"]))),128))]),i.hasMorePoems?(a(),o("button",{key:0,class:"load-more-button",onClick:t[0]||(t[0]=(...r)=>i.loadMore&&i.loadMore(...r))},"See more")):w("",!0)])],64)}const P=d(I,[["render",B]]),E=JSON.parse('{"title":"","description":"","frontmatter":{"page":true},"headers":[],"relativePath":"qapage/3.md","filePath":"qapage/3.md"}'),R={name:"qapage/3.md"},D=Object.assign(R,{setup(h){return(t,n)=>(a(),o("div",null,[b(P)]))}});export{E as __pageData,D as default};
