import{_ as d,o as a,c as i,a as e,t as s,C as p,F as l,p as g,e as y,f as w,q as b}from"./chunks/framework.DulMeQy4.js";const v={name:"PoemCard",props:{poem:{type:Object,required:!0}}},k={class:"card"},T={class:"question"},C={class:"answer"};function S(h,t,n,c,u,o){return a(),i("div",k,[e("div",T,s(n.poem.input),1),t[0]||(t[0]=e("div",{class:"separator"},null,-1)),e("div",C,s(n.poem.output)+"🚨"+s(n.poem.context),1)])}const A=d(v,[["render",S],["__scopeId","data-v-35038011"]]),I=JSON.parse(`[{"output":"In 2001","context":"singer Elan Atias released a dancehall version on the Buy Out Riddim instrumental","input":"best known performed by Sean Paul","field4":"with the song entitled","field5":"\\"\\"Like Glue\\"\\". This was the first time the song was performed on a totally different instrumental tracking. The lyrics were also re-written. In 2008","field6":"Sizzla also released a dancehall single (\\"\\"No Time To Gaze\\"\\") based on the UB40 version."},{"output":"In March 2017","context":"Andrew Bogut posted the UB40 version on his Twitter[22] to signify he was joining the Cleveland Cavaliers ÿ the team's colours include the darkish red \\"\\"wine\\"\\".\\"","input":"Who wrote the original song red red wine?"},{"output":"20,000","context":"Coordinates: 360610N 1151042W? / ?36.10278N 115.17833W? / 36.10278; -115.17833\\r\\nT-Mobile Arena is a multi-purpose indoor arena on the Las Vegas Strip in Paradise, Nevada. Opened on April 6, 2016, the arena was built as a joint venture between MGM Resorts International and the Anschutz Entertainment Group.\\r\\nThe arena is the home venue for the National Hockey League's Vegas Golden Knights, who began play in 2017. Since its opening, T-Mobile Arena has primarily been used for entertainment events such as concerts, and has been booked for mixed martial arts and professional boxing events, and well as other annual sporting events.\\r\\nThe arena is accessed by a new development project known as The Park, with retail and dining space between New York-New York and the Park MGM casino hotels.[4][5][6]\\r\\n\\r\\n\\r\\nThe Anschutz Entertainment Group (AEG) first tried to build an arena in Las Vegas in association with Harrah's Entertainment. In 2007, the joint venture announced they would build a 20,000 seat stadium behind the Bally's and Paris casino-hotels.[7] Caesars Entertainment, Inc. had previously envisioned using the location to build a baseball park, but the company's buyout by Harrah's cancelled the plans. Through the following year, Harrah's became uncertain on continuing with the project, not knowing if AEG would split the costs, and whether building a major league-ready stadium without a guaranteed franchise to play on it would be feasible given the enduring financial crisis.[8] The original plans were to break ground in June 2008 and finish the arena in 2010, but by 2009, it was revealed the stalled project had not even done a traffic study despite being located near a busy intersection.[9] In 2010, the plans were changed to use an area behind the Imperial Palace. However, given the financing would require a special taxation district, opposition from Clark County regarding using public money in the project stalled it even further.[10] AEG eventually backed out completely by 2012, once MGM Resorts International came up with their own project using a terrain behind the New York-New York and Monte Carlo resorts. This attracted AEG primarily for not relying on public funding.[11]\\r\\nMGM and AEG announced their joint arena plan on March 1, 2013.[12] Plans were further fleshed out over the following months with the announcement of a $100-million pedestrian shopping area, The Park, to serve as a gateway to the arena,[13] and the retention of prominent sports architecture firm Populous to design the project.[14] Other firms on the project include: the ICON Venue Group,[15] Thornton Tomasetti,[16] ME Engineers,[17] Penta Building Group and Hunt Construction Group.[18]\\r\\nThe project broke ground on May 1, 2014,[19] followed by the demolition of existing buildings, and excavation of an oval area for the arena. The final steel beam of the structure was placed on May 27, 2015.[20]\\r\\nIn January 2016, T-Mobile US announced it had acquired the naming rights to the new arena in a multi-year contract.[21][22] The arena held its grand opening on April 6, 2016 with a concert by Las Vegas natives The Killers, Shamir and Wayne Newton.[23] Country music artists Martina McBride and Cam performed at a soft opening on March 31, 2016.[24]\\r\\nIn 2016, the National Hockey League awarded a Las Vegas expansion team to an ownership group led by Bill Foley, with T-Mobile Arena as its home venue.[25] As part of the team's lease, Foley negotiated an option to buy a stake in the arena from MGM and AEG.[1] He exercised that option in September 2016, buying a 15 percent interest for around $35 million.[1][26]\\r\\nInterior of venue, shown on March 31, 2016.\\r\\nInterior of venue, shown 2016.\\r\\nT-Mobile Arena at night.\\r\\nDuring its construction, T-Mobile Arena was pointed to as the home arena for a possible National Hockey League expansion team in Las Vegas.[27][28][29] The expansion bid was approved and announced by the NHL on June 22, 2016; the new team, the Vegas Golden Knights, began play in the 2017ÿ18 season.[25][30]\\r\\nThe Ultimate Fighting Championship's first event at the venue was UFC 200, held on July 9, 2016.[31] In March 2017, the UFC signed a seven-year agreement to become an official tenant of T-Mobile Arena. The promotion agreed to host at least four events per-year at the facility, in exchange for receiving permanent retail space and signage.[32]\\r\\nThe Professional Bull Riders World Finals moved to T-Mobile Arena in 2016, moving from the Thomas & Mack Center,[33] followed by the Pac-12 Conference Men's Basketball Tournament, which moved from the MGM Grand Garden Arena.[34]\\r\\nIn addition to Golden Knights games and UFC events, a number of major sporting events have been held at the arena, including boxing matches such as Canelo lvarez vs. Gennady Golovkin and Floyd Mayweather Jr. vs. Conor McGregor. By virtue of the Golden Knights winning the 2017-18 Western Conference finals, it also played host to three games of the 2018 Stanley Cup Finals, between the Golden Knights and the Washington Capitals.\\r\\nThe arena has hosted nationally televised entertainment events such as the Academy of Country Music Awards, the Billboard Music Awards, the iHeartRadio Music Festival, the Latin Grammys, the Miss USA beauty pageant, and WWE professional wrestling events.","input":"How many seats in the las vegas arena?"},{"output":"Hangul","context":"Korean, Jeju, Cia-Cia\\r\\n\\r\\nThe Korean alphabet, known as Hangul (/?h?nu?l/ HAHN-gool;[1] from Korean hangeul ?? [ha(?)n.?l]), has been used to write the Korean language since its creation in the 15th century by Sejong the Great.[2][3]\\r\\n\\r\\nIt is the official writing system of North Korea and South Korea. It is a co-official writing system in the Yanbian Korean Autonomous Prefecture and Changbai Korean Autonomous County in Jilin Province, China. It is sometimes used to write the Cia-Cia language spoken near the town of Bau-Bau, Indonesia.\\r\\n\\r\\nThe alphabet consists of 14 consonants and 10 vowels. Its letters are grouped into syllabic blocks, vertically and horizontally. For example, the Korean word for \\"honeybee\\" is written ??, not ??????.[4] As it combines the features of alphabetic and syllabic writing systems, it has been described as an \\"alphabetic syllabary\\" by some linguists.[5][6] As in traditional Chinese writing, Korean texts were traditionally written top to bottom, right to left, and are occasionally still written this way for stylistic purposes. Today, it is typically written from left to right with spaces between words and western-style punctuation.[7]\\r\\n\\r\\nSome linguists consider it the most logical writing system in the world, partly because the shapes of its consonants mimic the shapes of the speaker's mouth when pronouncing each consonant.[5][7][8]\\r\\n\\r\\nThe Korean alphabet was originally called Hunminjeongeum (????), after the document that introduced the script to the Korean people in 1446.[10]\\r\\n\\r\\nNorth Koreans call the Korean alphabet Chos?n'g?l (???) after Chos?n, the North Korean name for Korea.[11] The McCuneÿReischauer system is used there.\\r\\n\\r\\nToday, South Koreans call the Korean alphabet hangeul (??), a name coined by Korean linguist Ju Si-gyeong in 1912. The name combines the ancient Korean word han (?), meaning \\"great\\", and geul (?), meaning \\"script\\". The word han is used to refer to Korea in general, so the name also means \\"Korean script\\".[12] It has been romanized in multiple ways:\\r\\n\\r\\nUntil the early 20th century, the Korean elite preferred to write using Chinese characters called Hanja. They referred to Hanja as jinseo (??) or \\"true letters\\". Some accounts say the elite referred to the Korean alphabet derisively as amkeul (??) meaning \\"women's script\\", and ahaetgeul (???) meaning \\"children's script\\", though there is no written evidence of this.[13]\\r\\n\\r\\nSupporters of the Korean alphabet referred to it as jeong-eum (??) meaning \\"correct pronunciation\\", gungmun (??) meaning \\"national script\\", and eonmun (??) meaning \\"vernacular script\\".[13]\\r\\n\\r\\nBefore the creation of the new Korean alphabet, Koreans primarily wrote using Classical Chinese alongside native phonetic writing systems that predate the modern Korean alphabet by hundreds of years, including Idu script, Hyangchal, Gugyeol and Gakpil.[14][15][16][17] However, due to fundamental differences between the Korean and Chinese languages, and the large number of characters, many lower class Koreans were illiterate.[18] To promote literacy among the common people, the fourth king of the Joseon dynasty, Sejong the Great, personally created and promulgated a new alphabet.[3][18][19]\\r\\n\\r\\nThe Korean alphabet was designed so that people with little education could learn to read and write. A popular saying about the alphabet is, \\"A wise man can acquaint himself with them before the morning is over; even a stupid man can learn them in the space of ten days.\\"[20]\\r\\n\\r\\nThe project was completed in late December 1443 or January 1444, and described in 1446 in a document titled Hunminjeongeum (\\"The Proper Sounds for the Education of the People\\"), after which the alphabet itself was originally named.[13] The publication date of the Hunminjeongeum, October 9, became Hangul Day in South Korea. Its North Korean equivalent, Chos?n'g?l Day, is on January 15.\\r\\n\\r\\nAnother document published in 1446 and titled Hunmin Jeongeum Haerye (\\"Hunmin Jeongeum Explanation and Examples\\") was discovered in 1940. This document explains that the design of the consonant letters is based on articulatory phonetics and the design of the vowel letters are based on the principles of yin and yang and vowel harmony.\\r\\n\\r\\nThe Korean alphabet faced opposition in the 1440s by the literary elite, including politician Choe Manri and other Korean Confucian scholars. They believed Hanja was the only legitimate writing system. They also saw the circulation of the Korean alphabet as a threat to their status.[18] However, the Korean alphabet entered popular culture as King Sejong had intended, used especially by women and writers of popular fiction.[21] King Yeonsangun banned the study and publication of the Korean alphabet in 1504, after a document criticizing the king entered the public.[22] Similarly, King Jungjong abolished the Ministry of Eonmun, a governmental institution related to Hangul research, in 1506.[23]\\r\\n\\r\\nThe late 16th century, however, saw a revival of the Korean alphabet as gasa and sijo poetry flourished. In the 17th century, the Korean alphabet novels became a major genre.[24] However, the use of the Korean alphabet had gone without standardisation for so long that spelling had become quite irregular.[21]\\r\\n\\r\\nIn 1796, the Dutch scholar Isaac Titsingh became the first person to bring a book written in Korean to the West. His small library included the Japanese book, Sangoku Tsran Zusetsu (An Illustrated Description of Three Countries) by Hayashi Shihei.[25] This book, which was published in 1785, described the Joseon Kingdom[26] and the Korean alphabet.[27] In 1832, the Oriental Translation Fund of Great Britain and Ireland supported the posthumous abridged publication of Titsingh's French translation.[28]\\r\\n\\r\\nThanks to growing Korean nationalism, the Gabo Reformists' push, and Western missionaries' promotion of the Korean alphabet in schools and literature[29] The Korean alphabet was adopted in official documents for the first time in 1894.[22] Elementary school texts began using the Korean alphabet in 1895, and Tongnip Sinmun, established in 1896, was the first newspaper printed in both Korean and English.[30]\\r\\n\\r\\nDuring the Japanese forced occupation, which began in 1910, Japanese was made the official language of Korea. However, the Korean alphabet was still taught in Korean-established schools built after the annexation and Korean was written in a mixed Hanja-Hangul script, where most lexical roots were written in Hanja and grammatical forms in the Korean alphabet. Japan banned earlier Korean literature from the public schools, which became mandatory for children.\\r\\n\\r\\nOrthography of the Korean alphabet was partially standardized in 1912, when the vowel arae-a (?)ÿwhich has now disappeared from Koreanÿwas restricted to Sino-Korean roots: the emphatic consonants were standardized to and final consonants restricted to. Long vowels were marked by a diacritic dot to the left of the syllable, but this was dropped in 1921.[21]\\r\\n\\r\\nA second colonial reform occurred in 1930. The arae-a was abolished: the emphatic consonants were changed to and more final consonants, ? were allowed, making the orthography more morphophonemic. The double-consonant ? was written alone (without a vowel) when it occurred between nouns, and the nominative particle -? was introduced after vowels, replacing -?.[21]\\r\\n\\r\\nJu Si-gyeong, the linguist who had coined the term Hangul to replace Eonmun or \\"Vulgar Script\\" in 1912, established the Korean Language Research Society (later renamed the Hangul Society), which further reformed orthography with Standardized System of Hangul in 1933. The principal change was to make the Korean alphabet as morphophonemically practical given the existing letters.[21] A system for transliterating foreign orthographies was published in 1940.\\r\\n\\r\\nHowever, Japan banned the Korean language from schools in 1938 as part of a policy of cultural assimilation,[31] and all Korean-language publications were outlawed in 1941.[32]\\r\\n\\r\\nThe definitive modern Korean alphabet orthography was published in 1946, just after Korean independence from Japanese rule. In 1948, North Korea attempted to make the script perfectly morphophonemic through the addition of new letters, and in 1953, Syngman Rhee in South Korea attempted to simplify the orthography by returning to the colonial orthography of 1921, but both reforms were abandoned after only a few years.[21]\\r\\n\\r\\nBoth North Korea and South Korea have used the Korean alphabet or mixed script as their official writing system, with ever-decreasing use of Hanja. Beginning in the 1970s, Hanja began to experience a gradual decline in commercial or unofficial writing in the South due to government intervention, with some South Korean newspapers now only using Hanja as abbreviations or disambiguation of homonyms. There has been widespread debate as to the future of Hanja in South Korea. North Korea instated the Korean alphabet as its exclusive writing system in 1949, and banned the use of Hanja completely.\\r\\n\\r\\nWhile both North Korea and South Korea claim 99 percent literacy, a 2003 study found that 25 percent of those in the older generation in the South were not completely literate in the Korean alphabet.[33]\\r\\n\\r\\nThe Hunminjeongeum Society in Seoul attempts to spread the use of the Korean alphabet to unwritten languages of Asia.[34] In 2009, the Korean alphabet was unofficially adopted by the town of Bau-Bau, in Southeast Sulawesi, Indonesia, to write the Cia-Cia language.[35][36][37] A number of Indonesian Cia-Cia speakers who visited Seoul generated large media attention in South Korea, and they were greeted on their arrival by Oh Se-hoon, the mayor of Seoul.[38] It was confirmed in October 2012 that the attempts to disseminate the use of the Korean alphabet in Indonesia failed.[39] Some people continue to use the Korean alphabet at home or co-officially.\\r\\n\\r\\n Letters in the Korean alphabet are called \\"jamo (??)\\". There are 19 consonants and 21 vowels used in the modern sort.\\r\\n\\r\\nThe following consonants are used in the modern Korean alphabet:\\r\\n\\r\\nThe chart below shows all 19 consonants in South Korean alphabetic order with Revised Romanization equivalents for each letter. Consonants in the Korean alphabet may sound differently depending on whether they are the initial or final letter in a syllable. Some consonants only appear in either the initial or final position in a syllable.\\r\\n\\r\\n(e.g.  ?? - kang+ru = kang+nu, ?? - iss+eo = is-seo, -??? - -hap+ni+da = -ham-ni-da)\\r\\n\\r\\n(k)\\r\\n\\r\\n(kk)\\r\\n\\r\\n(n)\\r\\n\\r\\n(t)\\r\\n\\r\\n(-)\\r\\n\\r\\n(l)\\r\\n\\r\\n(m)\\r\\n\\r\\n(p)\\r\\n\\r\\n(-)\\r\\n\\r\\n(t)\\r\\n\\r\\n(ss/ s/ t/ n)\\r\\n\\r\\n(ng)\\r\\n\\r\\n(t)\\r\\n\\r\\n(-)\\r\\n\\r\\n(t)\\r\\n\\r\\n(k)\\r\\n\\r\\n(t)\\r\\n\\r\\n(p)\\r\\n\\r\\n(h)\\r\\n\\r\\nl+h\\r\\n\\r\\nConsonants in the Korean alphabet can be combined into 11 consonant clusters, which always appear in the final position in a syllable. They are:, and ?.\\r\\n\\r\\n(e.g. [solely] ? dag; [preceding word final letter] ?? - eop-ta, ?? an-ja) \\r\\n\\r\\n(gs)\\r\\n\\r\\n(nj)\\r\\n\\r\\n(nh)\\r\\n\\r\\n(lg)\\r\\n\\r\\n(lm)\\r\\n\\r\\n(lb)\\r\\n\\r\\n(ls)\\r\\n\\r\\n(lt)\\r\\n\\r\\n(lp)\\r\\n\\r\\n(lh)\\r\\n\\r\\n(ps)\\r\\n\\r\\nnt+ch\\r\\n\\r\\nThe chart below shows the 21 vowels used in the modern Korean Alphabet in South Korean alphabetic order with Revised Romanization equivalents for each letter. Linguists disagree on the number of phonemes versus diphthongs among vowels in the Korean alphabet.[40]\\r\\n\\r\\nalphabetic order in the Korean alphabet is called the ganada order, (??? ?) after the first three letters of the alphabet. The alphabetical order of the Korean alphabet does not mix consonants and vowels. Rather, first are velar consonants, then coronals, labials, sibilants, etc. The vowels come after the consonants.\\r\\n\\r\\nThe order from the Hunminjeongeum in 1446 was:\\r\\n\\r\\nIn 1527, Choe Sejin reorganized the alphabet:\\r\\n\\r\\nThis is the basis of the modern alphabetic orders. It was before the development of the Korean tense consonants and the double letters that represent them, and before the conflation of the letters ? (null) and ? (ng). Thus, when the North Korean and South Korean governments implemented full use of the Korean alphabet, they ordered these letters differently, with North Korea placing new letters at the end of the alphabet and South Korea grouping similar letters together.\\r\\n\\r\\nThe new, doubled letters are placed at the end of the consonants, just before the nullso as not to alter the traditional order of the rest of the alphabet.\\r\\n\\r\\nAll digraphs and trigraphs, including the old diphthongs ? andare placed after the simple vowels, again maintaining Choe's alphabetic order.\\r\\n\\r\\nThe order of the final letters is:\\r\\n\\r\\nUnlike when it is initial, this ? is pronounced, as the nasal ? ng, which occurs only as a final in the modern language. The double letters are placed to the very end, as in the initial order, but the combined consonants are ordered immediately after their first element.\\r\\n\\r\\nIn the Southern order a more modern order is maintained where double letters are placed immediately after their single counterparts:\\r\\n\\r\\nThe modern monophthongal vowels come first, with the derived forms interspersed according to their form: i is added first, then iotized, then iotized with added i. Diphthongs beginning with w are ordered according to their spelling, as ? or ? plus a second vowel, not as separate digraphs.\\r\\n\\r\\nThe order of the final letters (??) is:\\r\\n\\r\\n(\\"None\\" means there is no final letter.)\\r\\n\\r\\nEvery syllable begins with a consonant (or the silent ?) that is followed by a vowel (e.g. ? + ? = ?). Some syllables such as \\"?\\" and \\"?\\" have a final consonant or final consonant cluster (??). Then, 399 combinations are possible for \\"two-letter syllables\\" and 10,773 possible combinations for syllables with more than two \\"letters\\" (27 possible final endings), for a total of 11,172 possible combinations of Korean alphabet \\"letters\\" to form syllables.\\r\\n\\r\\nLetters in the Korean alphabet were named by Korean linguist Choe Sejin in 1527. South Korea uses Choe's traditional names, most of which follow the format of letter + i + eu + letter. However, as the syllables ? euk, ? eut, and ? eut did not occur in the language, Choe gave those letters the modified names ?? giyeok, ?? digeut, and ?? siot, using native syllables.\\r\\n\\r\\nOriginally, Choe gaveand ? the irregular one-syllable names of ji, chi, ki, ti, pi, and hi, because they should not be used as final consonants, as specified in Hunminjeongeum. However, after establishment of the new orthography in 1933, which let all consonants be used as finals, the names changed to the present forms.\\r\\n\\r\\nNorth Korea regularised Choe's original names when it made the Korean alphabet its official orthography.\\r\\n\\r\\nThe chart below shows names used in North Korea for consonants in the Korean alphabet. The letters are arranged in North Korean alphabetic order, and the letter names are romanised with the McCune-Reischauer system, which is widely used in North Korea. The tense consonants are described with the word ? toen meaning \\"hard\\".\\r\\n\\r\\nIn North Korea, an alternative way to refer to a consonant is letter + ? (?), for example, k? (?) for the letterand ss? (?) for the letter ?.\\r\\n\\r\\nAs in South Korea, the names of vowels in the Korean alphabet are the same as the sound of each vowel.\\r\\n\\r\\nThe chart below shows names used in South Korea for consonants of the Korean alphabet. The letters are arranged in the South Korean alphabetic order, and the letter names are romanised in the Revised Romanisation system, which is the official romanisation system of South Korea. The tense consonants are described with the word ? ssang meaning \\"double\\".\\r\\n\\r\\nThe names of vowels in the Korean alphabet are the same as the sound of each vowel. For example, ? is called ? a.\\r\\n\\r\\nLetters in the Korean alphabet have adopted certain rules of Chinese calligraphy, although ? and ? use a circle, which is not used in printed Chinese characters.\\r\\n\\r\\n? (giyeok ??)\\r\\n\\r\\n? (nieun ??)\\r\\n\\r\\n? (digeut ??)\\r\\n\\r\\n? (rieul ??)\\r\\n\\r\\n? (mieum ??)\\r\\n\\r\\n? (bieup ??)\\r\\n\\r\\n? (siot ??)\\r\\n\\r\\n? (ieung ??)\\r\\n\\r\\n? (jieut ??)\\r\\n\\r\\n? (chieut ??)\\r\\n\\r\\n? (kieuk ??)\\r\\n\\r\\n? (tieut ??)\\r\\n\\r\\n? (pieup ??)\\r\\n\\r\\n? (hieut ??)\\r\\n\\r\\n? (a)\\r\\n\\r\\n? (ae)\\r\\n\\r\\n? (eo)\\r\\n\\r\\n? (e)\\r\\n\\r\\n? (o)\\r\\n\\r\\n? (u)\\r\\n\\r\\n? (eu)\\r\\n\\r\\nFor the iotized vowels, which are not shown, the short stroke is simply doubled.\\r\\n\\r\\nScripts typically transcribe languages at the level of morphemes (logographic scripts like Hanja), of syllables (syllabaries like kana), of segments (alphabetic scripts like the Latin script used to write English and many other languages), or, on occasion, of distinctive features. The Korean alphabet incorporates aspects of the latter three, grouping sounds into syllables, using distinct symbols for segments, and in some cases using distinct strokes to indicate distinctive features such as place of articulation (labial, coronal, velar, or glottal) and manner of articulation (plosive, nasal, sibilant, aspiration) for consonants, and iotation (a preceding i-sound), harmonic class and i-mutation for vowels.\\r\\n\\r\\nFor instance, the consonant ? t [t?] is composed of three strokes, each one meaningful: the top stroke indicates ? is a plosive, like ? g, ? d, ? j, which have the same stroke (the last is an affricate, a plosiveÿfricative sequence); the middle stroke indicates that ? is aspirated, like ? h, ? k, ? ch, which also have this stroke; and the bottom stroke indicates that ? is alveolar, like ? n, ? d, and ? l. (This element is said to represent the shape of the tongue when pronouncing coronal consonants, though this is not certain.) Two consonants, ? andhave dual pronunciations, and appear to be composed of two elements corresponding to these two pronunciations: [?]~silence for ? and [m]~[w] for obsolete ?.\\r\\n\\r\\nWith vowel letters, a short stroke connected to the main line of the letter indicates that this is one of the vowels that can be iotated; this stroke is then doubled when the vowel is iotated. The position of the stroke indicates which harmonic class the vowel belongs to, \\"light\\" (top or right) or \\"dark\\" (bottom or left). In the modern alphabet, an additional vertical stroke indicates i-mutation, deriving ? [?], ? [e], ? [?], and ? [y] from ? [a], ? [?], ? [o], and ? [u]. However, this is not part of the intentional design of the script, but rather a natural development from what were originally diphthongs ending in the vowel ? [i]. Indeed, in many Korean dialects,[citation needed] including the standard dialect of Seoul, some of these may still be diphthongs.\\r\\n\\r\\nSome linguists have praised the Korean alphabet for its featural design; beyond the fact that the shapes of the letters are related to the features of the sounds they represent, the Korean alphabet also attracts approval for the fact that vowels are made from vertical or horizontal lines so that they are easily distinguishable from consonants.\\r\\n\\r\\nAlthough the design of the script may be featural, for all practical purposes it behaves as an alphabet. The letter ? is not read as three letters alveolar aspirated plosive, for instance, but as a single consonant t. Likewise, the former diphthong ? is read as a single vowel e.\\r\\n\\r\\nBeside the letters, the Korean alphabet originally employed diacritic marks to indicate pitch accent. A syllable with a high pitch (??) was marked with a dot (???) to the left of it (when writing vertically); a syllable with a rising pitch (??) was marked with a double dot, like a colon (???). These are no longer used. Although vowel length is still phonemic in some varieties of Korean, it is no longer written.\\r\\n\\r\\nThe consonant letters fall into five homorganic groups, each with a basic shape, and one or more letters derived from this shape by means of additional strokes. In the Hunmin Jeong-eum Haerye account, the basic shapes iconically represent the articulations the tongue, palate, teeth, and throat take when making these sounds.\\r\\n\\r\\nThe Korean names for the groups are taken from Chinese phonetics:\\r\\n\\r\\nVowel letters are based on three elements:\\r\\n\\r\\nShort strokes (dots in the earliest documents) were added to these three basic elements to derive the vowel letter:\\r\\n\\r\\nThe Korean alphabet never had a w, except in Sino-Korean vocabulary. Since an o or u before an a or eo became a [w] sound, and [w] occurred nowhere else, [w] could always be analyzed as a phonemic o or u, and no letter for [w] was needed. However, vowel harmony is observed: \\"dark\\" ??u with \\"dark\\" ??eo for ? wo; \\"bright\\" ??o with \\"bright\\" ??a for ? wa:\\r\\n\\r\\nThe compound vowels ending in ? i were originally diphthongs. However, several have since evolved into pure vowels:\\r\\n\\r\\nThere is no letter for y. Instead, this sound is indicated by doubling the stroke attached to the baseline of the vowel letter. Of the seven basic vowels, four could be preceded by a y sound, and these four were written as a dot next to a line. (Through the influence of Chinese calligraphy, the dots soon became connected to the line: ????.) A preceding y sound, called \\"iotation\\", was indicated by doubling this dot: ???? yeo, ya, yu, yo. The three vowels that could not be iotated were written with a single stroke: ??? eu, (arae a), i.\\r\\n\\r\\nThe simple iotated vowels are:\\r\\n\\r\\nThere are also two iotated diphthongs:\\r\\n\\r\\nThe Korean language of the 15th century had vowel harmony to a greater extent than it does today. Vowels in grammatical morphemes changed according to their environment, falling into groups that \\"harmonized\\" with each other. This affected the morphology of the language, and Korean phonology described it in terms of yin and yang: If a root word had yang ('bright') vowels, then most suffixes attached to it also had to have yang vowels; conversely, if the root had yin ('dark') vowels, the suffixes had to be yin as well. There was a third harmonic group called \\"mediating\\" ('neutral' in Western terminology) that could coexist with either yin or yang vowels.\\r\\n\\r\\nThe Korean neutral vowel was ? i. The yin vowels were ??? eu, u, eo; the dots are in the yin directions of 'down' and 'left'. The yang vowels were ???o, a, with the dots in the yang directions of 'up' and 'right'. The Hunmin Jeong-eum Haerye states that the shapes of the non-dotted letters ??? were chosen to represent the concepts of yin, yang, and mediation: Earth, Heaven, and Human. (The letter ? ? is now obsolete except in the Jeju language.)\\r\\n\\r\\nThe third parameter in designing the vowel letters was choosing ? as the graphic base of ? andand ? as the graphic base of ? and ?. A full understanding of what these horizontal and vertical groups had in common would require knowing the exact sound values these vowels had in the 15th century.\\r\\n\\r\\nThe uncertainty is primarily with the three letters ???. Some linguists reconstruct these as *a, *?, *e, respectively; others as *?, *e, *a. A third reconstruction is to make them all middle vowels as *?, *?, *a.[41] With the third reconstruction, Middle Korean vowels actually line up in a vowel harmony pattern, albeit with only one front vowel and four middle vowels:\\r\\n\\r\\nHowever, the horizontal letters ??? eu,?u,?o do all appear to have been mid to high back vowels, [*?, *u, *o], and thus to have formed a coherent group phonetically in every reconstruction.\\r\\n\\r\\nThe generally accepted account[nb 1][42] on the design of the letters is that the vowels are derived from various combinations of the following three components: ? ? ?. Here, ? symbolically stands for the (sun in) heaven, ? stands for the (flat) earth, and ? stands for an (upright) human. The original sequence of the Korean vowels, as stated in Hunminjeongeum, listed these three vowels first, followed by various combinations. Thus, the original order of the vowels was: ? ? ? ? ? ? ? ? ? ? ?. Note that two positive vowels (? ?) including one ? are followed by two negative vowels including onethen by two positive vowels each including two ofand then by two negative vowels each including two of ?.\\r\\n\\r\\nThe same theory provides the most simple explanation of the shapes of the consonants as an approximation of the shapes of the most representative organ needed to form that sound. The original order of the consonants in Hunmin Jeong-eum was: ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?.\\r\\n\\r\\n? representing the /k/ sound geometrically describes a tongue just before the moment of pronunciation as the tongue blocks the passage of air.\\r\\n\\r\\n? representing the /k?/ sound is derived from ? by adding another stroke.\\r\\n\\r\\n? representing the /?/ sound may have been derived from ? by addition of a stroke.\\r\\n\\r\\n? representing the /t/ sound is derived from ? by addition of a stroke.\\r\\n\\r\\n? representing the /t?/ sound is derived from ? by adding another stroke.\\r\\n\\r\\n? representing the /n/ sound geometrically describes a tongue making contact with an upper palate just before making the \\"n\\" sound.\\r\\n\\r\\n? representing the /p/ sound is derived from ? by adding strokes.\\r\\n\\r\\n? representing the /p?/ sound is a variant ofwhich is obtained by rotating 90 degrees and extending the horizontal strokes.\\r\\n\\r\\n? representing the /m/ sound geometrically describes a closed mouth before opening the lips.\\r\\n\\r\\n? representing the /t?/ sound is derived from the shape of ? by adding strokes.\\r\\n\\r\\n? representing the /t??/ sound is derived from ? by adding another stroke.\\r\\n\\r\\n? representing the /s/ sound geometrically describes a near contact between the tongue and the teeth.[citation needed]\\r\\n\\r\\n? representing the /?/ sound geometrically describes an open throat with a bar to indicate that there is an aspiration.\\r\\n\\r\\n? representing the /h/ sound is derived from ? with the extra stroke representing a stronger flow of the aspiration.\\r\\n\\r\\n? representing the absence of a consonant geometrically describes an open mouth, which necessarily accompanies the following vowel.\\r\\n\\r\\n? representing the /?/ and /l/ sounds geometrically describes a backward-bending tongue.\\r\\n\\r\\n? representing a weak /z/ sound is also derived from the shape of the teeth, but has a different origin than ?[clarification needed] and is not derived from ? by addition of a stroke.\\r\\n\\r\\nAlthough the Hunmin Jeong-eum Haerye explains the design of the consonantal letters in terms of articulatory phonetics, as a purely innovative creation, several theories suggest which external sources may have inspired or influenced King Sejong's creation. Professor Gari Ledyard of Columbia University studied possible connections between Hangul and the Mongol 'Phags-pa script of the Yuan dynasty. He believed that the role of 'Phags-pa script in the creation of the Korean alphabet was quite limited:\\r\\n\\r\\nIt should be clear to any reader that in the total picture, that ['Phags-pa script's] role was quite limited ... Nothing would disturb me more, after this study is published, than to discover in a work on the history of writing a statement like the following: \\"According to recent investigations, the Korean alphabet was derived from the Mongol's phags-pa script.\\"[43] An affine theory states that the consonants are derived from the shape of the speaker's lips and tongue during the pronunciation of the consonants (initially, at least), but this would appear somewhat to strain credulity.[44]\\r\\n\\r\\nLedyard posits that five of the Korean letters have shapes inspired by 'Phags-pa; a sixth basic letter, the null initialwas invented by Sejong. The rest of the letters were derived internally from these six, essentially as described in the Hunmin Jeong-eum Haerye. However, the five borrowed consonants were not the graphically simplest letters considered basic by the Hunmin Jeong-eum Haerye, but instead the consonants basic to Chinese phonology:and ?.\\r\\n\\r\\nThe Hunmin Jeong-eum states that King Sejong adapted the m (gojeon, \\"GѸ Seal Script\\") in creating the Korean alphabet. The m has never been identified. The primary meaning of  gѸ is \\"old\\" (\\"Old Seal Script\\"), frustrating philologists because the Korean alphabet bears no functional similarity to Chinese m zhunz seal scripts. However, Ledyard believes  gѸ may be a pun on з MnggѸ \\"Mongol\\", and that m is an abbreviation of зm \\"Mongol Seal Script\\", that is, the formal variant of the 'Phags-pa alphabet written to look like the Chinese seal script. There were 'Phags-pa manuscripts in the Korean palace library, including some in the seal-script form, and several of Sejong's ministers knew the script well.\\r\\n\\r\\nIf this was the case, Sejong's evasion on the Mongol connection can be understood in light of Korea's relationship with Ming China after the fall of the Mongol Yuan dynasty, and of the literati's contempt for the Mongols as \\"barbarians\\".\\r\\n\\r\\nAccording to Ledyard, the five borrowed letters were graphically simplified, which allowed for consonant clusters and left room to add a stroke to derive the aspirate plosives, ????. But in contrast to the traditional account, the non-plosives (? ? ? ?) were derived by removing the top of the basic letters. He points out that while it is easy to derive ? from ? by removing the top, it is not clear how to derive ? from ? in the traditional account, since the shape of ? is not analogous to those of the other plosives.\\r\\n\\r\\nThe explanation of the letter ng also differs from the traditional account. Many Chinese words began with ng, but by King Sejong's day, initial ng was either silent or pronounced [?] in China, and was silent when these words were borrowed into Korean. Also, the expected shape of ng (the short vertical line left by removing the top stroke of ?) would have looked almost identical to the vowel ? [i]. Sejong's solution solved both problems: The vertical stroke left from ? was added to the null symbol ? to create ? (a circle with a vertical line on top), iconically capturing both the pronunciation [?] in the middle or end of a word, and the usual silence at the beginning. (The graphic distinction between null ? and ng ? was eventually lost.)\\r\\n\\r\\nAnother letter composed of two elements to represent two regional pronunciations waswhich transcribed the Chinese initial a. This represented either m or w in various Chinese dialects, and was composed of ? [m] plus ? (from 'Phags-pa [w]). In 'Phags-pa, a loop under a letter represented w after vowels, and Ledyard hypothesized that this became the loop at the bottom of ?. In 'Phags-pa the Chinese initial a is also transcribed as a compound with w, but in its case the w is placed under an h. Actually, the Chinese consonant series a w, v, f is transcribed in 'Phags-pa by the addition of a w under three graphic variants of the letter for h, and the Korean alphabet parallels this convention by adding the w loop to the labial series ??? m, b, p, producing now-obsolete ??? w, v, f. (Phonetic values in Korean are uncertain, as these consonants were only used to transcribe Chinese.)\\r\\n\\r\\nAs a final piece of evidence, Ledyard notes that most of the borrowed Korean letters were simple geometric shapes, at least originally, but that ? d [t] always had a small lip protruding from the upper left corner, just as the 'Phags-pa d [t] did. This lip can be traced back to the Tibetan letter d.\\r\\n\\r\\nNumerous obsolete Korean letters and sequences are no longer used in Korean. Some of these letters were only ever used to represent the sounds of Chinese rime tables. Some of the Korean sounds represented by these obsolete letters still exist in some dialects.\\r\\n\\r\\nIn the original Korean alphabet system, double letters were used to represent Chinese voiced (??) consonants, which survive in the Shanghainese slack consonants and were not used for Korean words. It was only later that a similar convention was used to represent the modern \\"tense\\" (faucalized) consonants of Korean.\\r\\n\\r\\nThe sibilant (\\"dental\\") consonants were modified to represent the two series of Chinese sibilants, alveolar and retroflex, a \\"round\\" vs. \\"sharp\\" distinction (analogous to s vs sh) which was never made in Korean, and was even being lost from southern Chinese. The alveolar letters had longer left stems, while retroflexes had longer right stems:\\r\\n\\r\\nTo make the Korean alphabet a perfect morphophonological fit to the Korean language, North Korea introduced six new letters, which were published in the New Orthography for the Korean Language and used officially from 1948 to 1954.\\r\\n\\r\\nTwo obsolete letters were restored: ??? (??), which was used to indicate an alternation in pronunciation between initial /l/ and final /d/; and ??? (??), which was only pronounced between vowels. Two modifications of the letter ? were introduced, one for awhich is silent finally, and one for awhich doubled between vowels. A hybrid ?-? letter was introduced for words that alternated between those two sounds (that is, a /b/, which became /w/ before a vowel). Finally, a vowel ?1? was introduced for variable iotation.\\r\\n\\r\\nHangul Jamo (U+1100ÿU+11FF) and Hangul Compatibility Jamo (U+3130ÿU+318F) blocks were added to the Unicode Standard in June 1993 with the release of version 1.1. The characters were relocated to their present locations in July, 1996 with the release of version 2.0.\\r\\n\\r\\nHangul Jamo Extended-A (U+A960ÿU+A97F) and Hangul Jamo Extended-B (U+D7B0ÿU+D7FF) blocks were added to the Unicode Standard in October 2009 with the release of version 5.2.\\r\\n\\r\\nParenthesised (U+3200ÿU+321E) and circled (U+3260ÿU+327E) Hangul compatibility characters are in the Enclosed CJK Letters and Months block:\\r\\n\\r\\nHalf-width Hangul compatibility characters (U+FFA0ÿU+FFDC) are in the Halfwidth and Fullwidth Forms block:\\r\\n\\r\\nThe Korean alphabet in other Unicode blocks:\\r\\n\\r\\nExcept for a few grammatical morphemes prior to the twentieth century, no letter stands alone to represent elements of the Korean language. Instead, letters are grouped into syllabic or morphemic blocks of at least two and often three: a consonant or a doubled consonant called the initial (??, ? choseong syllable onset), a vowel or diphthong called the medial (??, ? jungseong syllable nucleus), and, optionally, a consonant or consonant cluster at the end of the syllable, called the final (??, ? jongseong syllable coda). When a syllable has no actual initial consonant, the null initial ? ieung is used as a placeholder. (In the modern Korean alphabet, placeholders are not used for the final position.) Thus, a block contains a minimum of two letters, an initial and a medial. Although the Korean alphabet had historically been organised into syllables, in the modern orthography it is first organised into morphemes, and only secondarily into syllables within those morphemes, with the exception that single-consonant morphemes may not be written alone.\\r\\n\\r\\nThe sets of initial and final consonants are not the same. For instance, ? ng only occurs in final position, while the doubled letters that can occur in final position are limited to ? ss and ? kk.\\r\\n\\r\\nNot including obsolete letters, 11,172 blocks are possible in the Korean alphabet.\\r\\n\\r\\nEgyptian hieroglyphs 32 c. BCE\\r\\n\\r\\nHangul 1443 (probably influenced by Tibetan)\\r\\n\\r\\nThe placement or \\"stacking\\" of letters in the block follows set patterns based on the shape of the medial.\\r\\n\\r\\nConsonant and vowel sequences such as ? bs, ? wo, or obsolete ? bsd, ? ye are written left to right.\\r\\n\\r\\nVowels (medials) are written under the initial consonant, to the right, or wrap around the initial from bottom to right, depending on their shape: If the vowel has a horizontal axis like ? eu, then it is written under the initial; if it has a vertical axis like ? i, then it is written to the right of the initial; and if it combines both orientations, like ? ui, then it wraps around the initial from the bottom to the right:\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nA final consonant, if present, is always written at the bottom, under the vowel. This is called ?? batchim \\"supporting floor\\":\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nA complex final is written left to right:\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nBlocks are always written in phonetic order, initial-medial-final. Therefore:\\r\\n\\r\\nNormally the resulting block is written within a square of the same size and shape as a Hanja (Chinese character) by compressing or stretching the letters to fill the bounds of the block; therefore someone not familiar with the scripts may mistake the Korean alphabet for Hanja or Chinese.\\r\\n\\r\\nHowever, some recent fonts (for example Eun,[48] HY????M, UnJamo]) move towards the European practice of letters whose relative size is fixed, and use whitespace to fill letter positions not used in a particular block, and away from the East Asian tradition of square block characters (Դݔ). They break one or more of the traditional rules:\\r\\n\\r\\nThese fonts have been used as design accents on signs or headings, rather than for typesetting large volumes of body text.\\r\\n\\r\\nThere was a minor and unsuccessful movement in the early twentieth century to abolish syllabic blocks and write the letters individually and in a row, in the fashion of the European alphabets: e.g. ?????? for ?? Hangeul.[49]\\r\\n\\r\\nAvant-garde typographer Ahn Sangsu made a font for the \\"Hangul Dada\\" exposition that exploded the syllable blocks; but while it strings out the letters horizontally, it retains the distinctive vertical position each letter would normally have within a block, unlike the century-old linear writing proposals.[50]\\r\\n\\r\\nWhile Koreans have largely accepted the European-derived conventions of writing successive syllables left-to-right in horizontal lines instead of in vertical columns, adding spaces between words, and European-style punctuation, they rejected eliminating syllabic blocks, the most distinctive feature of this writing system.\\r\\n\\r\\nUntil the 20th century, no official orthography of the Korean alphabet had been established. Due to liaison, heavy consonant assimilation, dialectical variants and other reasons, a Korean word can potentially be spelled in multiple ways. Sejong seemed to prefer morphophonemic spelling (representing the underlying root forms) rather than a phonemic one (representing the actual sounds). However, early in its history the Korean alphabet was dominated by phonemic spelling. Over the centuries the orthography became partially morphophonemic, first in nouns and later in verbs. The modern Korean alphabet is as morphophonemic as is practical. The difference between phonetic Romanisation, phonemic orthography and morpho-phonemic orthography can be illustrated with the phrase motaneun sarami:\\r\\n\\r\\nmotaneun sarami\\r\\n[mo.t?a.n?n.sa.?a.mi]\\r\\na person who cannot do it\\r\\n\\r\\n??????\\r\\n/mo.t?a.n?n.sa.la.mi/\\r\\n\\r\\n??????\\r\\n|mot-ha-n?n-sa.lam-i|\\r\\n\\r\\nAfter the Gabo Reform in 1894, the Joseon Dynasty and later the Korean Empire started to write all official documents in the Korean alphabet. Under the government's management, proper usage of the Korean alphabet and Hanja, including orthography, was discussed, until the Korean Empire was annexed by Japan in 1910.\\r\\n\\r\\nThe Government-General of Korea popularised a writing style that mixed Hanja and the Korean alphabet, and was used in the later Joseon dynasty. The government revised the spelling rules in 1912, 1921 and 1930, to be relatively phonemic.\\r\\n\\r\\nThe Hangul Society, founded by Ju Si-gyeong, announced a proposal for a new, strongly morphophonemic orthography in 1933, which became the prototype of the contemporary orthographies in both North and South Korea. After Korea was divided, the North and South revised orthographies separately. The guiding text for orthography of the Korean alphabet is called Hangeul Matchumbeop, whose last South Korean revision was published in 1988 by the Ministry of Education.\\r\\n\\r\\nSince the Late Joseon dynasty period, various Hanja-Hangul mixed systems were used. In these systems, Hanja were used for lexical roots, and the Korean alphabet for grammatical words and inflections, much as kanji and kana are used in Japanese. Hanja have been almost entirely phased out of daily use in North Korea, and in South Korea they are mostly restricted to parenthetical glosses for proper names and for disambiguating homonyms.\\r\\n\\r\\nIndo-Arabic numerals are mixed in with the Korean alphabet, as in 2007? 3? 22? (22 March 2007). In Korean pop-culture Roman words may be injected for artistic purposes.\\r\\n\\r\\nLatin script and occasionally other scripts may be sprinkled within Korean texts for illustrative purposes, or for unassimilated loanwords. Very occasionally non-Hangul letters may be mixed into Korean syllabic blocks, as G? Ga at right.\\r\\n\\r\\nBecause of syllable clustering, words are shorter on the page than their linear counterparts would be, and the boundaries between syllables are easily visible (which may aid reading, if segmenting words into syllables is more natural for the reader than dividing them into phonemes).[51] Because the component parts of the syllable are relatively simple phonemic characters, the number of strokes per character on average is lower than in Chinese characters. Unlike syllabaries, such as Japanese kana, or Chinese logographs, none of which encode the constituent phonemes within a syllable, the graphic complexity of Korean syllabic blocks varies in direct proportion with the phonemic complexity of the syllable.[52] Unlike linear alphabets such as those derived from Latin, Korean orthography allows the reader to \\"utilize both the horizontal and vertical visual fields\\".[53] Finally, since Korean syllables are represented both as collections of phonemes and as unique-looking graphs, they may allow for both visual and aural retrieval of words from the lexicon.\\r\\n\\r\\nThe Korean alphabet may be written either vertically or horizontally. The traditional direction is from top to bottom, right to left. Horizontal writing in the style of the Latin script was promoted by Ju Si-gyeong, and has become overwhelmingly prevalent.\\r\\n\\r\\nIn Hunmin Jeongeum, the Korean alphabet was printed in sans-serif angular lines of even thickness. This style is found in books published before about 1900, and can be found in stone carvings (on statues, for example).\\r\\n\\r\\nOver the centuries, an ink-brush style of calligraphy developed, employing the same style of lines and angles as traditional Korean calligraphy. This brush style is called gungche (?? ?mN), which means \\"Palace Style\\" because the style was mostly developed and used by the maidservants (gungnyeo, ?? ?mW) of the court in Joseon dynasty.\\r\\n\\r\\nModern styles that are more suited for printed media were developed in the 20th century. In 1993, new names for both Myeongjo (]) and Gothic styles were introduced when Ministry of Culture initiated an effort to standardize typographic terms, and the names Batang (??, meaning \\"background\\") and Dodum (??, meaning \\"stand out\\") replaced Myeongjo and Gothic respectively. These names are also used in Microsoft Windows.\\r\\n\\r\\nA sans-serif style with lines of equal width is popular with pencil and pen writing and is often the default typeface of Web browsers. A minor advantage of this style is that it makes it easier to distinguish -eung from -ung even in small or untidy print, as the jongseong ieung (?) of such fonts usually lacks a serif that could be mistaken for the short vertical line of the letter ? (u).","input":"What is the name of the korean alphabet?"},{"output":"23 and 24 June 2010","context":"Marina Bay Sands is an integrated resort fronting Marina Bay in Singapore. At its opening in 2010, it was billed as the world's most expensive standalone casino property at S$8 billion, including the land cost.[2][3]\\r\\nThe resort includes a 2,561-room hotel, a 120,000-square-metre (1,300,000?sq?ft) convention-exhibition centre, the 74,000-square-metre (800,000?sq?ft) The Shoppes at Marina Bay Sands mall, a museum, two large theatres, \\"celebrity chef\\" restaurants, two floating Crystal Pavilions, art-science exhibits, and the world's largest atrium casino with 500 tables and 1,600 slot machines.\\r\\nThe complex is topped by a 340-metre-long (1,120?ft) SkyPark with a capacity of 3,900 people and a 150?m (490?ft) infinity swimming pool, set on top of the world's largest public cantilevered platform, which overhangs the north tower by 67?m (220?ft).[4][5] The 20-hectare resort was designed by Moshe Safdie architects.[6][7][8] The architect was Aedas,[9] and they were responsible for employing all consultants and for developing, co-ordinating and implementing the design. Engineering was provided by Arup and Parsons Brinkerhoff (MEP). The main contractor was Ssangyong Engineering and Construction.[10][11]\\r\\nOriginally set to open in 2009, Las Vegas Sands faced delays caused by escalating costs of material and labour shortages from the outset. The global financial crisis also pressured the company to delay its projects elsewhere to complete the integrated resort.[12] Although Marina Bay Sands has been compared in scale and development costs to MGM's CityCenter, the latter is a mixed-use development, with condominium properties (comprising three of the seven main structures) being sold off.[13][14]\\r\\nThe resort and SkyPark were officially opened on 23 and 24 June 2010 as part of a two-day celebration, following the casino's opening on 27 April that year.[15] The SkyPark opened the following day. The theatres were completed in time for the first performance of Riverdance on 30 November. The indoor skating rink, which uses artificial ice, opened to a performance by Michelle Kwan on 18 December. The ArtScience Museum opened to the public and the debut of a 13-minute light, laser and water show called Wonder Full on 19 February 2011 marked the full completion of the integrated resort.\\r\\nThe grand opening of Marina Bay Sands was held on 17 February 2011. It also marked the opening of the seven celebrity chef restaurants. The musical The Lion King debuted on 3 March 2011.[16] The last portion of the Marina Bay Sands, the floating pavilions, were finally opened to the public when the two tenants, Louis Vuitton and Pangaea Club, opened on 18 and 22 September 2011, respectively.[17]\\r\\n\\r\\n\\r\\nMarina Bay Sands is one of two winning proposals for Singapore's first integrated resorts, the other being the Resorts World Sentosa, which incorporates a family-friendly Universal Studios Theme Park (Universal Studios Singapore). The two large-scale resorts were conceived to meet Singapore's economic and tourism objectives for the next decade and will have 30-year casino licenses, exclusive for the first ten years. Bidders were assessed based on four criteria: tourism appeal and contribution, architectural concept and design, development investment, and strength of the consortium and partners\\r\\nOn 27 May 2006, Las Vegas Sands (LVS) was declared the winner with its business-oriented resort.[18] LVS submitted its winning bid on its own. Its original partner City Developments Limited (CDL), with a proposed 15% equity stake, pulled out of the partnership in the second phase of the tender process. CDL's CEO, Kwek Leng Beng said his company's pullout was a combination of factorssuch as difficulties in getting numerous companies he owns to comply in time, as well as reluctance of some parties to disclose certain private information in probity checks required by the Singapore government.[19] However, Kwek was retained as an advisor for Sands' bid.\\r\\nLas Vegas Sands initially committed to invest S$3.85 billion in the project, not including the fixed S$1.2 billion cost of the 6,000,000 square feet (560,000?m2) site itself.[20] With the escalating costs of materials, such as sand and steel, and labour shortages owing to other major infrastructure and property development in the country, Sheldon Adelson placed the total cost of the development at S$8.0 billion as of July 2009.[2][21]\\r\\nLas Vegas Sands declared the undertaking as \\"one of the world's most challenging construction projects and certainly the most expensive stand-alone integrated resort property ever built\\".[22] It expects the casino to generate at least $1 billion in annual profit.[13] Two months after the initial phased opening, the casino attracts around 25,000 visitors daily, about a third being Singaporeans and permanent residents who pay a $100 daily entry levy or $2,000 for annual unlimited access.[23] Half a million gamblers passed through the casino in June 2010.[24] In the third quarter of 2012, the revenues of the Marina Bay Sands fell almost 28 per cent from a year earlier.[25]\\r\\nFor the economy, Marina Bay Sands is projected to stimulate an addition of $2.7 billion or 0.8% to Singapore's Gross Domestic Product by 2015, employing 10,000 people directly and 20,000 jobs being created in other industries.[19]\\r\\nThe resort is designed by Moshe Safdie,[6][7][8] who says it was initially inspired by card decks. In addition to the casino, other key components of the plan are three hotel towers with 2,500 rooms and suites, a 19,000?m2 (200,000?sq?ft) ArtScience Museum and a convention centre with 110,000?m2 (1,200,000?sq?ft) of space, capable of accommodating up to 45,000 people. A continuous lobby at the base linked the three towers. The resort's architecture and major design changes along the way were also approved by its feng shui consultants, the late Chong Swan Lek and Louisa Ong-Lee.[26][27]\\r\\nA distinctive feature of the hotel is the SkyPark, a three-acre park on top of the building with swimming pools, gardens, and jogging paths. The structure bridges all three towers with a segment cantilevered off the north tower. The hull of the SkyPark was pre-fabricated off-site in 14 separate steel sections and then assembled on top of the towers.[28] There are four movement joints beneath the main pools, designed to help them withstand the natural motion of the towers, and each joint has a unique range of motion. The total range of motion is 500 millimetres (20 inches). In addition to wind, the hotel towers are also subject to settlement in the earth over time, so engineers built and installed custom jack legs to allow for future adjustment at more than 500 points beneath the pool system. This jacking system is important primarily to ensure the infinity edge of the pool continues to function properly.[29]\\r\\nThe three towers are broader at the base and narrow as they rise. Each tower has two asymmetric legs, with a curved eastern leg leaning against the other, creating a significant technical challenge in its construction. Substantial temporary structures were necessary to support the legs of the tower while they were under construction, and required real-time monitoring for continual assessment and analyses in the course of their erection. The structural engineering for the project was handled by Arup, with Parsons Brinckerhoff the MEP engineers. This building was built by South Korean construction company \\"SsangYong\\".[30]\\r\\nMarina Bay Sands was originally planned to be completed in a single phase in 2009,[21] but rising construction costs and the financial crisis forced the company to open it in phases. The first phase's preview opening was further delayed until 27 April 2010, and the official opening was pushed back to 23 June 2010. The rest of the complex remained under construction and was opened after a grand opening on 17 February 2011.\\r\\nOn 27 April 2010, Marina Bay Sands had the first of a planned 3 to 4 phase openings. The casino, parts of the conference hall, a segment of the Shoppes, 963 hotel rooms and the event plaza were opened at the auspicious time of 3:18 p.m as part of the \\"preview opening\\".[31]\\r\\nThe Inter-Pacific Bar Association (IPBA) held the first conference at Marina Bay Sands Convention Centre on 2ÿ5 May 2010, but the event was marred by uncompleted facilities and power failure during a speech. IPBA withheld payment of S$300,000 and was consequently sued by Marina Bay Sands.[32] In June IPBA counter-sued, describing the venue as a \\"complete disaster\\" and that its earlier payments had been imposed by \\"duress, fear and force\\".[32] An \\"amicable settlement\\" with undisclosed terms was announced in August.\\r\\nOn 23 June 2010, the resort had its official opening with a \\"2-day celebration\\"; this includes the Sands SkyPark, the Event Plaza along Marina Bay, more shops, additional dining options and nightlife offerings, and the rest of the hotel rooms. First day events includeda \\"World Championship Climb\\" on the glass facade of the building to the SkyPark, with seven teams of 21 top rock climbers from around the world competing, and an evening concert for 4,000 invited guests and customers, featuring Jacintha Abisheganaden, Sylvia Ratonel, Tabitha Nauser and Toni Braxton among others. The SkyPark was opened on the second day at 2?p.m.,[22] with about 2,000 adult tickets costing S$20 each sold.[33]\\r\\nThe two Sands theatres were completed in time for the first performance by Riverdance on 30 November 2010. The ArtScience Museum opened its doors to the public at 10?am on 19 February 2011. The highly anticipated musical The Lion King made its debut on 3 March 2011. The floating pavilions were opened when the tenants Louis Vuitton and Pangaea Club finished their refurbishment and opened on 18 September 2011 and 22 September 2011, respectively. The Lion King musical ran till its last show on 30 October 2011.[34]\\r\\nMarina Bay Sands has three 55-storey hotel towers which were topped out in July 2009. The three towers are connected by a 1 hectare roof terrace, Sands SkyPark.[35] The observation deck provides panoramic views across the bay.[36]\\r\\nIn front of the three towers include a Theatre Block, a Convention and Exhibition Facilities Block, as well as the Casino Block, which have up to 1,000 gaming tables and 1,400 slot machines. The ArtScience Museum is constructed next to the three blocks and has the shape of a lotus. Its roof is retractable, providing a waterfall through the roof of collected rainwater when closed in the day and laser shows when opened at night. In front of the Event Plaza is Wonder Full, a light and water show that is the largest in Southeast Asia and was produced by Laservision.[37] The ArtScience Museum and Wonder Full show opened on 17 February 2011.\\r\\nThe SkyPark has the world's longest elevated swimming pool,[38][29] with a 146-metre (479?ft) vanishing edge (a concept called as infinity pool) located 191 metres (627?ft) above ground. The pools are made up of 422,000 pounds (191,000?kg) of stainless steel and can hold 376,500 US gallons (1,425 cubic metres) of water. The SkyPark also has rooftop nightclubs such as Lavo (New York, Vegas) and Ce La Vie,[39] gardens, hundreds of trees and plants, and a public observatory deck on the cantilever with 360-degree views of the Singapore skyline. The SkyPark is accessible only to the hotel guests for security reasons.\\r\\nThe Shoppes at Marina Bay Sands have close to 93,000?m2 (1,000,000?sq?ft) of retail space with over 300 stores and F&B outlets, featuring boutiques such as Ralph Lauren, Chanel, Cartier, Prada, Gucci, Herms, Emporio Armani, Chopard, REDValentino, Dior, Dunhill, Vertu, Miu Miu, Saint Laurent Paris, Salvatore Ferragamo, Montblanc, Blancpain, Vera Wang Bride, a Herms watch boutique, and Herve Leger.\\r\\nA canal runs through the length of the Shoppes, in the same style as The Venetian in Las Vegas. Sampan rides on the canal are available for guests and shoppers at the shopping mall, similar to the gondola rides available in the Venetian. Also housed within the Shoppes are six of the ten Celebrity Chef restaurantsBread Street Kitchen (by Gordon Ramsay), Cut (by Wolfgang Puck), Waku Ghin (by Tetsuya Wakuda), Pizzeria and Osteria Mozza (by Mario Batali), Long Chim (by David Thompson) and DB Bistro & Oyster Bar (by Daniel Boulud).\\r\\nThere are two Crystal Pavilions. Despite a brief legal dispute in June 2011, it was decided that one of the Pavilions will house two nightclubsAvalon and Pangaea. In addition, the second Pavilion houses the world's largest Louis Vuitton boutique, in addition to being on a floating island, at 1,900?m2 (20,000?sq?ft), which is connected to the portion of the boutique in the Shoppes via an underwater tunnel. Both Pavilions opened in 2011 just before the 2011 Formula One season came to the Marina Bay Street Circuit.\\r\\nThe Sands Theatre and Grand Theatre seat 1,680 people and 2,155 people, respectively, with The Lion King showing, and international acts, such as Cirque loize and A. R. Rahman's Jai Ho, located in the latter during their world tours. The musical, Wicked, is set to run for a limited season which started 7 December 2011. Next to the theatres is a skating rink (synthetic ice) measuring 600?m2 (6,500?sq?ft).\\r\\nDragonfire boxing is another regular event, which started on 5 May 2012 with the boxers Chris John with Daud Yordan.\\r\\nMoshe Safdie designed an Art Path within the resort, incorporating installations by five artists including Zheng Chongbin, Antony Gormley and Sol LeWitt. The pieces are meant to play on environmental influences including light, water and wind, integrating art with architecture.[6][7][8][40]\\r\\nBy Mass Rapid Transit (MRT):\\r\\nBy public bus:\\r\\nBy water taxi:\\r\\nThe trailer of the 2016 movie Independence Day: Resurgence has a scene depicting the destruction of the property after being caught in the gravitational pull of a hovering alien spacecraft.[41]\\r\\nConstruction area taken from The Float at Marina Bay on 18 August 2007\\r\\nPart of the parcel of land for Marina Bay Sands in the foreground prior to development. The parcel overlooks Singapore's financial district in the background.\\r\\nMarina Bay Sands with Singapore Merlion\\r\\nView of Marina Bay Sands in the background with Custom House located at the foreground\\r\\nAerial of the roof top pool Marina Bay Sands\\r\\nAerial of Marina Bay Sands Hotel, Singapore\\r\\nVenetian gondolas in Mandalay Bay shopping mall\\r\\nRooftop Pool Marina bay, Singapore\\r\\nCoordinates: 11657.54N 1035130.30E? / ?1.2826500N 103.8584167E? / 1.2826500; 103.8584167","input":"When was the marina bay sands hotel built?"},{"output":"a flame, or a heated tube","context":"An ignition system generates a spark or heats an electrode to a high temperature to ignite a fuel-air mixture in spark ignition internal combustion engines oil-fired and gas-fired boilers, rocket engines, etc. The widest application for spark ignition internal combustion engines is in petrol (gasoline) road vehicles: cars (autos), four-by-fours (SUVs), motorcycles, pickups, vans, trucks, and buses.\\r\\nCompression ignition Diesel engines ignite the fuel-air mixture by the heat of compression and do not need a spark. They usually have glowplugs that preheat the combustion chamber to allow starting in cold weather. Other engines may use a flame, or a heated tube, for ignition. While this was common for very early engines it is now rare.\\r\\nThe first electric spark ignition was probably Alessandro Volta's toy electric pistol from the 1780s.\\r\\n\\r\\n\\r\\nThe simplest form of spark ignition is that using a magneto. The engine spins a magnet inside a coil, or, in the earlier designs, a coil inside a fixed magnet, and also operates a contact breaker, interrupting the current and causing the voltage to be increased sufficiently to jump a small gap. The spark plugs are connected directly from the magneto output. Early magnetos had one coil, with the contact breaker (sparking plug) inside the combustion chamber. In about 1902, Bosch introduced a double-coil magneto, with a fixed sparking plug, and the contact breaker outside the cylinder. Magnetos are not used in modern cars, but because they generate their own electricity they are often found on small engines such as those found in mopeds, lawnmowers, snowblowers, chainsaws, etc. where a battery-based electrical system is not present for any combination of necessity, weight, cost, and reliability reasons. They are also used on piston-engined aircraft engines. Although an electrical supply is available, magneto systems are used mainly because of their higher reliability.\\r\\nMagnetos were used on the small engine's ancestor, the stationary \\"hit and miss\\" engine which was used in the early twentieth century, on older gasoline or distillate farm tractors before battery starting and lighting became common, and on aircraft piston engines. Magnetos were used in these engines because their simplicity and self-contained operation was more reliable, and because magnetos weighed less than having a battery and dynamo or alternator.\\r\\nAircraft engines usually have dual magnetos to provide redundancy in the event of a failure, and to increase efficiency by thoroughly and quickly burning the fuel air mix from both sides towards the center. The Wright brothers used a magneto invented in 1902 and built for them in 1903 by Dayton, Ohio inventor, Vincent Groby Apple.[1] Some older automobiles had both a magneto system and a battery actuated system (see below) running simultaneously to ensure proper ignition under all conditions with the limited performance each system provided at the time. This gave the benefits of easy starting (from the battery system) with reliable sparking at speed (from the magneto).\\r\\nMany modern magneto systems (except for small engines) have removed the second (high voltage) coil from the magneto itself and placed it in an external coil assembly similar to the ignition coil described below. In this development, the induced current in the coil in the magneto also flows through the primary of the external coil, generating a high voltage in the secondary as a result. Such a system is referred to as an 'energy transfer system'. Energy transfer systems provide the ultimate in ignition reliability.\\r\\nThe output of a magneto depends on the speed of the engine, and therefore starting can be problematic. Some magnetos include an impulse system, which spins the magnet quickly at the proper moment, making easier starting at slow cranking speeds. Some engines, such as aircraft but also the Ford Model T, used a system which relied on non rechargeable dry cells, (similar to a large flashlight battery, and which was not maintained by a charging system as on modern automobiles) to start the engine or for starting and running at low speed. The operator would manually switch the ignition over to magneto operation for high speed operation.\\r\\nTo provide high voltage for the spark from the low voltage batteries, a 'tickler' was used, which was essentially a larger version of the once widespread electric buzzer. With this apparatus, the direct current passes through an electromagnetic coil which pulls open a pair of contact points, interrupting the current; the magnetic field collapses, the spring-loaded points close again, the circuit is reestablished, and the cycle repeats rapidly. The rapidly collapsing magnetic field, however, induces a high voltage across the coil which can only relieve itself by arcing across the contact points; while in the case of the buzzer this is a problem as it causes the points to oxidize and/or weld together, in the case of the ignition system this becomes the source of the high voltage to operate the spark plugs.\\r\\nIn this mode of operation, the coil would \\"buzz\\" continuously, producing a constant train of sparks. The entire apparatus was known as the 'Model T spark coil' (in contrast to the modern ignition coil which is only the actual coil component of the system). Long after the demise of the Model T as transportation they remained a popular self-contained source of high voltage for electrical home experimenters, appearing in articles in magazines such as Popular Mechanics and projects for school science fairs as late as the early 1960s. In the UK these devices were commonly known as trembler coils and were popular in cars pre-1910, and also in commercial vehicles with large engines until around 1925 to ease starting.\\r\\nThe Model T (built into the flywheel) differed from modern implementations by not providing high voltage directly at the output; the maximum voltage produced was about 30 volts, and therefore also had to be run through the spark coil to provide high enough voltage for ignition, as described above, although the coil would not \\"buzz\\" continuously in this case, only going through one cycle per spark. In either case, the low voltage was switched to the appropriate spark plug by the 'timer' mounted on the front of the engine. This performed the equivalent function to the modern distributor, although by directing the low voltage, not the high voltage as for the distributor. The timing of the spark was adjustable by rotating this mechanism through a lever mounted on the steering column. As the precise timing of the spark depends on both the 'timer' and the trembler contacts within the coil, this is less consistent than the breaker points of the later distributor. However, for the low speed and the low compression of such early engines, this imprecise timing was acceptable.\\r\\nWith the universal adoption of electrical starting for automobiles, and the availability of a large battery to provide a constant source of electricity, magneto systems were abandoned for systems which interrupted current at battery voltage, using an ignition coil to step the voltage up to the needs of the ignition, and a distributor to route the ensuing pulse to the correct spark plug at the correct time.\\r\\nThe Benz Patent-Motorwagon and the Ford Model T used a trembler coil ignition system. A trembler coil was a battery-powered induction coil; the trembler interrupted the current through the coil and caused a quick series of sparks during each firing. The trembler coil would be energized at an appropriate point in the engine cycle. In the Model T, the four-cylinder engine had a trembler coil for each cylinder; a commutator (timer case) delivered power to the trembler coils. The Model T would be started on battery but then switched to an alternator.[2]\\r\\nAn improved ignition system was developed by the Dayton Engineering Laboratories Co. (Delco) and introduced in the 1910 Cadillac. This ignition was developed by Charles Kettering and was a wonder in its day. It consisted of a single ignition coil, points (the switch), a capacitor (to prevent the points from arcing at break) and a distributor (to direct the spark from the ignition coil to the correct cylinder).\\r\\nThe points allow the coil magnetic field to build. When the points open by a cam arrangement, the magnetic field collapses inducing an EMF in the primary that is much larger than the battery voltage and the transformer action produces a large output voltage (20 kV or greater) from the secondary.\\r\\nThe capacitor suppresses arcing at the points when they open; without the capacitor, the energy stored in the coil would be expended at an arc across the points rather than at the spark plug gap. The Kettering system became the primary ignition system for many years in the automotive industry due to its lower cost, and relative simplicity.\\r\\nThe ignition system is typically controlled by a key operated Ignition switch.\\r\\nMost four-stroke engines have used a mechanically timed electrical ignition system. The heart of the system is the distributor. The distributor contains a rotating cam driven by the engine's drive, a set of breaker points, a condenser, a rotor and a distributor cap. External to the distributor is the ignition coil, the spark plugs and wires linking the distributor to the spark plugs and ignition coil. (see diagram Below)\\r\\nThe system is powered by a lead-acid battery, which is charged by the car's electrical system using a dynamo or alternator. The engine operates contact breaker points, which interrupt the current to an induction coil (known as the ignition coil).\\r\\nThe ignition coil consists of two transformer windings  the primary and secondary. These windings share a common magnetic core. An alternating current in the primary induces an alternating magnetic field in the core and hence an alternating current in the secondary. The ignition coil's secondary has more turns than the primary. This is a step-up transformer, which produces a high voltage from the secondary winding. The primary winding is connected to the battery (usually through a current-limiting ballast resistor). Inside the ignition coil one end of each winding is connected together. This common point is taken to the capacitor/contact breaker junction. The other, high voltage, end of the secondary is connected to the distributor's rotor.\\r\\nThe ignition firing sequence begins with the points (or contact breaker) closed. A steady current flows from the battery, through the current-limiting resistor, through the primary coil, through the closed breaker points and finally back to the battery. This current produces a magnetic field within the coil's core. This magnetic field forms the energy reservoir that will be used to drive the ignition spark.\\r\\nAs the engine crankshaft turns, it also turns the distributor shaft at half the speed. In a four-stroke engine, the crankshaft turns twice for the ignition cycle. A multi-lobed cam is attached to the distributor shaft; there is one lobe for each engine cylinder. A spring-loaded rubbing block follows the lobed portions of the cam contour and controls the opening and closing of points. During most of the cycle, the rubbing block keeps the points closed to allow a current to build in the ignition coil's primary winding. As a piston reaches the top of the engine's compression cycle, the cam's lobe is high enough to cause the breaker points to open. Opening the points causes the current through the primary coil to stop. Without the steady current through the primary, the magnetic field generated in the coil immediately collapses. This high rate of change of magnetic flux induces a high voltage in the coil's secondary windings that ultimately causes the spark plug's gap to arc and ignite the fuel.\\r\\nThe spark generation story is a little more complicated. The purpose of the ignition coil is to make a spark that jumps the spark plug's gap, which might be 0.025 inches (0.64?mm) (it also has to jump the rotor-to-distributor-post gap). At the moment the points open, there is a much smaller gap, say about 0.00004 inches (0.001?mm), across the points. Something must be done to prevent the points from arcing as they separate; if the points arc, then they will drain the magnetic energy that was intended for the spark plug. The capacitor (condenser) performs that task. The capacitor temporarily keeps the primary current flowing so the voltage across the points is below the point's arcing voltage. There is a race: the voltage across the points is increasing as the primary current charges the capacitor, but at the same time the points' separation (and consequent arcing voltage) is increasing. Ultimately, the point separation will increase to something such as 0.015 inches (0.38?mm), the maximum separation of the points.\\r\\nIn addition to staying below the arcing voltage, the ignition system keep the voltage across the points below the breakdown voltage for an air gap to prevent a glow discharge across the points. Such a glow discharge would quickly transition to an arc, and the arc would prevent the spark plug from firing. The minimum voltage for a glow discharge in air is about 320?V. Consequently, the capacitor value is chosen to also keep the voltage across the points to be less than 320?V. Keeping the points from arcing when they separate is the reason the ignition coil includes a secondary winding rather than using just a simple inductor. If the transformer has a 100:1 ratio, then the secondary voltage can reach 30?kV.\\r\\nThe ignition coil's high voltage output is connected to the rotor that sits on top of the distributor shaft. Surrounding the rotor is the distributor cap. The arrangement sequentially directs the output of the secondary winding to the appropriate spark plugs. The high voltage from the coil's secondary (typically 20,000 to 50,000 volts) causes a spark to form across the gap of the spark plug that in turn ignites the compressed air-fuel mixture within the engine. It is the creation of this spark which consumes the energy that was stored in the ignition coils magnetic field.\\r\\nThe flat twin cylinder 1948 Citro?n 2CV used one double ended coil without a distributor, and just contact breakers, in a wasted spark system.\\r\\nSome two-cylinder motorcycles and motor scooters had two contact points feeding twin coils each connected directly to one of the two sparking plugs without a distributor; e.g. the BSA Thunderbolt and Triumph Tigress.\\r\\nHigh performance engines with eight or more cylinders that operate at high r.p.m. (such as those used in motor racing) demand both a higher rate of spark and a higher spark energy than the simple ignition circuit can provide. This problem is overcome by using either of these adaptations:\\r\\nA distributor-based system is not greatly different from a magneto system except that more separate elements are involved. There are also advantages to this arrangement. For example, the position of the contact breaker points relative to the engine angle can be changed a small amount dynamically, allowing the ignition timing to be automatically advanced with increasing revolutions per minute (RPM) or increased manifold vacuum, giving better efficiency and performance.\\r\\nHowever it is necessary to check periodically the maximum opening gap of the breaker(s), using a feeler gauge, since this mechanical adjustment affects the \\"dwell\\" time during which the coil charges, and breakers should be re-dressed or replaced when they have become pitted by electric arcing. This system was used almost universally until the late 1970s, when electronic ignition systems started to appear.\\r\\nThe disadvantage of the mechanical system is the use of breaker points to interrupt the low-voltage high-current through the primary winding of the coil; the points are subject to mechanical wear where they ride the cam to open and shut, as well as oxidation and burning at the contact surfaces from the constant sparking. They require regular adjustment to compensate for wear, and the opening of the contact breakers, which is responsible for spark timing, is subject to mechanical variations.\\r\\nIn addition, the spark voltage is also dependent on contact effectiveness, and poor sparking can lead to lower engine efficiency. A mechanical contact breaker system cannot control an average ignition current of more than about 3 A while still giving a reasonable service life, and this may limit the power of the spark and ultimate engine speed.\\r\\nElectronic ignition (EI) solves these problems. In the initial systems, points were still used but they handled only a low current which was used to control the high primary current through a solid state switching system. Soon, however, even these contact breaker points were replaced by an angular sensor of some kind - either optical, where a vaned rotor breaks a light beam, or more commonly using a Hall effect sensor, which responds to a rotating magnet mounted on the distributor shaft. The sensor output is shaped and processed by suitable circuitry, then used to trigger a switching device such as a thyristor, which switches a large current through the coil.\\r\\nThe first electronic ignition (a cold cathode type) was tested in 1948 by Delco-Remy,[3] while Lucas introduced a transistorized ignition in 1955, which was used on BRM and Coventry Climax Formula One engines in 1962.[3] The aftermarket began offering EI that year, with both the AutoLite Electric Transistor 201 and Tung-Sol EI-4 (thyratron capacitive discharge) being available.[4] Pontiac became the first automaker to offer an optional EI, the breakerless magnetic pulse-triggered Delcotronic, on some 1963 models; it was also available on some Corvettes.[4] The first commercially available all solid-state (SCR) capacitive discharge ignition was manufactured by Hyland Electronics in Canada also in 1963. Ford fitted a Lucas system on the Lotus 25s entered at Indianapolis the next year, ran a fleet test in 1964, and began offering optional EI on some models in 1965.[4] Beginning in 1958, Earl W. Meyer at Chrysler worked on EI, continuing until 1961 and resulting in use of EI on the company's NASCAR hemis in 1963 and 1964.[4]\\r\\nPrest-O-Lite's CD-65, which relied on capacitance discharge (CD), appeared in 1965, and had \\"an unprecedented 50,000 mile warranty.\\"[4] (This differs from the non-CD Prest-O-Lite system introduced on AMC products in 1972, and made standard equipment for the 1975 model year.)[4] A similar CD unit was available from Delco in 1966,[3] which was optional on Oldsmobile, Pontiac, and GMC vehicles in the 1967 model year.[4] Also in 1967, Motorola debuted their breakerless CD system.[4] The most famous aftermarket electronic ignition which debuted in 1965, was the Delta Mark 10 capacitive discharge ignition, which was sold assembled or as a kit.\\r\\nThe Fiat Dino is the first production car to come standard with EI in 1968, followed by the Jaguar XJ Series 1[5] in 1971, Chrysler (after a 1971 trial) in 1973 and by Ford and GM in 1975.[4]\\r\\nIn 1967, Prest-O-Lite made a \\"Black Box\\" ignition amplifier, intended to take the load off of the distributor's breaker points during high r.p.m. runs, which was used by Dodge and Plymouth on their factory Super Stock Coronet and Belvedere drag racers.[4] This amplifier was installed on the interior side of the cars' firewall, and had a duct which provided outside air to cool the unit.[citation needed] The rest of the system (distributor and spark plugs) remains as for the mechanical system. The lack of moving parts compared with the mechanical system leads to greater reliability and longer service intervals.\\r\\nChrysler introduced breakerless ignition in mid-1971 as an option for its 340 V8 and the 426 Street Hemi. For the 1972 model year, the system became standard on its high-performance engines (the 340?cu?in (5.6?l) and the four-barrel carburetor-equipped 400?hp (298?kW) 400?cu?in (7?l)) and was an option on its 318?cu?in (5.2?l), 360?cu?in (5.9?l), two-barrel 400?cu?in (6.6?l), and low-performance 440?cu?in (7.2?l) . Breakerless ignition was standardised across the model range for 1973.\\r\\nFor older cars, it is usually possible to retrofit an EI system in place of the mechanical one. In some cases, a modern distributor will fit into the older engine with no other modifications, like the H.E.I. distributor made by General Motors, the Hot-Spark electronic ignition conversion kit, and the Chrysler breakerless system.\\r\\nOther innovations are currently available on various cars. In some models, rather than one central coil, there are individual coils on each spark plug, sometimes known as direct ignition or coil on plug (COP). This allows the coil a longer time to accumulate a charge between sparks, and therefore a higher energy spark. A variation on this has each coil handle two plugs, on cylinders which are 360 degrees out of phase (and therefore reach TDC at the same time); in the four-cycle engine this means that one plug will be sparking during the end of the exhaust stroke while the other fires at the usual time, a so-called \\"wasted spark\\" arrangement which has no drawbacks apart from faster spark plug erosion; the paired cylinders are 1/4 and 2/3. Other systems do away with the distributor as a timing apparatus and use a magnetic crank angle sensor mounted on the crankshaft to trigger the ignition at the proper time.\\r\\nAt the turn of the 21st century digital electronic ignition modules became available for small engines on such applications as chainsaws, string trimmers, leaf blowers, and lawn mowers. This was made possible by low cost, high speed, and small footprint microcontrollers. Digital electronic ignition modules can be designed as either capacitor discharge ignition (CDI) or inductive discharge ignition (IDI) systems. Capacitive discharge digital ignitions store charged energy for the spark in a capacitor within the module that can be released to the spark plug at virtually any time throughout the engine cycle via a control signal from the microprocessor. This allows for greater timing flexibility, and engine performance; especially when designed hand-in-hand with the engine carburetor.\\r\\nIn an Engine Management System (EMS), electronics control fuel delivery and ignition timing. Primary sensors on the system are crankshaft angle (crankshaft or Top Dead Center (TDC) position), airflow into the engine and throttle position. The circuitry determines which cylinder needs fuel and how much, opens the requisite injector to deliver it, then causes a spark at the right moment to burn it. Early EMS systems used an analogue computer to accomplish this, but as embedded systems dropped in price and became fast enough to keep up with the changing inputs at high revolutions, digital systems started to appear.\\r\\nSome designs using an EMS retain the original ignition coil, distributor and high-tension leads found on cars throughout history. Other systems dispense with the distributor altogether and have individual coils mounted directly atop each spark plug. This removes the need for both distributor and high-tension leads, which reduces maintenance and increases long-term reliability.\\r\\nModern EMSs read in data from various sensors about the crankshaft position, intake manifold temperature, intake manifold pressure (or intake air volume), throttle position, fuel mixture via the oxygen sensor, detonation via a knock sensor, and exhaust gas temperature sensors. The EMS then uses the collected data to precisely determine how much fuel to deliver and when and how far to advance the ignition timing. With electronic ignition systems, individual cylinders[citation needed] can have their own individual timing so that timing can be as aggressive as possible per cylinder without fuel detonation. As a result, sophisticated electronic ignition systems can be both more fuel efficient, and produce better performance over their counterparts.\\r\\nGas turbine engines, including jet engines, have a CDI system using one or more ignitor plugs, which are only used at startup or in case the combustor(s) flame goes out.\\r\\nRocket engine ignition systems are especially critical. If prompt ignition does not occur, the combustion chamber can fill with excess fuel and oxidiser and significant overpressure can occur (a \\"hard start\\") or even an explosion. Rockets often employ pyrotechnic devices that place flames across the face of the injector plate, or, alternatively, hypergolic propellants that ignite spontaneously on contact with each other. The latter types of engines do away with ignition systems entirely and cannot experience hard starts, but the propellants are highly toxic and corrosive.","input":"What electric generator produced the spark for early car engines?"},{"output":"steel","context":"\\r\\n\\r\\nMillennium Force is a steel roller coaster located at Cedar Point amusement park in Sandusky, Ohio. Manufactured by Intamin, it was the park's fourteenth roller coaster dating back to the opening of Blue Streak in 1964. Upon completion in 2000, Millennium Force broke six world records and was the world's first giga coaster, a term coined by Intamin and Cedar Point to represent roller coasters that exceed 300 feet (91?m) in height and complete a full circuit. It was briefly the tallest and fastest in the world until Steel Dragon 2000 opened later the same year. The ride is also the third-longest roller coaster in North America following The Beast at Kings Island and Fury 325 at Carowinds.\\r\\n\\r\\nIt features a 310-foot-tall (94?m) cable lift hill with a 300-foot (91?m) drop, two tunnels, three overbanked turns, and four hills. The coaster also has a top speed of 93?mph (150?km/h). Since its debut, Millennium Force has been voted the number one steel roller coaster ten times in Amusement Today's annual Golden Ticket Awards, and its lowest ranking in the poll has only been two. Although Millennium Force has been surpassed in height and speed, it remains one of the tallest and fastest in the world.\\r\\n\\r\\nThe planning, design and development phases of Millennium took place over five years.[1] The first rumors that a new record-breaking roller coaster would be built at Cedar Point, which included speculation about a ten inversion roller coaster from Bolliger & Mabillard and an Arrow Dynamics MegaLooper, began circulating in early 1998.[2][2][3] A roller coaster from D. H. Morgan Manufacturing was also rumored.[4] On July 2, 1999, Cedar Fair Entertainment Company filed a trademark for the name Millennium Force,[5] which raised more speculation about what the ride would be like.[6] About a week later, the first track pieces were seen at the park, which confirmed that the ride would be manufactured by Intamin. Cedar Point officials also confirmed that it would not have inversions.[7]\\r\\n\\r\\nMillennium Force was announced on July 22, 1999, as the tallest roller coaster in the world, taking the record from Fujiyama at Fuji-Q Highland in Japan.[8] Don Miears, General Manager of Cedar Point said, \\"Millennium Force introduces the world to a whole new level of roller coaster riding.\\"[9] The ride cost $25 million to design and build.[10] Millennium Force was built in the Frontier Trail section of the park and the Giant Wheel was relocated to make room for it.[11][12] Cedar Point, Intamin, and Werner Stengel designed the layout of the ride. After the ride was announced, several disputes about whether Millennium Force or Superman: The Escape was the tallest and fastest roller coaster in the world arose between Cedar Point and Six Flags Magic Mountain. Superman: The Escape is 415 feet (126?m) high and its speed is 100 miles per hour (160?km/h); however, it is a shuttle roller coaster, not a complete-circuit roller coaster.[13][14]\\r\\n\\r\\nConstruction started in August 1999 when the site was cleared.[15] The removal and relocation of the Giant Wheel began in October on closing day; the first of 226 supports were installed on October 11, starting at the brake run.[1][16] Two hundred twenty-six footers, each about 5 feet (1.5?m) deep were dug; the largest ones were 56 by 56 feet (17 by 17?m).[1] The concrete construction was done by Mosser Construction.[17] The lift hill was topped off in early January 2000.[18]\\r\\n\\r\\nThe ride's construction took seven months, and 120 construction workers and project managers participated. Testing took two months.[1] The park conducted a \\"pull-through\\" by pulling a train along the course to ensure proper clearance. The ride was inspected and tested with water-dummies on the trains.[15] The first media event was held on May 11, 2000, and the ride opened to the public on May 13. When it opened, it broke six world records. It was the first Giga Coaster and was the world's fastest complete-circuit roller coaster, but was later overtaken by other rides.[19][20] About a month after Millennium's debut, Cedar Point introduced a new queuing system called  \\"Ticket to Ride\\" to reduce the waiting times, which allowed visitors to buy a ticket then return later and wait in a shorter line.[21][22] In August, Cedar Point engaged John Hancock and Associates and Stalker Radar of Indianapolis to measure the height and speed of Millennium Force. The height was measured at 310?feet 11?inches (94.77?m), and the speed was measured at 93 miles per hour (150?km/h), slightly faster than what the park had been advertising (92?mph).[23]\\r\\n\\r\\nBefore the start of the 2004 season, Millennium Force's seat belts were modified because of an incident that occurred on Superman the Ride, a similar roller coaster at Six Flags New England.[24] The new seat belts were shorter and some riders had difficulties with them.[24][25] The roller coaster's layout was repainted over a three-year period of time, before the 2011, 2012 and 2013 season.[26] In 2012, the park added a new LED lighting system.[27]\\r\\n\\r\\nMillennium Force's entrance is located behind the Cedar Point & Lake Erie Railroad's Celebration Plaza station. The queue is situated between the ride's last overbanked turn and the station. A DJ booth is provided to entertain waiting visitors; the park's \\"Jamming DJ's\\" take requests for family friendly songs from people in the queue.[28] It was then replaced by Cedar Point's FUNtv, which plays music videos of popular songs, the Gatekeeper/Maverick shuffle, park trivia, sports news, park advertisements, weather forecasts, and popular news headlines.  About a month after Millennium's debut, Cedar Point introduced a new queue system known as \\"Ticket to Ride\\" (later FreeWay) to reduce the wait time. Visitors could buy tickets then return later and wait in a shorter line.[21][22] This system was discontinued in 2004 after several people complained it was unfair that others were going ahead of them in line.[29] In 2012, Cedar Point introduced its Fast Lane queue system on the ride; visitors can buy a wristband which enables them to wait in a shorter line.[30] The system was tested at Kings Island the previous year, where it received positive reviews.[29]\\r\\n\\r\\nMillennium Force covers 13 acres (5.3?ha); it runs parallel to the shoreline of Lake Erie then travels to an island located inside the park, that also houses the former Shoot the Rapids log flume and the Dinosaurs Alive! attractions.[31][32] There are two tunnels, three overbanked turns and four hills.[20][33] One cycle of the ride takes approximately 2 minutes and 20 seconds.[34]\\r\\n\\r\\nWhile the train is being loaded with passengers, the catch car for the cable lift descends the lift hill and latches onto the middle car underneath the train. Once the train is cleared, the cable lift immediately pulls the train up the 45 degree lift hill at 15 miles per hour (24?km/h) to a height of 310 feet (94?m). The train drops 300 feet (91?m) at an 80 degree angle and reaches a top speed of 93 miles per hour (150?km/h) at the bottom of the hill. It then climbs 169 feet (52?m) through a right overbanked turn at 122 degrees from the horizontal axis, then travels through a tunnel as it passes over the Frontier Trail. It then travels over a 182-foot (55?m) parabolic hill, which provides a moment of  zero gravity as it passes over a lagoon and down onto Adventure Island. While on Adventure Island, the train passes by the Dinosaurs Alive! attraction several times. It completes a 105-foot (32?m), 360-degree right-handed helix, followed by a left overbanked turn, passing the Shoot the Rapids water ride. It then completes a small right-hand turn before traveling over another hill to leave the island. The train then travels left through a second tunnel where the on-ride photo is taken, followed by a left turn and a small hill, passing by the queue. Finally, the train travels 68 feet (21?m) high through another right overbanked turn over the queue and is stopped by magnetic brakes. Passengers disembark the ride at an unloading station and the train moves to a second station where it is loaded.[20][34][35]\\r\\n\\r\\nMillennium Force is a Giga Coaster model designed by Werner Stengel and built by Swiss manufacturer Intamin.[34] It was the first of a series of roller coasters, including Top Thrill Dragsterthe tallest and fastest roller coaster in the world in 2003that Intamin built at Cedar Point.[36] As of  2015[update], Millennium Force is one of only two Giga Coasters built by Intamin.[37]\\r\\n\\r\\nMillennium Force operates with three stainless steel, stadium-style seating trains colored red, blue, and yellow.[9][33] Each train has nine cars that seat four passengers, allowing a maximum capacity of 36 people per train and 1,300 riders an hour.[34] Each seat has an individual, hydraulic, T-shaped lap bar and seat belt which rests across the rider's lap.[34] Each train weighs 19 tons.[1]\\r\\n\\r\\nThe station has two platforms, one for unloading and one for loading. Two trains are loaded and unloaded while the third train is running the course. There is also a separate line in the station where riders can wait for the first seat.[38] The loading platform has red overhead lights, which are located above the train.[39] Millennium Force's theme song is played in the station while riders are boarding.[40]\\r\\n\\r\\nThe steel tubular track is 6,595 feet (2,010?m) long and the lift is approximately 310 feet (94?m) high.[34] The track is blue and the supports are silver, and consists of 229 pieces of track, each weighing between 11,000 and 17,000 pounds (5,000 and 7,700?kg).[1]  Intamin supplied the track with hollow structural sections (HSS), which is used in all the track pieces, supports and towers. Millennium uses three different track shapes. The simplest sections are two-pipe track, made with two running rails connected by 6-inch (15?cm) square HSS cross-members. The ride also uses three-pipe track, which has two running rails with a backbone of round HSS, which forms a triangle. The third type of track forms a square and is considered the strongest. It has two running rails with two backbone tubes.[41]\\r\\n\\r\\nWhen the ride opened in 2000, Cedar Point chose High End Systems, headquartered in Austin, Texas, to light the ride. Rob Decker, Cedar Points Corporate Director of Planning & Design, said that they thought they would have to mount multiple floodlights on the tower. However, they were able to install thirty EC-1 floodlights at the base of the lift hill structure which provided lighting throughout the ride's structure. Of the six main support towers, three had six EC-1s, and three towers had four EC-1s. The three tallest towers had another unit in the middle.[42]\\r\\n\\r\\nOver the years, the lights were not maintained and grew noticeably dimmer. In 2012, Cedar Point introduced a new nighttime show, Luminosity? Ignite the Night!, to \\"re-energize\\" the park at the end of the day. New LED lights from Sunrise, Florida-based Chauvet Professional were installed to illuminate the ride. Twenty COLORado Range and ten COLORado Ridge wash lights were installed at the base of the lift hill structure.[27]\\r\\n\\r\\nWhen it opened in May 2000, Millennium Force broke six world records and used a new magnetic braking system instead of friction brakes found on most roller coasters.[20][33] This new system enabled a shorter brake run, which slows the train from 65 miles per hour (105?km/h)  down to a standstill in six seconds, to be built.[43]\\r\\n\\r\\nMillennium Force held the records for tallest and fastest complete-circuit roller coaster until August 2000, when Steel Dragon 2000 opened.[44] Millennium Force held the record for tallest and fastest roller coaster at Cedar Point until 2003, when Cedar Point debuted Top Thrill Dragster, which at the time was the tallest and fastest roller coaster in the world.[45]\\r\\n\\r\\nAs of  2015[update], Millennium Force has the seventh tallest lift, the seventh fastest speed, the fifth-longest track, and the seventh-highest drop among steel roller coasters in the world.[46][47][48][49] It is the second longest steel roller coaster in North America, and the third-longest roller coaster behind The Beast at Kings Island and Fury 325 at Carowinds.[50]\\r\\n\\r\\nMillennium Force has held records for the following:[33]\\r\\n\\r\\nCedar Point has held records for the following (May 2000 statistic on left and May 2013 statistic on right):[33]\\r\\n\\r\\nAs both a high altitude and high velocity ride, Millennium Force is affected by unfavorable weather conditions such as rain, lightning or strong winds; under these conditions the ride is closed, but in light rain it can remain open.[38] There is no minimum age requirement, but passengers must be between 48 and 78 inches (120 and 200?cm) to ride.[51] Persons over a certain weight or waist size are not allowed to ride if the seat and lapbar harness cannot accommodate them.[38] Passengers on Millennium Force may not take loose articles onto the train and are required to wear shirts and footwear. Headphones must be removed before boarding.[38] Passengers are advised not to ride Millennium Force if they have recently had surgery, heart trouble, high blood pressure, neck or back trouble, or any medical condition that may be aggravated by riding, or are pregnant.[52]\\r\\n\\r\\nMillennium Force made an impact on the way roller coasters were built. Following its debut, the use of cable lift hills, which require less maintenance and support more weight than a traditional chain lift, became a prevalent feature in the industry. Millennium Force also paved the way for additional coasters breaking the 300-foot (91?m) barrier. Top Thrill Dragster, also built by Intamin, opened three years later as the first complete-circuit roller coaster to exceed 400 feet (120?m) in height.[45] The company didn't build another \\"Giga Coaster\\" until 2010, when it built Intimidator 305 at Kings Dominion.[53] Intimidator 305 is similar to Millennium Force; it has a cable lift and similar layout but varies on the restraints, choosing to utilize shoulder harnesses instead of lap bars. Leviathan opened at Canada's Wonderland in May 2012 breaking 300 feet (91?m) as well. Manufactured by Bolliger & Mabillard, it opted for a chain lift instead of a cable lift.[35][54][55][56]\\r\\n\\r\\nMillennium Force has one of the longest lines in the park, with passengers waiting over four hours when the ride debuted.[57] The ride received positive reactions from visitors, many of whom said it was smooth and very comfortable. Others said, \\"It'll scare the daylights out of you\\".[58] In its first six years of operation, Millennium Force had over 10 million riders.[59] By August 2012, Millennium had given more than 21 million rides.[60] Several television shows, including the Travel Channel's Extreme Terror Rides,[61] Bert the Conqueror,[62] Off Limits,[63] the Discovery Channel's Extreme Rides,[43] and the National Geographic Channel's Super Coasters[64] have featured Millennium Force. Out of over 500 roller coasters that Werner Stengel has engineered, he stated that Millennium Force is his favorite.[65] Robb Alvey, a notable roller coaster enthusiast, called it a \\"milestone in roller coaster history\\".[66]\\r\\n\\r\\nMillennium Force has consistently ranked high in various polls and has won numerous awards. Millennium Force and Superman the Ride (formerly Bizarro) at Six Flags New England held the top two places in the Golden Ticket Awards from 2001ÿ2015, often swapping positions. Fury 325 has occupied the top spot since 2016. In the Travel Channel's Insane Coaster Wars, Millennium Force was voted the \\"fan favorite\\" in the Extreme Heights and The Top 10 categories.[66][67] In 2013, Time ranked Millennium Force as the top roller coaster in the United States.[68]","input":"What type of coaster is the millennium force?"},{"output":"July 1865","context":"","input":"When did the union pacific railroad began construction?"},{"output":"15 September 1916","context":"The development of tanks in World War I was a response to the stalemate that had developed on the Western Front. Although vehicles that incorporated the basic principles of the tank (armour, firepower, and all-terrain mobility) had been projected in the decade or so before the War, it was the alarmingly heavy casualties of the start of its trench warfare that stimulated development.[1][2] Research took place in both Great Britain and France, with Germany only belatedly following the Allies' lead.\\r\\nIn Great Britain, an initial vehicle, nicknamed Little Willie, was constructed at William Foster & Co., during August and September 1915.[3] The prototype of a new design that became the Mark I tank was demonstrated to the British Army on 2 February 1916. Although initially termed \\"Landships\\" by the Landships Committee, production vehicles were named \\"tanks\\", to preserve secrecy. The term was chosen when it became known that the factory workers at William Foster referred to the first prototype as \\"the tank\\" because of its resemblance to a steel water tank.\\r\\nThe French fielded their first tanks in April 1917 and ultimately produced far more tanks than all other combatants combined.\\r\\nThe Germans, on the other hand, began development only in response to the appearance of Allied tanks on the battlefield. Whilst the Allies manufactured several thousand tanks during the War, Germany deployed only 20 of her own.[4]\\r\\nThe first tanks were mechanically unreliable. There were problems that caused considerable attrition rates during combat deployment and transit. The heavily shelled terrain was impassable to conventional vehicles, and only highly mobile tanks such as the Mark and FTs performed reasonably well. The Mark I's rhomboid shape, caterpillar tracks, and 26-foot (8?m) length meant that it could negotiate obstacles, especially wide trenches, that wheeled vehicles could not. Along with the tank, the first self-propelled gun (the British Gun Carrier Mk I) and the first armoured personnel carrier (the British Mk IX) were also constructed in World War I.\\r\\n\\r\\n\\r\\nThe conceptual roots of the tank go back to ancient times, with siege engines which were able to provide protection for troops moving up against stone walls or other fortifications. With the coming of the Industrial Revolution and the demonstrable power of steam, James Cowan presented a proposal for a Steam Powered Land Ram in 1855, towards the end of the Crimean War. Looking like a helmet on 'footed' Boydell wheels, early forerunners of the Pedrail wheel, it was essentially an armoured steam tractor equipped with cannon and rotating scythes sprouting from the sides. Lord Palmerston is said to have dismissed it as 'barbaric'.\\r\\nFrom 1904 to 1909, David Roberts, the engineer and managing director of Hornsby & Sons of Grantham, built a series of tractors using his patented 'chain-track' which were put through their paces by the British Army, a (small) section of which wanted to evaluate artillery tractors. At one point in 1908, Major William E. Donohue of the Mechanical Transport Committee remarked to Roberts that he should design a new machine with armour, capable of carrying its own gun. But, disheartened by years of ultimately fruitless tinkering for the Army, Roberts did not take up the idea. In later years he expressed regret at not having pursued it.[5]\\r\\nAn engineer in the Austro-Hungarian Army, Lieutenant Gunther Burstyn, inspired by Holt tractors, designed a tracked armoured vehicle in 1911 carrying a light gun in a rotating turret; equipped also with hinged 'arms', two in front and two at the rear, carrying wheels on the ends to assist with obstacles and trenches, it was a very forward-looking design, if rather small. The Austrian government said it would be interested in evaluating it if Burstyn could secure commercial backing to produce a prototype. Lacking the requisite contacts, he let it drop. An approach to the German government was similarly fruitless.\\r\\nIn 1912, a South Australian, Lancelot De Mole, submitted a proposal to the British War Office for a \\"chain-rail vehicle which could be easily steered and carry heavy loads over rough ground and trenches\\". De Mole made more proposals to the War Office in 1914 and 1916, with a culminating proposal in late 1917, accompanied by a huge one-eighth scale model, yet all fell on substantially deaf ears. De Mole's proposal already had the climbing face, so typical of the later World War I British tanks, but it is unknown whether there was some connection. Inquiries to the government of Australia, after the war, yielded polite responses that Mr. De Mole's ideas had unfortunately been too advanced for the time to be properly recognised at their just value. The Commission on Awards to Inventors in 1919, which adjudicated all the competing claims to the development of the tank, recognised the brilliance of De Mole's design, even considering that it was superior to the machines actually developed, but due to its narrow remit, could only make a payment of S987 to De Mole to cover his expenses. De Mole noted in 1919 that he was urged by friends before the war to approach the Germans with his design, but declined to do so for patriotic reasons.\\r\\nBefore World War I, motorized vehicles were still relatively uncommon, and their use on the battlefield was initially limited, especially of heavier vehicles. Armoured cars soon became more commonplace with most belligerents, especially in more open terrain. On August 23, 1914, the French Colonel Jean Baptiste Eugne Estienne, later a major proponent of tanks, declared: Messieurs, la victoire appartiendra dans cette guerre  celui des deux belligrants qui parviendra le premier  placer un canon de 75 sur une voiture capable de se mouvoir en tout terrain (\\"Gentlemen, the victory will belong, in this war, to the one of the two belligerents who will be the first to succeed in mounting a 75 mm gun on a vehicle capable of moving in all types of terrain\\").\\r\\nArmored cars did indeed prove useful in open land such as in deserts, but were not very good at crossing obstacles (e.g. trenches, barriers) or in more challenging terrain. The other issue was that it was very hard to add much protection or armament.\\r\\nThe main limitation was the wheels, which gave a high ground pressure for the vehicle's weight. This could be solved by adding more wheels, but unless they also were driven, the effect was to reduce traction on the powered wheels. Driving extra wheels meant more drive train weight, in turn requiring a larger and heavier engine to maintain performance. Even worse, none of this extra weight was put into an improvement of armor or armament carried, and the vehicles were still incapable of crossing very rough terrain.\\r\\nThe adoption of caterpillar tracks offered a new solution to the problem. The tracks spread the weight of the vehicles over a much greater area, which was all used for traction to move the vehicle. The limitation on armor and firepower was no longer ground pressure but the power and weight of the power-plant.\\r\\nThe remaining issue was how to utilise and configure a vehicle. Major Ernest Dunlop Swinton RE, was the official British war correspondent serving in France in 1914. He recounts in his book Eyewitness how the idea of using caterpillar tracks to drive an armoured fighting vehicle came to him on October 19, 1914, while he was driving through northern France. In July 1914 he had received a letter from a friend, Hugh Marriott, a mining engineer, drawing his attention to a Holt caterpillar tractor that Marriott had seen in Belgium. Marriott thought it might be useful for transport over difficult ground, and Swinton had passed the information on to the appropriate departments. Now Swinton suggested the idea of an armoured tracked vehicle to the military authorities, by sending a proposal to Lieutenant-Colonel Maurice Hankey. Hankey in turn tried to interest Lord Kitchener in the idea; when this failed he sent a memorandum in December to the Committee of Imperial Defence, of which he was himself the secretary; Winston Churchill the First Lord of the Admiralty was one of the members of the committee. Hankey proposed to build a gigantic steel roller, pushed by tracked tractors, to shield the advancing infantry. Churchill in turn wrote a note on January 5 to the Prime Minister H. H. Asquith, in which he warned that the Germans might any moment introduce a comparable system. A worried Asquith now ordered Kitchener to form a committee, headed by General Scott-Moncrieff, to study the feasibility of Swinton's idea; however, after trials with a Holt 75 h.p. machine the committee concluded in February 1915 that the idea was impractical.\\r\\nWinston Churchill however decided that if the Army wouldn't take up the idea, the Navy should proceed independently, even if it were to exceed the limits of his authority. He created the Landships Committee in February 1915, initially to investigate designs for a massive troop transporter. As a truer picture of front-line conditions was developed the aims of the investigation changed. A requirement was formulated for an armoured vehicle capable of 4?mph (6?km/h), climbing a 5 feet (1.5 m) high parapet, crossing an 8 feet (2.4 m) wide gap, and armed with machine guns and a light artillery piece. A similar proposal was working its way through the Army GHQ in France, and in June the Landships Committee was made a joint service venture between the War Office and the Admiralty. The Naval involvement in Armoured Fighting Vehicle (AFV) design had originally come about through the Royal Naval Air Service Armoured Car Division, the only British unit fielding AFVs in 1914; surprisingly, until the end of the war most experimentation on heavy land vehicles was conducted by Royal Naval Air Service Squadron 20.\\r\\nAt first, protecting heavy gun tractors with armour appeared the most promising line of development. Alternative early 'big wheel' designs on the lines of the Russian tsar tank of 1915 were soon understood to be impractical. However, adapting the existing Holt Company caterpillar designs  the only robust tracked tractors available in 1915  into a fighting machine, as France and Germany did, was decided against. While armour and weapon systems were easy to acquire, other existing caterpillar and suspension units were too weak, existing engines were underpowered for the vehicles that the designers had in mind, and trench-crossing ability was poor because of the shortness of the wheelbase. The Killen-Strait tractor with three tracks was used for the first experiments in June but was much too small to be developed further. The large Pedrail monotrack vehicle was proposed in a number of different configurations, but non were adopted. Trials to couple two American Bullock tractors failed. There also were considerable differences of opinion between the several committee members. Col R.E.B. Crompton, a veteran military engineer and electrical pioneer, drafted numerous designs with Lucien Legros for armoured troop carrying vehicles and gun-armed vehicles, to have used either Bullock tracks or variants of the Pedrail. At the same time, Lt Robert Macfie, of the RNAS, and Albert Nesfield, an Ealing-based engineer, devised a number of armoured tracked vehicles, which incorporated an angled front 'climbing face' to the tracks. The two men fell out bitterly as their plans came to nought; Macfie in particular pursued a vendetta against the other members of the Landships Committee after the war.\\r\\nTo resolve the threatened dissipation of effort, it was ordered in late July that a contract was to be placed with William Foster & Co. Ltd, a company having done some prewar design work on heavy tractors and known to Churchill from an earlier experiment with a trench-crossing supply vehicle, to produce a proof-of-concept vehicle with two tracks, based on a lengthened Bullock tractor chassis. Construction work began three weeks later.\\r\\nFosters of Lincoln built the 14 ton \\"Little Willie\\", which first ran on 8 September. Powered by a 105?hp (78?kW) Daimler engine, the 10-foot-high (3.0?m) armoured box was initially fitted with a low Bullock caterpillar. A rotating top turret was planned with a 40?mm gun but abandoned due to weight problems, leaving the final vehicle unarmed and little more than a test-bed for the difficult track system. Difficulties with the commercial tracks supplied led to Tritton designing a completely new track system different from, and vastly more robust than, any other system then in use. The next design by Lieutenant Walter Gordon Wilson RNAS, a pre-war motor engineer, added a larger track frame to the hull of \\"Little Willie\\". In order to achieve the demanded gap clearance a rhomboidal shape was chosenstretching the form to improve the track footprint and climbing capacity. To keep a low centre of gravity the rotating turret design was dropped in favour of sponsons on the sides of the hull fitted with naval 6-pounder (57?mm) guns. A final specification was agreed on in late September for trials in early 1916, and the resulting 30 ton \\"Big Willie\\" (later called \\"Mother\\") together with \\"Little Willie\\" underwent trials at Hatfield Park on 29 January and 2 February. Attendees at the second trial included Lord Kitchener, Lloyd George, Reginald McKenna and other political luminaries. On 12 February an initial order for 100 \\"Mother\\" type vehicles was made, later expanded to 150.\\r\\nCrews never called tanks \\"Willies\\"; at first they referred to them as \\"landships\\", and later informally \\"buses\\".[6] Although landship was a natural term coming from an Admiralty committee, it was considered too descriptive and could give away British intentions. The committee therefore looked for an appropriate code term for the vehicles. Factory workers assembling the vehicles had been told they were producing \\"mobile water tanks\\" for desert warfare in Mesopotamia. Water Container was therefore considered but rejected because the committee would inevitably be known as the WC Committee (WC meaning water closet was a common British term for a toilet). The term tank, as in water tank, was in December 1915 finally accepted as its official designation. From then on, the term \\"tank\\" was established among British and also German soldiers. While in German Tank specifically refers to the World War I type (as opposed to modern Panzer), in English, Russian and other languages the name even for contemporary armoured vehicles is still based on the word tank.\\r\\nIt is sometimes mistakenly stated that, after completion, the tanks were shipped to France in large wooden crates. For secrecy and in order to not arouse any curiosity, the crates and the tanks themselves were then each labelled with a destination in Russian, \\"With Care to Petrograd\\". In fact the tanks were never shipped in crates: the inscription in Russian was applied on the hull for their transport from the factory to the first training centre at Thetford.\\r\\nThe first fifty had been delivered to France on 30 August. They were 'male' or 'female', depending upon whether their armament comprised two 6-pounder cannon and three Hotchkiss machine guns or four Vickers machine guns and one Hotchkiss. It had a crew of eight, four of whom were needed to handle the steering and drive gears. The tanks were capable of, at best, 6?km/h (4?mph), matching the speed of marching infantry with whom they were to be integrated to aid in the destruction of enemy machine guns. In practice, their speed on broken ground could be as little as 1?mph.\\r\\nAfter the war the Royal Commission on Awards to Inventors decided that the principal inventors of the Tank were Sir William Tritton, managing director of Fosters, and Major Walter Gordon Wilson.\\r\\nThe first use of tanks on the battlefield was the use of British Mark I tanks at the Battle of Flers-Courcelette (part of the Battle of the Somme) on 15 September 1916, with mixed results; many broke down, but nearly a third succeeded in breaking through. Of the forty-nine tanks shipped to the Somme, only thirty-two were able to begin the first attack in which they were used and only nine made it across \\"no man's land\\" to the German lines. The tanks had been rushed into combat before the design was mature enough (against Churchill's and Ernest Swinton's wishes)[7] and the number was small but their use gave important feedback on how to design newer tanks, the soundness of the concept, and their potential to affect the course of the war. On the other hand, the French Army was critical of the British employment of small numbers of tanks at this battle. They felt the British had sacrificed the secrecy of the weapon while employing it in numbers too small to be decisive. Considering that the British attack was part of an Anglo-French offensive while the Russians were also attacking at the same time, Haig felt justified in making a maximum effort, regardless of the limitations of the tank force.\\r\\nThe Mark Is were capable of performing on the real battlefield of World War I, one of the most difficult battlefield terrains ever. They did have reliability problems, but when they were working they could cross trenches or craters of 9 feet (2.7 m) and drive right through barbed wire. It was still common for them to get stuck, especially in larger bomb craters, but overall the rhomboid shape allowed for extreme terrain mobility.\\r\\nTank crews who had read press reports depicting the new weapon driving through buildings and trees, and crossing wide rivers, were disappointed.[6] Most World War I tanks could travel only at about a walking pace at best. Their steel armour could stop small arms fire and fragments from high-explosive artillery shells. However they were vulnerable to a direct hit from artillery and mortar shells. The environment inside was extremely unpleasant; as ventilation was inadequate the atmosphere was heavy with poisonous carbon monoxide from the engine and firing the weapons, fuel and oil vapours from the engine and cordite fumes from the weapons. Temperatures inside could reach 50C (122F). Entire crews lost consciousness inside the tanks, or collapsed when again exposed to fresh air.[8] Crews learned how to create and leave behind supply dumps of fuel, motor oil, and tread grease, and converted obsolete models into supply vehicles for newer ones.[6]\\r\\nTo counter the danger of bullet splash or fragments knocked off the inside of the hull, the crew wore helmets with goggles and chainmail masks. Fragments were not as dangerous as fire, because of explosive fumes and the large amount of fuel aboard; smoking was prohibited inside and within 20 yards outside tanks.[6] Gas masks were also standard issue, as they were to all soldiers at this point in the war due to the use of chemical warfare. The side armour of 8?mm initially made them largely immune to small arms fire, but could be penetrated by the recently developed armour-piercing K bullets. There was also the danger of being overrun by infantry and attacked with grenades. The next generation had thicker armour, making them nearly immune to the K bullets. In response, the Germans developed a larger purpose-made anti-tank rifle, and also a Geballte Ladung (\\"Bunched Charge\\")several regular stick grenades bundled together for a much bigger explosion.\\r\\nEngine power was a primary limitation on the tanks; the roughly one hundred horsepower engines gave a power-to-weight ratio of 3.3?hp/ton (2.5?kW/ton). By the end of the 20th century, power-to-weight ratios exceeded 20?hp/ton (15?kW/ton).\\r\\nMany feel that because the British Commander Field Marshal Douglas Haig was himself a horse cavalryman, his command failed to appreciate the value of tanks. In fact, horse cavalry doctrine in World War I was to \\"follow up a breakthrough with harassing attacks in the rear\\", but there were no breakthroughs on the Western Front until the tanks came along. Despite these supposed views of Haig, he made an order for 1,000 tanks shortly after the failure at the Somme and always remained firmly in favour of further production.\\r\\nIn 1919, Major General Sir Louis Jackson said: \\"The tank was a freak. The circumstances which called it into existence were exceptional and not likely to recur. If they do, they can be dealt with by other means.\\"[9]\\r\\nFrance at the same time developed its own tracked AFVs, but the situation there was very different. In Britain a single committee had coordinated design, and had to overcome the initial resistance of the Army, while the major industries remained passive. Almost all production effort was thus concentrated into the Mark I and its direct successors, all very similar in shape. In France, on the other hand, there were multiple and conflicting lines of development which were badly integrated, resulting in three major and quite disparate production types. A major arms producer, Schneider, took the lead in January 1915 and tried to build a first armoured vehicle based on the Baby Holt tractor but initially the development process was slow until in July they received political, even presidential, support by combining their project with that of a mechanical wire cutter devised by engineer and politician Jean-Louis Brton. In December 1915, the influential Colonel Estienne made the Supreme Command very enthusiastic about the idea of creating an armoured force based on these vehicles; strong Army support for tanks was a constant during the decades that followed. Already in January and February 1916 quite substantial orders were made, at that moment with a total number of 800 much larger than the British ones.\\r\\nArmy enthusiasm and haste had its immediate drawbacks however. As a result of the involvement of inexperienced army officers ordered to devise a new tank based on the larger 75?hp Holt chassis in a very short period of time, the first French tanks were poorly designed with respect to the need to cross trenches and did not take the sponson-mounting route of the British tanks. The first, the Char Schneider CA equipped with a short 75?mm howitzer, had poor mobility due to a short track length combined with a hull that overhung front and rear. It was unreliable as well; a maximum of only about 130 of the 400 built were ever operational at the same time. Then industrial rivalry began to play a detrimental role: it created the heavy Char St Chamond, a parallel development not ordered by the Army but approved by government through industrial lobby, which mounted much more impressive weaponry  its 75?mm was the most powerful gun fielded by any operational tank up till 1941  but also combined many of the Schneider CA's faults with an even larger overhanging body. Its innovative petro-electrical transmission, while allowing for easy steering, was insufficiently developed and led to a large number of breakdowns.\\r\\nBut industrial initiative also led to swift advances. The car industry, already used to vehicle mass production and having much more experience in vehicle layout, in 1916 designed the first practical light tanks, a class largely neglected by the British. It was Renault's excellent small tank design, the FT, incorporating a proper climbing face for the tracks, that was the first tank to incorporate a top-mounted turret with a full 360 traverse capability. In fact the FT was in many respects the first truly 'modern' tank having a layout that has been followed by almost all designs ever since: driver at the front; main armament in a fully rotating turret on top; engine at the rear. Previous models had been \\"box tanks\\", with a single crowded space combining the role of engine room, fighting compartment, ammunition stock and driver's cabin. (A very similar Peugeot prototype, with a fixed casemate mounting a short 75mm cannon, was trialled in 1918 but the idea was not pursued). The FT had the largest production run of any tank of the war, with over 3700 built, more numerous than all British tanks combined. That this would happen was at first far from certain; some in the French army lobbied for the alternative mass production of super-heavy tanks. Much design effort was put in this line of development resulting in the gigantic Char 2C, the most complex and technologically advanced tank of its day. Its very complexity ensured it being produced too late to participate in World War I and in the very small number of just ten, but it was the first tank with a three-man turret; the heaviest to enter service until late in World War II and still the largest ever operational.\\r\\nFrench production at first lagged behind the British. After August 1916 however, British tank manufacture was temporarily halted to wait for better designs, allowing the French to overtake their allies in numbers. When the French used tanks for the first time on 16 April 1917, during the Nivelle Offensive, they had four times more tanks available. But that did not last long as the offensive was a major failure; the Schneiders were badly deployed and suffered 50% losses from German long-range artillery. The Saint-Chamond tanks, first deployed on 5 May, proved to be so badly designed that they were unable to cross the first line of German trenches.\\r\\nGermany concentrated more on the development of anti-tank weapons than on development of tanks themselves. They only developed one type of tank which saw combat in the war. The A7V Sturmpanzerwagen was designed in 1917 and was used in battle from March 1918. It was manned by a crew of 18, and had eight machine guns and a 57mm cannon. Only 20 A7Vs were produced during the war.\\r\\nThe first battle in which tanks made a great impact was the Battle of Cambrai in 1917. British Colonel J.F.C. Fuller, chief of staff of the Tank Corps, was responsible for the tanks' role in the battle. They made an unprecedented breakthrough but, as ever on the Western front, the opportunity was not exploited. Ironically, it was the soon-to-be-supplanted horse cavalry that had been assigned the task of following up the motorised tank attack.\\r\\nTanks became more effective as the lesson of the early tanks was absorbed. The British produced the Mark IV in 1917. Similar to the early Marks in appearance, its construction was considered to produce a more reliable machine, the long-barrelled naval guns were shortened (the barrels of the earlier, longer guns were prone to digging in the mud when negotiating obstacles) and armour was increased just enough to defeat the standard German armour-piercing bullet.\\r\\nThe continued need for four men to drive the tank was solved with the Mark V which used Wilson's epicyclic gearing in 1918. Also in 1918 the French produced the Renault FT, the result of a co-operation between Estienne and Louis Renault. As mentioned before, it had the innovative turret position, and was operated by two men. At just 8 tons it was half the weight of the Medium A Whippet but the version with the cannon had more firepower. It was conceived for mass production, and the FT became the most produced tank of World War I by a wide margin, with over 3,000 delivered to the French Army. Large numbers were used by the Americans and several were also lent to the British.\\r\\nIn July 1918, the French used 480 tanks (mostly FTs) at the Battle of Soissons, and there were even larger assaults planned for the next year. In Plan 1919, the Entente hoped to commit over 30,000 tanks to battle in that year.\\r\\nFinally, in a preview of later developments, the British developed the Whippet. This tank was specifically designed to exploit breaches in the enemy front with its relatively higher speed (around 8mph vs 3-4mph for the British heavy tanks). The Whippet was faster than most other tanks, although it carried only machine gun armament, meaning it was not suited to combat with armoured vehicles but instead with infantry. Postwar tank designs reflected this trend towards greater tactical mobility.[citation needed]\\r\\nThe German General Staff did not have enthusiasm for the tanks, but allowed the development of anti-tank weapons. Regardless, development of a German tank was under way. The only project to be produced and fielded was the A7V, although only twenty were built. The majority of the fifty or so tanks fielded by Germany were captured British vehicles. A7Vs were captured by the Allies, but they were not used, and most ended up being scrapped.\\r\\nThe first tank-versus-tank battles took place 24 April 1918. It was an unexpected engagement between three German A7Vs and three British Mk. IVs at Villers-Bretonneux.\\r\\nFuller's Plan 1919, involving massive use of tanks for an offensive, was never used because the blockade of Germany and the entry of the US brought an end to the war.\\r\\nTucker, Spencer C. World War I: The Definitive Encyclopedia and Document Collection. Vol. 4. R-Z. 1536. Santa Barbara, CA: ABC-CLIO, LLC, 2014.\\r\\nArmoured Cars:","input":"When was the first tank used in ww1?"},{"output":"roughly 4,200","context":"Religion is a collection of cultural systems, beliefs and world views that establishes symbols that relate humanity to spirituality and, sometimes to moral values. While religion is hard to define, one standard model of religion, used in religious studies courses, was proposed by Clifford Geertz, who simply called it a \\"cultural system.\\"[1] A critique of Geertz's model by Talal Asad categorized religion as \\"an anthropological category.\\"[2] Many religions have narratives, symbols, traditions and sacred histories that are intended to give meaning to life or to explain the origin of life or the universe. They tend to derive morality, ethics, religious laws, or a preferred lifestyle from their ideas about the cosmos and human nature. According to some estimates, there are roughly 4,200 religions in the world.[3]\\r\\nThe word religion is sometimes used interchangeably with \\"faith\\" or \\"belief system\\", but religion differs from private belief in that it has a public aspect. Most religions have organized behaviours, including clerical hierarchies, a definition of what constitutes adherence or membership, congregations of laity, regular meetings or services for the purposes of veneration of a deity or for prayer, holy places (either natural or architectural) or religious texts. Certain religions also have a sacred language often used in liturgical services. The practice of a religion may also include sermons, commemoration of the activities of a god or gods, sacrifices, festivals, feasts, trance, initiations, funerals, marriages, meditation, music, art, dance, public service or other aspects of human culture. Religious beliefs have also been used to explain parapsychological phenomena such as out-of-body experiences, near-death experiences and reincarnation, along with many other paranormal experiences.[4][5]\\r\\nSome academics studying the subject have divided religions into three broad categories: world religions, a term which refers to transcultural, international faiths; indigenous religions, which refers to smaller, culture-specific or nation-specific religious groups; and new religious movements, which refers to recently developed faiths.[6] One modern academic theory of religion, social constructionism, says that religion is a modern concept that suggests all spiritual practice and worship follows a model similar to the Abrahamic religions as an orientation system that helps to interpret reality and define human beings,[7] and thus religion, as a concept, has been applied inappropriately to non-Western cultures that are not based upon such systems, or in which these systems are a substantially simpler construct.\\r\\n\\r\\n\\r\\nA group of monotheistic traditions sometimes grouped with one another for comparative purposes, because all refer to a patriarch named Abraham.\\r\\nCertain Christian groups are difficult to classify as \\"Eastern\\" or \\"Western.\\"\\r\\nMany Gnostic groups were closely related to early Christianity, for example, Valentinism. Irenaeus wrote polemics against them from the standpoint of the then-unified Catholic Church.[8]\\r\\nThe Yazidis are a syncretic Kurdish religion with a Gnostic influence:\\r\\nNone of these religions are still extant.\\r\\nRecent Sufi groups\\r\\nSamaritans use a slightly different version of the Pentateuch as their Torah, worshiping at Mount Gerizim instead of Jerusalem, and are possibly the descendants of the lost Northern Kingdom. They are definitely of ancient Israelite origin, but their status as Jews is disputed.[9]\\r\\nNoahidism is a monotheistic ideology based on the Seven Laws of Noah, and on their traditional interpretations within Rabbinic Judaism. According to Jewish law, non-Jews are not obligated to convert to Judaism, but they are required to observe the Seven Laws of Noah.\\r\\nSecond Temple Judaism\\r\\nIndian religions are the religions that originated in the Indian subcontinent; namely Hinduism, Jainism, Buddhism and Sikhism, and religions and traditions related to, and descended from them.\\r\\nAfrican diasporic religions are a number of related religions that developed in the Americas among African slaves and their descendants in various countries of the Caribbean Islands and Latin America, as well as parts of the southern United States. They derive from African traditional religions, especially of West and Central Africa, showing similarities to the Yoruba religion in particular.\\r\\nTraditionally, these faiths have all been classified \\"Pagan\\", but scholars prefer the terms \\"indigenous/primal/folk/ethnic religions\\".\\r\\nMost historical religions were polytheistic, but some, such as Atenism, were much closer to monotheism.","input":"How many religions are in the world today?"},{"output":"Danish","context":"The surname Rasmussen or Rasmusen (Danish pronunciation:?[??smusn?]) is a Danish and Norwegian surname, meaning Rasmus' son. It is the ninth-most-common surname in Denmark, shared by about 1.9% of the population.[1]\\r\\nPeople with this name include:","input":"What is the origin of the name rasmussen?"},{"output":"Pennington County","context":"Rapid City (Lakota: Mni L~zaha? Ot?~?wahe;[7] \\"Swift Water City\\") is the second most populous city in South Dakota and the county seat of Pennington County.[8] Named after Rapid Creek, on which the city is established, it is set against the eastern slope of the Black Hills mountain range. The population was 67,956 as of the 2010 Census.[9]\\r\\nKnown as the \\"Gateway to the Black Hills\\" and the \\"City of Presidents\\", it is split by a low mountain ridge that divides the western and eastern parts of the city. Ellsworth Air Force Base is located on the outskirts of the city. Camp Rapid, a part of the South Dakota Army National Guard, is located in the western part of the city. The historic \\"Old West\\" town of Deadwood is nearby. In the neighboring Black Hills are the popular tourist attractions of Mount Rushmore, the Crazy Horse Memorial, Custer State Park, and Wind Cave National Park.\\r\\n\\r\\n\\r\\nThe public discovery of gold in 1874 by the Black Hills Expedition brought a mass influx of settlers into the Black Hills region of South Dakota. Rapid City was founded, and originally known as \\"Hay Camp\\", in 1876 by a group of disappointed miners, who promoted their new city as the \\"Gateway to the Black Hills\\". John Richard Brennan and Samuel Scott, with a small group of men, laid out the site of the present Rapid City in February 1876, which was named for the spring-fed Rapid Creek that flows through it. A square mile was measured off and the six blocks in the center were designated as a business section. Committees were appointed to bring in prospective merchants and their families to locate in the new settlement. The city soon began selling supplies to miners and pioneers. Its location on the edge of the Plains and Hills and its large river valley made it the natural hub of railroads arriving in the late 1880s from both the south and east. By 1900, Rapid City had survived a boom and bust and was establishing itself as an important regional trade center for the upper midwest.\\r\\nAlthough the Black Hills became a popular tourist destination in the late 1890s, it was a combination of local efforts, the popularity of the automobile, and construction of improved highways that brought tourists to the Black Hills in large numbers after World War I. Gutzon Borglum, already a famous sculptor, began work on Mount Rushmore in 1927 and his son, Lincoln Borglum, continued the carving of the presidents' faces in rock following his father's death in 1941. The work was halted due to pressures leading to the US entry into World War II and the massive sculpture was declared complete in 1941. Although tourism sustained the city throughout the Great Depression of the 1930s, the gasoline rationing of World War II had a devastating effect on the tourist industry in the town, but this was more than made up for by the war-related growth.\\r\\nThe city benefited greatly from the opening of Rapid City Army Air Base, later Ellsworth Air Force Base, an Army Air Corps training base. As a result, the population of the area nearly doubled between 1940 and 1948, from almost 14,000 to nearly 27,000 people. Military families and civilian personnel soon took every available living space in town, and mobile home parks proliferated. Rapid City businesses profited from the military payroll. During the Cold War, missile installations proliferated in the area: a series of Nike Air Defense sites were constructed around Ellsworth in the 1950s. In the early 60s the construction of three Titan missile launch sites containing a total of nine Titan I missiles in the general vicinity of Rapid City took place. Beginning in November 1963, the land for a hundred miles east, northeast and northwest of the city was dotted with 150 Minuteman missile silos and 15 launch command centers, all of which were deactivated in the early 1990s.[10]\\r\\nIn 1949, city officials envisioned the city as a retail and wholesale trade center for the region and designed a plan for growth that focused on a civic center, more downtown parking places, new schools, and paved streets. A construction boom continued into the 1950s. Growth slowed in the 1960s, but the worst natural disaster in South Dakota history, the Black Hills Flood of 1972, led to another building boom a decade later. On June 9, 1972, heavy rains caused massive flash flooding along the course of Rapid Creek through the city. 238 people lost their lives and more than $100 million in property was destroyed.\\r\\nThe devastation of the flood and the outpouring of private donations and millions of dollars in federal aid led to the completion of one big part of the 1949 plan: clearing the area along the Rapid Creek and making it a public park. New homes and businesses were constructed to replace those that had been destroyed. Rushmore Plaza Civic Center and a new Central High School were built in part of the area that had been cleared. The new Central High School opened in 1978, with the graduating class in that year straddling both the original Central (housed in what is now Rapid City High School and community theater) and the new Central. The rebuilding in part insulated Rapid City from the drop in automotive tourism caused by the Oil Embargo in 1974, but tourism was depressed for most of a decade. In 1978, Rushmore Mall was built on the north edge of the city, adding to the city's position as a retail shopping center.\\r\\nIn 1980 in United States v. Sioux Nation of Indians, the Supreme Court of the United States ruled that the Federal government of the United States had illegally stolen the Black Hills from the Sioux people when the government unilaterally broke the treaty that guaranteed the Black Hills belonged to the Sioux. The court decision offered money, but the Sioux declined on principle that the theft of their land should not be validated, and still demand the return of the land.[11] This land includes Rapid City, which is by far the largest modern settlement in the Black Hills. As of 2010, the dispute has not been settled.\\r\\nIn the 1980s, growth was fueled by an increase in tourism, increasingly tied to the Sturgis Motorcycle Rally, followed by another decline in the late 1990s. Fears for the closure of Ellsworth AFB as part of the massive base closure process in the 1990s and 2000s led to attempts to expand other sectors of the economy, but growth continued and the city expanded significantly during this period.\\r\\nToday, Rapid City is South Dakota's primary city for tourism and recreation. With the approval of a Deep Underground Science and Engineering Laboratory at the Homestake Mine site in nearby Lead, Rapid City has a future of great advancements in technology, medicine, and scientific research.\\r\\nOn June 9ÿ10, 1972, extremely heavy rains over the eastern Black Hills of South Dakota produced record floods on Rapid Creek and other streams in the area. Nearly 15 inches (380?mm) of rain fell in about 6 hours near Nemo, and more than 10 inches (250?mm) of rain fell over an area of 60 square miles (160?km2). According to the Red Cross, the resulting peak floods (which occurred after dark) left 238 people dead and 3,057 people injured.[12] In addition to the human tragedy, total destruction was estimated in excess of $160 million (about $821 million in 2009 dollars), which included 1,335 homes and 5,000 automobiles that were destroyed. Runoff from this storm produced record floods (highest peak flows recorded) along Battle, Spring, Rapid, and Box Elder Creeks. Smaller floods also occurred along Elk Creek and Bear Butte Creek. Canyon Lake Dam, on the west side of Rapid City, broke the night of the flood, unleashing a wall of water down the creek. The 1972 flooding has an estimated recurrence interval of 500 years,[13] which means that a flood of this magnitude will occur on average once every 500 years. Every year there is a 0.2 percent chance (1 in 500) of experiencing a similar event. To prevent a similar tragedy from occurring in the future, the city's flood plain is no longer allowed to be built upon. Today the flood plain features golf courses, parks, sports arenas, and arboretums where neighborhoods and businesses once stood.\\r\\nIn 2007, the Rapid City Public Library created a 1972 Flood digital archive[14] that collects survivors' stories, photos and news accounts of the flood. The Journey Museum has an interactive display on the 1972 flood, which is an ongoing project to give future generations the best idea of how the people were affected and the changes made to it because of the loss of 238 lives. It will in the future include the biographies of all of those who died so they will be remembered as more than names on a memorial.\\r\\nRapid City is located at 440434N 1031342W? / ?44.076188N 103.228299W? / 44.076188; -103.228299. The downtown elevation of Rapid City is 3,202 feet (976 m) and Rapid City sits in the shadow of Black Elk Peak, which at 7,242 feet (2,207?m), is the highest point east of the Rocky Mountains.\\r\\nAccording to the United States Census Bureau, the city has a total area of 55.49 square miles (143.71?km2), of which 55.41 square miles (143.5?km2) is land and 0.08 square mile (0.2?km2) is water.[15]\\r\\nRapid City is located on the eastern edge of the Black Hills, and is split in half by the Dakota Hogback. Rapid City's \\"Westside\\" is located in the Red Valley between the foothills of the Black Hills proper and the Dakota Hogback, so named for the red Spearfish formation soils and the way the valley completely circles the Black Hills. Rapid City has grown up into the foothills, with both ridges and valleys developed, especially in the last 20 years, and wildfire is a distinct threat to these residential areas, as shown by the Westberry Trails fire in 1988.\\r\\nSkyline Drive follows the summits of the Dakota Hogback south from near Rapid Gap (where Rapid Creek cuts through the Hogback) to a large high plateau that forms the current south edge of Rapid City. The Central and Eastern portions of Rapid City lie in the wide valley of Rapid Creek outside the Hogback, which includes a number of mesas rising a hundred feet or more above the floodplain.\\r\\nRapid Creek flows through Rapid City, emerging from Dark Canyon above Canyon Lake and flowing in a large arc north of Downtown. Rapid Creek descends to the southeast as the valley widens. The floodplain of Rapid Creek is mostly a series of parks, arboretums, and bike trails, one legacy of the Black Hills Flood of 1972. To the north, a series of ridges separates Rapid Creek from Box Elder Creek, with large older and new residential areas and commercial areas along I-90. To the south, the terrain rises more steeply to the southern widening of the Dakota Hogback into a plateau dividing the Rapid Creek drainage from Spring Creek.\\r\\nRapid City features a steppe climate (K?ppen BSk), and is part of USDA Hardiness zone 5a.[16] Its location makes its climate unlike both the higher elevations of the Black Hills and the Great Plains to the east. It is characterized by long arid summers and long dry winters, with short but distinct spring and autumn seasons. Precipitation averages 16.3 inches or 414.0 millimetres annually, but has historically ranged from 9.12 inches or 231.6 millimetres in 1974 to 27.70 inches or 703.6 millimetres in 1946.[17][18]\\r\\nWinters are cold and dry, with December, with a daily average temperature of 24.9?F or ?3.9?C, being the coldest month in recent years; however, chinook winds can warm temperatures above 50?F or 10?C, doing so on average about 21 times from December to February. Temperature inversions, however, occasionally produce warmer temperatures in the Black Hills. On average, highs do not climb above freezing on 42 days, while the low temperature reaches 0?F or ?17.8?C on an average of seventeen nights.[17] Snowfall is frequent but usually not heavy; March and April are typically the snowiest months, and the seasonal total averages 41 inches or 1.04 metres, although historically ranging from 16.9 inches or 0.43 metres during 1980ÿ81 to 80.9 inches or 2.05 metres during 1985ÿ86. Extensive snow cover does not remain for long, with only nine days seasonally with 5 inches or 0.13 metres or more on the ground.[18] Measurable snow has occurred in every month except July.[17]\\r\\nCompared to locations in the east, the area warms rather gradually early in the year, with the last measurable snow typically occurring in late April and precipitation totals beginning to increase; May snow occurs several times per decade. Toward the middle of the year, storms typically develop over the Black Hills during the afternoon and move onto the plains in the evening. Only April through June have observed calendar-day precipitation amounts exceeding 3 inches or 76.2 millimetres, and June 15, 1963, with 3.78 inches or 96.0 millimetres, holds the single-day rainfall record;[citation needed] the record-wettest month is May 1996 with 8.18 inches or 207.8 millimetres. However, Rapid City still sees an average of twenty clear to partly cloudy days[19] and 67 percent of its possible sunshine in June.[20] This is the traditional \\"flood\\" season for Rapid and other creeks in the Eastern Hills. Temperatures warm rapidly as summer approaches.\\r\\nSummer in Rapid City is relatively nice, relatively dry, and relatively sunny. July is the warmest month of the year, having a daily average temperature of 87.1?F (30.6?C). There is an average of 34 days with 90?F (32.2?C)+ highs and 5.1 with 100?F (37.8?C)+ highs.[18] Due to the elevation and aridity, lows rarely remain at or above 70?F (21.1?C) and during July and August fall to or below 50?F or 10?C on an average 7.6 days.[17] Rapid City records an average of nine thunderstorm days in August,[19] but only 1.56 inches or 39.6 millimetres of rain in that month.\\r\\nFall is a precipitous transition season, with the average first freeze in Rapid City is October 4 and late August through September in the Black Hills. The Rapid City area's first snowfall is usually in October, although higher elevations sometimes receive significant snow in September. Occasional cold fronts moving through the area bring blustery northwest winds.\\r\\nSunshine is abundant in the region in all months except December, averaging 2850 hours, 64% of the possible total, per year.[20]\\r\\nRapid City holds a record for an extreme temperature drop of 47?F or 26.1?C in five minutes on January 10, 1911, from 60?F or 15.6?C to 13?F or ?10.6?C.[21] Official extreme temperatures range from ?31?F or ?35.0?C on February 2, 1996 up to 111?F or 43.9?C on July 15, 2006; the record low daily maximum is ?18?F or ?27.8?C on February 2, 1989, while the record high daily minimum is 75?F or 23.9?C on July 8, 1985 and July 28, 1960.[22]\\r\\nAs of the census[4] of 2010, there were 67,956 people, 28,586 households, and 16,957 families residing in the city. The population density was 1,226.4 inhabitants per square mile (473.5/km2). There were 30,254 housing units at an average density of 546.0 per square mile (210.8/km2). The racial makeup of the city was 80.4% White, 1.1% African American, 12.4% Native American, 1.0% Asian, 0.1% Pacific Islander, 0.7% from other races, and 4.1% from two or more races. Hispanic or Latino of any race were 4.1% of the population.\\r\\nThere were 28,586 households of which 29.9% had children under the age of 18 living with them, 41.2% were married couples living together, 13.1% had a female householder with no husband present, 5.1% had a male householder with no wife present, and 40.7% were non-families. 32.9% of all households were made up of individuals and 11.1% had someone living alone who was 65 years of age or older. The average household size was 2.29 and the average family size was 2.90.\\r\\nThe median age in the city was 35.6 years. 23.9% of residents were under the age of 18; 10.6% were between the ages of 18 and 24; 25.7% were from 25 to 44; 25% were from 45 to 64; and 14.5% were 65 years of age or older. The gender makeup of the city was 49.5% male and 50.5% female.[26]\\r\\nAs of the census of 2000, there were 59,607 people, 23,969 households, and 15,220 families residing in the city. The population density was 1,336.7 people per square mile (516.1/km2). There were 25,096 housing units at an average density of 562.8 per square mile (217.3/km2).[15] The racial makeup of the city was 84.33% White, 0.97% African American, 10.14% Native American, 1.00% Asian, 0.06% Pacific Islander, 0.73% from other races, and 2.77% from two or more races.[27] Hispanic or Latino of any race were 2.77% of the population.[27]\\r\\nThere were 23,969 households out of which 31.2% had children under the age of 18 living with them, 46.7% were married couples living together, 12.6% had a female householder with no husband present, and 36.5% were non-families. 29.4% of all households were made up of individuals and 10.0% had someone living alone who was 65 years of age or older. The average household size was 2.39 and the average family size was 2.96.[27]\\r\\nIn the city, the population was spread out with 25.3% under the age of 18, 11.8% from 18 to 24, 28.7% from 25 to 44, 20.9% from 45 to 64, and 13.2% who were 65 years of age or older. The median age was 35 years. For every 100 females there were 96.2 males. For every 100 females age 18 and over, there were 93.6 males.[26]\\r\\nAs of 2000 the median income for a household in the city was $35,978, and the median income for a family was $44,818. Males had a median income of $30,985 versus $21,913 for females. The per capita income for the city was $19,445. About 9.4% of families and 12.7% of the population were below the poverty line, including 17.6% of those under age 18 and 6.9% of those age 65 or over.\\r\\nRapid City is a major medical care center for a five-state region, centered around the Rapid City Regional Hospital and the Indian Health Service's Sioux San Hospital. Other smaller, independent medical facilities have been established in the area, including the Black Hills Surgery Center, The Heart Doctors, The Spine Center at Rapid City, Setliff Sinus Institute, Black Hills Eye Institute and Regional Behavioral Healthcare. Two Veterans Affairs hospitals are located nearby at Fort Meade, and Hot Springs. Emergency medical services (EMS) are provided by the Rapid City Fire Department. Emergency medical transportation by rotor and fixed wing aircraft is provided by Black Hills Life Flight, operated by Air Methods Corp. based in Denver, CO. Rapid City is also home to a number of non-profit public health organizations that engage in survey and clinic research, epidemiology, and area-based health promotion disease prevention. The Health Education and Promotion Council and Black Hills Center for American Indian Health are two notable non-profit organizations.\\r\\nRapid City institutions of higher education include the South Dakota School of Mines and Technology, Oglala Lakota College's He Sapa College Center, Black Hills State University - Rapid City University Center (includes classes and degrees through five other South Dakota post-secondary Institutions), National American University, Western Dakota Technical Institute, Black Hills Beauty College, John Witherspoon College, and several small sectarian preacher training schools. Black Hills State University is located in nearby Spearfish and offers several classes in Rapid City. The South Dakota state nurse training program is also based in Rapid City. There are two public high schools in the city, Central High School and Stevens High School.\\r\\nIn 2013, 26.6 percent of Rapid City residents 25 years or over had earned a bachelor's degree or higher.[28] This is on par with the average educational attainment in the United States. The highest rates of educational attainment in South Dakota can be found in metropolitan areas of Rapid City and Sioux Falls.\\r\\nThe local public schools fall under the Rapid City Area Schools school district. There are three high schools within the district. They are Central High School, Stevens High School and the newly renovated Rapid City High School, which also houses the Performing Arts Center. The middle schools include newly founded East Middle School, North Middle School, South Middle School, Southwest Middle School, and West Middle School. There are 16 elementary schools within the district. These are Black Hawk, Canyon Lake, Corral Drive, General Beadle, Grandview, Horace Mann, Kibben Kuster, Knollwood Heights, Meadowbrook, Pinedale, Rapid Valley, Robbinsdale, South Canyon, South Park, Valley View, and Woodrow Wilson.[29]\\r\\nThere are also various private schools in Rapid City. The city has four Christian high schools including Saint Thomas More, Rapid City Christian High School, Liberty Baptist Academy and Open Bible Christian School. Rapid City also has various private grade schools including St. Paul's Lutheran School of the WELS.[30]\\r\\nBecause of the importance of tourism in the area, and its extensive market area, Rapid City has many cultural resources usually found only in much larger urban areas. Among these are:\\r\\nRapid City also has a large amount of public sculpture on display in many parts of the city. The most visible is \\"The City of Presidents\\" ÿ a series of life-sized bronze statues representing each of the American presidents. The statues are located on street corners in the downtown area. Five South Dakota artists created the statues: Edward E. Hlavka, Lee Leuning, John Lopez, James Michael Maher, and James Van Nuys.[41] These statues are being erected by public subscription over a ten-year period between 2000 and 2010.\\r\\nRapid City has three sister cities, as designated by Sister Cities International:\\r\\nRapid City Nikko City Sister City Association\\r\\nRapid City's economy is diverse, but has only a moderate amount of industry. Heavy and medium industrial activities include a Portland cement plant (constructed and owned for 84 years[42] by the State of South Dakota and sold in 2003 to GCC, a Mexican-based conglomerate), Black Hills Ammunition an ammunition and reloading supplies manufacturing company, several custom sawmills, a lime plant, a computer peripheral component manufacturing plant, and several farm and ranch equipment manufacturers. Of particular note, Rapid City is the center for the manufacture of Black Hills gold jewelry, a popular product with tourists and Westerners in general. Rapid City is also the location of the only manufacturer of stamping machines used for the labeling of plywood and chipboard products.\\r\\nAlthough most gold mining has ceased in the Black Hills and was never done in or near Rapid City, mining of sand and gravel, as well as the raw materials for lime and Portland cement (including chemical-grade limestone, taconite iron ore, and gypsum) remains an important part of the economy.\\r\\nThe largest sector of the Rapid City economy is government services, including local, state, and federal. Major employers include Ellsworth Air Force Base,[43] home of the 28th Bomb Wing flying the B-1B long-range bomber; the Army National Guard based at Camp Rapid and hosting annual exercises in the Black Hills drawing troops from five to ten states; and various federal agencies including the National Park Service, US Forest Service, and Indian Health Service.\\r\\nThe Rapid City Regional Hospital Healthcare System covers one of the largest expansions of territory in the United States. The health care sector employs over 8,000 persons in the Rapid City area.[43]\\r\\nTourism is also a major portion of the Rapid City economy,[43] due to the proximity of Mount Rushmore, Sturgis, home of the Sturgis Motorcycle Rally, Deadwood, and other attractions in the Black Hills. Rapid City is the major source of services for the Motorcycle Rally, and the Rally's demand for motel rooms, camp sites, and other services for tourists during the first week of August means that Rapid City has the capacity to host large conventions and large numbers of tourists year-round. Various minor tourist attractions, including wildlife parks, specialty shops, caves, water parks, private museums, and other businesses are found in and near Rapid City.\\r\\nOther economic sectors include financial service and investing companies such as Waddell and Reed, Citibank, WaMu, Merrill Lynch, and Northwestern Mutual. Rapid City is the headquarters for Assurant Insurance's pre-need division and Rapid City has a strong medical services sector, and institutions of higher education. Rapid City is also the major market town for much of five states, drawing commerce from more than half of South Dakota, and large portions of North Dakota, Montana, Wyoming, and the Nebraska Panhandle.\\r\\nThe real compound annual growth rate of the gross domestic product of the Rapid City Metropolitan Statistical Area was 2.6% for 2001ÿ2013.[44]\\r\\nRapid City is a major transportation hub for the Northern Plains. Rapid City Regional Airport provides flights to the airline hub cities of Denver, Minneapolis, Salt Lake City, Dallas-Fort Worth, Las Vegas, Phoenix/Mesa, Houston, Atlanta and Chicago. The airport also has extensive General Aviation operations, including wildfire fighting activities and medical flight support to Rapid City medical facilities and Indian Health Service operations in the Dakotas.\\r\\nHistorically, Rapid City was served by three railroads. Presently, the city is served by the Rapid City, Pierre and Eastern Railroad (RCP&E). In addition to Rapid City, the RCP&E serves the Northern Black Hills and run east to Minnesota and south through Nebraska to connect with major transcontinental railroads Burlington Northern Santa Fe and Union Pacific. South Dakota does not have Amtrak service, one of the few states that doesn't.\\r\\nRapid City's central location allows easy transport of products to both coasts, and trucking is a major business activity in the city. Improved connections with Denver and I-80 to the south, via the Heartland Expressway now under construction will primarily benefit local trucking.\\r\\nRapid City's location on the boundary of the Western and Eastern power grids, together with the hydroelectric plants of the Mainstem Dams on the Missouri River and the large coal fields and power plants of the Powder River Basin of Wyoming make it one of the points where the two national power grids connect with each other, allowing switching of electrical power from east to west and vice versa. Rapid City previously had its own coal-fired power plant before Federal regulations forced it and many other coal plants in the area such as power stations near Gillette, Wyoming, to shut down. The Ben French power station located within city boundaries shut down September 2012, more than 2 years ahead of its scheduled shut down. Rapid City now obtains much of its power from both the Missouri dams and importing it from elsewhere. Electrical rates used to be considered relatively low until the shut down of the coal plants, so have progressively climbed the last several years as a lack of local power sources means massive expenses to import it from greater distances.\\r\\nRapid City obtains most of its water supply from Rapid Creek and the alluvial aquifers associated with the creek, owning significant water rights in Pactola Reservoir located some 15 miles (24?km) west of the city, but does also obtain water from some springs in the vicinity, and has the ability to draw water from deep formations that receive water from recharge in areas of the Black Hills where the formations come to the surface. The heavy dependence on shallow alluvial aquifers is of some concern to planners, as most suburbs of Rapid City use septic systems for domestic sewage treatment. However, water supplies remain relatively good for future growth.\\r\\nRapid City has limited city-to-city bus service along I-90, but many charter bus services operate in the area, and connect Rapid City and Deadwood with cities in Colorado, Nebraska, and Iowa. Rapid City does have a municipally-owned bus service with multiple bus stops and a headquarters in the city.\\r\\nThe estimated 2013 population of the Rapid City Metropolitan Statistical Area (Pennington County, Meade County and Custer County) was 141,131.[45] Most cities and towns in the Black Hills and the surrounding plains have a significant percentage of their population who commute to and from Rapid City, and many residents of Rapid City work in outlying towns. Among the nearer suburbs in Pennington and Meade Counties:\\r\\nPeople who have lived, resided, or were born in Rapid City, South Dakota.","input":"What county is rapid city south dakota in?"},{"output":"Aristotle","context":"","input":"Who introduced the earliest belief that life was spontaneously generated from nonliving matter?"},{"output":"Nikola Tesla","context":"Alternating current (AC) is an electric current which periodically reverses direction, in contrast to direct current (DC) which flows only in one direction. Alternating current is the form in which electric power is delivered to businesses and residences, and it is the form of electrical energy that consumers typically use when they plug kitchen appliances, televisions and electric lamps into a wall socket. A common source of DC power is a battery cell in a flashlight. The abbreviations AC and DC are often used to mean simply alternating and direct, as when they modify current or voltage.[1][2]\\r\\nThe usual waveform of alternating current in most electric power circuits is a sine wave. In certain applications, different waveforms are used, such as triangular or square waves. Audio and radio signals carried on electrical wires are also examples of alternating current. These types of alternating current carry information encoded (or modulated) onto the AC signal, such as sound (audio) or images (video). These currents typically alternate at higher frequencies than those used in power transmission.\\r\\nElectrical energy is distributed as alternating current because AC voltage may be increased or decreased with a transformer. This allows the power to be transmitted through power lines efficiently at high voltage, which reduces the energy lost as heat due to resistance of the wire, and transformed to a lower, safer, voltage for use. Use of a higher voltage leads to significantly more efficient transmission of power. The power losses (\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nP\\r\\n\\r\\n\\r\\nL\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle P_{\\\\rm {L}}}\\r\\n\\r\\n) in a conductor are a product of the square of the current (I) and the resistance (R) of the conductor, described by the formula\\r\\nThis means that when transmitting a fixed power on a given wire, if the current is halved (i.e. the voltage is doubled), the power loss will be four times less.\\r\\nThe power transmitted is equal to the product of the current and the voltage (assuming no phase difference); that is,\\r\\nConsequently, power transmitted at a higher voltage requires less loss-producing current than for the same power at a lower voltage. Power is often transmitted at hundreds of kilovolts, and transformed to 100?V ÿ 240?V for domestic use.\\r\\nHigh voltages have disadvantages, such as the increased insulation required, and generally increased difficulty in their safe handling. In a power plant, energy is generated at a convenient voltage for the design of a generator, and then stepped up to a high voltage for transmission. Near the loads, the transmission voltage is stepped down to the voltages used by equipment. Consumer voltages vary somewhat depending on the country and size of load, but generally motors and lighting are built to use up to a few hundred volts between phases. The voltage delivered to equipment such as lighting and motor loads is standardized, with an allowable range of voltage over which equipment is expected to operate. Standard power utilization voltages and percentage tolerance vary in the different mains power systems found in the world. High-voltage direct-current (HVDC) electric power transmission systems have become more viable as technology has provided efficient means of changing the voltage of DC power. HVDC systems, however, tend to be more expensive and less efficient over shorter distances than transformers.[citation needed] Transmission with high voltage direct current was not feasible in the early days of electric power transmission, as there was then no economically viable way to step down the voltage of DC for end user applications such as lighting incandescent bulbs.\\r\\nThree-phase electrical generation is very common. The simplest way is to use three separate coils in the generator stator, physically offset by an angle of 120 (one-third of a complete 360 phase) to each other. Three current waveforms are produced that are equal in magnitude and 120 out of phase to each other. If coils are added opposite to these (60 spacing), they generate the same phases with reverse polarity and so can be simply wired together. In practice, higher \\"pole orders\\" are commonly used. For example, a 12-pole machine would have 36 coils (10 spacing). The advantage is that lower rotational speeds can be used to generate the same frequency. For example, a 2-pole machine running at 3600?rpm and a 12-pole machine running at 600?rpm produce the same frequency; the lower speed is preferable for larger machines. If the load on a three-phase system is balanced equally among the phases, no current flows through the neutral point. Even in the worst-case unbalanced (linear) load, the neutral current will not exceed the highest of the phase currents. Non-linear loads (e.g. the switch-mode power supplies widely used) may require an oversized neutral bus and neutral conductor in the upstream distribution panel to handle harmonics. Harmonics can cause neutral conductor current levels to exceed that of one or all phase conductors.\\r\\nFor three-phase at utilization voltages a four-wire system is often used. When stepping down three-phase, a transformer with a Delta (3-wire) primary and a Star (4-wire, center-earthed) secondary is often used so there is no need for a neutral on the supply side. For smaller customers (just how small varies by country and age of the installation) only a single phase and neutral, or two phases and neutral, are taken to the property. For larger installations all three phases and neutral are taken to the main distribution panel. From the three-phase main panel, both single and three-phase circuits may lead off. Three-wire single-phase systems, with a single center-tapped transformer giving two live conductors, is a common distribution scheme for residential and small commercial buildings in North America. This arrangement is sometimes incorrectly referred to as \\"two phase\\". A similar method is used for a different reason on construction sites in the UK. Small power tools and lighting are supposed to be supplied by a local center-tapped transformer with a voltage of 55?V between each power conductor and earth. This significantly reduces the risk of electric shock in the event that one of the live conductors becomes exposed through an equipment fault whilst still allowing a reasonable voltage of 110?V between the two conductors for running the tools.\\r\\nA third wire, called the bond (or earth) wire, is often connected between non-current-carrying metal enclosures and earth ground. This conductor provides protection from electric shock due to accidental contact of circuit conductors with the metal chassis of portable appliances and tools. Bonding all non-current-carrying metal parts into one complete system ensures there is always a low electrical impedance path to ground sufficient to carry any fault current for as long as it takes for the system to clear the fault. This low impedance path allows the maximum amount of fault current, causing the overcurrent protection device (breakers, fuses) to trip or burn out as quickly as possible, bringing the electrical system to a safe state. All bond wires are bonded to ground at the main service panel, as is the neutral/identified conductor if present.\\r\\nThe frequency of the electrical system varies by country and sometimes within a country; most electric power is generated at either 50 or 60?hertz. Some countries have a mixture of 50?Hz and 60?Hz supplies, notably electricity power transmission in Japan. A low frequency eases the design of electric motors, particularly for hoisting, crushing and rolling applications, and commutator-type traction motors for applications such as railways. However, low frequency also causes noticeable flicker in arc lamps and incandescent light bulbs. The use of lower frequencies also provided the advantage of lower impedance losses, which are proportional to frequency. The original Niagara Falls generators were built to produce 25?Hz power, as a compromise between low frequency for traction and heavy induction motors, while still allowing incandescent lighting to operate (although with noticeable flicker). Most of the 25?Hz residential and commercial customers for Niagara Falls power were converted to 60?Hz by the late 1950s, although some[which?] 25?Hz industrial customers still existed as of the start of the 21st century. 16.7?Hz power (formerly 16 2/3?Hz) is still used in some European rail systems, such as in Austria, Germany, Norway, Sweden and Switzerland. Off-shore, military, textile industry, marine, aircraft, and spacecraft applications sometimes use 400?Hz, for benefits of reduced weight of apparatus or higher motor speeds. Computer mainframe systems were often powered by 400?Hz or 415?Hz for benefits of ripple reduction while using smaller internal AC to DC conversion units.[3] In any case, the input to the M-G set is the local customary voltage and frequency, variously 200?V (Japan), 208?V, 240?V (North America), 380?V, 400?V or 415?V (Europe), and variously 50?Hz or 60?Hz.\\r\\nA direct current flows uniformly throughout the cross-section of a uniform wire. An alternating current of any frequency is forced away from the wire's center, toward its outer surface. This is because the acceleration of an electric charge in an alternating current produces waves of electromagnetic radiation that cancel the propagation of electricity toward the center of materials with high conductivity. This phenomenon is called skin effect. At very high frequencies the current no longer flows in the wire, but effectively flows on the surface of the wire, within a thickness of a few skin depths. The skin depth is the thickness at which the current density is reduced by 63%. Even at relatively low frequencies used for power transmission (50?Hz ÿ 60?Hz), non-uniform distribution of current still occurs in sufficiently thick conductors. For example, the skin depth of a copper conductor is approximately 8.57?mm at 60?Hz, so high current conductors are usually hollow to reduce their mass and cost. Since the current tends to flow in the periphery of conductors, the effective cross-section of the conductor is reduced. This increases the effective AC resistance of the conductor, since resistance is inversely proportional to the cross-sectional area. The AC resistance often is many times higher than the DC resistance, causing a much higher energy loss due to ohmic heating (also called I2R loss).\\r\\nFor low to medium frequencies, conductors can be divided into stranded wires, each insulated from one another, and the relative positions of individual strands specially arranged within the conductor bundle. Wire constructed using this technique is called Litz wire. This measure helps to partially mitigate skin effect by forcing more equal current throughout the total cross section of the stranded conductors. Litz wire is used for making high-Q inductors, reducing losses in flexible conductors carrying very high currents at lower frequencies, and in the windings of devices carrying higher radio frequency current (up to hundreds of kilohertz), such as switch-mode power supplies and radio frequency transformers.\\r\\nAs written above, an alternating current is made of electric charge under periodic acceleration, which causes radiation of electromagnetic waves. Energy that is radiated is lost. Depending on the frequency, different techniques are used to minimize the loss due to radiation.\\r\\nAt frequencies up to about 1?GHz, pairs of wires are twisted together in a cable, forming a twisted pair. This reduces losses from electromagnetic radiation and inductive coupling. A twisted pair must be used with a balanced signalling system, so that the two wires carry equal but opposite currents. Each wire in a twisted pair radiates a signal, but it is effectively cancelled by radiation from the other wire, resulting in almost no radiation loss.\\r\\nCoaxial cables are commonly used at audio frequencies and above for convenience. A coaxial cable has a conductive wire inside a conductive tube, separated by a dielectric layer. The current flowing on the surface of the inner conductor is equal and opposite to the current flowing on the inner surface of the outer tube. The electromagnetic field is thus completely contained within the tube, and (ideally) no energy is lost to radiation or coupling outside the tube. Coaxial cables have acceptably small losses for frequencies up to about 5?GHz. For microwave frequencies greater than 5?GHz, the losses (due mainly to the electrical resistance of the central conductor) become too large, making waveguides a more efficient medium for transmitting energy. Coaxial cables with an air rather than solid dielectric are preferred as they transmit power with lower loss.\\r\\nWaveguides are similar to coaxial cables, as both consist of tubes, with the biggest difference being that the waveguide has no inner conductor. Waveguides can have any arbitrary cross section, but rectangular cross sections are the most common. Because waveguides do not have an inner conductor to carry a return current, waveguides cannot deliver energy by means of an electric current, but rather by means of a guided electromagnetic field. Although surface currents do flow on the inner walls of the waveguides, those surface currents do not carry power. Power is carried by the guided electromagnetic fields. The surface currents are set up by the guided electromagnetic fields and have the effect of keeping the fields inside the waveguide and preventing leakage of the fields to the space outside the waveguide. Waveguides have dimensions comparable to the wavelength of the alternating current to be transmitted, so they are only feasible at microwave frequencies. In addition to this mechanical feasibility, electrical resistance of the non-ideal metals forming the walls of the waveguide cause dissipation of power (surface currents flowing on lossy conductors dissipate power). At higher frequencies, the power lost to this dissipation becomes unacceptably large.\\r\\nAt frequencies greater than 200?GHz, waveguide dimensions become impractically small, and the ohmic losses in the waveguide walls become large. Instead, fiber optics, which are a form of dielectric waveguides, can be used. For such frequencies, the concepts of voltages and currents are no longer used.\\r\\nAlternating currents are accompanied (or caused) by alternating voltages. An AC voltage v can be described mathematically as a function of time by the following equation:\\r\\nwhere\\r\\nThe peak-to-peak value of an AC voltage is defined as the difference between its positive peak and its negative peak. Since the maximum value of \\r\\n\\r\\n\\r\\n\\r\\nsin\\r\\n?\\r\\n(\\r\\nx\\r\\n)\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\sin(x)}\\r\\n\\r\\n is +1 and the minimum value is ?1, an AC voltage swings between \\r\\n\\r\\n\\r\\n\\r\\n+\\r\\n\\r\\nV\\r\\n\\r\\n\\r\\np\\r\\ne\\r\\na\\r\\nk\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle +V_{\\\\rm {peak}}}\\r\\n\\r\\n and \\r\\n\\r\\n\\r\\n\\r\\n?\\r\\n\\r\\nV\\r\\n\\r\\n\\r\\np\\r\\ne\\r\\na\\r\\nk\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle -V_{\\\\rm {peak}}}\\r\\n\\r\\n. The peak-to-peak voltage, usually written as \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nV\\r\\n\\r\\n\\r\\np\\r\\np\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle V_{\\\\rm {pp}}}\\r\\n\\r\\n or \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nV\\r\\n\\r\\n\\r\\nP\\r\\n?\\r\\nP\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle V_{\\\\rm {P-P}}}\\r\\n\\r\\n, is therefore \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nV\\r\\n\\r\\n\\r\\np\\r\\ne\\r\\na\\r\\nk\\r\\n\\r\\n\\r\\n\\r\\n?\\r\\n(\\r\\n?\\r\\n\\r\\nV\\r\\n\\r\\n\\r\\np\\r\\ne\\r\\na\\r\\nk\\r\\n\\r\\n\\r\\n\\r\\n)\\r\\n=\\r\\n2\\r\\n\\r\\nV\\r\\n\\r\\n\\r\\np\\r\\ne\\r\\na\\r\\nk\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle V_{\\\\rm {peak}}-(-V_{\\\\rm {peak}})=2V_{\\\\rm {peak}}}\\r\\n\\r\\n.\\r\\nThe relationship between voltage and the power delivered is\\r\\nRather than using instantaneous power, \\r\\n\\r\\n\\r\\n\\r\\np\\r\\n(\\r\\nt\\r\\n)\\r\\n\\r\\n\\r\\n{\\\\displaystyle p(t)}\\r\\n\\r\\n, it is more practical to use a time averaged power (where the averaging is performed over any integer number of cycles). Therefore, AC voltage is often expressed as a root mean square (RMS) value, written as \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nV\\r\\n\\r\\n\\r\\nr\\r\\nm\\r\\ns\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle V_{\\\\rm {rms}}}\\r\\n\\r\\n, because\\r\\nBelow it is assumed an AC waveform (with no DC component).\\r\\nTo illustrate these concepts, consider a 230?V AC mains supply used in many countries around the world. It is so called because its root mean square value is 230?V. This means that the time-averaged power delivered is equivalent to the power delivered by a DC voltage of 230?V. To determine the peak voltage (amplitude), we can rearrange the above equation to:\\r\\nFor 230?V AC, the peak voltage \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nV\\r\\n\\r\\n\\r\\np\\r\\ne\\r\\na\\r\\nk\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle V_{\\\\mathrm {peak} }}\\r\\n\\r\\n is therefore \\r\\n\\r\\n\\r\\n\\r\\n230\\r\\nV\\r\\nG\\r\\n\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle 230V\\\\times {\\\\sqrt {2}}}\\r\\n\\r\\n, which is about 325?V. During the course of one cycle the voltage rises from zero to 325?V, falls through zero to -325?V, and returns to zero.\\r\\nAlternating current is used to transmit information, as in the cases of telephone and cable television. Information signals are carried over a wide range of AC frequencies. POTS telephone signals have a frequency of about 3 kHz, close to the baseband audio frequency. Cable television and other cable-transmitted information currents may alternate at frequencies of tens to thousands of megahertz. These frequencies are similar to the electromagnetic wave frequencies often used to transmit the same types of information over the air.\\r\\nThe first alternator to produce alternating current was a dynamo electric generator based on Michael Faraday's principles constructed by the French instrument maker Hippolyte Pixii in 1832.[4] Pixii later added a commutator to his device to produce the (then) more commonly used direct current. The earliest recorded practical application of alternating current is by Guillaume Duchenne, inventor and developer of electrotherapy. In 1855, he announced that AC was superior to direct current for electrotherapeutic triggering of muscle contractions.[5] Alternating current technology had first developed in Europe due to the work of Guillaume Duchenne (1850s), the Hungarian Ganz Works company (1870s), and in the 1880s: Sebastian Ziani de Ferranti, Lucien Gaulard, and Galileo Ferraris.\\r\\nIn 1876, Russian engineer Pavel Yablochkov invented a lighting system where sets of induction coils were installed along a high voltage AC line. Instead of changing voltage, the primary windings transferred power to the secondary windings which were connected to one or several 'electric candles' (arc lamps) of his own design,[6][7] used to keep the failure of one lamp from disabling the entire circuit.[6] In 1878, the Ganz factory, Budapest, Hungary, began manufacturing equipment for electric lighting and, by 1883, had installed over fifty systems in Austria-Hungary. Their AC systems used arc and incandescent lamps, generators, and other equipment.[8]\\r\\nAlternating current systems can use transformers to change voltage from low to high level and back, allowing generation and consumption at low voltages but transmission, possibly over great distances, at high voltage, with savings in the cost of conductors and energy losses. A bipolar open-core power transformer developed by Lucien Gaulard and John Dixon Gibbs was demonstrated in London in 1881, and attracted the interest of Westinghouse. They also exhibited the invention in Turin in 1884. However these early induction coils with open magnetic circuits are inefficient at transferring power to loads. Until about 1880, the paradigm for AC power transmission from a high voltage supply to a low voltage load was a series circuit. Open-core transformers with a ratio near 1:1 were connected with their primaries in series to allow use of a high voltage for transmission while presenting a low voltage to the lamps. The inherent flaw in this method was that turning off a single lamp (or other electric device) affected the voltage supplied to all others on the same circuit. Many adjustable transformer designs were introduced to compensate for this problematic characteristic of the series circuit, including those employing methods of adjusting the core or bypassing the magnetic flux around part of a coil.[9] The direct current systems did not have these drawbacks, giving it significant advantages over early AC systems.\\r\\nIn the autumn of 1884, Kroly Zipernowsky, Ott܇ Blthy and Miksa Dri (ZBD), three engineers associated with the Ganz factory, determined that open-core devices were impractical, as they were incapable of reliably regulating voltage.[10] In their joint 1885 patent applications for novel transformers (later called ZBD transformers), they described two designs with closed magnetic circuits where copper windings were either a wound around iron wire ring core or b)?surrounded by iron wire core.[9] In both designs, the magnetic flux linking the primary and secondary windings traveled almost entirely within the confines of the iron core, with no intentional path through air (see toroidal cores). The new transformers were 3.4 times more efficient than the open-core bipolar devices of Gaulard and Gibbs.[11] The Ganz factory in 1884 shipped the world's first five high-efficiency AC transformers.[12] This first unit had been manufactured to the following specifications: 1,400 W, 40?Hz, 120:72 V, 11.6:19.4 A, ratio 1.67:1, one-phase, shell form.[12]\\r\\nThe ZBD patents included two other major interrelated innovations: one concerning the use of parallel connected, instead of series connected, utilization loads, the other concerning the ability to have high turns ratio transformers such that the supply network voltage could be much higher (initially 1400?V to 2000?V) than the voltage of utilization loads (100?V initially preferred).[13][14] When employed in parallel connected electric distribution systems, closed-core transformers finally made it technically and economically feasible to provide electric power for lighting in homes, businesses and public spaces.[15][16] The other essential milestone was the introduction of 'voltage source, voltage intensive' (VSVI) systems'[17] by the invention of constant voltage generators in 1885.[18] Ott܇ Blthy also invented the first AC electricity meter.[19][20][21][22]\\r\\nThe AC power systems was developed and adopted rapidly after 1886 due to its ability to distribute electricity efficiently over long distances, overcoming the limitations of the direct current system. In 1886, the ZBD engineers designed the world's first power station that used AC generators to power a parallel-connected common electrical network, the steam-powered Rome-Cerchi power plant.[23] The reliability of the AC technology received impetus after the Ganz Works electrified a large European metropolis: Rome in 1886.[23]\\r\\nIn the UK, Sebastian de Ferranti, who had been developing AC generators and transformers in London since 1882, redesigned the AC system at the Grosvenor Gallery power station in 1886 for the London Electric Supply Corporation (LESCo) including alternators of his own design and transformer designs similar to Gaulard and Gibbs.[24] In 1890 he designed their power station at Deptford[25] and converted the Grosvenor Gallery station across the Thames into an electrical substation, showing the way to integrate older plants into a universal AC supply system.[26]\\r\\nIn the US William Stanley, Jr. designed one of the first practical devices to transfer AC power efficiently between isolated circuits. Using pairs of coils wound on a common iron core, his design, called an induction coil, was an early (1885) transformer. Stanley also worked on engineering and adapting European designs such as the Gaulard and Gibbs transformer for US entrepreneur George Westinghouse who started building AC systems in 1886. The spread of Westinghouse and other AC systems triggered a push back in late 1887 by Edison (a proponent of direct current) who attempted to discredit alternating current as too dangerous in a public campaign called the \\"War of Currents\\". In 1888 alternating current systems gained further viability with introduction of a functional AC motor, something these systems had lacked up till then. The design, an induction motor, was independently invented by Galileo Ferraris and Nikola Tesla (with Tesla's design being licensed by Westinghouse in the US). This design was further developed into the modern practical three-phase form by Mikhail Dolivo-Dobrovolsky and Charles Eugene Lancelot Brown.[27]\\r\\nThe Ames Hydroelectric Generating Plant (spring of 1891) and the original Niagara Falls Adams Power Plant (August 25, 1895) were among the first hydroelectric alternating current power plants. The first long distance transmission of single-phase electricity was from a hydroelectric generating plant in Oregon at Willamette Falls which in 1890 sent power fourteen miles downriver to downtown Portland for street lighting.[28] In 1891, a second transmission system was installed in Telluride Colorado.[29] The San Antonio Canyon Generator was the third commercial single-phase hydroelectric AC power plant in the United States to provide long-distance electricity. It was completed on December 31, 1892 by Almarian William Decker to provide power to the city of Pomona, California which was 14 miles away. In 1893 he next designed the first commercial three-phase power plant in the United States using alternating current was the hydroelectric Mill Creek No. 1 Hydroelectric Plant near Redlands, California. Decker's design incorporated 10?kV three-phase transmission and established the standards for the complete system of generation, transmission and motors used today. The Jaruga Hydroelectric Power Plant in Croatia was set in operation on 28 August 1895. The two generators (42?Hz, 550?kW each) and the transformers were produced and installed by the Hungarian company Ganz. The transmission line from the power plant to the City of ?ibenik was 11.5 kilometers (7.1?mi) long on wooden towers, and the municipal distribution grid 3000?V/110?V included six transforming stations. Alternating current circuit theory developed rapidly in the latter part of the 19th and early 20th century. Notable contributors to the theoretical basis of alternating current calculations include Charles Steinmetz, Oliver Heaviside, and many others.[30][31] Calculations in unbalanced three-phase systems were simplified by the symmetrical components methods discussed by Charles Legeyt Fortescue in 1918.","input":"Who developed the first alternating current electric system?"},{"output":"Rotta Desilijic Tiure or Rotta the Huttlet","context":"The Hutts are a fictional alien race in the Star Wars universe. They appear in The Phantom Menace, Return of the Jedi and The Clone Wars, as well as the special edition release of A New Hope. They also appear in various Star Wars games, including those based on the movies, and the Knights of the Old Republic series. None of these are very friendly and all are criminally involved.[1] In the comic book series Tales of the Jedi: Golden Age of the Sith and Tales of the Jedi: The Fall of the Sith Empire, however, there is a Hutt character named Aarrba who is sympathetic to the main characters, Gav and Jori Daragon.\\r\\n\\r\\n\\r\\nAccording to the movie, the Hutts originated on a forest planet called Varl, in a binary star system consisting of the two stars Evona and Ardos, which the Hutts worshiped as gods. According to Hutt legend, Evona was absorbed by a black hole, and Ardos collapsed on itself over grief for its mate. Since the Hutts survived the deaths of their gods, they believed they had become gods, hence their egocentrism. Scientists believe the Hutts destroyed their world in a civil war.\\r\\nAfter Varl's devastation, the Hutts migrated to a planet called Evocar, and displaced the peaceful natives through canny business practices, even going so far as to evict them. The Hutts renamed their new planet Nal Hutta\\"Glorious Jewel\\" in Huttese. Nal Hutta is the capital of Hutt Space, the species' empire. The primary moon of Nal Hutta is Nar Shaddaa.\\r\\nBefore the establishment of the Old Republic, the Hutts were the dominant species in the galaxy, although they never built up an extensive empire; their dominance focused instead on trade and economic empires.\\r\\nAdult Hutts are shaped rather like extremely large shell-less gastropods (up to one thousand kilograms) with stubby arms, no rear limbs and numerous redundant internal organs. Locomotion is through a series of rippling contractions akin to a slug's locomotion. In the novelization of Return of the Jedi, it is mentioned that Hutts are born bipedal, but their \\"rump legs\\" fused together over time due to lack of movement. Hutts are naturally long-lived, with a lifespan of up to a thousand years, reproducing asexually and nursing their young in pouches not unlike marsupials. An infant Hutt, known as a Huttlet, is the size of an orange when born, and lives in the parent's pouch for five decades before becoming \\"fully developed.\\" Adolescents become adults when they reach the age of 130 years. Though traditionally referred to as males, all members of the species are hermaphroditic; personality type and gender roles are assumed voluntarily, or upon a viewer's deduction. Upon becoming pregnant, Hutts are referred to as female, although some Hutts do not accept this and choose to retain their masculine persona, whereas others alternate between male and female character.[2]\\r\\nHutt skin is extremely thick, and when combined with their redundant organs and tough flesh, can result in Hutts being able to survive direct blaster fire hits. Hutts are also inedible by most life forms, including Sarlacci, resistant to the Force due to their unique thought patterns, and are able to see the ultraviolet and infrared portions of the electromagnetic spectrum.[2]\\r\\nNal Hutta is ruled by the Clans of the Ancients, which is composed of leaders of the eldest clans on Nal Hutta. Many Hutts leave their home world to form kajidics, or criminal empires, under the control of the Clan. Hutts hold their families in very high regard except when leadership of the clan is available and will kill members of their families for personal advancement.\\r\\nIf a non-Hutt kills a Hutt, then it will usually result in a death-mark, or bounty, being put on the offending party. Luke Skywalker, Han Solo, and Princess Leia were the most famous recipients in their role in the death of Jabba the Hutt. The death mark against them lasted for about ten years before it was removed by Durga the Hutt during the Darksaber incident. Hutt grudges last a very long time, however, and the deathmark was reinstated by others after Durga's death.\\r\\nHutts do not generally reveal their family names to non-Hutts. Close subordinates, such as counselors, are very familiar with Huttese clan politics as they must be to advise and orchestrate attacks and business well; as such only a few Hutt clans are known by name. The two most prominent are Desilijic, the Clan of Jabba the Hutt, and Besadii, one of the most powerful before the death of Durga the Hutt.\\r\\nThe Hutts' native language, Huttese, is a lingua franca of galactic organized crime.\\r\\nThe language is a constructed language, with many distorted English words, most having the same syllables as the English. Its phonology is said to be based on the Quechua language.[3]\\r\\nNot only the Hutts speak Huttese. For example, all of the singers in the Max Rebo Band sing in Huttese. Bib Fortuna a non-Hutt but who works for Jabba the Hutt and many gangsters in the Star Wars galaxy also speak the language for economical purposes. C-3PO the protocol droid who is fluent in over 6 million forms of communication can also comprehend and speak fluent Huttese as seen in the films.\\r\\nArok was a masculine Hutt of the Hutt Grand Council, the ruling council on Nal Hutta, who discussed the decision about Ziro Desilijic Tiure's release. He was also present when Darth Maul and the Shadow Collective launched an attack on the Council's chambers. Arok had a smoking habit. He eventually became the leader of his Kajidic and earned a spot on the Clans of the Ancients.\\r\\nAruk Besadii Aora or Aruk the Hutt was a Hutt crime lord and former leader of the Besadii kajidic.[4] He was a physically large Hutt and refused to take orders from anybody. Aruk is the father of Durga Besadii Tai and when Durga was born with a large birthmark on his face, other Hutts told Aruk that he was impure and not worthy of being called a Hutt and implored him to kill his son, but Aruk was fond of the child and sensed that he would grow up to be a cunning and ruthless Huttthe perfect heir to his criminal empire. He also threatened to murder all who wished Durga killed and began to raise his child himself. Aruk provided Durga with a good education and he eventually became his father's apprentice. Aruk was considered by many as an \\"Old Fashioned Hutt\\"; one reason was because Jabba's fascination with scantily-clad humanoid females disgusted him and the other was his unwavering belief in the power of the Besadii kajidic. Aruk was killed when Teroenza poisoned his supply of nala tree frogs which he liked eating.\\r\\nBeldorion was a Hutt who trained to be a Jedi (Planet of Twilight) sometime before the Clone Wars (the only known Huttese Jedi). Beldorion journeyed to Nam Chorios with his fellow Jedi Taselda, ostensibly to investigate the Theran movement. When he arrived, Beldorion sensed that Nam Chorios itself was a potent nexus for the power of the Force. Therefore, Beldorion stayed and established himself as ruler of the planet, struggling for power with Taselda, who was also drawn in by Chorios' power. Beldorion became a pawn of the humanoid droch Dzym. He gave himself such titles as \\"Beldorion of the Ruby Eyes\\" and \\"Beldorion the Splendid.\\" With the Force and Dzym's help, Beldorion remained strong and youthful, his body all muscle, avoiding the corpulence and immobility of most Hutts his age. However, at the onset of the Clone Wars, Supreme Chancellor Palpatine used special emergency powers to send Seti Ashgad to Nam Chorios in a political expansionist movement. Seeing that Beldorion the Hutt had no real interest in ruling Nam Chorios so long as his desires were satisfied, Ashgad rose to become the planet's unofficial ruler. But Ashgad soon realized that Beldorion had only been a figurehead for a more insidious figure, Dzym.\\r\\nAbout thirteen years after the Battle of Yavin, Luke Skywalker and Leia Organa Solo traveled to Nam Chorios to meet with Ashgad. While there, Leia was taken prisoner and met Beldorion. While he held her captive, Beldorion told her stories of the ancient Jedi Masters such as Thon and Yoda, whose power he admired, if not their principles. Leia eventually escaped with Luke to disrupt Ashgad and Dzym's plan to unleash a plague throughout the sector. During the attempt to stop Ashgad, Leia was attacked by Beldorion. The old Hutt was all muscle and fire, and attacked with his lightsaber with astonishing quickness. Although Leia had not been trained extensively in lightsaber combat, she did have combat training and a keen insight into the flow of the Force and was able to defeat Beldorion.[5][6]\\r\\nBorga Besadii Diori or Borga the Hutt was the mother of the late Randa Besadii Diori and guardian of Gardulla the Younger and Decca Besadii Diori. She took control of the Besadii kajidic after Durga's death. During the Yuuzhan Vong War, she negotiated a truce between the Hutts and the Yuuzhan Vong to let the Hutts have a portion of some of their space. Although the truce was successful, little did Borga know, the Yuuzhan Vong would end up betraying her. Later, Borga negotiated with the New Republic to sell the information on the invaders' next attack. When the Yuuzhan Vong found out, they immediately attacked Hutt space. Borga led the Hutt defenses of Nal Hutta however she was no match for the Yuuzhan Vong who conquered Hutt Space, forcing a large number of Hutts to move to Tatooine. Borga and many other Hutts, however, remained on Nal Hutta as prisoners. She tried to persuade the Yuuzhan Vong to release her and her fellow captives but she was coldly turned away.\\r\\nHis Great Obesity, Durga Besadii Tai or Durga the Hutt was a Hutt and the successor of Aruk as head of the Besadii kajidic. Note also that he captured the Death Star's engineer and \\"hired\\" him to build him his own superlaser mechanism, which, before being destroyed in Hoth's asteroid belt, was known as Darksaber. A notable feature of Durga is his green birthmark that stretches along the side of his face.\\r\\nGradulla Besadii Diori or Gardulla the Hutt, later known as Gardulla the Elder or Gardulla the Besadii Elder, was one of the Hutt crime lords of Tatooine. Her assistant is Diva Funquita. She is best known for buying Shmi and Anakin Skywalker, then losing them to Watto, a junk dealer, whilst betting on the pod-races. Gardulla is a sometimes rival of Jabba the Hutt and appears briefly as his guest at the Podrace scene in The Phantom Menace. Gardulla also sponsors Podracers, including Gasgano. After the Boonta Eve Classic, Gardulla offered Watto a substantial sum to regain ownership of Anakin, but the Toydarian had already lost the boy to Qui-Gon Jinn.\\r\\nGardulla attempted to feed Jango Fett to her personal Krayt dragon, but was in turn killed by the bounty hunter by being pushed into the Krayt dragon's lair and devoured after being interrogated for information on the Bando Gora cult. Gardulla has a son, Gardulla the Younger and a daughter, Decca Besadii Diori.\\r\\nGorga Desilijic Aarrpo or Gorga the Hutt, is the nephew of Jabba the Hutt. He was referenced in the game Star Wars Bounty Hunter, posting several secondary bounties. Gorga was extremely angry at Big Gizz and Spiker, former Swoop riders for Jabba, dropped Jabba's urns on him and was very horrified and displeased that his uncle's ashes had blown away. While on Tatooine, a feminine natured Hutt named Anachro the H'uun caught Gorga's eye. Gorga found her to be beautiful. Unfortunately for him, Anachro was the daughter of Orko the H'uun, an enemy of his. Gorga hired Boba Fett to kill Bar-Kooda, a pirate kingpin that had been harassing Orko's freighters. Fett succeeded, and Gorga, Anachro, and Orko celebrated Gorga and Anachro's impending nuptials by eating Bar-Kooda's corpse. When Anachro was captured by slavers, Gorga hired Boba Fett to find her but Orko accused Gorga of staging her kidnapping and nearly tore each other apart, however Fett brought Anachro back safely and although, the both of them made a public apology towards the other, Gorga still despised his father-in-law.\\r\\nGorga later hired Fett once more to assassinate Orko, but when it was revealed Anachro was pregnant, he called off the assassination. However, Ry-Kooda, Bar-Kooda's brother, had murdered Orko in a particularly brutal fashion. Anachro accused Gorga of the murder, and in grief left him. Ry-Kooda then tried to kill Anachro but Gorga stopped him and Boba Fett ultimately killed Ry-Kooda. The excitement caused Anachro to give birth and the both of them reconciled and got back together.\\r\\nKossak the Hutt is a powerful businessman said to have lived around the same time as Xim the Despot and was directly responsible for Xim's defeat at The Third Battle of Vontor. What is known of this is that Kossak the Hutt had tricked the Klatooinians,Weequays,Vodrans and the Nikto into signing themselves into virtual slavery and that it was Kossak that used the Vodrans and Klatooinians during the final battle that ended the reign of Xim The Despot.\\r\\nJabba the Hutt is an antagonist who first appeared on film in Return of the Jedi, though was later added to the special edition of Star Wars Episode IV: A New Hope. Jabba was originally portrayed by an immense latex puppet, but in later releases he is a computer-generated image (CGI). His assistant is Bib Fortuna. Besides the films, Jabba the Hutt is featured in Star Wars literature and is sometimes referenced by his full name, Jabba Desilijic Tiure.[7] Jabba also appears in the computer game Star Wars Galaxies.\\r\\nHe is a 600-year-old Hutt crime lord and gangster who employs a retinue of criminals, bounty hunters, smugglers, assassins, and bodyguards to operate his criminal empire. Jabba the Hutt's palace on the desert planet Tatooine is a former monastery for a group of mystics known as the B'omarr monks. There, he keeps a host of entertainers, slaves, droids, and alien creatures at his disposal. Jabba has a grim sense of humor, a bellicose laugh, an insatiable appetite, and an affinity for gambling, slave girls, torture, and has a pet rancor at the \\"basement\\" of his Palace.\\r\\nThe character was incorporated into the Star Wars merchandising campaign that corresponded with the theatrical release of Return of the Jedi. Jabba the Hutt's image has since played an influential role in popular culture, particularly in the United States. His name is used as a satirical literary device and a political caricature to underscore negative qualities such as suffering from morbid obesity and corruption.[8][9]\\r\\nQueen Jool or Jool the Hutt was the Hutt owner of Rik's Cantina on Coruscant. She lived in a swamp below the bar. Her left eye had been replaced by a jeweled and feathered cybernetic implant that allowed her to observe the cantina's doings. Aside from owning and operating the bar, she was also a sly information broker. Jool was a suave and flirtatious Hutt. She is an ally of Cade Skywalker.\\r\\nVogga the Hutt is a Huttese businessman based on Nar Shaddaa who specialized in fuelspecifically high-grade fuel suitable for, among other things, Citadel Station. Like all Hutts, he technically is a hermaphrodite, but generally has a masculine personality. His first and only appearance is in Star Wars: Knights of the Old Republic II: The Sith Lords. He enjoys watching scantily-clad female dancers, though this always puts him to sleep. One of the Jedi Exile's companions can dance for him; this is confirmed.\\r\\nAfter the Jedi Exile inadvertently caused the destruction of the Peragus II mining facilities, the biggest competitor to Vogga's importing of fuel from Sleheyron, Vogga began attempting to take advantage of the sudden shortage of fuel. G0-T0 opposed the Hutt's business plan. In retaliation, Vogga hired a considerable number of bounty hunters (like Hanharr) and bribed a number of G0-T0's underlings (like Visquis). The Exile took advantage of this when he registered the Ebon Hawk as a freighter of Vogga's; unsurprisingly, this resulted in G0-T0 intercepting the freighter, whereupon the Exile caused G0-T0's yacht to decloak. Vogga's waiting vessels promptly blew it out of space. Vogga further won in that following the destruction of G0-T0's yacht, the Jedi Exile arranged for shipment of fuel to Telos.\\r\\nZorba Desilijic Tiure or Zorba the Hutt is the father of Jabba the Hutt.[10] He did not immediately learn of his son's death because he was imprisoned on the planet Kip. Zorba resembled his son, though he had long, white hair braids and a white beard. All of Jabba's possessions were bequeathed to Zorba, including the desert palace on Tatooine. He blamed Princess Leia Organa Solo for the murder of his son Jabba. Zorba then challenged Lando in a game of sabacc and won Cloud City. Lando soon won back Cloud City in a future game. In one instance Zorba was referred to as 'Koztas'.\\r\\nGrappa the Hutt appears in the Crimson Empire novels. He is in league with the Black Sun criminal gang and Itha spectral-like species known as the Zanibar. He first appears looking like Tarrant Snil and like Jabba appears to enjoy the company of slave female humanoids and big parties. However he is quick to lose his temper and ends up killing not only a Zanibar but a spokesman from the Black Sun. He allows both Mirth Sinn and her ex-lieutenant Massimo to be sacrificed to the Zanibar. Kir Kanos saves Mirth Sinn but Massimo is less lucky. Grappa was also scared when he received a telecom of a figure known as The Faceless One. After the Black Sun guards sent assassins after him, Grappa fled only to be caught by the Zanibar when he couldn't pay them the money he owed them. He was taken to be sacrificed on their homeworld of Xo.\\r\\nKorpa the Hutt is cousin of Vogga the Hutt. He is a small-time crime lord, trying to take over his cousin's businesses. Following a starship duel with his would-be assassin in the twin system of Dva Lokwanya, he lands on a small planet Okopania, meeting with bounty hunter Ser Onja to arrange the assassination of Vogga. Receiving a payment of rare G'ovna crystals, Ser Onja doublecrosses Korpa, sabotaging his ship to explode on takeoff.\\r\\nRotta Desilijic Tiure or Rotta the Huttlet is Jabba's 10-year-old son, appearing in The Clone Wars animated movie. He was kidnapped by the Separatists, but returned to Jabba by the Republic although Jabba was convinced by Dooku that the Jedi kidnapped his son.\\r\\nZiro Desilijic Tiure or Ziro the Hutt was the uncle of Jabba the Hutt and the owner of a club on Coruscant. In the events of the Clone Wars animated movie and series, Ziro was part of a failed plot with Count Dooku to kidnap Rotta the Huttlet in a plan to frame the Jedi and seize power from Jabba. When the plan failed as the result of Padm Amidala's meddling, Ziro was imprisoned after being forced to admit his part in Rotta's abduction. From his cell he attempted to seek revenge by sending an assassin after Padm, the scheme backfiring on him when the assassin is caught. Later, because he possessed a book detailing the shady actions of the Hutt Council, Ziro was released by Cad Bane and brought before the Hutts. Ziro was freed from the Hutt prison by Sy Snootles, but then killed by her, as well, once he had led her to the book, which she had been hired to acquire by Jabba.\\r\\nZiro, being one of the few Hutts to speak in English/Basic, is voiced by Corey Burton with a lispy southern drawl modeled on the voice of Truman Capote.\\r\\nMama the Hutt is the mother of Ziro the Hutt and Zorba the Hutt. She lives alone on Nal Hutta, and as Ziro says, her home is the one place Gardulla would never show up. She is much larger than any average Hutt. So large in fact, that she towers over other Hutts. She appears in Star Wars: The Clone Wars in the episode \\"Hunt for Ziro\\". Ziro visits her after many years of not speaking to her and borrows her starship. Later Cad Bane and Todo 360 charge into her home and force her to tell them where Ziro's heading. And finally, Jedi Masters Obi-Wan Kenobi and Quinlan Vos break down her door and ask her where Ziro went.\\r\\nJuvard the Hutt, commonly known as Doctor Oggurobb, entire name is Juvard Illip Oggurobb, is a masculine Hutt doctor during the Second Great Galactic War who served the Hutt Cartel during Toborro the Hutt's occupation of Makeb in 3,640 BBY.\\r\\nDue to his large stature and unusual look, Jabba has been parodied many times","input":"What is jabba the hutt's son's name?"},{"output":"Shasta and Trinity Counties in California, United States","context":"July?23,?2018?(2018-07-23) ÿ present ?()\\r\\n\\r\\nThe Carr Fire is a wildfire burning in Shasta and Trinity Counties in California, United States.  As of August 12, 2018, the fire had burned 202,976 acres (821?km2; 317?sq?mi) and is 61% contained. It is the sixth-most destructive fire in California history.[3] The fire was reported on the afternoon of July 23, 2018, at the intersection of Highway 299 and Carr Powerhouse Road  in the Whiskeytown district of the WhiskeytownÿShastaÿTrinity National Recreation Area. The fire was started when a flat tire on a vehicle caused the wheel's rim to scrape against the asphalt, thus creating sparks.[4]\\r\\n\\r\\nOn July 26, the fire jumped the Sacramento River, making its way into the city of Redding, causing the evacuation of 38,000 people. Evacuations also took place in Summit City, Keswick, Lewiston, Shasta Lake City, Igo, Ono and French Gulch. The fire has destroyed 1,599 buildings, at least 1,077 of which were homes, and damaged another 282, with over 500 structures remaining threatened. Eight people have died in the fire, including three firefighters (a plow driver, fire inspector and one fireman who died in a head-on collision en route to fight said fire), a great-grandmother and her two great-grandchildren, and an employee of Pacific Gas and Electric Company (PG&E). Three firefighters have also been injured.\\r\\n\\r\\nThe Carr Fire was reported on the afternoon of July 23, 2018, at the intersection of Highway 299 and Carr Powerhouse Road, in the Whiskeytown district of the WhiskeytownÿShastaÿTrinity National Recreation Area, in Shasta County, California, near French Gulch. The fire was believed to have been started by a vehicle having mechanical failures, which ignited the ground and quickly spread.[5] Hot conditions and steep, inaccessible terrain caused challenges for fire crews as they strengthened containment lines. Highway 299 was closed and French Gulch was placed under mandatory evacuation.[6]\\r\\n\\r\\nOvernight from July 25 to 26, the fire grew to 20,000 acres (81?km2) in total burned land.[7] As of the evening of July 26, the fire had burned 28,763 acres (116?km2) and was 10 percent contained.[8] It was reported to have destroyed 15 buildings and damaged 5, while remaining a threat to 496 buildings.[1] The fire jumped the Sacramento River and portions of the western area of Redding were put under mandatory evacuation orders. Power to residents in North Redding was shut off by Redding Electric Utility. A state of emergency was declared by Governor Jerry Brown.[8] The evacuation center at Shasta High School was relocated to Shasta College.[9] A firefighter was killed while operating a bulldozer.[10] The National Guard was called in to help fight the fire on the night of July 26.[11]\\r\\n\\r\\nThe fire remained active overnight, with fire crews continuing to build containment lines. However, crews were stalled in their work due to the fire's extreme behavior.[12] Just after midnight, evacuation orders were put in place for Shasta Dam, Summit City, and neighborhoods in western Redding.[13] A second firefighter, Jeremy Stoke of the Redding Fire Department, was killed and it was reported that three firefighters from Marin County sustained burns. They were defending a structure when a heat blast from the flames came towards them. All three were released, with one being evaluated at the University of California Davis Burn Center for burns on his face, hands and ears.[10][14][15]\\r\\n\\r\\nBy the evening of July 27, the fire had destroyed 500 structures and threatened almost 5,000. CrossPointe Community Church was named the third evacuation place.[16] Amtrak announced that their Coast Starlight service would stop in Sacramento and Klamath Falls with alternative transportation being provided.[17]\\r\\nContainment lines remained the priority for firefighters overnight. Red flag warnings and heat advisories were put in place for the area.[18]\\r\\n\\r\\nBy the next morning, over 38,000 individuals had been evacuated.[15] The Shasta College evacuation center reached capacity by July 28 and two more shelters operated by the Red Cross, and one at Grace Baptist Church, were opened.[19] President Donald Trump declared a state of emergency for the state of California due to this fire and other fires burning in the state.[20] The communities of Happy Valley and Anderson, as well as other areas, were put under mandatory evacuation in the mid-morning.[1] A woman and two children, who were reported missing on July 26 due to the fire, were reported dead.[2] More buildings were evaluated for damage, bringing the total up to 536 destroyed and 117 damaged. Winds were erratic, fueled by hot weather, which created spot fires throughout the fire area.[21] Weaverville Elementary School was closed as an evacuation center and a new center was opened at Trinity High School.[22] In the evening, new evacuation orders were put in place for Highway 299 at Trinity Dam Road west to Douglas City and other nearby subdivisions.[23]\\r\\n\\r\\nA sixth fatality was reported on July 29, as the fire moved from densely populated areas and into rural parts of Shasta and Trinity Counties. The community of Lewiston was evacuated. By the evening, fire containment had grown from 5 to 17 percent. The National Guard was assigned to Redding to monitor for looting in evacuated neighborhoods.[24] The next day, repopulation began of areas of western Redding, Shasta Lake, and Happy Valley that had previously been evacuated.[25][26][27] Overnight, strengthening containment lines remained a priority as east and west winds converged and created challenges for firefighters.[1] Repopulation efforts continued, starting on the morning of July 31 for areas of western Redding, Summit City, Buckeye and Happy Valley.[28][29] Celebrity chef Guy Fieri provided food for evacuees in Redding.[30]\\r\\n\\r\\nBy the evening of July 31, the fire had burned 112,888 acres (457?km2) and was 30 percent contained.[1] Crews were challenged by the fire along the western edge, where the fire burned in high terrain with strong winds and dry fuels.[31]\\r\\n\\r\\nA powerful fire whirl with winds estimated in excess of 143?mph (230?km/h)equivalent to an EF3 tornadodeveloped within the Carr Fire in Redding, California, on July?26. Remaining on the ground from 7:30ÿ8:00?p.m., the fire whirl reached an estimated height of 18,000?ft (5,500?m) and caused extensive tornado-like damage while spreading the fire.[32][33] The winds toppled transmission towers, shredded foliage, and debarked and uprooted trees. The smoke plume from the whirl \\"dominated\\" the majority of the wildfire.[33] Substantial damage occurred in areas untouched by fire, including signs of ground scouring.[32] Three people were killed inside their Redding home after the structure's walls were blown out and the roof collapsed on the occupants. Several other homes suffered significant roof damage.[34]\\r\\n\\r\\nThe fire grew over 2,000 acres (8?km2) and to 35 percent containment as the fire burned into August 1.[31] Late morning, evacuation orders were lifted for the Mary Lake Subdivision and, later in the day, residents were allowed back to Plateau Road.[35][36] The City of Redding shut down their Carr Fire-related missing persons hotline as all missing people were accounted for. Shasta College, which served as an evacuation center, resumed normal services. Six people were reported as arrested for alleged looting or illegally being in evacuated areas.[35] The area west of Lakehead, California, was closed to public access to allow for fire crews' safety.[37] Thus far, the fire had destroyed 1,546 structures, including 1,058 residential and 13 commercial.[38]\\r\\n\\r\\nOver 1,600 structures remained threatened due to the fire as of August 2. It continued to grow as the terrain, wind and dry fuels continued to create challenges for fire crews. The Sunset West, Sunset Terrace, Ranch Land Acres, Middletown Park neighborhoods and Centerville were reopened to population in the morning.[39] As of the morning of August 2, the fire was 125,842 acres (509?km2) and remained 35 percent contained.[1]\\r\\n\\r\\nBy August 4, the fire grew to 145,015 acres (587?km2) and to 41 percent containment. California Governor Jerry Brown toured the site and announced that he had requested a major disaster declaration, which provides federal assistance.[40] Later that day, President Donald Trump approved the request for Shasta County.[41] A seventh fatality was reported when a PG&E employee died in a vehicle incident.[42]\\r\\n\\r\\nBy August 9, the fire grew to 178,752 acres (723?km2) and to 49 percent containment. Early that morning a Cal Fire heavy equipment mechanic was killed in a traffic incident, bringing the number of fatalities to eight.[43]\\r\\n\\r\\nThe Carr Fire is currently the sixth most destructive in California history.[39] It caused evacuations of over 36,000 people in the communities of French Gulch, Igo, Ono, Lewiston, Douglas City, Shasta, Shasta Lake City, Summit City, and the City of Redding, and caused closures of portions of California State Route 299. The fire directly impacted the water sources Keswick Dam and Shasta Dam.[44]\\r\\n\\r\\nThe following areas, as of August 1, were under mandatory evacuation:[1]\\r\\n\\r\\nEvacuation centers are located at Shasta College and Trinity High School.[45][46]\\r\\n\\r\\nThe fire affected recreational activities. At early stages, the access to WhiskeytownÿShastaÿTrinity National Recreation Area was halted, specifically in Shasta County, including access to Whiskey Creek and Whiskeytown Lake.[6] The area surrounding Shasta Dam and the dam's visitors center were evacuated and closed.[1] Lake Redding Park and the adjacent golf course were closed due to the fire after it jumped the Sacramento River, destroying close to 40 homes in the surrounding neighborhood.[47] The Bureau of Land Management closed trails in western Redding.[1]\\r\\n\\r\\nAmtrak service on the Coast Starlight was disrupted between Sacramento and Klamath Falls, Oregon. Amtrak arranged alternative transportation for travelers between those two cities.[17]\\r\\n\\r\\nLarge portions of Highway 299 were closed as a result of the fire. Many sections of the highway's route through Redding were closed, including the North Market Street Bridge which connects downtown Redding to the Benton Tract neighborhood. Highway 273 was closed in many areas.[1]\\r\\n\\r\\nAccess to Keswick Dam was restricted and the surrounding areas were evacuated as a result of the fire.[1]\\r\\n\\r\\nAccess to the remains of the historic ghost town of Gas Point was restricted due to the fire. A 2008 fire had destroyed the historic town.[48] The historic town of French Gulch was evacuated and closed. This was the second time the community had been evacuated due to a fire, the prior evacuation taking place in August 2004, in which 103 structures burned in the community.[6] The Shasta State Historic Park was also affected, where the 1920s schoolhouse was destroyed and other buildings were damaged. Artifacts had been removed before the fire.[49]\\r\\n\\r\\nThe fire affected air quality throughout Northern California and the Central Valley down to Bakersfield, Oregon, Washington and Nevada. Smoke reached as far north as Seattle, Washington, and Boise, Idaho.[50][51]\\r\\n\\r\\nTwo firefighters have been killed in the Carr Fire. One was a contract firefighter who was driving a bulldozer when he died.[10] The second was Redding-based fire inspector Jeremy Stoke.[44] On July 28, a great-grandmother and her two great-grandchildren were found dead, as they did not have a car and were unable to evacuate.[52] A sixth fatality was reported on July 29. An evacuation order was issued to the victim, but they did not evacuate.[24] The victim was recovering from heart surgery, which possibly prevented him from leaving.[53] On August 4, a PG&E employee was killed in a vehicle incident.[42] On August 9, a Cal Fire heavy equipment mechanic was killed in a traffic incident.[43]","input":"What is the location of the carr fire?"},{"output":"Aconcagua","context":"Aconcagua (Spanish pronunciation:?[ako??ka?wa]) is the highest mountain outside Asia, at 6,960.8 metres (22,837?ft), and the highest point in the Southern Hemisphere.[1] It is located in the Andes mountain range, in the Mendoza Province, Argentina, and lies 112 kilometres (70?mi) northwest of its capital, the city of Mendoza, about five kilometres from San Juan Province and 15 kilometres from the international border with Chile. The mountain itself lies entirely within Argentina, immediately east of Argentina's border with Chile.[3] Its nearest higher neighbor is Tirich Mir in the Hindu Kush, 16,520 kilometres (10,270?mi) away. It is one of the Seven Summits.\\r\\nAconcagua is bounded by the Valle de las Vacas to the north and east and the Valle de los Horcones Inferior to the west and south. The mountain and its surroundings are part of the Aconcagua Provincial Park. The mountain has a number of glaciers. The largest glacier is the Ventisquero Horcones Inferior at about 10?kilometres long, which descends from the south face to about 3600?metres in altitude near the Confluencia camp.[4] Two other large glacier systems are the Ventisquero de las Vacas Sur and Glaciar Este/Ventisquero Relinchos system at about 5?kilometres long. The most well-known is the north-eastern or Polish Glacier, as it is a common route of ascent.\\r\\n\\r\\n\\r\\nThe origin of the name is contested; it is either from the Mapudungun Aconca-Hue, which refers to the Aconcagua River and means \\"comes from the other side\\",[3] the Quechua Ackon Cahuak, meaning \\"'Sentinel of Stone\\",[5] the Quechua Anco Cahuac, meaning \\"White Sentinel\\",[2] or the Aymara Janq'u Q'awa, meaning \\"White Ravine\\".[6]\\r\\nThe mountain was created by the subduction of the Nazca Plate beneath the South American Plate. Aconcagua used to be an active stratovolcano (from the Late Cretaceous or Early Paleocene through the Miocene) and consisted of several volcanic complexes on the edge of a basin with a shallow sea. However, sometime in the Miocene, about 8 to 10 million years ago, the subduction angle started to decrease resulting in a stop of the melting and more horizontal stresses between the oceanic plate and the continent, causing the thrust faults that lifted Aconcagua up off its volcanic root. The rocks found on Aconcaguas flanks are all volcanic and consist of lavas, breccias and pyroclastics. The shallow marine basin had already formed earlier (Triassic), even before Aconcagua arose as a volcano. However, volcanism has been present in this region for as long as this basin was around and volcanic deposits interfinger with marine deposits throughout the sequence. The colorful greenish, blueish and grey deposits that can be seen in the Horcones Valley and south of Puente Del Inca, are carbonates, limestones, turbidites and evaporates that filled this basin. The red colored rocks are intrusions, cinder deposits and conglomerates of volcanic origin.[7]\\r\\nIn mountaineering terms, Aconcagua is technically an easy mountain if approached from the north, via the normal route. Aconcagua is arguably the highest non-technical mountain in the world, since the northern route does not absolutely require ropes, axes, and pins. Although the effects of altitude are severe (atmospheric pressure is 40% of sea-level at the summit), the use of supplemental oxygen is not common. Altitude sickness will affect most climbers to some extent, depending on the degree of acclimatization.[8] Even if the normal climb is technically easy, multiple casualties occur every year on this mountain (in January 2009 alone five climbers died).[citation needed] This is due to the large numbers of climbers who make the attempt and because many climbers underestimate the objective risks of the elevation and of cold weather, which is the real challenge on this mountain. Given the weather conditions close to the summit, cold weather injuries are very common.\\r\\nThe Polish Glacier Traverse route, also known as the \\"Falso de los Polacos\\" route, crosses through the Vacas valley, ascends to the base of the Polish Glacier, then traverses across to the normal route for the final ascent to the summit. The third most popular route is by the Polish Glacier itself.\\r\\nProvincial Park rangers do not maintain records of successful summits but estimates suggest a summit rate of 30-40%[citation needed]. About 75% of climbers are foreigners and 25% are Argentinean. Among foreigners, the United States leads in number of climbers, followed by Germany and the UK. About 54% of climbers ascend the Normal Route, 43% up the Polish Glacier Route, and the remaining 3% on other routes.[9]\\r\\nThe routes to the peak from the south and south-west ridges are more demanding and the south face climb is considered quite difficult.\\r\\nThe camp sites on the normal route are listed below (altitudes are approximate).\\r\\nSummit attempts are usually made from a high camp at either Berln or Colera, or from the lower camp at Nido de C܇ndores. All camps are used frequently, namely Plaza de Mulas and Nido de C܇ndores.\\r\\nThe first attempt to reach the summit of Aconcagua by a European was made in 1883 by a party led by the German geologist and explorer Paul Gssfeldt. Bribing porters with the story of treasure on the mountain, he approached the mountain via the Rio Volcan, making two attempts on the peak by the north-west ridge and reaching an altitude of 6,500 metres (21,300?ft). The route that he prospected is now the normal route up the mountain.\\r\\nThe first recorded[2] ascent was in 1897 by a European expedition led by the British mountaineer Edward FitzGerald. FitzGerald failed to reach the summit himself over eight attempts between December 1896 and February 1897, but the (Swiss) guide of the expedition, Matthias Zurbriggen reached the summit on January 14. On the final attempt a month later, two other expedition members, Stuart Vines and Nicola Lanti, reached the summit on February 13.[12]\\r\\nThe east side of Aconcagua was first scaled by a Polish expedition, with Konstanty Narkiewicz-Jodko, Stefan Daszyski, Wiktor Ostrowski and Stefan Osiecki summiting on March 9, 1934, over what is now known as the Polish Glacier. A route over the Southwest Ridge was pioneered over seven days in January 1953 by the Swiss-Argentine team of Frederico and Dorly Marmillod, Francisco Ibanez and Fernando Grajales. The famously difficult South Face was conquered by a French team led by Ren Ferlet?(fr). Pierre Lesueur, Adrien Dagory, Robert Paragot, Edmond Denis, Lucien Berardini and Guy Poulet reached the summit after a month of effort on 25 February 1954.[13][14]\\r\\nThe youngest person to reach the summit of Aconcagua was Tyler Armstrong of California. He was nine years old when he reached the summit on December 24, 2013.[15] The oldest person to climb it was Scott Lewis, who reached the summit on November 26, 2007, when he was 87 years old.[16]\\r\\nIn the base camp Plaza de Mulas (at 4300 meters above sea level) there is the highest contemporary art gallery tent called \\"Nautilus\\" of the Argentine painter Miguel Doura.[17]\\r\\nIn 2014 Kilian Jornet set a record for climbing and descending Aconcagua from Horcones in 12 hours and 49 minutes.[18] The record was broken less than two months later by Ecuadorian-Swiss Karl Egloff, in a time of 11 hours 52 minutes, nearly an hour faster than Kilian Jornet.[19]\\r\\nThe mountain has a cameo in a 1942 Disney cartoon called Pedro.[20] The cartoon stars an anthropomorphic small airplane named Pedro who makes an air mail run over the Andes and has a near-disastrous encounter with Aconcagua, which is depicted in the film as an anthropomorphic menace.\\r\\nAconcagua is the highest peak of Americas and is also considered an easy high altitude peak, being nearly seven thousand metres.[21] And through that, Aconcagua is believed to have the highest death rate of any mountain in South America ÿ around three a year ÿ which has earned it the nickname, Mountain of Death. More than a hundred people have died on Aconcagua since records began.[22]\\r\\nDue to the improper disposal of human waste in the mountain environment there are significant health hazards[21] that pose a threat to both animals and human beings.[23] Only boiled or chemically treated water is accepted for drinking. Additionally, Ecofriendly toilets are available only to members of an organised expedition, meaning climbers have to be contracted to a toilet service at the base camp and similar camps along the route. Currently, from two base camps (Plaza de Mulas and Plaza Argentina), over 120 barrels of waste (approx. 22,500?kg) are flown out by helicopter each season.[24] In addition, individual mountaineers must make a payment before using these toilets. Some large organisers will give a price up to US$100, some smaller US$5/day or US$10 for the entire stay. Thus, many independent mountaineers defecate on the mountainside.[21]","input":"What's the highest mountain in south america?"},{"output":"Polar Bear","context":"Ontario Parks is the branch of the Ministry of Natural Resources and Forestry that administers the provincial parks in Ontario, Canada. The Ontario Parks system covers over 78,000 square kilometres (30,460?sq mi), about 10 percent of the province's surface area or the equivalent of an area approximately equal to Nova Scotia. The Ontario Parks system is often used as the model for other parks systems in North America. This can be attributed to its delicate balance of recreation, preservation, and conservation. Many parks in Ontario also offer a Natural Heritage Education program.\\r\\nOntario Parks' mandate is to protect significant natural and cultural resources in a system of parks and protected areas that is sustainable and provides opportunities for inspiration, enjoyment and education: now and for future generations.[1]\\r\\n\\r\\n\\r\\nThe Ontario Parks system began its long and rough history in 1893 with the creation of Algonquin Park, originally designed to protect loggers' interests from settlement. The management and creation of provincial parks came under the Department of Lands and Forests in 1954 and led to a period of accelerated park creation: a ninefold increase in the number of parks over the next six years. In the 1970s the Ontario Ministry of Natural Resources' (MNR) was formed. Currently, Ontario Parks does not have full agency status, but is a branch of the Natural Resource Management Division of the MNR.\\r\\nThe history of Ontario's provincial parks stretches for over 100 years. Here are some of the milestones from the past century plus:[2]\\r\\n1893 ÿ Algonquin Park is created as a public park and forest reservation, fish and game preserve, health resort and pleasure ground.\\r\\n1894 ÿ Rondeau becomes Ontario's second provincial park.\\r\\n1913 ÿ The Parks Act sets aside land not suitable for agriculture or settlement.\\r\\n1954 ÿ Ontario still has only 8 provincial parks: Algonquin, Quetico, Long Point, Rondeau, Presqu'le, Ipperwash, Lake Superior and Sibley (now known as Sleeping Giant).\\r\\nA Division of Parks is created within the Department of Lands and Forests. This heralds a new and aggressive program to create more parks, primarily on the Great Lake and northern tourism highways.\\r\\n1960 ÿ There are now 72 provincial parks in Ontario, hosting over 5 million visitors annually.\\r\\n1967 ÿ Ontario introduces a new policy that divides parks into specific categories, or classes, with compatible sets of uses.\\r\\n1970 ÿ Polar Bear, Ontario's largest provincial park at 24,000 square kilometres, is created.\\r\\n1978 ÿ Ontario Provincial Parks: Planning and Management Policies are approved by Cabinet giving Ontario one of the world's leading parks planning systems.\\r\\n1983 ÿ The new land use planning system leads to the announcement of 155 new parks to be designated.\\r\\n1985 ÿ There are now 220 parks in Ontario encompassing over 5.5 millions hectares of land.\\r\\n1993 ÿ Ontario celebrates the centennial of the provincial parks system and Algonquin's 100th anniversary.\\r\\n1996 ÿ The provincial parks system adopts a new entrepreneurial operating model where revenue generated by parks can be reinvested in the parks system. This is symbolized by a new name, Ontario Parks, and a new visual identity.\\r\\n1996 ÿ Ontario Parks partners with the Natural Conservancy of Canada to create Legacy 2000, a program to protect significant natural areas. Under this agreement more than 11,000 hectares are secured.\\r\\n1999 ÿ Ontario's Living Legacy is announced. This land use strategy identifies 378 new protected areas, including 61 new parks and 45 parks additions. Ontario's Living Legacy will protect over 2.4 million hectares of land, including additions to the provincial parks system of over 900,000 hectares.\\r\\n2001 ÿ Ontario now has a total of 280 provincial parks encompassing 7.1 million hectares or almost 9 percent of the province's area. Over 9 million visitors annually enjoy Ontario Parks.\\r\\n2007 ÿ Introduction of new legislation: \\"Provincial Parks and Conservation Reserves Act\\" with 329 provincial parks and 292 conservation reserves.\\r\\nOntario Parks system uses a classification system to divide the provincial parks into the following categories:[3]\\r\\nAs of 2008[update], Ontario Parks system manages 65 recreational class parks (394.8?km2), six cultural heritage class parks (67.4?km2), 80 natural environment class parks (14,675.3?km2), 109 nature reserve class parks (1,152?km2), 62 waterway class parks (14,446.2?km2), and 8 wilderness class parks (48,237.5?km2).","input":"What is the largest provincial park in ontario?"},{"output":"2.0-litre","context":"The Toyota 86 is a series of 2+2 seater sports cars which was jointly developed by Toyota and Subaru and solely manufactured by Subaru. It features a boxer engine, front engine, rear wheel drive drivetrain, 2+2 seating and a fastback coup body style.\\r\\nSubaru retails their version of the car as the Subaru BRZ. As a Toyota it is sold worldwide under different names with the most common being the Toyota 86as used in Asia, Australia, North America (from August 2016), South Africa, and South America.[1] The name Toyota GT86 is used in Europe; both of the preceding names in New Zealand; and Toyota FT86 in Nicaragua and Jamaica. In the United States and Canada, the coupe previously sold as the Scion FR-S. After the Scion brand was discontinued in August 2016, the FR-S was renamed as the Toyota 86.[2][3]\\r\\n      \\r\\n\\r\\n\\r\\nThe development code of this vehicle is 086A[4] and its main production names 86 (pronounced \\"eight-six\\" or Hachi-Roku (˦) in Japanese) or GT86, reference historic Toyota front-engined and rear-wheel drive sports coups and hatchbacks, in the form of:\\r\\nToyota also referenced to its first sports car, the Sports 800, given that both this car and the 86 share a boxer engine layout,[5] as widely used by project partner and 86 manufacturer, Subaru.\\r\\nInitial layout and design elements for the 86 were presented by Toyota using its \\"FT\\" (Future Toyota) concept car nomenclature. The first was the Toyota FT-HS, which was presented at the Detroit Motor Show in 2007. It had a front engine, rear-wheel drive layout and 2+2 seating and was powered by a V6 engine with hybrid electric assistance. In 2008, Toyota bought 16.5% of Fuji Heavy Industries, which includes the Subaru automotive brand.[6] Toyota, led by project leader Tetsuya Tada,[7] then offered Subaru to become involved in its new sport coup project, by co-developing the new D-4S boxer engine,[8] however, this was rejected since the design conflicted with Subaru's reputation for high performance all-wheel drive (AWD) cars. This outcome resulted in the project coming to a six-month halt before Toyota invited journalists and Subaru engineers to test a developmental prototype. Following this test, Subaru agreed to become further involved in development.[9]\\r\\nThe new collaboration thus produced a new concept car, the FT-86, which was revealed at the Tokyo Motor Show in October 2009. Smaller than the FT-HS, the design of the FT-86 was further refined by Toyota's ED2 design studio while the hybrid V6 powerplant was replaced by the new D-4S boxer. Subaru provided the chassis and gearbox, adapting those of their Impreza. The concept was painted in Shoujyouhi Red, which was reported as being based on the backside of a Japanese macaque.[10]\\r\\nAt the 2010 Tokyo Motor Show, Toyota then launched its G Sports line of aftermarket accessories, along with the FT-86 G Sports concept car. It featured G Sports carbon fibre panels, a vented bonnet, rear wing, 19?in (48?cm) wheels, Recaro race seats, and an interior rollcage.[11] The D-4S engine also added a turbocharger.[12]\\r\\nIn 2011, Toyota and Subaru unveiled five near-production concept cars to show their progress with the project. The first, known as the FT-86 II Concept, was unveiled at the Geneva Motor Show in March 2011. ED2 refined the design of the initial FT-86, by developing new front and rear fascias, and marginally increasing the dimensions of the concept.[13] At the same show, Subaru also unveiled a transparent silhouette of the car that showed off the new D-4S boxer engine and displayed the \\"Boxer Sports Car Architecture\\".[14]\\r\\nScion followed next in April 2011 at the New York Motor Show with the FR-S Sports Coup Concept, co-developed with aftermarket tuner Five Axis.[15] Another semi-transparent Subaru concept, known as the BRZ Prologue, was shown at the Frankfurt Motor Show that September,[16] followed in November at the Los Angeles Motor Show by the BRZ Concept STi, the first full mock-up of Subaru's version of the 86 with input from Subaru Tecnica International (STI).[17]\\r\\nThe first production Toyota 86 debuted at the 2011 Tokyo Auto Show. All variants are built at Subaru's Gunma Main Plant,[18] with the first cars assembled on 2 February before sales began in March and deliveries in April. 7,000 orders were placed for the Toyota 86 in the first month of production,[19] while Subaru took in 3,500 orders.[20]\\r\\nIn the United States, Scion were allocated 10,000 units of the 2013 model year (MY13) production,[21] while Subaru was limited to only 6,000 units.[22]\\r\\nThe 86's engine, known by the Toyota code 4U-GSE and Subaru code FA20, is a naturally aspirated four-cylinder engine that uses Subaru's horizontally opposed boxer engine design, with the addition of Toyota's D-4S injection system, which uses both direct and port fuel injection. Given its placement, the 86 can be considered having a front engine, rear wheel drive drivetrain layout. The engine runs on 98 RON (premium unleaded) fuel and features a 12.5:1 compression ratio and a bore and stroke of 86?mm (3.4?in) that results in 200 horsepower (149?kW; 203?PS) at 7,000 rpm and 151?lb{ft (205?N{m) of torque at 6,000 rpm.[23] As part of the 86's low-weight design, the car utilizes an aluminium hood, a solid roof, and a trunk as opposed to a hatchback.[24][25] The boxer engine sits as far back and as low as possible in the engine bay for a weight distribution of 53% in front and 47% in the rear. The low-sitting engine provides a lower center of gravity, allowing the engine to sit lower than the Nissan GTR and just 0.6 inches higher than the Lexus LFA.[24]\\r\\nThe 86, BRZ and FR-S are offered with two 6-speed transmissions, an in-house developed Toyota TL70 manual gearbox (based on Aisin AI's AZ6[26]) and an Aisin-Warner A960E automatic transmission, which is modified from that used on the Lexus IS 250. The latter uses a traditional wet torque converter design, but its software has been engineered to mimic the response of a dual-clutch gearbox. The automatic transmission uses three different modes: Sport, Snow, and Normal. A torque sensing limited slip differential is standard on most models.\\r\\nThe vehicles are offered with 16\\" steel and alloy wheels shod with Yokohama dB Decibel E70 tyres in 205/55 size or 17\\" alloy wheels shod with Michelin Primacy HP tyres in 215/45 size, depending on sales market. The limited editions Toyota Racing Development (TRD) GT86 models are instead offered with 18\\" forged aluminium wheels, which are shod with either Yokohama Advan Sport tyres Michelin Pilot Sport 3 tyres in 225/40 size, also depending on market. All non-TRD cars feature ventilated front disc brakes and solid rear disc brakes on base models or, on higher models, also ventilated rear disc brakes with two piston-opposed calipers in the front and single caliper design in the rear. The TRD editions instead have an upgraded braking system comprising upsized TRD two-piece rotors and TRD six-pot 355mm front and four-pot 345mm rear calipers (compared to the GTS' 294mm and 290mm calipers and GT's 277mmm and 286mm, respectively). Suspension design comprises front MacPherson struts and double wishbones at the rear.\\r\\nThe 86 was designed around a front-mounted boxer engine, rear-wheel drive configuration, inspired by the AE86. The flat architecture of the boxer engine allows it to be mounted low, dropping the center of gravity down, resulting in sporty handling characteristics.[5] The exterior design of the 86 delivers a slippery drag coefficient of?Cd=0.27[27] and was inspired by the Toyota 2000GT's low-to-the-ground profile and long, sleek hood. Its design cues translate onto the 86 in such areas as: upward trailing edge of the doors; the upward finish to the side-window line; the front and rear haunches; the circular taillights set in silver (singular instead of double as on the 2000GT).\\r\\nAccording to the 86's designers, \\"The goal was to create an authentic rear-wheel drive sports car with compelling style, exceptionally balanced performance and handling, flexible utility and surprising MPG.\\"[5] When asked about the TRD version of the car, the lead engineer Mr. Tada said \\"There is definitely going to be a more TRD oriented variant down the line. However any of the parts that would be standard on the TRD model will fit on your current Toyota 86 so there is no need to wait.\\"[28]\\r\\nThe 86 \\"boxer\\" side badge appears on all Toyota and Scion versions of the car, but not the Subaru BRZ. Aside from badging, the main differences between the 86/GT86 and the BRZ are the front grilles and bumper bars. The rest, including the 17?inch alloy wheels, are shared.\\r\\nTo enhance its identity, the vehicle is also characterized by symbolic references and various motifs associated with the number 86 and Toyota heritage:[4][29]\\r\\nThe interior features a 2+2 seating configuration, which utilizes low mounted front seats. The rear seats fold down enabling increased storage space for larger items.[24] Three interior variations exist, the FR-S and base 86 models have cloth seats with all black interior trim that features a black patterned dash trim, while the shift boot features red stitching. The BRZ has two available interiors, one identical to the FR-S but with silver dash trim, a red stitched parking brake boot, black gauge faces (instead of the white tachometer of the 86 GTS models) and a touch-screen navigation head unit; the second option upgrades to leather and Alcantara heated seats, automatic HVAC controls, and a push-button start. The top-of-the-range 86 models are fitted like the BRZ except as noted above, and the Japanese interior can be had in black/red leather and Alcantara or full black leather and Alcantara (Australia being offered only the latter).\\r\\nThe Toyota 86 is available in Japan from Toyota's Netz Store and Corolla Store line of dealerships; the 1980s Corolla Levin and Sprinter Trueno were sold at the same networks. Four trim levels are offered, with the RC model being the base aimed at people wishing to modify or race their vehicles. This model is available with only a 6-speed manual transmission and comes with unpainted bumpers and mirrors, 16?inch steel wheels, simpler interior trim components, analogue speedometer and no stereo or air conditioning. Outside Japan, the RC model is only available in New Zealand. The G model adds all the interior components missing from the RC, plus a fully painted exterior and 16?inch alloy wheels and the availability of an automatic transmission. The GT86 model adds high intensity discharge headlights with LED daytime running lights, fog lamps, automatic climate control, keyless start with engine start button, 17?inch alloy wheels, chrome exhaust tips, white tachometer face with analogue and digital speedometer, silver accents on the centre dash and steering wheel, aluminium pedals. The top-of-the-range GT Limited adds leather and Alcantara seating and a rear spoiler.\\r\\nIn Europe, GT86 models are generally the same as the Japanese 86 GT with a red/black leather/Alcantara interior with red stitching. In the United Kingdom, the Japanese G model is sold as the GT86 Primo[30] and the car has also been available as a limited edition Toyota Racing Development \\"TRD GT86\\", which features: 18?inch forged aluminium wheels with Yokohama Advan Sport tyres; full bodykit with front and side skirts, rear spoiler and new diffuser; quad-exhaust system; TRD-branded detailing on the filler cap, radiator cap and gear knob. In New Zealand, the TRD 86 is sold with the above features except for Michelin Pilot Sport 3 tyres instead plus upgraded TRD braking system. Options not available to all markets include a Bose sound system upgrade.\\r\\nIn Australia, the GT is the equivalent of the Japanese G model but with only an all black interior trim and standard radio head unit, whereas the top-of-the-range GTS model is the equivalent of the Japanese GT Limited except for an all black leather/Alcantara and red-stitch interior trim only and touchscreen multimedia head unit. Upon Australian launch in June 2012, all models for Australia featured a full-size spare wheel, the GTS lacked a rear spoiler, and a limited slip differential or LSD was standard on all models except automatic GT's.[29] The full-size spare wheel was phased out after the first shipments to Australia, replaced with a repair kit. This model also benefitted from a remapping of its Electronic Control Unit (ECU) to address initial reports of rough idling and stalling.[34] The range of models and main options had the following retail prices: GT manual A$29,990; GT automatic A$32,490; GTS manual A$35,490; GTS automatic A$37,990; metallic paint A$425 for all models; \\"Aero pack\\" bodykit A$3,000 for GTS only.\\r\\nAs of the August 2013 production update (which carried the formal year designation MY14), the automatic GT also gained LSD as standard (but with a price increase of A$300; manual price unchanged in Australia) and the GTS gained the same rear spoiler fitted to the Japanese GTS Limited and the Subaru BRZ (with a price increase of A$500 for both the manual and automatic model in Australia).[35] Other distinguishing features on the MY14 models include the removal of the lettered \\"TOYOTA\\" badge from the rear bonnet of the GTS and optional availability of rear parking sonar sensors on GT and GTS.\\r\\nIn July 2014, an updated version of the Australian Toyota 86 range was launched with year designation MY15. The key highlights include: revised suspension settings; \\"shark-fin\\" roof antenna; GTS instrument cluster on GT; carbon-fibre look dash insert and reverse-view camera on GTS; new white and silver exterior paints. The price of the GT remained unchanged while the GTS was the subject of a price increase of A$500 and A$800 for the manual and automatic version, respectively.[36]\\r\\nIn late 2014, as part of its MY15 range, Toyota offered in the UK two new models: the GT86 Aero, featuring a full bodykit and 18?inch OZ Ultraleggera alloy wheels in anthracite grey finish; and the GT86 \\"Giallo\\" (meaning yellow in Italian), limited to only 86 units.[37] Similar to the latter, Toyota also offered in Italy a total of 50 \\"Limited Edition\\" models.[38] Externally, the key distinguishing feature of these limited editions is the new Sunrise Yellow metallic paint and black side stripes (bonnet, roof and bonnet stripes are available in the UK at no extra cost and standard in Italy). The interior is distinguished by a limited edition badge and heated quilt leather seats with yellow 86 logo. The retail price of the Limited Edition in Italy is ?28,500, which translates to ?1,700 more than the standard base model.[39]\\r\\nAt the same time in Japan, Toyota released the 14R-60 model limited to 100 units, inspired by the GT86 TRD Griffon Project of 2013. Its engine power remains the same as the standard models despite featuring various drivetrain changes such as twin central exhausts, a TRD mechanical LSD, a short-shifter, and revised gearing for the six-speed manual transmission. Other changes include extra body reinforcement, a variable-height coil-over spring suspension setup and more rigid suspension bushings. A TRD bodykit with carbonfibre components is complemented by 18?inch magnesium wheels and, overall, 14R-60 model results lighter than the base model. Inside there are race-style bucket seats with four-point belts, an Alcantara-clad steering wheel, carbonfibre dashboard trim and yellow piping and highlights. Price-wise, this Japan-only model is listed for 6,300,000, which is significantly higher than the 2,100,000 for the base RC model or 3,100,000 for the top-of-the-range GT Limited.[40]\\r\\nIn 2015, the 86xstyle Cb was officially launched after its presentations at the 2013 and 2014 Tokyo Auto Salon. It is characterised by a drastically different front end design with revised lights and bumper bar but standard bonnet. Available in 6-speed manual or automatic transmission, it has revised interior trimmings including a red Cb logo embroidered leather steering wheel, white (instead of red) backlit instruments and a dark woodgrain-style panel across the dashboard. The most peculiar features are the replacement of the front side gills with a set of LED-illuminated fins and optional contrasting colour for the cars upper body section. Another option is different alloy wheels than those fitted as standard on the GT86. On sale from April, this Japan-only model is listed for 4,180,000, which is a 1,280,000 premium over the regular 86 GT on which this variant is based.[41]\\r\\nTo celebrate Australia's 86 2016 Pro-Am racing series,[42][43][44] the following November Toyota launched 450 \\"Blackline\\" units (250 of which with manual transmission). Based on the standard GTS model, this limited edition carries a A$2,000 premium because of its cosmetic upgrade with TRD parts and special livery.[45]\\r\\nIn Indonesia, the 86 was launched in 2012.[46] The facelifted version was launched in August 2016.[47] Toyota Indonesia sells the 86 in the TRD package with only an automatic transmission and the non-TRD package with both manual and automatic transmission.[48]\\r\\nPeculiarly, in Jamaica and Nicaragua, the 86 is marketed and sold using one of its pre-launch concept car badges, the \\"FT-86\\".[49][50]\\r\\nThe BRZ's name comes from three elements: Boxer engine, Rear-wheel drive, and Z standing for the zenith.[51] The Subaru BRZ differs from the 86's design in the front fascia, with a different grille and headlight assembly, as well as a different front fender vent. The BRZ's grill is hexagonal in shape, compared to the Toyota's trapezoid. The BRZ features a wraparound of LED parking lights in the headlight assembly, while daytime running lights are integrated into the bumper. The suspension setup of the Subaru is different from the Toyota.[52] Like the Japanese Toyota 86, Subaru offers an RA base model lacking most interior comforts and utilizing 16?inch steel wheels, with the only difference from the 86 RC being that the BRZ RA's bumpers are painted the same color as the body. Two main trim levels are offered: R trim, known as Premium in North America, and S trim, known as Limited in North America. European and Australian BRZs offer a Toyota stereo unit, while Japanese and North American vehicles use a Subaru unit. Australian BRZs were originally available for sale only online.\\r\\nIn 2013, Subaru unveiled a BRZ tS model for the Japanese market, tuned by STI. The tS model features an improved suspension setup, 18 inch silver BBS wheels, STI bodykit and front spoiler, a larger drive shaft, and Brembo brakes, along with interior changes to include a new steering wheel, front seat, gauges, and Alcantara accents.[53] A further tS GT Package includes Recaro seats, black BBS wheels, and an adjustable carbon fibre rear wing. The tS is limited to 500 units in total, with a maximum of 250 of them being the GT package.[54] In 2015, a similar release of 300 units was sold again only in Japan.[55]\\r\\nIn 2014, as part of running changes consistent with those of the MY15 Toyota 86 GTS, the Subaru BRZ also featured a new key fob and two new colours, including WR Blue Pearl metallic finish.[56] In addition, Subaru also launched special editions both for the United States and Australia markets. For the former, one thousand BRZ Series. Blue editions were marketed at additional cost, half painted in Blue Pearl and the other half in Crystal Pearl White. This model featured STI body kit parts, 17-inch STI black alloy wheels and red brake calipers. For Australia, Subaru launched a similar variant known as the Special Edition, also at additional cost. It featured stripes across the bonnet, boot and roof; 17-inch STI black alloy wheels; STI boot spoiler plus front, side and rear-side under spoilers; a rear diffuser and a push-button starter switch. It was available in every existing BRZ paint hue.[57]\\r\\nIn 2015, Subaru released the limited edition Hyper Blue range across its WRX, WRX STI and BRZ models. In Australia, the BRZ was limited to 50 units with manual transmission only. This limited edition is characterised by the said blue paint and a host of other cosmetic upgrades.[58]\\r\\nThe Scion FR-S is exclusive to the United States and Canada. Its name is derived from a description of the platform: Front-engine, Rear-wheel drive, Sport.[15] Unlike all other 86 variants, the FR-S originally had no trim levels and are all offered with Scion's BeSpoke stereo system.\\r\\nAs part of the 10th anniversary of the Scion marque, 2,500 units of \\"10 Series\\" FR-S models were released by Scion for model year 2014. They were painted in Silver Ignition and fitted with extra equipment, including HID headlights, automatic climate control, push button start, illuminated exterior badges plus shifter knob.[59][60]\\r\\nIn January 2014, Scion released 2000 units of the FR-S \\"Monogram Series\\" editions adding extra features at special prices. In this case, this FR-S closely matched the equipment offered on the BRZ (or Toyota's GTS-variant) with the following: heated leather and Alcantara seats; heated side mirrors; high-intensity discharge headlamps; dual-zone climate control; BeSpoke audio and navigation. It cost US$27,400 and US$28,500 respectively, for the manual or automatic transmission model. It was said that this limited edition represented a US$1,900 saving over separately priced options.[61]\\r\\nPresented at the April 2014 New York Auto Show and mirroring the European \\"Giallo\\" and \\"Limited Edition\\" yellow-painted special editions, Scion released 1500 units of the \\"Release Series 1.0\\" in similar Yuzu Yellow paint. Its starting price is US$31,000 and it features TRD bodykit and quad-tip exhaust system, along with TRD lowered suspension, TRD steering wheel and shift knob and the highest specification (dual A/C, HID headlamps with LED daytime running lamps, push-button start-stop) plus a numbered commemorative plaque near the gearshift lever.[62]\\r\\nDue to the discontinuation of the Scion marque, in August 2016 the FR-S was re-branded as the Toyota 86 for the 2017 model year.[2][3][63]\\r\\n       \\r\\nAs part of the Subaru BRZ market launch, a 2-part movie documenting the vehicle's development was produced.[64] In Canada, a TV commercial titled Scorched was produced by OMD, with creative from DDB. The execution was handled by DDB PR with Juxta Productions working on the interior. The commercial was shot at Queen and McCaul St. in Toronto.[65][66][67][68]\\r\\nIn Australia, Subaru BRZ was the first new car ever to be sold on that market exclusively online, with orders opening on 16 July 2012. It was also marketed with free servicing for 3 years or 60,000?km. According to Subaru this sale concept was a success, after the entire 2012 Australian allocation of 201 cars was sold in under 3 hours. The first buyer was able to secure their car in less than 20 minutes from the site going live. This sale process was implemented as a consequence of the demand for the Toyota 86 far outstripping supply (resulting in long delivery times) and a low BRZ supplies for Australia. As of 1 January 2014, the vehicle became available both online and at dealerships, with free servicing no longer included in the purchase.[69]\\r\\nScion made a similar decision in the United States, creating the 'First 86' program to allow 86 buyers to take delivery of their cars before the general public sales. On 12 January 2012 users had eight hours and six minutes to submit their requests to a program website. Winners were required to take their confirmation number and $500 to a dealer within 96 hours to claim their cars.[70] Scion produced a commercial called Close Call featuring Ken Gushi avoiding a collision with a deer while driving Scion FR-S in Mt. Diablo State Park in Northern California.[71]\\r\\nA British Toyota GT86 commercial titled The Real Deal was banned for encouraging motorists to drive irresponsibly.[72]\\r\\nIn Europe, the GT86 was awarded the following titles in 2012:\\r\\nIn Australia, the 86 was awarded the following titles in 2012:\\r\\nOther awards received include:\\r\\nThe Subaru BRZ was also crowned:\\r\\nIn addition, the Toyota-Subaru D-4S boxer engine was named one of Ward's 10 Best Engines in 2013.[84]\\r\\nIn 2011, with the unveiling of the Super BRZ Concept STi, Subaru also unveiled their latest entry in the Super GT series' GT300-category. R&D Sport would develop the BRZ GT300 to replace their Legacy for the 2012 season.[85] The BRZ GT300 does not utilize the production car's FA20 engine, instead opting for the Legacy's EJ20 engine.\\r\\nThe Toyota 86 MC also competes in the GT300. Unlike the BRZ GT300, the 86 MC is based on Super GT's Mother Chassis. As with all Mother Chassis-based cars, the 86 MC utilizes a standard Dome-produced chassis and GT Association-branded Nissan V8 engine; little is shared with the production car apart from its name and exterior styling.[86] In 2016, VivaC team Tsuchiya's 86 MC won the GT300 drivers' and teams' championships, with Takeshi Tsuchiya and Takamitsu Matsui at the wheel.\\r\\nToyota, in partnership with Gazoo Racing, announced plans to develop the 86 for motorsport use in multiple disciplines. Toyota and Gazoo will support private teams in the Super Taikyu Endurance Series and All-Japan Rally Championship.[87] Gazoo Racing entered 86s in the 24 Hours Nrburgring, winning their SP3 class in 2012. Privateers Toyota Swiss Racing also claimed the V3 category in the same year.[88] In the United Kingdom, GPRM is developing a turbocharged version of the 86 for classification in the SRO Group's GT4 category for use in Europe. The engine developments are being carried out by Nicholson McLaren Engines.[89]\\r\\nIn the United States, Ken Gushi utilized a GPP Scion Racing FR-S built by GReddy Racing for the US Formula Drift championship. The FR-S features a turbocharged EJ25 boxer engine from a Subaru WRX STI[90] produced more than 450?kW (600?bhp).[91] Ryan Tuerck drove a Scion FR-S powered by a stroked 2JZ-GTE producing more than 520?kW (700?bhp) for Retaks Backpacks and Maxxis Tires in the 2013 US Formula Drift championship.[92] Also in 2013, the FR-S replaced the Scion tC for the Toyota Pro/Celebrity Race at the Grand Prix of Long Beach. In all cases, the competition FR-S were standard production units modified for racing safety and reliability.[93] By contrast, the 86 entered by Nobuhiro Tajima to compete at the 2013 Pikes Peak Hill Climb only used the production unit's silhouette.[94]\\r\\nIn October 2012, Toyota Racing Development and Gazoo Racing announced a production racing model for the Toyota 86. The 86 Racing adds brake and oil cooler modifications, as well as a 4-point racing harness and rollcage. The stock 86 wheels are replaced by simple steel rims, while the exterior colour was only available in white.[95] Subaru followed in early 2013 with the BRZ RA Racing, featuring similar modifications. Both cars are only available in the Japanese market, and are eligible for a one-make racing series run by Gazoo Racing. Unlike the Toyota, the BRZ is available in any of the production car's colours.[96][97]\\r\\nIn February 2015, Toyota Australia announced a Pro-Am series with races exclusively during that country's V8 Supercars events from 2016. Its inceptor was long-time Toyota racing driver, Neal Bates. The race cars are based on manual production models with key specifications (such as engine management, extractors and exhaust, suspension, brakes, oil cooler, wheels and tyres) controlled to ensure their suitability and reliability while keeping costs as low as possible.[42][43][98]\\r\\nSince 2015 Toyota has competed in the Tire Rack One Lap of America, campaigning a modified Scion FR-S, prepared by engineers from the Production Engineering Division in Erlanger, Kentucky.[citation needed]\\r\\nThere are 3 versions of 2013 Scion FR-S built with $15,000 build budget, created as part of the eighth annual Scion Tuner Challenge. The FR-S Tuner Challenge vehicles are the: Carbon Stealth FR-S\\" by John Toca of Chicago, Illinois; FR-S GT by Daniel Song of Orange County, California; Minty FReSh by Chris Basselgia of Lebanon, Pennsylvania.\\r\\nThe vehicles were unveiled in 2012 SEMA show.[99]\\r\\nThe 2012 challenge was won by the Minty FReSh.[100]\\r\\nAt the January 2013 Tokyo Auto Salon, Subaru unveiled a BRZ Premium Sport Package concept featuring various STI parts as well as 19 inch BBS wheels and a carbon fiber roof.\\r\\n86Gstyle Cb is a version of Toyota 86 built by Gazoo Racing features a completely remodeled front designed to appeal to female drivers.[101]\\r\\nToyota GT86 Modellista is a version of Toyota 86 with new side skirts, rear bumper and diffuser, a special lip spoiler, 18 inch matte chrome Wing Dancer II wheels with 225/40 Toyo tires, a two-tone black and red interior, instrument cluster and interior panels are in a red metal finish.[102]\\r\\nTOM'S N086V is a version of Toyota 86 with a GR V6 engine rated at 298?kW (400?hp).[103]\\r\\nTRD Griffon Concept is a version of GT86 designed specifically for track driving, created by Toyota Racing Development. Changes include bonnet, roof, doors, boot lid and rear wings made from lightweight carbon fibre; carbonfibre reinforced plastic bumpers, wider front wings and rear diffuser; windows made from polycarbonate material, TRD driver's bucket seat, gear shift knob, ignition button and oil pressure and water temperature gauges; Momo steering wheel, Takata seatbelts, a TRD mechanical LSD replacing standard Torsen limited-slip differential, coil over suspension kit, final gear ratio shortened to 4.8:1, an oil cooler for the engine, a TRD mono block brake calliper kit with racing spec brake pads, TWS 18-inch wheels with Yokohama Advan tyres, stock Toyota GT86 engine. The vehicle is 227?kg (500?lb) lighter than stock Toyota GT86.\\r\\nTRD Griffon Concept was unveiled in 2013 Tokyo Auto Salon,[104] followed by 2013 Goodwood Festival of Speed.[105]\\r\\nThe FT-86 Open concept was a convertible concept vehicle based on Toyota 86. It included electrically operated multi-layered fabric roof with glass, high-contrast white and navy blue interior and exterior designed by Toyota Boshoku Milan Design (TBMD) to capture the spirit and atmosphere of Milan, white body colour, yellow-gold stitching in the floor mats and seats. It was first shown at the Geneva Motor Show in March 2013,[106][107] followed by the 2013 Tokyo Motor Show (with Flash Red body colour and electrically operated soft top)[108][109]\\r\\nHowever, Subaru brand chief Yasuyuki Yoshinaga has said that a convertible 86 would need a complete redesign to meet safety standards and that it is unlikely to happen.[110]\\r\\nAlso seen at the Tokyo Motor Show, this vehicle was presented as a combination of sport and utility adopting a heavily BRZ inspired shooting-brake body shape. Its compact body measured an overall length of 4,300?mm (169.3?in) and was described as what Subaru perceives to be the next trend in urban SUVs.[111][112]\\r\\nThis concept car is a Toyota 86/Scion FR-S modified by GAZOO Racing equipped with: a GRMN exclusive turbocharger and scroll supercharger 6-speed manual transmissionl GRMN suspension tuning; GRMN brake calipers and brake rotors; GRMN dual exhaust; GRMN, alloy wheels and tires; different front and rear fender panels and bumper bars; rear wing; rear garnish; bucket seats; 4-point seat belts; roll cage; back skin tone interior; extra instrumentation (boost, water temperature and oil temperature gauges).\\r\\nThe vehicle was unveiled in Nurburgring Circuit.[113][114]\\r\\nJust like the year before, the 2014 Tokyo Auto Salon saw the presentation of various Toyota 86-based custom models and concepts.\\r\\nThe GRMN 86 Concept is a version of Toyota 86 that incorporates the technical expertise gained through the 24 Hours Nrburgring endurance race, achieving optimal vehicle weight reduction, a lower center of gravity, an enhanced powertrain and improved body rigidity. It included FA20 engine, 6-speed manual transmission, 215/40R17 tires, carbon fiber engine cover, roof, rear hatch, diffuser, side skirt, tail wing, seats; polycarbonate windows, reinforced engine parts, oil cooler, rewritten ECU, mechanical limited slip differential.[117][118][119]\\r\\nThe 86xstyle Cb (model ZN6-A2E7) is a re-presentation of the concept seen at the 2013 Tokyo Auto Salon. Its listed features are a 6-speed automatic transmission, style Cb TB sport seat, leather-wrapped steering wheel, original meter and lighting, style Cb original floor mat, ToyotaxNHZD-W62G navigation system, dark smoke plated inner panel register RL, centre cluster garnish, door panel; metallic steering wheel door switch base, shift bezel; Zack suspension absorber, BBS style Cb original colour wheels (18x7J front, 18x7.5J rear), Bridgestone POTENZA S001 86 exclusive spec tires (215/40R18 85W front, 225/40R18 88W rear).[120]\\r\\n86 x Style Cb Spider (model ZN6-A2B8) is a Toyota convertible by Toyota Original Accessory, with 6-speed automatic transmission, fender garnish with side lamp, trunk spoiler and licence garnish, rear combination lamp (in dark smoke plated), backup lamp rear bumper, spider aero bulge, rear diffuser integrated into rear bumper, one-off style Cb sport seat, leather-wrapped steering wheel, style Cb original meter panel/new decorative panel with lighting, style Cb original floor mat, brembo brake with front 4-piston and rear 2-piston calipers, Goodyear Eagle LS Premium tires (215/40R18 89W front, 225/45R18 91W rear)[121][122]\\r\\nThe GAZOO Racing TRD 86 is a race car version of Toyota 86 for the TRD Rally Challenge, built by GAZOO Racing. It included 6-speed manual transmission.[123]\\r\\nThe GAZOO Racing LUCK 86 is a race car version of Toyota 86 for the JN3 class of Japanese Rally Championship, built by GAZOO Racing. It included 6-speed manual transmission.[118]\\r\\nThe GAZOO Racing SPIRIT 86 is a race car version of Toyota 86 for the Super Taikyu Series, built by GAZOO Racing. It included 6-speed manual transmission.[124]\\r\\nThe 86 Supercharger was produced by Team Netz with TOM'S is a version of the Toyota 86 built for the online community Area 86. It included 6-speed manual transmission, roots style supercharger, exclusive ECU, water-cooled intercooler, exclusive muffler, original aero kit, Saten white pearl 37J body panel, TEAM NETZ original front bumper (made by ABS), TOM'S side step, TOM's rear under spoiler, TOM'S ADVOX suspension kit with exclusive setting, TOM'S brake pad and brake line, 8.0J INSET44-inch TWS T66F wheel in original gun metal colour, 225/40R18 MichelinxPilot Sport 3 tires.[125]\\r\\nThe TRD Griffon Concept 014 is based on the 2013 TRD Griffon Concept.[126] In turn, the 86 TRD Customize Concept 014 is based on the 86 TRD Griffon Concept 014, with roof fin, rear diffuser, HID bulb kit, winker bulb, full bucket driver seat, passenger sports seat, shoulder pad set, interior panel set (carbon), steering wheel and interior boot set, sport meter set (water temperature, oil temperature, oil pressure), leather shift knob (for manual transmission car), knee pad, battery clamp, fuel cap cover, full length adjustable suspension set, pillow upper set, stabilizer set (front, rear), front strut tower bar, member brace set, door stabilizer set, sports air filter, high response muffler Ver.R, sound changer, circuit brake kit, clutch cover, clutch disc (sport phasing), fly wheel, quick shift set (18-inch cast aluminium TRD TF6 18x7.5J-inch wheels, Goodyear EAGLExRSxSportx86spec 225/40R18 tires), lug nut set (M12GP1.25), oil filler cap, sport oil filter, radiator cap.[127]\\r\\nThe Autobacs G7 86 Potenza (No. 557) (model ZN6-VPNT8A),[128] Manatura Kota-R BRZ (No. 61) (DBA-ZC6),[129] N1 Tech Potenza Win 86 (No. 100) (ZN6-VPNT8A),[130] NETZ Gunma FK Massimo 86 (No. 62) (ZN6-VPNT8A)[131] are race car versions of Toyota 86 Racing, BRZ RA Racing, Toyota 86 Racing, Toyota 86 Racing respectively, for the GAZOO Racing 86/BRZ Race.\\r\\nBuilt by Los Angeles metalshop, Cartel Customs, and displayed at 2014 SEMA show, this concept car is the first targa top version of any 86-based models. Apart from the Porsche 911-style removable roof, it features upgraded and lowered coil-over suspension, 19-in forged chrome wheels, upgrade braking system and a turbocharged engine with a centre exhaust tip. Inside it has an upgraded sound system and two-tone beige/black leather interior (including over the dashboard). The exterior is characterised by enlarged wheelarches and an integrated \\"duck tail\\" rear spoiler, and is painted in two-tone Azzurro California Blue with a contrasting black sill line up to the roof and rear louvre window.[132][133]\\r\\nSubaru unveiled the BRZ-based STI Performance Concept at the 2015 New York Auto Show. It stated that this concept car does not preview a production model but rather a visualization of the future application of the STI program to the BRZ. The concept car utilizes the same turbocharged 2.0-litre engine employed in the BRZ GT300 race car, producing an estimated 220?kW (300?bhp) and 330?lb{ft (447?N{m). Even so, Subaru also stated that a turbocharger will not find its way into the BRZ production. Mechanically, the concept car has chassis, suspension and brake upgrades from the Japan-only BRZ tS. Externally, it is distinguished by LED headlights and taillights, new-style alloy wheels and a full bodykit featuring new-design front fascia, rear diffuser and rear wing.\\r\\nThe Toyota 86 Shooting Brake Concept was displayed in Sydney, Australia in 2016.[clarification needed] Toyotas global chief engineer Tetsuya Tada saw a quarter scale clay model of the car during a trip to the Australian branch in 2014 and arranged for a full scale, fully function version to be built in Japan by Toyota's Takumi (\\"artisan\\") craftsmen.[136] Tada said, while we never say never, and I would love this concept to become a production reality, it is very much a concept that demonstrates the passion within Toyota for cars that are fun to drive\\". Commenting on the new car, Toyota's Australian Divisional Manager National Marketing Brad Cramb said: The Toyota 86 lends itself perfectly to a concept that expands its appeal with added versatility while retaining its sleek and sporty coupe styling and sharp, responsive driving character.\\r\\nIn 2016, Toyota UK created a \\"Fujiwara Tofu Shop\\" version of the car as a homage to the manga Initial D and the car the protagonist drives, an AE86 Sprinter Trueno.[137][138]","input":"What size engine does a subaru brz have?"},{"output":"Czech","context":"Czech (/?t??k/; ?e?tina Czech pronunciation: [?t????c?na]), historically also Bohemian[6] (/bo??hi?mi?n, b?-/;[7] lingua Bohemica in Latin), is a West Slavic language of the CzechÿSlovak group,[6] which is extensively influenced by Latin[8] and German.[9] Spoken by over 10 million people, it serves as the official language of the Czech Republic. Czech is closely related to Slovak, to the point of mutual intelligibility to a very high degree.[10]\\r\\nThe Czecho-Slovak group developed within West Slavic in the high medieval period, and the standardisation of Czech and Slovak within the CzechÿSlovak dialect continuum emerges in the early modern period. In the later 18th to mid-19th century, the modern written standard became codified in the context of the Czech National Revival. The main vernacular, known as Common Czech, is based on the vernacular of Prague, but is now spoken throughout most of the Czech Republic. The Moravian dialects spoken in the eastern part of the country are also classified as Czech, although some of their eastern variants are closer to Slovak.\\r\\nCzech has a moderately-sized phoneme inventory, comprising five vowels (each short or long) and twenty-five consonants (divided into \\"hard\\", \\"neutral\\" and \\"soft\\" categories). Words may contain uncommon (or complicated) consonant clusters, including one consonant represented by the graphemeor lack vowels altogether. Czech uses a simple orthography which phonologists have used as a model.\\r\\n\\r\\n\\r\\nCzech is a member of the West Slavic sub-branch of the Slavic branch of the Indo-European language family. This branch includes Polish, Kashubian, Upper and Lower Sorbian and Slovak. Slovak is the closest language genetic neighbor of Czech, followed by Polish and Silesian.[11]\\r\\nThe West Slavic languages are spoken in Central Europe. Czech is distinguished from other West Slavic languages by a more-restricted distinction between \\"hard\\" and \\"soft\\" consonants (see Phonology below).[11]\\r\\nThe term \\"Old Czech\\" is applied to the period predating the 16th century, with the earliest records of the high medieval period also classified as \\"early Old Czech\\", but it is also possible to speak simply about \\"Medieval Czech\\".\\r\\nAround the 7th century, the Slavic expansion reached Central Europe, settling on the eastern fringes of the Frankish Empire. The West Slavic polity of Great Moravia formed by the 9th century. The Christianization of Bohemia took place during the 9th and 10th centuries. The diversification of the Czech-Slovak group within West Slavic began around that time, marked among other things by its ephemeral use of the voiced velar fricative consonant (/?/)[12] and consistent stress on the first syllable.[13]\\r\\nThe Bohemian (Czech) language is first recorded in writing in glosses and short notes during the 12th to 13th centuries. Literary works written in Czech appear in the early 14th century and administrative documents first appear towards the late 14th century. The first complete Bible translation also dates to this period.[14] Old Czech texts, including poetry and cookbooks, were produced outside the university as well.[15]\\r\\nLiterary activity becomes widespread in the early 15th century in the context of the Bohemian Reformation. Jan Hus contributed significantly to the standardization of Czech orthography, advocated for widespread literacy among Czech commoners (particularly in religion) and made early efforts to model written Czech after the spoken language.[14]\\r\\nThere was no standardization distinguishing between Czech and Slovak prior to the 15th century.[16] In the 16th century, the division between Czech and Slovak becomes apparent, marking the confessional division between Lutheran Protestants in Slovakia using Czech orthography and Catholics, especially Slovak Jesuits, beginning to use a separate Slovak orthography based on the language of the Trnava region.\\r\\nThe publication of the Kralice Bible between 1579 and 1593 (the first complete Czech translation of the Bible from the original languages) became very important for standardization of the Czech language in the following centuries.\\r\\nIn 1615, the Bohemian diet tried to declare Czech to be the only official language of the kingdom. After the Bohemian Revolt (of predominantly Protestant aristocracy) which was defeated by the Habsburgs in 1620, the Protestant intellectuals had to leave the country. This emigration together with other consequences of the Thirty Years' War had a negative impact on the further use of the Czech language. In 1627, Czech and German became official languages of the Kingdom of Bohemia and in the 18th century German became dominant in Bohemia and Moravia, especially among the upper classes.[17]\\r\\nThe modern standard Czech language originates in standardization efforts of the 18th century.[18] By then the language had developed a literary tradition, and since then it has changed little; journals from that period have no substantial differences from modern standard Czech, and contemporary Czechs can understand them with little difficulty.[19] Changes include the morphological shift of  to ej and  to  (although  survives for some uses) and the merging of  and the former ej.[20] Sometime before the 18th century, the Czech language abandoned a distinction between phonemic /l/ and /?/ which survives in Slovak.[21]\\r\\nWith the beginning of the national revival of the mid-18th century, Czech historians began to emphasize their people's accomplishments from the 15th through the 17th centuries, rebelling against the Counter-Reformation (the Habsburg re-catholization efforts which had denigrated Czech and other non-Latin languages).[22] Czech philologists studied sixteenth-century texts, advocating the return of the language to high culture.[23] This period is known as the Czech National Revival[24] (or Renaissance).[23]\\r\\nDuring the national revival, in 1809 linguist and historian Josef Dobrovsky released a German-language grammar of Old Czech entitled Ausfhrliches Lehrgeb?ude der b?hmischen Sprache (Comprehensive Doctrine of the Bohemian Language). Dobrovsky had intended his book to be descriptive, and did not think Czech had a realistic chance of returning as a major language. However, Josef Jungmann and other revivalists used Dobrovsky's book to advocate for a Czech linguistic revival.[24] Changes during this time included spelling reform (notably,  in place of the former j and j in place of g), the use of t (rather than ti) to end infinitive verbs and the non-capitalization of nouns (which had been a late borrowing from German).[21] These changes differentiated Czech from Slovak.[25] Modern scholars disagree about whether the conservative revivalists were motivated by nationalism or considered contemporary spoken Czech unsuitable for formal, widespread use.[24]\\r\\nAdherence to historical patterns was later relaxed and standard Czech adopted a number of features from Common Czech (a widespread, informal register), such as leaving some proper nouns undeclined. This has resulted in a relatively high level of homogeneity among all varieties of the language.[26]\\r\\nIn 2005 and 2007, Czech was spoken by about 10 million residents of the Czech Republic.[17][27] A Eurobarometer survey conducted from January to March 2012 found that the first language of 98 percent of Czech citizens was Czech, the third-highest in the European Union (behind Greece and Hungary).[28]\\r\\nCzech, the official language of the Czech Republic (a member of the European Union since 2004), is one of the EU's official languages and the 2012 Eurobarometer survey found that Czech was the foreign language most often used in Slovakia.[28] Economist Jonathan van Parys collected data on language knowledge in Europe for the 2012 European Day of Languages. The five countries with the greatest use of Czech were the Czech Republic (98.77 percent), Slovakia (24.86 percent), Portugal (1.93 percent), Poland (0.98 percent) and Germany (0.47 percent).[29]\\r\\nCzech speakers in Slovakia primarily live in cities. Since it is a recognised minority language in Slovakia, Slovak citizens who speak only Czech may communicate with the government in their language to the extent that Slovak speakers in the Czech Republic may do so.[30]\\r\\nImmigration of Czechs from Europe to the United States occurred primarily from 1848 to 1914. Czech is a Less Commonly Taught Language in U.S. schools, and is taught at Czech heritage centers. Large communities of Czech Americans live in the states of Texas, Nebraska and Wisconsin.[31] In the 2000 United States Census, Czech was reported as the most-common language spoken at home (besides English) in Valley, Butler and Saunders Counties, Nebraska and Republic County, Kansas. With the exception of Spanish (the non-English language most commonly spoken at home nationwide), Czech was the most-common home language in over a dozen additional counties in Nebraska, Kansas, Texas, North Dakota and Minnesota.[32] As of 2009, 70,500 Americans spoke Czech as their first language (49th place nationwide, behind Turkish and ahead of Swedish).[33]\\r\\nThe main vernacular is \\"Common Czech\\", based on the dialect of the Prague region. Other Bohemian dialects have become marginalized, while Moravian dialects remain more widespread, with a political movement for Moravian linguistic revival active since the 1990s.\\r\\nThe main Czech vernacular, spoken primarily near Prague but also throughout the country, is known as Common Czech (obecn ?e?tina). This is an academic distinction; most Czechs are unaware of the term or associate it with vernacular (or incorrect) Czech.[34] Compared to standard Czech, Common Czech is characterized by simpler inflection patterns and differences in sound distribution.[35]\\r\\nCommon Czech has become ubiquitous in most parts of the Czech Republic since the later 20th century. It is usually defined as an interdialect used in common speech in Bohemia and western parts of Moravia (by about two thirds of all inhabitants of the Czech Republic). Common Czech is not codified, but some of its elements have become adopted in the written standard. Since the second half of the 20th century, Common Czech elements have also been spreading to regions previously unaffected, as a consequence of media influence. Standard Czech is still the norm for politicians, businesspeople and other Czechs in formal situations, but Common Czech is gaining ground in journalism and the mass media.[35]\\r\\nCommon Czech is characterized by quite regular differences from the standard morphology and phonology. These variations are more or less common to all Common Czech dialects:\\r\\nExample of declension (with the comparison with the standard Czech):\\r\\nmlady ?lovk ÿ young man/person, mlad lid ÿ young people, mlady stt ÿ young state, mlad ?ena ÿ young woman, mlad zv?e ÿ young animal\\r\\nApart from the Common Czech vernacular, there remain a variety of other Bohemian dialect, mostly in marginal rural areas. Dialect use began to weaken in the second half of the 20th century, and by the early 1990s dialect use was stigmatized, associated with the shrinking lower class and used in literature or other media for comedic effect. Increased travel and media availability to dialect-speaking populations has encouraged them to shift to (or add to their own dialect) standard Czech.[36] Although Czech has received considerable scholarly interest for a Slavic language, this interest has focused primarily on modern standard Czech and historical texts rather than dialects.[34]\\r\\nThe Czech Statistical Office in 2003 recognized the following Bohemian dialects:[37]\\r\\nThe Czech dialects spoken in Moravia and Silesia are known as Moravian (morav?tina). In the Austro-Hungarian Empire, \\"Bohemian-Moravian-Slovak\\" was a language citizens could register as speaking (with German, Polish and several others).[38] Of the Czech dialects, only Moravian is distinguished in nationwide surveys by the Czech Statistical Office. As of 2011, 62,908 Czech citizens spoke Moravian as their first language and 45,561 were diglossal (speaking Moravian and standard Czech as first languages).[39]\\r\\nBeginning in the sixteenth century, some varieties of Czech resembled Slovak;[16] the southeastern Moravian dialects, in particular, are sometimes considered dialects of Slovak rather than Czech. These dialects form a continuum between the Czech and Slovak languages,[40] using the same declension patterns for nouns and pronouns and the same verb conjugations as Slovak.[41]\\r\\nThe Czech Statistical Office in 2003 recognized the following Moravian dialects:[37]\\r\\nIn a 1964 textbook on Czech dialectology, B?etislav Koudela used the following sentence to highlight phonetic differences between dialects:[42]\\r\\nCzech and Slovak have been considered mutually intelligible; speakers of either language can communicate with greater ease than those of any other pair of West Slavic languages. Since the 1993 dissolution of Czechoslovakia, mutual intelligibility has declined for younger speakers, probably because Czech speakers now experience less exposure to Slovak and vice versa.[43]\\r\\nIn phonetic differences, Czech is characterized by a glottal stop before initial vowels and Slovak by its less-frequent use of long vowels than Czech;[44] however, Slovak has long forms of the consonants r and l when they function as vowels.[45] Phonemic differences between the two languages are generally consistent, typical of two dialects of a language. Grammatically, although Czech (unlike Slovak) has a vocative case,[44] both languages share a common syntax.[16]\\r\\nOne study showed that Czech and Slovak lexicons differed by 80 percent, but this high percentage was found to stem primarily from differing orthographies and slight inconsistencies in morphological formation;[46] Slovak morphology is more regular (when changing from the nominative to the locative case, Praha becomes Praze in Czech and Prahe in Slovak). The two lexicons are generally considered similar, with most differences found in colloquial vocabulary and some scientific terminology. Slovak has slightly more borrowed words than Czech.[16]\\r\\nThe similarities between Czech and Slovak led to the languages being considered a single language by a group of 19th-century scholars who called themselves \\"Czechoslavs\\" (?echoslovan), believing that the peoples were connected in a way which excluded German Bohemians and (to a lesser extent) Hungarians and other Slavs.[47] During the First Czechoslovak Republic (1918ÿ1938), although \\"Czechoslovak\\" was designated as the republic's official language, both Czech and Slovak written standards were used. Standard written Slovak was partially modeled on literary Czech, and Czech was preferred for some official functions in the Slovak half of the republic. Czech influence on Slovak was protested by Slovak scholars, and when Slovakia broke off from Czechoslovakia in 1938 as the Slovak State (which then aligned with Nazi Germany in World War II), literary Slovak was deliberately distanced from Czech. When the Axis powers lost the war and Czechoslovakia reformed, Slovak developed somewhat on its own (with Czech influence); during the Prague Spring of 1968, Slovak gained independence from (and equality with) Czech,[16] due to the transformation of Czechoslovakia from a unitary state to a federation. Since the dissolution of Czechoslovakia in 1993, \\"Czechoslovak\\" has referred to improvised pidgins of the languages which have arisen from the decrease in mutual intelligibility.[48]\\r\\nCzech vocabulary derives primarily from Slavic, Baltic and other Indo-European roots. Although most verbs have Balto-Slavic origins, pronouns, prepositions and some verbs have wider, Indo-European roots.[49] Some loanwords have been restructured by folk etymology to resemble native Czech words (h?bitov, \\"graveyard\\" and listina, \\"list\\").[50]\\r\\nMost Czech loanwords originated in one of two time periods. Earlier loanwords, primarily from German,[51] Greek and Latin,[52] arrived before the Czech National Revival. More recent loanwords derive primarily from English and French,[51] and also from Hebrew, Arabic and Persian. Many Russian loanwords, principally animal names and naval terms, also exist in Czech.[53]\\r\\nAlthough older German loanwords were colloquial, recent borrowings from other languages are associated with high culture.[51] During the nineteenth century, words with Greek and Latin roots were rejected in favor of those based on older Czech words and common Slavic roots; \\"music\\" is muzyka in Polish and ֿ (muzyka) in Russian, but in Czech it is hudba.[52] Some Czech words have been borrowed as loanwords into English and other languagesfor example, robot (from robota, \\"labor\\")[54] and polka (from polka, \\"Polish woman\\" or from \\"p?lka\\" \\"half\\").[55]\\r\\nThe modern written standard is directly based on the standardisation during the Czech National Revival in the 1830s, significantly influenced by Josef Jungmann's Czech-German dictionary published during 1834ÿ1839. Jungmann used vocabulary of the Bible of Kralice (1579ÿ1613) period and of the language used by his contemporaries. He borrowed words not present in Czech from other Slavic languages or created neologisms.[56]\\r\\nCzech contains ten basic vowel phonemes, and three more found only in loanwords. They are /a/, /?/, /?/, /o/, and /u/, their long counterparts /a?/, /??/, /i?/, /o?/ and /u?/, and three diphthongs, /ou?/, /au?/ and /?u?/. The latter two diphthongs and the long /o?/ are exclusive to loanwords.[57] Vowels are never reduced to schwa sounds when unstressed.[58] Each word usually has primary stress on its first syllable, except for enclitics (minor, monosyllabic, unstressed syllables). In all words of more than two syllables, every odd-numbered syllable receives secondary stress. Stress is unrelated to vowel length, and the possibility of stressed short vowels and unstressed long vowels can be confusing to students whose native language combines the features (such as English).[59]\\r\\nVoiced consonants with unvoiced counterparts are unvoiced at the end of a word, or when they are followed by unvoiced consonants.[60] Czech consonants are categorized as \\"hard\\", \\"neutral\\" or \\"soft\\":\\r\\nThis distinction describes the declension patterns of nouns, which is based on the category of a noun's ending consonant. Hard consonants may not be followed by i or  in writing, or soft ones by y or y (except in loanwords such as kilogram).[61] Neutral consonants may take either character. Hard consonants are sometimes known as \\"strong\\", and soft ones as \\"weak\\".[62]\\r\\nThe phoneme represented by the letter ? (capital ?) is considered unique to Czech.[63] It represents the raised alveolar non-sonorant trill (IPA: [r?]), a sound somewhere between Czech's r and ? (example: ?\\"?eka\\" (river)?(help{info)),[63] and is present in Dvo?k.\\r\\nThe consonants /r/ and /l/ can be syllabic, acting as syllable nuclei in place of a vowel. This can be difficult for non-native speakers to pronounce, and Str? prst skrz krk (\\"Stick [your] finger down [your] throat\\") is a Czech tongue twister.[64]\\r\\nConsonants\\r\\nVowels\\r\\nSlavic grammar is fusional; its nouns, verbs, and adjectives are inflected by phonological processes to modify their meanings and grammatical functions, and the easily separable affixes characteristic of agglutinative languages are limited.[65] Slavic-language inflection is complex and pervasive, inflecting for case, gender and number in nouns and tense, aspect, mood, person and subject number and gender in verbs.[66]\\r\\nParts of speech include adjectives, adverbs, numbers, interrogative words, prepositions, conjunctions and interjections.[67] Adverbs are primarily formed by taking the final y or  of an adjective and replacing it with e, , or o.[68] Negative statements are formed by adding the affix ne- to the verb of a clause, with one exception: je (he, she or it is) becomes nen.[69]\\r\\nBecause Czech uses grammatical case to convey word function in a sentence (instead of relying on word order, as English does), its word order is flexible. As a pro-drop language, in Czech an intransitive sentence can consist of only a verb; information about its subject is encoded in the verb.[70] Enclitics (primarily auxiliary verbs and pronouns) must appear in the second syntactic slot of a sentence, after the first stressed unit. The first slot must contain a subject and object, a main form of a verb, an adverb or a conjunction (except for the light conjunctions a, \\"and\\", i, \\"and even\\" or ale, \\"but\\").[71]\\r\\nCzech syntax has a subjectÿverbÿobject sentence structure. In practice, however, word order is flexible and used for topicalization and focus. Although Czech has a periphrastic passive construction (like English), colloquial word-order changes frequently produce the passive voice. For example, to change \\"Peter killed Paul\\" to \\"Paul was killed by Peter\\" the order of subject and object is inverted: Petr zabil Pavla (\\"Peter killed Paul\\") becomes \\"Paul, Peter killed\\" (Pavla zabil Petr). Pavla is in the accusative case, the grammatical object (in this case, the victim) of the verb.[72]\\r\\nA word at the end of a clause is typically emphasized, unless an upward intonation indicates that the sentence is a question:[73]\\r\\nIn portions of Bohemia (including Prague), questions such as J pes bagetu? without an interrogative word (such as co, \\"what\\" or kdo, \\"who\\") are intoned in a slow rise from low to high, quickly dropping to low on the last word or phrase.[74]\\r\\nIn Czech syntax, adjectives precede nouns.[75] Relative clauses are introduced by relativizers such as the adjective ktery, analogous to the English relative pronouns \\"which\\", \\"that\\", \\"who\\" and \\"whom\\". As with other adjectives, it is declined into the appropriate case (see Declension below) to match its associated noun, person and number. Relative clauses follow the noun they modify, and the following is a glossed example:[76]\\r\\nEnglish: I want to visit the university that John attends.\\r\\nIn Czech, nouns and adjectives are declined into one of seven grammatical cases. Nouns are inflected to indicate their use in a sentence. A nominativeÿaccusative language, Czech marks subject nouns with nominative case and object nouns with accusative case. The genitive case marks possessive nouns and some types of movement. The remaining cases (instrumental, locative, vocative and dative) indicate semantic relationships, such as secondary objects, movement or position (dative case) and accompaniment (instrumental case). An adjective's case agrees with that of the noun it describes. When Czech children learn their language's declension patterns, the cases are referred to by number:[77]\\r\\nSome Czech grammatical texts order the cases differently, grouping the nominative and accusative (and the dative and locative) together because those declension patterns are often identical; this order accommodates learners with experience in other inflected languages, such as Latin or Russian. This order is nominative, accusative, genitive, dative, locative, instrumental and vocative.[77]\\r\\nSome prepositions require the nouns they modify to take a particular case. The cases assigned by each preposition are based on the physical (or metaphorical) direction, or location, conveyed by it. For example, od (from, away from) and z (out of, off) assign the genitive case. Other prepositions take one of several cases, with their meaning dependent on the case; na means \\"onto\\" or \\"for\\" with the accusative case, but \\"on\\" with the locative.[78]\\r\\nExamples of declension patterns (using prepositions) for a few nouns with adjectives follow. Only one plural example is given, since plural declension patterns are similar across genders.\\r\\nThis is a glossed example of a sentence using several cases:\\r\\nEnglish: I carried the box into the house with my friend.\\r\\nCzech distinguishes three gendersmasculine, feminine, and neuterand the masculine gender is subdivided into animate and inanimate. With few exceptions, feminine nouns in the nominative case end in -a, -e, or -ost; neuter nouns in -o, -e, or -, and masculine nouns in a consonant.[79] Adjectives agree in gender and animacy (for masculine nouns in the accusative or genitive singular and the nominative plural) with the nouns they modify.[80] The main effect of gender in Czech is the difference in noun and adjective declension, but other effects include past-tense verb endings: for example, dlal (he did, or made); dlala (she did, or made) and dlalo (it did, or made).[81]\\r\\nNouns are also inflected for number, distinguishing between singular and plural. Typical of a Slavic language, Czech cardinal numbers one through four allow the nouns and adjectives they modify to take any case, but numbers over five place these nouns and adjectives in the genitive case when the entire expression is in nominative or accusative case. The Czech koruna is an example of this feature; it is shown here as the subject of a hypothetical sentence, and declined as genitive for numbers five and up.[82]\\r\\nNumerical words decline for case and, for numbers one and two, for gender. Numbers one through five are shown below as examples, and have some of the most exceptions among Czech numbers. The number one has declension patterns identical to those of the demonstrative pronoun, to.[83][84]\\r\\nAlthough Czech's grammatical numbers are singular and plural, several residuals of dual forms remain. Some nouns for paired body parts use a historical dual form to express plural in some cases: ruka (hand)ruce (nominative); noha (leg)nohama (instrumental), nohou (genitive/locative); oko (eye)o?i, and ucho (ear)u?i. While two of these nouns are neuter in their singular forms, all plural forms are considered feminine; their gender is relevant to their associated adjectives and verbs.[85] These forms are plural semantically, used for any non-singular count, as in mezi ?ty?ma o?ima (face to face, lit. among four eyes). The plural number paradigms of these nouns are actually a mixture of historical dual and plural forms. For example, nohy (legs; nominative/accusative) is a standard plural form of this type of noun.\\r\\nCzech verb conjugation is less complex than noun and adjective declension because it codes for fewer categories. Verbs agree with their subjects in person (first, second or third) and number (singular or plural), and are conjugated for tense (past, present or future). For example, the conjugated verb mluvme (we speak) is in the present tense and first-person plural; it is distinguished from other conjugations of the infinitive mluvit by its ending, me.[86]\\r\\nTypical of Slavic languages, Czech marks its verbs for one of two grammatical aspects: perfective and imperfective. Most verbs are part of inflected aspect pairsfor example, koupit (perfective) and kupovat (imperfective). Although the verbs' meaning is similar, in perfective verbs the action is completed and in imperfective verbs it is ongoing. This is distinct from past and present tense,[87] and any Czech verb of either aspect can be conjugated into any of its three tenses.[86] Aspect describes the state of the action at the time specified by the tense.[87]\\r\\nThe verbs of most aspect pairs differ in one of two ways: by prefix or by suffix. In prefix pairs, the perfective verb has an added prefixfor example, the imperfective pst (to write, to be writing) compared with the perfective napsat (to write down, to finish writing). The most common prefixes are na-, o-, po-, s-, u-, vy-, z- and za-.[88] In suffix pairs, a different infinitive ending is added to the perfective stem; for example, the perfective verbs koupit (to buy) and prodat (to sell) have the imperfective forms kupovat and prodvat.[89] Imperfective verbs may undergo further morphology to make other imperfective verbs (iterative and frequentative forms), denoting repeated or regular action. The verb jt (to go) has the iterative form chodit (to go repeatedly) and the frequentative form chodvat (to go regularly).[90]\\r\\nMany verbs have only one aspect, and verbs describing continual states of beingbyt (to be), chtt (to want), moct (to be able to), le?et (to lie down, to be lying down)have no perfective form. Conversely, verbs describing immediate states of changefor example, othotnt (to become pregnant) and nadchnout se (to become enthusiastic)have no imperfective aspect.[91]\\r\\nAlthough Czech's use of present and future tense is largely similar to that of English, the language uses past tense to represent the English present perfect and past perfect; ona b?ela could mean she ran, she has run or she had run.[92]\\r\\nIn some contexts, Czech's perfective present (which differs from the English present perfect) implies future action; in others, it connotes habitual action.[93] As a result, the language has a proper future tense to minimize ambiguity. The future tense does not involve conjugating the verb describing an action to be undertaken in the future; instead, the future form of byt (as shown in the table at left) is placed before the infinitive (for example, budu jst\\"I will eat\\").[94]\\r\\nThis conjugation is not followed by byt itself, so future-oriented expressions involving nouns, adjectives, or prepositions (rather than verbs) omit byt. \\"I will be happy\\" is translated as Budu ??astny (not Budu byt ??astny).[94]\\r\\nThe infinitive form ends in t (archaically, ti). It is the form found in dictionaries and the form that follows auxiliary verbs (for example, m??u t sly?et\\"I can hear you\\").[95] Czech verbs have three grammatical moods: indicative, imperative and conditional.[96] The imperative mood adds specific endings for each of three person (or number) categories: -?/-i/-ej for second-person singular, -te/-ete/-ejte for second-person plural and -me/-eme/-ejme for first-person plural.[97] The conditional mood is formed with a particle after the past-tense verb. This mood indicates possible events, expressed in English as \\"I would\\" or \\"I wish\\".[98]\\r\\nMost Czech verbs fall into one of five classes, which determine their conjugation patterns. The future tense of byt would be classified as a Class I verb because of its endings. Examples of the present tense of each class and some common irregular verbs follow in the tables below:[99]\\r\\nCzech has one of the most phonemic orthographies of all European languages. Its thirty-one graphemes represent thirty sounds (in most dialects, i and y have the same sound), and it contains only one digraph: ch, which follows h in the alphabet.[100] As a result, some of its characters have been used by phonologists to denote corresponding sounds in other languages. The characters q, w and x appear only in foreign words.[101] The h?ek () is used with certain letters to form new characters:andas well as , ,and ? (the latter five uncommon outside Czech). The last two letters are sometimes written with a comma above (?, an abbreviated h?ek) because of their height.[102] The character ܇ exists only in loanwords and onomatopoeia.[103]\\r\\nUnlike most European languages, Czech distinguishes vowel length; long vowels are indicated by an acute accent or, occasionally witha ring. Long u is usually written ~ at the beginning of a word or morpheme (~roda, ne~rodny) and ? elsewhere,[104] except for loanwords (sk~tr) or onomatopoeia (b~).[105] Long vowels and  are not considered separate letters.[106]\\r\\nCzech typographical features not associated with phonetics generally resemble those of most Latin European languages, including English. Proper nouns, honorifics, and the first letters of quotations are capitalized, and punctuation is typical of other Latin European languages. Writing of ordinal numerals is similar to most European languages. The Czech language uses a decimal comma instead of a decimal point. When writing a long number, spaces between every three numbers (e.g. between hundreds and thousands) may be used for better orientation in handwritten texts, but not in decimal places, like in English. The number 1,234,567.8910 may be written as 1234567,8910 or 1 234 567,8910. Ordinal numbers (1st) use a point as in German (1.). In proper noun phrases (except personal names), only the first word is capitalized (Pra?sky hrad, Prague Castle).[107][108]\\r\\nAccording to Article 1 of the United Nations Universal Declaration of Human Rights:\\r\\nCzech: V?ichni lid se rod svobodn a sob rovn co do d?stojnosti a prv. Jsou nadni rozumem a svdomm a maj spolu jednat v duchu bratrstv.[109]\\r\\nEnglish: \\"All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood.\\"[110]","input":"What language do they speak in the czech republic?"},{"output":"aphelion","context":"The perihelion (/?p?r??hi?li?n/) of any orbit of a celestial body about the Sun is the point where the body comes nearest to the Sun. It is the opposite of aphelion (/?p?hi?li?n/), which is the point in the orbit where the celestial body is farthest from the Sun.[1]\\r\\n\\r\\n\\r\\nThe words perihelion and aphelion were coined by Johannes Kepler[2] to describe the orbital motion of the planets. The words are formed from the prefixes peri- (Greek:near) and apo- (Greek: ??, away from) affixed to the Greek word for the sun, ??.[3]\\r\\nPerihelion and aphelion are sometimes incorrectly used for the orbits of objects about bodies other than the Sun. The correct terms are:\\r\\nAccording to Kepler's first law of planetary motion, all planets, comets, and asteroids in the Solar System have approximately elliptical orbits around the Sun.[4] Newton's and Einstein's laws of gravity imply that the orbits are only approximately elliptical because of perturbations due to the gravitational attraction of other bodies. Every ellipse has two focus points, and the Sun is at one of these focus points for the elliptical orbits of its satellites. Hence, an orbiting body has a closest and a farthest point from its parent object, that is, a perihelion and an aphelion. Each extreme is known as an apsis.\\r\\nOrbital eccentricity measures the flatness (departure from a perfect circle) of the orbit.\\r\\nEarth is about 147.1 million kilometers (91.4 million miles) from the Sun at perihelion around January 3, in contrast to about 152.1 million kilometers (94.5 million miles) at aphelion around July 4  a difference of about 5.0 million kilometers (3.1 million miles). (These dates change over time due to precession and other orbital factors, which follow cyclical patterns known as Milankovitch cycles. For a table of these dates for various years, see Apsis.)\\r\\nBecause of the increased distance at aphelion, only 93.55% of the solar radiation from the Sun falls on a given area of land as does at perihelion. However, this fluctuation does not account for the seasons,[5] as it is summer in the northern hemisphere when it is winter in the southern hemisphere and vice versa. Instead, seasons result from the tilt of Earth's axis, which is 23.4 degrees away from perpendicular to the plane of Earth's orbit around the sun. Winter falls on the hemisphere where sunlight strikes least directly, and summer falls where sunlight strikes most directly, regardless of the Earth's distance from the Sun.\\r\\nIn the northern hemisphere, summer occurs at the same time as aphelion. Despite this, there are larger land masses in the northern hemisphere, which are easier to heat than the seas. Consequently, summers are 2.3?C (4?F) warmer in the northern hemisphere than in the southern hemisphere under similar conditions.[6]","input":"What represents the greatest distance sun to earth?"},{"output":"about 100 years","context":"Project Longshot was a conceptual interstellar spacecraft design. It would have been an unmanned probe, intended to fly to and enter orbit around Alpha Centauri B powered by nuclear pulse propulsion.[1]\\r\\n\\r\\n\\r\\nDeveloped by the US Naval Academy and NASA, from 1987 to 1988, Longshot was designed to be built at Space Station Freedom, the precursor to the existing International Space Station. Similar to Project Daedalus, Longshot was designed with existing technology in mind, although some development would have been required. For example, the Project Longshot concept assumes \\"a three-order-of-magnitude leap over current propulsion technology\\".[1]\\r\\nUnlike Daedalus, which used an open-cycle fusion engine, Longshot would use a long-lived nuclear fission reactor for power. Initially generating 300 kilowatts, the reactor would power a number of lasers in the engine that would be used to ignite inertial confinement fusion similar to that in Daedalus. The main design difference is that Daedalus also relied on the fusion reaction to power the ship, whereas in the Longshot design the internal reactor would provide this power.[1]\\r\\nThe reactor would also be used to power a laser for communications back to Earth, with a maximum power of 250 kW. For most of the journey, this would be used at a much lower power for sending data about the interstellar medium; but during the flyby, the main engine section would be discarded and the entire power capacity dedicated to communications at about 1 kilobit per second.\\r\\nLongshot would have a mass of 396 tonnes (873,000?lb) at the start of the mission including 264 tonnes of helium-3/deuterium pellet fuel/propellant. The active mission payload, which includes the fission reactor but not the discarded main propulsion section, would have a mass of around 30 tonnes.\\r\\nA difference in the mission architecture between Longshot and the Daedalus study is that Longshot would go into orbit about the target star while the higher speed Daedalus would do a one shot fly-by lasting a comparatively short time.\\r\\nThe journey to Alpha Centauri B orbit would take about 100 years, at an average velocity of approximately 13411?km/s (about 4.5% the speed of light) and another 4.39?years would be necessary for the data to reach Earth.\\r\\nAccording to the Journal article \\"Alpha Centauri: Our First target for Interstellar Probes,\\" after the completion of the New Horizons primary mission of Pluto Fly-By, we should set our sights at other star systems like Alpha Centauri. This would be a good target because of its proximity to Earth.[2]\\r\\nBeals, K. A., M. Beaulieu, F. J. Dembia, J. Kerstiens, D. L. Kramer, J. R. West and J. A. Zito. Project Longshot: An Unmanned Probe To Alpha Centauri. U S Naval Academy. NASA-CR-184718. 1988.\\r\\n The full text of Project Longshot: An Unmanned Probe To Alpha Centauri at Wikisource (Please note that the article cited here refers to an Alpha and Beta Centauri as the orbital target of the mission, but the correct nomenclature for these two components of the Alpha Centauri binary star system is Alpha Centauri A and B. Beta Centauri is an entirely different, unassociated star.)","input":"How long would it take to get to alpha centauri with current technology?"},{"output":"a whale","context":"The characters in the American animated television series SpongeBob SquarePants were created by artist, animator, and former marine biologist Stephen Hillenburg. The series chronicles the adventures of the title character and his various friends in the fictional underwater city of Bikini Bottom. Most characters are anthropomorphic sea creatures based on real-life species. Many of the characters' designs originated in an unpublished educational comic book titled The Intertidal Zone, which Hillenburg created in 1989.\\r\\nSpongeBob SquarePants features the voices of Tom Kenny, Bill Fagerbakke, Rodger Bumpass, Clancy Brown, Mr. Lawrence, Jill Talley, Carolyn Lawrence, Mary Jo Catlett and Lori Alan. Most one-off and background characters are voiced by Dee Bradley Baker, Sirena Irwin, Bob Joles, Mark Fite and Thomas F. Wilson. In addition to the series' regular cast, various celebrities from a wide range of professions have voiced guest characters and recurring roles.\\r\\nThe show's characters have received positive critical reception and attention from celebrities. They have made frequent appearances in media outside of the television show, including a theatrical film series and many video games. The characters have also been referenced and parodied throughout popular culture. The title character SpongeBob became a merchandising icon during the height of the show's second season and has seen continued commercial popularity.\\r\\n\\r\\n\\r\\nStephen Hillenburg originally conceived early versions of the SpongeBob SquarePants characters in 1984, while he was teaching and studying marine biology at what is now the Orange County Marine Institute in Dana Point, California.[1] During this period, Hillenburg became fascinated with animation, and wrote a comic book titled The Intertidal Zone starring various anthropomorphic forms of sea creatures, many of which would evolve into SpongeBob SquarePants characters,[2] including \\"Bob the Sponge\\", who was the co-host of the comic and resembled an actual sea sponge as opposed to SpongeBob.[3] In 1987, Hillenburg left the institute to pursue his dream of becoming an animator.[2][3]\\r\\nPatrick, Mr. Krabs, Pearl, and Squidward were the first other characters Hillenburg created for the show.[4] Many of their characteristics were based on Hillenburg's experiences during his time at the Ocean Institute or inspired by the traits of their species. Patrick's personality embodies the nature of the starfish; according to Hillenburg, they look \\"dumb and slow\\" but are \\"very active and aggressive\\" in reality, like Patrick.[5] Hillenburg drew inspiration from his former manager at a seafood restaurant while creating Mr. Krabs.[6] According to him, this manager was redheaded, muscular, and a former army cook; these traits were all adapted into Krabs' character.[7] His decision to design Pearl was influenced by his regular supervision of whale watches at the Ocean Institute, as well as by a cetacean skeleton at the institute.[8] He drew Pearl with an oversized, almost geometric head as a reference to sperm whales having the largest brain size of any extant animal on Earth.[4] He designed Squidward as an octopus because of the species' bulbous mantle; the octopus, he said, has \\"such a large bulbous head and Squidward thinks he's an intellectual, so of course he's gonna have [one].\\"[5] Hillenburg drew Squidward with six tentacles because \\"it was really just simpler for animation to draw him with six legs instead of eight\\".[5]\\r\\nSeveral additions were made to the series' main cast before and after Hillenburg pitched the series to Nickelodeon; in his series bible, he added Sandy Cheeks the squirrel as a \\"character that could be a friend to SpongeBob but not a love interest.\\"[9] Plankton and Karen were included in his bible but were not meant to make regular appearances; Plankton's voice actor Mr. Lawrence said that he \\"was only supposed to be in one or two episodes, but I was a writer on the show and I really liked this character\\".[10] Following his first voice recording, Lawrence drafted some of his own ideas, hoping to \\"prove Plankton could survive as more than a one-note character.\\"[11] From then on, Plankton and Karen's roles in the series grew as Lawrence wrote ideas to give them more personality; notably, he decided to write Karen as Plankton's wife, rather than just his computer as was originally intended.[12] They were both officially promoted to main cast members in the credits of the 2004 theatrical film, in which they play central roles.\\r\\nHillenburg added Mrs. Puff in response to a request by Nickelodeon that SpongeBob attend school. Nickelodeon executives initially wanted to make SpongeBob a child since their most successful cartoons at the time focused on young, school-age characters.[13] Hillenburg stated that the network wanted SpongeBob to be like \\"Arnold [from Hey Arnold!] under the sea,\\" but he told them, \\"No, that's not the show.\\"[13] As a compromise, he decided to put SpongeBob in a boat-driving school, allowing him to keep writing SpongeBob as an adult while also using the school as a main plot element.[13] Showrunner Vincent Waller suggested that if Nickelodeon had creative control over SpongeBob, almost every episode would take place at Mrs. Puff's school, rather than at a variety of locations.[14] The choice to make Mrs. Puff a pufferfish, who inflates into a ball when SpongeBob crashes, was made to evoke the appearance of car airbags.[15]\\r\\nSpongeBob SquarePants (voiced by Tom Kenny) is a yellow anthropomorphic sea sponge who physically resembles a rectangular cleaning sponge clad in brown short pants, a white collared shirt, and a red tie. He lives in a pineapple house and is employed as a fry cook at a fast food restaurant called the Krusty Krab.[16] He diligently attends Mrs. Puff's Boating School but has never passed; his lack of a driver's license is a running gag throughout the series. He is relentlessly optimistic and enthusiastic toward his job and his friends. SpongeBob's hobbies include catching jellyfish, blowing bubbles, playing with his best friend Patrick, and unintentionally irritating his neighbor Squidward. He first appears in \\"Help Wanted\\".[17]\\r\\nPatrick Star (voiced by Bill Fagerbakke) is a pink starfish who lives under a rock and wears flowered swim trunks. His most prominent character trait is his extremely low intelligence. He is best friends with SpongeBob and often unknowingly encourages activities that get the two into trouble.[16] While typically unemployed throughout the course of the series, Patrick holds various short-term jobs as the storyline of each episode requires. He is generally slow and easy-going but can sometimes get aggressive, much like real starfish.[18]\\r\\nSquidward Tentacles (voiced by Rodger Bumpass) is an octopus with a large nose who works as a cashier at the Krusty Krab. He is SpongeBob's next-door neighbor with a dry, sarcastic sense of humor.[19] He believes himself to be a talented artist and musician, but nobody else recognizes his abilities. He plays the clarinet and often paints self-portraits in different styles, which he hangs up around his moai house. Although he does not like SpongeBob and Patrick, they are oblivious to his animosity and consider him a close friend.\\r\\nEugene Harold Krabs (voiced by Clancy Brown) is a red crab who owns and operates the Krusty Krab restaurant where SpongeBob works. He is self-content, cunning, and obsessed with the value and essence of money.[16] He lives in an anchor with his teenage daughter Pearl, who is a whale. He dislikes spending money but will go to great lengths to make Pearl happy.[20] He tends to worry more about his riches than about the needs of his employees. Having served in the navy, he loves sailing, whales, sea shanties, and talking like a pirate.\\r\\nSheldon Plankton (voiced by Mr. Lawrence) and Karen Plankton (voiced by Jill Talley) are the owners of the Chum Bucket, an unsuccessful restaurant located across the street from the Krusty Krab. Their business is a commercial failure because they sell mostly inedible foods made from chum. Plankton is a small planktonic copepod[21] and the self-proclaimed archenemy of Mr. Krabs. He is a skilled inventor and possesses a Napoleon complex due to his short stature.[22] Karen is Plankton's own invention, a talking supercomputer who supplies him with evil plans to steal Krabs' secret recipe for Krabby Patties.[23] She is married to Plankton and usually takes residence in the Chum Bucket laboratory.\\r\\nSandra \\"Sandy\\" Cheeks (voiced by Carolyn Lawrence) is a squirrel from Texas who lives in an air-filled glass dome and wears a diving suit to breathe underwater.[24] Whenever any aquatic creatures enter her home, they must wear helmets of water. Sandy works as a scientist, explorer, and inventor. She is a rodeo champion with a number of athletic interests, such as \\"sand-boarding\\" and karate.[25] She speaks with a Southern drawl and uses typical Southern slang words and phrases.\\r\\nMrs. Puff (voiced by Mary Jo Catlett) is an elderly, paranoid pufferfish who is SpongeBob's teacher at boating school, an underwater driver's education facility where students drive boats like cars. She wears a sailor suit and her school is made from a submerged lighthouse. SpongeBob is Mrs. Puff's most dedicated student and knows the answer to every question on her written and oral exams, but always panics and crashes when he actually boards a vessel.[26] She puffs up into a ball when she is scared or injured.[27]\\r\\nPearl Krabs (voiced by Lori Alan) is a teenage sperm whale and Mr. Krabs' daughter.[23] She wants to fit in with her fish peers, but finds this impossible to do because of the large size inherent to her species. She will inherit the Krusty Krab from her father when she grows older, but is still in high school and does not yet have a job at the family business. Pearl's favorite activities are working at the Bikini Bottom Mall, using her father's credit card to buy anything that is in style, and listening to pop music.[28]\\r\\nGary (voiced by Tom Kenny) is SpongeBob's pet sea snail who lives with him in their pineapple home and vocalizes like a cat.[29] Despite only communicating through meows, other characters can understand and talk to him. Depicted as a level-headed character, Gary often serves as a voice of reason for SpongeBob and solves problems that his owner cannot. He has a pink shell that is impractically spacious on the inside.\\r\\nPatchy the Pirate (portrayed by Tom Kenny) is the host of the series' special episodes. He is a live-action pirate and the president of the fictional SpongeBob fan club. He lives in an unnamed suburb of Encino, California, and segments hosted by him are often presented in a dual narrative with the animated stories. He made a special guest star appearance on Big Time Rush in the episode \\"Big Time Beach Party\\" with Carlos Pena Jr. and Logan Henderson.\\r\\nPotty the Parrot (voiced by Stephen Hillenburg, 2000ÿ2004; Paul Tibbitt, 2005ÿ2012; Mr. Lawrence, 2017ÿpresent) is Patchy's green pet parrot, depicted as a crudely-made puppet with googly eyes controlled by very obvious strings. The character's name is a reference to \\"Polly wants a cracker,\\" a phrase often used for parrots to vocally mimic. Potty is obnoxious and often annoys or talks back to Patchy while the latter is trying to host an episode.\\r\\nThe French Narrator (voiced by Tom Kenny) is a scuba diver with a camera who often introduces episodes or narrates the intertitles as if the series was a nature documentary about the ocean. He has a thick French accent as a reference to the distinctive speaking style of oceanographer and filmmaker Jacques Cousteau. He is normally only heard, but physically appears twice: in \\"No Free Rides\\", in which SpongeBob and Mrs. Puff inadvertently hit him while driving, and in \\"Feral Friends\\", in which he is revealed to own a submarine.\\r\\nMermaid Man (voiced by Ernest Borgnine) and his sidekick Barnacle Boy (voiced by Tim Conway)[30] are two elderly and partially senile superheroes who live in a retirement home and are stars of SpongeBob and Patrick's favorite television show. Mermaid Man is known for completely forgetting things and yelling a prolonged \\"EVIL!\\" whenever he hears the word, while Barnacle Boy seems to be the smarter, more sensible, and more irritable of the two. \\"Mermaid Man Begins\\" confirms that their given first names are Ernie and Tim. Aquaman artist Ramona Fradon drew the characters' comic book adventures.[31] Since Borgnine's death, both characters have been retired and limited to cameo appearances.\\r\\nThe Flying Dutchman (voiced by Brian Doyle-Murray) is an irritable pirate ghost who glows green.[32] He is named after the ghost ship of the same name. He haunts the seven seas because his unburied corpse was used as a window display. He collects souls as a Satan-like character and resides in a cavern containing Davy Jones' Locker, a literal locker stuffed with smelly socks, which within the series is analogous to Hell and occasionally mentioned as a curse word. In \\"SpongeBob SquarePants vs. The Big One,\\" the musician Davy Jones makes a cameo appearance throwing socks from the locker at the Dutchman. He is first mentioned in \\"Squidward the Unfriendly Ghost\\" but does not have a speaking role until \\"Scaredy Pants\\".\\r\\nKing Neptune (voiced by John O'Hurley/Jeffrey Tambor) is a mighty, trident-wielding merman god who rules the sea, based on the mythological deity of the same name. In the series, Neptune lives in a palace in Atlantis with his wife Amphitrite and son Triton. He is usually portrayed as arrogant and selfish, showing little sympathy for the sea's fish populace. Neptune has a mostly blue-green color scheme with a long brown beard and hair. A different King Neptune is featured in The SpongeBob SquarePants Movie. In the film, he resides near Bikini Bottom with his daughter Mindy and resembles a green-skinned king with a robe, neatly-trimmed hair, a domed crown to cover his bald spot, and powers limited to what can be exercised through his trident.\\r\\nThe Realistic Fish Head (voiced by Mr. Lawrence) is an announcer and news anchor fish, resembling a cut-out of a live-action trout. He appears in the series' opening theme. His name has changed repeatedly throughout the series; it is Elaine in \\"The Great Patty Caper\\", Johnny in Battle for Bikini Bottom, and \\"T. McTrout\\" in commercials for Nicktoons UK.\\r\\nPerch Perkins (voiced by Dee Bradley Baker) is a perch who works as a famous field news reporter. While the Realistic Fish Head only reports on television news programs, Perch makes physical appearances reporting about events that occur. He is normally purple with a dark purple coat with a black wig and headphones, although some episodes and Nicktoons MLB show him with an orange color scheme and a red coat.\\r\\nLarry the Lobster (voiced by Mr. Lawrence) is a lobster lifeguard at Goo Lagoon. Larry is a bodybuilder and workout fanatic who lifts weights.[32] He first appears in \\"Ripped Pants\\".\\r\\nMr. Harold SquarePants (voiced by Tom Kenny) and Mrs. Margaret SquarePants (voiced by Sirena Irwin) are SpongeBob's parents, who more closely resemble round sea sponges than SpongeBob. Harold is brown with glasses and a moustache, while Margaret is dark orange. They seem to live outside of Bikini Bottom, but still take the time to visit their son on occasion. They are proud of SpongeBob but embarrassed that he still does not have a driver's license.\\r\\nGrandma SquarePants (voiced by Marion Ross) is SpongeBob's paternal grandmother. She has six children with her late husband, whose wisdom SpongeBob sometimes cites when he plans something. She spoils SpongeBob whenever he visits her house with cookies, milk, sweaters, and bedtime stories, even though SpongeBob can get embarrassed by it.[32]\\r\\nSquilliam Fancyson III (voiced by Dee Bradley Baker) is Squidward Tentacles' arrogant and wealthy arch-rival who has been able to succeed in everything Squidward has only dreamed of doing. He owns a ridiculously large, almost castle-like four-story mansion with an expansive garden on the rooftop. He first appears in \\"Band Geeks\\".\\r\\nMrs. Betsy \\"Mama\\" Krabs (voiced by Paul Tibbitt/Sirena Irwin) is Mr. Krabs' overbearing mother who still treats him slightly like a child. She is a friend of Old Man Jenkins. She first appears in \\"Sailor Mouth\\" and has been mostly retired from the show, aside from a cameo in \\"Lame and Fortune\\".\\r\\nMan Ray (voiced by John Rhys-Davies/Bob Joles) and the Dirty Bubble (voiced by Charles Nelson Reilly/Tom Kenny) are villains against Mermaid Man and Barnacle Boy. Man Ray has a man's body and a helmet shaped to look like a stingray's head, which hides the fact that he does not have a head. The Dirty Bubble is a giant brown bubble with a face. Man Ray retires as supervillain in his first appearance, but he sometimes plays antagonistic roles afterwards.\\r\\nBubble Bass (voiced by Dee Bradley Baker) is an overweight green bass who was the antagonist of \\"Pickles\\" in season 1 and returned as a recurring townsperson in season 8. He is a nemesis of SpongeBob and is very picky about his food.\\r\\nScooter (voiced by Carlos Alazraqui) is a fish who enjoys surfing and is often seen at Goo Lagoon. He speaks like a stereotypical southern Californian and often calls SpongeBob \\"dude.\\" He dies and becomes an angel in the second-season episode \\"Bubble Buddy\\", but returns unharmed for future episodes.\\r\\nThe Purple Doctorfish (voiced by Rodger Bumpass) is a doctor who works as a physician at the Bikini Bottom Hospital and as a traveling veterinarian for pet snails. He has a calm demeanor and a deep, suave voice. SpongeBob was initially scared of visiting his office in \\"Suds\\" but later faces his fears and discovers he likes visiting the doctor's.\\r\\nOld Man Jenkins (voiced by Tom Kenny/Mr. Lawrence/Dee Bradley Baker) is an elderly townsperson who lives at the Shady Shoals retirement home and is a common patron of the Krusty Krab. His appearance and job changes often. One of his critical appearances is in \\"The Sponge Who Could Fly\\" wherein he plays a farmer, a sailor, and finally, a human cannonball. He believes SpongeBob is a box of Bran Flakes.\\r\\nJellyfish (voiced by Tom Kenny) are wild animals who reside in Jellyfish Fields, a meadow in Bikini Bottom, and have a strong affinity for music. Within the series, jellyfish behave like sentient insects, squirt jelly, buzz and swarm like bees, and can sting their enemies with electric shocks that leave painful welts.\\r\\nThe characters of SpongeBob SquarePants have been well-received overall. The titular character SpongeBob has become very popular with children and adults. The character's popularity has spread from Nickelodeon's original demographic of two- to eleven-year-olds, to teenagers and adults.[34][35] The popularity of SpongeBob translated well into sales figures. In 2002, SpongeBob SquarePants dolls sold at a rate of 75,000 per week, which was faster than Tickle Me Elmo dolls were selling at the time.[35] SpongeBob has gained popularity in Japan, specifically with Japanese women. Nickelodeon's parent company Viacom purposefully targeted marketing at women in the country as a method of building the SpongeBob SquarePants brand. Skeptics initially doubted that SpongeBob could be popular in Japan as the character's design is very different from already popular designs for Hello Kitty and Pikachu.[36] However, the characters have also attracted some negative reception, including SpongeBob himself, who was listed as number four on AskMen's Top 10: Irritating '90s Cartoon Characters. Nevertheless, SpongeBob SquarePants was ranked ninth on TV Guide's top 50 cartoon characters.[37]\\r\\nThe show's characters have received recognition from celebrities and well-known figures in media. Barack Obama named SpongeBob his favorite television character in 2007 and admitted that SpongeBob SquarePants was \\"the show I watch with my daughters.\\"[38][39][40] British Prime Minister Gordon Brown has also said he watches the show with his children.[41] Sigourney Weaver and Bruce Willis were reported to be fans of the SpongeBob character in 2008.[35] Film critic A. O. Scott named Squidward, Mrs. Puff, and Sandy his favorite characters on the show in 2004.[42] American singer Pharrell Williams, who says he is a fan of the show, said that \\"Squidward is my favorite, though. If he was a human, I would hang out with him.\\"[43] Fashion designer Peter Jensen designed a line of sweatshirts inspired by SpongeBob and called Mrs. Puff his \\"absolute favorite\\" character in an interview with Women's Wear Daily.[44] Peter Keepnews of The New York Times commended Patrick, calling him \\"a popular character, and the new episodes illustrate why: He is unfailingly enthusiastic, touchingly loyal and absolutely undeterred by his intellectual limitations. Hilariously voiced by Bill Fagerbakke, he is not just an endearing comic creation but a role model for idiots everywhere.\\"[45]\\r\\nThe show's voice actors have received attention from honorary organizations for the portrayals of their characters. Mary Jo Catlett and Tom Kenny were both nominated at the 29th Annie Awards ceremony in 2001 for their vocal performances as Mrs. Puff and SpongeBob.[46] Kenny received an additional two nominations at the 2008 and 2010 ceremonies, the latter of which he won for voicing SpongeBob in \\"Truth or Square\\".[47] In 2012, Rodger Bumpass' performance as Squidward was nominated for Outstanding Performer in an Animated Program at the 39th Daytime Emmy Awards.[48][49] Additionally, Patrick as a character won in the category \\"Favorite Animated Animal Sidekick\\" at the 2014 Kids' Choice Awards.[50]\\r\\nThe characters of SpongeBob SquarePants appeared in the 2004 theatrical film The SpongeBob SquarePants Movie and its 2015 sequel. Both films feature the regular television cast and blend animated elements with live-action sequences. They have also been featured in a variety of associated merchandise, particularly video games; from 2001 to 2013, the SpongeBob franchise had multiple video games released each year, with the show's voice cast reprising their character roles for many titles.[51] Every main cast member with the exception of Clancy Brown has voiced their respective characters in each game that they appear; Brown's character Mr. Krabs is instead voiced by Joe Whyte in SuperSponge, Operation Krabby Patty, and Battle for Bikini Bottom and by Bob Joles in the Truth or Square game.\\r\\nThe SpongeBob characters have been featured at a variety of theme park attractions. In 2003, Kings Island announced plans to build the first SpongeBob-themed amusement park ride, a dark ride roller coaster titled \\"Mrs. Puff's Crash Course Boating School\\".[52] Plans were halted when Kings Island changed ownership, and the first ride featuring SpongeBob theming was instead \\"SpongeBob's Boatmobiles\\"also based on Mrs. Puff's Boating School and opened in 2003at California's Great America.[53] Amusement rides based on the characters have since been opened at Blackpool Pleasure Beach, Dreamworld, Movie Park Germany, and Nickelodeon Universe. Two 4D films featuring 3-D models of the characters and a motion simulator experience, SpongeBob SquarePants 4-D and The Great Jelly Rescue, were sold to theme parks and aquariums worldwide in 2005 and 2013 respectively.[54]\\r\\nMascot costumes of the SpongeBob characters debuted at Nickelodeon Suites Resort in 2005 and have made regular appearances at Nickelodeon events since.[55] Plankton, Karen, and Gary are the only main characters who have never been realized as mascots;[56] at events, they are normally depicted as puppets or statues instead. In December 2011, a parade of SpongeBob mascots and floats titled \\"SpongeBob ParadePants\\" opened at Sea World Australia.[57] In November 2017, a Broadway musical based on the show began touring. Unlike previous shows, the characters were not represented with mascot costumes but by actors wearing clothing inspired by the characters' designs.\\r\\nThe characters of SpongeBob SquarePants have appeared throughout popular culture. In 2007, the Amsterdam-based company Boom Chicago created a SpongeBob parody called \\"SpongeBob SquarePants in China\\", in which a stereotypically Chinese Patrick refuses to go to work and advocates freedom of speech, rights of leisure, and income.[58] During the same year, production company Camp Chaos created a SpongeBob parody titled SpongeBong HempPants, which features five of the series' characters parodied in the form of various drugs. The show was seen on VH1 and Comedy Central, both owned by Nickelodeon's parent company Viacom.[59] Comedy Central's Drawn Together also features a parody of SpongeBob named \\"Wooldoor Sockbat\\" whose theme tune is inspired by SpongeBob's Hawaiian-style background music. Two animated series that former SpongeBob writer Dan Povenmire worked on have incorporated references to the characters; the Phineas and Ferb special \\"Summer Belongs to You\\" features a joke in which Phineas Flynn holds up inanimate representations of SpongeBob and Patrick, and the Family Guy episode \\"Road to Rupert\\" includes SpongeBob's \\"Campfire Song Song\\" from \\"The Camping Episode\\". SpongeBob, Patrick, Mr. Krabs, Pearl, and Squidward all appear in \\"Major League of Extraordinary Gentlemen\\", an episode of the sketch comedy Robot Chicken. A segment of the episode, animated in stop motion with SpongeBob toy figures, features Mr. Krabs using crab legs as the secret ingredient for Krabby Patties.[60] SpongeBob has also made cameo appearances in The Simpsons, Mad, The Loud House, South Park, and Futurama.","input":"Is pearl from spongebob a whale or shark?"},{"output":"William O. Douglas","context":"A total of 113 people have served on the Supreme Court of the United States, the highest judicial body in the United States, since it was established in 1789. Supreme Court justices have life tenure, and so they serve until they die, resign or retire, or are impeached and removed from office.  For the 105 non-incumbent justices, the average length of service was 6,203 days (16 years, 359 days).[1][A] Their length of service ranges from William O. Douglas's 13,358 days (7004133580000000000?36?years, 209?days) on the Court to the 163-day tenure of Thomas Johnson. Among the current members of the Court, Associate Justice Clarence Thomas is the longest-serving justice, with a tenure of 7003980700000000000?9,807 days (7003980700000000000?26?years, 310?days) as of August 29, 2018.\\r\\n\\r\\nThe table below ranks all United States Supreme Court Justices by time in office.[B] For five individuals confirmed for associate justice, and later confirmed for chief justice separatelyCharles Evans Hughes, William Rehnquist, John Rutledge, Harlan F. Stone, and Edward Douglass Whitetheir cumulative length of service on the Court is measured. The basis of the ranking is the difference between dates; if counted by number of calendar days all the figures would be one greater, with the exception of Charles Evans Hughes and John Rutledge, who would receive two days, as each served on the Court twice (their service as associate justice and as chief justice was separated by a period of years off the Court). The start date given for each justice is the day he or she took the prescribed oath of office, with the end date being the date of the justice's death, resignation, or retirement. A highlighted row indicates a justice currently serving on the Court.","input":"Who is the longest sitting supreme court justice?"},{"output":"October 1941","context":"","input":"When did wonder woman first appeared in a comic book?"},{"output":"Neil Finn","context":"Crowded House are a rock band formed in Melbourne, Australia, in 1985. The founding members were New Zealander Neil Finn (vocalist, guitarist, primary songwriter) and Australians Paul Hester (drums) and Nick Seymour (bass). Later band members included Neil Finn's brother, Tim Finn, and Americans Mark Hart and Matt Sherrod.[1][2]\\r\\nOriginally active from 1985 to 1996, the band had consistent commercial and critical success in Australia and New Zealand[3][4][5] and international chart success in two phases, beginning with their self-titled debut album, which reached number twelve on the US Album Chart in 1987 and provided the Top Ten hits \\"Don't Dream It's Over\\" and \\"Something So Strong\\".[6][7] Further international success came in the UK, Europe and South Africa with their third and fourth albums, Woodface and Together Alone and the compilation album Recurring Dream, which included the hits \\"Fall at Your Feet\\", \\"Weather with You\\", \\"Distant Sun\\", \\"Locked Out\\", \\"Instinct\\" and \\"Not the Girl You Think You Are\\".[8][9] Neil and Tim Finn were each awarded an OBE in June 1993, for their contribution to the music of New Zealand.[10]\\r\\nFounding drummer Hester left in May 1994 citing family reasons, but briefly returned for their \\"Farewell to the World\\" concerts in Melbourne and Sydney in 1996.[1] Neil Finn had decided to end the band to concentrate on his solo career and the Finn Brothers project with Tim.[1] On 26 March 2005 Hester died by suicide, aged 46.[11] In 2006 the group re-formed with a new drummer Matt Sherrod and released two further albums (in 2007 and 2010), both of which reached number one on Australia's album chart.[4] As of July 2010 the group has sold 10 million albums.[12] In November 2016 they were inducted into the ARIA Hall of Fame.[13]\\r\\n\\r\\n\\r\\nNeil Finn (vocals, guitar, piano) and drummer Paul Hester (ex-The Cheks, Deckchairs Overboard) were former members of New Zealand band Split Enz, which spent part of 1975ÿ6 in Australia and several years in England.[1] Neil Finn is the younger brother of Split Enz founding member Tim Finn, who joined Crowded House in 1990 on vocals, guitars and keyboards for the album Woodface.[1] Bassist Nick Seymour (ex-Plays with Marionettes, Bang, The Horla) is the younger brother of singer-songwriter and guitarist Mark Seymour[1] of the now defunct Australian rock group Hunters & Collectors.[8]\\r\\nFinn and Hester decided to form a new band during the first Split Enz farewell tour, \\"Enz with a Bang\\", in late 1984.[1] Seymour approached Finn during the after party for the Melbourne show and asked if he could audition for the new band.[8] The Mullanes formed in Melbourne in early 1985 with Finn, Hester, Seymour and guitarist Craig Hooper (ex-The Reels) and first performed on 11 June.[1] They secured a record contract with Capitol Records, but Hooper left the band before the remaining trio moved to Los Angeles to record their debut album.[1][14] At Capitol's behest, the band's name was changed to Crowded House, which alluded to the lack of space at the small Hollywood Hills house they shared during the recording of the album Crowded House.[1][14][15] Former Split Enz keyboardist Eddie Rayner produced the track \\"Can't Carry On\\" and was asked to join the band. He toured with them in 1988, but was unable to become a full member due to family commitments.\\r\\nThanks to their Split Enz connection, the newly formed Crowded House had an established Australasian fanbase.[1] They began by playing at festivals in Australia and New Zealand and released their debut album, Crowded House, in June 1986.[1] Capitol Records initially failed to see the band's potential and gave them only low-key promotion,[8] forcing the band to play at small venues to try and gain attention. The album's first single, \\"Mean to Me\\", reached the Australian Kent Music Report Singles Chart top 30 in June.[3] It failed to chart in the US,[6] but moderate American airplay introduced US listeners to the group.\\r\\nA single, \\"Don't Dream It's Over\\", was released in December 1986 and proved an international hit, reaching number two on the US Billboard Hot 100[6] and number one in Canada.[16] New Zealand radio stations initially gave the song little support until months later when it became successful internationally.[citation needed] Ultimately, the song reached number one on the New Zealand singles chart and number eight in Australia.[3][5] It remains the group's most commercially successful song.\\r\\nIn March 1987, the group were awarded \\"Best New Talent\\", along with \\"Song of the Year\\" and \\"Best Video\\" awards for \\"Don't Dream It's Over\\" at the inaugural ARIA Music Awards.[17] The video also earned the group the MTV Video Music Award for Best New Artist that year.[18] The song has often been covered by other artists and gave Paul Young a hit single in 1991. It was also used for a New Zealand Tourism Board advertisement in its \\"100% Pure New Zealand\\" worldwide promotion from October 2005.[19] In May 2001, \\"Don't Dream it's Over\\" was voted seventh in a poll of the best Australian songs of all time by the Australasian Performing Rights Association.[20]\\r\\nIn June 1987, a year after its release, Crowded House finally reached number one on the Kent Music Report Album Charts.[3] It also reached number three in New Zealand[5] and number twelve on the US Billboard album chart.[7] The follow-up to \\"Don't Dream it's Over\\", \\"Something So Strong\\", was another global smash, reaching the Top 10 in New Zealand,[5] America,[6] and Canada. \\"World Where You Live\\" and \\"Now We're Getting Somewhere\\" were also released as singles with chart success.[3][6][8]\\r\\nAs the band's primary songwriter, Neil Finn was under pressure to create a second album to match their debut and the band joked that one potential title for the new release was Mediocre Follow-Up.[8] Eventually titled Temple of Low Men, their second album was released in July 1988 with strong promotion by Capitol Records. The album did not fare as well as their debut in the US, only reaching number 40,[7] but it achieved Australasian success, reaching number one in Australia[4] and number two in New Zealand.[5] The first single \\"Better Be Home Soon\\" peaked at number two on both Australian and New Zealand singles charts[4][5] and reached top 50 in the US,[6] though the following four singles were less successful.[4][5] Crowded House undertook a short tour of Australia and Canada to promote the album, with Eddie Rayner on keyboards. Multi-instrumentalist Mark Hart, who would eventually become a full band member, replaced Rayner in January 1989. After the tour, Finn fired Seymour from the band.[2] Music journalist Ed Nimmervoll claimed that Seymour's temporary departure was because Finn blamed him for causing his writer's block;[14] however, Finn cited \\"artistic differences\\" as the reason.[2] Seymour said that after a month he contacted Finn and they agreed that he would return to the band.[2]\\r\\nCrowded House took a break after the Canadian leg of the Temple of Low Men tour. Neil Finn and his brother Tim recorded songs they had co-written for their own album, Finn.[8] Following the recording sessions with Tim, Neil began writing and recording a third Crowded House album with Hester and Seymour, but these tracks were rejected by the record company, so Neil asked Tim if Crowded House could use the Finn songs. Tim jokingly agreed on the proviso that he become a member, which Neil apparently took literally. With Tim as an official member, the band returned to the studio. The new tracks, as well as some from the previously rejected recordings were combined to make Woodface, which was released in July 1991. The album features eight tracks co-written by Neil and Tim,[8] which feature the brothers harmonising on lead vocals, except on the sombre \\"All I Ask\\" on which Tim sang lead. The track was later used on AIDS awareness commercials in Australia.[8] Five of the album's tracks were Neil's solo compositions and two were by Hester, the exuberant \\"Italian Plastic\\", which became a crowd favourite at concerts[8] and the hidden track \\"I'm Still Here\\".\\r\\n\\"Chocolate Cake\\", a humorous comment on American excesses that was not taken well by some US critics and sections of the American public, was released in June 1991 as the first single. Perhaps unsurprisingly it failed to chart in the US, however it reached number two on Billboard's Modern Rock Tracks chart.[6] The song peaked at number seven in New Zealand and reached the top 20 in Australia.[4][5] The second single, \\"Fall at Your Feet\\", was less successful in Australia and New Zealand but did at least reach the US Hot 100.[6] The album reached number one in New Zealand,[5] number two in Australia,[4] number six in the UK[21][22] and made the top 20 in several European countries.[23][24][25] The third single from Woodface, \\"Weather With You\\", peaked at No.?7 in early 1992 giving the band their highest UK chart placement. By contrast, the album had limited success in the US, only reaching number 83 on the Billboard 200 Album Chart.[7]\\r\\nTim Finn left Crowded House during the Woodface tour in November 1991, part-way through the UK leg.[1] Performances on this tour, at the Town and Country Club in London, were recorded live and given a limited release in Australia, while individual songs from those shows were released as B-sides of singles in some countries.[26] In June 1993 the New Zealand Government recommended that the Queen award an OBE to Neil and Tim Finn for their contribution to the music of New Zealand.[10]\\r\\nFor their fourth album, Together Alone, Crowded House used producer Martin Glover (aka \\"Youth\\") and invited touring musician Mark Hart (guitar and keyboards) to become a permanent band member.[1][14] The album was recorded at Karekare Beach, New Zealand, which gave its name to the opening track, \\"Kare Kare\\". The album was released in October 1993 and sold well internationally on the strength of lead single \\"Distant Sun\\" and followup \\"Private Universe\\". It topped the New Zealand Album Chart,[5] reached number 2 in Australia[4] and number 4 in the UK.[21] \\"Locked Out\\" was the album's first US single and received airplay on MTV and VH1. This track and \\"My Sharona\\" by The Knack, which were both included the soundtrack of the film Reality Bites, were bundled together on a jukebox single to promote the film soundtrack.[8]\\r\\nCrowded House were midway through a US tour when Paul Hester quit the band on 15 April 1994.[14] He flew home to Melbourne to await the birth of his first child and indicated that he required more time with his family.[1][14] Wally Ingram, drummer for support act Sheryl Crow, temporarily filled in[14] until a replacement, Peter Jones (ex-Harem Scarem, Vince Jones, Kate Ceberano's Septet) was found.[1] After the tour, the Finn Brothers released their album Finn in November 1995. In June 1996, at a press conference to announce the release of their greatest hits album Recurring Dream, Neil revealed that Crowded House were to disband. The June 1996 concerts in Europe and Canada were to be their final performances.[8]\\r\\nRecurring Dream contained four songs from each of the band's studio albums, along with three new songs. The album debuted at number one in Australia,[4] New Zealand[5] and the UK[21] in July 1996. Early copies included a bonus CD of live material. The album's three new songs, which were released as singles, were \\"Instinct\\", \\"Not the Girl You Think You Are\\" and \\"Everything Is Good for You\\", which featured backing vocals from Pearl Jam's Eddie Vedder. Paul Hester returned to the band to play drums on the three new tracks.[27]\\r\\nWorried that their goodbye had been too low-key and had disregarded their home fans, the band performed the Farewell to the World concert on the steps of the Sydney Opera House on 24 November 1996, which raised funds for the Sydney Children's Hospital. The concert featured the line-up of Neil Finn, Nick Seymour, Mark Hart and Paul Hester. Tim Finn and Peter Jones both made guest appearances. Support bands on the day were Custard, Powderfinger and You Am I. The concert had one of the highest live audiences in Australian history with the crowd being estimated at between 120,000 and 250,000 people.[8][28] Farewell to the World was released on VHS in December 1996. In 2007, a double CD and a DVD were issued as to commemorate the concert's tenth anniversary. The DVD featured newly recorded audio commentary by Finn, Hart and Seymour and other new bonus material.[28]\\r\\nFollowing the 1996 break-up of Crowded House, the members embarked upon a variety of projects. Neil Finn released two solo studio albums, Try Whistling This (1998) and One Nil (2001), as well as two live albums, Sessions at West 54th (2000) and 7 Worlds Collide (2001). 7 Worlds Collide saw him performing with guest musicians including Eddie Vedder, Johnny Marr, Ed O'Brien and Phil Selway of Radiohead, Tim Finn, Sebastian Steinberg, Lisa Germano and Betchadupa (featuring his son Liam Finn). A double CD and DVD of the shows were released in November 2001.\\r\\nTim Finn had resumed his solo career after leaving the group in 1992 and he also worked with Neil on a second Finn Brothers album, Everyone Is Here, which was released in 2004. Paul Hester joined The Finn Brothers on stage for three songs at their Palais Theatre show in Melbourne at the end of 2004. Nick Seymour also joined them on stage in Dublin, where he was living, in 2004. Peter Jones and Nick Seymour joined Australian group Deadstar for their second album, Milk, in 1997. Seymour later worked as a record producer in Dublin, producing Irish group Bell X1's debut album, Neither Am I in 2000. Mark Hart rejoined Supertramp in the late 1990s and later toured with Ringo Starr & His All-Starr Band. In 2001 he released a solo album, Nada Sonata.[29]\\r\\nPaul Hester worked with children's entertainers The Wiggles, playing \\"Paul the Cook\\".[30] He also had his own ABC show Hessie's Shed in Australia from late 1997.[1] He formed the band Largest Living Things,[1] which was the name rejected by Capitol Records in favour of Crowded House.[11] It was on Hessie's Shed that Finn, Hester and Seymour last shared a stage, on an episode filmed as part of Finn's promotion for his solo album Try Whistling This in 1998. Finn and Hester performed \\"Not the Girl You Think You Are\\" with Largest Living Things, before being joined by Seymour for \\"Sister Madly\\" and a version of Paul Kelly's \\"Leaps and Bounds\\", which also featured Kelly on vocals. In late 2003, Hester hosted the series Music Max's Sessions. Hester and Seymour were reunited when they both joined singer-songwriter Matt O'Donnell's Melbourne-based group Tarmac Adam.[31] The band released one album, 2003's Handheld Torch, which was produced by Seymour.\\r\\nIn May 1999 Crowded House issued a compilation of unreleased songs, Afterglow, which included the track \\"Recurring Dream\\", recorded when the group were still called The Mullanes and included Craig Hooper on guitar.[1] The album's liner notes included information about the songs, written by music journalist David Hepworth. Some limited-release versions included a second CD with songwriting commentary by Finn. The liner notes confirmed that Crowded House had no plans to reunite at that time.[1] A 2003 compilation album, Classic Masters, was released only in the US, while 2005 saw the release of the album She Will Have Her Way, a collection of cover versions of Crowded House, Split Enz, Tim Finn and Finn Brothers songs by Australasian female artists. The album reached the top 5 in Australia and New Zealand.[32]\\r\\nOn 26 March 2005 Paul Hester was found dead, after hanging himself from a tree in a park near his home in Melbourne. He was 46?years old. His obituary in The Sydney Morning Herald stated that he had fought \\"a long battle with depression.\\"[11] Following the news of Hester's death, Nick Seymour joined The Finn Brothers on stage at the Royal Albert Hall in London, where the three played in memory of Paul. A snare drum with a top hat on it stood at the front of the stage as a tribute.[33] Writing in 2010 Neil Finn said, \\"When we lost Paul it was like someone pulled the rug out from underneath everything, a terrible jolt out of the dark blue. He was the best drummer I had ever played with and for many years, my closest friend.\\"[34]\\r\\nIn 2006 Neil Finn asked Nick Seymour to play bass on his third solo album. Seymour agreed and the two joined up with producer and multi-instrumentalist Ethan Johns to begin recording.[14] As the recording sessions progressed it was decided that the album would be issued under the Crowded House band name, rather than as a Neil Finn solo album. In January 2007, the group publicly announced their reformation and on 23 February, after 20?days of auditions, former Beck drummer Matt Sherrod joined Finn, Seymour and Mark Hart to complete the new line up.[14] As Sherrod and Hart had not participated in the initial sessions, four new tracks were recorded with producer Steve Lillywhite including the album's first single \\"Don't Stop Now\\".[14]\\r\\nOn 17 March 2007 the band played a live show at their rehearsal studio in front of around fifty fans, friends and family. The performance was streamed live as a webcast. The two-and-a-half-hour set included some new tracks, including \\"Silent House\\" co-written by Finn with the Dixie Chicks. A concert onboard The Thekla, moored in Bristol, followed on 19 March. Crowded House played at the Marquee Theatre in Tempe, Arizona on 26 April as a warm-up for their appearance at the Coachella Festival on 29 April in Indio, California. They also played at the Australian Live Earth concert in Sydney on 7 July. The next day, Finn and Seymour were interviewed on Rove Live and the band, with Hart and Sherrod, performed \\"Don't Stop Now\\" to promote the new album, which was titled Time on Earth. The single was a minor hit in Australia[4] and the UK.[21] The album was released worldwide in June and July. It topped the album chart in New Zealand[5] and made number 2 in Australia[4] and number 3 in the UK.[21]\\r\\nOn 6 December 2008 Crowded House played the Homebake festival in Sydney, with warm up gigs at small venues in Hobart, Melbourne and Sydney. For these shows the band were augmented by multi-instrumentalist Don McGlashan and Neil's younger son, Elroy Finn, on guitar. On 14 March 2009 the band joined Neil's older son, Liam Finn, on stage for three songs at the Sound Relief concert in Melbourne.\\r\\nCrowded House began recording their follow-up to Time on Earth in April 2009, at Finn's own Roundhead Studios. The album, Intriguer, was produced by Jim Scott who had worked on The Sun Came Out by Neil's 7 Worlds Collide project. In August 2009, Finn travelled to Los Angeles to record some overdubs at Jim Scott's Los Angeles studio before they began mixing tracks. The album was released in June 2010, in time for the band's appearance at the West Coast Blues & Roots Festival near Perth. Finn stated that the album contains some, \\"Unexpected twists and turns\\" and some songs that, \\"Sound like nothing we've done before.\\"[35] Intriguer topped the Australian album chart,[4] reached number 3 in New Zealand[5] and number 12 in the UK.[21]\\r\\nCrowded House undertook an extensive world tour in 2010 in support of Intriguer. This was the first album where the band regularly interacted with fans via the internet on their own re-launched website, Twitter and Facebook. The band sold recordings of the shows on the Intriguer tour on USB flash drives and made individual live tracks available for free download. The band's final concert was at the A Day on the Green festival in Auckland on 27 February 2011.[36]\\r\\nA new compilation album, The Very Very Best of Crowded House, was released in October 2010 to celebrate the band's 25th anniversary.[37] It includes 19 of the band's greatest hits and is also available in a box set with a 25 track DVD of their music videos. A deluxe digital version, available for download only, has 32 tracks including a rare 1987 live recording of the band's version of the Hunters & Collectors song \\"Throw Your Arms Around Me\\". No mention of this album has been made on the band's official website or Twitter page, which suggests that they are not involved with its release.\\r\\nFollowing the success of the album She Will Have Her Way in 2005, a second album of cover versions of Finn Brothers songs (including numerous Crowded House songs) was released on 12 November 2010. Entitled He Will Have His Way, all tracks on this album are performed by Australasian male artists.[38] In November 2011, there was an Australian tour by various artists involved with the \\"She Will Have Her Way\\" and \\"He Will Have His Way\\" projects, including Paul Dempsey, Clare Bowditch, Seeker Lover Keeper (Sarah Blasko, Sally Seltmann and Holly Throsby), Alexander Gow (Oh Mercy) and Lior.[39]\\r\\nFormer Crowded House drummer Peter Jones died from brain cancer on 18 May 2012 aged 49. A statement issued by the band described him as, \\"A warm-hearted, funny and talented man, who was a valuable member of Crowded House.\\"[40]\\r\\nIn September 2015, the song \\"Help Is Coming\\" from the Afterglow album, was released as a download and limited edition 7\\" single to raise money for the charity Save the Children. The B-side, \\"Anthem\\", was a previously unreleased track that was initially recorded in 1995, with the final vocal added in 2015. The money will be used to provide shelter, water, sanitation and hygiene for refugees in Syria, Lebanon and Iraq. Neil Finn said of \\"Help Is Coming\\"...\\"It was always a song about refugees, even if at the time I was thinking about the immigrants setting off on ships from Europe to America, looking for a better life for their families. There is such a huge scale and urgency to the current refugee crises that barely a day goes by without some crushing image or news account to confront us. We can't be silent any more.\\"[41]\\r\\nIn 2016, Neil Finn mentioned in an interview with the Dutch newspaper Volkskrant that Crowded House are on hiatus.[42] Later that year, he and Seymour announced a series of concerts at the Sydney Opera House to mark the 20th anniversary of the Farewell to the World show (24 Nov 1996). The band performed four shows, 24ÿ27 November 2016.[43] Around the same time, each of the band's 7 studio albums (including the rarities collection Afterglow) was reissued in deluxe 2-CD format with bonus tracks including demos, live recordings, alternate mixes, b-sides and outtakes.\\r\\nAs the primary songwriter for the band, Neil Finn has always set the tone for the band's sound. Allmusic said that Finn \\"has consistently proven his knack for crafting high-quality songs that combine irresistible melodies with meticulous lyrical detail.\\"[44] Neil's brother Tim was an early and important musical influence. Neil first saw Tim play with Split Enz in 1972, and said \\"that performance and those first songs made a lasting impression on me.\\"[45] His mother was another significant musical influence, encouraging him to listen to a variety of genres, including Irish folk music and Mori music. She would play piano at family parties and encourage Neil and Tim to accompany her.\\r\\nBassist Nick Seymour, who is also an artist, designed or co-designed all of the band's album covers and interior artwork. He also designed some of the costumes worn by the group, notably those from the cover of the group's debut album Crowded House. Seymour collaborated with Finn and Hester on the set design of some of their early music videos, including \\"Don't Dream It's Over\\" and \\"Better Be Home Soon\\". Since the band reunited, Seymour has again designed their album covers.[2]\\r\\nThe majority of the covers for the band's singles were not designed by Seymour. The artwork for \\"Pineapple Head\\" was created by Reg Mombassa of Mental As Anything. For the first four albums Mombassa and Noel Crombie, who had been the main designer of Split Enz's artwork, assisted Seymour in creating sets and costumes. For the Farewell to the World concerts Crombie designed the set, while Mombassa and Seymour designed promotional materials and artwork.[46]\\r\\nCrowded House has won several national and international awards. In Australia, the group has won eleven ARIA Awards from 26 nominations, including the inaugural Best New Talent award in 1987.[17] The majority of their ARIAs were awarded for their first two albums, Crowded House and Temple of Low Men.[17] They won eight APRA Awards from eleven nominations and were nominated for The New Zealand Silver Scroll for \\"Don't Stop Now\\" in 2007.[47] \\"Don't Dream It's Over\\" was named the seventh best Australian song of all time in 2001.[20] In 1987, Crowded House won the American MTV Video Music Award for Best New Artist for their song \\"Don't Dream It's Over\\", which was also nominated for three other awards.[18] In 1994, the group was named International Group of the Year at the BRIT Awards.[48] In 2009, \\"Don't Dream It's Over\\" was ranked number fifty on the Triple J Hottest 100 of All Time, voted by the Australian public.[49]\\r\\nIn November 2016 Crowded House were inducted into the ARIA Hall of Fame, 30 years after their formation.","input":"Who is the lead singer of crowded house?"},{"output":"more than 100 minutes","context":"M. angustirostris\\r\\nM. leonina\\r\\nElephant seals are large, oceangoing earless seals in the genus Mirounga. The two species, the northern elephant seal (M. angustirostris) and the southern elephant seal (M. leonina), were both hunted to the brink of extinction by the end of the 19th century, but the numbers have since recovered.\\r\\nThe northern elephant seal, somewhat smaller than its southern relative, ranges over the Pacific coast of the U.S., Canada and Mexico. The most northerly breeding location on the Pacific Coast is at Race Rocks, at the southern tip of Vancouver Island in the Strait of Juan de Fuca. The southern elephant seal is found in the Southern Hemisphere on islands such as South Georgia and Macquarie Island, and on the coasts of New Zealand, South Africa, and Argentina in the Peninsula Valds, which is the fourth-largest elephant seal colony in the world. In southern Chile, there is a small colony of 120 animals at Jackson Bay, Admiralty Sound (Seno Almirantazgo), Tierra del Fuego.[1] The oldest known unambiguous elephant seal fossils are fragmentary fossils of an unnamed member of the tribe Miroungini described from the late Pliocene Petane Formation of New Zealand.[2] Teeth originally identified as representing an unnamed species of Mirounga have been found in South Africa, and dated to the Miocene epoch;[3][4] however Boessenecker & Churchill (2016) considered these teeth to be almost certainly misidentified odontocete teeth.[2]\\r\\nElephant seals breed annually and are seemingly faithful to colonies that have established breeding areas.[5]\\r\\n\\r\\n\\r\\nElephant seals are marine mammals classified under the order Pinnipedia, which in Latin, means feather or fin footed.[6] Elephant seals are considered true seals, and fall under the family Phocidae.[7] Phocids (true seals), are characterized by having no external ear and reduced limbs.[7] The reduction of their limbs helps them be more streamlined and move easily in the water.[6] However, it makes navigating on land a bit difficult because they cannot turn their hind flippers forward to walk like the Otariids.[6] In addition, the hind flipper of elephant seals have a lot of surface area, which helps propel them in the water.[6] Elephant seals spend the majority of their time (90%) underwater in search of food, and can cover 60 miles a day when they head out to sea.[7] When elephant seals are born, they can weigh up to 80 pounds and reach lengths up to 4 feet.[7] Sexual dimorphism is prominently seen in elephant seals due to the fact that male elephant seals can weigh up to 10 times more than females.[8] Also, the large proboscis, which is considered a secondary sexual characteristic, helps males assert dominance during mating season.[7]\\r\\nElephant seals take their name from the large proboscis of the adult male (bull), which resembles an elephant's trunk.[9] The bull's proboscis is used in producing extraordinarily loud roaring noises, especially during the mating season. More importantly, however, the nose acts as a sort of rebreather, filled with cavities designed to reabsorb moisture from their exhalations.[10] This is important during the mating season when the seals do not leave the beach to feed, and must conserve body moisture as there is no incoming source of water. They are colossally large in comparison with other pinnipeds, with southern elephant seal bulls typically reaching a length of 5?m (16?ft) and a weight of 3,000?kg (6,600?lb), and are much larger than the adult females (cows), with some exceptionally large males reaching up to 6?m (20?ft) in length and weighing 4,000?kg (8,800?lb); cows typically measure about 3?m (10?ft) and 900?kg (2,000?lb). Northern elephant seal bulls reach a length of 4.3 to 4.8?m (14 to 16?ft) and the heaviest weigh about 2,500?kg (5,500?lb).[11][12] When elephant seals are born, they can weigh up to 80 pounds and reach lengths up to 4 feet.[7] Sexual dimorphism is prominently seen in elephant seals due to the fact that male elephant seals can weigh up to 10 times more than females.[7] Also, the large proboscis, which is considered a secondary sexual characteristic, helps males assert dominance during mating season.[7]\\r\\nThe northern and southern elephant seal can be distinguished by looking at various external features. On average, the southern elephant seal tends to be larger than the northern species.[8] Adult male elephant seals belonging to the northern species tend to have a larger proboscis, and thick chest area with a red coloration compared to the southern species.[8] Females do not have the large proboscis and can be distinguished between species by looking at their nose characteristics.[8] Southern females tend to have smaller blunt nose compared to northern females.[8]\\r\\nElephant seals spend up to 80% of their lives in the ocean. They can hold their breath for more than 100 minutes[13][14] ÿ longer than any other noncetacean mammal. Elephant seals dive to 1,550 m beneath the ocean's surface[13] (the deepest recorded dive of an elephant seal is 2,388?m (7,835?ft) by a southern elephant seal).[15] The average depth of their dives is about 300 to 600?m (980 to 1,970?ft), typically for around 20?minutes for females and 60?minutes for males, as they search for their favorite foods, which are skates, rays, squid, octopuses, eels, small sharks and large fish. Their stomachs also often contain gastroliths. They spend only brief amounts of time at the surface to rest in between dives (2-3 minutes).[7] Females tend to dive a bit deeper due to their prey source.[7]\\r\\nElephant seals are shielded from extreme cold by their blubber, more so than by fur. Their hair and outer layers of skin molt in large patches. The skin has to be regrown by blood vessels reaching through the blubber. When molting occurs, the seal is susceptible to the cold, and must rest on land, in a safe place called a \\"haul out\\". Northern males and young adults haul out during June to July to molt; northern females and immature seals during April to May.\\r\\nElephant seals have a very large volume of blood, allowing them to hold a large amount of oxygen for use when diving. They have large sinuses in their abdomens to hold blood and can also store oxygen in their muscles with increased myoglobin concentrations in muscle. In addition, they have a larger proportion of oxygen-carrying red blood cells. These adaptations allow elephant seals to dive to such depths and remain underwater for up to two hours.[16]\\r\\nElephant seals are also able to slow down their heartbeat (bradycardia) and divert blood flow from the external areas of the body to important core organs.[7] In addition, they can also slow down their metabolism while performing deep dives.[7]\\r\\nElephant seals also have a helpful feature in their bodies known as the countercurrent heat exchanger to help conserve energy and prevent heat loss.[7] In this system, arteries and veins are organized in a way to maintain a constant body temperature by having the cool blood flowing to the heart warmed by blood going to external areas of the animal.[7]\\r\\nMilk produced by elephant seals is remarkably high in milkfat compared to other mammals. After an initially lower state, it rises to over 50% milkfat (human breast milk is about 4% milkfat, and cow milk is about 3.5% milkfat).[17]\\r\\nElephant seals have large circular eyes that have more rods than cones to help them see in low light conditions when they are diving.[6][7] These seals also possess a structure called the tapetum lucidum, which helps their vision by having light reflected back to the retina to allow more chances for photoreceptors to detect light.[6]\\r\\nTheir body is covered in blubber, which helps them keep warm and reduce drag while they are swimming.[7] The shape of their body also helps them maneuver well in the water, but limits their movement on land.[7] Also, elephant seals have the ability to fast for long periods of time while breeding or molting.[7] The turbinate process, another unique adaptation, is very beneficial when these seals are fasting, breeding, molting, or hauling out.[7] This unique nasal structure recycles moisture when they breath and helps prevent water loss.[7]\\r\\nElephant seals have external whiskers called vibrissae to help them locate prey and navigate their environment.[7] The vibrissae are connected to blood vessels, nerves, and muscles making them an important sensing tool.[6]\\r\\nDue to evolutionary changes, their ear has been modified to work extremely well underwater.[6] The structure of the inner ear helps amplify incoming sounds, and allows these seals to have good directional hearing due to the isolation of the inner ear.[6] In addition to these adaptations, tissues in the ear canal allow the pressure in the ear to be adjusted while these seals perform their deep dives.[6]\\r\\nDominant males arrive at potential breeding sites in November, and will spend 3 months on the beach fasting to ensure that they can mate with as many females as possible.[7] Male elephant seals use fighting, vocal noises, and different positions to determine who will be deemed the dominate male.[7][18] When males reach 8 to 9 years of age, they have developed a pronounced long nose, in addition to a chest shield, which is thickened skin in their chest area.[7] Showing off their noses, making loud vocalizations, and altering their posture are a few ways males show off their dominance.[7][18] When battles come into play, seals will stand tall, and ram themselves into one another using their chest plates and sharp teeth.[7]\\r\\nWhen the pregnant females arrive, the dominating males have already selected their territory on the beach.[7] Females cluster in groups called harems, which could consist up to 50 or more females surrounding one alpha male.[7] Outside of these groups, a beta bull is normally roaming around on the beach.[7] The beta bull helps the alpha by preventing other males accessing the females.[7] In return, the beta bull might have an opportunity to mate with one of the females while the alpha is occupied.[7]\\r\\nBirth on average only takes a few minutes, and the mother and pup have a connection due to each other's unique smell and sound.[7] The moms will fast and nurse up to 28 days, providing their pups with rich milk.[7] The last two to three days however, females will be ready to mate, and the dominate males will pounce on the opportunity.[7] During this exhaustive process, males and females lose up to a third of their body weight during the breeding season.[7] The gestation period for females is 11 months, and the pupping seasons lasts from mid December through the middle of February.[7] The new pups will spend up to 10 more additional weeks on land learning how to swim and dive.[7]\\r\\nThe average lifespan of a Northern Elephant Seal is 9 years, while the average lifespan of a Southern Elephant Seal is 20ÿ22 years.[19] Males reach maturity at five to six years, but generally do not achieve alpha status until the age of eight, with the prime breeding years being between ages 9 and 12. The longest life expectancy of a male northern elephant seal is approximately 14 years.\\r\\nFemales begin breeding at age 3ÿ6 (median=4), and have one pup per breeding attempt.[20] Once they begin breeding, 79% of adult females breed each year.[21] Breeding success is much lower for first-time mothers relative to experienced breeders.[21] Annual survival probability of adult females is 0.83 for experienced breeding females, but only 0.66 for first-time breeders indicating a significant cost of reproduction.[21] More male pups are produced than female pups in years with warmer sea surface temperature in the northeastern Pacific Ocean.[22]\\r\\nOnce a year, elephant seals go through a process called molting where they shed the outer layer of hair and skin.[7] This molting process takes up to a month to fully complete.[7] When it comes time to molt, they will haul out on land to shed their outer layer, and will not consume any food during this time.[7] The females and juveniles will molt first, followed by the sub adult males, and finally the large mature males.[7]\\r\\nThe main predator of elephant seals is the great white shark.[7] Orcas are also another predator to elephant seals.[7] Cookie cutter sharks can even take notorious bites out of their skin.[7]\\r\\nThe IUCN lists both species of elephant seal as being of least concern, although they are still threatened by entanglement in marine debris, fishery interactions, and boat collisions. Though a complete population count of elephant seals is not possible because all age classes are not ashore at the same time, the most recent estimate of the California breeding stock was approximately 124,000 individuals. In the United States, the elephant seal, like all marine mammals, is protected under the Marine Mammal Protection Act (MMPA), passed in 1972, which outlaws hunting, killing, capture, and harassment of the animal.[23]\\r\\nSouth Georgia elephant seal\\r\\nElephant seals (Mirounga angustirostris) on Piedras Blancas beach, near San Simeon, California\\r\\nMale, female and pup\\r\\nNorthern elephant seals during molting season at Piedras Blancas beach, near San Simeon, California\\r\\nTwo bulls fighting\\r\\nElephant seal snout\\r\\nJuvenile southern elephant seal\\r\\nBeachmasters, the dominant bulls fighting at Macquarie Island\\r\\nElephant seals at Piedras Blancas, California","input":"How long can an elephant seal hold its breath?"},{"output":"the Schie?befehl (\\"order to fire\\" or \\"command to shoot\\")","context":"There were numerous escape attempts and victims of the inner German border during its 45 years of existence from 1945 to 1990.\\r\\n\\r\\n\\r\\nBetween 1945 and 1988, around 4 million East Germans migrated to the West. 3.454 million of them left between 1945 and the construction of the Berlin Wall in 1961. The great majority simply walked across the border or, after 1952, exited through West Berlin. After the border was fortified and the Berlin Wall was constructed, the number of illegal border crossings fell drastically. The numbers fell further as the border defenses were improved over the subsequent decades. In 1961, 8,507 people fled across the border, most of them through West Berlin. The construction of the Berlin Wall that year reduced the number of escapees by 75% to around 2,300 per annum for the rest of the decade. The Wall changed Berlin from being one of the easiest places to cross the border, from the East, to being one of the most difficult.[1] The number of escapees fell further to 868 per annum during the 1970s and to only 334 per annum between 1980 and 1988. However, escapees were never more than a small minority of the total number of emigrants from East Germany. Far more people left the country after being granted official permits, by fleeing through third countries or by being ransomed by the West German government. During the 1980s, only about 1% of those who left East Germany did so by escaping across the border.[2]\\r\\nEscapees had various motives for attempting to flee East Germany. The vast majority had an essentially economic motive: they wished to improve their living conditions and opportunities in the West. Some fled for political reasons, but many were impelled to leave by specific social and political events. The imposition of collective agriculture and the crushing of the 1953 East German uprising prompted thousands to flee to the West, as did further coercive economic restructuring in 1960. Thousands of those who fled did so to escape the clearance of their villages along the border. By the 1980s, the number of escape attempts was rising again as East Germany's economy stagnated and living conditions deteriorated.[3]\\r\\nAttempts to flee across the border were carefully studied and recorded by the East German authorities to identify possible weak points. These would be addressed by strengthening the fortifications in vulnerable areas. The East German Army (NVA) and the Ministry for State Security (Stasi) carried out statistical surveys to identify trends. In one example, a study was carried out by the NVA at the end of the 1970s to review attempted \\"border breaches\\" (Grenzdurchbrche). It found that 4,956?people had attempted to escape across the border between 1?January 1974 and 30?November 1979. Of those, 3,984?people (80.4%) were arrested by the People's Police in the Sperrzone, the outer restricted zone. 205?people (4.1%) were caught at the signal fence. Within the inner security zone, the Schutzstreifen, a further 743?people (15%) were arrested by the border guards. 48?people (1%) were stopped?ÿ i.e. killed or injured?ÿ by landmines and 43?people (0.9%) by SM-70 directional mines on the border fence. A further 67?people (1.35%) were intercepted at the border fence (shot and/or arrested). The study highlighted the effectiveness of the SM-70 as a means of stopping people getting across the fence. A total of 229?people?ÿ just 4.6% of attempted escapees, representing less than one in twenty?ÿ made it across the border fence. Of these, the largest number (129, or 55% of successful escapees) succeeded in making it across the fence in unmined sectors. 89?people (39% of escapees) managed to cross both the minefields and the border fence, but just 12?people (6% of the total) succeeded in getting past the SM-70s.[4]\\r\\nEscape attempts were severely punished by the East German state. From 1953, the regime described the act of escaping as Republikflucht (literally \\"flight from the Republic\\"), by analogy with the existing military term Fahnenflucht (\\"desertion\\"). A successful escapee was not a Flchtling (\\"refugee\\") but a Republikflchtiger (\\"Republic-deserter\\"). Those who attempted to escape were called Sperrbrecher (literally \\"blockade runners\\" but more loosely translated as \\"border violators\\").[3] Those who helped escapees were not Fluchthelfer (\\"escape helpers\\"), the Western term, but Menschenh?ndler (\\"human traffickers\\").[5] Such ideologically coloured language enabled the regime to portray border crossers as little better than traitors and criminals.[6] An East German propaganda booklet published in 1955 outlined the official view of escapees:\\r\\nBoth from the moral standpoint as well as in terms of the interests of the whole German nation, leaving the GDR is an act of political and moral backwardness and depravity.\\r\\nThose who let themselves be recruited objectively serve West German Reaction and militarism, whether they know it or not. Is it not despicable when for the sake of a few alluring job offers or other false promises about a \\"guaranteed future\\" one leaves a country in which the seed for a new and more beautiful life is sprouting, and is already showing the first fruits, for the place that favors a new war and destruction?\\r\\nIs it not an act of political depravity when citizens, whether young people, workers, or members of the intelligentsia, leave and betray what our people have created through common labor in our republic to offer themselves to the American or British secret services or work for the West German factory owners, Junkers, or militarists? Does not leaving the land of progress for the morass of an historically outdated social order demonstrate political backwardness and blindness? ...\\r\\n[W]orkers throughout Germany will demand punishment for those who today leave the German Democratic Republic, the strong bastion of the fight for peace, to serve the deadly enemy of the German people, the imperialists and militarists.[7]\\r\\nRepublikflucht became a crime in 1957, punishable by heavy fines and up to three years' imprisonment. Any act associated with an escape attempt was subject to this legislation. Those caught in the act were often tried for espionage as well and given proportionately harsher sentences.[8] More than 75,000?people?ÿ an average of more than seven people a day?ÿ were imprisoned for attempting to escape across the border, serving an average of one to two years' imprisonment. Border guards who attempted to escape were treated much more harshly and were on average imprisoned for five years.[9] Those who helped escapees were also subject to punishment, facing prison terms or deportation to internal exile in faraway towns. Some 50,000?East Germans suffered this fate between 1952 and 1989.[10]\\r\\nRefugees used a variety of methods to escape across the border. The great majority crossed on foot, though some took more unusual routes. One of the most spectacular was the balloon escape in September 1979 of eight people from two families in a home-made hot-air balloon. Their flight involved an ascent to more than 2,500 metres (8,200?ft) before landing near the West German town of Naila,[11] inspiring the film Night Crossing. Other escapees relied more on physical strength and endurance. An escapee in 1987 used meat hooks to scale the border fences,[12] while in 1971 a doctor swam 45 kilometres (28?mi) across the Baltic Sea from Rostock almost to the Danish island of Lolland, before he was picked up by a West German yacht.[13] Another escapee used an air mattress to escape across the Baltic in 1987.[14] Mass escapes were rare. One of the few that succeeded took place on 2?October 1961, when 53?people from the border village of B?seckendorf?ÿ a quarter of the village's population?ÿ escaped en masse, followed by another 13?inhabitants in February 1963.[15] An unusual mass escape occurred in September 1964 when 14?East Germans, including eleven children, were smuggled across the border in a refrigerated truck. They were able to escape detection by being concealed under the carcasses of slaughtered and stuffed pigs being transported to the West.[16]\\r\\nThose working on or near the border were occasionally able to use their privileged access and knowledge to escape. For the border guards, this presented special dangers, as their colleagues were under orders to shoot without warning if an escape attempt was made. The dilemmas they faced were highlighted in the May 1969 defection of a soldier and a non-commissioned officer (NCO) of the Grenztruppen. When the NCO made his escape, the soldier, Jrgen Lange, decided not to shoot him. As this exposed Lange to severe punishment by his superiors for disobeying the order to shoot, Lange made his own escape ten minutes later. When he reached the West German side, Lange found that his rifle had been sabotaged by his NCO to prevent him firing in the first place.[17] Soviet soldiers also sometimes escaped across the border, though this was very rare. Only eight such defections succeeded between 1953 and 1984.[18]\\r\\nThe traffic was not one-way; thousands of people a year migrated from West Germany to East Germany. The East German press described such individuals as \\"west zone refugees\\" who were fleeing \\"political pressure\\", \\"growing unlawfulness\\" or \\"worsening economic conditions\\". Research carried out by the West German government found more prosaic reasons, such as marital problems, family estrangement and the homesickness of those who had lived in East Germany in the past.[19] A number of Allied military personnel, including British, French, German and United States troops, also defected.[20] By the end of the Cold War, as many as 300?United States citizens were thought to have defected across the Iron Curtain for a variety of reasons[21]?ÿ whether to escape criminal charges, for political reasons or because (as the St. Petersburg Times put it) \\"girl-hungry GI's [were tempted] with seductive sirens, who usually desert the love-lorn soldier once he is across the border.\\" The fate of such defectors varied considerably. Some were sent straight to labour camps on charges of espionage. Others committed suicide, while a few were able to find wives and work on the eastern side of the border.[22]\\r\\nFrom 1945 onwards, unauthorised crossers of the inner German border risked being shot by Soviet or East German border guards. The use of deadly force was termed the Schie?befehl (\\"order to fire\\" or \\"command to shoot\\"). It was formally in force as early as 1948, when regulations concerning the use of firearms on the border were promulgated. A regulation issued to East German police 27?May 1952 stipulated that \\"failure to obey the orders of the Border Patrol will be met by the use of arms.\\" From the 1960s through to the end of the 1980s, the border guards were given daily verbal orders (Vergatterung) to \\"track down, arrest or annihilate border violators.\\" The GDR formally codified its regulations on the use of deadly force in March 1982, when the State Border Law mandated that firearms were to be used as the \\"maximum measure in the use of force\\" against individuals who \\"publicly attempt to break through the state border\\".[23] The GDR's leadership explicitly endorsed the use of deadly force. General Heinz Hoffmann, the GDR Minister of Defence, declared in August 1966 that \\"anyone who does not respect our border will feel the bullet.\\" In 1974, Erich Honecker, as Chairman of the National Defense Council of East Germany, ordered: \\"Firearms are to be ruthlessly used in the event of attempts to break through the border, and the comrades who have successfully used their firearms are to be commended.\\"[24]\\r\\nEast German border guards had a standard procedure to follow if they detected unauthorised individuals in the border zone. (Though the West Germans referred to the control strip as a \\"death strip\\", deadly force could be used at any location along the border?ÿ it did not depend on an individual's being in, or crossing, the control strip.) If the individual was less than 100 metres (330?ft) away, the border guard would first order: \\"Stop! Border sentry! Hands up!\\" (\\"Halt! Grenzposten! H?nde hoch!\\") or \\"Stop, stand still, or I will shoot!\\" (\\"Halt! Stehenbleiben, oder ich schie?e!\\"). If the individual was further away or on the Western side of the border fence the guard was authorised to shoot without warning. If the escapee was a fellow border guard, he could be shot immediately from any distance without prior warning. Border guards were instructed not to shoot if innocent bystanders might be hit or if the escapee had made it into West German territory, or if the line of fire was into West Germany. In practice, though, shots fired from East Germany often landed in West German territory.[25]\\r\\nThe border guards were under considerable pressure to obey the Schie?befehl. If they shot escapees they were rewarded with medals, bonuses and sometimes promotion. In one typical example, the killers of one would-be escapee in East Berlin in February 1972 were rewarded by being decorated with the \\"Order of Merit of the Border Troops of the GDR\\" and a bonus of 150?marks.[26] By contrast, failure to shoot or suspicion that a shooter had deliberately missed was punished.[27]\\r\\nThe Schie?befehl was, not surprisingly, very controversial in the West and was singled out for criticism by the West Germans. The West German authorities established a \\"Central Recording Office\\" to record details of deaths on the border, with the ultimate aim of prosecuting the offenders. This significantly discomfited the East German authorities, who repeatedly but unsuccessfully demanded the office's closure.[28] The GDR authorities occasionally suspended the Schie?befehl on occasions when it would have been politically inconvenient to have to explain dead refugees, such as during a visit to the GDR by the French foreign minister in 1985.[23] It was also a problem for many of the East German border guards and was the motivating factor behind a number of escapes, when guards facing a crisis of confidence defected because of their unwillingness to shoot fellow citizens.[27]\\r\\nIt is not known how many people died on the inner German border or who they were, as East Germany treated such information as a closely guarded secret. But numbers have risen steadily since unification, as evidence has been gathered from East German records. Current unofficial estimates put the figure at up to 1,100?people,[29] though officially released figures give a lower count for the death toll before and after the Berlin Wall was built.\\r\\n(1) Figures from the Arbeitsgemeinschaft 13.?August\\r\\n(2) Figures from the Zentrale Erfassungsstelle fr Regierungs- und Vereinigungskriminalit?t\\r\\n\\r\\nThere were many ways to die on the inner German border. Some escapees were shot by the border guards, while others were killed by mines and booby-traps. A substantial number drowned while trying to cross the Baltic and the Elbe river. Some died of heart attacks during their escape attempts; in one incident, a baby died after its parents gave it sleeping pills to keep it quiet during the crossing.[31]\\r\\nNot all of those killed on the border were attempting to escape. On 13?October 1961, Westf?lische Rundschau journalist Kurt Lichtenstein was shot on the border near the village of Zicherie after he attempted to speak with East German farm workers. His death aroused condemnation across the political spectrum in West Germany; he was a former parliamentary representative of the German Communist Party.[32] The incident prompted students from Braunschweig to erect a sign on the border protesting the killing.[33] An apparent mix-up over papers at a border crossing point led to the shooting of Benito Corghi, an Italian truck driver, in August 1976. Corghi was a member of the Italian Communist Party, which denounced the killing. The episode severely embarrassed the East German government and produced an unusual apology.[34] In one notorious shooting on 1?May 1976, a former East German political prisoner, Michael Gartenschl?ger, who had fled to the West some years before, was ambushed and killed by a Stasi commando squad on the border near Bchen as he tried to dismantle an SM-70 anti-personnel mine. When his body was buried it was described merely as an \\"unknown body fished out of the water\\". The Stasi's after-action report, however, declared that \\"before he could carry out the act [of removing the mine], Gartenschl?ger was liquidated by security forces of the GDR\\".[35]\\r\\nTwenty-five East German border guards died after being shot from the Western side of the border or by resisting escapees or (often accidentally) by their own colleagues.[36] The East German government described them as \\"victims of armed assaults and imperialist provocations against the state border of the GDR\\"[37] and alleged that \\"bandits\\" in the West took potshots at border guards doing their duty?ÿ a version of events that was uncorroborated by Western accounts of border incidents.\\r\\nThe two sides commemorated their dead in significantly different ways. Various mostly unofficial memorials were set up on the western side by people seeking to commemorate victims of the border. West Germans such as Michael Gartenschl?ger and Kurt Lichtenstein were commemorated with signs and memorials, some of which were supported by the government. After the policy of dtente was initiated in the 1970s this became politically inconvenient and state support for border memorials largely ceased. The taboo in East Germany surrounding escapees meant that the great majority of deaths went unpublicised and uncommemorated. The border guards who died on the frontier were, however, portrayed as \\"martyrs\\" by the East German regime. Four stone memorials were erected in East Berlin to mark their deaths.[38] The regime named schools, barracks and other public facilities after the dead guards and used their memorials as places of pilgrimage to signify that (as a slogan put it) \\"their deaths are our commitment\\" to maintaining the border. After 1989 the memorials were vandalised, neglected and ultimately removed.[39]\\r\\nFew East German escapees were commemorated in the West, not least because their identities were mostly unknown until after 1989. One notable exception was Helmut Kleinert, a 23-year-old from Quedlinburg in Saxony-Anhalt who was machine-gunned to death on 1?August 1963 as he and his 22-year-old pregnant wife attempted to cross the border near Hohegei? in the Harz mountains.[40] A memorial dedicated to \\"The Unknown\\" was soon erected by local people on the western side of the border. When Kleinert's identity became known in the West, his name was added to the memorial. It became something of a shrine with piles of flowers and wreaths deposited by visitors. The East German regime strongly objected and erected a watchtower nearby, from which threats and communist propaganda were broadcast across the border. Ultimately, in August 1971, the memorial was replaced by a stone set 150 metres (490?ft) away and out of sight of the border.[41]","input":"How did the soviets first attempt to stem the flow of refugees leaving east germany for west berlin?"},{"output":"June 20, 2006","context":"Blu-ray or Blu-ray Disc (BD) is a digital optical disc data storage format. It was designed to supersede the DVD format, and is capable of storing several hours of video in high-definition (HDTV 720p and 1080p) and ultra high-definition resolution (2160p). The main application of Blu-ray is as a medium for video material such as feature films and for the physical distribution of video games for the PlayStation 3, PlayStation 4 and Xbox One. The name \\"Blu-ray\\" refers to the blue laser (actually a violet laser) used to read the disc, which allows information to be stored at a greater density than is possible with the longer-wavelength red laser used for DVDs.\\r\\nThe plastic disc is 120 millimetres (4.7?in) in diameter and 1.2 millimetres (0.047?in) thick, the same size as DVDs and CDs.[5] Conventional or pre-BD-XL Blu-ray discs contain 25?GB per layer, with dual layer discs (50?GB) being the industry standard for feature-length video discs. Triple-layer discs (100?GB) and quadruple-layer discs (128?GB) are available for BD-XL re-writer drives.[6]\\r\\nHigh-definition (HD) video may be stored on Blu-ray discs with up to 2160p resolution (3840G2160 pixels) and at up to 60 frames per second. DVD-Video discs were limited to a maximum resolution of 480p (NTSC, 720G480 pixels) or 576p (PAL, 720G576 pixels).[7] Besides these hardware specifications, Blu-ray is associated with a set of multimedia formats.\\r\\nThe BD format was developed by the Blu-ray Disc Association, a group representing makers of consumer electronics, computer hardware, and motion pictures. Sony unveiled the first Blu-ray disc prototypes in October 2000, and the first prototype player was released in April 2003 in Japan. Afterwards, it continued to be developed until its official release on June 20, 2006, beginning the high definition optical disc format war, where Blu-ray Disc competed with the HD DVD format. Toshiba, the main company supporting HD DVD, conceded in February 2008,[8] and later released its own Blu-ray Disc player in late 2009.[9] According to Media Research, high-definition software sales in the US were slower in the first two years than DVD software sales.[10] Blu-ray faces competition from video on demand (VOD) and the continued sale of DVDs.[11] Notably, as of January 2016, 44% of U.S. broadband households had a Blu-ray player.[12]\\r\\n\\r\\n\\r\\nThe information density of the DVD format was limited by the wavelength of the laser diodes used. Following protracted development, blue laser diodes operating at 405 nanometers became available on a production basis. Sony started two projects in collaboration with Philips[13] applying the new diodes: UDO (Ultra Density Optical),[14] and DVR Blue (together with Pioneer),[15] a format of rewritable discs that would eventually become Blu-ray Disc (more specifically, BD-RE). The core technologies of the formats are similar. The first DVR Blue prototypes were unveiled at the CEATEC exhibition in October 2000 by Sony.[16] A trademark for the \\"Blue Disc\\" logo was filed February 9, 2001.[17] On February 19, 2002, the project was officially announced as Blu-ray Disc,[18][19] and Blu-ray Disc Founders was founded by the nine initial members.\\r\\nThe first consumer device arrived in stores on April 10, 2003: the Sony BDZ-S77, a $3,800 (US) BD-RE recorder that was made available only in Japan.[20] But there was no standard for prerecorded video, and no movies were released for this player. Hollywood studios insisted that players be equipped with digital rights management before they would release movies for the new format, and they wanted a new DRM system that would be more secure than the failed Content Scramble System (CSS) used on DVDs. On October 4, 2004, the name \\"Blu-ray Disc Founders\\" was officially changed to the Blu-ray Disc Association (BDA), and 20th Century Fox joined the BDA's Board of Directors.[21] The Blu-ray Disc physical specifications were completed in 2004.[22]\\r\\nIn January 2005, TDK announced that they had now developed an ultra-hard yet very thin polymer coating (\\"Durabis\\") for Blu-ray discs; this was a significant technical advance because a far tougher protection was desired in the consumer market to protect bare discs against scratching and damage compared to DVD, while technically Blu-ray Disc required a much thinner layer for the denser and higher frequency blue laser.[23] Cartridges, originally used for scratch protection, were no longer necessary and were scrapped. The BD-ROM specifications were finalized in early 2006.[24]\\r\\nAACS LA, a consortium founded in 2004,[25] had been developing the DRM platform that could be used to securely distribute movies to consumers. However, the final AACS standard was delayed,[26] and then delayed again when an important member of the Blu-ray Disc group voiced concerns.[27] At the request of the initial hardware manufacturers, including Toshiba, Pioneer, and Samsung, an interim standard was published that did not include some features, such as managed copy.[28]\\r\\nThe first BD-ROM players (Samsung BD-P1000) were shipped in mid-June 2006, though HD DVD players beat them to market by a few months.[29][30] The first Blu-ray Disc titles were released on June 20, 2006: 50 First Dates, The Fifth Element, Hitch, House of Flying Daggers, Underworld: Evolution, xXx (all Sony), Twister (Warner Bros.), and MGM's The Terminator.[31] The earliest releases used MPEG-2 video compression, the same method used on standard DVDs. The first releases using the newer VC-1 and AVC formats were introduced in September 2006.[32] The first movies using 50?GB dual-layer discs were introduced in October 2006.[33] The first audio-only albums were released in May 2008.[34][35]\\r\\nThe first mass-market Blu-ray Disc rewritable drive for the PC was the BWU-100A, released by Sony on July 18, 2006.[36] It recorded both single and dual-layer BD-Rs as well as BD-REs and had a suggested retail price of US $699. As of June 2008[update], more than 2,500 Blu-ray Disc titles were available in Australia and the United Kingdom, with 3,500 in the United States and Canada.[37] In Japan, as of July 2010[update], more than 3,300 titles have been released.[38]\\r\\nThe DVD Forum, chaired by Toshiba, was split over whether to develop the more expensive blue laser technology. In March 2002 the forum approved a proposal, which was endorsed by Warner Bros. and other motion picture studios. The proposal involved compressing HD video onto dual-layer standard DVD-9 discs.[39][40] In spite of this decision, however, the DVD Forum's Steering Committee announced in April that it was pursuing its own blue-laser high-definition video solution. In August, Toshiba and NEC announced their competing standard, Advanced Optical Disc.[41] It was finally adopted by the DVD Forum and renamed HD DVD the next year,[42] after being voted down twice by DVD Forum members who were also Blu-ray Disc Association membersa situation that drew preliminary investigations by the U.S. Department of Justice.[43]\\r\\nHD DVD had a head start in the high-definition video market, as Blu-ray Disc sales were slow to gain market share. The first Blu-ray Disc player was perceived as expensive and buggy, and there were few titles available.[44]\\r\\nThe appearance of the Sony PlayStation 3, which contained a Blu-ray Disc player for primary storage, helped support Blu-ray.[45] Sony also ran a more thorough and influential marketing campaign for the format.[46] AVCHD camcorders were also introduced in 2006. These recordings can be played back on many Blu-ray Disc players without re-encoding but are not compatible with HD DVD players. By January 2007, Blu-ray Discs had outsold HD DVDs,[47] and during the first three-quarters of 2007, BD outsold HD DVD by about two to one. At CES 2007, Warner proposed Total Hi Defa hybrid disc containing Blu-ray on one side and HD DVD on the other, but it was never released.\\r\\nIn a June 28, 2007, press release, Twentieth Century Fox cited Blu-ray Disc's adoption of the BD+ anticopying system as key to their decision to support the Blu-ray Disc format.[48][49] On January 4, 2008, a day before CES 2008, Warner Bros. (the only major studio still releasing movies in both HD DVD and Blu-ray Disc format) announced that it would release only in Blu-ray Disc after May 2008.[50] This effectively included other studios that came under the Warner umbrella, such as New Line Cinema and HBOthough in Europe, HBO distribution partner, the BBC, announced it would, while keeping an eye on market forces, continue to release product on both formats. This led to a chain reaction in the industry, with major U.S. retailers such as Best Buy, Walmart, and Circuit City and Canadian chains such as Future Shop dropping HD DVD in their stores. A then major European retailer, Woolworths, dropped HD DVD from its inventory.[51] Netflix and Blockbustermajor DVD rental companiessaid they would no longer carry HD DVD.\\r\\nFollowing these new developments, on February 19, 2008, Toshiba announced it would end production of HD DVD devices,[52] allowing Blu-ray Disc to become the industry standard for high-density optical discs. Universal Studios, the sole major movie studio to back HD DVD since its inception, said shortly after Toshiba's announcement: \\"While Universal values the close partnership we have shared with Toshiba, it is time to turn our focus to releasing new and catalog titles on Blu-ray Disc.\\"[53] Paramount Pictures, which started releasing movies only in HD DVD format during late 2007, also said it would start releasing in Blu-ray Disc. Both studios announced initial Blu-ray lineups in May 2008. With this, all major Hollywood studios supported Blu-ray.[54]\\r\\nAccording to Media Research, high-definition software sales in the US were slower in the first two years than DVD software sales.[10] 16.3 million DVD software units were sold in the first two years (1997ÿ98) compared to 8.3 million high-definition software units (2006ÿ07).[10][55] One reason given for this difference was the smaller marketplace (26.5 million HDTVs in 2007 compared to 100 million SDTVs in 1998).[55] Former HD DVD supporter Microsoft did not make a Blu-ray Disc drive for the Xbox 360.[56] The 360's successor Xbox One features a Blu-ray drive, as does the PS4, with both supporting 3D Blu-ray after later firmware updates.[57][58]\\r\\nShortly after the \\"format war\\" ended, Blu-ray disc sales began to increase. A study by The NPD Group found that awareness of Blu-ray Disc had reached 60% of U.S. households. Nielsen VideoScan sales numbers showed that for some titles, such as 20th Century Fox's Hitman, up to 14% of total disc sales were from Blu-ray, although the average Blu-ray sales for the first half of the year were only around 5%. In December 2008, the Blu-ray Disc version of The Dark Knight sold 600,000 copies on the first day of its launch in the United States, Canada, and the United Kingdom.[59] A week after the launch, The Dark Knight BD had sold over 1.7 million copies worldwide, making it the first Blu-ray Disc title to sell over a million copies in the first week of release.[60]\\r\\nAccording to Singulus Technologies AG, Blu-ray is being adopted faster than the DVD format was at a similar period in its development. This conclusion was based on the fact that Singulus Technologies has received orders for 21 Blu-ray dual-layer machines during the first quarter of 2008, while 17 DVD machines of this type were made in the same period in 1997.[63] According to GfK Retail and Technology, in the first week of November 2008, sales of Blu-ray recorders surpassed DVD recorders in Japan.[64] According to the Digital Entertainment Group, the number of Blu-ray Disc playback devices (both set-top box and game console) sold in the U.S. had reached 28.5 million by the end of 2010.[62]\\r\\nBlu-ray faces competition from video on demand[65] and from new technologies that allow access to movies on any format or device, such as Digital Entertainment Content Ecosystem or Disney's Keychest.[66] Some commentators have suggested that renting Blu-ray will play a vital part in keeping the technology affordable while allowing it to move forward.[67] In an effort to increase sales, studios are releasing movies in combo packs with Blu-ray Discs and DVDs as well as digital copies that can be played on computers and mobile devices. Some are released on \\"flipper\\" discs with Blu-ray on one side and DVD on the other. Other strategies are to release movies with the special features only on Blu-ray Discs and none on DVDs.\\r\\nThe Holographic Versatile Disc (HVD), described in the ECMA-377 standard, has been in development by The Holography System Development (HSD) Forum using a green writing/reading laser (532?nm) and a red positioning/addressing laser (650?nm). It is to offer MPEG-2, MPEG-4 AVC (H.264), HEVC (H.265), and VC-1 encoding, supporting a maximum storage capacity of 6TB.[68] No systems corresponding to the Ecma International HVD standard have been released.[69] Because the Blu-ray Disc format is upgradable it poses challenges to the adoption of the HVD format. 4K Blu-ray discs and players became available in the first quarter of 2016, having a storage capacity of up to 100?GB.[70][71]\\r\\nAlthough the Blu-ray Disc specification has been finalized, engineers continue to work on advancing the technology. By 2005, quad-layer (128?GB) discs had been demonstrated on a drive with modified optics[72] and standard unaltered optics.[73] Hitachi stated that such a disc could be used to store 7?hours of 32?Mbit/s video (HDTV) or 3?hours and 30?minutes of 64?Mbit/s video (Ultra high definition television). In August 2006, TDK announced that they had created a working experimental Blu-ray Disc capable of holding 200?GB of data on a single side, using six 33?GB data layers.[74]\\r\\nAlso, behind closed doors at CES 2007, Ritek revealed that they had successfully developed a High Definition optical disc process that extends the disc capacity to ten layers, which increases the capacity of the discs to 250?GB. However, they noted that the major obstacle is that current read/write technology does not allow additional layers.[75] JVC has developed a three-layer technology that allows putting both standard-definition DVD data and HD data on a BD/(standard) DVD combination.[76] This would have enabled the consumer to purchase a disc that can be played on DVD players and can also reveal its HD version when played on a BD player.[77] Japanese optical disc manufacturer Infinity announced the first \\"hybrid\\" Blu-ray Disc/(standard) DVD combo, to be released February 18, 2009. This disc set of the TV series \\"Code Blue\\" featured four hybrid discs containing a single Blu-ray Disc layer (25?GB) and two DVD layers (9?GB) on the same side of the disc.[78]\\r\\nIn January 2007, Hitachi showcased a 100?GB Blu-ray Disc, consisting of four layers containing 25?GB each.[79] Unlike TDK and Panasonic's 100?GB discs, they claim this disc is readable on standard Blu-ray Disc drives that are currently in circulation, and it is believed that a firmware update is the only requirement to make it readable to current players and drives.[80] In December 2008, Pioneer Corporation unveiled a 400?GB Blu-ray Disc (containing 16 data layers, 25?GB each) that will be compatible with current players after a firmware update. Its planned launch was in the 2009ÿ10 time frame for ROM and 2010ÿ13 for rewritable discs. Ongoing development was underway to create a 1?TB Blu-ray Disc.[81]\\r\\nAt CES 2009, Panasonic unveiled the DMP-B15, the first portable Blu-ray Disc player, and Sharp introduced the LC-BD60U and LC-BD80U series, the first LCD HDTVs with integrated Blu-ray Disc players. Sharp has also announced that they will sell HDTVs with integrated Blu-ray Disc recorders in the United States by the end of 2009. Set-top box recorders were not being sold in the U.S. for fear of unauthorized copying. However, personal computers with Blu-ray recorder drives were available. On January 1, 2010, Sony, in association with Panasonic, announced plans to increase the storage capacity on their Blu-ray Discs from 25?GB to 33.4?GB via a technology called i-MLSE (Maximum likelihood Sequence Estimation). The higher-capacity discs, according to Sony, would be readable on existing Blu-ray Disc players with a firmware upgrade. No date was set to include the increased space, although in 2010 Blu-ray.com reported that \\"it will likely happen sometime later this year.\\"[82]\\r\\nOn July 20, 2010, the research team of Sony and Japanese Tohoku University announced the joint development of a blue-violet laser,[83] to help create Blu-ray discs with a capacity of 1 TB using only two layers (and potentially more than 1 TB with additional layering). By comparison, the first blue laser was invented in 1996, with the first prototype discs coming four years later. \\r\\nOn January 7, 2013, Sony announced that it would release \\"Mastered in 4K\\" Blu-ray Disc titles which are sourced at 4K and encoded at 1080p.[84] \\"Mastered in 4K\\" Blu-ray Disc titles can be played on existing Blu-ray Disc players and have a larger color space using xvYCC.[84][85] On January 14, 2013, Blu-ray Disc Association president, Andy Parsons, stated that a task force was created three months prior to conduct a study concerning an extension to the Blu-ray Disc specification that would add the ability to contain 4K Ultra HD video.[86][87]\\r\\nOn August 5, 2015, The Blu-ray Disc Association (BDA) announced it will commence licensing the Ultra HD Blu-ray format starting August 24, 2015. The Ultra HD Blu-ray format delivered high dynamic range content that significantly expanded the range between the brightest and darkest elements, expanded color range, high frame rate (up to 60fps) and up to 3840G2160 resolution, object-based sound formats, and an optional \\"digital bridge\\" feature. New players were required to play this format, which were able to play both DVDs, traditional Blu-rays and the new format. New Ultra HD Blu-ray discs hold up to 66?GB and 100?GB of data on dual and triple layer discs respectively.[88]\\r\\nWhile a DVD uses a 650?nm red laser, Blu-ray Disc uses a 405?nm \\"blue\\" laser diode. Although the laser is called \\"blue\\", its color is actually in the violet range. The shorter wavelength can be focused to a smaller area, thus enabling it to read information recorded in pits that are less than half the size of those on a DVD, and can consequently be spaced more closely, resulting in a shorter track pitch, enabling a Blu-ray Disc to hold about five times the amount of information that can be stored on a DVD. The lasers are GaN (gallium nitride) laser diodes that produce 405?nm light directly, that is, without frequency doubling or other nonlinear optical mechanisms.[90] Conventional DVDs use 650?nm red lasers, and CDs use 780?nm near-infrared lasers.\\r\\nThe minimum \\"spot size\\" on which a laser can be focused is limited by diffraction and depends on the wavelength of the light and the numerical aperture of the lens used to focus it. By decreasing the wavelength, increasing the numerical aperture from 0.60 to 0.85, and making the cover layer thinner to avoid unwanted optical effects, designers can cause the laser beam to focus on a smaller spot, which effectively allows more information to be stored in the same area.[91] For Blu-ray Disc, the spot size is 580?nm.[92] This allows a reduction of the pit size from 400?nm for DVD to 150?nm for Blu-ray Disc, and of the track pitch from 740?nm to 320?nm.[91] See Compact Disc for information on optical discs' physical structure. In addition to the optical improvements, Blu-ray Discs feature improvements in data encoding that further increase the amount of content that can be stored.[93]\\r\\nSince the Blu-ray Disc data layer is closer to the surface of the disc compared to the DVD standard, it was more vulnerable to scratches in early designs.[94] The first discs were therefore housed in cartridges for protection, resembling Professional Discs introduced by Sony in 2003. Using a cartridge would increase the price of an already expensive medium, so designers chose hard-coating of the pickup surface instead. TDK was the first company to develop a working scratch-protection coating for Blu-ray Discs, naming it Durabis. In addition, both Sony's and Panasonic's replication methods include proprietary hard-coat technologies. Sony's rewritable media are spin-coated, using a scratch-resistant and antistatic coating. Verbatim's recordable and rewritable Blu-ray Discs use their own proprietary technology, called Hard Coat.[95]\\r\\nThe Blu-ray Disc specification requires the testing of resistance to scratches by mechanical abrasion.[91] In contrast, DVD media are not required to be scratch-resistant, but since development of the technology, some companies, such as Verbatim, implemented hard-coating for more expensive lines of recordable DVDs.\\r\\nThe table shows the speeds available. Even the lowest speed (1x) is sufficient to play and record real-time 1080p video; the higher speeds are relevant for general data storage and more sophisticated handling of video.\\r\\nThe usable data rate of a Blu-ray Disc drive can be limited by the capacity of the drive's data interface. With a USB 2.0 interface, the maximum exploitable drive speed is 288?Mbit/s or 36?MB/s (also called 8G speed).[96] A USB 3.0 interface (with proper cabling) does not have this limitation,[97] nor do even the oldest version of Serial ATA (SATA) nor the latest Parallel ATA standards.[98] Blu-ray drives that are integrated into a computer (as opposed to physically separate and connected via a cable) typically have a SATA interface.[99]\\r\\nPre-recorded Blu-ray Disc titles usually ship in packages similar to but slightly smaller (18.5?mm shorter and 2?mm thinner: 135?mm x 171.5?mm x 13?mm.[100]), as well as more rounded than a standard DVD keep case, generally with the format prominently displayed in a horizontal stripe across the top of the case (translucent blue for Blu-ray video discs, clear for Blu-ray 3D video releases, red for PlayStation 3 Greatest Hits Games, transparent for regular PlayStation 3 games, transparent dark blue for PlayStation 4 games and transparent green for Xbox One games). Warren Osborn and The Seastone Media Group, LLC created the package that was adopted worldwide following the Blu-ray vs. HD DVD market adoption choice.[101] Because of the fact that Blu-ray cases are smaller than DVD cases, more Blu-Rays than DVDs can fit on a shelf, making Blu-ray an arguably better choice for situations with limited storage space.\\r\\nThe \\"Mini Blu-ray Disc\\" (also, \\"Mini-BD\\" and \\"Mini Blu-ray\\") is a compact 8?cm (~3?in)-diameter variant of the Blu-ray Disc that can store 7.8?GB of data in its single layer configuration, or 15.6?GB on a dual layer disc.[102] It is similar in concept to the MiniDVD and MiniCD. Recordable (BD-R) and rewritable (BD-RE) versions of Mini Blu-ray Disc have been developed specifically for compact camcorders and other compact recording devices.[103]\\r\\n\\"Blu-ray Disc recordable\\" refers to two optical disc formats that can be recorded with an optical disc recorder. BD-Rs can be written to once, whereas BD-REs can be erased and re-recorded multiple times. The current practical maximum speed for Blu-ray Discs is about 12G. Higher speeds of rotation (10,000+ rpm) cause too much wobble for the discs to be written properly, as with the 20G and 52G maximum speeds, respectively, of standard DVDs and CDs. Since September 2007, BD-RE is also available in the smaller 8?cm Mini Blu-ray Disc size.[103][104]\\r\\nOn September 18, 2007, Pioneer and Mitsubishi codeveloped BD-R LTH (\\"Low to High\\" in groove recording), which features an organic dye recording layer that can be manufactured by modifying existing CD-R and DVD-R production equipment, significantly reducing manufacturing costs.[105] In February 2008, Taiyo Yuden, Mitsubishi, and Maxell released the first BD-R LTH Discs,[106] and in March 2008, Sony's PlayStation 3 officially gained the ability to use BD-R LTH Discs with the 2.20 firmware update.[107] In May 2009 Verbatim/Mitsubishi announced the industry's first 6X BD-R LTH media, which allows recording a 25?GB disc in about 16 minutes.[108] Unlike with the previous releases of 120?mm optical discs (i.e. CDs and standard DVDs), Blu-ray recorders hit the market almost simultaneously with Blu-ray's debut.\\r\\nThe BD9 format was proposed to the Blu-ray Disc Association by Warner Home Video as a cost-effective alternative to the 25/50?GB BD-ROM discs. The format was supposed to use the same codecs and program structure as Blu-ray Disc video but recorded onto less expensive 8.5?GB dual-layer DVD. This red-laser media could be manufactured on existing DVD production lines with lower costs of production than the 25/50?GB Blu-ray media.[109]\\r\\nUsage of BD9 for releasing content on \\"pressed\\" discs never caught on. With the end of the format war, manufacturers ramped production of Blu-ray Discs and lowered prices to compete with DVDs. On the other hand, the idea of using inexpensive DVD media became popular among individual users. A lower-capacity version of this format that uses single-layer 4.7?GB DVDs has been unofficially called BD5. Both formats are being used by individuals for recording high definition content in Blu-ray format onto recordable DVD media.[110][111] Despite the fact that the BD9 format has been adopted as part of the BD-ROM basic format, none of the existing Blu-ray player models explicitly claim to be able to read it. Consequently, the discs recorded in BD9 and BD5 formats are not guaranteed to play on standard Blu-ray Disc players. AVCHD and AVCREC also use inexpensive media like DVDs, but unlike BD9 and BD5 these formats have limited interactivity, codec types, and data rates. As of March 2011, BD9 was removed as an official BD-ROM disc.[112]\\r\\nThe BDXL format allows 100?GB and 128?GB write-once discs,[113][114] and 100?GB rewritable discs for commercial applications. It was defined in June 2010.[citation needed] BD-R 3.0 Format Specification (BDXL) defined a multi-layered disc recordable in BDAV format with the speed of 2G and 4G, capable of 100/128?GB and usage of UDF2.5/2.6.[115] BD-RE 4.0 Format Specification (BDXL) defined a multi-layered disc rewritable in BDAV with the speed of 2G and 4G, capable of 100?GB and usage of UDF2.5 as file system.[116]\\r\\nThe IH-BD (Intra-Hybrid Blu-ray) format includes a 25?GB rewritable layer (BD-RE) and a 25?GB write once layer (BD-ROM), designed to work with existing Blu-ray Discs.[113][114]\\r\\nBlu-ray Disc specifies the use of Universal Disk Format (UDF) 2.50 as a convergent friendly format for both PC and consumer electronics environments. It is used in the latest specifications of BD-ROM, BD-RE, and BD-R.[117][118][119] In the first BD-RE specification (defined in 2002), the BDFS (Blu-ray Disc File System) was used. The BD-RE 1.0 specification was defined mainly for the digital recording of high-definition television (HDTV) broadcast television. The BDFS was replaced by UDF 2.50 in the second BD-RE specification in 2005, in order to enable interoperability among consumer electronics Blu-ray recorders and personal computer systems. These optical disc recording technologies enabled PC recording and playback of BD-RE.[119][120][121] BD-R can use UDF 2.50/2.60.[122]\\r\\nThe Blu-ray Disc application for recording of digital broadcasting has been developed as System Description Blu-ray Rewritable Disc Format part 3 Audio Visual Basic Specifications (BDAV). The requirements related with computer file system have been specified in System Description Blu-ray Rewritable Disc Format part 2 File System Specifications version 1.0 (BDFS).[123] Initially, the BD-RE version 1.0 (BDFS) was specifically developed for recording of digital broadcasts using the Blu-ray Disc application (BDAV application). But these requirements are superseded by the Blu-ray Rewritable Disc File System Specifications version 2.0 (UDF) (a.k.a. RE 2.0) and Blu-ray Recordable Disc File System Specifications version 1.0 (UDF) (a.k.a. R 1.0). Additionally, a new application format, BDMV (System Description Blu-ray Disc Prerecorded Format part 3 Audio Visual Basic Specifications) for High Definition Content Distribution was developed for BD-ROM. The only file system developed for BDMV is the System Description Blu-ray Read-Only Disc Format part 2 File System Specifications version 1.0 (UDF) which defines the requirements for UDF 2.50.[119][123]\\r\\nAll BDMV application files are stored under a BDMV directory.[128][129][130][131]\\r\\nAudio, video, and other streams are multiplexed and stored on Blu-ray Discs in a container format based on the MPEG transport stream. It is also known as BDAV MPEG-2 transport stream and can use filename extension .m2ts.[128][132] Blu-ray Disc titles authored with menus are in the BDMV (Blu-ray Disc Movie) format and contain audio, video, and other streams in BDAV container.[133][134] There is also the BDAV (Blu-ray Disc Audio/Visual) format, the consumer oriented alternative to the BDMV format used for movie releases. The BDAV format is used on BD-REs and BD-Rs for audio/video recording.[134] BDMV format was later defined also for BD-RE and BD-R (in September 2006, in the third revision of BD-RE specification and second revision of BD-R specification).[117][118]\\r\\nBlu-ray Disc employs the MPEG transport stream recording method. That enables transport streams of digital broadcasts to be recorded as they are broadcast, without altering the format.[135] It also enables flexible editing of a digital broadcast that is recorded as is and where the data can be edited just by rewriting the playback stream. Although it is quite natural, a function for high-speed and easy-to-use retrieval is built in.[135][136] Blu-ray Disc Video use MPEG transport streams, compared to DVD's MPEG program streams. An MPEG transport stream contains one or more MPEG program streams, so this allows multiple video programs to be stored in the same file so they can be played back simultaneously (e.g. with \\"picture-in-picture\\" effect).\\r\\nThe BD-ROM specification mandates certain codec compatibilities for both hardware decoders (players) and movie software (content).[132][137] Windows Media Player does not come with the codecs required to play Blu-ray discs.[138]\\r\\nOriginally BD-ROMs stored video up to 1920G1080 pixel resolution at up to 60 (59.94) fields per second. Currently with UHD BD-ROM videos can be stored at a maximum of 3840G2160 pixel resolution at up to 60 (59.94) frames per second, progressively scanned. While most current Blu-ray players and recorders can read and write 1920G1080 video at the full 59.94p and 50p progressive format, new players for the UHD specifications will be able to read at 3840G2160 video at either 59.94p and 50p formats.\\r\\n^ a Interlaced formats are listed in fields per second.\\r\\n^ b MPEG-2 at 1440G1080 was previously not included in a draft version of the specification from March 2005.[141]\\r\\nFor video, all players are required to process H.262/MPEG-2 Part 2, H.264/MPEG-4 Part 10: AVC, and SMPTE VC-1.[142] BD-ROM titles with video must store video using one of the three mandatory formats; multiple formats on a single title are allowed. Blu-ray Disc allows video with a bit depth of 8-bits per color YCbCr with 4:2:0 chroma subsampling.[143][144] The choice of formats affects the producer's licensing/royalty costs as well as the title's maximum run time, due to differences in compression efficiency. Discs encoded in MPEG-2 video typically limit content producers to around two hours of high-definition content on a single-layer (25?GB) BD-ROM. The more-advanced video formats (VC-1 and MPEG-4 AVC) typically achieve a video run time twice that of MPEG-2, with comparable quality.\\r\\nMPEG-2 was used by many studios (including Paramount Pictures, which initially used the VC-1 format for HD DVD releases) for the first series of Blu-ray Discs, which were launched throughout 2006.[145] Modern releases are now often encoded in either MPEG-4 AVC or VC-1, allowing film studios to place all content on one disc, reducing costs and improving ease of use. Using these formats also frees a lot of space for storage of bonus content in HD (1080i/p), as opposed to the SD (480i/p) typically used for most titles. Some studios, such as Warner Bros., have released bonus content on discs encoded in a different format than the main feature title. For example, the Blu-ray Disc release of Superman Returns uses VC-1 for the feature film and MPEG-2 for some of its bonus content.[146] Today, Warner and other studios typically provide bonus content in the video format that matches the feature.\\r\\nFor audio, BD-ROM players are required to implement Dolby Digital (AC-3), DTS, and linear PCM. Players may optionally implement Dolby Digital Plus and DTS-HD High Resolution Audio as well as lossless formats Dolby TrueHD and DTS-HD Master Audio.[147] BD-ROM titles must use one of the mandatory schemes for the primary soundtrack. A secondary audiotrack, if present, may use any of the mandatory or optional codecs.\\r\\nFor users recording digital television programming, the recordable Blu-ray Disc standard's initial data rate of 36?Mbit/s is more than adequate to record high-definition broadcasts from any source (IPTV, cable/satellite, or terrestrial). BD Video movies have a maximum data transfer rate of 54?Mbit/s, a maximum AV bitrate of 48?Mbit/s (for both audio and video data), and a maximum video bit rate of 40?Mbit/s. This compares to HD DVD movies, which have a maximum data transfer rate of 36?Mbit/s, a maximum AV bitrate of 30.24?Mbit/s, and a maximum video bitrate of 29.4?Mbit/s.[149]\\r\\nAt the 2005 JavaOne trade show, it was announced that Sun Microsystems' Java cross-platform software environment would be included in all Blu-ray Disc players as a mandatory part of the standard.[150] Java is used to implement interactive menus on Blu-ray Discs, as opposed to the method used on DVD-video discs. DVDs use pre-rendered MPEG segments and selectable subtitle pictures, which are considerably more primitive and rarely seamless. At the conference, Java creator James Gosling suggested that the inclusion of a Java virtual machine, as well as network connectivity in some BD devices, will allow updates to Blu-ray Discs via the Internet, adding content such as additional subtitle languages and promotional features not included on the disc at pressing time.[151] This Java Version is called BD-J and is built on a profile of the Globally Executable MHP (GEM) standard; GEM is the worldwide version of the Multimedia Home Platform standard.\\r\\nThe BD-ROM specification defines four Blu-ray Disc player profiles, including an audio-only player profile (BD-Audio) that does not require video decoding or BD-J. All of the video-based player profiles (BD-Video) are required to have a full implementation of BD-J.\\r\\n^ a This is used for storing audio/video and title updates. It can either be built-in memory or removable media, such as a memory card or USB flash memory.\\r\\n^ b A secondary audio decoder is typically used for interactive audio and commentary.\\r\\n^ c Profile 3.0 is a separate audio-only player profile. The first Blu-ray Disc album to be released was Divertimenti, by record label Lindberg Lyd, and it has been confirmed to work on the PS3.[152][153]\\r\\n^ d Also known as Initial Standard profile.\\r\\n^ e Also known as Final Standard profile.\\r\\nOn November 2, 2007, the Grace Period Profile was superseded by Bonus View as the minimum profile for new BD-Video players released to the market.[154] When Blu-ray Disc software not authored with interactive features dependent on Bonus View or BD-Live hardware capabilities is played on Profile 1.0 players, it is able to play the main feature of the disc, but some extra features may not be available or will have limited capability.[155]\\r\\nThe biggest difference between Bonus View and BD-Live is that BD-Live requires the Blu-ray Disc player to have an Internet connection to access Internet-based content. BD-Live features have included Internet chats, scheduled chats with the director, Internet games, downloadable featurettes, downloadable quizzes, and downloadable movie trailers.[156][157][158] Note that while some Bonus View players may have an Ethernet port, these are used for firmware updates and are not used for Internet-based content.[159] In addition, Profile 2.0 also requires more local storage in order to handle this content.\\r\\nProfile 1.0 players are not eligible for Bonus View or BD-Live compliant upgrades and do not have the function or capability to access these upgrades, with the exception of the latest players and the PlayStation 3. Internet is required to use.[160][161][162]\\r\\nAs with the implementation of region codes for DVDs, Blu-ray Disc players sold in a specific geographical region are designed to play only discs authorized by the content provider for that region. This is intended to permit content providers (motion picture studios, television production company etc.) to do effective price differentiation between regions. According to the Blu-ray Disc Association, all Blu-ray Disc players and Blu-ray Disc-equipped computer systems are required to enforce regional coding. However, content providers need not use region playback codes.[164] Some current estimates suggest 70% of available [movie] Blu-ray Discs from the major studios are region-code-free and can, therefore, be played on any Blu-ray Disc player, in any region.[165]\\r\\nMovie distributors have different region coding policies. Among major U.S. studios, Walt Disney Pictures, Warner Bros., Paramount Pictures, Universal Studios, and Sony Pictures have released most of their titles region-free.[166][167][168][169][170][171] MGM and Lions Gate Entertainment have released a mix of region-free and region-coded titles.[172][173] 20th Century Fox has released most of their titles region-coded.[174] Vintage film restoration and distribution company The Criterion Collection uses US region coding in all Blu-ray releases.[175][176]\\r\\nThe Blu-ray Disc region coding scheme divides the world into three regions, labeled A, B, and C.\\r\\nIn circumvention of region coding restrictions, stand-alone Blu-ray Disc players are sometimes modified by third parties to allow for playback of Blu-ray Discs (and DVDs) with any region code.[177] Instructions (\\"hacks\\") describing how to reset the Blu-ray region counter of computer player applications to make them multi-region indefinitely are also regularly posted to video enthusiast websites and forums. Unlike DVD region codes, Blu-ray region codes are verified only by the player software, not by the optical drive's firmware.\\r\\nThe latest type of Blu-Ray disc, suitable for UltraHD content, are region-free.[178]\\r\\nThe Blu-ray Disc format employs several layers of digital rights management (DRM) which restrict the usage of the discs.[179][180] This has led to extensive criticism of the format by organizations opposed to DRM, such as the Free Software Foundation,[181] and consumers because new releases require player firmware updates to allow disc playback.[182][183]\\r\\nBlu-ray equipment is required to implement the High-bandwidth Digital Content Protection (HDCP) system to encrypt the data sent by players to rendering devices through physical connections. This is aimed at preventing the copying of copyrighted content as it travels across cables. Through a protocol flag in the media stream called the Image Constraint Token (ICT), a Blu-ray Disc can enforce its reproduction in a lower resolution whenever a full HDCP-compliant link is not used. In order to ease the transition to high definition formats, the adoption of this protection method was postponed until 2011.[184]\\r\\nThe Advanced Access Content System (AACS) is a standard for content distribution and digital rights management. It was developed by AS Licensing Administrator, LLC (AACS LA), a consortium that includes Disney, Intel, Microsoft, Panasonic, Warner Bros., IBM, Toshiba, and Sony. Since the appearance of the format on devices in 2006, several successful attacks have been made on it. The first known attack relied on the trusted client problem. In addition, decryption keys have been extracted from a weakly protected player (WinDVD). Since keys can be revoked in newer releases,[185] this is only a temporary attack, and new keys must continually be discovered in order to decrypt the latest discs.\\r\\nBD+ was developed by Cryptography Research Inc. and is based on their concept of Self-Protecting Digital Content.[186] BD+, effectively a small virtual machine embedded in authorized players, allows content providers to include executable programs on Blu-ray Discs. Such programs can:[179]\\r\\nIf a playback device manufacturer finds that its devices have been hacked, it can potentially release BD+ code that detects and circumvents the vulnerability. These programs can then be included in all new content releases.[187] The specifications of the BD+ virtual machine are available only to licensed device manufacturers. A list of licensed commercial adopters is available from the BD+ website.\\r\\nThe first titles using BD+ were released in October 2007. Since November 2007, versions of BD+ protection have been circumvented by various versions of the AnyDVD HD program.[188][189] Other programs known to be capable of circumventing BD+ protection are DumpHD (versions 0.6 and above, along with some supporting software),[190] MakeMKV,[191] and two applications from DVDFab (Passkey and HD Decrypter[192]).\\r\\nBD-ROM Mark is a small amount of cryptographic data that is stored separately from normal Blu-ray Disc data, aiming to prevent replication of the discs. The cryptographic data is needed to decrypt the copyrighted disc content protected by AACS.[193] A specially licensed piece of hardware is required to insert the ROM-Mark into the media during mastering. During replication, this ROM Mark is transferred together with the recorded data to the disc. In consequence, any copies of a disc made with a regular recorder will lack the ROM-Mark data and will be unreadable on standard players.\\r\\nThe Blu-ray Disc Association recommends but does not require that Blu-ray Disc drives be capable of reading standard DVDs and CDs, for backward compatibility.[194] Most Blu-ray Disc players are capable of reading both CDs and DVDs; however, a few of the early Blu-ray Disc players released in 2006, such as the Sony BDP-S1, could play DVDs but not CDs.[195][196][197] In addition, Blu-ray players cannot play HD DVDs, and HD DVD players cannot play Blu-ray discs. Some Blu-ray players can also play Video CDs, and all 4k Blu-ray players can play regular Blu-ray discs, and most can play DVDs and CDs, but there are no known 4k Blu-ray players that can play Video CDs as of October 13, 2017. The PlayStation 4 does not support CDs.\\r\\nHigh Fidelity Pure Audio (HFPA) is a marketing initiative, spearheaded by the Universal Music Group, for audio-only Blu-ray optical discs. Launched in 2013 as a potential successor to the Compact disc, it has been compared with DVD-A and SACD, which had similar aims.\\r\\nAVCHD was originally developed as a high definition format for consumer tapeless camcorders. Derived from the Blu-ray Disc specification, AVCHD shares a similar random access directory structure but is restricted to lower audio and video bitrates, simpler interactivity, and the use of AVC-video and Dolby AC-3 (or linear PCM) audio. Being primarily an acquisition format, AVCHD playback is not recognized by all devices that play Blu-ray Disc. Nevertheless, many such devices are capable of playing AVCHD recordings from removable media, such as DVDs, SD/SDHC memory cards, \\"Memory Stick\\" cards, and hard disk drives.[198]\\r\\nAVCREC uses a BDAV container to record high definition content on conventional DVDs.[199] Presently AVCREC is tightly integrated with the Japanese ISDB broadcast standard and is not marketed outside of Japan. AVCREC is used primarily in set-top digital video recorders and in this regard is comparable to HD REC.\\r\\nThe Blu-ray Disc Association (BDA) created a task force made up of executives from the film industry and the consumer electronics and IT sectors to help define standards for putting 3D film and 3D television content on a Blu-ray Disc.[200] On December 17, 2009, the BDA officially announced 3D specs for Blu-ray Disc, allowing backward compatibility with current 2D Blu-ray players.[201] The BDA has said, \\"The Blu-ray 3D specification calls for encoding 3D video using the \\"Stereo High\\" profile defined by Multiview Video Coding (MVC), an extension to the ITU-T H.264 Advanced Video Coding (AVC) codec currently implemented by all Blu-ray Disc players. MPEG4-MVC compresses both left and right eye views with a typical 50% overhead compared to equivalent 2D content, and can provide full 1080p resolution backward compatibility with current 2D Blu-ray Disc players.\\"[202] This means the MVC (3D) stream is backward compatible with H.264/AVC (2D) stream, allowing older 2D devices and software to decode stereoscopic video streams, ignoring additional information for the second view.\\r\\nSony added Blu-ray 3D support to its PlayStation 3 console via a firmware upgrade on 21 September 2010.[203] The console had previously gained 3D gaming capability via an update on 21 April 2010.[204] Since the version 3.70 software update in August 9, 2011, the PlayStation 3 can play DTS-HD Master Audio and DTS-HD High Resolution Audio while playing 3D Blu-ray.[205] Dolby TrueHD is used on a small minority of Blu-ray 3D releases, and bitstreaming implemented in slim PlayStation 3 models only (original \\"fat\\" PS3 models decode internally and send audio as LPCM).[206]\\r\\nUltra HD Blu-ray is a new disc format, incompatible with existing Blu-ray Disc players, that supports 60fps 4K UHD video encoded in HEVC with 10-bit HDR and a wider color gamut.","input":"When was the first blu ray movie released?"},{"output":"December 2010","context":"Spontaneous human combustion (SHC) is a term encompassing reported cases of the combustion of a living (or very recently deceased) human body without an apparent external source of ignition. In addition to reported cases, examples of the phenomenon appear in literature, and both types have been observed to share common characteristics, regarding circumstances and remains of the victim.\\r\\nForensic investigations have attempted to analyze reported instances of SHC and have resulted in hypotheses regarding potential causes and mechanisms, including victim behavior and habits, alcohol consumption and proximity to potential sources of ignition, as well as the behavior of fires that consume melted fats. Natural explanations, as well as unverified natural phenomena, have been proposed to explain reports of SHC. Current scientific consensus is that most, and perhaps all, cases of SHC involve overlooked external sources of ignition.\\r\\n\\r\\n\\r\\n\\"Spontaneous human combustion\\" refers to the death from a fire originating without an apparent external source of ignition; the fire is believed to start within the body of the victim. This idea and the term 'spontaneous human combustion' were first both proposed in 1746 by Paul Rolli in an article published in the Philosophical Transactions.[1] Writing in the British Medical Journal in 1938, coroner Gavin Thurston describes the phenomenon as having \\"attracted the attention not only of the medical profession but of the laity\\" as early as 1834 (more than one hundred years prior to Thurston's article).[2] In his 1995 book Ablaze!, Larry E. Arnold wrote that there had been about 200 cited reports of spontaneous human combustion worldwide over a period of around 300 years.[3]\\r\\nThe topic received coverage in the British Medical Journal in 1938. An article by L. A. Parry cited an 1823-published book Medical Jurisprudence,[4] which stated that commonalities among recorded cases of spontaneous human combustion included the following characteristics:\\r\\n\\"[...]the recorded cases have these things in common:\\r\\nAlcoholism is a common theme in early SHC literary references, in part because some Victorian era physicians and writers believed spontaneous human combustion was the result of alcoholism.[6]\\r\\nAn extensive two-year research project, involving thirty historical cases of alleged SHC, was conducted in 1984 by science investigator Joe Nickell and forensic analyst John F. Fischer. Their lengthy, two-part report was published in the journal of the International Association of Arson Investigators,[7]:3ÿ11 as well as part of a book.[8] Nickell has written frequently on the subject,[7][8] appeared on television documentaries, conducted additional research, and lectured at the New York State Academy of Fire Science at Montour Falls, New York, as a guest instructor.\\r\\nNickell and Fischer's investigation, which looked at cases in the 18th, 19th and 20th centuries, showed that the burned bodies were near plausible sources for the ignition: candles, lamps, fireplaces, and so on. Such sources were often omitted from published accounts of these incidents, presumably to deepen the aura of mystery surrounding an apparently \\"spontaneous\\" death. The investigations also found that there was a correlation between alleged SHC deaths and the victim's intoxication (or other forms of incapacitation) which could conceivably have caused them to be careless and unable to respond properly to an accident. Where the destruction of the body was not particularly extensive, a primary source of combustible fuel could plausibly have been the victim's clothing or a covering such as a blanket or comforter.\\r\\nHowever, where the destruction was extensive, additional fuel sources were involved, such as chair stuffing, floor coverings, the flooring itself, and the like. The investigators described how such materials helped retain melted fat to burn and destroy more of the body, yielding still more liquified fat, in a cyclic process known as the \\"wick effect\\" or the \\"candle effect\\".\\r\\nAccording to Nickell and Fischer's investigation, nearby objects often went undamaged because fire tends to burn upward, and it burns laterally with some difficulty. The fires in question are relatively small, achieving considerable destruction by the wick effect, and relatively nearby objects may not be close enough to catch fire themselves (much as one can get rather close to a modest campfire without burning). As with other mysteries, Nickell and Fischer cautioned against \\"single, simplistic explanation for all unusual burning deaths\\" but rather urged investigating \\"on an individual basis\\".[8]:169\\r\\nNeurologist Steven Novella has said that skepticism about human spontaneous combustion is now bleeding over into becoming popular skepticism about spontaneous combustion.[9]\\r\\nA 2002 study by Angi M. Christensen of the University of Tennessee cremated both healthy and osteoporotic samples of human bone and compared the resulting color changes and fragmentation. The study found that osteoporotic bone samples \\"consistently displayed more discoloration and a greater degree of fragmentation than healthy ones.\\" The same study found that when human tissue is burned, the resulting flame produces a small amount of heat, indicating that fire is unlikely to spread from burning tissue.[10]\\r\\nSome hypothesis attempt to explain how SHC might occur without an external flame source, while other hypotheses suggest incidents that might appear as spontaneous combustion actually had an external source of ignition ÿ and that the likelihood of spontaneous human combustion without an external ignition source is quite low.[11] Benjamin Radford, science writer and deputy editor of the science magazine Skeptical Inquirer, casts doubt on the plausibility of spontaneous human combustion, \\"If SHC is a real phenomenon (and not the result of an elderly or infirm person being too close to a flame source), why doesn't it happen more often? There are 5 billion [The world's population reached 5 billion in 1987] people in the world, and yet we don't see reports of people bursting into flame while walking down the street, attending football games, or sipping a coffee at a local Starbucks.\\"[12] Paranormal researcher Brian Dunning states that SHC stories \\"are simply the rare cases where a natural death in isolation has been followed by a slow combustion from some nearby source of ignition.\\" He further suggested that reports of people suddenly aflame should be called \\"Unsolved deaths by fire\\", stating that an unknown cause did not necessarily imply that the fire lacked an external ignition source.[13]\\r\\nOn July 2, 1951, Mary Reeser, a 67-year-old woman, was found burned to death in her house after her landlady realized that the house's doorknob was extremely hot. The landlady notified the police, and upon entering the home, they found Reeser's remains completely burned into ash, with only one leg remaining. The chair she was sitting in was also destroyed. During the investigation, detectives found that Reeser's temperature was around 3500 degrees Fahrenheit, which puzzled the investigators due to such hot temperatures leaving almost all the room Reeser was in intact. Reeser was a user of sleeping pills, as well as a smoker. A common theory was that she was smoking a cigarette after taking sleeping pills, and then fell asleep while still having a lit cigarette, which would have burned her gown, leading to her death. Investigators also found that the fire had burned a socket, which stopped a clock at 2:26am, suggesting that Reeser had been burned at around that time.\\r\\nHenry Thomas, a 73-year-old man, was found burned to death in the living room of his council house on the Rassau estate in Ebbw Vale, South Wales, in 1980. His entire body was incinerated, leaving only his skull and a portion of each leg below the knee. The feet and legs were still clothed in socks and trousers. Half of the chair in which he had been sitting was also destroyed. Police forensic officers decided that the incineration of Thomas was due to the wick effect. His death was ruled 'death by burning', as he had plainly inhaled the contents of his own combustion.[26]\\r\\nIn December 2010, the death of Michael Faherty in County Galway, Ireland, was recorded as \\"spontaneous combustion\\" by the coroner. The doctor, Ciaran McLoughlin, made this statement at the inquiry into the death: \\"This fire was thoroughly investigated and I'm left with the conclusion that this fits into the category of spontaneous human combustion, for which there is no adequate explanation.\\"[27]","input":"When was the last reported case of spontaneous human combustion?"},{"output":"Tubers","context":"Tubers are enlarged structures in some plant species used as storage organs for nutrients. They are used for the plant's perennation (survival of the winter or dry months), to provide energy and nutrients for regrowth during the next growing season, and as a means of asexual reproduction.[1] Stem tubers form from thickened rhizomes (underground stems) or stolons (horizontal connections between organisms). Common plant species with stem tubers include potato and yam. Some sources also treat modified lateral roots (root tubers) under the definition; these are encountered in sweet potato, cassava, and dahlia.\\r\\n\\r\\nThe term originates from Latin tuber, meaning \\"lump, bump, swelling\\".[2]\\r\\n\\r\\nSome sources define the term \\"tuber\\" to mean only structures derived from stems;[3] others use the term for structures derived from stems or roots.[4]\\r\\n\\r\\nA stem tuber forms from thickened rhizomes or stolons. The top sides of the tuber produce shoots that grow into typical stems and leaves and the under sides produce roots. They tend to form at the sides of the parent plant and are most often located near the soil surface. The underground stem tuber is normally a short-lived storage and regenerative organ developing from a shoot that branches off a mature plant. The offsprings or new tubers are attached to a parent tuber or form at the end of a hypogeogenous (initiated below ground) rhizome. In the autumn the plant dies, except for the new offspring stem tubers which have one dominant bud, which in spring regrows a new shoot producing stems and leaves, in summer the tubers decay and new tubers begin to grow. Some plants also form smaller tubers and/or tubercules which act like seeds, producing small plants that resemble (in morphology and size) seedlings. Some stem tubers are long-lived, such as those of tuberous begonia, but many plants have tubers that survive only until the plants have fully leafed out, at which point the tuber is reduced to a shriveled-up husk.\\r\\n\\r\\nStem tubers generally start off as enlargements of the hypocotyl section of a seedling but also sometimes include the first node or two of the epicotyl and the upper section of the root. The stem tuber has a vertical orientation with one or a few vegetative buds on the top and fibrous roots produced on the bottom from a basal section, typically the stem tuber has an oblong rounded shape.\\r\\n\\r\\nTuberous begonia, yams,[5][6] and Cyclamen are commonly grown stem tubers. Mignonette vine (Anredera cordifolia) produces aerial stem tubers on 12-to-25-foot-tall (3.7 to 7.6?m) vines, the tubers fall to the ground and grow.  Plectranthus esculentus of the mint family Lamiaceae, produces tuberous under ground organs from the base of the stem, weighing up to 1.8?kg per tuber, forming from axillary buds producing short stolons that grow into tubers.[7]\\r\\n\\r\\nPotatoes are stem tubers. Enlarged stolons thicken to develop into storage organs.[8][9][10][Links have expired]\\r\\n\\r\\nThe tuber has all the parts of a normal stem, including nodes and internodes. The nodes are the eyes and each has a leaf scar. The nodes or eyes are arranged around the tuber in a spiral fashion beginning on the end opposite the attachment point to the stolon. The terminal bud is produced at the farthest point away from the stolon attachment and tubers thus show the same apical dominance as a normal stem. Internally, a tuber is filled with starch stored in enlarged parenchyma like cells. The inside of a tuber has the typical cell structures of any stem, including a pith, vascular zones, and a cortex.\\r\\n\\r\\nThe tuber is produced in one growing season and used to perennate the plant and as a means of propagation. When fall comes, the above-ground structure of the plant dies, but the tubers survive over winter underground until spring, when they regenerate new shoots that use the stored food in the tuber to grow. As the main shoot develops from the tuber, the base of the shoot close to the tuber produces adventitious roots and lateral buds on the shoot. The shoot also produces stolons that are long etiolated stems. The stolon elongates during long days with the presence of high auxins levels that prevent root growth off of the stolon. Before new tuber formation begins, the stolon must be a certain age. The enzyme lipoxygenase makes a hormone, jasmonic acid, which is involved in the control of potato tuber development.\\r\\n\\r\\nThe stolons are easily recognized when potato plants are grown from seeds. As the plants grow, stolons are produced around the soil surface from the nodes. The tubers form close to the soil surface and sometimes even on top of the ground. When potatoes are cultivated, the tubers are cut into pieces and planted much deeper into the soil. Planting the pieces deeper creates more area for the plants to generate the tubers and their size increases. The pieces sprout shoots that grow to the surface. These shoots are rhizome-like and generate short stolons from the nodes while in the ground.  When the shoots reach the soil surface, they produce roots and shoots that grow into the green plant.\\r\\n\\r\\nA tuberous root or storage root, is a modified lateral root, enlarged to function as a storage organ. The  enlarged area of the root-tuber, or storage root, can be produced at the end or middle of a root or involve the entire root. It is thus different in origin but similar in function and appearance to a stem tuber. Examples of plants with notable tuberous roots include the sweet potato, cassava, and dahlia.\\r\\n\\r\\nRoot tubers are perennating organs, thickened roots that store nutrients over periods when the plant cannot actively grow, thus permitting survival from one year to the next. The massive enlargement of secondary roots typically represented by sweet potato (Ipomoea batatas), have the internal and external cell and tissue structures of a normal root, they produce adventitious roots and stems which again produce adventitious roots.[11]\\r\\n\\r\\nIn root-tubers, there are no nodes and internodes or reduced leaves. Root tubers have one end called the proximal end, which is the end that was attached to the old plant; this end has crown tissue that produces buds which grow into new stems and foliage.[12] The other end of the root tuber is called the distal end, and it normally produces unmodified roots. In stem tubers the order is reversed, with the distal end producing stems. Tuberous roots are biennial in duration: the first year the plant produces root-tubers, and at the end of the growing season, the plant shoots often die, leaving the newly generated tubers. The next growing season, the root-tubers produce new shoots. As the shoots of the new plant grow, the stored reserves of the root-tuber are consumed in the production of new roots, stems, and reproductive organs; any remaining root tissue dies concurrently to the plant's regeneration of next generation of root-tubers.\\r\\n\\r\\nHemerocallis fulva plus a number of Daylily hybrids have large root-tubers, H. fulva spreads by underground stolons[13] that end with a new fan that grows roots that produce thick root tubers and then send out more stolons.[14][15]\\r\\n\\r\\nRoot tubers, along with other storage tissues that plants produce, are consumed by animals as a rich source of nutrients. The root-tubers of Arrowhead plants of the genus Sagittaria are eaten by ducks.[16]\\r\\n\\r\\nPlants with root tubers are propagated in late summer to late winter by digging up the tubers and separating them, making sure that each piece has some crown tissue for replanting.","input":"Is a potato a tuber or a vegetable?"},{"output":"Trombay","context":"Nuclear power is the fifth-largest source of electricity in India after coal, gas, hydroelectricity and wind power. As of 2016[update], India has 22 nuclear reactors in operation in 7 nuclear power plants, having a total installed capacity of 6,780 MW.[1][2] Nuclear power produced a total of 35 TWh of electricity in 2016.[3] 6 more reactors are under construction with a combined generation capacity of 4,300 MW.\\r\\nIn October 2010, India drew up a plan to reach a nuclear power capacity of 63 GW in 2032,[4] but after the 2011 Fukushima nuclear disaster in Japan people around proposed Indian nuclear power plant sites have launched protests, raising questions about atomic energy as a clean and safe alternative to fossil fuels.[5] There have been mass protests against the French-backed 9,900 MW Jaitapur Nuclear Power Project in Maharashtra and the Russian-backed 2,000 MW Kudankulam Nuclear Power Plant in Tamil Nadu. The state government of West Bengal state has also refused permission to a proposed 6,000 MW facility near the town of Haripur that intended to host six Russian reactors.[5] A Public Interest Litigation (PIL) has also been filed against the governments civil nuclear programme at the Supreme Court.[5][6]\\r\\nThe capacity factor of Indian reactors was at 79% in the year 2011-12 compared to 71% in 2010-11. Nine out of twenty Indian reactors recorded 97% capacity factor during 2011-12. With the imported uranium from France, the 220 MW Kakrapar 2 PHWR reactors recorded 99% capacity factor during 2011-12. The Availability factor for the year 2011-12 was at 89%.\\r\\nIndia has been making advances in the field of thorium-based fuels, working to design and develop a prototype for an atomic reactor using thorium and low-enriched uranium, a key part of India's three stage nuclear power programme.[7] The country has also recently re-initiated its involvement in the LENR research activities,[8] in addition to supporting work done in the fusion power area through the ITER initiative.\\r\\n\\r\\n\\r\\nAs early as 1901, the Geological Survey of India (GSI) had recognised India as potentially having significant deposits of radioactive ores, including pitchblende, uranium and thorianite. In the ensuing 50 years, however, little to no effort was made to exploit those resources.[10] During the 1920s and 1930s, Indian scientists maintained close links to their counterparts in Europe and the United States, and were well aware of the latest developments in physics. Several Indian physicists, notably Daulat Singh Kothari, Meghnad Saha, Homi J. Bhabha and R. S. Krishnan, conducted pioneering research in nuclear physics in Europe during the 1930s.\\r\\nBy 1939, Meghnad Saha, the Palit Professor of Physics at the University of Calcutta, had recognised the significance of the discovery of nuclear fission, and had begun to conduct various experiments in his laboratory related to nuclear physics. In 1940, he incorporated nuclear physics into the university's post-graduate curriculum.[11] In the same year, the Sir Dorabji Tata Trust sanctioned funds for installing a cyclotron at the University of Calcutta, but various difficulties likely related to the war delayed the project.[12] In 1944, Homi J. Bhabha, a distinguished nuclear physicist who had established a research school at the Indian Institute of Science, Bangalore, wrote a letter to his distant cousin J. R. D. Tata, the chairman of the Tata Group. He requested funds to establish a research institute of fundamental physics, \\"with special reference to cosmic rays and nuclear physics.\\" The Tata Institute of Fundamental Research (TIFR) was inaugurated in Mumbai the following year.[13]\\r\\nFollowing the atomic bombing of Hiroshima in August 1945, R.S. Krishnan, a nuclear physicist who had studied under Norman Feather and John Cockroft, and who recognised the massive energy-generating potential of uranium, observed, \\"If the tremendous energy released from atomic explosions is made available to drive machinery, etc., it will bring about an industrial revolution of a far-reaching character.\\" He further noted, however, the difficulties in harnessing nuclear power for peaceful usage, \\"...a great deal more research work is needed before atomic power can be put to industrial use.\\"[14]\\r\\nIn March 1946, the Board of Scientific and Industrial Research (BSIR), under the Council of Scientific and Industrial Research (CSIR), set up an Atomic Research Committee under Bhabha's leadership to explore India's atomic energy resources and to suggest ways to develop and harness them, along with establishing contacts with similar organisations in other nations.[15] At the same time, the University of Travancore's research council met to discuss Travancore's future industrial development. Among other matters, the council made recommendations for developing the state's resources of monazite, a valuable thorium ore, and ilmenite, with regard to their applications in atomic energy. The council suggested the project could be undertaken by an all-India programme.[15] This was followed by the deputation of Bhabha and Sir Shanti Swarup Bhatnagar, the Director of the CSIR, to Travancore in April 1947 and the establishment of a working relationship with the kingdom's dewan, Sir C. P. Ramaswami Iyer.[16]\\r\\nEarly in 1947, plans were made to establish a Uranium Unit under the Geological Survey of India, to focus on identifying and developing resources of uranium-bearing minerals.[17] In June 1947, two months before Indian independence, Chakravarti Rajagopalachari, then Minister for Industry, Supply, Education and Finance in the Interim Government of India, established an Advisory Board for Research in Atomic Energy. Chaired by Bhabha and placed under the CSIR, the Advisory Board included Saha, Bhatnagar and several other distinguished scientists, notably Sir K. S. Krishnan, the co-discoverer of the Raman effect, geologist Darashaw Nosherwan Wadia and Nazir Ahmed, a student of Ernest Rutherford. A Joint Committee comprising the above scientists and three representatives of the Travancore government was set up to determine how best to utilise Travancore's resources of monazite.[18] Following the independence and partition of India, Travancore briefly declared itself independent before acceding to the new Dominion of India in 1949 after a period of intense negotiations, while Ahmad departed for Pakistan, where he would eventually head that nation's atomic energy agency.\\r\\nOn 23 March 1948, Prime Minister Jawaharlal Nehru introduced the Atomic Energy Bill in the Indian Parliament,[19] and it was subsequently passed as the Indian Atomic Energy Act. Modelled on the British Atomic Energy Act 1946, the Act granted sweeping powers to the central government over nuclear science and research, including surveying for atomic minerals, the development of such mineral resources on an industrial scale, conducting research regarding the scientific and technical problems connected with developing atomic energy for peaceful purposes, the training and education of the necessary personnel and the fostering of fundamental research in the nuclear sciences in Indian laboratories, institutes and universities.[13] Around the same time, the Government of West Bengal sanctioned the construction of a nuclear physics institute under the University of Calcutta; the cornerstone was laid in May 1948,[20] and the institute was inaugurated on 11 January 1950 by Irne Joliot-Curie.[11]\\r\\nWith effect from 1 June 1948, the Advisory Board for Research in Atomic Energy, together with its parent organisation the CSIR, was folded into the new Department of Scientific Research and placed directly under the Prime Minister. On 3 August 1948, the Atomic Energy Commission of India (AEC) was established and made separate from the Department of Scientific Research, with Bhabha as its first chairman.[21] In January 1949, the AEC met to formulate a uniform under- and post-graduate university syllabus for theoretical and fundamental physics and chemistry, to guarantee sufficient numbers of nuclear scientists and to ensure they would receive consistent levels of training and education.[22] In the same year, the Tata Institute of Fundamental Research was designated by the CSIR as the hub for all major nuclear science research projects. In 1950, the government announced it would purchase all available stocks of uranium and beryllium minerals and ores, and declared large rewards for any significant discoveries of the same.[23][24] On 3 January 1954, the Atomic Energy Establishment, Trombay (AEET) was established by the Atomic Energy Commission to consolidate all nuclear reactor research and technology-related developments; on 3 August, the Atomic Energy Commission and all its subordinate agencies, including the Tata Institute of Fundamental Research and the nuclear research institute at Calcutta University, were transferred to the new Department of Atomic Energy and placed under the direct charge of the Prime Minister's Office.[13]\\r\\nAt a meeting of the Atomic Energy Commission on 15 March 1955, the decision was made to construct a small nuclear reactor at Trombay. The reactor would be used for training personnel for the operation of future reactors and for research, including experiments in nuclear physics, studying the effects of irradiation and the production of isotopes for medical, agricultural and industrial research.[25] In October 1955, an agreement was signed by the United Kingdom Atomic Energy Authority and the Indian Department of Atomic Energy, under which Britain would supply uranium fuel elements for a pool-type reactor to be designed by India.[25] The agreement further ensured the \\"close cooperation and mutual assistance between the Department and the Authority in the promotion and development of the peaceful uses of atomic energy,\\" and provided for future design and collaboration in the construction of a high flux reactor at a later date.[26] Named Apsara, the reactor was housed in a 100 x 50 x 70 concrete building. India's and Asia's first nuclear reactor, Apsara reached criticality at 3:45 p.m on 4 August 1956 and was inaugurated by Prime Minister Nehru on 20 January 1957.[25][27][28]\\r\\nIn April 1955, the Canadian government under Prime Minister Louis St. Laurent offered to assist in building an NRX-type reactor for India under the Colombo Plan, of which both India and Canada were then members. Prime Minister St. Laurent expressed hopes the reactor would serve India well in the development of peaceful atomic research and development. On behalf of the Indian government, Nehru formally accepted the offer that September, stating the reactor would be made available to any accredited foreign scientists, including those from other Colombo Plan member states.[29][30][31] On 28 April 1956, Nehru and the Canadian High Commissioner to India Escott Reid signed an agreement for a \\"Canada-India Colombo Plan Atomic Reactor Project.\\" Under the terms of the agreement, Canada would provide a 40 MW CIRUS reactor for solely research purposes, including the initial manufacture and engineering of the reactor, and would also provide technical expertise, including training Indian personnel in its operation. India would supply the reactor site and foundation, and would also pay all \\"internal\\" costs, including the construction of the reactor complex, the costs of local labour and any shipping and insurance fees.[32] Under Article II of the agreement, India would make the reactor facilities available to other Colombo Plan nations. Article III stipulated that the \\"reactor and any products resulting from its use will be employed for peaceful purposes only;\\"[32] at the time, however, there were no effective safeguards to ensure this clause.[30][31] A further agreement was made with the United States government to supply 21 tons of heavy water for the reactor.[33] Construction of the reactor began later in 1956, with Indian technical personnel sent to Chalk River for training.[34] CIRUS was completed in early 1960 and after achieving criticality in July 1960, was inaugurated by Nehru in January 1961.[35] Construction of a third research reactor, ZERLINA (Zero Energy Reactor for Lattice Investigations and New Assemblies) began at Trombay in 1958; ZERLINA was also commissioned in 1961.[36]\\r\\nBy February 1960, deliberations had begun to build India's first nuclear power stations; it was decided the first power plant would be erected in Western India, with locations in Rajasthan, near Delhi and near Madras noted for future electricity-generating reactors.[37] On 11 October 1960, the Indian government issued a global tender for India's first nuclear power station near Tarapur, Maharashtra and consisting of two reactors, each generating around 150 MW of electricity and to be commissioned in 1965.[38] In August 1961, the Indian and Canadian governments agreed to conduct a joint study on building a Canada-India nuclear power plant in Rajasthan; the reactor would be based on the CANDU reactor at Douglas Point and would generate 200 MW of energy.[35] The agreement for India's first nuclear power plant at Rajasthan, RAPP-1, was signed in 1963, followed by RAPP-2 in 1966. These reactors contained rigid safeguards to ensure they would not be used for a military programme. RAPP-1 began operation in 1972. Due to technical problems the reactor had to be downrated from 200 MW to 100 MW.[citation needed] The technical and design information were given free of charge by Atomic Energy of Canada Limited to India.[citation needed] The United States and Canada terminated their assistance after the detonation of India's first nuclear explosion in 1974.\\r\\nAfter successful commissioning of Kudankulam units 1 & 2, an agreement was made with Russia in June 2017 for the units 5 & 6 (2 x 1000 MW) with an estimated cost of INR 250 million (3.85 million US$) per MW.[39][40] Earlier, India had also entered in to an agreement with Russia in October 2016 for the units 3 & 4 (2 x 1000 MW) with an estimated cost of INR 200 million (3.08 million US$) per MW.[39]\\r\\nIndia's domestic uranium reserves are small and the country is dependent on uranium imports to fuel its nuclear power industry. Since early 1990s, Russia has been a major supplier of nuclear fuel to India.[41] Due to dwindling domestic uranium reserves,[42] electricity generation from nuclear power in India declined by 12.83% from 2006 to 2008.[43] Following a waiver from the Nuclear Suppliers Group (NSG) in September 2008 which allowed it to commence international nuclear trade,[44] India has signed bilateral deals on civilian nuclear energy technology cooperation with several other countries, including France,[45] the United States,[46] the United Kingdom,[47] Canada,[48] and South Korea.[49] India has also uranium supply agreements with Russia,[50][51] Mongolia,[52] Kazakhstan,[53] Argentina[54] and Namibia.[55] An Indian private company won a uranium exploration contract in Niger.[56]\\r\\nIn March 2011 large deposits of uranium have been discovered in the Tummalapalle belt and in the Bhima basin at Gogi in Karnataka by the Atomic Minerals Directorate for Exploration and Research (AMD) of India. The Tummalapalle belt uranium reserves promises to be one of the world's top 20 uranium reserves discoveries. 44,000 tonnes of natural uranium have been discovered in the belt so far, which is estimated to have three times that amount.[57][58][59] The natural uranium deposits of the Bhima basin has better grade of natural uranium ore, even though it is smaller than the Tummalapalle belt.\\r\\nIn recent years, India has shown increased interest in thorium fuels and fuel cycles because of large deposits of thorium (518,000 tonnes) in the form of monazite in beach sands as compared to very modest reserves of low-grade uranium (92,000 tonnes).[60]\\r\\nAs of 2016, India has signed civil nuclear agreements with 14 countries: Argentina, Australia, Canada, Czech Republic, France, Japan, Kazakhstan, Mongolia, Namibia, Russia, South Korea, the United Kingdom, the United States, and Vietnam.[61] The 48-nation NSG granted a waiver to India on 6 September 2008 allowing it to access civilian nuclear technology and fuel from other countries.[62] India the only known country with nuclear weapons which is not a party to the Non-Proliferation Treaty (NPT) but is still allowed to carry out nuclear commerce with the rest of the world.[63]\\r\\nThe nuclear agreement with USA led to India issuing a Letter of Intent for purchasing 10,000?MW from the USA. However, liability concerns and a few other issues are preventing further progress on the issue. Experts say that India's nuclear liability law discourages foreign nuclear companies. This law gives accident victims the right to seek damages from plant suppliers in the event of a mishap. It has \\"deterred foreign players like General Electric and Westinghouse Electric, a US-based unit of Toshiba, with companies asking for further clarification on compensation liability for private operators\\".[64]\\r\\nRussia has an ongoing agreement of 1988 vintage with India regarding establishing of two VVER 1000?MW reactors (water-cooled water-moderated light water power reactors) at Koodankulam in Tamil Nadu.[65] A 2008 agreement caters for provision of an additional four third generation VVER-1200 reactors of capacity 1170?MW each.[66] Russia has assisted in Indias efforts to design a nuclear plant for its nuclear submarine.[67] In 2009, the Russians stated that Russia would not agree to curbs on export of sensitive technology to India. A new accord signed in Dec 2009 with Russia gives India freedom to proceed with the closed fuel cycle, which includes mining, preparation of the fuel for use in reactors, and reprocessing of spent fuel.[68][69]\\r\\nAfter the Nuclear Suppliers Group agreed to allow nuclear exports to India, France was the first country to sign a civilian nuclear agreement with India, on 30 September 2008.[70] During the December 2010 visit of the French President Nicolas Sarkozy to India, framework agreements were signed for the setting up two third-generation EPR reactors of 1650?MW each at Jaitapur, Maharashtra by the French company Areva. The deal caters for the first set of two of six planned reactors and the supply of nuclear fuel for 25 years.[71] The contract and pricing is yet to be finalised. Construction is unlikely to start before 2014 because of regulatory issues and difficulty in sourcing major components from Japan due to India not being a signatory to the Nuclear Non-Proliferation Treaty.[72]\\r\\nIndia and Mongolia signed a crucial civil nuclear agreement on 15 June 2009 for supply of Uranium to India, during Prime Minister Manmohan Singh's visit to Mongolia making it the fifth nation in the world to seal a civil nuclear pact with India. The MoU on development of cooperation in the field of peaceful uses of radioactive minerals and nuclear energy was signed by senior officials in the department of atomic energy of the two countries.[73]\\r\\nOn 2 September 2009, India and Namibia signed five agreements, including one on civil nuclear energy which allows for supply of uranium from the African country. This was signed during President Hifikepunye Pohamba's five-day visit to India in May 2009. Namibia is the fifth largest producer of uranium in the world. The Indo-Namibian agreement in peaceful uses of nuclear energy allows for supply of uranium and setting up of nuclear reactors.[74]\\r\\nOn 14 October 2009, India and Argentina signed an agreement in New Delhi on civil nuclear cooperation and nine other pacts to establish strategic partnership. According to official sources, the agreement was signed by Vivek Katju, Secretary in the Ministry of External Affairs and Argentine foreign minister Jorge Talana. Taking into consideration their respective capabilities and experience in the peaceful uses of nuclear energy, both India and Argentina have agreed to encourage and support scientific, technical and commercial cooperation for mutual benefit in this field.[75][76]\\r\\nThe Prime Ministers of India and Canada signed a civil nuclear cooperation agreement in Toronto on 28 June 2010 which when all steps are taken, will provide access for Canada's nuclear industry to India's expanding nuclear market and also fuel for India's reactors. Canada is one of the world's largest exporters of uranium[77] and Canada's heavy water nuclear technology is marketed abroad with CANDU-type units operating in India, Pakistan, Argentina, South Korea, Romania and China. On 6 November 2012, India and Canada finalised their 2010 nuclear export agreement, opening the way for Canada to begin uranium exports to India.[78]\\r\\nOn 16 April 2011, India and Kazakhstan signed an inter-governmental agreement for Cooperation in Peaceful Uses of Atomic Energy, that envisages a legal framework for supply of fuel, construction and operation of atomic power plants, exploration and joint mining of uranium, exchange of scientific and research information, reactor safety mechanisms and use of radiation technologies for healthcare. PM Manmohan Singh visited Astana where a deal was signed. After the talks, the Kazakh President Nazarbaev announced that his country would supply India with 2100 tonnes of uranium and was ready to do more. India and Kazakhstan already have civil nuclear cooperation since January 2009 when Nuclear Power Corporation of India Limited (NPCIL) and Kazakh nuclear company KazAtomProm signed an MoU during the visit of Nazarbaev to Delhi. Under the contract, KazAtomProm supplies uranium which is used by Indian reactors.[79][80]\\r\\nSouth Korea became the latest country to sign a nuclear agreement with India after it got the waiver from the Nuclear Suppliers' Group (NSG) in 2008. On 25 July 2011 India and South Korea signed a nuclear agreement, which will allow South Korea with a legal foundation to participate in Indias nuclear expansion programme, and to bid for constructing nuclear power plants in India.[81]\\r\\nIn 2014, India and Australia signed a civil nuclear agreement which allows the export of uranium to India. This was signed in New Delhi during Australian Prime Minister Tony Abbott's meeting with the Indian Prime Minister Narendra Modi on 4 September 2014. Australia is the third largest producer of uranium in the world. The agreement allows supply of uranium for peaceful generation of power for civil use in India.[82][83]\\r\\nIndia's Prime Minister Narendra Modi and UK Prime Minister David Cameron signed Civil Nuclear Agreement on 12 Nov, 2015.[84]\\r\\nIn November 2016 Japan signed a nuclear cooperation agreement with India. Japanese nuclear plant builders saw this as potential lifeline given that domestic orders had ended following the Fukushima Daiichi nuclear disaster, and India is proposing to build about 20 new reactors over the next decade.[85]\\r\\nAs of 2009, India envisages to increase the contribution of nuclear power to overall electricity generation capacity from 2.8% to 9% within 25?years.[86] By 2020, India's installed nuclear power generation capacity is expected to increase to 20?GW.[87] As of 2009[update], India stands 9th in the world in terms of number of operational nuclear power reactors. Indigenous atomic reactors include TAPS-3, and -4, both of which are 540?MW reactors.[88]\\r\\nThe Indian nuclear power industry is expected to undergo a significant expansion in the coming years, in part due to the passing of the U.S.-India Civil Nuclear Agreement. This agreement will allow India to carry out trade of nuclear fuel and technologies with other countries and significantly enhance its power generation capacity.[89] When the agreement goes through, India is expected to generate an additional 25?GW of nuclear power by 2020, bringing total estimated nuclear power generation to 45?GW.[90]\\r\\nRisks related to nuclear power generation prompted Indian legislators to enact the 2010 Nuclear Liability Act which stipulates that nuclear suppliers, contractors and operators must bear financial responsibility in case of an accident. The legislation addresses key issues such as nuclear radiation and safety regulations, operational control and maintenance management of nuclear power plants, compensation in the event of a radiation-leak accident, disaster clean-up costs, operator responsibility and supplier liability.[91] A nuclear accident like the 2011 Fukushima Daiichi nuclear disaster would have dire economic consequences in heavily populated India as did the 1984 Union Carbide Bhopal disaster, considered among the world's worst industrial disasters.[92]\\r\\nIndia has already been using imported enriched uranium for light-water reactors that are currently under IAEA safeguards, but it has developed other aspects of the nuclear fuel cycle to support its reactors. Development of select technologies has been strongly affected by limited imports. Use of heavy water reactors has been particularly attractive for the nation because it allows Uranium to be burnt with little to no enrichment capabilities. India has also done a great amount of work in the development of a thorium centred fuel cycle. While uranium deposits in the nation are limited there are much greater reserves of thorium and it could provide hundreds of times the energy with the same mass of fuel. The fact that thorium can theoretically be utilised in heavy water reactors has tied the development of the two. A prototype reactor that would burn Uranium-Plutonium fuel while irradiating a thorium blanket is under construction at Kalpakkam by BHAVINI.\\r\\nUranium used for the weapons programme has been separated from the power programme, using uranium from indigenous reserves. This domestic reserve of 80,000 to 112,000?tons of uranium (approx 1% of global uranium reserves) is large enough to supply all of India's commercial and military reactors as well as supply all the needs of India's nuclear weapons arsenal. Currently, India's nuclear power reactors consume, at most, 478?tonnes of uranium per year.[93] Even if India were quadruple its nuclear power output (and reactor base) to 20?GW by 2020, nuclear power generation would only consume 2000?tonnes of uranium per annum. Based on India's known commercially viable reserves of 80,000 to 112,000?tons of uranium, this represents a 40ÿ50?years uranium supply for India's nuclear power reactors (note with reprocessing and breeder reactor technology, this supply could be stretched out many times over). Furthermore, the uranium requirements of India's Nuclear Arsenal are only a fifteenth (1/15) of that required for power generation (approx. 32?tonnes), meaning that India's domestic fissile material supply is more than enough to meet all needs for it strategic nuclear arsenal. Therefore, India has sufficient uranium resources to meet its strategic and power requirements for the foreseeable future.[93]\\r\\nFormer Indian President A. P. J. Abdul Kalam stated while he was in office that \\"energy independence is India's first and highest priority. India has to go for nuclear power generation in a big way using thorium-based reactors. Thorium, a non fissile material is available in abundance in our country.\\"[94] India has vast thorium reserves and quite limited uranium reserves.[95][96]\\r\\nThe long-term goal of India's nuclear program has been to develop an advanced heavy-water thorium cycle. The first stage of this employs the pressurized heavy water reactors (PHWR) fueled by natural uranium, and light water reactors, which produce plutonium incidentally to their prime purpose of electricity generation. The second stage uses fast neutron reactors burning the plutonium with the blanket around the core having uranium as well as thorium, so that further plutonium (ideally high-fissile Pu) is produced as well as U-233. The Atomic and Molecular Data Unit (AMD) has identified almost 12 million tonnes of monazite resources (typically with 6-7% thorium). In stage 3, Advanced Heavy Water Reactors (AHWR) would burn thorium-plutonium fuels in such a manner that breeds U-233 which can eventually be used as a self-sustaining fissile driver for a fleet of breeding AHWRs. An alternative stage 3 is molten salt breeder reactors (MSBR), which are believed to be another possible option for eventual large-scale deployment.[61]\\r\\nIn June 2014, Kudankulam-1 became the single largest power generating unit in India (1000?MWe).[97][98]\\r\\nCurrently, twenty-two nuclear power reactors have a total install capacity of 6,780?MW (3.5% of total installed base).[99][100]\\r\\nNote: Some sites may be abandoned if not found technically feasible or due to strategic, geopolitical, international and domestic issues.\\r\\nThe details of the nuclear power generation capacity in the country are given below?:[115]\\r\\nFollowing the March 2011 Fukushima nuclear disaster in Japan, populations around proposed Indian NPP sites have launched protests that had found resonance around the country.[5] There have been mass protests against the French-backed 9,900 MW Jaitapur Nuclear Power Project in Maharashtra and the Russian-backed 2,000 MW Koodankulam Nuclear Power Plant in Tamil Nadu. The Government of West Bengal initially refused permission to a proposed 6,000 MW facility near the town of Haripur that intended to host 6 Russian reactors.[5][117] But now it's possible for Bengal to have its first nuclear power plant at Haripur despite resistance.[118]\\r\\nA Public-interest litigation (PIL) has also been filed against the governments civil nuclear program at the Supreme Court. The PIL specifically asks for the \\"staying of all proposed nuclear power plants till satisfactory safety measures and cost-benefit analyses are completed by independent agencies\\".[6][119] But the Supreme Court said it was not an expert in the nuclear field to issue a direction to the government on the nuclear liability issue.[120]","input":"Where was the first nuclear reactor established in india?"},{"output":"magmatic eruptions, which involve the decompression of gas within magma that propels it forward","context":"Several types of volcanic eruptionsduring which lava, tephra (ash, lapilli, volcanic bombs and volcanic blocks), and assorted gases are expelled from a volcanic vent or fissurehave been distinguished by volcanologists. These are often named after famous volcanoes where that type of behavior has been observed. Some volcanoes may exhibit only one characteristic type of eruption during a period of activity, while others may display an entire sequence of types all in one eruptive series.\\r\\nThere are three different types of eruptions. The most well-observed are magmatic eruptions, which involve the decompression of gas within magma that propels it forward. Phreatomagmatic eruptions are another type of volcanic eruption, driven by the compression of gas within magma, the direct opposite of the process powering magmatic activity. The third eruptive type is the phreatic eruption, which is driven by the superheating of steam via contact with magma; these eruptive types often exhibit no magmatic release, instead causing the granulation of existing rock.\\r\\nWithin these wide-defining eruptive types are several subtypes. The weakest are Hawaiian and submarine, then Strombolian, followed by Vulcanian and Surtseyan. The stronger eruptive types are Pelean eruptions, followed by Plinian eruptions; the strongest eruptions are called \\"Ultra-Plinian.\\" Subglacial and phreatic eruptions are defined by their eruptive mechanism, and vary in strength. An important measure of eruptive strength is Volcanic Explosivity Index (VEI), an order of magnitude scale ranging from 0 to 8 that often correlates to eruptive types.\\r\\n\\r\\n\\r\\nVolcanic eruptions arise through three main mechanisms:[1]\\r\\nThere are two types of eruptions in terms of activity, explosive eruptions and effusive eruptions. Explosive eruptions are characterized by gas-driven explosions that propels magma and tephra.[1] Effusive eruptions, meanwhile, are characterized by the outpouring of lava without significant explosive eruption.[2]\\r\\nVolcanic eruptions vary widely in strength. On the one extreme there are effusive Hawaiian eruptions, which are characterized by lava fountains and fluid lava flows, which are typically not very dangerous. On the other extreme, Plinian eruptions are large, violent, and highly dangerous explosive events. Volcanoes are not bound to one eruptive style, and frequently display many different types, both passive and explosive, even in the span of a single eruptive cycle.[3] Volcanoes do not always erupt vertically from a single crater near their peak, either. Some volcanoes exhibit lateral and fissure eruptions. Notably, many Hawaiian eruptions start from rift zones,[4] and some of the strongest Surtseyan eruptions develop along fracture zones.[5] Scientists believed that pulses of magma mixed together in the chamber before climbing upwarda process estimated to take several thousands of years. But Columbia University volcanologists found that the eruption of Costa Ricas Iraz~ Volcano in 1963 was likely triggered by magma that took a nonstop route from the mantle over just a few months.[6]\\r\\nThe volcanic explosivity index (commonly shortened to VEI) is a scale, from 0 to 8, for measuring the strength of eruptions. It is used by the Smithsonian Institution's Global Volcanism Program in assessing the impact of historic and prehistoric lava flows. It operates in a way similar to the Richter scale for earthquakes, in that each interval in value represents a tenfold increasing in magnitude (it is logarithmic).[7] The vast majority of volcanic eruptions are of VEIs between 0 and 2.[3]\\r\\nVolcanic eruptions by VEI index[7]\\r\\nMagmatic eruptions produce juvenile clasts during explosive decompression from gas release. They range in intensity from the relatively small lava fountains on Hawaii to catastrophic Ultra-Plinian eruption columns more than 30?km (19?mi) high, bigger than the eruption of Mount Vesuvius in 79 that buried Pompeii.[1]\\r\\nHawaiian eruptions are a type of volcanic eruption, named after the Hawaiian volcanoes with which this eruptive type is hallmark. Hawaiian eruptions are the calmest types of volcanic events, characterized by the effusive eruption of very fluid basalt-type lavas with low gaseous content. The volume of ejected material from Hawaiian eruptions is less than half of that found in other eruptive types. Steady production of small amounts of lava builds up the large, broad form of a shield volcano. Eruptions are not centralized at the main summit as with other volcanic types, and often occur at vents around the summit and from fissure vents radiating out of the center.[4]\\r\\nHawaiian eruptions often begin as a line of vent eruptions along a fissure vent, a so-called \\"curtain of fire.\\" These die down as the lava begins to concentrate at a few of the vents. Central-vent eruptions, meanwhile, often take the form of large lava fountains (both continuous and sporadic), which can reach heights of hundreds of meters or more. The particles from lava fountains usually cool in the air before hitting the ground, resulting in the accumulation of cindery scoria fragments; however, when the air is especially thick with clasts, they cannot cool off fast enough due to the surrounding heat, and hit the ground still hot, the accumulation of which forms spatter cones. If eruptive rates are high enough, they may even form splatter-fed lava flows. Hawaiian eruptions are often extremely long lived; Pu?u ??, a cinder cone of Kilauea, has been erupting continuously since 1983. Another Hawaiian volcanic feature is the formation of active lava lakes, self-maintaining pools of raw lava with a thin crust of semi-cooled rock; there are currently only 6 such lakes in the world, and the one at Kؐlauea's Kupaianaha vent is one of them.[4]\\r\\nFlows from Hawaiian eruptions are basaltic, and can be divided into two types by their structural characteristics. Pahoehoe lava is a relatively smooth lava flow that can be billowy or ropey. They can move as one sheet, by the advancement of \\"toes,\\" or as a snaking lava column. A'a lava flows are denser and more viscous than pahoehoe, and tend to move slower. Flows can measure 2 to 20?m (7 to 66?ft) thick. A'a flows are so thick that the outside layers cools into a rubble-like mass, insulating the still-hot interior and preventing it from cooling. A'a lava moves in a peculiar waythe front of the flow steepens due to pressure from behind until it breaks off, after which the general mass behind it moves forward. Pahoehoe lava can sometimes become A'a lava due to increasing viscosity or increasing rate of shear, but A'a lava never turns into pahoehoe flow.[10]\\r\\nHawaiian eruptions are responsible for several unique volcanological objects. Small volcanic particles are carried and formed by the wind, chilling quickly into teardrop-shaped glassy fragments known as Pele's tears (after Pele, the Hawaiian volcano deity). During especially high winds these chunks may even take the form of long drawn-out strands, known as Pele's hair. Sometimes basalt aerates into reticulite, the lowest density rock type on earth.[4]\\r\\nAlthough Hawaiian eruptions are named after the volcanoes of Hawaii, they are not necessarily restricted to them; the largest lava fountain ever recorded formed on the island of Izu shima (on Mount Mihara) in 1986, a 1,600?m (5,249?ft) gusher that was more than twice as high as the mountain itself (which stands at 764?m (2,507?ft)).[4][11]\\r\\nVolcanoes known to have Hawaiian activity include:\\r\\nStrombolian eruptions are a type of volcanic eruption, named after the volcano Stromboli, which has been erupting continuously for centuries.[12] Strombolian eruptions are driven by the bursting of gas bubbles within the magma. These gas bubbles within the magma accumulate and coalesce into large bubbles, called gas slugs. These grow large enough to rise through the lava column.[13] Upon reaching the surface, the difference in air pressure causes the bubble to burst with a loud pop,[12] throwing magma in the air in a way similar to a soap bubble. Because of the high gas pressures associated with the lavas, continued activity is generally in the form of episodic explosive eruptions accompanied by the distinctive loud blasts.[12] During eruptions, these blasts occur as often as every few minutes.[14]\\r\\nThe term \\"Strombolian\\" has been used indiscriminately to describe a wide variety of volcanic eruptions, varying from small volcanic blasts to large eruptive columns. In reality, true Strombolian eruptions are characterized by short-lived and explosive eruptions of lavas with intermediate viscosity, often ejected high into the air. Columns can measure hundreds of meters in height. The lavas formed by Strombolian eruptions are a form of relatively viscous basaltic lava, and its end product is mostly scoria.[12] The relative passivity of Strombolian eruptions, and its non-damaging nature to its source vent allow Strombolian eruptions to continue unabated for thousands of years, and also makes it one of the least dangerous eruptive types.[14]\\r\\nStrombolian eruptions eject volcanic bombs and lapilli fragments that travel in parabolic paths before landing around their source vent. The steady accumulation of small fragments builds cinder cones composed completely of basaltic pyroclasts. This form of accumulation tends to result in well-ordered rings of tephra.[12]\\r\\nStrombolian eruptions are similar to Hawaiian eruptions, but there are differences. Strombolian eruptions are noisier, produce no sustained eruptive columns, do not produce some volcanic products associated with Hawaiian volcanism (specifically Pele's tears and Pele's hair), and produce fewer molten lava flows (although the eruptive material does tend to form small rivulets).[12][14]\\r\\nVolcanoes known to have Strombolian activity include:\\r\\nVulcanian eruptions are a type of volcanic eruption, named after the volcano Vulcano.[20] It was named so following Giuseppe Mercalli's observations of its 1888ÿ1890 eruptions.[21] In Vulcanian eruptions, intermediate viscous magma within the volcano make it difficult for vesiculate gases to escape. Similar to Strombolian eruptions, this leads to the buildup of high gas pressure, eventually popping the cap holding the magma down and resulting in an explosive eruption. However, unlike Strombolian eruptions, ejected lava fragments are not aerodynamic; this is due to the higher viscosity of Vulcanian magma and the greater incorporation of crystalline material broken off from the former cap. They are also more explosive than their Strombolian counterparts, with eruptive columns often reaching between 5 and 10?km (3 and 6?mi) high. Lastly, Vulcanian deposits are andesitic to dacitic rather than basaltic.[20]\\r\\nInitial Vulcanian activity is characterized by a series of short-lived explosions, lasting a few minutes to a few hours and typified by the ejection of volcanic bombs and blocks. These eruptions wear down the lava dome holding the magma down, and it disintegrates, leading to much more quiet and continuous eruptions. Thus an early sign of future Vulcanian activity is lava dome growth, and its collapse generates an outpouring of pyroclastic material down the volcano's slope.[20]\\r\\nDeposits near the source vent consist of large volcanic blocks and bombs, with so-called \\"bread-crust bombs\\" being especially common. These deeply cracked volcanic chunks form when the exterior of ejected lava cools quickly into a glassy or fine-grained shell, but the inside continues to cool and vesiculate. The center of the fragment expands, cracking the exterior. However the bulk of Vulcanian deposits are fine grained ash. The ash is only moderately dispersed, and its abundance indicates a high degree of fragmentation, the result of high gas contents within the magma. In some cases these have been found to be the result of interaction with meteoric water, suggesting that Vulcanian eruptions are partially hydrovolcanic.[20]\\r\\nVolcanoes that have exhibited Vulcanian activity include:\\r\\nPelan eruptions (or nue ardente) are a type of volcanic eruption, named after the volcano Mount Pele in Martinique, the site of a massive Pelan eruption in 1902 that is one of the worst natural disasters in history. In Pelan eruptions, a large amount of gas, dust, ash, and lava fragments are blown out the volcano's central crater,[24] driven by the collapse of rhyolite, dacite, and andesite lava dome collapses that often create large eruptive columns. An early sign of a coming eruption is the growth of a so-called Pelan or lava spine, a bulge in the volcano's summit preempting its total collapse.[25] The material collapses upon itself, forming a fast-moving pyroclastic flow[24] (known as a block-and-ash flow)[26] that moves down the side of the mountain at tremendous speeds, often over 150?km (93?mi) per hour. These massive landslides make Pelan eruptions one of the most dangerous in the world, capable of tearing through populated areas and causing massive loss of life. The 1902 eruption of Mount Pele caused tremendous destruction, killing more than 30,000 people and completely destroying the town of St. Pierre, the worst volcanic event in the 20th century.[24]\\r\\nPelan eruptions are characterized most prominently by the incandescent pyroclastic flows that they drive. The mechanics of a Pelan eruption are very similar to that of a Vulcanian eruption, except that in Pelan eruptions the volcano's structure is able to withstand more pressure, hence the eruption occurs as one large explosion rather than several smaller ones.[27]\\r\\nVolcanoes known to have Pelan activity include:\\r\\nPyroclastic flows at Mayon Volcano, Philippines, 1984.\\r\\nThe lava spine that developed after the 1902 eruption of Mount Pele\\r\\nMount Lamington following the devastating 1951 eruption.\\r\\nPlinian eruptions (or Vesuvian) are a type of volcanic eruption, named for the historical eruption of Mount Vesuvius in 79 AD that buried the Roman towns of Pompeii and Herculaneum and, specifically, for its chronicler Pliny the Younger.[31] The process powering Plinian eruptions starts in the magma chamber, where dissolved volatile gases are stored in the magma. The gases vesiculate and accumulate as they rise through the magma conduit. These bubbles agglutinate and once they reach a certain size (about 75% of the total volume of the magma conduit) they explode. The narrow confines of the conduit force the gases and associated magma up, forming an eruptive column. Eruption velocity is controlled by the gas contents of the column, and low-strength surface rocks commonly crack under the pressure of the eruption, forming a flared outgoing structure that pushes the gases even faster.[32]\\r\\nThese massive eruptive columns are the distinctive feature of a Plinian eruption, and reach up 2 to 45?km (1 to 28?mi) into the atmosphere. The densest part of the plume, directly above the volcano, is driven internally by gas expansion. As it reaches higher into the air the plume expands and becomes less dense, convection and thermal expansion of volcanic ash drive it even further up into the stratosphere. At the top of the plume, powerful prevailing winds drive the plume in a direction away from the volcano.[32]\\r\\nThese highly explosive eruptions are associated with volatile-rich dacitic to rhyolitic lavas, and occur most typically at stratovolcanoes. Eruptions can last anywhere from hours to days, with longer eruptions being associated with more felsic volcanoes. Although they are associated with felsic magma, Plinian eruptions can just as well occur at basaltic volcanoes, given that the magma chamber differentiates and has a structure rich in silicon dioxide.[31]\\r\\nPlinian eruptions are similar to both Vulcanian and Strombolian eruptions, except that rather than creating discrete explosive events, Plinian eruptions form sustained eruptive columns. They are also similar to Hawaiian lava fountains in that both eruptive types produce sustained eruption columns maintained by the growth of bubbles that move up at about the same speed as the magma surrounding them.[31]\\r\\nRegions affected by Plinian eruptions are subjected to heavy pumice airfall affecting an area 0.5 to 50?km3 (0 to 12?cu?mi) in size.[31] The material in the ash plume eventually finds its way back to the ground, covering the landscape in a thick layer of many cubic kilometers of ash.[33]\\r\\nHowever the most dangerous eruptive feature are the pyroclastic flows generated by material collapse, which move down the side of the mountain at extreme speeds[31] of up to 700?km (435?mi) per hour and with the ability to extend the reach of the eruption hundreds of kilometers.[33] The ejection of hot material from the volcano's summit melts snowbanks and ice deposits on the volcano, which mixes with tephra to form lahars, fast moving mudslides with the consistency of wet concrete that move at the speed of a river rapid.[31]\\r\\nMajor Plinian eruptive events include:\\r\\nPhreatomagmatic eruptions are eruptions that arise from interactions between water and magma. They are driven from thermal contraction (as opposed to magmatic eruptions, which are driven by thermal expansion) of magma when it comes in contact with water. This temperature difference between the two causes violent water-lava interactions that make up the eruption. The products of phreatomagmatic eruptions are believed to be more regular in shape and finer grained than the products of magmatic eruptions because of the differences in eruptive mechanisms.[1][36]\\r\\nThere is debate about the exact nature of phreatomagmatic eruptions, and some scientists believe that fuel-coolant reactions may be more critical to the explosive nature than thermal contraction.[36] Fuel coolant reactions may fragment the volcanic material by propagating stress waves, widening cracks and increasing surface area that ultimately leads to rapid cooling and explosive contraction-driven eruptions.[1]\\r\\nA Surtseyan eruption (or hydrovolcanic) is a type of volcanic eruption caused by shallow-water interactions between water and lava, named so after its most famous example, the eruption and formation of the island of Surtsey off the coast of Iceland in 1963. Surtseyan eruptions are the \\"wet\\" equivalent of ground-based Strombolian eruptions, but because of where they are taking place they are much more explosive. This is because as water is heated by lava, it flashes in steam and expands violently, fragmenting the magma it is in contact with into fine-grained ash. Surtseyan eruptions are the hallmark of shallow-water volcanic oceanic islands, however they are not specifically confined to them. Surtseyan eruptions can happen on land as well, and are caused by rising magma that comes into contact with an aquifer (water-bearing rock formation) at shallow levels under the volcano.[5] The products of Surtseyan eruptions are generally oxidized palagonite basalts (though andesitic eruptions do occur, albeit rarely), and like Strombolian eruptions Surtseyan eruptions are generally continuous or otherwise rhythmic.[37]\\r\\nA distinct defining feature of a Surtseyan eruption is the formation of a pyroclastic surge (or base surge), a ground hugging radial cloud that develops along with the eruption column. Base surges are caused by the gravitational collapse of a vaporous eruptive column, one that is denser overall then a regular volcanic column. The densest part of the cloud is nearest to the vent, resulting a wedge shape. Associated with these laterally moving rings are dune-shaped depositions of rock left behind by the lateral movement. These are occasionally disrupted by bomb sags, rock that was flung out by the explosive eruption and followed a ballistic path to the ground. Accumulations of wet, spherical ash known as accretionary lapilli is another common surge indicator.[5]\\r\\nOver time Surtseyan eruptions tend to form maars, broad low-relief volcanic craters dug into the ground, and tuff rings, circular structures built of rapidly quenched lava. These structures are associated with a single vent eruption, however if eruptions arise along fracture zones a rift zone may be dug out; these eruptions tend to be more violent then the ones forming a tuff ring or maars, an example being the 1886 eruption of Mount Tarawera.[5][37] Littoral cones are another hydrovolcanic feature, generated by the explosive deposition of basaltic tephra (although they are not truly volcanic vents). They form when lava accumulates within cracks in lava, superheats and explodes in a steam explosion, breaking the rock apart and depositing it on the volcano's flank. Consecutive explosions of this type eventually generate the cone.[5]\\r\\nVolcanoes known to have Surtseyan activity include:\\r\\nSurtsey, erupting 13 days after breaching the water. A tuff ring surrounds the vent.\\r\\nThe fissure formed by the 1886 eruption of Mount Tarawera, an example of a fracture zone eruption.\\r\\nSubmarine eruptions are a type of volcanic eruption that occurs underwater. An estimated 75% of the total volcanic eruptive volume is generated by submarine eruptions near mid ocean ridges alone, however because of the problems associated with detecting deep sea volcanics, they remained virtually unknown until advances in the 1990s made it possible to observe them.[40]\\r\\nSubmarine eruptions may produce seamounts which may break the surface to form volcanic islands and island chains.\\r\\nSubmarine volcanism is driven by various processes. Volcanoes near plate boundaries and mid-ocean ridges are built by the decompression melting of mantle rock that rises on an upwelling portion of a convection cell to the crustal surface. Eruptions associated with subducting zones, meanwhile, are driven by subducting plates that add volatiles to the rising plate, lowering its melting point. Each process generates different rock; mid-ocean ridge volcanics are primarily basaltic, whereas subduction flows are mostly calc-alkaline, and more explosive and viscous.[41]\\r\\nSpreading rates along mid-ocean ridges vary widely, from 2?cm (0.8?in) per year at the Mid-Atlantic Ridge, to up to 16?cm (6?in) along the East Pacific Rise. Higher spreading rates are a probably cause for higher levels of volcanism. The technology for studying seamount eruptions did not exist until advancements in hydrophone technology made it possible to \\"listen\\" to acoustic waves, known as T-waves, released by submarine earthquakes associated with submarine volcanic eruptions. The reason for this is that land-based seismometers cannot detect sea-based earthquakes below a magnitude of 4, but acoustic waves travel well in water and long periods of time. A system in the North Pacific, maintained by the United States Navy and originally intended for the detection of submarines, has detected an event on average every 2 to 3 years.[40]\\r\\nThe most common underwater flow is pillow lava, a circular lava flow named after its unusual shape. Less common are glassy, marginal sheet flows, indicative of larger-scale flows. Volcaniclastic sedimentary rocks are common in shallow-water environments. As plate movement starts to carry the volcanoes away from their eruptive source, eruption rates start to die down, and water erosion grinds the volcano down. The final stages of eruption caps the seamount in alkalic flows.[41] There are about 100,000 deepwater volcanoes in the world,[42] although most are beyond the active stage of their life.[41] Some exemplary seamounts are Loihi Seamount, Bowie Seamount, Davidson Seamount, and Axial Seamount.\\r\\nSubglacial eruptions are a type of volcanic eruption characterized by interactions between lava and ice, often under a glacier. The nature of glaciovolcanism dictates that it occurs at areas of high latitude and high altitude.[43] It has been suggested that subglacial volcanoes that are not actively erupting often dump heat into the ice covering them, producing meltwater.[44] This meltwater mix means that subglacial eruptions often generate dangerous j?kulhlaups (floods) and lahars.[43]\\r\\nThe study of glaciovolcanism is still a relatively new field. Early accounts described the unusual flat-topped steep-sided volcanoes (called tuyas) in Iceland that were suggested to have formed from eruptions below ice. The first English-language paper on the subject was published in 1947 by William Henry Mathews, describing the Tuya Butte field in northwest British Columbia, Canada. The eruptive process that builds these structures, originally inferred in the paper,[43] begins with volcanic growth below the glacier. At first the eruptions resemble those that occur in the deep sea, forming piles of pillow lava at the base of the volcanic structure. Some of the lava shatters when it comes in contact with the cold ice, forming a glassy breccia called hyaloclastite. After a while the ice finally melts into a lake, and the more explosive eruptions of Surtseyan activity begins, building up flanks made up of mostly hyaloclastite. Eventually the lake boils off from continued volcanism, and the lava flows become more effusive and thicken as the lava cools much more slowly, often forming columnar jointing. Well-preserved tuyas show all of these stages, for example Hjorleifshofdi in Iceland.[45]\\r\\nProducts of volcano-ice interactions stand as various structures, whose shape is dependent on complex eruptive and environmental interactions. Glacial volcanism is a good indicator of past ice distribution, making it an important climatic marker. Since they are imbedded in ice, as ice retracts worldwide there are concerns that tuyas and other structures may destabalize, resulting in mass landslides. Evidence of volcanic-glacial interactions are evident in Iceland and parts of British Columbia, and it is even possible that they play a role in deglaciation.[43]\\r\\nGlaciovolcanic products have been identified in Iceland, the Canadian province of British Columbia, the U.S. states of Hawaii and Alaska, the Cascade Range of western North America, South America and even on the planet Mars.[43] Volcanoes known to have subglacial activity include:\\r\\nViable microbial communities have been found living in deep (?2800 m) geothermal groundwater at 349 K and pressures >300 bar. Furthermore, microbes have been postulated to exist in basaltic rocks in rinds of altered volcanic glass. All of these conditions could exist in polar regions of Mars today where subglacial volcanism has occurred.\\r\\nPhreatic eruptions (or steam-blast eruptions) are a type of eruption driven by the expansion of steam. When cold ground or surface water come into contact with hot rock or magma it superheats and explodes, fracturing the surrounding rock[49] and thrusting out a mixture of steam, water, ash, volcanic bombs, and volcanic blocks.[50] The distinguishing feature of phreatic explosions is that they only blast out fragments of pre-existing solid rock from the volcanic conduit; no new magma is erupted.[51] Because they are driven by the cracking of rock strata under pressure, phreatic activity does not always result in an eruption; if the rock face is strong enough to withstand the explosive force, outright eruptions may not occur, although cracks in the rock will probably develop and weaken it, furthering future eruptions.[49]\\r\\nOften a precursor of future volcanic activity,[52] phreatic eruptions are generally weak, although there have been exceptions.[51] Some phreatic events may be triggered by earthquake activity, another volcanic precursor, and they may also travel along dike lines.[49] Phreatic eruptions form base surges, lahars, avalanches, and volcanic block \\"rain.\\" They may also release deadly toxic gas able to suffocate anyone in range of the eruption.[52]\\r\\nVolcanoes known to exhibit phreatic activity include:","input":"What is the different types of volcanic eruption?"},{"output":"sandstone","context":"\\r\\n\\r\\nUluru (/?u?l??ru?/, Pitjantjatjara: Ulu?u), also known as Ayers Rock (/???rz ?r?k/) and officially gazetted as \\"Uluru?/ Ayers Rock\\",[1] is a large sandstone rock formation in the southern part of the Northern Territory in central Australia. It lies 335?km (208?mi) south west of the nearest large town, Alice Springs, 450?km (280?mi) by road.\\r\\n\\r\\nUluru is sacred to the Pitjantjatjara Anangu, the Aboriginal people of the area. The area around the formation is home to an abundance of springs, waterholes, rock caves and ancient paintings. Uluru is listed as a UNESCO World Heritage Site. Uluru and Kata Tjuta, also known as the Olgas, are the two major features of the Ulu?u-Kata Tju?a National Park.\\r\\n\\r\\nThe local Anangu, the Pitjantjatjara people, call the landmark Ulu?u (Pitjantjatjara?[?l???]). This word is a proper noun, with no further particular meaning in the Pitjantjatjara dialect, although it is used as a local family name by the senior Traditional Owners of Uluru.[2]\\r\\n\\r\\nOn 19 July 1873, the surveyor William Gosse sighted the landmark and named it Ayers Rock in honour of the then Chief Secretary of South Australia, Sir Henry Ayers.[3] Since then, both names have been used.\\r\\n\\r\\nIn 1993, a dual naming policy was adopted that allowed official names that consist of both the traditional Aboriginal name and the English name. On 15 December 1993, it was renamed \\"Ayers Rock / Uluru\\" and became the first official dual-named feature in the Northern Territory. The order of the dual names was officially reversed to \\"Uluru / Ayers Rock\\" on 6 November 2002 following a request from the Regional Tourism Association in Alice Springs.[4]\\r\\n\\r\\nUluru is one of Australia's most recognisable natural landmarks. The sandstone formation stands 348?m (1,142?ft) high, rising 863?m (2,831?ft) above sea level with most of its bulk lying underground, and has a total circumference of 9.4?km (5.8?mi).[5] Both Uluru and the nearby Kata Tjuta formation have great cultural significance for the A?angu people, the traditional inhabitants of the area, who lead walking tours to inform visitors about the local flora and fauna, bush food and the Aboriginal dreamtime stories of the area.\\r\\n\\r\\nUluru is notable for appearing to change colour at different times of the day and year, most notably when it glows red at dawn and sunset.\\r\\n\\r\\nKata Tjuta, also called Mount Olga or the Olgas, lies 25?km (16?mi) west of Uluru. Special viewing areas with road access and parking have been constructed to give tourists the best views of both sites at dawn and dusk.\\r\\n\\r\\nUluru is an inselberg, literally \\"island mountain\\".[6][7][8] An inselberg is a prominent isolated residual knob or hill that rises abruptly from and is surrounded by extensive and relatively flat erosion lowlands in a hot, dry region.[9] Uluru is also often referred to as a monolith, although this is a somewhat ambiguous term that is generally avoided by geologists. The remarkable feature of Uluru is its homogeneity and lack of jointing and parting at bedding surfaces, leading to the lack of development of scree slopes and soil. These characteristics led to its survival, while the surrounding rocks were eroded.[10] For the purpose of mapping and describing the geological history of the area, geologists refer to the rock strata making up Uluru as the Mutitjulu Arkose, and it is one of many sedimentary formations filling the Amadeus Basin.[6]\\r\\n\\r\\nUluru is dominantly composed of coarse-grained arkose (a type of sandstone characterized by an abundance of feldspar) and some conglomerate.[6][11] Average composition is 50% feldspar, 25ÿ35% quartz and up to 25% rock fragments; most feldspar is K-feldspar with only minor plagioclase as subrounded grains and highly altered inclusions within K-feldspar.[6] The grains are typically 2ÿ4 millimetres (0.079ÿ0.157?in) in diameter, and are angular to subangular; the finer sandstone is well sorted, with sorting decreasing with increasing grain size.[6] The rock fragments include subrounded basalt, invariably replaced to various degrees by chlorite and epidote.[6] The minerals present suggest derivation from a predominantly granite source, similar to the Musgrave Block exposed to the south.[10] When relatively fresh, the rock has a grey colour, but weathering of iron-bearing minerals by the process of oxidation gives the outer surface layer of rock a red-brown rusty colour.[6] Features related to deposition of the sediment include cross-bedding and ripples, analysis of which indicated deposition from broad shallow high energy fluvial channels and sheet flooding, typical of alluvial fans.[6][10]\\r\\n\\r\\nThe Mutitjulu Arkose is believed to be of about the same age as the conglomerate at Kata Tjuta, and to have a similar origin despite the rock type being different, but it is younger than the rocks exposed to the east at Mount Conner,[6] and unrelated to them. The strata at Uluru are nearly vertical, dipping to the south west at 85, and have an exposed thickness of at least 2,400?m (7,900?ft). The strata dip below the surrounding plain and no doubt extend well beyond Uluru in the subsurface, but the extent is not known.\\r\\n\\r\\nThe rock was originally sand, deposited as part of an extensive alluvial fan that extended out from the ancestors of the Musgrave, Mann and Petermann Ranges to the south and west, but separate from a nearby fan that deposited the sand, pebbles and cobbles that now make up Kata Tjuta.[6][10]\\r\\n\\r\\nThe similar mineral composition of the Mutitjulu Arkose and the granite ranges to the south is now explained. The ancestors of the ranges to the south were once much larger than the eroded remnants we see today. They were thrust up during a mountain building episode referred to as the Petermann Orogeny that took place in late Neoproterozoic to early Cambrian times (550ÿ530 Ma), and thus the Mutitjulu Arkose is believed to have been deposited at about the same time.\\r\\n\\r\\nThe arkose sandstone which makes up the formation is composed of grains that show little sorting based on grain size, exhibit very little rounding and the feldspars in the rock are relatively fresh in appearance. This lack of sorting and grain rounding is typical of arkosic sandstones and is indicative of relatively rapid erosion from the granites of the growing mountains to the south. The layers of sand were nearly horizontal when deposited, but were tilted to their near vertical position during a later episode of mountain building, possibly the Alice Springs Orogeny of Palaeozoic age (400ÿ300 Ma).[6]\\r\\n\\r\\nHistorically, 46 species of native mammals are known to have been living near Uluru; according to recent surveys there are currently 21. A?angu acknowledge that a decrease in the number has implications for the condition and health of the landscape. Moves are supported for the reintroduction of locally extinct animals such as malleefowl, common brushtail possum, rufous hare-wallaby or mala, bilby, burrowing bettong, and the black-flanked rock-wallaby.[12]\\r\\n\\r\\nThe mulgara, the only mammal listed as vulnerable, is mostly restricted to the transitional sand plain area, a narrow band of country that stretches from the vicinity of Uluru to the northern boundary of the park and into Ayers Rock Resort. This area also contains the marsupial mole, woma python, and great desert skink.\\r\\n\\r\\nThe bat population of the park comprises at least seven species that depend on day roosting sites within caves and crevices of Uluru and Kata Tjuta. Most of the bats forage for aerial prey within 100?m (330?ft) or so from the rock face. The park has a very rich reptile fauna of high conservation significance, with 73 species having been reliably recorded. Four species of frogs are abundant at the base of Uluru and Kata Tjuta following summer rains. The great desert skink is listed as vulnerable.\\r\\n\\r\\nA?angu continue to hunt and gather animal species in remote areas of the park and on A?angu land elsewhere. Hunting is largely confined to the red kangaroo, bush turkey, emu, and lizards such as the sand goanna and perentie.\\r\\n\\r\\nOf the 27 mammal species found in the park, six are introduced: the house mouse, camel, fox, cat, dog, and rabbit. These species are distributed throughout the park, but their densities are greatest near the rich water run-off areas of Uluru and Kata Tjuta.\\r\\n\\r\\nUlu?uÿKata Tju?a National Park flora represents a large portion of plants found in Central Australia. A number of these species are considered rare and restricted in the park or the immediate region. Many rare and endemic plants are found in the park.\\r\\n\\r\\nThe growth and reproduction of plant communities rely on irregular rainfall. Some plants are able to survive fire and some are dependent on it to reproduce. Plants are an important part of Tjukurpa, and ceremonies are held for each of the major plant foods. Many plants are associated with ancestral beings.\\r\\n\\r\\nFlora in Ulu?uÿKata Tju?a National Park can be broken into these categories:\\r\\n\\r\\nTrees such as the mulga and centralian bloodwood are used to make tools such as spearheads, boomerangs, and bowls. The red sap of the bloodwood is used as a disinfectant and an inhalant for coughs and colds.\\r\\n\\r\\nSeveral rare and endangered species are found in the park. Most of them, like adder's tongue ferns, are restricted to the moist areas at the base of the formation, which are areas of high visitor use and subject to erosion.\\r\\n\\r\\nSince the first Europeans arrived, 34 exotic plant species have been recorded in the park, representing about 6.4% of the total park flora. Some, such as perennial buffel grass (Cenchrus ciliaris), were introduced to rehabilitate areas damaged by erosion. It is the most threatening weed in the park and has spread to invade water- and nutrient-rich drainage lines. A few others, such as burrgrass, were brought in accidentally, carried on cars and people.\\r\\n\\r\\nThe park has a hot desert climate and receives an average rainfall of 284.6?mm (11.2?in) per year.[13] The average high temperature in summer (DecemberÿJanuary) is 37.8?C (100.0?F), and the average low temperature in winter (JuneÿJuly) is 4.7?C (40.5?F). Temperature extremes in the park have been recorded at 46?C (115?F) during the summer and ?5?C (23?F) during winter. UV levels are extreme between October and March, averaging between 11 and 15 on the UV index.[14][15]\\r\\n\\r\\nLocal Aboriginal people recognise five seasons:[5]\\r\\n\\r\\nAccording to the A?angu, traditional landowners of Uluru:[16]\\r\\n\\r\\nThe world was once a featureless place. None of the places we know existed until creator beings, in the forms of people, plants and animals, traveled widely across the land. Then, in a process of creation and destruction, they formed the landscape as we know it today. A?angu land is still inhabited by the spirits of dozens of these ancestral creator beings which are referred to as Tjukuritja or Waparitja.\\r\\n\\r\\nThere are a number of differing accounts given, by outsiders, of Aboriginal ancestral stories for the origins of Uluru and its many cracks and fissures. One such account, taken from Robert Layton's (1989) Uluru: An Aboriginal history of Ayers Rock,[17] reads as follows:\\r\\n\\r\\nUluru was built up during the creation period by two boys who played in the mud after rain. When they had finished their game they travelled south to Wiputa ... Fighting together, the two boys made their way to the table topped Mount Conner, on top of which their bodies are preserved as boulders. (Page 5)\\r\\n\\r\\nTwo other accounts are given in Norbert Brockman's (1997) Encyclopedia of Sacred Places.[18] The first tells of serpent beings who waged many wars around Uluru, scarring the rock. The second tells of two tribes of ancestral spirits who were invited to a feast, but were distracted by the beautiful Sleepy Lizard Women and did not show up. In response, the angry hosts sang evil into a mud sculpture that came to life as the dingo. There followed a great battle, which ended in the deaths of the leaders of both tribes. The earth itself rose up in grief at the bloodshed, becoming Uluru.\\r\\n\\r\\nThe Commonwealth Department of Environment's webpage advises:[16]\\r\\n\\r\\nMany...Tjukurpa such as Kalaya (Emu), Liru (poisonous snake), Lungkata (blue tongue lizard), Luunpa (kingfisher) and Tjintir-tjintirpa (willie wagtail) travel through Ulu?u-Kata Tju?a National Park. Other Tjukurpa affect only one specific area.\\r\\n\\r\\nKuniya, the woma python, lived in the rocks at Uluru where she fought the Liru, the poisonous snake.\\r\\n\\r\\nIt is sometimes reported that those who take rocks from the formation will be cursed and suffer misfortune. There have been many instances where people who removed such rocks attempted to mail them back to various agencies in an attempt to remove the perceived curse.[19][20]\\r\\n\\r\\nArchaeological findings to the east and west indicate that humans settled in the area more than 10,000 years ago.[17] Europeans arrived in the Australian Western Desert in the 1870s. Uluru and Kata Tjuta were first mapped by Europeans in 1872 during the expeditionary period made possible by the construction of the Australian Overland Telegraph Line. In separate expeditions, Ernest Giles and William Gosse were the first European explorers to this area.\\r\\n\\r\\nWhile exploring the area in 1872, Giles sighted Kata Tjuta from a location near Kings Canyon and called it Mount Olga, while the following year Gosse observed Uluru and named it Ayers Rock, in honour of the Chief Secretary of South Australia, Sir Henry Ayers. Further explorations followed with the aim of establishing the possibilities of the area for pastoralism. In the late 19th century, pastoralists attempted to establish themselves in areas adjoining the Southwestern/Petermann Reserve and interaction between A?angu and white people became more frequent and more violent. Due to the effects of grazing and drought, bush food stores became depleted. Competition for these resources created conflict between the two groups, resulting in more frequent police patrols. Later, during the depression in the 1930s, A?angu became involved in dingo scalping with 'doggers' who introduced A?angu to European foods and ways.\\r\\n\\r\\nBetween 1918 and 1921, large adjoining areas of South Australia, Western Australia, and the Northern Territory were declared as Aboriginal reserves, sanctuaries for nomadic people who had virtually no contact with European settlers. In 1920, part of Ulu?uÿKata Tju?a National Park was declared an Aboriginal Reserve (commonly known as the South-Western or Petermann Reserve) by the Australian government under the Aboriginals Ordinance.\\r\\n\\r\\nThe first tourists arrived in the Uluru area in 1936. Beginning in the 1940s, permanent European settlement of the area for reasons of the Aboriginal welfare policy and to help promote tourism of Uluru. This increased tourism prompted the formation of the first vehicular tracks in 1948 and tour bus services began early in the 1950s. In 1958, the area that would become the Ulu?uÿKata Tju?a National Park was excised from the Petermann Reserve; it was placed under the management of the Northern Territory Reserves Board and named the Ayers RockÿMount Olga National Park. The first ranger was Bill Harney, a well-recognised central Australian figure.[12] By 1959, the first motel leases had been granted and Eddie Connellan had constructed an airstrip close to the northern side of Uluru.[3]\\r\\n\\r\\nOn 26 October 1985, the Australian government returned ownership of Uluru to the local Pitjantjatjara Aborigines, with one of the conditions being that the A?angu would lease it back to the National Parks and Wildlife agency for 99 years and that it would be jointly managed. An agreement originally made between the community and Prime Minister Bob Hawke that the climb to the top by tourists would be stopped was later broken.[21][22]  The Aboriginal community of Mutitjulu, with a population of approximately 300, is located near the eastern end of Uluru. From Uluru it is 17?km (11?mi) by road to the tourist town of Yulara, population 3,000, which is situated just outside the national park.\\r\\n\\r\\nOn 8 October 2009, the Talinguru Nyakuntjaku viewing area opened to public visitation. The A$21?million project about 3 kilometres (1.9?mi) on the east side of Uluru involved design and construction supervision by the A?angu traditional owners, with 11 kilometres (6.8?mi) of roads and 1.6 kilometres (1?mi) of walking trails being built for the area.[23][24]\\r\\n\\r\\nThe development of tourism infrastructure adjacent to the base of Uluru that began in the 1950s soon produced adverse environmental impacts. It was decided in the early 1970s to remove all accommodation-related tourist facilities and re-establish them outside the park. In 1975, a reservation of 104 square kilometres (40?sq?mi) of land beyond the park's northern boundary, 15 kilometres (9?mi) from Uluru, was approved for the development of a tourist facility and an associated airport, to be known as Yulara. The camp ground within the park was closed in 1983 and the motels closed in late 1984, coinciding with the opening of the Yulara resort. In 1992, the majority interest in the Yulara resort held by the Northern Territory Government was sold and the resort was renamed Ayers Rock Resort.\\r\\n\\r\\nSince the park was listed as a World Heritage Site, annual visitor numbers rose to over 400,000 visitors by the year 2000.[25] Increased tourism provides regional and national economic benefits. It also presents an ongoing challenge to balance conservation of cultural values and visitor needs.\\r\\n\\r\\nAdmission to the park costs A$25 per person and provides a three-day pass. Passes are non-transferable and are checked by park rangers.\\r\\n\\r\\nThe local A?angu do not climb Uluru because of its great spiritual significance. They request that visitors do not climb the rock, partly due to the path crossing a sacred traditional Dreamtime track, and also due to a sense of responsibility for the safety of visitors. The visitors guide says \\"the climb is not prohibited, but we prefer that, as a guest on A?angu land, you will choose to respect our law and culture by not climbing.\\"[5]\\r\\n\\r\\nAccording to a 2010 publication, just over one-third of all visitors to the park climb Uluru; a high percentage of these were children.[26] A chain handhold added in 1964 and extended in 1976 makes the hour-long climb easier, but it is still a steep, 800?m (0.5?mi) hike to the top, where it can be quite windy. It is recommended individuals drink plenty of water while climbing, and those who are unfit, suffer from vertigo or medical conditions restricting exercise, do not attempt it. Climbing Uluru is generally closed to the public when high winds are present at the top. There have been at least 37 deaths relating to recreational climbing since such incidents began being recorded.[5][27] About one-sixth of visitors made the climb between 2011 and 2015.[28]\\r\\n\\r\\nOn 11 December 1983, the Prime Minister of Australia, Bob Hawke, promised to hand back the land title to the A?angu traditional custodians and caretakers and agreed to the community's 10-point plan which included forbidding the climbing of Uluru.  The government, however, set access to climb Uluru and a 99-year lease, instead of the previously agreed upon 50-year lease, as conditions before the title was officially given back to the A?angu on 26 October 1985.[21][29]\\r\\n\\r\\nThe Aboriginal traditional owners of Ulu?uÿKata Tju?a National Park (Nguraritja) and the Federal Government's National Parks share decision-making on the management of Ulu?uÿKata Tju?a National Park. Under their joint Ulu?uÿKata Tju?a National Park Management Plan 2010ÿ20, issued by the Director of National Parks under the Environment Protection and Biodiversity Conservation Act 1999, clause 6.3.3 provides that the Director and the Ulu?uÿKata Tju?a Board of Management work towards closure of the climb and, additionally, provides that it will close upon any of three conditions being met: there are \\"adequate new visitor experiences\\", less than 20 per cent of visitors make the climb or the \\"critical factors\\" in decisions to visit are \\"cultural and natural experiences\\".[30] Despite cogent evidence the second condition was met by July 2013, the climb remained open.[31]\\r\\n\\r\\nSeveral controversial incidents on top of Uluru in 2010, including a striptease, golfing and nudity, led to renewed calls for banning the climb.[32][33]\\r\\n\\r\\nOn 1 November 2017, the Ulu?uÿKata Tju?a National Park board voted unanimously to prohibit climbing Uluru, with the ban to take effect in October 2019.[34]\\r\\n\\r\\nPrince Charles and Diana, The Princess of Wales returning from photo session on Uluru, March 1983\\r\\n\\r\\nSign informing tourists that the climb is closed due to strong winds\\r\\n\\r\\nClimbing of Uluru will cease permanently in October 2019\\r\\n\\r\\nThe A?angu also request that visitors do not photograph certain sections of Uluru, for reasons related to traditional Tjukurpa beliefs. These areas are the sites of gender-linked rituals and are forbidden ground for A?angu of the opposite sex to those participating in the rituals in question. The photographic restriction is intended to prevent A?angu from inadvertently violating this taboo by encountering photographs of the forbidden sites in the outside world.[35]","input":"What kind of rock is uluru made from?"},{"output":"3,027","context":"The Cosmopolitan of Las Vegas[2] (commonly referred to simply as The Cosmopolitan or The Cosmo) is a luxury resort casino and hotel on the Las Vegas Strip in Paradise, Nevada. The resort opened on December 15, 2010, and is located just south of the Bellagio on the west side of Las Vegas Boulevard.\\r\\nIt consists of two highrise towers, the Boulevard Tower and the Chelsea Tower, both of which are 184 meters (603?ft) tall.[3] The $3.9 billion project features 3,027 rooms, a 110,000?sq?ft (10,000?m2) casino,[4] 300,000?sq?ft (28,000?m2) of retail and restaurant space, a 40,000?sq?ft (3,700?m2) spa and fitness facility, a 3,200-seat theater, and 150,000?sq?ft (14,000?m2) of meeting and convention space.\\r\\nIn 2013, the hotel was rated \\"The Best Hotel in the World\\" by Gogobot.[5] In 2015, the resort was named to the Cond Nast Traveller Gold List as one of the \\"Top Hotels in the World\\".[6]\\r\\n\\r\\n\\r\\nCosmopolitan features 3,027 hotel rooms[7][8], many of which feature their own private terrace; a 110,000?sq?ft (10,000?m2) casino; 300,000?sq?ft (28,000?m2) of retail and restaurant space; a 40,000?sq?ft (3,700?m2) spa and fitness facility; a 3,200-seat theater; and 150,000?sq?ft (14,000?m2) of meeting and convention space. The Cosmopolitan's 100,000?sq?ft (9,300?m2) casino features views of the Las Vegas Strip. The Pools at the Cosmopolitan features three different types: a relaxing pool, day club pool and nightclub pool.\\r\\nThe Cosmopolitan is also home to the Marquee Nightclub & Dayclub, which was the top grossing nightclub in the United States in 2012.[9] In January 2014, the Cosmopolitan added a new nightclub concept, Rose. Rabbit. Lie.\\r\\nPlans for the property were first announced in April 2004.[10] The developer, 3700 Associates, was a joint venture formed by David Friedman (a former Las Vegas Sands executive), Ian Bruce Eichner (a real estate developer), and Soros Fund Management.[10] The developers purchased the site, an 8.5-acre U-shaped parcel surrounding the Jockey Club timeshare building, for $90 million from a company controlled by New Frontier owner Margaret Elardi.[10] Further details about the project, including the Cosmopolitan name, were released in November 2004.[11]\\r\\nThe Cosmopolitan's design team was led by Friedmutter Group as executive architect, with Arquitectonica as the design architect for the building's themed exterior. The building was engineered by DeSimone Consulting Engineers. The interior design team included Digital Kitchen, Prophet, the Friedmutter Group, The Rockwell Group, Jeffrey Beers, Adam Tihany, and Bentel & Bentel.\\r\\nThe resort was built on what used to be the parking lot for the Jockey Club. Because the Cosmopolitan occupies much of the parking lot, it was agreed that the Club residents could use part of the Cosmopolitan's parking garage.[citation needed]\\r\\nThe Cosmopolitan was the second Las Vegas hotel, after The Palazzo, to feature an underground parking garage underneath the hotel. As a result, the parking garage was built first. In December 2007, work finished on the 70-foot (21?m) hole for the parking structure, while other foundation work remained in progress. The hotel was originally planned to open and be operated by Hyatt as the Grand Hyatt Las Vegas.\\r\\nOriginal plans called for the casino to be on the second floor, but this was later changed and the casino was built on ground level, like most other Las Vegas hotel-casinos. Planned condo units were cancelled and replaced with studios and other hotel rooms.[12]\\r\\nIn January 2008, it was reported that the $3.9 billion project faced financial complications, as Eichner's company defaulted on a $760 million construction loan from Deutsche Bank when the developer missed a payment after failing to secure refinancing for the project. Construction moved forward as the developers searched for new financing. In late February 2008, Global Hyatt Corporation and New York-based Marathon Asset Management agreed to recapitalize the condominium-hotel project.[13] however, one month later the developer said Deutsche Bank AG would begin foreclosure proceedings.[14] They bought the hotel for $1 billion during the summer and hired The Related Cos., developers of Time Warner Center in New York, to re-position the asset, manage the development process and assist in leasing the retail and restaurant collection.[15][16] Related recommended many revisions, including bringing the casino entrance onto the strip.[17]\\r\\nIn June 2008, Hearst Corp filed a trademark suit against the owners of the casino. Hearst owns the trademark to Cosmopolitan magazine. In March 2010, the suit was settled, and the resort was renamed Cosmopolitan of Las Vegas.[2]\\r\\nIn August 2008, it was announced that MGM Mirage, Starwood Hotels & Resorts Worldwide, Hyatt and Hilton were in talks to acquire the property.[18] It was speculated that MGM Mirage would integrate the project into Bellagio and CityCenter; Starwood were to establish its W and St. Regis brands; and Hyatt would have continued with its plans to operate a Grand Hyatt. In April 2009, the Sun reported that the hotel would be managed by Hilton and would become the Hilton's first in their new Denizen hotel line.[19] Later that month, however, those plans changed; Starwood sued Hilton, claiming trade-secret theft and essentially killing the Denizen brand.[16]\\r\\nIn June 2009, 400 homeowners filed a lawsuit against the developers, claiming breach of contract and seeking refunds for their deposits. They believed that the projected finish date of June 2010 was unrealistic and expressed fear that the developers might turn the condo rooms into hotel rooms only or \\"finish the building as a shell and not do any interior work.\\"[16]\\r\\nIn April 2010, it was announced that the Cosmopolitan would open in stages, beginning in December and ending in July 2011. It was the only hotel-casino to open on the Strip in 2010. The project officially opened on December 15, 2010, and became part of Marriott International's Autograph Collection, a collection of independent hotels with access to Marriott's reservation and rewards system. In January 2014, the Cosmopolitan announced that points through their Identity rewards program could be redeemed at 3,800 of Marriott's properties.[20] Cosmopolitan is also partnered with the Ritz-Carlton, which is Ritz's first presence on the Las Vegas Strip and their second property in the Las Vegas area.\\r\\nIn May 2014, the Cosmopolitan was sold by Deutsche Bank to Blackstone Group for $1.73 billion.[21]\\r\\nOn July 25, 2015, a fire broke out on the pool deck of the resort, burning trees and cabanas, and sending plumes of smoke into the air. Two people were treated for smoke inhalation as a result of the blaze, including one person who was transported to a local hospital.[22] The cause of the fire was not immediately known.[23]\\r\\nIn March 2010, the casino announced several celebrity chefs and restaurants that would open there.[24] Included were Bruce and Eric Bromberg's Blue Ribbon, Costas Spiliadis' Estiatorio Milos, Scott Conant's Scarpetta, and David Myers' Comme ?a.\\r\\nOn May 2, the resort announced that Jos Andrs would be joining the resort with three restaurants - creating his namesake restaurant, \\" by Jos Andrs\\", and one based on his tapas restaurant, Jaleo. Another restaurant, China Poblano, is a new concept combining Mexican and Chinese cuisine.\\r\\nAdditional restaurants include: D.O.C.G. a restaurant and wine bar by Scott Conant; Holstein's, a specialty burger restaurant. Also, STK, a steakhouse by Todd Mark Miller; along with The Henry, Va Bene Caff, and Wicked Spoon.[25]\\r\\nIn April 2011, Cosmopolitan security staff allegedly removed a transgender guest named Stephanie from a women's restroom, photographed her, and said that she would be banned for life if she did not leave the premises. Shortly after the incident, the hotel-casino was flooded with complaints on its Facebook page, which prompted the hotel-casino to issue an apology to the transgender community and to Stephanie that they would \\"welcome her back to the resort anytime.\\" The incident also prompted the hotel-casino to train its staff on awareness initiatives involving the sensitive issue.[26]\\r\\nNight view from the east side.\\r\\nCosmopolitan construction as seen from Caesars Palace\\r\\nThe Cosmopolitan nearing completion in March 2010\\r\\nThe street front view from across the Strip\\r\\nViewed from the Las Vegas Eiffel Tower\\r\\nNight view","input":"How many rooms are in the cosmopolitan las vegas?"},{"output":"more than 4,000","context":"Offshore oil and gas in the Gulf of Mexico is a major source of oil and natural gas in the United States. The western and central Gulf of Mexico, which includes offshore Texas, Louisiana, Mississippi, and Alabama, is one of the major petroleum-producing areas of the United States.\\r\\nAccording to the Energy Information Administration, \\"Gulf of Mexico federal offshore oil production accounts for 17% of total U.S. crude oil production and federal offshore natural gas production in the Gulf accounts for 5% of total U.S. dry production. Over 45% of total U.S. petroleum refining capacity is located along the Gulf coast, as well as 51% of total U.S. natural gas processing plant capacity.\\"[1]\\r\\nMajor fields include Eugene Island block 330 oil field, Atlantis Oil Field, and the Tiber oilfield (discovered 2009). Notable oil platforms include Baldpate, Bullwinkle, Mad Dog, Magnolia, Mars, Petronius, and Thunder Horse. Notable individual wells include Jack 2 and Knotty Head.\\r\\n\\r\\n\\r\\nAs technology has progressed over the years, oil companies have extended drilling and production farther and farther from shore, and into deeper and deeper waters. In 1937 Superior Oil of California and Pure Oil constructed a platform just over a mile from the shore at a depth of 13 feet. A year later, Humble Oil built a mile-long wooden trestle with railway tracks into the sea at McFadden Beach on the Gulf of Mexico, placing a derrick at its end - this was later destroyed by a hurricane.[2] A platform was installed in a hundred feet of water for the first time in 1955; in two hundred feet of water in 1962; and in a thousand feet of water in 1979.[3] \\"By 1970, the technology existed to drill in 2,000 feet of water and actual exploratory drilling was taking place at 1,400 feet.\\"[4] By 2009, more than 70% of Gulf of Mexico oil production came from wells drilled in depths greater than 1,000 feet (300?m), almost double from the percentage ten years ago.[5]\\r\\nThe deepest water depth in which a discovery has been made is 9,975 feet (3,040?m), at Lloyd Ridge 370 (Diamond).[6]\\r\\nThe federal government has not allowed drilling in federal waters in the eastern Gulf of Mexico, which includes offshore Florida and part of offshore Alabama, since 1995. In March 2010, President Barack Obama announced plans to allow drilling in the eastern Gulf of Mexico, in federal waters greater than 125 miles (201?km) from the coasts of Alabama and Florida.[7] In December 2010, following the Deepwater Horizon oil spill, the Obama administration reversed its plans to open the eastern Gulf, and imposed a moratorium on new drilling in the eastern Gulf of Mexico for at least seven years.[8]\\r\\nThe Deepwater Horizon oil spill (also referred to as the BP oil spill, the BP oil disaster, the Gulf of Mexico oil spill, and the Macondo blowout) began on April 20, 2010, in the Gulf of Mexico on the BP-operated Macondo Prospect. Killing eleven people,[9][10][11][12] it is considered the largest marine oil spill in the history of the petroleum industry and estimated to be 8% to 31% larger in volume than the previous largest, the Ixtoc I oil spill.\\r\\nIn 2012, federal leases in the Gulf of Mexico produced 463 million barrels (73.6G10^6?m3) of oil, which made up 19.5% of all U.S. oil production that year, and more than that of any U.S. state other than Texas. The 2012 production was less than the 570 million barrels (91G10^6?m3) in 2009;[13] however, due to new deep-water discoveries, the U.S. Bureau of Ocean Energy Management, Regulation and Enforcement projects that oil production from the Gulf of Mexico will increase to 686 million barrels (109.1G10^6?m3) per year by 2013.[14]\\r\\nThe state of Louisiana issued its first offshore oil and gas lease in 1936, and the following year the Pure Oil Company discovered the first Louisiana offshore oil field, the Creole Field, 1.2 miles (1.9?km) from the shore of Cameron Parish, from a platform built on timber pilings in 10-to-15-foot-deep (3.0 to 4.6?m) water.[15][16] Today, there are more than 4,000 production platforms and drilling rigs off the coast of Louisiana.[citation needed]\\r\\nThe first offshore well in Texas was drilled in 1938, but the first oil discovery was not made until 1941, off of Jefferson County.[17] Through 2007, Texas state waters have produced 39 million barrels (6.2G10^6?m3) of oil and 4.0?trillion cubic feet (110?km3). In 2007, Texas state waters produced 600,000 barrels (95,000?m3) of oil and condensate and 26?billion cubic feet (0.74?km3) gas.[18][19]\\r\\nThe first oil test in offshore Alabama was made in Mobile Bay in 1951. The first discovery in state waters of offshore Alabama was made in 1979. By 2005 a total of 80 wells have been drilled in state water, and production in Alabama state water provided 154?billion cubic feet (4.4?km3) per year, half the state's gas production.[20]\\r\\nThe eastern Gulf of Mexico, which includes offshore Gulf Coast Florida, has never been a petroleum-producing area. From the 1950s to the 1990s, oil companies drilled exploratory wells off the Gulf Coast of Florida.[21] Nineteen wells were drilled in state waters, and forty were drilled in federal waters.\\r\\nGulf Oil drilled the first offshore Florida oil exploration wells in 1947, in state waters in Florida Bay south of Cape Sable, Monroe County.[22] In 1956 Humble Oil drilled an exploratory well in state waters of Pensacola Bay, Santa Rosa County.[23] In 1959 Gulf Oil drilled the first offshore Florida well drilled from an offshore platform, off the Florida Keys.[24] All the wells drilled in state waters were dry holes.\\r\\nThe first federal lease sale offshore Florida was in 1959. In the 1980s the state of Florida objected to further federal lease sales in offshore Florida, and the last one was held in 1985. Because of state objections, the federal government agreed to pay $200 million to nine oil companies to buy back leases south of 26 degrees north latitude.[25]\\r\\nIn the 1970s and early 1980s, oil companies drilled 16 wells on and around the Destin Dome, in federal waters off the Florida Panhandle; none were successful. Then from 1987 to 1995 Chevron made commercial gas discoveries on the Destin Dome 25 miles (40?km) off the coast. The discovery extended the Norphlet productive trend, which is highly productive in Alabama state waters in Mobile Bay. However, the state of Florida objected to plans to produce the deposits, and in May 2002, the US government agreed to buy back 7 leases from Chevron, Conoco, and Murphy Oil for $115 million.[26]\\r\\nIn 1947, the state of Florida issued a long-term oil and gas lease for state waters in the Gulf, stretching from Apalachicola Bay in the north to Naples in the south. The lease, which now belongs to Coastal Petroleum, was renegotiated in 1975 to leave Coastal with partial rights from 0ÿ7.4 miles (0.0ÿ11.9?km) from the shore, and full rights to state waters from 7.4ÿ10.4 miles (11.9ÿ16.7?km) from the shore.[27] Florida has since banned offshore drilling in state waters, and has a long-running legal dispute with Coastal over Coastal's efforts to drill the offshore lease.\\r\\nFlorida banned drilling in state waters in 1992, and has also opposed additional drilling in federal waters off Florida. However, in April 2009 three committees of the Florida House of Representatives approved a bill that would allow offshore drilling in state waters more than 3 miles (4.8?km) from shore. Because state waters extend only 3 miles (4.8?km) from shore on the east coast of Florida, the legislation would have affected only state waters on the Gulf coast of the state, where state waters extend out to 10.5 statute miles (16.9?km) from shore. The bill passed the Florida House in April 2009, but died soon after in the Florida Senate.[28]\\r\\nNatural gas hydrates have long been known to exist in sediments beneath the Gulf of Mexico. In May 2009 the US Geological Survey announced the discovery of thick natural gas hydrate deposits beneath the Gulf of Mexico that are recoverable by current technology.[29] To date, natural gas from hydrates has not been produced from the Gulf of Mexico.","input":"How many oil rigs are off the coast of louisiana?"},{"output":"Warren Hastings","context":"The Governor-General of India (or, from 1858 to 1947, officially the Viceroy and Governor-General of India, commonly shortened to Viceroy of India) was originally the head of the British administration in India and, later, after Indian independence in 1947, the representative of the Indian head of state. The office was created in 1773, with the title of Governor-General of the Presidency of Fort William. The officer had direct control only over Fort William, but supervised other British East India Company officials in India. Complete authority over all of British India was granted in 1833, and the official came to be known as the \\"Governor-General of India\\".\\r\\nIn 1858, the territories of the East India Company came under the direct control of the British government; see British Raj. The governor-general (now also the viceroy) headed the central government of India, which administered the provinces of British India, including the Punjab, Bengal, Bombay, Madras, the United Provinces, and others.[1] However, much of India was not ruled directly by the British government; outside the provinces of British India, there were hundreds of nominally sovereign princely states or \\"native states\\", whose relationship was not with the British government, but directly with the monarch. To reflect the governor-general's role as the representative of the monarch to the feudal rulers of the princely states, from 1858 the term Viceroy and Governor-General of India (known in short as the Viceroy of India) was applied to him.\\r\\nThe title of viceroy was abandoned when British India split into the two independent dominions of India and Pakistan, but the office of governor-general continued to exist in each country separatelyuntil they adopted republican constitutions in 1950 and 1956, respectively.\\r\\nUntil 1858, the governor-general was selected by the Court of Directors of the East India Company, to whom he was responsible. Thereafter, he was appointed by the sovereign on the advice of the British government; the Secretary of State for India, a member of the UK Cabinet, was responsible for instructing him on the exercise of his powers. After 1947, the sovereign continued to appoint the governor-general, but did so on the advice of the Indian government.\\r\\nGovernors-General served at the pleasure of the sovereign, though the practice was to have them serve five-year terms. Governors-General could have their commission rescinded; and if one was removed, or left, a provisional governor-general was sometimes appointed until a new holder of the office could be chosen. The first Governor-General of British India was Warren Hastings, and the first Governor-General of independent India was Louis Mountbatten.\\r\\n\\r\\n\\r\\nMany parts of the Indian subcontinent were governed by the East India Company, which nominally acted as the agent of the Mughal Emperor. In 1773, motivated by corruption in the Company, the British government assumed partial control over the governance of India with the passage of the Regulating Act of 1773. A Governor-General and Supreme Council of Bengal were appointed to rule over the Presidency of Fort William in Bengal. The first Governor-General and Council were named in the Act.\\r\\nThe Charter Act 1833 replaced the Governor-General and Council of Fort William with the Governor-General and Council of India. The power to elect the Governor-General was retained by the Court of Directors, but the choice became subject to the Sovereign's approval.\\r\\nAfter the Indian Rebellion of 1857, the East India Company's territories in India were put under the direct control of the Sovereign. The Government of India Act 1858 vested the power to appoint the Governor-General in the Sovereign. The Governor-General, in turn, had the power to appoint all lieutenant governors in India, subject to the Sovereign's approval.\\r\\nIndia and Pakistan acquired independence in 1947, but Governors-General continued to be appointed over each nation until republican constitutions were written. Louis Mountbatten, 1st Earl Mountbatten of Burma remained Governor-General of India for some time after independence, but the two nations were otherwise headed by native Governors-General. India became a secular republic in 1950; Pakistan became an Islamic one in 1956.\\r\\nThe Governor-General originally had power only over the Presidency of Fort William in Bengal. The Regulating Act, however, granted them additional powers relating to foreign affairs and defence. The other Presidencies of the East India Company (Madras, Bombay and Bencoolen) were neither allowed to declare war on nor make peace with an Indian prince without receiving the prior approval of the Governor-General and Council of Fort William.[citation needed]\\r\\nThe powers of the Governor-General in respect of foreign affairs were increased by the India Act 1784. The Act provided that the other Governors under the East India Company could not declare war, make peace or conclude a treaty with an Indian prince unless expressly directed to do so by the Governor-General, or by the Company's Court of Directors.\\r\\nWhile the Governor-General thus became the controller of foreign policy in India, he was not the explicit head of British India. This status only came with the Charter Act 1833, which granted him \\"superintendence, direction and control of the whole civil and military Government\\" of all of British India. The Act also granted legislative powers to the Governor-General and Council.\\r\\nAfter 1858, the Governor-General (henceforth usually known as the Viceroy) functioned as the chief administrator of India and as the Sovereign's representative. India was divided into numerous provinces, each under the head of a Governor, Lieutenant Governor or Chief Commissioner or Administrator. Governors were appointed by the British Government, to whom they were directly responsible; Lieutenant Governors, Chief Commissioners, and Administrators, however, were appointed by and were subordinate to the Viceroy. The Viceroy also oversaw the most powerful princely rulers: the Nizam of Hyderabad, the Maharaja of Mysore, the Maharaja (Scindia) of Gwalior, the Maharaja of Jammu and Kashmir and the Gaekwad (Gaekwar) Maharaja of Baroda. The remaining princely rulers were overseen either by the Rajputana Agency and Central India Agency (which were headed by representatives of the Viceroy), or by provincial authorities.\\r\\nThe Chamber of Princes was an institution established in 1920 by a Royal Proclamation of the King-Emperor to provide a forum in which the princely rulers could voice their needs and aspirations to the government. The chamber usually met only once a year, with the Viceroy presiding, but it appointed a Standing Committee which met more often.\\r\\nUpon independence in August 1947, the title of Viceroy was abolished. The representative of the British Sovereign became known once again as the Governor-General. C. Rajagopalachari became the only Indian Governor-General. However, once India acquired independence, the Governor-General's role became almost entirely ceremonial, with power being exercised on a day-to-day basis by the Indian cabinet. After the nation became a republic in 1950, the President of India continued to perform the same functions.\\r\\nThe Governor-General was always advised by a Council on the exercise of his legislative and executive powers. The Governor-General, while exercising many functions, was referred to as the \\"Governor-General in Council.\\"\\r\\nThe Regulating Act 1773 provided for the election of four counsellors by the East India Company's Court of Directors. The Governor-General had a vote along with the counsellors, but he also had an additional vote to break ties. The decision of the Council was binding on the Governor-General.\\r\\nIn 1784, the Council was reduced to three members; the Governor-General continued to have both an ordinary vote and a casting vote. In 1786, the power of the Governor-General was increased even further, as Council decisions ceased to be binding.\\r\\nThe Charter Act 1833 made further changes to the structure of the Council. The Act was the first law to distinguish between the executive and legislative responsibilities of the Governor-General. As provided under the Act, there were to be four members of the Council elected by the Court of Directors. The first three members were permitted to participate on all occasions, but the fourth member was only allowed to sit and vote when legislation was being debated.\\r\\nIn 1858, the Court of Directors ceased to have the power to elect members of the Council. Instead, the one member who had a vote only on legislative questions came to be appointed by the Sovereign, and the other three members by the Secretary of State for India.\\r\\nThe Indian Councils Act 1861 made several changes to the Council's composition. Three members were to be appointed by the Secretary of State for India, and two by the Sovereign. (The power to appoint all five members passed to the Crown in 1869). The Viceroy was empowered to appoint an additional six to twelve members (changed to ten to sixteen in 1892, and to sixty in 1909). The five individuals appointed by the Sovereign or the Indian Secretary headed the executive departments, while those appointed by the Viceroy debated and voted on legislation.\\r\\nIn 1919, an Indian legislature, consisting of a Council of State and a Legislative Assembly, took over the legislative functions of the Viceroy's Council. The Viceroy nonetheless retained significant power over legislation. He could authorise the expenditure of money without the Legislature's consent for \\"ecclesiastical, political [and] defense\\" purposes, and for any purpose during \\"emergencies.\\" He was permitted to veto, or even stop debate on, any bill. If he recommended the passage of a bill, but only one chamber cooperated, he could declare the bill passed over the objections of the other chamber. The Legislature had no authority over foreign affairs and defence. The President of the Council of State was appointed by the Viceroy; the Legislative Assembly elected its President, but the election required the Viceroy's approval.\\r\\nUntil 1833, the title of the position was \\"Governor-General of Bengal\\". The Government of India Act 1833 converted the title into \\"Governor-General of India.\\" The title \\"Viceroy and Governor-General\\" was first used in the queen's proclamation appointing Viscount Canning in 1858.[3] It was never conferred by an act of parliament, but was used in warrants of precedence and in the statutes of knightly orders. In usage, \\"viceroy\\" is employed where the governor-general's position as the monarch's representative is in view.[4] The viceregal title was not used when the sovereign was present in India. It was meant to indicate new responsibilities, especially ritualistic ones, but it conferred no new statutory authority. The governor-general regularly used the title in communications with the Imperial Legislative Council, but all legislation was made only in the name of the Governor-General-in-Council (or the Government of India).[5]\\r\\nThe Governor-General was styled Excellency and enjoyed precedence over all other government officials in India. He was referred to as 'His Excellency' and addressed as 'Your Excellency'. From 1858 to 1947, the Governor-General was known as the Viceroy of India (from the French roi, meaning 'king'), and wives of Viceroys were known as Vicereines (from the French reine, meaning 'queen'). The Vicereine was referred to as 'Her Excellency' and was also addressed as 'Your Excellency'. Neither title was employed while the Sovereign was in India. However, the only reigning British Sovereign to visit India during the period of British rule was King George V, who accompanied by his consort Queen Mary attended the Delhi Durbar in 1911.[citation needed]\\r\\nWhen the Order of the Star of India was founded in 1861, the Viceroy was made its Grand Master ex officio. The Viceroy was also made the ex officio Grand Master of the Order of the Indian Empire upon its foundation in 1877.\\r\\nMost Governors-General and Viceroys were peers. Frequently, a Viceroy who was already a peer would be granted a peerage of higher rank, as with the granting of a marquessate to Lord Reading and an earldom and later a marquessate to Freeman Freeman-Thomas. Of those Viceroys who were not peers, Sir John Shore was a baronet, and Lord William Bentinck was entitled to the courtesy title 'Lord' because he was the son of a Duke. Only the first and last Governors-General?ÿ Warren Hastings and Chakravarti Rajagopalachari?ÿ as well as some provisional Governors-General, had no honorific titles at all.\\r\\nFrom around 1885, the Viceroy of India was allowed to fly a Union Flag augmented in the centre with the 'Star of India' surmounted by a Crown. This flag was not the Viceroy's personal flag; it was also used by Governors, Lieutenant Governors, Chief Commissioners and other British officers in India. When at sea, only the Viceroy flew the flag from the mainmast, while other officials flew it from the foremast.\\r\\nFrom 1947 to 1950, the Governor-General of India used a dark blue flag bearing the royal crest (a lion standing on the Crown), beneath which was the word 'India' in gold majuscules. The same design is still used by many other Commonwealth Realm Governors-General. This last flag was the personal flag of the Governor-General only.\\r\\nThe Governor-General of Fort William resided in Belvedere House, Calcutta, until the early nineteenth century, when Government House was constructed. In 1854, the Lieutenant Governor of Bengal took up residence there. Now, the Belvedere Estate houses the National Library of India.\\r\\nLord Wellesley, who is reputed to have said that 'India should be governed from a palace, not from a country house', constructed a grand mansion, known as Government House, between 1799 and 1803. The mansion remained in use until the capital moved from Calcutta to Delhi in 1912. Thereafter, the Lieutenant Governor of Bengal, who had hitherto resided in Belvedere House, was upgraded to a full Governor and transferred to Government House. Now, it serves as the residence of the Governor of the Indian state of West Bengal, and is referred to by its Bengali name Raj Bhavan.\\r\\nAfter the capital moved from Calcutta to Delhi, the Viceroy occupied the newly built Viceroy's House, designed by Sir Edwin Lutyens. Though construction began in 1912, it did not conclude until 1929; the palace was not formally inaugurated until 1931. The final cost exceeded S877,000 (over S35,000,000 in modern terms)?ÿ more than twice the figure originally allocated. Today the residence, now known by the Hindi name of 'Rashtrapati Bhavan', is used by the President of India.\\r\\nThroughout the British administration, Governors-General retreated to the Viceregal Lodge (Rashtrapati Niwas) at Shimla each summer to escape the heat, and the government of India moved with them. The Viceregal Lodge now houses the Indian Institute of Advanced Study.\\r\\nBadge of the Governor-General (1885ÿ1947)\\r\\nStandard of the Governor-General (1885ÿ1947)\\r\\nStandard of the Governor-General (1947ÿ50)","input":"Who was the first govenor general of india?"},{"output":"Mandalay Bay","context":"The Hacienda Resort Hotel and Casino was a hotel and casino on the Las Vegas Strip in Paradise, Nevada, that operated from 1956 to 1996. It was one of a chain of four Hacienda properties, with the other three being located in Fresno, Bakersfield, and Indio, California. Each Hacienda featured a distinctive horse and rider sign; the Las Vegas sign is now prominently displayed at the Neon Museum.\\r\\nLocated by itself on the far south end of the Las Vegas Strip, it was the first resort seen by tourists driving up from California. Since it was so far from the other resorts at the time, many people who stayed at the Hacienda would not go elsewhere. The Hacienda was also located close to McCarran International Airport, and at one point they had their own airline, Hacienda Airlines, to fly in gamblers from all over the US. The Hacienda was known for their inexpensive, all-inclusive junkets marketed to American Midwestern retirees.\\r\\nWork on the Lady Luck Hotel had begun by 1953.[1] Before construction reached the halfway mark, the projects' financing fell apart, and management was denied a gaming license by state regulators.[1] One of the investors, Warren \\"Doc\\" Bayley, a travel columnist and owner of the Hacienda Motel in Fresno, stepped in to take over, agreeing to lease the property for $55,000 per month for 15 years.[1][2] He changed the name from Lady Luck to Hacienda.[1]\\r\\nThe Hacienda opened on October 17, 1956, at a cost of $6 million, with 266 rooms and the largest swimming pool on the Strip.[3] Bayley formed Hacienda Airlines in 1957. Offering packages that included transportation from Los Angeles to the Hacienda as well as a room and some casino chips.[4] The airline included DC-3s, DC-4s and Lockheed Constellations numbering as many as 30 aircraft.[4]\\r\\nAfter Bayley's death in 1965, his widow, Judith Bayley, took over management.[1] After her death, the property was sold in 1972 for $5 million to a group led by Allen R. Glick,[5] who was later revealed as a frontman for organized crime interests.[6]\\r\\nIn 1977, Paul Lowden, the Hacienda's entertainment director and owner of a 15% stake, bought out Glick and the other owners for $21 million. The Gaming Control Board voted to deny Lowden a license due to his association with Glick, but was overruled by the Gaming Commission.[6]\\r\\nMagician Herbert L. Becker produced, directed and wrote his own show at the Hacienda beginning in 1977. The show ran for two years, on a staggered schedule before Becker went into retirement.\\r\\nMagician Lance Burton also produced, directed and wrote his own show at the Hacienda beginning in 1991. The show ran for five years before Burton moved to the Monte Carlo Resort and Casino.\\r\\nIn 1995, the Hacienda was purchased by Circus Circus Enterprises from Lowden's Archon Corporation.[7] By this time, it was dwarfed by the many new megaresorts that were being built, in particular the Luxor which had just been recently completed. On December 10, 1996, the Hacienda was closed to the public after 40 years, and imploded later that month. This implosion was broadcast on the Fox Network as a part of their New Year's Eve 1996 telecast. Despite the implosion, parts of the old resort still stood, due to the building not falling into its footprint, but toppling into its parking lot. The next day a wrecking crew was brought in to bring down the remaining parts.\\r\\nIn March 1999, it was replaced by the Mandalay Bay.\\r\\nThe Hacienda name was licensed to the Hacienda Hotel and Casino in Boulder City.","input":"What hotel replaced the hacienda in las vegas?"},{"output":"eastern and western diamondback rattlesnake","context":"\\r\\nThis is a list of some people who received a fatal snake bite in the United States by decade in reverse chronological order. There is no evidence it is a comprehensive list.\\r\\n\\r\\nThe United States has about 20 species of venomous snakes, which include 16 species of rattlesnakes, two species of coral snakes, one species of cottonmouth (or water moccasin), and four species of copperhead. At least one type of venomous snake is found in every state except Alaska and Hawaii.[4]\\r\\n\\r\\nIt has been estimated that 7,000ÿ8,000 people per year receive venomous bites in the United States, and about five of those people die.[5] Most fatal bites are attributed to the eastern and western diamondback rattlesnake. Copperheads account for more cases of venomous snake bite than any other North American species; however, their venom is the least toxic, so their bite is seldom fatal.[6]\\r\\n\\r\\nVenomous snakes are distributed unevenly throughout the United States  the vast majority of snake bites occur in warm weather states. States like Florida and Texas have a wide variety and large population of venomous snakes. Bites from venomous snakes are extremely rare in the states near the CanadaÿUS border. Maine, for example, has only one species (timber rattlesnake); they are rarely seen, and then only in the southern part of the state, but the species is likely extinct in Maine, with the last sighting in 1901.[7]\\r\\n\\r\\nSpecies:","input":"What's the deadliest snake in the united states?"},{"output":"AD 80","context":"The Colosseum or Coliseum (/k?l??si??m/ kol-?-SEE-?m), also known as the Flavian Amphitheatre (Latin: Amphitheatrum Flavium; Italian: Anfiteatro Flavio [a?fite?a?tro ?fla?vjo] or Colosseo [kolos?s??o]), is an oval amphitheatre in the centre of the city of Rome, Italy. Built of travertine, tuff, and brick-faced concrete,[1] it is the largest amphitheatre ever built. The Colosseum is situated just east of the Roman Forum. Construction began under the emperor Vespasian in AD 72,[2] and was completed in AD 80 under his successor and heir Titus.[3] Further modifications were made during the reign of Domitian (81ÿ96).[4] These three emperors are known as the Flavian dynasty, and the amphitheatre was named in Latin for its association with their family name (Flavius).\\r\\nThe Colosseum could hold, it is estimated, between 50,000 and 80,000 spectators,[5][6] having an average audience of some 65,000;[7][8] it was used for gladiatorial contests and public spectacles such as mock sea battles (for only a short time as the hypogeum was soon filled in with mechanisms to support the other activities), animal hunts, executions, re-enactments of famous battles, and dramas based on Classical mythology. The building ceased to be used for entertainment in the early medieval era. It was later reused for such purposes as housing, workshops, quarters for a religious order, a fortress, a quarry, and a Christian shrine.\\r\\nAlthough partially ruined because of damage caused by earthquakes and stone-robbers, the Colosseum is still an iconic symbol of Imperial Rome. It is one of Rome's most popular tourist attractions and also has links to the Roman Catholic Church, as each Good Friday the Pope leads a torchlit \\"Way of the Cross\\" procession that starts in the area around the Colosseum.[9]\\r\\nThe Colosseum is also depicted on the Italian version of the five-cent euro coin.\\r\\nThe Colosseum's original Latin name was Amphitheatrum Flavium, often anglicized as Flavian Amphitheatre. The building was constructed by emperors of the Flavian dynasty, following the reign of Nero.[10] This name is still used in modern English, but generally the structure is better known as the Colosseum. In antiquity, Romans may have referred to the Colosseum by the unofficial name Amphitheatrum Caesareum (with Caesareum an adjective pertaining to the title Caesar), but this name may have been strictly poetic[11][12] as it was not exclusive to the Colosseum; Vespasian and Titus, builders of the Colosseum, also constructed an amphitheater of the same name in Puteoli (modern Pozzuoli).[13]\\r\\nThe name Colosseum has long been believed to be derived from a colossal statue of Nero nearby[4] (the statue of Nero was named after the Colossus of Rhodes).[citation needed] This statue was later remodeled by Nero's successors into the likeness of Helios (Sol) or Apollo, the sun god, by adding the appropriate solar crown. Nero's head was also replaced several times with the heads of succeeding emperors. Despite its pagan links, the statue remained standing well into the medieval era and was credited with magical powers. It came to be seen as an iconic symbol of the permanence of Rome.\\r\\nIn the 8th century, a famous epigram attributed to the Venerable Bede celebrated the symbolic significance of the statue in a prophecy that is variously quoted: Quamdiu stat Colis?us, stat et Roma; quando cadet colis?us, cadet et Roma; quando cadet Roma, cadet et mundus (\\"as long as the Colossus stands, so shall Rome; when the Colossus falls, Rome shall fall; when Rome falls, so falls the world\\").[14] This is often mistranslated to refer to the Colosseum rather than the Colossus (as in, for instance, Byron's poem Childe Harold's Pilgrimage). However, at the time that the Pseudo-Bede wrote, the masculine noun coliseus was applied to the statue rather than to what was still known as the Flavian amphitheatre.\\r\\nThe Colossus did eventually fall, possibly being pulled down to reuse its bronze. By the year 1000 the name \\"Colosseum\\" had been coined to refer to the amphitheatre. The statue itself was largely forgotten and only its base survives, situated between the Colosseum and the nearby Temple of Venus and Roma.[15]\\r\\nThe name further evolved to Coliseum during the Middle Ages. In Italy, the amphitheatre is still known as il Colosseo, and other Romance languages have come to use similar forms such as Coloseumul (Romanian), le Colise (French), el Coliseo (Spanish) and o Coliseu (Portuguese).\\r\\n\\r\\n\\r\\nThe site chosen was a flat area on the floor of a low valley between the Caelian, Esquiline and Palatine Hills, through which a canalised stream ran. By the 2nd century BC the area was densely inhabited. It was devastated by the Great Fire of Rome in AD 64, following which Nero seized much of the area to add to his personal domain. He built the grandiose Domus Aurea on the site, in front of which he created an artificial lake surrounded by pavilions, gardens and porticoes. The existing Aqua Claudia aqueduct was extended to supply water to the area and the gigantic bronze Colossus of Nero was set up nearby at the entrance to the Domus Aurea.[15]\\r\\nAlthough the Colossus was preserved, much of the Domus Aurea was torn down. The lake was filled in and the land reused as the location for the new Flavian Amphitheatre. Gladiatorial schools and other support buildings were constructed nearby within the former grounds of the Domus Aurea. Vespasian's decision to build the Colosseum on the site of Nero's lake can be seen as a populist gesture of returning to the people an area of the city which Nero had appropriated for his own use. In contrast to many other amphitheatres, which were located on the outskirts of a city, the Colosseum was constructed in the city centre; in effect, placing it both symbolically and precisely at the heart of Rome.\\r\\nConstruction was funded by the opulent spoils taken from the Jewish Temple after the Great Jewish Revolt in 70 AD led to the Siege of Jerusalem. According to a reconstructed inscription found on the site, \\"the emperor Vespasian ordered this new amphitheatre to be erected from his general's share of the booty.\\" Along with the spoils, estimated 100,000 Jewish prisoners were brought back to Rome after the war, and many contributed to the massive workforce needed for construction. The slaves undertook manual labor such as working in the quarries at Tivoli where the travertine was quarried, along with lifting and transporting the quarried stones 20 miles from Tivoli to Rome.[16] Along with this free source of unskilled labor, teams of professional Roman builders, engineers, artists, painters and decorators undertook the more specialized tasks necessary for building the Colosseum.\\r\\nConstruction of the Colosseum began under the rule of Vespasian[4] in around 70ÿ72 AD (73-75 AD according to some sources)[16] The Colosseum had been completed up to the third story by the time of Vespasian's death in 79. The top level was finished by his son, Titus, in 80,[4] and the inaugural games were held in A.D. 80 or 81.[16] Dio Cassius recounts that over 9,000 wild animals were killed during the inaugural games of the amphitheatre. Commemorative coinage was issued celebrating the inauguration.[17] The building was remodelled further under Vespasian's younger son, the newly designated Emperor Domitian, who constructed the hypogeum, a series of underground tunnels used to house animals and slaves. He also added a gallery to the top of the Colosseum to increase its seating capacity.[18]\\r\\nIn 217, the Colosseum was badly damaged by a major fire (caused by lightning, according to Dio Cassius[19]) which destroyed the wooden upper levels of the amphitheatre's interior. It was not fully repaired until about 240 and underwent further repairs in 250 or 252 and again in 320. Gladiatorial fights are last mentioned around 435. An inscription records the restoration of various parts of the Colosseum under Theodosius II and Valentinian III (reigned 425ÿ455), possibly to repair damage caused by a major earthquake in 443; more work followed in 484[20] and 508. The arena continued to be used for contests well into the 6th century. Animal hunts continued until at least 523, when Anicius Maximus celebrated his consulship with some venationes, criticised by King Theodoric the Great for their high cost.[15]\\r\\nThe Colosseum underwent several radical changes of use during the medieval period. By the late 6th century a small chapel had been built into the structure of the amphitheater, though this apparently did not confer any particular religious significance on the building as a whole. The arena was converted into a cemetery. The numerous vaulted spaces in the arcades under the seating were converted into housing and workshops, and are recorded as still being rented out as late as the 12th century. Around 1200 the Frangipani family took over the Colosseum and fortified it, apparently using it as a castle.\\r\\nSevere damage was inflicted on the Colosseum by the great earthquake in 1349, causing the outer south side, lying on a less stable alluvial terrain, to collapse. Much of the tumbled stone was reused to build palaces, churches, hospitals and other buildings elsewhere in Rome. A religious order moved into the northern third of the Colosseum in the mid-14th century [21] and continued to inhabit it until as late as the early 19th century. The interior of the amphitheater was extensively stripped of stone, which was reused elsewhere, or (in the case of the marble fa?ade) was burned to make quicklime.[15] The bronze clamps which held the stonework together were pried or hacked out of the walls, leaving numerous pockmarks which still scar the building today.\\r\\nDuring the 16th and 17th century, Church officials sought a productive role for the Colosseum. Pope Sixtus V (1585ÿ1590) planned to turn the building into a wool factory to provide employment for Rome's prostitutes, though this proposal fell through with his premature death.[22] In 1671 Cardinal Altieri authorized its use for bullfights; a public outcry caused the idea to be hastily abandoned.\\r\\nIn 1749, Pope Benedict XIV endorsed the view that the Colosseum was a sacred site where early Christians had been martyred. He forbade the use of the Colosseum as a quarry and consecrated the building to the Passion of Christ and installed Stations of the Cross, declaring it sanctified by the blood of the Christian martyrs who perished there (see Significance in Christianity). However, there is no historical evidence to support Benedict's claim, nor is there even any evidence that anyone before the 16th century suggested this might be the case; the Catholic Encyclopedia concludes that there are no historical grounds for the supposition, other than the reasonably plausible conjecture that some of the many martyrs may well have been.[23]\\r\\nLater popes initiated various stabilization and restoration projects, removing the extensive vegetation which had overgrown the structure and threatened to damage it further. The fa?ade was reinforced with triangular brick wedges in 1807 and 1827, and the interior was repaired in 1831, 1846 and in the 1930s. The arena substructure was partly excavated in 1810ÿ1814 and 1874 and was fully exposed under Benito Mussolini in the 1930s.[15]\\r\\nThe Colosseum is today one of Rome's most popular tourist attractions, receiving millions of visitors annually. The effects of pollution and general deterioration over time prompted a major restoration programme carried out between 1993 and 2000, at a cost of 40?billion Italian lire ($19.3m / ?20.6m at 2000 prices).\\r\\nIn recent years the Colosseum has become a symbol of the international campaign against capital punishment, which was abolished in Italy in 1948. Several antiÿdeath penalty demonstrations took place in front of the Colosseum in 2000. Since that time, as a gesture against the death penalty, the local authorities of Rome change the color of the Colosseum's night time illumination from white to gold whenever a person condemned to the death penalty anywhere in the world gets their sentence commuted or is released,[24] or if a jurisdiction abolishes the death penalty. Most recently, the Colosseum was illuminated in gold in November 2012 following the abolishment of capital punishment in the American state of Connecticut in April 2012.[25]\\r\\nBecause of the ruined state of the interior, it is impractical to use the Colosseum to host large events; only a few hundred spectators can be accommodated in temporary seating. However, much larger concerts have been held just outside, using the Colosseum as a backdrop. Performers who have played at the Colosseum in recent years have included Ray Charles (May 2002),[26] Paul McCartney (May 2003),[27] Elton John (September 2005),[28] and Billy Joel (July 2006).\\r\\nUnlike earlier Greek theatres that were built into hillsides, the Colosseum is an entirely free-standing structure. It derives its basic exterior and interior architecture from that of two Roman theatres back to back. It is elliptical in plan and is 189 meters (615?ft / 640 Roman feet) long, and 156 meters (510?ft / 528 Roman feet) wide, with a base area of 24,000 square metres (6 acres). The height of the outer wall is 48 meters (157?ft / 165 Roman feet). The perimeter originally measured 545 meters (1,788?ft / 1,835 Roman feet). The central arena is an oval 87?m (287?ft) long and 55?m (180?ft) wide, surrounded by a wall 5?m (15?ft) high, above which rose tiers of seating.\\r\\nThe outer wall is estimated to have required over 100,000 cubic metres (3,531,467 cubic feet) of travertine stone which were set without mortar; they were held together by 300 tons of iron clamps.[15] However, it has suffered extensive damage over the centuries, with large segments having collapsed following earthquakes. The north side of the perimeter wall is still standing; the distinctive triangular brick wedges at each end are modern additions, having been constructed in the early 19th century to shore up the wall. The remainder of the present-day exterior of the Colosseum is in fact the original interior wall.\\r\\nThe surviving part of the outer wall's monumental fa?ade comprises three stories of superimposed arcades surmounted by a podium on which stands a tall attic, both of which are pierced by windows interspersed at regular intervals. The arcades are framed by half-columns of the Doric, Ionic, and Corinthian orders, while the attic is decorated with Corinthian pilasters.[29] Each of the arches in the second- and third-floor arcades framed statues, probably honoring divinities and other figures from Classical mythology.\\r\\nTwo hundred and forty mast corbels were positioned around the top of the attic. They originally supported a retractable awning, known as the velarium, that kept the sun and rain off spectators. This consisted of a canvas-covered, net-like structure made of ropes, with a hole in the center.[4] It covered two-thirds of the arena, and sloped down towards the center to catch the wind and provide a breeze for the audience. Sailors, specially enlisted from the Roman naval headquarters at Misenum and housed in the nearby Castra Misenatium, were used to work the velarium.[30]\\r\\nThe Colosseum's huge crowd capacity made it essential that the venue could be filled or evacuated quickly. Its architects adopted solutions very similar to those used in modern stadiums to deal with the same problem. The amphitheatre was ringed by eighty entrances at ground level, 76 of which were used by ordinary spectators.[4] Each entrance and exit was numbered, as was each staircase. The northern main entrance was reserved for the Roman Emperor and his aides, whilst the other three axial entrances were most likely used by the elite. All four axial entrances were richly decorated with painted stucco reliefs, of which fragments survive. Many of the original outer entrances have disappeared with the collapse of the perimeter wall, but entrances XXIII (23) to LIV (54) survive.[15]\\r\\nSpectators were given tickets in the form of numbered pottery shards, which directed them to the appropriate section and row. They accessed their seats via vomitoria (singular vomitorium), passageways that opened into a tier of seats from below or behind. These quickly dispersed people into their seats and, upon conclusion of the event or in an emergency evacuation, could permit their exit within only a few minutes. The name vomitoria derived from the Latin word for a rapid discharge, from which English derives the word vomit.\\r\\nAccording to the Codex-Calendar of 354, the Colosseum could accommodate 87,000 people, although modern estimates put the figure at around 50,000. They were seated in a tiered arrangement that reflected the rigidly stratified nature of Roman society. Special boxes were provided at the north and south ends respectively for the Emperor and the Vestal Virgins, providing the best views of the arena. Flanking them at the same level was a broad platform or podium for the senatorial class, who were allowed to bring their own chairs. The names of some 5th century senators can still be seen carved into the stonework, presumably reserving areas for their use.\\r\\nThe tier above the senators, known as the maenianum primum, was occupied by the non-senatorial noble class or knights (equites). The next level up, the maenianum secundum, was originally reserved for ordinary Roman citizens (plebeians) and was divided into two sections. The lower part (the immum) was for wealthy citizens, while the upper part (the summum) was for poor citizens. Specific sectors were provided for other social groups: for instance, boys with their tutors, soldiers on leave, foreign dignitaries, scribes, heralds, priests and so on. Stone (and later marble) seating was provided for the citizens and nobles, who presumably would have brought their own cushions with them. Inscriptions identified the areas reserved for specific groups.\\r\\nAnother level, the maenianum secundum in legneis, was added at the very top of the building during the reign of Domitian. This comprised a gallery for the common poor, slaves and women. It would have been either standing room only, or would have had very steep wooden benches. Some groups were banned altogether from the Colosseum, notably gravediggers, actors and former gladiators.[15]\\r\\nEach tier was divided into sections (maeniana) by curved passages and low walls (praecinctiones or baltei), and were subdivided into cunei, or wedges, by the steps and aisles from the vomitoria. Each row (gradus) of seats was numbered, permitting each individual seat to be exactly designated by its gradus, cuneus, and number.[31]\\r\\nThe arena itself was 83?meters by 48?meters (272?ft by 157?ft / 280 by 163?Roman feet).[15] It comprised a wooden floor covered by sand (the Latin word for sand is harena or arena), covering an elaborate underground structure called the hypogeum (literally meaning \\"underground\\"). The hypogeum was not part of the original construction but was ordered to be built by Emperor Domitian. Little now remains of the original arena floor, but the hypogeum is still clearly visible. It consisted of a two-level subterranean network of tunnels and cages beneath the arena where gladiators and animals were held before contests began. Eighty vertical shafts provided instant access to the arena for caged animals and scenery pieces concealed underneath; larger hinged platforms, called hegmata, provided access for elephants and the like. It was restructured on numerous occasions; at least twelve different phases of construction can be seen.[15]\\r\\nThe hypogeum was connected by underground tunnels to a number of points outside the Colosseum. Animals and performers were brought through the tunnel from nearby stables, with the gladiators' barracks at the Ludus Magnus to the east also being connected by tunnels. Separate tunnels were provided for the Emperor and the Vestal Virgins to permit them to enter and exit the Colosseum without needing to pass through the crowds.[15]\\r\\nSubstantial quantities of machinery also existed in the hypogeum. Elevators and pulleys raised and lowered scenery and props, as well as lifting caged animals to the surface for release. There is evidence for the existence of major hydraulic mechanisms[15] and according to ancient accounts, it was possible to flood the arena rapidly, presumably via a connection to a nearby aqueduct. However, the construction of the hypogeum at Domitian's behest put an end to the practise of flooding, and thus also to naval battles, early in the Colosseum's existence.\\r\\nThe Colosseum and its activities supported a substantial industry in the area. In addition to the amphitheatre itself, many other buildings nearby were linked to the games. Immediately to the east is the remains of the Ludus Magnus, a training school for gladiators. This was connected to the Colosseum by an underground passage, to allow easy access for the gladiators. The Ludus Magnus had its own miniature training arena, which was itself a popular attraction for Roman spectators. Other training schools were in the same area, including the Ludus Matutinus (Morning School), where fighters of animals were trained, plus the Dacian and Gallic Schools.\\r\\nAlso nearby were the Armamentarium, comprising an armory to store weapons; the Summum Choragium, where machinery was stored; the Sanitarium, which had facilities to treat wounded gladiators; and the Spoliarium, where bodies of dead gladiators were stripped of their armor and disposed of.\\r\\nAround the perimeter of the Colosseum, at a distance of 18?m (59?ft) from the perimeter, was a series of tall stone posts, with five remaining on the eastern side. Various explanations have been advanced for their presence; they may have been a religious boundary, or an outer boundary for ticket checks, or an anchor for the velarium or awning.[15]\\r\\nRight next to the Colosseum is also the Arch of Constantine.\\r\\nThe Colosseum was used to host gladiatorial shows as well as a variety of other events. The shows, called munera, were always given by private individuals rather than the state. They had a strong religious element but were also demonstrations of power and family prestige, and were immensely popular with the population. Another popular type of show was the animal hunt, or venatio. This utilized a great variety of wild beasts, mainly imported from Africa and the Middle East, and included creatures such as rhinoceros, hippopotamuses, elephants, giraffes, aurochs, wisents, Barbary lions, panthers, leopards, bears, Caspian tigers, crocodiles and ostriches. Battles and hunts were often staged amid elaborate sets with movable trees and buildings. Such events were occasionally on a huge scale; Trajan is said to have celebrated his victories in Dacia in 107 with contests involving 11,000 animals and 10,000 gladiators over the course of 123 days. During lunch intervals, executions ad bestias would be staged. Those condemned to death would be sent into the arena, naked and unarmed, to face the beasts of death which would literally tear them to pieces. Other performances would also take place by acrobats and magicians, typically during the intervals.\\r\\nDuring the early days of the Colosseum, ancient writers recorded that the building was used for naumachiae (more properly known as navalia proelia) or simulated sea battles. Accounts of the inaugural games held by Titus in AD 80 describe it being filled with water for a display of specially trained swimming horses and bulls. There is also an account of a re-enactment of a famous sea battle between the Corcyrean (Corfiot) Greeks and the Corinthians. This has been the subject of some debate among historians; although providing the water would not have been a problem, it is unclear how the arena could have been waterproofed, nor would there have been enough space in the arena for the warships to move around. It has been suggested that the reports either have the location wrong, or that the Colosseum originally featured a wide floodable channel down its central axis (which would later have been replaced by the hypogeum).[15]\\r\\nSylvae or recreations of natural scenes were also held in the arena. Painters, technicians and architects would construct a simulation of a forest with real trees and bushes planted in the arena's floor, and animals would then be introduced. Such scenes might be used simply to display a natural environment for the urban population, or could otherwise be used as the backdrop for hunts or dramas depicting episodes from mythology. They were also occasionally used for executions in which the hero of the story ÿ played by a condemned person ÿ was killed in one of various gruesome but mythologically authentic ways, such as being mauled by beasts or burned to death.\\r\\nThe Colosseum today is now a major tourist attraction in Rome with thousands of tourists each year paying to view the interior arena, though entrance for citizens of the European Union (EU) is partially subsidised, and entrance is free for EU citizens under eighteen or over sixty-five years of age.[32] There is now a museum dedicated to Eros located in the upper floor of the outer wall of the building. Part of the arena floor has been re-floored. Beneath the Colosseum, a network of subterranean passageways once used to transport wild animals and gladiators to the arena opened to the public in summer 2010.[33]\\r\\nThe Colosseum is also the site of Roman Catholic ceremonies in the 20th and 21st centuries. For instance, Pope Benedict XVI led the Stations of the Cross called the Scriptural Way of the Cross (which calls for more meditation) at the Colosseum[34][35] on Good Fridays.[9]\\r\\nIn 2011 Diego Della Valle, head of the shoe firm Tod's, entered into an agreement with local officials to sponsor a ?25?million restoration of the Colosseum. Work was planned to begin at the end of 2011, taking up to two and a half years.[36] Due to the controversial nature of using a publicÿprivate partnership to fund the restoration, work was delayed and began in 2013. The restoration is the first full cleaning and repair in the Colosseum's history.[37] The first stage is to clean and restore the Colosseum's arcaded fa?ade and replace the metal enclosures that block the ground-level arches. Taking three years, the final product of this work was unveiled July 1, 2016, when the Italian minister of culture, Dario Franceschini, also announced that the funds have been committed to replace the floors by the end of 2018. These will provide a stage that Franceschini says will be used for \\"cultural events of the highest level.\\"[38] The project also plans to create a services center and to restore the galleries and underground spaces inside the Colosseum.[39]. New to tours of the restored marvel beginning November 1, 2017, the top two levels have been opened for guided visits. The fourth level held the marketplace, and the top fifth tier is where the poorest citizens, the plebians, gathered and watched the show, bringing picnics for the day-long event. [40]\\r\\nColosseum 2013\\r\\nColosseum 2013\\r\\nColosseum 2012\\r\\nColosseum 2013\\r\\nColosseum 2013\\r\\nColosseum 2013\\r\\nColosseum 2013\\r\\nColosseum 2014\\r\\nThe Colosseum is generally regarded by Christians as a site of the martyrdom of large numbers of believers during the persecution of Christians in the Roman Empire, as evidenced by Church history and tradition.[41][42][43] On the other hand, other scholars believe that the majority of martyrdoms may have occurred at other venues within the city of Rome, rather than at the Colosseum, citing a lack of still-intact physical evidence or historical records.[44][45] These scholars assert that \\"some Christians were executed as common criminals in the Colosseumtheir crime being refusal to reverence the Roman gods\\", but most Christian martyrs of the early Church were executed for their faith at the Circus Maximus.[46][47] According to Iren?us (died about 202), Ignatius of Antioch was fed to the lions in Rome around 107 A.D and although Irenaeus says nothing about this happening at the Colosseum, tradition ascribes it to that place.[48][49][50][51]\\r\\nIn the Middle Ages, the Colosseum was not regarded as a monument, and was used as what some modern sources label a \\"quarry,\\"[52] which is to say that stones from the Colosseum were taken for the building of other sacred sites.[53] This fact is used to support the idea that, at a time when sites associated with martyrs were highly venerated the Colosseum was not being treated as a sacred site.[54] It was not included in the itineraries compiled for the use of pilgrims nor in works such as the 12th century Mirabilia Urbis Romae (\\"Marvels of the City of Rome\\"), which claims the Circus Flaminius ÿ but not the Colosseum ÿ as the site of martyrdoms.[55] Part of the structure was inhabited by a Christian religious order, but it is not known whether this was for any particular religious reason.\\r\\nPope Pius V (1566ÿ1572) is said to have recommended that pilgrims gather sand from the arena of the Colosseum to serve as a relic, on the grounds that it was impregnated with the blood of martyrs, although some of his contemporaries did not share his conviction.[56] A century later Fioravante Martinelli listed the Colosseum at the head of a list of places sacred to the martyrs in his 1653 book Roma ex ethnica sacra. Martinelli's book evidently had an effect on public opinion; in response to Cardinal Altieri's proposal some years later to turn the Colosseum into a bullring, Carlo Tomassi published a pamphlet in protest against what he regarded as an act of desecration. The ensuing controversy persuaded Pope Clement X to close the Colosseum's external arcades and declare it a sanctuary.[57]\\r\\nAt the insistence of St. Leonard of Port Maurice, Pope Benedict XIV (1740ÿ1758) forbade the quarrying of the Colosseum and erected Stations of the Cross around the arena, which remained until February 1874.[58] Benedict Joseph Labre spent the later years of his life within the walls of the Colosseum, living on alms, before he died in 1783.[58] Several 19th century popes funded repair and restoration work on the Colosseum, and it still retains its Christian connection today. A Christian cross stands in the Colosseum, with a plaque, stating:\\r\\nThe amphitheater, one consecrated to triumphs, entertainments, and the impious worship of pagan gods, is now dedicated to the sufferings of the martyrs purified from impious superstitions.[48]\\r\\nOther Christian crosses stand in several points around the arena and every Good Friday the Pope leads a Via Crucis procession to the amphitheater.\\r\\nThe Colosseum has a wide and well-documented history of flora ever since Domenico Panaroli made the first catalogue of its plants in 1643. Since then, 684 species have been identified there. The peak was in 1855 (420 species). Attempts were made in 1871 to eradicate the vegetation, because of concerns over the damage that was being caused to the masonry, but much of it has returned.[15] 242 species have been counted today and of the species first identified by Panaroli, 200 remain.\\r\\nThe variation of plants can be explained by the change of climate in Rome through the centuries. Additionally, bird migration, flower blooming, and the growth of Rome that caused the Colosseum to become embedded within the modern city centre rather than on the outskirts of the ancient city, as well as deliberate transport of species, are also contributing causes. Another reason often given is their seeds being unwittingly transported either on the fur or in the feces of animals brought there from all corners of the empire.[59]\\r\\nCoordinates: 415324.61N 122932.17E? / ?41.8901694N 12.4922694E? / 41.8901694; 12.4922694","input":"When was the colosseum in rome italy built?"},{"output":"Saint John in the United States Virgin Islands, over 5,500 acres of adjacent ocean, plus nearly all of Hassel Island","context":"The Virgin Islands National Park is a United States National Park, covering approximately 60% of the island of Saint John in the United States Virgin Islands, over 5,500 acres of adjacent ocean, plus nearly all of Hassel Island, just off the Charlotte Amalie, Saint Thomas harbor. It became the 29th U.S. national park in 1956.\\r\\nThe park is famous for scuba diving and snorkeling and has miles of hiking trails through the tropical rainforest.\\r\\nCruz Bay is the gateway port to the park. Ferries operate hourly from Red Hook, St. Thomas, thrice daily from Charlotte Amalie, St. Thomas and West End, Tortola, twice daily from Jost Van Dyke, and twice weekly from Virgin Gorda.[3]\\r\\nThe Virgin Islands National Park Visitor Center is located in Cruz Bay. It contains restrooms, maps and information, an outdoor picnic area, a dock, and a gift shop.\\r\\nThe park had an average of over 450,000 visitors per year in the period from 2007 to 2016.[2]\\r\\n\\r\\n\\r\\n\`In 1956, Laurance Rockefeller's Jackson Hole Preserve donated its extensive lands on the island to the United States' National Park Service, under the condition that the lands had to be protected from future development. The remaining portion, the Caneel Bay Resort, operates on a lease arrangement with the NPS, which owns the underlying land.\\r\\nThe boundaries of the Virgin Islands National Park include 75% of the island, but various in-holdings within the park boundary (e.g., Peter Bay, Maho Bay) reduce the park lands to 60% of the island acreage.\\r\\nMuch of the island's waters, coral reefs, and shoreline have been protected by being included in the national park. This protection was expanded in 2001, when the Virgin Islands Coral Reef National Monument was created.\\r\\nBeaches, coral reefs, hiking trails, and natural sites are the park's main attractions.\\r\\nThe park is free to enter and the only fee is at Trunk Bay Beach, which charges admission for adults. Overnight and day use mooring balls are available to boaters, for a mooring and anchoring fee.\\r\\nVisitors can stay in numerous resorts, hotels, and vacation villas near the park on St. John. Cinnamon Bay Campground is located inside the park, as is Caneel Bay resort on the north shore which lies on Rockefeller's former personal estate.\\r\\nSafari taxis are available in Cruz Bay and at the most popular National Park beaches along the north shore. Note that taxi prices are per person in the Virgin Islands.\\r\\nThe beaches of Virgin Islands National Park are regularly named some of the best in the world. The most popular beaches are Trunk Bay, Cinnamon Bay, Honeymoon Beach, Hawksnest Bay, Maho Bay, and Salt Pond Bay.\\r\\nTrunk Bay is a body of water and a beach on Saint John in the United States Virgin Islands. It has consistently been voted one of the Ten Best Beaches in The World by Cond Nast Traveler magazine and has received similar recognition from other publications.[4] Amenities include a snack bar, showers and restrooms, lifeguards, and an underwater trail for snorkeling its coral reef.[4][5] The beach area is divided into two halves, the main Trunk Bay beach and swim area and Burgesman Cove which is located on the west end of Trunk Bay near Jumbie Bay. Trunk Bay is the only National Park beach on Saint John which requires a fee to visit. Parking is limited at Trunk Bay, but taxis from Cruz Bay are readily available.[6]\\r\\nCinnamon Bay beach is a long, wide stretch of sand on the north shore of St. John. The beach is popular for sunbathing, snorkeling, and water sports. The New York Times named Cinnamon Bay one of the \\"6 Caribbean Beaches to See Before You Die.\\"[7] The bay is also home to the Cinnamon Bay Campground, a restaurant, sundries shop, and water sports rental.[8]\\r\\nHoneymoon Beach is on the north shore of St. John and can be accessed from Cruz Bay by hiking the one mile long Lind Point Trail or from Caneel Bay Resort. Cond Nast Traveler named Honeymoon Beach one of the \\"Top 10 Island Beaches for Unplugging.\\"[9] The beach features soft white sand under tall palm trees. There are kayak, snorkel equipment, and beach chair rentals available.\\r\\nMaho Bay is known for its soft sand and calm, shallow waters. The sand and seagrass sea floor make it a good place to see sea turtles and stingrays. Harper's Bazaar named Maho Bay one of the best beaches in the world.[10]\\r\\nLocated on St. John's south shore, Salt Pond Bay is a protected bay and beach. The beach can be reached by hiking a short trail from Route 107, about 4 miles south of Coral Bay. The bay is a popular snorkeling spot and has fringing reefs on both sides of the bay, sea grass in the center, and a deep coral reef far out in the middle of the bay. Overnight and day use mooring balls are available for boaters. From Salt Pond Bay, hikers can access Drunk Bay and Ram Head Trail. USA Today called Salt Pond Bay one of the best in the Virgin Islands.[11]\\r\\nThe park includes the sugar-plantation-ruins-littered Cinnamon Bay Nature Trail and the Bordeaux Mountain Trail that leads to the highest point on the island at 1,277 feet (389?m) above sea level.\\r\\nThe most popular hike is the Reef Bay Trail. This route paves the way to witnessing the beauty of the surrounding forestlands, remnants of sugar mills, historical Tano petroglyph rock carvings,[12] a spring-fed waterfall and reflection pool, and a chance for rest and relaxation or snorkeling excitement at Genti Bay. The hike is strenuous and the round trip from Centerline Road is over 6 miles. The National Park offers a ranger guided hike that includes a boat ride back to Cruz Bay from the bottom of Reef Bay.\\r\\nThe Bordeaux Mountain trail is a steep and rocky path leading from Little Lameshur Bay to the highest point of the island. The trail is unmaintained and although there are several overlooks along the way, there is no view from the top of this densely forested mountain. The trail gains almost 1,300 feet of elevation in about one mile.\\r\\nThe one mile long Lind Point Trail begins in Cruz Bay, behind the Virgin Islands National Park Visitors Center. It climbs up to Lind Point, overlooking Cruz Bay harbor, before continuing on to Honeymoon Beach.\\r\\nStarting in Cruz Bay, just north of Mongoose Junction, the Caneel Hill Trail travels up a steep incline to the top of Caneel Hill. There is a wooden observation platform at the top with views of St. John, St. Thomas, Jost Van Dyke, and many smaller islands. On a clear day, it's possible to see St. Croix and even Puerto Rico.\\r\\nBeginning at Salt Pond Bay, the Ram Head Trail travels about one mile down a dry and rocky peninsula to the southernmost point on St. John.\\r\\nAcross from the entrance to Cinnamon Bay Campground, the Cinnamon Bay Nature Trail is a half mile loop winding through the ruins of a sugar factory. Signs along the path explain the history of the area. The trail is a mixture of boardwalks and paved paths with no steep hills.\\r\\nThe park is littered with dozens of historic ruins from the colonial and plantation eras through the 1950s.\\r\\nThe Annaberg plantation is a partially restored sugar factory and windmill located just east of Mary's Point. National Park signage guides visitors through the ruins and explains the process of turning sugar cane into molasses. Volunteers and park rangers are frequently in the area to answer questions. The bake house hosts cooking demonstrations and offers samples of dumb bread. The windmill is located on Annaberg Point, which offers views of Tortola, Great Thatch Island, and the Narrows.\\r\\nThe ruins of the Reef Bay sugar factory can be reached via Reef Bay Trail or L'Esperance trail.\\r\\nThe Reef Bay Trail petroglyphs are Taino rock carvings located on rock pools near a waterfall. They can be reached via a quarter mile long spur trail from Reef Bay Trail. The Petroglyph site was added to the National Register of Historic Places in 1982.\\r\\nThe well preserved ruins of the Catherineberg sugar mill are some of the most easily accessed in the park. From Centerline Road, turn onto John Head Road and park right next to the sugar mill.\\r\\nVirgin Islands National Park is spread out on 14,737 acres (5,964?ha) of land. The park covers almost 60 percent of St. John Island, adjacent ocean, and almost all of Hassel Island.\\r\\nThe main features of the Virgin Islands National Park are the coral reefs and oceans. They almost completely surround the park. Another important feature of the Virgin Islands are the tropical forests. Wild donkeys, deer, mongoose, pigs, goats, birds, iguanas, skinks, tortoise, frogs, and crabs are common seen. Bats are the only land mammal native to the park.\\r\\nThe Virgin Islands National Park has a tropical savannah climate. The average rainfall per year is 55 inches (1,400?mm). In the winter, trade winds blow from 11 to 21 knots (39?km/h). The average temperature for the park is 79?F (26?C). At the Virgin Islands, the dominant plant species are dry tropical forest plants.\\r\\nThere is very little temperature difference between summer and winter and the sea is warm year round. The tourist season is from December to April and outside of those months prices for accommodations drop considerably. Camping and rustic lodging are available in the park from November through August at Cinnamon Bay Campground. Caneel Bay Resort provides luxury accommodations along with upscale dining in the park from November through July.\\r\\nLocated at the east end of the Greater Antilles, St. John resides on the northeastern end of the Caribbean Plate. The island formed during the Cretaceous with the eruption of the Water Island Formation, consisting of keratophyres and pillow basalts. Igneous activity then changed to that of an island arc, characterized by the Louisenhoj Formation, consisting of andesite and basalt. Volcanism abated during the deposition of the Outer Brass Limestone. Volcanism resumed as evidenced by the Late Cretaceous Tutu Formation, consisting of volcaniclastic turbidites, basalt, and andesite. A diabase dike swarm followed and then compressive folding attributed to the Caribbean Plate colliding with the Bahama Platform. The Late Eocene saw the intrusion of Narrows pluton and Virgin Gorda batholith, associated with the Greater Antilles arc magmatism, and more compressive folding associated with the spreading of the Cayman Trough. This spreading is also tied to sinistral strike-slip faulting at 39 Ma.[13]","input":"Where is the virgin islands national park located?"},{"output":"pyramidion","context":"A pyramidion (plural pyramidia) is the uppermost piece or capstone of an Egyptian pyramid or obelisk,[1] in archaeological parlance.[2] They were called benbenet in the Ancient Egyptian language,[3] which associated the pyramid as a whole with the sacred benben stone.[2] During Egypt's Old Kingdom, pyramidia were generally made of diorite, granite, or fine limestone, which were then covered in gold or electrum; during the Middle Kingdom and through the end of the pyramid-building era, they were built from granite.[4] A pyramidion was \\"covered in gold leaf to reflect the rays of the sun\\"; during Egypt's Middle Kingdom, they were often \\"inscribed with royal titles and religious symbols.\\"[2]\\r\\nVery few pyramidia have survived into modern times. Most of those that have are made of polished black granite, inscribed with the name of the pyramid's owner. Four pyramidia ÿ the world's largest collection ÿ are housed in the main hall of the Egyptian Museum in Cairo. Among them are the pyramidia from the so-called Black Pyramid of Amenemhat III at Dahshur and of the Pyramid of Khendjer at Saqqara.[5]:115[6]\\r\\nA badly damaged white Tura limestone pyramidion, thought to have been created for the Red Pyramid of Sneferu at Dahshur, has been reconstructed and is on open-air display beside that pyramid; it presents a minor mystery, however, as its angle of inclination is steeper than that of the edifice it was apparently created to surmount.\\r\\n\\r\\n\\r\\nDuring the New Kingdom, some private underground tombs were marked on the surface by small brick pyramids that terminated in pyramidia. The four lateral sides included texts and scenes related to the cult of the Sun God (as the representation of Pharaoh).\\r\\nThe scenes typically depict the course of the sun, rising on one lateral face, setting on the opposite face, and traveling, through the night, through the underworld, ruled by Osiris.\\r\\nThe pyramidion of the scribe Moses (mes,s, New Kingdom, 19th Dynasty, c. 1250 BC, limestone, 53?cm tall) depicts himself making an offering, with his name on two opposite faces. The adjacent opposite faces feature a baboon: \\"Screeching upon the rising of the Sun, and the Day\\". (The baboon is also the god-scribe representation of the Scribe, for the god Thoth.)[7]\\r\\nThe pyramidion of Ptahemwia (19th Dynasty, Ramesside Period, c. 1200 BC, limestone, 28?cm wide, 42?cm tall) likewise displays sun-related scenes.[5]:252 The Sun God, Re-Horakhti, and the god of the Underworld, Osiris, are shown on one lateral face.\\r\\nFacing the two gods, on the adjacent lateral face, is the deceased Ptahemwia, standing in an offering pose, facing three columns of hieroglyphs.[5]:252","input":"What is the top of a pyramid called?"},{"output":"Confederate president, Jefferson Davis","context":"American Indian Wars\\r\\nCortina Troubles\\r\\nAmerican Civil War\\r\\nThe Confederate States Army (C.S.A.) was the military land force of the Confederate States of America (Confederacy) during the American Civil War (1861-1865).[2] On February 28, 1861, the Provisional Confederate Congress established a provisional volunteer army and gave control over military operations and authority for mustering state forces and volunteers to the newly chosen Confederate president, Jefferson Davis (1808-1889). Davis was a graduate of the U.S. Military Academy on the Hudson River at West Point, New York, and colonel of a volunteer regiment during the MexicanÿAmerican War (1846-1848). He had also been a United States Senator from Mississippi and U.S. Secretary of War in the administration of 14th President Franklin Pierce (1853-1857). On March 1, 1861, Davis assumed control of the military situation at Charleston, South Carolina on behalf of the Confederate States government, where South Carolina state militia threatened to seize Fort Sumter, an island fortification in Charleston harbor from the small U.S. Army garrison. By March 1861, the Provisional Confederate Congress expanded the provisional forces and established a more permanent Confederate States Army.\\r\\nAn accurate count of the total number of individuals who served in the Confederate Army is not possible due to incomplete and destroyed Confederate records; all but extremely improbable estimates of the total number of Confederate soldiers range between 600,000 and 1,500,000 men. The better estimates of the number of individual Confederate soldiers are between 750,000 and 1,000,000 men. This does not include an unknown number of slaves who were pressed into performing various tasks for the army, such as construction of fortifications and defenses or driving wagons.[3] Since these figures include estimates of the total number of individual soldiers who served at any time during the war, they do not represent the size of the army at any given date. These numbers do not include men who served in Confederate States Navy.\\r\\nAlthough most of the soldiers who fought in the American Civil War were volunteers, both sides by 1862 resorted to conscription, primarily as a means to force men to register and to volunteer. In the absence of exact records, estimates of the percentage of Confederate soldiers who were draftees are about double the 6 percent of United States soldiers who were conscripts.[4]\\r\\nConfederate casualty figures also are incomplete and unreliable. The best estimates of the number of deaths of Confederate soldiers are about 94,000 killed or mortally wounded in battle, 164,000 deaths from disease and between 26,000 and 31,000 deaths in United States prison camps. One estimate of Confederate wounded, which is considered incomplete, is 194,026. These numbers do not include men who died from other causes such as accidents, which would add several thousand to the death toll.[5]\\r\\nThe main Confederate armies, the Army of Northern Virginia under General Robert E. Lee and the remnants of the Army of Tennessee and various other units under General Joseph E. Johnston, surrendered to the U.S. on April 9, 1865 (officially April 12), and April 18, 1865 (officially April 26). Other Confederate forces surrendered between April 16, 1865 and June 28, 1865.[6] By the end of the war, more than 100,000 Confederate soldiers had deserted.[7] The Confederacy's government effectively dissolved when it fled Richmond in April and exerted no control of the remaining armies.\\r\\n\\r\\n\\r\\nBy the time Abraham Lincoln took office as President of the United States on March 4, 1861, the seven seceding slave states had formed the Confederate States. The Confederacy seized federal property, including nearly all U.S. Army forts, within its borders. Lincoln was determined to hold the forts remaining under U.S. control when he took office, especially Fort Sumter in the harbor of Charleston, South Carolina. By the time Lincoln was sworn in as president, the Provisional Confederate Congress had authorized the organization of a large Provisional Army of the Confederate States (PACS).\\r\\nUnder orders from Confederate President Jefferson Davis, C.S. troops under the command of General P. G. T. Beauregard bombarded Fort Sumter on April 12ÿ13, 1861, forcing its capitulation on April 14. The United States were outraged by the Confederacy's attack and demanded war. It rallied behind Lincoln's call on April 15, for all the states to send troops to recapture the forts from the secessionists, to put down the rebellion and to preserve the United States intact. Four more slave states then joined the Confederacy. Both the United States and the Confederate States began in earnest to raise large, mostly volunteer, armies with the objectives of putting down the rebellion and preserving the Union, on the one hand, or of establishing independence from the United States, on the other.\\r\\nThe Confederate Congress provided for a Confederate army patterned after the United States Army. It was to consist of a large provisional force to exist only in time of war and a small permanent regular army. The provisional, volunteer army was established by an act of the Provisional Confederate Congress passed on February 28, 1861, one week before the act which established the permanent regular army organization, passed on March 6. Although the two forces were to exist concurrently, very little was done to organize the Confederate regular army.\\r\\nMembers of all the Confederate States military forces (the army, the navy, and the marine corps) are often referred to as \\"Confederates\\", and members of the Confederate army were referred to as \\"Confederate soldiers\\". Supplementing the Confederate army were the various state militias of the Confederacy:\\r\\nControl and operation of the Confederate army was administered by the Confederate States War Department, which was established by the Confederate Provisional Congress in an act on February 21, 1861. The Confederate Congress gave control over military operations, and authority for mustering state forces and volunteers to the President of the Confederate States of America on February 28, 1861, and March 6, 1861. On March 8 the Confederate Congress passed a law that authorized Davis to issue proclamations to call up no more than 100,000 men.[9] The War Department asked for 8,000 volunteers on March 9, 20,000 on April 8, and 49,000 on and after April 16. Davis proposed an army of 100,000 men in his message to Congress on April 29.[10]\\r\\nOn August 8, 1861, the Confederacy called for 400,000 volunteers to serve for one or three years. In April 1862,[11] the Confederacy passed the first conscription law in either C.S. or U.S. history, the Conscription Act,[12] which made all able bodied white men between the ages of 18 and 35 liable for a three-year term of service in the PACS. It also extended the terms of enlistment for all one-year soldiers to three years. Men employed in certain occupations considered to be most valuable for the home front (such as railroad and river workers, civil officials, telegraph operators, miners, druggists and teachers) were exempt from the draft.[13] The act was amended twice in 1862. On September 27, the maximum age of conscription was extended to 45.[14] On October 11, the Confederate Congress passed the so-called \\"Twenty Negro Law\\",[15] which exempted anyone who owned 20 or more slaves, a move that caused deep resentment among conscripts who did not own slaves.\\r\\nThe Confederate Congress made several more amendments over the course of the war to address losses suffered in battle as well as the United States greater supply of manpower. In December 1863, they abolished the practice of allowing a rich drafted man to hire a substitute to take his place in the ranks. Substitution had also been practiced in the United States, leading to similar resentment from the lower classes. In February 1864, the age limits were extended to between 17 and 50.[16] Challenges to the subsequent acts came before five state supreme courts; all five upheld them.[17]\\r\\nIn his 2010 book Major Problems in the Civil War, historian Michael Perman says that historians are of two minds on why millions of men seemed so eager to fight, suffer and die over four years:\\r\\nSome historians emphasize that Civil War soldiers were driven by political ideology, holding firm beliefs about the importance of liberty, Union, or state rights, or about the need to protect or to destroy slavery. Others point to less overtly political reasons to fight, such as the defense of one's home and family, or the honor and brotherhood to be preserved when fighting alongside other men. Most historians agree that, no matter what he thought about when he went into the war, the experience of combat affected him profoundly and sometimes affected his reasons for continuing to fight.\\r\\nEducated soldiers drew upon their knowledge of American history to justify their costs. McPherson says:\\r\\nThe most popular press coming out of Richmond before and during the Civil War sought to inspire a sense of patriotism, Confederate identity, and moral high ground in the southern population though newspaper media.[20]\\r\\nThe southern churches met the shortage of Army chaplains by sending missionaries. The Southern Baptists started in 1862 and had a total of 78 missionaries. Presbyterians were even more active with 112 missionaries and early 1865. Other missionaries were funded and supported by the Episcopalians, Methodists, and Lutherans. One result was wave after wave of revivals in the Army. [21] Religion played a major part in the lives of Confederate soldiers. Some men with a weak religious affiliation became committed Christians, and saw their military service in terms of God's wishes. Religion strengthened the soldiers' loyalty to comrades and the Confederacy.[22][23][24][25] Military historian Samuel J. Watson argues that Christian faith was a major factor in combat motivation. The soldiers' faith was consoling for the loss of comrades; it was a shield against fear; it helped cut down on drinking and fighting; it enlarged the soldiers community of close friends and helped make up for long-term separation from home.[26][27]\\r\\nIn his 1997 book For Cause and Comrades, which examines the motivations of the American Civil War's soldiers, historian James M. McPherson contrasts the views of Confederate soldiers regarding slavery to that of the colonial American revolutionaries of the 18th century.[28] He stated that while the American colonists of the 1770s saw an incongruity with slave ownership and proclaiming to be fighting for liberty, the Confederacy's soldiers did not, as the Confederate ideology of white supremacy negated any contradiction between the two:\\r\\nUnlike many slaveholders in the age of Thomas Jefferson, Confederate soldiers from slaveholding families expressed no feelings of embarrassment or inconsistency in fighting for their own liberty while holding other people in slavery. Indeed, white supremacy and the right of property in slaves were at the core of the ideology for which Confederate soldiers fought.\\r\\nMcPherson states that Confederate soldiers did not discuss the issue of slavery as often as United States soldiers did, because most Confederate soldiers readily accepted as an obvious fact that they were fighting to perpetuate slavery and thus did not feel the need to debate over it:\\r\\n[O]nly 20 percent of the sample of 429 Southern soldiers explicitly voiced proslavery convictions in their letters or diaries. As one might expect, a much higher percentage of soldiers from slaveholding families than from nonslaveholding families expressed such a purpose: 33 percent, compared with 12 percent. Ironically, the proportion of Union soldiers who wrote about the slavery question was greater, as the next chapter will show. There is a ready explanation for this apparent paradox. Emancipation was a salient issue for Union soldiers because it was controversial. Slavery was less salient for most Confederate soldiers because it was not controversial. They took slavery for granted as one of the Southern 'rights' and institutions for which they fought, and did not feel compelled to discuss it.\\r\\nContinuing, McPherson also stated that of the hundreds of Confederate soldiers' letters he had examined, none of them contained any anti-slavery sentiment whatsoever:\\r\\nAlthough only 20 percent of the soldiers avowed explicit proslavery purposes in their letters and diaries, none at all dissented from that view.\\r\\nBut McPherson admits flaws in his sampling of letters. Soldiers from slaveholding families were overrepresented by 100%:\\r\\nNonslaveholding farmers are underrepresented in the Confederate sample. Indeed, while about one-third of all Confederate soldiers belonged to slaveholding families, slightly more than two-thirds of the sample whose slaveholding status is known did so.\\r\\nIn some cases, Confederate men were motivated to join the army in response to the Unitard States actions in regards to opposition to slavery.[31] After U.S. President Abraham Lincoln issued the Emancipation Proclamation, some Confederate soldiers welcomed the move, as they believed it would strengthen pro-slavery sentiment in the Confederacy and thus, lead to greater enlistment of white men into the Confederate army.[31]\\r\\nOne Confederate soldier from Texas gave his reasons for fighting for the Confederacy, stating that \\"we are fighting for our property\\",[32] contrasting this with the motivations of Union soldiers, who he claimed were fighting for the \\"flimsy and abstract idea that a negro is equal to an Anglo\\".[32] One Louisianan artillery soldier stated, \\"I never want to see the day when a negro is put on an equality with a white person. There is too many free niggers . . . now to suit me, let alone having four millions.\\"[33] A North Carolinian soldier stated, \\"[A] white man is better than a nigger.\\"[33]\\r\\nIn 1894, Virginian and former Confederate soldier John S. Mosby, reflecting back on his role in the war, stated in a letter to a friend that \\"I've always understood that we went to war on account of the thing we quarreled with the North about. I've never heard of any other cause than slavery.\\"[34][35]\\r\\nAt many points during the war, and especially near the end, Confederate armies were very poorly fed. Back home their families were in worsening condition and faced starvation and marauders. Many soldiers went home temporarily (\\"absent without official leave\\") and quietly returned when their family problems had been resolved. By September 1864, however, President Davis publicly admitted that two thirds of the soldiers were absent, \\"most of them without leave.\\" The problem escalated rapidly after that, and fewer and fewer men returned.[36] Soldiers who were fighting in defense of their homes realized that they had to desert to fulfill that duty. Historian Mark Weitz argues that the official count of 103,400 deserters is too low. He concludes that most of the desertions came because the soldier felt he owed a higher duty to his own family than to the Confederacy.[37]\\r\\nConfederate policies generally were severe. For example, on August 19, 1862 General Stonewall Jackson approved the court-martial sentence of execution for three soldiers for desertion. He rejected pleas for clemency from the soldier's regimental commander. Jackson's goal was to maintain discipline in a volunteer army whose homes were under threat of enemy occupation.[38][39]\\r\\nHistorians have emphasized how soldiers from poor families deserted because they were urgently needed at home. Local pressures mounted as United States forces occupied more and more of the Confederacy, putting more and more families at risk.[40] One Confederate officer at the time noted, \\"The deserters belong almost entirely to the poorest class of non slave-holders whose labor is indispensable to the daily support of their families\\" and that \\"When the father, husband or son is forced into the service, the suffering at home with them is inevitable. It is not in the nature of these men to remain quiet in the ranks under such circumstances.\\"[41]\\r\\nSome soldiers also deserted from ideological motivations.[42] A growing threat to the solidarity of the Confederacy was dissatisfaction in the Appalachian mountain districts caused by lingering unionism and a distrust of the slave power. Many of their soldiers deserted, returned home, and formed a military force that fought off regular army units trying to punish them.[43][44] North Carolina lost 23% of its soldiers (24,122) to desertion. The state provided more soldiers per capita than any other Confederate state, and had more deserters as well.[45][46]\\r\\nYoung Mark Twain deserted long before he became a famous writer and lecturer, but he often commented upon the episode in comic fashion. Beneath his desertion from a Missouri State Guard unit was his deep unease about losing his personal honor, his fear of facing death as a soldier, and his rejection of a Southern identity as a professional author.[47]\\r\\nBecause of the destruction of any central repository of records in Richmond in 1865 and the comparatively poor record-keeping of the time, there can be no definitive number that represents the strength of the Confederate States Army. Estimates range from 500,000 to 2,000,000 men who were involved at any time during the war. Reports from the War Department began at the end of 1861 (326,768 men), 1862 (449,439), 1863 (464,646), 1864 (400,787), and \\"last reports\\" (358,692). Estimates of enlistments throughout the war were 1,227,890 to 1,406,180.[48]\\r\\nThe following calls for men were issued:\\r\\nThe CSA was initially a (strategically) defensive army, and many soldiers were resentful when Lee led the Army of Northern Virginia in an invasion of the North in the Antietam Campaign.\\r\\nThe army did not have a formal overall military commander, or general-in-chief, until late in the war. The Confederate President, Jefferson Davis, himself a former U.S. Army officer and U.S. Secretary of War, served as commander-in-chief and provided the strategic direction for Confederate land and naval forces. The following men had varying degrees of control:\\r\\nThe lack of centralized control was a strategic weakness for the Confederacy, and there are few instances of multiple armies acting in concert across multiple theaters to achieve a common objective. (An exception to this was in late 1862 when Lee's invasion of Maryland was coincident with two other actions: Bragg's invasion of Kentucky and Earl Van Dorn's advance against Corinth, Mississippi. All three initiatives were unsuccessful, however.) Likewise, an extreme example of \\"States Rights\\" control of C.S. soldiers was Georgia Governor Joseph E. Brown, who not only reportedly tried to keep Georgia troops from leaving the State of Georgia in 1861 but also tried to keep them from C.S. government control when U.S. forces entered Georgia in 1864.[citation needed]\\r\\nMany of the Confederacy's senior military leaders (including Robert E. Lee, Albert Sidney Johnston, James Longstreet) and even President Jefferson Davis were former U.S. Army and, in smaller numbers, U.S. Navy officers who had been opposed to, disapproved of, or were at least unenthusiastic about secession but resigned their U.S. commissions upon hearing that their states had left the Union. They felt that they had no choice but to help defend their homes. President Abraham Lincoln was exasperated to hear of such men who professed to love their country but were willing to fight against it.\\r\\nAs in the U.S. Army, the Confederate army's soldiers were organized by military specialty. The combat arms included infantry, cavalry and artillery.\\r\\nAlthough fewer soldiers might comprise a squad or platoon, the smallest infantry maneuver unit in the Army was a company of 100 soldiers. Ten companies were organized into an infantry regiment, which theoretically had 1,000 men. In reality, as disease, desertions and casualties took their toll, and the common practice of sending replacements to form new regiments took hold, most regiments were greatly reduced in strength. By the mid-war, most regiments averaged 300ÿ400 men, with Confederate units slightly smaller on average than their U.S. counterparts. For example, at the pivotal Battle of Chancellorsville, the average U.S. Army infantry regiment's strength was 433 men, versus 409 for Confederate infantry regiments.[53]\\r\\nRegiments, which were the basic units of army organization through which soldiers were supplied and deployed, were raised by individual states. They were generally referred by number and state, for example 1st Texas, 12th Virginia. To the extent the word \\"battalion\\" was used to describe a military unit, it referred to a multi-company task force of a regiment or a near-regimental size unit. Throughout the war, the Confederacy raised the equivalent of 1,010 regiments in all branches, including militias, versus 2,050 regiments for the U.S. Army.[54]\\r\\nFour regiments usually formed a brigade, although as the number of men in many regiments became greatly reduced, especially later in the war, more than four were often assigned to a brigade. Occasionally, regiments would be transferred between brigades. Two to four brigades usually formed a division. Two to four divisions usually formed a corps. Two to four corps usually formed an army. Occasionally, a single corps might operate independently as if it were a small army. The Confederate States Army consisted of several field armies, named after their primary area of operation. The largest Confederate field army was the Army of Northern Virginia, whose surrender at Appomattox Courthouse in 1865 marked the end of major combat operations in the US Civil War.\\r\\nCompanies were commanded by captains and had two or more lieutenants. Regiments were commanded by colonels. Lieutenant colonels were second in command. At least one major was next in command. Brigades were commanded by brigadier generals although casualties or other attrition sometimes meant that brigades would be commanded by senior colonels or even a lower grade officer. Barring the same type of circumstances which might leave a lower grade officer in temporary command, divisions were commanded by major generals and corps were commanded by lieutenant generals. A few corps commanders were never confirmed as lieutenant generals and exercised corps command for varying periods of time as major generals. Armies of more than one corps were commanded by (full) generals.\\r\\nCorporal of the Artillery division of the Confederate States of America Army.\\r\\nConfederate mortar crew at Warrington, Florida in 1861, across from Fort Pickens.\\r\\nConfederate artillery at Charleston Harbor, 1863.\\r\\nThere were four grades of general officer (general, lieutenant general, major general, and brigadier general), but all wore the same insignia regardless of grade. This was a decision made early in the conflict. The Confederate Congress initially made the rank of brigadier general the highest rank. As the war progressed, the other general-officer ranks were quickly added, but no insignia for them was created. (Robert E. Lee was a notable exception to this. He chose to wear the rank insignia of a colonel.) Only seven men achieved the rank of (full) general;[55] the highest ranking (earliest date of rank) was Samuel Cooper, Adjutant General and Inspector General of the Confederate States Army.\\r\\nOfficers' uniforms bore a braid design on the sleeves and kepi, the number of adjacent strips (and therefore the width of the lines of the design) denoting rank. The color of the piping and kepi denoted the military branch. The braid was sometimes left off by officers since it made them conspicuous targets. The kepi was rarely used, the common slouch hat being preferred for its practicality in the Southern climate.\\r\\nBranch colors were used for color of chevronsblue for infantry, yellow for cavalry, and red for artillery. This could differ with some units, however, depending on available resources or the unit commander's desire. Cavalry regiments from Texas, for example, often used red insignia and at least one Texas infantry regiment used black.\\r\\nThe CSA differed from many contemporaneous armies in that all officers under the rank of brigadier general were elected by the soldiers under their command. The Confederate Congress authorized the awarding of medals for courage and good conduct on October 13, 1862, but war time difficulties prevented the procurement of the needed medals. To avoid postponing recognition for their valor, those nominated for the awards had their names placed on a Roll of Honor, which would be read at the first dress parade after its receipt and be published in at least one newspaper in each state.\\r\\nThe C.S. Army was composed of independent armies and military departments that were constituted, renamed, and disbanded as needs arose, particularly in reaction to offensives launched by the United States. These major units were generally named after states or geographic regions (in comparison to the U.S. Armys custom of naming armies after rivers). Armies were usually commanded by full generals (there were seven in the C.S. Army) or lieutenant generals. Some of the more important armies and their commanders were:\\r\\nSome other prominent Confederate generals who led significant units operating sometimes independently in the CSA included Thomas J. \\"Stonewall\\" Jackson, James Longstreet, J. E. B. Stuart, Gideon Pillow, and A. P. Hill.\\r\\nThe supply situation for most Confederate armies was dismal, even when they were victorious on the battlefield. The central government was short of money so each state government had to supply its own regiments. The lack of central authority and the ineffective railroads, combined with the frequent unwillingness or inability of Southern state governments to provide adequate funding, were key factors in the Confederate army's demise. The Confederacy early on lost control of most of its major river and ocean ports to capture or blockade. The road system was poor, and it relied more and more on a heavily overburdened railroad system. U.S. forces destroyed track, engines, cars, bridges and telegraph lines as often as possible, knowing that new equipment was unavailable to the Confederacy.[57] Occasional raids into the North were designed to bring back money and supplies. In 1864, the Confederates burned down Chambersburg, a Pennsylvania city they had raided twice in the years before, due to its failure to pay an extortion demand.[58]\\r\\nAs a result of severe supply problems, as well as the lack of textile factories in the Confederacy and the successful U.S. naval blockade of Southern ports, the typical Confederate soldier was rarely able to wear the standard regulation uniform, particularly as the war progressed. While on the march or in parade formation, Confederate armies often displayed a wide array of dress, ranging from faded, patched-together regulation uniforms; rough, homespun uniforms colored with homemade dyes such as butternut (a yellow-brown color), and even soldiers in a hodgepodge of civilian clothing. After a successful battle, it was not unusual for victorious Confederate troops to procure U.S. Army uniform parts from captured supplies and dead U.S. soldiers; this would occasionally cause confusion in later battles and skirmishes.[59]\\r\\nIndividual states were expected to supply their soldiers, which led to a lack of uniformity. Some states (such as North Carolina) were able to better supply their soldiers, while other states (such as Texas) were unable for various reasons to adequately supply their troops as the war continued.\\r\\nFurthermore, each state often had its own uniform regulations and insignia, which meant that the \\"standard\\" Confederate uniform often featured a variety of differences based on the state the soldier came from. For example, uniforms for North Carolina regiments often featured a colored strip of cloth on their shoulders to designate what part of the service the soldier was in. Confederate soldiers also frequently suffered from inadequate supplies of shoes, tents, and other gear, and would be forced to innovate and make do with whatever they could scrounge from the local countryside. While Confederate officers were generally better-supplied and were normally able to wear a regulation officer's uniform, they often chose to share other hardships ÿ such as the lack of adequate food ÿ with their troops.\\r\\nConfederate soldiers were also faced with inadequate food rations, especially as the war progressed. There was plenty of meat in the Confederacy. The unsolvable problem was shipping it to the armies, especially when Lee's army in Virginia was at the end of a long, tenuous supply line. United States victory at Vicksburg in 1863 shut off supplies from Texas and the west.[60]\\r\\nBy 1863 Confederate generals such as Robert E. Lee often spent as much time and effort searching for food for their men as they did in planning strategy and tactics. Individual commanders often had to \\"beg, borrow or steal\\" food and ammunition from whatever sources were available, including captured U.S. depots and encampments, and private citizens regardless of their loyalties. Lee's campaign against Gettysburg and southern Pennsylvania (a rich agricultural region) was driven in part by his desperate need of supplies, especially food.[61]\\r\\nGeneral Sherman's total warfare reduced the ability of the South to produce food and ship it to the armies or its cities. Coupled with the U.S. blockade of all ports the devastation of plantations, farms and railroads meant the Confederacy increasingly lost the capacity to feed its soldiers and civilians.\\r\\nNative Americans served in both the United States and Confederate military during the American Civil War.[62][63] They fought knowing they might jeopardize their freedom, unique cultures, and ancestral lands if they ended up on the losing side of the Civil War.[62][64] During the Civil War 28,693 Native Americans served in the U.S. and Confederate armies, participating in battles such as Pea Ridge, Second Manassas, Antietam, Spotsylvania, Cold Harbor, and in Federal assaults on Petersburg.[62][63] Many Native American tribes, such as the Creek and the Choctaw, were slaveholders themselves, and thus, found a political and economic commonality with the Confederacy.[65]\\r\\nAt the beginning of the war, Albert Pike was appointed as Confederate envoy to Native Americans. In this capacity he negotiated several treaties, one such treaty was the Treaty with Choctaws and Chickasaws conducted in July 1861. The treaty covered sixty-four terms covering many subjects like Choctaw and Chickasaw nation sovereignty, Confederate States of America citizenship possibilities, and an entitled delegate in the House of Representatives of the Confederate States of America. The Cherokee, Choctaw, Seminole, Catawba, and Creek tribes were the only tribes to fight on the Confederate side. The Confederacy wanted to recruit Indians east of the Mississippi River in 1862, so they opened up a recruiting camp in Mobile, Alabama \\"at the foot of Stone Street\\".[66] The Mobile Advertiser and Register would advertise for a chance at military service.\\r\\nA Chance for Active Service. The Secretary of War has authorized me to enlist all the Indians east of the Mississippi River into the service of the Confederate States, as Scouts. In addition to the Indians, I will receive all white male citizens, who are good marksmen. To each member, Fifty Dollars Bounty, clothes, arms, camp equipage &c: furnished. The weapons shall be Enfield Rifles. For further information address me at Mobile, Ala. (Signed) S. G. Spann, Comm'ing Choctaw Forces.\\r\\nStand Watie, along with a few Cherokee, sided with the Confederate army, in which he was made colonel and commanded a battalion of Cherokee.[62] Reluctantly, on October 7, 1861, Chief Ross signed a treaty transferring all obligations due to the Cherokee from the United States to the Confederate States.[62] In the treaty, the Cherokee were guaranteed protection, rations of food, livestock, tools and other goods, as well as a delegate to the Confederate Congress at Richmond.[62]\\r\\nIn exchange, the Cherokee would furnish ten companies of mounted men, and allow the construction of military posts and roads within the Cherokee Nation. However, no Indian regiment was to be called on to fight outside Indian Territory.[62] As a result of the Treaty, the 2nd Cherokee Mounted Rifles, led by Col. John Drew, was formed. Following the Battle of Pea Ridge, Arkansas, March 7ÿ8, 1862, Drew's Mounted Rifles defected to the United States forces in Kansas, where they joined the Indian Home Guard. In the summer of 1862, U.S. troops captured Chief Ross, who was paroled and spent the remainder of the war in Washington and Philadelphia proclaiming Cherokee loyalty to the United States Army.[62]\\r\\nWilliam Holland Thomas, the only white chief of the Eastern Band of Cherokee Indians, recruited hundreds of Cherokees for the Confederate army, particularly for Thomas' Legion. The Legion, raised in September 1862, fought until the end of the War.\\r\\nChoctaw Confederate battalions were formed in Indian Territory and later in Mississippi in support of the southern cause. The Choctaws, who were expecting support from the Confederates, got little. Webb Garrison, a Civil War historian, describes their response: when Confederate Brigadier General Albert Pike authorized the raising of regiments during the fall of 1860, Creeks, Choctaws, and Cherokees responded with considerable enthusiasm. Their zeal for the Confederate cause, however, began to evaporate when they found that neither arms nor pay had been arranged for them. A disgusted officer later acknowledged that \\"with the exception of a partial supply for the Choctaw regiment, no tents, clothing, or camp and garrison equipage was furnished to any of them.\\"[67]\\r\\nWith so many white males conscripted into the army and roughly 40% of its population unfree, the work required to maintain a functioning society in the Confederacy ended up largely on the backs of slaves.[74] Even Georgian governor Joseph E. Brown noted that \\"the country and the army are mainly dependent upon slave labor for support.\\"[75] African American slave labor was used in a wide variety of logistical support roles for the Confederacy, from infrastructure and mining, to teamster and medical roles such as hospital attendants and nurses.[76][77]\\r\\nThe Confederacy did not allow African Americans to join the army, including both free blacks and slaves. The idea of arming the Confederacy's slaves for use as soldiers was speculated on from the onset of the war, but such proposals were not seriously considered by Jefferson Davis or others in the Confederate administration until late in the war, when severe manpower shortages were faced.[78] Gary Gallagher says, \\"When Lee publicly advocated arming slaves in early 1865, he did so as a desperate expedient that might prolong Southern military resistance.\\".[79] After acrimonious debate the Confederate Congress agreed in March, 1865. The war was nearly over by then and very few slaves ended up being enlisted before the Confederate armies all surrendered.[11]\\r\\nAs early as November 1864, some Confederates knew that the chance of securing victory against the U.S. was slim.[80] Despite lacking foreign assistance and recognition and facing slim chances of victory against superior U.S. assets, Confederate newspapers such as the Georgian Atlanta Southern Confederacy continued to maintain their position and oppose the idea of armed black men in the Confederate army, even late in the war as January 1865.[81] They stated that it was incongruous with the Confederacy's goals and views regarding African Americans and slavery. The Georgian newspaper opined that using black men as soldiers would be an embarrassment to Confederates and their children, saying that although African Americans should be used for slave labor, they should not be used as armed soldiers, opining that:\\r\\nProminent Confederates such as R. M. T. Hunter and Georgian Democrat Howell Cobb opposed arming slaves, saying that it was \\"suicidal\\" and would run contrary to the Confederacy's ideology. Opposing such a move, Cobb stated that African Americans were untrustworthy and innately lacked the qualities to make good soldiers, and that using them would cause many Confederates to quit the army.[82][83][84][85]\\r\\nThe overwhelming support most Confederates had for maintaining black slavery was the primary cause of their strong opposition to using African Americans as armed soldiers. Maintaining the institution of slavery was the primary goal of the Confederacy's existence, and thus, using their slaves as soldiers was incongruous with that goal. According to historian Paul D. Escott:\\r\\n[F]or a great many of the most powerful southerners the idea of arming and freeing the slaves was repugnant because the protection of slavery had been and still remained the central core of Confederate purpose... Slavery was the basis of the planter class's wealth, power, and position in society. The South's leading men had built their world upon slavery and the idea of voluntarily destroying that world, even in the ultimate crisis, was almost unthinkable to them. Such feelings moved Senator R. M. T. Hunter to deliver a long speech against the bill to arm the slaves.[86]\\r\\nThough most Confederates were opposed to the idea of using black soldiers, a small number suggested the idea. An acrimonious and controversial debate was raised by a letter from Patrick Cleburne[87] urging the Confederacy to raise black soldiers by offering emancipation; Jefferson Davis refused to consider the proposal and issued instructions forbidding the matter from being discussed.[88] It would not be until Robert E. Lee wrote the Confederate Congress urging them that the idea would take serious traction.[89]\\r\\nOn March 13, 1865,[11] the Confederate Congress passed General Order 14[90][91] by a single vote in the Confederate senate,[11][92] and Jefferson Davis signed the order into law. The order was issued March 23, but as it was late in the war, only a few African American companies were raised in the Richmond area before the town was captured by the U.S. Army and placed back under U.S. control.[93]\\r\\nAccording to historian James M. McPherson in 1994, \\"no black soldiers fought in the Confederate army, unless they were passing as white.\\"[dubious ÿ discuss] [11] He noted that some Confederates brought along \\"their body servants, who in many cases had grown up with them\\" and that \\"on occasion some of those body servants were known to have picked up a rifle... But there was no official recruitment of black soldiers in the Confederate army until the very end of the war\\", when it was brought about only by a \\"desperate shortage of manpower.\\"[11]\\r\\nIn some cases, the Confederates forced their African American slaves to fire upon U.S. soldiers at gunpoint,[72][73] such as at the first Battle of Bull Run. According to John Parker, one such slave who was forced by the Confederates to fight U.S. soldiers, \\"Our masters tried all they could to make us fight... They promised to give us our freedom and money besides, but none of us believed them; we only fought because we had to.\\" Parker stated that had he been given an opportunity, he would have turned against his Confederate captors, and \\"could do it with pleasure\\".[72][73] According to abolitionist Henry Highland Garnet in 1862, he had met a slave who \\"had unwillingly fought on the side of Rebellion\\", but said slave had since defected to \\"the side of Union and universal liberty.\\"[73]\\r\\nDuring the Siege of Yorktown (1862), The United States Army's elite sniper unit, the 1st United States Sharpshooters, was devastatingly effective at shooting Confederate artillerymen defending the city. In response, some Confederate artillery crews started forcing slaves to load the cannons. \\"They forced their negroes to load their cannon,\\" reported a U.S. officer. They shot them if they would not load the cannon, and we shot them if they did.[94]\\r\\nIn other cases, under explicit orders from their commanders, Confederate armies would often forcibly kidnap free African American civilians during their incursions into U.S. territory, sending them south into Confederate territory and thus enslaving them, as was the case with the Army of Northern Virginia when it invaded Pennsylvania in 1863.[95][96]\\r\\nThe usage of black men as U.S. soldiers by the U.S., combined with Abraham Lincoln's issuing of the Emancipation Proclamation, profoundly angered the Confederacy,[97] with the Confederates calling it uncivilized.[98] As a response, in May 1863 the Confederacy passed a law demanding \\"full and ample retaliation\\" against the United States, stating that any black person captured in \\"arms against the Confederate States\\" or giving aid and comfort to their enemies would be turned over to state authorities, where they could be tried as slave insurrectionists; a capital offense punishable with a sentence of death.[99][100] However, Confederate authorities feared retaliation, and as such no black prisoner was ever put on trial and executed.[101]\\r\\nJames McPherson states that \\"Confederate troops sometimes murdered black soldiers and their officers as they tried to surrender. In most cases, though, Confederate officers returned captured black soldiers to slavery or put them to hard labor on southern fortifications.\\"[102][103] African American USCT soldiers were often singled out by the Confederates and suffered extra violence when captured by them.[68] They were often the victims of battlefield massacres and atrocities at the hands of the Confederates,[68] most notably at Fort Pillow in Tennessee and at the Battle of the Crater in Virginia.[104][105]\\r\\nThe Confederate law declaring black U.S. soldiers as being insurrectionist slaves, combined with the Confederacy's discriminatory mistreatment of captured black U.S. soldiers, became a stumbling block for prisoner exchanges between the United States and the Confederacy, as the U.S. government in the Lieber Code officially objected to the Confederacy's discriminatory mistreatment of prisoners of war on basis of color.[106][107] The Republican Party's platform of the 1864 presidential election reflected this view, as it too condemned the Confederacy's discriminatory mistreatment of captured black U.S. soldiers.[108] According to the authors of Liberty, Equality, Power, \\"Expressing outrage at this treatment, in 1863 the Lincoln administration suspended the exchange of prisoners until the Confederacy agree to treat white and black prisoners alike. The Confederacy refused.\\"[106]\\r\\nIncomplete and destroyed records make an accurate count of the number of men who served in the Confederate army impossible. Historians provide estimates of the actual number of individual Confederate soldiers between 750,000 and 1,000,000 men.[109]\\r\\nThe exact number is unknown. Since these figures include estimates of the total number of individual soldiers who served in each army at any time during the war, they do not represent the size of the armies at any given date. Confederate casualty figures are as incomplete and unreliable as the figures on the number of Confederate soldiers. The best estimates of the number of deaths of Confederate soldiers appear to be about 94,000 killed or mortally wounded in battle, 164,000 deaths from disease and between 26,000 and 31,000 deaths in U.S. prison camps. In contrast, about 25,000 U.S. soldiers died as a result of accidents, drowning, murder, killed after capture, suicide, execution for various crimes, execution by the Confederates (64), sunstroke, other and not stated. Confederate casualties for all these reasons are unavailable. Since some Confederate soldiers would have died for these reasons, more total deaths and total casualties for the Confederacy must have occurred. One estimate of Confederate wounded, which is considered incomplete, is 194,026; another is 226,000. At the end of the war 174,223 men of the Confederate forces surrendered to the U.S. Army.[110][111]\\r\\nCompared to the U.S. Army at the time, the Confederate army was not very ethnically diverse. Ninety-one percent of Confederate soldiers were native-born white men and only 9% were foreign-born white men, Irishmen being the largest group with others including Germans, French, Mexicans, and British. A small number of Asian men were forcibly inducted into the Confederate army against their will when they arrived in Louisiana from overseas.[112][113]\\r\\n340-377.","input":"Who was the leader of the confederate army?"},{"output":"lymphoma","context":"Stepmom is a 1998 comedy-drama film directed by Chris Columbus and starring Julia Roberts, Susan Sarandon, and Ed Harris. Sarandon won the San Diego Film Critics Society Award for Best Actress and Harris won the National Board of Review Award for Best Supporting Actor, sharing the win with his role in The Truman Show.\\r\\n\\r\\nJackie and Luke Harrison are a divorced New York City couple struggling to help their children Anna and Ben be happy with this sudden change of lifestyle. Luke, an attorney, is living with his new girlfriend, Isabel Kelly, a successful fashion photographer several years his junior.[3] Isabel tries hard to make Anna and Ben feel comfortable and happy with her, but Anna repeatedly rejects her overtures while Ben, who is generally kind to Isabel, adds extra complication with his mischievous nature. Isabel behaves with contempt tempered by caution around Jackie, believing she overcompensates for her divorce by spoiling her children.\\r\\n\\r\\nJackie, a former publisher turned stay-at-home mom, gives Isabel a cold reception, seeing her as an overly ambitious career woman. She also continues to harbor malice towards Luke, as seen in a confrontation about Isabel. After a long string of arguments and hurt feelings involving Isabel, Jackie, and Anna, Luke proposes to Isabel, making her Anna and Ben's soon-to-be official stepmother. This causes even more friction. Jackie is diagnosed with lymphoma, which is discovered to be terminal. She experiences a range of negative emotions, angry at the woman who she feels was responsible for breaking up her family, and angry that after all of the sacrifices she made for her family, she will never see her children grow up. Jackie actively sabotages Isabel's effort to bond with the children even to the point of refusing to allow her to take Anna to see a rock band that she likes and then taking her to the same concert a few weeks later herself.\\r\\n\\r\\nLuke and Jackie later tell the children about the engagement, and Anna is furious. Jackie tells Luke and the children about her illness, resulting in Anna storming out. That night Jackie shows that she can be fun by dancing and singing with Anna and Ben.\\r\\n\\r\\nIsabel and Anna continue to clash. Isabel gets the children a golden retriever puppy, and Anna says that she is allergic to dogs. Surprised, Isabel apologizes and says that her father didn't tell her that. After another argument between the two, Anna takes the dog inside her room, indicating she lied about her allergy. Eventually, Isabel and Anna's relationship improves. They start to bond over painting, when Isabel teaches Anna how to paint trees.\\r\\n\\r\\nJackie and Isabel disagree repeatedly, largely over Isabel's parenting. Ben goes missing on Isabel's watch and Jackie claims that she has never lost him, which she later admits to be untrue. When Anna has problems with a boy she once liked, the two women give opposite advice, causing more tension between Jackie and Isabel. They manage to establish a shaky truce, as they come to terms that Isabel will soon step into the role of a surrogate mother. The two women finally bond when Isabel reveals her admiration of Jackie's maternal instincts, while Jackie in turn praises Isabel's hipness as a means to connect with Anna. Isabel finally lets her guard down when she tells Jackie her biggest fear is that on Anna's wedding day, all Anna will wish for is her mother's presence. Jackie says her own fear is that Anna will forget her. Jackie explains to Isabel that, while Jackie will always have their past, Isabel will have their future.\\r\\n\\r\\nThe film ends with the family celebrating Christmas. Jackie, who is bedridden, is visited in her room by Ben and Anna. Individually, Jackie tells her children that though she will die, she will remain with them as long as they remember her. Later that day, Isabel is taking a family portrait of Luke and Jackie with the children. Jackie demonstrates her acceptance of Isabel by inviting her to join them, stating \\"let's get a photo with the whole family\\". Isabel does, and as the closing credits begin, both women are shown happily in a photo side by side, finally at peace with one another and with future events ahead of them (Jackie's death and Isabel's marriage to Luke).\\r\\n\\r\\nStepmom opened at No. 2 at the North American box office behind Patch Adams making $19.1 million USD in its opening weekend.[4] It stayed at the second spot for another week. The film grossed $91,137,662 in the US[5] and $159,710,793 worldwide[1] from a budget of $50 million.\\r\\n\\r\\nStepmom received mixed reviews from critics.[6] It earned a 44% rating on Rotten Tomatoes.[7]\\r\\n\\r\\nSusan Sarandon was nominated for the Golden Globe Award for Best Actress ÿ Motion Picture Drama and won the San Diego Film Critics Society Award for Best Actress. Ed Harris won the National Board of Review Award for Best Supporting Actor for his roles in Stepmom and The Truman Show.\\r\\n\\r\\nThe soundtrack to Stepmom was released on August 12, 1998 via Sony Classical label.\\r\\n\\r\\nKaran Johar decided to adapt Stepmom for the Indian audience. Although he initially intended to buy the rights to the film, he eventually opted to co-produce it with Sony Pictures.[9] The version titled We Are Family (2010) was released to mixed reviews and became an average grosser.[10][11]","input":"What type of cancer did susan sarandon have in stepmom?"},{"output":"Tyler Hubbard","context":"Florida Georgia Line (sometimes abbreviated as FGL) is an American country music duo consisting of vocalists Tyler Hubbard and Brian Kelley. Their 2012 debut single \\"Cruise\\", which remains their most popular song, broke two major sales records: it was downloaded over seven million times, making it the first country song ever to receive the Diamond certification, and it became the best-selling digital country song of all time, with 24 weeks at number one, until it was surpassed in July 2017 by Sam Hunt's \\"Body Like a Back Road\\".[4] \\"Cruise\\" helped to pioneer a style of country music known as \\"bro-country\\", which incorporates production elements from rock and hip-hop music, and tends to cover subject matter such as partying, drinking, driving trucks and romantic attraction.[5] Much of their subsequent music has been tagged with the \\"bro-country\\" label as well.[6]\\r\\n\\r\\nFlorida Georgia Line was formed in 2010 in Nashville, Tennessee[1] and began as a cover band. In December 2011, they signed to the Big Loud Mountain label.[7] Their second EP, It'z Just What We Do, was released in 2012 and charted on the Billboard Top Country Albums chart. Several months later they signed with Republic Nashville, part of the Big Machine Label Group.[8] They released their second album, Anything Goes on October 14, 2014. Their third album, Dig Your Roots, was released on August 26, 2016.\\r\\n\\r\\nBoth members of Florida Georgia Line first gained interest in music through church worship services. Brian Kelley, from Ormond Beach, Florida, was a star pitcher on his high school baseball team, leading to a scholarship at Florida State University; he later transferred to Belmont University after it became clear to him he would not succeed in the sport.[9] He began learning to play guitar then began writing music inspired by Christian rock group Casting Crowns.[10] Tyler Hubbard, a native of Monroe, Georgia, was a church worship leader who formed a hip hop group, Ingenious Circuit, in his teens. The two had a myriad of musical interests growing up: \\"Me and my friends drove trucks, listened to Garth Brooks, Alabama, Lil Wayne and Eminem,\\" said Kelley.[10]\\r\\n\\r\\nThe duo met at Belmont University in 2008 through a campus worship group, and following graduation, decided to give themselves two years to succeed as a country duo. They moved in with one another and began several odd jobs to pay bills, while playing clubs on the weekends.[9][11] While independent, they recorded and digitally distributed their first EP, Anything Like Me (2010).[9] They were discovered by Nickelback producer Joey Moi at a county fair, and the three began entering the studio together.[10] Unlike typical country music sessions, the group spent days polishing songs, which were collected on the duo's second EP, It'z Just What We Do (2012). In terms of production, the band modeled their sound on bands such as Nickelback, Shinedown, and Three Days Grace, while Moi aimed for each song to resemble hair metal group Def Leppard in structure.[10] Major labels became interested when the song \\"Cruise\\" first aired on satellite radio on  \\"The Highway\\" channel and began selling well on iTunes, leading to a deal with Republic Nashville and Big Machine Label Group.[10]\\r\\n\\r\\nKelley likes to think of his career not as a career, but as a lifestyle. \\"Country music is always evolving and will continue to evolve,\\" he told Forbes magazine.[12] In 2017, they featured in the song \\"Last Day Alive\\" by The Chainsmokers. They have also collaborated with Bebe Rexha on her song \\"Meant to Be\\".[citation needed]\\r\\n\\r\\nFlorida Georgia Line's first EP, released on December 14, 2010, is a six-song EP produced with Wesley Walker. All of the songs were written by either Hubbard or Hubbard and Kelley. The EP consists of the songs \\"You're Country\\", \\"Now That She's Gone\\", \\"Man I Am Today\\", \\"Never Let Her Go\\" (co-written with \\"Cruise\\" co-writer Chase Rice), \\"Black Tears\\", and \\"Backwoods Beauty Queen\\". The song \\"Black Tears\\" was also on Jason Aldean's 2012 album Night Train.[13]\\r\\n\\r\\nThe duo's second EP is a five-song EP produced by Joey Moi on Big Loud Mountain Records and released on May 15, 2012. It starts off with \\"Cruise\\" and also includes \\"Get Your Shine On\\", \\"Tip It Back\\", \\"Tell Me How You Like It\\", and the title track \\"It'z Just What We Do\\".[14]\\r\\n\\r\\nThe duo's first studio album, Here's to the Good Times, was an 11-song album produced by Joey Moi on Republic Nashville and released on December 4, 2012. The pair's first full-length, Here's to the Good Times, was the sixth-best-selling album of 2013 (topping Drake and Katy Perry, among others).[15] \\"Cruise\\", the first single, reached number one on the Country Airplay chart dated December 15, 2012.[16] A remix of \\"Cruise\\" featuring Nelly later hit number four on the US Billboard Hot 100. Florida Georgia Line's signature hit, \\"Cruise\\", holds one major record to date: the best-selling country digital song of all time, with sales surpassing 10 million. The song spent a record 24 weeks at number one on Billboard's Hot Country Songs chart, which was the longest reign in the history of the chart until July 2017 when it was surpassed by Sam Hunt's \\"Body Like a Back Road\\".\\r\\n\\r\\nThe album's second single, \\"Get Your Shine On\\", was released to country radio on January 21, 2013 and reached number one on the Country Airplay chart in May 2013. It was co-written by the duo along with Rodney Clawson and Chris Tompkins. \\"Round Here\\" was released as the album's third single on June 3, 2013 and reached number one on the Country Airplay chart in September 2013. The album's fourth single, \\"Stay\\", was released to country radio on October 7, 2013. It was co-written and originally recorded by Black Stone Cherry. It reached number one on the Hot Country Songs chart and the Country Airplay chart in December 2013.\\r\\n\\r\\nA deluxe edition of Here's to the Good Times titled Here's to the Good Times... This Is How We Roll was released on November 25, 2013.[17] \\"This Is How We Roll\\", a collaboration with Luke Bryan, was released from the deluxe edition as the album's fifth single on February 10, 2014 and reached number one on the Hot Country Songs chart in March 2014.\\r\\n\\r\\nFlorida Georgia Line toured the United States as part of the Dirt Road Diaries Tour with Thompson Square and headlining act Luke Bryan.[18]\\r\\n\\r\\nIn June 2013, the album reached number one on the Billboard Top Country Albums chart.[19] It stayed at the top spot for ten weeks.\\r\\n\\r\\nThe duo revealed on August 15, 2014, that their second studio album would be titled Anything Goes with a release date of October 14, 2014.[20] The album's first single, \\"Dirt\\", was released to country radio and digital sales outlets on July 8, 2014 and became the sixth consecutive single by Florida Georgia Line to make the top five on the Billboard Hot Country Songs chart. \\"Sun Daze\\" was released to digital sales outlets on September 16, 2014. A week later, the album's title track, \\"Anything Goes\\", was released on September 22, 2014. Florida Georgia Line also appeared on the Hot Tours recap.[21] \\"Confession\\" released to country radio on November 3, 2015 and reached number one on the Country Airplay chart in April 2016.\\r\\n\\r\\nIn 2016, Florida Georgia Line became the first and only country artist to receive the Digital Diamond Award, for their single \\"Cruise\\" crossing the 10G Platinum threshold.[22][23]\\r\\n\\r\\nThe duo released their third studio album Dig Your Roots on August 29, 2016, featuring Tim McGraw, Ziggy Marley, and the Backstreet Boys. They are currently on their Dig Your Roots tour, with Ryan Folles, Chris Lane, and Dustin Lynch.\\r\\n\\r\\nThey collaborated with Bebe Rexha on the song \\"Meant to Be\\" for her EP, All Your Fault: Pt. 2.\\r\\n\\r\\nAlong with Hank Williams Jr. and Jason Derulo, Florida Georgia Line sang \\"All My Rowdy Friends Are Here on Monday Night\\" for ESPN's Monday Night Football NFL broadcasts in 2017.\\r\\n\\r\\nThe duo released \\"Simple\\" to country radio on June 1, 2018.[24] Since then, they have released the preview tracks \\"Colorado,\\" \\"Talk You Out of It,\\" and \\"Sittin Pretty.\\"[25]\\r\\n\\r\\nIn July 2016, Florida Georgia Line came under fire when they banned law enforcement from being backstage   during their concerts in Wisconsin and Iowa[26] due to   police shootings in Dallas, Baton Rouge, and Falcon Heights.   The band later asked for a police escort leaving their concert, which was denied  by the music festival management team due to security concerns.[27] Following the incident, Brian Kelley called Kenosha County Sheriff David Beth and apologized, calling it a misunderstanding.[28] The duo issued a statement on Twitter that said, \\"we want you to know that we have nothing but love and respect for the police. We are bummed anyone ever got a different impression.\\"[29]\\r\\n\\r\\nOn December 16, 2013, Kelley married his girlfriend of seven months, Brittney Marie Cole. In February 2014, Hubbard sustained a back injury in a dirt bike accident.[30] On July 1, 2015, Tyler Hubbard married his longtime girlfriend Hayley Stommel.[31][32] In 2014, Kelley appeared on Animal Planet's Treehouse Masters.[33]\\r\\n\\r\\nOn December 23, 2017, Hubbard and his wife Hayley welcomed their first child together, daughter Olivia Rose Hubbard.[34]\\r\\n\\r\\nIn 2015, Forbes estimated that Florida Georgia Line's annual income was $36.5 million, split evenly between both men.[35]\\r\\n\\r\\nStudio albums\\r\\n\\r\\nHeadlining\\r\\n\\r\\nSupporting","input":"What are the names of florida georgia line?"},{"output":"2nd millennium BC","context":"Early study of triangles can be traced to the 2nd millennium BC, in Egyptian mathematics (Rhind Mathematical Papyrus) and Babylonian mathematics. Systematic study of trigonometric functions began in Hellenistic mathematics, reaching India as part of Hellenistic astronomy.[1] In Indian astronomy, the study of trigonometric functions flourished in the Gupta period, especially due to Aryabhata (sixth century CE). During the Middle Ages, the study of trigonometry continued in Islamic mathematics, hence it was adopted as a separate subject in the Latin West beginning in the Renaissance with Regiomontanus. The development of modern trigonometry shifted during the western Age of Enlightenment, beginning with 17th-century mathematics (Isaac Newton and James Stirling) and reaching its modern form with Leonhard Euler (1748).\\r\\n\\r\\n\\r\\nThe term \\"trigonometry\\" was derived from Greek ? trignon, \\"triangle\\" and ? metron, \\"measure\\".[2]\\r\\nThe modern word \\"sine\\" is derived from the Latin word sinus, which means \\"bay\\", \\"bosom\\" or \\"fold\\", translating Arabic jayb. The Arabic term is in origin a corruption of Sanskrit jؐv, or \\"chord\\". Sanskrit jؐv in learned usage was a synonym of jy \\"chord\\", originally the term for \\"bow-string\\". Sanskrit jؐv was rendered into Arabic as jiba.[3][4] This term was then transformed into the genuine Arabic word jayb,[4] meaning \\"bosom, fold, bay\\", either by the Arabs or by a mistake of the European translators such as Robert of Chester (perhaps because the words were written without vowels), who translated jayb into Latin as sinus.[3] Particularly Fibonacci's sinus rectus arcus proved influential in establishing the term sinus.[5] The words \\"minute\\" and \\"second\\" are derived from the Latin phrases partes minutae primae and partes minutae secundae.[6] These roughly translate to \\"first small parts\\" and \\"second small parts\\".\\r\\nThe ancient Egyptians and Babylonians had known of theorems on the ratios of the sides of similar triangles for many centuries. However, as pre-Hellenic societies lacked the concept of an angle measure, they were limited to studying the sides of triangles instead.[7]\\r\\nThe Babylonian astronomers kept detailed records on the rising and setting of stars, the motion of the planets, and the solar and lunar eclipses, all of which required familiarity with angular distances measured on the celestial sphere.[4] Based on one interpretation of the Plimpton 322 cuneiform tablet (c. 1900 BC), some have even asserted that the ancient Babylonians had a table of secants.[8] There is, however, much debate as to whether it is a table of Pythagorean triples, a solution of quadratic equations, or a trigonometric table.\\r\\nThe Egyptians, on the other hand, used a primitive form of trigonometry for building pyramids in the 2nd millennium BC.[4] The Rhind Mathematical Papyrus, written by the Egyptian scribe Ahmes (c. 1680ÿ1620 BC), contains the following problem related to trigonometry:[4]\\r\\n\\"If a pyramid is 250 cubits high and the side of its base 360 cubits long, what is its seked?\\"\\r\\nAhmes' solution to the problem is the ratio of half the side of the base of the pyramid to its height, or the run-to-rise ratio of its face. In other words, the quantity he found for the seked is the cotangent of the angle to the base of the pyramid and its face.[4]\\r\\nAncient Greek and Hellenistic mathematicians made use of the chord. Given a circle and an arc on the circle, the chord is the line that subtends the arc. A chord's perpendicular bisector passes through the center of the circle and bisects the angle. One half of the bisected chord is the sine of one half the bisected angle, that is,\\r\\nand consequently the sine function is also known as the half-chord. Due to this relationship, a number of trigonometric identities and theorems that are known today were also known to Hellenistic mathematicians, but in their equivalent chord form.[9]\\r\\nAlthough there is no trigonometry in the works of Euclid and Archimedes, in the strict sense of the word, there are theorems presented in a geometric way (rather than a trigonometric way) that are equivalent to specific trigonometric laws or formulas.[7] For instance, propositions twelve and thirteen of book two of the Elements are the laws of cosines for obtuse and acute angles, respectively. Theorems on the lengths of chords are applications of the law of sines. And Archimedes' theorem on broken chords is equivalent to formulas for sines of sums and differences of angles.[7] To compensate for the lack of a table of chords, mathematicians of Aristarchus' time would sometimes use the statement that, in modern notation, sin?ϫ/sin??<?ϫ/?<?tan?ϫ/tan? whenever 0?<??<?ϫ?<?90, now known as Aristarchus's inequality.[10]\\r\\nThe first trigonometric table was apparently compiled by Hipparchus of Nicaea (180 ÿ 125 BCE), who is now consequently known as \\"the father of trigonometry.\\"[11] Hipparchus was the first to tabulate the corresponding values of arc and chord for a series of angles.[5][11]\\r\\nAlthough it is not known when the systematic use of the 360 circle came into mathematics, it is known that the systematic introduction of the 360 circle came a little after Aristarchus of Samos composed On the Sizes and Distances of the Sun and Moon (ca. 260 BC), since he measured an angle in terms of a fraction of a quadrant.[10] It seems that the systematic use of the 360 circle is largely due to Hipparchus and his table of chords. Hipparchus may have taken the idea of this division from Hypsicles who had earlier divided the day into 360 parts, a division of the day that may have been suggested by Babylonian astronomy.[12] In ancient astronomy, the zodiac had been divided into twelve \\"signs\\" or thirty-six \\"decans\\". A seasonal cycle of roughly 360 days could have corresponded to the signs and decans of the zodiac by dividing each sign into thirty parts and each decan into ten parts.[6] It is due to the Babylonian sexagesimal numeral system that each degree is divided into sixty minutes and each minute is divided into sixty seconds.[6]\\r\\nMenelaus of Alexandria (ca. 100 AD) wrote in three books his Sphaerica. In Book I, he established a basis for spherical triangles analogous to the Euclidean basis for plane triangles.[9] He establishes a theorem that is without Euclidean analogue, that two spherical triangles are congruent if corresponding angles are equal, but he did not distinguish between congruent and symmetric spherical triangles.[9] Another theorem that he establishes is that the sum of the angles of a spherical triangle is greater than 180.[9] Book II of Sphaerica applies spherical geometry to astronomy. And Book III contains the \\"theorem of Menelaus\\".[9] He further gave his famous \\"rule of six quantities\\".[13]\\r\\nLater, Claudius Ptolemy (ca. 90 ÿ ca. 168 AD) expanded upon Hipparchus' Chords in a Circle in his Almagest, or the Mathematical Syntaxis. The Almagest is primarily a work on astronomy, and astronomy relies on trigonometry. Ptolemy's table of chords gives the lengths of chords of a circle of diameter 120 as a function of the number of degrees?n in the corresponding arc of the circle, for n ranging from 1/2 to 180 by increments of?1/2.[14] The thirteen books of the Almagest are the most influential and significant trigonometric work of all antiquity.[15] A theorem that was central to Ptolemy's calculation of chords was what is still known today as Ptolemy's theorem, that the sum of the products of the opposite sides of a cyclic quadrilateral is equal to the product of the diagonals. A special case of Ptolemy's theorem appeared as proposition 93 in Euclid's Data. Ptolemy's theorem leads to the equivalent of the four sum-and-difference formulas for sine and cosine that are today known as Ptolemy's formulas, although Ptolemy himself used chords instead of sine and cosine.[15] Ptolemy further derived the equivalent of the half-angle formula\\r\\nPtolemy used these results to create his trigonometric tables, but whether these tables were derived from Hipparchus' work cannot be determined.[15]\\r\\nNeither the tables of Hipparchus nor those of Ptolemy have survived to the present day, although descriptions by other ancient authors leave little doubt that they once existed.[16]\\r\\nSome of the early and very significant developments of trigonometry were in India. Influential works from the 4thÿ5th century, known as the Siddhantas (of which there were five, the most important of which is the Surya Siddhanta[17]) first defined the sine as the modern relationship between half an angle and half a chord, while also defining the cosine, versine, and inverse sine.[18] Soon afterwards, another Indian mathematician and astronomer, Aryabhata (476ÿ550 AD), collected and expanded upon the developments of the Siddhantas in an important work called the Aryabhatiya.[19] The Siddhantas and the Aryabhatiya contain the earliest surviving tables of sine values and versine (1???cosine) values, in 3.75 intervals from 0 to 90, to an accuracy of 4 decimal places.[20] They used the words jya for sine, kojya for cosine, utkrama-jya for versine, and otkram jya for inverse sine. The words jya and kojya eventually became sine and cosine respectively after a mistranslation described above.\\r\\nIn the 7th century, Bhaskara the First produced a formula for calculating the sine of an acute angle without the use of a table. He also gave the following approximation formula for sin(x), which had a relative error of less than?1.9%:\\r\\nLater in the 7th century, Brahmagupta redeveloped the formula\\r\\n(also derived earlier, as mentioned above) and the Brahmagupta interpolation formula for computing sine values.[21]\\r\\nMadhava (c. 1400) made early strides in the analysis of trigonometric functions and their infinite series expansions. He developed the concepts of the power series and Taylor series, and produced the power series expansions of sine, cosine, tangent, and arctangent.[22][23] Using the Taylor series approximations of sine and cosine, he produced a sine table to 12 decimal places of accuracy and a cosine table to 9 decimal places of accuracy. He also gave the power series of  and the Ĳ, radius, diameter, and circumference of a circle in terms of trigonometric functions. His works were expanded by his followers at the Kerala School up to the 16th century.[22][23]\\r\\nThe Indian text the Yuktibh? contains proof for the expansion of the sine and cosine functions and the derivation and proof of the power series for inverse tangent, discovered by Madhava. The Yuktibh? also contains rules for finding the sines and the cosines of the sum and difference of two angles.\\r\\nThe Indian works were later translated and expanded in the medieval Islamic world by Muslim mathematicians of mostly Persian and Arab descent, who enunciated a large number of theorems which freed the subject of trigonometry from dependence upon the complete quadrilateral, as was the case in Hellenistic mathematics due to the application of Menelaus' theorem. According to E. S. Kennedy, it was after this development in Islamic mathematics that \\"the first real trigonometry emerged, in the sense that only then did the object of study become the spherical or plane triangle, its sides and angles.\\"[25]\\r\\nIn addition to Indian works, Hellenistic methods dealing with spherical triangles were also known, particularly the method of Menelaus of Alexandria, who developed \\"Menelaus' theorem\\" to deal with spherical problems.[9][26] However, E. S. Kennedy points out that while it was possible in pre-Islamic mathematics to compute the magnitudes of a spherical figure, in principle, by use of the table of chords and Menelaus' theorem, the application of the theorem to spherical problems was very difficult in practice.[27] In order to observe holy days on the Islamic calendar in which timings were determined by phases of the moon, astronomers initially used Menelaus' method to calculate the place of the moon and stars, though this method proved to be clumsy and difficult. It involved setting up two intersecting right triangles; by applying Menelaus' theorem it was possible to solve one of the six sides, but only if the other five sides were known. To tell the time from the sun's altitude, for instance, repeated applications of Menelaus' theorem were required. For medieval Islamic astronomers, there was an obvious challenge to find a simpler trigonometric method.[28]\\r\\nIn the early 9th century AD, Muhammad ibn Ms al-Khwrizmؐ produced accurate sine and cosine tables, and the first table of tangents. He was also a pioneer in spherical trigonometry. In 830 AD, Habash al-Hasib al-Marwazi produced the first table of cotangents.[29][30] Muhammad ibn Jbir al-Harrnؐ al-Battnؐ (Albatenius) (853-929 AD) discovered the reciprocal functions of secant and cosecant, and produced the first table of cosecants for each degree from 1 to 90.[30]\\r\\nBy the 10th century AD, in the work of Ab al-Waf' al-Bzjnؐ, Muslim mathematicians were using all six trigonometric functions.[31] Abu al-Wafa had sine tables in 0.25 increments, to 8 decimal places of accuracy, and accurate tables of tangent values.[31] He also developed the following trigonometric formula:[32]\\r\\nIn his original text, Ab al-Waf' states: \\"If we want that, we multiply the given sine by the cosine minutes, and the result is half the sine of the double\\".[32] Ab al-Waf also established the angle addition and difference identities presented with complete proofs:[32]\\r\\nFor the second one, the text states: \\"We multiply the sine of each of the two arcs by the cosine of the other minutes. If we want the sine of the sum, we add the products, if we want the sine of the difference, we take their difference\\".[32]\\r\\nHe also discovered the law of sines for spherical trigonometry:[29]\\r\\nAlso in the late 10th and early 11th centuries AD, the Egyptian astronomer Ibn Yunus performed many careful trigonometric calculations and demonstrated the following trigonometric identity:[33]\\r\\nAl-Jayyani (989ÿ1079) of al-Andalus wrote The book of unknown arcs of a sphere, which is considered \\"the first treatise on spherical trigonometry\\".[34] It \\"contains formulae for right-handed triangles, the general law of sines, and the solution of a spherical triangle by means of the polar triangle.\\" This treatise later had a \\"strong influence on European mathematics\\", and his \\"definition of ratios as numbers\\" and \\"method of solving a spherical triangle when all sides are unknown\\" are likely to have influenced Regiomontanus.[34]\\r\\nThe method of triangulation was first developed by Muslim mathematicians, who applied it to practical uses such as surveying[35] and Islamic geography, as described by Abu Rayhan Biruni in the early 11th century. Biruni himself introduced triangulation techniques to measure the size of the Earth and the distances between various places.[36] In the late 11th century, Omar Khayym (1048ÿ1131) solved cubic equations using approximate numerical solutions found by interpolation in trigonometric tables. In the 13th century, Nasؐr al-Dؐn al-Tsؐ was the first to treat trigonometry as a mathematical discipline independent from astronomy, and he developed spherical trigonometry into its present form.[30] He listed the six distinct cases of a right-angled triangle in spherical trigonometry, and in his On the Sector Figure, he stated the law of sines for plane and spherical triangles, discovered the law of tangents for spherical triangles, and provided proofs for both these laws.[37]\\r\\nIn the 15th century, Jamshؐd al-Kshؐ provided the first explicit statement of the law of cosines in a form suitable for triangulation.[citation needed] In France, the law of cosines is still referred to as the theorem of Al-Kashi. He also gave trigonometric tables of values of the sine function to four sexagesimal digits (equivalent to 8 decimal places) for each 1 of argument with differences to be added for each 1/60 of?1.[citation needed] Ulugh Beg also gives accurate tables of sines and tangents correct to 8 decimal places around the same time.[citation needed]\\r\\nIn China, Aryabhata's table of sines were translated into the Chinese mathematical book of the Kaiyuan Zhanjing, compiled in 718 AD during the Tang Dynasty.[38] Although the Chinese excelled in other fields of mathematics such as solid geometry, binomial theorem, and complex algebraic formulas, early forms of trigonometry were not as widely appreciated as in the earlier Greek, Hellenistic, Indian and Islamic worlds.[39] Instead, the early Chinese used an empirical substitute known as chong cha, while practical use of plane trigonometry in using the sine, the tangent, and the secant were known.[38] However, this embryonic state of trigonometry in China slowly began to change and advance during the Song Dynasty (960ÿ1279), where Chinese mathematicians began to express greater emphasis for the need of spherical trigonometry in calendrical science and astronomical calculations.[38] The polymath Chinese scientist, mathematician and official Shen Kuo (1031ÿ1095) used trigonometric functions to solve mathematical problems of chords and arcs.[38] Victor J. Katz writes that in Shen's formula \\"technique of intersecting circles\\", he created an approximation of the arc?s of a circle given the diameter?d, sagitta?v, and length?c of the chord subtending the arc, the length of which he approximated as[40]\\r\\nSal Restivo writes that Shen's work in the lengths of arcs of circles provided the basis for spherical trigonometry developed in the 13th century by the mathematician and astronomer Guo Shoujing (1231ÿ1316).[41] As the historians L. Gauchet and Joseph Needham state, Guo Shoujing used spherical trigonometry in his calculations to improve the calendar system and Chinese astronomy.[38][42] Along with a later 17th-century Chinese illustration of Guo's mathematical proofs, Needham states that:\\r\\nGuo used a quadrangular spherical pyramid, the basal quadrilateral of which consisted of one equatorial and one ecliptic arc, together with two meridian arcs, one of which passed through the summer solstice point...By such methods he was able to obtain the du l (degrees of equator corresponding to degrees of ecliptic), the ji cha (values of chords for given ecliptic arcs), and the cha l (difference between chords of arcs differing by 1 degree).[43]\\r\\nDespite the achievements of Shen and Guo's work in trigonometry, another substantial work in Chinese trigonometry would not be published again until 1607, with the dual publication of Euclid's Elements by Chinese official and astronomer Xu Guangqi (1562ÿ1633) and the Italian Jesuit Matteo Ricci (1552ÿ1610).[44]\\r\\nIn 1342, Levi ben Gershon, known as Gersonides, wrote On Sines, Chords and Arcs, in particular proving the sine law for plane triangles and giving five-figure sine tables.[45]\\r\\nA simplified trigonometric table, the \\"toleta de marteloio\\", was used by sailors in the Mediterranean Sea during the 14th-15th Centuries to calculate navigation courses. It is described by Ramon Llull of Majorca in 1295, and laid out in the 1436 atlas of Venetian captain Andrea Bianco.\\r\\nRegiomontanus was perhaps the first mathematician in Europe to treat trigonometry as a distinct mathematical discipline,[46] in his De triangulis omnimodis written in 1464, as well as his later Tabulae directionum which included the tangent function, unnamed.\\r\\nThe Opus palatinum de triangulis of Georg Joachim Rheticus, a student of Copernicus, was probably the first in Europe to define trigonometric functions directly in terms of right triangles instead of circles, with tables for all six trigonometric functions; this work was finished by Rheticus' student Valentin Otho in 1596.\\r\\nIn the 17th century, Isaac Newton and James Stirling developed the general NewtonÿStirling interpolation formula for trigonometric functions.\\r\\nIn the 18th century, Leonhard Euler's Introductio in analysin infinitorum (1748) was mostly responsible for establishing the analytic treatment of trigonometric functions in Europe, deriving their infinite series and presenting \\"Euler's formula\\"?eix?=?cos?x?+?i?sin?x. Euler used the near-modern abbreviations sin., cos., tang., cot., sec., and cosec. Prior to this, Roger Cotes had computed the derivative of sine in his Harmonia Mensurarum (1722).[47] Also in the 18th century, Brook Taylor defined the general Taylor series and gave the series expansions and approximations for all six trigonometric functions. The works of James Gregory in the 17th century and Colin Maclaurin in the 18th century were also very influential in the development of trigonometric series.","input":"When was trigonometry first thought to be used?"},{"output":"end of March 1949","context":"The Lion, the Witch and the Wardrobe is a fantasy novel for children by C. S. Lewis, and illustrators Pauline Baynes, Chris Van Allsburg in 1978, and Leo and Diane Dillon in 1994, published by Geoffrey Bles in 1950. It is the first published and best known of seven novels in The Chronicles of Narnia (1950ÿ1956). Among all the author's books it is also the most widely held in libraries.[2] Although it was written as well as published first in the series, it is volume two in recent editions, which are sequenced by the stories' chronology (the first being The Magician's Nephew). Like the others, it was illustrated by Pauline Baynes, and her work has been retained in many later editions.[1][3]\\r\\nMost of the novel is set in Narnia, a land of talking animals and mythical creatures that one White Witch has ruled for 100 years of deep winter. In the frame story, four English children are relocated to a large, old country house following a wartime evacuation. The youngest visits Narnia three times via the magic of a wardrobe in a spare room. All four children are together on her third visit, which verifies her fantastic claims and comprises the subsequent 12 of 17 chapters except for a brief conclusion. In Narnia, the siblings seem fit to fulfill an old prophecy and so are soon adventuring both to save Narnia and their lives. Lewis wrote the book for, and dedicated it to, his goddaughter Lucy Barfield. She was the daughter of Owen Barfield, Lewis's friend, teacher, adviser, and trustee.[4]\\r\\n\\r\\n\\r\\nIn 1940, four siblings ÿ Peter, Susan, Edmund, and Lucy Pevensie ÿ are among many children evacuated from London during World War II to escape the Blitz. They are sent to the countryside to live with professor Digory Kirke. Exploring the professor's house, Lucy finds a wardrobe which doubles as a magic portal to a forest in a land called Narnia. At a lamppost oddly located in the forest, she meets Tumnus, a faun, who invites her to tea in his home. There the faun confesses that he invited her not out of hospitality, but with the intention of betraying her to the White Witch. The witch has ruled Narnia for years, using magic to keep it frozen in a perpetual winter. She has ordered all Narnians to turn in any humans (\\"Sons of Adam\\" or \\"Daughters of Eve\\") they come across. But now that he has come to know and like a human, Tumnus repents his original intention and escorts Lucy back to the lamppost.\\r\\nLucy returns through the wardrobe and finds that only a few seconds have passed in normal time during her absence. Her siblings do not believe her story about another world inside the wardrobe, which is now found to have a solid back panel.\\r\\nDuring a game of hide-and-seek on some days later, Lucy again passes into Narnia. This time her brother Edmund chances to follow her. He meets Jadis, who calls herself Queen of Narnia. When she learns that he is human and has two sisters and a brother, she places an enchantment on him. She urges him to bring his siblings to her castle, promising in return to make him her heir. When Lucy and Edmund return together through the wardrobe, Edmund realizes that the queen he met and the witch Lucy describes are one and the same. He denies to the others that he has been in Narnia at all. Peter and Susan are puzzled by Lucy's insistence, and consult the Professor, who surprises them by taking Lucy's side in the debate of Narnia's existence.\\r\\nSoon afterward, all four children enter Narnia together after hiding in the wardrobe to avoid the professor's dour housekeeper, Mrs. Macready. Remembering the winter cold ahead, they take coats from the wardrobe before exploring. Lucy guides them to Tumnus's cave, but they find it ransacked, with a notice from Jadis (the White Witch) proclaiming his arrest for harbouring humans.\\r\\nA talking beaver intercepts them, proves himself a friend, and hides the children in his den. There, he and Mrs. Beaver tell them of a prophecy that Jadis's power will fail when two Sons of Adam and two Daughters of Eve fill the four thrones at Cair Paravel. Aslan, the great lion and the rightful King, has been absent for many years but is now \\"on the move again\\" in Narnia.\\r\\nEdmund steals away to Jadis's castle, which is filled with statues of Narnian victims she has turned to stone. Jadis is furious when Edmund appears alone and angrier still to learn that Aslan may have returned. She takes him on her sledge to catch the others or to reach Aslan's court before them.\\r\\nMeanwhile, Mr Beaver realises that Edmund has betrayed them, and they set off at once to seek Aslan at the Stone Table. As they travel, the Witch's spell over Narnia begins to break: Father Christmas (who has not been seen in Narnia for a hundred years) arrives with magical presents: a sword for Peter, a horn and a bow with arrows for Susan, a knife and a bottle of healing cordial for Lucy. The snow melts, and winter ends. Aslan welcomes the children and the Beavers to his camp near the Stone Table. Upon hearing Edmund's situation, he orders a rescue party of loyal Narnians.\\r\\nAfter much hardship at the hands of the Witch and her sledge driver, Edmund is rescued from their camp and reunited with his siblings. Jadis approaches in truce to parley with Aslan. She insists that, according to \\"deep magic from the dawn of time\\", she holds the right to kill Edmund following his treason. Aslan bargains with her privately and she renounces her claim.\\r\\nThat evening, Aslan secretly returns to the Stone Table, shadowed by Susan and Lucy. Upon noticing them, Aslan welcomes their company but warns them not to interfere with what is about to happen. He has traded his own life to the witch for Edmund's, and the girls watch as Jadis oversees his shaming before her underlings. She orders Aslan tied to the Stone Table, shaved and muzzled; and she administers the killing blow herself.\\r\\nConfident now of victory, the Witch leads her army away to battle. Susan and Lucy remain weeping over Aslan's abandoned body. They un-muzzle him and see mice gnaw away his bonds. The Stone Table breaks and Aslan is restored to life. He tells Lucy and Susan that Jadis was unaware of the \\"deeper magic from before the dawn of time\\" that will resurrect an innocent killed in place of a traitor.\\r\\nAslan carries Lucy and Susan on his back as he hurries to Jadis's castle. He breathes upon the stone statues in the courtyard, restoring them to life.\\r\\nMeanwhile, Peter and Edmund lead the Narnians against Jadis, and Edmund is seriously wounded. Aslan arrives with the former statues as reinforcements. The Narnians rout Jadis's supporters, and Aslan kills Jadis. Aslan breathes life into those Jadis has turned to stone on the battlefield, and Lucy uses her magic cordial to revive the wounded, starting with Edmund. The Pevensie children are crowned kings and queens of Narnia at Cair Paravel. Soon afterward, Aslan slips away and disappears.\\r\\nFifteen years later, the four rulers chase a wish-granting white stag through the forest whereupon they rediscover the lamppost. They soon find their way not through branches but coats. They come back through the wardrobe in the Professor's house and are suddenly children again, dressed in their old clothes. Almost no time has passed in the real world, despite their many years in Narnia.\\r\\nThe four children consult the Professor. He forgives them the absence of the four coats they stole, and hints that theirs would prove not to be the first adventure in Narnia, nor by any means the last.\\r\\nThe Pevensie Siblings\\r\\nRaised in London, evacuated to the Dorset countryside, and reaching adulthood in Narnia, they are the four main characters. In one chapter, Father Christmas arrives to endow those present (three Pevensies and two beavers) with a feast, weapons, and magical items. After the restoration of Narnia, a Tetrarchy is established with the four siblings as the rulers.\\r\\nAt the Country Home\\r\\nThe house that shelters the Pevensie children is run by a Professor, staffed by servants, and frequently toured by historians.\\r\\nNarnians\\r\\nThe magical land of Narnia is populated by talking animals, mythological species, and sentient flora.\\r\\nLewis described the origin of The Lion, the Witch and the Wardrobe in an essay titled \\"It All Began with a Picture\\":[6]\\r\\nThe Lion all began with a picture of a Faun carrying an umbrella and parcels in a snowy wood. This picture had been in my mind since I was about sixteen. Then one day, when I was about forty, I said to myself: 'Let's try to make a story about it.'\\r\\nShortly before the Second World War many children were evacuated from London to the English countryside to escape bomber attacks on London by Nazi Germany. On 2 September 1939 three school girls, Margaret, Mary and Katherine,[7][8] came to live at The Kilns in Risinghurst, Lewis's home three miles east of Oxford city centre. Lewis later suggested that the experience gave him a new appreciation of children and in late September[9] he began a children's story on an odd sheet that has survived as part of another manuscript:\\r\\nThis book is about four children whose names were Ann, Martin, Rose and Peter. But it is most about Peter who was the youngest. They all had to go away from London suddenly because of Air Raids, and because Father, who was in the Army, had gone off to the War and Mother was doing some kind of war work. They were sent to stay with a kind of relation of Mother's who was a very old professor who lived all by himself in the country.[10]\\r\\nThe plot element of entering a new world through the back of a wardrobe had certainly entered Lewis's mind by 1946, when he used it to describe his first encounter with really good poetry:\\r\\nI did not in the least feel that I was getting in more quantity or better quality a pleasure I had already known. It was more as if a cupboard which one had hitherto valued as a place for hanging coats proved one day, when you opened the door, to lead to the garden of the Hesperides?...[11]\\r\\nHow much more of the story Lewis then wrote is uncertain. Roger Lancelyn Green thinks that he might even have completed it. In September 1947 Lewis wrote in a letter about stories for children: \\"I have tried one myself but it was, by the unanimous verdict of my friends, so bad that I destroyed it.\\"[12]\\r\\nIn August 1948, during a visit by an American writer, Chad Walsh, Lewis talked vaguely about completing a children's book he had begun \\"in the tradition of E. Nesbit\\".[13] After this conversation not much happened until the beginning of the next year. Then everything changed. In his essay \\"It All Began With a Picture\\" Lewis continues: \\"At first I had very little idea how the story would go. But then suddenly Aslan came bounding into it. I think I had been having a good many dreams of lions about that time. Apart from that, I don't know where the Lion came from or why he came. But once he was there, he pulled the whole story together, and soon he pulled the six other Narnian stories in after him.\\"[14]\\r\\nThe major ideas of the book echo lines Lewis had written fourteen years earlier in his alliterative poem The Planets:\\r\\n...?Of wrath ended\\r\\nAnd woes mended, of winter passed\\r\\nAnd guilt forgiven, and good fortune\\r\\nJove is master; and of jocund revel,\\r\\nLaughter of ladies. The lion-hearted\\r\\n...?are Jove's children.[15]\\r\\nOn 10 March 1949 Roger Lancelyn Green dined with Lewis at Magdalen College. After the meal Lewis read two chapters from his new children's story to Green. Lewis asked Green's opinion of the tale and Green said that he thought it was good. The manuscript of The Lion, the Witch and the Wardrobe was complete by the end of March 1949. Lucy Barfield received it by the end of May.[16] When on 16 October 1950 Geoffrey Bles in London published the first edition, three new \\"chronicles\\", Prince Caspian, The Voyage of the Dawn Treader and The Horse and His Boy, had also been completed.\\r\\nLewis's publisher, Geoffrey Bles, allowed him to choose the illustrator for the novel and the Narnia series. Lewis chose Pauline Baynes, possibly based on J. R. R. Tolkiens recommendation. Baynes had greatly impressed Tolkien with her illustrations for his Farmer Giles of Ham (1949). However, Baynes claimed that Lewis learned about her work after going into a bookshop and asking for a recommendation for an illustrator who was skilled at portraying both humans and animals. In December 1949, Bles showed Lewis the first drawings for the novel, and Lewis sent Baynes a note congratulating her, particularly on the level of detail. Lewiss appreciation of the illustrations is evident in a letter he wrote to Baynes after The Last Battle won the Carnegie Medal for best childrens book of 1956: \\"is it not rather 'our' medal? Im sure the illustrations were taken into account as well as the text\\".[17]\\r\\nThe British edition of the novel had 43 illustrations; American editions generally had fewer. The popular United States paperback edition published by Collier between 1970 and 1994, which sold many millions, had only 17 illustrations, many of them severely cropped from the originals, giving many readers in that country a very different experience when reading the novel. All the illustrations were restored for the 1994 worldwide HarperCollins edition, although these lacked the clarity of early printings.[18]\\r\\nLewis very much enjoyed writing The Lion, the Witch and the Wardrobe and embarked on the sequel Prince Caspian soon after finishing the first novel. He completed the sequel by end of 1949, less than a year after finishing the initial book. The Lion, the Witch and the Wardrobe had few readers during 1949 and was not published until late in 1950, so his initial enthusiasm did not stem from favourable reception by the public.[19]\\r\\nWhile Lewis is known today on the strength of the Narnia stories as a highly successful childrens writer, the initial critical response was muted. At the time it was fashionable for children's stories to be realistic; fantasy and fairy tales were seen as indulgent, appropriate only for very young readers and potentially harmful to older children, even hindering their ability to relate to everyday life. Some reviewers considered the tale overtly moralistic or the Christian elements over-stated  attempts to indoctrinate children. Others were concerned that the many violent incidents might frighten children.[20]\\r\\nLewis's publisher, Geoffrey Bles, feared that the Narnia tales would not sell, and might damage Lewis reputation and affect sales of his other books. Nevertheless, the novel and its successors were highly popular with young readers, and Lewis's publisher was soon eager to release further Narnia stories.[21]\\r\\nIn the United States a 2004 study found that The Lion was a common read-aloud book for seventh-graders in schools in San Diego County, California.[22] In 2005 it was included on TIME's unranked list of the 100 best English-language novels published since 1923.[23] Based on a 2007 online poll, the U.S. National Education Association named it one of \\"Teachers' Top 100 Books for Children\\".[24] In 2012 it was ranked number five among all-time children's novels in a survey published by School Library Journal, a monthly with primarily U.S. audience.[25]\\r\\nA 2012 survey by the University of Worcester determined that it was the second most common book that UK adults had read as children, after Alice's Adventures in Wonderland. (Adults, perhaps limited to parents, ranked Alice and The Lion fifth and sixth as books the next generation should read, or their children should read during their lifetimes.)[26]\\r\\nTIME magazine included the novel in its \\"All-TIME 100 Novels\\" (best English-language novels from 1923 to 2005).[23] In 2003, the novel was listed at number 9 on the BBC's survey The Big Read.[27] It has also been published in 47 foreign languages.[28]\\r\\nLewis wrote that \\"The Narnian books are not as much allegory as supposal. Suppose there were a Narnian world and it, like ours, needed redemption. What kind of incarnation and Passion might Christ be supposed to undergo there?\\"[29]\\r\\nThe main story is an allegory of Christ's crucifixion:[30][31] Aslan sacrifices himself for Edmund, a traitor who may deserve death, in the same way that Christians believe Jesus sacrificed himself for sinners. Aslan is killed on the Stone Table, symbolizing Mosaic Law, which breaks when he is resurrected, symbolizing the replacement of the strict justice of Old Testament law with redeeming grace and forgiveness granted on the basis of substitutional atonement, according to Christian theology.[32] As with the Christian Passion, it is women (Susan and Lucy) who tend Aslan's body after he dies and are the first to see him after his resurrection. The significance of the death contains elements of both the ransom theory of atonement and the satisfaction theory: Aslan suffers Edmund's penalty (satisfaction), and buys him back from the White Witch, who was entitled to him by reason of his treachery (ransom). In Christian belief, Christ is associated with the Biblical \\"Lion of Judah\\" of Revelation 5:5.\\r\\nProfessor Kirke is based on W.T. Kirkpatrick, who tutored a 16-year-old Lewis. \\"Kirk,\\" as he was sometimes called, taught the young Lewis much about thinking and communicating clearly, skills that would be invaluable to him later.[33]\\r\\nNarnia is caught in endless winter that has lasted a century when the children first enter. Norse tradition mythologises a \\"great winter,\\" known as the Fimbulwinter, said to precede Ragnar?k. The trapping of Edmund by the White Witch is reminiscent of the seduction and imprisonment of Kay by The Snow Queen in Hans Christian Andersen's novella of that name.[34]\\r\\nThe dwarves and giants are found in Norse mythology; fauns, centaurs, minotaurs and dryads derive from Greek mythology. Father Christmas, of course, was part of popular English folklore.\\r\\nThere are several parallels between the White Witch and the immortal white queen, Ayesha, of H. Rider Haggard's She, a novel greatly admired by C.S. Lewis.[35]\\r\\nThe Story of the Amulet written by Edith Nesbit also contains scenes that can be considered precursors to sequences presenting Jadis, particularly in The Magician's Nephew.[36] Nesbit's short story The Aunt and Amabel includes the motif of a girl entering a wardrobe to gain access to a magical place.[37]\\r\\nThe freeing of Aslan's body from the stone table by field mice is reminiscent of Aesop's fable of \\"The Lion and the Mouse.\\" In the fable, a lion catches a mouse, but the mouse persuades the lion to release him, promising that the favor would be rewarded. Later in the story, he gnaws through the lion's bonds after he has been captured by hunters. It is also reminiscent of a scene from Edgar Allan Poe's story \\"The Pit and the Pendulum,\\" in which a prisoner is freed when rats gnaw through his bonds.[38] In a later book, \\"Prince Caspian,\\" we learn that as reward for their actions, mice gained the same intelligence and speech as other Narnian animals.[39]\\r\\nDue to labor union rules,[40] the text of The Lion, the Witch and the Wardrobe was reset for the publication of the first American edition of by Macmillan US in 1950.[1] Lewis took that opportunity to make the following changes to the original British edition published by Geoffrey Bles[3] earlier that same year:\\r\\nWhen HarperCollins took over publication of the series in 1994, they began using the original British edition for all subsequent English editions worldwide.[46] The current US edition published by Scholastic has 36,135 words.[47]\\r\\nThe story has been adapted three times for television. The first adaptation was a ten-part serial produced by ABC Weekend Television for ITV and broadcast in 1967. In 1979, an animated TV-movie,[48] directed by Peanuts director Bill Melndez, was broadcast and won the first Emmy Award for Outstanding Animated Program. A third television adaptation was produced in 1988 by the BBC using a combination of live actors, animatronic puppets and animation. Only this last one was the first of a series of 3 Narnia adaptations. The programme was nominated for an Emmy and won a BAFTA. It was followed by three further Narnia adaptations.\\r\\nStage adaptations include a 1984 version staged at London's Westminster Theatre, produced by Vanessa Ford Productions. The play, adapted by Glyn Robbins, was directed by Richard Williams and designed by Marty Flood.[49] Jules Tasca, Ted Drachman, and Thomas Tierney collaborated on a musical adaptation published in 1986.[50]\\r\\nIn 1997, Trumpets Inc., a Filipino Christian theatre and musical production company, produced a musical rendition that Douglas Gresham, Lewis's stepson (and co-producer of the Walden Media film adaptations), has openly declared that he feels is the closest to Lewis's intention.[51][52][53] It starred among others popular young Filipino singer Sam Concepcion as Edmund Pevensie.[54] The book and lyrics were written by Jaime del Mundo and Luna Inocian, while music was composed by Lito Villareal.\\r\\nIn 1998, the Royal Shakespeare Company did an adaptation by Adrian Mitchell, for which the acting edition has been published.[55] The Stratford Festival in Canada mounted a new production of Mitchell's work in June 2016. [2] [3]\\r\\nIn 2003, there was an Australian commercial stage production which toured the country by Malcolm C. Cooke Productions, using both life-size puppets and human actors. It was directed by notable film director Nadia Tass, and starred Amanda Muggleton, Dennis Olsen, Meaghan Davies and Yolande Brown.[56][57]\\r\\nIn 2011, a two-actor stage adaptation by Le Clanch du Rand opened Off-Broadway in New York City at St. Luke's Theatre. The production was directed by Julia Beardsley O'Brien and starred Erin Layton and Andrew Fortman.[58] As of 2014, the production is currently running with a replacement cast of Abigail Taylor-Sansom and Rockford Sansom.[59]\\r\\nIn 2016, the Stratford Festival presented a dramatization by Adrian Mitchell, directed by Tim Carroll.[60]\\r\\nMultiple audio editions have been released, both straightforward readings and dramatizations.\\r\\nIn 1981, Michael Hordern read abridged versions of the classic tale (and the others in the series). In 2000, an unabridged audio book was released, narrated by Michael York. (All the books were released in audio form, read by different actors.)\\r\\nIn 1988, BBC Radio 4 mounted a full dramatization. In 1998, Focus on the Family Radio Theatre also adapted this story. Both the original BBC version and the Focus on the Family version have been broadcast on BBC radio. Both are the first in a series of adaptations of all seven of the Narnia books. The BBC series uses the title Tales of Narnia, while the Focus on the Family version uses the more familiar Chronicles moniker. The Focus on the Family version is also longer, with a full orchestra score, narration, a larger cast of actors, and introductions by Douglas Gresham, C.S. Lewis' stepson.\\r\\nIn 2005, the story was adapted for a theatrical film, co-produced by Walt Disney and Walden Media. It has so far been followed by two more films: The Chronicles of Narnia: Prince Caspian and The Chronicles of Narnia: The Voyage of the Dawn Treader. The latter was co-produced by Twentieth-Century Fox and Walden Media.","input":"When was the lion witch and wardrobe written?"},{"output":"English (specifically American English)","context":"","input":"What language do they speak in the us?"},{"output":"2,000ÿ8,000","context":"Taste buds contain the taste receptor cells, which are also known as gustatory cells.[1] The taste receptors are located around the small structures known as papillae found on the upper surface of the tongue, soft palate, upper esophagus, the cheek, and epiglottis.[2] These structures are involved in detecting the five elements of taste perception: salty, sour, bitter, sweet and umami. A popular myth assigns these different tastes to different regions of the tongue; in reality these tastes can be detected by any area of the tongue. Via small openings in the tongue epithelium, called taste pores, parts of the food dissolved in saliva come into contact with the taste receptors.[1] These are located on top of the taste receptor cells that constitute the taste buds. The taste receptor cells send information detected by clusters of various receptors and ion channels to the gustatory areas of the brain via the seventh, ninth and tenth cranial nerves.\\r\\n\\r\\nOn average, the human tongue has 2,000ÿ8,000 taste buds.[3]\\r\\n\\r\\nThe taste buds on the tongue sit on raised protrusions of the tongue surface called papillae. There are three types of lingual papillae that contain taste buds present on the human tongue:\\r\\n\\r\\nThe fourth type of papillae the filiform papillae are the most numerous but do not contain taste buds.[4][5] They are characterized by increased keratinisation and are involved in the mechanical aspect of providing abrasion.\\r\\n\\r\\nSalt, sweet, sour and umami tastes causes depolarization of the taste cells, although different mechanisms are applied.\\r\\n\\r\\nBitter causes an internal release of Ca2+, no external Ca2+ is required.\\r\\n\\r\\nThe bud is formed by two kinds of cells: supporting cells and gustatory cells.\\r\\n\\r\\nThe supporting (sustentacular cells) are mostly arranged like the staves of a cask, and form an outer envelope for the bud. Some, however, are found in the interior of the bud between the gustatory cells.\\r\\n\\r\\nThe gustatory (taste) cells, a chemoreceptor, occupy the central portion of the bud; they are spindle-shaped, and each possesses a large spherical nucleus near the middle of the cell.\\r\\n\\r\\nThe peripheral end of the cell terminates at the gustatory pore in a fine hair filament, the gustatory hair.\\r\\n\\r\\nThe central process passes toward the deep extremity of the bud, and there ends in single or bifurcated varicosities.\\r\\n\\r\\nThe nerve fibrils after losing their medullary sheaths enter the taste bud, and end in fine extremities between the gustatory cells; other nerve fibrils ramify between the supporting cells and terminate in fine extremities; these, however, are believed to be nerves of ordinary sensation and not gustatory.\\r\\n\\r\\nThe average life of a taste bud is 10 days.[6]","input":"How many taste buds on the human tongue?"},{"output":"702 AD","context":"","input":"When did the first samurai exist in japan?"},{"output":"70 miles (113 km) from the coast","context":"Coton in the Elms is a village and parish in the English county of Derbyshire. At 70 miles (113 km) from the coast, it is the furthest place in the United Kingdom from coastal waters. The population of the civil parish as of the 2011 census was 896.[1]  It is located 5 miles southwest of Swadlincote and 6 miles south of Burton upon Trent.\\r\\n\\r\\nLess than a mile southeast of the village is Church Flatts Farm, which is defined by the Ordnance Survey as the furthest point from the sea in the UK.[2][3]\\r\\n\\r\\nCoton is mentioned over a thousand years ago when land was transferred to Wulfrige the Black in AD942.[4] It is also on the salt route known as Walton Way, which starts in nearby Walton-on-Trent.[5]\\r\\n\\r\\nCoton in the Elms is mentioned in the Domesday book where it is then spelt Cotes. The book says[6] under the title of The lands of the Abbey of Burton\\".[n 1]\\r\\n\\r\\n\\"In Coton in the Elms ?lfgar had two carucates of land to the geld. There is land for three ploughs. Now the abbot has it of the king. There are now one plough in demesne and six villans and three bordars having two ploughs. TRE worth 40 shillings now 30 shillings.\\"[n 2]\\r\\nCoton is situated on the Walton Way and is first mentioned in 942 in a charter giving land in the area to Wulfrige the Black. This formed part of a much larger estate covering many of the villages in the area. Coton would seem to have been roughly in the centre of this estate. It would appear that it was a crossroads as there is an old lane which runs all the way from Tamworth through Coton and on northwards towards Burton on Trent. At the time of Domesday Burton Abbey held land at Coton - however this had been initially seized by King William - no doubt in part due to the rebellion led by Earl Morcar. However, by the time of Domesday this land had been restored to Burton. The village itself forms a diamond of roads around a small village green. The original route of the Walton Way may have been the south west corner of this diamond as this runs past the Church and Church Farm. To the north east of the village coal mining became important and this is reflected in the lane name Coalpit Lane.\\r\\n\\r\\nThe present church of St Mary was built in 1844-7 by Henry Isaac Stevens but not on the site of the original church, which was behind the Shoulder of Mutton pub. It has a narrow west tower with a recessed spire. It is generally believed that when the original church fell into disrepair, the bells were taken to the neighbouring Lullington village, so the inhabitants of Coton can still hear the old bells when the wind is in the right direction.\\r\\n\\r\\nThere is a Methodist chapel, built in 1922 to replace a smaller building in Chapel Street. The old building became known as the band room, where for many years a good band was run by a Mr Coates, who was also the village post master. It has also been used as a village hall.\\r\\n\\r\\nThe main occupations of the village inhabitants in the past has been mining and farming, though the pits are now all closed. For many of today's population (782 in 1991) it is a commuter base for the larger towns such as Burton-on-Trent, Swadlincote and Tamworth.\\r\\n\\r\\nCoton in the Elms has 2 pubs. The Black Horse was refurbished in 2009. The Queen's Head Inn dates back to the 17th century, part of the premises was once a shop. Another pub, the Shoulder of Mutton, closed in 2010 and is currently being converted to a house.\\r\\n\\r\\nSoutheast of the village ÿ at grid reference SK253144 ÿ is Church Flatts Farm, which is calculated by the Ordnance Survey to be the farthest point from the sea (at the mean low water line) in Great Britain.[2] The location is Latitude: 52 43.6' N Longitude: 1 37.2' W. This place in Coton was chosen as equidistant from Fosdyke Wash in Lincolnshire; White Sands between Neston in Cheshire and Flint, Flintshire in Wales; and Westbury-on-Severn in Gloucestershire ÿ all of which are 113 kilometres (70?mi) away.[2][3]\\r\\n\\r\\nThe nearest high tide point is on the River Trent at Cromwell Lock, north of Newark-on-Trent, in Nottinghamshire, 72 kilometres (45?mi) away.[2]","input":"How far from the sea can you be in england?"},{"output":"supervisors","context":"Management (or managing) is the administration of an organization, whether it is a business, a not-for-profit organization, or government body. Management includes the activities of setting the strategy of an organization and coordinating the efforts of its employees (or of volunteers) to accomplish its objectives through the application of available resources, such as financial, natural, technological, and human resources. The term \\"management\\" may also refer to those people who manage an organization.\\r\\nSocial scientists study management as an academic discipline, investigating areas such as social organization and organizational leadership. Some people study management at colleges or universities; major degrees in management include the Bachelor of Commerce (B.Com.) and Master of Business Administration (MBA.) and, for the public sector, the Master of Public Administration (MPA) degree. Individuals who aim to become management specialists or experts, management researchers, or professors may complete the Doctor of Management (DM), the Doctor of Business Administration (DBA), or the PhD in Business Administration or Management.\\r\\nLarger organizations generally have three levels of managers, which are typically organized[by whom?] in a hierarchical, pyramid structure:\\r\\nIn smaller organizations, an individual manager may have a much wider scope. A single manager may perform several roles or even all of the roles commonly observed in a large organization.\\r\\n\\r\\n\\r\\nViews on the definition and scope of management include:\\r\\nManagement involves identifying the mission, objective, procedures, rules and manipulation[3] of the human capital of an enterprise to contribute to the success of the enterprise.[citation needed] This implies effective communication: an enterprise environment (as opposed to a physical or mechanical mechanism) implies human motivation and implies some sort of successful progress or system outcome.[citation needed] As such, management is not the manipulation of a mechanism (machine or automated program), not the herding of animals, and can occur either in a legal or in an illegal enterprise or environment. From an individual's perspective, management does not need to be seen solely from an enterprise point of view, because management is an essential function to improve one's life and relationships.[citation needed] Management is therefore everywhere[citation needed] and it has a wider range of application.[clarification needed] Based on this, management must have humans. Communication and a positive endeavor are two main aspects of it either through enterprise or independent pursuit.[citation needed] Plans, measurements, motivational psychological tools, goals, and economic measures (profit, etc.) may or may not be necessary components for there to be management. At first, one views management functionally, such as measuring quantity, adjusting plans, meeting goals.[citation needed] This applies even in situations where planning does not take place. From this perspective, Henri Fayol (1841ÿ1925)[4][page?needed] considers management to consist of six functions:\\r\\nIn another way of thinking, Mary Parker Follett (1868ÿ1933), allegedly defined management as \\"the art of getting things done through people\\".[5] She described management as philosophy.[6][need quotation to verify]\\r\\nCritics[which?], however, find this definition useful but far too narrow. The phrase \\"management is what managers do\\" occurs widely,[7] suggesting the difficulty of defining management without circularity, the shifting nature of definitions[citation needed] and the connection of managerial practices with the existence of a managerial cadre or of a class.\\r\\nOne habit of thought regards management as equivalent to \\"business administration\\" and thus excludes management in places outside commerce, as for example in charities and in the public sector. More broadly, every organization must \\"manage\\" its work, people, processes, technology, etc. to maximize effectiveness.[citation needed] Nonetheless, many people refer to university departments that teach management as \\"business schools\\". Some such institutions (such as the Harvard Business School) use that name, while others (such as the Yale School of Management) employ the broader term \\"management\\".\\r\\nEnglish-speakers may also use the term \\"management\\" or \\"the management\\" as a collective word describing the managers of an organization, for example of a corporation.[8] Historically this use of the term often contrasted with the term \\"labor\\" ÿ referring to those being managed.[9]\\r\\nBut in the present era[when?] the concept of management is identified[by whom?] in the wide areas[which?] and its frontiers have been pushed to a broader range.[citation needed] Apart from profitable organizations even non-profitable organizations (NGOs) apply management concepts. The concept and its uses are not constrained[by whom?]. Management on the whole is the process of planning, organizing, coordinating, leading and controlling.\\r\\nIn profitable organizations, management's primary function is the satisfaction of a range of stakeholders. This typically involves making a profit (for the shareholders), creating valued products at a reasonable cost (for customers), and providing great employment opportunities for employees. In nonprofit management, add the importance of keeping the faith of donors. In most models of management and governance, shareholders vote for the board of directors, and the board then hires senior management. Some organizations have experimented with other methods (such as employee-voting models) of selecting or reviewing managers, but this is rare.\\r\\nIn the public sector of countries constituted as representative democracies, voters elect politicians to public office. Such politicians hire many managers and administrators, and in some countries like the United States political appointees lose their jobs on the election of a new president/governor/mayor.\\r\\nSome see management (by definition) as late-modern (in the sense of late modernity) conceptualization. On those terms it cannot have a pre-modern history, only harbingers (such as stewards). Others, however, detect management-like-thought back to Sumerian traders and to the builders of the pyramids of ancient Egypt. Slave-owners through the centuries faced the problems of exploiting/motivating a dependent but sometimes unenthusiastic or recalcitrant workforce, but many pre-industrial enterprises, given their small scale, did not feel compelled to face the issues of management systematically. However, innovations such as the spread of Hindu numerals (5th to 15th centuries) and the codification of double-entry book-keeping (1494) provided tools for management assessment, planning and control.\\r\\nAlso, Machiavelli wrote about how to make organisations efficient and effective. The principles that Machiavelli set forth in Discourses (1531) can be adapted to apply the management of organisations today:\\r\\nWith the changing workplaces of industrial revolutions in the 18th and 19th centuries, military theory and practice contributed approaches to managing the newly-popular factories.[11]\\r\\nGiven the scale of most commercial operations and the lack of mechanized record-keeping and recording before the industrial revolution, it made sense for most owners of enterprises in those times to carry out management functions by and for themselves. But with growing size and complexity of organizations, the split between owners (individuals, industrial dynasties or groups of shareholders) and day-to-day managers (independent specialists in planning and control) gradually became more common.\\r\\nThe English verb \\"manage\\" comes from the Italian maneggiare (to handle, especially tools or a horse), which derives from the two Latin words manus (hand) and agere (to act). The French word for housekeeping, mnagerie, derived from mnager (\\"to keep house\\"; compare mnage for \\"household\\"), also encompasses taking care of domestic animals. Mnagerie is the French translation of Xenophon's famous book Oeconomicus[12] (Greek: Ѯ???) on household matters and husbandry. The French word mesnagement (or mnagement) influenced the semantic development of the English word management in the 17th and 18th centuries.[13]\\r\\nManagement (according to some definitions) has existed for millennia, and several writers have produced background works that have contributed to modern management theories.[14][need quotation to verify] Some theorists have cited ancient military texts as providing lessons for civilian managers. For example, Chinese general Sun Tzu in his 6th century BC work The Art of War recommends being aware of and acting on strengths and weaknesses of both a manager's organization and a foe's.[14] The writings of influential Chinese Legalist philosopher Shen Buhai may be considered[by whom?] to embody a rare premodern example of abstract theory of administration.[15]\\r\\nVarious ancient and medieval civilizations produced \\"mirrors for princes\\" books, which aimed to advise new monarchs on how to govern. Plato described job specialization in 350 B.C., and Alfarabi listed several leadership traits in A.D. 900.[16] Other examples include the Indian Arthashastra by Chanakya (written around 300 BCE), and The Prince by Italian author Niccol Machiavelli (c. 1515).[17]\\r\\nWritten in 1776 by Adam Smith, a Scottish moral philosopher, The Wealth of Nations discussed efficient organization of work through division of labour.[17] Smith described how changes in processes could boost productivity in the manufacture of pins. While individuals could produce 200 pins per day, Smith analyzed the steps involved in manufacture and, with 10 specialists, enabled production of 48,000 pins per day.[17][need quotation to verify]\\r\\nClassical economists such as Adam Smith (1723ÿ1790) and John Stuart Mill (1806ÿ1873) provided a theoretical background to resource-allocation, production, and pricing issues. About the same time, innovators like Eli Whitney (1765ÿ1825), James Watt (1736ÿ1819), and Matthew Boulton (1728ÿ1809) developed elements of technical production such as standardization, quality-control procedures, cost-accounting, interchangeability of parts, and work-planning. Many of these aspects of management existed in the pre-1861 slave-based sector of the US economy. That environment saw 4 million people, as the contemporary usages had it, \\"managed\\" in profitable quasi-mass production.\\r\\nSalaried managers as an identifiable group first became prominent in the late 19th century.[18]\\r\\nBy about 1900 one finds managers trying to place their theories on what they regarded as a thoroughly scientific basis (see scientism for perceived limitations of this belief). Examples include Henry R. Towne's Science of management in the 1890s, Frederick Winslow Taylor's The Principles of Scientific Management (1911), Lillian Gilbreth's Psychology of Management (1914),[19] Frank and Lillian Gilbreth's Applied motion study (1917), and Henry L. Gantt's charts (1910s). J. Duncan wrote the first college management-textbook in 1911. In 1912 Yoichi Ueno introduced Taylorism to Japan and became the first management consultant of the \\"Japanese-management style\\". His son Ichiro Ueno pioneered Japanese quality assurance.\\r\\nThe first comprehensive theories of management appeared around 1920. The Harvard Business School offered the first Master of Business Administration degree (MBA) in 1921. People like Henri Fayol (1841ÿ1925) and Alexander Church described the various branches of management and their inter-relationships. In the early 20th century, people like Ordway Tead (1891ÿ1973), Walter Scott and J. Mooney applied the principles of psychology to management. Other writers, such as Elton Mayo (1880ÿ1949), Mary Parker Follett (1868ÿ1933), Chester Barnard (1886ÿ1961), Max Weber (1864ÿ1920), who saw what he called the \\"administrator\\" as bureaucrat[20]), Rensis Likert (1903ÿ1981), and Chris Argyris (born 1923) approached the phenomenon of management from a sociological perspective.\\r\\nPeter Drucker (1909ÿ2005) wrote one of the earliest books on applied management: Concept of the Corporation (published in 1946). It resulted from Alfred Sloan (chairman of General Motors until 1956) commissioning a study of the organisation. Drucker went on to write 39 books, many in the same vein.\\r\\nH. Dodge, Ronald Fisher (1890ÿ1962), and Thornton C. Fry introduced statistical techniques into management-studies. In the 1940s, Patrick Blackett worked in the development of the applied-mathematics science of operations research, initially for military operations. Operations research, sometimes known as \\"management science\\" (but distinct from Taylor's scientific management), attempts to take a scientific approach to solving decision-problems, and can apply directly to multiple management problems, particularly in the areas of logistics and operations.\\r\\nSome of the more recent[update] developments include the Theory of Constraints, management by objectives, reengineering, Six Sigma and various information-technology-driven theories such as agile software development, as well as group-management theories such as Cog's Ladder.\\r\\nAs the general recognition of managers as a class solidified during the 20th century and gave perceived practitioners of the art/science of management a certain amount of prestige, so the way opened for popularised systems of management ideas to peddle their wares. In this context many management fads may have had more to do with pop psychology than with scientific theories of management.\\r\\nTowards the end of the 20th century, business management came to consist of six separate branches,[citation needed] namely:\\r\\nIn the 21st century observers find it increasingly difficult to subdivide management into functional categories in this way. More and more processes simultaneously involve several categories. Instead, one tends to think in terms of the various processes, tasks, and objects subject to management.[citation needed]\\r\\nBranches of management theory also exist relating to nonprofits and to government: such as public administration, public management, and educational management. Further, management programs related to civil-society organizations have also spawned programs in nonprofit management and social entrepreneurship.\\r\\nNote that many of the assumptions made by management have come under attack from business-ethics viewpoints, critical management studies, and anti-corporate activism.\\r\\nAs one consequence, workplace democracy (sometimes referred to as Workers' self-management) has become both more common and advocated to a greater extent, in some places distributing all management functions among workers, each of whom takes on a portion of the work. However, these models predate any current political issue, and may occur more naturally than does a command hierarchy. All management embraces to some degree a democratic principlein that in the long term, the majority of workers must support management. Otherwise, they leave to find other work or go on strike. Despite the move toward workplace democracy, command-and-control organization structures remain commonplace as de facto organization structure. Indeed, the entrenched nature of command-and-control is evident in the way that recent layoffs have been conducted with management ranks affected far less than employees at the lower levels. In some cases, management has even rewarded itself with bonuses after laying off lower-level workers.[21]\\r\\nAccording to leadership academic Manfred F.R. Kets de Vries, a contemporary senior management team will almost inevitably have some personality disorders.[22]\\r\\nAccording to Fayol, management operates through five basic functions: planning, organizing, coordinating, commanding, and controlling.\\r\\nManagement skills include:\\r\\nMost organizations have three management levels: first-level, middle-level, and top-level managers. First-line managers are the lowest level of management and manage the work of nonmanagerial individuals who are directly involved with the production or creation of the organization's products. First-line managers are often called supervisors, but may also be called line managers, office managers, or even foremen. Middle managers include all levels of management between the first-line level and the top level of the organization. These managers manage the work of first-line managers and may have titles such as department head, project leader, plant manager, or division manager. Top managers are responsible for making organization-wide decisions and establishing the plans and goals that affect the entire organization. These individuals typically have titles such as executive vice president, president, managing director, chief operating officer, chief executive officer, or chairman of the board.\\r\\nThese managers are classified in a hierarchy of authority, and perform different tasks. In many organizations, the number of managers in every level resembles a pyramid. Each level is explained below in specifications of their different responsibilities and likely job titles.[citation needed]\\r\\nThe top or senior layer of management consists of the board of directors (including non-executive directors and executive directors), president, vice-president, CEOs and other members of the C-level executives. Different organizations have various members in their C-suite, which may include a Chief Financial Officer, Chief Technology Officer, and so on. They are responsible for controlling and overseeing the operations of the entire organization. They set a \\"tone at the top\\" and develop strategic plans, company policies, and make decisions on the overall direction of the organization. In addition, top-level managers play a significant role in the mobilization of outside resources. Senior managers are accountable to the shareholders, the general public and to public bodies that oversee corporations and similar organizations. Some members of the senior management may serve as the public face of the organization, and they may make speeches to introduce new strategies or appear in marketing.\\r\\nThe board of directors is typically primarily composed of non-executives who owe a fiduciary duty to shareholders and are not closely involved in the day-to-day activities of the organization, although this varies depending on the type (e.g., public versus private), size and culture of the organization. These directors are theoretically liable for breaches of that duty and typically insured under directors and officers liability insurance. Fortune 500 directors are estimated to spend 4.4 hours per week on board duties, and median compensation was $212,512 in 2010. The board sets corporate strategy, makes major decisions such as major acquisitions,[24] and hires, evaluates, and fires the top-level manager (Chief Executive Officer or CEO). The CEO typically hires other positions. However, board involvement in the hiring of other positions such as the Chief Financial Officer (CFO) has increased.[25] In 2013, a survey of over 160 CEOs and directors of public and private companies found that the top weaknesses of CEOs were \\"mentoring skills\\" and \\"board engagement\\", and 10% of companies never evaluated the CEO.[26] The board may also have certain employees (e.g., internal auditors) report to them or directly hire independent contractors; for example, the board (through the audit committee) typically selects the auditor.\\r\\nHelpful skills of top management vary by the type of organization but typically include[27] a broad understanding of competition, world economies, and politics. In addition, the CEO is responsible for implementing and determining (within the board's framework) the broad policies of the organization. Executive management accomplishes the day-to-day details, including: instructions for preparation of department budgets, procedures, schedules; appointment of middle level executives such as department managers; coordination of departments; media and governmental relations; and shareholder communication.\\r\\nConsist of general managers, branch managers and department managers. They are accountable to the top management for their department's function. They devote more time to organizational and directional functions. Their roles can be emphasized as executing organizational plans in conformance with the company's policies and the objectives of the top management, they define and discuss information and policies from top management to lower management, and most importantly they inspire and provide guidance to lower level managers towards better performance.\\r\\nMiddle management is the midway management of a categorized organization, being secondary to the senior management but above the deepest levels of operational members. An operational manager may be well-thought-out by middle management, or may be categorized as non-management operate, liable to the policy of the specific organization. Efficiency of the middle level is vital in any organization, since they bridge the gap between top level and bottom level staffs.\\r\\nTheir functions include:\\r\\nLower managers include supervisors, section leaders, forepersons and team leaders. They focus on controlling and directing regular employees. They are usually responsible for assigning employees' tasks, guiding and supervising employees on day-to-day activities, ensuring the quality and quantity of production and/or service, making recommendations and suggestions to employees on their work, and channeling employee concerns that they cannot resolve to mid-level managers or other administrators. First-level or \\"front line\\" managers also act as role models for their employees. In some types of work, front line managers may also do some of the same tasks that employees do, at least some of the time. For example, in some restaurants, the front line managers will also serve customers during a very busy period of the day.\\r\\nFront-line managers typically provide:\\r\\nSome front-line managers may also provide career planning for employees who aim to rise within the organization.\\r\\nColleges and universities around the world offer bachelor's degrees, graduate degrees, diplomas and certificates in management, generally within their colleges of business, business schools or faculty of management but also in other related departments. In the 2010s, there has been an increase in online management education and training in the form of electronic educational technology ( also called e-learning). Online education has increased the accessibility of management training to people who do not live near a college or university, or who cannot afford to travel to a city where such training is available.\\r\\nWhile some professions require academic credentials in order to work in the profession (e.g., law, medicine, engineering, which require, respectively the Bachelor of Law, Doctor of Medicine and Bachelor of Engineering degrees), management and administration positions do not necessarily require the completion of academic degrees. Some well-known senior executives in the US who did not complete a degree include Steve Jobs, Bill Gates and Mark Zuckerberg. However, many managers and executives have completed some type of business or management training, such as a Bachelor of Commerce or a Master of Business Administration degree. Some major organizations, including companies, not-for-profit organizations and governments, require applicants to managerial or executive positions to hold at minimum Bachelor's degree in a field related to administration or management, or in the case of business jobs, a Bachelor of Commerce or a similar degree.\\r\\nAt the undergraduate level, the most common business program is the Bachelor of Commerce (B.Com.). A B.Com. is typically a four-year program that includes courses that give students an overview of the role of managers in planning and directing within an organization. Course topics include accounting, financial management, statistics, marketing, strategy, and other related areas. There are many other undergraduate degrees that include the study of management, such as Bachelor of Arts degrees with a major in business administration or management and Bachelor of Public Administration (B.P.A), a degree designed for individuals aiming to work as bureaucrats in the government jobs. Many colleges and universities also offer certificates and diplomas in business administration or management, which typically require one to two years of full-time study.\\r\\nAt the graduate level students aiming at careers as managers or executives may choose to specialize in major subareas of management or business administration such as entrepreneurship, human resources, international business, organizational behavior, organizational theory, strategic management,[28] accounting, corporate finance, entertainment, global management, healthcare management, investment management, sustainability and real estate. A Master of Business Administration (MBA) is the most popular professional master's degree and can be obtained from many universities in the United States. MBAs provide further education in management and leadership for graduate students. Other master's degrees in business and management include Master of Management (MM) and the Master of Science (M.Sc.) in business administration or management, which is typically taken by students aiming to become researchers or professors. There are also specialized master's degrees in administration for individuals aiming at careers outside of business, such as the Master of Public Administration (MPA) degree (also offered as a Master of Arts in Public Administration in some universities), for students aiming to become managers or executives in the public service and the Master of Health Administration, for students aiming to become managers or executives in the health care and hospital sector.\\r\\nManagement doctorates are the most advanced terminal degrees in the field of business and management. Most individuals obtaining management doctorates take the programs to obtain the training in research methods, statistical analysis and writing academic papers that they will need to seek careers as researchers, senior consultants and/or professors in business administration or management. There are three main types of management doctorates: the Doctor of Management (D.M.), the Doctor of Business Administration (D.B.A.), and the Ph.D. in Business Administration or Management. In the 2010s, doctorates in business administration and management are available with many specializations.\\r\\nWhile management trends can change so fast, the long term trend in management has been defined by a market embracing diversity and a rising service industry. Managers are currently being trained to encourage greater equality for minorities and women in the workplace, by offering increased flexibility in working hours, better retraining, and innovative (and usually industry-specific) performance markers. Managers destined for the service sector are being trained to use unique measurement techniques, better worker support and more charismatic leadership styles.[29] Human resources finds itself increasingly working with management in a training capacity to help collect management data on the success (or failure) of management actions with employees.[30]","input":"What is the first level of management in a company?"},{"output":"Arsenal","context":"The 2017 FA Cup Final was the 136th final of the FA Cup, the world's oldest football cup competition. It took place on 27 May 2017 at Wembley Stadium in London, England and was contested between London rivals Arsenal and Chelsea. Arsenal won the game 2ÿ1 to secure a record 13th title, while manager Arsne Wenger became the most successful manager in the tournament's history with seven wins.\\r\\n\\r\\nThe winners would enter the 2017ÿ18 UEFA Europa League group stage, had they not already qualified for the UEFA Champions League via other competitions.[3]\\r\\n\\r\\nThis was a rematch of the 2002 FA Cup Final and the first final since 2003 in which both sides split the league games against each other during the course of the season, with a 3ÿ0 victory by Arsenal in September 2016, and a 3ÿ1 win by Chelsea in February 2017. The game was broadcast live in the United Kingdom by both BBC and BT Sport. BBC One provided the free-to-air coverage and BT Sport 2 was the pay-TV alternative.[4][5]  In North America, this was the first FA Cup Final to be televised by CTV in Canada and by FOX in the United States.\\r\\n\\r\\nDue to the circumstances surrounding his appearance,[6] and performance on the day,[7] Arsenal fans and former players have dubbed the game The Mertesacker Final.[8]\\r\\n\\r\\nIn all results below, the score of the finalist is given first.\\r\\n\\r\\nArsenal, as a Premier League team, started their campaign in the third round. In it, they were drawn away at Football League Championship Preston North End. At Deepdale, Arsenal won 2ÿ1 with goals from Aaron Ramsey and Olivier Giroud.[9] In the Fourth Round, Arsenal drew fellow Premier League Southampton. At St Mary's Stadium, Arsenal won 5ÿ0 with two goals from Danny Welbeck and a hat-trick from Theo Walcott.[10] In the Fifth Round, Arsenal were drawn against non-league National League Sutton United away. At Gander Green Lane, Arsenal won 2ÿ0 with goals from Lucas Prez and Walcott.[11] The match was also noted for Sutton United's reserve goalkeeper Wayne Shaw being investigated by The FA and Gambling Commission for eating a pie pitchside despite there being betting odds on him doing so.[12] In the quarter-finals, Arsenal were drawn at home against National League Lincoln City. At the Emirates Stadium, Arsenal won 5ÿ0 with goals from Walcott, Giroud, an own goal by Luke Waterfall, Alexis Snchez and Ramsey.[13] In the semi-final at neutral Wembley Stadium, Arsenal played against Premier League Manchester City and reached the final after a 2ÿ1 win with goals from Nacho Monreal and Snchez.[14]\\r\\n\\r\\nIn all results below, the score of the finalist is given first.\\r\\n\\r\\nChelsea also started in the third round where they were drawn at home against League One side Peterborough United. At Stamford Bridge, Chelsea won 4ÿ1 with two goals from Pedro and a goal each from Michy Batshuayi and Willian despite having club captain John Terry sent off.[15] In the fourth round, they were drawn with Championship team Brentford at home. Chelsea won 4ÿ0 with goals from Pedro, Willian, Branislav Ivanovi? and Batshuayi.[16] In the fifth round, Chelsea were drawn away against Championship Wolverhampton Wanderers. At Molineux Stadium, Chelsea won 2ÿ0 with goals from Pedro and Diego Costa.[17]  In the Quarter-finals, they were drawn against fellow Premier League side and FA Cup holders Manchester United. At Stamford Bridge, Chelsea won 1ÿ0 thanks to a goal from N'Golo Kant.[18] In the semi-finals at Wembley Stadium, Chelsea were drawn against fellow Premier League and London rivals,\\r\\nTottenham Hotspur. Chelsea reached the final with a 4ÿ2 win with two goals from Willian and a goal each from Eden Hazard and Nemanja Mati?.[19]\\r\\n\\r\\nArsenal were appearing in the final of the FA Cup for the 20th time, the club's third in four years. They had won the cup twelve times previously (in 1930, 1936, 1950, 1971, 1979, 1993, 1998, 2002, 2003, 2005, 2014 and 2015) and were beaten in the final seven times, most recently in 2001. By comparison, Chelsea were making their 12th appearance in a FA Cup final.[20] The club won the cup seven times (1970, 1997, 2000, 2007, 2009, 2010 and 2012) and lost four finals. Arsenal and Chelsea had previously met 13 times in the FA Cup. Arsenal held an advantage in those meetings, winning seven of the last eight. Chelsea, however, won the last FA Cup tie, a 2ÿ1 victory in April 2009.[21] This was the second FA Cup final to feature both sides; the first was won by Arsenal in 2002.[22]\\r\\n\\r\\nThe most recent meeting between the two teams was a league encounter in February 2017. Chelsea beat Arsenal by three goals to one, a result which moved them 12 points clear in first position.[23] The win was significant given Chelsea lost the reverse fixture 3ÿ0 in September 2016, a \\"watershed moment\\" in their season according to BBC journalist Phil McNulty.[24] While Arsenal struggled to build momentum throughout autumn and winter, Chelsea manager Antonio Conte's tactical switch from 4ÿ3ÿ3 to 3ÿ4ÿ3 thereafter resulted in a 13-match winning run.[25][26] They won the Premier League with two matches to spare,[26] and later set a new divisional record for the most wins (30).[27] \\r\\nArsenal ended the season in fifth place, their lowest placing under manager Arsne Wenger, and missed out on UEFA Champions League football for the first time in 20 years.[28] Wenger's future had been cast into doubt following a bad run of form in February and March, which saw the team lose 10ÿ2 on aggregate against Bayern Munich in the Champions League, and four of their five league matches.[29] To arrest the decline, Wenger adopted a similar tactical change to Conte, playing three defenders at the back.[30] Arsenal went on to win eight of their last nine fixtures, but Wenger admitted his team were outsiders for the final: \\"This time we are not favourites, its quite even or maybe Chelsea are ahead, so its a bit similar to what happened in the semi-final against Manchester City. Thats part of what makes it all exciting as well.\\"[31] Of his future he said, \\"It will not be my last match anyway, because I will stay, no matter what happens, in football.\\"[32]\\r\\n\\r\\nPaul Merson's pre-match assessment[33]\\r\\n\\r\\nConte described Wenger as one of the greats in football, and felt he would remain as Arsenal manager come the season's end.[34] \\"He has done a fantastic job. Sometimes in England I think you undervalue the achievement of qualifying for the Champions League. Only this season they haven't qualified for the Champions League,\\" he continued.[34] Conte reiterated the importance of his players keeping their focus and wanted Chelsea to \\"pay great attention and focus\\" to their opponents.[35] Hazard, who was playing in his first FA Cup final, was eager to win the competition: \\"For Chelsea, for such a big club like this, you need to win one, two, three trophies every season if you can. Now we have the possibility to win another trophy so all the players are ready for that. It's such a great competition for the fans.\\"[34]\\r\\n\\r\\nChelsea and Arsenal were expected to line up in a 3ÿ4ÿ3 formation.[36] Whereas the former club had no injury or suspension worries, Arsenal had doubts over the fitness of Petr ?ech and Shkodran Mustafi, and were already without defenders Laurent Koscielny (suspension) and Gabriel (ankle injury).[36] Per Mertesacker was expected to start; the Germany international only featured once for Arsenal's first team during the season.[37]  The day before the final The Guardian reported that Wenger chose David Ospina to start in goal ahead of ?ech.[38]\\r\\n\\r\\nBoth clubs received an allocation of approximately 28,000 tickets.[39] For adults, these were priced S45, S65, S85 and S115, with concessions in place.[39] Chelsea supporters were situated in the west side of the ground, while Arsenal's were allocated in the east.[40]  The remaining 14,000 tickets were distributed to volunteers involved in the FA's work.[39] Finalists stood to receive S900,000 minimum, the winners earned S1.8 million.[41] Security at Wembley Stadium was tightened in the wake of the Manchester Arena bombing; as a security measure Arsenal cancelled a screening of the game at their ground.[42] Both clubs cancelled plans for open top bus victory parades.[43]\\r\\n\\r\\nSol Campbell and Eddie Newton came onto the pitch to greet the supporters and place the trophy on a plinth.[44] As they departed, the traditional Cup Final hymn, \\"Abide with Me\\" was sung by representatives of eight clubs, including Lincoln City, Guernsey, Millwall and Sutton United.[45] The teams emerged moments later led by their managers, and players were greeted by Prince William, Duke of Cambridge. Soprano Emily Haig sang the national anthem and a minute's silence was then held to honour the victims of the Manchester attack.[44][45] Prince William, Andy Burnham, the Mayor of Greater Manchester and FA chairman Greg Clarke lay wreaths on the pitch in tribute.[44]\\r\\n\\r\\nDespite what was expected to be a tight affair, Arsenal dominated the early proceedings and opened the scoring with a goal from Alexis Snchez in the 4th minute, shooting past the advancing goalkeeper from six yards out with his right foot. The goal was initially flagged as offside due to Aaron Ramsey being in an offside position. After discussing with his linesman, referee Anthony Taylor overrode the decision and awarded Arsenal the goal due to Ramsey not attempting to play the ball.[46]\\r\\nSnchez also handled the ball in the lead up to the goal but this was not seen by the referee.[47]\\r\\nArsenal then hit the post twice from close range in the first half through Aaron Ramsey and Danny Welbeck.\\r\\n\\r\\nIn the second half, Victor Moses received a second yellow card for diving in the penalty box in the 68th minute, leaving Chelsea with ten men. Chelsea equalised through Diego Costa in the 76th minute when he controlled the ball on his chest in the penalty area before shooting low to the left with his right foot. Three minutes later Aaron Ramsey scored for Arsenal by heading in an Olivier Giroud cross from the left from six yards out.[48]\\r\\n\\r\\nMan of the Match:\\r\\nAlexis Snchez (Arsenal)\\r\\n\\r\\nAssistant referees:[1]\\r\\nGary Beswick (Durham)\\r\\nMarc Perry (Birmingham)\\r\\nFourth official:[1]\\r\\nBobby Madley (West Yorkshire)\\r\\nFifth official:[1]\\r\\nAdam Nunn (Wiltshire)\\r\\n\\r\\nMatch rules[49]","input":"Who won last year's fa cup final?"},{"output":"a highly developed mixed economy","context":"","input":"What kind of economy does the usa have?"},{"output":"a re-creation of a Mediterranean style European village located atop the Chav܇n River in La Romana, Dominican Republic","context":"Altos de Chav܇n is a re-creation of a Mediterranean style European village located atop the Chav܇n River in La Romana, Dominican Republic. It is the most popular attraction in the city and hosts a cultural center, an archeological museum, and an amphitheater. The project was conceived by the Italian architect Roberto Copa, and the industrialist Charles Bluhdorn.\\r\\n\\r\\nThe project began in 1976 when the construction of a nearby road and bridge crossing the Chav܇n River had to be blasted through a mountain of stone. Charles Bludhorn, chairman of Paramount then parent Gulf+Western, had the idea of using the stones to re-create a sixteenth-century style Mediterranean village, similar to some of the architecture found in the historic center of Santo Domingo. Construction was completed in the early 1980s.\\r\\n\\r\\nCharles Bluhdorn's daughter, Dominique Bluhdorn, is the current president of the Altos de Chav܇n Cultural Center Foundation. Narrow, cobble-covered alleyways lined with lanterns and shuttered limestone walls yield several good Mediterranean-style restaurants, a number of quaint shops featuring the diverse craftwork of local artisans, and three galleries exhibiting the talents of students from the on-site design school (La Escuela de Dise?o, an affiliate of Parsons School of Design in New York City). Notable attendees of the Altos de Chav܇n Design School have included Lisa Thon and Ma Lourdes Taveras L܇pez.\\r\\n\\r\\nAdding authenticity to the project is the charming St. Stanislaus Church (Iglesia San Estanislao de Cracovia in Spanish) with its plaza and sparkling fountain that is a popular wedding venue. The Church of St Stanislaus was named after the patron saint of Poland in tribute to Pope John Paul II, who visited Santo Domingo in 1979 and left some of the saint's ashes behind. It was in this church that Louis Alphonse, Duke of Anjou married Venezuelan heiress Maria Margarita de Vargas y Santaella on November 6, 2004.\\r\\n\\r\\nA Roman-styled 5,000-seat amphitheater hosts 20th century musical actsThe Pet Shop Boys, Frank Sinatra, and Julio Iglesias to name a fewwhile Gnesis nightclub provides a popular dance venue for guests from the Casa de Campo resort nearby.  The Regional Museum of Archaeology (El Museo Arqueol܇gico Regional) contains a collection of pre-Columbian Indian artifacts unearthed in the surrounding area.  Altos de Chav܇n overlooks Rio Chav܇n and the Dye Fore golf course of Casa de Campo; both built by former Gulf+Western chairman Charles Bluhdorn.\\r\\n\\r\\nThe Concert for the Americas was held here in August 1982. Performers included Frank Sinatra, Buddy Rich, Heart and Santana.","input":"What is altos de chavon in dominican republic?"},{"output":"music director or chief conductor, or by the German words Kapellmeister or Dirigent","context":"Conducting is the art of directing a musical performance, such as an orchestral or choral concert. It has been defined as \\"the art of directing the simultaneous performance of several players or singers by the use of gesture.\\"[1] The primary duties of the conductor are to interpret the score created by a composer in a manner which is reflective of the specific indications within that score, set the tempo, ensure correct entries by various members of the ensemble, and to \\"shape\\" the phrasing where appropriate.[2] To convey their ideas and interpretation, conductors communicate with their musicians primarily through hand gestures, typically though not invariably with the aid of a baton, and may use other gestures or signals, such as eye contact with relevant performers.[3] A conductor's directions will almost invariably be supplemented or reinforced by verbal instructions or suggestions to their musicians in rehearsal prior to a performance.[3]\\r\\n\\r\\nThe conductor typically stands on a raised podium with a large music stand for the full score, which contains the musical notation for all the instruments or voices. Since the mid-19th century, most conductors have not played an instrument when conducting, although in earlier periods of classical music history, leading an ensemble while playing an instrument was common. In Baroque music from the 1600s to the 1750s, the group would typically be led by the harpsichordist or first violinist (see concertmaster), an approach that in modern times has been revived by several music directors for music from this period. Conducting while playing a piano or synthesizer may also be done with musical theatre pit orchestras. Communication is typically non-verbal during a performance (this is strictly the case in art music, but in jazz big bands or large pop ensembles, there may be occasional spoken instructions, such as a \\"count in\\"). However, in rehearsals, frequent interruptions allow the conductor to give verbal directions as to how the music should be played or sung.\\r\\n\\r\\nConductors act as guides to the orchestras or choirs they conduct. They choose the works to be performed and study their scores, to which they may make certain adjustments (e.g., regarding tempo, articulation, phrasing, repetitions of sections, and so on), work out their interpretation, and relay their vision to the performers. They may also attend to organizational matters, such as scheduling rehearsals,[4] planning a concert season, hearing auditions and selecting members, and promoting their ensemble in the media. Orchestras, choirs, concert bands and other sizable musical ensembles such as big bands are usually led by conductors.\\r\\n\\r\\nThe principal conductor of an orchestra or opera company is sometimes referred to as a music director or chief conductor, or by the German words Kapellmeister or Dirigent. Conductors of choirs or choruses are sometimes referred to as choral director, chorus master, or choirmaster, particularly for choirs associated with an orchestra. Conductors of concert bands, military bands, marching bands and other bands may hold the title of band director, bandmaster, or drum major. Respected senior conductors are sometimes referred to by the Italian word, maestro (\\"master\\" as in \\"one who has mastered the art\\").\\r\\n\\r\\nAn early form of conducting is cheironomy, the use of hand gestures to indicate melodic shape. This has been practiced at least as far back as the Middle Ages. In the Christian church, the person giving these symbols held a staff to signify his role, and it seems that as music became rhythmically more complex, the staff was moved up and down to indicate the beat, acting as an early form of baton.\\r\\n\\r\\nIn the 17th century, other devices to indicate the passing of time came into use. Rolled up sheets of paper, smaller sticks and unadorned hands are all shown in pictures from this period. The large staff was responsible for the death of Jean-Baptiste Lully, who injured his foot with one while conducting a Te Deum for the King's recovery from illness. The wound became gangrenous and Lully refused amputation, whereupon the gangrene spread to his leg and he died two months later.[5]\\r\\n\\r\\nIn instrumental music throughout the 18th century, a member of the ensemble usually acted as the conductor. This was sometimes the concertmaster, who could use his bow as a baton, or a lutenist who would move the neck of his instrument in time with the beat. It was common to conduct from the harpsichord in pieces that had a basso continuo part. In opera performances, there were sometimes two conductors ÿ the keyboard player was in charge of the singers, and the principal violinist or leader was in charge of the orchestra.\\r\\n\\r\\nOn Fri, 30 Sep 1791 in Vienna, Mozart's opera Die Zauberfl?te (The Magic Flute) premiered at the Theater auf der Wieden (also known as the Wiednertheater), with Mozart himself conducting the orchestra, according to documents and publicity posters from that time. [6]\\r\\n\\r\\nIn 1798, Joseph Haydn conducted the premiere of Creation with his hands and a baton while Kapellmeister\\r\\nWeigl [sat] at the fortepiano.[7]\\r\\n\\r\\nBy the early 19th century (ca. 1820), it became the norm to have a dedicated conductor, who did not also play an instrument during the performance. While some orchestras protested the introduction of the conductor, since they were used to having a concertmaster or keyboard player act as leader, eventually the role of a conductor was established. The size of the usual orchestra expanded during this period, and the use of a baton became more common, as it was easier to see than bare hands or rolled-up paper. Among the earliest notable conductors were Louis Spohr, Carl Maria von Weber, Louis-Antoine Jullien and Felix Mendelssohn, all of whom were also composers. Mendelssohn is claimed to have been the first conductor to utilize a wooden baton to keep time, a practice still generally in use in the 2010s. Prominent conductors who did not or do not use a baton include Pierre Boulez, Kurt Masur, James Conlon, Yuri Temirkanov,[8] Leopold Stokowski, Vasily Safonov, Eugene Ormandy (for a period), and Dimitri Mitropoulos.[9]\\r\\n\\r\\nThe composers Hector Berlioz and Richard Wagner attained greatness as conductors, and they wrote two of the earliest essays dedicated to the subject. Berlioz is considered the first virtuoso conductor. Wagner was largely responsible for shaping the conductor's role as one who imposes his own view of a piece onto the performance rather than one who is just responsible for ensuring entries are made at the right time and that there is a unified beat. Predecessors who focused on conducting include Fran?ois Habeneck, who founded the Orchestre de la Socit des concerts du Conservatoire in 1828, though Berlioz was later to be alarmed at Habeneck's loose standards of rehearsal. Pianist and composer Franz Liszt was also a conductor.\\r\\n\\r\\nWagner's one-time champion Hans von Blow (1830ÿ1894) was particularly celebrated as a conductor, although he also maintained his initial career as a pianist, an instrument on which he was regarded as among the greatest performers (he was a prized piano student of Franz Liszt, whose daughter Cosima he married ÿ although she was to abandon him for Wagner. Liszt was a major figure in the history of conducting, who attained remarkable performances).\\r\\n\\r\\nBlow raised the technical standards of conducting to an unprecedented level through such innovations as separate, detailed rehearsals of different sections of the orchestra (\\"sectional rehearsal\\"). In his posts as head of (sequentially) the Bavarian State Opera, Meiningen Court Orchestra, and Berlin Philharmonic he brought a level of nuance and subtlety to orchestral performance previously heard only in solo instrumental playing, and in doing so made a profound impression on young artists like Richard Strauss, who at the age of 20 served as his assistant, and Felix Weingartner, who came to disapprove of his interpretations but was deeply impressed by his orchestral standards. Composer Gustav Mahler was also a noted conductor.\\r\\n\\r\\nThe next generation of conductors brought technical standards to new levels; perhaps most notable was the Hungarian-born Arthur Nikisch (1855ÿ1922), who succeeded Blow as music director of the Berlin Philharmonic in 1895. He had previously served as head of the Leipzig Opera, Boston Symphony Orchestra, and Leipzig Gewandhaus Orchestra, and was to serve as music director of the London Symphony Orchestra. Nikisch premiered important works by Anton Bruckner and Pyotr Ilyich Tchaikovsky, who greatly admired his work; Johannes Brahms, after hearing him conduct his Fourth Symphony, said it was \\"quite exemplary, it's impossible to hear it any better.\\"\\r\\n\\r\\nNikisch took the London Symphony Orchestra on tour through the United States in April 1912, the first American tour by a European orchestra. He also made one of the earliest recordings of a complete symphony: the Beethoven Fifth with the Berlin Philharmonic in November 1913. Nikisch was also the first conductor to have his art captured on film ÿ alas, silently. The film confirms reports that he made particularly mesmerizing use of eye contact and expression to communicate with an orchestra; such later conductors as Fritz Reiner stated that this aspect of his technique had a strong influence on their own.\\r\\n\\r\\nConductors of the generations after Nikisch often left extensive recorded evidence of their arts. Two particularly influential and widely recorded figures are often treated, somewhat inaccurately, as interpretive antipodes. They were the Italian conductor Arturo Toscanini (1867ÿ1957) and the German conductor Wilhelm Furtw?ngler (1886ÿ1954). Toscanini played in orchestras under Giuseppe Verdi and made his debut conducting Aida in 1886, filling in at the last minute for an indisposed conductor. He is to this day regarded by such authorities as James Levine as the greatest of all Verdi conductors. But Toscanini's repertory was wide, and it was in his interpretations of the German symphonists Beethoven and Brahms that he was particularly renowned and influential, favoring stricter and faster tempi than a conductor like Blow or, before him, Wagner. Still, his style shows more inflection than his reputation may suggest, and he was particularly gifted at revealing detail and getting orchestras to play in a singing manner.\\r\\n\\r\\nFurtw?ngler, whom many regard as the greatest interpreter of Wagner (although Toscanini was also admired in this composer) and Bruckner, conducted Beethoven and Brahms with a good deal of inflection of tempo ÿ but generally in a manner that revealed the structure and direction of the music particularly clearly. He was an accomplished composer as well as performer, and a disciple of the theorist Heinrich Schenker, who emphasized concern for underlying long-range harmonic tensions and resolutions in a piece, a strength of Furtw?ngler's conducting. Along with his interest in the large-scale, Furtw?ngler also shaped the details of the piece in a particularly compelling and expressive manner.\\r\\n\\r\\nThe two men had very different techniques: Toscanini's was Italianate, with a long, large baton and clear beats (often not using his left hand); Furtw?ngler beat time with less apparent precision, because he wanted a more rounded sound (although it is a myth that his technique was vague; many musicians have attested that he was easy to follow in his own way). In any event, their examples illustrate a larger point about conducting technique in the first half of the 20th century: it was not standardized. Great and influential conductors of the middle 20th century like Leopold Stokowski (1882ÿ1977), Otto Klemperer (1885ÿ1973), Herbert von Karajan (1908ÿ1989) and Leonard Bernstein (1918ÿ1990) ÿ incidentally, the first American conductor to attain greatness and international fame ÿ had widely varied techniques.\\r\\n\\r\\nKarajan and Bernstein formed another apparent antipode in the 1960sÿ80s, Karajan as music director of the Berlin Philharmonic (1955ÿ89) and Bernstein as, for part of that period, music director of the New York Philharmonic (1957ÿ69), and later frequent guest conductor in Europe. Karajan's technique was highly controlled, and eventually he conducted with his eyes often closed; Bernstein's technique was demonstrative, with highly expressive facial gestures and hand and body movements. Karajan could conduct for hours without moving his feet, while Bernstein was known at times to leap into the air at a great climax. As the music director of the Berlin Philharmonic, Karajan cultivated warm, blended beauty of tone, which has sometimes been criticized as too uniformly applied; by contrast, in Bernstein's only appearance with the Berlin Philharmonic in 1979 ÿ performing Mahler's Symphony No. 9 ÿ he tried to get the orchestra to produce an \\"ugly\\" tone in a certain passage in which he believed it suited the expressive meaning of the music (the first horn player refused, and finally agreed to let an understudy play instead of himself).\\r\\n\\r\\nBoth Karajan and Bernstein made extensive use of advances in media to convey their art, but in tellingly different ways. Bernstein hosted major prime-time national television series to educate and reach out to children and the public at large about classical music; Karajan made a series of films late in his life, but in them, he did not talk. Both made numerous recordings, but their attitudes toward recording differed: Karajan frequently made new studio recordings to take advantage of advances in recording technique, which fascinated him ÿ he played a role in setting the specifications of the compact disc ÿ but Bernstein, in his post-New York days, came to insist on (for the most part) live concert recordings, believing that music-making did not come to life in a studio without an audience.\\r\\n\\r\\nIn the last third of the 20th century, conducting technique ÿ particularly with the right hand and the baton ÿ became increasingly standardized. Conductors like Willem Mengelberg in Amsterdam until the end of World War II had had extensive rehearsal time to mold orchestras very precisely, and thus could have idiosyncratic techniques; modern conductors, who spend less time with any given orchestra, must get results with much less rehearsal time. A more standardized technique allows communication to be much more rapid. Nonetheless, conductors' techniques still show a great deal of variety, particularly with the use of the left hand, facial and eye expression, and body language.\\r\\n\\r\\nWomen conductors were almost unheard of in the ranks of leading orchestral conductors through most of the 19th and 20th centuries, but today, artists like Hortense von Gelmini?(de),[10] Marin Alsop and Simone Young have broken the gender barrier. Alsop was appointed music director of the Baltimore Symphony Orchestra in 2007 ÿ the first woman ever appointed to head a major US orchestra ÿ and also of the Orquestra Sinf?nica do Estado de S?o Paulo in 2012, and Alsop was the first woman to conduct on the last night of The Proms. Young scored similar firsts when she became head of the Hamburg State Opera and Philharmoniker Hamburg in 2005; she is also the first woman conductor to record the Ring Cycle of Richard Wagner. The Guardian called conducting \\"one of the last glass ceilings in the music industry\\".[11] A 2013 article stated that in France, out of 574 concerts only 17 were conducted by women and no women conducted at the National Opra in Paris.[12] \\"Bachtrack reported that, in a list of the world's 150 top conductors that year, only five were women.\\"[13]\\r\\n\\r\\nWhile Mexico has produced several major international conductors, Alondra de la Parra has become the first Mexican-born woman to attain distinction in the profession. Similarly, Asian origin has become unremarkable, because of the international successes of conductors from the Far East such as Seiji Ozawa, who was the Boston Symphony Orchestra's music director from 1973 until 2002 after holding similar posts in San Francisco and Toronto, and Myung-Whun Chung, who has held major posts in Germany and France and now is bringing the Seoul Philharmonic Orchestra to international attention. There is still under-representation of artists of black origin in the conducting profession, but there have been notable exceptions, such as Henry Lewis, Dean Dixon, James DePreist, Paul Freeman, and Michael Morgan. For more information on black conductors, see Black conductors. According to a 2004 article in The Guardian, \\"black conductors are rare in the classical music world and even in symphony orchestras it is unusual to see more than one or two black musicians.\\"[14]\\r\\n\\r\\nConducting is a means of communicating artistic directions to performers during a performance. Although there are many formal rules on how to conduct correctly, others are subjective, and a wide variety of different conducting styles exist depending upon the training and sophistication of the conductor. The primary responsibilities of the conductor are to unify performers, set the tempo, execute clear preparations and beats, listen critically and shape the sound of the ensemble, and to control the interpretation and pacing of the music. Communication is non-verbal during a performance, however in rehearsal frequent interruptions allow directions as to how the music should be played. During rehearsals, the conductor may stop the playing of a piece to request changes in the phrasing or request a change in the timbre of a certain section. In amateur orchestras, the rehearsals are often stopped to draw the musicians' attentions to performance errors or transposition mistakes.\\r\\n\\r\\nConducting requires an understanding of the elements of musical expression (tempo, dynamics, articulation) and the ability to communicate them effectively to an ensemble. The ability to communicate nuances of phrasing and expression through gestures is also beneficial. Conducting gestures are preferably prepared beforehand by the conductor while studying the score, but may sometimes be spontaneous.\\r\\n\\r\\nA distinction is sometimes made between orchestral conducting and choral conducting. Typically, orchestral conductors use a baton more often than choral conductors. The grip of the baton varies from conductor to conductor.\\r\\n\\r\\nAt the beginning of a piece of music, the conductor raises his hands (or hand if he only uses a single hand) to indicate that the piece is about to begin. This is a signal for the orchestra members to ready their instruments to be played or for the choristers to be ready and watching. The conductor then looks at the different sections of the orchestra (winds, strings, etc.) or choir to ensure that all the orchestra members are ready to play and choir members are ready. In some choral works, the conductor may signal to a pianist or organist to play a note or chord so that the choir members can determine their starting notes. Then the conductor gives one or more preparatory beats to commence the music. The preparatory beat before the orchestra or choir begins is the upbeat. The beat of the music is typically indicated with the conductor's right hand, with or without a baton. The hand traces a shape in the air in every bar (measure) depending on the time signature, indicating each beat with a change from downward to upward motion.[15] The images show the most common beat patterns, as seen from the conductor's point of view.[citation needed]\\r\\n\\r\\nThe downbeat indicates the first beat of the bar, and the upbeat indicates the beat before the first note of the piece and the last beat of the bar. The instant at which the beat occurs is called the ictus (plural: icts or ictuses), and is usually indicated by a sudden (though not necessarily large) click of the wrist or change in baton direction. In some instances, \\"ictus\\" is also used to refer to a horizontal plane in which all the ictuses are physically located, such as the top of a music stand where a baton is tapped at each ictus. The gesture leading up to the ictus is called the \\"preparation\\", and the continuous flow of steady beats is called the \\"takt\\" (the German word for bar, measure and beat).\\r\\n\\r\\nIf the tempo is slow or slowing, or if the time signature is compound, a conductor will sometimes indicate \\"subdivisions\\" of the beats. The conductor can do this by adding a smaller movement in the same direction as the movement for the beat that it belongs to.\\r\\n\\r\\nChanges to the tempo are indicated by changing the speed of the beat. To carry out and to control a rallentando (slowing down the pace of the music), a conductor may introduce beat subdivisions.\\r\\n\\r\\nWhile some conductors use both hands to indicate the beat, with the left hand mirroring the right, formal education discourages such an approach. The second hand can be used for cueing the entrances of individual players or sections, and to aid indications of dynamics, phrasing, expression, and other elements.\\r\\n\\r\\nDuring an instrumental solo section (or, in an opera orchestra during a vocalist's unaccompanied solo), some conductors stop counting out all the subdivisions and simply tap the baton down once per bar, to aid performers who are counting bars of rests.\\r\\n\\r\\nThere is a difference between the \\"textbook\\" definition of where the ictus of a downbeat occurs and the actual performance practice in professional orchestras. With an abrupt, loud sforzando chord, a professional orchestra will often play slightly after the striking of the ictus point of the baton stroke.\\r\\n\\r\\nDynamics are indicated in various ways. The dynamic may be communicated by the size of the conducting movements, larger shapes representing louder sounds. Changes in dynamic may be signalled with the hand that is not being used to indicate the beat: an upward motion (usually palm-up) indicates a crescendo; a downward motion (usually palm-down) indicates a diminuendo. Changing the size of conducting movements frequently results in changes in the character of the music depending upon the circumstances.\\r\\n\\r\\nDynamics can be fine-tuned using various gestures: showing one's palm to the performers or leaning away from them may demonstrate a decrease in volume. To adjust the overall balance of the various instruments or voices, these signals can be combined or directed toward a particular section or performer.\\r\\n\\r\\nThe indication of entries, when a performer or section should begin playing (perhaps after a long period of rests), is called \\"cueing\\". A cue must forecast with certainty the exact moment of the coming ictus, so that all the players or singers affected by the cue can begin playing simultaneously. Cueing is most important for cases where a performer or section has not been playing for a lengthy time. Cueing is also helpful in the case of a pedal point with string players, when a section has been playing the pedal point for a lengthy period; a cue is important to indicate when they should change to a new note. Cueing is achieved by \\"engaging\\" the players before their entry (by looking at them) and executing a clear preparation gesture, often directed toward the specific players. An inhalation, which may or may not be a semi-audible \\"sniff\\" from the conductor, is a common element in the cueing technique of some conductors. Mere eye contact or a look in the general direction of the players may be sufficient in many instances, as when more than one section of the ensemble enters at the same time. Larger musical events may warrant the use of a larger or more emphatic cue designed to encourage emotion and energy.\\r\\n\\r\\nArticulation may be indicated by the character of the ictus, ranging from short and sharp for staccato, to long and fluid for legato. Many conductors change the tension of the hands: strained muscles and rigid movements may correspond to marcato, while relaxed hands and soft movements may correspond to legato or espressivo. Phrasing may be indicated by wide overhead arcs or by a smooth hand motion either forwards or side-to-side. A held note is often indicated by a hand held flat with palm up. The end of a note, called a \\"cutoff\\" or \\"release\\", may be indicated by a circular motion, the closing of the palm, or the pinching of finger and thumb. A release is usually preceded by a preparation and concluded with a complete stillness.\\r\\n\\r\\nConductors aim to maintain eye contact with the ensemble as much as possible, encouraging eye contact in return and increasing the dialogue between players/singers and conductor. Facial expressions may also be important to demonstrate the character of the music or to encourage the players.\\r\\n\\r\\nIn some cases, such as where there has been little rehearsal time to prepare a piece, a conductor may discreetly indicate how the bars of music will be beat immediately before the start of the movement by holding up their fingers in front of their chest (so only the performers can see). For example, in a 44 piece that the conductor will beat \\"in two\\" (two ictus points or beats per bar, as if it were 22), the conductor would hold up two fingers in front of his chest.\\r\\n\\r\\nIn most cases, there is a short pause between movements of a symphony, concerto or dance suite. This brief pause gives orchestra or choir members time to turn the pages of their part and ready themselves for the start of the next movement. String players may apply rosin or wipe sweat off their hands with a handkerchief. Reed players may take this time to change to a new reed. In some cases, woodwind or brass players will use the pause to switch to a different instrument (e.g., from trumpet to cornet or from clarinet to E? clarinet). If the conductor wishes to immediately begin one movement after another for musical reasons, this is called attacca. The conductor will instruct the orchestra members and choristers to write the term in their parts, so that they will be ready to go immediately to the next movement.\\r\\n\\r\\nThe roles of a conductor vary a great deal between different conducting positions and different ensembles. In some cases, a conductor will also be the musical director of the symphony, choosing the program for the entire season, including concerts by guest conductors, concerto soloists, pop concerts, and so on. A senior conductor may attend some or all of the auditions for new members of the orchestra, to ensure that the candidates have the playing style and tone that the conductor prefers and that candidates meet the highest performance standards. Some choral conductors are hired to prepare a choir for several weeks which will subsequently be directed by another conductor. The choral conductor is usually acknowledged for their preparatory work in the concert program.\\r\\n\\r\\nSome conductors may have a significant public relations role, giving interviews to the local news channel and appearing on television talk shows to promote the upcoming season or particular concerts. On the other hand, a conductor hired to guest conduct a single concert may only have the responsibility of rehearsing the orchestra for several pieces and conducting one or two concerts. While a handful of conductors have become well-known celebrities, such as Leonard Bernstein, most are only known within the classical music scene.\\r\\n\\r\\nClassical choral and instrumental conducting have established comprehensive systems of instruction and training. Aspiring conductors can study at colleges, conservatories, and universities. Conservatories, which are the standard musical training system in France and in Quebec (Canada) provide lessons and amateur conducting experience. Universities offer a range of conducting programs, including courses in conducting as part of bachelor's degrees, a small number of Master of Music degrees in conducting, and an even smaller number of Doctor of Musical Arts degrees in conducting. \\r\\n\\r\\nAs well, there are a variety of other training programs such as classical summer camps and training festivals, which give students the opportunity to conduct a wide range of music. Aspiring conductors need to obtain a broad education about the history of music, including the major periods of classical music and regarding music theory. Many conductors learn to play a keyboard instrument such as the piano or the pipe organ, a skill that helps them to be able to analyze symphonies and try out their interpretations before they have access to an orchestra to conduct. Many conductors get experience playing in an orchestra or singing in a choir, an experience which gives them good insights into how orchestras and choirs are conducted and rehearsed.\\r\\n\\r\\nIn 2014, orchestra conductors typically hold a master's degree in music and choir conductors in the US typically hold a bachelor's degree in music.[16] Bachelor's degrees (referred to as B.Mus. or B.M) are four-year programs that include conducting lessons, amateur orchestra experience, and a sequence of courses in music history, music theory, and liberal arts courses (e.g., English literature), which give the student a more well-rounded education. Students do not usually specialize in conducting at the B.Mus. stage; instead, they usually develop general music skills such as singing, playing an orchestral instrument, performing in a choir, playing in orchestra, and playing a keyboard instrument such as the piano or the organ. \\r\\n\\r\\nAnother topic that conducting students study is the languages used in Classical music opera. Orchestral conductors are expected to be able to rehearse and lead choirs in works for orchestra and choir. As such, orchestral conductors need to know the major languages used in choral writing (including French, Italian and Latin, among others) and they must understand the correct diction of these languages in a choral singing context. The opposite is also true: a choral conductor will be expected to rehearse and lead a string orchestra or full orchestra when performing works for choir and orchestra. As such, a choral conductor needs to know how to rehearse and lead instrument sections.\\r\\n\\r\\nMaster of music degrees (M.mus.) in conducting consist of private conducting lessons, ensemble experience, coaching, and graduate courses in music history and music theory, along with one or two conducted concerts. A Master's degree in music (referred to as an M.Mus. or M.M.) is often the required minimum credential for people who wish to become a professor of conducting.\\r\\n\\r\\nDoctor of Musical Arts (referred to as D.M.A., DMA, D.Mus.A. or A.Mus.D) degrees in conducting provide an opportunity for advanced study at the highest artistic and pedagogical level, requiring usually an additional 54+ credit hours beyond a master's degree (which is about 30+ credits beyond a bachelor's degree). For this reason, admission is highly selective. Examinations in music history, music theory, ear training/dictation, and an entrance examination and conducting audition are required. Students perform a number of conducted concerts, including a combination lecture-conducted concert with an accompanying doctoral dissertation, advanced coursework. Students must typically maintain a minimum B average. A DMA in conducting is a terminal degree, and as such, it qualifies the holder to teach in colleges, universities and conservatories. In addition to academic study, another part of the training pathway for many conductors is conducting amateur orchestras, such as youth orchestras, school orchestras and community orchestras.\\r\\n\\r\\nA small number of conductors become professionals without formal training in conducting. These individuals often have achieved renown as instrumental or vocal performers, and they have often undertaken a great deal of training in their area of expertise (instrumental performance or singing). Another way that a small number of conductors become professionals without formal training in conducting is by learning on the job by conducting amateur orchestras, school orchestras, and community orchestras (or the equivalent choral ensembles).\\r\\n\\r\\nThe average salary of conductors in the US in 2014 was $48,180. A 3% growth rate is forecast for conducting jobs from 2014 to 2024, a slower than average growth rate.[16]","input":"What is the conductor of an orchestra called?"},{"output":"steel","context":"Gunmetal, also known as red brass in the United States, is a type of bronze ÿ an alloy of copper, tin, and zinc. Proportions vary by source,[1][2] but 88% copper, 8ÿ10% tin, and 2ÿ4% zinc is an approximation. Originally used chiefly for making guns, it was eventually superseded in this department by steel. Gunmetal, which casts and machines well and is resistant to corrosion from steam and salt water,[3] is used to make steam and hydraulic castings, valves, gears, statues, and various small objects, such as buttons. It has a tensile strength of 221 to 310 MPa, a specific gravity of 8.7, a Brinell hardness of 65 to 74, and a melting point of around 1,000 degrees Celsius.\\r\\n\\r\\nGunmetal can also mean steel treated to simulate gunmetal bronze.[2] Bushings made of this metal are used in machinery.\\r\\n\\r\\nThe Victoria Cross, Britain's highest award for military valour, is traditionally made using gunmetal from a cannon captured at the Siege of Sevastopol during the Crimean War.\\r\\n\\r\\nThe British Gwalior Star medal, awarded to the British participants in the 1843 campaign against the Scindias, is made from guns captured at the Battles of Maharajpur and Punniar, during the Gwalior Campaign.\\r\\n\\r\\nGun money, Irish late 17th-century emergency coins, contain gunmetal, as worn and scrapped guns were used to make them; but also many other metals, in particular brass and bronze, as people donated pots and pans and other metal objects.\\r\\n\\r\\nGunmetal as a colour is entirely different from the reddish alloy of the same name described above. It is a shade of grey that has a bluish purplish tinge.[9]","input":"What type of metal are guns made of?"},{"output":"during the Civil War","context":"The history of taxation in the United States begins with the colonial protest against British taxation policy in the 1760s, leading to the American Revolution. The independent nation collected taxes on imports (\\"tariffs\\"), whiskey, and (for a while) on glass windows. States and localities collected poll taxes on voters and property taxes on land and commercial buildings. There are state and federal excise taxes. State and federal inheritance taxes began after 1900, while the states (but not the federal government) began collecting sales taxes in the 1930s. The United States imposed income taxes briefly during the Civil War and the 1890s. In 1913, the 16th Amendment was ratified, permanently legalizing an income tax.\\r\\n\\r\\n\\r\\nTaxes were low at the local, colonial and imperial levels throughout the colonial era.[1] The issue that led to the Revolution was whether parliament had the right to impose taxes on the Americans when they were not represented in parliament.\\r\\nThe Stamp Act of 1765 was the fourth Stamp Act to be passed by the Parliament of Great Britain and required all legal documents, permits, commercial contracts, newspapers, wills, pamphlets, and playing cards in the American colonies to carry a tax stamp. The exact date the Act was enacted was on November 1, 1765. The Act was enacted in order to defray the cost of maintaining the military presence protecting the colonies. Americans rose up in strong protest, arguing in terms of \\"No Taxation without Representation\\". Boycotts forced Britain to repeal the stamp tax, while convincing many British leaders it was essential to tax the colonists on something in order to demonstrate the sovereignty of Parliament.\\r\\nThe Townshend Revenue Act were two tax laws passed by Parliament in 1767; they were proposed by Charles Townshend, Chancellor of the Exchequer. They placed a tax on common products imported into the American Colonies, such as lead, paper, paint, glass, and tea. In contrast to the Stamp Act of 1765, the laws were not a direct tax that people paid daily, but a tax on imports that was collected from the ship's captain when he unloaded the cargo. The Townshend Acts also created three new admiralty courts to try Americans who ignored the laws.[2]\\r\\nThe tax on sugar, cloth and coffee. These were non-British exports.\\r\\nThe Tea Act of 1773 received the royal assent on May 10, 1773. This act was a \\"drawback on duties and tariffs\\" on tea. The act was designed to undercut tea smugglers to the benefit of the East India Company.\\r\\nThe Boston Tea Party was an act of protest by the American colonists against Great Britain for the Tea Act in which they dumped many chests of tea into Boston Harbor. The cuts to taxation on tea undermined American smugglers, who destroyed the tea in retaliation for its exemption from taxes. Britain reacted harshly, and the conflict escalated to war in 1775.\\r\\nAn assessment levied by the government upon a person at a fixed rate regardless of income or worth.\\r\\nTariffs have played different roles in trade policy and the economic history of the United States. Tariffs were the largest source of federal revenue from the 1790s to the eve of World War I, until it was surpassed by income taxes. Since the revenue from the tariff was considered essential and easy to collect at the major ports, it was agreed the nation should have a tariff for revenue purposes.[3][4]\\r\\nAnother role the tariff played was in the protection of local industry; it was the political dimension of the tariff. From the 1790s to the present day, the tariff (and closely related issues such as import quotas and trade treaties) generated enormous political stresses. These stresses lead to the Nullification crisis during the 19th century, and the creation of the World Trade Organization.\\r\\nWhen Alexander Hamilton was the United States Secretary of the Treasury he issued the Report on Manufactures, which reasoned that applying tariffs in moderation, in addition to raising revenue to fund the federal government, would also encourage domestic manufacturing and growth of the economy by applying the funds raised in part towards subsidies (called bounties in his time) to manufacturers. The main purposes sought by Hamilton through the tariff were to: (1) protect American infant industry for a short term until it could compete; (2) raise revenue to pay the expenses of government; (3) raise revenue to directly support manufacturing through bounties (subsidies).[5] This resulted in the passage of three tariffs by Congress, the Tariff of 1789, the Tariff of 1790, and the Tariff of 1792 which progressively increased tariffs.\\r\\nTariffs contributed to sectionalism between the North and the South. The Tariff of 1824 increased tariffs in order to protect American industry in the face of cheaper imported commodities such as iron products, wool and cotton textiles, and agricultural goods from England. This tariff was the first in which the sectional interests of the North and the South truly came into conflict because the South advocated lower tariffs in order to take advantage of tariff reciprocity from England and other countries that purchased raw agricultural materials from the South.[citation needed]\\r\\nThe Tariff of 1828, also known as the Tariff of Abominations, and the Tariff of 1832 accelerated sectionalism between the North and the South. For a brief moment in 1832, South Carolina made vague threats to leave the Union over the tariff issue.[6] In 1833, to ease North-South relations, Congress lowered the tariffs.[6] In the 1850s, the South gained greater influence over tariff policy and made subsequent reductions.[7]\\r\\nIn 1861, just prior to the Civil War, Congress enacted the Morrill Tariff, which applied high rates and inaugurated a period of relatively continuous trade protection in the United States that lasted until the Underwood Tariff of 1913. The schedule of the Morrill Tariff and its two successor bills were retained long after the end of the Civil War.[8]\\r\\nIn 1921, Congress sought to protect local agriculture as opposed to industry by passing the Emergency Tariff, which increased rates on wheat, sugar, meat, wool and other agricultural products brought into the United States from foreign nations, which provided protection for domestic producers of those items.\\r\\nHowever, one year later Congress passed another tariff, the Fordney-McCumber Tariff, which applied the scientific tariff and the American Selling Price. The purpose of the scientific tariff was to equalize production costs among countries so that no country could undercut the prices charged by American companies.[9] The difference of production costs was calculated by the Tariff Commission. A second novelty was the American Selling Price. This allowed the president to calculate the duty based on the price of the American price of a good, not the imported good.[9]\\r\\nDuring the outbreak of the Great Depression in 1930, Congress raised tariffs via the Smoot-Hawley Tariff Act on over 20,000 imported goods to record levels, and, in the opinion of most economists, worsened the Great Depression by causing other countries to reciprocate thereby plunging American imports and exports by more than half.[citation needed]\\r\\nIn 1948, the US signed the General Agreement on Tariffs and Trade (GATT), which reduced tariff barriers and other quantitative restrictions and subsidies on trade through a series of agreements.\\r\\nIn 1993, the GATT was updated (GATT 1994) to include new obligations upon its signatories. One of the most significant changes was the creation of the World Trade Organization (WTO). Whereas GATT was a set of rules agreed upon by nations, the WTO is an institutional body. The WTO expanded its scope from traded goods to trade within the service sector and intellectual property rights. Although it was designed to serve multilateral agreements, during several rounds of GATT negotiations (particularly the Tokyo Round) plurilateral agreements created selective trading and caused fragmentation among members. WTO arrangements are generally a multilateral agreement settlement mechanism of GATT.[10]\\r\\nFederal excise taxes are applied to specific items such as motor fuels, tires, telephone usage, tobacco products, and alcoholic beverages. Excise taxes are often, but not always, allocated to special funds related to the object or activity taxed.\\r\\nDuring the presidency of George Washington, Alexander Hamilton proposed a tax on distilled spirits to fund his policy of assuming the war debt of the American Revolution for those states which had failed to pay. After a vigorous debate, the House decided by a vote of 35-21 to approve legislation imposing a seven-cent-per-gallon excise tax on whiskey. This marks the first time in American history that Congress voted to tax an American product; this led to the Whiskey Rebellion.\\r\\nThe history of income taxation in the United States began in the 19th century with the imposition of income taxes to fund war efforts. However, the constitutionality of income taxation was widely held in doubt [Pollock v. Farmers' Loan & Trust Company, 157 U.S. 429 (1895)] \\"[11] until 1913 with the ratification of the 16th Amendment.\\r\\nArticle I, Section 8, Clause 1 of the United States Constitution assigns Congress the power to impose \\"Taxes, Duties, Imposts and Excises,\\" but Article I, Section 8 requires that, \\"Duties, Imposts and Excises shall be uniform throughout the United States.\\"[12]\\r\\nIn addition, the Constitution specifically limited Congress' ability to impose direct taxes, by requiring it to distribute direct taxes in proportion to each state's census population. It was thought that head taxes and property taxes (slaves could be taxed as either or both) were likely to be abused, and that they bore no relation to the activities in which the federal government had a legitimate interest. The fourth clause of section 9 therefore specifies that, \\"No Capitation, or other direct, Tax shall be laid, unless in Proportion to the Census or enumeration herein before directed to be taken.\\"\\r\\nTaxation was also the subject of Federalist No. 33 penned secretly by the Federalist Alexander Hamilton under the pseudonym Publius. In it, he explains that the wording of the \\"Necessary and Proper\\" clause should serve as guidelines for the legislation of laws regarding taxation. The legislative branch is to be the judge, but any abuse of those powers of judging can be overturned by the people, whether as states or as a larger group.\\r\\nWhat seemed to be a straightforward limitation on the power of the legislature based on the subject of the tax proved inexact and unclear when applied to an income tax, which can be arguably viewed either as a direct or an indirect tax. The courts have generally held that direct taxes are limited to taxes on people (variously called \\"capitation\\", \\"poll tax\\" or \\"head tax\\") and property.[13] All other taxes are commonly referred to as \\"indirect taxes\\".[14]\\r\\nIn order to help pay for its war effort in the American Civil War, Congress imposed its first personal income tax in 1861.[15] It was part of the Revenue Act of 1861 (3% of all incomes over US $800; rescinded in 1872). Congress also enacted the Revenue Act of 1862, which levied a 3% tax on incomes above $600, rising to 5% for incomes above $10,000. Rates were raised in 1864. This income tax was repealed in 1872.\\r\\nA new income tax statute was enacted as part of the 1894 Tariff Act.[16][17] At that time, the United States Constitution specified that Congress could impose a \\"direct\\" tax only if the law apportioned that tax among the states according to each state's census population.[18]\\r\\nIn 1895, the United States Supreme Court ruled, in Pollock v. Farmers' Loan & Trust Co., that taxes on rents from real estate, on interest income from personal property and other income from personal property (which includes dividend income) were direct taxes on property and therefore had to be apportioned. Since apportionment of income taxes is impractical, the Pollock rulings had the effect of prohibiting a federal tax on income from property. Due to the political difficulties of taxing individual wages without taxing income from property, a federal income tax was impractical from the time of the Pollock decision until the time of ratification of the Sixteenth Amendment (below).\\r\\nIn response to the Supreme Court decision in the Pollock case, Congress proposed the Sixteenth Amendment, which was ratified in 1913,[19] and which states:\\r\\nThe Congress shall have power to lay and collect taxes on incomes, from whatever source derived, without apportionment among the several States, and without regard to any census or enumeration.\\r\\nThe Supreme Court in Brushaber v. Union Pacific Railroad, 240 U.S. 1 (1916), indicated that the Sixteenth Amendment did not expand the federal government's existing power to tax income (meaning profit or gain from any source) but rather removed the possibility of classifying an income tax as a direct tax on the basis of the source of the income. The Amendment removed the need for the income tax on interest, dividends and rents to be apportioned among the states on the basis of population. Income taxes are required, however, to abide by the law of geographical uniformity.\\r\\nCongress enacted an income tax in October 1913 as part of the Revenue Act of 1913, levying a 1% tax on net personal incomes above $3,000, with a 6% surtax on incomes above $500,000. By 1918, the top rate of the income tax was increased to 77% (on income over $1,000,000, equivalent of 15,300,000 in 2012 dollars[20]) to finance World War I. The average rate for the rich however, was only 15%.[21] The top marginal tax rate was reduced to 58% in 1922, to 25% in 1925 and finally to 24% in 1929. In 1932 the top marginal tax rate was increased to 63% during the Great Depression and steadily increased, reaching 94% (on all income over $200,000, equivalent of 2,500,000 in 2012 dollars[22])in 1945. During World War II, Congress introduced payroll withholding and quarterly tax payments.[23]\\r\\nFollowing World War II tax increases, top marginal individual tax rates stayed near or above 90%, and the effective tax rate at 70% for the highest incomes (few paid the top rate), until 1964 when the top marginal tax rate was lowered to 70%. Kennedy explicitly called for a top rate of 65 percent, but added that it should be set at 70 percent if certain deductions weren't phased out at the top of the income scale.[24][25][26] The top marginal tax rate was lowered to 50% in 1982 and eventually to 28% in 1988. It slowly increased to 39.6% in 2000, then was reduced to 35% for the period 2003 through 2012.[23] Corporate tax rates were lowered from 48% to 46% in 1981 (PL 97-34), then to 34% in 1986 (PL 99-514), and increased to 35% in 1993.\\r\\nTimothy Noah, senior editor of the New Republic, argues that while Ronald Reagan made massive reductions in the nominal marginal income tax rates with his Tax Reform Act of 1986, this reform did not make a similarly massive reduction in the effective tax rate on the higher marginal incomes. Noah writes in his ten part series entitled \\"The Great Divergence,\\" that in 1979, the effective tax rate on the top 0.01 percent of taxpayers was 42.9 percent, according to the Congressional Budget Office, but that by Reagan's last year in office it was 32.2%. This effective rate on high incomes held steadily until the first few years of the Clinton presidency when it increased to a peak high of 41%. However, it fell back down to the low 30s by his second term in the White House. This percentage reduction in the effective marginal income tax rate for the wealthiest Americans, 9%, is not a very large decrease in their tax burden, according to Noah, especially in comparison to the 20% drop in nominal rates from 1980 to 1981 and the 15% drop in nominal rates from 1986 to 1987. In addition to this small reduction on the income taxes of the wealthiest taxpayers in America, Noah discovered that the effective income tax burden for the bottom 20% of wage earners was 8% in 1979 and dropped to 6.4% under the Clinton Administration. This effective rate further dropped under the George W. Bush Administration. Under Bush, the rate decreased from 6.4% to 4.3%. Looking at the simple math, reductions in the effective income tax burden on the poor coinciding with modest reductions in the effective income tax rate on the wealthiest 0.01% of tax payers could not alone have been the direct cause of increased income inequality that began in the 1980s.[27] These figures also correspond to an analysis of effective tax rates from 1979ÿ2005 by the Congressional Budget Office.[28]\\r\\nCongress re-adopted the income tax in 1913, levying a 1% tax on net personal incomes above $3,000, with a 6% surtax on incomes above $500,000. By 1918, the top rate of the income tax was increased to 77% (on income over $1,000,000) to finance World War I. The top marginal tax rate was reduced to 58% in 1922, to 25% in 1925, and finally to 24% in 1929. In 1932 the top marginal tax rate was increased to 63% during the Great Depression and steadily increased.\\r\\nDuring World War II, Congress introduced payroll withholding and quarterly tax payments. In pursuit of equality (rather than revenue) President Franklin D. Roosevelt proposed a 100% tax on all incomes over $25,000.[30][31] When Congress did not enact that proposal, Roosevelt issued an executive order attempting to achieve a similar result through a salary cap on certain salaries in connection with contracts between the private sector and the federal government.[32][33][34] For tax years 1944 through 1951, the highest marginal tax rate for individuals was 91%, increasing to 92% for 1952 and 1953, and reverting to 91% for tax years 1954 through 1963.[35]\\r\\nFor the 1964 tax year, the top marginal tax rate for individuals was lowered to 77%, and then to 70% for tax years 1965 through 1981. In 1978 income brackets were adjusted for inflation, so fewer people were taxed at high rates.[36] The top marginal tax rate was lowered to 50% for tax years 1982 through 1986.[37] Reagan undid 40% of his 1981 tax cut, in 1983 he hiked gas and payroll taxes, and in 1984 he raised tax revenue by closing loopholes for businesses.[38] According to historian and domestic policy adviser Bruce Bartlett, Reagan's 12 tax increases over the course of his presidency took back half of the 1981 tax cut.[39]\\r\\nFor tax year 1987, the highest marginal tax rate was 38.5% for individuals.[40] It was lowered to 28% in revenue neutral fashion, eliminating many loopholes and shelters, along with in corporate taxes, (with a 33% \\"bubble rate\\") for tax years 1988 through 1990.[41][42] Ultimately, the combination of base broadening and rate reduction raised revenue equal to about 4% of existing tax revenue[43]\\r\\nFor the 1991 and 1992 tax years, the top marginal rate was increased to 31% in a budget deal President George H. W. Bush made with the Congress.[44]\\r\\nIn 1993 the Clinton administration proposed and the Congress accepted (with no Republican support) an increase in the top marginal rate to 39.6% for the 1993 tax year, where it remained through tax year 2000.[45]\\r\\nIn 2001, President George W. Bush proposed and the Congress accepted an eventual lowering of the top marginal rate to 35%. However, this was done in stages: with a highest marginal rate of 39.1% for 2001, then 38.6% for 2002 and finally 35% for years 2003 through 2010.[46] This measure had a sunset provision and was scheduled to expire for the 2011 tax year, when rates would have returned to those adopted during the Clinton years unless Congress changed the law;[47] Congress did so by passing the Tax Relief, Unemployment Insurance Reauthorization and Job Creation Act of 2010, signed by President Barack Obama on December 17, 2010.\\r\\nAt first the income tax was incrementally expanded by the Congress of the United States, and then inflation automatically raised most persons into tax brackets formerly reserved for the wealthy until income tax brackets were adjusted for inflation. Income tax now applies to almost two-thirds of the population.[48] The lowest earning workers, especially those with dependents, pay no income taxes as a group and actually get a small subsidy from the federal government because of child credits and the Earned Income Tax Credit.[citation needed]\\r\\nWhile the government was originally funded via tariffs upon imported goods, tariffs now represent only a minor portion of federal revenues. Non-tax fees are generated to recompense agencies for services or to fill specific trust funds such as the fee placed upon airline tickets for airport expansion and air traffic control. Often the receipts intended to be placed in \\"trust\\" funds are used for other purposes, with the government posting an IOU ('I owe you') in the form of a federal bond or other accounting instrument, then spending the money on unrelated current expenditures.\\r\\nNet long-term capital gains as well as certain types of qualified dividend income are taxed preferentially. The federal government collects several specific taxes in addition to the general income tax. Social Security and Medicare are large social support programs which are funded by taxes on personal earned income (see below).\\r\\nTax statutes passed after the ratification of the Sixteenth Amendment in 1913 are sometimes referred to as the \\"modern\\" tax statutes. Hundreds of Congressional acts have been passed since 1913, as well as several codifications (i.e., topical reorganizations) of the statutes (see Codification).\\r\\nThe modern interpretation of the Sixteenth Amendment taxation power can be found in Commissioner v. Glenshaw Glass Co. 348 U.S. 426 (1955). In that case, a taxpayer had received an award of punitive damages from a competitor, and sought to avoid paying taxes on that award. The U.S. Supreme Court observed that Congress, in imposing the income tax, had defined income to include:\\r\\ngains, profits, and income derived from salaries, wages, or compensation for personal service . . . of whatever kind and in whatever form paid, or from professions, vocations, trades, businesses, commerce, or sales, or dealings in property, whether real or personal, growing out of the ownership or use of or interest in such property; also from interest, rent, dividends, securities, or the transaction of any business carried on for gain or profit, or gains or profits and income derived from any source whatever.[49]\\r\\nThe Court held that \\"this language was used by Congress to exert in this field the full measure of its taxing power\\", id., and that \\"the Court has given a liberal construction to this broad phraseology in recognition of the intention of Congress to tax all gains except those specifically exempted.\\"[50]\\r\\nThe Court then enunciated what is now understood by Congress and the Courts to be the definition of taxable income, \\"instances of undeniable accessions to wealth, clearly realized, and over which the taxpayers have complete dominion.\\" Id. at 431. The defendant in that case suggested that a 1954 rewording of the tax code had limited the income that could be taxed, a position which the Court rejected, stating:\\r\\nThe definition of gross income has been simplified, but no effect upon its present broad scope was intended. Certainly punitive damages cannot reasonably be classified as gifts, nor do they come under any other exemption provision in the Code. We would do violence to the plain meaning of the statute and restrict a clear legislative attempt to bring the taxing power to bear upon all receipts constitutionally taxable were we to say that the payments in question here are not gross income.[51]\\r\\nIn Conner v. United States,[52] a couple had lost their home to a fire, and had received compensation for their loss from the insurance company, partly in the form of hotel costs reimbursed. The U.S. District Court acknowledged the authority of the IRS to assess taxes on all forms of payment, but did not permit taxation on the compensation provided by the insurance company, because unlike a wage or a sale of goods at a profit, this was not a gain. As the court noted, \\"Congress has taxed income, not compensation\\".[53] By contrast, at least two Federal courts of appeals have indicated that Congress may constitutionally tax an item as \\"income,\\" regardless of whether that item is in fact income. See Penn Mutual Indemnity Co. v. Commissioner[54] and Murphy v. Internal Revenue Serv.[55]\\r\\nThe origins of the estate and gift tax occurred during the rise of the state inheritance tax in the late 19th century and the progressive era.\\r\\nIn the 1880s and 1890s many states passed inheritance taxes, which taxed the donees on the receipt of their inheritance. While many objected to the application of an inheritance tax, some including Andrew Carnegie and John D. Rockefeller supported increases in the taxation of inheritance.[56]\\r\\nAt the beginning of the 20th century President Theodore Roosevelt advocated the application of a progressive inheritance tax on the federal level.[57]\\r\\nIn 1916, Congress adopted the present federal estate tax, which instead of taxing the wealth that a donee inherited as occurred in the state inheritance taxes it taxed the wealth of a donor's estate upon transfer.\\r\\nLater, Congress passed the Revenue Act of 1924, which imposed the gift tax, a tax on gifts given by the donor.\\r\\nIn 1948 Congress allowed marital deductions for the estate and the gift tax. In 1981, Congress expanded this deduction to an unlimited amount for gifts between spouses.[58]\\r\\nToday, the estate tax is a tax imposed on the transfer of the \\"taxable estate\\" of a deceased person, whether such property is transferred via a will or according to the state laws of intestacy. The estate tax is one part of the Unified Gift and Estate Tax system in the United States. The other part of the system, the gift tax, imposes a tax on transfers of property during a person's life; the gift tax prevents avoidance of the estate tax should a person want to give away his/her estate just before dying.\\r\\nIn addition to the federal government, many states also impose an estate tax, with the state version called either an estate tax or an inheritance tax. Since the 1990s, the term \\"death tax\\" has been widely used by those who want to eliminate the estate tax, because the terminology used in discussing a political issue affects popular opinion.[59]\\r\\nIf an asset is left to a spouse or a charitable organization, the tax usually does not apply. The tax is imposed on other transfers of property made as an incident of the death of the owner, such as a transfer of property from an intestate estate or trust, or the payment of certain life insurance benefits or financial account sums to beneficiaries.\\r\\nPrior to the Great Depression, the following economic problems were considered great hazards to working-class Americans:\\r\\nIn the 1930s, the New Deal introduced Social Security to rectify the first three problems (retirement, injury-induced disability, or congenital disability). It introduced the FICA tax as the means to pay for Social Security.\\r\\nIn the 1960s, Medicare was introduced to rectify the fourth problem (health care for the elderly). The FICA tax was increased in order to pay for this expense.\\r\\nPresident Franklin D. Roosevelt introduced the Social Security (FICA) Program. FICA began with voluntary participation, participants would have to pay 1% of the first $1,400 of their annual incomes into the Program, the money the participants elected to put into the Program would be deductible from their income for tax purposes each year, the money the participants put into the independent \\"Trust Fund\\" rather than into the General operating fund, and therefore, would only be used to fund the Social Security Retirement Program, and no other Government program, and, the annuity payments to the retirees would never be taxed as income.[citation needed]\\r\\nDuring the Lyndon B. Johnson administration Social Security moved from the trust fund to the general fund.[citation needed] Participants may not have an income tax deduction for Social Security withholding.[citation needed] Immigrants became eligible for Social Security benefits during the Carter administration.[citation needed] During the Reagan administration Social Security annuities became taxable.[60]\\r\\nThe alternative minimum tax (AMT) was introduced by the Tax Reform Act of 1969,[61] and became operative in 1970. It was intended to target 155 high-income households that had been eligible for so many tax benefits that they owed little or no income tax under the tax code of the time.[62]\\r\\nIn recent years, the AMT has been under increased attention. With the Tax Reform Act of 1986, the AMT was broadened and refocused on home owners in high tax states. Because the AMT is not indexed to inflation and recent tax cuts,[62][63] an increasing number of middle-income taxpayers have been finding themselves subject to this tax.\\r\\nIn 2006, the IRS's National Taxpayer Advocate's report highlighted the AMT as the single most serious problem with the tax code. The advocate noted that the AMT punishes taxpayers for having children or living in a high-tax state, and that the complexity of the AMT leads to most taxpayers who owe AMT not realizing it until preparing their returns or being notified by the IRS. [2]\\r\\nThe origins of the income tax on gains from capital assets did not distinguish capital gains from ordinary income. From 1913 to 1921, income from capital gains were taxed at ordinary rates, initially up to a maximum rate of 7 percent.[64]\\r\\nCongress began to distinguish the taxation of capital gains from the taxation of ordinary income according to the holding period of the asset with the Revenue Act of 1921, allowed a tax rate of 12.5 percent gain for assets held at least two years.[64]\\r\\nIn addition to different tax rates depending on holding period, Congress began excluding certain percentages of capital gains depending on holding period. From 1934 to 1941, taxpayers could exclude percentages of gains that varied with the holding period: 20, 40, 60, and 70 percent of gains were excluded on assets held 1, 2, 5, and 10 years, respectively.[64] Beginning in 1942, taxpayers could exclude 50 percent of capital gains from income on assets held at least six months or elect a 25 percent alternative tax rate if their ordinary tax rate exceeded 50 percent.[64]\\r\\nCapital gains tax rates were significantly increased in the 1969 and 1976 Tax Reform Acts.[64]\\r\\nThe 1970s and 1980s saw a period of oscillating capital gains tax rates. In 1978, Congress reduced capital gains tax rates by eliminating the minimum tax on excluded gains and increasing the exclusion to 60 percent, thereby reducing the maximum rate to 28 percent.[64] The 1981 tax rate reductions further reduced capital gains rates to a maximum of 20 percent.\\r\\nLater in the 1980s Congress began increasing the capital gains tax rate and repealing the exclusion of capital gains. The Tax Reform Act of 1986 repealed the exclusion from income that provided for tax-exemption of long term capital gains, raising the maximum rate to 28 percent (33 percent for taxpayers subject to phaseouts).[64] When the top ordinary tax rates were increased by the 1990 and 1993 budget acts, an alternative tax rate of 28 percent was provided.[64] Effective tax rates exceeded 28 percent for many high-income taxpayers, however, because of interactions with other tax provisions.[64]\\r\\nThe end of the 1990s and the beginning of the present century heralded major reductions in taxing the income from gains on capital assets. Lower rates for 18-month and five-year assets were adopted in 1997 with the Taxpayer Relief Act of 1997.[64] In 2001, President George W. Bush signed the Economic Growth and Tax Relief Reconciliation Act of 2001, into law as part of a $1.35 trillion tax cut program.\\r\\nThe United States' corporate tax rate was at its highest, 52.8 percent, in 1968 and 1969. The top rate was hiked last in 1993 to 35 percent.[65] Under the \\"Tax Cuts and Jobs Act\\" of 2017, the rate adjusted to 21 percent.","input":"When was the first income tax law enacted?"},{"output":"Roger Williams","context":"The First Baptist Church in America is the First Baptist Church of Providence, Rhode Island, also known as the First Baptist Meetinghouse. It is the oldest Baptist church congregation in the United States, founded by Roger Williams in Providence, Rhode Island in 1638. The present church building was erected in 1774ÿ75 and held its first meetings in May 1775. It is located at 75 North Main Street in Providence's College Hill neighborhood and is a National Historic Landmark.\\r\\n\\r\\n\\r\\nRoger Williams had been holding religious services in his home for nearly a year before he converted his congregation into a Baptist church in 1638. This followed his founding of Providence in 1636. For the next sixty years, the congregation met outside in nice weather or in congregants' homes. Baptists in Rhode Island through most of the 17th century declined to erect meetinghouses because they felt that buildings reflected vanity. Eventually, however, they came to see the utility of some gathering place, and they erected severely plain-style meetinghouses like the Quakers.\\r\\nRoger Williams was a Calvinist, but within a few years of its founding, the congregation became more Arminian, and was clearly a General Six-Principle Baptist church by 1652. It remained a General Baptist church until it switched back to a Calvinist variety under the leadership of James Manning in the 1770s. Following Williams as pastor of the church was Rev. Chad Brown, founder of the famous Brown family of Rhode Island. A number of the streets in Providence bear the names of pastors of First Baptist Church, including Williams, Brown, Gregory Dexter, Thomas Olney, William Wickenden, Manning, and Stephen Gano. In 1700 Reverend Pardon Tillinghast built the first church building, a 400-square-foot (37?m2) structure, near the corner of Smith and North Main Streets. In 1711 he donated the building and land to the church in a deed describing the church as General Six-Principle Baptist in theology. In 1736 the congregation built its second meetinghouse on an adjoining lot at the corner of Smith and North Main Streets. This building was about 40 G 40 feet square.\\r\\nWhen it was built in 1774ÿ75, the current Meeting House represented a dramatic departure from the traditional Baptist meetinghouse style. It was the first Baptist meetinghouse to have a steeple and bell, making it more like Anglican and Congregational church buildings. The builders were part of a movement among Baptists in the urban centers of Boston, Newport, New York, and Philadelphia to bring respectability and recognition to Baptists.\\r\\nCentral to that movement was the creation of an educated ministry and the founding of a college. The Philadelphia Association of Baptist Churches sent Dr. James Manning to Rhode Island to found the College in the English Colony of Rhode Island and Providence Plantations (later renamed Brown University) in 1764. Beginning in Warren, the college then relocated to Providence in 1770. The college president, the Reverend Manning was called to be the pastor of the Providence church in 1771, and during his ministry the present Meeting House was erected \\"for the publick worship of Almighty God and also for holding commencement in.\\"[3] Subsequent Brown presidents Maxcy and Wayland also served as ministers at the church. The Brown family that soon gave its name to the University were prominent members of the Church, and descendants of founders of the Church, as well as, the Rhode Island Colony (the second pastor of the congregation after Roger Williams was Rev. Chad Brown). Although the university is now secular, in honor of its history and tradition, the Meeting House continues, as it has since 1776, to be the site for Brown University's undergraduate commencement.[4]\\r\\nConstruction began on the building in the summer of 1774, and it was the biggest building project in New England at the time. Due to the closure of the Massachusetts ports by the British as punishment for the Boston Tea Party, out-of-work ship builders and carpenters came to Providence to work on the Meeting House. The main portion of the Meeting House was dedicated in mid-May 1775, and the steeple erected in just three days in the first week of June. Notable additions to the Meeting House have included a Waterford crystal chandelier given by Hope Brown Ives (1792), a large pipe organ given by her brother Nicholas Brown, Jr., the younger (1834), the creation of rooms for Sunday school, fellowship hall, and offices on the lower level (1819ÿ59), and an addition to the east end of the Meeting House to accommodate an indoor baptistery (1884). The building was designated a National Historic Landmark in 1960, and listed on the National Register of Historic Places in 1966.[2][1]\\r\\nIn addition to weekly worship services, the Meeting House hosts concerts, talks, and lectures by world-renowned artists, performers, academics, and elected officials. Brown University holds commencement services at The Meeting House.\\r\\nIn 2001, History professor J. Stanley Lemons wrote a history of the church, entitled First: The History of the First Baptist Church in America[5][6]\\r\\nThe First Baptist Church in America is affiliated with the American Baptist Churches of Rhode Island (ABCORI) and the American Baptist Churches/USA (ABCUSA). The church actively supports the Rhode Island State Council of Churches, the National Council of Churches, the Baptist World Alliance, and the Baptist Joint Committee for Religious Liberty. Many members have served in various denominational, academic, and divinity school positions, including the presidency of Brown University.\\r\\nFirst Baptist Church in America in the 1800s\\r\\nFirst Baptist Church in undated postcard\\r\\nInterior view\\r\\nSteeple viewed from east.","input":"Who founded the first baptist church in america?"},{"output":"December 18, 1993","context":"The MGM Grand Las Vegas (formerly Marina and MGM-Marina) is a hotel and casino located on the Las Vegas Strip in Paradise, Nevada. The MGM Grand is the largest single hotel in the United States with 5,124 rooms. It is also the third-largest hotel complex in the world by number of rooms and second-largest hotel resort complex in the United States behind the combined The Venetian and The Palazzo. When it opened in 1993, the MGM Grand was the largest hotel complex in the world.\\r\\nOwned and operated by MGM Resorts International, the 30-floor main building is 293?ft (89?m) high. The property includes five outdoor pools, rivers, and waterfalls that cover 6.6 acres (2.7?ha),[1] a 380,000?sq?ft (35,000?m2) convention center, the MGM Grand Garden Arena, and the Grand Spa. It also houses numerous shops, night clubs, restaurants and the largest casino in Clark County, which occupies 171,500?sq?ft (15,930?m2).\\r\\nLocated on the Tropicana - Las Vegas Boulevard intersection, pedestrians are not allowed to cross at street level. Instead, the MGM Grand is linked by overhead pedestrian bridges to its neighboring casinos: to the south across Tropicana Avenue, the Tropicana, and to the west across the Strip, New York-New York.\\r\\n\\r\\n\\r\\nThe property was originally the site of the Golf Club Motel during the 1960s.[2] In 1972, Tom Wiesner co-founded Southwest Securities Development Company, and later founded Wiesner Investment Company.[3] In November 1973, Southwest Securities Development was planning the Airport Marina Hotel, to be built at the site of the 170-room Golf Club Motel, which was located near McCarran International Airport. Southwest planned to renovate the motel structure and add a 14-story addition with 518 rooms. Fred Harvey Company would serve as the operator of the hotel, its restaurants, and other areas of the resort. Fred Harvey had previously opened hotels in other parts of the United States under the Airport Marina name. Southwest also planned to construct a 28,400?sq?ft (2,640?m2) casino that would operate separately from Fred Harvey.[4]\\r\\nThe 700-room Marina, located at 3805 South Las Vegas Boulevard, was built by Wiesner Investment Company and was opened in 1975.[3][5] In 1989, Wiesner and his partners sold the Marina to Kirk Kerkorian,[6] who also bought the Tropicana Country Club, located behind the Marina and across Tropicana Avenue from the Tropicana and San Rmo hotels to obtain the site that would become the home of the MGM Grand. Kerkorian saw the Marina as a stable and solidly built resort, and decided not to destroy the hotel, but to build around it.[7] During that time, the Marina was known as the MGM-Marina Hotel.[8][9][10]\\r\\nThe Marina closed on November 30, 1990, and ground was broken for the new casino hotel complex on October 7, 1991. The Marina hotel building still exists as the west wing of the main hotel building.[8][9]\\r\\nWhen the latest MGM Grand opened on December 18, 1993, it was owned by MGM Grand Inc. At that time it had an extensive Wizard of Oz theme, including the green \\"Emerald City\\" color of the building and the decorative use of Wizard of Oz memorabilia. After entering the casino's main entrance, one would find themselves in the Oz Casino facing Emerald City. Dorothy, the Scarecrow, the Tin Man, and the Cowardly Lion were seen in front of the city. The Emerald City attraction featured an elaborate yellow brick road walk-through, complete with the cornfield, apple orchard, and haunted forest, as well as audio-animatronic figures of Dorothy, the Scarecrow, the Tin Man, the Cowardly Lion, and the Wicked Witch of the West. It would end at the door of the city, leading inside for a performance of \\"The Wizard's Secrets\\". When MGM Grand began its extensive refurbishment in 1996, the Oz Casino was the first to go. The Emerald City was completely demolished, and the Emerald City Gift Shop was moved to a new shopping section of the casino. The store remained open until early 2003.\\r\\nOriginally, the main entrance on the Strip was under the head of a giant cartoon-like version of MGM's logo, Leo the Lion, but this entrance feature was changed to a more traditional entrance. In 1998, a large bronze statue of Leo was added above the entrance to keep with the MGM Lion theme, while not scaring away guests. The statue weighs 50 tons, and at 45 feet (14?m) tall, on a 25-foot pedestal, is the largest bronze statue in the U.S.[11]\\r\\nWhen the MGM Grand opened, the intention was to create the first true destination hotel in the Las Vegas area by including the MGM Grand Adventures Theme Park behind the casino. The plan was to make the Las Vegas Strip more family friendly by providing activities for those too young to linger inside the casino. The theme park performed poorly and did not reopen for the 2001 season. On December 5, 2002, MGM Resorts International (then named MGM Mirage) announced that the former theme park would be developed as a luxury condominium and hotel complex called The Signature at MGM Grand.\\r\\nThe Las Vegas Monorail was built to connect MGM Grand to Bally's in 1995. The coming-out party for the monorail, on behalf of Bally's, consisted of showgirls and guys from Bally's famed show, Jubilee!, helping groups to the monorail. Characters from the Wizard of Oz greeted the groups on the MGM side. The track was later updated to become the southernmost section of the Las Vegas Monorail. The MGM Grand station was refurbished, the trains were replaced with Bombardier M-VI's, and the track was extended beyond the southern station to provide for track switching for the trains, as well as a starting point for a potential future southern extension to the monorail line.\\r\\nIn 2000, in an attempt to appeal to a more \\"mature\\" clientele, the hotel underwent a major renovation, and almost all traces of the Oz theme were removed. The theme is now more of the Art Deco era of classic Hollywood, and the hotel started billing itself as The City of Entertainment. More recently, the resort has used the phrase \\"Maximum Vegas\\", referring to the vast amount of activities MGM Grand offers its guests.\\r\\nOn April 26, 2000, MGM opened a new satellite registration/hotel check-in center at McCarran International Airport. This was the first of its kind opened by a hotel company at any United States airport.[12] However, this airport check-in center appears to have closed in late 2013.\\r\\nIn 2005, MGM opened the West Wing, a renovation of the original Marina Hotel rooms.\\r\\nIn October 2011, MGM began a renovation in which all of its rooms and suites in the main tower were fully renovated, along with the casino floor and other public areas. This has provided the hotel with a more contemporary room design. The work was completed in September 2012.\\r\\nA parody of the MGM Grand was featured in the BMX video game Mat Hoffman's Pro BMX 2. Leo the Lion was replaced with dragons.\\r\\nThe MGM Grand was among many casinos at which the MIT Blackjack Team gambled in the book Bringing Down The House.\\r\\nThe MGM Grand is the home base of David Whele in Dominion.\\r\\nThe MGM Grand has one of the largest gaming floors in all of Las Vegas, measuring 171,500 square feet (15,930?m2). There are more than 2,500 machines for gaming as well as 139 poker and table games.[15]\\r\\nThe slot machines at the MGM Grand range from 1S to $1,000 and include progressive slots, video poker, and multi-game machines. There is a special High Limit Slots area, featuring slot machines with payouts up to $500,000.\\r\\nThe race and sports book is a state of-the-art betting area that features thirty-six 60-inch plasma TVs, along with twenty-four 42-inch plasmas. Bets are offered on a range of sports including soccer, football, boxing, MMA and more. They are also the first room to offer what they call \\"SkyBoxes\\". These boxes can hold up to ten guests and come with beverage servers and complimentary food.[16]\\r\\nThe hotel rooms are located in several buildings including:\\r\\nThe Signature at MGM Grand is a condo hotel project by MGM Mirage and Turnberry Associates, who teamed up to build the three currently open Signature at the MGM Grand towers. The 38-story, 475-foot (145?m) tall structures have 576 all-suite units each and were priced from $450,000 to more than $2.0 million. Signature is located on the property where the MGM Grand Adventures Theme Park once stood. Each tower has its own private pool with cabanas as well as access to MGM Grand pools. Additional guest/owner amenities at The Signature include a Starbucks, meeting rooms, exercise room, bar and restaurant. Each tower is connected with walkways including moving walkways for the connection to the MGM Grand.","input":"When was the mgm grand built in las vegas?"},{"output":"Mount Mitchell","context":"Mount Mitchell is the highest peak of the Appalachian Mountains and the highest peak in mainland eastern North America. It is located near Burnsville in Yancey County, North Carolina, in the Black Mountain subrange of the Appalachians, and about 19 miles (31?km) northeast of Asheville. It is protected by Mount Mitchell State Park and surrounded by the Pisgah National Forest. Mount Mitchell's elevation is 6,684 feet (2,037?m) above sea level.[1]\\r\\n\\r\\n\\r\\nThe peak is the highest mountain in the United States east of the Mississippi River, and the highest in all of eastern North America south of the Arctic Cordillera. The nearest higher peaks are in the Black Hills of South Dakota and the highland foothills of Colorado.\\r\\nThe mountain, previously known as Black Dome for its rounded shape, was named after Elisha Mitchell, a professor at the University of North Carolina, who first explored the Black Mountain region in 1835, and determined that the height of the range exceeded by several hundred feet that of Mount Washington in New Hampshire, commonly thought at the time to be the highest point east of the Rocky Mountains. Mitchell fell to his death at nearby Mitchell Falls in 1857, having returned to verify his earlier measurements.\\r\\nA 4.6-mile (7.4?km) road (NC 128) connects the scenic Blue Ridge Parkway to a parking lot where a steep paved 980-foot (300?m) trail leads through a conifer forest to the summit. The 40-foot (12?m) stone observation tower on the summit was torn down in late 2006. A new observation deck was constructed and opened to visitors in January 2009.[3] Also on the summit is the tomb of Dr. Mitchell.\\r\\nMount Mitchell was formed during the Precambrian when marine deposits were metamorphosed into gneiss and schist. These metasedimentary rocks were later uplifted during the Alleghenian orogeny.[4] The soils are well drained, dark brown and stony with fine-earth material ranging in texture from sandy clay loam to loam or sandy loam; Burton and Craggey are the most common series around the summit.[5]\\r\\nThe mountain's summit is coated in a dense stand of Southern Appalachian spruce-fir forest, which consists primarily of two evergreen species the red spruce and the Fraser fir. Most of the mature Fraser firs, however, were killed off by the non-native Balsam woolly adelgid in the latter half of the 20th century. The high elevations also expose plant life to high levels of pollution, including acid precipitation in the form of rain, snow, and fog. These acids damage the red spruce trees in part by releasing natural metals from the soil like aluminum, and by leaching important minerals. To what extent this pollution harms the high-altitude ecosystem is debatable.[7]\\r\\nWhile the mountain is still mostly lush and green in the summer, many dead Fraser fir trunks can be seen due to these serious problems. Repairing the damage is a difficult issue, as the pollutants are often carried in from long distances. Sources can be local or hundreds of miles or kilometers away, requiring cooperation from as far away as the Midwest.\\r\\nWildflowers are abundant all summer long. Young fir and spruce trees do well in the subalpine climate, and their pine cones feed the birds along with wild blueberry and blackberry shrubs.\\r\\nThe second highest point in eastern North America, Mount Craig at 6,647 feet (2,026?m), is roughly a mile to the north of Mount Mitchell.\\r\\nThe summit area of Mount Mitchell is marked by a humid continental climate (K?ppen Dfb) bordering extremely close to a subalpine climate (k?ppen climate classification Dfc), with mild summers and long, moderately cold winters, being more similar to southeastern Canada than the southeastern U.S.. The monthly daily average temperature ranges from 25.2?F (?3.8?C) in January to 59.1?F (15.1?C) in July. The coldest temperature ever recorded in the state occurred there on January 21, 1985 when it fell to ?34?F (?37?C), during a severe cold spell that brought freezing temperatures as far south as Miami. It is also the coldest average reporting station in the state at 43.8?F (6.6?C) (based on data collected from 1971 to 2000) which is well below any other station.[8] Unlike the lower elevations in the surrounding regions, heavy snows often fall from December to March, with 50 inches (127?cm) accumulating in the Great Blizzard of 1993 and 66 inches (168?cm) in the January 2016 blizzard.[9][8] Snow flurries have been reported on the summit even in the summer months of June, July, and August. Due to the high elevation, precipitation is heavy and reliable year-round, averaging 74.7 inches (1,900?mm) for the year, with no month receiving less than 5?in (127?mm) of average precipitation. The summit is often windy, with gusts that can blow up to 178?mph (286?km/h).[10]\\r\\n?\\r\\nSign atop Mt. Mitchell\\r\\nMount Mitchell; View From the Top.\\r\\nMount Gibbes, Clingman's Peak, and Potato Knob from the southwest on the Blue Ridge Parkway\\r\\nBlack Mountains from the Blue Ridge Parkway\\r\\nForest floor high on Mount Mitchell\\r\\nExample of the spruce-fir forest near the top of Mount Mitchell","input":"What is the highest peak in north carolina?"},{"output":"autosomal dominant","context":"","input":"What type of genetic mutation is huntington's disease?"},{"output":"Swedish Social Democratic Party","context":"Politics of Sweden takes place in a framework of a parliamentary representative democratic constitutional monarchy. Executive power is exercised by the government, led by the Prime Minister of Sweden. Legislative power is vested in both the government and parliament, elected within a multi-party system. The Judiciary is independent, appointed by the government and employed until retirement. Sweden is a monarchy.\\r\\nSweden has a typical Western European history of democracy, beginning with the old Viking age Ting electing kings, ending with a regular royal power in the 14th century, that in periods became more or less democratic depending on the general European trends. The current democratic regime is a product of a stable development of successively added democratic institutions introduced during the 19th century up to 1921, when women's suffrage was introduced. The Government of Sweden has adhered to parliamentarism  de jure since 1975, de facto since 1917.\\r\\nSince the Great Depression, Swedish national politics has largely been dominated by the Social Democratic Workers' Party, which has held a plurality (and sometimes a majority) in parliament since 1917.\\r\\n\\r\\n\\r\\nThe Constitution of Sweden consists of four fundamental laws. The most important is the Instrument of Government of 1974 which sets out the basic principles of political life in Sweden, defining rights and freedoms. The Act of Succession is a treaty between the old Riksdag of the Estates and House of Bernadotte regulating their rights to accede to the Swedish throne.\\r\\nThe four fundamental laws are:\\r\\nThe highest executive authority of the State is vested in the Government, which consists of a Prime Minister and roughly 22 Ministers who head the ministries. The Ministers are appointed at the sole discretion of the Prime Minister. The Prime Minister is nominated by the Speaker and appointed following a vote in the Riksdag itself. The Monarch plays no part in this process. The only way to get rid of a government is through a motion of no confidence (misstroendevotum) in the Riksdag. This motion must get a majority of the total amount of votes in the Riksdag (at least 175). Another example of the power the legislature has given the Government is the adoption of the budget in the Riksdag. The Government's proposition to budget is adopted, unless a majority of the members of the Riksdag vote against it. This to make it possible to govern even in minority.\\r\\nThe unicameral Riksdag has 349 members, popularly elected every 4 years. It is in session generally from September through mid-June.\\r\\nLegislation may be initiated by the Cabinet or by members of the Riksdag. Members are elected on the basis of proportional representation for a four-year term. The Riksdag can alter the Constitution of Sweden, but only with approval by a supermajority and confirmation after the following general elections.\\r\\nThe Swedish Social Democratic Party has played a leading political role since 1917, after Reformists confirmed their strength and the revolutionaries left the party. After 1932, the Cabinets have been dominated by the Social Democrats. Only five general elections (1976, 1979, 1991, 2006 and 2010) have given the centre-right bloc enough seats in the Riksdag to form a government. This is considered one reason for the Swedish post-war welfare state, with a government expenditure of slightly more than 50% of the gross domestic product.\\r\\nSwedish law, drawing on Germanic, Roman, and Anglo-American law, is neither as codified as in France and other countries influenced by the Napoleonic Code, nor as dependent on judicial practice and precedents as in the United States.\\r\\nSweden has a history of strong political involvement by ordinary people through its \\"popular movements\\" (Folkr?relser in Swedish), the most notable being trade unions, the women's movement, the temperance movement, and  more recently  sports movement. Election turnout in Sweden has always been high in international comparisons, although it has declined in recent decades, and is around 82 percent (81.99 in Sweden general election, 2006).\\r\\nSome Swedish political figures that have become known worldwide include Joe Hill, Carl Skoglund, Raoul Wallenberg, Folke Bernadotte, Dag Hammarskj?ld, Olof Palme, Carl Bildt, Hans Blix, and Anna Lindh.\\r\\nAccording to a survey investigation by the sociologist Jenny Hansson,[2] Swedish national parliamentarians have an average work week of 66 hours, including side responsibilities. Hansson's investigation further reports that the average Swedish national parliamentarian sleeps 6.5 hours per night.\\r\\nSweden is divided into 21 counties. In each county there is a county administrative board and a county council. Each county contains several municipalities, in total 290. Stockholm is the capital of Sweden. The King, the Riksdag and the Government have their permanent seat in Stockholm. Up to 1968 when the Overgovernor's Office was incorporated into Stockholm County, it had a special status.\\r\\nAfter the 1973 oil crisis, the energy politics were determined to become less dependent on the import of petroleum. Since then, electricity has been generated mostly from hydropower and nuclear power. Sweden wants to be independent of petroleum use by 2020. The Three Mile Island accident (United States) prompted the Swedish parliament in 1980 after a referendum to decide that no further nuclear power plants should be built and that a nuclear power phase-out should be completed by 2010. As of 2005[update], the use of renewables amounted to 26% of the energy supply in Sweden, most important being hydropower and biomass. In 2003, electricity from hydropower accounted for 53 TWh and 40% of the country's production of electricity with nuclear power delivering 65 TWh (49%). At the same time, the use of biofuels, peat etc. produced 13 TWh of electricity.[3] Sweden is the highest ranked country in the Climate Change Performance Index.[4]\\r\\nIn March 2005, an opinion poll showed that 83% supported maintaining or increasing nuclear power.[5] Since then however, reports about radioactive leakages at a nuclear waste store in Forsmark, Sweden, have been published.[6] This does not seem to have changed the public support of continued use of nuclear power.\\r\\nFollowing the recommendation of the 1980 referendum, two nuclear power reactors were closed by government decision in 1999 and 2005, respectively. However, in February 2009, the Swedish centre-right wing government announced that new nuclear power stations may be constructed if they replace old ones, thus ending the previous de facto phase out policy.[7]\\r\\nThroughout the 20th century, Swedish foreign policy was based on the principle of non-alignment in peacetime, neutrality in wartime. This principle has often been criticised in Sweden, allegedly being a facade, claiming that the Swedish government had an advanced collaboration with western countries within NATO.\\r\\nDuring Cold War era politics, Sweden was not under the Warsaw Pact and received only minimal aid from the Marshall Plan. In 1952, a Swedish DC-3 was shot down over the Baltic Sea while gathering reconnaissance. It was later revealed that the plane had been shot down by the Soviet Union. Another plane, a Catalina search and rescue craft, was sent out a few days later and shot down by Soviets warplanes as well.\\r\\nSweden is also very active in international peace efforts, especially through the United Nations, and in support to the Third World.[citation needed]\\r\\nIn 1995 Sweden, together with Finland and Austria, joined the European Union which extended the number of member countries from 12 to 15. Membership and its issues are among the most important questions in Swedish politics. Apart from the European Union, Sweden is also an active member of the United Nations and several other organisations such as the Organisation for Economic Co-operation and Development and International Monetary Fund.","input":"What political party is in power in sweden?"},{"output":"from September 24, 1970, to March 7, 1975","context":"The Odd Couple, formally titled onscreen Neil Simon's The Odd Couple, is an American television situation comedy broadcast from September 24, 1970, to March 7, 1975, on ABC. It stars Tony Randall as Felix Unger and Jack Klugman as Oscar Madison, and was the first of several sitcoms developed by Garry Marshall for Paramount Television. The show is based on the 1965 play of the same name, which was written by Neil Simon, as well as on the play's 1968 film adaptation. Felix and Oscar are both divorced. They share a Manhattan apartment, and their different lifestyles inevitably lead to conflicts and laughs.\\r\\nIn 1997, the episodes \\"Password\\" and \\"The Fat Farm\\" were ranked #5 and #58, respectively, on TV Guide's 100 Greatest Episodes of All Time.[4] The show received three nominations for the Primetime Emmy Award for Outstanding Comedy Series. Its fourth season, from 1973ÿ74, remains the most recent nominee for a show that aired during a Friday time slot.[citation needed]\\r\\n\\r\\n\\r\\nThe success of the 1968 film version of the stage play of The Odd Couple, which starred Jack Lemmon as Felix and Walter Matthau as Oscar, served as the catalyst to bringing the characters to television. The original casting considerations for the TV show included Mickey Rooney or Martin Balsam as Oscar and Dean Martin or Art Carney as Felix (Carney had originated the role on Broadway).\\r\\nEventually Tony Randall (as Felix) and Jack Klugman (as Oscar) were hired. Both had starred in different productions of the play. Randall, who was hired first, had still wanted Mickey Rooney to play Oscar. The show's co-executive producer, Garry Marshall, had to lobby hard to get Klugman successfully hired. Once the casting was in place, the show's writers (Marshall, Jerry Belson, Jerry Paris, Bob Brunner, Mark Rothman and Lowell Ganz, among others) came up with a multitude of situations for Felix and Oscar to be in, while staying true to the soul of the play, which always reverted to the human tensions between the two that created the comic situations.\\r\\nThe show premiered September 24, 1970 on ABC. The first season was filmed using the single-camera method and a laugh track, utilizing the apartment set featured from the 1968 film version. Klugman and Randall expressed displeasure with using the laugh track without a live audience. Co-creator/executive producer Garry Marshall also disliked the practice; theatre veteran Randall particularly resented the process of having to wait several seconds between punchlines in order to allot enough space for the laughter to be inserted. The production team eventually experimented with omitting the laugh track altogether for the premiere episode \\"Oscar's New Life\\" (laughs were subsequently added on repeats to maintain continuity). ABC relented by the second season and the show was filmed with three cameras and performed like a stage play in front of a live studio audience, with laugh sweetening completed during post-production.\\r\\nThe change also required a new, larger set to be constructed within a theatre.[5]\\r\\nWith a live audience present, Randall and Klugman enjoyed the spontaneity that came with it; any missed or blown lines went by without stopping (they could always be re-filmed during post-production). In addition, it gave the show a certain edge that was lost in the first season, although actors had to deliver lines louder, since they were on a larger sound stage as opposed to a quiet studio with only minimal crew present.[6]\\r\\nKlugman later recalled, \\"We spent three days rehearsing the show. We sat around a table the first day. We tore the script apart. We took out all the jokes and put in character. The only reason we leave in any jokes is for the rotten canned laughter. I hated it. I watch the shows at home, I see Oscar come in and he says, 'Hi,' and there is the laughter. 'Hey,' I think, 'what the hell did I do?' I hate it; it insults the audience.\\"[7]\\r\\nThroughout its run, The Odd Couple was juggled around ABC's programming schedule. The show struggled in the Nielsen ratings and was canceled at the end of every season.[citation needed] However, ABC renewed the show for each upcoming season because the ratings for the summer reruns were high. In the final first-run episode, \\"Felix Remarries\\", Felix finally wins Gloria back and they remarry as Oscar regains the freedom of living alone again. The final scene unfolds in this way, as the two say their goodbyes:\\r\\nThe 114 episodes went on to syndication and home video. There were some minor changes made in the development of the series. In both TV series and play, Felix's last name was spelled Unger but in the film it is spelled Ungar. In the stage play, Felix is a news writer for CBS (in the film he writes the news for \\"television\\"), while in the TV series he is a commercial photographer. (His slogan, which he is quick to vocalize, is \\"Portraits a specialty.\\") His wife is named Frances in the play and in the film, but is Gloria in the TV series.[citation needed]\\r\\nOscar has at least two children, including a son \\"Brucey\\", who are referred to but not seen in the play and the film. In the series, Oscar is childless. In the film and the play, Felix has a son and a younger daughter. In the series, the children's ages are reversed and they are named Leonard and Edna, after Tony Randall's real first name and his own sister's. During the first season, the show was shot on the sets used for the movie, but for the second season (partially necessitated by the switch to a three-camera setup and the addition of a studio audience), the layout of the apartment was retconned.[citation needed]\\r\\nThe Pigeon Sisters (Monica Evans as Cecily and Carole Shelley as Gwendolyn, reprising their roles from the film and stage play) made four appearances during the first third of the first season. Their characters were not seen and rarely mentioned after that. Oscar later had a girlfriend during that latter part of the first season and half of the second, Dr. Nancy Cunningham (played by Joan Hotchkis), an attractive doctor, whose colleague, Dr. Melnitz (played by Bill Quinn in several episodes), is a sarcastic physician who treats both Felix and Oscar. Felix gained a girlfriend in the third season, Miriam Welby (played by Elinor Donahue), and they lasted into the fifth season, presumably breaking up before Felix remarried Gloria in the series finale. Christopher Shea appeared in three episodes of the first season as Philip, Felix and Oscar's 11-year-old neighbor. Oscar's occasional good-time girlfriend, \\"Crazy Rhoda Zimmerman\\", is often referred to but never appears onscreen.\\r\\nThe TV show also featured their ex-wives. Janis Hansen played Felix's ex, Gloria (named Frances in the play and film) and Jack Klugman's real life wife Brett Somers as Blanche, Oscar's ex. (The couple separated in real life during the run of the show.) There were many episodes in which Felix felt he had made a mistake by not fighting harder for Gloria, and took comically drastic measures to try to win her back. In contrast, Oscar was happy to be divorced from Blanche and she from him as the two constantly traded sarcastic barbs. The only major drawback from Oscar's point of view was the alimony he was ordered to pay. Willie Aames and later Leif Garrett made a few appearances as Felix's son, Leonard. Pamelyn Ferdin and later Doney Oatman appeared as Felix's teenaged daughter, Edna.\\r\\nThe two other major supporting characters, Murray the Cop and Myrna Turner, Oscar's secretary, were played by Al Molinaro and Penny Marshall (Garry's sister) respectively. Alice Ghostley played Murray's wife Mimi in one episode of the first season when Felix quickly outstays his welcome after he moves out of Oscar's apartment following a falling-out. She appeared once in the second season as played by Jane Dulo. Garry Walberg, Ryan McDonald and Larry Gelman played Oscar's poker cronies Homer \\"Speed\\" Deegan, Roy, and the bald, bespectacled Vinnie Barella, rounding out the rest of the regulars. Ryan McDonald left the show after the seventh of the first season's eight episodes in which there was a poker game, and the character of Roy was rarely mentioned and never seen again.\\r\\nGarry Walberg (who later appeared with Klugman on the series Quincy M.E., and Larry Gelman each made a handful of scattered guest appearances after the first season. Richard Stahl appeared in nine episodes as, among other things, a pet-shop owner, a florist, a psychiatrist, and a non-denominational monk, never playing the same role twice. Actor Herbie Faye appeared five times on the series in different roles. Oscar's mother appeared in two different episodes, played once by Elvia Allman, and once by Jane Dulo, both veteran actresses.\\r\\nThe show often had celebrity guest stars, who reflected the cultural leanings either of Oscar or Felix, often playing themselves or occasionally fictional characters. For Oscar, country guitar legend Roy Clark played an old practical joke-playing friend, who nonetheless, has enormous musical talent, as even Felix acknowledges. Sportscaster Howard Cosell (2 episodes) and then ABC television producer Roone Arledge (1 episode) played themselves.\\r\\nPop singer Jaye P. Morgan played herself as one of Oscar's many girlfriends. For Felix, Marilyn Horne played a shy, mousy co-worker of Oscar (named \\"Jackie\\"). Opera singers Martina Arroyo and Richard Fredricks appeared as themselves, as did Edward Vilella, Monty Hall, Richard Dawson, Wolfman Jack, David Steinberg, Hugh Hefner, Rodney Allen Rippy, John Simon, Bubba Smith, Deacon Jones, and Allen Ludden and Betty White (married in real life). In one episode, noted tennis frenemies and one-time real life competitors Bobby Riggs and Billie Jean King appeared as themselves.\\r\\nIn one episode singer-songwriter Paul Williams appears when Felix's daughter Edna wants to run away to follow Williams on tour. (Williams dissuades her.)[8] Dick Clark appeared as himself, a radio disc jockey who calls Oscar in a contest, where he wins a new car (\\"The New Car\\", episode 76). Neil Simon (the man who wrote the play for which the series is based on) makes an uncredited appearance in the fifth season episode \\"\\"Two on the Aisle\\".[9]\\r\\nDuring its original run the show had mediocre ratings at best (the show was never among the Top 30 programs on the Nielsen ratings list during its entire run). Nonetheless, both actors were nominated for Emmy Awards in each year of the show's run. Jack Klugman won two Emmy Awards for his work (in 1971 and 1973), and Tony Randall won an Emmy as well (in 1975, in which, upon acceptance of the award, he commented on the fact that he wished he \\"had a job\\", since the show had recently been cancelled).\\r\\nKlugman was nominated for a Golden Globe in 1972 and won one in 1974. The show itself was also nominated for an Emmy Award for Outstanding Comedy Series in the years 1971, 1972 and 1974. To date, these are the last Emmy nominations to a sitcom airing on a Friday night.\\r\\n\\"On November 13, Felix Unger was asked to remove himself from his place of residence. (Unger's unseen wife slams door, only to reopen it and angrily hand Felix his saucepan) That request came from his wife. Deep down, he knew she was right, but he also knew that someday, he would return to her. With nowhere else to go, he appeared at the home of his childhood friend, Oscar Madison. Sometime earlier, Madison's wife had thrown him out, requesting that he never return. Can two divorced men share an apartment without driving each other crazy?\\"\\r\\nThis opening narration was featured during the show's first and second seasons (in the U.S. DVD release, it is also used in the third season set). It was narrated by voice actor Bill Woodson. The \\"childhood friend\\" reference was only used during the first season and was later changed to simply \\"friend\\" (in fact, the \\"childhood friend\\" reference was added partway through the first season, as the fourth episode explains that Felix and Oscar met during jury duty. And, in a 1973 episode, the two were in the Army together, with Felix being Oscar's superior, at the time Oscar and wife Blanche (Brett Somers) married. There was a flashback episode where Blanche and Oscar lived in the apartment Oscar now shares with Felix. Such inconsistencies in continuity were common for the show [10]) Also, \\"sometime earlier\\" was changed to \\"several years earlier\\" followed by Madison's wife throwing him out, requesting that he never return.[citation needed]\\r\\nThe opening credit sequence consisted of Felix and Oscar in various humorous situations around New York City such as cavorting around a Maypole. In later seasons, the opening sequence featured highlights from past episodes mixed with the previous footage. The closing credit sequences for the first four years of the show consisted of more of the duo's zany antics or a scene where Felix meets Oscar by a big fountain in New York City's Columbus Circle: Oscar throws a cigar butt in the fountain, Felix barks at him to pick it up, and Oscar scoops it up with his shoe then places the wet and soiled cigar butt in Felix's pocket. Towards the end of the introduction title sequence the duo can be seen sitting on a park bench at W58th and 5th Ave in front of the Grand Army Plaza Monuments, Pulitzer Fountain, where Oscar throws his lunch wrapper on the ground and Felix beckons him to pick it up. In later seasons, another clip was incorporated into the credits (a re-taping of a scene from an actual episode) in which Oscar washes his hands in the kitchen sink and begins to dry them on the curtains; Felix protests this, and so Oscar instead dries his hands on Felix' shirt. For the final season, the credits were shown against a blue background.[citation needed]\\r\\nKlugman and Randall did a series of commercials for different products as Felix and Oscar. In 1972, they appeared in TV commercials for Yoplait yogurt. (Klugman also did commercials without Randall for the product in the early 1980s.) In 1974 they appeared in ads for the game Challenge Yahtzee; for a while, their likenesses also appeared on the game's packaging, with the slogan \\"You play your wayI'll play mine!\\" [11] In the late 1980s and early 1990s, Klugman and Randall reprised their characters in a series of commercials for Eagle Snacks, although they called each other by their real names.\\r\\nThey also reprised their roles as Felix and Oscar in regional productions, this time performing the original Neil Simon play, from the late 1980s until the mid-1990s. They had also performed the Simon play on a few road shows during the TV version's off season during the summer in the early to mid-1970s. In 1997, they appeared in a Broadway revival of another Simon play, The Sunshine Boys.[12]\\r\\nIn the 1980s, while starring in the NBC drama Quincy, M.E., Klugman did commercials for Canon copiers. Minolta countered by hiring Randall, then on the NBC sitcom Love, Sidney, to do a commercial where he channeled his Felix role, mentioning that he \\"can change copy colors without getting that disgusting black powder all over my hands!\\" He closed by saying \\"But that doesn't mean I'm a neat freak. Of course, I'm not a slob, either, like, uh... \\" and waved his hand, to suggest Klugman as Oscar.[citation needed]\\r\\nKlugman and Randall reunited in the 1993 television movie, The Odd Couple: Together Again to a mixed reception. Klugman had lost a vocal cord to throat cancer and this struggle was included in the script. In the film, Felix tries to help Oscar recover. He also becomes overly involved in Edna's upcoming wedding, much to her and Gloria (Barbara Barrie)'s dismay.\\r\\nA cartoon version of The Odd Couple premiered on September 6, 1975 on ABC titled The Oddball Couple during their Saturday morning kids' programming block, Funshine Saturday. Although authorized by Neil Simon (who received a \\"based on\\" credit) completely different characters were created: \\"Spiffy\\" (a cat voiced by Frank Nelson) and \\"Fleabag\\" (a dog voiced by Paul Winchell) who live together in a house that is half sloppy and rundown and half pristine and tidy along with a matching car. It was directed and produced by the same team that produced the Pink Panther cartoons: David DePatie and Friz Freleng were executive producers, Gerry Chiniquy, and Robert McKimson among others, directed several episodes. The characters' professions in this version were reversed from the original series, with the fastidious Spiffy working as a reporter and the rumpled Fleabag a photographer, often working together. The show was canceled in 1977.[citation needed]\\r\\nIn 1982, as a hedge against the 1981 Writers Guild of America strike, ABC aired a new version of The Odd Couple, this time with two African-Americans, Ron Glass as Felix and Demond Wilson as Oscar. It was called The New Odd Couple, and initially used eight previously-filmed scripts from the original series; when the strike ended during the series' production, union writers returned and original episodes were written from then on. It ran less than half a season.[citation needed]\\r\\nA Chilean version titled Una Pareja Dispareja began airing in January 2009 on TVN. This version takes several of its cues from Two and a Half Men, a Chuck Lorre-created sitcom with a similar premise to The Odd Couple. Some of the details taken from Two and a Half Men include Felix and Oscar being siblings instead of friends, as well as Felix being a doctor and Oscar a musician.[citation needed]\\r\\nAnother American remake, also called The Odd Couple, aired on CBS for three seasons from 2015 to 2017. This version, a multi-camera sitcom, was co-created and co-produced by Matthew Perry, who played Oscar, while Thomas Lennon played Felix.[13][14]\\r\\nThe Complete First Season of The Odd Couple was released on DVD in Region 1 on August 18, 2006 by Time Life Video under license from Paramount Home Entertainment (Paramount Television was the program's original distributor). Some episodes, mainly from the first season, were available on a VHS videotape set during the 1990s, and distributed by Columbia House.\\r\\nEach episode on the First Season DVDs contain an introduction from the show's producer Garry Marshall. Also included as extras are Emmy Awards speeches, bloopers, TV interviews with the show's stars and a clip of The Odd Couple on Broadway.[citation needed]\\r\\nParamount/CBS DVD have since released the remaining seasons (two through five) of The Odd Couple on DVD in Region 1. Season 1 was released in Region 2 on April 28, 2008. While the Time/Life Season 1 DVD release contained only unedited episodes as originally broadcast, CBS Home Entertainment opted to edit their DVDs of seasons two through five, removing short segments or occasionally entire scenes which included music sung by Felix or some other character. A notable example of this can be seen in the Season 5 episode \\"Strike Up the Band or Else\\" where, in the epilogue, guest star Pernell Roberts' character is going to sing, and the episode abruptly ends and closing credits roll. Fans and critics alike lambasted CBS/Paramount for the shoddy treatment The Odd Couple DVD releases received, concluding that the studio has misled consumers by labeling their DVD sets as \\"complete\\" when they have been intentionally edited to avoid paying royalties required by the music publishers.[15] To date, there are no plans to re-release the series utilizing the uncut master prints.\\r\\nOn June 16, 2015, CBS DVD released The Odd Couple- The Complete Series on DVD in Region 1, albeit with the same edits and removal of scenes with music.[16]","input":"How many years was the odd couple on tv?"},{"output":"3D stop-motion","context":"\\r\\n\\r\\nCoraline is a 2009 American 3D stop-motion dark fantasy horror film based on Neil Gaiman's 2002 novel of the same name. It was the first feature film produced by Laika and was distributed by Focus Features. The film depicts an adventurous girl finding an idealized parallel world behind a secret door in her new home, unaware that the alternate world contains a dark and sinister secret. Written and directed by Henry Selick, the film was made with Gaiman's approval and co-operation.[4]\\r\\n\\r\\nThe film was released in United States theaters on February 6, 2009, after a world premiere at the Portland International Film Festival,[5] and received positive reviews from critics. The film made $16.85 million during opening weekend, ranking third at the box office.[6] At the end of its box office run, the film had grossed over $124 million worldwide. Coraline won Annie Awards for Best Music in an Animated Feature Production, Best Character Design in an Animated Feature Production and Best Production Design in an Animated Feature Production, and received Academy Award and Golden Globe nominations for Best Animated Feature. In retrospective years, the film assured a cult status.\\r\\n\\r\\nCoraline Jones and her parents move from Pontiac, Michigan, to their new home in Ashland, Oregon, the dilapidated Pink Palace Apartments. Her eccentric new neighbors include Mr. Bobinsky, Miss Spink and Miss Forcible. Due to her parents constantly working, Coraline frequently explores the apartment. Whilst exploring, she meets a black cat and Wyborne \\"Wybie\\" Lovat, the grandson of the landlady, whose twin sister mysteriously disappeared years ago. \\r\\n\\r\\nWybie gives Coraline a button-eyed ragdoll that resembles her. The doll then lures her to a small door in the living room, which is bricked up and can only be unlocked by a button key. That night, a mouse guides her through the door, where the bricks have been replaced by a corridor to the Other World, inhabited by button-eyed doppelg?ngers of people from her world. Coraline meets the Other Mother and Other Father, who are much more attentive and entertaining than her real parents.  \\r\\n\\r\\nAfter dinner, she goes to sleep in her Other Bedroom, but awakes in her real bedroom. Despite cryptic warnings from her neighbors, Coraline visits the Other World three times, where she meets the Other Mr. Bobinsky, the Other Miss Spink and Miss Forcible, and the Other Wybie, who is mute. Despite having no Other World counterpart, the black cat is able to speak in the Other World. \\r\\n\\r\\nThe Other Mother invites Coraline to stay forever, under the condition that a pair of buttons will be sewn over her eyes. Terrified, Coraline attempts to flee, but the Other Mother sees through her plan and blocks all the exits to the real world. The other cat  appears and reveals to her the sinister truth about the Other World and the Other Mother. The Other Mother, appearing taller and more grotesque, then \\"disciplines\\" Coraline by imprisoning her behind a wall. There, Coraline meets the ghosts of previous victims, including the missing twin sister of Wybie's grandmother. They reveal that the Other Mother, whom they refer to as the Beldam, created and sent button-eyed rag dolls that resembled them in order to spy on their lives. With the promise of a better life, she lured them into the Other World, where she sewed buttons over their eyes and consumed their lives. To free their souls, their real eyes need to be found. Coraline promises to help.\\r\\n\\r\\nCoraline is suddenly rescued from the mirror by the Other Wybie, whose mouth has been stitched by the Beldam. He helps her escape back to the real world, but Coraline discovers that her parents are missing. She eventually deduces that they have been kidnapped by the Beldam. The cat advises Coraline to propose a \\"game\\": if Coraline cannot find her parents and the ghosts' eyes, she will let buttons be sewn over her eyes, but if she can, they will all be set free. The Beldam reluctantly agrees. \\r\\n\\r\\nOne by one, Coraline finds the ghosts' eyes in the Other World, now turned nightmarish, from its deranged inhabitants. As she does, the Other Pink Palace Apartments' surroundings gradually disintegrate until only the living room is left. Inside, Coraline sees the Beldam in her arachnoid form. Warned that the Beldam will never accept Coraline's victory, she tricks her into unlocking the door. While the Beldam is distracted, Coraline finds her parents trapped in a snow globe, grabs it, and throws the cat at the Beldam's face, ripping her button eyes out. The Beldam furiously converts the floor into a spiderweb but Coraline manages to climb out of it, slam and lock the door shut on the Beldam's hand, severing it. Her parents reappear in the real world, with no memory of what happened. That night, the ghosts warn her to get rid of the button key to prevent the Beldam from accessing the real world. As Coraline prepares to drop it down the well, the severed hand attacks her and tries to drag her back to the Other World. Wybie smashes it with a rock, then throws the remains and the key into the well and seals it shut to prevent anyone else from entering the Other World.\\r\\n\\r\\nThe next day, Coraline and her parents, who have finally finished their work, host a garden party for the neighbors. Coraline also prepares to tell Mrs. Lovat the truth about her twin sister.\\r\\n\\r\\nÿHenry Selick[10]\\r\\n\\r\\nDirector Henry Selick met author Neil Gaiman just as he was finishing the novel Coraline, and given that Gaiman was a fan of Selick's The Nightmare Before Christmas, he invited him to a possible adaptation of the film. As Selick thought a direct adaptation would lead to \\"maybe a 47-minute movie\\", his screenplay had some expansions, such as the creation of Wybie. When looking for a design away from the style seen in most animation, Selick discovered the work of Japanese illustrator Tadahiro Uesugi and invited him to become the concept artist. One of Uesugi's biggest influences was on the color palette, which was muted in reality and more colorful in the Other World.[9] Uesugi declared that \\"at the beginning, it was supposed to be a small project over a few weeks to simply create characters; however, I ended up working on the project for over a year, eventually designing sets and backgrounds, on top of drawing the basic images for the story to be built upon.\\"[11]\\r\\n\\r\\nCoraline was staged in a 140,000-square-foot (13,000 m2) warehouse in Hillsboro, Oregon.[10][12] The stage was divided into 50 lots,[13] which played host to nearly 150 sets.[10] Among the sets were three miniature Victorian mansions, a 42-foot (12.8 m) apple orchard, and a model of Ashland, Oregon, including tiny details such as banners for the Oregon Shakespeare Festival.[12] More than 28[clarification needed] animators worked at a time on rehearsing or shooting scenes, producing 90ÿ100 seconds of finished animation each week.[14] To add the stereoscopy for the 3D release, the animators shot each frame from two slightly apart camera positions.[9]\\r\\n\\r\\nEvery object on screen was made for the film.[9] The crew used three 3D printing systems from Objet in the development and production of the film. Thousands of high-quality 3D models, ranging from facial expressions to doorknobs, were printed in 3D using the Polyjet matrix systems, which enable the fast transformation of CAD (computer-aided design) drawings into high-quality 3D models.[15] The puppets had separate parts for the upper and lower parts of the head that could be exchanged for different facial expressions.[9]  The characters of Coraline could potentially exhibit over 208,000 facial expressions.[15]\\r\\nComputer artists composited separatedly-shot elements together, or added elements of their own which had to look handcrafted instead of computer-generated?ÿ for instance, the flames were done with traditional animation and painted digitally, and the fog was dry ice.[9]\\r\\n\\r\\nAt its peak, the film involved the efforts of 450 people,[10] including from 30[12] to 35[10] animators and digital designers in the Digital Design Group (DDG) directed by Dan Casey and more than 250 technicians and designers.[12] One crew member, Althea Crome,  was hired specifically to knit miniature sweaters and other clothing for the puppet characters, sometimes using knitting needles as thin as human hair.[10] The clothes would also simulate wear using paint and a file.[9]  Several students from The Art Institute of Portland were also involved in making the film.\\r\\n\\r\\nThe soundtrack for Coraline features songs composed by French composer Bruno Coulais with one, \\"Other Father Song\\", by They Might Be Giants. The Other Father's singing voice is provided by John Linnell, one of the singers from the band. They wrote 10 songs for the film; when a melancholy tone was decided, all but one were cut. Coulais' score was performed by the Hungarian Symphony Orchestra and features choral pieces sung by the Children's Choir of Nice in a nonsense language.[16] Selick mentions that the main soloist, \\"a young girl you hear singing in several parts of the film\\" is coincidentally named Coraline.[16] Coraline won Coulais the 2009 Annie Award for best score for an animated feature.\\r\\n\\r\\nThe film was released in the United States on DVD and Blu-ray on July 21, 2009, by Universal Studios Home Entertainment. A 3-D version comes with four sets of 3-D glassesspecifically the green-magenta anaglyph image. Coraline was released in the United Kingdom on DVD and Blu-ray on October 12, 2009. A 3-D version of the film was also released on a 2-Disc Collector's Edition. The DVD opened to first week sales of 1,036,845 and over $19 million in revenue. Total sales stand at over 2.6 million units and over $45 million in revenue.[17] A two-disc Blu-ray 3D set which includes a stereoscopic 3D on the first disc and an anaglyph 3D image was released in 2011.\\r\\n\\r\\nThe website for Coraline involves an interactive exploration game where the player can scroll through Coraline's world. It won the 2009 Webby Award for \\"Best Use of Animation or Motion Graphics\\", both by the people and the Webby organization. It was also nominated for the Webby \\"Movie and Film\\" category.[18] On June 16, 2008, D3 Publisher announced the release of a video game based on the film. It was developed by Papaya Studio for the Wii and PlayStation 2 and by Art Co. for Nintendo DS. It was released on January 27, 2009, close to the film's theatrical release.[19] The soundtrack was released digitally February 3, 2009, by E1 Music, and in stores on February 24, 2009.\\r\\n\\r\\nAccording to Paul Dergarabedian, a film business analyst with Media by Numbers, for the film to succeed it needed a box office comparable to Wallace & Gromit: The Curse of the Were-Rabbit, which grossed $16 million its opening weekend and ended up making more than $192 million worldwide; prior to the film's release, Dergarabedian thought Laika \\"should be really pleased\\" if it made close to $10 million on its opening weekend.[12] In its US opening weekend, the film made $16.85 million, ranking third at the box office.[6] It made $15 million on its second weekend, bringing its U.S. total up to $35.6 million, $25.5 million of which coming from 3D presentations.[20] As of November 2009, the film had grossed $75,286,229 in the United States and Canada and $49,310,169 in other territories, making a total of $124,596,398 worldwide.[3]\\r\\n\\r\\nOn review aggregator website Rotten Tomatoes, the film holds an approval rating of 90% based on 262 reviews, with an average rating of 7.4/10. The website's critical consensus reads, \\"With its vivid stop-motion animation combined with Neil Gaiman's imaginative story, Coraline is a film that's both visually stunning and wondrously entertaining.\\"[21] On Metacritic, the film has a weighted average score of 80 out of 100, based on 38 critics, indicating \\"generally favorable reviews\\".[22]\\r\\n\\r\\nDavid Edelstein said the film is \\"a bona fide fairy tale\\" that needed a \\"touch less entrancement and a touch more?... story\\".[23] A. O. Scott of The New York Times called the film \\"exquisitely realized\\" with a \\"slower pace and a more contemplative tone than the novel. It is certainly exciting, but rather than race through ever noisier set pieces toward a hectic climax in the manner of so much animation aimed at kids, Coraline lingers in an atmosphere that is creepy, wonderfully strange and full of feeling.\\"[24]","input":"What kind of animation is the movie coraline?"},{"output":"buses","context":"Transportation in the Las Vegas Valley including the cities of Las Vegas, North Las Vegas and Henderson is a multi faceted system. The street system is mostly laid out in a north-south/east-west system of roads. While most residents rely on cars, there is an extensive network of bus routes reaching many areas of the county. The Las Vegas Valley, being the one of the largest tourist destinations in the world, has a mass transportation system which favors the Las Vegas Strip.[citation needed]\\r\\nMany proposals have been made to expand the transportation system in the Las Vegas Valley including commuter rail[2] and rapid transit.[3]\\r\\n\\r\\n\\r\\nCurrently, the easiest, and most used method for traveling in and out of the Las Vegas Valley is by air. McCarran International Airport, the world's ninth busiest airport by traffic movements, is five miles from downtown Las Vegas, and is the only commercial airport serving the Las Vegas Valley. It serves as a \\"focus city\\" for Southwest Airlines, the largest operator in Las Vegas. McCarran consists of two terminals with a third under construction. Terminal One is used for domestic flights to and from other US cities. It contains 96 gates in four concourses. Terminal Three opened in June 2012, and added an additional fourteen gates, seven of which are to be used for international travelers to and from London, Mexico City, Frankfurt, Seoul, Toronto, Vancouver, and Paris (seasonally).\\r\\nTransportation to and from the airport is currently limited to automobiles, taxis, shuttles and buses. In late 2007 Clark County commissioners gave permission to the Las Vegas Monorail Company for an extension to McCarran International Terminal One although funding had yet to be determined. The extension was met with negativity by limo and taxi companies that had previously been the major transportation providers for arriving tourists. By 2011, funding was in doubt and the Las Vegas Monorail Company had yet to begin construction.\\r\\nOther airports in the Las Vegas Valley include the North Las Vegas Airport, a noncommercial airport used mostly by hobbyist pilots and small charter airlines, and Henderson Executive Airport, a noncommercial airport used mostly by business jets, and small charter airlines. A second, larger commercial airport is planned. Ivanpah Valley Airport, as it is known, is a developing relief airport between Primm and Sloan. It will be constructed on 6,500 acres (2,630 hectares) of undeveloped land previously owned by the BLM. However, as of August 2011, due to the economic downturn and lack of demand increase, the airport has been put on temporary hold and is still in the design phase.\\r\\nUnlike other monorails which traditionally serve as short line people movers (such as the Mexico City International Airport Monorail or the Walt Disney World Monorail System), the Las Vegas Monorail is the primary rapid transit system in Las Vegas. It was built primarily as a tourist transit system, and exclusively serves the Las Vegas Strip. The system served more than five million people in 2010. Although ridership has declined, it still remains a key piece of the Las Vegas transportation system.[dubious ÿ discuss][citation needed]\\r\\nThe system was conceived in 1993 as a connection between the MGM Grand and Bally's Las Vegas.[4] It was completed, after many delays, in the summer of 2004 with the completion of what is known as \\"Phase One\\" of the monorail. The monorail runs between the MGM Grand and the SLS which opened in August 2014 replacing the Sahara Casino.\\r\\nLas Vegas along with AAA is launching a self-driving shuttle on November 8. The shuttle will travel along a half-mile route near Downtown East Fremont. The shuttle reaches average speeds of 15 mph. The city is considering this a trial run and has plans to run the shuttle for one year. [5]\\r\\nBefore Las Vegas became a tourist destination, railroads were a major industry in southern Nevada. The Los Angeles and Salt Lake Railroad was the first to lay track in the Las Vegas Valley. By 1905 the Los Angeles and Salt Lake had connected Salt Lake City to Southern California through Las Vegas. The railroad provided freight and passenger service to Las Vegas until it was acquired by the Union Pacific Railroad in 1921.\\r\\nThe Union Pacific Railroad began the City of Los Angeles between Chicago and Los Angeles in 1936. This train ran until it was combined with the City of San Francisco in 1960. In 1956 the City of Las Vegas began between Los Angeles and Las Vegas. The train was renamed the Las Vegas Holiday Special and ran until it was discontinued in 1968. Amtrak operated the Las Vegas Limited between Las Vegas and Los Angeles for three months in 1976. A new service, the Desert Wind, began in 1979.\\r\\nThe Desert Wind operated on Union Pacific tracks between Salt Lake City Denver & Rio Grande Depot and Los Angeles Union Station with a stop at the Las Vegas Amtrak station. The Desert Wind faced fierce competition from airlines and the interstate highway system. This, along with frequent delays caused by UP freight trains, made the Desert Wind unpopular. It was discontinued in 1997 and replaced by Amtrak's Thruway Motorcoach.\\r\\nCurrently, Amtrak Thruway Motorcoach serves Las Vegas with a bus stop at McCarran International and a bus stop in Downtown Las Vegas. There has been no commercial passenger rail service since the discontinuation of the Desert Wind in 1997. The Southern Nevada Railway operates excursion trips on former UP tracks in Boulder City. Amtrak plans for restoration of Las Vegas rail service surfaced almost immediately after the discontinuation of the Desert Wind. These plans recommended using Talgo trains between Los Angeles and Las Vegas, similar to Amtrak's Cascades route in the Pacific Northwest. This plan was never implemented and Las Vegas went without passenger rail service. Las Vegas is one of the largest metro areas in the US without passenger rail service.\\r\\nIn 2005 DesertXpress Enterprises LLC was formed in an attempt to restore passenger rail service to Las Vegas. They officially released their plan to construct a high-speed route to SoCal later that year. In 2009, after years of environmental reports, determining right of way, and debating over what federal agency would have regulatory authority, Secretary of Transportation Ray LaHood announced the official recognition of DesertXpress as a high-speed route.[6]\\r\\nIn early 2011, DesertXpress applied for a federal, $5 billion loan through the FRAs RRIF. If approved this would be the largest single amount loaned out since the program began. This contradicted original statements made by DesertXpress Enterprises, that they would not use any tax payer funds. This loan request came months before the final EIS was approved.[7]\\r\\nTheir XpressWest project is a plan to construct a 185?mi (298?km) high-speed route from Las Vegas to Southern California. The terminus of this line, Victorville, has been criticized due to its distance from Downtown Los Angeles, the place long considered to be the prime location for any high-speed rail terminal. Victorville, approximately 85 miles from Los Angeles, was chosen due to the exponential cost of building high-speed rail infrastructure in urban areas, such as the Los Angeles metropolitan area.\\r\\nA competing company, Las Vegas Railway Express, also plans to begin passenger rail service between Las Vegas and Southern California, though at lower speeds.","input":"What is the public transportation in las vegas?"},{"output":"24 November 1859","context":"","input":"When was charles darwin's book the origin of species published?"},{"output":"Point Udall, Guam","context":"This is a list of the extreme points of the United States, the points that are farther north, south, east, or west than any other location in the country. Also included are extreme points in elevation, extreme distances, and other points of peculiar geographic interest.\\r\\n\\r\\n\\r\\nThere are three methods for reckoning the eastern and western extremes of the United States.\\r\\nOne method is to use the Prime Meridian as the dividing line between east and west. This meridian running through Greenwich, London, is defined as zero degrees longitude and could be called the least eastern and least western place in the world. The 180th meridian, on the opposite side of the globe, is therefore the easternmost and westernmost place in the world.\\r\\nAnother method is to use the International Date Line as the easternmostÿwesternmost extreme. On the equinox, the easternmost place would be where the day first begins, and the westernmost is where the day last ends.[citation needed]\\r\\nStill another method is to first determine the geographic center of the country and from there measure the shortest distance to every other point. All U.S. territory is spread across less than 180 of longitude, so from any spot in the U.S. it is more direct to reach Point Udall, U.S. Virgin Islands, by traveling east than by traveling west. Likewise, there is not a single point in U.S. territory from which heading east is a shorter route to Point Udall, Guam, than heading west would be, even accounting for circumpolar routes. The two Udalls for whom the two Points are named were brothers, Mo Udall in Guam and Stewart Udall in the Virgin Islands.[4]","input":"What is the westernmost point of the united states?"},{"output":"14 pounds","context":"The stone or stone weight (abbreviation: st.)[1] is an English and imperial unit of mass now equal to 14?pounds (6.35029318?kg).[nb 1]\\r\\n\\r\\nEngland and other Germanic-speaking countries of northern Europe formerly used various standardised \\"stones\\" for trade, with their values ranging from about 5 to 40 local pounds (roughly 3 to 15?kg) depending on the location and objects  weighed. The United Kingdom's imperial system adopted the wool stone of 14 pounds in 1835. With the advent of metrication, Europe's various \\"stones\\" were superseded by or adapted to the kilogram from the mid-19th century on. The stone continues in customary use in Britain and Ireland used for measuring body weight, but was prohibited for commercial use in the UK by the Weights and Measures Act of 1985.\\r\\n\\r\\nThe name \\"stone\\" derives from the use of stones for weights, a practice that dates back into antiquity. The Biblical law against the carrying of \\"diverse weights, a large and a small\\"[7] is more literally translated as \\"you shall not carry a stone and a stone (??? ????), a large and a small\\". There was no standardised \\"stone\\" in the ancient Jewish world,[8] but in Roman times stone weights were crafted to multiples of the Roman pound.[9] Such weights varied in quality: the Yale Medical Library holds 10 and 50-pound examples of polished serpentine,[10] while a 40-pound example at the Eschborn Museum is made of sandstone.[11]\\r\\n\\r\\nThe English stone under law varied by commodity and in practice varied according to local standards. The Assize of Weights and Measures, a statute of uncertain date from c.?1300, describes stones of 5 merchants' pounds used for glass; stones of 8 lb. used for beeswax, sugar, pepper, alum, cumin, almonds,[12] cinnamon, and nutmegs;[13] stones of 12?lb. used for lead; and the London stone of ?12?1?2?lb. used for wool.[12][13] In 1350, Edward III issued a new statute defining the stone weight, to be used for wool and \\"other Merchandizes\\", at 14 pounds,[nb 2] reaffirmed by Henry VII in 1495.[15]\\r\\n\\r\\nIn England, merchants traditionally sold potatoes in half-stone increments of 7 pounds. Live animals were weighed in stones of 14?lb; but, once slaughtered, their carcasses were weighed in stones of 8?lb. Thus, if the animal's carcass accounted for ?8?14 of the animal's weight, the butcher could return the dressed carcasses to the animal's owner stone for stone, keeping the offal, blood and hide as his due for slaughtering and dressing the animal.[17] Smithfield market continued to use the 8?lb stone for meat until shortly before the Second World War.[18] The Oxford English Dictionary also lists:[19]\\r\\n\\r\\nThe Scottish stone was equal to 16 Scottish pounds (17?lb 8?oz avoirdupois or 7.936?kg). In 1661, the Royal Commission of Scotland recommended that the Troy stone be used as a standard of weight and that it be kept in the custody of the burgh of Lanark. The tron (or local) stone of Edinburgh, also standardised in 1661, was 16 tron pounds (24?lb 1 oz avoirdupois or 9.996?kg).[20][21] In 1789, an encyclopedic enumeration of measurements was printed for the use of \\"his Majesty's Sheriffs and Stewards Depute, and Justices of Peace,?... and to the Magistrates of the Royal Boroughs of Scotland\\" and provided a county-by-county and commodity-by-commodity breakdown of values and conversions for the stone and other measures.[22] The Scots stone ceased to be used for trade when the Act of 1824 established a uniform system of measure across the whole of the United Kingdom, which at that time included all of Ireland.[23]\\r\\n\\r\\nBefore the early 19th century, as in England, the stone varied both with locality and with commodity. For example, the Belfast stone for measuring flax equaled 16.75 avoirdupois pounds.[24]) The most usual value was 14 pounds.[25] Among the oddities related to the use of the stone was the practice in County Clare of a stone of potatoes being 16?lb in the summer and 18?lb in the winter.[25]\\r\\n\\r\\n\\r\\nThe 1772 edition of the Encyclop?dia Britannica defined the stone:[26]\\r\\nSTONE also denotes a certain quantity or weight of some commodities. A stone of beef, in London, is the quantity of eight pounds; in Hertfordshire, twelve pounds; in Scotland sixteen pounds.\\r\\nThe Weights and Measures Act of 1824, which applied to all of the United Kingdom, consolidated the weights and measures legislation of several centuries into a single document. It revoked the provision that bales of wool should be made up of 20 stones, each of 14 pounds, but made no provision for the continued use of the stone. Ten years later, a stone still varied from 5 pounds (glass) to 8 pounds (meat and fish) to 14 pounds (wool and \\"horseman's weight\\").[27] However, the Act of 1835 permitted using a stone of 14 pounds for trade[28] but other values remained in use. James Britten, in 1880 for example, catalogued a number of different values of the stone in various British towns and cities, ranging from 4?lb to 26?lb.[29] The value of the stone and associated units of measure that were legalised for purposes of trade were clarified by the Weights and Measures Act 1835 as follows:[28]\\r\\n\\r\\nIn 1965, the then Federation of British Industry informed the British Government that its members favoured adopting the metric system. The Board of Trade, on behalf of the Government, agreed to support a ten-year metrication programme. There would be minimal legislation, as the programme was to be voluntary and costs were to be borne where they fell.[30] Under the guidance of the Metrication Board, the agricultural product markets achieved a voluntary switchover by 1976.[31] The stone was not included in the Directive 80/181/EEC as a unit of measure that could be used within the EEC for \\"economic, public health, public safety or administrative purposes\\",[32] though its use as a \\"supplementary unit\\" was permitted. The scope of the directive was extended to include all aspects of the EU internal market as from 1 January 2010.[33]\\r\\n\\r\\nWith the adoption of metric units by the agricultural sector, the stone was, in practice, no longer used for trade; and, in the Weights and Measures Act 1985, passed in compliance with EU directive 80/181/EEC,[32] the stone was removed from the list of units permitted for trade in the United Kingdom.[34][35][36] In 1983, in response to the same directive, similar legislation was passed in Ireland.[37] The Act repealed earlier acts that defined the stone as a unit of measure for trade.[36] (British law had previously been silent regarding other uses of the stone.)\\r\\n\\r\\nThe stone remains widely used in the UK and Ireland for human body weight: in those countries people may commonly be said to weigh, e.g., \\"11 stone 4\\" (11 stones and 4 pounds), rather than \\"72 kilograms\\" as in many other countries, or \\"158 pounds\\" (the conventional way of expressing the same weight in the US).[38] The correct plural form of stone in this context is stone (as in, \\"11 stone\\" or \\"12 stone 6 pounds\\"); in other contexts, the correct plural is stones (as in, \\"Please enter your weight in stones and pounds\\"). In Australia and New Zealand, metrication has almost entirely displaced stones and pounds since the 1970s.\\r\\n\\r\\nIn many sports in both Britain and Ireland, such as professional boxing, wrestling and horse racing,[39] the stone is used to express body weights.\\r\\n\\r\\nThe use of the stone in the British Empire was varied. In Canada for example, it never had a legal status.[40]\\r\\nShortly after the United States declared independence, Thomas Jefferson, then Secretary of State presented a report on weights and measures to the U.S. House of Representatives. Even though all the weights and measures in use in the United States at the time were derived from English weights and measures, his report made no mention of the stone being used. He did, however, propose a decimal system of weights in which his \\"[decimal] pound\\" would have been 9.375 ounces (265.8?g) and the \\"[decimal] stone\\" would have been 5.8595 pounds (2.6578?kg).[41]\\r\\n\\r\\nBefore the advent of metrication, units called \\"stone\\" (German: Stein; Dutch: steen; Polish: kamie) were used in many North-Western European countries.[42][43] Its value, usually between 3 and 10?kg, varied from city to city and sometimes from commodity to commodity. The number of local \\"pounds\\" in a stone also varied from city to city. During the early 19th century, states such as the Netherlands (including Belgium) and the South Western German states, which had redefined their system of measures using the kilogramme des Archives as a reference for weight (mass), also redefined their stone to align it with the kilogram.\\r\\n\\r\\nThis table shows a selection of stones from various North European Continental cities:\\r\\n\\r\\nAlthough the advent of the metric system spelt the demise of the stone as a unit of measure, the stone was used in some early discussions and implementations of the metric system. In his Philosophical essay written in 1668, John Wilkins proposed a system of measure whose unit of length, the standard, was approximately one metre and whose unit of mass was the mass of a cubic standard of rainwater (which would have been approximately 1,000?kg). He proposed that one tenth of this mass (100?kg) should be called a stone.[46][47] In 1791, a few years before the French Revolutionary Government agreed on the metre as the basis of the metric system, Thomas Jefferson, in a report to Congress proposed that the United States should adopt a decimal currency system (which was adopted) and a decimal-based system of measure (which was not adopted).[48] Jefferson's proposal for units of measure included a \\"decimal\\" pound equal to 9.375 ounces (265.8?g) in the \\"customary\\" system and a \\"decimal\\" stone of 10 \\"decimal\\" pounds or 5.8595 pounds (2.6578?kg).\\r\\n\\r\\nNeither Wilkins' nor Jefferson's proposals were adopted; but, in the Netherlands, where the metric system was adopted in 1817, the pond (pound) was set equal to a kilogram.<ref group=nb>In modern colloquial Dutch, a pond is used as an alternative for 500 grams or half a kilogram, and the steen (stone), which had previously been 8 Amsterdam pond (3.953?kg), was redefined as being 3?kg.[43]","input":"How much is a stone in american weight?"},{"output":"born to a calico mother and a father of an unknown breed","context":"Tardar Sauce (born April 4, 2012),[1] commonly known as Grumpy Cat, is a cat internet celebrity. She is known for her permanently \\"grumpy\\" facial appearance, which is caused by an underbite and feline dwarfism.[2][3][4] She came to prominence when a photograph of her was posted on social news website Reddit by Bryan Bundesen, the brother of her owner Tabatha, in September 2012,[2][5] and lolcats and parodies created from the photograph by Reddit users went viral. She is the subject of a popular internet meme in which negative lolcats (such as \\"I Had Fun Once... It Was Awful\\") are made from photographs of her.\\r\\n\\r\\n\\r\\nTardar Sauce was one of a litter of four kittens born to a calico mother and a father of an unknown breed at the home of her owner, Tabatha Bundesen.[6][7] The Bundesens say that Tardar Sauce's face appears grumpy because the feline has a form of dwarfism. She and her brother Pokey were born to normal parents with \\"a flat face, bubble eyes, and a short tail\\".[8] Tardar Sauce is undersized and has hind legs that \\"are a bit different\\".[2][4] Although she has a \\"grumpy\\" appearance and is called \\"Grumpy Cat\\", according to the Bundesens, 99% of the time she is a \\"normal kitty\\".[2][4][9]\\r\\nBen Lashes is Grumpy Cat's manager, who also represents Keyboard Cat and Nyan Cat.[10][11] Tabatha Bundesen took a leave of absence from her day job at Red Lobster to manage Grumpy Cat's schedule while Bryan Bundesen manages the Grumpy Cat website, Facebook, YouTube and Twitter accounts.[5][9][12][13]\\r\\nPhoto sessions are only once a week, and handling by strangers is limited.[2] At South by Southwest Interactive, Tardar Sauce made limited two-hour appearances each day as Grumpy Cat.[14]\\r\\nGrumpy Cat has appeared on NBC News's Today,[15] ABC News's Good Morning America,[16] CBS Evening News, Anderson Live,[17] VH1's Big Morning Buzz Live, The Soup[18] and FOX's American Idol. Grumpy Cat appeared on the \\"Garage Logic\\" radio broadcast the day of the Minnesota State Fair live Internet Cat Film Festival. Grumpy Cat promoted Grumpy Cat: A Grumpy Book at BookExpo America.[13] She attended her book's launch at Kitson and The Grove's Barnes & Noble in Los Angeles.[19][20] In 2014, she appeared in a television commercial for Honey Nut Cheerios.[21] She also appeared on the season finale of The Bachelorette and was a special guest on the November 17 edition of WWE Monday Night Raw.[22]\\r\\nIn March 2013, Grumpy Cat attended SXSW Interactive, hosted at the Mashable House.[4][5][23] Friskies paid travel expenses to Austin in order to film \\"Will Kitty Play With It?\\"[13][24] CNN, CBS, and CNET called Grumpy Cat the undisputed \\"biggest star\\" of SXSW Interactive over Elon Musk, Al Gore, and Neil Gaiman.[5][25][26] Over 600[27] fans, including Dennis Crowley, waited for hours in the line, which was nearly three blocks long, to take a photo.[4][5][28] Ian Somerhalder took photos with Grumpy Cat and called her \\"my new love\\", \\"very peaced out\\", \\"sweet as pumpkin pie\\", and \\"kind of amazing\\".[29][30][31][32][33]\\r\\nIn October 2016, Grumpy Cat made a special appearance on Disney Channel's Bizaardvark.[34]\\r\\nGrumpy Cat appeared in episodes of the Friskies YouTube game show \\"Will Kitty Play With It?\\"[4][24][35][36] In September 2013, it was announced that Grumpy Cat would become the Official Spokescat of Friskies.[37] TMZ reported that Friskies paid for flying first class, a private hotel room with king-sized bed, a personal assistant, a chauffeur, and unlimited Friskies food and bottled water.[24] On March 22, 2013, Grumpy Cat traveled to New York City promoting the show and appeared on Good Morning America[16] and Anderson Live[17] and visited Time for a photoshoot.[27] Michael Noer \\"interviewed\\" Grumpy Cat for Forbes, released March 25.[38]\\r\\nAccording to the United States Patent and Trademark Office database, \\"Grumpy Cat Limited\\" applied to trademark \\"Grumpy Cat\\" and an image of her at the end of January 2013.[39] Licensed merchandise like t-shirts and mugs are advertised on the website and sold at Hot Topic.[2][10] Stuffed toys are also available, the official plush being produced by Gund.[40] Ganz, the company behind Webkinz, also has a small Grumpy Cat plush which allows for anyone to play with her on their Webkinz page.[41] There are also various key chains and unofficial plushes produced. Bryan said that by March 2013 they earned \\"mid-five figures\\"[5] and \\"low-six-figure\\" by May 2013.[13] The company has an estimated value of $1 million.[12] Grenade Beverage LLC makes Grumpy Cat \\"Grumppuccino\\" iced coffee beverages.[13][42][43] In December 2015, Grumpy Cat, Ltd. sued Grenade Beverage over trademark infringement when the beverage company expanded its line of Grumpy Cat coffees; however, Grenade contends the suit is without merit.[44]\\r\\nThe official Grumpy Cat book, Grumpy Cat: A Grumpy Book, was published on July 23, 2013, by Chronicle Books.[13] The book is available in both print and digital formats from retailers worldwide. It debuted at #8 Hardcover Nonfiction on the Publishers Weekly best seller list and #7 on the New York Times Bestseller List.[45][46] Additionally, Chronicle Books published The Grumpy Cat 2014 Wall Calendar on July 23, 2013.[47] Another Grumpy Cat book called The Grumpy Guide to Life: Observations by Grumpy Cat was published by Chronicle Books, which debuted at #3 on the New York Times Bestseller List.[48] Dynamite Entertainment publishes a comic book about Grumpy Cat and her brother, titled The Misadventures of Grumpy Cat and Pokey.[49] Dover Publications has also published Grumpy Cat paper doll, sticker, coloring, and tattoo books.[50] An official video game called Grumpy Cat: Unimpressed was released by Ganz Studios and is playable on Facebook, iOS devices and Android devices. The game is match-three game where if combos are performed, Grumpy Cat's insults will appear. The players unlock her memes as they pass each level and she can be made angry with meows, hairballs and laser pointers.[51]\\r\\nGrumpy Cat appears in Lil Bub & Friendz, a documentary premiered at the Tribeca Film Festival on April 18, 2013, and won the Tribeca Online Festival Best Feature Film.[10][52][53][54] In May 2013, Broken Road Productions optioned Grumpy Cat for a \\"Garfield-like feature film\\" adaptation.[13][18][55][56] Producer Todd Garner said \\"We think we can build a big family comedy around this character\\".[18]\\r\\nOn June 11, 2014, it was announced that Lifetime would be producing a film about Grumpy Cat, entitled Grumpy Cat's Worst Christmas Ever, which debuted on November 29, 2014. Filming took place over the summer, and Tim Hill and Jeff Morris wrote the script.[57] It was reported that Aubrey Plaza would be lending her voice talent for the Grumpy Cat character.[58] Plaza is also a producer on the film and on November 6, 2014, Lifetime released a tongue-in-cheek video about the casting and Plaza's \\"process\\" for becoming the voice of Grumpy Cat.[59] [60]","input":"What breed of cat is the grumpy cat?"},{"output":"212 days per year","context":"Forks is a city in Clallam County, Washington, United States. The population was 3,558 at the 2010 census.[5] The population was 3,783 at 2016 Estimate from Office of Financial Management. It is named after the forks in the nearby Quillayute, Bogachiel, Calawah, and Sol Duc rivers.\\r\\n\\r\\nFor many years, the city's economy was fueled by the local timber industry. More recently it has drawn tourism related to the novel series Twilight and movies of the same name, set in Forks. With recent declines in the timber industry, Forks has relied on the nearby Clallam Bay Corrections Center and Olympic Corrections Center as sources of jobs. Forks is a popular destination for sport fishers who fish for salmon and rainbow trout in nearby rivers. It is also supported by visitors to Olympic National Park.\\r\\n\\r\\nForks was officially incorporated on August 28, 1945, following an election of the constituents who would become its first town members.\\r\\n\\r\\nThe city gained popularity for being a key setting in Stephenie Meyer's Twilight series (2005 to 2008) and related film adaptations. The city's atmosphere and idyllic Pacific Northwest setting has inspired its being featured in film, literature, and video games.\\r\\n\\r\\nAs of the census[2] of 2010, there were 3,532 people, 1,264 households, and 849 families residing in the city. The population density was 967.7 inhabitants per square mile (373.6/km2). There were 1,374 housing units at an average density of 376.4 per square mile (145.3/km2). The racial makeup of the city was 67.7% White, 0.5% African American, 6.6% Native American, 1.2% Asian, 0.1% Pacific Islander, 18.1% from other races, and 5.9% from two or more races. Hispanic or Latino of any race were 25.9% of the population.\\r\\n\\r\\nThere were 1,264 households of which 40.9% had children under the age of 18 living with them, 46.0% were married couples living together, 13.5% had a female householder with no husband present, 7.7% had a male householder with no wife present, and 32.8% were non-families. 25.3% of all households were made up of individuals and 8.2% had someone living alone who was 65 years of age or older. The average household size was 2.72 and the average family size was 3.16.\\r\\n\\r\\nThe median age in the city was 31.3 years. 29.2% of residents were under the age of 18; 10.3% were between the ages of 18 and 24; 27.6% were from 25 to 44; 23.2% were from 45 to 64; and 9.7% were 65 years of age or older. The gender makeup of the city was 51.5% male and 48.5% female.\\r\\n\\r\\nAs of the census of 2000, there were 3,120 people, 1,169 households, and 792 families residing in the city. The population density was 854.8 people per square mile (330.2/km2). There were 1,361 housing units at an average density of 435.6 per square mile (168.4/km2). The racial makeup of the city was 81.47% White, 0.42% African American, 5.03% Native American, 1.51% Asian, 0.16% Pacific Islander, 8.49% from other races, and 2.92% from two or more races. Hispanic or Latino of any race were 3.54% of the population.\\r\\n\\r\\nThere were 1,169 households out of which 36.9% had children under the age of 18 living with them, 49.4% were married couples living together, 11.4% had a female householder with no husband present, and 32.2% were non-families. 24.6% of all households were made up of individuals and 7.4% had someone living alone who was 65 years of age or older. The average household size was 2.65 and the average family size was 3.15.\\r\\n\\r\\nIn the city, the age distribution of the population shows 30.4% under the age of 18, 11.1% from 18 to 24, 27.2% from 25 to 44, 22.1% from 45 to 64, and 9.1% who were 65 years of age or older. The median age was 31 years. For every 100 females, there were 111.7 males. For every 100 females age 18 and over, there were 108.9 males.\\r\\n\\r\\nThe median income for a household in the city was $34,280, and the median income for a family was $38,844. Males had a median income of $35,718 versus $23,690 for females. The per capita income for the city was $13,686. About 14.6% of families and 20.5% of the population were below the poverty line, including 25.7% of those under age 18 and 12.4% of those age 65 or over.\\r\\n\\r\\nForks has an oceanic climate in a temperate rainforest with very high rainfall. Although there is a drying trend in summer, rain is still abundant, just not as wet as the rest of the year. Forks averages 212 days per year with measurable precipitation.[8] The Olympic rainforest surrounds the town.\\r\\n\\r\\nAccording to the United States Census Bureau, the city has a total area of 3.65 square miles (9.45?km2), all of it land.[1]\\r\\n\\r\\n\\r\\n\\r\\nThe City is organized under Washington State law as a Non-charter Code City. Its structure is that of an elected Mayor and a five-member elected City Council. Unlike other cities on the Olympic Peninsula, Forks operates under what is called a \\"strong Mayor\\" form of government with the Mayor being the Chief Executive Officer overseeing four department heads (Clerk/Treasurer, Public Works, Police, and Legal/Planning).[14]\\r\\n\\r\\nForks Municipal Airport (IATA: S18, ICAO: KS18, FAA LID: S18) is located in Clallam County, 1 mile (1.6?km) southwest of Forks. The Airport has six based aircraft, including 3 single-engine aircraft and 3 helicopters. The latest available data indicate that the Airport had a total of 13,550 annual operations.\\r\\n\\r\\nRunway 4-22 is Forks Municipal Airport's sole runway. This runway is 2,400 feet (730?m) long, 75 feet (23?m) wide, is equipped with medium intensity runway lighting, and has an asphalt surface. Approaches to both ends of this runway are visual.[15]\\r\\n\\r\\nForks is served by two public transit agencies. Clallam Transit route 17 provides local service in Forks, while three other routes provide connections to Port Angeles (14), La Push (15), and Clallam Bay and Neah Bay (16). Jefferson Transit runs an \\"Olympic Connection\\" bus that provides service on Highway 101 south of Forks as far as Lake Quinault. From there, transfers to Aberdeen are available via Grays Harbor transit. All five of these bus routes serve Forks six days a week, with no service on Sundays.\\r\\n\\r\\nKFKB 1490 and KBDB-FM 96.7 are the two local commercial stations serving the area. Both are owned by Forks Broadcasting.\\r\\n\\r\\nKNWU 91.5 is the public radio station serving the area.  It is a satellite station of Washington State University's statewide Northwest Public Radio network.\\r\\n\\r\\nForks is a part of the Quillayute Valley School District, with Forks High School being the community's high school. Forks is home to the University of Washington's Olympic Natural Resources Center.[16]\\r\\n\\r\\nOn the south end of town is the Forks Timber Museum. Constructed in 1989 by the Forks High School carpentry class, the 3,200-square-foot (300?m2) building provides a look into the local history of the timber industry, loggers of the past, and their tools of the trade. The museum has exhibits depicting local history dating to the 1870s.[17]\\r\\n\\r\\nForks serves as the hub for numerous day excursions to the Hoh Rainforest, the Pacific Beaches, and various wilderness trails.\\r\\n\\r\\nAnother source of tourism is Stephenie Meyer's Twilight series, which is set in the town.[18] Tours are available of locations that resemble the places described in Meyer's books. The films were not shot in Forks.[19][20]\\r\\n\\r\\nThe average annual number of tourists visiting the town rose from 10,000 before Twilight to 19,000 in 2008, the year of the first film, and 73,000 by 2010.[21]\\r\\n\\r\\nForks is well known for its winter steelhead fishing with the Quillayute river system - the Hoh, Sol Duc, Bogachiel and Calawah rivers. Other nearby Clallam, Sekiu and Hoko rivers are also good for king salmon fishing and steelheading as well. Local guides are available for both native and hatchery runs and for float trips. Fishing gear and clothing is available at local stores.\\r\\n\\r\\nForks displays one of a few Shay engines remaining in Washington. Shay locomotives are unusual in that they have a crank shaft running down the side, powering all wheels. They were designed to be used to transport lumber out of forests. Rayonier #10 (c/n 3348) was built for stock by Lima in 1930. It has three cylinders and three trucks. The Ozette Timber Company bought it 11 years later. In 1945 it was acquired by Rayonier for their lumber operation near Forks. It was retired near the north end of Forks in Tillicum Park in 1959.\\r\\n\\r\\nThe Forks Lions Club erected an attractive shelter over the #10 in 1999. It has also built and maintained most of the structures in the Shay Tillicum Park over the last 40 years.[22][23][24]\\r\\n\\r\\nRainfest, a celebration of the arts sponsored by the West Olympic Council for the Arts, occurs in April. It includes a combination of arts and craft related events. In recent years quilt classes and a quilt show have been sponsored by the Piece Makers Quilt Club.\\r\\n\\r\\nIn March of every year, the Quillayute Valley Scholarship Auction occurs. This annual fundraising event raises tens of thousands of dollars for scholarships. Since the first scholarship award in 1964, to Robert Henry (now D.D.S.), the Committee has awarded over US$1m in scholarships to Forks students.\\r\\n\\r\\nIn the summer, Forks hosts its traditional \\"Old Fashioned Fourth of July\\" celebration with a Grand Fourth of July Parade. The numerous events include a demolition derby and fireworks display. July is also the month for Quileute Days at La Push with its parade, traditional salmon bake, bone games, softball tournament, canoe races, and street fair. In August, the Forks Family Festival combines arts and crafts vendors with children activities.\\r\\n\\r\\nIn late September, the Forks Chamber of Commerce partners with the Quileute Tribe and the City of Forks to host the Last Chance Fishing Derby at La Push; cash prizes are offered to those wanting to fish for salmon on the Pacific Ocean. The first week in October is when the community celebrates its heritage during Heritage Days. One of the more celebrated events during this week-long festival is the \\"Old Timers Round Table;\\" this is a moderated conversation broadcast live via the local radio station, featuring longtime residents of the region talking about days long past.\\r\\n\\r\\nThe Forks City Council passed a resolution in 2007 celebrating \\"Stephenie Meyer Day\\" in honor of the Twilight young adult novels and film series, set for September 13, the day before the fictional Bella's birthday.[25] In 2015 the event was still driving tourism, with visitor numbers peaking in 2010, then settling to 50% more than before the Twilight phenomenon.[26]\\r\\n\\"Stephanie Meyer Day\\" has been replaced with the title \\"Forever Twilight in Forks Festival\\" which is still celebrated annually on the week of September 13th. [27][28]The festival includes activities such as a movie marathon, a blood drive, dance lessons, and more. The upcoming dates for Forever Twilight in Forks 2018 are from September 13th to September 16th.[29]","input":"How often does it rain in forks washington?"},{"output":"Eddie Brigati","context":"The Rascals (initially known as The Young Rascals) were an American rock band, formed in Garfield, New Jersey in 1965. Between 1966 and 1968 the New Jersey act reached the top 20 of the Billboard Hot 100 with nine singles, including the #1s \\"Good Lovin'\\" (1966), \\"Groovin'\\" (1967), and \\"People Got to Be Free\\" (1968), as well as big radio hits such as the much-covered \\"How Can I Be Sure?\\" (#4 1967) and \\"A Beautiful Morning\\" (#3 1968), plus another critical favorite \\"A Girl Like You\\" (#10 1967). The band was inducted into the Rock and Roll Hall of Fame in 1997.[1]\\r\\n\\r\\nThe Rascals were inducted into the Hit Parade Hall of Fame in 2010 and also reunited in 2012 for a series of shows in New York and New Jersey. The reunion continued on in 2013 with shows on Broadway.\\r\\n\\r\\nEddie Brigati (vocals), Felix Cavaliere (keyboard, vocals),[2] Gene Cornish (guitar) and Dino Danelli (drums) started the band in Brigati and Danelli's hometown of Garfield, New Jersey. Brigati, Cavaliere, and Cornish had previously been members of Joey Dee and the Starliters.[3] Eddie's brother, David Brigati, an original Starliter, helped arrange the vocal harmonies and sang backgrounds on many of the group's recordings (informally earning the designation as the \\"fifth Rascal\\"). When Atlantic Records signed them, they discovered that another group, Borrah Minnevitch's and Johnny Puleo's 'Harmonica Rascals', objected to their release of records under the name 'The Rascals'. To avoid conflict, managers Sid Bernstein and founder Billy (Amato) Smith decided to rename the group 'The Young Rascals'.\\r\\n\\r\\nThe Young Rascals' first television performance was on the program Hullabaloo on February 24, 1966 where they performed their debut single \\"I Ain't Gonna Eat Out My Heart Anymore\\". The track reached #23 in Canada and touched the lower reaches of the US charts. This modest success was followed by the US/Canada #1 single \\"Good Lovin'\\" (1966, originally recorded by Lemme B. Good & The Olympics in 1965 with much different lyrics).\\r\\n\\r\\nThe band's songwriting team of Eddie Brigati and Cavaliere then began providing most of their songs, and the hits kept coming for two years. Their immediate follow-ups to \\"Good Lovin'\\", including \\"You Better Run\\" (1966; covered in 1980 by Pat Benatar) and \\"Come On Up\\" were only modest hits. \\"(I've Been) Lonely Too Long\\" (1967) did better, and \\"Groovin'\\"[4] (#1 US/Canada, 1967) returned them to the top of the charts. They reeled off a succession of top 20 US hits, including \\"A Girl Like You\\" (1967), \\"How Can I Be Sure\\" (1967), \\"It's Wonderful\\" (1968), and \\"A Beautiful Morning\\" (1968). The band was exceptionally popular in Canada where \\"A Girl Like You\\", \\"How Can I Be Sure?\\" and \\"A Beautiful Morning\\" all reached #1. But they struggled in the UK, where they only twice reached the top 75, with \\"Groovin'\\" (#8) and \\"A Girl Like You\\" (#35). The band would bill themselves as the Young Rascals for the last time with the single release of \\"It's Wonderful\\"; they were known thence forwards as simply 'the Rascals'.\\r\\n\\r\\nBruce Eder, writing for AllMusic, rates the band's 1967 album Groovin' as their best, noting the record's soulful core and innovative use of jazz and Latin instrumental arrangements. 1968's Once Upon A Dream was the first Rascals album designed from conception as an album, rather than as a vehicle to package their singles (eight of Groovin''s eleven songs had been released as single A or B sides, most in advance of the album). Once Upon a Dream, which peaked at #9 on the album charts, contained the single \\"It's Wonderful\\" plus many other strong songs, including \\"Easy Rollin',\\" \\"Rainy Day,\\" \\"My World,\\" and the title track. Perhaps understandably, the album's song \\"My Hawaii\\" became a top of the charts hit in Hawaii.\\r\\n\\r\\nTime Peace: The Rascals' Greatest Hits, released in mid-1968, topped the U.S. album chart and became the group's best-selling album. The same year, \\"People Got to Be Free\\", a horn-punctuated plea for racial tolerance (the band was known for refusing to tour on segregated bills)[5] in the wake of the assassinations that year of Senator Robert F. Kennedy and Reverend Martin Luther King, Jr., became their third and final U.S. #1 single, and their sixth and final Canadian #1. It was also their final U.S. Top Ten hit, although they remained a Canadian top 10 act for the next few years.\\r\\n\\r\\n\\"A Ray of Hope\\", \\"Heaven\\", \\"See\\", and \\"Carry Me Back\\" were all modest U.S. hits for the band during late 1968 and 1969; all entered the top 40, but none higher than #24. In Canada, however, the Rascals were still major stars; all these songs went top ten, completing a run of 11 straight Canadian top ten hits for The Rascals from 1967 to 1969. December 1969's \\"Hold On\\" broke the run of top 40 US singles for the Rascals, stalling at #51, as well as the run of Canadian top tens, peaking at #22.\\r\\n\\r\\nDuring their period of greatest celebrity, the band's influence on aspiring R & B-flavored white acts was without equal, especially in the northeastern U.S. Notable bands that incorporated (sometimes to the point of parody) the Rascals' full-on stage demeanor and energy as well as the intense, hyper-dramatic vocalizing, drumstick-spinning gyrations and heavy bottom-end rhythm also achieved some prominence: the Vagrants (featuring Leslie West, later of Mountain), and the epitome of over-the-top funky psychedelia, the Vanilla Fudge, all owed their styles to the Rascals' synthesis of show-biz and soul.\\r\\n\\r\\nBrigati left the group in 1970, followed by Cornish in 1971. Their last Rascals album was Search and Nearness (#198 U.S.), which featured Brigati's lead vocals on the Cornish-penned \\"You Don't Know\\" and a cover of The Box Tops' hit \\"The Letter\\", and drummer Danelli's composition \\"Fortunes\\". The only single release from the album to chart was the spiritually themed \\"Glory, Glory\\" (#58 U.S., #40 Canada), with backing vocals by The Sweet Inspirations. Search and Nearness would be the Rascals' last album for Atlantic Records, with Cavaliere and Danelli taking the band to Columbia Records in mid-1971.\\r\\n\\r\\nCavaliere shifted towards more jazz- and gospel-influenced writing for the Rascals' next two albums, Peaceful World (U.S. #122) and The Island Of Real (U.S. #180), using Robert Popwell and Buzzy Feiten on bass and guitar respectively, and new singers Annie Sutton and Molly Holt. These albums didn't sell as well as their earlier work, with none of their associated singles reaching higher than #95 on the U.S. chart. Towards the end of 1970 Danny Weis (previously with Rhinoceros and Iron Butterfly) then joined as a replacement for Feiten on guitar and Feiten then again replaced Weis before the group disbanded.\\r\\n\\r\\nCavaliere released several solo albums during the 1970s. Brigati, with his brother David, released Lost in the Wilderness in 1976. Cornish and Danelli worked together in Bulldog, who released two albums  one for MCA Records in 1973, the second for Buddah in '74  and Fotomaker, who issued three albums on Atlantic in 1978-79. In 1982, Danelli joined Steve Van Zandt in Little Steven and the Disciples of Soul for the group's first two albums.\\r\\n\\r\\nAfter appearing at Atlantic Records 40th Anniversary Celebration on May 14, 1988, the Rascals reunited (with Cavaliere, Cornish, and Danelli) for a brief reunion tour in 1988;\\r\\nEddie Brigati opted not to participate. The reunion group featured an expanded lineup that included Mel Owens (in Brigati's place) on vocals and percussion, Steve Mackey on bass, Ed Mattey on guitar, Dena Iverson & Cindy McCabe on backup vocals and a horn section from Nashville to beef up the sound. The reunion did not last beyond the end of the year.\\r\\n\\r\\nAfter that, Cavaliere returned to his solo career and in the 1990s there were two factions touring: The New Rascals (featuring Cornish and Danelli) and Cavaliere, who sometimes called his grouping Felix Cavaliere's Rascals. The New Rascals lasted only a short time but toured again in 2006 with two new members, Bill Pascali (formerly of Vanilla Fudge) on vocals and keyboards and Charlie Souza on bass and vocals. The New Rascals released a concert DVD, shot at club Centro in New Jersey on Route 35.\\r\\n\\r\\nIn early 2009, Eddie Brigati went on to put together a project of young musicians who played all the classics. Eddie performed with the group along with his brother David. Called The Boys From The Music House, the band consisted of 4 talented young boys from New Jersey. Anthony Duke Claus, a cousin of Eddie's, sang lead vocals and played tambourine, Joseph Pomarico played lead guitar, harmonica and sang background vocals. Adam Sullivan played the piano and the classic organ along with singing some background vocals, and Matt Gazzano played the drums.\\r\\n\\r\\nOn April 24, 2010, all four members of The Rascals reunited for the Kristen Ann Carr benefit, which was held at New York's Tribeca Grill; Bruce Springsteen and Stevie Van Zandt joined the band for a closing \\"Good Lovin'\\".\\r\\n\\r\\nThe group's original lineup reunited for their first public performances in over 40 years with The Rascals: Once Upon a Dream, a combination concert/theatrical event that was produced and directed by Steven Van Zandt and Maureen Van Zandt with lighting/projection by Marc Brickman. In addition to the concert experience, the history of The Rascals, and the history of the 1960s through their music, is a combination of interviews with the four Rascals, filmed scenes of actors enacting key moments in the band's history, news footage, and archival footage of the band. The show originally ran for six performances in December 2012 at the Capitol Theatre in Port Chester, New York.\\r\\n\\r\\nFifteen performances of the show were subsequently delivered from April 15 to May 5, 2013 at the Richard Rodgers Theatre on Broadway in New York City.[6][7] Near the end of the show's Broadway run, it was announced that Once Upon a Dream would be taken on the road, with performances scheduled in various cities on the East coast of North America during MayÿDecember 2013.[8]\\r\\n\\r\\nFollowing its national tour, the show was expected to return to Broadway for a second three-week limited-run from December 2013 through January 2014, at the Marquis Theatre, but was canceled.[9]\\r\\n\\r\\nThe Rascals were inducted into the Rock and Roll Hall of Fame on May 6, 1997. Steve Van Zandt gave the induction speech and presented the award. For the first time in years, all four original members appeared together. For their jam session (including David Brigati), they performed \\"Good Lovin'\\", \\"Groovin'\\", \\"How Can I Be Sure?\\", and \\"People Got To Be Free\\".[10]\\r\\n\\r\\nIn 2005 The Rascals were inducted into the Vocal Group Hall of Fame.\\r\\n\\r\\nIn August 2007 the Rascals' catalog of Atlantic Records albums was re-released by Atlantic Records affiliate Rhino Records.\\r\\n\\r\\nOn June 18, 2009, Eddie Brigati and Felix Cavaliere were inducted into the Songwriters Hall of Fame at a ceremony in New York City.\\r\\n\\r\\nAlthough the Rascals performed on all of their recordings, they often used studio musicians as well. Below is a short list of musicians who played on many of their recordings.\\r\\n\\r\\nBass: Ron Carter, Chuck Rainey, Richard Davis, Gerald Jemmott, Harold Cowart, Robert \\"Pops\\" Popwell.\\r\\n\\r\\nSaxophone: King Curtis, Steve Marcus, Danny Labatte, Hubert Laws (flute), Joe Young, Charles Dinwiddle, Seldon Powell\\r\\n\\r\\nHarmonica: Buddy Lucas, Michael Weinstein\\r\\n\\r\\nTrumpet: Melvin Lastie, Joe Newman, Steve Madaio, Marky Markowitz\\r\\n\\r\\nPiano: Joe Bushkin\\r\\n\\r\\nPercussion: Kwaski Dzidzornu, Ralph MacDonald, Jack Scarangella, Daniel Ben Zebolun.\\r\\n\\r\\nHarp: Louis Collin\\r\\n\\r\\nGuitar: Linc Chamberland, Howard \\"Buzz\\" Feiten","input":"Who was the lead singer for the rock group the rascals?"},{"output":"over 100","context":"This is a list of cancer types. Cancer is a group of diseases that involve abnormal increases in the number of cells, with the potential to invade or spread to other parts of the body.[1] Not all tumors or lumps are cancerous; benign tumors are not classified as being cancer because they do not spread to other parts of the body.[1] There are over 100 different known cancers that affect humans.[1]\\r\\nCancers are often described by the body part that they originated in. However, some body parts contain multiple types of tissue, so for greater precision, cancers are additionally classified by the type of cell that the tumor cells originated from. These types include:\\r\\nCancers are usually named using -carcinoma, -sarcoma or -blastoma as a suffix, with the Latin or Greek word for the organ or tissue of origin as the root. For example, cancers of the liver parenchyma arising from malignant epithelial cells is called hepatocarcinoma, while a malignancy arising from primitive liver precursor cells is called a hepatoblastoma, and a cancer arising from fat cells is called a liposarcoma. For some common cancers, the English organ name is used. For example, the most common type of breast cancer is called ductal carcinoma of the breast. Here, the adjective ductal refers to the appearance of the cancer under the microscope, which suggests that it has originated in the milk ducts.[citation needed]\\r\\nBenign tumors (which are not cancers) are usually named using -oma as a suffix with the organ name as the root. For example, a benign tumor of smooth muscle cells is called a leiomyoma (the common name of this frequently occurring benign tumor in the uterus is fibroid). Confusingly, some types of cancer use the -noma suffix, examples including melanoma and seminoma.[3][4]\\r\\nSome types of cancer are named for the size and shape of the cells under a microscope, such as giant cell carcinoma, spindle cell carcinoma, and small-cell carcinoma.[citation needed]","input":"How many different type of cancer are there?"},{"output":"Brazil","context":"\\r\\n\\r\\nThe FIFA World Cup, often simply called the World Cup, is an international association football competition contested by the senior men's national teams of the members of the Fdration Internationale de Football Association (FIFA), the sport's global governing body. The championship has been awarded every four years since the inaugural tournament in 1930, except in 1942 and 1946 when it was not held because of the Second World War. The current champion is France, which won its second title at the 2018 tournament in Russia.\\r\\n\\r\\nThe current format of the competition involves a qualification phase, which currently takes place over the preceding three years, to determine which teams qualify for the tournament phase, which is often called the World Cup Finals. After this, 32 teams, including the automatically qualifying host nation(s), compete in the tournament phase for the title at venues within the host nation(s) over a period of about a month.\\r\\n\\r\\nThe 21 World Cup tournaments have been won by eight national teams. Brazil have won five times, and they are the only team to have played in every tournament. The other World Cup winners are Germany and Italy, with four titles each; Argentina, France and inaugural winner Uruguay, with two titles each; and England and Spain with one title each.\\r\\n\\r\\nThe World Cup is the most prestigious association football tournament in the world, as well as the most widely viewed and followed sporting event in the world, exceeding even the Olympic Games; the cumulative audience of all matches of the 2006 World Cup was estimated to be 26.29?billion with an estimated 715.1?million people watching the final match, a ninth of the entire population of the planet.[1][2][3][4]\\r\\n\\r\\n17 countries have hosted the World Cup. Brazil, France, Italy, Germany and Mexico have each hosted twice, while Uruguay, Switzerland, Sweden, Chile, England, Argentina, Spain, the United States, Japan and South Korea (jointly), South Africa and Russia have each hosted once. Qatar are planned as hosts of the 2022 finals, and 2026 will be a joint hosted finals between Canada, the United States and Mexico, which will give Mexico the distinction of being the first country to have hosted games in three different finals.\\r\\n\\r\\nThe world's first international football match was a challenge match played in Glasgow in 1872 between Scotland and England,[5] which ended in a 0ÿ0 draw. The first international tournament, the inaugural British Home Championship, took place in 1884.[6] As football grew in popularity in other parts of the world at the start of the 20th century, it was held as a demonstration sport with no medals awarded at the 1900 and 1904 Summer Olympics (however, the IOC has retroactively upgraded their status to official events), and at the 1906 Intercalated Games.[7]\\r\\n\\r\\nAfter FIFA was founded in 1904, it tried to arrange an international football tournament between nations outside the Olympic framework in Switzerland in 1906. These were very early days for international football, and the official history of FIFA describes the competition as having been a failure.[8]\\r\\n\\r\\nAt the 1908 Summer Olympics in London, football became an official competition. Planned by The Football Association (FA), England's football governing body, the event was for amateur players only and was regarded suspiciously as a show rather than a competition. Great Britain (represented by the England national amateur football team) won the gold medals. They repeated the feat at the 1912 Summer Olympics in Stockholm.\\r\\n\\r\\nWith the Olympic event continuing to be contested only between amateur teams, Sir Thomas Lipton organised the Sir Thomas Lipton Trophy tournament in Turin in 1909. The Lipton tournament was a championship between individual clubs (not national teams) from different nations, each one of which represented an entire nation. The competition is sometimes described as The First World Cup,[9] and featured the most prestigious professional club sides from Italy, Germany and Switzerland, but the FA of England refused to be associated with the competition and declined the offer to send a professional team. Lipton invited West Auckland, an amateur side from County Durham, to represent England instead. West Auckland won the tournament and returned in 1911 to successfully defend their title.\\r\\n\\r\\nIn 1914, FIFA agreed to recognise the Olympic tournament as a \\"world football championship for amateurs\\", and took responsibility for managing the event.[10] This paved the way for the world's first intercontinental football competition, at the 1920 Summer Olympics, contested by Egypt and 13 European teams, and won by Belgium.[11] Uruguay won the next two Olympic football tournaments in 1924 and 1928. Those were also the first two open world championships, as 1924 was the start of FIFA's professional era.\\r\\n\\r\\nDue to the success of the Olympic football tournaments, FIFA, with President Jules Rimet as the driving force, again started looking at staging its own international tournament outside of the Olympics. On 28 May 1928, the FIFA Congress in Amsterdam decided to stage a world championship itself.[12] With Uruguay now two-time official football world champions and to celebrate their centenary of independence in 1930, FIFA named Uruguay as the host country of the inaugural World Cup tournament.\\r\\n\\r\\nThe national associations of selected nations were invited to send a team, but the choice of Uruguay as a venue for the competition meant a long and costly trip across the Atlantic Ocean for European sides. Indeed, no European country pledged to send a team until two months before the start of the competition. Rimet eventually persuaded teams from Belgium, France, Romania, and Yugoslavia to make the trip. In total, 13 nations took part: seven from South America, four from Europe and two from North America.\\r\\n\\r\\nThe first two World Cup matches took place simultaneously on 13 July 1930, and were won by France and the USA, who defeated Mexico 4ÿ1 and Belgium 3ÿ0 respectively. The first goal in World Cup history was scored by Lucien Laurent of France.[13] In the final, Uruguay defeated Argentina 4ÿ2 in front of 93,000 people in Montevideo, and became the first nation to win the World Cup.[14] After the creation of the World Cup, FIFA and the IOC disagreed over the status of amateur players, and so football was dropped from the 1932 Summer Olympics.[15] Olympic football returned at the 1936 Summer Olympics, but was now overshadowed by the more prestigious World Cup.\\r\\n\\r\\nThe issues facing the early World Cup tournaments were the difficulties of intercontinental travel, and war. Few South American teams were willing to travel to Europe for the 1934 World Cup and all North and South American nations except Brazil and Cuba boycotted the 1938 tournament. Brazil was the only South American team to compete in both. The 1942 and 1946 competitions, which Germany and Brazil sought to host,[16] were cancelled due to World War II and its aftermath.\\r\\n\\r\\nThe 1950 World Cup, held in Brazil, was the first to include British participants. British teams withdrew from FIFA in 1920, partly out of unwillingness to play against the countries they had been at war with, and partly as a protest against foreign influence on football,[17] but rejoined in 1946 following FIFA's invitation.[18] The tournament also saw the return of 1930 champions Uruguay, who had boycotted the previous two World Cups. Uruguay won the tournament again after defeating the host nation Brazil, in the match called \\"Maracanazo\\" (Portuguese: Maracana?o).\\r\\n\\r\\nIn the tournaments between 1934 and 1978, 16 teams competed in each tournament, except in 1938, when Austria was absorbed into Germany after qualifying, leaving the tournament with 15 teams, and in 1950, when India, Scotland, and Turkey withdrew, leaving the tournament with 13 teams.[19] Most of the participating nations were from Europe and South America, with a small minority from North America, Africa, Asia, and Oceania. These teams were usually defeated easily by the European and South American teams. Until 1982, the only teams from outside Europe and South America to advance out of the first round were: USA, semi-finalists in 1930; Cuba, quarter-finalists in 1938; North Korea, quarter-finalists in 1966; and Mexico, quarter-finalists in 1970.\\r\\n\\r\\nThe tournament was expanded to 24 teams in 1982,[20] and then to 32 in 1998,[21] also allowing more teams from Africa, Asia and North America to take part. Since then, teams from these regions have enjoyed more success, with several having reached the quarter-finals: Mexico, quarter-finalists in 1986; Cameroon, quarter-finalists in 1990; South Korea, finishing in fourth place in 2002; Senegal, along with USA, both quarter-finalists in 2002; Ghana, quarter-finalists in 2010; and Costa Rica, quarter-finalists in 2014. Nevertheless, European and South American teams continue to dominate, e.g., the quarter-finalists in 1994, 1998, 2006 and 2018 were all from Europe or South America and so were the finalists of all tournaments so far.\\r\\n\\r\\nTwo hundred teams entered the 2002 FIFA World Cup qualification rounds; 198 nations attempted to qualify for the 2006 FIFA World Cup, while a record 204 countries entered qualification for the 2010 FIFA World Cup.[22]\\r\\n\\r\\nIn October 2013, Sepp Blatter spoke of guaranteeing the Caribbean Football Union's region a position in the World Cup.[23] In the edition of 25 October 2013 of the FIFA Weekly Blatter wrote that: \\"From a purely sporting perspective, I would like to see globalisation finally taken seriously, and the African and Asian national associations accorded the status they deserve at the FIFA World Cup. It cannot be that the European and South American confederations lay claim to the majority of the berths at the World Cup.\\"[24] Those two remarks suggested to commentators that Blatter could be putting himself forward for re-election to the FIFA Presidency.[25]\\r\\n\\r\\nFollowing the magazine's publication, Blatter's would-be opponent for the FIFA Presidency, UEFA President Michel Platini, responded that he intended to extend the World Cup to 40 national associations, increasing the number of participants by eight. Platini said that he would allocate an additional berth to UEFA, two to the Asian Football Confederation and the Confederation of African Football, two shared between CONCACAF and CONMEBOL, and a guaranteed place for the Oceania Football Confederation.[26] Platini was clear about why he wanted to expand the World Cup. He said: \\"[The World Cup is] not based on the quality of the teams because you don't have the best 32 at the World Cup?... but it's a good compromise.?... It's a political matter so why not have more Africans? The competition is to bring all the people of all the world. If you don't give the possibility to participate, they don't improve.\\"[26]\\r\\n\\r\\nIn October 2016 FIFA president Gianni Infantino stated his support for a 48-team World Cup in 2026.[27] On 10 January 2017, FIFA confirmed the 2026 World Cup will have 48 finalist teams.[28]\\r\\n\\r\\nBy May 2015, the games were under a particularly dark cloud because of the 2015 FIFA corruption case, allegations and criminal charges of bribery, fraud and money laundering to corrupt the issuing of media and marketing rights (rigged bids) for FIFA games,[29] with FIFA officials accused of taking bribes totaling more than $150?million over 24 years. In late May, the U.S. Justice Department announced a 47-count indictment with charges of racketeering, wire fraud and money laundering conspiracy against 14 people. Arrests of over a dozen FIFA officials were made since that time, particularly on 29 May and 3 December.[30] By the end of May 2015, a total of nine FIFA officials and five executives of sports and broadcasting markets had already been charged on corruption. At the time, FIFA president Sepp Blatter announced he would relinquish his position in February 2016.[31]\\r\\n\\r\\nOn 4 June 2015 Chuck Blazer while co-operating with the FBI and the Swiss authorities admitted that he and the other members of FIFA's then-executive committee were bribed in order to promote the 1998 and 2010 World Cups.[32] On 10 June 2015 Swiss authorities seized computer data from the offices of Sepp Blatter.[33] The same day, FIFA postponed the bidding process for the 2026 FIFA World Cup in light of the allegations surrounding bribery in the awarding of the 2018 and 2022 tournaments. Then-secretary general Jr?me Valcke stated, \\"Due to the situation, I think it's nonsense to start any bidding process for the time being.\\"[34] On 28 October 2015, Blatter and FIFA VP Michel Platini, a potential candidate for presidency, were suspended for 90 days; both maintained their innocence in statements made to the news media.[35]\\r\\n\\r\\nOn 3 December 2015 two FIFA vice-presidents were arrested on suspicion of bribery in the same Zurich hotel where seven FIFA officials had been arrested in May.[36] An additional 16 indictments by the U.S. Department of Justice were announced on the same day.[37]\\r\\n\\r\\nAn equivalent tournament for women's football, the FIFA Women's World Cup, was first held in 1991 in China.[38] The women's tournament is smaller in scale and profile than the men's, but is growing; the number of entrants for the 2007 tournament was 120, more than double that of 1991.[39]\\r\\n\\r\\nMen's football has been included in every Summer Olympic Games except 1896 and 1932. Unlike many other sports, the men's football tournament at the Olympics is not a top-level tournament, and since 1992, an under-23 tournament with each team allowed three over-age players.[40] Women's football made its Olympic debut in 1996.\\r\\n\\r\\nThe FIFA Confederations Cup is a tournament held one year before the World Cup at the World Cup host nation(s) as a dress rehearsal for the upcoming World Cup. It is contested by the winners of each of the six FIFA confederation championships, along with the FIFA World Cup champion and the host country.[41]\\r\\n\\r\\nFIFA also organises international tournaments for youth football (FIFA U-20 World Cup, FIFA U-17 World Cup, FIFA U-20 Women's World Cup, FIFA U-17 Women's World Cup), club football (FIFA Club World Cup), and football variants such as futsal (FIFA Futsal World Cup) and beach soccer (FIFA Beach Soccer World Cup). The latter three do not have a women's version, although a FIFA Women's Club World Cup has been proposed.[42]\\r\\n\\r\\nThe FIFA U-20 Women's World Cup is held the year before each Women's World Cup and both tournaments are awarded in a single bidding process. The U-20 tournament serves as a dress rehearsal for the larger competition.[43]\\r\\n\\r\\nFrom 1930 to 1970, the Jules Rimet Trophy was awarded to the World Cup winning team. It was originally simply known as the World Cup or Coupe du Monde, but in 1946 it was renamed after the FIFA president Jules Rimet who set up the first tournament. In 1970, Brazil's third victory in the tournament entitled them to keep the trophy permanently. However, the trophy was stolen in 1983 and has never been recovered, apparently melted down by the thieves.[44]\\r\\n\\r\\nAfter 1970, a new trophy, known as the FIFA World Cup Trophy, was designed. The experts of FIFA, coming from seven countries, evaluated the 53 presented models, finally opting for the work of the Italian designer Silvio Gazzaniga. The new trophy is 36?cm (14.2?in) high, made of solid 18 carat (75%) gold and weighs 6.175?kg (13.6?lb).[45] The base contains two layers of semi-precious malachite while the bottom side of the trophy bears the engraved year and name of each FIFA World Cup winner since 1974.[45] The description of the trophy by Gazzaniga was: \\"The lines spring out from the base, rising in spirals, stretching out to receive the world. From the remarkable dynamic tensions of the compact body of the sculpture rise the figures of two athletes at the stirring moment of victory.\\"[46]\\r\\n\\r\\nThis new trophy is not awarded to the winning nation permanently. World Cup winners retain the trophy only until the post-match celebration is finished. They are awarded a gold-plated replica rather than the solid gold original immediately afterwards.[47]\\r\\n\\r\\nCurrently, all members (players, coaches, and managers) of the top three teams receive medals with an insignia of the World Cup Trophy; winners' (gold), runners-up' (silver), and third-place (bronze). In the 2002 edition, fourth-place medals were awarded to hosts South Korea. Before the 1978 tournament, medals were only awarded to the eleven players on the pitch at the end of the final and the third-place match. In November 2007, FIFA announced that all members of World Cup-winning squads between 1930 and 1974 were to be retroactively awarded winners' medals.[48][49][50]\\r\\n\\r\\nSince the second World Cup in 1934, qualifying tournaments have been held to thin the field for the final tournament.[51] They are held within the six FIFA continental zones (Africa, Asia, North and Central America and Caribbean, South America, Oceania, and Europe), overseen by their respective confederations. For each tournament, FIFA decides the number of places awarded to each of the continental zones beforehand, generally based on the relative strength of the confederations' teams.\\r\\n\\r\\nThe qualification process can start as early as almost three years before the final tournament and last over a two-year period. The formats of the qualification tournaments differ between confederations. Usually, one or two places are awarded to winners of intercontinental play-offs. For example, the winner of the Oceanian zone and the fifth-placed team from the Asian zone entered a play-off for a spot in the 2010 World Cup.[52] From the 1938 World Cup onwards, host nations receive automatic qualification to the final tournament. This right was also granted to the defending champions between 1938 and 2002, but was withdrawn from the 2006 FIFA World Cup onward, requiring the champions to qualify. Brazil, winners in 2002, were the first defending champions to play qualifying matches.[53]\\r\\n\\r\\nThe current final tournament has been used since 1998 and features 32 national teams competing over the course of a month in the host nation(s). There are two stages: the group stage followed by the knockout stage.[54]\\r\\n\\r\\nIn the group stage, teams compete within eight groups of four teams each. Eight teams are seeded, including the hosts, with the other seeded teams selected using a formula based on the FIFA World Rankings and/or performances in recent World Cups, and drawn to separate groups.[55] The other teams are assigned to different \\"pots\\", usually based on geographical criteria, and teams in each pot are drawn at random to the eight groups. Since 1998, constraints have been applied to the draw to ensure that no group contains more than two European teams or more than one team from any other confederation.[56]\\r\\n\\r\\nEach group plays a round-robin tournament, in which each team is scheduled for three matches against other teams in the same group. This means that a total of six matches are played within a group. The last round of matches of each group is scheduled at the same time to preserve fairness among all four teams.[57] The top two teams from each group advance to the knockout stage. Points are used to rank the teams within a group. Since 1994, three points have been awarded for a win, one for a draw and none for a loss (before, winners received two points).\\r\\n\\r\\nIf one considers all possible outcomes (win, draw, loss) for all six matches in a group, there are 729 (= 36) outcome combinations possible. However, 207 of these combinations lead to ties between the second and third places. In such case, the ranking among these teams is determined as follows:[58]\\r\\n\\r\\nThe knockout stage is a single-elimination tournament in which teams play each other in one-off matches, with extra time and penalty shootouts used to decide the winner if necessary. It begins with the round of 16 (or the second round) in which the winner of each group plays against the runner-up of another group. This is followed by the quarter-finals, the semi-finals, the third-place match (contested by the losing semi-finalists), and the final.[54]\\r\\n\\r\\nOn 10 January 2017, FIFA approved a new format, the 48-team World Cup (to accommodate more teams), which consists of 16 groups of three teams each, with two teams qualifying from each group, to form a round of 32 knockout stage, to be implemented by 2026.[59]\\r\\n\\r\\nEarly World Cups were given to countries at meetings of FIFA's congress. The locations were controversial because South America and Europe were by far the two centres of strength in football and travel between them required three weeks by boat. The decision to hold the first World Cup in Uruguay, for example, led to only four European nations competing.[60] The next two World Cups were both held in Europe. The decision to hold the second of these in France was disputed, as the South American countries understood that the location would alternate between the two continents. Both Argentina and Uruguay thus boycotted the 1938 FIFA World Cup.[61]\\r\\n\\r\\nSince the 1958 FIFA World Cup, to avoid future boycotts or controversy, FIFA began a pattern of alternating the hosts between the Americas and Europe, which continued until the 1998 FIFA World Cup. The 2002 FIFA World Cup, hosted jointly by South Korea and Japan, was the first one held in Asia, and the first tournament with multiple hosts.[62] South Africa became the first African nation to host the World Cup in 2010. The 2014 FIFA World Cup was hosted by Brazil, the first held in South America since Argentina 1978,[63] and was the first occasion where consecutive World Cups were held outside Europe.\\r\\n\\r\\nThe host country is now chosen in a vote by FIFA's Council. This is done under an exhaustive ballot system. The national football association of a country desiring to host the event receives a \\"Hosting Agreement\\" from FIFA, which explains the steps and requirements that are expected from a strong bid. The bidding association also receives a form, the submission of which represents the official confirmation of the candidacy. After this, a FIFA designated group of inspectors visit the country to identify that the country meets the requirements needed to host the event and a report on the country is produced. The decision on who will host the World Cup is usually made six or seven years in advance of the tournament. However, there have been occasions where the hosts of multiple future tournaments were announced at the same time, as was the case for the 2018 and 2022 World Cups, which were awarded to Russia and Qatar, with Qatar becoming the first Middle Eastern country to host the tournament.[64][65]\\r\\n\\r\\nFor the 2010 and 2014 World Cups, the final tournament is rotated between confederations, allowing only countries from the chosen confederation (Africa in 2010, South America in 2014) to bid to host the tournament. The rotation policy was introduced after the controversy surrounding Germany's victory over South Africa in the vote to host the 2006 tournament. However, the policy of continental rotation will not continue beyond 2014, so any country, except those belonging to confederations that hosted the two preceding tournaments, can apply as hosts for World Cups starting from 2018.[66] This is partly to avoid a similar scenario to the bidding process for the 2014 tournament, where Brazil was the only official bidder.[67]\\r\\n\\r\\nThe 2026 FIFA World Cup was chosen to be held in the United States, Canada and Mexico, marking the first time a World Cup has been shared by three host nations.[68] The 2026 tournament will be the biggest World Cup ever held, with 48 teams playing 80 matches. Sixty matches will take place in the US, including all matches from the quarter-finals onward, while Canada and Mexico will host 10 games each.[68]\\r\\n\\r\\nSix of the eight champions have won one of their titles while playing in their own homeland, the exceptions being Brazil, who finished as runners-up after losing the deciding match on home soil in 1950 and lost their semi-final against Germany in 2014, and Spain, which reached the second round on home soil in 1982. England (1966) won its only title while playing as a host nation. Uruguay (1930), Italy (1934), Argentina (1978) and \\r\\nFrance (1998) won their first titles as host nations but have gone on to win again, while Germany (1974) won their second title on home soil.[69]\\r\\n\\r\\nOther nations have also been successful when hosting the tournament. Switzerland (quarter-finals 1954), Sweden (runners-up in 1958), Chile (third place in 1962), South Korea (fourth place in 2002), and Mexico (quarter-finals in 1970 and 1986) all have their best results when serving as hosts. So far, South Africa (2010) has been the only host nation to fail to advance beyond the first round.[70]\\r\\n\\r\\n The best-attended single match, shown in the last three columns, has been the final in half of the 20 World Cups as of 2014. Another match or matches drew more attendance than the final in 1930, 1938, 1958, 1962, 1970ÿ1982, 1990 and 2006.\\r\\n\\r\\nThe World Cup was first televised in 1954 and is now the most widely viewed and followed sporting event in the world. The cumulative audience of all matches of the 2006 World Cup is estimated to be 26.29?billion.[1] 715.1?million individuals watched the final match of this tournament (a ninth of the entire population of the planet). The 2006 World Cup draw, which decided the distribution of teams into groups, was watched by 300 million viewers.[73] The World Cup attracts many sponsors such as Coca-Cola, McDonald's and Adidas. For these companies and many more, being a sponsor strongly impacts their global brands. Host countries typically experience a multimillion-dollar revenue increase from the month-long event.\\r\\nThe governing body of the sport, FIFA, generated $4.8?billion in revenue from the 2014 tournament.[74]\\r\\n\\r\\nEach FIFA World Cup since 1966 has its own mascot or logo. World Cup Willie, the mascot for the 1966 competition, was the first World Cup mascot.[75] World Cups have also featured official match balls specially designed for each tournament.[76]\\r\\n\\r\\nThe World Cup even has a statistically significant effect on birth rates, the male/female sex ratio of newborns, and heart attacks in nations whose national teams are competing.[77][78][79]\\r\\n\\r\\nIn all, 79 nations have played in at least one World Cup.[83] Of these, eight national teams have won the World Cup, and they have added stars to their badges, with each star representing a World Cup victory. (Uruguay, however, choose to display four stars on their badge, representing their two gold medals at the 1924 and 1928 Summer Olympics and their two World Cup titles in 1930 and 1950).\\r\\n\\r\\nWith five titles, Brazil are the most successful World Cup team and also the only nation to have played in every World Cup (21) to date.[84] Brazil were also the first team to win the World Cup for the third (1970), fourth (1994) and fifth (2002) time. Italy (1934 and 1938) and Brazil (1958 and 1962) are the only nations to have won consecutive titles. West Germany (1982ÿ1990) and Brazil (1994ÿ2002) are the only nations to appear in three consecutive World Cup finals. Germany has made the most top-four finishes (13), medals (12), as well as the most finals (8).\\r\\n\\r\\nTo date, the final of the World Cup has only been contested by teams from the UEFA (Europe) and CONMEBOL (South America) confederations. European nations have won twelve titles, while South American have won nine. Only two teams from outside these two continents have ever reached the semi-finals of the competition: United States (North, Central America and Caribbean) in 1930 and South Korea (Asia) in 2002. The best result of an African team is reaching the quarter-finals: Cameroon in 1990, Senegal in 2002 and Ghana in 2010. Only one Oceanian qualifier, Australia in 2006, has advanced to the second round.[85]\\r\\n\\r\\nBrazil, Argentina, Spain and Germany are the only teams to win a World Cup outside their continental confederation; Brazil came out victorious in Europe (1958), North America (1970 and 1994) and Asia (2002). Argentina won a World Cup in North America in 1986, while Spain won in Africa in 2010. In 2014, Germany became the first European team to win in the Americas. Only on five occasions have consecutive World Cups been won by teams from the same continent, and currently it is the first time with four champions in a row from the same continental confederation. Italy and Brazil successfully defended their titles in 1938 and 1962 respectively, while Italy's triumph in 2006 has been followed by wins for Spain in 2010, Germany in 2014 and France in 2018. Currently, it is also the first time that one of the currently winning continents (Europe) is ahead of the other (South America) by more than one championship.\\r\\n\\r\\nAt the end of each World Cup, awards are presented to the players and teams for accomplishments other than their final team positions in the tournament. There are currently six awards:[86]\\r\\n\\r\\nAn All-Star Team consisting of the best players of the tournament has also been announced for each tournament since 1998.\\r\\n\\r\\nThree players share the record for playing in the most World Cups; Mexico's Antonio Carbajal (1950ÿ1966) and Rafael Mrquez (2002-2018); and Germany's Lothar Matth?us (1982ÿ1998) all played in five tournaments.[91] Matth?us has played the most World Cup matches overall, with 25 appearances.[92] Brazil's Djalma Santos (1954ÿ1962), West Germany's Franz Beckenbauer (1966ÿ1974) and Germany's Philipp Lahm (2006ÿ2014) are the only players to be named to three Finals All-Star Teams.[93]\\r\\n\\r\\nMiroslav Klose of Germany (2002ÿ2014) is the all-time top scorer at the finals, with 16 goals. He broke Ronaldo of Brazil's record of 15 goals (1998ÿ2006) during the 2014 semi-final match against Brazil. West Germany's Gerd Mller (1970ÿ1974) is third, with 14 goals.[94] The fourth placed goalscorer, France's Just Fontaine, holds the record for the most goals scored in a single World Cup; all his 13 goals were scored in the 1958 tournament.[95]\\r\\n\\r\\nIn November 2007, FIFA announced that all members of World Cup-winning squads between 1930 and 1974 were to be retroactively awarded winners' medals.[48] This made Brazil's Pel the only player to have won three World Cup winners' medals (1958, 1962, and 1970, although he did not play in the 1962 final due to injury),[96] with 20 other players who have won two winners' medals. Seven players have collected all three types of World Cup medals (winners', runner- ups', and third-place); five players were from West Germany's squad of 1966ÿ1974 including Franz Beckenbauer, Jrgen Grabowski, Horst-Dieter H?ttges, Sepp Maier and Wolfgang Overath (1966ÿ1974), Italy's Franco Baresi (1982, 1990, 1994) and the most recent has been Miroslav Klose of Germany (2002ÿ2014) with four consecutive medals.[97]\\r\\n\\r\\nBrazil's Mrio Zagallo, West Germany's Franz Beckenbauer and France's Didier Deschamps are the only people to date to win the World Cup as both player and head coach. Zagallo won in 1958 and 1962 as a player and in 1970 as head coach.[98] Beckenbauer won in 1974 as captain and in 1990 as head coach,[99] and Deschamps repeated the feat in 2018, after having won in 1998 as captain.[100] Italy's Vittorio Pozzo is the only head coach to ever win two World Cups (1934 and 1938).[101] All World Cup-winning head coaches were natives of the country they coached to victory.[102]\\r\\n\\r\\nAmong the national teams, Germany and Brazil have played the most World Cup matches (109), Germany appeared in the most finals (8), semi-finals (13), quarter-finals (16), while Brazil has appeared in the most World Cups (21), has the most wins (73) and has scored the most goals (229).[103][104] The two teams have played each other twice in the World Cup, in the 2002 final and in the 2014 semi-final.[105]","input":"What teams have the most world cup wins?"},{"output":"Lincoln","context":"President of the United States\\r\\nAppointments\\r\\nAssassination and legacy\\r\\n\\r\\n\\r\\nJohn F. Kennedy, the 35th President of the United States, was assassinated on Friday, November 22, 1963, at 12:30?p.m. in Dallas, Texas while riding in a presidential motorcade in Dealey Plaza.[1] Kennedy was riding with his wife Jacqueline, Texas Governor John Connally, and Connally's wife, Nellie, and was fatally shot by former U.S. Marine[2] Lee Harvey Oswald. A ten-month investigation by the Warren Commission from November 1963 to September 1964 concluded that Oswald acted alone in shooting Kennedy and that Jack Ruby also acted alone when he killed Oswald before he could stand trial.[3] Kennedy's death marked the fourth (following those of Lincoln, Garfield, and McKinley) and most recent assassination of an American President. Vice President Lyndon B. Johnson automatically became President upon Kennedy's death.[4]\\r\\nIn contrast to the conclusions of the Warren Commission, the United States House Select Committee on Assassinations (HSCA) concluded in 1979 that Kennedy was \\"probably assassinated as a result of a conspiracy\\".[5] The HSCA agreed with the Warren Commission that the injuries sustained by Kennedy and Connally were caused by Oswald's three rifle shots, but they also determined the existence of an additional gunshot based on analysis of an audio recording and therefore \\"... a high probability that two gunmen fired at [the] President.\\"[6][7] The Committee was not able to identify any individuals or groups involved with the possible conspiracy. In addition, the HSCA found that the original federal investigations were \\"seriously flawed\\" with respect to information-sharing and the possibility of conspiracy.[8] As recommended by the HSCA, the acoustic evidence indicating conspiracy was subsequently re-examined and rejected.[9]\\r\\nIn light of the investigative reports determining that \\"reliable acoustic data do not support a conclusion that there was a second gunman,\\" the U.S. Justice Department concluded active investigations and stated \\"that no persuasive evidence can be identified to support the theory of a conspiracy in ... the assassination of President Kennedy.\\"[10] However, Kennedy's assassination is still the subject of widespread debate and has spawned numerous conspiracy theories and alternative scenarios. Polling in 2013 showed that 60% of Americans believe that a group of conspirators was responsible for the assassination.[11][12]\\r\\n\\r\\n\\r\\nPresident John F. Kennedy decided to travel to Texas to smooth over frictions in the Democratic Party between liberals Ralph Yarborough and Don Yarborough (no relation) and conservative John Connally.[13]\\r\\nA presidential visit to Texas was first agreed upon by Kennedy, Vice President Lyndon B. Johnson (a Texas native) and Texas Governor John Connally while all three men were together in a meeting in El Paso on June 5, 1963.[14]\\r\\nPresident Kennedy later decided to embark on the trip with three basic goals in mind: he wanted to help raise more Democratic Party presidential campaign fund contributions;[14] he wanted to begin his quest for reelection in November 1964;[15] and, because the Kennedy-Johnson ticket had barely won Texas in 1960 (and had even lost in Dallas), President Kennedy wanted to help mend political fences among several leading Texas Democratic party members who appeared to be fighting politically amongst themselves.[16]\\r\\nPresident Kennedy's trip to Dallas was first announced to the public in September 1963.[17] The exact motorcade route was finalized on November 18 and announced to the public a few days before November 22.[18]\\r\\nPresident Kennedy's motorcade route through Dallas with Johnson and Connally was planned to give him maximum exposure to local crowds prior to his arrival[19] for a luncheon at the Trade Mart, where he would meet with civic and business leaders. The White House staff informed the Secret Service that the President would arrive at Dallas Love Field via a short flight from Carswell Air Force Base in Fort Worth.[19][20]\\r\\nThe Dallas Trade Mart had been preliminarily selected for the luncheon, and Kenneth O'DonnellPresident Kennedy's friend and appointments secretary had selected the Trade Mart as the final destination on the motorcade route .[19][20] Leaving from Dallas Love Field, the motorcade had been allotted 45?minutes to reach the Trade Mart at a planned arrival time of 12:15?p.m. The itinerary was designed to be a meandering 10-mile (16-km) route between the two places, and the parade route vehicles could be driven slowly in the allotted time.\\r\\nSpecial Agent Winston G. Lawson, a member of the White House detail who acted as the advance Secret Service Agent, and Secret Service Agent Forrest V. Sorrels, Special Agent in charge of the Dallas office, were most active in planning the actual route. On November 14, both men attended a meeting at Love Field and drove over the route that Sorrels believed was best suited for the motorcade. From Love Field, the route passed through a suburban portion of Dallas, through Downtown along Main Street, and finally to the Trade Mart via a short segment of the Stemmons Freeway.[21]\\r\\nThe President had planned to return to Love Field to depart for a fundraising dinner in Austin later that day. For the return trip, the agents selected a more direct route, which was approximately four miles, or 6.4 kilometers (some of this route would be used after the assassination). The planned route to the Trade Mart was widely reported in Dallas newspapers several days before the event, for the benefit of people who wished to view the motorcade.[21]\\r\\nTo pass through Downtown Dallas, a route west along Dallas' Main Street, rather than Elm Street (one block to the north) was chosen, because this was the traditional parade route, and provided the maximal building and crowd views. The route on Main Street precluded a direct turn onto the Fort Worth Turnpike exit (which served also as the Stemmons Freeway exit), which was the route to the Trade Mart, because this exit was only accessible from Elm Street. The planned motorcade route thus included a short one-block turn at the end of the downtown segment of Main Street, onto Houston Street for one block northward, before turning again west onto Elm, in order to proceed through Dealey Plaza before exiting Elm onto the Stemmons Freeway. The Texas School Book Depository was situated at the northwest corner of Houston and Elm.[22]\\r\\nThree vehicles were used for Secret Service and police protection in the Dallas motorcade. The first car, an unmarked white Ford (hardtop), carried Dallas Police Chief Jesse Curry, Secret Service Agent Win Lawson, Sheriff Bill Decker and Dallas Field Agent Forrest Sorrels. The second car, a 1961 Lincoln Continental convertible, was occupied by driver Agent Bill Greer, SAIC Roy Kellerman, Governor John Connally, Nellie Connally, President Kennedy and Jackie Kennedy.[23]\\r\\nThe third car, a 1955 Cadillac convertible code-named \\"Halfback\\", contained driver Agent Sam Kinney, ATSAIC Emory Roberts, presidential aides Ken O'Donnell and Dave Powers, driver Agent George Hickey and PRS agent Glen Bennett. Secret Service agents Clint Hill, Jack Ready, Tim McIntyre and Paul Landis rode on the running boards.\\r\\nOn November 22after a breakfast speech in Fort Worth, where President Kennedy had stayed overnight after arriving from San Antonio, Houston, and Washington, D.C., the previous day[24] the president boarded Air Force One, which departed at 11:10 and arrived at Love Field 15 minutes later. At about 11:40, the presidential motorcade left Love Field for the trip through Dallas, running on a schedule about 10 minutes longer than the planned 45, due to enthusiastic crowds estimated at 150,000ÿ200,000 people, and two unplanned stops directed by the president.[25][26] By the time the motorcade reached Dealey Plaza, they were only five minutes away from their planned destination.\\r\\nPresident Kennedy's open-top 1961 Lincoln Continental four-door convertible limousine entered Dealey Plaza at 12:30?p.m. CST. Nellie Connally, the First Lady of Texas, turned around to the President, who was sitting behind her, and commented, \\"Mr. President, you can't say Dallas doesn't love you,\\" which President Kennedy acknowledged by saying \\"No, you certainly can't.\\" Those were the last words ever spoken by John F. Kennedy.[27][28][29]\\r\\nFrom Houston Street, the presidential limousine made the planned left turn onto Elm Street, allowing it access to the Stemmons Freeway exit. As the vehicle turned onto Elm, the motorcade passed the Texas School Book Depository. Shots were fired at President Kennedy as his motorcade continued down Elm Street. About 80% of the witnesses recalled hearing three shots.[30]\\r\\nA minority of the witnesses recognized the first gunshot they heard as weapon fire, but there was hardly any reaction to the first shot from a majority of the people in the crowd or those riding in the motorcade. Many bystanders later said that they heard what they first thought to be a firecracker or the backfire of one of the vehicles shortly after the President began waving.[31] Although some close witnesses[32] recalled seeing the limousine slow down, nearly stop, or completely stop, the Warren Commission, based on the Zapruder film, found that the limousine had an average speed of 11.2?miles per hour over the 186?ft of Elm Street immediately preceding the fatal head shot.[citation needed]\\r\\nWithin one second of each other, President Kennedy, Governor Connally, and Mrs. Kennedy all turned abruptly from looking to their left to looking to their right, between Zapruder film frames 155 and 169.[citation needed] Connally, like the President, was a World War II military veteran but unlike him, a longtime hunter. Connally testified that he immediately recognized the sound of a high-powered rifle, then he turned his head and torso rightward, attempting to see President Kennedy behind him. Governor Connally testified he could not see the President, so he then started to turn forward again (turning from his right to his left). Connally also testified that when his head was facing about 20 degrees left of center,[28] he was hit in his upper right back by a bullet he did not hear fired. The doctor who operated on Connally measured his head at the time he was hit as turned 27 degrees left of center.[28] After Connally was hit he shouted, \\"Oh, no, no, no. My God. They're going to kill us all!\\"[33]\\r\\nMrs. Connally testified that just after hearing a loud, frightening noise that came from somewhere behind her and to her right, she turned toward President Kennedy and saw him raise his arms and elbows, with his hands in front of his face and throat. She then heard another gunshot and then Governor Connally yelling. Mrs. Connally then turned away from Kennedy toward her husband, at which point another gunshot sounded and she and the limousine's rear interior were covered with fragments of skull, blood, and brain.\\r\\nAccording to the Warren Commission[34] and the House Select Committee on Assassinations,[35] Kennedy was waving to the crowds on his right with his right arm upraised on the side of the limo when a shot entered his upper back, penetrated his neck and slightly damaged a spinal vertebra and the top of his right lung. The bullet exited his throat nearly centerline just beneath his larynx and nicked the left side of his suit tie knot. He raised his elbows and clenched his fists in front of his face and neck, then leaned forward and left. Mrs. Kennedy, facing him, then put her arms around him in concern.[28][36]\\r\\nGovernor Connally also reacted after the same bullet penetrated his back just below his right armpit. The bullet created an oval entry wound, impacted and destroyed four inches of his right fifth rib, and exited his chest just below his right nipple. This created a two-and-a-half inch oval sucking-air chest wound. That same bullet then entered his arm just above his right wrist and cleanly shattered his right radius bone into eight pieces. The bullet exited just below the wrist at the inner side of his right palm and finally lodged in his left inner thigh.[28][36] The Warren Commission theorized that the \\"single bullet\\" (see single-bullet theory) struck sometime between Zapruder frames 210 to 225, while the House Select Committee theorized that it struck exactly at Zapruder frame 190.[37]\\r\\nAccording to the Warren Commission, a second shot that struck the President was recorded at Zapruder film frame 313. The Commission made no conclusion as to whether this was the second or third bullet fired. The presidential limousine then passed in front of the John Neely Bryan north pergola concrete structure. The two investigative committees concluded that the second shot to hit the president entered the rear of his head (the House Select Committee placed the entry wound four inches higher than the Warren Commission placed it) and passed in fragments through his skull; this created a large, \\"roughly ovular\\" [sic] hole on the rear, right side. The president's blood and fragments of his scalp, brain, and skull landed on the interior of the car, the inner and outer surfaces of the front glass windshield and raised sun visors, as well as on the front engine hood and the rear trunk lid. His blood and fragments also landed on the follow-up Secret Service car and its driver's left arm, as well on the motorcycle officers who were riding on both sides of the President just behind his vehicle.[38][39]\\r\\nSecret Service Special Agent Clint Hill was riding on the left front running board of the follow-up car, which was immediately behind the Presidential limousine. Hill testified that he heard one shot, then, as documented in other films and concurrent with Zapruder frame 308, he jumped off into Elm Street and ran forward to try to get on the limousine and protect the President. (Hill testified to the Warren Commission that after he jumped into Elm Street, he heard two more shots.)[40]\\r\\nAfter the President had been shot in the head, Mrs. Kennedy began to climb out onto the back of the limousine, though she later had no recollection of doing so.[33][41] Hill believed she was reaching for something, perhaps a piece of the President's skull.[40] He jumped onto the back of the limousine while at the same time Mrs. Kennedy returned to her seat, and he clung to the car as it exited Dealey Plaza and accelerated, speeding to Parkland Memorial Hospital.\\r\\nAfter Mrs. Kennedy crawled back into her limousine seat, both Governor Connally and Mrs. Connally heard her say more than once, \\"They have killed my husband,\\" and \\"I have his brains in my hand.\\"[27][28] In a long-redacted interview for Life magazine days later, Mrs. Kennedy recalled, \\"All the ride to the hospital I kept bending over him saying, 'Jack, Jack, can you hear me? I love you, Jack.' I kept holding the top of his head down trying to keep the ...\\" The President's widow could not finish her sentence.[42]\\r\\nGovernor Connally was riding in the same limousine in a seat directly in front of the President and three inches more to the left than Kennedy; he was also seriously injured, but survived. Doctors later stated that after the Governor was shot, his wife pulled him onto her lap, and the resulting posture helped close his front chest wound, which was causing air to be sucked directly into his chest around his collapsed right lung.\\r\\nJames Tague was a spectator and witness to the assassination. He received a minor wound to his right cheek while standing 531 feet (162?m) away from the depository's sixth floor easternmost window, 270 feet (82?m) in front of and slightly to the right of President Kennedy's head facing direction and more than 16 feet (4.9?m) below the top of the President's head. Tague's injury occurred when a bullet or bullet fragment with no copper casing struck the nearby Main Street south curb. A deputy sheriff noticed some blood on Tague's cheek, and Tague realized something had stung his face during the shooting. When Tague pointed to where he had been standing, the police officer noticed a bullet smear on a nearby curb. Nine months later the FBI removed the curb, and a spectrographic analysis revealed metallic residue consistent with that of the lead core in Oswald's ammunition.[43] Tague testified before the Warren Commission and initially stated that he was wounded on his cheek by either the second or third shot of the three shots that he remembered hearing. When the Commission counsel pressed him to be more specific, Tague testified that he was wounded by the second shot.[44]\\r\\nThe presidential limousine was passing a grassy knoll on the north side of Elm Street at the moment of the fatal head shot. As the motorcade left the plaza, police officers and spectators ran up the knoll and from a railroad bridge over Elm Street (the triple underpass), to the area behind a five-foot (1.5?m) high stockade fence atop the knoll, separating it from a parking lot. No sniper was found.[45] S. M. Holland, who had been watching the motorcade on the triple underpass, testified that \\"immediately\\" after the shots were fired, he spotted a plume of smoke arising from the trees by the fence and then ran around the corner where the overpass joined the fence, but did not see anyone running from the area.[46][47]\\r\\nLee Bowers, a railroad switchman who was sitting in a two-story tower,[47] had an unobstructed view of the rear of the stockade fence atop the grassy knoll during the shooting.[48] He saw a total of four men in the area between his tower and Elm Street: a middle-aged man and a younger man, standing 10 to 15 feet (3.0 to 4.6?m) apart near the triple underpass, who did not seem to know each other, and one or two uniformed parking lot attendants. At the time of the shooting, he saw \\"something out of the ordinary, a sort of milling around\\", which he could not identify. Bowers testified that one or both of the men were still there when motorcycle officer Clyde Haygood ran up the grassy knoll to the back of the fence.[49] In a 1966 interview, Bowers clarified that the two men he saw were standing in the opening between the pergola and the fence, and that \\"no one\\" was behind the fence at the time the shots were fired.[50][51]\\r\\nMeanwhile, Howard Brennan, a steamfitter who was sitting across the street from the Texas School Book Depository, notified police that he was watching the motorcade go by when he heard a shot that came from above and looked up to see a man with a rifle take another shot from a corner window on the sixth floor. He said he had seen the same man minutes earlier looking out the window.[52] Brennan gave a description of the shooter,[53] and Dallas police subsequently broadcast descriptions at 12:45?p.m., 12:48?p.m., and 12:55?p.m.[54] After the second shot was fired, Brennan recalled, \\"This man I saw previous was aiming for his last shot?... and maybe paused for another second as though to assure himself that he had hit his mark.\\"[55]\\r\\nAs Brennan spoke to the police in front of the building, they were joined by Harold Norman and James Jarman, Jr.,[56] two employees of the Texas School Book Depository who had watched the motorcade from windows at the southeast corner of the fifth floor.[57] Norman reported that he heard three gunshots come from directly over their heads.[58] Norman also heard the sounds of a bolt-action rifle and cartridges dropping on the floor above them.[59]\\r\\nEstimates of when Dallas police sealed off the exits from the Texas School Book Depository range from 12:33 to after 12:50?p.m.[60][61]\\r\\nThere were 104 ear witnesses in Dealey Plaza who were on record with an opinion as to the direction from which the shots came. Fifty-four (51.9%) thought that all shots came from the direction of the Texas School Book Depository. Thirty-three (31.7%) thought that all shots came from the area of the grassy knoll or the triple underpass. Nine (8.7%) thought that all shots came from a location entirely distinct from the knoll or the depository. Five (4.8%) thought that they heard shots from two locations, and 3 (2.9%) thought that the shots came from a direction consistent with both the knoll and the depository.[30][62]\\r\\nThe Warren Commission additionally concluded that three shots were fired and said that \\"a substantial majority of the witnesses stated that the shots were not evenly spaced. Most witnesses recalled that the second and third shots were bunched together.\\"[63]\\r\\nRoy Truly, Lee Harvey Oswald's supervisor at the depository, reported him missing to the Dallas police.[64] About 70?minutes after the assassination, Oswald was arrested for the murder of Dallas police officer J. D. Tippit. According to witness Helen Markam, Tippit had spotted Oswald walking along a sidewalk in the residential neighborhood of Oak Cliff,[65] three miles from Dealey Plaza. Officer Tippit had earlier received a radio message that gave a description of the suspect being sought in the assassination, and he called Oswald over to the patrol car.\\r\\nMarkam testified that after an exchange of words, Tippit got out of his car and Oswald shot him four times.[65] Multiple witnesses saw a man they identified as Oswald shoot Tippit or flee the scene after emptying the bullet casings from his gun. Oswald was next seen by shoe store manager Johnny Brewer \\"ducking into\\" the entrance alcove of his store. Suspicious of this activity, Brewer watched Oswald continue up the street and slip into the nearby Texas Theatre without paying.[66] Brewer alerted the theater's ticket clerk, who telephoned the police[67] at about 1:40?p.m.\\r\\nAccording to M.N. McDonald, who was one of the arresting officers, Oswald resisted arrest and was attempting to draw his pistol when he was struck and forcibly restrained by the police.[68] He was charged with the murders of President Kennedy and Officer Tippit later that night.[69] Oswald denied shooting anyone and claimed he was a patsy who was arrested because he had lived in the Soviet Union.[70][71][72]\\r\\nOswald's case never came to trial. Two days after the assassination, as he was being escorted to a car in the basement of Dallas Police Headquarters for the transfer from the city jail to the county jail, Oswald was fatally shot by Dallas nightclub owner Jack Ruby. The incident was broadcast live on American television at 11:21?a.m. CST on Sunday, November 24. Unconscious, Oswald was rushed by ambulance to Parkland Memorial Hospital, the same facility where doctors had tried to save President Kennedy's life two days earlier; he died at 1:07?p.m.[73] Oswald's death was announced on a TV news broadcast by Dallas police chief Jesse Curry. An autopsy was performed by Dallas County Medical Examiner Dr. Earl Rose at 2:45?p.m. the same day. The stated cause of death in the autopsy report was \\"hemorrhage secondary to gunshot wound of the chest\\".[74] Arrested immediately after the shooting, Ruby later said that he had been distraught over the Kennedy assassination and that killing Oswald would spare \\"... Mrs. Kennedy the discomfiture of coming back to trial.\\"[75]\\r\\nAn Italian Carcano M91/38 bolt-action rifle (see 6.5G52mm MannlicherÿCarcano cartridge) was found on the 6th floor of the Texas School Book Depository by Deputy Constable Seymour Weitzman and Deputy Sheriff Eugene Boone soon after the assassination of President Kennedy.[76] The recovery was filmed by Tom Alyea of WFAA-TV.[77]\\r\\nThis footage shows the rifle to be a Carcano, and it was later verified by photographic analysis commissioned by the HSCA that the rifle filmed was the same one later identified as the assassination weapon.[78] Compared to photographs taken of Oswald holding the rifle in his backyard, \\"one notch in the stock at [a] point that appears very faintly in the photograph\\" matched,[79] as well as the rifle's dimensions.[80]\\r\\nThe secondhand Carcano rifle had been purchased by Oswald in previous March, under the alias \\"A. Hidell\\" and delivered to a post office in Dallas where Oswald had rented a post-office box.[81] According to the Warren Commission Report, a partial palm print of Oswald was also found on the barrel of the gun,[82][83] and a tuft of fibers found in a crevice of the rifle was consistent with the fibers and colors of the shirt Oswald was wearing at the time of his arrest.[84][85]\\r\\nA bullet found on Governor Connally's hospital gurney and two bullet fragments found in the Presidential limousine were ballistically matched to this rifle.[86]\\r\\nThe staff at Parkland Hospital's Trauma Room 1 who treated President Kennedy observed that his condition was moribund, meaning that he had no chance of survival upon arriving at the hospital. George Burkley,[87] the President's personal physician, stated that a gunshot wound to the skull was the cause of death. Burkley signed President Kennedy's death certificate.[88]\\r\\nAt 1:00?p.m., CST (19:00 UTC), the President was pronounced dead after all heart activity had ceased. Father Oscar Huber[89] administered the last rites of the Roman Catholic Church. Father Huber[89] told The New York Times that the President was already dead by the time he arrived at the hospital, and he had to draw back a sheet covering the President's face to administer the sacrament of Extreme Unction. President Kennedy's death was officially announced by White House Acting Press Secretary Malcolm Kilduff at 1:33?p.m. CST (19:33 UTC).[90][91] Kilduff was acting press secretary on the trip because Pierre Salinger was traveling to Japan with half the Cabinet, including Secretary of State Dean Rusk.[92][93][94] Governor Connally, meanwhile, was taken to emergency surgery, where he underwent two operations that day.\\r\\nMembers of the President's security detail were attempting to remove Kennedy's body from the hospital when they briefly scuffled with Dallas officials, including Dallas County Coroner Earl Rose, who believed that he was legally obligated to perform an autopsy before Kennedy's body was removed.[95] The Secret Service pushed through and Rose eventually stepped aside.[96] The forensic panel of the HSCA, of which Rose was a member, later reported that Texas law indicated that it was the responsibility of the justice of the peace to determine the cause of death as well as the necessity of whether an autopsy was needed to determine the cause of death.[97] Theran Ward, a justice of the peace in Dallas County, signed the official record of inquest[97] as well as a second certificate of death.[98]\\r\\nA few minutes after 2:00?p.m. CST (20:00 UTC), Kennedy's remains were taken from Parkland Hospital to Love Field. His casket was then loaded onto Air Force One through the rear door, where it remained at the rear of the passenger compartment in place of a removed row of seats.[99] Johnson had accompanied Kennedy to Dallas and was riding two cars behind the President in the motorcade. The new President refused to leave for Washington without the remains of Kennedy and his widow Jacqueline.\\r\\nAt 2:38?p.m. CST (20:38 UTC), Lyndon Johnson, with Jacqueline Kennedy at his side, took the oath of office that was administered by federal judge Sarah T. Hughes on board Air Force One shortly before it departed from Love Field for the flight back to Washington, D.C.[100]\\r\\nThe autopsy was performed at the Bethesda Naval Hospital in Bethesda, Maryland; the procedure began at about 8?p.m. and ended at about midnight EST. The choice of autopsy hospital in the Washington, D.C., area was made at the request of Mrs. Kennedy, on the basis that John F. Kennedy had been a naval officer during World War II.[101]\\r\\nThe state funeral took place in Washington, D.C., during the three days that followed the assassination.[102]\\r\\nThe body of President Kennedy was flown back to Washington, D.C., and placed in the East Room of the White House for 24 hours.[103][104] On the Sunday after the assassination, his coffin was carried on a horse-drawn caisson to the United States Capitol to lie in state.[105] Throughout the day and night, hundreds of thousands of people lined up to view the guarded casket.[106] Representatives from over 90 countries attended the state funeral on Monday, November 25.[107] After the Requiem Mass at St. Matthew's Cathedral, the President was laid to rest 2.7 miles from the White House at Arlington National Cemetery in Virginia.\\r\\nNo radio or television stations broadcast the assassination live because the area through which the motorcade was traveling was not considered important enough for a live broadcast.[citation needed] Most media crews were not even with the motorcade but were waiting instead at the Dallas Trade Mart in anticipation of President Kennedy's arrival. Those members of the media who were with the motorcade were riding at the rear of the procession.\\r\\nThe Dallas police were recording their radio transmissions over two channels. A frequency designated as Channel One was used for routine police communications; Channel Two was an auxiliary channel dedicated to the President's motorcade. Up until the time of the assassination, most of the broadcasts on the second channel consisted of Police Chief Jesse Curry's announcements of the location of the motorcade as it wound through the city.\\r\\nPresident Kennedy's last seconds traveling through Dealey Plaza were recorded on silent 8 mm film for the 26.6?seconds before, during, and immediately following the assassination. This famous film footage was taken by garment manufacturer and amateur cameraman Abraham Zapruder, in what became known as the Zapruder film. Frame enlargements from the Zapruder film were published by Life magazine shortly after the assassination. The footage was first shown publicly as a film at the trial of Clay Shaw in 1969, and on television in 1975.[108] According to the Guinness Book of World Records, in 1999 an arbitration panel ordered the United States government to pay $615,384 per second of film to Zapruder's heirs for giving the film to the National Archives. The complete film, which lasts for 26?seconds, was valued at $16 million.[109][110]\\r\\nZapruder was not the only person who photographed at least part of the assassination; a total of 32 photographers were in Dealey Plaza. Amateur movies taken by Orville Nix, Marie Muchmore (shown on television in New York on November 26, 1963),[111][112][113] and photographer Charles Bronson captured the fatal shot, although at a greater distance than Zapruder. Other motion picture films were taken in Dealey Plaza at or around the time of the shooting by Robert Hughes, F. Mark Bell, Elsie Dorman, John Martin Jr., Patsy Paschall, Tina Towner, James Underwood, Dave Wiegman, Mal Couch, Thomas Atkins, and an unknown woman in a blue dress on the south side of Elm Street.[114]\\r\\nStill photos were taken by Phillip Willis, Mary Moorman, Hugh W. Betzner Jr., Wilma Bond, Robert Croft, and many others. Ike Altgens was the lone professional photographer in Dealey Plaza who was not in the press cars; he was a photo editor for the Associated Press in Dallas.\\r\\nAn unidentified woman, nicknamed the Babushka Lady by researchers, might have been filming the Presidential motorcade during the assassination. She was seen apparently doing so on film and in photographs taken by the others.\\r\\nPreviously unknown color footage filmed on the assassination day by George Jefferies was released on February 19, 2007, by the Sixth Floor Museum, Dallas, Texas.[115][116] The film does not include the shooting, having been taken roughly 90?seconds beforehand and a couple of blocks away. The only detail relevant to the investigation of the assassination is a clear view of President Kennedy's bunched suit jacket, just below the collar, which has led to different calculations about how low in the back President Kennedy was first shot (see discussion above).\\r\\nAfter the Dallas Police arrested Oswald and collected physical evidence at the crime scenes, they held Oswald at their headquarters for interrogation. All afternoon, they asked Oswald about the Tippit shooting and the assassination of the President. They intermittently questioned him for approximately 12?hours between 2:30?p.m., on November 22, and 11?a.m., on November 24.[117] Throughout this interrogation, Oswald denied any involvement with either Kennedy's assassination or Patrolman Tippit's murder.[117] Captain Fritz of the homicide and robbery bureau did most of the questioning and kept only rudimentary notes.[118][119] Days later, he wrote a report of the interrogation from notes he made afterwards.[118] There were no stenographic or tape recordings. Representatives of other law enforcement agencies were also present, including the FBI and the Secret Service, and occasionally participated in the questioning.[120] Several of the FBI agents who were present wrote contemporaneous reports of the interrogation.[121]\\r\\nOn the evening of the assassination, Dallas Police performed paraffin tests on Oswald's hands and right cheek in an apparent effort to determine, by means of a scientific test, whether or not he had recently fired a weapon.[120] The results were positive for the hands and negative for the right cheek.[120] These tests were unreliable, and the Warren Commission did not rely on the results of the test in making their findings.[120]\\r\\nOswald provided little information during his questioning by police. When confronted with evidence that he could not explain, he resorted to statements that were found to be false.[120][122]\\r\\nThe FBI was the first authority to complete an investigation. On December 9, 1963, the FBI issued a report and gave it to the Warren Commission.[123]\\r\\nThe FBI stated that three bullets were fired during the Kennedy assassination; the Warren Commission agreed with the FBI investigation that three shots were fired but disagreed with the FBI report on which shots hit Kennedy and which hit Governor Connally. The FBI report claimed that the first shot hit President Kennedy, the second shot hit Governor Connally, and the third shot hit President Kennedy in the head, killing him. In contrast, the Warren Commission concluded that one of the three shots missed, one of the shots hit President Kennedy and then struck Governor Connally, and a third shot struck President Kennedy in the head, killing him.\\r\\nThe President's Commission on the Assassination of President Kennedy, known unofficially as the Warren Commission, was established on November 29, 1963, by President Johnson to investigate the assassination.[124] Its 888-page final report was presented to Johnson on September 24, 1964,[125] and made public three days later.[126] It concluded that Lee Harvey Oswald acted alone in the killing of President Kennedy and the wounding of Texas Governor John Connally,[127] and that Jack Ruby also acted alone in the murder of Oswald.[128] The Commission's findings have since proven controversial and been both challenged and supported by later studies.\\r\\nThe Commission took its unofficial name, \\"The Warren Commission\\", from its chairman, Chief Justice Earl Warren. According to published transcripts of Johnson's presidential phone conversations, some major officials were opposed to forming such a commission, and several commission members took part only with extreme reluctance.[129] One of their chief reservations was that a commission would ultimately create more controversy than consensus, and those fears ultimately proved valid.[129]\\r\\nAll of the Warren Commission's records were submitted to the National Archives in 1964. The unpublished portion of those records was initially sealed for 75?years (to 2039) under a general National Archives policy that applied to all federal investigations by the executive branch of government,[130] a period \\"intended to serve as protection for innocent persons who could otherwise be damaged because of their relationship with participants in the case\\".[131] The 75-year rule no longer exists, supplanted by the Freedom of Information Act of 1966 and the JFK Records Act of 1992.\\r\\nIn 1968, a panel of four medical experts appointed by Attorney General Ramsey Clark met in Washington, D.C., to examine various photographs, X-ray films, documents, and other evidence about the death of President Kennedy. The Clark Panel determined that President Kennedy was struck by two bullets fired from above and behind him, one of which traversed the base of the neck on the right side without striking bone and the other of which entered the skull from behind and destroyed its upper right side.[132]\\r\\nThe United States President's Commission on CIA activities within the United States was set up under President Gerald Ford in 1975 to investigate the activities of the CIA within the United States. The commission was led by Vice President Nelson Rockefeller, and is sometimes referred to as the Rockefeller Commission.\\r\\nPart of the commission's work dealt with the Kennedy assassination, specifically the head snap as seen in the Zapruder film (first shown to the general public in 1975), and the possible presence of E. Howard Hunt and Frank Sturgis in Dallas.[133] The commission concluded that neither Hunt nor Sturgis was in Dallas at the time of the assassination.[134]\\r\\nThe Church Committee is the common term referring to the 1975 United States Senate Select Committee to Study Governmental Operations with Respect to Intelligence Activities, a U.S. Senate committee chaired by Senator Frank Church, to investigate the illegal intelligence gathering by the Central Intelligence Agency (CIA) and Federal Bureau of Investigation (FBI) after the Watergate incident. It also investigated the CIA and FBI conduct relating to the JFK assassination.\\r\\nTheir report concluded that the investigation on the assassination by FBI and CIA were fundamentally deficient and the facts that have greatly affected the investigation had not been forwarded to the Warren Commission by the agencies. The report hinted that there was a possibility that senior officials in both agencies made conscious decisions not to disclose potentially important information.[135]\\r\\nAs a result of increasing public and congressional skepticism regarding the Warren Commission's findings and the transparency of government agencies, House Resolution 1540 was passed in September 1976, creating the United States House Select Committee on Assassinations (HSCA) to investigate the assassinations of President Kennedy and Martin Luther King, Jr..[136]\\r\\nThe Committee investigated until 1978, and in March 1979 issued its final report, concluding that President John F. Kennedy was probably assassinated as a result of a conspiracy.[5] The chief reason for this conclusion was, according to the report's dissent, the subsequently discredited[9][10] acoustic analysis of a police channel dictabelt recording. The Committee concluded that previous investigations into Oswald's responsibility were \\"thorough and reliable\\" but they did not adequately investigate the possibility of a conspiracy, and that Federal agencies performed with \\"varying degrees of competency\\".[137] Specifically, the FBI and CIA were found to be deficient in sharing information with other agencies and the Warren Commission. Instead of furnishing all information relevant to the investigation, the FBI and CIA only responded to specific requests and were still occasionally inadequate.[138] Furthermore, the Secret Service did not properly analyze information it possessed prior to the assassination and was inadequately prepared to protect the President.[5]\\r\\nConcerning the conclusions of \\"probable conspiracy\\", four of the twelve committee members wrote dissenting opinions.[139] In accordance with the recommendations of the HSCA, the Dictabelt recording and acoustic evidence of a second assassin was subsequently reexamined. In light of investigative reports from the FBI's Technical Services Division and a specially appointed National Academy of Sciences Committee determining that \\"reliable acoustic data do not support a conclusion that there was a second gunman,\\"[140] the Justice Department concluded \\"that no persuasive evidence can be identified to support the theory of a conspiracy in ... the assassination of President Kennedy\\".[10]\\r\\nAlthough the final report and supporting volumes of the HSCA was publicly released, the working papers and primary documents were sealed until 2029 under Congressional rules and only partially released as part of the 1992 JFK Act.[141]\\r\\nIn 1992, the popular but controversial movie JFK had renewed public interest in the assassination and particularly in the still-classified documents referenced in the film's postscript. Largely in response to the film, Congress passed the JFK Act, or \\"President John F. Kennedy Assassination Records Collection Act of 1992\\". The goal of the legislation was to collect at the National Archives and make publicly available all of the assassination-related records held by federal and state government agencies, private citizens and various other organizations.\\r\\nThe JFK Act also mandated the creation of an independent office, the Assassination Records Review Board, to review the submitted records for completeness and continued secrecy. The Review Board was not commissioned to make any findings or conclusions regarding the assassination, just to collect and release all related documents. From 1994 until 1998, the Assassination Records Review Board gathered and unsealed about 60,000 documents, consisting of over 4?million pages.[142][143] Government agencies requested that some records remain classified and these were reviewed under section 6 criteria of the JFK Act. There were 29,420 such records and all of them were fully or partially released, with stringent requirements for redaction.\\r\\nAll remaining assassination-related records (approximately 5,000 pages) were scheduled to be released by October 26, 2017, with the exception of documents certified for continued postponement by the President under the following conditions: (1) \\"continued postponement is made necessary by an identifiable harm to the military, defense, intelligence operations, law enforcement, or conduct of foreign relations\\" and (2) \\"the identifiable harm is of such gravity that it outweighs the public interest in disclosure.\\" There is some concern among researchers that significant records, particularly those of the CIA, may still remain classified after 2017.[144][145] Although these documents may include interesting historical information, all of the records were examined by the Review Board and were not determined to impact the facts of the Kennedy assassination.[146] President Donald Trump said in October 2017 that he would not block the release of documents.[145]\\r\\nMany conspiracy theories posit that the assassination involved people or organizations in addition to Lee Harvey Oswald. Most current theories put forth a criminal conspiracy involving parties as varied as the CIA, the Mafia, Vice President Johnson, Cuban President Fidel Castro, the KGB, or some combination of those entities.[147]\\r\\nPublic opinion polls have consistently shown that a majority of Americans believe there was a conspiracy to kill Kennedy. Gallup polls have also found that only 20ÿ30% of the population believe that Oswald had acted alone. These polls also show that there is no agreement on who else may have been involved.[12][148] Former Los Angeles District Attorney Vincent Bugliosi estimated that a total of 42 groups, 82 assassins, and 214 people had been accused in various Kennedy assassination conspiracy theories.[149]\\r\\nThe last remaining documents which were required to be released under Section 5 of the President John F. Kennedy Assassination Records Collection Act of 1992 were released on October 26, 2017, while the remaining ones still classified will only be analyzed for redactions.[150]\\r\\nThe assassination evoked stunned reactions worldwide. The first hour after the shooting was a time of great confusion before the President's death was announced. The incident took place during the Cold War, and it was at first unclear whether the shooting might be part of a larger attack upon the United States. There was also concern whether Vice President Johnson, who had been riding two cars behind in the motorcade, was safe.\\r\\nThe news shocked the nation. People wept openly and gathered in department stores to watch the television coverage, while others prayed. Traffic in some areas came to a halt as the news spread from car to car.[151] Schools across the United States dismissed their students early.[152] Anger against Texas and Texans was reported from some individuals. Various Cleveland Browns fans, for example, carried signs at the next Sunday's home game against the Dallas Cowboys decrying the city of Dallas as having \\"killed the President\\".[153][154]\\r\\nHowever, there were also instances of Kennedy's opponents cheering the assassination. A journalist reported rejoicing in the streets of Amarillo, with a woman crying out, Hey, great, JFKs croaked![155]\\r\\nThe event left a lasting impression on many worldwide. As with the December 7, 1941, attack on Pearl Harbor before it and the September 11 attacks after it, asking \\"Where were you when you heard about President Kennedy's assassination\\" would become a common topic of discussion.[156][157][158][159]\\r\\nThe plane that served as Air Force One at the time of the assassination is on display at the National Museum of the United States Air Force in Dayton, Ohio. The museum offers tours of the aircraft that include the rear of the aircraft where President Kennedy's casket was placed and the location where Mrs. Kennedy stood in her blood-stained pink dress while Vice President Johnson was sworn in as president. The 1961 Lincoln Continental limousine is on display at the Henry Ford Museum in Dearborn, Michigan.[160]\\r\\nEquipment (including a gurney) from the trauma room at Parkland Memorial Hospital, where President Kennedy was pronounced dead, was purchased from the hospital by the federal government in 1973 and is now stored by the National Archives at an underground facility in Lenexa, Kansas. The First Lady's pink suit, the autopsy report, X-rays and President Kennedy's blood-stained jacket, shirt and tie worn during the assassination are stored in the National Archives facility in College Park, Maryland, with access controlled by a representative of the Kennedy family. The rifle used by Oswald, his diary, revolver, bullet fragments, and the windshield of Kennedy's limousine are also stored by the Archives.[160] The Lincoln Catafalque, which President Kennedy's coffin rested on while he lay in state in the Capitol, is on display at the United States Capitol Visitor Center.[161]\\r\\nOn October 12, 1993, the three-acre park within Dealey Plaza, the buildings facing it, the overpass, and a portion of the adjacent railyard ÿ including the railroad switching tower ÿ were designated part of the Dealey Plaza Historic District by the National Park Service. Much of the area is accessible to visitors, including the park and grassy knoll. Elm Street is still an active city thoroughfare, and a large X in the middle of the road marks the approximate spot of the presidential limousine when the shots rang out.[162] The Texas School Book Depository and its Sixth Floor Museum now draw over 325,000 visitors each year to Dealey Plaza. The museum is operated by the Dallas County Historical Foundation. The sixth floor of the building contains a re-creation of the sniper's nest that was used by Oswald.[163] The Sixth Floor Museum also manages the John Fitzgerald Kennedy Memorial located one block east of Dealey Plaza.[164]\\r\\nThe Historic Auto Attractions museum in Roscoe, Illinois has permanently displayed items related to the assassination, including the catalog that Oswald used to order the rifle, a hat and jacket that belonged to Jack Ruby and the shoes he wore when he shot Oswald, as well as a window from the Texas School Book Depository. The Texas State Archives have the clothes that Governor Connally wore on November 22, 1963.\\r\\nAt the direction of the deceased President's brother, Attorney General Robert F. Kennedy, some items were intentionally destroyed by the United States government. The casket that was used to transport President Kennedy's body aboard Air Force One from Dallas to Washington was dropped into the sea by the Air Force, because \\"its public display would be extremely offensive and contrary to public policy\\".[165] Other items such as the hat worn by Jack Ruby the day he shot Lee Harvey Oswald and the toe tag on Oswald's corpse are in the hands of private collectors and have sold for tens of thousands of dollars at auctions.[160]\\r\\nThe gun that Jack Ruby used to kill Oswald, which was owned by his brother Earl, was sold by the Herman Darvick Autograph Auctions in New York City on December 26, 1991, for $220,000.[166]\\r\\nDealey Plaza and Texas School Book Depository in 1969, six years after the assassination\\r\\nPlaque on the building that was the former Texas School Book Depository\\r\\nDealey Plaza, with Elm Street on the right and the Triple Underpass in the middle.\\r\\nLooking southeast, with the pergola and knoll behind the photographer: the X on the street marks the approximate position of President Kennedy in the limousine at the moment he and Governor Connally were shot (photo taken in July 2006).","input":"Who was the first president to get assasinated?"},{"output":"Command & Conquer 4: Tiberian Twilight","context":"Command & Conquer (abbreviated as C&C or CnC) is a real-time strategy (RTS) video game franchise, first developed by Westwood Studios. The first game was one of the earliest of the RTS genre, itself based on Westwood Studios' landmark strategy game Dune II and introducing trademarks followed in the rest of the series. This includes full-motion video cutscenes with a notable ensemble cast to progress the story, as opposed to digitally in-game rendered cutscenes. Westwood Studios was taken over by Electronic Arts in 1998 and eventually closed down in 2003. The studio and some of its members were absorbed into EA Los Angeles, which continued development on the series.\\r\\n\\r\\n\\r\\nAfter Westwood Studios developed the successful Dune II, Computer Gaming World reported in 1993 that the company would not use the Dune license for Westwood's next strategy game \\"mostly because the programmers are tired of sand\\". The magazine stated that it would have \\"new terrain and enemies\\", and that \\"the design team is serious about doing a multi-player version\\".[2]\\r\\nCommand & Conquer was released worldwide by Westwood in 1995. The plot is set sometime in the near future where the Earth becomes contaminated by a mysterious resource known only as Tiberium. A global war ensues between the UN-formed Global Defense Initiative to contain it and the cult quasi-state revolutionary Brotherhood of Nod, led by the enigmatic Kane, which seeks to harness it. Highly successful, it was followed by Command & Conquer: Red Alert in 1996 which is set in an alternate universe where the Soviet Union wages war with the Allied West. Developed as the prequel to the original, the Red Alert series was spun off into a separate, lighthearted and comic series, while the original game and its sequels became known as the \\"Tiberium\\" series, retaining its sci-fi and serious tone. The first game is sometimes referred to as Tiberian Dawn as a result.\\r\\nThe original game was followed by Command & Conquer: Tiberian Sun in 1999 and its expansion pack. In 2002, a first person-shooter set in the Tiberium universe, Command & Conquer: Renegade, was released and praised for its online features. The highly anticipated Command & Conquer 3: Tiberium Wars was released in 2007 and followed by the expansion pack Command & Conquer 3: Kane's Wrath. Command & Conquer 4: Tiberian Twilight, released in 2010 as the conclusion to the Tiberium saga, received noticeably more mixed reviews because of its deviation from traditional gameplay and story. The Red Alert series was continued by the 2000 title Command & Conquer: Red Alert 2, its expansion, Yuri's Revenge and Command & Conquer: Red Alert 3 in 2008, which introduced a third \\"Empire of the Rising Sun\\" faction. A spin-off game in 2003, Command & Conquer: Generals, set in a more realistic near-future and featuring the United States, China and the Global Liberation Army was followed by an expansion pack, Zero Hour.\\r\\nThe series was originally marketed to an Anglophone audience, though many of the games have been translated into other languages including German, French, Spanish, Italian, Russian, Korean, and Chinese. The series is primarily developed for personal computers running Microsoft Windows, although some titles have been ported to various video game consoles and the Apple Macintosh. Other games for platforms such as iOS and web-based have also been developed. As of July 2010, the Command & Conquer franchise consists of eleven games and eight expansion packs. The first three games of the series have been released as Freeware to promote the successors.[3] EA had confirmed that a new free-to-play game, entitled Command & Conquer, was in development with the studio Victory Games. It was set to be the next game in the series and was expected to be released in 2013. However, after a short alpha period the game was cancelled, and Victory Games disbanded by EA.[4][5] The Command & Conquer series has been a commercial success with over 30 million Command & Conquer games sold as of 2009.\\r\\nThe Command & Conquer games belong to the real-time strategy genre, with the exception of the first person shooter Command & Conquer: Renegade. A staple of the series is the parallel campaigns of various different factions to one central storyline. Games in the series also offered multiplayer game options, via LAN and modem connection. All games in the series have also offered online play, as well as \\"skirmish\\" matches in which players can face AI enemies.\\r\\nAll Command & Conquer real-time strategy games except Command & Conquer: Generals and its expansions have featured the \\"side bar\\" for navigation and control as opposed to many other similar games where the control bar is located on the bottom of the screen.\\r\\nCommand & Conquer gameplay typically requires the player to construct a base and acquire resources, in order to fund the ongoing production of various types of forces with which to assault and conquer the opponent's base. All available structures of the faction chosen by the player are constructed on-site at so-called \\"construction yard\\" - which typically begin as large-sized vehicles capable of deploying themselves into the aforementioned construction yards, called MCVs or Mobile Construction Vehicle. When a construction yard has finished building a new structure, the player can select a spot near to a preexisting structure in order to place it, where the prefabricated building will then rapidly unfold in a distinctive manner.\\r\\nIn all games in the series except Command & Conquer: Generals and its expansion, Zero Hour, funds are acquired by specialized \\"harvester\\" units which bring their cargo (Tiberium for the Tiberian series of games or ore or the more valuable gems for the Red Alert series) to a \\"refinery\\" structure. This in turn will convert the raw material into usable resources, expressed as credits. The raw materials themselves, in games released before Red Alert 2 as well as Command & Conquer 3 require storage space in the form of refineries and, in the case of excess, \\"storage silo\\" structures. In Generals and Zero Hour, funds are collected by two methods: collection of supplies by specialized units and converted to money in \\"supply centers\\" or directly produced by specialized units, buildings, or tech buildings at a set interval of time.\\r\\nAll factions have structures and units with similar functions at their disposal. However, they are adjusted to fit each faction's theme and have somewhat varying properties. Units can be classified into infantry, vehicles, and aircraft, each with their own subdivisions (note: in the Red Alert series there is also naval craft available). Unit effectiveness against opponents follows the rock-paper-scissors (intransitivity) principle found in most real-time strategy games.\\r\\nVirtually every type of structure in the series acts as a tech tree node, and additional units, structures and faction-specific abilities will become available as new structures are built and placed. Access to advanced units and abilities may be temporarily blocked if the required structures are destroyed or if they are not being provided with adequate power by the supporting \\"power plant\\" structures.\\r\\nEach Command & Conquer game has included the ability to play multiplayer games against other humans. Each box of Command & Conquer contains two CD copies of the game, immediately making multiplayer gaming possible with a single purchase of the game. Westwood Studios advertised this on the packaging with the slogan \\"A second copy, so you and your friend can destroy each other.\\" This resulted in Command & Conquer becoming the first RTS game title to feature competitive online play,[6] and this is considered the most pertinent outside factor in the success of Command & Conquer.[7] All games in the series up to Command & Conquer: Red Alert 2 also featured two CDs that could be used for this reason. However, later games did not.\\r\\nCommand & Conquer: Red Alert 3 was noted for being the first RTS game to enable the campaigns to be played cooperatively online; others had only supported single player campaigns. However, it was only possible to connect to other computers through EA's servers and not with LAN play.\\r\\nGames produced by Westwood use the proprietary Westwood Online system to facilitate multiplayer games over the Internet; Renegade also supported GameSpy. Games under EA's development continued to use GameSpy, but dropped support for Westwood Online in favor of using EA's own servers. The GameSpy master servers have shut down in 2013.[8] The community filled the gap with their services.[9]\\r\\nCommand & Conquer, released on August 31, 1995, was the first game in the series and is widely considered as the title which originally defined and popularized the real-time strategy genre.[6][7][10][11][12][13] Command & Conquer introduced the warring factions of the Global Defense Initiative (GDI) and the Brotherhood of Nod. Command & Conquer was well received and was widely praised by critics: \\"Command & Conquer is one of the finest, most brilliantly-designed computer games I have ever seen\\" said GameSpot reviewer Chris Hudak.[14] Command & Conquer has attained 94% as an aggregate score from Metacritic[15] with the less well received Covert Operations expansion pack obtaining an aggregate score of 72% after its 1996 release.[16]\\r\\nCommand & Conquer: Tiberian Sun, released on August 27, 1999, takes place approximately 30 years after the events in its predecessor. While the original Command & Conquer's plot was centered around an allegorical world politics setting, Tiberian Sun shifted this to a more sci-fi-like setting against the apocalyptic background of Tiberium beginning to assimilate vast portions of the Earth's ecosystems. In 1998, Westwood Studios, the developers of Tiberian Sun, was acquired by Electronic Arts. However, EA had no direct part in the development of the title. Compared to its predecessor, Tiberian Sun relies heavily on science fiction technologies and introduces a new isometric game engine featuring varying level terrain to give the impression of a true 3D environment.\\r\\nThe full motion video is also scripted differently; while the cutscenes of Command & Conquer and Red Alert were filmed from a first-person perspective, Tiberian Sun used traditional cinematic shots for its FMVs featuring well known Hollywood actors such as James Earl Jones of the original Star Wars trilogy and Michael Biehn of Terminator and Aliens.\\r\\nElectronic Arts forced the release of Tiberian Sun before the developers at Westwood had finished it. As a result, it was not as well received as Command & Conquer and received an aggregate score of 80% for the title and 73% for the expansion pack titled Firestorm. However the solid storyline, new concepts, more realistic graphics, atmospheric soundtrack and traditional gameplay were praised by critics, making up for some of its weaknesses.\\r\\nCommand & Conquer: Renegade, released February 26, 2002, takes place in the final days of the events of Command & Conquer and was the last Command & Conquer game to be created by Westwood Studios before their liquidation in 2003. Unlike any other games in the series, Renegade is a first person shooter[17] giving players their only chance to see the Command & Conquer universe from a first person perspective. Although receiving average reviews, with an aggregate score of 75% on both GameRankings and Metacritic, Renegade was praised for its online features. GameSpy awarded Renegade its 2002 \\"Wish it had been better\\" award, condemning the single player but saying that \\"C&C: Renegade's multiplayer was innovative and fun\\".[18] Online play was praised for encouraging teamwork and coordinated assaults, unlike other contemporary first-person shooters.[19]\\r\\nCommand & Conquer 3: Tiberium Wars, released March 29, 2007, was a return to the real-time strategy roots of the Command & Conquer series. As a direct sequel to Tiberian Sun, Tiberium Wars is set approximately 17 years after the events of Tiberian Sun and features the introduction of a third faction, the Scrin. The sequel was highly anticipated by fans and critics alike and attained an aggregate score of 85% from both GameRankings and Metacritic. PC Gamer U.S. gave the game its \\"Editor's Choice\\" rating at 90%, stating that \\"one of the greatest RTS franchises of all time returns to glory\\", while PC Gamer UK gave it a more reserved rating of 82%, stating that it was \\"a welcome, but limited, return.\\"\\r\\nShortly after the release of Tiberium Wars, the expansion pack Command & Conquer 3: Kane's Wrath was announced. Released on March 24, 2008, Kane's Wrath limited the player to only the Brotherhood of Nod in the campaign mode, though the original factions and six new sub-factions are available for the new strategic mode and skirmish mode. Reception was mainly positive with the expansion attaining an aggregate score of 77%.\\r\\nCommand & Conquer 4: Tiberian Twilight, released on March 16, 2010, saw a big change in gameplay from the previous Command & Conquer by removing the resource gathering and base building elements in previous games as well as the removal of the third faction, the Scrin. It is a direct sequel to Kane's Wrath (however not directly following on from its storyline), and is set 10 years after the game's final events, a time when Tiberium has advanced to its next evolutionary stage, and is rapidly spreading across Earth making it soon to be uninhabitable. The game came in for severe criticism from series fans for being so different from its predecessors.\\r\\nRenegade X, is a free, fan-made remake of Command & Conquer: Renegade. The developers received approval from EA to release their game,[20] and it entered open beta on February 26, 2014. Renegade X includes a short single-player campaign called Black Dawn.\\r\\nCommand & Conquer: Red Alert, released on October 31, 1996, is set in an alternate universe 1950s and was originally made to be the prequel to Command & Conquer[21] establishing Red Alert as the prologue of the entire Tiberium series of games. Since then Louis Castle has said that connecting Red Alert with the Tiberium series was a \\"failed experiment\\". Red Alert introduces the Allies and the Soviets as rival factions roughly analogous to NATO and the Warsaw Pact of the Cold War. The game was received well by critics and has the highest average score of any Command & Conquer game with an average of over 90% from GameRankings and Metacritic, unlike the title's two expansion packs, Red Alert: Counterstrike and Red Alert: The Aftermath of which both received below average reviews for the series with 63% and 70% average scores respectively. Both expansions gave the game more missions and more units. For PlayStation only, there was also a separate release to the original called Red Alert: Retaliation which included all the maps, missions and units of Red Alert: Counterstrike and Red Alert: The Aftermath as well as some newly filmed cut-scenes only available with Red Alert: Retaliation. Before being re-released as freeware on 31 August 2008 by Electronic Arts Command & Conquer: Red Alert had sold over three million copies.[22]\\r\\nCommand & Conquer: Red Alert 2 was released on October 23, 2000. It featured a Soviet invasion of North America with tanks, conscripts, gargantuan airships, and psychically dominated anti-ship giant squid. Since that game lacked reference to the Tiberian series, the connection established in the first Red Alert game became unclear. Opinion on whether or not the time travel events of the series were forming a separate continuity or just another side adventure on the way to the Tiberium era was divided. However, it has been implied by the original creators of the series, now working at Petroglyph Games, that Red Alert 2 takes place in a parallel universe that came about as a result of time travel experiments taking place some time into the Tiberian series.[23] Red Alert 2 was again received fairly positively with an aggregate score of 86% from GameRankings.\\r\\nAn expansion pack to Red Alert 2, Command & Conquer: Yuri's Revenge was released on October 10, 2001. In Yuri's Revenge, an ex-Soviet figure named Yuri, tries to conquer the world using psychic technology and his own private army. The expansion pack received mostly positive reviews. GameRankings reports an average score of 85% based on 31 reviews,[24] making Yuri's Revenge the best received expansion pack in the entire Command & Conquer series.\\r\\nCommand & Conquer: Red Alert 3, released on October 28, 2008, followed up on the story of Red Alert 2 and continued the series' more \\"light-hearted\\" take on Command & Conquer. Red Alert 3 escalated matters further by introducing many new comical units and the very well received Empire of the Rising Sun faction, an anime inspired version of the Empire of Japan. Executive producer Chris Corry stated in a pre-release interview that Red Alert 3 will further differentiate the playable factions from each other and \\"[play] up the silliness in their faction design whenever possible.\\"[25] This approach was seen as popular with Red Alert 3 obtaining an aggregate score of 82% from Metacritic. A stand-alone expansion to Red Alert 3, Command & Conquer: Red Alert 3 ÿ Uprising was released on March 12, 2009 to fairly poor reviews for the series with an average score of 64% from Metacritic. Another downloadable standalone game for the PlayStation 3 and Xbox 360 was released known as Command & Conquer: Red Alert 3 - Commander's Challenge which contained the Commander's Challenge mode of Uprising for consoles.\\r\\nCommand & Conquer: Red Alert (iOS) was released on October 16, 2009 for iOS which was a continuation of the story of Red Alert 2 and takes place before Red Alert 3. It contained two factions, the Allies and Soviet Union with a third faction, the Empire of the Rising Sun, to be added in its expansion pack.\\r\\nCommand & Conquer: Generals, released on February 10, 2003, had a plotline which was completely unrelated to the other games of the Command & Conquer series. Generals is set in the near future and features the United States, China and the fictional terrorist organization, the Global Liberation Army. Generals uses an engine dubbed \\"SAGE\\" (or Strategy Action Game Engine) and is the first fully three-dimensional Command & Conquer real-time strategy game. After its release, Generals received mostly positive reviews. Based on 34 reviews, Metacritic gives it a score of 84/100[26] which includes a score of 9.3/10 from IGN.[27] Generals has also received the E3 2002 Game Critics Awards Best Strategy Game award.[28] One review noted that Generals was the first ever Command & Conquer real-time strategy game that did not include full-motion video cutscenes to tell the story and that it departed from the unique interface and base-building mechanics that had characterized all of the previous C&C RTS titles.[29]\\r\\nAn expansion for Generals, Command & Conquer: Generals ÿ Zero Hour, was released on September 22, 2003 to further the Generals storyline. Zero Hour added 9 new armies to the game, over a dozen new campaign missions, and a gameplay mode known as Generals Challenge.[30] Unlike Generals, Zero Hour featured the return of full motion videos to the series. Zero Hour obtained much the same reception as Generals with an aggregate score of 85% and 84% from GameRankings and Metacritic respectively.\\r\\nAfter EA Los Angeles started up their new internal group Danger Close and switched its focus to the Medal of Honor series, EA launched a new studio named Victory Games to continue the Command & Conquer franchise.[31] On December 10, 2011, Electronic Arts posted that the next game in the series would be Command & Conquer: Generals 2.[32] On December 14, it was also announced that a new browser-based, free-to-play MMO Command & Conquer game is currently under development, under the name Command & Conquer: Tiberium Alliances.[33] On December 15, Tiberium Alliances began a closed beta.[34]\\r\\nOn August 15, 2012, it was announced that Generals 2 would be repurposed to a free-to-play game known as simply Command & Conquer.[35] The new game would have been based around the Generals franchise. However, following feedback from players who were able to play the alpha trial, the game was cancelled in October 2013.[36] In 2013, EA has said that the franchise will continue, but has given no other information.[37] In 2014, EA was looking for a new developer of the reboot.[38] Development on this title was cancelled.\\r\\nSee also canceled Command & Conquer games.\\r\\nMuch of the music for the series was composed and produced by Westwood Studios' former sound director and video game music composer Frank Klepacki for the early games, with composition duties being taken on by several others following the liquidation of Westwood Studios in 2003. Klepacki returned to the series in 2008 however to assist with the soundtrack for Red Alert 3.\\r\\nThe music has been received positively by critics, although praise was higher with earlier entries.\\r\\nThe original score for Command & Conquer: Red Alert was composed by Frank Klepacki and was voted the best video game soundtrack of 1996 by PC Gamer and Gameslice magazines.[39] Among his most famous songs from the series is the theme of Red Alert, titled \\"Hell March\\", which accents the style of the game with adrenalized riffs of electric guitar, the sounds of marching feet, and synthesizers to a dramatic chant. Originally intended to be the theme for the Brotherhood of Nod faction in the Covert Operations expansion to the original 1995 Command & Conquer game,[40] the track eventually ended up enlisting itself as a staple in the Red Alert series instead, and a second version of \\"Hell March\\" was specifically created for Command & Conquer: Red Alert 2.\\r\\nAfter C&C came out we wasted no time kicking out Covert Ops. I wrote some more ambient style themes they asked me for, and then I began tinkering with this heavy metal song that I was trying to gear towards Nod for the next big C&C game. Brett Sperry came in my office and said \\"You got anything I can hear for the new C&C?\\" I played it for him. He said \\"What's the name of this one?\\" I said \\"Hell March.\\" He said \\"That's the signature song for our next game.\\"[41]\\r\\nThe Command & Conquer series have been a commercial success with over 30 million Command & Conquer games sold as of 2009.[42] Games in the series have nearly consistently scored highly on video game review aggregator websites GameRankings and Metacritic, which collect data from numerous review websites. As noted in the table below, the highest rated game is Command & Conquer with a score of 94% from Metacritic. The highest rated game averaged over both sites is Command & Conquer: Red Alert with an average of just over 90%. As a series, Command & Conquer games have averaged approximately 80% when including expansion packs and approximately 84% without.\\r\\nCommand & Conquer's long history resulted in Guinness World Records awarding the series six world records in the Guinness World Records: Gamer's Edition 2008. These records include \\"Biggest Selling RTS Series\\", \\"Most Number of Platforms for an RTS\\", and \\"Longest Running Actor in Video Game Role\\" for Joe Kucan, who has played the part of Kane, the villainous mastermind of the series, for 15 years.","input":"What is the newest command and conquer game?"},{"output":"Sarbananda Sonowal","context":"The Government of Assam is the provincial governing authority of Assam, a state of India. It consists of the Governor nominated by the Government of India as the head of the state, currently Jagdish Mukhi.[1] The head of government is the Chief Minister, currently Sarbananda Sonowal,[2] who is the leader of the group that commands a majority in the 126-membered unicameral Assam Legislative Assembly. The Assam Assembly is elected by universal adult suffrage for a period of five years. The Chief Minister is assisted by a Council of Ministers that he nominates, the size of which is restricted.\\r\\nIn 2016, the BJP-led National Democratic Alliance won a majority of seats in the legislature, with 86 seats, followed by Congress with 26 seats and AIUDF with 13.\\r\\nMinisters sworn on 24 May 2016:[5]","input":"Who is the deputy chief minister of assam?"},{"output":"as a colony for former African American slaves and their free black descendants","context":"Liberia is a country in West Africa which was founded, established, colonized, and controlled by citizens of the United States and ex-Caribbean slaves as a colony for former African American slaves and their free black descendants. It is one of only two sovereign countries in the world that were started by citizens and ex-Caribbean slaves of a political power as a colony for former slaves of the same political power, the other being Sierra Leone, established by Great Britain. In 1847, Liberia proclaimed its independence from the American Colonization Society (ACS).\\r\\nLiberia was under control and as protectorate of United States. It retained its independence throughout the Scramble for Africa by European colonial powers during the late 19th century, and the country remained in the American sphere of influence. Until 1980, Liberia was dominated by the small minority of descendants of the free black colonists, known collectively as Americo-Liberians. Little economic development occurred. From the 1920s, the country became dependent on exploitation of natural resources, particularly the rubber industry and the Firestone Company.\\r\\n\\r\\n\\r\\nHistorians believe that many of the indigenous peoples of Liberia migrated there from the north and east between the 12th and 16th centuries AD. Portuguese explorers established contacts with people of the land later known as \\"Liberia\\" as early as 1462. They named the area Costa da Pimentia (Pepper Coast) or Grain Coast because of the abundance of melegueta pepper. In 1602 the Dutch established a trading post at Grand Cape Mount but destroyed it a year later. In 1663, the British installed trading posts on the Pepper Coast. No further known settlements by non-African colonists occurred along the Grain Coast (an alternative name) until the arrival in 1821 of free blacks from the United States.\\r\\nFrom around 1800, in the United States, people opposed to slavery were planning ways to achieve manumission of more slaves and, ultimately, to abolish the institution. At the same time, slaveholders in the South opposed having free blacks in their midst, as they believed the free people threatened the stability of their slave societies. While mostly freed in the North, former slaves and free blacks suffered considerable discrimination, and some territories and states in the Northwest prohibited migration by free people of color.\\r\\nSome abolitionists, including distinguished blacks like Paul Cuffee, believed that blacks should return to their homeland.[1] Cuffees dream was that free African Americans and freed slaves \\"could establish a prosperous colony in Africa,\\" one based on emigration and trade.[1] In 1811, Cuffee founded the Friendly Society of Sierra Leone, a cooperative black group intended to encourage the Black Settlers of Sierra Leone, and the Natives of Africa generally, in the Cultivation of their Soil, by the Sale of their Produce.[1] As Wright put it, \\"Cuffee hoped to send at least one vessel each year to Sierra Leone, transporting African-American settlers and goods to the colony and returning with marketable African products.\\"[1]\\r\\nThe first ship, Mayflower of Liberia (formerly Elizabeth), departed New York on February 6, 1820, for West Africa carrying 86 settlers.[2][3] Between 1821 and 1838, the American Colonization Society developed the first settlement, which would be known as Liberia.[4] On July 26, 1847, it declared its independence.[5]\\r\\nAs early as the period of the American Revolution, many white members of American society thought that African Americans could not succeed in living in their society as free people. Some considered blacks physically and mentally inferior to whites, and others believed that the racism and societal polarization resulting from slavery were insurmountable obstacles for integration of the races. Thomas Jefferson was among those who proposed colonization in Africa: relocating free blacks outside the new nation.[6]\\r\\nAfter 1783 the ranks of free blacks expanded markedly. Northern states abolished slavery, some on a schedule of gradual abolition that kept adults enslaved until the 1840s in New York and New Jersey. In addition, some slaveholders were inspired by the ideals of the Revolutionary War and freed their slaves, often by will at the owner's death. The number of free blacks increased markedly in the South, especially in the Upper South where changing agriculture reduced the need for slave labor. In addition, Quaker, Methodist and Baptist preachers were active in those years encouraging slaveholders to free their slaves. The Northeast states abolished slavery following the war, generally on a graduated basis where it was still economically viable, as in the mid-Atlantic states.[citation needed]\\r\\nIn 1800 and 1802, slave rebellions occurred (see Gabriels rebellion) in Virginia, and were brutally suppressed by slaveholders. Some planters feared that free blacks would encourage slaves to run away or revolt. From 1782ÿ1810, the percentage of free blacks in the Upper South increased from less than one percent to 13.5%. In the nation as a whole, the number of free people of color also increased. In 1790, there were 59,467 free blacks, out of a total U.S. population of almost four million and a total black U.S. population of 800,000. By 1800, there were 108,378 free blacks in a population of 7.2 million.[citation needed] These factors significantly influenced the popularity of the concept of colonization as a solution to the \\"problem \\" of free blacks.[citation needed]\\r\\nIn 1787, Britain had started to resettle the Black Poor of London in the colony of Freetown in modern-day Sierra Leone. Many were Black Loyalists, former American slaves who had been freed in exchange for their services during the American Revolution. The Crown also offered resettlement to former slaves whom they had first resettled in Nova Scotia. The Black Loyalists there found both the discrimination and climate hard to bear. Wealthy African-American shipowner Paul Cuffee thought that colonization was worth supporting. Aided by support from certain members of Congress and British officials, he conveyed 38 American Blacks to Freetown in 1816 at his own expense. He died in 1817, but his private initiative helped arouse public interest in the idea of colonization.[citation needed]\\r\\nThe American Colonization Society (ACS) was founded in 1817 by Virginia politician Charles F. Mercer and Presbyterian minister Robert Finley of New Jersey. The goal of the ACS was to settle free blacks outside of the United States; its method was to help them relocate to Africa.[4]\\r\\nFrom January 1820, the ACS sent ships from New York to West Africa. The first had 88 free black emigrants and three white ACS agents on board. The agents were to find an appropriate area for a settlement. Additional ACS representatives arrived in the second ACS ship Nautilus. In December 1821, they acquired Cape Mesurado, a 36-mile-long (58?km) strip of land near present-day Monrovia, from the indigenous ruler King Peter (perhaps with some threat of force).[7]\\r\\nFrom the beginning, the colonists were attacked by indigenous peoples whose territory this was, such as the Malink tribes. In addition, they suffered from disease, the harsh climate, lack of food and medicine, and poor housing conditions.[8]\\r\\nUntil 1835, five more colonies were started by American state colonization societies, and one by the U.S. government, all in the area of the ACS settlement. The first colony on Cape Mesurado was extended, along the coast as well as inland, sometimes by use of force against the native tribes. In 1838 these colonies came together to create the Commonwealth of Liberia. Monrovia would be named the capital.[4] By 1842, four of the other American state colonies were incorporated into Liberia, and one was destroyed by indigenous people. The colonists of African-American descent became known as Americo-Liberians. Many were of mixed-race including European ancestry. They were distinct as African Americans in their education, religion and culture and they did not identify with the indigenous, non-Christian peoples.[citation needed]\\r\\nThe ACS administrators gradually gave the maturing colony more self-governance. In 1839, it was renamed the Commonwealth of Liberia; in 1841 the Commonwealth's first black Governor, J.J. Roberts, was appointed. By the 1840s, the ACS was effectively bankrupt; Liberia had become a financial burden for it. In 1846, the ACS directed the Americo-Liberians to proclaim their independence. In 1847, Roberts proclaimed the colony the free and independent republic of Liberia. It then counted some 3000 settlers. Representatives drew up a constitution, modeled after that of the United States.[citation needed]\\r\\nBetween 1847 and 1980, the state of Liberia was dominated by the small minority of black colonists and their descendants, known collectively as Americo-Liberians. The Americo-Liberian minority, many of whom were mixed race African Americans, tended to marry within their group. They had established plantations and businesses, and were generally richer than the indigenous people of Liberia and exercised overwhelming political power.[9]\\r\\nPolitically, Liberia was dominated by two political parties. The Americo-Liberians had limited the franchise to prevent indigenous Liberians from voting in elections.[10] The Liberian Party (later the Republican Party), was supported primarily by mixed-race African Americans from poorer backgrounds, while the True Whig Party received much of its following from richer blacks.[11] From the first presidential election in 1847, the Liberian Party held political dominance. It used its position of power to attempt to cripple its opposition.[10]\\r\\nIn 1869, however, the Whigs won the presidential election under Edward James Roye. Although Roye was deposed after two years and the Republicans returned to government, the Whigs regained power in 1878. This party maintained power constantly afterward.[10]\\r\\nA series of rebellions among the indigenous Liberian population took place between the 1850s and 1920s. In 1854, a newly independent African-American state in the region, the Republic of Maryland, was forced by an insurgency of the Grebo and the Kru people to join Liberia. Liberia's expansion brought the colony into border disputes with French and British colonists in French Guinea and Sierra Leone, respectively. The presence and protection of the United States Navy in West Africa until 1916 prevented any military threat to Liberian territory or independence.[12]\\r\\nThe social order in Liberia was dominated by a group of Americo-Liberians. Although descended from peoples of African origin, the ancestors of Americo-Liberians had been born in the United States for generations before emigrating to Africa; they held American cultural, religious and social values, shaped by their own heritage. Like many Americans and Europeans of the period, the Americo-Liberian held beliefs in the religious superiority of Protestant Christianity and the cultural power of European civilization over indigenous animism and culture.\\r\\nThe Americo-Liberians created communities and social infrastructure closely based on what they knew - American society. They spoke English, and built churches and houses in styles resembling those they were familiar with in the southern United States. Although they never constituted more than five percent of the population of Liberia, they controlled key resources that allowed them to dominate the local native peoples: access to the ocean, modern technical skills, literacy and higher levels of education, and valuable relationships with many United States institutions, including the American government.[13]\\r\\nReflecting the system of racial segregation in the United States, the Americo-Liberians created a cultural and racial caste system with themselves at the top and indigenous Liberians at the bottom.[14][15][16] They believed in a form of \\"racial equality\\" which meant that all residents of Liberia had the potential to become \\"civilized\\" through western-style education and conversion to Christianity.\\r\\nDuring World War II thousands of indigenous Liberians migrated from the nation's rural interior to the coastal regions in search of jobs. The Liberian Government had long opposed this kind of migration, but was no longer able to restrain it. In the decades after 1945, the Liberian government received hundreds of millions of dollars of unrestricted foreign investment, which destabilized the Liberian economy. Government revenue rose enormously, but was being grossly embezzled by government officials. Growing economic disparities caused increased hostility between indigenous groups and Americo-Liberians.[citation needed]\\r\\nThe social tensions led President Tubman to enfranchise the indigenous Liberians either in 1951 or 1963 (accounts differ). Tubman and his Whig Party continued to repress political opposition, and to rig elections.\\r\\nThe suppression of the slave trade in West Africa by American and British navies after 1808 also produced new settlers, as these two navies would resettle liberated slaves in Liberia or Sierra Leone rather than trying to return them to their homelands. In the later 19th century, Liberia had to compete economically with European colonies in Africa. The economy of Liberia was always based on the production of agricultural produce for export. In particular, Liberia's important coffee industry was destroyed in the 1870s by the emergence of production in Brazil.[17]\\r\\nNew technology available in Europe increasingly drove Liberian shipping companies out of business.[17] Although Roye's government attempted to procure funding for a railway in 1871, the plan never materialized. The first railway was not built until 1945.[18] From the late 19th century, European powers such as the United Kingdom and Germany invested in infrastructure in their African colonies, making them more competitive in terms of getting products to market, improving communications, etc.\\r\\nThe national currency, the Liberian dollar, collapsed in 1907. The country was later forced to adopt the United States Dollar. The Liberian government was constantly dependent on foreign loans at high rates of exchange, which endangered the country's independence.[18]\\r\\nIn 1926, Firestone, an American rubber company, started the worlds largest rubber plantation in Liberia. This industry created 25,000 jobs, and rubber quickly became the backbone of the Liberian economy; in the 1950s, rubber accounted for 40 percent of the national budget. During the 1930s Liberia signed concession agreements with Dutch, Danish, German and Polish investors in what has been described as an \\"open door\\" economic policy.[19]\\r\\nBetween 1946 and 1960, exports of natural resources such as iron, timber and rubber rose strongly. In 1971, Liberia had the world's largest rubber industry, and was the third largest exporter of iron ore. Since 1948, ship registrations was another important source of state revenue.\\r\\nFrom 1962 until 1980, the U.S. donated $280 million in aid to Liberia, in exchange for which Liberia offered its land free of rent for U.S. government facilities. Throughout the 1970s the price of rubber in the world commodities market was depressed, putting pressure on Liberian state finances.\\r\\nAfter 1927, the League of Nations investigated accusations that the Liberian government forcibly recruited and sold indigenous people as contract labor or slaves.[18] In its 1930 report the League admonished the Liberian government for \\"systematically and for years fostering and encouraging a policy of gross intimidation and suppression\\", \\"[suppressing] the native, prevent him from realizing his powers and limitations and prevent him from asserting himself in any way whatever, for the benefit of the dominant and colonizing race, although originally the same African stock as themselves.\\"[20] (see also Presidency Charles King 1920ÿ1930). President Charles D. B. King hastily resigned.\\r\\nLiberian rulers also built up ties with the Soviet bloc and other powers, striving for an independent position in world politics. They maintained strong bonds with the Western world allowed them to.\\r\\nThe United States had a long history of intervening in Liberia's internal affairs, repeatedly sending naval vessels to help suppress insurrections by indigenous tribes before and after independence (in 1821, 1843, 1876, 1910, and 1915). The United States had lost interest in Liberia after 1876, and the country became closely tied to British capital. Starting in 1909, the U.S. became heavily involved in the country. By 1909, Liberia faced serious external threats to its sovereignty from the British over unpaid foreign loans and annexation of its borderlands.\\r\\nIn 1912 the U.S. arranged a 40-year international loan of $1.7 million, against which Liberia had to agree to four Western powers (United States, Britain, France and Germany) controlling Liberian Government revenues until 1926. American administration of the border police stabilized the frontier with Sierra Leone (part of the British Empire) and checked French ambitions to annex more Liberian territory. The American navy established a coaling station in Liberia.[21]\\r\\nLiberia remained neutral for most of World War I, before joining the war on the Allied side in April 1918.[21] After its declaration of war, Liberia expelled its resident German merchants. As they constituted the country's largest investors and trading partners, Liberia suffered economically as a result.[22][not in citation given]\\r\\nIn 1926, the Liberian government gave a concession to the American rubber company Firestone to start the worlds largest rubber plantation at Harbel, Liberia. At the same time, Firestone arranged a $5 million private loan to Liberia. In the 1930s Liberia was again virtually bankrupt. After some United States pressure, it agreed to an assistance plan from the League of Nations. As part of this plan, two key officials of the League were placed in positions to \\"advise\\" the Liberian government.\\r\\nIn 1942, Liberia signed a Defense Pact with the United States. Rubber was a strategically important commodity, and Liberia assured the U.S. and its allies of all the natural rubber they needed. Also, Liberia allowed the U.S. to use its territory as a bridgehead for transports of soldiers and war supplies, to construct military bases, airports, the Freeport of Monrovia, roads to the interior, etc.[23] Many of these personnel who passed through Liberia were African-American soldiers (who at the time were in segregated army divisions) being deployed into military service in Europe. The American military presence boosted the Liberian economy; thousands of laborers descended from the interior to the coastal region. The countrys huge iron ore deposits were made accessible to commerce.\\r\\nThe Defense Areas Agreement between the U.S. and Liberia entailed the US-financed construction of Roberts Field airport, the Freeport of Monrovia, and roads into the interior of Liberia. By the end of World War II, approximately 5,000 American troops had been stationed in Liberia.[24] Arguments substantiating this notion are that World War II infrastructure developments did not positively affect social and political struggles in Liberia and that, decades after the development from World War II, Americo-Liberians disproportionately controlled and benefited from Liberias growing economy and increase in foreign investment.[25]\\r\\nAfter World War II, the U.S. pressured Liberia to resist the expansion of Soviet influence in Africa during the Cold War. Liberian president Tubman was agreeable to this policy. Between 1946 and 1960 Liberia received some $500 million in unrestricted foreign investment, mainly from the U.S. From 1962 to 1980, the U.S. donated $280 million in aid to Liberia. In the 1970s under president Tolbert, Liberia strove for a more non-aligned and independent posture, and established diplomatic relations with the Soviet Union, China, Cuba and Eastern bloc countries. It also severed ties with Israel during the Yom Kippur War in 1973, but announced it supported American involvement in the Vietnam War.\\r\\nPresident William R. Tolbert, Jr. pursued a policy of suppressing opposition. Dissatisfaction over governmental plans to raise the price of rice in 1979 led to protest demonstrations in the streets of Monrovia. Tolbert ordered his troops to fire on the demonstrators, and seventy people were killed. Rioting ensued throughout Liberia, finally leading to a military coup d'tat in April 1980. Tolbert was killed during the coup, and several of his ministers were executed soon afterwards, marking the end of Americo-Liberian domination of the country.\\r\\nAfter a bloody overthrow of the Americo-Liberian rgime by indigenous Liberians in 1980, a 'Redemption Council' took control of Liberia. Internal unrest, opposition to the new military regime, and governmental repression steadily grew, until in 1989 Liberia sank into outright tribal and civil war.\\r\\nSamuel Kanyon Doe (1951ÿ1990) was a member of the small ethnic group the Krahn, a master sergeant in the Liberian army, and trained by U.S. Army Special Forces[citation needed]. On April 12, 1980, Doe led a bloody coup d'tat against president Tolbert, in which Tolbert and twenty-six of his supporters were murdered; ten days later thirteen of Tolberts Cabinet members were publicly executed. Thus ended 133 years of Americo-Liberian political domination over Liberia. Doe established a military regime called the People's Redemption Council (PRC). Many people welcomed Doe's takeover as a shift favouring the majority of the population that had been excluded from power. Immediately following the coup, the PRC tolerated a relatively free press.\\r\\nDoe quickly established good relations with the United States, especially after U.S. President Ronald Reagan took office in 1981. Reagan increased financial aid for Liberia, from the $20 million it had been in 1979, to $75 million, and later $95 million per year. Liberia became again an important Cold War ally of the U.S.. Liberia served to protect important U.S. facilities and investments in Africa, and to counter the perceived spread of Soviet influence on the continent. Doe closed the Libyan mission in Monrovia and even severed diplomatic relations with the Soviet Union. He agreed to a modification of the mutual defense pact with the U.S., which granted staging rights at 24 hours' notice at Liberia's sea- and airports for the U.S. Rapid Deployment Forces. Under Doe, Liberian ports were opened to American, Canadian, and European ships, which brought in considerable foreign investment from shipping firms and earned Liberia a reputation as a tax haven.\\r\\nDoe overcame seven coup attempts between 1981 and 1985. In August 1981 he had Thomas Weh Syen and four other PRC members arrested and executed for allegedly conspiring against him. Then Does government declared an amnesty for all political prisoners and exiles, and released sixty political prisoners. Soon there were more internal rifts in the PRC. Doe became paranoid about the possibility of a counter-coup, and his government grew increasingly corrupt and repressive, banning political opposition, shutting down newspapers and jailing reporters. He began to systematically eliminate PRC members who challenged his authority, and to place people of his own ethnic Krahn background in key positions, which intensified popular anger. Meanwhile, the economy deteriorated precipitously. Popular support for Doe's government evaporated.\\r\\nA draft constitution providing for a multiparty republic had been issued in 1983 and was approved by referendum in 1984. After the referendum, Doe staged a presidential election on October 15, 1985. Nine political parties sought to challenge Doe's National Democratic Party of Liberia (NDPL), but only three were allowed to take part. Prior to the election, more than fifty of Doe's opponents were murdered. Doe was elected with 51% of the vote, but the election was heavily rigged. Foreign observers declared the elections fraudulent, and most of the elected opposition candidates refused to take their seats. U.S. Assistant Secretary of State for Africa Chester Crocker testified before Congress that the election was imperfect but that at least it was a step toward democracy. He further justified his support for the election results with the claim that, in any case, all African elections were known to be rigged at that time.\\r\\nIn November 1985 Thomas Quiwonkpa, Doe's former second-in-command, with an estimated 500 to 600 people, failed in an attempt to seize power; all were killed. Doe was sworn in as President on January 6, 1986. Doe then initiated crackdowns against certain tribes, such as the Gio (or Dan) and Mano, in the north, where most of the coup plotters came from. This government's mistreatment of certain ethnic groups resulted in divisions and violence among indigenous peoples, who until then had coexisted relatively peacefully. In the late 1980s, as fiscal austerity took hold in the United States and the perceived threat of Communism declined with the waning of the Cold War, the U.S. became disenchanted with Doe's government and began cutting off critical foreign aid to Liberia. This, together with the popular opposition, made Does position precarious.\\r\\nIn the late 1980s opposition from abroad to Does regime led to economic collapse. Doe had already been repressing and crushing internal opposition for some time, when in November 1985 another coup attempt against him failed. Doe retaliated against tribes such as the Gio (or Dan) and Mano in the north, where most of the coup plotters had come from. Does Krahn tribe began attacking other tribes, particularly in Nimba County in the northeast of Liberia, bordering on C?te dIvoire (Ivory Coast) and on Guinea. Some Liberian northerners fled brutal treatment from the Liberian army into the Ivory Coast.\\r\\nCharles Taylor, born 1948, is son to a Gola mother and either an Americo-Liberian or an Afro-Trinidadian father. Taylor was a student at Bentley College in Waltham, Massachusetts, U.S.A., from 1972 to 1977, earning a degree in economics. After the 1980 coup dtat he served some time in Does government until he was sacked in 1983 on accusation of embezzling government funds. He fled Liberia, was arrested in 1984 in Massachusetts on a Liberian warrant for extradition, and jailed in Massachusetts; escaped from jail in 1985, and probably fled to Libya. In 1989, while in the Ivory Coast, Taylor assembled a group of rebels into the National Patriotic Front of Liberia (NPFL), mostly from the Gio and Mano tribes.\\r\\nDecember 1989, the NPFL invaded Nimba County in Liberia. Thousands of Gio and Mano joined them, Liberians of other ethnic background as well. The Liberian army (AFL) counterattacked, and retaliated against the whole population of the region. Mid 1990, a war was raging between Krahn on one side, and Gio and Mano on the other. On both sides, thousands of civilians were massacred.\\r\\nBy the middle of 1990, Taylor controlled much of the country, and by June laid siege to Monrovia. In July, Yormie Johnson split off from NPFL and formed the Independent National Patriotic Front of Liberia (INPFL), based on the Gio tribe. Both NPFL and INPFL continued siege on Monrovia.\\r\\nIn August 1990, the Economic Community of West African States (ECOWAS), an organisation of West African states, created a military intervention force called Economic Community of West African States Monitoring Group (ECOMOG) of 4,000 troops, to restore order. President Doe and Yormie Johnson (INPFL) agreed to this intervention, Taylor didnt. On September 9, President Doe paid a visit to the barely established headquarters of ECOMOG in the Free Port of Monrovia. While he was at the ECOMOG headquarters, he was attacked by INPFL, taken to the INPFLs Caldwell base, tortured and killed.\\r\\nNovember 1990, ECOWAS agreed with some principal Liberian players but without Charles Taylor, on an Interim Government of National Unity (IGNU) under President Dr. Amos Sawyer. Sawyer established his authority over most of Monrovia, with the help of a paramilitary police force, the 'Black Berets', under Brownie Samukai, while the rest of the country was in the hands of the various warring factions.\\r\\nJune 1991, former Liberian army fighters formed rebel group United Liberation Movement of Liberia for Democracy (ULIMO), entered western Liberia in September 91, and gained territories from the NPFL.\\r\\nIn 1993, ECOWAS brokered a peace agreement in Cotonou, Benin. On 22 September 1993, the United Nations established the United Nations Observer Mission in Liberia (UNOMIL) to support ECOMOG in implementing the Cotonou agreement. March 1994, the Interim Government of Amos Sawyer was succeeded by a Council of State of six members headed by David D. Kpormakpor. Renewed armed hostilities broke out in 1994 and held on. During the course of the year, ULIMO split into two militias: ULIMO-J, a Krahn faction led by Roosevelt Johnson, and ULIMO-K, a Mandigo-based faction under Alhaji G.V. Kromah. Faction leaders agreed to the Akosombo peace agreement in Ghana but with little consequence. October 1994, the UN reduced its number of UNOMIL observers to about 90 because of the lack of will of combatants to honour peace agreements. December 1994, factions and parties signed the Accra agreement, but fighting continued. August 1995, factions signed an agreement largely brokered by Jerry Rawlings, Ghanaian President; Charles Taylor agreed. September 1995, Kpormakpors Council of State is succeeded by one under civilian Wilton G. S. Sankawulo and with the factional heads Charles Taylor, Alhaji Kromah and George Boley in it. April 1996, followers of Taylor and Kromah assaulted the headquarters of Roosevelt Johnson in Monrovia, and the peace accord collapsed. In August 1996, a new ceasefire is reached in Abuja, Nigeria. September 3, 1996, Ruth Perry followed Sankawulo as chairwoman of the Council of State, with the same three militia leaders in it.\\r\\nCharles Taylor won the 1997 presidential elections with 75.33 percent of the vote, while the runner-up, Unity Party leader Ellen Johnson Sirleaf, received a mere 9.58 percent of the vote. Accordingly, Taylor's National Patriotic Party gained 21 of a possible 26 seats in the Senate, and 49 of a possible 64 seats in the House of Representatives.[26] The election was judged free and fair by some observers although it was charged that Taylor had employed widespread intimidation to achieve victory at the polls.[citation needed]\\r\\nBloodshed in Liberia did slow considerably, but it did not end. Violence kept flaring up. During his entire reign, Taylor had to fight insurgencies against his government. Suspicions were, Taylor continued to assist rebel forces in neighbouring countries, like Sierra Leone, trading weapons for diamonds.\\r\\nSome ULIMO forces reformed themselves as the Liberians United for Reconciliation and Democracy (LURD), backed by the government of neighbouring Guinea. In 1999, they emerged in northern Liberia, in April 2000 they started fighting in Lofa County in northernmost Liberia. By the spring of 2001 they were posing a major threat to the Taylor government. Liberia was now engaged in a complex three-way conflict with Sierra Leone and the Guinea Republic.\\r\\nMeanwhile, the United Nations Security Council in March 2001 (Resolution 1343)[27] concluded that Liberia and Charles Taylor played roles in the civil war in Sierra Leone, and therefore:\\r\\nBy the beginning of 2002, Sierra Leone and Guinea were supporting the LURD, while Taylor was supporting opposition factions in both countries. By supporting Sierra Leonean rebels, Taylor also drew the enmity of the British and Americans.\\r\\nOther elements of the former ULIMO-factions formed another new small rebel group in the Republic of Ivory Coast, the Movement for Democracy in Liberia (MODEL) Headed by Mr Yayah Nimley, in 2003 and emerged in the south of Liberia.\\r\\nIn 2002, the women in Liberia were tired of seeing their country torn apart. Organized by social worker Leymah Gbowee, women started gathering and praying in a fish market to protest the violence.[28] They organized the Women in Peacebuilding Network (WIPNET), and issued a statement of intent: \\"In the past we were silent, but after being killed, raped, dehumanized, and infected with diseases, and watching our children and families destroyed, war has taught us that the future lies in saying NO to violence and YES to peace! We will not relent until peace prevails.\\"[29]\\r\\nJoined by Liberian Muslim Women's Organization,[30] Christian and Muslim women joined forces to create Women of Liberia Mass Action for Peace. They wore white, to symbolize peace. They staged silent nonviolence protests and forced a meeting with President Charles Taylor and extracted a promise from him to attend peace talks in Ghana.[31]\\r\\nIn 2003, a delegation of Liberian women went to Ghana to continue to apply pressure on the warring factions during the peace process. They staged a sit in outside of the Presidential Palace, blocking all the doors and windows and preventing anyone from leaving the peace talks without a resolution. Women of Liberia Mass Action for Peace became a political force against violence and against their government.[32] Their actions brought about an agreement during the stalled peace talks. As a result, the women were able to achieve peace in Liberia after a 14-year civil war and later helped bring to power the country's first female head of state, Ellen Johnson Sirleaf.\\r\\nOn March 7, 2003, the war tribunal Special Court for Sierra Leone (SCSL) decided to summon Charles Taylor and charge him with war crimes and crimes against humanity, but they kept this decision and this charge secret until June that year.[33]\\r\\nDue to concerns over the lack of social, humanitarian and development use of industry revenue by the Liberian government, the UN Security Council enacted a 10-month embargo on timber imports from Liberia on July 7, 2003 (passed in Resolution 1478). [34]\\r\\nBy mid-2003, LURD controlled the northern third of the country and was threatening the capital, MODEL was active in the south, and Taylor's government controlled only a third of the country: Monrovia and central Liberia.\\r\\nOn June 4, 2003, ECOWAS organized peace talks in Accra, Ghana, among the Government of Liberia, civil society, and the rebel groups LURD and MODEL. On the opening ceremony, in Taylors presence, the SCSL revealed their charge against Taylor which they had kept secret since March, and also issued an international arrest warrant for Taylor.[33] The SCSL indicted Taylor for bearing the greatest responsibility for atrocities in Sierra Leone since November 1996. The Ghanaian authorities did not attempt to arrest Taylor, declaring they could not round up a president they themselves had invited as a guest for peace talks.[33] The same day, Taylor returned to Liberia.\\r\\nJune 2003, LURD began a siege of Monrovia. July 9, the Nigerian President offered Taylor safe exile in his country, if Taylor stayed out of Liberian politics.[35] Also in July, American President Bush stated twice that Taylor must leave Liberia. Taylor insisted that he would resign only if American peacekeeping troops were deployed to Liberia. August 1, 2003, the Security Council, (Resolution 1497) decided on a multinational force in Liberia, to be followed-on by a United Nations stabilization force. ECOWAS sent troops under the banner of 'ECOMIL' to Liberia.[36] These troops started to arrive in Liberia probably as of August 15. The U.S. provided logistical support.[37] President Taylor resigned, and flew into exile in Nigeria. Vice-President Moses Blah replaced Taylor as interim-President. A ECOWAS-ECOMIL force of 1000 Nigerian troops was airlifted into Liberia on August 15, to halt the occupation of Monrovia by rebel forces. Meanwhile, U.S. stationed a Marine Expeditionary Unit with 2300 Marines offshore Liberia.\\r\\nOn August 18, 2003, the Liberian Government, the rebels, political parties, and leaders from civil society signed the Accra Comprehensive Peace Agreement that laid the framework for a two-year National Transitional Government of Liberia. August 21, they selected businessman Charles Gyude Bryant as Chair of the National Transitional Government of Liberia (NTGL), effective on October 14. These changes paved the way for the ECOWAS peacekeeping mission to expand into a 3,600-strong force, constituted by Benin, Gambia, Ghana, Guinea-Bissau, Mali, Nigeria, Senegal and Togo.\\r\\nOn October 1, 2003, UNMIL took over the peacekeeping duties from ECOWAS. Some 3,500 West African troops were provisionally re-hatted as United Nations peacekeepers. The UN Secretary-General commended the African Governments who have contributed to UNMIL, as well as the United States for its support to the regional force. October 14, 2003, Blah handed power to Gyude Bryant.\\r\\nFighting initially continued in parts of the country, and tensions between the factions did not immediately vanish. But fighters were being disarmed; in June 2004, a program to reintegrate the fighters into society began; the economy recovered somewhat in 2004; by year's end, the funds for the re-integration program proved inadequate; also by the end of 2004, more than 100,000 Liberian fighters had been disarmed, and the disarmament program was ended.\\r\\nIn light of the progress made, President Bryant requested an end to the UN embargo on Liberian diamonds (since March 2001) and timber (since May 2003), but the Security Council postponed such a move until the peace was more secure. Because of a supposed fundamentally broken system of governance that contributed to 23 years of conflict in Liberia, and failures of the Transitional Government in curbing corruption, the Liberian government and the International Contact Group on Liberia signed onto the anti-corruption program GEMAP, starting September 2005.\\r\\nThe transitional government prepared for fair and peaceful democratic elections on October 11, 2005, with UNMIL troops safeguarding the peace. Twenty three candidates stood for the presidential election, with George Weah, international footballer, UNICEF Goodwill Ambassador and member of the Kru ethnic group, and Ellen Johnson Sirleaf, a former World Bank economist and finance minister, Harvard-trained economist and of mixed Americo-Liberian and indigenous descent. In the first round, no candidate took the required majority, Weah won this round with 28% of the vote. A run-off between the top two vote getters, Weah and Ellen Johnson Sirleaf, was necessary.\\r\\nThe second round of elections took place on November 8, 2005. Ellen Johnson Sirleaf won this runoff decisively. Both the general election and runoff were marked by peace and order, with thousands of Liberians waiting patiently in the Liberian heat to cast their ballots. Sirleaf claimed victory of this round, winning 59 per cent of the vote. However, Weah alleged electoral fraud, despite international observers declaring the election to be free and fair. Although Weah was still threatening to take his claims to the Supreme Court if no evidence of fraud was found, Johnson-Sirleaf was declared winner on November 23, 2005, and took office on January 16, 2006; becoming the first African woman to do so.\\r\\nIn November 2005, the International Labor Rights Fund filed an Alien Tort Claims Act (ATCA) case against Bridgestone, the parent company of Firestone, alleging forced labor\\", the modern equivalent of slavery, on the Firestone Plantation in Harbel.[38] In May 2006, the United Nations Mission in Liberia (UNMIL) released a report: Human Rights in Liberias Rubber Plantations: Tapping into the Future which detailed the results of its investigation into the conditions on the Firestone plantation in Liberia.[39][citation not found]\\r\\nUnder international pressure, President Sirleaf requested in March 2006 that Nigeria extradite Charles Taylor, who was then brought before an international tribunal in Sierra Leone to face charges of crimes against humanity, arising from events during the Sierra Leone civil war (his trial was later transferred to The Hague for security purposes). In June 2006, the United Nations ended its embargo on Liberian timber (effective since May 2003), but continued its diamond embargo (effective since March 2001) until an effective certificate of origin program was established, a decision that was reaffirmed in October 2006.\\r\\nIn March 2007, former Interim President Bryant was arrested and charged with having embezzled government funds while in office. In August 2007, the Supreme Court of Liberia allowed the criminal prosecution for this to proceed in the lower courts.[40] The court ruled that Bryant was not entitled to immunity as the head of state under the Constitution as he was not elected to the position and he was not acting in accordance with law when he allegedly stole USD $1.3 million in property from the government.[40][41]\\r\\nIn 2014 an Ebola virus disease epidemic struck West Africa (see Ebola virus epidemic in West Africa), and spread to Liberia in early 2014. A few initial cases grew into an Ebola virus epidemic in Liberia.\\r\\n?This article incorporates?public domain material from the United States Department of State website https://www.state.gov/r/pa/ei/bgn/6618.htm.","input":"Why was the african country of liberia formed?"},{"output":"Albany","context":"","input":"Google what is the capital of new york?"},{"output":"March 24, 2005","context":"The first season of the American television comedy The Office premiered in the United States on NBC on March 24, 2005, concluded on April 26, 2005, and consists of six episodes.  The Office is an American adaptation of the British TV series of the same name, and is presented in a mockumentary format, portraying the daily lives of office employees in the Scranton, Pennsylvania branch of the fictitious Dunder Mifflin Paper Company.\\r\\n\\r\\nThis season introduced the main characters, and established the general plot, which revolves around Michael Scott (Steve Carell), regional manager of the Scranton branch office, trying to convince the filmmakers of the documentary that he presides over a happy, well-running office. Meanwhile, sales rep Jim Halpert (John Krasinski) finds methods to undermine his cube-mate, Dwight Schrute (Rainn Wilson); receptionist Pam Beesly (Jenna Fischer) tries to deal with Michael's insensitivities and flubs; and temporary employee Ryan Howard (B. J. Novak) is acting mostly as an observer of the insanity around him.\\r\\n\\r\\nSeason one of The Office aired on Tuesdays in the United States at 9:30?p.m. The season debuted to high numbers, and garnered moderately positive reviews from critics aside from a poorly received pilot episode. While some enjoyed the pilot, others opined that it was a mere copy of the original British version. Universal Studios Home Entertainment released season one in a single DVD on August 16, 2005. The DVD contained all six episodes, along with commentaries from creators, writers, actors, and directors on most of the episodes, as well as deleted scenes from all of the episodes.\\r\\n\\r\\nThe first season of the show was produced by Reveille Productions and Deedle-Dee Productions, both in association with NBC Universal Television Studios.  The show is based upon the British series created by Ricky Gervais and Stephen Merchant, who are executive producers on the show, and it is produced by Greg Daniels, also an executive producer, along with consulting producers Larry Wilmore[1] and Lester Lewis.[2]  The show's writers include Daniels, Gervais, Merchant, and Michael Schur,[3] while Mindy Kaling, Paul Lieberstein, and B. J. Novak double as writers as well as actors in the show, and between them, wrote three episodes on the season. For this season, Schur was a co-producer, Kaling was a staff writer, Lieberstein was a consulting producer, and Novak was an executive story editor. The first episode, \\"Pilot\\", was written by Daniels, but the majority of the episode was adapted from \\"Episode One\\" of the British series, with many scenes being transferred almost verbatim.[4]\\r\\n\\r\\nSeason one featured episodes directed by five different directors.  The Office features both a \\"team of directors\\" as well as several directors who are freelanced.  Ken Kwapis, directed the first two episodes \\"Pilot\\" and \\"Diversity Day\\", and would go on to direct another eleven episodes in total, including the final episode of the series.  Ken Whittingham, who directed \\"Health Care\\" would go on to direct another eight episodes in total.  Daniels both produced and directed the episode \\"Basketball\\".  The Office was almost entirely filmed in an actual office building in Los Angeles, California for its first season.  Aside from Los Angeles, the city of Scranton, Pennsylvania, where the show is set, was also used for shots for the opening theme.[5]\\r\\n\\r\\nMany characters portrayed by The Office cast are based on the British version of the show.  While these characters normally have the same attitude and perceptions as their British counterparts, the roles have been redesigned to better fit the American show.  The show is known for its generally large cast size, many of whom are known particularly for their improvisational work.  Steve Carell stars as Michael Scott, Regional Manager of the Dunder Mifflin Scranton Branch.[6]  Loosely based on David Brent, Gervais' character in the British version,[7] Scott is a dim-witted and lonely man, who attempts to win friends as the office comedian, usually making himself look bad in the process. Rainn Wilson portrays Dwight Schrute, who, based upon Gareth Keenan, is the Assistant to the Regional Manager, although the character frequently intentionally omits the \\"to the\\" in his title.[8] John Krasinski portrays Jim Halpert, a sales representative and prankster, who is based upon Tim Canterbury, and is in love with Pam Beesly, the receptionist.[9] Pam, who is based on Dawn Tinsley, is shy, but is often a cohort with Jim in his pranks on Dwight.[10]  B. J. Novak portrays Ryan Howard, who is a temporary worker.[11]\\r\\n\\r\\nThe show includes many supporting characters playing roles of office workers, working in various positions around the office. Angela Martin, Oscar Martinez, and Kevin Malone are the office's accountants, and are portrayed by Angela Kinsey, Oscar Nunez, and Brian Baumgartner, respectively.  Schrute, Halpert, Phyllis Lapin (portrayed by Phyllis Smith), and Stanley Hudson (portrayed by Leslie David Baker), compose the sales division of Dunder Mifflin Scranton.  Kate Flannery portrays Meredith Palmer, the promiscuous Supplier Relations Representative, writer-actress Mindy Kaling portrays Kelly Kapoor, the pop culture-obsessed Customer Service Representative, writer-actor Paul Lieberstein portrays Toby Flenderson, the sad-eyed Human Resources Representative, and Creed Bratton plays a fictionalized version of himself as the office's Quality Assurance Officer.  Other characters include Roy Anderson, Pam's fiance played by David Denman, Warehouse Supervisor Darryl Philbin, played by Craig Robinson, and Jan Levinson, Michael's main love interest, who is portrayed by Melora Hardin.[12]\\r\\n\\r\\nThe first episode of The Office scored well in ratings, gaining over eleven million viewers, as well as ranking third in its timeslot on the night of its airing.[13][14]  But the episode aired on a Thursday evening, and between the change from the first episode and the second episode, The Office moved to its regular time slot on Tuesday evenings. The Office tumbled in the ratings, averaging under 6.0 million viewers, just over half that of the previous episode.[15][16]  The first-season finale \\"Hot Girl\\" received one of the lowest rating in the show's history, earning just a 2.2 rating with a 10 share.[17] After the lackluster reception of the episode, many critics erroneously predicted that \\"Hot Girl\\" would also serve as the de facto series finale.[17] The Office averaged 5.4 million viewers for its entire season, ranking it #102 for the 2004ÿ2005 U.S. television season.[18]\\r\\n\\r\\nThe series premiere, \\"Pilot\\", received largely mixed reviews from critics.[19] After the first episodes, critics thought The Office would be another failed remake of a British comedy, much like how the American version of Coupling was in relation to the original British series.[20] The Deseret Morning News believed The Office was a failed remake, and said \\"Maybe, after The Office dies a quick death on NBC, the network will decide that trying to Americanize British TV comedies isn't such a great idea.\\"[21] The New York Daily News said the show was \\"neither daring nor funny\\", adding that \\"NBC's version is so diluted there's little left but muddy water\\".[22] The Los Angeles Times complained that Steve Carell, who portrays Scott and also appeared in the movie Anchorman: The Legend of Ron Burgundy, was \\"too cartoon\\" and said: \\"Lost in translation is the sadness behind the characters.\\"[22]\\r\\n\\r\\nDespite these criticisms, the remainder of the season earned mostly positive reviews among critics. The season scored 62 out of 100 on Metacritic (a website that assigns a weighted average score for media), which translates to \\"generally favorable reviews.\\"[23] Time magazine wrote that \\"It's ironic that NBC's most original sitcom in years is a remake, but who cares? The Office is a daring, unflinching take on very American workplace tensions.\\"[19] Boston.com felt that the first season of The Office was good, and the differences between the characters of the American and the original series added to the popularity of the series.[24] Rob Owen of the Pittsburgh Post-Gazette felt that The Office succeeded in its first season, and that although NBC had failed in the past with television shows such as Coupling, it had found achievement with The Office.[25] Entertainment Weekly awarded the season a \\"B+\\" and wrote that The Office \\"is clever and insular, capturing all the drudgery, awkwardness, and rivalry of cubicle living\\" and that the last five episodes help to illustrate that the series has \\"crossed the pond handily.\\"[26]\\r\\n\\r\\nIn addition, \\"Diversity Day,\\" the season's second episode, has been regarded as one of the best episodes of the entire show. TV Guide named it the nineteenth greatest episode of any television show in 2009.[27] Rolling Stone magazine named the scene wherein Michael shows the office his diversity video the third greatest moment from The Office.[28]\\r\\n\\r\\nIn its first year, The Office was nominated for several awards, including three Writers Guild of America Award nods. These included nominations for Best Comedy Series and Best New Series. In addition, for his work on this episode, B. J. Novak was nominated for a Writers Guild of America Award for Best Screenplay ÿ Episodic Comedy.[29]","input":"When was the first season of the office?"},{"output":"May 2007","context":"MS Liberty of the Seas is a Royal Caribbean International Freedom-class cruise ship which entered regular service in May 2007. It was initially announced that she would be called Endeavour of the Seas, however this name was later changed.[4] The 15-deck ship accommodates 3,634 passengers served by 1,360 crew. She was built in 18 months at the Aker Finnyards Turku Shipyard, Finland, where her sister ship, Freedom of the Seas, was also built. Initially built at 154,407?gross tonnage?(GT), she joined her sister ship, Freedom of the Seas, as the largest cruise ships and passenger vessels then ever built. She is 1,111.9?ft (338.91?m) long, 184?ft (56.08?m) wide, and cruises at 21.6-knot (40?km/h; 25?mph).\\r\\nLiberty of the Seas is the second of the Freedom class vessels. A third ship, Independence of the Seas, was delivered in April 2008. In 2009, the first in a new Oasis Class of ships measuring 220,000 gross tons displaced the Freedom class as the world's largest passenger ships.\\r\\n\\r\\n\\r\\nOn April 19, 2007, Liberty of the Seas was delivered to parent company Royal Caribbean Cruises Ltd.[5] On April 22, 2007 she made her first port of call Southampton, on a promotional visit.[6] She arrived at Cape Liberty Cruise Port on May 3, 2007.\\r\\nOn May 18, 2017, the ship was christened by Toronto-based travel agent Donnalea Madeley, who, along with her husband, is also the founder of the charity Hands Across the Nations.[7]\\r\\nIn January 2011, Liberty of the Seas underwent renovations to include features introduced on Oasis class ships that have proven to be popular. Features of this renovation included an outdoor video screen in the main pool area and the inclusion of the DreamWorks Experience.[8]\\r\\nLater in 2011, Liberty of the Seas completed her first transatlantic repositioning cruise, moving from Miami, Florida to being home-ported in Barcelona, Spain. She stayed in Europe for the summer and part of fall, and then returned to Miami. Until 2015, Liberty of the Seas spent summers in Europe and winters in either Port of Miami or Port Everglades in Florida. In 2015, Liberty of the Seas repositioned to Cape Liberty Cruise Port in Bayonne, NJ from May to November,[9] after which she repositioned to Galveston, Texas.[10]\\r\\nIn February 2016, Liberty of the Seas again underwent renovations, adding additional cabins atop the front of the ship, introducing new restaurants, and making enhancements to the pool deck. After the enhancements, Liberty of the Seas was 155,889?gross tonnage?(GT), making her larger than the other two Freedom-class ships, and the 6th largest cruise ship in the world, beating the Norwegian Epic by 16 GT.[11][12]\\r\\nLiberty of the Seas, like her sister ships Freedom of the Seas & Independence of the Seas, features extensive sports facilities including the FlowRider onboard wave generator for surfing, an interactive water play area for children, a full-sized volleyball / basketball court, an ice skating rink, a boxing ring, and a large fitness center. A 2016 drydock refurbishment added the \\"Perfect Storm\\" water slide complex, featuring two racing slides and a boomerang-style slide, and the \\"Splashaway Bay\\" kids-only water play area, featuring smaller waterslides.\\r\\nOther amenities include two whirlpools that are cantilevered and project out from the sides of the ship to provide unimpeded views of the sea below, Wi-Fi and cell phone connectivity throughout most of the ship, a modular conference center for business meetings, and flat screen televisions in only some of the rooms. Many of the ship's interiors were extensively decorated by muralist Clarissa Parish.[13]\\r\\nRestaurants include a three level formal dining room, Jade Cafe Asian themed casual dining, Windjammer Cafe traditional casual dining, Sorrento's Pizzeria, Promenade Cafe, Ben & Jerry's Ice cream shop, Johnny Rockets diner, Chops Steakhouse, and Portofino Italian restaurant.[14] The 2016 refurbishment changed the \\"Portofino\\" Italian restaurant to \\"Giovannis Table\\", and added the \\"Sabor\\" Mexican restaurant in the space formerly occupied by the ship's nightclub.\\r\\nNew additions made during the 2011 refurbishment include 3D Movies, passenger service kiosks, the DreamWorks experience, Cupcake Cupboard, Royal Babies, Tot's Nursery, and the addition of Broadway show \\"Saturday Night Fever: The Musical\\". The Cupcake Cupboard took the place of the barber shop on the Royal Promenade, relocating the barber shop to the Vitality Spa.[15]\\r\\nThe DreamWorks Experience began on Liberty of the Seas January 30, 2011. The DreamWorks Experience includes a variety DreamWorks characters and stories into the cruise experience. Such features of the DreamWorks Experience include character meet and greets, character parades, table-side visits from characters during meals, DreamWorks movies on stateroom televisions, and 3D DreamWorks movies on board.[16]\\r\\nFeatures of the DreamWorks Experience specific to Liberty of the Seas are character meals, DreamWorks characters parade, photo opportunities with the characters, 3D movie theater, first-run DreamWorks films on board, special DreamWorks programming available on stateroom televisions, Adventure Ocean activities with characters.[8]\\r\\nThe DreamWorks Experience was first introduced on the Oasis class ship, Allure of the Seas,[15] on December 12, 2010, and later on the Oasis class ship Oasis of the Seas on February 26, 2011 and Freedom of the Seas on March 27, 2011.[8]\\r\\nLiberty Of The Seas docked in San Juan, Puerto Rico.\\r\\nLiberty of the Seas docked in Cozumel, Mexico.\\r\\nLiberty of the Seas moored in Labadee, Haiti.\\r\\nLiberty of the Seas docked in the Port of Miami.\\r\\nLiberty of the Seas docked in Labadee, Haiti, One of Royal Caribbean's private islands.","input":"When was royal caribbean liberty of the seas built?"},{"output":"around three million years (Ma) ago during the Piacenzian age","context":"The Great American Interchange was an important late Cenozoic paleozoogeographic event in which land and freshwater fauna migrated from North America via Central America to South America and vice versa, as the volcanic Isthmus of Panama rose up from the sea floor and bridged the formerly separated continents. The migration peaked dramatically around three million years (Ma) ago during the Piacenzian age. It resulted in the joining of the Neotropic (roughly South America) and Nearctic (roughly North America) ecozones definitively to form the Americas. The interchange is visible from observation of both biostratigraphy and nature (neontology). Its most dramatic effect is on the zoogeography of mammals but it also gave an opportunity for reptiles, amphibians, arthropods, weak-flying or flightless birds, and even freshwater fish to migrate.\\r\\nThe occurrence of the interchange was first discussed in 1876 by the \\"father of biogeography\\", Alfred Russel Wallace.[1][2] Wallace had spent 1848ÿ1852 exploring and collecting specimens in the Amazon basin. Others who made significant contributions to understanding the event in the century that followed include Florentino Ameghino, W. D. Matthew, W. B. Scott, Bryan Patterson, George Gaylord Simpson and S. David Webb.[3] The Pliocene timing of the formation of the connection between North and South America was discussed in 1910 by Henry Fairfield Osborn.[4]\\r\\nAnalogous interchanges occurred earlier in the Cenozoic, when the formerly isolated land masses of India[5] and Africa[6] made contact with Eurasia c. 50 and 30 Ma ago, respectively.\\r\\n\\r\\n\\r\\nAfter the late Mesozoic breakup of Gondwana, South America spent most of the Cenozoic era as an island continent whose \\"splendid isolation\\" allowed its fauna to evolve into many forms found nowhere else on Earth, most of which are now extinct.[7] Its endemic mammals initially consisted primarily of metatherians (marsupials and sparassodonts), xenarthrans, and a diverse group of native ungulates: notoungulates (the \\"southern ungulates\\"), litopterns, astrapotheres, pyrotheres and xenungulates.[n 1] [n 2] A few non-therian mammals ÿ monotremes, gondwanatheres, dryolestids and possibly cimolodont multituberculates ÿ were also present in the Paleocene; while none of these diversified significantly and most lineages did not survive long, forms like Necrolestes and Patagonia remained as recently as the Miocene.[14]\\r\\nMarsupials appear to have traveled via Gondwanan land connections from South America through Antarctica to Australia in the late Cretaceous or early Tertiary.[15][n 3] One living South American marsupial, the monito del monte, has been shown to be more closely related to Australian marsupials than to other South American marsupials; however, it is the most basal australidelphian,[n 4] meaning that this superorder arose in South America and then colonized Australia after the monito del monte split off.[15] A 61-Ma-old platypus-like monotreme fossil from Patagonia may represent an Australian immigrant. Paleognath birds (ratites and South American tinamous) may have migrated by this route around the same time, more likely in the direction from South America to Australia/New Zealand.[16] Other taxa that may have dispersed by the same route (if not by flying or floating across the ocean) are parrots, chelid turtles and (extinct) meiolaniid turtles.\\r\\nMarsupials present in South America included didelphimorphs (opossums) and several other small groups; larger predatory relatives of these also existed, like the borhyaenids and the sabertooth Thylacosmilus (sparassodont metatherians which are no longer considered to be true marsupials).[17] After the extinction of sparassodonts, and before the arrival of carnivorans, giant opossums like Thylophorops represented true marsupial macropredators.\\r\\nMetatherians (and a few xenarthran armadillos like Macroeuphractus) were the only South American mammals to specialize as carnivores; their relative inefficiency created openings for nonmammalian predators to play more prominent roles than usual (similar to the situation in Australia). Sparassodonts and giant opossums shared the ecological niches for large predators with fearsome flightless \\"terror birds\\" (phorusrhacids), whose closest extant relatives are the seriemas.[18][19] (Similar large terrestrial predatory birds, the bathornithids, were found in North America during the early Cenozoic, but they died out in the Early Miocene, about 20 million years ago.) Through the skies over late Miocene South America (6 Ma ago) soared the largest flying bird known, the teratorn Argentavis, with a wing span of 6 m or more, which may have subsisted in part on the leftovers of Thylacosmilus kills.[20] Terrestrial ziphodont[n 5] sebecid crocodilians were also present at least through the middle Miocene[21][22][23][24] and maybe to the Miocene-Pliocene boundary.[25] Some of South America's aquatic crocodilians, such as Gryposuchus, Mourasuchus and Purussaurus, reached monstrous sizes, with lengths up to 12 m (comparable to the largest Mesozoic crocodyliforms). They shared their habitat with one of the largest turtles of all time, the 3.3?m (11?ft) Stupendemys.\\r\\nXenarthrans are a curious group of mammals that developed morphological adaptations for specialized diets very early in their history.[26] In addition to those extant today (armadillos, anteaters and tree sloths), a great diversity of larger types were present, including pampatheres, the ankylosaur-like glyptodonts, predatory euphractines, various ground sloths, some of which reached the size of elephants (e.g. Megatherium), and even semiaquatic to aquatic marine sloths.[27][28]\\r\\nThe notoungulates and litopterns had many strange forms, like Macrauchenia, a camel-like litoptern with a small proboscis. They also produced a number of familiar-looking body types that represent examples of parallel or convergent evolution: one-toed Thoatherium had legs like those of a horse, Pachyrukhos resembled a rabbit, Homalodotherium was a semi-bipedal clawed browser like a chalicothere, and horned Trigodon looked like a rhino. Both groups started evolving in the Lower Paleocene, possibly from condylarth stock, diversified, dwindled before the great interchange, and went extinct at the end of the Pleistocene. The pyrotheres and astrapotheres were also strange but were less diverse and disappeared earlier, well before the interchange.\\r\\nThe North American fauna was a typical boreoeutherian one (supplemented with Afrotherian proboscids).\\r\\nThe invasions of South America started about 40 Ma ago (middle Eocene), when caviomorph rodents arrived in South America.[29][30][31] Their subsequent vigorous diversification displaced some of South America's small marsupials and gave rise to ÿ among others ÿ capybaras, chinchillas, viscachas, and New World porcupines. (The independent development of spines by New and Old World porcupines is another example of parallel evolution.) This invasion most likely came from Africa.[32][33] The crossing from West Africa to the northeast corner of Brazil was much shorter then, due to continental drift, and may have been aided by island hopping (e.g. via St. Paul's Rocks, if they were an inhabitable island at the time) and westward oceanic currents.[34] Crossings of the ocean were accomplished when at least one fertilised female (more commonly a group of animals) accidentally floated over on driftwood or mangrove rafts. (Island-hopping caviomorphs would subsequently colonize the West Indies as far as the Bahamas,[35][36] reaching the Greater Antilles by the early Oligocene.[37]) Over time, some caviomorph rodents evolved into larger forms that competed with some of the native South American ungulates, which may have contributed to the gradual loss of diversity suffered by the latter after the early Oligocene.[7] By the Pliocene, some caviomorphs (e.g., Josephoartigasia) attained sizes on the order of 500?kg (1,100?lb) or larger.[38]\\r\\nLater (by 36 Ma ago)[39] primates followed, again from Africa in a fashion similar to that of the rodents.[29] Primates capable of migrating had to be small. Like caviomorph rodents, South American monkeys are believed to be a clade (i.e., monophyletic). However, although they would have had little effective competition, all extant New World monkeys appear to derive from a radiation that occurred long afterwards, in the Early Miocene about 18 Ma ago.[29] Subsequent to this, monkeys apparently most closely related to titis island-hopped to Cuba, Hispaniola and Jamaica. Additionally, a find of seven 21-Ma-old apparent cebid teeth in Panama suggests that South American monkeys had dispersed across the seaway separating Central and South America by that early date. However, all extant Central American monkeys are believed to be descended from much later migrants, and there is as yet no evidence that these early Central American cebids established an extensive or long-lasting population, perhaps due to a shortage of suitable rainforest habitat at the time.[40][41]\\r\\nRemarkably, the descendents of those few bedraggled waifs that crawled ashore from their rafts of African flotsam in the Eocene now constitute more than twice as many of South America's species as the descendents of all the nonflying mammals previously resident on the continent (372 caviomorph and monkey species versus 136 marsupial and xenarthran species).[n 6]\\r\\nMany of South America's bats may have arrived from Africa during roughly the same period, possibly with the aid of intervening islands, although by flying rather than floating. Noctilionoid bats ancestral to those in the neotropical families Furipteridae, Mormoopidae, Noctilionidae, Phyllostomidae, and Thyropteridae are thought to have reached South America from Africa in the Eocene,[43] possibly via Antarctica.[44] Similarly, molossid bats may have reached South America from Africa in as many as five dispersals, starting in the Eocene.[43] Emballonurid bats may have also reached South America from Africa about 30 Ma ago, based on molecular evidence.[43][45] Vespertilionid bats may have arrived in five dispersals from North America and one from Africa.[43] Natalid bats are thought to have arrived during the Pliocene from North America via the Caribbean.[43]\\r\\nTortoises also arrived in South America in the Oligocene. It was long thought that they had come from North America, but a recent comparative genetic analysis concludes that the South American genus Chelonoidis (formerly part of Geochelone) is actually most closely related to African hingeback tortoises.[n 7][46] Tortoises are aided in oceanic dispersal by their ability to float with their heads up, and to survive up to six months without food or water.[46] South American tortoises then went on to colonize the West Indies[47] and Galpagos Islands. A number of clades of American geckos seem to have rafted over from Africa during both the Paleogene and Neogene.[48] Skinks of the related genera Mabuya and Trachylepis apparently dispersed across the Atlantic from Africa to South America and Fernando de Noronha, respectively, during the last 9 Ma.[49] Surprisingly, South America's burrowing amphisbaenians[50] and blind snakes[51] also appear to have rafted from Africa, as does the hoatzin, a weak-flying bird of South American rainforests.[52]\\r\\nThe earliest traditionally recognized mammalian arrival from North America was a procyonid that island-hopped from Central America before the isthmus of Panama land bridge formed, around 7.3 Ma ago.[53] This was South America's first eutherian carnivore. South American procyonids then diversified into forms now extinct (e.g. the \\"dog-coati\\" Cyonasua, which evolved into the bear-like Chapalmalania). However, all extant procyonid genera appear to have originated in North America.[54] It has been suggested that the first South American procyonids may have contributed to the extinction of sebecid crocodilians by eating their eggs, but this view has not been universally viewed as plausible.[n 8][24] The procyonids were followed to South America by rafting/island-hopping hog-nosed skunks[55] and sigmodontine rodents[56][57][58][59] The oryzomyine tribe of sigmodontine rodents went on to colonize the Lesser Antilles up to Anguilla.\\r\\nOne group has proposed that a number of large Neartic herbivores actually reached South America as early as 9ÿ10 Ma ago, in the late Miocene, via the \\"Baudo pathway\\", an early land bridge that was probably incomplete and required some swimming and island-hopping to traverse. The limited evidence for these early immigrants may reflect their presence primarily in the Amazon basin, an area where fewer fossils have been collected. These taxa are: a proboscidean (Amahuacatherium),[60][61][n 9] peccaries (Sylvochoerus and Waldochoerus),[63] tapirs and a palaeomerycid (from a family probably ancestral to cervids), Surameryx; the paleomerycids were probably unable to successfully colonize South America.[64]\\r\\nSimilarly, megalonychid and mylodontid ground sloths island-hopped to North America by 9 Ma ago.[56] Megalonychids had colonized the Antilles previously, by the early Miocene.[65] (Megatheriid and nothrotheriid ground sloths did not migrate north until the formation of the isthmus.) Terror birds may have also island-hopped to North America as early as 5 Ma ago.[66]\\r\\nThe Caribbean islands were populated primarily by species from South America. This was due to the prevailing direction of oceanic currents, rather than to a competition between North and South American forms.[35][36] (Except in the case of Jamaica, oryzomyine rodents of North American origin were able to enter the region only after invading South America.)\\r\\nThe formation of the Isthmus of Panama led to the last and most conspicuous wave, the great interchange, around 3?Ma ago. This included the immigration into South America of North American ungulates (including camelids, tapirs, deer and horses), proboscids (gomphotheres), carnivorans (including felids like cougars and saber-toothed cats, canids, mustelids, procyonids and bears) and a number of types of rodents[n 10]. The larger members of the reverse migration, besides ground sloths and terror birds, were glyptodonts, pampatheres, capybaras and the notoungulate Mixotoxodon (the only South American ungulate known to have invaded Central America).\\r\\nIn general, the initial net migration was symmetrical. Later on, however, the Neotropic species proved far less successful than the Nearctic. This misfortune happened both ways. Northwardly migrating animals often were not able to compete for resources as well as the North American species already occupying the same ecological niches; those that did become established were not able to diversify much.[67] Southwardly migrating Nearctic species established themselves in larger numbers and diversified considerably more,[67] and are thought to have caused the extinction of a large proportion of the South American fauna. (There were no extinctions in North America plainly linked to South American immigrants.) Although terror birds were able to invade part of North America, their success was temporary; this lineage disappeared about two million years ago. The large Neotropic metatherian predators fared no better. Native South American ungulates also did poorly, with only a handful of genera withstanding the northern onslaught. (It has long been recognized that several of the largest forms, macraucheniids and toxodontids, survived to the end of the Pleistocene. Recent fossil finds indicate that one species of the horse-like proterotheriid litopterns did as well.[68] The notoungulate mesotheriids and hegetotheriids also managed to hold on at least part way through the Pleistocene.)[A] On the other hand, South America's small marsupials survived in large numbers, while the primitive-looking xenarthrans proved to be surprisingly competitive and became the most successful invaders of North America. The African immigrants, the caviomorph rodents and platyrrhine monkeys, were less impacted by the interchange than most of South America's 'old-timers', although the caviomorphs suffered a significant loss of diversity,[n 11][n 12] including the elimination of the largest forms (e.g. the dinomyids). With the exception of the North American porcupine and several extinct porcupines and capybaras, however, they did not migrate past Central America.[n 13]\\r\\nThe initial wave of southwardly migrating Nearctic carnivorans rapidly occupied the South American predatory niches, displacing phorusrhacids and sparassodonts,[n 14] as well as eliminating Chapalmalania. It has been argued that canids probably played the major role in the borhyaenids' extinction; they are ecologically and morphologically more similar to them than other carnivorans, and are also the most diverse family of modern carnivorans on the continent.[71] The paucity of early competition and plentiful prey seems to have allowed short-faced bears to rapidly evolve into the largest known bear or terrestrial mammalian carnivore species; Arctotherium angustidens is estimated to have weighed around 1600?kg. Later species of Arctotherium exhibited a trend towards smaller size and a more omnivorous diet, probably due to increasing competition from later-arriving or evolving carnivores.[72][73] In contrast, Smilodon showed a trend toward increasing body size that culminated in the appearance of S. populator, at up to nearly 500?kg the most massive felid known.\\r\\nDue in large part to the success of the xenarthrans, one area of South American ecospace the Nearctic invaders were unable to dominate was the niches for megaherbivores.[74] Before 12,000 years ago, South America was home to about 25 species of herbivores weighing more than 1000?kg, consisting of Neotropic ground sloths, glyptodonts and toxodontids, as well as gomphotheres and camelids of Nearctic origin.[n 15] Native South American forms made up about 75% of these species. However, none of these megaherbivores have survived.\\r\\nArmadillos, opossums and porcupines are present in North America today because of the Great American Interchange. Opossums and porcupines were among most successful northward migrants, reaching as far as Canada and Alaska, respectively. Most major groups of xenarthrans were present in North America up until the end-Pleistocene Quaternary extinction event (as a result of at least eight successful invasions of temperate North America, and at least six more invasions of Central America only). Among the megafauna, ground sloths were notably successful emigrants; Megalonyx spread as far north as the Yukon[76] and Alaska,[77] and might well have eventually reached Eurasia if the extinction event had not intervened.\\r\\nGenerally speaking, however, the dispersal and subsequent explosive adaptive radiation of sigmodontine rodents throughout South America (leading to over 80 currently recognized genera) was vastly more successful (both spatially and by number of species) than any northward migration of South American mammals. Other examples of North American mammal groups that diversified conspicuously in South America include canids and cervids, both of which currently have 3 or 4 genera in North America, 2 or 3 in Central America, and 6 in South America.[n 16][n 17] Although members of Canis (specifically, coyotes) currently range only as far south as Panama,[n 18] South America still has more extant genera of canids than any other continent.[n 16]\\r\\nThe effect of formation of the isthmus on the marine biota of the area was the inverse of its effect on terrestrial organisms, a development that has been termed the \\"Great American Schism\\". The connection between the east Pacific Ocean and the Caribbean (the Central American Seaway) was severed, setting now-separated populations on divergent evolutionary paths.[81] Caribbean species also had to adapt to an environment of lower productivity after the inflow of nutrient-rich water of deep Pacific origin was blocked.[82]\\r\\nThe eventual triumph of the Nearctic migrants was ultimately based on geography, which played into the hands of the northern invaders in two crucial respects. The first was a matter of climate. Any species that reached Panama from either direction obviously had to be able to tolerate moist tropical conditions. Those migrating southward would then be able to occupy much of South America without encountering climates that were markedly different. However, northward migrants would have encountered drier and/or cooler conditions by the time they reached the vicinity of the Trans-Mexican Volcanic Belt. The challenge this climatic asymmetry (see map on right) presented was particularly acute for Neotropic species specialized for tropical rainforest environments, who had little prospect of penetrating beyond Central America. As a result, Central America currently has 41 mammal species of Neotropical origin,[n 19] compared to only 3 for temperate North America. However, species of South American origin (marsupials, xenarthrans, caviomorph rodents and monkeys) still comprise only 21% of species from nonflying, nonmarine mammal groups in Central America, while North American invaders constitute 49% of species from such groups in South America. Thus, climate alone cannot fully account for the greater success of species of Nearctic origin during the interchange.\\r\\nThe second and more important advantage geography gave to the northerners is related to the land area available for their ancestors to evolve in. During the Cenozoic, North America was periodically connected to Eurasia via Beringia, allowing multiple migrations back and forth to unite the faunas of the two continents.[n 20] Eurasia was connected in turn to Africa, which contributed further to the species that made their way to North America.[n 21] South America, on the other hand, was connected only to Antarctica and Australia, two much smaller and less hospitable continents, and only in the early Cenozoic. Moreover, this land connection does not seem to have carried much traffic (apparently no mammals other than marsupials and perhaps a few monotremes ever migrated by this route), particularly in the direction of South America. This means that Northern Hemisphere species arose over a land area roughly six times greater than was available to South American species. North American species were thus products of a larger and more competitive arena,[n 22][67][83][84] where evolution would have proceeded more rapidly. They tended to be more efficient and brainier,[n 23][n 24] generally able to outrun and outwit their South American counterparts, who were products of an evolutionary backwater. These advantages can be clearly seen in the cases of ungulates and their predators, where South American forms were replaced wholesale by the invaders.\\r\\nThe greater eventual success of South America's African immigrants compared to its native early Cenozoic mammal fauna is another example of this phenomenon, since the former evolved over a greater land area; their ancestors migrated from Eurasia to Africa, two significantly larger continents, before finding their way to South America.[42]\\r\\nAgainst this backdrop, the ability of South America's xenarthrans to compete effectively against the northerners represents a special case. The explanation for the xenarthrans' success lies in part in their idiosyncratic approach to defending against predation, based on possession of body armor and/or formidable claws. The xenarthrans did not need to be fleet-footed or quick-witted to survive. Such a strategy may have been forced on them by their low metabolic rate (the lowest among the therians).[92][93] Their low metabolic rate may in turn have been advantageous in allowing them to subsist on less abundant[94] and/or less nutritious food sources. Unfortunately, the defensive adaptations of the large xenarthrans would have offered little protection against humans armed with spears and other projectiles.\\r\\nAt the end of the Pleistocene epoch, about 12,000 years ago, three dramatic developments occurred in the Americas at roughly the same time (geologically speaking). Paleoindians invaded and occupied the New World, the last glacial period came to an end, and a large fraction of the megafauna of both North and South America went extinct. This wave of extinctions swept off the face of the Earth many of the successful participants of the Great American Interchange, as well as other species that had not migrated. All the pampatheres, glyptodonts, ground sloths, equids, proboscids,[95][96][97] giant short-faced bears, dire wolves and machairodont species of both continents disappeared. The last of the South and Central American notoungulates and litopterns died out, as well as North America's giant beavers, lions, dholes, cheetahs, and many of its antilocaprid, bovid, cervid, tapirid and tayassuid ungulates. Some groups disappeared over most or all of their original range but survived in their adopted homes, e.g. South American tapirs, camelids and tremarctine bears (cougars and jaguars may have been temporarily reduced to South American refugia also). Others, such as capybaras, survived in their original range but died out in areas they had migrated to. Notably, this extinction pulse eliminated all Neotropic migrants to North America larger than about 15?kg (the size of a big porcupine), and all native South American mammals larger than about 65?kg (the size of a big capybara or giant anteater). In contrast, the largest surviving native North American mammal, the wood bison, can exceed 900?kg, and the largest surviving Nearctic migrant to South America, Baird's tapir, can reach 400?kg.\\r\\nThe near-simultaneity of the megafaunal extinctions with the glacial retreat and the peopling of the Americas has led to proposals that both climate change and human hunting played a role.[74] Although the subject is contentious,[98][99][100][101][102] a number of considerations suggest that human activities were pivotal.[75][103] The extinctions did not occur selectively in the climatic zones that would have been most affected by the warming trend, and there is no plausible general climate-based megafauna-killing mechanism that could explain the continent-wide extinctions. The climate change took place worldwide, but had little effect on the megafauna in areas like Africa and southern Asia, where megafaunal species had coevolved with humans. Numerous very similar glacial retreats had occurred previously within the ice age of the last several Ma without ever producing comparable waves of extinction in the Americas or anywhere else. Similar megafaunal extinctions have occurred on other recently populated land masses (e.g. Australia,[104][105] Japan,[106] Madagascar,[107] New Zealand,[108] and many smaller islands around the world, such as Cyprus,[109] Crete, Tilos and New Caledonia[110]) at different times that correspond closely to the first arrival of humans at each location. These extinction pulses invariably swept rapidly over the full extent of a contiguous land mass, regardless of whether it was an island or a hemisphere-spanning set of connected continents. This was true despite the fact that all the larger land masses involved (as well as many of the smaller ones) contained multiple climatic zones that would have been affected differently by any climate changes ongoing at the time. However, on sizable islands far enough offshore from newly occupied territory to escape immediate human colonization, megafaunal species sometimes survived for many thousands of years after they or related species became extinct on the mainland; examples include giant kangaroos in Tasmania,[111][112] giant Chelonoidis tortoises of the Galpagos Islands (formerly also of South America[74]), giant Dipsochelys tortoises of the Seychelles (formerly also of Madagascar), giant meiolaniid turtles on Lord Howe Island, New Caledonia and Vanuatu (previously also of Australia),[113][n 25] ground sloths on the Antilles,[116][117] Steller's sea cows off the Commander Islands[118] and woolly mammoths on Wrangel Island[119] and Saint Paul Island.[120] The glacial retreat may have played a primarily indirect role in the extinctions in the Americas by simply facilitating the movement of humans southeastward from Beringia down to North America. The reason that a number of groups went extinct in North America but lived on in South America (while there are no examples of the opposite pattern) appears to be that the dense rainforest of the Amazon basin and the high peaks of the Andes provided environments that afforded a degree of protection from human predation.[121][n 26][n 27]\\r\\nExtant or extinct (?) North American taxa whose ancestors migrated out of South America:[n 28]\\r\\nGray tree frog, Hyla versicolor\\r\\nNine-banded armadillo, Dasypus novemcinctus\\r\\nThe pampathere ?Holmesina septentrionalis\\r\\nThe glyptodont ?Glyptotherium\\r\\nThe megatheriid ground sloth ?Eremotherium\\r\\nThe toxodontid ?Mixotoxodon\\r\\nExtant or extinct (?) Central American taxa[n 31] whose ancestors migrated out of South America:[n 28]\\r\\nStrawberry poison-dart frog, Oophaga pumilio\\r\\nSpectacled caiman, Caiman crocodilus\\r\\nThe two-toed sloth Choloepus hoffmanni\\r\\nCentral American agouti, Dasyprocta punctata\\r\\nWhite-headed capuchin, Cebus capucinus\\r\\nGreat tinamou, Tinamus major\\r\\nExtant or extinct (?) South American taxa whose ancestors migrated out of North America (considered as including Central America):[n 28]\\r\\nFer-de-lance, Bothrops asper\\r\\nDrymoreomys albimaculatus, a sigmodontine rodent\\r\\nThe camelid Lama guanicoe\\r\\n?Cuvieronius, a gomphothere\\r\\nThe coati Nasua nasua\\r\\nSaber-toothed ?Smilodon populator","input":"When did south america and north america join?"},{"output":"a mixture of elements, a surrounding layer of liquid metallic hydrogen with some helium, and an outer layer predominantly of molecular hydrogen","context":"by volume:\\r\\nIces:\\r\\nJupiter is the fifth planet from the Sun and the largest in the Solar System. It is a giant planet with a mass one-thousandth that of the Sun, but two and a half times that of all the other planets in the Solar System combined. Jupiter and Saturn are gas giants; the other two giant planets, Uranus and Neptune are ice giants. Jupiter has been known to astronomers since antiquity.[11] The Romans named it after their god Jupiter.[12] When viewed from Earth, Jupiter can reach an apparent magnitude of ?2.94, bright enough for its reflected light to cast shadows,[13] and making it on average the third-brightest object in the night sky after the Moon and Venus.\\r\\nJupiter is primarily composed of hydrogen with a quarter of its mass being helium, though helium comprises only about a tenth of the number of molecules. It may also have a rocky core of heavier elements,[14] but like the other giant planets, Jupiter lacks a well-defined solid surface. Because of its rapid rotation, the planet's shape is that of an oblate spheroid (it has a slight but noticeable bulge around the equator). The outer atmosphere is visibly segregated into several bands at different latitudes, resulting in turbulence and storms along their interacting boundaries. A prominent result is the Great Red Spot, a giant storm that is known to have existed since at least the 17th century when it was first seen by telescope. Surrounding Jupiter is a faint planetary ring system and a powerful magnetosphere. Jupiter has at least 69 moons,[15] including the four large Galilean moons discovered by Galileo Galilei in 1610. Ganymede, the largest of these, has a diameter greater than that of the planet Mercury.\\r\\nJupiter has been explored on several occasions by robotic spacecraft, most notably during the early Pioneer and Voyager flyby missions and later by the Galileo orbiter. In late February 2007, Jupiter was visited by the New Horizons probe, which used Jupiter's gravity to increase its speed and bend its trajectory en route to Pluto. The latest probe to visit the planet is Juno, which entered into orbit around Jupiter on July 4, 2016.[16][17] Future targets for exploration in the Jupiter system include the probable ice-covered liquid ocean of its moon Europa.\\r\\n\\r\\n\\r\\nEarth and its neighbor planets may have formed from fragments of planets after collisions with Jupiter destroyed those super-Earths near the Sun. As Jupiter came toward the inner Solar System, in what theorists call the Grand Tack Hypothesis, gravitational tugs and pulls occurred causing a series of collisions between the super-Earths as their orbits began to overlap.[18]\\r\\nAstronomers have discovered nearly 500 planetary systems with multiple planets. Regularly these systems include a few planets with masses several times greater than Earth's (super-Earths), orbiting closer to their star than Mercury is to the Sun, and sometimes also Jupiter-mass gas giants close to their star.\\r\\nJupiter moving out of the inner Solar System would have allowed the formation of inner planets, including Earth.[19]\\r\\nJupiter is composed primarily of gaseous and liquid matter. It is the largest of the four giant planets in the Solar System and hence its largest planet. It has a diameter of 142,984?km (88,846?mi) at its equator. The average density of Jupiter, 1.326?g/cm3, is the second highest of the giant planets, but lower than those of the four terrestrial planets.\\r\\nJupiter's upper atmosphere is about 88ÿ92% hydrogen and 8ÿ12% helium by percent volume of gas molecules. A helium atom has about four times as much mass as a hydrogen atom, so the composition changes when described as the proportion of mass contributed by different atoms. Thus, Jupiter's atmosphere is approximately 75% hydrogen and 24% helium by mass, with the remaining one percent of the mass consisting of other elements. The atmosphere contains trace amounts of methane, water vapor, ammonia, and silicon-based compounds. There are also traces of carbon, ethane, hydrogen sulfide, neon, oxygen, phosphine, and sulfur. The outermost layer of the atmosphere contains crystals of frozen ammonia. The interior contains denser materials - by mass it is roughly 71% hydrogen, 24% helium, and 5% other elements.[20][21] Through infrared and ultraviolet measurements, trace amounts of benzene and other hydrocarbons have also been found.[22]\\r\\nThe atmospheric proportions of hydrogen and helium are close to the theoretical composition of the primordial solar nebula. Neon in the upper atmosphere only consists of 20 parts per million by mass, which is about a tenth as abundant as in the Sun.[23] Helium is also depleted to about 80% of the Sun's helium composition. This depletion is a result of precipitation of these elements into the interior of the planet.[24]\\r\\nBased on spectroscopy, Saturn is thought to be similar in composition to Jupiter, but the other giant planets Uranus and Neptune have relatively less hydrogen and helium and relatively more ices and are thus now termed ice giants.[25]\\r\\nJupiter's mass is 2.5 times that of all the other planets in the Solar System combinedthis is so massive that its barycenter with the Sun lies above the Sun's surface at 1.068?solar radii from the Sun's center.[26] Jupiter is much larger than Earth and considerably less dense: its volume is that of about 1,321 Earths, but it is only 318 times as massive.[5][27] Jupiter's radius is about 1/10 the radius of the Sun,[28] and its mass is 0.001 times the mass of the Sun, so the densities of the two bodies are similar.[29] A \\"Jupiter mass\\" (MJ or MJup) is often used as a unit to describe masses of other objects, particularly extrasolar planets and brown dwarfs. So, for example, the extrasolar planet HD 209458 b has a mass of 0.69?MJ, while Kappa Andromedae b has a mass of 12.8?MJ.[30]\\r\\nTheoretical models indicate that if Jupiter had much more mass than it does at present, it would shrink.[31] For small changes in mass, the radius would not change appreciably, and above about 500?M? (1.6 Jupiter masses)[31] the interior would become so much more compressed under the increased pressure that its volume would decrease despite the increasing amount of matter. As a result, Jupiter is thought to have about as large a diameter as a planet of its composition and evolutionary history can achieve.[32] The process of further shrinkage with increasing mass would continue until appreciable stellar ignition was achieved, as in high-mass brown dwarfs having around 50 Jupiter masses.[33]\\r\\nAlthough Jupiter would need to be about 75 times as massive to fuse hydrogen and become a star, the smallest red dwarf is only about 30 percent larger in radius than Jupiter.[34][35] Despite this, Jupiter still radiates more heat than it receives from the Sun; the amount of heat produced inside it is similar to the total solar radiation it receives.[36] This additional heat is generated by the KelvinÿHelmholtz mechanism through contraction. This process causes Jupiter to shrink by about 2?cm each year.[37] When it was first formed, Jupiter was much hotter and was about twice its current diameter.[38]\\r\\nJupiter is thought to consist of a dense core with a mixture of elements, a surrounding layer of liquid metallic hydrogen with some helium, and an outer layer predominantly of molecular hydrogen.[37] Beyond this basic outline, there is still considerable uncertainty. The core is often described as rocky, but its detailed composition is unknown, as are the properties of materials at the temperatures and pressures of those depths (see below). In 1997, the existence of the core was suggested by gravitational measurements,[37] indicating a mass of from 12 to 45 times that of Earth, or roughly 4%ÿ14% of the total mass of Jupiter.[36][39] The presence of a core during at least part of Jupiter's history is suggested by models of planetary formation that require the formation of a rocky or icy core massive enough to collect its bulk of hydrogen and helium from the protosolar nebula. Assuming it did exist, it may have shrunk as convection currents of hot liquid metallic hydrogen mixed with the molten core and carried its contents to higher levels in the planetary interior. A core may now be entirely absent, as gravitational measurements are not yet precise enough to rule that possibility out entirely.[37][40]\\r\\nThe uncertainty of the models is tied to the error margin in hitherto measured parameters: one of the rotational coefficients (J6) used to describe the planet's gravitational moment, Jupiter's equatorial radius, and its temperature at 1 bar pressure. The Juno mission, which arrived in July 2016,[16] is expected to further constrain the values of these parameters for better models of the core.[41]\\r\\nThe core region may be surrounded by dense metallic hydrogen, which extends outward to about 78% of the radius of the planet.[36] Rain-like droplets of helium and neon precipitate downward through this layer, depleting the abundance of these elements in the upper atmosphere.[24][42] Rainfalls of diamonds have been suggested to occur on Jupiter, as well as on Saturn[43] and ice giants Uranus and Neptune.[44]\\r\\nAbove the layer of metallic hydrogen lies a transparent interior atmosphere of hydrogen. At this depth, the pressure and temperature are above hydrogen's critical pressure of 1.2858 MPa and critical temperature of only 32.938?K.[45] In this state, there are no distinct liquid and gas phaseshydrogen is said to be in a supercritical fluid state. It is convenient to treat hydrogen as gas in the upper layer extending downward from the cloud layer to a depth of about 1,000?km,[36] and as liquid in deeper layers. Physically, there is no clear boundarythe gas smoothly becomes hotter and denser as one descends.[46][47]\\r\\nThe temperature and pressure inside Jupiter increase steadily toward the core, due to the KelvinÿHelmholtz mechanism. At the pressure level of 10?bars (1 MPa), the temperature is around 340?K (67?C; 152?F). At the phase transition region where hydrogenheated beyond its critical pointbecomes metallic, it is calculated the temperature is 10,000?K (9,700?C; 17,500?F) and the pressure is 200?GPa. The temperature at the core boundary is estimated to be 36,000?K (35,700?C; 64,300?F) and the interior pressure is roughly 3,000ÿ4,500?GPa.[36]\\r\\nJupiter has the largest planetary atmosphere in the Solar System, spanning over 5,000?km (3,000?mi) in altitude.[48][49] Because Jupiter has no surface, the base of its atmosphere is usually considered to be the point at which atmospheric pressure is equal to 100?kPa (1.0?bar).\\r\\nJupiter is perpetually covered with clouds composed of ammonia crystals and possibly ammonium hydrosulfide. The clouds are located in the tropopause and are arranged into bands of different latitudes, known as tropical regions. These are sub-divided into lighter-hued zones and darker belts. The interactions of these conflicting circulation patterns cause storms and turbulence. Wind speeds of 100?m/s (360?km/h) are common in zonal jets.[50] The zones have been observed to vary in width, color and intensity from year to year, but they have remained sufficiently stable for scientists to give them identifying designations.[27]\\r\\nThe cloud layer is only about 50?km (31?mi) deep, and consists of at least two decks of clouds: a thick lower deck and a thin clearer region. There may also be a thin layer of water clouds underlying the ammonia layer. Supporting the idea of water clouds are the flashes of lightning detected in the atmosphere of Jupiter. These electrical discharges can be up to a thousand times as powerful as lightning on Earth.[51] The water clouds are assumed to generate thunderstorms in the same way as terrestrial thunderstorms, driven by the heat rising from the interior.[52]\\r\\nThe orange and brown coloration in the clouds of Jupiter are caused by upwelling compounds that change color when they are exposed to ultraviolet light from the Sun. The exact makeup remains uncertain, but the substances are thought to be phosphorus, sulfur or possibly hydrocarbons.[36][53] These colorful compounds, known as chromophores, mix with the warmer, lower deck of clouds. The zones are formed when rising convection cells form crystallizing ammonia that masks out these lower clouds from view.[54]\\r\\nJupiter's low axial tilt means that the poles constantly receive less solar radiation than at the planet's equatorial region. Convection within the interior of the planet transports more energy to the poles, balancing out the temperatures at the cloud layer.[27]\\r\\nThe best known feature of Jupiter is the Great Red Spot, a persistent anticyclonic storm that is larger than Earth, located 22 south of the equator. It is known to have been in existence since at least 1831,[55] and possibly since 1665.[56][57] Images by the Hubble Space Telescope have shown as many as two \\"red spots\\" adjacent to the Great Red Spot.[58][59] The storm is large enough to be visible through Earth-based telescopes with an aperture of 12?cm or larger.[60] The oval object rotates counterclockwise, with a period of about six days.[61] The maximum altitude of this storm is about 8?km (5?mi) above the surrounding cloudtops.[62]\\r\\nThe Great Red Spot is large enough to accommodate Earth within its boundaries.[64] Mathematical models suggest that the storm is stable and may be a permanent feature of the planet.[65] However, it has significantly decreased in size since its discovery. Initial observations in the late 1800s showed it to be approximately 41,000?km (25,500?mi) across. By the time of the Voyager flybys in 1979, the storm had a length of 23,300?km (14,500?mi) and a width of approximately 13,000?km (8,000?mi).[66] Hubble observations in 1995 showed it had decreased in size again to 20,950?km (13,020?mi), and observations in 2009 showed the size to be 17,910?km (11,130?mi). As of 2015[update], the storm was measured at approximately 16,500 by 10,940?km (10,250 by 6,800?mi),[66] and is decreasing in length by about 930?km (580?mi) per year.[64][67]\\r\\nStorms such as this are common within the turbulent atmospheres of giant planets. Jupiter also has white ovals and brown ovals, which are lesser unnamed storms. White ovals tend to consist of relatively cool clouds within the upper atmosphere. Brown ovals are warmer and located within the \\"normal cloud layer\\". Such storms can last as little as a few hours or stretch on for centuries.\\r\\nEven before Voyager proved that the feature was a storm, there was strong evidence that the spot could not be associated with any deeper feature on the planet's surface, as the Spot rotates differentially with respect to the rest of the atmosphere, sometimes faster and sometimes more slowly.\\r\\nIn 2000, an atmospheric feature formed in the southern hemisphere that is similar in appearance to the Great Red Spot, but smaller. This was created when several smaller, white oval-shaped storms merged to form a single featurethese three smaller white ovals were first observed in 1938. The merged feature was named Oval BA, and has been nicknamed Red Spot Junior. It has since increased in intensity and changed color from white to red.[68][69][70]\\r\\nIn April 2017, scientists reported the discovery of a \\"Great Cold Spot\\" in Jupiter's thermosphere at its north pole that is 24,000?km (15,000?mi) across, 12,000?km (7,500?mi) wide, and 200?C (360?F) cooler than surrounding material. The feature was discovered by researchers at the Very Large Telescope in Chile, who then searched archived data from the NASA Infrared Telescope Facility between 1995 and 2000. They found that, while the Spot changes size, shape and intensity over the short term, it has maintained its general position in the atmosphere across more than 15 years of available data. Scientists believe the Spot is a giant vortex similar to the Great Red Spot and also appears to be quasi-stable like the vortices in Earth's thermosphere. Interactions between charged particles generated from Io and the planet's strong magnetic field likely resulted in redistribution of heat flow, forming the Spot.[71][72][73][74]\\r\\nJupiter's magnetic field is fourteen times as strong as that of Earth, ranging from 4.2?gauss (0.42 mT) at the equator to 10ÿ14 gauss (1.0ÿ1.4 mT) at the poles, making it the strongest in the Solar System (except for sunspots).[54] This field is thought to be generated by eddy currentsswirling movements of conducting materialswithin the liquid metallic hydrogen core. The volcanoes on the moon Io emit large amounts of sulfur dioxide forming a gas torus along the moon's orbit. The gas is ionized in the magnetosphere producing sulfur and oxygen ions. They, together with hydrogen ions originating from the atmosphere of Jupiter, form a plasma sheet in Jupiter's equatorial plane. The plasma in the sheet co-rotates with the planet causing deformation of the dipole magnetic field into that of magnetodisk. Electrons within the plasma sheet generate a strong radio signature that produces bursts in the range of 0.6ÿ30?MHz.[75]\\r\\nAt about 75 Jupiter radii from the planet, the interaction of the magnetosphere with the solar wind generates a bow shock. Surrounding Jupiter's magnetosphere is a magnetopause, located at the inner edge of a magnetosheatha region between it and the bow shock. The solar wind interacts with these regions, elongating the magnetosphere on Jupiter's lee side and extending it outward until it nearly reaches the orbit of Saturn. The four largest moons of Jupiter all orbit within the magnetosphere, which protects them from the solar wind.[36]\\r\\nThe magnetosphere of Jupiter is responsible for intense episodes of radio emission from the planet's polar regions. Volcanic activity on Jupiter's moon Io (see below) injects gas into Jupiter's magnetosphere, producing a torus of particles about the planet. As Io moves through this torus, the interaction generates Alfvn waves that carry ionized matter into the polar regions of Jupiter. As a result, radio waves are generated through a cyclotron maser mechanism, and the energy is transmitted out along a cone-shaped surface. When Earth intersects this cone, the radio emissions from Jupiter can exceed the solar radio output.[76]\\r\\nJupiter is the only planet whose barycenter with the Sun lies outside the volume of the Sun, though by only 7% of the Sun's radius.[77] The average distance between Jupiter and the Sun is 778 million?km (about 5.2 times the average distance between Earth and the Sun, or 5.2 AU) and it completes an orbit every 11.86?years. This is approximately two-fifths the orbital period of Saturn, forming a near orbital resonance between the two largest planets in the Solar System.[78] The elliptical orbit of Jupiter is inclined 1.31 compared to Earth. Because the eccentricity of its orbit is 0.048, Jupiter's distance from the Sun varies by 75 million?km between its nearest approach (perihelion) and furthest distance (aphelion).\\r\\nThe axial tilt of Jupiter is relatively small: only 3.13. As a result, it does not experience significant seasonal changes, in contrast to, for example, Earth and Mars.[79]\\r\\nJupiter's rotation is the fastest of all the Solar System's planets, completing a rotation on its axis in slightly less than ten hours; this creates an equatorial bulge easily seen through an Earth-based amateur telescope. The planet is shaped as an oblate spheroid, meaning that the diameter across its equator is longer than the diameter measured between its poles. On Jupiter, the equatorial diameter is 9,275?km (5,763?mi) longer than the diameter measured through the poles.[47]\\r\\nBecause Jupiter is not a solid body, its upper atmosphere undergoes differential rotation. The rotation of Jupiter's polar atmosphere is about 5?minutes longer than that of the equatorial atmosphere; three systems are used as frames of reference, particularly when graphing the motion of atmospheric features. System I applies from the latitudes 10?N to 10?S; its period is the planet's shortest, at 9h 50m 30.0s. System II applies at all latitudes north and south of these; its period is 9h 55m 40.6s. System III was first defined by radio astronomers, and corresponds to the rotation of the planet's magnetosphere; its period is Jupiter's official rotation.[80]\\r\\nJupiter is usually the fourth brightest object in the sky (after the Sun, the Moon and Venus);[54] at times Mars appears brighter than Jupiter. Depending on Jupiter's position with respect to the Earth, it can vary in visual magnitude from as bright as ?2.9 at opposition down to ?1.6 during conjunction with the Sun. The angular diameter of Jupiter likewise varies from 50.1 to 29.8 arc seconds.[5] Favorable oppositions occur when Jupiter is passing through perihelion, an event that occurs once per orbit.\\r\\nEarth overtakes Jupiter every 398.9 days as it orbits the Sun, a duration called the synodic period. As it does so, Jupiter appears to undergo retrograde motion with respect to the background stars. That is, for a period Jupiter seems to move backward in the night sky, performing a looping motion.\\r\\nBecause the orbit of Jupiter is outside that of Earth, the phase angle of Jupiter as viewed from Earth never exceeds 11.5. That is, the planet always appears nearly fully illuminated when viewed through Earth-based telescopes. It was only during spacecraft missions to Jupiter that crescent views of the planet were obtained.[81] A small telescope will usually show Jupiter's four Galilean moons and the prominent cloud belts across Jupiter's atmosphere.[82] A large telescope will show Jupiter's Great Red Spot when it faces Earth.\\r\\nThe observation of Jupiter dates back to at least the Babylonian astronomers of the 7th or 8th century BC.[83] The ancient Chinese also observed the orbit of Suxؐng (?qx) and established their cycle of 12 earthly branches based on its approximate number of years; the Chinese language still uses its name (simplified as ) when referring to years of age. By the 4th century BC, these observations had developed into the Chinese zodiac,[84] with each year associated with a Tai Sui star and god controlling the region of the heavens opposite Jupiter's position in the night sky; these beliefs survive in some Taoist religious practices and in the East Asian zodiac's twelve animals, now often popularly assumed to be related to the arrival of the animals before Buddha. The Chinese historian Xi Zezong has claimed that Gan De, an ancient Chinese astronomer, discovered one of Jupiter's moons in 362?BC with the unaided eye. If accurate, this would predate Galileo's discovery by nearly two millennia.[85][86] In his 2nd century work the Almagest, the Hellenistic astronomer Claudius Ptolemaeus constructed a geocentric planetary model based on deferents and epicycles to explain Jupiter's motion relative to Earth, giving its orbital period around Earth as 4332.38?days, or 11.86?years.[87] In 499, Aryabhata, a mathematicianÿastronomer from the classical age of Indian mathematics and astronomy, also used a geocentric model to estimate Jupiter's period as 4332.2722?days, or 11.86?years.[88][verification needed]\\r\\nIn 1610, Galileo Galilei discovered the four largest moons of Jupiter (now known as the Galilean moons) using a telescope; thought to be the first telescopic observation of moons other than Earth's. One day after Galileo, Simon Marius independently discovered moons around Jupiter, though he did not publish his discovery in a book until 1614.[89] It was Marius's names for the four major moons, however, that stuckIo, Europa, Ganymede and Callisto. These findings were also the first discovery of celestial motion not apparently centered on Earth. The discovery was a major point in favor of Copernicus' heliocentric theory of the motions of the planets; Galileo's outspoken support of the Copernican theory placed him under the threat of the Inquisition.[90]\\r\\nDuring the 1660s, Giovanni Cassini used a new telescope to discover spots and colorful bands on Jupiter and observed that the planet appeared oblate; that is, flattened at the poles. He was also able to estimate the rotation period of the planet.[91] In 1690 Cassini noticed that the atmosphere undergoes differential rotation.[36]\\r\\nThe Great Red Spot, a prominent oval-shaped feature in the southern hemisphere of Jupiter, may have been observed as early as 1664 by Robert Hooke and in 1665 by Cassini, although this is disputed. The pharmacist Heinrich Schwabe produced the earliest known drawing to show details of the Great Red Spot in 1831.[92]\\r\\nThe Red Spot was reportedly lost from sight on several occasions between 1665 and 1708 before becoming quite conspicuous in 1878. It was recorded as fading again in 1883 and at the start of the 20th century.[93]\\r\\nBoth Giovanni Borelli and Cassini made careful tables of the motions of Jupiter's moons, allowing predictions of the times when the moons would pass before or behind the planet. By the 1670s, it was observed that when Jupiter was on the opposite side of the Sun from Earth, these events would occur about 17?minutes later than expected. Ole R?mer deduced that light is not instantaneous (a conclusion that Cassini had earlier rejected),[21] and this timing discrepancy was used to estimate the speed of light.[94]\\r\\nIn 1892, E. E. Barnard observed a fifth satellite of Jupiter with the 36-inch (910?mm) refractor at Lick Observatory in California. The discovery of this relatively small object, a testament to his keen eyesight, quickly made him famous. This moon was later named Amalthea.[95] It was the last planetary moon to be discovered directly by visual observation.[96]\\r\\nIn 1932, Rupert Wildt identified absorption bands of ammonia and methane in the spectra of Jupiter.[97]\\r\\nThree long-lived anticyclonic features termed white ovals were observed in 1938. For several decades they remained as separate features in the atmosphere, sometimes approaching each other but never merging. Finally, two of the ovals merged in 1998, then absorbed the third in 2000, becoming Oval BA.[98]\\r\\nIn 1955, Bernard Burke and Kenneth Franklin detected bursts of radio signals coming from Jupiter at 22.2?MHz.[36] The period of these bursts matched the rotation of the planet, and they were also able to use this information to refine the rotation rate. Radio bursts from Jupiter were found to come in two forms: long bursts (or L-bursts) lasting up to several seconds, and short bursts (or S-bursts) that had a duration of less than a hundredth of a second.[99]\\r\\nScientists discovered that there were three forms of radio signals transmitted from Jupiter.\\r\\nSince 1973 a number of automated spacecraft have visited Jupiter, most notably the Pioneer 10 space probe, the first spacecraft to get close enough to Jupiter to send back revelations about the properties and phenomena of the Solar System's largest planet.[102][103] Flights to other planets within the Solar System are accomplished at a cost in energy, which is described by the net change in velocity of the spacecraft, or delta-v. Entering a Hohmann transfer orbit from Earth to Jupiter from low Earth orbit requires a delta-v of 6.3?km/s[104] which is comparable to the 9.7?km/s delta-v needed to reach low Earth orbit.[105] Fortunately, gravity assists through planetary flybys can be used to reduce the energy required to reach Jupiter, albeit at the cost of a significantly longer flight duration.[106]\\r\\nBeginning in 1973, several spacecraft have performed planetary flyby maneuvers that brought them within observation range of Jupiter. The Pioneer missions obtained the first close-up images of Jupiter's atmosphere and several of its moons. They discovered that the radiation fields near the planet were much stronger than expected, but both spacecraft managed to survive in that environment. The trajectories of these spacecraft were used to refine the mass estimates of the Jovian system. Radio occultations by the planet resulted in better measurements of Jupiter's diameter and the amount of polar flattening.[27][108]\\r\\nSix years later, the Voyager missions vastly improved the understanding of the Galilean moons and discovered Jupiter's rings. They also confirmed that the Great Red Spot was anticyclonic. Comparison of images showed that the Red Spot had changed hue since the Pioneer missions, turning from orange to dark brown. A torus of ionized atoms was discovered along Io's orbital path, and volcanoes were found on the moon's surface, some in the process of erupting. As the spacecraft passed behind the planet, it observed flashes of lightning in the night side atmosphere.[27][109]\\r\\nThe next mission to encounter Jupiter was the Ulysses solar probe. It performed a flyby maneuver to attain a polar orbit around the Sun. During this pass, the spacecraft conducted studies on Jupiter's magnetosphere. Ulysses has no cameras so no images were taken. A second flyby six years later was at a much greater distance.[107]\\r\\nIn 2000, the Cassini probe flew by Jupiter on its way to Saturn, and provided some of the highest-resolution images ever made of the planet.[110]\\r\\nThe New Horizons probe flew by Jupiter for a gravity assist en route to Pluto. Its closest approach was on February 28, 2007.[111] The probe's cameras measured plasma output from volcanoes on Io and studied all four Galilean moons in detail, as well as making long-distance observations of the outer moons Himalia and Elara.[112] Imaging of the Jovian system began September 4, 2006.[113][114]\\r\\nThe first spacecraft to orbit Jupiter was the Galileo probe, which entered orbit on December 7, 1995.[32] It orbited the planet for over seven years, conducting multiple flybys of all the Galilean moons and Amalthea. The spacecraft also witnessed the impact of Comet ShoemakerÿLevy 9 as it approached Jupiter in 1994, giving a unique vantage point for the event. Its originally designed capacity was limited by the failed deployment of its high-gain radio antenna, although extensive information was still gained about the Jovian system from Galileo.[115]\\r\\nA 340-kilogram titanium atmospheric probe was released from the spacecraft in July 1995, entering Jupiter's atmosphere on December 7.[32] It parachuted through 150?km (93?mi) of the atmosphere at a speed of about 2,575?km/h (1600?mph)[32] and collected data for 57.6?minutes before it was crushed by the pressure of about 23 atmospheres at a temperature of 153?C.[116] It melted thereafter, and possibly vaporized. The Galileo orbiter itself experienced a more rapid version of the same fate when it was deliberately steered into the planet on September 21, 2003 at a speed of over 50?km/s to avoid any possibility of it crashing into and possibly contaminating Europa, a moon which has been hypothesized to have the possibility of harboring life.[115]\\r\\nData from this mission revealed that hydrogen composes up to 90% of Jupiter's atmosphere.[32] The recorded temperature was more than 300?C (>570?F) and the windspeed measured more than 644?km/h (>400?mph) before the probes vapourised.[32]\\r\\nNASA's Juno mission arrived at Jupiter on July 4, 2016, and is expected to complete 37 orbits over the next 20 months.[16] The mission plan called for Juno to study the planet in detail from a polar orbit.[117] On August 27, 2016, the spacecraft completed its first fly-by of Jupiter and sent back the first-ever images of Jupiters north pole.[118]\\r\\nThe next planned mission to the Jovian system will be the European Space Agency's Jupiter Icy Moon Explorer (JUICE), due to launch in 2022,[119] followed by NASA's Europa Clipper mission in 2025.[120]\\r\\nThere has been great interest in studying the icy moons in detail because of the possibility of subsurface liquid oceans on Jupiter's moons Europa, Ganymede, and Callisto. Funding difficulties have delayed progress. NASA's JIMO (Jupiter Icy Moons Orbiter) was cancelled in 2005.[121] A subsequent proposal was developed for a joint NASA/ESA mission called EJSM/Laplace, with a provisional launch date around 2020. EJSM/Laplace would have consisted of the NASA-led Jupiter Europa Orbiter and the ESA-led Jupiter Ganymede Orbiter.[122] However, ESA had formally ended the partnership by April 2011, citing budget issues at NASA and the consequences on the mission timetable. Instead, ESA planned to go ahead with a European-only mission to compete in its L1 Cosmic Vision selection.[123]\\r\\nJupiter has 69 known natural satellites.[124] Of these, 53 are less than 10?kilometres in diameter and have only been discovered since 1975. The four largest moons, visible from Earth with binoculars on a clear night, known as the \\"Galilean moons\\", are Io, Europa, Ganymede, and Callisto.\\r\\nThe moons discovered by GalileoIo, Europa, Ganymede, and Callistoare among the largest satellites in the Solar System. The orbits of three of them (Io, Europa, and Ganymede) form a pattern known as a Laplace resonance; for every four orbits that Io makes around Jupiter, Europa makes exactly two orbits and Ganymede makes exactly one. This resonance causes the gravitational effects of the three large moons to distort their orbits into elliptical shapes, because each moon receives an extra tug from its neighbors at the same point in every orbit it makes. The tidal force from Jupiter, on the other hand, works to circularize their orbits.[125]\\r\\nThe eccentricity of their orbits causes regular flexing of the three moons' shapes, with Jupiter's gravity stretching them out as they approach it and allowing them to spring back to more spherical shapes as they swing away. This tidal flexing heats the moons' interiors by friction. This is seen most dramatically in the extraordinary volcanic activity of innermost Io (which is subject to the strongest tidal forces), and to a lesser degree in the geological youth of Europa's surface (indicating recent resurfacing of the moon's exterior).\\r\\nBefore the discoveries of the Voyager missions, Jupiter's moons were arranged neatly into four groups of four, based on commonality of their orbital elements. Since then, the large number of new small outer moons has complicated this picture. There are now thought to be six main groups, although some are more distinct than others.\\r\\nA basic sub-division is a grouping of the eight inner regular moons, which have nearly circular orbits near the plane of Jupiter's equator and are thought to have formed with Jupiter. The remainder of the moons consist of an unknown number of small irregular moons with elliptical and inclined orbits, which are thought to be captured asteroids or fragments of captured asteroids. Irregular moons that belong to a group share similar orbital elements and thus may have a common origin, perhaps as a larger moon or captured body that broke up.[126][127]\\r\\nJupiter has a faint planetary ring system composed of three main segments: an inner torus of particles known as the halo, a relatively bright main ring, and an outer gossamer ring.[129] These rings appear to be made of dust, rather than ice as with Saturn's rings.[36] The main ring is probably made of material ejected from the satellites Adrastea and Metis. Material that would normally fall back to the moon is pulled into Jupiter because of its strong gravitational influence. The orbit of the material veers towards Jupiter and new material is added by additional impacts.[130] In a similar way, the moons Thebe and Amalthea probably produce the two distinct components of the dusty gossamer ring.[130] There is also evidence of a rocky ring strung along Amalthea's orbit which may consist of collisional debris from that moon.[131]\\r\\nAlong with the Sun, the gravitational influence of Jupiter has helped shape the Solar System. The orbits of most of the system's planets lie closer to Jupiter's orbital plane than the Sun's equatorial plane (Mercury is the only planet that is closer to the Sun's equator in orbital tilt), the Kirkwood gaps in the asteroid belt are mostly caused by Jupiter, and the planet may have been responsible for the Late Heavy Bombardment of the inner Solar System's history.[132]\\r\\nAlong with its moons, Jupiter's gravitational field controls numerous asteroids that have settled into the regions of the Lagrangian points preceding and following Jupiter in its orbit around the Sun. These are known as the Trojan asteroids, and are divided into Greek and Trojan \\"camps\\" to commemorate the Iliad. The first of these, 588 Achilles, was discovered by Max Wolf in 1906; since then more than two thousand have been discovered.[133] The largest is 624 Hektor.\\r\\nMost short-period comets belong to the Jupiter familydefined as comets with semi-major axes smaller than Jupiter's. Jupiter family comets are thought to form in the Kuiper belt outside the orbit of Neptune. During close encounters with Jupiter their orbits are perturbed into a smaller period and then circularized by regular gravitational interaction with the Sun and Jupiter.[134]\\r\\nDue to the magnitude of Jupiter's mass, the center of gravity between it and the Sun lies just above the Sun's surface.[135] Jupiter is the only body in the Solar System for which this is true.\\r\\nJupiter has been called the Solar System's vacuum cleaner,[137] because of its immense gravity well and location near the inner Solar System. It receives the most frequent comet impacts of the Solar System's planets.[138] It was thought that the planet served to partially shield the inner system from cometary bombardment.[32] However, recent computer simulations suggest that Jupiter does not cause a net decrease in the number of comets that pass through the inner Solar System, as its gravity perturbs their orbits inward roughly as often as it accretes or ejects them.[139] This topic remains controversial among scientists, as some think it draws comets towards Earth from the Kuiper belt while others think that Jupiter protects Earth from the alleged Oort cloud.[140] Jupiter experiences about 200 times more asteroid and comet impacts than Earth.[32]\\r\\nA 1997 survey of early astronomical records and drawings suggested that a certain dark surface feature discovered by astronomer Giovanni Cassini in 1690 may have been an impact scar. The survey initially produced eight more candidate sites as potential impact observations that he and others had recorded between 1664 and 1839. It was later determined, however, that these candidate sites had little or no possibility of being the results of the proposed impacts.[141]\\r\\nMore recent discoveries include the following:\\r\\nThe planet Jupiter has been known since ancient times. It is visible to the naked eye in the night sky and can occasionally be seen in the daytime when the Sun is low.[152] To the Babylonians, this object represented their god Marduk. They used Jupiter's roughly 12-year orbit along the ecliptic to define the constellations of their zodiac.[27][153]\\r\\nThe Romans named it after Jupiter (Latin: Iuppiter, Ipiter) (also called Jove), the principal god of Roman mythology, whose name comes from the Proto-Indo-European vocative compound *Dyu-p?ter (nominative: *Dyus-p?tr, meaning \\"Father Sky-God\\", or \\"Father Day-God\\").[154] In turn, Jupiter was the counterpart to the mythical Greek Zeus (??), also referred to as Dias (?ϫ?), the planetary name of which is retained in modern Greek.[155]\\r\\nThe astronomical symbol for the planet, , is a stylized representation of the god's lightning bolt. The original Greek deity Zeus supplies the root zeno-, used to form some Jupiter-related words, such as zenographic.[d]\\r\\nJovian is the adjectival form of Jupiter. The older adjectival form jovial, employed by astrologers in the Middle Ages, has come to mean \\"happy\\" or \\"merry\\", moods ascribed to Jupiter's astrological influence.[156]\\r\\nThe Chinese, Koreans and Japanese called it the \\"wood star\\" (Chinese: Jx; pinyin: mxؐng), based on the Chinese Five Elements.[157][158][159] Chinese Taoism personified it as the Fu star. The Greeks called it ϫ?Ĳ (Phaethon, meaning \\"blazing\\"). In Vedic astrology, Hindu astrologers named the planet after Brihaspati, the religious teacher of the gods, and often called it \\"Guru\\", which literally means the \\"Heavy One\\".[160]\\r\\nIn Germanic mythology, Jupiter is equated to Thor, whence the English name Thursday for the Roman dies Jovis.[161]\\r\\nIn the Central Asian-Turkic myths, Jupiter is called Erendiz or Erentz, from eren (of uncertain meaning) and yultuz (\\"star\\"). There are many theories about the meaning of eren. These peoples calculated the period of the orbit of Jupiter as 11 years and 300 days. They believed that some social and natural events connected to Erentz's movements on the sky.[162]\\r\\nSolar System?L Local Interstellar Cloud?L Local Bubble?L Gould Belt?L Orion Arm?L Milky Way?L Milky Way subgroup?L Local Group?L Virgo Supercluster?L Laniakea Supercluster?L PiscesÿCetus Supercluster Complex?L Observable universe?L Universe\\r\\nEach arrow (L) may be read as \\"within\\" or \\"part of\\".","input":"What is jupiter's core made up of?"},{"output":"Pinarayi Vijayan","context":"\\r\\n\\r\\nPinarayi Vijayan (born 24 May 1945[2]) is an Indian politician who is the current Chief Minister of Kerala, in office since 25 May 2016.[3]\\r\\n\\r\\nA member of the Politburo of the Communist Party of India (Marxist), he was the longest-serving secretary of the Kerala State Committee of the CPI(M) from 1998 to 2015. He also served in the government of Kerala as Minister of Electric Power and Co-operatives from 1996 to 1998. Vijayan won a seat in the May 2016 Kerala Legislative Assembly election as the CPI(M) candidate for Dharmadom constituency[4] and was selected as the leader of the Left Democratic Front (LDF) and became the 12th Chief Minister of Kerala.[5][6]\\r\\n\\r\\nVijayan was born on 24 May 1945[2] in a poor family[7] in Pinarayi in Malabar district (present-day Kannur District), as the youngest son of Koran and Kalyani. He had 14 siblings of which only three survived. After graduating school, he worked as a handloom weaver for a year before joining for Preÿuniversity course in the Government Brennen College, Thalassery. Subsequently, he completed his degree course from the same college.[8][9]\\r\\n\\r\\nPinarayi Vijayan entered politics through student union activities at Government Brennen College, Thalassery. He eventually joined the Communist Party of India (Marxist) in 1964. Vijayan became Kannur district secretary of the Kerala Students Federation (KSF), which later became the Students Federation of India (SFI). He went on to become the state secretary and subsequently the state president of KSF. He then moved on to Kerala State Youth Federation (KSYF), which later became the Democratic Youth Federation of India (DYFI). He became the president of the state committee. During that period, when communists in Kerala were organising the political activities from different hide-outs, Pinarayi Vijayan was imprisoned for one and a half years.\\r\\n\\r\\nLater he was elected as the president of the Kerala state co-operative bank. During the emergency, he was arrested and tortured by police. He became the Kannur district secretary of the CPI(M) when M.V. Raghavan left the party over the alternative document' row. Within three years, he became a member of the State Secretariat. He was elected to the Assembly in 1970, 1977 and 1991 from Koothuparamba, in 1996 from Payyannur and in 2016 from Dharmadom. He was the Minister for Electric power and Co-operatives in the E.K. Nayanar ministry from 1996 to 1998. In 1998, he became the state secretary of the CPI(M), following the death of the incumbent Chadayan Govindan. He was elected to the Politburo of the CPI(M) in 2002.[8]\\r\\n\\r\\nOn 26 May 2007 the CPI(M) suspended Pinarayi Vijayan and V. S. Achuthanandan from the Politburo for their public remarks on each other. Pinarayi was reinstated into the Politburo later.[10]\\r\\n\\r\\nPinarayi Vijayan was selected by the CPI(M) as Chief Minister of Kerala in May 2016, following the 2016 Legislative Assembly election. Vijayan was selected as the leader of Left Democratic Front government.[5][6] He was sworn in on 25 May 2016 in front of a large number of party workers, along with his 19-member cabinet. Vijayan also holds the charge of Home Affairs & Vigilance Departments along with the other portfolios normally held by the Chief Ministers, and not mentioned elsewhere. He is elected from Dharmadom constituency. During his reign he introduced various schemes like Haritha Keralam Mission, Project LIFE, Ardram Mission and Comprehensive Education Reforms. For the first time in India, an all-woman police squad called Pink Patrol was introduced in Kerala to ascertain the security of women and children in public places.\\r\\n\\r\\nHe is married to Kamala Vijayan and has two children, Veena and Vivek. His wife is a retired teacher. Their son works in HSBC bank, in Abu Dhabi and daughter is in Bangalore, India where she manages a web startup. The family resides in the official residence of the Chief Minister at Trivandrum.\\r\\n\\r\\n\\r\\n\\r\\nClose up image of Pinarayi Vijayan\\r\\n\\r\\nPinarayi Vijayan inaugurating ESAF Small Finance Bank at Thrissur\\r\\n\\r\\nPinarayi Vijayan with the recipient of Vanita Ratnam Award 2018\\r\\n\\r\\nPinarayi Vijayan with police officers","input":"Who is the current chief minister of kerala?"},{"output":"Dennis Ritchie between 1969 and 1973 at Bell Labs","context":"C (/si?/, as in the letter c) is a general-purpose, imperative computer programming language, supporting structured programming, lexical variable scope and recursion, while a static type system prevents many unintended operations. By design, C provides constructs that map efficiently to typical machine instructions, and therefore it has found lasting use in applications that had formerly been coded in assembly language, including operating systems, as well as various application software for computers ranging from supercomputers to embedded systems.\\r\\nC was originally developed by Dennis Ritchie between 1969 and 1973 at Bell Labs,[5] and used to re-implement the Unix operating system.[6] It has since become one of the most widely used programming languages of all time,[7][8] with C compilers from various vendors available for the majority of existing computer architectures and operating systems. C has been standardized by the American National Standards Institute (ANSI) since 1989 (see ANSI C) and subsequently by the International Organization for Standardization (ISO).\\r\\nC is an imperative procedural language. It was designed to be compiled using a relatively straightforward compiler, to provide low-level access to memory, to provide language constructs that map efficiently to machine instructions, and to require minimal run-time support. Despite its low-level capabilities, the language was designed to encourage cross-platform programming. A standards-compliant and portably written C program can be compiled for a very wide variety of computer platforms and operating systems with few changes to its source code. The language has become available on a very wide range of platforms, from embedded microcontrollers to supercomputers.\\r\\n\\r\\n\\r\\nLike most imperative languages in the ALGOL tradition, C has facilities for structured programming and allows lexical variable scope and recursion, while a static type system prevents many unintended operations. In C, all executable code is contained within subroutines, which are called \\"functions\\" (although not in the strict sense of functional programming). Function parameters are always passed by value. Pass-by-reference is simulated in C by explicitly passing pointer values. C program source text is free-format, using the semicolon as a statement terminator and curly braces for grouping blocks of statements.\\r\\nThe C language also exhibits the following characteristics:\\r\\nWhile C does not include some features found in some other languages, such as object orientation or garbage collection, such features can be implemented or emulated in C, often by way of external libraries (e.g., the Boehm garbage collector or the GLib Object System).\\r\\nMany later languages have borrowed directly or indirectly from C, including C++, D, Go, Rust, Java, JavaScript, Limbo, LPC, C#, Objective-C, Perl, PHP, Python, Swift, Verilog (hardware description language),[4] and Unix's C shell. These languages have drawn many of their control structures and other basic features from C. Most of them (with Python being the most dramatic exception) are also very syntactically similar to C in general, and they tend to combine the recognizable expression and statement syntax of C with underlying type systems, data models, and semantics that can be radically different.\\r\\nThe origin of C is closely tied to the development of the Unix operating system, originally implemented in assembly language on a PDP-7 by Dennis Ritchie and Ken Thompson, incorporating several ideas from colleagues. Eventually, they decided to port the operating system to a PDP-11. The original PDP-11 version of Unix was developed in assembly language. The developers were considering rewriting the system using the B language, Thompson's simplified version of BCPL.[9] However B's inability to take advantage of some of the PDP-11's features, notably byte addressability, led to C. The name of C was chosen simply as the next after B.[10]\\r\\nThe development of C started in 1972 on the PDP-11 Unix system[11] and first appeared in Version 2 Unix.[12] The language was not initially designed with portability in mind, but soon ran on different platforms as well: a compiler for the Honeywell 6000 was written within the first year of C's history, while an IBM System/370 port followed soon.[1][11]\\r\\nAlso in 1972, a large part of Unix was rewritten in C.[13] By 1973, with the addition of struct types, the C language had become powerful enough that most of the Unix kernel was now in C.\\r\\nUnix was one of the first operating system kernels implemented in a language other than assembly. Earlier instances include the Multics system which was written in PL/I), and Master Control Program (MCP) for the Burroughs B5000 written in ALGOL in 1961. In around 1977, Ritchie and Stephen C. Johnson made further changes to the language to facilitate portability of the Unix operating system. Johnson's Portable C Compiler served as the basis for several implementations of C on new platforms.[11]\\r\\nIn 1978, Brian Kernighan and Dennis Ritchie published the first edition of The C Programming Language.[1] This book, known to C programmers as \\"K&R\\", served for many years as an informal specification of the language. The version of C that it describes is commonly referred to as K&R C. The second edition of the book[14] covers the later ANSI C standard, described below.\\r\\nK&R introduced several language features:\\r\\nEven after the publication of the 1989 ANSI standard, for many years K&R C was still considered the \\"lowest common denominator\\" to which C programmers restricted themselves when maximum portability was desired, since many older compilers were still in use, and because carefully written K&R C code can be legal Standard C as well.\\r\\nIn early versions of C, only functions that return types other than int must be declared if used before the function definition; functions used without prior declaration were presumed to return type int.\\r\\nFor example:\\r\\nThe int type specifiers which are commented out could be omitted in K&R C, but are required in later standards.\\r\\nSince K&R function declarations did not include any information about function arguments, function parameter type checks were not performed, although some compilers would issue a warning message if a local function was called with the wrong number of arguments, or if multiple calls to an external function used different numbers or types of arguments. Separate tools such as Unix's lint utility were developed that (among other things) could check for consistency of function use across multiple source files.\\r\\nIn the years following the publication of K&R C, several features were added to the language, supported by compilers from AT&T (in particular PCC[15]) and some other vendors. These included:\\r\\nThe large number of extensions and lack of agreement on a standard library, together with the language popularity and the fact that not even the Unix compilers precisely implemented the K&R specification, led to the necessity of standardization.\\r\\nDuring the late 1970s and 1980s, versions of C were implemented for a wide variety of mainframe computers, minicomputers, and microcomputers, including the IBM PC, as its popularity began to increase significantly.\\r\\nIn 1983, the American National Standards Institute (ANSI) formed a committee, X3J11, to establish a standard specification of C. X3J11 based the C standard on the Unix implementation; however, the non-portable portion of the Unix C library was handed off to the IEEE working group 1003 to become the basis for the 1988 POSIX standard. In 1989, the C standard was ratified as ANSI X3.159-1989 \\"Programming Language C\\". This version of the language is often referred to as ANSI C, Standard C, or sometimes C89.\\r\\nIn 1990, the ANSI C standard (with formatting changes) was adopted by the International Organization for Standardization (ISO) as ISO/IEC 9899:1990, which is sometimes called C90. Therefore, the terms \\"C89\\" and \\"C90\\" refer to the same programming language.\\r\\nANSI, like other national standards bodies, no longer develops the C standard independently, but defers to the international C standard, maintained by the working group ISO/IEC JTC1/SC22/WG14. National adoption of an update to the international standard typically occurs within a year of ISO publication.\\r\\nOne of the aims of the C standardization process was to produce a superset of K&R C, incorporating many of the subsequently introduced unofficial features. The standards committee also included several additional features such as function prototypes (borrowed from C++), void pointers, support for international character sets and locales, and preprocessor enhancements. Although the syntax for parameter declarations was augmented to include the style used in C++, the K&R interface continued to be permitted, for compatibility with existing source code.\\r\\nC89 is supported by current C compilers, and most C code being written today is based on it. Any program written only in Standard C and without any hardware-dependent assumptions will run correctly on any platform with a conforming C implementation, within its resource limits. Without such precautions, programs may compile only on a certain platform or with a particular compiler, due, for example, to the use of non-standard libraries, such as GUI libraries, or to a reliance on compiler- or platform-specific attributes such as the exact size of data types and byte endianness.\\r\\nIn cases where code must be compilable by either standard-conforming or K&R C-based compilers, the __STDC__ macro can be used to split the code into Standard and K&R sections to prevent the use on a K&R C-based compiler of features available only in Standard C.\\r\\nAfter the ANSI/ISO standardization process, the C language specification remained relatively static for several years. In 1995, Normative Amendment 1 to the 1990 C standard (ISO/IEC 9899/AMD1:1995, known informally as C95) was published, to correct some details and to add more extensive support for international character sets.[citation needed]\\r\\nThe C standard was further revised in the late 1990s, leading to the publication of ISO/IEC 9899:1999 in 1999, which is commonly referred to as \\"C99\\". It has since been amended three times by Technical Corrigenda.[16]\\r\\nC99 introduced several new features, including inline functions, several new data types (including long long int and a complex type to represent complex numbers), variable-length arrays and flexible array members, improved support for IEEE 754 floating point, support for variadic macros (macros of variable arity), and support for one-line comments beginning with //, as in BCPL or C++. Many of these had already been implemented as extensions in several C compilers.\\r\\nC99 is for the most part backward compatible with C90, but is stricter in some ways; in particular, a declaration that lacks a type specifier no longer has int implicitly assumed. A standard macro __STDC_VERSION__ is defined with value 199901L to indicate that C99 support is available. GCC, Solaris Studio, and other C compilers now support many or all of the new features of C99. The C compiler in Microsoft Visual C++, however, implements the C89 standard and those parts of C99 that are required for compatibility with C++11.[17]\\r\\nIn 2007, work began on another revision of the C standard, informally called \\"C1X\\" until its official publication on 2011-12-08. The C standards committee adopted guidelines to limit the adoption of new features that had not been tested by existing implementations.\\r\\nThe C11 standard adds numerous new features to C and the library, including type generic macros, anonymous structures, improved Unicode support, atomic operations, multi-threading, and bounds-checked functions. It also makes some portions of the existing C99 library optional, and improves compatibility with C++. The standard macro __STDC_VERSION__ is defined as 201112L to indicate that C11 support is available.\\r\\nHistorically, embedded C programming requires nonstandard extensions to the C language in order to support exotic features such as fixed-point arithmetic, multiple distinct memory banks, and basic I/O operations.\\r\\nIn 2008, the C Standards Committee published a technical report extending the C language[18] to address these issues by providing a common standard for all implementations to adhere to. It includes a number of features not available in normal C, such as fixed-point arithmetic, named address spaces, and basic I/O hardware addressing.\\r\\nC has a formal grammar specified by the C standard.[19] Line endings are generally not significant in C; however, line boundaries do have significance during the preprocessing phase. Comments may appear either between the delimiters /* and */, or (since C99) following // until the end of the line. Comments delimited by /* and */ do not nest, and these sequences of characters are not interpreted as comment delimiters if they appear inside string or character literals.[20]\\r\\nC source files contain declarations and function definitions. Function definitions, in turn, contain declarations and statements. Declarations either define new types using keywords such as struct, union, and enum, or assign types to and perhaps reserve storage for new variables, usually by writing the type followed by the variable name. Keywords such as char and int specify built-in types. Sections of code are enclosed in braces ({ and }, sometimes called \\"curly brackets\\") to limit the scope of declarations and to act as a single statement for control structures.\\r\\nAs an imperative language, C uses statements to specify actions. The most common statement is an expression statement, consisting of an expression to be evaluated, followed by a semicolon; as a side effect of the evaluation, functions may be called and variables may be assigned new values. To modify the normal sequential execution of statements, C provides several control-flow statements identified by reserved keywords. Structured programming is supported by if(-else) conditional execution and by do-while, while, and for iterative execution (looping). The for statement has separate initialization, testing, and reinitialization expressions, any or all of which can be omitted. break and continue can be used to leave the innermost enclosing loop statement or skip to its reinitialization. There is also a non-structured goto statement which branches directly to the designated label within the function. switch selects a case to be executed based on the value of an integer expression.\\r\\nExpressions can use a variety of built-in operators and may contain function calls. The order in which arguments to functions and operands to most operators are evaluated is unspecified. The evaluations may even be interleaved. However, all side effects (including storage to variables) will occur before the next \\"sequence point\\"; sequence points include the end of each expression statement, and the entry to and return from each function call. Sequence points also occur during evaluation of expressions containing certain operators (&&, ||, ?: and the comma operator). This permits a high degree of object code optimization by the compiler, but requires C programmers to take more care to obtain reliable results than is needed for other programming languages.\\r\\nKernighan and Ritchie say in the Introduction of The C Programming Language: \\"C, like any other language, has its blemishes. Some of the operators have the wrong precedence; some parts of the syntax could be better.\\"[21] The C standard did not attempt to correct many of these blemishes, because of the impact of such changes on already existing software.\\r\\nThe basic C source character set includes the following characters:\\r\\nNewline indicates the end of a text line; it need not correspond to an actual single character, although for convenience C treats it as one.\\r\\nAdditional multi-byte encoded characters may be used in string literals, but they are not entirely portable. The latest C standard (C11) allows multi-national Unicode characters to be embedded portably within C source text by using \\\\uXXXX or \\\\UXXXXXXXX encoding (where the X denotes a hexadecimal character), although this feature is not yet widely implemented.\\r\\nThe basic C execution character set contains the same characters, along with representations for alert, backspace, and carriage return. Run-time support for extended character sets has increased with each revision of the C standard.\\r\\nC89 has 32 reserved words, also known as keywords, which are the words that cannot be used for any purposes other than those for which they are predefined:\\r\\nC99 reserved five more words:\\r\\nC11 reserved seven more words:[22]\\r\\nMost of the recently reserved words begin with an underscore followed by a capital letter, because identifiers of that form were previously reserved by the C standard for use only by implementations. Since existing program source code should not have been using these identifiers, it would not be affected when C implementations started supporting these extensions to the programming language. Some standard headers do define more convenient synonyms for underscored identifiers. The language previously included a reserved word called entry, but this was seldom implemented, and has now been removed as a reserved word.[23]\\r\\nC supports a rich set of operators, which are symbols used within an expression to specify the manipulations to be performed while evaluating that expression. C has operators for:\\r\\nC uses the operator = (used in mathematics to express equality) to indicate assignment, following the precedent of Fortran and PL/I, but unlike ALGOL and its derivatives. C uses the operator == to test for equality. The similarity between these two operators (assignment and equality) may result in the accidental use of one in place of the other, and in many cases, the mistake does not produce an error message (although some compilers produce warnings). For example, the conditional expression if(a==b+1) might mistakenly be written as if(a=b+1), which will be evaluated as true if a is not zero after the assignment.[24]\\r\\nThe C operator precedence is not always intuitive. For example, the operator == binds more tightly than (is executed prior to) the operators & (bitwise AND) and | (bitwise OR) in expressions such as x & 1 == 0, which must be written as (x & 1) == 0 if that is the coder's intent.[25]\\r\\nThe \\"hello, world\\" example, which appeared in the first edition of K&R, has become the model for an introductory program in most programming textbooks, regardless of programming language. The program prints \\"hello, world\\" to the standard output, which is usually a terminal or screen display.\\r\\nThe original version was:[26]\\r\\nA standard-conforming \\"hello, world\\" program is:[a]\\r\\nThe first line of the program contains a preprocessing directive, indicated by #include. This causes the compiler to replace that line with the entire text of the stdio.h standard header, which contains declarations for standard input and output functions such as printf. The angle brackets surrounding stdio.h indicate that stdio.h is located using a search strategy that prefers headers provided with the compiler to other headers having the same name, as opposed to double quotes which typically include local or project-specific header files.\\r\\nThe next line indicates that a function named main is being defined. The main function serves a special purpose in C programs; the run-time environment calls the main function to begin program execution. The type specifier int indicates that the value that is returned to the invoker (in this case the run-time environment) as a result of evaluating the main function, is an integer. The keyword void as a parameter list indicates that this function takes no arguments.[b]\\r\\nThe opening curly brace indicates the beginning of the definition of the main function.\\r\\nThe next line calls (diverts execution to) a function named printf, which in this case is supplied from a system library. In this call, the printf function is passed (provided with) a single argument, the address of the first character in the string literal \\"hello, world\\\\n\\". The string literal is an unnamed array with elements of type char, set up automatically by the compiler with a final 0-valued character to mark the end of the array (printf needs to know this). The \\\\n is an escape sequence that C translates to a newline character, which on output signifies the end of the current line. The return value of the printf function is of type int, but it is silently discarded since it is not used. (A more careful program might test the return value to determine whether or not the printf function succeeded.) The semicolon ; terminates the statement.\\r\\nThe closing curly brace indicates the end of the code for the main function. According to the C99 specification and newer, the main function, unlike any other function, will implicitly return a value of 0 upon reaching the } that terminates the function. (Formerly an explicit return 0; statement was required.) This is interpreted by the run-time system as an exit code indicating successful execution.[27]\\r\\nThe type system in C is static and weakly typed, which makes it similar to the type system of ALGOL descendants such as Pascal.[28] There are built-in types for integers of various sizes, both signed and unsigned, floating-point numbers, and enumerated types (enum). Integer type char is often used for single-byte characters. C99 added a boolean datatype. There are also derived types including arrays, pointers, records (struct), and untagged unions (union).\\r\\nC is often used in low-level systems programming where escapes from the type system may be necessary. The compiler attempts to ensure type correctness of most expressions, but the programmer can override the checks in various ways, either by using a type cast to explicitly convert a value from one type to another, or by using pointers or unions to reinterpret the underlying bits of a data object in some other way.\\r\\nSome find C's declaration syntax unintuitive, particularly for function pointers. (Ritchie's idea was to declare identifiers in contexts resembling their use: \\"declaration reflects use\\".)[29]\\r\\nC's usual arithmetic conversions allow for efficient code to be generated, but can sometimes produce unexpected results. For example, a comparison of signed and unsigned integers of equal width requires a conversion of the signed value to unsigned. This can generate unexpected results if the signed value is negative.\\r\\nC supports the use of pointers, a type of reference that records the address or location of an object or function in memory. Pointers can be dereferenced to access data stored at the address pointed to, or to invoke a pointed-to function. Pointers can be manipulated using assignment or pointer arithmetic. The run-time representation of a pointer value is typically a raw memory address (perhaps augmented by an offset-within-word field), but since a pointer's type includes the type of the thing pointed to, expressions including pointers can be type-checked at compile time. Pointer arithmetic is automatically scaled by the size of the pointed-to data type. Pointers are used for many purposes in C. Text strings are commonly manipulated using pointers into arrays of characters. Dynamic memory allocation is performed using pointers. Many data types, such as trees, are commonly implemented as dynamically allocated struct objects linked together using pointers. Pointers to functions are useful for passing functions as arguments to higher-order functions (such as qsort or bsearch) or as callbacks to be invoked by event handlers.[27]\\r\\nA null pointer value explicitly points to no valid location. Dereferencing a null pointer value is undefined, often resulting in a segmentation fault. Null pointer values are useful for indicating special cases such as no \\"next\\" pointer in the final node of a linked list, or as an error indication from functions returning pointers. In appropriate contexts in source code, such as for assigning to a pointer variable, a null pointer constant can be written as 0, with or without explicit casting to a pointer type, or as the NULL macro defined by several standard headers. In conditional contexts, null pointer values evaluate to false, while all other pointer values evaluate to true.\\r\\nVoid pointers (void *) point to objects of unspecified type, and can therefore be used as \\"generic\\" data pointers. Since the size and type of the pointed-to object is not known, void pointers cannot be dereferenced, nor is pointer arithmetic on them allowed, although they can easily be (and in many contexts implicitly are) converted to and from any other object pointer type.[27]\\r\\nCareless use of pointers is potentially dangerous. Because they are typically unchecked, a pointer variable can be made to point to any arbitrary location, which can cause undesirable effects. Although properly used pointers point to safe places, they can be made to point to unsafe places by using invalid pointer arithmetic; the objects they point to may continue to be used after deallocation (dangling pointers); they may be used without having been initialized (wild pointers); or they may be directly assigned an unsafe value using a cast, union, or through another corrupt pointer. In general, C is permissive in allowing manipulation of and conversion between pointer types, although compilers typically provide options for various levels of checking. Some other programming languages address these problems by using more restrictive reference types.\\r\\nArray types in C are traditionally of a fixed, static size specified at compile time. (The more recent C99 standard also allows a form of variable-length arrays.) However, it is also possible to allocate a block of memory (of arbitrary size) at run-time, using the standard library's malloc function, and treat it as an array. C's unification of arrays and pointers means that declared arrays and these dynamically allocated simulated arrays are virtually interchangeable.\\r\\nSince arrays are always accessed (in effect) via pointers, array accesses are typically not checked against the underlying array size, although some compilers may provide bounds checking as an option.[30] Array bounds violations are therefore possible and rather common in carelessly written code, and can lead to various repercussions, including illegal memory accesses, corruption of data, buffer overruns, and run-time exceptions. If bounds checking is desired, it must be done manually.\\r\\nC does not have a special provision for declaring multi-dimensional arrays, but rather relies on recursion within the type system to declare arrays of arrays, which effectively accomplishes the same thing. The index values of the resulting \\"multi-dimensional array\\" can be thought of as increasing in row-major order.\\r\\nMulti-dimensional arrays are commonly used in numerical algorithms (mainly from applied linear algebra) to store matrices. The structure of the C array is well suited to this particular task. However, since arrays are passed merely as pointers, the bounds of the array must be known fixed values or else explicitly passed to any subroutine that requires them, and dynamically sized arrays of arrays cannot be accessed using double indexing. (A workaround for this is to allocate the array with an additional \\"row vector\\" of pointers to the columns.)\\r\\nC99 introduced \\"variable-length arrays\\" which address some, but not all, of the issues with ordinary C arrays.\\r\\nThe subscript notation x[i] (where x designates a pointer) is syntactic sugar for *(x+i).[31] Taking advantage of the compiler's knowledge of the pointer type, the address that x + i points to is not the base address (pointed to by x) incremented by i bytes, but rather is defined to be the base address incremented by i multiplied by the size of an element that x points to. Thus, x[i] designates the i+1th element of the array.\\r\\nFurthermore, in most expression contexts (a notable exception is as operand of sizeof), the name of an array is automatically converted to a pointer to the array's first element. This implies that an array is never copied as a whole when named as an argument to a function, but rather only the address of its first element is passed. Therefore, although function calls in C use pass-by-value semantics, arrays are in effect passed by reference.\\r\\nThe size of an element can be determined by applying the operator sizeof to any dereferenced element of x, as in n = sizeof *x or n = sizeof x[0], and the number of elements in a declared array A can be determined as sizeof A / sizeof A[0]. The latter only applies to array names: variables declared with subscripts (int A[20]). Due to the semantics of C, it is not possible to determine the entire size of arrays through pointers to arrays or those created by dynamic allocation (malloc); code such as sizeof arr / sizeof arr[0] (where arr designates a pointer) will not work since the compiler assumes the size of the pointer itself is being requested.[32][33] Since array name arguments to sizeof are not converted to pointers, they do not exhibit such ambiguity. However, arrays created by dynamic allocation are accessed by pointers rather than true array variables, so they suffer from the same sizeof issues as array pointers.\\r\\nThus, despite this apparent equivalence between array and pointer variables, there is still a distinction to be made between them. Even though the name of an array is, in most expression contexts, converted into a pointer (to its first element), this pointer does not itself occupy any storage; the array name is not an l-value, and its address is a constant, unlike a pointer variable. Consequently, what an array \\"points to\\" cannot be changed, and it is impossible to assign a new address to an array name. Array contents may be copied, however, by using the memcpy function, or by accessing the individual elements.\\r\\nOne of the most important functions of a programming language is to provide facilities for managing memory and the objects that are stored in memory. C provides three distinct ways to allocate memory for objects:[27]\\r\\nThese three approaches are appropriate in different situations and have various trade-offs. For example, static memory allocation has little allocation overhead, automatic allocation may involve slightly more overhead, and dynamic memory allocation can potentially have a great deal of overhead for both allocation and deallocation. The persistent nature of static objects is useful for maintaining state information across function calls, automatic allocation is easy to use but stack space is typically much more limited and transient than either static memory or heap space, and dynamic memory allocation allows convenient allocation of objects whose size is known only at run-time. Most C programs make extensive use of all three.\\r\\nWhere possible, automatic or static allocation is usually simplest because the storage is managed by the compiler, freeing the programmer of the potentially error-prone chore of manually allocating and releasing storage. However, many data structures can change in size at runtime, and since static allocations (and automatic allocations before C99) must have a fixed size at compile-time, there are many situations in which dynamic allocation is necessary.[27] Prior to the C99 standard, variable-sized arrays were a common example of this. (See the article on malloc for an example of dynamically allocated arrays.) Unlike automatic allocation, which can fail at run time with uncontrolled consequences, the dynamic allocation functions return an indication (in the form of a null pointer value) when the required storage cannot be allocated. (Static allocation that is too large is usually detected by the linker or loader, before the program can even begin execution.)\\r\\nUnless otherwise specified, static objects contain zero or null pointer values upon program startup. Automatically and dynamically allocated objects are initialized only if an initial value is explicitly specified; otherwise they initially have indeterminate values (typically, whatever bit pattern happens to be present in the storage, which might not even represent a valid value for that type). If the program attempts to access an uninitialized value, the results are undefined. Many modern compilers try to detect and warn about this problem, but both false positives and false negatives can occur.\\r\\nAnother issue is that heap memory allocation has to be synchronized with its actual usage in any program in order for it to be reused as much as possible. For example, if the only pointer to a heap memory allocation goes out of scope or has its value overwritten before free() is called, then that memory cannot be recovered for later reuse and is essentially lost to the program, a phenomenon known as a memory leak. Conversely, it is possible for memory to be freed but continue to be referenced, leading to unpredictable results. Typically, the symptoms will appear in a portion of the program far removed from the actual error, making it difficult to track down the problem. (Such issues are ameliorated in languages with automatic garbage collection.)\\r\\nThe C programming language uses libraries as its primary method of extension. In C, a library is a set of functions contained within a single \\"archive\\" file. Each library typically has a header file, which contains the prototypes of the functions contained within the library that may be used by a program, and declarations of special data types and macro symbols used with these functions. In order for a program to use a library, it must include the library's header file, and the library must be linked with the program, which in many cases requires compiler flags (e.g., -lm, shorthand for \\"link the math library\\").[27]\\r\\nThe most common C library is the C standard library, which is specified by the ISO and ANSI C standards and comes with every C implementation (implementations which target limited environments such as embedded systems may provide only a subset of the standard library). This library supports stream input and output, memory allocation, mathematics, character strings, and time values. Several separate standard headers (for example, stdio.h) specify the interfaces for these and other standard library facilities.\\r\\nAnother common set of C library functions are those used by applications specifically targeted for Unix and Unix-like systems, especially functions which provide an interface to the kernel. These functions are detailed in various standards such as POSIX and the Single UNIX Specification.\\r\\nSince many programs have been written in C, there are a wide variety of other libraries available. Libraries are often written in C because C compilers generate efficient object code; programmers then create interfaces to the library so that the routines can be used from higher-level languages like Java, Perl, and Python.[27]\\r\\nA number of tools have been developed to help C programmers find and fix statements with undefined behavior or possibly erroneous expressions, with greater rigor than that provided by the compiler. The tool lint was the first such, leading to many others.\\r\\nAutomated source code checking and auditing are beneficial in any language, and for C many such tools exist, such as Lint. A common practice is to use Lint to detect questionable code when a program is first written. Once a program passes Lint, it is then compiled using the C compiler. Also, many compilers can optionally warn about syntactically valid constructs that are likely to actually be errors. MISRA C is a proprietary set of guidelines to avoid such questionable code, developed for embedded systems.[34]\\r\\nThere are also compilers, libraries, and operating system level mechanisms for performing actions that are not a standard part of C, such as bounds checking for arrays, detection of buffer overflow, serialization, dynamic memory tracking, and automatic garbage collection.\\r\\nTools such as Purify or Valgrind and linking with libraries containing special versions of the memory allocation functions can help uncover runtime errors in memory usage.\\r\\nC is widely used for system programming in implementing operating systems and embedded system applications,[36] because C code, when written for portability, can be used for most purposes, yet when needed, system-specific code can be used to access specific hardware addresses and to perform type punning to match externally imposed interface requirements, with a low run-time demand on system resources.\\r\\nC can also be used for website programming using CGI as a \\"gateway\\" for information between the Web application, the server, and the browser.[37] C is often chosen over interpreted languages because of its speed, stability, and near-universal availability.[38]\\r\\nOne consequence of C wide availability and efficiency is that compilers, libraries and interpreters of other programming languages are often implemented in C. The reference implementations of Python, Perl and PHP, for example, are all written in C.\\r\\nBecause the layer of abstraction is thin and the overhead is low, C enables programmers to create efficient implementations of algorithms and data structures, useful for computationally intense programs. For example, the GNU Multiple Precision Arithmetic Library, the GNU Scientific Library, Mathematica, and MATLAB are completely or partially written in C.\\r\\nC is sometimes used as an intermediate language by implementations of other languages. This approach may be used for portability or convenience; by using C as an intermediate language, additional machine-specific code generators are not necessary. C has some features, such as line-number preprocessor directives and optional superfluous commas at the end of initializer lists, that support compilation of generated code. However, some of C shortcomings have prompted the development of other C-based languages specifically designed for use as intermediate languages, such as C--.\\r\\nC has also been widely used to implement end-user applications. However, such applications can also be written in newer, higher-level languages.\\r\\nC has both directly and indirectly influenced many later languages such as C#, D, Go, Java, JavaScript, Limbo, LPC, Perl, PHP, Python, and Unix's C shell.[39] The most pervasive influence has been syntactical, all of the languages mentioned combine the statement and (more or less recognizably) expression syntax of C with type systems, data models and/or large-scale program structures that differ from those of C, sometimes radically.\\r\\nSeveral C or near-C interpreters exist, including Ch and CINT, which can also be used for scripting.\\r\\nWhen object-oriented languages became popular, C++ and Objective-C were two different extensions of C that provided object-oriented capabilities. Both languages were originally implemented as source-to-source compilers; source code was translated into C, and then compiled with a C compiler.[40]\\r\\nThe C++ programming language was devised by Bjarne Stroustrup as an approach to providing object-oriented functionality with a C-like syntax.[41] C++ adds greater typing strength, scoping, and other tools useful in object-oriented programming, and permits generic programming via templates. Nearly a superset of C, C++ now supports most of C, with a few exceptions.\\r\\nObjective-C was originally a very \\"thin\\" layer on top of C, and remains a strict superset of C that permits object-oriented programming using a hybrid dynamic/static typing paradigm. Objective-C derives its syntax from both C and Smalltalk: syntax that involves preprocessing, expressions, function declarations, and function calls is inherited from C, while the syntax for object-oriented features was originally taken from Smalltalk.\\r\\nIn addition to C++ and Objective-C, Ch, Cilk and Unified Parallel C are nearly supersets of C.","input":"Where was c originally developed and by whom?"},{"output":"Radamel Falcao","context":"\\r\\n\\r\\nThe Colombia national football team (Spanish: Selecci܇n de f~tbol de Colombia) represents Colombia in international football competitions and is overseen by the Colombian Football Federation. It is a member of the CONMEBOL and is currently ranked 16th in the FIFA World Rankings.[3] The team are nicknamed Los Cafeteros due to the coffee production in their country.\\r\\n\\r\\nSince the mid-1980s, the national team has been a symbol fighting the country's negative reputation. This has made the sport popular and made the national team a sign of nationalism, pride and passion for many Colombians worldwide. Colombia is known for having a passionate fan base.[4][5]\\r\\n\\r\\nColombia had its strongest period during the 1990s. A 1993 match resulted in a 5ÿ0 win over Argentina which began a special \\"mutual respect\\" rivalry between both nations.[6] The goalkeeper Ren Higuita achieved fame from his eccentric scorpion kick clearance against England at Wembley Stadium in 1995. Stars from Colombia's team included Carlos Valderrama and Faustino Asprilla. During this era Colombia qualified for the 1990, 1994, and 1998 World Cups, only reaching the second round in 1990. Following the murder  of Andrs Escobar after the 1994 World Cup, Colombia's team faded in the latter half of the 1990s. They were the champions of the 2001 Copa Amrica, which they hosted and set a new Copa Amrica record of conceding no goals and winning each match. Prior to that success, they were runners-up to Peru in the 1975 Copa Amrica. In total, Colombia has gained a top four result in seven Copa Amricas. Colombia was the first team to win FIFA best mover in 1993 where the achievement was first introduced and the second team after Croatia to win it twice in 2012.[7]\\r\\n\\r\\nColombia missed three World Cups between 2002 and 2010. During the 2014 World Cup qualifiers, Colombia showed improvement over the 2011 Copa Amrica, bringing its rank up to the top ten for the first time since 2002 and into the top five consistently for the first time since 2004. After a 16-year-long wait, in 2014 Colombia finally returned to the World Cup, where they were able to advance to the quarter-finals, the furthest Colombia has ever made it in a World Cup.[7][8] Colombia's midfielder James Rodrguez won two awards, the Golden Boot for most goals (6) and Best Goal of the Tournament.\\r\\n\\r\\nThe 1962 World Cup match against the Soviet Union finished in a 4ÿ4 tie after Colombia had been down 4ÿ1, making it one of the biggest comebacks in World Cup history. In that game, Colombia also scored a direct corner kick goal, also making it the only direct corner kick goal in World Cup history.\\r\\n\\r\\nColombia played its first official matches at the 1938 Central American and Caribbean Games. The Colombia national football team was composed mostly by all the players of the Club Juventud Bogotana (now Millonarios).[9] Alfonso Novoa was the manager of Colombia until 23 February.\\r\\n\\r\\nThe first game was played on 10 February 1938 against Mexico. Colombia was defeated 1ÿ3; Luis Argelles, Luis de la Fuente and Horacio Casarn scored for Mexico, while Marcos Meja scored for Colombia. Colombia was able to obtain the bronze medal, with two wins and three losses. The same year, Colombia played at the I Bolivarian Games in Bogot, where they finished fourth with one win and three losses. Fernando Paternoster was the manager of Colombia, the side's first foreign manager.\\r\\n\\r\\nColombia did not play again until 1945, when they participated for the first time at the South American Championship, finishing in fifth place. This time, Colombia was composed by players of Junior de Barranquilla save for Antonio de la Hoz (who played for Sporting de Barranquilla) and Pedro Ricardo L܇pez (who played for Boca Juniors de Cali).[10] Roberto Melndez was player and coach of Colombia throughout the tournament.\\r\\n\\r\\nThe first match of Colombia in the professional era was played on 6 April in the 1949 South American Championship, a 3ÿ0 defeat against Paraguay. Austrian coach Friedrich Donnenfeld was the manager of Colombia during the tournament; he had moved with his family to Colombia due to World War II, and Atltico Junior would be his first team as a coach.[11] As Junior was chosen to represent Colombia in the tournament, he became in the first European manager of the Colombia national team. The team, however, repeated their losing streak since, as in the previous tournament, ended eighth with two draws and five losses, scoring four goals.\\r\\n\\r\\nAfter a withdrawal in 1938 and getting banned in 1954 (due to the controversial El Dorado era), Colombia participated for the first time in qualifying for the 1958 FIFA World Cup in Sweden. Their first match was on 16 June 1957 against Uruguay in Bogot, a 1ÿ1 draw. Colombia lost their next matches, leaving them at the bottom of the group.\\r\\n\\r\\nAt the 1962 World Cup, Colombia lost their first match, 2ÿ1 against Uruguay. Luis Cubilla and Jorge Sasa scored for Uruguay at the 56th and 75th minute respectively, while Francisco Zuluaga scored a 19th-minute penalty goal for Colombia. In the second match, they earned a 4ÿ4 draw with the Soviet Union, champions of the 1960 European Nations' Cup. In this game, Colombia scored four goals against Soviet goalkeeper Lev Yashin, widely considered the best goalkeeper in football history. Also in that game, Marcos Coll scored the only olympic goal in World Cup history so far. Unfortunately, the Colombian campaign in 1962 ended with a 5ÿ0 defeat against Yugoslavia, who finished in fourth place in the tournament.\\r\\n\\r\\nAt 1990 World Cup, Colombia defeated United Arab Emirates 2ÿ0, lost to Yugoslavia 1ÿ0, and earned their place in the round of 16 after a 1ÿ1 draw with West Germany, who would later win the World Cup. Colombia would be eliminated in their next match against Cameroon with a 2ÿ1 defeat in extra time.\\r\\n\\r\\nFor the 1994 World Cup, Colombia finished top of their qualifying group without having lost a match, which included a historic 5ÿ0 win over Argentina in Buenos Aires. Expectations of the team were high, some even naming them as favourites to win the tournament. Colombia was assigned to the Group A with the hosts United States, Romania, and Switzerland. During the tournament, Colombia only earned one win and suffered two losses, which would eliminate them in the first phase. During the match against the United States, an unwanted incident occurred, when Andrs Escobar scored an own goal, leading to Colombia's elimination. Escobar was later murdered following the own goal in Colombia.\\r\\n\\r\\nColombia ended their qualification for the 1998 World Cup in third place with 28 points, two points below first-place Argentina with 30 points. Colombia was assigned to the Group G alongside Tunisia, England and Romania. Romania obtained a 1ÿ0 victory in the first match. Colombia's second match was a 1ÿ0 win against Tunisia, with a goal from Leider Preciado. In the last match, however, England won the game 2ÿ0, thereby eliminating Colombia.\\r\\n\\r\\nThe 2001 Copa Amrica was the first Copa Amrica held in Colombia. Prior to the tournament, meetings were held by CONMEBOL authorities who were concerned about potential security issues in Colombia, and the tournament was cancelled on 1 July, just ten days before the opening match.[12] On 6 July, CONMEBOL decided to reinstate the tournament, which was held on schedule. Canada had already disbanded its training camp and released its players, so Costa Rica (a CONCACAF invitee) was invited to the tournament. Claiming that Argentine players had received death threats from terrorist groups, the Argentine Football Association decided to withdraw from the competition the day before the first game, with Honduras (a CONCACAF invitee) hastily invited and flown in by the Colombian Air Force to participate.[12] There were no terrorist incidents within the competition. Colombia had a strong run through the tournament, winning their first Copa Amrica title by defeating Mexico (a CONCACAF invitee) with a goal from Ivn C܇rdoba in the second half.\\r\\n\\r\\nFor the 2002 World Cup, Colombia only managed to place sixth in the qualification round, tied with Uruguay, but failing to qualify due to goal difference. Colombia would also eventually fail to qualify for the 2006 edition in Germany and for the 2010 World Cup, mainly because their constant change of formations and struggles to score goals in the last games of the qualification.\\r\\n\\r\\nIn the 2011 Copa Amrica, Colombia made a good run topping their group and achieving a draw to the host nation Argentina, who were the favourites. In the next round, Colombia would be eliminated in a 2ÿ0 loss against Peru in extra time.\\r\\n\\r\\nJackson Martnez on the current generation and its run into the 2014 FIFA World Cup.[13]\\r\\n\\r\\nThe Colombian side gained Leonel lvarez as the new coach following the resignation of Hernn Daro G܇mez, but was sacked after three games with disappointing results, which led in the hiring of Jos Pkerman. The Colombian squad would break a personal qualifying best record, and raise the FIFA ranking consistently into the top ten and allowed them to qualify for the World Cup for the first time in 16 years. Celebrations broke throughout the nation, as many neutrals hailed Colombia as a dark-horse towards being a World Cup contender.[14][15][16][17] Often, Colombia were noted by many figures in Colombia such as Carlos Valderrama as a team that could become the most successful Colombian squad in history.[14][18]\\r\\n\\r\\nColombia topped off their return in the 2014 World Cup after a 16-year absence by defeating Greece 3ÿ0.[19] Colombia then edged a 2ÿ1 victory over the Ivory Coast to dispute Group C's top spot days later.[20] On the same day, Japan and Greece drew 0ÿ0 and automatically qualified Colombia to the round of 16 for the first time in 24 years since the 1990 World Cup.[21] In its final group stage game, Colombia defeated Japan 4ÿ1 to win Group C and become the third South American team (following Brazil and Argentina) to go 3ÿ0 in group stage in World Cup history. The Japan match also saw goalkeeper Faryd Mondrag܇n, the last active player from the country's previous World Cup appearance in 1998, become the oldest player ever to appear in a World Cup final tournament. Colombia went on to defeat Uruguay 2ÿ0 on 28 June in the knockout round, securing a spot in the quarter-finals for the first time in their history. Colombia then fell to hosts Brazil 2ÿ1 in the quarter-final round in controversy, where media and figures such as Diego Maradona criticized FIFA and Carlos Velasco Carballo for \\"favoring\\" Brazil and being biased in disallowing a goal from Mario Yepes and allowing too many fouls by the Brazilians to occur without any yellow cards being shown.[22][23][24][25][26][27]\\r\\n\\r\\nDespite the elimination, the national team was greeted by tens of thousands of Colombians in Bogot, welcoming them back as heroes and restoring pride to the nation.[28][29] Colombia would then receive the FIFA Fair Play Trophy and have James Rodrguez and Juan Cuadrado end as the World Cup's leading goal scorer and assist leader, respectively.[30][31]\\r\\n\\r\\nColombia had a disappointing 2015 Copa Amrica, having won only a single game during the group stage match against Brazil, with their only goal of the tournament. Colombia would be eliminated by Argentina in the next round via penalty shootout, ending their campaign with one win, two draws and one loss. Only one goal was scored for throughout the tournament, by Jeison Murillo, who would later win the tournament's Best Young Player award and be included in the tournament's Star XI.\\r\\n\\r\\nColombia began their campaign with a 0ÿ2 victory against hosts United States. Days later, they sealed their qualification to the quarter-finals with a 2ÿ1 victory against Paraguay. However, they fell to Costa Rica 2ÿ3 and finished second in the group following a complete change with 11 of their starters. On 17 June, they advanced to the semi-finals with a win against Peru on penalties 4ÿ2 in front of 79,000 fans at MetLife Stadium. Colombia would then lose (2ÿ0) to eventual tournament winners Chile following mistakes by their defence. Colombia won the third-place match against the United States to seal their best result since winning the 2001 tournament.\\r\\n\\r\\nColombia qualified for the 2018 FIFA World Cup and drew a challenging group; playing with Japan, Poland and Senegal.[32] The team was nevertheless considered the group favorites, but began their campaign with an unexpected 2ÿ1 defeat to Japan, with Carlos Snchez being sent off after just three minutes of play.[33][34][35] Colombia resurrected their hopes of advancing from the group with a 3ÿ0 win over Poland, whose own chances of advancing were ended with the defeat. After the match, head coach Jos Pkerman dedicated the win to Carlos Snchez.[36][37][38] On 28 June, Colombia beat Senegal by a scoreline of 1ÿ0, topping their group and advancing into the round of sixteen.[39][40][41] On 3 July in Moscow, Colombia were knocked out by England in the round of 16; the game finished 1ÿ1 after extra time, with England winning 4ÿ3 on penalties.[42][43]\\r\\n\\r\\nMatch referee Mark Geiger proved to be controversial, with criticism from both sets of teams.[44] Colombia captain Radamel Falcao and Manager Jose Pekerman both accused Geiger of favouring the England team during the game.[45][46] Diego Maradona once again claimed favoritism against Colombia, citing that \\"England's penalty was a terrible call and that the ref won the match for England\\" and that Colombia were victims of a \\"monumental robbery\\".[47][48][49][50] In response, FIFA said Maradona's comments were \\"entirely inappropriate\\" and insinuations about the referee \\"completely unfounded\\". A FIFA statement read: Following comments made by Diego Armando Maradona in relation to yesterdays round of 16 game, Colombia vs England, FIFA strongly rebukes the criticism of the performance of the match officials which it considers to have been positive in a tough and highly emotional match.\\r\\nFurthermore, it also considers the additional comments and insinuations made as being entirely inappropriate and completely unfounded. [51][52]\\r\\nMaradona apologized to FIFA and its president, admitting that some of things he said were unacceptable. \\"I said a couple of things and, I admit, some of them are unacceptable,\\" said Maradona on social media.[53]\\r\\n\\r\\nJose Mourinho was also very critical of the English squad, claiming theatrical antics from them as well as the overall refereeing done while stating, \\"I was surprised to see central defenders like Harry Maguire, normally he is a very honest guy, diving in the attacking box asking the referee for VAR. Every team has lots of diving, lots of pretending, lots of putting pressure on the referee. The game loses qualityand for me that was the negative point.[54][55][56]\\r\\n\\r\\nWith political issues with history/culture related nations Ecuador and Venezuela, Colombia has always taken interest. While Colombia has natural rival matches with neighbors Ecuador and Venezuela, the matches are not as popular as the rival matches against Argentina and Brazil.\\r\\n\\r\\nThe historical Colombian 5ÿ0 victory in 1993, beating host Argentina in the 1994 World Cup qualifiers, was the very first time Argentina lost in its home stadium Estadio Monumental Antonio Vespucio Liberti during a qualifying match for a World Cup. Argentina come as a previous twice World Cup champion. It caused a huge upset and start of a respective rivalries. Unlike other rivalries full of hostility, the ColombianÿArgentine rivalry is more based on \\"respect\\" than a \\"hated\\" relationship always attracting great interest between both nations.[57] Thus, the ColombianÿArgentine rivalry has been considered \\"unique\\" and \\"special\\". In a way, the ColombianÿArgentine relationship is viewed as \\"sparring partners\\" in world football.\\r\\n\\r\\nDuring the 2014 World Cup quarter-finals, Brazil faced Colombia, with the match ending in a 2ÿ1 defeat. A disallowed goal from Colombian captain Mario Yepes would have tied the match for Colombia. Matches afterwards between the two countries have been played with great intensity and hostility. However, following the tragic LaMia Flight 2933 incident in 2016, the rivalry has improved in a less hostile matter; the sportsmanship from Atltico Nacional in regards to  concede the title to allow Chapecoense to be awarded the championship was highly praised amongst not only Brazilians but globally. A unofficial friendly between the two countries was played in 2017 using only domestic players in honor of the plane crash's victims as well as the friendship between the respective domestic clubs.\\r\\n\\r\\nThe following table shows Colombia's all-time international record, correct as of 1 June 2018.[58][59]\\r\\n\\r\\n??Win\\r\\n??Draw\\r\\n??Loss\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nReport (CONMEBOL)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThe following players were called up for the two friendly matches against Venezuela and Argentina on 7 and 11 September 2018 respectively\\r\\nCaps and goals updated as of 3 July 2018 after the match against England.\\r\\n\\r\\nThe following players have been recently called up in the last 12 months.\\r\\n\\r\\n\\r\\n\\r\\n[61]\\r\\n\\r\\n???? Champions?????? Runners-up?????? Third Place?????? Fourth Place??\\r\\n\\r\\n???? Champions?????? Runners-up?????? Third Place?????? Fourth Place??\\r\\n\\r\\nThe following is a list of the Colombian national team managers since its first official match in 1938:[62]\\r\\n\\r\\n Media related to Colombia national football team at Wikimedia Commons","input":"Who is the captain of colombia football team?"},{"output":"August 17, 2018","context":"\\r\\n\\r\\nSweetener is the fourth studio album by American singer Ariana Grande. It was released on August 17, 2018, through Republic Records.[4] The album is the follow-up to her 2016 studio album, Dangerous Woman, and features guest appearances from Pharrell Williams, Nicki Minaj and Missy Elliott.\\r\\n\\r\\nThe lead single, \\"No Tears Left to Cry\\", was released on April 20, 2018, and debuted at number three on the US Billboard Hot 100. \\"The Light Is Coming\\", featuring Minaj, was released as a promotional single on June 20, 2018, along with the pre-order of the album. \\"God Is a Woman\\" was released as the second single on July 13, 2018, and peaked at number 8.\\r\\n\\r\\nThe album debuted at number one on the US Billboard 200, becoming her third to reach the top position in the country. It also topped several international album charts, including in Australia, Belgium, Canada, Ireland, Italy, New Zealand, Norway, Portugal, Spain, Sweden, Switzerland and the United Kingdom.\\r\\n\\r\\nOn November 13, 2016, Grande stated on Snapchat that she had finished her fourth album. She later clarified by saying, \\"I didn't mean to make an album, and I don't know if it's done at all, but I just have a bunch of songs that I really really like. I've been working a lot and have been creating and feeling inspired.\\"[5][6] In December 2017, she confirmed that she was still working on the album.[7]\\r\\n\\r\\nGrande's manager Scooter Braun told Variety that the album has a more mature sound: \\"It's time for [Ariana] to sing the songs that define her ... Whitney, Mariah, Adele ÿ when they sing, that's their song. Ariana has big vocal moments; it's time for her song.\\"[8] Pharrell Williams told Los Angeles Times: \\"The things that [Ariana] has to say on this album, it's pretty next-level.\\"[9] Producers Max Martin and Savan Kotecha were later confirmed to have collaborated with Grande in the album.[10] On December 28, 2017, Grande shared several pictures of her in the studio throughout the year.[11] The following week, Grande shared a snippet from the album on her Instagram, which was later revealed to be a track titled \\"Get Well Soon\\".[12]\\r\\n\\r\\nOn April 16, 2018, it was reported that Grande may move up the lead single release to April 20, 2018, due to labelmate Post Malone's album being released on April 27.[13] On April 17, 2018, Grande announced that the album's lead single, \\"No Tears Left to Cry\\", would be released on April 20, 2018.[14]\\r\\n\\r\\nOn The Tonight Show Starring Jimmy Fallon, Grande announced that her album would be called Sweetener. She said the meaning behind the title is \\"It's kind of about like bringing light to a situation, or to someone's life, or somebody else who brings light to your life, or sweetening the situation.\\"[15] A May 2018 cover article in Time magazine by Sam Lansky notes that, for the first time with this album, Grande \\"took the lead on writing\\".[16] In late May 2018, she announced that the album would feature 15 tracks and three collaborations, which are Missy Elliott, Nicki Minaj and Pharrell Williams.[17]\\r\\n\\r\\nIn early June 2018, Grande announced at Wango Tango that the album would be available for pre-order on June 20, and \\"The Light Is Coming\\" would be released along with it.[18] The second single, \\"God Is a Woman\\", was initially scheduled to be released on July 20, 2018,[19] however, she later moved the release forward a week to July 13.[20] Prior to the album's release, Spencer Kornhaber of The Atlantic commented that the first three singles from the album \\"sparked with a sense of defiance and rattled mortality ... [a] trifecta of pseudo-spiritualism and sneaky innovation. ... Grande's music and videos radiate [intoxicating, unworried confidence]\\".[21]\\r\\n\\r\\n? Ariana Grande on the album's sound.[22]\\r\\n\\r\\nSweetener consists mostly of pop, R&B, and trap songs that include elements of house, funk, neo soul and hip hop music on its beats and productions.[1][2][23] The melodies and harmonies on the album are diverse and include uptempo songs and many different down tempo sentimental ballads.[24] It explores a diversity of other music genres, including tropical house, EDM, synthpop and minimalist urban influences.[25] Stephen Thomas Erlewine from Allmusic stated that the album \\"deepens the R&B inclinations of 2016's Dangerous Woman.\\"[24] In an interview with Zach Sang she said: \\"Listen, the thing that I love most about this project sonically, is that all I really did was sing in my sweet lower register\\".[26]\\r\\n\\r\\nThe album begins with 38-second a cappella intro, \\"Raindrops (An Angel Cried)\\",[27] written by Bob Gaudio and performed by The Four Seasons. The song is known to completely show Grande's vocals.[28] \\"Blazed\\" is a high tempo funk-influenced song.[29] It features vocals and background vocals by Pharrell Williams, who also produced the track.[30] She first admitted the name of the song on her Twitter account.[31] Lyrically, it is about \\"loving someone and being with them.\\"[citation needed] \\"The Light Is Coming\\" merges hip hop and R&B elements.[32] Grande sings the lyrics \\"The light is coming / to give back everything the darkness stole\\". Which is sung over a \\"jittery beat\\" that is used with quick drums and synths.[33][34] It samples a CNN archive clip of a man who is shouting at former senator Arlen Specter at a town hall meeting in Pennsylvania in 2009 concerning healthcare (\\"You wouldn't let anybody speak for this and instead!\\").[35][36] Israel Daramola described the song as a \\"glitchy, thumping\\" dance record with a sample that highlights Grande's \\"nursery rhyme-style melody\\"[37] \\"R.E.M\\" is an R&B song that is built over a smooth doo-wop beat.[1] The song's title stands for \\"rapid eye movement\\", which is where memorable and vivid dreams occur.[38] In an interview with Jimmy Fallon for the Tonight Show, she admitted that \\"R.E.M\\" was her favourite song.[39] She later confirmed on Twitter that \\"R.E.M.\\" is a song based on Beyonc's demo titled \\"Wake Up\\", a leftover from the singer's 2013 self-titled album.[40]\\r\\n\\r\\nThe track \\"God Is a Woman\\" contains lyrics about female sexual empowerment[41] and spirituality;[42] Time described the song as \\"an anthemic, sultry banger\\".[43] a trap-pop song,[44] \\"God Is a Woman\\" contains influences of reggae.[45][46] and is performed in the key of E? minor with a tempo of 72ÿ76 beats per minute.[47] \\"Sweetener\\" (which is the title track) was the first song that Grande recorded for the album, and it features Williams vocals in the background similar to \\"R.E.M\\". Being a trap-inspired song,[24] the chorus contains the lyrics \\"When life deals us cards / Make everything taste like it is salt / Then you come through like the sweetener you are.\\"[48] which symbolises empowerment.[49] \\"Successful\\" is a 90s-inspired neo soul song, that has elements of gospel and trap.[24] Lyrically, it's about \\"girls feeling good about their own individual success.\\"[50] \\"Everytime\\" is a \\"trap-pop\\" song that contains a pop-rap chorus.[23] \\"Breathin\\" is a dance-pop song that contains influences of synthpop.[49][51] It was written by songwriter Peter Svensson.[52] The Independent called the song an \\"emotional highlight\\" and that it is a \\"mental health bop over a good, solid pop beat.\\"[53] Lyrically, it is about Grande's overcoming growth from anxiety.[54]\\r\\n\\r\\n\\"No Tears Left To Cry\\" is a dance-pop and disco song with a UK garage beat.[55][56][1] and was served as the first official single for the album.[57] Lyrically, it is about the Manchester Arena bombing.[58] \\"Borderline\\" is a 90s contemporary R&B song features American rapper Missy Elliott.[24] It's one of Grande's favourites on the album.[59] \\"Better Off\\" is a power ballad that discusses a toxic relationship that Grande was in with former-boyfriend Mac Miller.[60] \\"Goodnight n Go\\" is an EDM song with deep house and tropical influences.[1][24] It contains a sample of \\"Goodnight and Go\\", written and performed by Grande's inspiration Imogen Heap.[61][62] In an interview with Billboard Heap said that \\"it feels like a gift\\". She went on saying: \\"When somebody that famous picks up on a song that has had its day and gives it a second life, it's a real gift. I think she's done a lovely version of it.\\"[63] \\"Pete Davidson\\" is an interlude of the album and has a trap and hip hop production. Lyrically, it is about her then-fianc, Pete Davidson.[24][64][65] \\"Get Well Soon\\" is a soul-ballad that has a laid back R&B melody.[1] At the end of the song, 40 seconds of silence are played as a tribute to the twenty-two victims of the Manchester Arena bombing, which took place after her concert on May 22, 2017.[66][67]\\r\\n\\r\\nGrande went silent on all social media after sharing a snippet of a song from the album on December 31, 2017.[12] On April 17, 2018, Grande broke her silence by sharing a teaser of the album's lead single, \\"No Tears Left to Cry\\", which was released on April 20, 2018, alongside its music video. She first performed the song at Coachella later that night, as a guest during the performance of DJ Kygo. Grande announced the title of the album and several song titles on The Tonight Show Starring Jimmy Fallon on May 1, 2018, shortly before performing \\"No Tears Left to Cry\\".[68] She also opened the 2018 Billboard Music Awards with a performance of the song on May 20, 2018.[69] On June 2, 2018, Grande performed at Wango Tango in California, closing her set with a performance of \\"No Tears Left to Cry\\" and also sharing a snippet of \\"The Light Is Coming\\".[70] \\r\\nOn August 8, 2018, three dates were announced for a series of promotional concerts in the United States, titled The Sweetener Sessions, in partnership with American Express.[71]\\r\\n\\r\\nGrande also announced a world tour in support of the album. The tour, titled Sweetener World Tour is scheduled to begin on March 18, 2019.[72]\\r\\n\\r\\nThe album's lead single, \\"No Tears Left to Cry\\", was released on April 20, 2018 alongside its music video.[14] The track debuted at number three on the US Billboard Hot 100, becoming Grande's ninth Hot 100 top 10 and sixth to debut in the top 10, tying Grande with Lady Gaga and Rihanna in sixth among acts with the most top 10 debuts on the chart.[73] The single made Grande the first artist in the chart's 60-year history to debut in the top 10 with lead single from each of her first four albums.[74]\\r\\n\\r\\nThe second single, \\"God Is a Woman\\", was released on July 13, 2018, with its music video premiering 12 hours after the song's release.[19][20] The single debuted at number eleven on the Hot 100 and peaked at number eight, making it Grande's tenth top ten song on the chart and placing her as the twelfth overall artist and seventh female artist with the most Hot 100 top 10s in the 2010s decade.[75][76]\\r\\n\\r\\n\\"Breathin\\" was released to US contemporary hit radio as the third single from the album on September 18, 2018.[77] The song has reached number 22 on the Hot 100.[78]\\r\\n\\r\\nA promotional single, \\"The Light Is Coming\\", featuring Nicki Minaj, was released on June 20, 2018, along with the pre-order of the album.[18] The song debuted at number 95 on the Billboard Hot 100 and later peaked at number 89, after the release of the album.\\r\\n\\r\\nAt Metacritic, which assigns a normalised rating out of 100 to reviews from mainstream critics, Sweetener has an average score of 81 based on 20 reviews.[80]\\r\\n\\r\\nIn The New York Times, Jon Pareles wrote that Grande's voice \\"can be silky, breathy or cutting, swooping through long melismas or jabbing out short R&B phrases; it's always supple and airborne, never forced.  Ms. Grande sails above any fray, past or present. Her aplomb is her triumph.\\"[85] Brittany Spanos of Rolling Stone called the album \\"a refreshing, cohesive package.  [The producers' approach lets] Grande's easy way with trap phrasing find a home next to her flair for Broadway-esque dramatic runs\\"; it combines \\"the sensual romance of the album's plentiful love songs and the aching heartbreak of the others.\\" Spanos concludes that it is Grande's \\"best album yet, and one of 2018's strongest pop releases to date.[23] Kate Solomon of The Independent commented that with music that is \\"often unexpected, sometimes in a good way, it is an album by an artist in flux ÿ trying to move forward while reluctant to fully relinquish old ideas.\\"[82]\\r\\n\\r\\nWriting for NME, Douglas Greenwood deemed the album \\"[a] confident, accomplished, sometimes left-field collection of pop bangers, proving that she's not shy of experimentation.\\" He also commented that \\"there are a couple of songs on Sweetener that you'd happily leave on the shelf.\\"[49] Similarly, in The Guardian, Alexis Petridis said that \\"her collaborations with Pharrell really push the boundaries. But they make the rest of this album seem formulaic.\\" He considered the album \\"uneven\\", with its attempts to balance out what Grande called a \\"weird\\" record. Petridis felt that \\"the world could use more pop music as imaginative as Sweetener's highlights.\\"[64]\\r\\n\\r\\nNeil McCormick in The Daily Telegraph felt that \\"the quality of the songs is high, although there are moments when they might be trying too hard to demonstrate that the teen queen is all grown up now,\\" and argued, \\"as modern, branded, blockbuster pop albums go, Sweetener is a delightful confection.\\" He commented less favorably about guest rappers Nicki Minaj and Missy Elliott, who \\"sound like they dialled in clichd verses for a pay cheque.\\"[2]\\r\\n\\r\\nIn the United States, Sweetener opened at number one on the US Billboard 200 with 231,000 album-equivalent units, of which 127,000 were from traditional album sales, thus becoming Grande's third number-one album in the United States. It also logged the largest streaming week for a non-hip hop album by a female artist; the songs were streamed 126.7 million times in the album's first week.[86] On the US Billboard Hot 100 chart issue dated September 1, ten songs (nine of which are from Sweetener) appeared simultaneously, placing Grande as the fourth female artist with the most simultaneous entries on the chart by a solo female artist behind Taylor Swift, Beyonc, and Cardi B.[87] Grande also topped the Artist 100 chart the same week due to album sales and song streams.[88] In its second week, Sweetener dropped to number four moving 75,000 equivalent album units,[89] while in its third week, it fell one position to number five moving an additional 56,000 equivalent album units.[90]\\r\\n\\r\\nIn the United Kingdom, Sweetener debuted at number one on the UK Albums Chart, moving 45,000 album-equivalent units.[91] It became her second number-one album in the UK, and her fastest selling album to date.[92] Following its release, two album tracks entered the UK Singles Chart as \\"Breathin\\" debuted at number 8, and \\"Sweetener\\" landed at number 22, while the single \\"God Is a Woman\\" ascended six places to number 6.[93]\\r\\n\\r\\nIn Australia, the album became Grande's third number one on the ARIA Albums Chart,[94] with all 15 of its tracks placing on the ARIA Singles Chart in the same week.[95]\\r\\n\\r\\nNotes\\r\\n\\r\\nCredits adapted from the liner notes of Sweetener.[101]\\r\\n\\r\\nPerformers and musicians\\r\\n\\r\\nProduction\\r\\n\\r\\nArtwork\\r\\n\\r\\n*sales figures based on certification alone^shipments figures based on certification alone","input":"When did ariana grandes new album come out?"},{"output":"Diary of a Wimpy Kid: The Movie","context":"\\r\\n\\r\\nDiary of a Wimpy Kid (sometimes known as Diary of a Wimpy Kid: The Movie) is a 2010 American comedy film directed by Thor Freudenthal and based on Jeff Kinney's book of the same name.[4][5][6] The film stars Zachary Gordon and Robert Capron. Devon Bostick, Rachael Harris, Steve Zahn, and Chlo? Grace Moretz also have prominent roles. It is the first film in the Diary of a Wimpy Kid film series, and was followed by three sequels, Diary of a Wimpy Kid: Rodrick Rules (2011), Diary of a Wimpy Kid: Dog Days (2012) and Diary of a Wimpy Kid: The Long Haul (2017).[7] The film earned $75.7 million on a $15 million budget. It is the only film in the series to be directed by Freudenthal, who was replaced by David Bowers for the rest of the installments. The film was theatrically released on March 19, 2010 in the United States by 20th Century Fox.\\r\\n\\r\\nThe film starts with Rodrick Heffley waking up his brother Greg, saying it is time for school. However, Rodrick tricks Greg, as it is night and school doesn't start for another week. After the title sequence, Greg attends his first day at middle school and discovers the ups and downs, such as the missing stall doors in the boys' bathroom and the difficulties of obtaining a seat during lunch break. During P.E. lessons, he and his best friend Rowley Jefferson escape from a game of Gladiator and learn about a rotten piece of cheese on the basketball court that makes anyone who touches it an outcast, known colloquially as the Cheese Touch. Greg also meets Angie, a girl who isolates herself from the other students to survive. Greg states his intention of becoming the most popular student in school, and also makes it an effort to make Rowley popular as well by changing his style of clothing and looks, and how he wears a backpack..\\r\\n\\r\\nAt the end of the first day, Rowley unintentionally embarrasses both boys by asking Greg if he wants to come over and \\"play\\". Greg looks through Rodrick's yearbook at home and Rodrick catches them, threatening to kill Greg, so in revenge, Greg pees on him. The next day, Greg signs up for wrestling to become popular but suffers back-to-back humiliating losses against Fregley, a weird outcast, and Patty Farrell, Greg's arch-enemy from elementary school. On Halloween, the two boys encounter teenagers while trick or treating who spray a fire extinguisher at them. When Greg threatens to call the cops, the teenagers chase them to his Grandma's house, but Greg and Rowley escape.\\r\\n\\r\\nThe boys join Safety Patrol in an effort to become popular, and they try out for a contest that offers a student a chance to become the new cartoonist for the school paper. After Greg breaks Rowley's arm during a game the boys played, Rowley becomes extremely popular, and wins the contest. Greg becomes jealous of him. During a Safety Patrol assignment, Greg panics when he encounters a truck identical to the teenagers' from Halloween, and hides the kids in a construction zone. Greg is spotted by a neighbor who mistakes him for Rowley. To his own bewilderment, Rowley is suspended from the Patrol, but Greg eventually confesses to Rowley that he was the who was responsible. Upset and feeling betrayed because Greg didn't confess for his actions, Rowley berates Greg for not being a good friend, and that all he cares about is himself, and ends their friendship. Greg is eventually suspended from the Safety Patrol while Rowley is reinstated, Rowley then makes friends with his classmate Collin, who replaces Greg as Rowley's new best friend. \\r\\n\\r\\nGreg decides to pursue popularity without Rowley by joining the school's production of The Wizard of Oz. At tryouts, Greg's soprano voice earns him the role of Dorothy; however, Patty threatens the teacher into casting her instead. Greg signs up as a tree, hoping to throw apples on Patty during the play, but during rehearsal, the trees are told they won't throw apples but sing a song instead. At the performance, Greg refuses to sing as Rodrick is videotaping the performance, and begins throwing apples after Patty throws a huge fit at what Greg has done, ending the play in chaos. \\r\\n\\r\\nLater, Rodrick found an invitation to the mother-son sweetheart dance, which Greg was trying his hardest to hide. Greg retaliates by letting his baby brother Manny read Rodrick's pornographic magazines. Rodrick is grounded for leaving his magazines out in the open where  Manny is able to find them, but Greg fails to reconcile with Rowley.\\r\\n\\r\\nOne day at school, Rowley and Greg confront each other. Patty and the other kids force Greg and Rowley to fight; however, neither of them are good at fighting. The teenagers from Halloween arrive at the scene and catch Rowley and Greg. They force Rowley to eat the Cheese before a teacher forces them to flee. When the other kids notice that the Cheese has been moved from its has been bitten, Greg takes the fall for Rowley by saying he ate it. This mends their friendship but makes Greg an outcast, as he is thought to have the Cheese Touch, so everyone runs away from him except for Rowley and Angie.\\r\\n\\r\\nWhen the yearbooks are published, he and Rowley make the Class Favorites page as \\"Cutest Best Friends.\\" Surprisingly though, people were brave enough to be close to Greg. The last scene in the movie is the photo of Greg and Rowley in the yearbook, and the end credits play with animated scenes from the movie and book.\\r\\n\\r\\nFilming of Diary of a Wimpy Kid was in Vancouver and wrapped up on October 16, 2009. Lucas Cruikshank, best known for creating the web series Fred, had auditioned for the role as Greg Heffley. Even though he was 16 at the time, the crew members were impressed with his performance, but he was \\"too old for the role\\". The role was given to Zachary Gordon, who was 5 years younger than Cruikshank. Cruikshank mentioned this on his official YouTube channel, which was on a video where he talked about his film roles that he didn't get. 7 years later, Cruikshank asked if he could audition again for The Long Haul, but the casting crew still didn't let him.\\r\\n\\r\\nThe official trailer for Wimpy Kid was released virally on January 21, 2010 and was shown in theaters with Tooth Fairy.[8] A poster for the film was released shortly after. Another trailer was shown with Percy Jackson & the Olympians: The Lightning Thief.[9]\\r\\n\\r\\nThe official Facebook account for Wimpy Kid had uploaded three clips from the film, as of March 1, 2010.[10]\\r\\nIn the United Kingdom and Ireland the film was released in cinemas on August 25, 2010.\\r\\n\\r\\nThe soundtrack was released on CD by La La Land Records with the score composed by Theodore Shapiro, containing 34 tracks.\\r\\n\\r\\nA tie-in book, written by Kinney, called The Wimpy Kid Movie Diary was published on March 16, 2010, by Amulet Books (an imprint of Abrams Books). It includes film stills, storyboards, preliminary concept drawings, and also behind the scenes information to humorously chronicle the making of the film. It also includes some new illustrations.[11][12]\\r\\n\\r\\nThe film was released on DVD and Blu-ray on August 3, 2010. The Blu-ray Version features six pages from Rowley's diary, Diary of an Awesome, Friendly Kid.\\r\\n\\r\\nReview aggregator site Rotten Tomatoes gives the film an approval rating of 53%, based on 106 reviews with an average rating of 5.5/10. The website's critical consensus reads, \\"Unlike its bestselling source material, Diary of a Wimpy Kid fails to place a likable protagonist at the center of its middle-school humor ÿ and its underlying message is drowned out as a result.\\"[13] It also holds a rating of 56/100 at Metacritic, based on 26 reviews, indicating \\"mixed or average reviews\\".[14] Roger Ebert gave the film three-and-a-half stars out of four, writing \\"It's nimble, bright and funny. It doesn't dumb down. It doesn't patronize. It knows something about human nature.\\"[15] Glenn Whipp of the Associated Press was less positive, saying, \\"In transferring the clean, precise humor of Kinney's illustrations and prose to the big-screen, the material loses just a bit of its charm.\\"[16] At the Movies host David Stratton gave the film one star while co-host Margaret Pomeranz gave it half a star. Stratton called the film \\"tiresome\\" and said there was \\"nothing remotely interesting in Thor Freudenthal's direction or the screenplay.\\" Pomeranz disliked the character of Greg Heffley, saying \\"I really thought he was unpleasant. I did not want to spend time with him. I could not wait for the end of this film.\\"[17]\\r\\n\\r\\nThe film opened in second place at the weekend box office grossing $22.1 million, behind Alice in Wonderland.[18]\\r\\n\\r\\nDespite a lack of distinctive marketing, Diary of a Wimpy Kid drew a decent crowd, opening to $22.1 million on approximately 3,400 screens at 3,077 sites, notably beating out the heavily hyped The Bounty Hunter. It was the biggest start ever for a non-animated, non-fantasy children's book adaptation. Diary of a Wimpy Kid grossed more in its first three days than other film adaptions to children's novels like How to Eat Fried Worms and Hoot grossed in their entire runs.[18] The film grossed $64,003,625 in North America and $11,696,873 in other territories for a worldwide total of $75,700,498.[19]\\r\\n\\r\\nThree sequels were released in 2011, 2012 and 2017 respectively. Diary of a Wimpy Kid: Rodrick Rules was released on March 25, 2011. It was based on the second book in the series,  Rodrick Rules. Zachary Gordon reprised his role in the film. Diary of a Wimpy Kid: Dog Days was released on August 3, 2012 and is based on The Last Straw and Dog Days, including scenes from both books. An animated short film, Diary of a Wimpy Kid: Class Clown, was released along with the DVD of Diary of a Wimpy Kid: Dog Days. A film based on The Long Haul was released in May 2017 featuring a new cast starring Jason Drucker, Alicia Silverstone, and Tom Everett Scott.","input":"What is the first diary of a wimpy kid movie?"},{"output":"Michael Gaughan","context":"Coordinates: 360041N 1151031W? / ?36.011426N 115.1753W? / 36.011426; -115.1753\\r\\n\\r\\nThe South Point Hotel and Casino consists of a 24-story hotel tower, casino and 90,000 square feet (8,400?m2) convention center located on a 60 acres (24?ha) site along Las Vegas Boulevard in Enterprise, Nevada and adjacent to Silverado Ranch.  The casino is owned and operated by Michael Gaughan and it serves as the primary sponsor of Gaughan's son Brendan Gaughan's race car.\\r\\n\\r\\nThis $500 million project started construction in 2003, under the South Coast name.  Based on advance booking, Coast Casinos announced expansion plans to add additional hotel rooms, with a second tower, for a total of 1,350 rooms.  The foundation was also poured for a possible third tower during the initial construction phase.\\r\\n\\r\\nThe casino received approval to open from the Nevada Gaming Commission on November 17, 2005.  At opening on December 22, 2005, the South Coast was the first megaresort located south of McCarran International Airport and the Las Vegas Strip.  The hotel contained 662 rooms and 800,000 square feet (74,000?m2) of space that was not finished and was available to be converted into restaurant or casino space.\\r\\n\\r\\nIn mid July 2006, it was announced that Michael Gaughan would sell all of his Boyd stock to Boyd Gaming in exchange for full ownership of the South Coast.  The Nevada Gaming Commission approved the sale on October 19, 2006. After the deal closed, the South Coast was renamed South Point on October 24.\\r\\n\\r\\nOn August 24, 2007, the South Point announced an 830-room expansion with construction of the third hotel tower, turning the hotel towers into a \\"T\\"-shaped facility as seen from above. The $95 million expansion, planned for completion in July 2008, would add 10,000 square feet (930?m2) of convention space and 5 food and beverage locations.[1]  The third tower opened on July 21, 2008, with the hotel now offering a total of 2,163 rooms and 160,000 square feet (15,000?m2) of meeting and convention space; the largest of any hotel in Las Vegas that is not on the Strip.[citation needed] An expansion opened in July 2010, and included the new Grandview Lounge,[2] named after the adjacent  Grandview resort timeshare property.[3]","input":"Who owns the south point hotel and casino?"},{"output":"Hugo Grotius (1625), Thomas Hobbes (1651), Samuel Pufendorf (1673), John Locke (1689), Jean-Jacques Rousseau (1762), and Immanuel Kant (1797)","context":"In both moral and political philosophy, the social contract or political contract is a theory or model, originating during the Age of Enlightenment, that typically addresses the questions of the origin of society and the legitimacy of the authority of the state over the individual.[1] Social contract arguments typically posit that individuals have consented, either explicitly or tacitly, to surrender some of their freedoms and submit to the authority of the ruler or magistrate (or to the decision of a majority), in exchange for protection of their remaining rights. The question of the relation between natural and legal rights, therefore, is often an aspect of social contract theory. The term takes its name from The Social Contract (Du contrat social ou Principes du droit politique), a 1762 book by Jean-Jacques Rousseau that discussed this concept.\\r\\nAlthough the antecedents of social contract theory are found in antiquity, in Greek and Stoic philosophy and Roman and Canon Law, the heyday of the social contract was the mid-17th to early 19th centuries, when it emerged as the leading doctrine of political legitimacy. The starting point for most social contract theories is an examination of the human condition absent any political order that Thomas Hobbes termed the \\"state of nature\\".[2] In this condition, individuals' actions are bound only by their personal power and conscience. From this shared starting point, social contract theorists seek to demonstrate, in different ways, why a rational individual would voluntarily consent to give up their natural freedom to obtain the benefits of political order.\\r\\nHugo Grotius (1625), Thomas Hobbes (1651), Samuel Pufendorf (1673), John Locke (1689), Jean-Jacques Rousseau (1762), and Immanuel Kant (1797) are among the most prominent of 17th- and 18th-century theorists of social contract and natural rights. Each solved the problem of political authority in a different way. Grotius posited that individual human beings had natural rights. Thomas Hobbes famously said that in a \\"state of nature\\", human life would be \\"solitary, poor, nasty, brutish and short\\". In the absence of political order and law, everyone would have unlimited natural freedoms, including the \\"right to all things\\" and thus the freedom to plunder, rape, and murder; there would be an endless \\"war of all against all\\" (bellum omnium contra omnes). To avoid this, free men contract with each other to establish political community, i.e. civil society, through a social contract in which they all gain security in return for subjecting themselves to an absolute sovereign, one man or an assembly of men. Though the sovereign's edicts may well be arbitrary and tyrannical, Hobbes saw absolute government as the only alternative to the terrifying anarchy of a state of nature. Hobbes asserted that humans consent to abdicate their rights in favor of the absolute authority of government (whether monarchical or parliamentary). Pufendorf disputed Hobbes's equation of a state of nature with war.[3]\\r\\nAlternatively, John Locke and Jean-Jacques Rousseau have argued that we gain civil rights in return for accepting the obligation to respect and defend the rights of others, giving up some freedoms to do so. The central assertion of social contract approaches is that law and political order are not natural, but are instead human creations. The social contract and the political order it creates are simply the means towards an endthe benefit of the individuals involvedand legitimate only to the extent that they fulfill their part of the agreement. According to Hobbes (in whose view government is not a party to the original contract) citizens are not obligated to submit to the government when it is too weak to act effectively to suppress factionalism and civil unrest. According to other social contract theorists, when the government fails to secure their natural rights (Locke) or satisfy the best interests of society (called the \\"general will\\" in Rousseau), citizens can withdraw their obligation to obey, or change the leadership through elections or other means including, when necessary, violence.\\r\\nLocke believed that natural rights were inalienable, and that the rule of God therefore superseded government authority, and Rousseau believed that democracy (self-rule) was the best way of ensuring the general welfare while maintaining individual freedom under the rule of law. The Lockean concept of the social contract was invoked in the United States Declaration of Independence. Social contract theories were eclipsed in the 19th?century in favor of utilitarianism, Hegelianism, and Marxism, and were revived in the 20th?century, notably in the form of a thought experiment by John Rawls.[3]\\r\\n\\r\\n\\r\\nThe concept of the social contract is posed by Glaucon, as described by Plato in The Republic, Book?II.\\r\\nThey say that to do injustice is, by nature, good; to suffer injustice, evil; but that the evil is greater than the good. And so when men have both done and suffered injustice and have had experience of both, not being able to avoid the one and obtain the other, they think that they had better agree among themselves to have neither; hence there arise laws and mutual covenants; and that which is ordained by law is termed by them lawful and just. This they affirm to be the origin and nature of justice;it is a mean or compromise, between the best of all, which is to do injustice and not be punished, and the worst of all, which is to suffer injustice without the power of retaliation; and justice, being at a middle point between the two, is tolerated not as a good, but as the lesser evil, and honoured by reason of the inability of men to do injustice. For no man who is worthy to be called a man would ever submit to such an agreement if he were able to resist; he would be mad if he did. Such is the received account, Socrates, of the nature and origin of justice.[4]\\r\\nThe social contract theory also appears in Crito, another dialogue from Plato.\\r\\nSocial contract formulations are preserved in many of the world's oldest records.[5] The Buddhist text of the second century BCE, Mahvastu, recounts the legend of Mahasammata. The story goes as follows:\\r\\nIn the early days of the cosmic cycle mankind lived on an immaterial plane, dancing on air in a sort of fairyland, where there was no need of food or clothing, and no private property, family, government or laws. Then gradually the process of cosmic decay began its work, and mankind became earthbound, and felt the need of food and shelter. As men lost their primeval glory, distinctions of class arose, and they entered into agreements with one another, accepting the institution of private property and the family. With this theft, murder, adultery, and other crime began, and so the people met together and decided to appoint one man from among them to maintain order in return for a share of the produce of their fields and herds. He was called \\"the Great Chosen One\\" (Mahasammata), and he received the title of raja because he pleased the people.[6]\\r\\nIn his rock edicts, the Buddhist king Asoka was said to have argued for a broad and far-reaching social contract. The Buddhist vinaya also reflects social contracts expected of the monks; one such instance is when the people of a certain town complained about monks felling saka trees, the Buddha tells his monks that they must stop and give way to social norms.\\r\\nEpicurus seems to have had a strong sense of social contract, with justice and law being rooted in mutual agreement and advantage, as evidenced by these lines, among others, from his Principal Doctrines (see also Epicurean ethics):\\r\\n31. Natural justice is a pledge of reciprocal benefit, to prevent one man from harming or being harmed by another.\\r\\n32. Those animals which are incapable of making binding agreements with one another not to inflict nor suffer harm are without either justice or injustice; and likewise for those peoples who either could not or would not form binding agreements not to inflict nor suffer harm.\\r\\n33. There never was such a thing as absolute justice, but only agreements made in mutual dealings among men in whatever places at various times providing against the infliction or suffering of harm.[7]\\r\\nQuentin Skinner has argued that several critical modern innovations in contract theory are found in the writings from French Calvinists and Huguenots, whose work in turn was invoked by writers in the Low Countries who objected to their subjection to Spain and, later still, by Catholics in England.[8] Francisco Surez (1548ÿ1617), from the School of Salamanca, might be considered an early theorist of the social contract, theorizing natural law in an attempt to limit the divine right of absolute monarchy. All of these groups were led to articulate notions of popular sovereignty by means of a social covenant or contract, and all of these arguments began with proto-\\"state of nature\\" arguments, to the effect that the basis of politics is that everyone is by nature free of subjection to any government.\\r\\nThese arguments, however, relied on a corporatist theory found in Roman law, according to which \\"a populus\\" can exist as a distinct legal entity. Thus, these arguments held that a group of people can join a government because it has the capacity to exercise a single will and make decisions with a single voice in the absence of sovereign authoritya notion rejected by Hobbes and later contract theorists.\\r\\nIn the early 17th century, Grotius (1583ÿ1645) introduced the modern idea that individuals had natural rights that enabled self-preservation, employing this idea as a basis for moral consensus in the face of religious diversity and the rise of natural science. He seeks to find a parsimonious basis for a moral beginning for society, a kind of natural law that everyone could accept. He goes so far as to say in his On the Law of War and Peace that even if we were to concede what we cannot concede without the utmost wickedness, namely that there is no God, these laws would still hold.\\r\\nThe idea was considered incendiary since it suggested that power can ultimately go back to the individuals if the political society that they have set up forfeits the purpose for which it was originally established, which is to preserve themselves. In other words, individual persons are sovereign. Grotius says that the people are sui juris (under their own jurisdiction). People have rights as human beings, but there is a delineation of those rights because of what is possible for everyone to accept morally; everyone has to accept that each person as an individual is entitled to try to preserve himself. Each person should, therefore, avoid doing harm to, or interfering with, another, and any breach of these rights should be punished.\\r\\nThe first modern philosopher to articulate a detailed contract theory was Thomas Hobbes (1588ÿ1679). According to Hobbes, the lives of individuals in the state of nature were \\"solitary, poor, nasty, brutish and short\\", a state in which self-interest and the absence of rights and contracts prevented the \\"social\\", or society. Life was \\"anarchic\\" (without leadership or the concept of sovereignty). Individuals in the state of nature were apolitical and asocial. This state of nature is followed by the social contract.\\r\\nThe social contract was an \\"occurrence\\" during which individuals came together and ceded some of their individual rights so that others would cede theirs (e.g. person?A gives up his/her right to kill person?B if person?B does the same). This resulted in the establishment of the state, a sovereign entity like the individuals now under its rule used to be, which would create laws to regulate social interactions. Human life was thus no longer \\"a war of all against all\\".\\r\\nThe state system, which grew out of the social contract, was, however, also anarchic (without leadership). Just as the individuals in the state of nature had been sovereigns and thus guided by self-interest and the absence of rights, so states now acted in their self-interest in competition with each other. Just like the state of nature, states were thus bound to be in conflict because there was no sovereign over and above the state (i.e. more powerful) capable of imposing some system such as social-contract laws on everyone by force. Indeed, Hobbes' work helped to serve as a basis for the realism theories of international relations, advanced by E. H. Carr and Hans Morgenthau.\\r\\nHobbes wrote in Leviathan (book) that humans (\\"we\\") need the \\"terrour of some Power\\" otherwise humans will not heed the law of reciprocity, i.e. \\"(in summe) doing to others, as wee would be done to\\".[9]\\r\\nJohn Locke's conception of the social contract differed from Hobbes' in several fundamental ways, retaining only the central notion that persons in a state of nature would willingly come together to form a state. Locke believed that individuals in a state of nature would be bound morally, by the Law of Nature, not to harm each other in their lives or possessions, but without government to defend them against those seeking to injure or enslave them, people would have no security in their rights and would live in fear. Locke argued that individuals would agree to form a state that would provide a \\"neutral judge\\", acting to protect the lives, liberty, and property of those who lived within it.[citation needed]\\r\\nWhile Hobbes argued for near-absolute authority, Locke argued for inviolate freedom under law in his Second Treatise of Government. Locke argued that a government's legitimacy comes from the citizens' delegation to the government of their absolute right of violence (reserving the inalienable right of self-defense or \\"self-preservation\\"), along with elements of other rights (e.g. property will be liable to taxation) as necessary to achieve the goal of security through granting the state a monopoly of violence, whereby the government, as an impartial judge, may use the collective force of the populace to administer and enforce the law, rather than each man acting as his own judge, jury, and executionerthe condition in the state of nature.[citation needed]\\r\\nJean-Jacques Rousseau (1712ÿ1778), in his influential 1762 treatise The Social Contract, outlined a different version of social contract theory, as the foundations of political rights based on unlimited popular sovereignty. Although Rousseau wrote that the British were perhaps at the time the freest people on earth, he did not approve of their representative government. Rousseau believed that liberty was possible only where there was direct rule by the people as a whole in lawmaking, where popular sovereignty was indivisible and inalienable. But he also maintained that the people often did not know their \\"real will\\", and that a proper society would not occur until a great leader (\\"the Legislator\\") arose to change the values and customs of the people, likely through the strategic use of religion.\\r\\nRousseau's political theory differs in important ways from that of Locke and Hobbes. Rousseau's collectivism is most evident in his development of the \\"luminous conception\\" (which he credited to Diderot) of the general will. Rousseau argues a citizen cannot pursue his true interest by being an egoist but must instead subordinate himself to the law created by the citizenry acting as a collective.\\r\\n[The social contract] can be reduced to the following terms: Each of us puts his person and all his power in common under the supreme direction of the general will; and in a body we receive each member as an indivisible part of the whole.[10]\\r\\nRousseau's striking phrase that man must \\"be forced to be free\\"[11] should be understood this way: since the indivisible and inalienable popular sovereignty decides what is good for the whole, then if an individual lapses back into his ordinary egoism and disobeys the law, he will be forced to listen to what was decided when the people acted as a collectivity (i.e. as citizens). Thus, the law, inasmuch as it is created by the people acting as a body, is not a limitation of individual freedom, but rather its expression.\\r\\nThus, enforcement of laws, including criminal law, is not a restriction on individual liberty: the individual, as a citizen, explicitly agreed to be constrained if, as a private individual, he did not respect his own will as formulated in the general will. Because laws represent the restraints of civil freedom, they represent the leap made from humans in the state of nature into civil society. In this sense, the law is a civilizing force, and therefore Rousseau believed that the laws that govern a people helped to mold their character.\\r\\nWhile Rousseau's social contract is based on popular sovereignty and not on individual sovereignty, there are other theories espoused by individualists, libertarians, and anarchists that do not involve agreeing to anything more than negative rights and creates only a limited state, if any.\\r\\nPierre-Joseph Proudhon (1809ÿ1865) advocated a conception of social contract that did not involve an individual surrendering sovereignty to others. According to him, the social contract was not between individuals and the state, but rather among individuals who refrain from coercing or governing each other, each one maintaining complete sovereignty upon him- or herself:\\r\\nWhat really is the Social Contract? An agreement of the citizen with the government? No, that would mean but the continuation of [Rousseau's] idea. The social contract is an agreement of man with man; an agreement from which must result what we call society. In this, the notion of commutative justice, first brought forward by the primitive fact of exchange, ... is substituted for that of distributive justice ... Translating these words, contract, commutative justice, which are the language of the law, into the language of business, and you have commerce, that is to say, in its highest significance, the act by which man and man declare themselves essentially producers, and abdicate all pretension to govern each other.\\r\\nBuilding on the work of Immanuel Kant with its presumption of limits on the state,[12] John Rawls (1921ÿ2002), in A Theory of Justice (1971), proposed a contractarian approach whereby rational people in a hypothetical \\"original position\\" would set aside their individual preferences and capacities under a \\"veil of ignorance\\" and agree to certain general principles of justice and legal organization. This idea is also used as a game-theoretical formalization of the notion of fairness.\\r\\nDavid Gauthier \\"neo-Hobbesian\\" theory argues that cooperation between two independent and self-interested parties is indeed possible, especially when it comes to understanding morality and politics.[13] Gauthier notably points out the advantages of cooperation between two parties when it comes to the challenge of the prisoner's dilemma. He proposes that, if two parties were to stick to the original agreed-upon arrangement and morals outlined by the contract, they would both experience an optimal result.[13][14] In his model for the social contract, factors including trust, rationality, and self-interest keep each party honest and dissuade them from breaking the rules.[13][14]\\r\\nPhilip Pettit (b. 1945) has argued, in Republicanism: A Theory of Freedom and Government (1997), that the theory of social contract, classically based on the consent of the governed, should be modified. Instead of arguing for explicit consent, which can always be manufactured, Pettit argues that the absence of an effective rebellion against it is a contract's only legitimacy.\\r\\nAn early critic of social contract theory was Rousseau's friend, the philosopher David Hume, who in 1742 published an essay \\"Of Civil Liberty\\". The second part of this essay, entitled \\"Of the Original Contract\\",[15] stresses that the concept of a \\"social contract\\" is a convenient fiction:\\r\\nAs no party, in the present age can well support itself without a philosophical or speculative system of principles annexed to its political or practical one; we accordingly find that each of the factions into which this nation is divided has reared up a fabric of the former kind, in order to protect and cover that scheme of actions which it pursues. ... The one party [defenders of the absolute and divine right of kings, or Tories], by tracing up government to the DEITY, endeavor to render it so sacred and inviolate that it must be little less than sacrilege, however tyrannical it may become, to touch or invade it in the smallest article. The other party [the Whigs, or believers in constitutional monarchy], by founding government altogether on the consent of the PEOPLE suppose that there is a kind of original contract by which the subjects have tacitly reserved the power of resisting their sovereign, whenever they find themselves aggrieved by that authority with which they have for certain purposes voluntarily entrusted him.\\r\\nHume argued that consent of the governed was the ideal foundation on which a government should rest, but that it had not actually occurred this way in general.\\r\\nMy intention here is not to exclude the consent of the people from being one just foundation of government where it has place. It is surely the best and most sacred of any. I only contend that it has very seldom had place in any degree and never almost in its full extent. And that therefore some other foundation of government must also be admitted.\\r\\nLegal scholar Randy Barnett has argued[16] that, while presence in the territory of a society may be necessary for consent, this does not constitute consent to all rules the society might make regardless of their content. A second condition of consent is that the rules be consistent with underlying principles of justice and the protection of natural and social rights, and have procedures for effective protection of those rights (or liberties). This has also been discussed by O.?A. Brownson,[17] who argued that, in a sense, three \\"constitutions\\" are involved: first, the constitution of nature that includes all of what the Founders called \\"natural law\\"; second, the constitution of society, an unwritten and commonly understood set of rules for the society formed by a social contract before it establishes a government, by which it does establish the third, a constitution of government. To consent, a necessary condition is that the rules be constitutional in that sense.\\r\\nThe theory of an implicit social contract holds that by remaining in the territory controlled by some society, which usually has a government, people give consent to join that society and be governed by its government, if any. This consent is what gives legitimacy to such a government.\\r\\nOther writers have argued that consent to join the society is not necessarily consent to its government. For that, the government must be set up according to a constitution of government that is consistent with the superior unwritten constitutions of nature and society.[17]\\r\\nAccording to the will theory of contract, a contract is not presumed valid unless all parties voluntarily agree to it, either tacitly or explicitly, without coercion. Lysander Spooner, a 19th-century lawyer and staunch supporter of a right of contract between individuals, argued in his essay No Treason that a supposed social contract cannot be used to justify governmental actions such as taxation because government will initiate force against anyone who does not wish to enter into such a contract. As a result, he maintains that such an agreement is not voluntary and therefore cannot be considered a legitimate contract at all.\\r\\nModern Anglo-American law, like European civil law, is based on a will theory of contract, according to which all terms of a contract are binding on the parties because they chose those terms for themselves. This was less true when Hobbes wrote Leviathan; at that time more importance was attached to consideration, meaning a mutual exchange of benefits necessary to the formation of a valid contract, and most contracts had implicit terms that arose from the nature of the contractual relationship rather than from the choices made by the parties. Accordingly, it has been argued that social contract theory is more consistent with the contract law of the time of Hobbes and Locke than with the contract law of our time, and that certain features in the social contract which seem anomalous to us, such as the belief that we are bound by a contract formulated by our distant ancestors, would not have seemed as strange to Hobbes' contemporaries as they do to us.[18]","input":"Who created the concept of a social contract?"},{"output":"luthier","context":"A luthier (/?lu?ti?r/ LOO-ti-?r)[1] is someone who builds or repairs string instruments generally consisting of a neck and a sound box. The word \\"luthier\\" comes from the French word luth, which means lute. A luthier was originally a maker of lutes, but the term now includes makers of stringed instruments such as the violin or classical guitar. A luthier does not make harps or pianos, as these require different skills and construction methods because their strings are secured to a frame.\\r\\nThe craft of making string instruments, or lutherie (sometimes spelled luthiery), is commonly divided into two main categories: makers of stringed instruments that are plucked or strummed, and those that are bowed.[2] Since bowed instruments require a bow, the second category includes a subtype known as a bow maker or archetier. Luthiers may also teach string-instrument making, either through apprenticeship or formal classroom instruction.\\r\\n\\r\\n\\r\\nImportant luthiers who specialized in the instruments of the lute family (lutes, archlutes, theorbos, vihuelas, etc.):\\r\\nand in modern times:\\r\\nTwo important luthiers of the early 19th century connected with the development of the modern classical guitar are Louis Panormo and Georg Staufer.[3] Antonio Torres Jurado is credited with developing the form of classical guitar still in use today. Christian Frederick Martin of Germany developed a form that evolved into the modern steel-string acoustic guitar.\\r\\nThe American luthier Orville Gibson specialized in mandolins, and is credited with creating the archtop guitar. The important 20th-century American luthiers John D'Angelico and Jimmy D'Aquisto made archtop guitars. Lloyd Loar worked briefly for the Gibson Guitar Corporation making mandolins and guitars. His designs for a family of arch top instruments (mandolin, mandola, guitar, et cetera) are held in high esteem by today's luthiers, who seek to reproduce their sound. Paul Bigsby's innovation of the tremolo arm for archtop and electric guitars is still in use today and may have influenced Leo Fender's design for the Stratocaster solid-body electric guitar, as well as the Jaguar and Jazzmaster. Concurrent with Fender's work, guitarist Les Paul independently developed a solid-body electric guitar. These were the first fretted, solid-body electric guitarsthough they were preceded by the cast aluminum \\"frying pan\\", a solid-body electric lap steel guitar developed and eventually patented by George Beauchamp, and built by Adolph Rickenbacher.[4] A company founded by luthier Friedrich Gretsch and continued by his son and grandson, Fred and Fred, Jr., originally made banjos, but is more famous today for its electric guitars. Vintage guitars are often sought by collectors.\\r\\nBowed instruments include: cello, crwth, double bass, erhu, fiddle, hudok, mouthbow, nyckelharpa, hurdy-gurdy, rabab, rebec, sarangi, viol (viola da gamba), viola, viola da braccio, viola d'amore, and violin.\\r\\nThe purported \\"inventor\\" of the violin is Andrea Amati. Amati was originally a lute maker, but turned to the new instrument form of violin in the mid-16th century. He was the progenitor of the famous Amati family of luthiers active in Cremona, Italy until the 18th century. Andrea Amati had two sons. His eldest was Antonio Amati (circa 1537ÿ1607), and the younger, Girolamo Amati (circa 1561ÿ1630). Girolamo is better known as Hieronymus, and together with his brother, produced many violins with labels inside the instrument reading \\"A&H\\". Antonio died having no known offspring, but Hieronymus became a father. His son Nicol (1596ÿ1684) was himself an important master luthier who had several apprentices of note, including Antonio Stradivari[5] (probably), Andrea Guarneri, Bartolomeo Pasta, Jacob Railich, Giovanni Battista Rogeri, Matthias Klotz, and possibly Jacob Stainer. It is even possible Bartolomeo Cristofori, later inventor of the piano, apprenticed under him (although census data does not support this, which paints this as a possible myth).[6]\\r\\nGasparo da Sal of Brescia (Italy) was another important early luthier of the violin family. About 80 of his instruments survive, and around 100 documents that relate to his work. He was also a double bass player and son and nephew of two violin players: Francesco and Agosti, respectively.\\r\\nGasparo Duiffopruggar of Fssen, Germany, was once incorrectly credited as the inventor of the violin. He was likely an important maker, but no documentation survives, and no instruments survive that experts unequivocally know are his.\\r\\nDa Sal made many instruments and exported to France and Spain, and probably to England. He had at least five apprentices: his son Francesco, a helper named Battista, Alexander of Marsiglia, Giacomo Lafranchini andthe most importantGiovanni Paolo Maggini. Maggini inherited da Sal's business in Brescia. Valentino Siani worked with Maggini. In 1620, Maggini moved to Florence.\\r\\nLuthiers born in the mid-17th century include Giovanni Grancino, Carlo Giuseppe Testore, and his sons Carlo Antonio Testore and Paolo Antonio Testore, all from Milan. From Venice[7] the luthiers Matteo Goffriller, Domenico Montagnana, Sanctus Seraphin, and Carlo Annibale Tononi were principals in the Venetian school of violin making (although the latter began his career in Bologna).[8] The Bergonzi family?(pt) of luthiers were the successors to the Amati family in Cremona. David Tecchler, who was born in Austria, later worked in both Venice and Rome.\\r\\nImportant luthiers from the early 18th century include Nicol Gagliano of Naples, Italy, Carlo Ferdinando Landolfi of Milan, and Giovanni Battista Guadagnini, who roamed throughout Italy during his lifetime. From Austria originally, Leopold Widhalm later established himself in Nrnberg, Germany.\\r\\nThe early 19th-century luthiers of the Mirecourt school of violin making in France were the Vuillaume family, Charles Jean Baptiste Collin-Mezin, and Collin-Mezin's son, Charles Collin-Mezin, Jr., Honore Derazey, Nicolas Lupot, Charles Macoutel, Charles Menngand, and Pierre Silvestre. Nicola Utili (also known as Nicola da Castel Bolognese) (Ravenna, Italy, March 1888 ÿ May 1962), beside traditional lute works, experimented the making of \\"pear-shaped\\" violins.\\r\\nThe Jr?me-Thibouville-Lamy firm started making wind instruments around 1730 at La Couture-Boussey, then moved to Mirecourt around 1760 and started making violins, guitars, mandolins, and musical accessories.","input":"What is a person who makes violins called?"},{"output":"More than 93%","context":"Lakshadweep (/l?k???dwi?p/, ?Lak?advؐp?(help{info), Lakshadؐb), formerly known as the Laccadive, Minicoy, and Aminidivi Islands (/?l?k?da?v ?m?n?k???...???m?n?di?vi/),[2] is a group of islands in the Laccadive Sea, 200 to 440?km (120 to 270?mi) off the south western coast of India. The archipelago is a Union Territory and is governed by the Union Government of India. They were also known as Laccadive Islands, although geographically this is only the name of the central subgroup of the group. Lakshadweep comes from Lakshadwipa, which means \\"one hundred thousand islands\\" in Sanskrit.[3][4] The islands form the smallest Union Territory of India: their total surface area is just 32?km2 (12?sq?mi). The lagoon area covers about 4,200?km2 (1,600?sq?mi), the territorial waters area 20,000?km2 (7,700?sq?mi) and the exclusive economic zone area 400,000?km2 (150,000?sq?mi). The region forms a single Indian district with 10 subdivisions. Kavaratti serves as the capital of the Union Territory and the region comes under the jurisdiction of Kerala High Court. The islands are the northernmost of the Lakshadweep-Maldives-Chagos group of islands, which are the tops of a vast undersea mountain range, the Chagos-Laccadive Ridge.[5]\\r\\nAs the islands do not have any aboriginal groups, different views have been postulated by the scholars about the history of habitation on these islands. Archaeological evidence supports the existence of human settlement in the region around 1500 BC. The islands have long been known to sailors, as indicated by an anonymous reference from the first century AD to the region in Periplus of the Erythraean Sea. The islands were referenced also in the Buddhist Jataka stories of the sixth century BC. The arrival of Muslim missionaries around the seventh century led to the advent of Islam in the region. During the medieval period, the region was ruled by the Chola dynasty and Kingdom of Cannanore. The Portuguese arrived around 1498 and were upstaged by 1545. The region was then ruled by the Muslim house of Arakkal, followed by Tipu Sultan. On his death in 1799, most of the region passed on to the British and with their departure, the Union Territory was formed in 1956.\\r\\nTen of the islands are inhabited. At the 2011 Indian census, the population of the Union Territory was 64,473. The majority of the indigenous population is Muslim and most of them belong to the Shafi school of the Sunni sect. The islanders are ethnically similar to the Malayali people of the nearest Indian state of Kerala. Most of the population speaks Malayalam with Mahi (or Mahl) being the most spoken language in Minicoy island. The islands are served by an airport on the Agatti island. The main occupation of the people is fishing and coconut cultivation, with tuna being the main item of export.\\r\\n\\r\\n\\r\\nA mention of the region in the Periplus of the Erythraean Sea, by an anonymous author, is one of the earliest references.[6] There are references to the control of the islands by the Cheras in the Sangam Pati??uppattu. Local traditions and legends attribute the first settlement on these islands to the period of Cheraman Perumal, the last Chera king of Kerala.[7] The oldest inhabited islands in the group are Amini, Kalpeni Andrott, Kavaratti, and Agatti. Archaeological evidence suggests that Buddhism prevailed in the region during the fifth and sixth centuries AD.[6] According to popular tradition, Islam was brought to Lakshadweep by an Arab named Ubaidulla in AD 661. His grave is located on the island of Andrott.[8] During the 11th century, the islands came under the rule of the Late Cholas[6] and subsequently the Kingdom of Cannanore.[9]\\r\\nIn the 16th century, the Portuguese ruled the seas between Ormuz and the Malabar Coast and south to Ceylon. As early as 1498, they took control of the archipelago (called Laquedivas by them), later on to exploit coir production, until the islanders expelled them in 1545. In the 17th century, the islands came under the rule of Ali Rajahs/Arakkal Bheevi of Kannur, who received them as a gift from the Kolathiris. The islands are also mentioned in great detail in the stories of the Arab traveller Ibn Batuta.[10]\\r\\nThe Aminidivi group of islands (Androth, Amini, Kadmat, Kiltan, Chetlath, and Bitra) came under the rule of Tipu Sultan in 1787. They passed to British control after the Third Anglo-Mysore War and were attached to South Canara. The rest of the islands came under the suzerainty of the Arakkal family of Cannanore in return for a payment of annual tribute. The British took over the administration of those islands for nonpayment of arrears. These islands were attached to the Malabar district of the Madras Presidency during the British Raj.[11]\\r\\nOn 1 November 1956, during the reorganization of Indian states, the Lakshadweep islands were separated from Madras organized into a separate union territory for administrative purposes. The new territory was called Laccadive, Minicoy, and Amindivi Islands before adopting the Lakshadweep name on 1 November 1973.[12]\\r\\nTo safeguard India's vital shipping lanes to the Middle East, and the growing relevance of the islands in security considerations, an Indian Navy base, INS Dweeprakshak, was commissioned on Kavaratti island.[13]\\r\\nA DX-pedition (VU7AG) by amateur radio operators was run on Agatti Island during November 2013.\\r\\nLakshadweep is an archipelago of twelve atolls, three reefs and five submerged banks, with a total of about thirty-nine islands and islets. The reefs are in fact also atolls, although mostly submerged, with only small unvegetated sand cays above the high-water mark. The submerged banks are sunken atolls. Almost all the atolls have a northeast-southwest orientation with the islands lying on the eastern rim, and a mostly submerged reef on the western rim, enclosing a lagoon. It has 10 inhabited islands, 17 uninhabited islands, attached islets, 4 newly formed islets and 5 submerged reefs.[14]\\r\\nThe main islands are Kavaratti, Agatti, Minicoy, and Amini. The total population of the territory is 60,595 according to the 2001 census. Agatti has an airport with direct flights from Kochi.\\r\\nThe Aminidivi subgroup of islands (consisting of Amini, Keltan, Chetlat, Kadamat, Bitra, and Perumal Par) and the Laccadive subgroup of islands (comprising mainly Androth, Kalpeni, Kavaratti, Pitti, and Suheli Par), both subgroups having a submarine connection between them through Pitti Bank. Together with Minicoy Island, a lonely atoll located at the southern end of the 200-km-broad Nine Degree Channel, they form the Coral Islands of India in the Arabian Sea. All these islands have been built up by corals and have fringing coral reefs very close to their shores.[15]\\r\\nTwo banks further north are not considered part of the group:\\r\\nThe atolls, reefs, and banks are listed from north to south in the table:\\r\\nThe Lakshadweep Archipelago forms a terrestrial ecoregion together with the Maldives and the Chagos.[16] It has over 600 species of marine fishes, 78 species of corals, 82 species of seaweed, 52 species of crabs, 2 species of lobsters, 48 species of gastropods, 12 species of bivalves, 101 species of birds.[17] It is one of the four coral reef regions in India.[18] The corals are a major attraction for the tourist. Pitti Island, is an important breeding place for sea turtles and for a number of pelagic birds such as the brown noddy (Anous stolidus), lesser crested tern (Sterna bengalensis) and greater crested tern (Sterna bergii).[19] The island has been declared a bird sanctuary.[20] Cetacean diversity off the Lakshadweep Islands and in adjacent areas is higher than other areas although a lack of scientific study results in poor understanding and conservation promoting. These include various whales (e.g. pygmy blue, Bryde's,[21] sperm[22]), smaller cetaceans (e.g. orca,[23] pilot whale[24]) and dolphins.[25][26][27][28]\\r\\nThe region does not have a rich flora and almost all the plants can be found on the mainland of India. There is also an absence of forest in the region. Nearly 400 species of flowering plants have been documented, including three species of sea grasses Cymodocia isoetifolia, Syringodium isoetifolium and Thalassia hemprichii, other angiosperms as Pandanus, Heliotropium foertherianum, Tournefortia argentea and Pemphis acidula as well as fungi, algae, lichens are also found. The common flora of the coral sands include coconut groves and coastal shrubs as Pemphis acidula, Cordia subcordata, Scaevola taccada, Thespesia populnea, Suriana maritima, Dodonaea viscosa, Guettarda speciosa and seaweeds such as sea lettuces, Codium and Hypena.[17][29]\\r\\nLakshadweep forms a single Indian district and is governed by an administrator appointed by the President of India under article 239 of the constitution. The present administrator is Mr. Farooq Khan IPS[30] There are 10 Sub Divisions of the territory. In Minicoy and Agatti the Sub Division is under a Deputy Collector while in the remaining 8 islands developmental activities are coordinated by Sub Divisional Officers. The Collector cum Development Commissioner who is also the District Magistrate oversees matters coming under District Administration, such as revenue, land settlement, law and order. The District Magistrate is assisted by one Additional District Magistrate and Ten Executive Magistrates with respect to enforcement of law and order. Administrator in his capacity as Inspector General of Lakshadweep Police has command and control of the Lakshadweep Police. Administration Secretariat is in Kavaratti.[31] The union territory comes under the jurisdiction of the Kerala High Court at Kochi along with a system of lower courts.[32] The territory elects one member to the Lok Sabha (lower house of the Parliament of India).[33]\\r\\nAccording to the 2011 census Lakshadweep has a population of 64,429,[34] roughly equal in number to that of the Marshall Islands.[35] This gives it a ranking of 627th among the 640 districts in India.[34] The district has a population density of 2,013 inhabitants per square kilometre (5,210/sq?mi).[34] Its population growth rate over the decade 2001-2011 was 6.23%.[34] Lakshadweep has a sex ratio of 946 females for every 1000 males,[34] and a literacy rate of 92.28%.[34]\\r\\nMost people of Lakshadweep are descendants of migrants from the Malabar Coast of southwest India and the islanders are ethnically similar to coastal Kerala's Malayali people. More than 93% of the population who are indigenous, are Muslims and the majority of them belong to the Shafi School of the Sunni Sect. The southernmost and second largest island of Minicoy has an ethnically Mahls population that are native to the Maldives.[14][36]\\r\\nReligion in State (2011)[37]\\r\\nThe inhabitants of Lakshadweep were known to practice different religious customs. Then Islam was propounded by the Sheikh Ubaidullah.[38]\\r\\nThe spread of Islam has contributed to the religious identity of Lakshadweep. Eid-ul-Fitr, Muharram, Eid-ul-Adha and Milad-un-Nabi are the prominent occasions when the people of the island gather in various mosques.\\r\\nReligious observance in Lakshadweep is characterized by certain festivals that are found in its core ethnic groups. Moulood is one such religious event when the islanders offer prayers to the divine power and eat in groups. The festival of Ratheeb is another uncommon occasion which originated in the Kavaratti region of Lakshadweep. The grave of Sheikh Kasim, one of the respected saints is praised during Ratheeb by the people of the island to gather his holy blessings.\\r\\nThe Sunni branch of Islam is the predominant faith.\\r\\nLanguages of Lakshadweep in 2001[39]\\r\\nThe principal languages of Lakshadweep are Malayalam, Jeseri (Dweep Bhasha) and Mahl.[40] The people of all the northern islands speak a dialect of Malayalam with the influence of Tamil and Arabic similar to Arwi. The people of Minicoy, the southernmost atoll, speak Mahl, a variant of Divehi language spoken in the Maldives.\\r\\nMalayalam with Malayalam script was introduced as the official language of Lakshadweep during the British raj. Previously a type of Arabic script (Arabi Malayalam) was used for the language. The policy was continued by the Indian government. Malayalam serves as a link language on the islands including on the Mahl dominated Minicoy Island.[41] The dances here include:-Lava Dance, Kolkali dance & Parichakli Dance.\\r\\nLakshadweep's gross territorial domestic product for 2004 is estimated at US$ 60?million at current prices. There is little economic inequality in Lakshadweep and the poverty index is low. Coconut fibre extraction and production of fibre products is Lakshadweep's main industry. There are five coir fibre factories, five production demonstration centres and seven fibre curling units run by the government of India. These units produce coir fibre, coir yarn, curled fibre and corridor mattings.[42]\\r\\nLakshadweep comprises the only coral atolls of the country. With a vast lagoon of 4,200?km2 (1,600?sq?mi), it has territorial waters of 20,000?km2 (7,700?sq?mi), Exclusive Economic Zone (EEZ) of 4,00,000 lakh (400,000?km2?[150,000?sq?mi]) and coastal line of about 132 kilometres (82?mi). There is an estimation of about one lakh tonnes (100,000 tonnes [110,000 tons]) of tuna and tuna-like fishes and about an equal quantity of shark in the sea around Lakshadweep. Fishing is the main livelihood of the islanders.[43] Freshly caught tuna is processed by drying it in the sun after cooking and smoking. The resultant product, known as 'mas', are popular products exported from these islands to southeast Asian countries.[44] Eleven workshops in islands and two boat building yards cater to the needs of fishermen. There are 375 boats in operation in Lakshadweep.[45]\\r\\nDue to its isolation and scenic appeal, Lakshadweep was already known as a tourist attraction for Indians since 1974.[46] This brings in significant revenue, which is likely to increase. Since such a small region cannot support industries, the government is actively promoting tourism as a means of income in Bangaram and Kadmat islands. Bangaram is projected to become a major destination for international tourism.[47] Marine fauna are plentiful. Water sports activities such as scuba diving, wind surfing, snorkelling, surfing, kayaking, canoeing, water skiing, sportfishing, yachting and night sea voyages are popular activities among tourists. Tourists flock to these islands throughout the year, except during the South-west monsoon months when seas are extremely rough. The government has also proposed to set up two customs clearance check-in offices so that tourists can enter directly instead of getting permission from the nearest customs office in Kochi, which is 260 nautical miles (300?mi; 480?km) from these islands. These will be the smallest customs offices in India. Tourism is expected to get a big boost after these offices open as the islands lie on one of the busiest cruise ways.\\r\\nA low-temperature thermal desalination plant opened on Kavaratti in 2005, at a cost of ?50?million (?922,000). The experimental plant, which uses the temperature difference between warm surface seawater and much colder seawater at 500m depth to generate potable water as well as energy, was slated to produce 100,000?litres/day of potable water from seawater.[50][51] Production costs in 2005 were ?220-250/m3 (?4.1-4.6/m3); the cost was supposed to drop to ?30-60/m3 (?0.55-1.11/m3) with increased capacity.[52]\\r\\nThe technology was developed by the National Institute of Ocean Technology. It can be used to produce drinking water and also for power generation and air conditioning. In addition, the deep seawater contains extra nutrients for fish, an important source of food and income for the local population. The government plans to set up desalination plants with a capacity of 10?million litres/per day on all islands and coastal areas.[50] In 2009, the NIOT announced plans to build plants on Minicoy, Agatti and Andrott.[53]\\r\\nAgatti Aerodrome on Agatti Island is the only airport in Lakshadweep. Alliance Air, a subsidiary of the state-owned carrier, serves Agatti and flies to Kochi and Bengaluru on the mainland. Kingfisher Airlines, had flights connecting Kochi and Bangalore to Agatti before the airline ceased operations. The other islands are linked by the Pawan Hans helicopter or boat service.[54] Six ships connect Kochi, Calicut(Beypore) and Lakshadweep: MV Kavaratti, MV Aminidivi, MV Minicoy, MV Arabian Sea, MV Lakshadweep Sea and MV Bharath Seema.[55]\\r\\nTourists need a permit to visit the islands; foreign nationals are not permitted to visit certain islands.[56] According to the current alcohol laws of India, alcoholic beverage consumption is not permitted in the Lakshadweep Archipelago except on Bangaram Island.[57]","input":"What percentage of the lakshadweep population belongs to the tribal community?"},{"output":"1 July 1997","context":"The transfer of sovereignty over Hong Kong from the United Kingdom to China, referred to as \\"the Handover\\" internationally or \\"the Return\\" in China, took place on 1 July 1997. The landmark event marked the end of British administration in Hong Kong, and is often regarded as marking the end of the British Empire.\\r\\n\\r\\n\\r\\nHong Kong's territory was acquired from three separate treaties: the Treaty of Nanking in 1842, the Convention of Peking in 1860, and The Convention for the Extension of Hong Kong Territory in 1898, which gave the UK the control of Hong Kong Island, Kowloon (area south of Boundary Street), and the New Territories (area north of Boundary Street and south of the Sham Chun River, and outlying islands), respectively.\\r\\nAlthough Hong Kong Island and Kowloon had been ceded to the United Kingdom in perpetuity, the control on the New Territories was a 99-year lease. The finite nature of the 99-year lease did not hinder Hong Kong's development as the New Territories were combined as a part of Hong Kong.\\r\\nHowever, by 1997, it was impractical to separate the three territories and only return the New Territories. In addition, with the scarcity of land and natural resources in Hong Kong Island and Kowloon, the New Territories were being developed with large-scale infrastructures and other developments, with the break-even day lying well past 30 June 1997. Thus, the status of the New Territories after the expiry of the 99-year lease became important for Hong Kong's economic development.[1]\\r\\nWhen the People's Republic of China obtained its seat in the United Nations as a result of the UN General Assembly Resolution 2758 in 1971, it began to act diplomatically on the sovereignty issues of Hong Kong and Macau. In March 1972, the Chinese UN representative, Huang Hua, wrote to the United Nations Decolonization Committee to state the position of the Chinese government:\\r\\nThe same year, on 8 November, the United Nations General Assembly passed the resolution on removing Hong Kong and Macau from the official list of colonies.[2]\\r\\nIn March 1979, the Governor of Hong Kong Murray MacLehose paid his first official visit to the People's Republic of China (PRC), taking the initiative to raise the question of Hong Kong's sovereignty with Deng Xiaoping.[3] Without clarifying and establishing the official position of the PRC government, the arranging of real estate leases and loans agreements in Hong Kong within the next 18 years would become difficult.[1]\\r\\nIn response to concerns over land leases in the New Territories, MacLehose proposed that British administration of the whole of Hong Kong, as opposed to sovereignty, be allowed to continue after 1997.[4] He also proposed that contracts include the phrase \\"for so long as the Crown administers the territory\\".[5]\\r\\nIn fact, as early as the mid-1970s, Hong Kong had faced additional risks raising loans for large-scale infrastructure projects such as its Mass Transit Railway (MTR) system and a new airport. Caught unprepared, Deng asserted the necessity of Hong Kong's return to China, upon which Hong Kong would be given special status by the PRC government.\\r\\nMacLehose's visit to the PRC raised the curtain on the issue of Hong Kong's sovereignty: Britain was made aware of the PRC's aspiration to resume sovereignty over Hong Kong and began to make arrangements accordingly to ensure the sustenance of her interests within the territory, as well as initiating the creation of a withdrawal plan in case of emergency.\\r\\nThree years later, Deng received the former British Prime Minister Edward Heath, who had been dispatched as the special envoy of Prime Minister Margaret Thatcher to establish an understanding of the PRC's view with regards to the question of Hong Kong; during their meeting, Deng outlined his plans to make the territory a special economic zone, which would retain its capitalist system under Chinese sovereignty.[6]\\r\\nIn the same year, Edward Youde, who succeeded MacLehose as the 26th Governor of Hong Kong, led a delegation of five Executive Councillors to London, including Chung Sze-yuen, Lydia Dunn, and Roger Lobo.[7] Chung presented their position on the sovereignty of Hong Kong to Thatcher, encouraging her to take into consideration the interests of the native Hong Kong population in her upcoming visit to China.[7]\\r\\nIn light of the increasing openness of the PRC government and economic reforms on the mainland, the then British Prime Minister Margaret Thatcher sought the PRC's agreement to a continued British presence in the territory.[8]\\r\\nHowever, the PRC took a contrary position: not only did the PRC wish for the New Territories, on lease until 1997, to be placed under the PRC's jurisdiction, it also refused to recognize the \\"unfair and unequal treaties\\" under which Hong Kong Island and Kowloon had been ceded to Britain in perpetuity.[9] Consequently, the PRC recognized only the British administration in Hong Kong, but not British sovereignty.[9]\\r\\nIn the wake of Governor MacLehose's visit, Britain and the PRC established initial diplomatic contact for further discussions of the Hong Kong question, paving the way for Thatcher's first visit to the PRC in September 1982.[10]\\r\\nMargaret Thatcher, in discussion with Deng Xiaoping, reiterated the validity of an extension of the lease of Hong Kong territory, particularly in light of binding treaties, including the Treaty of Nanking in 1842, the Convention of Peking in 1856, and the Convention for the Extension of Hong Kong Territory signed in 1890.\\r\\nIn response, Deng Xiaoping cited clearly the lack of room for compromise on the question of sovereignty over Hong Kong; the PRC, as the successor of Qing Dynasty and the Republic of China on the mainland, would recover the entirety of the New Territories, Kowloon and Hong Kong Island. China considered treaties about Hong Kong as unequal and ultimately refused to accept any outcome that would indicate permanent loss of sovereignty over Hong Kong's area, whatever wording the former treaties had.[11]\\r\\nDuring talks with Thatcher, China planned to invade and seize Hong Kong if the negotiations set off unrest in the colony. Thatcher later said that Deng told her bluntly that China could easily take Hong Kong by force, stating that \\"I could walk in and take the whole lot this afternoon\\", to which she replied that \\"there is nothing I could do to stop you, but the eyes of the world would now know what China is like\\".[12]\\r\\nAfter her visit with Deng in Beijing, Thatcher was received in Hong Kong as the first British Prime Minister to set foot on the territory whilst in office. At a press conference, Thatcher re-emphasised the validity of the three treaties, asserting the need for countries to respect treaties on universal terms: \\"There are three treaties in existence; we stick by our treaties unless we decide on something else. At the moment, we stick by our treaties.\\".[8]\\r\\nAt the same time, at the 5th session of the 5th National People's Congress, the constitution was amended to include a new Article 31 which stated that the country might establish Special Administrative Regions (SARs) when necessary.[13]\\r\\nThe additional Article would hold tremendous significance in settling the question of Hong Kong and later Macau, putting into social consciousness the concept of \\"One country, two systems\\". The concept would prove useful to deploy until the territories were secured and conditions were ripe for its gradual abrogation.\\r\\nA few months after Thatcher's visit to Beijing, the PRC government had yet to open negotiations with the British government regarding the sovereignty of Hong Kong.\\r\\nShortly before the initiation of sovereignty talks, Governor Youde declared his intention to represent the population of Hong Kong at the negotiations. This statement sparked a strong response from the PRC, prompting Deng Xiaoping to denounce talk of \\"the so-called 'three-legged stool'\\", which implied that Hong Kong was a party to talks on its future, alongside Beijing and London.[14]\\r\\nAt the preliminary stage of the talks, the British government proposed an exchange of sovereignty for administration and the implementation of a British administration post-handover.[8]\\r\\nThe PRC government refused, contending that the notions of sovereignty and administration were inseparable, and although it recognised Macau as a \\"Chinese territory under Portuguese administration\\", this was only temporary.[15]\\r\\nIn fact, during informal exchanges between 1979 and 1981, the PRC had proposed a \\"Macau solution\\" in Hong Kong, under which it would remain under British administration at China's discretion.[3]\\r\\nHowever, this had previously been rejected following the 1967 Leftist riots, with the then Governor, David Trench, claiming the leftists' aim was to leave the UK without effective control, or \\"to Macau us\\".[16]\\r\\nThe conflict that arose at that point of the negotiations ended the possibility of further negotiation. During the reception of former British Prime Minister Edward Heath during his sixth visit to the PRC, Deng Xiaoping commented quite clearly on the impossibility of exchanging sovereignty for administration, declaring an ultimatum: the British government must modify or give up its position or the PRC will announce its resolution of the issue of Hong Kong sovereignty unilaterally.[17]\\r\\nIn 1983, Typhoon Ellen ravaged Hong Kong, causing great amounts of damage to both life and property.[18] The Hong Kong dollar plummeted on Black Saturday, and the Financial Secretary John Bremridge publicly associated the economic uncertainty with the instability of the political climate.[19] In response, the PRC government condemned Britain through the press for \\"playing the economic card\\" in order to achieve their ends: to intimidate the PRC into conceding to British demands.[20]\\r\\nGovernor Youde with nine members of the Hong Kong Executive Council travelled to London to discuss with Prime Minister Thatcher the crisis of confidencethe problem with morale among the people of Hong Kong arising from the ruination of the Sino-British talks. The session concluded with Thatcher's writing of a letter addressed to the PRC Premier Zhao Ziyang.\\r\\nIn the letter, she expressed Britain's willingness to explore arrangements optimising the future prospects of Hong Kong while utilising the PRC's proposals as a foundation. Furthermore, and perhaps most significantly, she expressed Britain's concession on its position of a continued British presence in the form of an administration post-handover.\\r\\nTwo rounds of negotiations were held in October and November. On the sixth round of talks in November, Britain formally conceded its intentions of either maintaining a British administration in Hong Kong or seeking some form of co-administration with the PRC, and showed its sincerity in discussing PRC's proposal on the 1997 issue. Obstacles were cleared.\\r\\nSimon Keswick, chairman of Jardine Matheson & Co., said they were not pulling out of Hong Kong, but a new holding company would be established in Bermuda instead.[21] The PRC took this as yet another plot by the British. The Hong Kong government explained that it had been informed about the move only a few days before the announcement. The government would not and could not stop the company from making a business decision.\\r\\nJust as the atmosphere of the talks was becoming cordial, members of the Legislative Council of Hong Kong felt impatient at the long-running secrecy over the progress of Sino-British talks on the Hong Kong issue. A motion, tabled by legislator Roger Lobo, declared \\"This Council deems it essential that any proposals for the future of Hong Kong should be debated in this Council before agreement is reached\\", was passed unanimously.[22]\\r\\nThe PRC attacked the motion furiously, referring to it as \\"somebody's attempt to play the three-legged stool trick again\\".[23] At length, the PRC and Britain initiated the Joint Declaration on the question of Hong Kong's future in Beijing. Zhou Nan, the then PRC Deputy Foreign Minister and leader of the negotiation team, and Sir Richard Evans, British Ambassador to Beijing and leader of the team, signed respectively on behalf of the two governments.[24]\\r\\nThe Sino-British Joint Declaration was signed by the Prime Ministers of the People's Republic of China and the United Kingdom governments on 19 December 1984 in Beijing. The Declaration entered into force with the exchange of instruments of ratification on 27 May 1985 and was registered by the People's Republic of China and United Kingdom governments at the United Nations on 12 June 1985.\\r\\nIn the Joint Declaration, the People's Republic of China Government stated that it had decided to resume the exercise of sovereignty over Hong Kong (including Hong Kong Island, Kowloon, and the New Territories) with effect from 1 July 1997 and the United Kingdom Government declared that it would restore Hong Kong to the PRC with effect from 1 July 1997. In the document, the People's Republic of China Government also declared its basic policies regarding Hong Kong.\\r\\nIn accordance with the \\"One Country, Two Systems\\" principle agreed between the United Kingdom and the People's Republic of China, the socialist system of the People's Republic of China would not be practised in the Hong Kong Special Administrative Region (HKSAR), and Hong Kong's previous capitalist system and its way of life would remain unchanged for a period of 50 years. This would have left Hong Kong unchanged until 2047.\\r\\nThe Joint Declaration provided that these basic policies should be stipulated in the Hong Kong Basic Law. The ceremony of the signing of the Sino-British Joint Declaration took place at 18:00, 19 December 1984 at the Western Main Chamber of the Great Hall of the People. The Hong Kong and Macao Affairs Office at first proposed a list of 60-80 Hong Kong people to attend the ceremony. The number was finally extended to 101.\\r\\nThe list included Hong Kong government officials, members of the Legislative and Executive Councils, chairmen of the Hongkong and Shanghai Banking Corporation and Standard Chartered Bank, prominent businessmen such as Li Ka-shing, Pao Yue-kong and Fok Ying-tung, and also Martin Lee Chu-ming and Szeto Wah.\\r\\nThe Basic Law was drafted by a Drafting Committee composed of members from both Hong Kong and mainland China. A Basic Law Consultative Committee formed purely by Hong Kong people was established in 1985 to canvas views in Hong Kong on the drafts.\\r\\nThe first draft was published in April 1988, followed by a five-month public consultation exercise. The second draft was published in February 1989, and the subsequent consultation period ended in October 1989.\\r\\nThe Basic Law was formally promulgated on 4 April 1990 by the NPC, together with the designs for the flag and emblem of the HKSAR. Some members of the Basic Law drafting committee were ousted by Beijing following the 4 June 1989 Tiananmen Square protests, after voicing views supporting the students.\\r\\nThe Basic Law was said to be a mini-constitution drafted with the participation of Hong Kong people. The political system had been the most controversial issue in the drafting of the Basic Law. The special issue sub-group adopted the political model put forward by Louis Cha. This \\"mainstream\\" proposal was criticised for being too conservative.[citation needed]\\r\\nAccording to Clauses 158 and 159 of the Basic Law, powers of interpretation and amendment of the Basic Law are vested in the Standing Committee of the National People's Congress and the National People's Congress, respectively. Hong Kong's people have limited influence.\\r\\nAfter the Tiananmen Square protests of 1989, the Executive Councillors and the Legislative Councillors unexpectedly held an urgent meeting, in which they agreed unanimously that the British Government should give the people of Hong Kong the right of abode in the United Kingdom.[25]\\r\\nMore than 10,000 Hong Kong residents rushed to Central in order to get an application form for residency in the United Kingdom. On the eve of the deadline, over 100,000 lined up overnight for a BN(O) application form. While mass migration did begin well before 1989, the event did lead to the peak migration year in 1992 with 66,000 leaving.[26]\\r\\nMany citizens were pessimistic towards the future of Hong Kong and the transfer of the region's sovereignty. A tide of emigration, which was to last for no less than five years, broke out. At its peak, citizenship of small countries, such as Tonga, was also in great demand.[27]\\r\\nSingapore, which also had a predominantly Chinese population, was another popular destination, with the country's Commission (now Consulate-General) being besieged by anxious Hong Kong residents.[28] By September 1989, 6000 applications for residency in Singapore had been approved by the Commission.[29]\\r\\nSome consul staff were suspended or arrested for their corrupt behaviour in granting immigration visas. In April 1997, the acting immigration officer at the US Consulate-General, James DeBates, was suspended after his wife was arrested for smuggling of Chinese migrants into the United States.[30] The previous year, his predecessor, Jerry Stuchiner, had been arrested for smuggling forged Honduran passports into the territory before being sentenced to 40 months in prison.[31]\\r\\nCanada (Vancouver and Toronto), United Kingdom (London, Glasgow, and Manchester), Australia (Sydney and Melbourne), and the United States (San Francisco and New York) were, by and large, the most popular destinations. The United Kingdom devised the British Nationality Selection Scheme, granting 50,000 families British citizenship under the British Nationality Act (Hong Kong) 1990.[32]\\r\\nVancouver was among the most popular destinations, earning the nickname of \\"Hongcouver\\".[33] Richmond, a suburb of Vancouver, was nicknamed \\"Little Hong Kong\\".[34] Other popular settlements are found in Auckland, New Zealand and Dublin, Ireland. All in all, from the start of the settlement of the negotiation in 1984 to 1997, nearly 1 million people emigrated; consequently, Hong Kong suffered serious loss of capital.[35]\\r\\nChris Patten became the last governor of Hong Kong. This was regarded as a turning point in Hong Kong's history. Unlike his predecessors, Patten was not a diplomat, but a career politician and former Member of Parliament. He introduced democratic reforms which pushed PRCÿBritish relations to a standstill and affected the negotiations for a smooth handover.\\r\\nPatten introduced a package of electoral reforms in the Legislative Council. These reforms proposed to enlarge the electorate, thus making voting in the Legislative Council more democratic. This move posed significant changes because Hong Kong citizens would have the power to make decisions regarding their future.\\r\\nThe handover ceremony was held at the new wing of the Hong Kong Convention and Exhibition Centre in Wan Chai on the night of 30 June 1997.\\r\\nThe principal British guest was Prince Charles, who read a farewell speech on behalf of the Queen. The newly elected Prime Minister, Tony Blair, the Foreign Secretary Robin Cook, the departing Governor Chris Patten and General Sir Charles Guthrie, Chief of the Defence Staff, also attended.\\r\\nRepresenting the People's Republic of China were the President, Jiang Zemin, the Premier, Li Peng, and the first Chief Executive Tung Chee-hwa. The event was broadcast around the world.[36][37]\\r\\nAfter the Tiananmen Square protests of 1989, the Hong Kong government proposed a grand \\"Rose Garden Project\\" to restore faith and solidarity among the residents.[124] As the construction of the new Hong Kong International Airport would extend well after the handover, Governor Wilson met PRC Premier Li Peng in Beijing to ease the mind of the PRC government.[125]\\r\\nThe communist press published stories that the project was an evil plan to bleed Hong Kong dry before the handover, leaving the territory in serious debt.[126] After three years of negotiations, Britain and the PRC finally reached an agreement over the construction of the new airport, and signed a Memorandum of Understanding.[127] Removing hills and reclaiming land, it took only a few years to construct the new airport.\\r\\nThe Walled City was originally a single fort built in the mid-19th century on the site of an earlier 17th century watch post on the Kowloon Peninsula of Hong Kong.[128] After the ceding of Hong Kong Island to Britain in 1842 (Treaty of Nanjing), Manchu Qing Dynasty authorities of China felt it necessary for them to establish a military and administrative post to rule the area and to check further British influence in the area.\\r\\nThe 1898 Convention which handed additional parts of Hong Kong (the New Territories) to Britain for 99 years excluded the Walled City, with a population of roughly 700. It stated that China could continue to keep troops there, so long as they did not interfere with Britain's temporary rule.\\r\\nBritain quickly went back on this unofficial part of the agreement, attacking Kowloon Walled City in 1899, only to find it deserted. They did nothing with it, or the outpost, and thus posed the question of Kowloon Walled City's ownership squarely up in the air. The outpost consisted of a yamen, as well as buildings which grew into low-lying, densely packed neighbourhoods from the 1890s to 1940s.\\r\\nThe enclave remained part of Chinese territory despite the turbulent events of the early 20th century that saw the fall of the Qing government, the establishment of the Republic of China and later, a Communist Chinese government (PRC).\\r\\nSquatters began to occupy the Walled City, resisting several attempts by Britain in 1948 to drive them out. The Walled City became a haven for criminals and drug addicts, as the Hong Kong Police had no right to enter the City and China refused maintainability. The 1949 foundation of the People's Republic of China added thousands of refugees to the population, many from Guangdong; by this time, Britain had had enough, and simply adopted a \\"hands-off\\" policy.\\r\\nA murder that occurred in Kowloon Walled City in 1959 set off a small diplomatic crisis, as the two nations each tried to get the other to accept responsibility for a vast tract of land now virtually ruled by anti-Manchurian Triads.\\r\\nAfter the Joint Declaration in 1984, the PRC allowed British authorities to demolish the City and resettle its inhabitants. The mutual decision to tear down the walled city was made in 1987.[129] The government spent up to HK$ 3 billion to resettle the residents and shops.\\r\\nSome residents were not satisfied with the compensation, and some even obstructed the demolition in every possible way.[130] Ultimately, everything was settled, and the Walled City became a park.[131]\\r\\nRennie's Mill got its name from a Canadian businessman named Alfred Herbert Rennie, who established a flour mill at Junk Bay. The business failed, and Rennie hanged himself there in 1908. The incident gave the Chinese name for the site Tiu Keng Leng (?X), meaning \\"Hanging (neck) Ridge\\". The name was later formally changed to similar-sounding Tiu King Leng (?X) because it was regarded as inauspicious.\\r\\nIn the 1950s the (British) Government of Hong Kong settled a considerable number of refugees from Chinaformer Nationalist soldiers and other Kuomintang supportersat Rennie's Mill, following the Chinese civil war. For many years the area was a Kuomintang enclave known as \\"Little Taiwan\\", with the flag of the Republic of China flying, its own school system and practically off-limits to the Royal Hong Kong Police Force.\\r\\nIn 1996 the Hong Kong government finally forcibly evicted Rennie's Mill's residents, ostensibly to make room for new town developments, as part of the Tseung Kwan O New Town, but widely understood to be a move to please the Communist Chinese government before Hong Kong reverted to Communist Chinese rule in 1997.\\r\\nBefore the eviction, Rennie's Mill could be reached by the winding, hilly and narrow Po Lam Road South. At that time, Rennie's Mill's only means of public transport were the routes 90 and 290 of Kowloon Motor Bus, which were operated by minibuses, and by water transport.\\r\\nThe Republic of China on Taiwan promulgated the Laws and Regulations Regarding Hong Kong & Macao Affairs on 2 April 1997 by Presidential Order, and the Executive Yuan on 19 June 1997 ordered the provisions pertaining to Hong Kong to take effect on 1 July 1997.[132]\\r\\nThe United StatesÿHong Kong Policy Act or more commonly known as the Hong Kong Policy Act (P.L no. 102-383m 106 Stat. 1448) is a 1992 act enacted by the United States Congress. It allows the United States to continue to treat Hong Kong separately from China for matters concerning trade export and economics control after the handover.[133]\\r\\nThe United States was represented by then Secretary of State Madeleine Albright at the Hong Kong handover ceremony.[134] However, she partially boycotted it in protest of China's dissolution of the democratically elected Hong Kong legislature.[135]\\r\\nScholars have begun to study the complexities of the transfer as shown in the popular media, such as films, television and video and online games. For example, Hong Kong director Fruit Chan made a sci-fi thriller The Midnight After (2014) that stressed the sense of loss and alienation represented by survivors in an apocalyptic Hong Kong. Chan infuses a political agenda in the film by playing on Hong Kongers' collective anxiety towards communist China.[136] Yiman Wang has argued that America has viewed China through the prisms of films from Shanghai and Hong Kong, with a recent emphasis on futuristic disaster films set in Hong Kong after the transfer goes awry.[137]","input":"When did hong kong became part of china?"},{"output":"a pair of aortic arches rings the coelom","context":"An earthworm is a tube-shaped, segmented worm found in the phylum Annelida. Earthworms are commonly found living in soil, feeding on live and dead organic matter. An earthworm's digestive system runs through the length of its body. It conducts respiration through its skin. It has a double transport system composed of coelomic fluid that moves within the fluid-filled coelom and a simple, closed blood circulatory system. It has a central and a peripheral nervous system. The central nervous system consists of two ganglia above the mouth, one on either side, connected to a nerve cord running back along its length to motor neurons and sensory cells in each segment. Large numbers of chemoreceptors are concentrated near its mouth. Circumferential and longitudinal muscles on the periphery of each segment enable the worm to move. Similar sets of muscles line the gut, and their actions move the digesting food toward the worm's anus.[2]\\r\\nEarthworms are hermaphroditesÿeach individual carries both male and female sex organs. They lack either an internal skeleton or exoskeleton, but maintain their structure with fluid-filled coelom chambers that function as a hydrostatic skeleton.\\r\\n\\"Earthworm\\" is the common name for the largest members of Oligochaeta (which is either a class or a subclass depending on the author). In classical systems, they were placed in the order Opisthopora, on the basis of the male pores opening posterior to the female pores, though the internal male segments are anterior to the female. Theoretical cladistic studies have placed them, instead, in the suborder Lumbricina of the order Haplotaxida, but this may again soon change. Folk names for the earthworm include \\"dew-worm\\", \\"rainworm\\", \\"night crawler\\", and \\"angleworm\\" (due to its use as fishing bait).\\r\\nLarger terrestrial earthworms are also called megadriles (which translates to \\"big worms\\"), as opposed to the microdriles (\\"small worms\\") in the semiaquatic families Tubificidae, Lumbricidae, and Enchytraeidae, among others. The megadriles are characterized by having a distinct clitellum (which is more extensive than that of microdriles) and a vascular system with true capillaries.\\r\\nEarthworms are far less abundant in disturbed environments and are typically active only if water is present.[3]\\r\\n\\r\\n\\r\\nDepending on the species, an adult earthworm can be from 10?mm (0.39?in) long and 1?mm (0.039?in) wide to 3?m (9.8?ft) long and over 25?mm (0.98?in) wide, but the typical Lumbricus terrestris grows to about 360?mm (14?in) long.[4] Probably the longest worm on confirmed records is Amynthas mekongianus that extends up to 3?m (10?ft) [5] in the mud along the banks of the 4,350?km (2,703?mi) Mekong River in Southeast Asia.\\r\\nFrom front to back, the basic shape of the earthworm is a cylindrical tube, divided into a series of segments (called metamerisms) that compartmentalize the body. Furrows are generally[6] externally visible on the body demarking the segments; dorsal pores and nephridiopores exude a fluid that moistens and protects the worm's surface, allowing it to breathe. Except for the mouth and anal segments, each segment carries bristle-like hairs called lateral setae[7] used to anchor parts of the body during movement;[8] species may have four pairs of setae on each segment or more than eight sometimes forming a complete circle of setae per segment.[7] Special ventral setae are used to anchor mating earthworms by their penetration into the bodies of their mates.[citation needed]\\r\\nGenerally, within a species, the number of segments found is consistent across specimens, and individuals are born with the number of segments they will have throughout their lives. The first body segment (segment number 1) features both the earthworm's mouth and, overhanging the mouth, a fleshy lobe called the prostomium, which seals the entrance when the worm is at rest, but is also used to feel and chemically sense the worm's surroundings. Some species of earthworm can even use the prehensile prostomium to grab and drag items such as grasses and leaves into their burrow.\\r\\nAn adult earthworm develops a belt-like glandular swelling, called the clitellum, which covers several segments toward the front part of the animal. This is part of the reproductive system and produces egg capsules. The posterior is most commonly cylindrical like the rest of the body, but depending on the species, may also be quadrangular, octagonal, trapezoidal, or flattened. The last segment is called the periproct; the earthworm's anus, a short vertical slit, is found on this segment.[7]\\r\\nThe exterior of an individual segment is a thin cuticle over skin, commonly pigmented red to brown, which has specialized cells that secrete mucus over the cuticle to keep the body moist and ease movement through soil. Under the skin is a layer of nerve tissue, and two layers of musclesa thin outer layer of circular muscle, and a much thicker inner layer of longitudinal muscle.[9] Interior to the muscle layer is a fluid-filled chamber called a coelom[10] that by its pressurization provides structure to the worm's boneless body. The segments are separated from each other by septa (the plural of \\"septum\\")[11] which are perforated transverse walls, allowing the coelomic fluid to pass between segments.[12] A pair of structures called nephrostomes are located at the back of each septum; a nephric tubule leads from each nephrostome through the septum and into the following segment. This tubule then leads to the main body fluid filtering organ, the nephridium or metanephridium, which removes metabolic waste from the coelomic fluid and expels it through pores called nephridiopores on the worm's sides; usually two nephridia (sometimes more) are found in most segments.[13] At the center of a worm is the digestive tract, which runs straight through from mouth to anus without coiling, and is flanked above and below by blood vessels (the dorsal blood vessel and the ventral blood vessel as well as a subneural blood vessel) and the ventral nerve cord, and is surrounded in each segment by a pair of pallial blood vessels that connect the dorsal to the subneural blood vessels.\\r\\nMany earthworms can eject coelomic fluid through pores in the back in response to stress; Australian Didymogaster sylvaticus (known as the \\"blue squirter earthworm\\") can squirt fluid as high as 30?cm (12?in).[12]\\r\\nThe earthworm's nervous system has three parts: the central nervous system (CNS), peripheral nervous system and the sympathetic nervous system.[14][15]\\r\\nThe CNS consists of a bilobed brain (cerebral ganglia, or supra-pharyngeal ganglion), sub-pharyngeal ganglia, circum-pharyngeal connectives and a ventral nerve cord.\\r\\nEarthworms' brains consist of a pair of pear-shaped cerebral ganglia. These are located in the dorsal side of the alimentary canal in the third segment, in a groove between the buccal cavity and pharynx.\\r\\nA pair of circum-pharyngeal connectives from the brain encircle the pharynx and then connect with a pair of sub-pharyngeal ganglia located below the pharynx in the fourth segment. This arrangement means the brain, sub-pharyngeal ganglia and the circum-pharyngeal connectives form a nerve ring around the pharynx.\\r\\nThe ventral nerve cord (formed by nerve cells and nerve fibres) begins at the sub-pharyngeal ganglia and extends below the alimentary canal to the most posterior body segment. The ventral nerve cord has a swelling, or ganglion, in each segment, i.e. a segmental ganglion, which occurs from the fifth to the last segment of the body. There are also three giant axons, one medial giant axon (MGA) and two lateral giant axons (LGAs) on the mid-dorsal side of the ventral nerve cord. The MGA is 0.07?mm in diameter and transmits in an anterior-posterior direction at a rate of 32.2?m/s. The LGAs are slightly wider at 0.05?mm in diameter and transmit in a posterior-anterior direction at 12.6?m/s. The two LGAs are connected at regular intervals along the body and are therefore considered one giant axon.[16][17]\\r\\nThe sympathetic nervous system consists of nerve plexuses in the epidermis and alimentary canal. (A plexus is a web of nerve cells connected together in a two dimensional grid.) The nerves that run along the body wall pass between the outer circular and inner longitudinal muscle layers of the wall. They give off branches that form the intermuscular plexus and the subepidermal plexus. These nerves connect with the circumpharyngeal connective.\\r\\nOn the surface, crawling speed varies both within and among individuals. Earthworms crawl faster primarily by taking longer \\"strides\\" and a greater frequency of strides. Larger Lumbricus terrestris worms crawl at a greater absolute speed than smaller worms. They achieve this by taking slightly longer strides but with slightly lower stride frequencies.[18]\\r\\nTouching an earthworm, which causes a \\"pressure\\" response as well as (often) a response to the dehydrating quality of the salt on human skin (toxic to earthworms), stimulates the subepidermal nerve plexus which connects to the intermuscular plexus and causes the longitudinal muscles to contact, thereby the writhing movements when we pick up an earthworm. This behaviour is a reflex and does not require the CNS; it occurs even if the nerve cord is removed. Each segment of the earthworm has its own nerve plexus. The plexus of one segment is not connected directly to that of adjacent segments. The nerve cord is required to connect the nervous systems of the segments.[19]\\r\\nThe giant axons carry the fastest signals along the nerve cord. These are emergency signals that initiate reflex escape behaviours. The larger dorsal giant axon conducts signals the fastest, from the rear to the front of the animal. If the rear of the worm is touched, a signal is rapidly sent forwards causing the longitudinal muscles in each segment to contract. This causes the worm shorten very quickly as an attempt to escape from a predator or other potential threat. The two medial giant axons connect with each other and send signals from the front to the rear. Stimulation of these causes the earthworm to very quickly retreat (perhaps contracting into its burrow to escape a bird).\\r\\nThe presence of a nervous system is essential for an animal to be able to experience nociception or pain. However, other physiological capacities are also required such as opioid sensitivity and central modulation of responses by analgesics.[20] Enkephalin and ϫ-endorphin-like substances have been found in earthworms. Injections of naloxone (an opioid antagonist) inhibit the escape responses of earthworms. This indicates that opioid substances play a role in sensory modulation, similar to that found in many vertebrates.[21]\\r\\nEarthworms do not have eyes (although some worms do), however, they do have specialised photosensitive cells called \\"light cells of Hess\\". These photoreceptor cells have a central intracellular cavity (phaosome) filled with microvilli. As well as the microvilli, there are several sensory cilia in the phaosome which are structurally independent of the microvilli.[22] The photoreceptors are distributed in most parts of the epidermis but are more concentrated on the back and sides of the worm. A relatively small number occur on the ventral surface of the 1st segment. They are most numerous in the prostomium and reduce in density in the first three segments; they are very few in number past the third segment.[19]\\r\\nThe gut of the earthworm is a straight tube which extends from the worm's mouth to its anus. It is differentiated into a buccal cavity (generally running through the first one or two segments of the earthworm), pharynx (running generally about four segments in length), esophagus, crop, gizzard (usually) and intestine.[23]\\r\\nFood enters in the mouth. The pharynx acts as a suction pump; its muscular walls draw in food. In the pharynx, the pharyngeal glands secrete mucus. Food moves into the esophagus, where calcium (from the blood and ingested from previous meals) is pumped in to maintain proper blood calcium levels in the blood and food pH. From there the food passes into the crop and gizzard. In the gizzard, strong muscular contractions grind the food with the help of mineral particles ingested along with the food. Once through the gizzard, food continues through the intestine for digestion. The intestine secretes Pepsin to digest proteins, Amylase to digest polysaccharides, Cellulase to digest cellulose, and lipase to digest fats.[2] Earthworms use, in addition to the digestive proteins, a class of surface active compounds called drilodefensins, which help digest plant material.[24] Instead of being coiled like a mammalian intestine, an earthworm's intestine increases surface area to increase nutrient absorption by having many folds running along its length. The intestine has its own pair of muscle layers like the body, but in reverse orderan inner circular layer within an outer longitudinal layer.[25]\\r\\nThe earthworm has a dual circulatory system in which both the coelomic fluid and a closed circulatory system carry the food, waste, and respiratory gases. The closed circulatory system has five main blood vessels: the dorsal (top) vessel, which runs above the digestive tract; the ventral (bottom) vessel, which runs below the digestive tract; the subneural vessel, which runs below the ventral nerve cord; and two lateroneural vessels on either side of the nerve cord.[26] The dorsal vessel moves the blood forward, while the other four longitudinal vessels carry the blood rearward. In segments seven through eleven, a pair of aortic arches rings the coelom and acts as hearts, pumping the blood to the ventral vessel that acts as the aorta. The blood consists of ameboid cells and hemoglobin dissolved in the plasma. The second circulatory system derives from the cells of the digestive system that line the coelom. As the digestive cells become full, they release non-living cells of fat into the fluid-filled coelom, where they float freely but can pass through the walls separating each segment, moving food to other parts and assist in wound healing.[27]\\r\\nThe excretory system contains a pair of nephridia in every segment, except for the first three and the last ones.[28] The three types of nephridia are: integumentary, septal, and pharyngeal. The integumentary nephridia lie attached to the inner side of the body wall in all segments except the first two. The septal nephridia are attached to both sides of the septa behind the 15th segment. The pharyngeal nephridia are attached to fourth, fifth and sixth segments.[28] The waste in the coelom fluid from a forward segment is drawn in by the beating of cilia of the nephrostome. From there it is carried through the septum (wall) via a tube which forms a series of loops entwined by blood capillaries that also transfer waste into the tubule of the nephrostome. The excretory wastes are then finally discharged through a pore on the worm's side.[29]\\r\\nEarthworms have no special respiratory organs. Gases are exchanged through the moist skin and capillaries, where the oxygen is picked up by the hemoglobin dissolved in the blood plasma and carbon dioxide is released. Water, as well as salts, can also be moved through the skin by active transport.\\r\\nMating occurs on the surface, most often at night. Earthworms are hermaphrodites; that is, they have both male and female sexual organs. The sexual organs are located in segments 9 to 15. Earthworms have one or two pairs of testes contained within sacs. The two or four pairs of seminal vesicles produce, store and release the sperm via the male pores. Ovaries and oviducts in segment 13 release eggs via female pores on segment 14, while sperm is expelled from segment 15. One or more pairs of spermathecae are present in segments 9 and 10 (depending on the species) which are internal sacs that receive and store sperm from the other worm during copulation. As a result, segment 15 of one worm exudes sperm into segments 9 and 10 with its storage vesicles of its mate. Some species use external spermatophores for sperm transfer.\\r\\nIn Hormogaster samnitica and Hormogaster elisae transcriptome DNA libraries were sequenced and two sex pheromones, Attractin and Temptin, were detected in all tissue samples of both species.[30] Sex pheromones are probably important in earthworms because they live in an environment where chemical signaling may play a crucial role in attracting a partner and in facilitating outcrossing. Outcrossing would provide the benefit of masking the expression of deleterious recessive mutations in progeny.[31] (Also see complemenation.)\\r\\nCopulation and reproduction are separate processes in earthworms. The mating pair overlap front ends ventrally and each exchanges sperm with the other. The clitellum becomes very reddish to pinkish in color. Some time after copulation, long after the worms have separated, the clitellum (behind the spermathecae) secretes material which forms a ring around the worm. The worm then backs out of the ring, and as it does so, it injects its own eggs and the other worm's sperm into it. As the worm slips out of the ring, the ends of the cocoon seal to form a vaguely lemon-shaped incubator (cocoon) in which the embryonic worms develop. They emerge as small, but fully formed earthworms, but lack their sex structures, which develop in about 60 to 90 days. They attain full size in about one year. Scientists predict that the average lifespan under field conditions is four to eight years, while most garden varieties live only one to two years. Several common earthworm species are mostly parthenogenetic.\\r\\nAmong lumbricid earthworms, parthenogenesis arose from sexual relatives many times.[32] Parthenogenesis in some Aporrectodea trapezoides lineages arose 6.4 to 1.1 million years ago from sexual ancestors.[33]\\r\\nEarthworms have the ability to regenerate lost segments, but this ability varies between species and depends on the extent of the damage. Stephenson (1930) devoted a chapter of his monograph to this topic, while G.E. Gates spent 20 years studying regeneration in a variety of species, but because little interest was shown, Gates (1972) only published a few of his findings that, nevertheless, show it is theoretically possible to grow two whole worms from a bisected specimen in certain species. Gatess reports included:\\r\\nAn unidentified Tasmanian earthworm shown growing a replacement head has been reported.[36]\\r\\nEarthworms travel underground by the means of waves of muscular contractions which alternately shorten and lengthen the body (peristalsis). The shortened part is anchored to the surrounding soil by tiny claw-like bristles (setae) set along its segmented length. In all the body segments except the first, last and clitellum, there is a ring of S-shaped setae embedded in the epidermal pit of each segment (perichaetine). The whole burrowing process is aided by the secretion of lubricating mucus. Worms can make gurgling noises underground when disturbed as a result of their movement through their lubricated tunnels. Earthworms move through soil by expanding crevices with force; when forces are measured according to body weight, hatchlings can push 500 times their own body weight whereas large adults can push only 10 times their own body weight.[37]\\r\\nEarthworms work as biological \\"pistons\\" forcing air through the tunnels as they move. Thus earthworm activity aerates and mixes the soil, and is conducive to mineralization of nutrients and their uptake by vegetation. Certain species of earthworm come to the surface and graze on the higher concentrations of organic matter present there, mixing it with the mineral soil. Because a high level of organic matter mixing is associated with soil fertility, an abundance of earthworms is generally considered beneficial by farmers and gardeners.[38][39] In fact, as long ago as 1881 Charles Darwin wrote: \\"It may be doubted whether there are many other animals which have played so important a part in the history of the world, as have these lowly organized creatures.\\"[40]\\r\\nThe major benefits of earthworm activities to soil fertility can be summarized as:\\r\\nEarthworms accelerate nutrient cycling in the soil-plant system through fragmentation & mixing of plant debris ÿ physical grinding & chemical digestion.[3] The earthworm's existence cannot be taken for granted. Dr. W. E. Shewell-Cooper observed \\"tremendous numerical differences between adjacent gardens\\", and worm populations are affected by a host of environmental factors, many of which can be influenced by good management practices on the part of the gardener or farmer.[42]\\r\\nDarwin estimated that arable land contains up to 53,000 worms per acre (13/m2), but more recent research from Rothamsted Experimental Station has produced figures suggesting that even poor soil may support 250,000/acre (62/m2), whilst rich fertile farmland may have up to 1,750,000/acre (432/m2), meaning that the weight of earthworms beneath a farmer's soil could be greater than that of the livestock upon its surface.\\r\\nThe ability to break down organic materials and excrete concentrated nutrients makes the earthworm a functional contributor in restoration projects. In response to ecosystem disturbances, some opencast mining sites have utilized earthworms to prepare soil for the return of native flora. Sites using this method have observed advances in the return of ecosystem services that previously took much longer to re-establish.[43] Research from the Station d'cologie Tropicale de Lamto asserts that the earthworms positively influence the rate of macroaggregate formation, an important feature for soil structure.[44] The stability of aggregates in response to water was also found to be improved when constructed by earthworms.[44]\\r\\nFrom a total of around 7,000 species, only about 150 species are widely distributed around the world. These are the peregrine or cosmopolitan earthworms.[45]\\r\\nWhile, as the name earthworm suggests, the main habitat of earthworms is in soil, the situation is more complicated than that. The brandling worm Eisenia fetida lives in decaying plant matter and manure. Arctiostrotus vancouverensis from Vancouver Island and the Olympic Peninsula is generally found in decaying conifer logs. Aporrectodea limicola, Sparganophilus spp., and several others are found in mud in streams. Some species are arboreal, some aquatic and some euryhaline (salt-water tolerant) and littoral (living on the sea-shore, e.g. Pontodrilus litoralis). Even in the soil species, special habitats, such as soils derived from serpentine, have an earthworm fauna of their own.\\r\\nEarthworms are classified into three main ecophysiological categories: (1) leaf litter- or compost-dwelling worms that are nonburrowing, live at soil-litter interface and eat decomposing OM (called Epigeic) e.g. Eisenia fetida; (2) topsoil- or subsoil-dwelling worms that feed (on soil), burrow and cast within soil, creating horizontal burrows in upper 10ÿ30?cm of soil (called Endogeics); and (3) worms that construct permanent deep vertical burrows which they use to visit the surface to obtain plant material for food, such as leaves (called Anecic (meaning \\"reaching up\\")), e.g. Lumbricus terrestris.[46]\\r\\nEarthworm populations depend on both physical and chemical properties of the soil, such as temperature, moisture, pH, salts, aeration, and texture, as well as available food, and the ability of the species to reproduce and disperse. One of the most important environmental factors is pH, but earthworms vary in their preferences. Most favor neutral to slightly acidic soils. Lumbricus terrestris is still present in a pH of 5.4 and Dendrobaena octaedra at a pH of 4.3 and some Megascolecidae are present in extremely acidic humic soils. Soil pH may also influence the numbers of worms that go into diapause. The more acidic the soil, the sooner worms go into diapause and the longer they remain in diapause at a pH of 6.4.\\r\\nEarthworms form the base of many food chains. They are preyed upon by many species of birds (e.g. starlings, thrushes, gulls, crows, European robins and American robins), snakes, mammals (e.g. bears, foxes, hedgehogs, pigs, moles) and invertebrates (e.g. ground beetles and other beetles, snails, slugs). Earthworms have many internal parasites, including protozoa, platyhelminthes, and nematodes; they can be found in the worms' blood, seminal vesicles, coelom, or intestine, or in their cocoons.\\r\\nNitrogenous fertilizers tend to create acidic conditions, which are fatal to the worms, and dead specimens are often found on the surface following the application of substances such as DDT, lime sulphur, and lead arsenate. In Australia, changes in farming practices such as the application of superphosphates on pastures and a switch from pastoral farming to arable farming had a devastating effect on populations of the giant Gippsland earthworm, leading to their classification as a protected species.\\r\\nThe addition of organic matter, preferably as a surface mulch, on a regular basis will provide earthworms with their food and nutrient requirements, and will create the optimum conditions of temperature and moisture that will stimulate their activity.\\r\\nVarious species of worms are used in vermiculture, the practice of feeding organic waste to earthworms to decompose food waste. These are usually Eisenia fetida (or its close relative Eisenia andrei) or the Brandling worm, commonly known as the tiger worm or red wiggler. They are distinct from soil-dwelling earthworms. In the tropics, the African nightcrawler Eudrilus eugeniae and the Indian blue Perionyx excavatus are used.\\r\\nEarthworms are sold all over the world; the market is sizable. According to Doug Collicut, \\"In 1980, 370 million worms were exported from Canada, with a Canadian export value of $13 million and an American retail value of $54 million.\\"\\r\\nEarthworms are also sold as food for human consumption. Noke is a culinary term used by the Mori of New Zealand, and refers to earthworms which are considered delicacies for their chiefs.\\r\\nWithin the world of taxonomy, the stable 'Classical System' of Michaelsen (1900) and Stephenson (1930) was gradually eroded by the controversy over how to classify earthworms, such that Fender and McKey-Fender (1990) went so far as to say, \\"The family-level classification of the megascolecid earthworms is in chaos.\\"[47] Over the years, many scientists developed their own classification systems for earthworms, which led to confusion, and these systems have been and still continue to be revised and updated. The classification system used here, developed by Blakemore (2000), is a modern reversion to the Classical System that is historically proven and widely accepted.[48]\\r\\nCategorization of a megadrile earthworm into one of its taxonomic families under suborders Lumbricina and Moniligastrida is based on such features as the makeup of the clitellum, the location and disposition of the sex features (pores, prostatic glands, etc.), number of gizzards, and body shape.[48] Currently, over 6,000 species of terrestrial earthworms are named, as provided in a species name database,[49] but the number of synonyms is unknown.\\r\\nThe families, with their known distributions or origins:[48]","input":"What are the hearts of a worm called?"},{"output":"\\"Laura's First Date\\"","context":"Family Matters is an American sitcom series which originated on ABC from September 22, 1989 to May 9, 1997, before moving to CBS from September 19, 1997 to July 10, 1998. A spin-off of Perfect Strangers, the series revolves around the Winslow family, a middle-class African American family living in Chicago, Illinois.[1] Midway through the first season, the show introduced the Winslows' nerdy neighbor Steve Urkel (Jaleel White), who quickly became its breakout character and eventually the show's main character.[2] Having run for nine seasons, Family Matters became the second longest-running non-animated U.S. sitcom with a predominantly African American cast, behind only The Jeffersons (11). Having aired 215 episodes, Family Matters is ranked third, behind only Tyler Perry's House of Payne (254), and The Jeffersons (253).\\r\\n\\r\\nThe series originally focused on the character of police officer Carl Winslow and his family: wife Harriette, son Eddie, elder daughter Laura, and younger daughter Judy (who appeared until the character was written out in season four).[3] In the pilot episode, \\"The Mama Who Came to Dinner,\\" the family had also opened their home to Carl's street-wise mother, Estelle (Rosetta LeNoire), usually known as \\"Mother Winslow.\\" Prior to the start of the series, Harriette's sister, Rachel Crawford and her infant son, Richie, had moved into the Winslow household after the death of Rachel's husband. The Winslows' nerdy teenage next-door neighbor, Steve Urkel (Jaleel White), was introduced midway through the first season in the episode \\"Laura's First Date\\" and quickly became the focus of the show.[4] The popular sitcom was a mainstay of ABC's TGIF lineup from 1989 until 1997, at which point it became part of the CBS Block Party lineup for its final season. Family Matters was produced by Bickley-Warren Productions (1991-1998) and Miller-Boyett Productions, in association with Lorimar Television (1989ÿ1993) and later Warner Bros. Television (1993ÿ1998). As the show progressed, episodes began to center increasingly on Steve Urkel, and other original characters also played by White, including Steve's suave alter-ego, Stefan Urquelle, and his female cousin, Myrtle Urkel.\\r\\n\\r\\nIn early 1997, CBS picked up Family Matters and Step by Step in a $40 million deal to acquire the rights to the programs from ABC.[5] ABC then promised to pay Miller-Boyett Productions $1.5 million per episode for a ninth and tenth season of Family Matters. However, tensions had risen between Miller-Boyett Productions and ABC's corporate parent, The Walt Disney Company (which had bought the network in 1995 as part of its merger with ABC's then-parent Capital Cities/ABC, Inc.). Miller-Boyett thought that it would not be a big player on ABC after the network's recent purchase by Disney. In turn, Miller-Boyett Productions agreed to a $40 million offer from CBS for a 22-episode season for both Family Matters and Step By Step. CBS scheduled Family Matters along with Step By Step as a part of its new Friday lineup branded as the CBS Block Party and scheduled the family-oriented block against ABC's TGIF lineup, where the two series originated. Near the end of the ninth season, the cast was informed that a tenth and final season was planned, so scripts and plot synopses were written for the show.[citation needed] Ultimately, due to poor ratings, CBS cancelled Family Matters (as well as Step By Step) after one season, along with the rest of the \\"Block Party\\" lineup. CBS also pulled the show from its regular schedule in the winter. As a result, the series finale was broadcast with little fanfare during \\"burn off\\" summer TV time in 1998.\\r\\n\\r\\n\\r\\n\\r\\nFamily Matters was created by William Bickley and Michael Warren (who also wrote for, and were producers of parent series Perfect Strangers) and developed by Thomas L. Miller and Robert L. Boyett (who also served as producers on Perfect Strangers), all four also served as executive producers of the series. The series was produced by Miller-Boyett Productions, in association with Lorimar Television who co-produced the show until 1993, when Warner Bros. Television absorbed Lorimar (a sister company under the co-ownership of Time Warner). Starting with season three, the series was also produced by Bickley-Warren Productions. The series was filmed in front of a live studio audience; the Lorimar-produced episodes were shot at Lorimar Studios (later Sony Pictures Studios) in Culver City, California, while the Warner Bros.-produced episodes were filmed at Warner Bros. Studios in nearby Burbank. Family Matters is the second sitcom from the 80's and 90's to take place in the city of Chicago, the first is FOX's sitcom Married... with Children.\\r\\n\\r\\nThe show's original theme was Louis Armstrong's \\"What a Wonderful World\\"; it was scrapped after the fifth episode of season one (\\"Straight A's\\"), though it was heard only in the pilot episode in syndicated reruns. The second theme, \\"As Days Go By,\\" written by Jesse Frederick, Bennett Salvay and Scott Roeme and performed by Frederick, was the theme for the majority of the series until 1995; it was last used in the season seven episode \\"Fa La La La Laagghh,\\" the only episode during the final three seasons to feature it (this was heard in season one episodes in ABC Family and syndicated airings). A longer version of \\"As Days Go By\\" was used during the first three seasons, though in syndicated reruns the short version is heard (in ABC Family airings, the long theme was used for all of the episodes during the first three seasons).\\r\\n\\r\\nThe opening sequence begins with a shot of the Chicago Lakefront (the John Hancock Center can be seen in the center), then a shot of the Winslow home. In the opening titles, the main characters were shown around the Winslow home (though in some shots featured some characters in other places as well, such as Rachel at the Rachel's Place restaurant during the seasons 2ÿ4 version or Waldo at the Vanderbilt High School gym during the seasons 4ÿ6 version). The opening credits during the first three seasons feature a scene showing the Winslow family riding their bicycles across the Irv Kupcinet Bridge over the Chicago River; an allusion to parent series Perfect Strangers, which featured a scene of Balki and Larry (played by Bronson Pinchot and Mark Linn-Baker), riding a tour boat underneath the same bridge, shot from the same angle, in its own opening credits from seasons 3ÿ8 of that series. Clips of episodes were shown after the bike scene and before the house shot in the season one through three versions. The house shown at the beginning and the end of the opening credits (as well as in establishing shots for scenes set at the Winslow house) is located at 1516 West Wrightwood Avenue in Chicago (415544N 874000W? / ?41.92891N 87.666779W? / 41.92891; -87.666779). The closing shot at the end of the credits with the Winslow family at the piano (which also was shown during the closing credits when there was no tag scene), in which the shot pans outside the house and the camera zooms out showing neighborhoods and the northside Chicago skyline (Wrigleyville) in the background, was originally used in the pilot episode \\"The Mama Who Came to Dinner\\" (though the scene featuring the Winslows before the pan was redone twice in seasons two and five). The role of Richie as a baby was credited as being played by \\"Joseph [and] Julius Wright\\" in season 1, with Julius' name made to appear as Joseph's middle name in the titlesthe duo was credited this way because the show's producers did not want audiences to know that Richie was then played by twinsthe role of Richie as a baby was played by two children because California state law regulates the number of work hours for a young child, therefore it is common for the role of one baby in a television or film production to be played by twins (another Miller-Boyett series, Full House, credited Mary-Kate & Ashley Olsen in the same manner in its opening sequences until that show's seventh season, in which the Olsen twins were credited separately). In season five, after Hopkins left the show, White was given special billing in response to the popularity he earned as Steve Urkel. Appearing last in the credits, he was credited as \\"and Jaleel White as Steve Urkel,\\" starting in the sixth season (Hopkins was credited similarly as \\"and Telma Hopkins as Rachel\\" prior to season five). In season seven, the opening theme song and credit sequence were dropped entirelythough it was brought back for one episode: \\"Fa La La La Laagghh,\\" the eleventh episode of that same seasonfor all other episodes during seasons 7ÿ9, the names of the show's main cast members, as well as co-executive producers and executive producers were shown during each episode's teaser scene.\\r\\n\\r\\nFamily Matters is set in the same \\"TV universe\\" as several other TV shows related to ABC's TGIF or CBS' Block Party:\\r\\n\\r\\nIn September 1993, Warner Bros. Domestic Television Distribution began distributing Family Matters for broadcast in off-network syndication; most television stations stopped carrying the show by around 2002, though some stations in larger markets such as WTOG in Tampa, Florida continued to air Family Matters until as recently as 2005 and WPIX as 2007. In 1995, reruns of the series began airing on TBS Superstation, where it ran until 2003. From 1997 to 2003, reruns of the series aired on WGN America. In 2003, ABC Family picked up the series and aired it for five years until February 29, 2008. From 2004 to 2006, UPN aired the show for 2 years. BET aired reruns briefly in December 2009 and began airing the series on a regular basis on March 1, 2013. MTV2 also began airing reruns on September 7, 2013. The show aired on Nick at Nite from June 29, 2008 to December 31, 2012. ABC Family and Nick at Nite airings cut the tag scenes at the end of all episodes, despite the fact that many episodes during the series have tag scenes during the closing credits. In 2015, the series now airs on a Viacom owned cable network BET Her. In Canada, the series also aired on CTV and CBC for reruns.\\r\\n\\r\\nOn September 29, 2017, Family Matters became available for streaming on Hulu along with fellow Warner Bros. TV productions Full House, Hangin' with Mr. Cooper, Perfect Strangers and Step by Step in addition to Disney-ABC TV productions Boy Meets World, Dinosaurs and Home Improvement.[7]\\r\\n\\r\\nWarner Home Video has released the first four seasons of Family Matters on DVD in Region 1[8][9][10] while the remaining five seasons were released by the Warner Archive Collection.[11][12][13][14][15] On February 4, 2014, Warner Home Video released season 4 on DVD, but consumers complained when it was found that the season 4 set contained syndication edits rather than the original broadcast masters. Warner Bros. responded to the complaints, offered a replacement program to receive corrected discs and reissuing the set with corrected broadcast copies on April 4. All episodes are the original broadcast form, except for the episode \\"Number One With a Bullet\\", disc 1, episode 6. The entire series is also available for digital download on Amazon.com and the iTunes Store, all but season 6 remastered in both SD and HD.[16]\\r\\n\\r\\nWatchMojo.com rated Family Matters as the #8 African American TV show. Steve Urkel was rated as the #2 most annoying TV character and as the #4 TV neighbor. His catchphrase Did I do that? was rated as the #10 sitcom catchphrase.\\r\\n\\r\\nT?G?I?f","input":"When did steve urkel and laura get together?"},{"output":"Charlotte of Mecklenburg-Strelitz","context":"Charlotte /???rl?t/ is the most populous city in the U.S. state of North Carolina. Located in the Piedmont, it is the county seat of Mecklenburg County.\\r\\nIn 2016, the U.S.?Census Bureau estimated the population was 842,051,[4] making it the 17th-most populous city in the United States. The Charlotte metropolitan area ranks 22nd-largest in the U.S., and had a 2016 population of 2,474,314.[2] The Charlotte metropolitan area is part of a sixteen-county market region or combined statistical area with a 2016 U.S.?Census population estimate of 2,632,249.[5] Between 2004 and 2014, Charlotte was ranked as the country's fastest growing metro area, with 888,000 new residents.[6] Based on U.S. Census data from 2005 to 2015, it tops the 50 largest U.S. cities as the millennial hub.[7] It is the second-largest city in the southeastern United States, just behind Jacksonville, Florida. It is the third-fastest growing major city in the United States.[8] It is listed as a \\"gamma-minus\\" global city by the Globalization and World Cities Research Network.[9] Residents are referred to as \\"Charlotteans\\".\\r\\nCharlotte is home to the corporate headquarters of Bank of America and the east coast operations of Wells Fargo, which along with other financial institutions made it the second-largest banking center in the United States from 1995 to 2017[10] and the third-largest from 2017 to present.[11]\\r\\nAmong Charlotte's many notable attractions, some of the most popular include the Carolina Panthers of the NFL, the Charlotte Hornets of the NBA, the Charlotte Checkers of the AHL, the Charlotte Independence of the USL, the Charlotte Hounds of Major League Lacrosse, two NASCAR Cup Series races and the NASCAR All-Star Race, the Wells Fargo Championship, the NASCAR Hall of Fame, the Charlotte Ballet, Carowinds amusement park, and the U.S. National Whitewater Center. Charlotte Douglas International Airport is a major international hub, and was ranked the 23rd-busiest airport in the world by passenger traffic in 2013.[12]\\r\\nCharlotte has a humid subtropical climate. It is located several miles east of the Catawba River and southeast of Lake Norman, the largest man-made lake in North Carolina. Lake Wylie and Mountain Island Lake are two smaller man-made lakes located near the city.\\r\\n\\r\\n\\r\\nFollowing thousands of years of indigenous cultures, the Catawba Native Americans were the first known historic tribe to settle Mecklenburg County (in the Charlotte area) and were first recorded around 1567 in Spanish records. By 1759 half the Catawba tribe had died from smallpox, which was endemic among Europeans, because they had no acquired immunity to the new disease. At the time of their largest population, Catawba people numbered 10,000, but by 1826 their total population had dropped to 110.[13]\\r\\nThe European-American city of Charlotte was developed first by a wave of migration of Scots-Irish Presbyterians, or Ulster-Scot settlers from Northern Ireland, who dominated the culture of the Southern Piedmont Region. They made up the principal founding European population in the backcountry. German immigrants also settled here before the American Revolutionary War, but in much smaller numbers. They still contributed greatly to the early foundations of the region. The Flag of Charlotte is the Saint Andrews Flag of Scotland, or Saltire with a City Crest.\\r\\nMecklenburg County was initially part of Bath County (1696 to 1729) of New Hanover Precinct, which became New Hanover County in 1729. The western portion of New Hanover split into Bladen County in 1734, its western portion splitting into Anson County in 1750. Mecklenburg County formed from Anson County in 1762. Further apportionment was made in 1792, after the American Revolutionary War, with Cabarrus County formed from Mecklenburg.\\r\\nIn 1842, Union County formed from Mecklenburg's southeastern portion and a western portion of Anson County. These areas were all part of one of the original six judicial/military districts of North Carolina known as the Salisbury District.[14]\\r\\nThe area that is now Charlotte was settled by people of European descent around 1755, when Thomas Spratt and his family settled near what is now the Elizabeth neighborhood. Thomas Polk (granduncle of U.S.?President James K. Polk), who later married Thomas Spratt's daughter, built his house by the intersection of two Native American trading paths between the Yadkin and Catawba rivers.[15] One path ran northÿsouth and was part of the Great Wagon Road; the second path ran eastÿwest along what is now Trade Street.\\r\\nNicknamed the Queen City,[16] like its county a few years earlier, Charlotte was named in honor of German princess Charlotte of Mecklenburg-Strelitz, who had become the Queen Consort of Great Britain and Ireland in 1761, seven years before the town's incorporation. A second nickname derives from the American Revolutionary War, when British commander General Charles Cornwallis, 1st Marquess Cornwallis occupied the city but was driven out by hostile residents. He wrote that Charlotte was \\"a hornet's nest of rebellion\\", leading to the nickname The Hornet's Nest.\\r\\nWithin decades of Polk's settling, the area grew to become \\"Charlotte Town\\", incorporating in 1768.[17] The crossroads in the Piedmont became the heart of Uptown Charlotte. In 1770, surveyors marked the streets in a grid pattern for future development. The eastÿwest trading path became Trade Street, and the Great Wagon Road became Tryon Street, in honor of William Tryon, a royal governor of colonial North Carolina.[18] The intersection of Trade and Tryoncommonly known today as \\"Trade & Tryon,\\" or simply \\"The Square\\"[15]is more properly called \\"Independence Square\\".[19]\\r\\nWhile surveying the boundary between the Carolinas in 1772, William Moultrie stopped in Charlotte Town, whose five or six houses were \\"very ordinary built of logs\\".[20]\\r\\nLocal leaders came together in 1775 and signed the Mecklenburg Resolves, more popularly known as the Mecklenburg Declaration of Independence. While not a true declaration of independence from British rule, it is among the first such declarations that eventually led to the American Revolution. May 20, the traditional date of the signing of the declaration, is celebrated annually in Charlotte as \\"MecDec\\", with musket and cannon fire by reenactors in Independence Square. North Carolina's state flag and state seal also bear the date.\\r\\nCharlotte is traditionally considered the home of Southern Presbyterianism, but in the 19th?century, numerous churches, including Presbyterian, Baptist, Methodist, Episcopalian, Lutheran, and Roman Catholic formed, eventually giving Charlotte the nickname, \\"The City of Churches\\".[21]\\r\\nIn 1799, in nearby Cabarrus County, 12-year-old Conrad Reed found a 17-pound rock, which his family used as a doorstop. Three years later, a jeweler determined it was nearly solid gold, paying the family a paltry $3.50.[22] The first documented gold find in the United States of any consequence set off the nation's first gold rush. Many veins of gold were found in the area throughout the 19th and early 20th centuries, leading to the 1837 founding of the Charlotte Mint. North Carolina was the chief producer of gold in the United States until the Sierra Nevada find in 1848,[23] although the volume mined in the Charlotte area was dwarfed by subsequent rushes.\\r\\nSome groups still pan for gold occasionally in local streams and creeks. The Reed Gold Mine operated until 1912. The Charlotte Mint was active until 1861, when Confederate forces seized it at the outbreak of the Civil War. The mint was not reopened at the war's end, but the building, albeit in a different location, now houses the Mint Museum of Art.\\r\\nThe city's first boom came after the Civil War, as a cotton processing center and a railroad hub. Charlotte's city population at the 1880 Census grew to 7,084.[24]\\r\\nIn 1910, Charlotte passed Wilmington to become North Carolina's largest city.[25]\\r\\nPopulation grew again during World War I, when the U.S. government established Camp Greene north of present-day Wilkinson Boulevard. Many soldiers and suppliers stayed after the war, launching an urban ascent that eventually overtook older city rivals along the Piedmont Crescent.\\r\\nIn the 1920 census, Charlotte lost its title as the state's largest city to Winston-Salem, which with a population of 48,395 had 2,077 more people than Charlotte. However, Charlotte regained its status several years later.[26]\\r\\nThe city's modern-day banking industry achieved prominence in the 1970s and 1980s, largely under the leadership of financier Hugh McColl. McColl transformed North Carolina National Bank (NCNB) into a formidable national player that through aggressive acquisitions became known as NationsBank, eventually merging with BankAmerica to become Bank of America. First Union, later Wachovia in 2001, experienced similar growth before it was acquired by San Francisco-based Wells Fargo in 2008. Measured by control of assets, Charlotte is the second largest banking headquarters in the United States, after New York City.[27]\\r\\nOn September 22, 1989, the city took a direct hit from Hurricane Hugo. With sustained winds of 69?mph (111?km/h) and gusts of 87?mph (140?km/h) in some locations,[28] Hugo caused massive property damage, destroyed 80,000 trees, and knocked out electrical power to most of the population. Residents were without power for weeks, schools were closed for a week or more, and the cleanup took months. The city was caught unprepared; Charlotte is 200 miles (320?km) inland, and residents from coastal areas in both Carolinas often wait out hurricanes in Charlotte.\\r\\nIn December 2002, Charlotte and much of central North Carolina were hit by an ice storm that resulted in more than 1.3?million people losing power.[29] During an abnormally cold December, many were without power for weeks. Many of the city's Bradford pear trees split apart under the weight of the ice.\\r\\nIn August 2015 and in September 2016, the city experienced several days of protests related to the police shootings of Jonathan Ferrell and Keith Scott.[30][31]\\r\\nAccording to the United States Census Bureau, the city has a total area of 297.68 square miles (771.0?km2), of which 297.08 square miles (769.4?km2) is land and 0.6 square miles (1.6?km2) is water. Charlotte lies at an elevation of 748 feet (228?m), as measured at Charlotte/Douglas International Airport. Charlotte constitutes most of Mecklenburg County in the Carolina Piedmont. Charlotte center city sits atop a long rise between two creeks, Sugar Creek and Irwin Creek, and was built on the gunnies of the St. Catherine's and Rudisill gold mines.\\r\\nThough the Catawba River and its lakes lie several miles west, there are no significant bodies of water or other geological features near the city center. Consequently, development has neither been constrained nor helped by waterways or ports that have contributed to many cities of similar size. The lack of these obstructions has contributed to Charlotte's growth as a highway, rail, and air transportation hub.\\r\\nCharlotte has 199?neighborhoods radiating in all directions from Uptown.[32] Biddleville, the primary historic center of Charlotte's African-American community, is west of Uptown, starting at the Johnson C. Smith University campus and extending to the airport.[33] East of The Plaza and north of Central Avenue, Plaza-Midwood is known for its international population, including Eastern Europeans, Greeks, Middle-Easterners, and Hispanics.[34] North Tryon and the Sugar Creek area include several Asian-American communities. NoDa (North Davidson), north of Uptown, is an emerging center for arts and entertainment.[35] Myers Park, Dilworth, and Eastover are home to some of Charlotte's oldest and largest houses, on tree-lined boulevards, with Freedom Park, arguably the city's favorite, nearby.\\r\\nPark Road and the SouthPark area have an extensive array of shopping and dining offerings, with SouthPark essentially serving as a second urban core. Blossoming neighborhoods like Sedgefield, Dilworth and South End are great examples of that. Far South Boulevard is home to a large Hispanic community. Many students, researchers, and affiliated professionals live near UNC?Charlotte in the northeast area known as University City.\\r\\nThe large area known as Southeast Charlotte is home to many golf communities, luxury developments, mega-churches, the Jewish community center, and private schools. As undeveloped land within Mecklenburg has become scarce, many of these communities have expanded into Weddington and Waxhaw in Union County.[36] Ballantyne, in the south of Charlotte, and nearly every area on the I?485 perimeter, has experienced rapid growth over the past ten years.\\r\\nSince the 1980s in particular, Uptown Charlotte has undergone massive construction of buildings, housing Bank of America, Wells Fargo, Hearst Corporation, Duke Energy, several hotels, and multiple condominium developments.[37]\\r\\nThe 120?acre Park Road Park is a prominent landmark of the SouthPark neighborhood.[38] Park Road Park features 8 basketball courts, 2 horseshoe pits, 6 baseball fields, 5 Picnic Shelters, volleyball courts, playgrounds, trails, tennis courts, and an eleven-acre lake.[39] The Charlotte-Mecklenburg Parks & Recreation Department operates 36 tennis facilities and the 12 lighted tennis courts at the park.[40]\\r\\nThe urban section of Little Sugar Creek Greenway was completed in 2012. Inspired in part by the San Antonio River Walk, and integral to Charlotte's extensive urban park system, it is \\"a huge milestone\\" according to Gwen Cook, greenway planner for Mecklenburg County Park and Recreation.[41]\\r\\nCharlotte, like much of the Piedmont region of the southeastern United States, has a humid subtropical climate (K?ppen Cfa), with four distinct seasons; the city itself is part of USDA hardiness zone 8a, transitioning to 7b in the suburbs in all directions except the south.[42] Winters are short and generally cool, with a January daily average of 40.1?F (4.5?C). On average, there are 59?nights per year that drop to or below freezing, and only 1.5?days that fail to rise above freezing.[43] April is the driest month, with an average of 3.04 inches (7.7?cm) of precipitation. Summers are hot and humid, with a daily average in July of 78.5?F (25.8?C). There is an average 44?days per year with highs at or above 90?F (32?C).[43] Official record temperatures range from 104?F (40?C) recorded six times, most recently on July 1, 2012, down to ?5?F (?21?C) recorded on January 21, 1985, the most recent of three occasions. The record cold daily maximum is 14?F (?10?C) on February 12 and 13, 1899, and the record warm daily minimum is 82?F (28?C) on August 13, 1881.[43] The average window for freezing temperatures is November 5 through March 30, allowing a growing season of 220 days.[43]\\r\\nCharlotte is directly in the path of subtropical moisture from the Gulf of Mexico as it heads up the eastern seaboard, thus the city receives ample precipitation throughout the year but also many clear, sunny days; precipitation is generally less frequent in autumn than in spring.[43] On average, Charlotte receives 41.6 inches (1,060?mm) of precipitation annually, which is somewhat evenly distributed throughout the year, although summer is slightly wetter; annual precipitation has historically ranged from 26.23?in (666?mm) in 2001 to 68.44?in (1,738?mm) in 1884.[43] In addition, there is an average of 4.3 inches (10.9?cm) of snow, mainly in January and February and rarely December or March, with more frequent ice storms and sleet mixed in with rain; seasonal snowfall has historically ranged from trace amounts as recently as 2011ÿ12 to 22.6?in (57?cm) in 1959ÿ60.[43] These storms can have a major impact on the area, as they often pull tree limbs down onto power lines and make driving hazardous.\\r\\nThe most recent U.S. Census estimate (2014, released in May 2015) showed 809,958 residents living within Charlotte's city limits and 1,012,539 in Mecklenburg County. The Combined Statistical Area, or trade area, of CharlotteÿConcordÿGastonia, NCÿSC had a population of 2,537,990.[2] Figures from the more comprehensive 2010 census show Charlotte's population density to be 2,457 per square mile (948.7/km2). There are 319,918 housing units at an average density of 1,074.6 per square mile (414.9/km2).[47]\\r\\nAccording to the 2010 United States Census, the racial composition of Charlotte was:\\r\\nIn 1970, the Census Bureau reported Charlotte's population as 30.2% Black and 68.9% White.[48]\\r\\nThe median income for a household in the city is $48,670, and the median income for a family is $59,452. Males have a median income of $38,767 versus $29,218 for females. The per capita income for the city is $29,825. The percentage of the population living at or below the poverty line is 10.6%, with 7.8% of families living at or below the poverty line. Out of the total population, 13.8% of those under the age of 18 and 9.7% of those 65 and older are living below the poverty line.\\r\\nCharlotte has historically been a Protestant city. It is the birthplace of Billy Graham, and is also the historic seat of Southern Presbyterianism, but the changing demographics of the city's increasing population have brought scores of new denominations and faiths. The Billy Graham Evangelistic Association, Wycliffe Bible Translators' JAARS Center, and SIM Missions Organization make their homes in the Charlotte general area. In total, Charlotte proper has 700 places of worship.\\r\\nThe Presbyterian Church (USA) is now the fourth largest denomination in Charlotte, with 68,000 members and 206 congregations. The second largest Presbyterian denomination, the Presbyterian Church in America has 43 churches and 12,000 members, followed by the Associate Reformed Presbyterian Church with 63 churches and 9,500 members.[49]\\r\\nThe Baptist Peace Fellowship of North America is headquartered in Charlotte, and both Reformed Theological Seminary and Gordon-Conwell Theological Seminary have campuses there; more recently, the Religious Studies academic departments of Charlotte's local colleges and universities have also grown considerably.\\r\\nThe Advent Christian Church is headquartered in Charlotte.\\r\\nThe Western North Carolina Annual Conference of the United Methodist Church is headquartered in Charlotte.\\r\\nThe largest Protestant church in Charlotte, by attendance, is Elevation Church, a Southern Baptist church founded by lead pastor Steven Furtick. The church has over 15,000 congregants at nine Charlotte locations.[50]\\r\\nCharlotte's Cathedral of Saint Patrick is the seat of the bishop of the Roman Catholic Diocese of Charlotte. The Traditional Latin Mass is offered by the Society of St. Pius X at St. Anthony Catholic Church in nearby Mount Holly. The Traditional Latin Mass is also offered at St. Ann, Charlotte, a church under the jurisdiction of the Roman Catholic Bishop of Charlotte. St. Matthew Parish, located in the Ballantyne neighborhood, is the largest Catholic parish with over 30,000 parishioners.[51]\\r\\nThe Greek Orthodox Church's cathedral for North Carolina, Holy Trinity Cathedral, is located in Charlotte.\\r\\nCharlotte has the largest Jewish population in the Carolinas. Shalom Park in south Charlotte is the hub of the Jewish community, featuring two synagogues, Temple Israel and Temple Beth El, as well as a community center, the Charlotte Jewish Day School for grades?Kÿ5, and the headquarters of the Charlotte Jewish News.[52]\\r\\nMost African Americans in Charlotte are Baptists affiliated with the National Baptist Convention, the largest predominantly African American denomination in the United States. African American Methodists are largely affiliated with either the African Methodist Episcopal Zion Church, headquartered in Charlotte, or the African Methodist Episcopal Church. African American Pentecostals are represented by several organizations such as the United House of Prayer for All People, Church of God in Christ, and the United Holy Church of America.\\r\\nAs of 2013[update], 51.91% of people in Charlotte practise religion on a regular basis, making it the second most religious city in North Carolina after Winston-Salem. The largest religion in Charlotte is Christianity, with Baptists (13.26%) having the largest number of adherents. The second largest Christian group is Roman Catholic (9.43%), followed by Methodist (8.02%) and Presbyterian (5.25%). Other Christian affiliates include Pentecostal (2.50%), Lutheran (1.30%), Episcopalian (1.20%), Latter-Day Saints (0.84%), and other Christian (8.87%) churches, including Eastern Orthodox and non-denominational. Judaism (0.57%) is the second largest religion after Christianity, followed by Eastern religions (0.34%) and Islam (0.32%).[53]\\r\\nCharlotte has become a major U.S. financial center with the third most banking assets after New York City and San Francisco.[11][54] The nation's second largest financial institution by total assets, Bank of America, calls the city home. The city was also the former corporate home of Wachovia until its 2008 acquisition by Wells Fargo; Wells Fargo integrated legacy Wachovia, with the two banks fully merged at the end of 2011, which included transitioning all of the Wachovia branches in the Carolinas to Wells Fargo branches by October 2011. Since then, Charlotte has become the regional headquarters for East Coast operations of Wells Fargo, which is headquartered in San Francisco, California. Charlotte also serves as the headquarters for Wells Fargo's capital markets activities including sales and trading, equity research, and investment banking. Bank of America's headquarters, along with other regional banking and financial services companies, are located primarily in the Uptown central business district. Microsoft's East Coast headquarters are located in Charlotte.[55]\\r\\nCharlotte has six Fortune 500 companies in its metropolitan area. Listed in order of their rank, they are: Bank of America, Lowe's in suburban Mooresville, Duke Energy, Nucor (steel producer), Sonic Automotive and Sealed Air Corp. The Charlotte area includes a diverse range of businesses, including foodstuffs such as Chiquita Brands International, Harris Teeter, Snyder's-Lance, Carolina Foods Inc, Bojangles', Food Lion, Compass Group USA, and Coca-Cola Bottling Co. Consolidated (Charlotte being the nation's second largest Coca-Cola bottler); motor and transportation companies such as RSC?Brands, Continental Tire the Americas,?LLC., Meineke Car Care Centers, Carlisle Companies (along with several other services), along with a wide array of other businesses.[56]\\r\\nCharlotte is the major center in the U.S.?motorsports industry, housing multiple offices of NASCAR, the NASCAR Hall of Fame, and Charlotte Motor Speedway in Concord. Approximately 75% of the NASCAR industry's race teams, employees and drivers are based nearby. The large presence of the racing technology industry and the newly built NHRA dragstrip, zMAX Dragway at Concord, are influencing other top professional drag racers to move their shops to Charlotte as well.\\r\\nLocated in the western part of Mecklenburg County is the U.S.?National Whitewater Center, which consists of man-made rapids of varying degrees, is open to the public year-round.[57]\\r\\nThe Charlotte Region has a major base of energy-oriented organizations and has become known as \\"Charlotte USA?ÿ The New Energy Capital.\\" In the region there are more than 240?companies directly tied to the energy sector, collectively employing more than 26,400. Since 2007 more than 4,000 energy sector jobs have been announced. Major energy players in Charlotte include AREVA, Babcock & Wilcox, Duke Energy, Electric Power Research Institute, Fluor, Metso Power, Piedmont Natural Gas, Siemens Energy, Shaw Group, Toshiba, URS?Corp., and Westinghouse. The University of North Carolina at Charlotte has a reputation in energy education and research, and its Energy Production and Infrastructure Center (EPIC) trains energy engineers and conducts research.\\r\\nThe area is an increasingly growing trucking and freight transportation hub for the East Coast. The Charlotte Center city has seen remarkable growth over the last decade. Numerous residential units continue to be built uptown, including over 20 skyscrapers under construction, recently completed, or in the planning stage. Many new restaurants, bars and clubs now operate in the Uptown area. Several projects are transforming the Midtown Charlotte/Elizabeth area.[58]\\r\\nIn 2013, Forbes named Charlotte among its list of Best Places for Business and Careers.[59] Charlotte was listed as the 20th largest city in the US, and the 60th fastest growing city in the US between 2000 and 2008.[60]\\r\\nAccording to Charlotte's 2014 Comprehensive Annual Financial Report,[61] the top employers in the city are:\\r\\nThe Charlotte region is home to many annual festivals and special events. The Carolina Renaissance Festival operates on Saturdays and Sundays each October and November. Located near the intersection of Highway 73 and Poplar Tent Road, the Carolina Renaissance Festival is one of the largest renaissance themed events in the country. It features 11 stages of outdoor variety entertainment, a 22-acre village marketplace, an interactive circus, an arts and crafts fair, a jousting tournament, and a feast, all rolled into one non-stop, day-long family adventure.\\r\\nTaste of Charlotte is a 3 day festival featuring over 100 samples from area restaurants along with Live Music and Entertainment, Interactive Childrens Activities, Cooking Demos, Street Performances, Unique Shopping and a large variety of local, regional and national partners interacting with festival goers, providing information, coupons and free stuff! Admission to Taste of Charlotte is FREE. Purchase festival coins to use for restaurant samples, beverages and kids activities.Located on Tryon Street, Taste of Charlotte now spans 6 city blocks from Stonewall to 5th Street. Enjoy delicious food while strolling the festival experiencing four stages of entertainment, street performances and interactive tours. Taste of Charlotte truly is a fun, friendly atmosphere for all ages\\r\\nCharlotte is \\"... the largest metropolitan area in the United States without a zoo.\\"[62] The Charlotte Zoo initiative is a proposal to allocate 250 acres (101?ha) of natural North Carolina land to be dedicated to the zoological foundation, which was incorporated in 2008. On August 18, 2012, News Channel 14 says that the initiative is \\"... still a few years away\\" and the plot of land is \\"... just seven miles from the center of uptown.\\" According to the news channel, \\"... the zoo will cost roughly $300 million, and will be completely privately-funded.\\"[63] The Charlotte Observer references two other zoos, the Riverbanks Zoo and Garden and the North Carolina Zoological Park as two \\"great zoos\\" that are accessible from the Charlotte-Mecklenberg area, both roughly more than 70 miles away.[64]\\r\\nCharlotte is also served by the Sea Life Charlotte-Concord Aquarium in the nearby city of Concord. The aquarium is 30,000 square feet in size, and is part of the Concord Mills mall. The aquarium opened on February 20, 2014.[65]\\r\\nCharlotte is home to two major professional sports franchises: the Carolina Panthers of the National Football League (NFL) and the Charlotte Hornets of the National Basketball Association (NBA). The Panthers have been located in Charlotte since the team's creation in 1995, and the current Hornets franchise has been located in Charlotte since its creation in 2004. The Panthers play their home games in Bank of America Stadium, while the Hornets play in the Spectrum Center. The original Hornets NBA franchise was established in 1988 as an expansion team, but it relocated to New Orleans, Louisiana in 2002 after animosity grew between the team's fans and principal owner George Shinn.[66] The NBA quickly granted Charlotte an expansion franchise following the departure of the Hornets, and the new franchise, the Charlotte Bobcats, began to play in 2004. The team retook the Hornets name when the New Orleans-based team renamed itself the New Orleans Pelicans in 2013.[67] The name change became official on May 20, 2014. On the same day, the franchise reclaimed the history and records of the original 1988ÿ2002 Hornets.[68] Charlotte is represented in ice hockey and baseball at the 'AAA' professional level by the Charlotte Checkers and the Charlotte Knights.\\r\\nCharlotte has a council-manager form of government. The mayor and city council are elected every two years, with no term limits. The mayor is ex?officio chairman of the city council, and only votes in case of a tie. Unlike other mayors in council-manager systems, Charlotte's mayor has the power to veto ordinances passed by the council; vetoes can be overridden by a two-thirds majority of the council. The council appoints a city manager to serve as chief administrative officer.\\r\\nUnlike some other cities and towns in North Carolina, elections are held on a partisan basis. The current mayor is Vi Lyles, a Democrat elected in 2017.[69]\\r\\nPatrick Cannon, a Democrat, was sworn in as mayor on December 2, 2013.[70] On March 26, 2014, Cannon was arrested on public corruption charges. Later the same day, he resigned as mayor.[71] On April 7, the city council held a special election and selected State Senator Dan Clodfelter, also a Democrat, to fill out the balance of Cannon's term.[72] Former Mecklenburg County Commission chairwoman Jennifer Roberts defeated Clodfelter in the 2015 Democratic primary, and went on to win the general election, becoming the first Democratic woman to hold the post. She was ousted in the 2017 Democratic primary by Mayor Pro Tem Lyles, who went on to become the city's fourth mayor in four years.\\r\\nHistorically, voters have been friendly to moderates of both parties. However, in recent years, Charlotte has swung heavily to the Democrats. Republican strength is concentrated in the southeastern portion of the city, while Democratic strength is concentrated in the south-central, eastern, and northern areas.\\r\\nThe city council comprises 11 members (7 from districts and 4 at-large). Democrats control the council with a 9-to-2 advantage, winning all 4 of the at-large seats in the November 2013 municipal election. While the city council is responsible for passing ordinances, many policy decisions must be approved by the North Carolina General Assembly as well, since North Carolina municipalities do not have home rule. While municipal powers have been broadly construed since the 1960s, the General Assembly still retains considerable authority over local matters.\\r\\nCharlotte is split between two congressional districts on the federal level. The southeastern portion is part of the 9th District, represented by Republican Robert Pittenger. Most of the city is in the 12th District, represented by Democrat Alma Adams.\\r\\nCharlotte was selected in 2011 to host the 2012 Democratic National Convention, which was held at the Spectrum Center. It began September 4, 2012, and ended on September 6.[1]\\r\\nEmergency medical services for the city of Charlotte are provided by MEDIC, the Mecklenburg EMS agency. MEDIC responded to over 93,000 calls for help in 2008, and transported over 71,000 patients to the major hospitals in Charlotte.[73] The agency employs nearly 350 paramedics, EMTs, and EMDs. In addition to dispatching MEDIC's EMS calls, the agency also dispatches all county fire calls outside of the city of Charlotte.[74] At any given time, between 20 and 40 ambulances will be deployed to cover the county.\\r\\nThe Charlotte Fire Department provides fire suppression, emergency medical services, public education, hazardous materials (HAZMAT) mitigation, technical rescues, and fire prevention and inspection with 1,164 personnel. Forty-two fire stations are strategically scattered throughout Charlotte to provide a reasonable response time to emergencies in the city limits.\\r\\nThe Charlotte-Mecklenburg Police Department (CMPD) is a combined jurisdiction agency. The CMPD has law enforcement jurisdiction in both the city of Charlotte and the few unincorporated areas left in Mecklenburg County. The other small towns maintain their own law enforcement agencies for their own jurisdictions. The department consists of approximately 1,700 sworn law enforcement officers, 550 civilian personnel, and more than 400 volunteers.[75] The Charlotte-Mecklenburg Police Department divides the city into 13 geographic areas, which vary in size both geographically and by the number of officers assigned to each division. The total crime index for Charlotte is 589.2 crimes committed per 100,000 residents as of 2008[update] and has shown a steady decline since 2005.[76] The national average is 320.9 per 100,000 residents.[76] An average of 4,939 vehicles are stolen every year in Charlotte.[77]\\r\\nAccording to the Congressional Quarterly Press; '2008 City Crime Rankings: Crime in Metropolitan America,' Charlotte, North Carolina ranks as the 62nd most dangerous city larger than 75,000 inhabitants.[78] However, the entire Charlotte-Gastonia Metropolitan Statistical Area ranked as 27th most dangerous out of 338 metro areas.[79]\\r\\nThe city's public school system, Charlotte-Mecklenburg Schools, is the 2nd largest in North Carolina and 17th largest in the nation.[80] In 2009, it won the NAEP Awards, the Nation's Report Card for urban school systems with top honors among 18 city systems for 4th grade math, 2nd place among 8th?graders.[81][82] An estimated 144,000 students are taught in 164 separate elementary, middle, and high schools.[83]\\r\\nCharlotte is home to a number of universities and colleges such as Central Piedmont Community College, Johnson C. Smith University, Johnson & Wales University, Queens University of Charlotte, and the University of North Carolina at Charlotte. Several notable colleges are located in the metropolitan suburbs. Located in Davidson, North Carolina, Davidson College is ranked in the top?ten nationally among liberal arts colleges, according to U.S.?News & World Report. Additional colleges in the area include Belmont Abbey College in the suburb of Belmont, North Carolina, and Wingate University in the suburb of Wingate, North Carolina. Also nearby are Winthrop University, Clinton Junior College, and York Technical College in Rock Hill, South Carolina.\\r\\nUNC Charlotte is the city's largest university. It is located in University City, the northeastern portion of Charlotte, which is also home to University Research Park, a 3,200 acres (13?km2) research and corporate park. With more than 29,000?students, UNC?Charlotte is the third largest university in the state system.\\r\\nCentral Piedmont Community College is the largest community college in the Carolinas, with more than 70,000 students each year and 6 campuses throughout the Charlotte-Mecklenburg region.[84] CPCC is part of the statewide North Carolina Community College System.\\r\\nThe Charlotte School of Law opened its doors in Charlotte in 2006 and was fully accredited by the American Bar Association in 2011. The law school offered the Juris Doctor degree but the Bar association rescinded the accreditation in 2017. Charlotte School of Law once was the largest law school in the Carolinas has ceased to operate.\\r\\nPfeiffer University has a satellite campus in Charlotte. Wake Forest University, with its main campus in Winston-Salem, North Carolina, also operates a satellite campus of its Babcock Graduate School of Management in the Uptown area.[85] The Connecticut School of Broadcasting, DeVry University, and ECPI University all have branches in Charlotte. The Universal Technical Institute has the NASCAR Technical Institute in nearby Mooresville, serving the Charlotte area. Montreat College (Charlotte) maintains a School of Professional and Adult Studies in the city. Additionally, Union Presbyterian Seminary has a non-residential campus offering the Master of Arts in Christian Education, and the Master of Divinity in Charlotte near the Beverley Woods area.\\r\\nThe North Carolina Research Campus, a 350-acre biotechnology hub located northeast of Charlotte in the city of Kannapolis, is a public-private venture including eight universities, one community college, the David H. Murdock Research Institute (DHMRI), the U.S. Department of Agriculture (USDA) and corporate entities that collaborate to advance the fields of human health, nutrition and agriculture. Partnering educational organizations include UNC Charlotte and Rowan-Cabarrus Community College, from the Charlotte region, as well as Appalachian State University, University of North Carolina at Chapel Hill, Duke University, University of North Carolina at Greensboro, North Carolina A&T State University, North Carolina Central University and North Carolina State University.[86] The research campus is part of a larger effort by leaders in the Charlotte area to attract energy, health, and other knowledge-based industries that contribute to North Carolina's strength in biotechnology.\\r\\nThe Charlotte Mecklenburg Library serves the Charlotte area with a large collection (more than 1.5?million) of books, CDs and DVDs at 15?locations in the city of Charlotte, with branches in the surrounding towns of Matthews, Mint Hill, Huntersville, Cornelius and Davidson. All locations provide free access to Internet-enabled computers and WiFi, and a library card from one location is accepted at all 20 locations.\\r\\nAlthough the library's roots go back to the Charlotte Literary and Library Association, founded on January 16, 1891,[87] the state-chartered Carnegie Library, which opened on the current North Tryon site of the Main Library, was the first non-subscription library opened to members of the public in the city of Charlotte. The philanthropist Andrew Carnegie donated $25,000 dollars for a library building, on the condition that the city of Charlotte donate a site and $2,500 per year for books and salaries,[88] and that the state grant a charter for the library. All conditions were met, and the Charlotte Carnegie Library opened in an imposing classical building on July 2, 1903.\\r\\nThe 1903 state charter also required that a library be opened for the disenfranchised African-American population of Charlotte. This was completed in 1905 with the opening of the Brevard Street Library for Negroes, an independent library in Brooklyn, a historically black area of Charlotte, on the corner of Brevard and East Second Streets (now Martin Luther King Boulevard).[89] The Brevard Street Library was the first library for African Americans in the state of North Carolina,[89] and some sources say in the southeast.[90] The library was closed in 1961 when the Brooklyn neighborhood in Second Ward was redeveloped, but its role as a cultural center for African-Americans in Charlotte is continued by the Beatties Ford and West Boulevard branches of the library system, as well as by Charlotte's African-American Cultural Center.\\r\\nAccording to Nielsen Media Research, Charlotte is the 22nd largest television market in the nation (as of the 2016-2017 season) and the largest in the state of North Carolina.[91] Major television stations located in Charlotte include CBS affiliate WBTV 3 (the oldest television station in the Carolinas), ABC affiliate WSOC-TV 9, NBC affiliate WCNC-TV 36, CW affiliate WCCB 18, and PBS member station WTVI 42. Two cable sports networks are also headquartered in Charlotte: the ESPN-controlled SEC Network and the regional Fox Sports Carolinas.\\r\\nOther stations serving the Charlotte market include Fox owned-and-operated station WJZY 46 in Belmont, UNC-TV/PBS member station WUNG-TV 58 in Concord, independent station WAXN-TV 64 (a sister to WSOC-TV) in Kannapolis, and two stations in Rock Hill, South Carolina: MyNetworkTV owned-and-operated station WMYT-TV 55 (a sister to WJZY) and PBS member station WNSC-TV 30. Additionally, INSP is headquartered in nearby Indian Land, South Carolina.\\r\\nCable television customers are served by Spectrum, which offers a localized feed of Raleigh-based Spectrum News North Carolina.\\r\\nCharlotte is the 24th largest radio market in the nation, according to Arbitron. While major groups like iHeartMedia, Entercom and Radio One have stations serving Charlotte, several smaller groups also own and operate stations in the area.\\r\\nCharlotte has one major daily newspaper, The Charlotte Observer. It boasts the largest circulation in North[92] and South Carolina.\\r\\nCharlotte has a municipal waste system consisting of trash pickup, water distribution, and waste treatment. There are five waste water treatment plants operated by Charlotte Water (previously Charlotte-Mecklenburg Utility Department).[93] Charlotte has a biosolids program.[94] Some Chester residents spoke out against the program on February 26, 2013.[95] Charlotte's sludge is handled, transported, and spread on farm fields in Chester by a company called Synagro, a wholly owned subsidiary of the Carlyle Group[96] Charlotte's sludge is of the \\"CLASS B\\" variety, which means it still contains detectable levels of pathogens.[97][98]\\r\\nThe Charlotte Area Transit System (CATS) is the agency responsible for operating mass transit in Charlotte and Mecklenburg County. CATS operates light rail transit, historical trolleys, express shuttles, and bus services serving Charlotte and its immediate suburbs. The LYNX light rail system comprises a 9.6?mile line northÿsouth line known as the Blue Line, which saw 2025 ridership projections (18,500) exceeded after its first year of service. Bus ridership continues to grow (66% since 1998).[99] The 2030 Transit Corridor System Plan looks to supplement established bus service with light rail and commuter rail lines as a part of the LYNX system.\\r\\nIn 2011, the city of Charlotte and CATS staff conducted public forums to present the final Environmental Impact Statement (EIS) and gather public input from residents, property owners, and business owners located in northeast Charlotte, which is where the LYNX light rail is proposed to be extended from uptown Charlotte to UNC?Charlotte campus.[100] Construction on this portion is expected to end in March 16th, 2018.[101]\\r\\nA 2011 study by Walk Score ranked Charlotte the 49th most walkable of the 50 largest cities in the United States.[102]\\r\\nCharlotte's central location between the population centers of the northeast and southeast has made it a transportation focal point and primary distribution center, with two major interstate highways, I-85 and I-77, intersecting near the city's center. The latter highway also connects to the population centers of the Rust Belt.\\r\\nCharlotte's beltway, designated I-485 and simply called \\"485\\" by local residents, has been under construction for over 20 years, but funding problems have slowed its progress. The final segment was finished in mid-2015.[103] Upon completion, 485 will have a total circumference of approximately 67 miles (108?km). Within the city, the I-277 loop freeway encircles Charlotte's uptown (usually referred to by its two separate sections, the John Belk Freeway and the Brookshire Freeway) while Charlotte Route 4 links major roads in a loop between I-277 and I-485. Independence Freeway, which carries U.S. 74 and links downtown with the Matthews area, is undergoing an expansion and widening in the eastern part of the city.\\r\\nCharlotte Douglas International Airport is the sixth busiest airport in both the U.S. and the world overall as measured by traffic (aircraft movements).[104] It is served by many domestic and international airlines including Air Canada and Lufthansa. It is a major hub for American Airlines, having historically been a hub for its predecessors US Airways and Piedmont Airlines. Nonstop flights are available to many destinations across the United States, Canada, Central America, the Caribbean, Europe, Mexico, and South America.\\r\\nCharlotte is served daily by three Amtrak routes:\\r\\nCharlotte is also served by both Greyhound and low-cost curbside carrier Megabus.\\r\\nThe city is planning a new centralized multimodal train station called the Gateway Station. It is expected to house the future LYNX Purple Line, the new Greyhound bus station, and the Crescent line that passes through Uptown Charlotte.\\r\\nSister Cities International has designated nine sister cities of Charlotte:[105]","input":"Who is the city of charlotte nc named after?"},{"output":"the late 1970s","context":"\\r\\n\\r\\nVietnamese Australians (Vietnamese: Ng??i ~c g?c Vi?t) are Australians of Vietnamese ancestry, or people who migrated to Australia from Vietnam. Communities of overseas Vietnamese are referred to as Vi?t Ki?u or ng??i Vi?t h?i ngo?i.\\r\\n\\r\\nUp until 1975 there were fewer than 2,000 Vietnam-born people in Australia.[2] Following the takeover of South Vietnam by the North Vietnamese communist government in April 1975, Australia, being a signatory to the Convention Relating to the Status of Refugees, agreed to resettle its share of Vietnam-born refugees under a refugee resettlement plan between 1975 and 1985.  After the initial intake of refugees in the late 1970s, there was a second immigration peak in 1983ÿ84, most likely a result of the 1982 agreement between the Australian and Vietnamese governments (the Orderly Departure Program) which allowed relatives of Vietnamese Australians to leave Vietnam and migrate to Australia.  A third immigration peak in the late 1980s seems to have been mainly due to Australia's family reunion scheme.[3] Over 90,000 refugees were processed, and entered Australia during this time.[citation needed]\\r\\n\\r\\nBy the 1990s, the number of Vietnam-born migrating to Australia had surpassed the number entering as refugees. From 1991 to 1993, the percentage of Vietnam-born migrants had reached 77 per cent of the total intake of Vietnam-born arriving in Australia, and by 2000, the percentage of Vietnam-born migrants had climbed to 98 per cent. In 2001ÿ2002, 1,919 Vietnam-born migrants and 44 humanitarian entrants settled in Australia.\\r\\n\\r\\nVietnamese Australians vary in income and social class levels. Australian born Vietnamese Australians are highly represented in Australian universities and many professions (particularly as information technology workers, optometrists, engineers, doctors and pharmacists), while many other members in the community are subject to high unemployment rates, poverty and crime.[4]\\r\\n\\r\\nVietnamese Australians have an exceptionally low rate of return migration to Vietnam. In December 2001, the Department of Foreign Affairs and Trade estimated that there were 3,950 Australian citizens resident in Vietnam. It is not clear what proportion of this number are returned emigrants with Australian citizenship or their Vietnamese Australian children, and what number is simply other Australians in Vietnam for business or other reasons. The greater proportion (3,000) were recorded in the south of the country.\\r\\n\\r\\nAbout 0.8% of the Australian resident population was born in Vietnam; in terms of birthplace, Vietnam has been the fifth-largest source of immigration to Australia, behind the United Kingdom, New Zealand, China, and India and the Philippines.[1] Only Cambodia, the United States, and France have larger Viet Kieu communities. According to results of the 2016 Census, 219,355 Australian residents declared that they were born in Vietnam[1]\\r\\n\\r\\nAt the 2016 census, 294,798 people declared that they have Vietnamese ancestry.[1]\\r\\n\\r\\nIn the 2001 census, the 155,000 people of Vietnamese ancestry were first or second generation Australians; first generation Australians of Vietnamese ancestry outnumbered second generation Australians with Vietnamese ancestry (74%?: 26%) Relatively few people of Vietnamese ancestry stated another ancestry (6%). Among the leading ancestries, the proportion of people who spoke a language other than English at home was highest for those of Vietnamese (96%).[5]\\r\\n\\r\\nAt the 2006 Census, 173,663 Australian residents declared themselves to be of Vietnamese ancestry. A further 2,190 declared themselves as having Hmong ancestry. Respondents could nominate up to two ancestries.[6] There may additionally be persons of Vietnamese descent born in Australia, or of arguably non-Vietnamese ancestries (such as Cantonese) born in Vietnam, who elected not to nominate their ancestry as Vietnamese.\\r\\n\\r\\nOver three-quarters of people born in Vietnam live in New South Wales (63,786, or 39.9%) and Victoria (58,878, or 36.8%).[6] In Melbourne the suburbs of Richmond, Footscray, Springvale, Sunshine and St Albans have a significant proportion of Vietnamese-Australians, while in Sydney they are concentrated in Cabramatta, Cabramatta West, Canley Vale, Canley Heights, Bankstown, St John's Park and Fairfield. Other places of significant Vietnamese presence include Brisbane, where many have settled in suburbs like Darra and Inala.\\r\\n\\r\\nAccording to census data released by the Australian Bureau of Statistics in 2004, Vietnamese Australians are, by religion, 30.3 per cent Catholic, 0.4 per cent Anglican, 3.1 Other Christian, 55.2 per cent Other Religions, mainly Buddhist, Taoism, and Ancestor Worship and 11.0 per cent No Religion.\\r\\n\\r\\nAccording to the 2016 census, 40.46% of Australians with Vietnamese ancestry are Buddhists, 28.77% are Christians, and 26.46% follow secular or no religious beliefs.[7]\\r\\n\\r\\nIn 2001, the Vietnamese language was spoken at home by 174,236 people in Australia. Vietnamese was the sixth most widely spoken language in the country after English, Chinese, Italian, Greek and Arabic.\\r\\n\\r\\nDuring October 2003, government owned SBS TV began airing a Vietnamese news program called Thoi Su ('News'). The stated purpose was to provide a news service to cater for Australia's Vietnamese population. This was received poorly by the significant portion of the Vietnamese community as many had previously fled after the fall of South Vietnam and thus harbour resentment to the communist government and its institutions, including the state-controlled media.  Thoi Su was regarded as a mouthpiece for the ruling Vietnamese Communist Party, and uncritically endorsed government policy and practices using strong language while failing to report issues objectively including political arrests or religious oppression in Vietnam.  A large protest was convened outside SBS's offices.[8] SBS decided to drop Thoi Su (which was being provided at no cost to SBS through a satellite connection).  SBS subsequently began broadcasting disclaimers before each foreign news program stating it does not endorse their contents.","input":"When did the first vietnamese refugees arrived in australia?"},{"output":"Forty-five","context":"","input":"How many different species of fox are there?"},{"output":"central Mexico","context":"","input":"What is the location of the aztec empire?"},{"output":"general shape and appearance","context":"Plucked\\r\\nThe sousaphone (US: /?su?z?fo?n/), is a brass instrument in the same family as the more widely known tuba. Created around 1893 by J.W. Pepper at the direction of American bandleader John Philip Sousa (whom the instrument was then named after), it was designed to be easier to play than the concert tuba while standing or marching, as well as to carry the sound of the instrument above the heads of the band. Like the tuba, sound is produced by moving air past the lips, causing them to vibrate or \\"buzz\\" into a large cupped mouthpiece. Unlike the tuba, the instrument is bent in a circle to fit around the body of the musician; it ends in a large, flaring bell that is pointed forward, projecting the sound ahead of the player. Because of the ease of carrying and the direction of sound, it is widely employed in marching bands, as well as various other musical genres. Sousaphones were originally made out of brass but in the mid-20th century started to be made from lighter materials like fiberglass; today both types are in wide use.\\r\\n\\r\\n\\r\\nThe first sousaphone was built by James Welsh Pepper in 1893 at the request of John Philip Sousa,[1][2] who was dissatisfied with the hlicons in use by the United States Marine Band. Some sources credit C.G. Conn with its construction, because of the first sousaphone he built later in 1898.[3] Sousa wanted a tuba-like instrument that would send sound upward and over the band, much like a concert (upright) tuba. The new instrument had an oversized bell pointing straight up, rather than the directional bell of a normal hlicon.\\r\\nThe sousaphone was initially developed as a concert instrument rather than for marching. Sousa wanted the new instrument for the professional band which he started after leaving the Marines, and this band marched only once. Sousa mainly used sousaphones built by C.G. Conn.[4] Although less balanced on a player's body than a helicon, because of the large spectacular bell high in the air, the Sousaphone retained the tuba-like sound by widening the bore and throat of the instrument significantly. Its upright bell led to the instrument being dubbed a \\"rain-catcher\\". Some versions of this design allowed the bell to also rotate forward, projecting the sound to the front of the band. This bell configuration remained the standard for several decades and is the standard today.\\r\\nThe instrument proved practical for marching, and by 1908 the United States Marine Band adopted it.[5]\\r\\nVersions with the characteristic extra 90 bend making a forward-facing bell were developed in the early 1900s. Early sousaphones had 22-inch-diameter (560?mm) bells, with 24-inch (610?mm) bells popular in the 1920s. From the mid-1930s onward, sousaphone bells have been standardized at a diameter of 26 inches (660?mm). Some larger sousaphones (Monster, Grand, Jumbo, Giant or Grand Jumbo, depending on brand) were produced in limited quantities.\\r\\nThe sousaphone is a valved brass instrument with the same tube length and musical range as other tubas. The sousaphone's shape is such that the bell is above the tubist's head and projecting forward. The valves are situated directly in front of the musician slightly above the waist and all of the weight rests on the left shoulder. The bell is normally detachable from the instrument body to facilitate transportation and storage. Except for the instrument's general shape and appearance, the sousaphone is technically similar to a tuba.\\r\\nFor simplicity and light weight, modern sousaphones almost always use three non-compensating piston valves in their construction, in direct contrast to their concert counterparts' large variation in number, type, and orientation. Both the tuba and sousaphone are semi-conical brass instruments. No valved brass instrument can be entirely conical, since the middle section containing the valves must be cylindrical. While the degree of bore conicity does affect the timbre of the instrument, much as in a cornet and trumpet, or a euphonium and a trombone, the bore profile of a sousaphone is similar to that of most tubas.\\r\\nTo facilitate making the mouthpiece accessible to players of different height or body shapes, most sousaphones contain a detachable tubing gooseneck which arises from the lead pipe on the upwind side of the valves. One or two slightly-angled bit(s) (short tubing lengths) are inserted into the gooseneck, and then the mouthpiece is inserted into the terminal bit. This arrangement may be adjusted in height and yaw angle to place the mouthpiece comfortably at the player's lips.\\r\\nMost sousaphones are manufactured from sheet brass, usually yellow or silver, with silver, lacquer, and gold plating options, much like many brass instruments. However, the sousaphone (uniquely) is also commonly seen manufactured from fiberglass, due to its lower cost, greater durability, and significantly lighter weight.\\r\\nThe weight of a sousaphone can be between 18 pounds (8?kg) and 50 pounds (23?kg).[6]\\r\\nMost modern sousaphones are made in the key of BB? (Low B Flat) and like tubas (which are commonly made in pitches of BB?, CC, EE?, and F) the instrument's part is written in \\"concert pitch\\", not transposed by key for a specific instrument. Although sousaphones may have a more restricted range than their concert tuba counterpart (most sousaphones have 3 valves instead of 4 to reduce weight), generally they can all play the same music and usually have parts written in the bass clef and the indicated octave is played (unlike double bass or electric bass that sound an octave lower than the indicated note.) Many older sousaphones were pitched in the key of E?, but current production of sousaphones in that key is limited.\\r\\nAlthough most major instrument manufacturers have made, and many continue to make, sousaphones, Conn and King (H.N. White) instruments are generally agreed among players to be the standards against which other sousaphones are judged for tone quality and playability.[citation needed] Perhaps the most highly regarded sousaphone ever built is the 0.734-inch-bore (18.6?mm) Conn model 20K, introduced in the mid-1930s and still in production. Some players, especially those who find the 20K too heavy for marching, prefer the slightly smaller 0.687-inch-bore (17.4?mm) King model 1250, first made in the late 1920s and also still in production as the model 2350. Historically, Holton, York and Martin sousaphones have also been considered fine horns. Unlike with other brass instruments, some players dislike the sousaphones made by non-American manufacturers.\\r\\nVery large bore (>= 0.750?inch) sousaphones, with oversized bells as large as 32 inches (81?cm) in diameter, were made by Conn (\\"Grand Jumbo\\" [46K (3-valve) & 48K (4-valve)]) and King (\\"Jumbo\\" [1265 (3- & 4-valve versions)] & \\"Giant\\" [1270 (3-valve) & 1271 (4-valve)]) in the mid-1920s and 1930s, and by Martin, York, & Buescher, but they disappeared from the catalogs during the Depression or at the onset of World War II. Because of their weight and cost, few were made and even fewer survive, especially the 4-valve models.\\r\\nIn recent years, sousaphones have been available made of fiberglass reinforced plastics instead of brass. The fiberglass versions are used mainly for marching, with brass instruments being used for all other situations. Depending on the model, the fiberglass version does not have as dark and rich a tone as the brass (King fiberglass sousaphones tended to have smooth fiberglass and a tone somewhat more like a brass sousaphone; Conn fiberglass sousaphones often had rough fiberglass exteriors and a thinner sound; the Conn is also lighter). Regardless, fiberglass sousaphones are lighter than their brass counterparts and work well for smaller players who could not otherwise play the heavy brass instruments in a marching band. Although the tone of fiberglass models tends to be thinner and less \\"warm\\" (earning them the nicknames \\"Plastic Bugle\\", \\"Toilet Bowl\\", and \\"Tupperware\\" among players in some ensembles[citation needed]), it is considered acceptable by the high schools due to the tradeoff in durability, cost, and weight.\\r\\nIn the 1920s and 1930s, four-valved sousaphones were often used by professional players, especially E? sousaphones; today, however, four-valved B? sousaphones are uncommon and are prized by collectors, especially those made by Conn, King (H.N. White), and Holton. Jupiter Company started production of four-valve BB? sousaphones in the late 2000s, and Dynasty USA makes a four-valve BBb sousaphone as well. Criticisms of the fourth valve on a sousaphone center around additional weight, although the fourth valve improves intonation and facilitates playing of the lower register.\\r\\nDue to the large size of most sousaphones, the sub-contra register (for which the fourth valve is largely intended) is already covered by alternate resonances, known as \\"false tones\\" (see Tuba article). Many beginners are not aware of the false-tone resonances on their sousaphones because these notes reside in the sub-contra register, which is nearly impossible for most beginners to access. Some professionals develop a \\"raised embouchure\\" to securely play these notes. This is where either the upper or lower lip (depending on the player) takes up most of the mouthpiece area. The embouchure provides almost twice the room for vibration of the single lip (compared to the 50ÿ50 embouchure).\\r\\nAsian sousaphones made in China and India are gaining popularity in the street band market. In Switzerland and Southern Germany, \\"Guggenmusik\\" bands often use these instruments that provide great display and passable tone. Most are tuned in E?. Brands like Zweiss with older British designs make affordable sousaphones that have broken the ?500 barrier. These are mostly in the medium-bell size of 23 inches (580?mm). Chinese brands are mostly reverse-engineered models and quite passable.\\r\\nIn large marching bands of the United States, the bell is often covered with a tight fitting cloth, called a sock, which enables the sousaphone section to spell out the school's name, initials, or mascot. The Leland Stanford Junior University Marching Band T??bz! have a tradition of painting the front surface of their sousaphone bells with a variety of images.\\r\\nSousaphone players are also known to perform the 'flaming tubas' in which flash paper is ignited in the bell, thus making it appear as if the musician is breathing fire. David Silverman (animator) (AKA Tubatron ) developed a propane powered flaming sousaphone with a trigger valve to control an array of flame jets across the top of the bell of his horn. The Yale Precision Marching Band has made a tradition of setting fire to the tops of the bells of their sousaphones, including in the fall of 1992 when sousaphones served as the \\"candles\\" of a \\"wedding cake\\" formed by the band when two band alumni were married during a halftime show. They also utilize what they refer to as the \\"berphone\\", a sousaphone that was disassembled from its coiled format and welded back together on a twelve-foot frame to extend straight up from the player's shoulders.\\r\\nJohn Philip Sousa was a benefactor of the University of Illinois music program and a friend of the university's Director of Bands Albert Austin Harding. The Marching Illini became the first band to march and play at the same time, and were the first band to use sousaphones on the field.[citation needed]\\r\\nThe sousaphone sections of some marching bands have developed specialized performance traditions. The University of California Marching Band Bass section traditionally \\"struts\\" during the band's pregame show. During the \\"strut\\" the section separates from the rest of the band, circles the North goal post, and rejoins the band to complete the Script Cal. The University of Southern California Trojan Marching Band sousaphones play John Williams' \\"Imperial March\\" from Star Wars in single file when crossing streets on their way to and from performances on the USC campus. When The Ohio State University Marching Band performs its traditional Script Ohio formation, a senior sousaphone player dots the \\"i\\".\\r\\nThe Fightin' Texas Aggie Band sousaphone section (called \\"Bass Horns\\" within the university but never, ever \\"tubas\\") execute a distinct two-step and four-step counter-march during marching performances. During halftime performances this is accompanied (specifically for the last rank consisting all of 12 bass horns) by a \\"huh! huh!\\" from the crowd.\\r\\nThe University of Delaware Fightin' Blue Hen Marching Band has several traditions involving sousaphone players. During pre-game, they branch off from the rest of the band. From here, the sousaphone players run in a snake around the field jumping to drum line cadence. At most pre-games they act out a skit as well. At post game, \\"In My Life\\" by The Beatles is played featuring a sousaphone solo while the band sings.\\r\\nAfter every pre-game show at Florida State University when the section (known by all the marching band members as \\"Flush\\"- short for \\"Royal Flush\\") run in a circle, with their horns tipped up parallel to the ground, around the Seminole head on the field with the head drum major in the center of the circle. This is called \\"Flushing the field\\" or \\"Flushing the Indian Head\\", derived from the sections nickname \\"Flush\\".\\r\\nThe Marching Virginians of Virginia Tech perform a version of the Hokie Pokie featuring the sousaphone section putting their sousaphones in, taking their sousaphones out, putting their sousaphones in, and shaking them all about ÿ followed by an all-sousaphone kick line.\\r\\nThe University of Toledo Sousaphone line (also called The RMB Dosbas) march off the field in a snake line after home games and performs the song \\"sonic boom\\" when the rest of the band meets back with them.\\r\\nFor the last 20 years The University of Idaho Vandals Marching Band Sousaphone section all wear long skirts that were originally used by the 1948 University Women's Chorus. University of Idaho Vandals Sousaphone Section\\r\\nThe sousaphone is an important fixture of the New Orleans brass band tradition and is still used in groups such as the Dirty Dozen Brass Band by Kirk Joseph. Soul Rebels Brass Band from New Orleans features sousaphone player Edward Lee, Jr.\\r\\nSinaloa, a state of Mexico, has a type of music called Banda Sinaloense, and the sousaphone is used there as a tuba.\\r\\nDamon \\"Tuba Gooding Jr.\\" Bryson from The Roots plays the sousaphone on Late Night with Jimmy Fallon.\\r\\nNat Mcintosh is the sousaphone player and co-founder of Youngblood Brass Band, who play a mixture of traditional New Orleans style brass band music and hip hop.\\r\\nThe Lemon Bucket Orkestra, a Canadian self-described \\"Balkan-Klezmer-Gypsy-Punk-Super-Party-Band\\", features a sousaphone as one of their instruments.\\r\\nRed Baraat, a Brooklyn-based dhol & brass band that fuses North Indian Bhangra with hip-hop, go-go and jazz music, features John Altieri on sousaphone.\\r\\nWarren G. Harding, the 29th President of the United States, was a sousaphone player.[7]","input":"What is the difference between tuba and sousaphone?"},{"output":"The Honky Tonk Man","context":"The WWE Intercontinental Championship is a professional wrestling championship contested in and owned by the American promotion WWE on the Raw brand. The title was introduced into WWE in 1979, which was known as the World Wrestling Federation (WWF) at the time. Pat Patterson, holder of the WWF North American Heavyweight Championship, was awarded the title (with the kayfabe explanation that he won a tournament in Rio de Janeiro, Brazil and unified the North American and South American titles).[1][2][3]\\r\\nThe Intercontinental Championship has been called the second most important championship in the company, after the WWE Championship.[4] It has been active in WWE for the second longest period, but is the third oldest active title, behind the WWE Championship (1963) and the United States Championship (1975), the latter of which was acquired from World Championship Wrestling (WCW) in 2001. In 2002, the WWF was renamed to World Wrestling Entertainment (WWE), and the championship was renamed as the WWE Intercontinental Championship.[5] As a result of the 2017 WWE Superstar Shake-up, it is exclusively contested on the Raw brand.\\r\\nOverall, there have been 78 different Intercontinental Champions. Chris Jericho holds the record for the most reigns with nine, The Honky Tonk Man holds the longest reign at 454 days. Only three more wrestlers ÿ Pedro Morales, Don Muraco, and Randy Savage ÿ have held the championship for a continuous reign of more than a year. The current champion is The Miz, who is in his seventh reign. He won the championship by defeating Dean Ambrose at Extreme Rules in Baltimore, Maryland on June 4, 2017.\\r\\n\\r\\n\\r\\nAs of September 18, 2017.\\r\\nAs of September 18, 2017.","input":"Who is the longest reigning wwe intercontinental champion?"},{"output":"June 30, 1973","context":"On December 1, 1969, the Selective Service System of the United States conducted two lotteries to determine the order of call to military service in the Vietnam War for men born from 1944 to 1950. These lotteries occurred during a period of conscription from just before World War II to 1973. It was the first time a lottery system had been used to select men for military service since 1942.\\r\\n\\r\\nThe lottery numbers assigned in December 1969 were used during calendar year 1970 both to call for induction and to call for physical examination, a preliminary call covering more men.\\r\\n\\r\\nThere was a draft system in place, for Vietnam, prior to the 1969 Lottery Draft system. I was drafted in 1965 to serve in Vietnam. It was the left over post WWII draft system. I was drafted in 1965, and shipped over to Vietnam the end of 1966 as Part of the 9th Infantry Div.\\r\\n\\r\\nThe days of the year (including February 29) were written on slips of paper. These pieces of paper were then placed in separate plastic capsules that were mixed in a shoebox and then dumped into a deep glass jar. Capsules were drawn from the jar one at a time.\\r\\n\\r\\nThe first number drawn was 258 (September 14), so all registrants with that birthday were assigned lottery number 1. The second number drawn corresponded to April 24, and so forth. All men of draft age (born 1944 to 1950) who shared a birth date would be called to serve at once. The first 195 birthdates drawn were later called to serve in the order they were drawn; the last of these was September 24.[1]\\r\\n\\r\\nAlso on December 1, 1969, a second lottery was held with the 26 letters of the alphabet. The first letter drawn was \\"J\\", which was assigned number 1. The second letter was \\"G\\", and so on, until all 26 letters were assigned numbers, with the last being \\"V\\". Among men with the same birthdate, the order of induction was determined by the ranks of the first letters of their last, first, and middle names.[2] Anyone with initials \\"JJJ\\" would have been first within the shared birthdate, followed by \\"JGJ\\", \\"JDJ\\", and \\"JXJ\\"; anyone with initials \\"VVV\\" would have been last.[3]\\r\\n\\r\\nPeople soon noticed that the lottery numbers were not distributed uniformly over the year. In particular, November and December births, or dates 306 to 366, were assigned mainly to lower draft numbers representing earlier calls to serve (see figure). This led to complaints that the lottery was not random as the legislation required. Analysis of the procedure suggested that mixing 366 capsules in the shoe box did not mix them sufficiently before dumping them into the jar. (\\"The capsules were put in a box month by month, January through December, and subsequent mixing efforts were insufficient to overcome this sequencing.\\")[2] Only five days in DecemberDec. 2, 12, 15, 17 and 19were higher than the last call number of 195; had the days been evenly distributed, 14 days in December would have been expected to remain uncalled. From January to December, the rank of the average draft pick numbers were 5 4 1 3 2 6 8 9 10 7 11 12. A Monte Carlo simulation found that the probability of a random order of months being this close to the 1ÿ12 sequence expected for unsorted slips was 0.09%.[4]\\r\\n\\r\\nDraft lotteries were conducted again in 1970 (for those born in 1951) and from 1971 to 1975 (for 1952 to 1956 births). The draft numbers issued in 1972 were never used the next year to call for induction into service, because the last call was December 7 and authority to induct expired on June 30, 1973.\\r\\n\\r\\nThe 1972 to 1975 lottery numbers were used to call some men born 1953 to 1956 for physical exams. The highest number called for a physical was 215 (for tables 1970 through 1976).[3]\\r\\n\\r\\nThe reason for the draft of 1969 was to add more much-needed military personnel towards the Vietnam War. After World War II, Japan left Vietnamese Emperor Bao Dai as the head of the country. Ho Chi Minh, another Vietnamese leader who was communist and sought immediate independence for the whole of Vietnam, saw this as an opportunity to strike (knowing Bao Dai had little support from the general population as he was widely regarded as a Japanese-installed puppet-leader) and successfully took over Hanoi and most of northern Vietnam. Ho Chi Minh then set up the Democratic Republic of Vietnam (the DRV, or North Vietnam) by the beginning of 1946. Emperor Bao, still in power in the southern half of the country, set up the State of Vietnam, with support from the returning French colonial rulers, with Saigon as its capital. Ho Chi Minh based his political structure and government off of other communist states such as Soviet Russia, while Emperor Bao Dai wanted a Vietnam that was modelled after the West, like the United States,[5] with a democratic and free government.\\r\\n\\r\\nBoth Ho's DRV (with support from the Soviet Union and China (after 1949)) and Bao Dai's State of Vietnam (with strong French military support) began open armed conflict against one another until the battle of Dien Bien Phu in 1954 ended with the communist Viet Minh forces as the victor. Afterwards at the Geneva Conference, Vietnam was decided as to be split along the 17th Parallel (N). There was supposed to be a nation-wide reunification election held in 1956 to determine which side would take over running the whole of Vietnam but another leader took over Bao Dai in the South. Ngo Dinh Diem took over leadership of the State of Vietnam (soon known as South Vietnam) and Diem, who took a very harsh opposing stance against communism, was entirely opposed to reconciliation with the North and against the elections of 1956 to be held at all.[5]\\r\\n\\r\\nIn other parts of the world, the Cold War was intensifying between Soviet Russia and the United States. The U.S. was becoming more rigid in its policies with the communist allies of Russia. President Dwight D. Eisenhower started supporting the South Vietnamese who were also against the communist north.[5]\\r\\n\\r\\nThe U.S. began training and equipping Diem's forces with weapons. Conflicts between communist sympathizers began occurring in the South. At the time, the U.S. had only committed around 800 personnel to train and outfit the South Vietnamese. In 1961, the John F. Kennedy administration started working under the Domino Theory, which stated that if South Vietnam was to fall to the North, then other places in southeast Asia were to become vulnerable to the communists as well. This caused President Kennedy to begin sending additional American soldiers to Vietnam. By 1962, there were around 9,000 personnel in Vietnam.[5]\\r\\n\\r\\nIn 1963, a coup was organized by South Vietnamese generals which resulted in the death of Diem. President Lyndon B. Johnson increased U.S. personnel in Vietnam due to the political instability in the country. In August 1964, two U.S. warships were attacked by North Vietnamese torpedo boats. Johnson issued an attack order against North Vietnam, and Congress passed a motion which gave him more authority over military decisions. In 1965, President Johnson had sent 82,000 troops to Vietnam, and his officials wanted another 175,000. Due to the heavy demand for military personnel, the United States required more than what the regular military could provide, causing the acceleration of the draft. Between 1965 and 1972 the draft provided 2,215,000 service members to the U.S. military.[5]\\r\\n\\r\\nPreviously in the United States, during the War of 1812, President Madison established a commission to recommend the best ways to raise military manpower; to keep the draft or to institute a volunteer army.[6]\\r\\n\\r\\nAfter much debate within the Nixon administration and Congress, it was decided that an all-volunteer force was affordable, feasible, and would enhance the nations security.[7] President Richard Nixon issued an executive order prescribing regulations for random selection by the United States Selective Service on November 26, 1969.[8]\\r\\n\\r\\nIn the 1960s anti-war movements started to occur in the U.S., mainly among those on college campuses and in more leftist circles, especially those who embraced the hippie lifestyle.[9] College students were entitled to a deferment (2-S status) but were subject to the draft if they dropped out or graduated.[10]\\r\\n\\r\\nIn 1967, the number of U.S. military personnel in Vietnam was around 500,000. The war was costing the U.S. $25 billion a year, and many of the young men drafted were being sent to a war they wanted no part of. Martin Luther King Jr. also started to support the anti-war movement on the grounds of it being immoral and the amount of African Americans that were being killed.[9]\\r\\n\\r\\nNovember 15, 1969 marked the largest anti war movement in the history of the United States. This protest featured many anti-war political speakers and popular singers of the time. Many people at the time saw Richard Nixon as a liar; when he took office, he claimed that he would begin troop withdrawals from Vietnam immediately. After ten months of being in office, the president had yet to start withdrawals, and United States citizens felt lied to. Later, president Nixon claimed to have been watching sports as the anti-war demonstration took place outside the White House.[9]\\r\\n\\r\\nThe 1970s were a time of turmoil in the United States, beginning with the civil rights movement which set the standards for practices by the anti-war movement. The 1969 draft lottery only encouraged resentment of the Vietnam War and the draft. It strengthened the anti-war movement,[verification needed] and all over the United States, people decried discrimination by the draft system \\"against low-education, low-income, underprivileged members of society\\".[11]\\r\\n\\r\\nThe draft lottery had social and economic consequences because it generated resistance to military service and the resisters, draft evaders or \\"draft dodgers\\", were generally young, well-educated, healthy men. The fear of military service in Vietnam influenced many young men born in the late 1940s to join the National Guard. These young men were aware that the National Guard would be unlikely to send its soldiers to Vietnam. Many men were unable to join the National Guard, even though they had passed their physicals, because many state National Guards had long waiting lists just to enlist. Still others chose legal sanctions such as imprisonment, either showing their disapproval by burning their draft cards or draft letters, or simply not presenting themselves for the military service test. Others left the country, commonly moving to Canada. The number of American citizens who moved to Canada during the Vietnam war because of the draft is estimated to be around 125,000; it is believed that about half returned to the United States after the Nixon era (when the war was also over)(1975).[citation needed]\\r\\n\\r\\nLottery procedure was improved the next year although public discontent continued to grow [12] until \\"authority to induct expired on June 30, 1973\\".[3]\\r\\n\\r\\nIn 1970, covering 1951 birthdates for use during 1971 (sometimes called the 1971 draft), scientists at the National Bureau of Standards prepared 78 random permutations of the numbers 1 to 366 using random numbers selected from published tables.[13] From the 78 permutations, 25 were selected at random and transcribed to calendars using 1 = January 1, 2 = January 2, ... 365 = December 31. Those calendars were sealed in envelopes. 25 more permutations were selected and sealed in 25 more envelopes without transcription to calendars. The two sets of 25 envelopes were furnished to the Selective Service System.[13]\\r\\n\\r\\nOn June 2, an official picked two envelopes, thus one calendar and one raw permutation. The 365 birthdates (for 1951) were written down, placed in capsules, and put in a drum in the order dictated by the selected calendar. Similarly, the numbers from 1 to 365 were written down and placed into capsules in the order dictated by the raw permutation.[13]\\r\\n\\r\\nOn July 1, the drawing date, one drum was rotated for an hour and the other for a half-hour (its rotating mechanism failed).[13] Pairs of capsules were then drawn, one from each drum, one with a 1951 birthdate and one with a number 1 to 366. The first date and number drawn were September 16 and 139, so all men born September 16, 1951, were assigned draft number 139. The 11th draws were the date July 9 and the number 1, so men born July 9 were assigned draft number 1 and drafted first.[13]\\r\\n\\r\\nThe military draft method used back in the 1950s and 1960s involved using dates and numbers mixed randomly and then drawn to decide who would go to war. In the present-day, not much has changed on how the draft would be conducted if it was ever needed. The Selective Service Committee who presides over the draft procedures still have a large tumbler that holds all the number and dates that will be drawn to select candidates and the only thing that seems to have changed between the method of the past and the present one is that instead of using pieces of paper in blue capsules the SSC now uses ping pong balls with the dates and numbers on them.[14]","input":"When did the viet nam war draft end?"},{"output":"indentured servants","context":"Slavery in the colonial United States (1600ÿ1776) developed from complex factors, and several theories have been proposed to explain development of the trade and institution. Slavery was strongly associated with the European colonies' need for labor, especially for the labor-intensive plantation economies of the sugar colonies in the Caribbean, operated by Great Britain, France, Spain, and the Dutch Republic.\\r\\nMost slaves who were brought or kidnapped to the Thirteen British colonies, which later became the Eastern seaboard of the United States, were imported from the Caribbean, not directly from Africa. They were predominately transported to the Caribbean islands as a result of the Atlantic slave trade. Indigenous people were also enslaved in the North American colonies, but on a much smaller scale, and Indian slavery ended in the eighteenth century. In the English colonies, slave status for Africans became hereditary in the mid-17th century and passage of colonial laws that defined children born in the colonies as taking the status of the mother, under the principle of partus sequitur ventrem .[2][3]\\r\\n\\r\\n\\r\\nWhile the British knew about Spanish and Portuguese slave trading, they did not implement slave labor in the Americas until the 17th century.[4] British travelers were fascinated by the dark-skinned people they found in West Africa; they developed mythologies that situated these new human beings in their view of the cosmos.[5]\\r\\nThe first Africans to arrive in England came voluntarily in 1555 with John Lok (an ancestor of the famous philosopher John Locke). Lok intended to teach them English in order to facilitate trading of material goods with West Africa.[6] This model gave way to a slave trade initiated by John Hawkins, who captured 300 Africans and sold them to the Spanish.[7] Blacks in England were subordinate but never had the legal status of chattel slaves.[8]\\r\\nIn 1607, England established Jamestown as its first permanent colony on the North American continent.[9] Tobacco became the chief commodity crop of the colony, due to the efforts of John Rolfe in 1611. Once it became clear that tobacco was going to drive the Jamestown economy, more workers were needed for the labor-intensive crop. The British aristocracy also needed to find a labor force to work on its sugar plantations in the Americas. The major sources were indentured servants from Britain, Native Americans, and West Africans.[10] During this period, Barbados became an English Colony in 1624 and the Caribbean's Jamaica in 1655. These and other Caribbean colonies became the center of wealth generated from sugar cane and the focus of the slave trade for the growing English empire.[11]\\r\\nThe English entertained two lines of thought simultaneously toward the indigenous Native Americans. Because these people were lighter skinned, they were seen as more European and therefore as candidates for civilization. At the same time, because they were occupying the land desired by the colonial powers, they were from the beginning, targets of potential military attack.[12]\\r\\nAt first, indentured servants were used as the needed labor.[13] These servants provided up to seven years of service in exchange for having their trip to Jamestown paid for by someone in Jamestown. Once the seven years was over, the indentured servant was free to live in Jamestown as a regular citizen. However, colonists began to see indentured servants as too costly, in part because the high mortality rate meant the force had to be resupplied. In 1619, Dutch traders brought African slaves taken from a Spanish ship to Jamestown; in North America, the Africans were also generally treated as indentured servants in the early colonial era.[14]\\r\\nSeveral colonial colleges held enslaved people as workers and relied on them to operate.[15]\\r\\nUntil the early 18th century, enslaved Africans were difficult to acquire in the colonies that became the United States, as most were sold to the West Indies, where the large plantations and high mortality rates required continued importation of slaves. One of the first major centers of African slavery in the English North American colonies occurred with the founding of Charles Town and the Province of Carolina in 1670. The colony was founded mainly by planters from the overpopulated British sugar island of Barbados, who brought relatively large numbers of African slaves from that island to establish new plantations.[16]\\r\\nFor several decades it was difficult for planters north of the Caribbean to acquire African slaves. To meet agricultural labor needs, colonists practiced Indian slavery for some time. The Carolinians transformed the Indian slave trade during the late 17th and early 18th centuries by treating such slaves as a trade commodity to be exported, mainly to the West Indies. Historian Alan Gallay estimates that between 1670 and 1715, between 24,000 and 51,000 captive Native Americans were exported from South Carolinamuch more than the number of Africans imported to the colonies of the future United States during the same period.[17]\\r\\nThe first Africans to be brought to British North America landed in Virginia in 1619. They arrived on a Dutch ship that had captured them from the Spanish. These approximately 20 individuals appear to have been treated as indentured servants, and a significant number of enslaved Africans earned freedom by fulfilling a work contract or for converting to Christianity.[18] Some successful free people of color, such as Anthony Johnson, in turn acquired slaves or indentured servants for workers. Historians such as Edmund Morgan say this evidence suggests that racial attitudes were much more flexible in 17th-century Virginia than they would later become.[19] A 1625 census recorded 23 Africans in Virginia. In 1649 there were 300, and in 1690 there were 950.[20]\\r\\nSlaves, African and indigenous, made up a smaller part of the New England economy, which was based on yeoman farming and trades, and a smaller fraction of the population, but they were present.[21] The Puritans codified slavery in 1641.[22][23] The Massachusetts royal colony passed the Body of Liberties, which prohibited slavery in many instances, but did allow three legal bases of slavery.[23] Slaves could be held if they were captives of war, if they sold themselves into slavery or were purchased from elsewhere, or if they were sentenced to slavery by the governing authority.[23] The Body of Liberties used the word \\"strangers\\" to refer to people bought and sold as slaves, as they were generally not English subjects. Colonists came to equate this term with Native Americans and Africans.[24]\\r\\nThe Dutch West India Company introduced slavery in 1625 with the importation of eleven enslaved blacks who worked as farmers, fur traders, and builders to New Amsterdam (present day New York City), capital of the nascent province of New Netherland.[25] The Dutch colony expanded across the North River (Hudson River) to Bergen (in today's New Jersey). Later slaves were also held privately by settlers to the area.[26][27] Although enslaved, the Africans had a few basic rights and families were usually kept intact. They were admitted to the Dutch Reformed Church and married by its ministers, and their children could be baptized. Slaves could testify in court, sign legal documents, and bring civil actions against whites. Some were permitted to work after hours earning wages equal to those paid to white workers. When the colony fell to the English in the 1660s, the company freed all its slaves, which created an early nucleus of free negros in the area.[25]\\r\\nThe English continued to import slaves to support needed work. Enslaved Africans performed a wide variety of skilled and unskilled jobs, mostly in the burgeoning port city and surrounding agricultural areas. In 1703 more than 42% of New York City's households held slaves, a percentage higher than in the cities of Boston and Philadelphia, and second only to Charleston in the South.[28]\\r\\nThe French introduced legalized slavery into their colonies in New France both near the Great Lakes and the Mississippi River. (They also used slave labor on their island colonies in the Caribbean: Guadeloupe and especially Saint-Domingue.) After the port of New Orleans was founded in 1718 with access to the Gulf Coast, French colonists imported more African slaves to the Illinois Country for use as agricultural or mining laborers. By the mid-eighteenth century, slaves accounted for as many as a third of the limited population in that rural area.[29]\\r\\nSlavery was much more extensive in colonial Louisiana, where the French developed sugar cane plantations along the Mississippi river. Slavery was maintained during the French (1699 ÿ 1763, and 1800 ÿ 1803) and Spanish (1763 ÿ 1800) periods of government. The first people enslaved by the French were Native Americans, but they could easily escape into the countryside which they knew well. Beginning in the early 18th century, the French imported Africans as laborers in their efforts to develop the colony. Mortality rates were high for both colonists and Africans, and new workers had to be imported.\\r\\nImplemented in colonial Louisiana in 1724, Louis XIV of France's Code Noir regulated the slave trade and the institution of slavery in the French colonies. As a result, Louisiana and the Mobile area developed very different patterns of slavery compared to the British colonies.[30] As written, the Code Noir gave some rights to slaves, including the right to marry. Although it authorized and codified cruel corporal punishment against slaves under certain conditions, it forbade slave owners to torture slaves, to separate married couples (and to separate young children from their mothers). It required owners to instruct slaves in the Catholic faith, implying that Africans were human beings endowed with a soul. , an idea that had not been acknowledged until then.[31][32][33]\\r\\nThe Code Noir forbade interracial marriages, but interracial relationships were formed in La Louisiane from the earliest years. In New Orleans society particularly, a formal system of concubinage, known as pla?age, developed. Usually formed between young white men and African or African-American women, these relationships were formalized with contracts that sometimes provided for freedom for a woman and her children (if she was still enslaved), education for the mixed-race children of the union, and sometimes a property settlement. The free people of color became an intermediate social caste between the whites and the mass of enslaved blacks; many practice artisan trades, and some acquired educations and property.\\r\\nGradually in the English colonies, slavery became known as a racial caste that generally encompassed all people of African descent, even if mixed race. From the 17th century, Virginia defined all children born to enslaved mothers as born into slavery, regardless of their father's ancestry. Similarly, Virginia denied that converting a slave to Christianity was grounds for freedom. Even free people of color or mixed-race (known as mulattoes) were restricted in their rights, especially as colonies passed harsher laws after early slave revolts. During the centuries of slavery in the British colonies, many slaves were of mixed-race ancestry.[30][33]\\r\\nThe Spanish introduced slavery in Florida soon after they claimed it in 1513. Spanish settlement was sparse and they held comparatively few slaves.[34] But the Spanish promised freedom to refugee slaves from the English South Carolina and Georgia colonies, in order to destabilize English settlement. If the slaves converted to Catholicism and agreed to serve in a militia for Spain, they could become Spanish citizens. By 1730 the black settlement known as Fort Mose developed near St. Augustine and was later fortified. There were two known Fort Mose sites in the eighteenth century, and the men helped defend St. Augustine against the British. It is \\"the only known free black town in the present-day southern United States that a European colonial government sponsored.[35] The Fort Mose Site, today a National Historic Landmark, is the location of the second Fort Mose.\\"[35] During the nineteenth century, this site became marsh and wetlands.\\r\\nIn 1763, Great Britain took over Florida in an exchange with Spain after defeating France in the Seven Years' War. Spain evacuated its citizens from St. Augustine, including the residents of Fort Mose, transporting them to Cuba. As Britain developed the colony for plantation agriculture, the percentage of slaves in the population rose from 18% in twenty years to almost 65% by 1783.[36]\\r\\nThe barriers of slavery hardened in the Second half of the 17th century, and imported Africans' prospects grew increasingly dim. By 1640, the Virginia courts had sentenced at least one black servant, John Punch, to slavery.[37] In 1656 Elizabeth Key won a suit for freedom based on her father's status as a free Englishman, and his having baptized her as Christian in the Church of England. In 1662 the Virginia House of Burgesses passed a law with the doctrine of partus, stating that any child born in the colony would follow the status of its mother, bond or free. This was an overturn of a longheld principle of English Common Law, whereby a child's status followed that of the father. It enabled slaveholders and other white men to hide the mixed-race children born of their rape of slave women and removed their responsibility to acknowledge, support, or emancipate the children.\\r\\nDuring the second half of the 17th century, the British economy improved and the supply of British indentured servants declined, as poor Britons had better economic opportunities at home. At the same time, Bacon's Rebellion of 1676 led planters to worry about the prospective dangers of creating a large class of restless, landless, and relatively poor white men (most of them former indentured servants). Wealthy Virginia and Maryland planters began to buy slaves in preference to indentured servants during the 1660s and 1670s, and poorer planters followed suit by c.1700. (Slaves cost more than servants, so initially only the wealthy could invest in slaves.) The first British colonists in Carolina introduced African slavery into the colony in 1670, the year the colony was founded, and Charleston ultimately became the busiest slave port in North America. Slavery spread from the South Carolina Lowcountry first to Georgia, then across the Deep South as Virginia's influence had crossed the Appalachians to Kentucky and Tennessee. Northerners also purchased slaves, though on a much smaller scale. Enslaved people outnumbered free whites in South Carolina from the early 1700s to the Civil War. An authoritarian political culture evolved to prevent slave rebellion and justify white slave holding. Northern slaves typically dwelled in towns, rather than on plantations as in the South, and worked as artisans and artisans' assistants, sailors and longshoremen, and domestic servants.[38]\\r\\nIn 1672, King Charles II rechartered the Royal African Company (it had initially been set up in 1660), as an English monopoly for the African slave and commodities tradethereafter in 1698, by statute, the English parliament opened the trade to all English subjects.[39] The slave trade to the mid-Atlantic colonies increased substantially in the 1680s, and by 1710 the African population in Virginia had increased to 23,100 (42% of total); Maryland contained 8,000 Africans (23% of total).[40] In the early 18th century, England passed Spain and Portugal to become the world's leading slave-trader.[39][41]\\r\\nThe North American royal colonies not only imported Africans but also captured Native Americans, impressing them into slavery. Many Native Americans were shipped as slaves to the Caribbean. Many of these slaves from the British colonies were able to escape by heading south, to the Spanish colony of Florida. There they were given their freedom, if they declared their allegiance to the King of Spain and accepted the Catholic Church. In 1739 Fort Mose was established by African American freedmen and became the northern defense post for St. Augustine. In 1740, English forces attacked and destroyed the fort, which was rebuilt in 1752. Because Fort Mose became a haven for escaped slaves from the English colonies to the north, it is considered a precursor site of the Underground Railroad.[42]\\r\\nCuriously, chattel slavery developed in British North America before the legal apparatus that supported slavery did. During the late 17th century and early 18th century, harsh new slave codes limited the rights of African slaves and cut off their avenues to freedom. The first full-scale slave code in British North America was South Carolina's (1696), which was modeled on the colonial Barbados slave code of 1661 and was updated and expanded regularly throughout the 18th century.[43]\\r\\nA 1691 Virginia law prohibited slaveholders from emancipating slaves unless they paid for the freedmen's transportation out of Virginia.[44] Virginia criminalized interracial marriage in 1691,[45] and subsequent laws abolished blacks' rights to vote, hold office, and bear arms.[44] Virginia's House of Burgesses established the basic legal framework for slavery in 1705.[46]\\r\\nOnly a fraction of the enslaved Africans brought to the New World ended up in British North America  perhaps 5-7%. The vast majority of slaves transported across the Atlantic Ocean were sent to the Caribbean sugar colonies, Brazil, or Spanish America. Throughout the Americas, but especially in the Caribbean, tropical disease took a large toll on their population and required large numbers of replacements. Many Africans had a limited natural immunity to yellow fever and malaria; but malnutrition, poor housing, inadequate clothing allowances, and overwork contributed to a high mortality rate.\\r\\nIn British North America the slave population rapidly increased via the birth rate, whereas in the Caribbean colonies they did not. The lack of proper nourishment, being suppressed sexually, and poor health are possible reasons. Of the small numbers of babies born to slaves in the Caribbean, only about 1/4 survived the miserable conditions on sugar plantations.\\r\\nIt was not only the major colonial powers of Western Europe such as France, England, Spain, Portugal, and the Netherlands that were involved. Other countries, including Sweden and Denmark, participated in the trans-Atlantic slave trade though on a much more limited scale.\\r\\n\\"Depending upon their age and gender, slaves were assigned a particular task, or tasks, that had to be completed during the course of the day.\\"[47] In certain settings, men would participate in the hard labor, such as working on the farm, while women would generally work in the household. They would \\"be sent out on errands, but in most cases their jobs required that they spend much of their time within their owner's household.\\"[48] These gender distinctions were mainly applied in the Northern colonies and on larger plantations. In Southern colonies and smaller farms, however, women and men typically engaged in the same roles, both working in the tobacco crop fields for example.\\r\\nAlthough slave women and men in some areas performed the same type of day-to-day work, \\"[t]he female slave...was faced with the prospect of being forced into sexual relationships for the purpose of reproduction.\\"[49] This reproduction would either be forced between one African slave and another, or between the slave woman and the owner. Slave owners saw slave women in terms of prospective fertility. That way, the number of slaves on a plantation could multiply without having to purchase another African. Unlike the patriarchal society of white Anglo-American colonists, \\"slave families\\" were more matriarchal in practice. \\"Masters believed that slave mothers, like white women, had a natural bond with their children that therefore it was their responsibility-more so than that of slave fathers-to care for their offspring.\\"[50] Therefore, women had the extra responsibility, on top of their other day-to-day work, to take care of children. Men, in turn, were often separated from their families. \\"At the same time that slaveholders promoted a strong bond between slave mother and their children, they denied to slave fathers their paternal rights of ownership and authority...\\"[50] Biological families were often separated by sale.\\r\\nSome historians, notably Edmund Morgan, have suggested that indentured servitude provided a model for slavery in 17th-century Virginia. In practice, indentured servants were teenagers in England whose father sold their labor voluntarily for a period of time (typically four to seven years), in return for free passage to the colonies, room and board and clothes, and training in an occupation. After that they received cash, clothing, tools, and/or land, and became ordinary settlers.\\r\\nPre-contact indigenous peoples in the American southeast had practiced a form of slavery on people captured during warfare. Larger societies structured as chiefdoms kept slaves as unpaid field laborers, while in band societies the ownership of enslaved captives attested to their captor's military prowess.[51] Some war captives were also subjected to ritualized torture and execution.[52] Alan Gallay and other historians emphasize differences between Native American enslavement of war captives and the European slave trading system, into which numerous native peoples were integrated.[53] In North America, among the indigenous people, slavery was more a 'rite of passage' or system of assimilating outside individuals into groups rather than a property or ownership right. Richard White, in The Middle Ground elucidates the complex social relationships between American Indian groups and the early empires, including 'slave' culture and scalping.[54] Robbie Ethridge states, \\"Let there be no doubtthat the commercial trade in Indian slaves was not a continuation and adaptation of pre-existing captivity patterns. It was a new kind of slaving, requiring a new kind of occupational specialtyorganized militaristic slavers.\\"[55] One example of this militaristic slaving can be seen in Nathaniel Bacon's actions in Virginia during the late 1670s. In June 1676, the Virginia assembly granted Bacon and his men what equated to a slave-hunting license by providing that any enemy Indians caught were to be slaves for life. They also provided soldiers who had captured Indians with the right to \\"reteyne and keepe all such Indian slaves or other Indian goods as they either have taken or hereafter shall take.\\"[56] By this order, the assembly had made a public decision to enslave Indians. In the years to follow, other laws resulted in Indians being grouped with other non-Christian servants who had imported to the colonies (Negro slaves) as slaves for life.\\r\\nPuritan New England, Virginia, Spanish Florida, and the Carolina colonies engaged in large-scale enslavement of Native Americans, often through the use of Indian proxies to wage war and acquire the slaves. In New England, slave raiding accompanied the Pequot War and King Philip's War, but declined after the latter war ended in 1676. Enslaved Indians were in Jamestown from the early years of the settlement, but large-scale cooperation between English slavers and the Westo and Occaneechi peoples, whom they armed with guns, did not begin until the 1640s. These groups conducted enslaving raids in what is now Georgia, Tennessee, North Carolina, South Carolina, Florida, and possible Alabama.[57] The Carolina slave trade, which included both trading and direct raids by colonists,[58] was the largest among the British colonies in North America,[59] estimated at 24,000 to 51,000 Indians by Gallay.[60]\\r\\nHistorian Ulrich Phillips argues that Africans were inculcated as slaves and the best answer to the labor shortage in the New World because American Indian slaves were more familiar with the environment, and would often successfully escape into the wilderness that African slaves had much more difficulty surviving in. Also, early colonial America depended heavily on the sugar trade, which led to malaria, a disease the Africans were far less susceptible to than Native American slaves.[61]\\r\\nColonial slave rebellions before 1776, or before 1801 for Louisiana, include:\\r\\nIn the early 21st century, new research has revealed that small numbers of East Indians were brought to the colonies as enslaved laborers, during the period when both India and the colonies were under British control. As an example, an ad in the Virginia Gazette of Aug. 4, 1768, describes one young \\"East Indian\\" as \\"a well made fellow, about 5 feet 4 inches high\\" who had \\"a thin visage, a very sly look, and a remarkable set of fine white teeth.\\" Another slave is identified as \\"an East India negro man\\" who speaks French and English.[63] Most of the Indian slaves were already converted to Christianity, were fluent in English, and took western names.[63] Their original names and homes will never be known. Their descendants have mostly merged with the African-American community, which also incorporated European ancestors. Today, descendants of such East Indian slaves may find a small percent of DNA from their Asiatic ancestors, as most of their ancestry is African-American.[citation needed]\\r\\nAfrican and African American slaves expressed their opposition to slavery through armed uprisings such as the Stono Rebellion (1739) in South Carolina. More typically, they resisted through work slowdowns, tool-breaking, and running away, either for short periods or permanently. Until the Revolutionary era, almost no white American colonists spoke out against slavery. Even the Quakers generally tolerated slaveholding (and slave-trading) until the mid-18th century, although they emerged as vocal opponents of slavery in the Revolutionary era.\\r\\nIn 1688, four German Quakers in Germantown, a town outside Philadelphia, wrote a petition against the use of slaves by the English colonists in the nearby countryside. They presented the petition to their local Quaker Meeting, and the Meeting was sympathetic, but could not decide what the appropriate response should be. The Meeting passed the petition up the chain of authority to Philadelphia Yearly Meeting, where it continued to be ignored. It was archived and forgotten for 150 years.\\r\\nIn 1844 the Quaker petition was rediscovered and became a focus of the burgeoning abolitionist movement. It was the first public American document of its kind to protest slavery.It was also one of the first public declarations of universal human rights. While the petition was forgotten for a time, the idea that every human has equal rights was regularly discussed in Philadelphia Quaker society through the eighteenth century. Slavery was officially sanctioned in 1776 by the Philadelphia Yearly Meeting.\\r\\nDuring the Great Awakening of the late eighteenth century, Methodist and Baptist preachers toured in the South, trying to persuade planters to manumit their slaves on the basis of equality in God's eyes. They also accepted slaves as members and preachers of new chapels and churches. The first black churches (all Baptist) in what became the United States were founded by slaves and free blacks in Aiken County, South Carolina in 1773,[64] Petersburg, Virginia in 1774, and Savannah, Georgia in 1778, before the end of the Revolutionary War.[65][66]\\r\\nFollowing the Revolution, the northern states all abolished slavery, with New Jersey acting last in 1804. In states that passed gradual abolition laws, such as New York and New Jersey, children born to slave mothers had to serve an extended period of indenture into young adulthood. In other cases, some slaves were reclassified as indentured servants, effectively maintaining slavery by another name.[67] These state jurisdictions enacted the first abolition laws in the entire New World.[68]\\r\\nOften citing Revolutionary ideals, some slaveholders freed their slaves in the first two decades after independence, either outright or through their wills. The proportion of free blacks rose markedly in the Upper South in this period, before the invention of the cotton gin created a new demand for slaves in the developing \\"Cotton Kingdom\\" of the Deep South.\\r\\nBy 1808 (the first year allowed by the Constitution to intervene in the slave trade), all states (except South Carolina) had banned the international buying or selling of slaves. Acting on the advice of President Thomas Jefferson, who denounced the international trade as \\"violations of human rights which have been so long continued on the unoffending inhabitants of Africa, in which the morality, the reputation, and the best interests of our country have long been eager to proscribe\\", in 1807 Congress banned the international slave trade. However, the domestic slave trade continued.[69] It brought great wealth to the South, especially to New Orleans, which became the fourth largest city in the country, also based on the growth of its port. In the antebellum years, more than one million enslaved African Americans were transported from the Upper South to the developing Deep South, mostly in the slave trade. Cotton culture, dependent on slavery, formed the basis of new wealth in the Deep South.","input":"What were the different models of labor used in the british colonies?"},{"output":"El Giza, Egypt","context":"5152'I2'\\r\\nThe Great Pyramid of Giza (also known as the Pyramid of Khufu or the Pyramid of Cheops) is the oldest and largest of the three pyramids in the Giza pyramid complex bordering what is now El Giza, Egypt. It is the oldest of the Seven Wonders of the Ancient World, and the only one to remain largely intact.\\r\\nBased on a mark in an interior chamber naming the work gang and a reference to the fourth dynasty Egyptian Pharaoh Khufu, Egyptologists believe that the pyramid was built as a tomb over a 10- to 20-year period concluding around 2560 BC. Initially at 146.5 metres (481 feet), the Great Pyramid was the tallest man-made structure in the world for more than 3,800 years. Originally, the Great Pyramid was covered by limestone casing stones that formed a smooth outer surface; what is seen today is the underlying core structure. Some of the casing stones that once covered the structure can still be seen around the base. There have been varying scientific and alternative theories about the Great Pyramid's construction techniques. Most accepted construction hypotheses are based on the idea that it was built by moving huge stones from a quarry and dragging and lifting them into place.\\r\\nThere are three known chambers inside the Great Pyramid. The lowest chamber is cut into the bedrock upon which the pyramid was built and was unfinished. The so-called[1] Queen's Chamber and King's Chamber are higher up within the pyramid structure. The main part of the Giza complex is a set of buildings that included two mortuary temples in honour of Khufu (one close to the pyramid and one near the Nile), three smaller pyramids for Khufu's wives, an even smaller \\"satellite\\" pyramid, a raised causeway connecting the two temples, and small mastaba tombs surrounding the pyramid for nobles.\\r\\n\\r\\n\\r\\nEgyptologists believe the pyramid was built as a tomb for the Fourth Dynasty Egyptian pharaoh Khufu (often Hellenized as \\"Cheops\\") and was constructed over a 20-year period. Khufu's vizier, Hemiunu (also called Hemon) is believed by some to be the architect of the Great Pyramid.[2] It is thought that, at construction, the Great Pyramid was originally 280 Egyptian Royal cubits tall (146.5 metres (480.6?ft)), but with erosion and absence of its pyramidion, its present height is 138.8 metres (455.4?ft). Each base side was 440?cubits, 230.4 metres (755.9?ft) long. The mass of the pyramid is estimated at 5.9?million tonnes. The volume, including an internal hillock, is roughly 2,500,000 cubic metres (88,000,000?cu?ft).[3]\\r\\nBased on these estimates, building the pyramid in 20 years would involve installing approximately 800 tonnes of stone every day. Additionally, since it consists of an estimated 2.3?million blocks, completing the building in 20 years would involve moving an average of more than 12 of the blocks into place each hour, day and night. The first precision measurements of the pyramid were made by Egyptologist Sir Flinders Petrie in 1880ÿ82 and published as The Pyramids and Temples of Gizeh.[4] Almost all reports are based on his measurements. Many of the casing-stones and inner chamber blocks of the Great Pyramid fit together with extremely high precision. Based on measurements taken on the north-eastern casing stones, the mean opening of the joints is only 0.5 millimetre wide (1/50 of an inch).[5]\\r\\nThe pyramid remained the tallest man-made structure in the world for over 3,800 years,[6] unsurpassed until the 160-metre-tall (520?ft) spire of Lincoln Cathedral was completed c.?1300. The accuracy of the pyramid's workmanship is such that the four sides of the base have an average error of only 58?millimetres in length.[7] The base is horizontal and flat to within I15?mm (0.6?in).[8] The sides of the square base are closely aligned to the four cardinal compass points (within four?minutes of arc)[9] based on true north, not magnetic north,[10] and the finished base was squared to a mean corner error of only 12 seconds of arc.[11]\\r\\nThe completed design dimensions, as suggested by Petrie's survey and subsequent studies, are estimated to have originally been 280 Egyptian Royal cubits high by 440 cubits long at each of the four sides of its base. The ratio of the perimeter to height of 1760/280 Egyptian Royal cubits equates to 2 to an accuracy of better than 0.05% (corresponding to the well-known approximation of  as 22/7). Some Egyptologists consider this to have been the result of deliberate design proportion. Verner wrote, \\"We can conclude that although the ancient Egyptians could not precisely define the value of , in practice they used it\\".[12] Petrie, author of Pyramids and Temples of Gizeh concluded: \\"but these relations of areas and of circular ratio are so systematic that we should grant that they were in the builder's design\\".[13] Others have argued that the Ancient Egyptians had no concept of pi and would not have thought to encode it in their monuments. They believe that the observed pyramid slope may be based on a simple seked slope choice alone, with no regard to the overall size and proportions of the finished building.[14] In 2013, rolls of papyrus called the Diary of Merer were discovered written by some of those who delivered limestone and other construction materials from Tora to Giza.[15]\\r\\nThe Great Pyramid consists of an estimated 2.3?million blocks which most believe to have been transported from nearby quarries. The Tura limestone used for the casing was quarried across the river. The largest granite stones in the pyramid, found in the \\"King's\\" chamber, weigh 25 to 80 tonnes and were transported from Aswan, more than 800?km (500?mi) away. Traditionally,[clarification needed] ancient Egyptians cut stone blocks by hammering into them wooden wedges, which were then soaked with water. As the water was absorbed, the wedges expanded, causing the rock to crack. Once they were cut, they were carried by boat either up or down the Nile River to the pyramid.[16] It is estimated that 5.5?million tonnes of limestone, 8,000 tonnes of granite (imported from Aswan), and 500,000 tonnes of mortar were used in the construction of the Great Pyramid.[17]\\r\\nAt completion, the Great Pyramid was surfaced by white \\"casing stones\\"?ÿ slant-faced, but flat-topped, blocks of highly polished white limestone. These were carefully cut to what is approximately a face slope with a seked of 5? palms to give the required dimensions. Visibly, all that remains is the underlying stepped core structure seen today. In AD?1303, a massive earthquake loosened many of the outer casing stones, which were then carted away by Bahri Sultan An-Nasir Nasir-ad-Din al-Hasan in 1356 to build mosques and fortresses in nearby Cairo. Many more casing stones were removed from the great pyramids by Muhammad Ali Pasha in the early 19th century to build the upper portion of his Alabaster Mosque in Cairo, not far from Giza. These limestone casings can still be seen as parts of these structures. Later explorers reported massive piles of rubble at the base of the pyramids left over from the continuing collapse of the casing stones, which were subsequently cleared away during continuing excavations of the site.\\r\\nNevertheless, a few of the casing stones from the lowest course can be seen to this day in situ around the base of the Great Pyramid, and display the same workmanship and precision that has been reported for centuries. Petrie also found a different orientation in the core and in the casing measuring 193?centimetres I 25 centimetres. He suggested a redetermination of north was made after the construction of the core, but a mistake was made, and the casing was built with a different orientation.[4] Petrie related the precision of the casing stones as to being \\"equal to opticians' work of the present day, but on a scale of acres\\" and \\"to place such stones in exact contact would be careful work; but to do so with cement in the joints seems almost impossible\\".[19] It has been suggested it was the mortar (Petrie's \\"cement\\") that made this seemingly impossible task possible, providing a level bed, which enabled the masons to set the stones exactly.[20][21]\\r\\nMany alternative, often contradictory, theories have been proposed regarding the pyramid's construction techniques.[22] Many disagree on whether the blocks were dragged, lifted, or even rolled into place. The Greeks believed that slave labour was used, but modern discoveries made at nearby workers' camps associated with construction at Giza suggest that it was built instead by tens of thousands of skilled workers. Verner posited that the labour was organized into a hierarchy, consisting of two gangs of 100,000 men, divided into five zaa or phyle of 20,000 men each, which may have been further divided according to the skills of the workers.[23]\\r\\nOne mystery of the pyramid's construction is its planning. John Romer suggests that they used the same method that had been used for earlier and later constructions, laying out parts of the plan on the ground at a 1-to-1 scale. He writes that \\"such a working diagram would also serve to generate the architecture of the pyramid with precision unmatched by any other means\\".[24] He also argues for a 14-year time-span for its construction.[25] A modern construction management study, in association with Mark Lehner and other Egyptologists, estimated that the total project required an average workforce of about 14,500 people and a peak workforce of roughly 40,000. Without the use of pulleys, wheels, or iron tools, they used critical path analysis methods, which suggest that the Great Pyramid was completed from start to finish in approximately 10 years.[26]\\r\\nThe original entrance to the Great Pyramid is on the north, 17 metres (56?ft) vertically above ground level and 7.29 metres (23.9?ft) east of the centre line of the pyramid. From this original entrance, there is a Descending Passage 0.96 metres (3.1?ft) high and 1.04 metres (3.4?ft) wide, which goes down at an angle of 26 31'23\\" through the masonry of the pyramid and then into the bedrock beneath it. After 105.23 metres (345.2?ft), the passage becomes level and continues for an additional 8.84 metres (29.0?ft) to the lower Chamber, which appears not to have been finished. There is a continuation of the horizontal passage in the south wall of the lower chamber; there is also a pit dug in the floor of the chamber. Some Egyptologists suggest that this Lower Chamber was intended to be the original burial chamber, but Pharaoh Khufu later changed his mind and wanted it to be higher up in the pyramid.[27]\\r\\n28.2 metres (93?ft) from the entrance is a square hole in the roof of the Descending Passage. Originally concealed with a slab of stone, this is the beginning of the Ascending Passage. The Ascending Passage is 39.3 metres (129?ft) long, as wide and high as the Descending Passage and slopes up at almost precisely the same angle to reach the Grand Gallery. The lower end of the Ascending Passage is closed by three huge blocks of granite, each about 1.5 metres (4.9?ft) long. One must use the Robbers' Tunnel (see below) to access the Ascending Passage. At the start of the Grand Gallery on the right-hand side there is a hole cut in the wall. This is the start of a vertical shaft which follows an irregular path through the masonry of the pyramid to join the Descending Passage. Also at the start of the Grand Gallery there is the Horizontal Passage leading to the \\"Queen's Chamber\\". The passage is 1.1m (3'8\\") high for most of its length, but near the chamber there is a step in the floor, after which the passage is 1.73 metres (5.7?ft) high.\\r\\nThe \\"Queen's Chamber\\"[1] is exactly halfway between the north and south faces of the pyramid and measures 5.75 metres (18.9?ft) north to south, 5.23 metres (17.2?ft) east to west, and has a pointed roof with an apex 6.23 metres (20.4?ft) above the floor. At the eastern end of the chamber there is a niche 4.67 metres (15.3?ft) high. The original depth of the niche was 1.04 metres (3.4?ft), but has since been deepened by treasure hunters.[28]\\r\\nIn the north and south walls of the Queen's Chamber there are shafts, which, unlike those in the King's Chamber that immediately slope upwards (see below), are horizontal for around 2?m (6.6?ft) before sloping upwards. The horizontal distance was cut in 1872 by a British engineer, Waynman Dixon, who believed a shaft similar to those in the King's Chamber must also exist. He was proved right, but because the shafts are not connected to the outer faces of the pyramid or the Queen's Chamber, their purpose is unknown. At the end of one of his shafts, Dixon discovered a ball of black diorite (a type of rock) and a bronze implement of unknown purpose. Both objects are currently in the British Museum.[29]\\r\\nThe shafts in the Queen's Chamber were explored in 1993 by the German engineer Rudolf Gantenbrink using a crawler robot he designed, Upuaut 2. After a climb of 65?m (213?ft),[30] he discovered that one of the shafts was blocked by limestone \\"doors\\" with two eroded copper \\"handles\\". Some years later the National Geographic Society created a similar robot which, in September 2002, drilled a small hole in the southern door, only to find another door behind it.[31] The northern passage, which was difficult to navigate because of twists and turns, was also found to be blocked by a door.[32]\\r\\nResearch continued in 2011 with the Djedi Project. Realizing the problem was that the National Geographic Society's camera was only able to see straight ahead of it, they instead used a fibre-optic \\"micro snake camera\\" that could see around corners. With this they were able to penetrate the first door of the southern shaft through the hole drilled in 2002, and view all the sides of the small chamber behind it. They discovered hieroglyphs written in red paint. They were also able to scrutinize the inside of the two copper \\"handles\\" embedded in the door, and they now believe them to be for decorative purposes. They also found the reverse side of the \\"door\\" to be finished and polished, which suggests that it was not put there just to block the shaft from debris, but rather for a more specific reason.[33]\\r\\nThe Grand Gallery continues the slope of the Ascending Passage, but is 8.6 metres (28?ft) high and 46.68 metres (153.1?ft) long. At the base it is 2.06 metres (6.8?ft) wide, but after 2.29 metres (7.5?ft) the blocks of stone in the walls are corbelled inwards by 7.6 centimetres (3.0?in) on each side. There are seven of these steps, so, at the top, the Grand Gallery is only 1.04 metres (3.4?ft) wide. It is roofed by slabs of stone laid at a slightly steeper angle than the floor of the gallery, so that each stone fits into a slot cut in the top of the gallery like the teeth of a ratchet. The purpose was to have each block supported by the wall of the Gallery, rather than resting on the block beneath it, in order to prevent cumulative pressure.[34]\\r\\nAt the upper end of the Gallery on the right-hand side there is a hole near the roof that opens into a short tunnel by which access can be gained to the lowest of the Relieving Chambers. The other Relieving Chambers were discovered in 1837ÿ1838 by Colonel Howard Vyse and J. S. Perring, who dug tunnels upwards using blasting powder.\\r\\nThe floor of the Grand Gallery consists of a shelf or step on either side, 51 centimetres (20?in) wide, leaving a lower ramp 1.04 metres (3.4?ft) wide between them. In the shelves there are 54 slots, 27 on each side matched by vertical and horizontal slots in the walls of the Gallery. These form a cross shape that rises out of the slot in the shelf. The purpose of these slots is not known, but the central gutter in the floor of the Gallery, which is the same width as the Ascending Passage, has led to speculation that the blocking stones were stored in the Grand Gallery and the slots held wooden beams to restrain them from sliding down the passage.[35] This, in turn, has led to the proposal that originally many more than 3 blocking stones were intended, to completely fill the Ascending Passage.[citation needed]\\r\\nAt the top of the Grand Gallery, there is a step giving onto a horizontal passage some metres long and approximately 1.02 metres (3.3?ft) in height and width, in which can be detected four slots, three of which were probably intended to hold granite portcullises. Fragments of granite found by Petrie in the Descending Passage may have come from these now-vanished doors.\\r\\nIn 2017, scientists from the Scan Pyramids Project discovered a large cavity above the Grand Gallery, using muon radiography that can detect cosmic rays. Its length is at least 30 metres (98?ft) and its cross-section is similar to that of the Grand Gallery. It was detected using three different technologies: nuclear emulsion films, scintillator hodoscopes, and gas detectors.[36][37] The purpose of the cavity is not known and it is not accessible but according to Zahi Hawass it may have been a gap used in the construction of the Grand Gallery.[38] The Japanese research team disputes this, however, saying that the huge void is completely different from the construction spaces previously identified.[39]\\r\\nThe \\"King's Chamber\\"[1] is 20 Egyptian Royal cubits or 10.47 metres (34.4?ft) from east to west and 10 cubits or 5.234 metres (17.17?ft) north to south. It has a flat roof 11 cubits and 5 digits or 5.852 metres (19 feet 2 inch) above the floor. 0.91?m (3.0?ft) above the floor there are two narrow shafts in the north and south walls (one is now filled by an extractor fan in an attempt to circulate air inside the pyramid). The purpose of these shafts is not clear: they appear to be aligned towards stars or areas of the northern and southern skies, yet one of them follows a dog-leg course through the masonry, indicating no intention to directly sight stars through them. They were long believed by Egyptologists to be \\"air shafts\\" for ventilation, but this idea has now been widely abandoned in favour of the shafts serving a ritualistic purpose associated with the ascension of the kings spirit to the heavens.[40]\\r\\nThe King's Chamber is entirely faced with granite. Above the roof, which is formed of nine slabs of stone weighing in total about 400 tons, are five compartments known as Relieving Chambers. The first four, like the King's Chamber, have flat roofs formed by the floor of the chamber above, but the final chamber has a pointed roof. Vyse suspected the presence of upper chambers when he found that he could push a long reed through a crack in the ceiling of the first chamber. From lower to upper, the chambers are known as \\"Davison's Chamber\\", \\"Wellington's Chamber\\", \\"Nelson's Chamber\\", \\"Lady Arbuthnot's Chamber\\", and \\"Campbell's Chamber\\". It is believed that the compartments were intended to safeguard the King's Chamber from the possibility of a roof collapsing under the weight of stone above the Chamber. As the chambers were not intended to be seen, they were not finished in any way and a few of the stones still retain masons' marks painted on them. One of the stones in Campbell's Chamber bears a mark, apparently the name of a work gang.[41][42]\\r\\nThe only object in the King's Chamber is a rectangular granite sarcophagus, one corner of which is broken. The sarcophagus is slightly larger than the Ascending Passage, which indicates that it must have been placed in the Chamber before the roof was put in place. Unlike the fine masonry of the walls of the Chamber, the sarcophagus is roughly finished, with saw-marks visible in several places. This is in contrast with the finely finished and decorated sarcophagi found in other pyramids of the same period. Petrie suggested that such a sarcophagus was intended but was lost in the river on the way north from Aswan and a hurriedly made replacement was used instead.\\r\\nToday tourists enter the Great Pyramid via the Robbers' Tunnel, a tunnel purportedly created around AD 820 by Caliph al-Ma'mun's workmen using a battering ram.[43][44] The tunnel is cut straight through the masonry of the pyramid for approximately 27 metres (89?ft), then turns sharply left to encounter the blocking stones in the Ascending Passage. It is believed that their efforts dislodged the stone fitted in the ceiling of the Descending Passage to hide the entrance to the Ascending Passage and it was the noise of that stone falling and then sliding down the Descending Passage, which alerted them to the need to turn left. Unable to remove these stones, however, the workmen tunnelled up beside them through the softer limestone of the Pyramid until they reached the Ascending Passage. It is possible to enter the Descending Passage from this point, but access is usually forbidden.[45]\\r\\nThe Great Pyramid is surrounded by a complex of several buildings including small pyramids. The Pyramid Temple, which stood on the east side of the pyramid and measured 52.2 metres (171?ft) north to south and 40 metres (130?ft) east to west, has almost entirely disappeared apart from the black basalt paving. There are only a few remnants of the causeway which linked the pyramid with the valley and the Valley Temple. The Valley Temple is buried beneath the village of Nazlet el-Samman; basalt paving and limestone walls have been found but the site has not been excavated.[46][47] The basalt blocks show \\"clear evidence\\" of having been cut with some kind of saw with an estimated cutting blade of 15 feet (4.6?m) in length, capable of cutting at a rate of 1.5 inches (38?mm) per minute. John Romer suggests that this \\"super saw\\" may have had copper teeth and weighed up to 300 pounds (140?kg). He theorizes that such a saw could have been attached to a wooden trestle and possibly used in conjunction with vegetable oil, cutting sand, emery or pounded quartz to cut the blocks, which would have required the labour of at least a dozen men to operate it.[48]\\r\\nOn the south side are the subsidiary pyramids, popularly known as the Queens' Pyramids. Three remain standing to nearly full height but the fourth was so ruined that its existence was not suspected until the recent discovery of the first course of stones and the remains of the capstone. Hidden beneath the paving around the pyramid was the tomb of Queen Hetepheres I, sister-wife of Sneferu and mother of Khufu. Discovered by accident by the Reisner expedition, the burial was intact, though the carefully sealed coffin proved to be empty.\\r\\nThe Giza pyramid complex, which includes among other structures the pyramids of Khufu, Khafre and Menkaure, is surrounded by a cyclopean stone wall, the Wall of the Crow. Mark Lehner has discovered a worker's town outside of the wall, otherwise known as \\"The Lost City\\", dated by pottery styles, seal impressions, and stratigraphy to have been constructed and occupied sometime during the reigns of Khafre (2520ÿ2494 BC) and Menkaure (2490ÿ2472 BC).[49][50] Recent discoveries by Mark Lehner and his team at the town and nearby, including what appears to have been a thriving port, suggest the town and associated living quarters consisting of barracks called \\"galleries\\" may not have been for the pyramid workers after all, but rather for the soldiers and sailors who utilized the port. In light of this new discovery, as to where then the pyramid workers may have lived, Lehner now suggests the alternative possibility they may have camped on the ramps he believes were used to construct the pyramids or possibly at nearby quarries.[51]\\r\\nIn the early 1970s, the Australian archaeologist Karl Kromer excavated a mound in the South Field of the plateau. This mound contained artefacts including mudbrick seals of Khufu, which he identified with an artisans' settlement.[52] Mudbrick buildings just south of Khufu's Valley Temple contained mud sealings of Khufu and have been suggested to be a settlement serving the cult of Khufu after his death.[53] A worker's cemetery used at least between Khufu's reign and the end of the Fifth Dynasty was discovered south of the Wall of the Crow by Zahi Hawass in 1990.[54]\\r\\nThere are three boat-shaped pits around the pyramid, of a size and shape to have held complete boats, though so shallow that any superstructure, if there ever was one, must have been removed or disassembled. In May 1954, the Egyptian archaeologist Kamal el-Mallakh discovered a fourth pit, a long, narrow rectangle, still covered with slabs of stone weighing up to 15 tons. Inside were 1,224 pieces of wood, the longest 23 metres (75?ft) long, the shortest 10 centimetres (0.33?ft). These were entrusted to a boat builder, Haj Ahmed Yusuf, who worked out how the pieces fit together. The entire process, including conservation and straightening of the warped wood, took fourteen years.\\r\\nThe result is a cedar-wood boat 43.6 metres (143?ft) long, its timbers held together by ropes, which is currently housed in a special boat-shaped, air-conditioned museum beside the pyramid. During construction of this museum, which stands above the boat pit, a second sealed boat pit was discovered. It was deliberately left unopened until 2011 when excavation began on the boat.[55]\\r\\nAlthough succeeding pyramids were smaller, pyramid-building continued until the end of the Middle Kingdom. However, as authors Brier and Hobbs claim, \\"all the pyramids were robbed\\" by the New Kingdom, when the construction of royal tombs in a desert valley, now known as the Valley of the Kings, began.[56][57] Joyce Tyldesley states that the Great Pyramid itself \\"is known to have been opened and emptied by the Middle Kingdom\\", before the Arab caliph Abdullah al-Mamun entered the pyramid around AD 820.[43]\\r\\nI. E. S. Edwards discusses Strabo's mention that the pyramid \\"a little way up one side has a stone that may be taken out, which being raised up there is a sloping passage to the foundations\\". Edwards suggested that the pyramid was entered by robbers after the end of the Old Kingdom and sealed and then reopened more than once until Strabo's door was added. He adds: \\"If this highly speculative surmise be correct, it is also necessary to assume either that the existence of the door was forgotten or that the entrance was again blocked with facing stones\\", in order to explain why al-Ma'mun could not find the entrance.[58]\\r\\nHe also discusses a story told by Herodotus. Herodotus visited Egypt in the 5th century BC and recounts a story that he was told concerning vaults under the pyramid built on an island where the body of Cheops lies. Edwards notes that the pyramid had \\"almost certainly been opened and its contents plundered long before the time of Herodotus\\" and that it might have been closed again during the Twenty-sixth Dynasty of Egypt when other monuments were restored. He suggests that the story told to Herodotus could have been the result of almost two centuries of telling and retelling by Pyramid guides.[59]","input":"What city is the great pyramid of giza located?"},{"output":"April 1917","context":"","input":"When did the u.s. enter world war 1?"},{"output":"Managua","context":"","input":"What is the capital of nicaragua in spanish?"},{"output":"1.5-mile-long","context":"The Belmont Stakes is an American Grade I stakes Thoroughbred horse race held every June at Belmont Park in Elmont, New York. It is a 1.5-mile-long (2.4?km) horse race, open to three-year-old Thoroughbreds. Colts and geldings carry a weight of 126 pounds (57?kg); fillies carry 121 pounds (55?kg). The race, nicknamed The Test of the Champion, and The Run for the Carnations, is the third and final leg of the Triple Crown and is held five weeks after the Kentucky Derby and three weeks after the Preakness Stakes. The 1973 Belmont Stakes and Triple Crown winner Secretariat holds the mile and a half stakes record (which is also a track and world record on dirt) of 2:24.\\r\\nThe attendance at the Belmont Stakes is among the American thoroughbred racing top-attended events. The 2004 Belmont Stakes drew a television audience of 21.9 million viewers, and had the highest household viewing rate since 1977 when Seattle Slew won the Triple Crown.[1]\\r\\nThe 150th Belmont Stakes took place on Saturday, June 9, 2018. Justify won the race and became the second horse in four years to win the Triple Crown.\\r\\n\\r\\n\\r\\nThe first Belmont Stakes was held at Jerome Park Racetrack in The Bronx, built in 1866 by stock market speculator Leonard Jerome (1817ÿ1891) and financed by August Belmont Sr. (1816ÿ1890), for whom the race was named. The first race in 1867 saw the filly Ruthless win, while the following year was won by General Duke.[2] The race continued to be held at Jerome Park until 1890, when it was moved to the nearby facility, Morris Park Racecourse.[3] The 1895 race was almost not held because of new laws that banned bookmaking in New York: it was eventually rescheduled for November 2.[4] The race remained at Morris Park Racecourse until the May 1905 opening of the new Belmont Park, 430-acre (1.7?km2) racetrack in Elmont, New York on Long Island, just outside the New York City borough of Queens.[3] When anti-gambling legislation was passed in New York State, Belmont Racetrack was closed, and the race was cancelled in 1911 and 1912.[5]\\r\\nThe first winner of the Triple Crown was Sir Barton, in 1919, before the series was recognized as such.[6] In 1920, the Belmont was won by the great Man o' War, who won by 20 lengths, setting a new stakes and American record.[7]\\r\\nStarting in 1926, the winner of the Belmont Stakes has been presented with August Belmont Trophy. The owner may keep the trophy for one year, and also receives a silver miniature for permanent use.[3]\\r\\nThe term Triple Crown was first used when Gallant Fox won the three races in 1930, but the term did not enter widespread use until 1935 when his son Omaha repeated the feat. Sir Barton was then honored retroactively.[8] Since 1931, the order of Triple Crown races has been the Kentucky Derby first, followed by the Preakness Stakes, and then the Belmont Stakes. Prior to 1931, the Preakness was run before the Derby eleven times. On May 12, 1917 and again on May 13, 1922, the Preakness and the Derby were run on the same day. On eleven occasions, the Belmont Stakes was run before the Preakness Stakes.[9] The date of each event is now set by the Kentucky Derby, which is always held on the first Saturday in May. The Preakness Stakes is currently held two weeks later; and the Belmont Stakes is held three weeks after the Preakness (five weeks after the Derby). The earliest possible date for the Derby is May 1, and the latest is May 7; the earliest possible date for the Belmont is thus June 5, and the latest is June 11.[10]\\r\\nIn 1937, War Admiral became the fourth Triple Crown winner after winning the Belmont in a new track record time of 2:28 3/5.[11] In the 1940s, four Triple Crown winners followed: Whirlaway in 1941, Count Fleet in 1943, Assault in 1946 and Citation in 1948. Count Fleet won the race by a then-record margin of twenty-five lengths.[12] He also set a stakes record of 2:28 1/5, a record tied by Citation. In 1957, the stakes record was smashed when Gallant Man ran the Belmont in 2:26 3/5 in a year when the Triple Crown series was split three ways.[13]\\r\\nThe Belmont Stakes race was held at Aqueduct Racetrack from 1963 to 1967, while the track at Belmont was restored and renovated.\\r\\nThe largest crowd of the 20th century was in 1971 with over 80,000 people, supplemented by the city's Latino community, there to cheer on their new hero, Ca?onero II, the Venezuelan colt who had won the Kentucky Derby and Preakness Stakes and was poised to win the U.S. Triple Crown. However, due to a foot infection that had bothered the horse for several days, Ca?onero II failed to win the Triple Crown when he struggled across the finish line in 4th place behind Pass Catcher, ridden by Walter Blum. Despite this loss, Ca?onero II was named the winner of the first Eclipse Award for Outstanding Three-Year-Old Male Horse.[14]\\r\\nOn June 9, 1973, Secretariat won the Belmont Stakes by thirty-one lengths in a record time of 2:24, becoming a Triple Crown champion, ending a 25-year gap between Citation, the Belmont and Triple Crown winner in 1948. Secretariat's record still stands as the fastest running of the Belmont Stakes and an American record for 1? miles on the dirt.[15] In 1977, Seattle Slew became the first horse to win the Triple Crown while undefeated. Affirmed was the last winner of the Triple Crown in the 20th century, taking the Belmont Stakes in 2:26 4/5 on June 10, 1978. Ridden by eighteen-year-old Steve Cauthen, Affirmed defeated rival Alydar with Jorge Velasquez in the saddle. At the time the race was the third-slowest start and the third-fastest finish with the quarter in 25, the half in 50, 3/4 in 1:14, the mile in 1:37 2/5.[16]\\r\\nIn 1988, Secretariat's son Risen Star won the Belmont in 2:26 2/5, then the second-fastest time in the history of the race. The next year, Easy Goer lowered the mark for second-fastest time to 2:26. Easy Goer also holds a Beyer Speed Figure of 122 for the race, the best of any Triple Crown race since these ratings were first published in 1987.[17]\\r\\nFor three years in a row, horses came to the Belmont Stakes with a Triple Crown on the line only to fail. In 2002, Belmont Park hosted what was then the largest crowd in its history when 103,222 saw War Emblem lose to longshot Sarava after stumbling at the start. In 2003, 101,864 watched Funny Cide finish third behind Empire Maker. In 2004, the attendance record was shattered when 120,139 people saw Smarty Jones upset by Birdstone.[18]\\r\\nIn 2007, Rags to Riches became the first filly to win the race since Tanya in 1905. Three more failed Triple Crown bids followed: in 2008, Big Brown lost to Da' Tara; in 2012, I'll Have Another was withdrawn due to injury; and in 2014, California Chrome was beaten by Tonalist. This fueled debate about whether the series needed to be changed, for example by lengthening the period between races.[19]\\r\\nAmerican Pharoah won the 2015 race, becoming the 12th horse in history to win the Triple Crown and the first in 37 years. The crowd that year was limited for the first time, to 90,000.[20] His time of 2:26.65 was the sixth-fastest in Belmont Stakes history, and the second-fastest time for a Triple Crown winner.[21]\\r\\nThe Belmont Stakes has been run at a mile and a half since 1926, having been run at that distance in 1874ÿ1889.\\r\\nThe race has also been run at the following distances: a mile and five furlongs in 1867ÿ1873; a mile and a quarter in 1890ÿ1892, 1895, and 1904ÿ1905; a mile and a furlong in 1893ÿ1894; and a mile and three furlongs from 1896ÿ1903 and 1906ÿ1925.\\r\\nThe purse for the first running in 1867 was $1,500 added,[22] meaning the purse was supplemented by nomination and entry fees. This made the total purse $2,500, with the winner receiving $1,850. The purse increased sharply in the Roaring Twenties, from Man O'War's earnings of $7,950 in 1920 to Gallant Fox's take of $66,040 in 1930. Purses declined as a result of the Great Depression, with War Admiral earning only $28,020 in 1937, then began to recover. Throughout the sixties and early seventies, the value to the winner was roughly $100,000, depending on the added money generated by entry fees (larger fields thus leading to higher prize money). The purse was repeatedly raised in the eighties and nineties, reaching $500,000 added, with the winner receiving roughly $400,000.[2] In 1998, the purse was changed to $1,000,000 guaranteed, with the winner receiving $600,000. In 2014, the purse was raised to $1,500,000.[23]\\r\\nWith one exception, the race has been run at a level weight of 126 pounds (with a 5-pound allowance for fillies) since 1900. The 126 pounds comes from the English Classics, where the standard weight is 9 stone, with one stone equaling 14 pounds. In 1913, the Belmont was run as a handicap with the winner carrying only 109 pounds compared to the runner-up carrying 126 pounds. Races run prior to 1900 had varied weight conditions.[2]\\r\\nThe first post parade in the United States was at the 14th Belmont, in 1880. Before 1921, the race was run in the clockwise tradition of English racing. Since then, the race has been run in the American, or counter-clockwise, direction. Because of its length (one lap around the enormous Belmont main track), and because it is the final race of the Triple Crown, it is called the \\"Test of the Champion\\". Most three-year-olds are unaccustomed to the distance, and lack the experience, if not the stamina, to maintain a winning speed for so long. In a long race such as the Belmont, positioning of the horse and the timing of the move to chase for the lead can be critical.\\r\\nThe Belmont Stakes is traditionally called \\"The Test of the Champion\\" because of its 1.5 mile lengthby far the longest of the three Triple Crown races, and one of the longest for a first-class race in the United States on the dirt. It is also known as \\"The Run for the Carnations\\" because the winning horse is draped with a blanket of white carnations after the race, in similar fashion to the blanket of roses and black-eyed Susans for the Derby and Preakness, respectively. The winning owner is ceremonially presented with the silver winner's trophy, designed by Paulding Farnham for Tiffany and Co. It was first presented to August Belmont Jr. in 1896 and donated by the Belmont family for annual presentation in 1926.\\r\\nDespite the fact that the Belmont Stakes is the oldest of the Triple Crown races, its traditions have been more subject to change. Until 1996, the post parade song was \\"The Sidewalks of New York\\". From 1997 to 2009, the song was changed to broadcast a recording by Frank Sinatra of the \\"Theme from New York, New York\\" in an attempt to appeal to younger fans.[24] In 2010, the song was changed to Jay-Z's \\"Empire State of Mind\\"[25] before reverting to \\"Theme from New York, New York\\" from 2011[26] through the present. This tradition is similar to the singing of the state song at the post parades of the first two Triple Crown races: \\"My Old Kentucky Home\\" at the Kentucky Derby and \\"Maryland, My Maryland\\" at the Preakness Stakes.[3] The change of song gave rise to \\"the myth of Mamie O'Rourke,\\" a reference to a character in the lyrics of \\"The Sidewalks of New York.\\" Before American Pharoah won the Triple Crown in 2015, some claimed that changing the official Belmont song \\"cursed\\" the Triple Crown and was why no horse had won since Affirmed in 1978. Others note that there was no Triple Crown winner between 1979 and 1996, even though \\"Sidewalks\\" was still played.[27]\\r\\nAlong with the change of song in 1997, the official drink was also changed, from the \\"White Carnation\\" to the \\"Belmont Breeze.\\"[28] The New York Times reviewed both cocktails unfavorably, calling the Belmont Breeze \\"a significant improvement over the nigh undrinkable White Carnation\\" despite the fact that it \\"tastes like a refined trashcan punch.\\"[29] In 2011, the Belmont Breeze was again changed to the current official drink known as the \\"Belmont Jewel.\\"\\r\\nWhile the origin of the white carnation as the official flower of the Belmont Stakes is unknown, traditionally, pure white carnations stand for love and luck. It takes approximately 700 \\"select\\" carnations imported from Colombia to create the 40-pound blanket draped over the winner of the Belmont Stakes. The NYRA has long used The Pennock Company, a wholesale florist based in Philadelphia, Pennsylvania to import the carnations used for the mantle.[30]\\r\\nFrom 1986 until 2005, the Triple Crown television rights comprised a single package. In late 2004, the New York Racing Association withdrew from that agreement to negotiate independently.[31] As a result of this NBC, who was the rights holder for all three events, was only able to keep its broadcast rights to the Kentucky Derby and Preakness Stakes. ABC regained the rights to the Belmont Stakes as part of a five-year contract that expired following the 2010 race; NBC has since regained the rights to the race through 2020.\\r\\nSpeed record:[36][a]\\r\\nMargin of Victory:[36]\\r\\nMost wins by a jockey:[36]\\r\\nMost wins by a trainer:[36]\\r\\nMost wins by an owner:[36]\\r\\nOnly 23 fillies have run in the Belmont; three of which have won:\\r\\nThis gives them a respectable 13% win rate when entered.[38] For context, three fillies have won the Kentucky Derby while five have won the Preakness Stakes. On average, fillies have won between 2% and 3% of the Triple Crown races, with similar numbers for geldings; while about 95% of these races have been won by colts. The last filly as of November 2017 to run in the Belmont was in 2013 when Unlimited Budget ran six behind the winner Palace Malice.\\r\\nA ? designates a Triple Crown Winner.\\r\\nA ? designates a filly.\\r\\nLegend - ? = Triple Crown Winners, ? = Filly","input":"What is the length of the belmont race?"},{"output":"Steve Wozniak","context":"Apple Computer 1, also known later as the Apple I, or Apple-1, is a desktop computer released by the Apple Computer Company (now Apple Inc.) in 1976. It was designed and hand-built by Steve Wozniak.[1][2] Wozniak's friend Steve Jobs had the idea of selling the computer. The Apple I was Apple's first product, and to finance its creation, Jobs sold his only motorized means of transportation, a VW Microbus,[3] for a few hundred dollars, and Wozniak sold his HP-65 calculator for $500; however, Wozniak said that Jobs planned to use his bicycle if necessary.[4] It was demonstrated in July 1976 at the Homebrew Computer Club in Palo Alto, California.[5]\\r\\nProduction was discontinued on September 30, 1977, after the June 10, 1977, introduction of its successor, the Apple II, which Byte magazine referred to as part of the \\"1977 Trinity\\" of personal computing (along with the PET 2001 and the TRS-80).[6]\\r\\n\\r\\n\\r\\nOn March 5, 1975, Steve Wozniak attended the first meeting of the Homebrew Computer Club in Gordon French's garage. He was so inspired that he immediately set to work on what would become the Apple I computer.[7] After building it for himself and showing it at the Club, he and Steve Jobs gave out schematics (technical designs) for the computer to interested club members and even helped some of them build and test out copies. Then, Steve Jobs suggested that they design and sell a single etched and silkscreened circuit boardjust the bare board, no electronic partsthat people could use to build the computers. Wozniak calculated that having the board design laid out would cost $1,000 and manufacturing would cost another $20 per board; he hoped to recoup his costs if 50 people bought the boards for $40 each. To fund this small venture, their first company, Jobs sold his van and Wozniak sold his HP-65 calculator. Very soon after, Steve Jobs arranged to sell \\"something like 50\\" completely built computers to the Byte Shop (a computer store in Mountain View, California) at $500 each. To fulfill the $25,000 order, they obtained $20,000 in parts at 30 days net and delivered the finished product in 10 days.[8]\\r\\nThe Apple I went on sale in July 1976 at a price of US$666.66,[9] because Wozniak \\"liked repeating digits\\" and because of a one-third markup on the $500 wholesale price.[10]\\r\\nThe first unit produced was used in a high school math class, and donated to Liza Loop's public access computer center.[11] About 200 units were produced and all but 25 were sold during nine or ten months.[8]\\r\\nThe Apple I's built-in computer terminal circuitry was distinctive. All one needed was a keyboard and a television set. Competing machines such as the Altair 8800 generally were programmed with front-mounted toggle switches and used indicator lights (red LEDs, most commonly) for output, and had to be extended with separate hardware to allow connection to a computer terminal or a teletypewriter machine. This made the Apple I an innovative machine for its day. In April 1977, the price was dropped to $475.[12] It continued to be sold through August 1977, despite the introduction of the Apple II in April 1977, which began shipping in June of that year.[13] In October 1977, the Apple I was officially discontinued and removed from Apple's price list.[14] As Wozniak was the only person who could answer most customer support questions about the computer, the company offered Apple I owners discounts and trade-ins for Apple IIs to persuade them to return their computers.[15] These recovered boards were then destroyed by Apple, contributing to their rarity today.[16]\\r\\nAs of 2013, at least 63 Apple I computers have been confirmed to exist. Only six have been verified to be in working condition.\\r\\nBoth Steve Jobs and Steve Wozniak have stated that Apple did not assign serial numbers to the Apple l. Several boards have been found with numbered stickers affixed to them, which appear to be inspection stickers from the PCB manufacturer/assembler. A batch of boards is known to have numbers hand-written in black permanent marker on the back; these usually appear as \\"01-00##\\" and anecdotal evidence suggests they are inventory control numbers added by the Byte Shop to the batch Apple sold them. These Byte Shop numbers have often erroneously been described as serial numbers by auction houses and in related press coverage.[42]\\r\\nSeveral Apple I clones and replicas have been released in recent years. These are all created by hobbyists and marketed to the hobbyist/collector community. Availability is usually limited to small runs in response to demand.","input":"Who were the first man to create apple computer?"},{"output":"the 19th and early 20th century","context":"First-wave feminism was a period of feminist activity and thought, that occurred within the time period of the 19th and early 20th century throughout the world. It focused on legal issues, primarily on gaining women's suffrage (the right to vote).\\r\\nFeminism has its source in the 18th century, specifically in the Enlightenment. In this cultural and philosophical movement there was a controversy over equality and gender differences. At the time appeared a new critical discourse that used the universal categories of this political philosophy. Enlightenment movement therefore was not feminist at its roots.\\r\\nThe political origins of feminism came from The French Revolution (1789). This event raised legal equality, freedoms and political rights as its central objectives but soon came the great contradiction that marked the struggle of early feminism: freedoms, rights and legal equality that had been the great conquests of the liberal revolutions didn't affect women. Rousseau's political theory designed the exclusion of women from the field of property and rights. So in the French Revolution the voice of women began to express themselves collectively.\\r\\nThe term first-wave was coined in March 1968 by Martha Lear writing in The New York Times Magazine, who at the same time also used the term \\"second-wave feminism\\".[1][2] At that time, the women's movement was focused on de facto (unofficial) inequalities, which it wished to distinguish from the objectives of the earlier feminists.\\r\\n\\r\\n\\r\\nAccording to Miriam Schneir, Simone de Beauvoir wrote that the first woman to \\"take up her pen in defense of her sex\\" was Christine de Pizan in the 15th century.[3] Heinrich Cornelius Agrippa and Modesta di Pozzo di Forzi worked in the 16th century.[3] Marie le Jars de Gournay, Anne Bradstreet and Fran?ois Poullain de la Barre wrote in the 17th.[3]\\r\\nMary Wollstonecraft's most famous work, which is called A Vindication of the Rights of Woman, was created in 1792. Its previous feminist work was Poullain de la Barre's Equality of sexes (1673). This period was affected by Rousseau's philosophy, the Illustration. The father of the Illustration defined an ideal democratic society that was based on the equality of men, where women were totally discriminated. Mary Wollstonecraft based her work on the ideas of Rousseau. Although at first it seems to be contradictory, Wollstonecraft's idea was to expand Rousseau's democratic society but based on gender equality.\\r\\nMary Wollstonecraft published one of the first feminist treatises, A Vindication of the Rights of Woman (1792), in which she advocated the social and moral equality of the sexes, extending the work of her 1790 pamphlet, A Vindication of the Rights of Men. Her later unfinished novel, Maria, or the Wrongs of Woman, earned her considerable criticism as she discussed women's sexual desires. She died young, and her widower, the philosopher William Godwin, quickly wrote a memoir of her that, contrary to his intentions, destroyed her reputation for generations.\\r\\nWollstonecraft is regarded as the grandmother of British feminism and her ideas shaped the thinking of the suffragettes, who campaigned for the women's vote. After generations of work, this was eventually achieved.\\r\\nEarly Feminism was directly correlated with the abolitionist movements and as a result many famous feminists and activists began to have their voices heard. Some of these early activists include, Sojourner Truth, Dr. Elizabeth Blackwell, Jane Addams, and Dorothy Day.[4] The first wave of feminism was primarily led by white women in the middle class, and it was not until the second wave of feminism that women of color began developing a voice.[5] The term Feminism was created like a political illustrated ideology at that period. Feminism emerged by the speech about the reform and correction of democracy based on equalitarian conditions. With Wollstonecraft's work, the illustrated feminist polemic was displayed, and as a result, suffragist movements were stood up.\\r\\nThe first wave of Australian feminism, which dates back to the late 19th century, was chiefly concerned with suffrage (women's right to vote) and consequently with women's access to parliaments and other political activities.[6]\\r\\nIn 1882, Rose Scott, a women's rights activist, began to hold a weekly salon meetings in her Sydney home, left to her by her late mother. Through these meetings, she became well known amongst politicians, judges, philanthropists, writers and poets. In 1889, she helped to found the Women's Literary Society, which later grew into the Womanhood Suffrage League in 1891. Leading politicians hosted by Scott included Bernhard Ringrose Wise, William Holman, William Morris Hughes and Thomas Bavin, who met and discussed the drafting of the bill that eventually became the Early Closing Act of 1899.[7]\\r\\nThe first women's movement was led by the Dansk Kvindesamfund (\\"Danish Women's Society\\"), founded in 1871. Line Luplau was one of the most notable woman in this era. Tagea Brandt was also part of this movement, and in her honor was established the Tagea Brandt Rejselegat or Travel Scholarship for women. The Dansk Kvindesamfund's efforts as a leading group of women for women led to the existence of the revised Danish constitution of 1915, giving women the right to vote and the provision of equal opportunity laws during the 1920s, which influenced the present-day legislative measures to grant women access to education, work, marital rights and other obligations.[8]\\r\\nEarly New Zealand feminists and suffragettes included Maud Pember Reeves (Australian-born; later lived in London), Kate Sheppard and Mary Ann Mller. In 1893, Elizabeth Yates became Mayor of Onehunga, the first time such a post had been held by a female anywhere in the British Empire. Early university graduates were Emily Siedeberg (doctor, graduated 1895) and Ethel Benjamin (lawyer, graduated 1897). The Female Law Practitioners Act was passed in 1896 and Benjamin was admitted as a barrister and solicitor of the Supreme Court of New Zealand in 1897 (see Women's suffrage in New Zealand).\\r\\nAlthough in the Netherlands during the Age of Enlightenment the idea of the equality of women and men made progress, no practical institutional measures or legislation resulted. In the second half of the nineteenth century many initiatives by feminists sprung up in The Netherlands. Aletta Jacobs (1854ÿ1929) requested and obtained as the first woman in the Netherlands the right to study at university in 1871, becoming the first female medical doctor and academic. She became a lifelong campaigner for women's suffrage, equal rights, birth control, and international peace, travelling worldwide for, e.g., the International Alliance of Women. Wilhelmina Drucker (1847ÿ1925) was a politician, a prolific writer and a peace activist, who fought for the vote and equal rights through political and feminist organisations she founded. In 1917ÿ1919 her goal of women's suffrage was reached.\\r\\nWhile in some distance in culture and language, the events of the Conference of Badasht (1848) presented progress on the concerns of first-wave feminism. There is a synchronicity in time and a likeness in theme and events between Persia (later named Iran) and the United States between the conference at Badasht and the Seneca Falls Convention.[9][10] First the conference happened over three weeks from late June to mid-July 1848 and the Seneca Falls Convention happened in mid-July 1848. Both conferences had women (Tahirih and Elizabeth Cady Stanton) take strong stances on the role of women in the public arena that some attending reacted to harshly. And lastly leading men present (Qudd~s and Frederick Douglass) supported these calls during the meetings healing the breach. Some even see a parallel in the background discussions that are partially documented to arrange how things would be brought up and settled.\\r\\nThe conference of Badasht is considered by Bah's as a signal moment that demonstrated that Islamic Sharia law had been abrogated[11][12] as well as a key demonstration of the thrust of raising the social position of women.[13] Although the unveiling led to accusations of immorality[14][15] the Bb responded by supporting her position and naming her the Pure (Thirih).[16] Modern women scholars review this kind of accusation as part of a pattern faced by women leaders and writers then and since[17] in a way that Azar Nafisi says \\"the Islamic regime today ... fears them and feels vulnerable in the face of a resistance that is not just political but existential.\\"[18] See the Bah' Faith and gender equality.\\r\\nFeminist issues and gender roles were discussed in media and literature during the 18th century by people such as Margareta Momma, Catharina Ahlgren, Anna Maria Rckersch?ld and Hedvig Charlotta Nordenflycht, but it created no movement of any kind. The first person to hold public speeches and agitate in favor of feminism was Sophie Sager in 1848,[19] and the first organization created to deal with a women's issue was Svenska l?rarinnors pensionsf?rening (Society for Retired Female Teachers) by Josefina Deland in 1855.[20]\\r\\nIn 1856, Fredrika Bremer published her famous Hertha, which aroused great controversy and created a debate referred to as the Hertha Debate. The two foremost questions was to abolish coverture for unmarried women, and for the state to provide women an equivalent to a university. Both questions were met: in 1858, a reform granted unmarried women the right to apply for legal majority by a simple procedure, and in 1861, H?gre l?rarinneseminariet was founded as a \\"Women's University\\". In 1859, the first women's magazine in Sweden and the Nordic countries, the Tidskrift f?r hemmet, was founded by Sophie Adlersparre and Rosalie Olivecrona. This has been referred to as the starting point of a women's movement in Sweden.\\r\\nThe organized women's movement begun in 1873, when Married Woman's Property Rights Association was co-founded by Anna Hierta-Retzius and Ellen Anckarsv?rd. The prime task of the organization was to abolish coverture. In 1884, Fredrika Bremer Association was founded by Sophie Adlersparre to work for the improvement in women's rights. The second half of the 19th century saw the creation of several women's rights organisations and a considerable activity within both active organization as well as intellectual debate. The 1880s saw the so-called Sedlighetsdebatten, were gender roles were discussed in literary debate in regards to sexual double standards in opposed to sexual equality. In 1902, finally, the National Association for Women's Suffrage was founded.\\r\\nIn 1921, women's suffrage was finally introduced. The women suffrage reform was followed by the Beh?righetslagen of 1923 (Act of Access of 1923), in which males and females were formally given equal access to all professions and positions in society, the only exceptions being military and priesthood positions.[21] The last two restrictions were removed in 1958, when women were allowed to become priests, and in a series of reforms between 1980 and 1989, when all military professions were opened to women.[22]\\r\\nThe early feminist reformers were unorganized, and including prominent individuals who had suffered as victim of injustice. This included individuals such as Caroline Norton whose personal tragedy where she was unable to obtain a divorce and was denied access to her three sons by her husband, led her to a life of intense campaigning which successful led to the passing of the Custody of Infants Act 1839 and the introduced the Tender years doctrine for child custody arrangement.[23][24][25] The Act gave married women, for the first time, a right to their children. However, because women needed to petition in the Court of Chancery, in practice few women had the financial means to petition for their rights.[26]\\r\\nThe first organized movement for English feminism was the Langham Place Circle of the 1850s, which included among others Barbara Bodichon (ne Leigh-Smith) and Bessie Rayner Parkes.[27] The group campaigned for many women's causes, including improved female rights in employment, and education. It also pursued women's property rights through its Married Women's Property Committee. In 1854, Bodichon published her Brief Summary of the Laws of England concerning Women,[28] which was used by the Social Science Association after it was formed in 1857 to push for the passage of the Married Women's Property Act 1882.[29] In 1858, Barbara Bodichon, Matilda Mary Hays and Bessie Rayner Parkes established the first feminist British periodical, the English Woman's Journal,[30] with Bessie Parkes the chief editor. The journal continued publication until 1864 and was succeeded in 1866 by the Englishwoman's Review edited until 1880 by Jessie Boucherett which continued publication until 1910. Jessie Boucherett and Adelaide Anne Proctor joined the Langham Place Circle in 1859. The group was active until 1866. Also in 1859, Jessie Boucherett, Barbara Bodichon and Adelaide Proctor formed the Society for Promoting the Employment of Women to promote the training and employment of women.[31] The society is one of the earliest British women's organisations, and continues to operate as the registered charity Futures for Women.[32] Helen Blackburn and Boucherett established the Women's Employment Defence League in 1891, to defend women's working rights against restrictive employment legislation.[33] They also together edited the Condition of Working Women and the Factory Acts in 1896. In the beginning of the 20th century, women's employment was still predominantly limited to factory labor and domestic work. During World War I, more women found work outside the home. As a result of the wartime experience of women in the workforce, the Sex Disqualification (Removal) Act 1919 opened professions and the civil service to women, and marriage was no longer a legal barrier to women working outside the home.\\r\\nIn 1918 Marie Stopes published the very influential Married Love,[34] in which she advocated gender equality in marriage and the importance of women's sexual desire. (Importation of the book into the United States was banned as obscene until 1931.)\\r\\nThe Representation of the People Act 1918 extended the franchise to women who were at least 30 years old and they or their husbands were property holders, while the Parliament (Qualification of Women) Act 1918 gave women the right to sit in Parliament, although it was only slowly that women were actually elected. In 1928, the franchise was extended to all women over 21 by the Representation of the People (Equal Franchise) Act 1928, on an equal basis to men.[35] Women started serving on school boards and local bodies, and numbers kept increasing. This period also saw more women gaining access to higher education. In 1910, \\"women were attending many leading medical schools, and in 1915 the American Medical Association began to admit women members.\\"[36] A Matrimonial Causes Act 1923 gave women the right to the same grounds for divorce as men.\\r\\nThe rise in unemployment during the Great Depression which started in the 1920s hit women first, and when the men also lost their jobs there was further strain on families. Many women served in the armed forces during World War II, when around 300,000 American women served in the navy and army, performing jobs such as secretaries, typists and nurses.\\r\\nMany feminist writers and women's rights activists argued that it was not equality to men which they needed but a recognition of what women need to fulfill their potential of their own natures, not only within the aspect of work but society and home life too. Virginia Woolf produced her essay A Room of One's Own based on the ideas of women as writers and characters in fiction. Woolf said that a woman must have money and a room of her own to be able to write.\\r\\nWoman in the Nineteenth Century by Margaret Fuller has been considered the first major feminist work in the United States and is often compared to Wollstonecraft's A Vindication of the Rights of Woman.[37] Prominent leaders of the feminist movement in the United States include Lucretia Coffin Mott, Elizabeth Cady Stanton, Lucy Stone, and Susan B. Anthony; Anthony and other activists such as Victoria Woodhull and Matilda Joslyn Gage made attempts to cast votes prior to their legal entitlement to do so, for which many of them faced charges. Other important leaders included several women who dissented against the law in order to have their voices heard, (Sarah and Angelina Grimk), in addition to other activists such as Carrie Chapman Catt, Alice Paul, Sojourner Truth, Ida B. Wells, Margaret Sanger and Lucy Burns.[38]\\r\\nFirst-wave feminism involved a wide range of women, some belonging to conservative Christian groups (such as Frances Willard and the Woman's Christian Temperance Union), others such as Matilda Joslyn Gage of the National Woman Suffrage Association (NWSA) resembling the radicalism of much of second-wave feminism. The majority of first-wave feminists were more moderate and conservative than radical or revolutionarylike the members of the American Woman Suffrage Association (AWSA) they were willing to work within the political system and they understood the clout of joining with sympathetic men in power to promote the cause of suffrage. The limited membership of the NWSA was narrowly focused on gaining a federal amendment for women's suffrage, whereas the AWSA, with ten times as many members, worked to gain suffrage on a state-by-state level as a necessary precursor to federal suffrage. The NWSA had broad goals, hoping to achieve a more equal social role for women, but the AWSA was aware of the divisive nature of many of those goals and instead chose to focus solely on suffrage. The NWSA was known for having more publicly aggressive tactics (such as picketing and hunger strikes) whereas the AWSA used more traditional strategies like lobbying, delivering speeches, applying political pressure and gathering signatures for petitions.[39]\\r\\nThe first wave of feminists, in contrast to the second wave, focused very little on the subjects of abortion, birth control, and overall reproductive rights of women. Though she never married, Anthony published her views about marriage, holding that a woman should be allowed to refuse sex with her husband; the American woman had no legal recourse at that time against rape by her husband.\\r\\nIn 1860, New York passed a revised Married Women's Property Act which gave women shared ownership of their children, allowing them to have a say in their children's wills, wages, and granting them the right to inherit property.[40] Further advances and setbacks were experienced in New York and other states, but with each new win the feminists were able to use it as an example to apply more leverage on unyielding legislative bodies. The end of the first wave is often linked with the passage of the Nineteenth Amendment to the United States Constitution (1920), granting women the right to vote. This was the major victory of the movement, which also included reforms in higher education, in the workplace and professions, and in health care.\\r\\nDuring the first wave, there was a notable connection between the slavery abolition movement and the women's rights movement. Frederick Douglass was heavily involved in both movements and believed that it was essential for both to work together in order to attain true equality in regards to race and sex.[41] Different accounts of the involvement of African-American women in the Women's Suffrage Movement are given. In a 1974 interview, Alice Paul notes that a compromise was made between southern groups to have white women march first, then men, then African-American women.[42] In another account by the National Association for the Advancement of Colored People (NAACP), difficulties in segregating women resulted in African-American women marching with their respective States without hindrance.[43] Among them was Ida B. Wells-Barnett, who marched with the Illinois delegation.","input":"When did the first wave of feminism occur?"},{"output":"Rear Admiral Rembrandt Cecil Robinson","context":"Harold Joseph \\"Harry\\" Greene (February 11, 1959 ÿ August 5, 2014) was a United States Army general who was killed during the War in Afghanistan. During his time with the U.S. Army, he held various commands associated with engineering and logistical support for U.S. and coalition troops. At the time of his death, he was deputy commanding general of Combined Security Transition Command ÿ Afghanistan.\\r\\nAt the rank of major general, Greene was the highest-ranking American service member killed by hostile action since Lieutenant General Timothy J. Maude was killed in the September 11 attacks, and the highest-ranking service member killed on foreign soil during a war since Rear Admiral Rembrandt Cecil Robinson was killed during the Vietnam War in May 1972.[12][13] To date, Greene is also the highest ranking American officer to be killed in combat in the ongoing Global War on Terrorism.[14]\\r\\nGreene was killed at Camp Qargha, Afghanistan when a member of the Afghan National Army opened fire on a delegation of general officers and other dignitaries who were conducting an inspection tour. Fourteen NATO and Afghan service members were wounded in the attack. The attacker was killed at the scene when NATO service members returned fire; a subsequent investigation indicated that the Afghan soldier, a 22 year old Pashtun, was motivated by unhappiness over being denied leave to travel home during the Eid al-Fitr holiday.\\r\\n\\r\\n\\r\\nGreene was born in Boston, Massachusetts on February 11, 1959, to Eva May (Shediack) and Harold F. Greene.[3][15] He grew up in Schenectady, New York[16] graduated from Guilderland High School in 1977,[17] and from Rensselaer Polytechnic Institute (RPI) with a bachelor's degree in materials engineering in 1980.[18] Greene's father lived in Guilderland, New York at the time of his death. His mother died in February 2013.[3] Greene received a master's degree in industrial engineering from RPI and a master's in materials engineering from the University of Southern California (USC). In addition, he received a master's degree in mechanical engineering from USC,[1] and a Ph.D. (1992) in materials science, also from USC.[1][6]\\r\\nGreene's military education included the Engineer Officer Basic and Advanced Courses, and the United States Army Command and General Staff College. He completed the Defense Systems Management College's Advanced Program Management Course at the Defense Acquisition University, and also held a Master of Strategic Studies degree from the United States Army War College.[19][20]\\r\\nGreene received his commission as an engineer officer in 1980, after completing Reserve Officer Training Corps at RPI.[1]\\r\\nAs he worked his way through the ranks, Greene's assignments included platoon leader, company executive officer, and battalion staff officer, Fort Polk; resident engineer in Athens; project engineer in Istanbul; brigade engineer and company commander, V Corps, West Germany; staff officer and materials engineer, Army Aviation and Troop Command, St. Louis; product manager, Aerial Common Sensor, Fort Monmouth; and assistant director, Combat Developments Directorate, U.S. Army Maneuver Support Center, Fort Leonard Wood.[14][21] At the time of the September 11 attacks in 2001, he was stationed at Fort Leonard Wood.[14]\\r\\nGreene was promoted to brigadier general in late 2009, and served as deputy commanding general of United States Army Research, Development and Engineering Command at Aberdeen Proving Ground.[22] and the commanding general of Natick Soldier Systems Center.[23] While at Natick, Greene urged the military to incorporate smartphones, video games and virtual worlds into military training.[24] Later, he became Program Executive Officer for Intelligence, Electronic Warfare and Sensors in the Office of the Assistant Secretary of the Army (Acquisition, Logistics and Technology). Promoted to major general in 2012, he was Deputy for Acquisition and Systems Management in the same office.[6] In January 2014 he was named deputy commander of Combined Security Transition Command ÿ Afghanistan during Operation Enduring Freedom ÿ Afghanistan.\\r\\nOn August 5, 2014, Greene was killed after being shot in the back of the head by an Afghan soldier with an M16 rifle at Camp Qargha's Marshal Fahim National Defense University in Kabul, Afghanistan.[25][26] He had been making a routine visit to a training facility at the time.[27] Fourteen NATO and Afghan service members were wounded in the attack,[28] including Brigadier General Michael Bartscher of the German Bundeswehr, two Afghan generals and another Afghan officer, eight Americans, and two British soldiers.[28][29]\\r\\nOn the morning of August 7, 2014, Greene's body arrived at Dover Air Force Base in Delaware.[30][31][32] Greene was buried in Arlington National Cemetery on August 14, 2014.[33]\\r\\nOn the September 25, 2015, nine British servicemen acting as the Close Protection Team for the entire group were each awarded the US Army Commendation Medal for their quick actions in killing the assailant as well as heroic and meritorious service in saving the lives of many others.[34]\\r\\nOn July 10, 2015, the Town of Natick, MA renamed Kansas Street in honor of the general. The street was dedicated General Greene Avenue.\\r\\nGreene was married to Sue Myers, a doctor[35] and retired colonel who worked as a professor at the U.S. Army War College in Carlisle, Pennsylvania.[3][1][32] At the time of his death, she lived in Falls Church, Virginia.[14] Greene had two children, a daughter, Amelia Greene, and a son, Matthew Greene, who is a U.S. Army lieutenant.[3][1]","input":"Who was the highest ranking officer killed in vietnam?"},{"output":"Fianna Fil","context":"There are a number of political parties in Ireland, and coalition governments are common. The state is unusual as a developed nation in that politics is not primarily characterised by the left-right political divide. The two largest political parties, Fianna Fil and Fine Gael, arose from a split in the original Sinn Fin party in the 1922ÿ1923 Civil War, Fine Gael from the faction (Cumann na nGaedheal) that supported the 1921 Anglo-Irish Treaty and Fianna Fil from the anti-Treaty faction. This enduring characteristic of the Irish party system is sometimes pejoratively referred to as \\"Civil War politics\\". The Labour Party was formed in 1912, and it has usually been the third party in parliamentary strength, though it is currently the fourth largest party in Dil ireann. In recent years, Sinn Fin has risen to prominence, surpassing the Labour Party in the 2016 general election.\\r\\n\\r\\nPolitical party registration is governed by the Electoral Acts, 1992 to 2012. The Register of Political Parties is maintained by the Houses of the Oireachtas.[1] In order to be registered to contest national elections a party must have either at least one member in Dil ireann or the European Parliament, or 300 recorded members aged 18 or over. Parties that register only to contest elections in part of the state, in local elections or in elections to ~dars na Gaeltachta need only 100 recorded members aged 18 or over. In either case at least half of the recorded members must be on the register of electors.[2]\\r\\n\\r\\nShould be noted that attached table tots to 752 members as opposed to 949 therefore almost 25% of members are not accounted for\\r\\n\\r\\nFine Gael is the largest party in the Oireachtas, the second largest party in local government in Ireland and has the largest delegation of MEPs from Ireland. It was founded in 1933 by a merger of the Cumann na nGaedheal, which had supported the Treaty and formed the government between 1922 and 1932, the National Guard (popularly called the Blueshirts) and the small National Centre Party. It is a member of the centre-right European People's Party and is led by Taoiseach Leo Varadkar. It has been in government in the periods 1922ÿ32, 1948ÿ51, 1954ÿ57, 1973ÿ77, 1981ÿ82, 1982ÿ87, 1994ÿ97, and 2011 to date. On each occasion, it was the leading party of a coalition with the Labour Party, and in three of those cases also with other smaller parties. At the 2011 general election, Fine Gael become the largest party in the Oireachtas with 36.1% of the vote.\\r\\n\\r\\nHistorically Fine Gael has been characterised as a centre-right party, supported by large farmers and businessmen, though this has not applied uniformly; for a period from the 1960s, for example, with the publication of the Just Society document, Fine Gael espoused some values of social democracy. During the 1980s, Fine Gael leader Garret FitzGerald advocated a liberal agenda in many areas of social reform. A government of Fine Gael and the Labour Party proposed a successful referendum in support of marriage equality in 2015. Historically Fine Gael has tended to support fiscal restraint and law and order domestically while adopting a less nationalist position on Northern Ireland than Fianna Fil. It generally has the most favourable stance of Irish parties towards the European Union and other international organisation.[citation needed]\\r\\n\\r\\nFine Gael has 49 TDs, 20 Senators, 4 MEPs and 233 councillors.\\r\\n\\r\\nFianna Fil is the second largest party in the Oireachtas and has the largest number of city and county council seats. It has been in government more than any other party: 1932ÿ48, 1951ÿ54, 1957ÿ73, 1977ÿ81, 1982, 1987ÿ94, and 1997ÿ2011. On all occasions up to 1989, it was in a single-party government; on all occasions since then it was the leading party in a coalition government. It is a member of the Alliance of Liberals and Democrats for Europe Party and is led by former minister Michel Martin.\\r\\n\\r\\nIt was founded in 1926 by amon de Valera as a radical anti-Treaty party, drawing support from small farmers and urban workers but has since become a party of the establishment. It was first elected to power in 1932 on a constitutional republican platform, promising to destroy constitutional links with Britain and reduce poverty by creating employment. It oversaw much of the industrial development of the Republic and has consequently drawn support from all social classes, making it a classic populist party. Generally speaking, Fianna Fil has taken more populist positions on economic and social matters than Fine Gael and the Labour Party. Their classic populist stance was highlighted during the years of Catholic dominance in Ireland before the mid-1980s and during the Celtic Tiger years when engaged in the high levels of public spending while deregulating and cutting taxes.\\r\\n\\r\\nBertie Ahern was the Taoiseach from 1997 to 2008 and negotiated numerous social partnership contracts, the Good Friday Agreement in Northern Ireland, and an agreement among EU heads of government on the European Constitution. He was succeeded by Brian Cowen in May 2008, after resigning due to evidence from the Mahon Tribunal into payments and planning matters. Support for Fianna Fil collapsed in the 2011 general election, which took place a few years into the financial crisis and soon after the government had sought a bailout from the troika of the IMF/EC/ECB. Fianna Fil lost more than three-quarters of its seats, coming third behind Fine Gael and the Labour Party. This lack of electoral success was short lived as the Republican Party swept to a resounding victory at the 2014 Local Elections before more than doubling their Dil seats at the 2016 General Election.\\r\\n\\r\\nIn September 2007, Fianna Fil announced that they would organise politically in the north, but have yet to contest elections for the Northern Ireland Assembly.\\r\\n\\r\\nFianna Fil has 44 TDs, 13 Senators, one MEP and 262 councillors.[4]\\r\\n\\r\\nSinn Fin is the third-largest party in the Oireachtas and the second-largest party in the Northern Assembly. The name Sinn Fin, meaning 'ourselves', has been used by a number of political organisations in Ireland since 1905, when first used by Arthur Griffith. Sinn Fin was the party of separatism before Irish independence, and broke through in the Westminster election of 1918, where it won 73 of the 105 Irish seats.\\r\\n\\r\\nThe modern-day Sinn Fin party emerged in 1970 after a split in the party, and was often distinguished as Provisional Sinn Fin. It was closely linked to the Provisional Irish Republican Army. It is led by Mary Lou McDonald.\\r\\n\\r\\nIt was the only political party to have seats in the parliaments of both Northern Ireland and the Republic of Ireland until the Green Party organised on an island-wide basis. Since supporting the Peace Process Sinn Fin has seen a dramatic increase in support in Northern Ireland and in the Republic of Ireland. It has emerged as the second largest party in the Northern Ireland Assembly with 27 seats out of 90 and the third largest in the Republic of Ireland with 23 seats in the Dil in the 2016 general election. With Fine Gael, it is one of only two parties in the Republic of Ireland with MEPs.\\r\\n\\r\\nSinn Fin's platform is primarily focused on achieving the reunification of Ireland and a large scale expansion of Ireland's social services (such as adopting a universal health care system and creating subsidised housing), reform of the tax system and support for small and co-operative businesses. Their political ideology mainly revolves around democratic socialism, Irish Republicanism, and civic nationalism.\\r\\n\\r\\nSinn Fin has 22 TDs, 6 Senators, 3 MEPs and 147 councillors in the Republic of Ireland.\\r\\n\\r\\nThe Labour Party is a social democratic party, founded in 1912 as part of the trade union movement, with which it maintains organisational links. For most of the history of the state, it was the third largest party, though it is currently in fourth position in parliamentary strength.\\r\\nIt has been in government in the periods 1948ÿ51, 1954ÿ57, 1973ÿ77, 1981ÿ82, 1982ÿ87, 1993ÿ94, 1994ÿ97, and 2011ÿ16.  On each of those occasions, it was in coalition with Fine Gael, with the exception of the period 1993 to 1994, when it was in coalition with Fianna Fil.\\r\\n\\r\\nThe Labour Party merged with the smaller Democratic Left party in 1999. It is a member of the Party of European Socialists and is led by Brendan Howlin.\\r\\n\\r\\nThe Labour Party has 7 TDs, 4 Senators and 48 councillors.\\r\\n\\r\\nSolidarityÿPeople Before Profit is an alliance between People Before Profit and Solidarity. People Before Profit (PBP) was formed in 2005, primarily by members of the Socialist Workers Party. The Anti-Austerity Alliance (AAA) was formed in 2014, primarily by members of the Socialist Party. In October 2015, they formed a new alliance for electoral purposes as the Anti-Austerity AllianceÿPeople Before Profit, but continue to organise separately. Both parties have shared platforms on abolishing water charges and the property tax along with tackling homelessness and the housing crisis. The founding TDs have stated their aim to build a mass party of the left and ultimately help form a left-wing government.[5] The AAA re-branded itself as Solidarity in March 2016.\\r\\n\\r\\nTogether they have 6 TDs (three each from Solidarity and PBP) and 23 councillors (11 from Solidarity and 12 from PBP).\\r\\n\\r\\nIndependents 4 Change has been registered as a political party since 2014. Its registered officer is Wexford TD Mick Wallace. The other deputies are Clare Daly and Joan Collins. Tommy Broughan was a member until July 2016. Three further TDs sit in the I4C Dil group while not being members of the party: Catherine Connolly, Thomas Pringle, and Maureen O'Sullivan.\\r\\n\\r\\nThey have 3 TDs and 1 councillor.\\r\\n\\r\\nThe Green Party was established in 1981 and is allied to the European Green Party. It won its first seat in the Dil in 1989, and had continued representation there until 2011. The party advocates ecological and socially liberal policies. In 1994 and again in 1999, two of Ireland's 15 MEPs were from the Green party, but both seats were lost in 2004.\\r\\n\\r\\nThe Green Party of Northern Ireland voted in 2005 to become a region of the Irish Green Party making it the second party to be organised on an all-Ireland basis. It has Northern Ireland members on the Irish Green Party national executive.\\r\\n\\r\\nIn June 2007, the Green Party entered coalition government with Fianna Fil and the Progressive Democrats. In January 2011 they left the coalition, and at the 2011 general election, lost all of their Dil seats.[6] They gained 2 seats at the 2016 general election.\\r\\n\\r\\nThe Green Party has 2 TDs, 1 Senator and 12 councillors.[6]\\r\\n\\r\\nThe Social Democrats were founded in July 2015 by three independent TDs Stephen Donnelly (who has since left the party for Fianna Fil), Catherine Murphy, and R܇isn Shortall, who will share leadership of the party until after the next general election. The Social Democrats describe themselves as being centre-left and in favour of Scandinavian style public services along with promoting indigenous small and medium-sized enterprise.\\r\\n\\r\\nThe Social Democrats have 2 TDs and 7 councillors.\\r\\n\\r\\nWorkers and Unemployed Action (WUA) is a left-wing political organisation formed in 1985 by Samus Healy in response to lack of employment and the economic situation in the South Tipperary area. Healy along with his brother Paddy Healy, were former members of the Trotskyist League for a Workers Republic. Healy was elected to Dil ireann as TD for Tipperary South at a by-election in 2000, holding the seat until 2007. He regained the seat at the 2011 general election. At the time of the 2011 election the WUA formed part of the United Left Alliance, but left in 2012.[7][8] WUA has one TD and one councillor.\\r\\n\\r\\nThe Human Dignity Alliance was founded by Senator R܇nn Mullen in June 2018. It has one senator.\\r\\n\\r\\nRenua was founded in March 2015 with Lucinda Creighton as its founding leader. It broadly advocates conservative and social conservative policies, including a flat tax and a three-strikes law at the 2016 general election. The founding parliamentary party deputies all left Fine Gael over their opposition to the Protection of Life During Pregnancy Act 2013. Subsequently Renua identifies itself as an anti-abortion party.[9]\\r\\n\\r\\nIt has no TDs, having lost all three at the 2016 general election. Renua has 2 councillors.\\r\\n\\r\\nThe Workers' Party is a MarxistÿLeninist party allied with the international workers and communist parties. It emerged from the Irish republican movement and was a continuation of Sinn Fin that did not break away in 1970. It retained links with the Official IRA. It renamed itself Sinn Fin The Workers' Party in 1977, and adopted its current title in 1982. It is organised in both the Republic of Ireland and Northern Ireland. During the 1980s it was a significant party on the political scene with 7 TDs elected in 1989 and 1 MEP. A special Ard Fheis (conference) in 1992 designed to re-constitute the party and remove links with the OIRA resulted in a formal split with the bulk of the parliamentary party and councillors leaving to form Democratic Left. Democratic Left voted to merge with the Labour Party in 1999. The Workers' Party has two councillors, ilis Ryan on Dublin City Council and Ted Tynan on Cork City Council.\\r\\n\\r\\nRepublican Sinn Fin were formed in 1986 by members of Sinn Fin who did not support the decision made at the party's ard fheis in that year to end its policy of abstentionism and to allow elected Sinn Fin TDs take their seats in Dil ireann.[10] Its first leader was Ruair ܇ Brdaigh, who was a previous leader of Sinn Fin, and had been elected as an abstentionist TD in 1957.\\r\\n\\r\\nThey have one councillor, Toms ܇ Curraoin on Galway County Council. As they are not a registered party, he is officially an independent councillor.\\r\\n\\r\\nThe Kerry Independent Alliance (previously the South Kerry Independent Alliance) have one councillor on Kerry County Council. It is registered to contest elections for Dil ireann and in Killarney for local elections.\\r\\n\\r\\nThe Communist Party of Ireland was first founded in 1921, and re-founded in 1933; the current communist party originates from 1970, when the Communist Party of Northern Ireland joined with the Irish Workers' Party (not related to the current Workers Party). While a registered political party, it rarely stands candidates in elections, and remains quite small. It was historically quite influential in the trade union movement.\\r\\n\\r\\nThe Socialist Party (initially known as Militant Labour) was formed in 1989 by members of the Militant Tendency who were expelled from the Labour Party. It was renamed the Socialist Party in 1996. The party is Trotskyist and is organised in both the Republic of Ireland and Northern Ireland. Joe Higgins was its first member elected at national level. It was part of the United Left Alliance in the 2011 general election,[7] along with the People Before Profit and the Workers and Unemployed Action Group, but that Alliance disintegrated over the course of the following Dil term. Its councillors contested the 2014 local elections as part of the Anti-Austerity Alliance. In 2014, it altered its registered name to Stop the Water Tax ÿ Socialist Party.[1][11] It now contests elections as part of the SolidarityÿPeople Before Profit party.\\r\\n\\r\\nThe party is affiliated to the Committee for a Workers' International (CWI).\\r\\n\\r\\nThe Socialist Workers Network was founded in 1971 as the Socialist Workers Movement. The party was set up by supporters of the International Socialists of Britain living in Ireland.\\r\\n\\r\\nJust as independent candidates, those standing for unregistered parties may choose either to be listed as \\"Non-Party\\", or to leave the section blank on the ballot paper.[2]","input":"What are the main political parties in ireland?"},{"output":"thirteen","context":"The Hawaiian alphabet (in Hawaiian: ka pؐ?p Hawai?i) is an alphabet used to write Hawaiian. It was adapted from the English alphabet in the early 19th century by American missionaries to print a bible in the Hawaiian language.\\r\\n\\r\\nIn 1778, British explorer James Cook made the first reported Europe voyage to Hawai?i. In his report, he wrote the name of the islands as \\"Owhyhee\\" or \\"Owhyee\\". In 1822, a writing system based on one similar to the new New Zealand Grammar was developed and printed by American Protestant missionary Elisha Loomis.[1] The original alphabet included five vowels and twelve consonants:\\r\\n\\r\\nand seven diphthongs:\\r\\n\\r\\nIn addition, the letters F, G, S, Y, and Z were used to spell foreign words.\\r\\n\\r\\nIn 1826, the developers voted to eliminate some of the letters which represented functionally redundant interchangeable letters, enabling the Hawaiian alphabet to approach the ideal state of one-symbol-one-sound, and thereby optimizing the ease with which people could teach and learn the reading and writing of Hawaiian.[2][3]\\r\\n\\r\\nDue to words with different meanings being spelled alike, use of the glottal stop became necessary. As early as 1823, the missionaries made limited use of the apostrophe to represent the glottal stop, but they did not make it a letter of the alphabet. In publishing the Hawaiian Bible, they used the ?okina to distinguish ko?u ('my') from kou ('your'). It was not until 1864 that the ?okina became a recognized letter of the Hawaiian alphabet.[2]\\r\\n\\r\\nAs early as 1821, one of the missionaries, Hiram Bingham, was using macrons in making handwritten transcriptions of Hawaiian vowels. The macron, or kahak, was used to differentiate between short and long vowels.\\r\\n\\r\\nThe current official Hawaiian alphabet consists of thirteen letters: five vowels (A?a, E?e, I?i, O?o, U?u) and eight consonants (H?h, K?k, L?l, M?m, N?n, P?p, W?w, ?).[2] Alphabetic order differs from the normal Latin order in that the vowels come first, then the consonants.  The five vowels with macrons ÿؐ?ؐ, ÿ are not treated as separate letters, but are alphabetized immediately after unaccented vowels. The ?okina is ignored for purposes of alphabetization.\\r\\n\\r\\nThe letter names were invented for Hawaiian specifically, since they do not follow traditional European letter names in most cases. The names of M, N, P, and possibly L were most likely derived from Greek, and that for W from the deleted letter V.\\r\\n\\r\\nwith lower offglide\\r\\n\\r\\nKaona = hidden meaning\\r\\n\\r\\nsimilar to ew in few","input":"How many hawaiian letters are in the alphabet?"},{"output":"Hipparchus","context":"The history of longitude is a record of the effort, by astronomers, cartographers and navigators over several centuries, to discover a means of determining longitude.\\r\\nThe measurement of longitude is important to both cartography and navigation, in particular to provide safe ocean navigation. Knowledge of both latitude and longitude was required. Finding an accurate and reliable method of determining longitude took centuries of study, and involved some of the greatest scientific minds in human history.\\r\\n\\r\\n\\r\\nEratosthenes in the 3rd century BC first proposed a system of latitude and longitude for a map of the world. By the 2nd century BC Hipparchus was the first to use such a system to uniquely specify places on the earth. He also proposed a system of determining longitude by comparing the local time of a place with an absolute time. This is the first recognition that longitude can be determined by accurate knowledge of time. In the 11th century Al-Biruni believed the earth rotated on its axis and this forms our modern notion of how time and longitude are related.[1]\\r\\nDetermining latitude was relatively easy in that it could be found from the altitude of the sun at noon (i.e. at its highest point) with the aid of a table giving the sun's declination for the day, or from many stars at night. For longitude, early ocean navigators had to rely on dead reckoning. This was inaccurate on long voyages out of sight of land and these voyages sometimes ended in tragedy as a result.\\r\\nDetermining longitude at sea was also much harder than on land. A stable surface to work from, a comfortable location to live in while performing the work, and the ability to repeat determinations over time made various astronomical techniques possible on land (such as the observation of eclipses) that were unfortunately impractical at sea. Whatever could be discovered from solving the problem at sea would only improve the determination of longitude on land.\\r\\nIn order to avoid problems with not knowing one's position accurately, navigators have, where possible, relied on taking advantage of their knowledge of latitude. They would sail to the latitude of their destination, turn toward their destination and follow a line of constant latitude. This was known as running down a westing (if westbound, easting otherwise).[2] This prevented a ship from taking the most direct route (a great circle) or a route with the most favourable winds and currents, extending the voyage by days or even weeks. This increased the likelihood of short rations,[3] which could lead to poor health or even death for members of the crew due to scurvy or starvation, with resultant risk to the ship.\\r\\nErrors in navigation have also resulted in shipwrecks. Motivated by a number of maritime disasters attributable to serious errors in reckoning position at sea, particularly such spectacular disasters as the Scilly naval disaster of 1707, which took Admiral Sir Cloudesley Shovell and his fleet, the British government established the Board of Longitude in 1714:\\r\\n\\"The Discovery of the Longitude is of such Consequence to Great Britain for the safety of the Navy and Merchant Ships as well as for the improvement of Trade that for want thereof many Ships have been retarded in their voyages, and many lost...\\" [and there will be a Longitude Prize] \\"for such person or persons as shall discover the Longitude.\\"\\r\\nThe prizes were to be awarded for the discovery and demonstration of a practical method for determining the longitude of a ship at sea. Prizes were offered in graduated amounts for solutions of increasing accuracy. These prizes, worth the equivalent of millions of pounds in today's currency, motivated many to search for a solution.\\r\\nBritain was not alone in the desire to solve the problem. France's King Louis XIV founded the Acadmie Royale des Sciences in 1666. It was charged with, among a range of other scientific activities, advancement of the science of navigation and the improvement of maps and sailing charts. From 1715, the Acadmie offered one of the two Prix Rouills specifically for navigation.[4] Spain's Philip II offered a prize for the discovery of a solution to the problem of the longitude in 1567; Philip III increased the prize in 1598. Holland added to the effort with a prize offered in 1636.[1] Navigators and scientists in most European countries were aware of the problem and were involved in finding a solution. Due to the international effort in solving the problem and the scale of the enterprise, it represented one of the largest scientific endeavours in history.\\r\\nSince the Earth rotates at a steady rate of 360 per day, or 15 per hour (in mean solar time), there is a direct relationship between time and longitude. If the navigator knew the time at a fixed reference point when some event occurred at the ship's location, the difference between the reference time and the apparent local time would give the ship's position relative to the fixed location. Finding apparent local time is relatively easy. The problem, ultimately, was how to determine the time at a distant reference point while on a ship.\\r\\nThe first publication of a method of determining time by observing the position of the Earth's moon was by Johannes Werner in his In hoc opere haec continentur Nova translatio primi libri geographiae Cl. Ptolomaei, published at Nuremberg in 1514. The method was discussed in detail by Petrus Apianus in his Cosmographicus liber (Landshut 1524).\\r\\nIt appears that Johannes Werner inspired by Amerigo Vespucci's letter written in 1502 where he wrote: \\"...I maintain that I learned [my longitude] ... by the eclipses and conjunctions of the Moon with the planets; and I have lost many nights of sleep in reconciling my calculations with the precepts of those sages who have devised the manuals and written of the movements, conjunctions, aspects, and eclipses of the two luminaries and of the wandering stars, such as the wise King Don Alfonso in his Tables, Johannes Regiomontanus in his Almanac, and Blanchinus, and the Rabbi Zacuto in his almanac, which is perpetual; and these were composed in different meridians: King Don Alfonso's book in the meridian of Toledo, and Johannes Regiomontanus's in that of Ferrara, and the other two in that of Salamanca.\\"2 The best \\"clock\\" to use for reference, is the stars. In the roughly 27.3 solar days of a lunar orbit, the Moon moves a full 360 degrees around the sky, returning to its old position among the stars. This is 13 degrees per day, or just over 0.5 degree per hour. So, while the rotation of the Earth causes the stars and the Moon to appear to move from east to west across the night sky, the Moon, because of its own orbit around the Earth, fights back against this apparent motion, and seems to move eastward (or retrograde) by about 0.5 degree per hour. In other words, the Moon \\"moves\\" west only 11.5 degrees per day.\\"\\r\\nIn 1612, having determined the orbital periods of Jupiter's four brightest satellites (Io, Europa, Ganymede and Callisto), Galileo proposed that with sufficiently accurate knowledge of their orbits one could use their positions as a universal clock, which would make possible the determination of longitude. He worked on this problem from time to time during the remainder of his life.\\r\\nTo be successful, this method required the observation of the moons from the deck of a moving ship. To this end, Galileo proposed the celatone, a device in the form of a helmet with a telescope mounted so as to accommodate the motion of the observer on the ship.[5] This was later replaced with the idea of a pair of nested hemispheric shells separated by a bath of oil. This would provide a platform that would allow the observer to remain stationary as the ship rolled beneath him, in the manner of a gimballed platform. To provide for the determination of time from the observed moons' positions, a Jovilabe was offered  this was an analogue computer that calculated time from the positions and that got its name from its similarities to an astrolabe.[6] The practical problems were severe and the method was never used at sea. However, it was used for longitude determination on land.\\r\\nAround 1683, Edmund Halley proposed using a telescope to observe the time of occultations or appulses of a star by the moon as a means of determining time while at sea.[7] He had accumulated observations of the moon's position and of certain stars to this end, and had deduced the means of correcting errors in predictions of the moon's position.\\r\\nUpon succeeding John Flamsteed in the post of Astronomer Royal, Halley had undertaken the task of observing both stellar positions and the path of the moon, with the intention of supplementing existing knowledge and advancing his proposal for determining longitude at sea.[7] By this time, he had abandoned the use of occultations in preference for appulses exclusively. No reason was given by Halley for abandoning occultations. However, there are few bright stars occulted by the moon, and the task of documenting the dim stars' positions and training navigators to recognize them would be daunting. Appulses with brighter stars would be more practical.\\r\\nWhile he had tested the method at sea, it was never widely used or considered as a viable method. His observations did contribute to the lunar distance method.\\r\\nHalley also hoped that careful observations of magnetic deviations could provide a determination of longitude. The magnetic field of the Earth was not well understood at the time. Mariners had observed that magnetic north deviated from geographic north in many locations. Halley and others hoped that the pattern of deviation, if consistent, could be used to determine longitude. If the measured deviation matched that recorded on a chart, the position would be known. Halley used his voyages on the pink Paramour to study the magnetic variance and was able to provide maps showing the halleyan or isogonic lines. This method was eventually to fail as the localized variations from general magnetic trends make the method unreliable.\\r\\nA Frenchman, the Sieur de St. Pierre, brought Werner's technique to the attention of King Charles II of England in 1674.[8] Being enthusiastic for the proposed technique, the king contacted his royal commissioners, who included Robert Hooke. They in turn consulted the astronomer John Flamsteed. Flamsteed supported the feasibility of the method but lamented the lack of detailed knowledge of the stellar positions and the moon's movement. At the same time, Sir Jonas Moore had suggested to King Charles the establishment of an observatory and proposed Flamsteed as the first Astronomer Royal. With the creation of the Royal Observatory, Greenwich and a program for measuring the positions of the stars with high precision, the process of gathering the data for a working method of lunar distances was under way.[9] To further the astronomers' ability to predict the moon's motion, Isaac Newton soon published his theory of gravitation, which could be applied to the motion of the moon.\\r\\nIn 1755, Tobias Mayer, the German astronomer and superintendent of the observatory at G?ttingen, who had been working on a method to determine accurately positions on land based on lunar distances, sent a proposal to the Admiralty. He had corresponded with Leonhard Euler, who contributed information and equations to describe the motions of the moon.[10] Based on this work, Mayer had produced a set of tables predicting the position of the Moon more accurately than ever before. The Admiralty passed them on to the Board of Longitude for evaluation and consideration for the Longitude Prize. James Bradley, the Astronomer Royal at that time, evaluated the tables, and found their predictions to be accurate to within half a degree. The calculations themselves, however, were extremely laborious and time-consuming.\\r\\nA decade later, Nevil Maskelyne, who as the newly appointed Astronomer Royal was on the Board of Longitude, armed with Mayer's tables and after his own experiments at sea trying out the lunar distance method, proposed annual publication of pre-calculated lunar distance predictions in an official nautical almanac for the purpose of finding longitude at sea.\\r\\nBeing very enthusiastic for the lunar distance method, Maskelyne and his team of computers worked feverishly through the year 1766, preparing tables for the new Nautical Almanac and Astronomical Ephemeris. Published first with data for the year 1767, it included daily tables of the positions of the Sun, Moon, and planets and other astronomical data, as well as tables of lunar distances giving the distance of the Moon from the Sun and nine stars suitable for lunar observations (ten stars for the first few years).[11] [12] This publication later became the standard almanac for mariners worldwide. Since it was based on the Royal Observatory, it helped lead to the international adoption a century later of the Greenwich Meridian as an international standard.\\r\\nAnother proposed solution was to use a mechanical timepiece, to be carried on a ship, that would maintain the correct time at a reference location. The concept of using a clock can be attributed to Gemma Frisius. Attempts had been made on land using pendulum clocks, with some success. In particular, Huygens had made accurate pendulum clocks that made it possible to determine longitude on land. He also proposed the use of a balance spring to regulate clocks. There is some dispute as to whether he or Robert Hooke first proposed this idea.[13] However, many, including Isaac Newton, were pessimistic that a clock of the required accuracy could ever be developed. At that time, there were no clocks that could maintain accurate time while being subjected to the conditions of a moving ship. The rolling, pitching and yawing, coupled with the pounding of wind and waves, would knock existing clocks out of the correct time.\\r\\nIn spite of this pessimism, a group felt that the answer lay in chronometrydeveloping an improved time piece that would work even on extended voyages at sea. A suitable timepiece was eventually built by John Harrison, a Yorkshire carpenter, with his marine chronometer; that timepiece was later known as H-4.\\r\\nHarrison built five, two of which were tested at sea. His first, H-1, was not tested under the conditions that were required by the Board of Longitude. Instead, the Admiralty required that it travel to Lisbon and back. It performed excellently, but the perfectionist in Harrison prevented him from sending it on the required trial to the West Indies. He instead embarked on the construction of H-2. This chronometer never went to sea, and was immediately followed by H-3. Still not satisfied with his own work, Harrison produced H-4, which did get its sea trial and satisfied all the requirements for the Longitude Prize. However, he was not awarded the prize and was forced to fight for his reward.\\r\\nThough the British Parliament rewarded John Harrison for his marine chronometer in 1773, his chronometers were not to become standard. Chronometers such as those by Thomas Earnshaw were suitable for general nautical use by the middle of the 19th century (1836).[14] However, they remained very expensive and the lunar distance method continued to be used for some decades.\\r\\nThe lunar distance method was initially labour-intensive because of the time-consuming complexity of the calculations for the Moon's position. Early trials of the method could involve four hours of effort.[9] However, the publication of the Nautical Almanac starting in 1767 provided tables of pre-calculated distances of the Moon from various celestial objects at three-hour intervals for every day of the year, making the process practical by reducing the time for calculations to less than 30 minutes and as little as ten minutes with some efficient tabular methods.[15] Lunar distances were widely used at sea from 1767 to about 1905. With the new tables with Haversines from Josef de Mendoza y Ros (1805), computation time was reduced to a few minutes.\\r\\nBetween 1800 and 1850 (earlier in British and French navigation practice, later in American, Russian, and other maritime countries), affordable, reliable marine chronometers became available, with a trend to replace the method of lunars as soon as they could reach the market in large numbers. It became possible to buy three or more chronometers, serving for checking on each other (redundancy), although according to Nathaniel Bowditch, their use was precluded because they were very expensive, [16] obviously much higher than a single sextant of sufficient quality for lunar distance navigation which continued in use until 1906.[17]\\r\\nTwo chronometers provided dual modular redundancy, allowing a backup if one should cease to work, but not allowing any error correction if the two displayed a different time, since in case of contradiction between the two chronometers, it would be impossible to know which one was wrong (the error detection obtained would be the same of having only one chronometer and checking it periodically: every day at noon against dead reckoning). Three chronometers provided triple modular redundancy, allowing error correction if one of the three was wrong, so the pilot would take the average of the two with closer readings (average precision vote). There is an old adage to this effect, stating: \\"Never go to sea with two chronometers; take one or three.\\"[18] At one time this observation or rule was an expensive one as the cost of three sufficiently accurate chronometers was more than the cost of many types of smaller merchant vessels.[19] Some vessels carried more than three chronometers ÿ for example, the HMS Beagle carried 22 chronometers.[20]\\r\\nBy 1850, the vast majority of ocean-going navigators worldwide had ceased using the method of lunar distances. Nonetheless, expert navigators continued to learn lunars as late as 1905, though for most this was a textbook exercise since they were a requirement for certain licenses. They also continued in use in land exploration and mapping where chronometers could not be kept secure in harsh conditions. The British Nautical Almanac published lunar distance tables until 1906 and the instructions until 1924.[21] Such tables last appeared in the 1912 USNO Nautical Almanac, though an appendix explaining how to generate single values of lunar distances was published as late as the early 1930s.[12] The presence of lunar distance tables in these publications until the early 20th century does not imply common usage until that time period but was simply a necessity due to a few remaining (soon to be obsolete) licensing requirements. The development of wireless telegraph time signals in the early 20th century, used in combination with marine chronometers, put a final end to the use of lunar distance tables.\\r\\nTime signals were first broadcast by wireless telegraphy in 1904, by the US Navy from Navy Yard in Boston. Another regular broadcast began in Halifax, Nova Scotia in 1907, and time signals that became more widely used were broadcast from the Eiffel Tower starting in 1910.[22] As ships adopted radio telegraph sets for communication, such time signals were used to correct chronometers. This method drastically reduced the importance of lunars as a means of verifying chronometers.\\r\\nModern sailors have a number of choices for determining accurate positional information, including radar and the Global Positioning System, commonly known as GPS, a satellite navigation system. With technical refinements that make position fixes accurate to within meters, the radio-based LORAN system was used in the late 20th Century but has been discontinued in North America. Combining independent methods is used as a way to improve the accuracy of position fixes. Even with the availability of multiple modern methods of determining longitude, a marine chronometer and sextant are routinely carried as a backup system.\\r\\nFor the determination of longitude on land, the preferred method became exchanges of chronometers between observatories to accurately determine the differences in local times in conjunction with observation of the transit of stars across the meridian.\\r\\nAn alternative method was the simultaneous observation of occultations of stars at different observatories. Since the event occurred at a known time, it provided an accurate means of determining longitude. In some cases, special expeditions were mounted to observe a special occultation or eclipse to determine the longitude of a location without a permanent observatory.\\r\\nFrom the mid-19th century, telegraph signalling allowed more precisely synchronization of star observations. This significantly improved longitude measurement accuracy. The Royal Observatory in Greenwich and the U.S. Coast Survey coordinated European and North American longitude measurement campaigns in the 1850s and 1860s, resulting in improved map accuracy and navigation safety. Synchronization by radio followed in the early 20th century. In the 1970s, the use of satellites was developed to more precisely measure geographic coordinates (GPS).\\r\\nIn the process of searching for a solution to the problem of determining longitude, many scientists added to the knowledge of astronomy and physics.","input":"Who invented the latitude and longitude grid system?"},{"output":"100ÿ400 billion stars","context":"The Milky Way is the galaxy[nb 1] that contains our Solar System. The descriptive \\"milky\\" is derived from the appearance from Earth of the galaxy ÿ a band of light seen in the night sky formed from stars that cannot be individually distinguished by the naked eye. The term Milky Way is a translation of the Latin via lactea, from the Greek ϫϫ?ϫ? ?? (galaxas kyklos, \\"milky circle\\").[21][22][23] From Earth, the Milky Way appears as a band because its disk-shaped structure is viewed from within. Galileo Galilei first resolved the band of light into individual stars with his telescope in 1610. Until the early 1920s, most astronomers thought that the Milky Way contained all the stars in the Universe.[24] Following the 1920 Great Debate between the astronomers Harlow Shapley and Heber Curtis,[25] observations by Edwin Hubble showed that the Milky Way is just one of many galaxies.\\r\\nThe Milky Way is a barred spiral galaxy with a diameter between 100,000[26] and 180,000 light-years (ly).[27] It is estimated to contain 100ÿ400 billion stars.[28][29] There are probably at least 100 billion planets in the Milky Way.[30][31] The Solar System is located within the disk, about 26,000 light-years from the Galactic Center, on the inner edge of the Orion Arm, one of the spiral-shaped concentrations of gas and dust. The stars in the innermost 10,000 light-years form a bulge and one or more bars that radiate from the bulge. The galactic center is an intense radio source known as Sagittarius A*, likely a supermassive black hole.\\r\\nStars and gases at a wide range of distances from the Galactic Center orbit at approximately 220 kilometers per second. The constant rotation speed contradicts the laws of Keplerian dynamics and suggests that much of the mass of the Milky Way does not emit or absorb electromagnetic radiation. This mass has been termed \\"dark matter\\".[32] The rotational period is about 240 million years at the position of the Sun.[18] The Milky Way as a whole is moving at a velocity of approximately 600?km per second with respect to extragalactic frames of reference. The oldest stars in the Milky Way are nearly as old as the Universe itself and thus probably formed shortly after the Dark Ages of the Big Bang.[9]\\r\\nThe Milky Way has several satellite galaxies and is part of the Local Group of galaxies, which form part of the Virgo Supercluster, which is itself a component of the Laniakea Supercluster.[33][34]\\r\\n\\r\\n\\r\\nThe Milky Way is visible from Earth as a hazy band of white light some 30 degrees wide arcing across the sky.[35] Although all the individual naked-eye stars in the entire sky are part of the Milky Way,[36][37] the light in this band originates from the accumulation of unresolved stars and other material located in the direction of the galactic plane. Dark regions within the band, such as the Great Rift and the Coalsack, are areas where light from distant stars is blocked by interstellar dust. The area of the sky obscured by the Milky Way is called the Zone of Avoidance.\\r\\nThe Milky Way has a relatively low surface brightness. Its visibility can be greatly reduced by background light such as light pollution or stray light from the Moon. The sky needs to be darker than about 20.2 magnitude per square arcsecond in order for the Milky Way to be seen.[38] It should be visible when the limiting magnitude is approximately +5.1 or better and shows a great deal of detail at +6.1.[39] This makes the Milky Way difficult to see from any brightly lit urban or suburban location, but very prominent when viewed from a rural area when the Moon is below the horizon.[nb 2] \\"The new world atlas of artificial night sky brightness\\" shows that more than one-third of Earth's population cannot see the Milky Way from their homes due to light pollution.[40]\\r\\nAs viewed from Earth, the visible region of the Milky Way's Galactic plane occupies an area of the sky that includes 30 constellations.[41] The center of the Galaxy lies in the direction of the constellation Sagittarius; it is here that the Milky Way is brightest. From Sagittarius, the hazy band of white light appears to pass around to the Galactic anticenter in Auriga. The band then continues the rest of the way around the sky, back to Sagittarius. The band divides the night sky into two roughly equal hemispheres.\\r\\nThe Galactic plane is inclined by about 60 degrees to the ecliptic (the plane of Earth's orbit). Relative to the celestial equator, it passes as far north as the constellation of Cassiopeia and as far south as the constellation of Crux, indicating the high inclination of Earths equatorial plane and the plane of the ecliptic, relative to the Galactic plane. The north Galactic pole is situated at right ascension 12h 49m, declination +27.4 (B1950) near  Comae Berenices, and the south Galactic pole is near ϫ Sculptoris. Because of this high inclination, depending on the time of night and year, the arc of the Milky Way may appear relatively low or relatively high in the sky. For observers from approximately 65 degrees north to 65 degrees south on Earth's surface, the Milky Way passes directly overhead twice a day.\\r\\nThe Milky Way is the second-largest galaxy in the Local Group, with its stellar disk approximately 100,000?ly (30?kpc) in diameter, and, on average, approximately 1,000?ly (0.3?kpc) thick.[4][5] As a guide to the relative physical scale of the Milky Way, if the Solar System out to Neptune were the size of a US quarter (24.3?mm (0.955?in)), the Milky Way would be approximately the size of the continental United States.[42] A ring-like filament of stars wrapping around the Milky Way may belong to the Milky Way itself, rippling above and below the relatively flat galactic plane.[27] If so, that would mean a diameter of 150,000ÿ180,000 light-years (46ÿ55?kpc).[43]\\r\\nEstimates of the mass of the Milky Way vary, depending upon the method and data used. At the low end of the estimate range, the mass of the Milky Way is 5.8G1011?solar masses (M?), somewhat less than that of the Andromeda Galaxy.[44][45][46] Measurements using the Very Long Baseline Array in 2009 found velocities as large as 254?km/s (570,000?mph) for stars at the outer edge of the Milky Way.[47] Because the orbital velocity depends on the total mass inside the orbital radius, this suggests that the Milky Way is more massive, roughly equaling the mass of Andromeda Galaxy at 7G1011?M? within 160,000?ly (49?kpc) of its center.[48] In 2010, a measurement of the radial velocity of halo stars found that the mass enclosed within 80 kiloparsecs is 7G1011?M?.[49] According to a study published in 2014, the mass of the entire Milky Way is estimated to be 8.5G1011?M?,[50] which is about half the mass of the Andromeda Galaxy.[50]\\r\\nMuch of the mass of the Milky Way appears to be dark matter, an unknown and invisible form of matter that interacts gravitationally with ordinary matter. A dark matter halo is spread out relatively uniformly to a distance beyond one hundred kiloparsecs (kpc) from the Galactic Center. Mathematical models of the Milky Way suggest that the mass of dark matter is 1ÿ1.5G1012?M?.[10][11][51] Recent studies indicate a range in mass, as large as 4.5G1012?M? [52] and as small as 8G1011?M?.[53]\\r\\nThe total mass of all the stars in the Milky Way is estimated to be between 4.6G1010?M?[54] and 6.43G1010?M?.[10] In addition to the stars, there is also interstellar gas, comprising 90% hydrogen and 10% helium by mass,[55] with two thirds of the hydrogen found in the atomic form and the remaining one-third as molecular hydrogen.[56] The mass of this gas is equal to between 10%[56] and 15%[55] of the total mass of the galaxy's stars. Interstellar dust accounts for an additional 1% of the total mass of the gas.[55]\\r\\nThe Milky Way contains between 200 and 400?billion stars[57][58] and at least 100?billion planets.[59] The exact figure depends on the number of very-low-mass stars, which are hard to detect, especially at distances of more than 300?ly (90?pc) from the Sun. As a comparison, the neighboring Andromeda Galaxy contains an estimated one trillion (1012) stars.[60] The Milky Way may also contain perhaps ten billion white dwarfs, a billion neutron stars, and a hundred million black holes.[nb 3][61][62][63] Filling the space between the stars is a disk of gas and dust called the interstellar medium. This disk has at least a comparable extent in radius to the stars,[64] whereas the thickness of the gas layer ranges from hundreds of light years for the colder gas to thousands of light years for warmer gas.[65][66]\\r\\nThe disk of stars in the Milky Way does not have a sharp edge beyond which there are no stars. Rather, the concentration of stars decreases with distance from the center of the Milky Way. For reasons that are not understood, beyond a radius of roughly 40,000 ly (13 kpc) from the center, the number of stars per cubic parsec drops much faster with radius.[67] Surrounding the galactic disk is a spherical Galactic Halo of stars and globular clusters that extends further outward but is limited in size by the orbits of two Milky Way satellites, the Large and Small Magellanic Clouds, whose closest approach to the Galactic Center is about 180,000?ly (55?kpc).[68] At this distance or beyond, the orbits of most halo objects would be disrupted by the Magellanic Clouds. Hence, such objects would probably be ejected from the vicinity of the Milky Way. The integrated absolute visual magnitude of the Milky Way is estimated to be around ?20.9.[69][70][a]\\r\\nBoth gravitational microlensing and planetary transit observations indicate that there may be at least as many planets bound to stars as there are stars in the Milky Way,[30][71] and microlensing measurements indicate that there are more rogue planets not bound to host stars than there are stars.[72][73] The Milky Way contains at least one planet per star, resulting in 100ÿ400 billion planets, according to a January 2013 study of the five-planet star system Kepler-32 with the Kepler space observatory.[31] A different January 2013 analysis of Kepler data estimated that at least 17 billion Earth-sized exoplanets reside in the Milky Way.[74] On November 4, 2013, astronomers reported, based on Kepler space mission data, that there could be as many as 40 billion Earth-sized planets orbiting in the habitable zones of Sun-like stars and red dwarfs within the Milky Way.[75][76][77] 11 billion of these estimated planets may be orbiting Sun-like stars.[78] The nearest such planet may be 4.2 light-years away, according to a 2016 study.[79] Such Earth-sized planets may be more numerous than gas giants.[30] Besides exoplanets, \\"exocomets\\", comets beyond the Solar System, have also been detected and may be common in the Milky Way.[80]\\r\\n360-degree panorama view of the Milky Way (an assembled mosaic of photographs) by ESO. The galactic centre is in the middle of the view, with galactic north up.\\r\\nThe Milky Way consists of a bar-shaped core region surrounded by a disk of gas, dust and stars. The mass distribution within the Milky Way closely resembles the type Sbc in the Hubble classification, which represents spiral galaxies with relatively loosely wound arms.[1] Astronomers first began to suspect that the Milky Way is a barred spiral galaxy, rather than an ordinary spiral galaxy, in the 1960s.[83][84][85] Their suspicions were confirmed by the Spitzer Space Telescope observations in 2005[86] that showed the Milky Way's central bar to be larger than previously thought.\\r\\nA galactic quadrant, or quadrant of the Milky Way, refers to one of four circular sectors in the division of the Milky Way. In actual astronomical practice, the delineation of the galactic quadrants is based upon the galactic coordinate system, which places the Sun as the origin of the mapping system.[87]\\r\\nQuadrants are described using ordinalsfor example, \\"1st galactic quadrant\\",[88] \\"second galactic quadrant\\",[89] or \\"third quadrant of the Milky Way\\".[90] Viewing from the north galactic pole with 0 degrees () as the ray that runs starting from the Sun and through the Galactic Center, the quadrants are as follows:\\r\\nThe Sun is 25,000ÿ28,000?ly (7.7ÿ8.6?kpc) from the Galactic Center. This value is estimated using geometric-based methods or by measuring selected astronomical objects that serve as standard candles, with different techniques yielding various values within this approximate range.[15][16][17][92][93][94] In the inner few kpc (around 10,000 light-years radius) is a dense concentration of mostly old stars in a roughly spheroidal shape called the bulge.[95] It has been proposed that the Milky Way lacks a bulge formed due to a collision and merger between previous galaxies, and that instead it only has a pseudobulge formed by its central bar.[96] However, confusion in the literature between the (peanut shell)-shaped structure created by instabilities in the bar, versus a possible bulge with an expected half-light radius of 0.5 kpc[97], abound.\\r\\nThe Galactic Center is marked by an intense radio source named Sagittarius A* (pronounced Sagittarius A-star). The motion of material around the center indicates that Sagittarius A* harbors a massive, compact object.[98] This concentration of mass is best explained as a supermassive black hole[nb 4][15][99] (SMBH) with an estimated mass of 4.1ÿ4.5 million times the mass of the Sun.[99] The rate of accretion of the SMBH is consistent with an inactive galactic nucleus, being estimated at around 6995100000000000000?1G10?5?M??y?1.[100] Observations indicate that there are SMBH located near the center of most normal galaxies.[101][102]\\r\\nThe nature of the Milky Way's bar is actively debated, with estimates for its half-length and orientation spanning from 1?to 5?kpc (3,000ÿ16,000?ly) and 10ÿ50 degrees relative to the line of sight from Earth to the Galactic Center.[93][94][103] Certain authors advocate that the Milky Way features two distinct bars, one nestled within the other.[104] However, RR Lyrae variables do not trace a prominent Galactic bar.[94][105][106] The bar may be surrounded by a ring called the \\"5-kpc ring\\" that contains a large fraction of the molecular hydrogen present in the Milky Way, as well as most of the Milky Way's star formation activity. Viewed from the Andromeda Galaxy, it would be the brightest feature of the Milky Way.[107] X-ray emission from the core is aligned with the massive stars surrounding the central bar[100] and the Galactic ridge.[108]\\r\\nIn 2010, two gigantic spherical bubbles of high energy emission were detected to the north and the south of the Milky Way core, using data from the Fermi Gamma-ray Space Telescope. The diameter of each of the bubbles is about 25,000 light-years (7.7?kpc); they stretch up to Grus and to Virgo on the night-sky of the southern hemisphere.[109][110] Subsequently, observations with the Parkes Telescope at radio frequencies identified polarized emission that is associated with the Fermi bubbles. These observations are best interpreted as a magnetized outflow driven by star formation in the central 640?ly (200?pc) of the Milky Way.[111]\\r\\nLater, on January 5, 2015, NASA reported observing an X-ray flare 400 times brighter than usual, a record-breaker, from Sagittarius A*. The unusual event may have been caused by the breaking apart of an asteroid falling into the black hole or by the entanglement of magnetic field lines within gas flowing into Sagittarius A*.[82]\\r\\nOutside the gravitational influence of the Galactic bars, the structure of the interstellar medium and stars in the disk of the Milky Way is organized into four spiral arms.[112] Spiral arms typically contain a higher density of interstellar gas and dust than the Galactic average as well as a greater concentration of star formation, as traced by H II regions[113][114] and molecular clouds.[115]\\r\\nThe Milky Way's spiral structure is uncertain, and there is currently no consensus on the nature of the Milky Way's spiral arms.[81] Perfect logarithmic spiral patterns only crudely describe features near the Sun,[114][116] because galaxies commonly have arms that branch, merge, twist unexpectedly, and feature a degree of irregularity.[94][116][117] The possible scenario of the Sun within a spur / Local arm[114] emphasizes that point and indicates that such features are probably not unique, and exist elsewhere in the Milky Way.[116] Estimates of the pitch angle of the arms range from about 7 to 25.[64][118] There are thought to be four spiral arms that all start near the Milky Way's center.[119] These are named as follows, with the positions of the arms shown in the image at right:\\r\\nTwo spiral arms, the ScutumÿCentaurus arm and the CarinaÿSagittarius arm, have tangent points inside the Sun's orbit about the center of the Milky Way. If these arms contain an overdensity of stars compared to the average density of stars in the Galactic disk, it would be detectable by counting the stars near the tangent point. Two surveys of near-infrared light, which is sensitive primarily to red giants and not affected by dust extinction, detected the predicted overabundance in the ScutumÿCentaurus arm but not in the CarinaÿSagittarius arm: the Scutum-Centaurus Arm contains approximately 30% more red giants than would be expected in the absence of a spiral arm.[118][121] This observation suggests that the Milky Way possesses only two major stellar arms: the Perseus arm and the ScutumÿCentaurus arm. The rest of the arms contain excess gas but not excess old stars.[81] In December 2013, astronomers found that the distribution of young stars and star-forming regions matches the four-arm spiral description of the Milky Way.[122][123][124] Thus, the Milky Way appears to have two spiral arms as traced by old stars and four spiral arms as traced by gas and young stars. The explanation for this apparent discrepancy is unclear.[124]\\r\\nThe Near 3 kpc Arm (also called Expanding 3 kpc Arm or simply 3 kpc Arm) was discovered in the 1950s by astronomer van Woerden and collaborators through 21-centimeter radio measurements of HI (atomic hydrogen).[125][126] It was found to be expanding away from the central bulge at more than 50 km/s. It is located in the fourth galactic quadrant at a distance of about 5.2 kpc from the Sun and 3.3 kpc from the Galactic Center. The Far 3 kpc Arm was discovered in 2008 by astronomer Tom Dame (Harvard-Smithsonian CfA). It is located in the first galactic quadrant at a distance of 3 kpc (about 10,000 ly) from the Galactic Center.[126][127]\\r\\nA simulation published in 2011 suggested that the Milky Way may have obtained its spiral arm structure as a result of repeated collisions with the Sagittarius Dwarf Elliptical Galaxy.[128]\\r\\nIt has been suggested that the Milky Way contains two different spiral patterns: an inner one, formed by the Sagittarius arm, that rotates fast and an outer one, formed by the Carina and Perseus arms, whose rotation velocity is slower and whose arms are tightly wound. In this scenario, suggested by numerical simulations of the dynamics of the different spiral arms, the outer pattern would form an outer pseudoring,[129] and the two patterns would be connected by the Cygnus arm.[130]\\r\\nOutside of the major spiral arms is the Monoceros Ring (or Outer Ring), a ring of gas and stars torn from other galaxies billions of years ago. However, several members of the scientific community recently restated their position affirming the Monoceros structure is nothing more than an over-density produced by the flared and warped thick disk of the Milky Way.[131]\\r\\nThe Galactic disk is surrounded by a spheroidal halo of old stars and globular clusters, of which 90% lie within 100,000 light-years (30?kpc) of the Galactic Center.[132] However, a few globular clusters have been found farther, such as PAL 4 and AM1 at more than 200,000 light-years from the Galactic Center. About 40% of the Milky Way's clusters are on retrograde orbits, which means they move in the opposite direction from the Milky Way rotation.[133] The globular clusters can follow rosette orbits about the Milky Way, in contrast to the elliptical orbit of a planet around a star.[134]\\r\\nAlthough the disk contains dust that obscures the view in some wavelengths, the halo component does not. Active star formation takes place in the disk (especially in the spiral arms, which represent areas of high density), but does not take place in the halo, as there is little gas cool enough to collapse into stars.[18] Open clusters are also located primarily in the disk.[135]\\r\\nDiscoveries in the early 21st century have added dimension to the knowledge of the Milky Way's structure. With the discovery that the disk of the Andromeda Galaxy (M31) extends much further than previously thought,[136] the possibility of the disk of the Milky Way extending further is apparent, and this is supported by evidence from the discovery of the Outer Arm extension of the Cygnus Arm[120][137] and of a similar extension of the Scutum-Centaurus Arm.[138] With the discovery of the Sagittarius Dwarf Elliptical Galaxy came the discovery of a ribbon of galactic debris as the polar orbit of the dwarf and its interaction with the Milky Way tears it apart. Similarly, with the discovery of the Canis Major Dwarf Galaxy, it was found that a ring of galactic debris from its interaction with the Milky Way encircles the Galactic disk.\\r\\nThe Sloan Digital Sky Survey of the northern sky shows a huge and diffuse structure (spread out across an area around 5,000 times the size of a full moon) within the Milky Way that does not seem to fit within current models. The collection of stars rises close to perpendicular to the plane of the spiral arms of the Milky Way. The proposed likely interpretation is that a dwarf galaxy is merging with the Milky Way. This galaxy is tentatively named the Virgo Stellar Stream and is found in the direction of Virgo about 30,000 light-years (9?kpc) away.[139]\\r\\nIn addition to the stellar halo, the Chandra X-ray Observatory, XMM-Newton, and Suzaku have provided evidence that there is a gaseous halo with a large amount of hot gas. The halo extends for hundreds of thousand of light years, much further than the stellar halo and close to the distance of the Large and Small Magellanic Clouds. The mass of this hot halo is nearly equivalent to the mass of the Milky Way itself.[140][141][142] The temperature of this halo gas is between 1 and 2.5?million?K (1.8 and 4.5?million?oF).[143]\\r\\nObservations of distant galaxies indicate that the Universe had about one-sixth as much baryonic (ordinary) matter as dark matter when it was just a few billion years old. However, only about half of those baryons are accounted for in the modern Universe based on observations of nearby galaxies like the Milky Way.[144] If the finding that the mass of the halo is comparable to the mass of the Milky Way is confirmed, it could be the identity of the missing baryons around the Milky Way.[144]\\r\\nThe Sun is near the inner rim of the Orion Arm, within the Local Fluff of the Local Bubble, and in the Gould Belt, at a distance of 26.4?I?1.0?kly (8.09?I?0.31?kpc)[15][16][17] from the Galactic Center. The Sun is currently 5ÿ30 parsecs (16ÿ98?ly) from the central plane of the Galactic disk.[145] The distance between the local arm and the next arm out, the Perseus Arm, is about 2,000 parsecs (6,500?ly).[146] The Sun, and thus the Solar System, is located in the Milky Way's galactic habitable zone.\\r\\nThere are about 208 stars brighter than absolute magnitude 8.5 within a sphere with a radius of 15 parsecs (49?ly) from the Sun, giving a density of one star per 69 cubic parsecs, or one star per 2,360 cubic light-years (from List of nearest bright stars). On the other hand, there are 64 known stars (of any magnitude, not counting 4 brown dwarfs) within 5 parsecs (16?ly) of the Sun, giving a density of about one star per 8.2 cubic parsecs, or one per 284 cubic light-years (from List of nearest stars). This illustrates the fact that there are far more faint stars than bright stars: in the entire sky, there are about 500 stars brighter than apparent magnitude 4 but 15.5 million stars brighter than apparent magnitude 14.[147]\\r\\nThe apex of the Sun's way, or the solar apex, is the direction that the Sun travels through space in the Milky Way. The general direction of the Sun's Galactic motion is towards the star Vega near the constellation of Hercules, at an angle of roughly 60 sky degrees to the direction of the Galactic Center. The Sun's orbit about the Milky Way is expected to be roughly elliptical with the addition of perturbations due to the Galactic spiral arms and non-uniform mass distributions. In addition, the Sun passes through the Galactic plane approximately 2.7 times per orbit.[148] This is very similar to how a simple harmonic oscillator works with no drag force (damping) term. These oscillations were until recently thought to coincide with mass lifeform extinction periods on Earth.[149] However, a reanalysis of the effects of the Sun's transit through the spiral structure based on CO data has failed to find a correlation.[150]\\r\\nIt takes the Solar System about 240 million years to complete one orbit of the Milky Way (a galactic year),[18] so the Sun is thought to have completed 18ÿ20 orbits during its lifetime and 1/1250 of a revolution since the origin of humans. The orbital speed of the Solar System about the center of the Milky Way is approximately 220?km/s (490,000?mph) or 0.073% of the speed of light. The Sun moves through the heliosphere at 84,000?km/h (52,000?mph). At this speed, it takes around 1,400 years for the Solar System to travel a distance of 1 light-year, or 8 days to travel 1 AU (astronomical unit).[151] The Solar System is headed in the direction of the zodiacal constellation Scorpius, which follows the ecliptic.[152]\\r\\nThe stars and gas in the Milky Way rotate about its center differentially, meaning that the rotation period varies with location. As is typical for spiral galaxies, the orbital speed of most stars in the Milky Way does not depend strongly on their distance from the center. Away from the central bulge or outer rim, the typical stellar orbital speed is between 210?I?10?km/s (470,000?I?22,000?mph).[1] Hence the orbital period of the typical star is directly proportional only to the length of the path traveled. This is unlike the situation within the Solar System, where two-body gravitational dynamics dominate, and different orbits have significantly different velocities associated with them. The rotation curve (shown in the figure) describes this rotation. Toward the center of the Milky Way the orbit speeds are too low, whereas beyond 7 kpcs the speeds are too high to match what would be expected from the universal law of gravitation.\\r\\nIf the Milky Way contained only the mass observed in stars, gas, and other baryonic (ordinary) matter, the rotation speed would decrease with distance from the center. However, the observed curve is relatively flat, indicating that there is additional mass that cannot be detected directly with electromagnetic radiation. This inconsistency is attributed to dark matter.[32] The rotation curve of the Milky Way agrees with the universal rotation curve of spiral galaxies, the best evidence for the existence of dark matter in galaxies. Alternatively, a minority of astronomers propose that a modification of the law of gravity may explain the observed rotation curve.[155]\\r\\nThe Milky Way began as one or several small overdensities in the mass distribution in the Universe shortly after the Big Bang.[156] Some of these overdensities were the seeds of globular clusters in which the oldest remaining stars in what is now the Milky Way formed. Nearly half the matter in the Milky Way may have come from other distant galaxies.[156] Nonetheless, these stars and clusters now comprise the stellar halo of the Milky Way. Within a few billion years of the birth of the first stars, the mass of the Milky Way was large enough so that it was spinning relatively quickly. Due to conservation of angular momentum, this led the gaseous interstellar medium to collapse from a roughly spheroidal shape to a disk. Therefore, later generations of stars formed in this spiral disk. Most younger stars, including the Sun, are observed to be in the disk.[157][158]\\r\\nSince the first stars began to form, the Milky Way has grown through both galaxy mergers (particularly early in the Milky Way's growth) and accretion of gas directly from the Galactic halo.[158] The Milky Way is currently accreting material from two of its nearest satellite galaxies, the Large and Small Magellanic Clouds, through the Magellanic Stream. Direct accretion of gas is observed in high-velocity clouds like the Smith Cloud.[159][160] However, properties of the Milky Way such as stellar mass, angular momentum, and metallicity in its outermost regions suggest it has undergone no mergers with large galaxies in the last 10 billion years. This lack of recent major mergers is unusual among similar spiral galaxies; its neighbour the Andromeda Galaxy appears to have a more typical history shaped by more recent mergers with relatively large galaxies.[161][162]\\r\\nAccording to recent studies, the Milky Way as well as the Andromeda Galaxy lie in what in the galaxy colorÿmagnitude diagram is known as the \\"green valley\\", a region populated by galaxies in transition from the \\"blue cloud\\" (galaxies actively forming new stars) to the \\"red sequence\\" (galaxies that lack star formation). Star-formation activity in green valley galaxies is slowing as they run out of star-forming gas in the interstellar medium. In simulated galaxies with similar properties, star formation will typically have been extinguished within about five billion years from now, even accounting for the expected, short-term increase in the rate of star formation due to the collision between both the Milky Way and the Andromeda Galaxy.[163] In fact, measurements of other galaxies similar to the Milky Way suggest it is among the reddest and brightest spiral galaxies that are still forming new stars and it is just slightly bluer than the bluest red sequence galaxies.[164]\\r\\nGlobular clusters are among the oldest objects in the Milky Way, which thus set a lower limit on the age of the Milky Way. The ages of individual stars in the Milky Way can be estimated by measuring the abundance of long-lived radioactive elements such as thorium-232 and uranium-238, then comparing the results to estimates of their original abundance, a technique called nucleocosmochronology. These yield values of about 12.5 I 3 billion years for CS 31082-001[166] and 13.8 I 4 billion years for BD +17 3248.[167] Once a white dwarf is formed, it begins to undergo radiative cooling and the surface temperature steadily drops. By measuring the temperatures of the coolest of these white dwarfs and comparing them to their expected initial temperature, an age estimate can be made. With this technique, the age of the globular cluster M4 was estimated as 12.7 I 0.7 billion years. Age estimates of the oldest of these clusters gives a best fit estimate of 12.6?billion years, and a 95% confidence upper limit of 16?billion years.[168]\\r\\nSeveral individual stars have been found in the Milky Way's halo with measured ages very close to the 13.80-billion-year age of the Universe. In 2007, a star in the galactic halo, HE 1523-0901, was estimated to be about 13.2 billion years old. As the oldest known object in the Milky Way at that time, this measurement placed a lower limit on the age of the Milky Way.[169] This estimate was made using the UV-Visual Echelle Spectrograph of the Very Large Telescope to measure the relative strengths of spectral lines caused by the presence of thorium and other elements created by the R-process. The line strengths yield abundances of different elemental isotopes, from which an estimate of the age of the star can be derived using nucleocosmochronology.[169] Another star, HD 140283, is 14.5 I 0.7 billion years old.[9][170]\\r\\nThe age of stars in the galactic thin disk has also been estimated using nucleocosmochronology. Measurements of thin disk stars yield an estimate that the thin disk formed 8.8 I 1.7 billion years ago. These measurements suggest there was a hiatus of almost 5 billion years between the formation of the galactic halo and the thin disk.[171] Recent analysis of the chemical signatures of thousands of stars suggests that stellar formation might have dropped by an order of magnitude at the time of disk formation, 10 to 8 billion years ago, when interstellar gas was too hot to form new stars at the same rate as before.[172]\\r\\nThe satellite galaxies surrounding the Milky way are not randomly distributed, but seemed to be the result of a break-up of some larger system producing a ring structure 500,000 light years in diameter and 50,000 light years wide.[173] Close encounters between galaxies, like that expected in 4 billion years with the Andromeda Galaxy rips off huge tails of gas, which, over time can coalesce to form dwarf galaxies in a ring at right angles to the main disc.[174]\\r\\nThe Milky Way and the Andromeda Galaxy are a binary system of giant spiral galaxies belonging to a group of 50 closely bound galaxies known as the Local Group, surrounded by a Local Void, itself being part of the Virgo Supercluster. Surrounding the Virgo Supercluster are a number of voids, devoid of many galaxies, the Microscopium Void to the \\"north\\", the Sculptor Void to the \\"left\\", the Bootes Void to the \\"right\\" and the Canes-Major Void to the South. These voids change shape over time, creating filamentous structures of galaxies. The Virgo Supercluster, for instance, is being drawn towards the Great Attractor,[175] which in turn forms part of a greater structure, called Laniakea.[176]\\r\\nTwo smaller galaxies and a number of dwarf galaxies in the Local Group orbit the Milky Way. The largest of these is the Large Magellanic Cloud with a diameter of 14,000 light-years. It has a close companion, the Small Magellanic Cloud. The Magellanic Stream is a stream of neutral hydrogen gas extending from these two small galaxies across 100 of the sky. The stream is thought to have been dragged from the Magellanic Clouds in tidal interactions with the Milky Way.[177] Some of the dwarf galaxies orbiting the Milky Way are Canis Major Dwarf (the closest), Sagittarius Dwarf Elliptical Galaxy, Ursa Minor Dwarf, Sculptor Dwarf, Sextans Dwarf, Fornax Dwarf, and Leo I Dwarf. The smallest dwarf galaxies of the Milky Way are only 500 light-years in diameter. These include Carina Dwarf, Draco Dwarf, and Leo II Dwarf. There may still be undetected dwarf galaxies that are dynamically bound to the Milky Way, which is supported by the detection of nine new satellites of the Milky Way in a relatively small patch of the night sky in 2015.[178] There are also some dwarf galaxies that have already been absorbed by the Milky Way, such as Omega Centauri.[179]\\r\\nIn 2014 researchers reported that most satellite galaxies of the Milky Way actually lie in a very large disk and orbit in the same direction.[180] This came as a surprise: according to standard cosmology, the satellite galaxies should form in dark matter halos, and they should be widely distributed and moving in random directions. This discrepancy is still not fully explained.[181]\\r\\nIn January 2006, researchers reported that the heretofore unexplained warp in the disk of the Milky Way has now been mapped and found to be a ripple or vibration set up by the Large and Small Magellanic Clouds as they orbit the Milky Way, causing vibrations when they pass through its edges. Previously, these two galaxies, at around 2% of the mass of the Milky Way, were considered too small to influence the Milky Way. However, in a computer model, the movement of these two galaxies creates a dark matter wake that amplifies their influence on the larger Milky Way.[182]\\r\\nCurrent measurements suggest the Andromeda Galaxy is approaching us at 100 to 140?km/s (220,000 to 310,000?mph). In 3 to 4 billion years, there may be an AndromedaÿMilky Way collision, depending on the importance of unknown lateral components to the galaxies' relative motion. If they collide, the chance of individual stars colliding with each other is extremely low, but instead the two galaxies will merge to form a single elliptical galaxy or perhaps a large disk galaxy[183] over the course of about a billion years.[184]\\r\\nAlthough special relativity states that there is no \\"preferred\\" inertial frame of reference in space with which to compare the Milky Way, the Milky Way does have a velocity with respect to cosmological frames of reference.\\r\\nOne such frame of reference is the Hubble flow, the apparent motions of galaxy clusters due to the expansion of space. Individual galaxies, including the Milky Way, have peculiar velocities relative to the average flow. Thus, to compare the Milky Way to the Hubble flow, one must consider a volume large enough so that the expansion of the Universe dominates over local, random motions. A large enough volume means that the mean motion of galaxies within this volume is equal to the Hubble flow. Astronomers believe the Milky Way is moving at approximately 630?km/s (1,400,000?mph) with respect to this local co-moving frame of reference.[185] The Milky Way is moving in the general direction of the Great Attractor and other galaxy clusters, including the Shapley supercluster, behind it.[186] The Local Group (a cluster of gravitationally bound galaxies containing, among others, the Milky Way and the Andromeda Galaxy) is part of a supercluster called the Local Supercluster, centered near the Virgo Cluster: although they are moving away from each other at 967?km/s (2,160,000?mph) as part of the Hubble flow, this velocity is less than would be expected given the 16.8?million pc distance due to the gravitational attraction between the Local Group and the Virgo Cluster.[187]\\r\\nAnother reference frame is provided by the cosmic microwave background (CMB). The Milky Way is moving at 552?I?6?km/s (1,235,000?I?13,000?mph)[188] with respect to the photons of the CMB, toward 10.5 right ascension, ?24 declination (J2000 epoch, near the center of Hydra). This motion is observed by satellites such as the Cosmic Background Explorer (COBE) and the Wilkinson Microwave Anisotropy Probe (WMAP) as a dipole contribution to the CMB, as photons in equilibrium in the CMB frame get blue-shifted in the direction of the motion and red-shifted in the opposite direction.[188]\\r\\nIn the Babylonian epic poem En?ma Eli?, the Milky Way is created from the severed tail of the primeval salt water dragoness Tiamat, set in the sky by Marduk, the Babylonian national god, after slaying her.[189][190] This story was once thought to have been based on an older Sumerian version in which Tiamat is instead slain by Enlil of Nippur,[191][192] but is now thought to be purely an invention of Babylonian propagandists with the intention to show Marduk as superior to the Sumerian deities.[192]\\r\\nLlys D?n (literally \\"The Court of D?n\\") is the traditional Welsh name for the constellation Cassiopeia. At least three of D?n's children also have astronomical associations: Caer Gwydion (\\"The fortress of Gwydion\\") is the traditional Welsh name for the Milky Way, and Caer Arianrhod (\\"The Fortress of Arianrhod\\") being the constellation of Corona Borealis.\\r\\nIn western culture, the name \\"Milky Way\\" is derived from its appearance as a dim un-resolved \\"milky\\" glowing band arching across the night sky. The term is a translation of the Classical Latin via lactea, in turn derived from the Hellenistic Greek ϫϫ?ϫ?, short for ϫϫ?ϫ? ?? (galaxas kyklos, \\"milky circle\\"). The Ancient Greek ϫϫ?ϫ? (galaxias) ÿ from root ϫϫٶ-, ?ϫ (\\"milk\\") + -?ϫ? (forming adjectives) ÿ is also the root of \\"galaxy\\", the name for our, and later all such, collections of stars.[21][193][194][195]\\r\\nIn Greek mythology, the Milky Way was formed after the trickster god Hermes suckled the infant Heracles at the breast of Hera, the queen of the gods, while she was asleep.[196][197] When Hera awoke, she tore Heracles away from her breast and splattered her breast milk across the heavens.[196][197] In another version of the story, Athena, the patron goddess of heroes, tricked Hera into suckling Heracles voluntarily,[196][197] but he bit her nipple so hard that she flung him away, spraying milk everywhere.[196][197]\\r\\nThe Milky Way, or \\"milk circle\\", was just one of 11 \\"circles\\" the Greeks identified in the sky, others being the zodiac, the meridian, the horizon, the equator, the tropics of Cancer and Capricorn, Arctic and Antarctic circles, and two colure circles passing through both poles.[198]\\r\\nIn Meteorologica (DK 59 A80), Aristotle (384ÿ322 BC) wrote that the Greek philosophers Anaxagoras (c.?500ÿ428 BC) and Democritus (460ÿ370 BC) proposed that the Milky Way might consist of distant stars.[199] However, Aristotle himself believed the Milky Way to be caused by \\"the ignition of the fiery exhalation of some stars which were large, numerous and close together\\"[200] and that the \\"ignition takes place in the upper part of the atmosphere, in the region of the world which is continuous with the heavenly motions.\\"[201][202] The Neoplatonist philosopher Olympiodorus the Younger (c.?495ÿ570 A.D.) criticized this view, arguing that if the Milky Way were sublunary, it should appear different at different times and places on Earth, and that it should have parallax, which it does not. In his view, the Milky Way is celestial. This idea would be influential later in the Islamic world.[203]\\r\\nThe Persian astronomer Ab Rayhn al-Bؐrnؐ (973ÿ1048) proposed that the Milky Way is \\"a collection of countless fragments of the nature of nebulous stars\\".[204] The Andalusian astronomer Avempace (d 1138) proposed the Milky Way to be made up of many stars but appears to be a continuous image due to the effect of refraction in Earth's atmosphere, citing his observation of a conjunction of Jupiter and Mars in 1106 or 1107 as evidence.[202] Ibn Qayyim Al-Jawziyya (1292ÿ1350) proposed that the Milky Way is \\"a myriad of tiny stars packed together in the sphere of the fixed stars\\" and that these stars are larger than planets.[205]\\r\\nAccording to Jamil Ragep, the Persian astronomer Na?ؐr al-Dؐn al-?sؐ (1201ÿ1274) in his Tadhkira writes: \\"The Milky Way, i.e. the Galaxy, is made up of a very large number of small, tightly clustered stars, which, on account of their concentration and smallness, seem to be cloudy patches. Because of this, it was likened to milk in color.\\"[206]\\r\\nActual proof of the Milky Way consisting of many stars came in 1610 when Galileo Galilei used a telescope to study the Milky Way and discovered that it is composed of a huge number of faint stars.[207][208] In a treatise in 1755, Immanuel Kant, drawing on earlier work by Thomas Wright,[209] speculated (correctly) that the Milky Way might be a rotating body of a huge number of stars, held together by gravitational forces akin to the Solar System but on much larger scales.[210] The resulting disk of stars would be seen as a band on the sky from our perspective inside the disk. Kant also conjectured that some of the nebulae visible in the night sky might be separate \\"galaxies\\" themselves, similar to our own. Kant referred to both the Milky Way and the \\"extragalactic nebulae\\" as \\"island universes\\", a term still current up to the 1930s.[211][212][213]\\r\\nThe first attempt to describe the shape of the Milky Way and the position of the Sun within it was carried out by William Herschel in 1785 by carefully counting the number of stars in different regions of the visible sky. He produced a diagram of the shape of the Milky Way with the Solar System close to the center.[214]\\r\\nIn 1845, Lord Rosse constructed a new telescope and was able to distinguish between elliptical and spiral-shaped nebulae. He also managed to make out individual point sources in some of these nebulae, lending credence to Kant's earlier conjecture.[215]\\r\\nIn 1917, Heber Curtis had observed the nova S Andromedae within the Great Andromeda Nebula (Messier object 31). Searching the photographic record, he found 11 more novae. Curtis noticed that these novae were, on average, 10 magnitudes fainter than those that occurred within the Milky Way. As a result, he was able to come up with a distance estimate of 150,000 parsecs. He became a proponent of the \\"island universes\\" hypothesis, which held that the spiral nebulae were actually independent galaxies.[216] In 1920 the Great Debate took place between Harlow Shapley and Heber Curtis, concerning the nature of the Milky Way, spiral nebulae, and the dimensions of the Universe. To support his claim that the Great Andromeda Nebula is an external galaxy, Curtis noted the appearance of dark lanes resembling the dust clouds in the Milky Way, as well as the significant Doppler shift.[217]\\r\\nThe controversy was conclusively settled by Edwin Hubble in the early 1920s using the Mount Wilson observatory 2.5?m (100?in) Hooker telescope. With the light-gathering power of this new telescope, he was able to produce astronomical photographs that resolved the outer parts of some spiral nebulae as collections of individual stars. He was also able to identify some Cepheid variables that he could use as a benchmark to estimate the distance to the nebulae. He found that the Andromeda Nebula is 275,000 parsecs from the Sun, far too distant to be part of the Milky Way.[218][219]\\r\\nThe ESA spacecraft Gaia provides distance estimates by determining the parallax of a billion stars and is mapping the Milky Way with four planned releases of maps in 2022.[220][221]\\r\\nCite error: A list-defined reference named \\"ssr120_315\\" is not used in the content (see the help page).","input":"How many stars are estimated to be in the milky way galaxy?"},{"output":"emissions of sulfur dioxide and nitrogen oxide","context":"Acid rain is a rain or any other form of precipitation that is unusually acidic, meaning that it has elevated levels of hydrogen ions (low pH). It can have harmful effects on plants, aquatic animals and infrastructure. Acid rain is caused by emissions of sulfur dioxide and nitrogen oxide, which react with the water molecules in the atmosphere to produce acids. Some governments have made efforts since the 1970s to reduce the release of sulfur dioxide and nitrogen oxide into the atmosphere with positive results. Nitrogen oxides can also be produced naturally by lightning strikes, and sulfur dioxide is produced by volcanic eruptions. Acid rain has been shown to have adverse impacts on forests, freshwaters and soils, killing insect and aquatic life-forms, causing paint to peel, corrosion of steel structures such as bridges, and weathering of stone buildings and statues as well as having impacts on human health.\\r\\n\\r\\n\\r\\n\\"Acid rain\\" is a popular term referring to the deposition of a mixture from wet (rain, snow, sleet, fog, cloudwater, and dew) and dry (acidifying particles and gases) acidic components. Distilled water, once carbon dioxide is removed, has a neutral pH of 7. Liquids with a pH less than 7 are acidic, and those with a pH greater than 7 are alkaline. \\"Clean\\" or unpolluted rain has an acidic pH, but usually no lower than 5.7, because carbon dioxide and water in the air react together to form carbonic acid, a weak acid according to the following reaction:\\r\\nCarbonic acid then can ionize in water forming low concentrations of hydronium and carbonate ions:\\r\\nHowever, unpolluted rain can also contain other chemicals which affect its pH (acidity level). A common example is nitric acid produced by electric discharge in the atmosphere such as lightning.[1] Acid deposition as an environmental issue (discussed later in the article) would include additional acids other than H2CO3.\\r\\nThe corrosive effect of polluted, acidic city air on limestone and marble was noted in the 17th century by John Evelyn, who remarked upon the poor condition of the Arundel marbles.[2] Since the Industrial Revolution, emissions of sulfur dioxide and nitrogen oxides into the atmosphere have increased.[3][4] In 1852, Robert Angus Smith was the first to show the relationship between acid rain and atmospheric pollution in Manchester, England.[5]\\r\\nThough acidic rain was discovered in 1853, it was not until the late 1960s that scientists began widely observing and studying the phenomenon.[6] The term \\"acid rain\\" was coined in 1872 by Robert Angus Smith.[7] Canadian Harold Harvey was among the first to research a \\"dead\\" lake. At first the main focus in research lay on local affects of acid rain. Waldemar Christofer Br?gger was the first to acknowledge long-distance transportation of pollutants crossing boarders from the United Kingdom to Norway[8]. Public awareness of acid rain in the U.S increased in the 1970s after The New York Times published reports from the Hubbard Brook Experimental Forest in New Hampshire of the myriad deleterious environmental effects shown to result from it.[9][10]\\r\\nOccasional pH readings in rain and fog water of well below 2.4 have been reported in industrialized areas.[3] Industrial acid rain is a substantial problem in China and Russia[11][12] and areas downwind from them. These areas all burn sulfur-containing coal to generate heat and electricity.[13]\\r\\nThe problem of acid rain has not only increased with population and industrial growth, but has become more widespread. The use of tall smokestacks to reduce local pollution has contributed to the spread of acid rain by releasing gases into regional atmospheric circulation.[14][15] Often deposition occurs a considerable distance downwind of the emissions, with mountainous regions tending to receive the greatest deposition (simply because of their higher rainfall). An example of this effect is the low pH of rain which falls in Scandinavia.\\r\\nThe earliest report about acid rain in the United States was from the chemical evidence from Hubbard Brook Valley. In 1972, a group of scientists including Gene Likens discovered the rain that was deposited at White Mountains of New Hampshire was acidic. The pH of the sample was measured to be 4.03 at Hubbard Brook.[17] The Hubbard Brook Ecosystem Study followed up with a series of research that analyzed the environmental effects of acid rain. Acid rain that mixed with stream water at Hubbard Brook was neutralized by the alumina from soils.[18] The result of this research indicates the chemical reaction between acid rain and aluminum leads to increasing rate of soil weathering. Experimental research was done to examine the effects of increased acidity in stream on ecological species. In 1980, a group of scientists modified the acidity of Norris Brook, New Hampshire, and observed the change in species behaviors. There was a decrease in species diversity, an increase in community dominants, and a decrease in the food web complexity.[19]\\r\\nIn 1980, the U.S. Congress passed an Acid Deposition Act.[20] This Act established an 18-year assessment and research program under the direction of the National Acidic Precipitation Assessment Program (NAPAP). NAPAP looked at the entire problem from a scientific perspective. It enlarged a network of monitoring sites to determine how acidic the precipitation actually was, and to determine long-term trends, and established a network for dry deposition. It looked at the effects of acid rain and funded research on the effects of acid precipitation on freshwater and terrestrial ecosystems, historical buildings, monuments, and building materials. It also funded extensive studies on atmospheric processes and potential control programs.\\r\\nFrom the start, policy advocates from all sides attempted to influence NAPAP activities to support their particular policy advocacy efforts, or to disparage those of their opponents.[20] For the U.S. Government's scientific enterprise, a significant impact of NAPAP were lessons learned in the assessment process and in environmental research management to a relatively large group of scientists, program managers and the public.[21]\\r\\nIn 1981, the National Academy of Sciences was looking into research about the controversial issues regarding acid rain.[22] President Ronald Reagan did not place a huge attention on the issues of acid rain[23] until his personal visit to Canada and confirmed that Canadian border suffered from the drifting pollution from smokestacks in Midwest of US. Reagan honored the agreement to Canadian Prime Minister Pierre Trudeaus enforcement of anti-pollution regulation.[24] In 1982, US President Ronald Reagan commissioned William Nierenberg to serve on the National Science Board.[25] Nierenberg selected scientists including Gene Likens to serve on a panel to draft a report on acid rain. In 1983, the panel of scientists came up with a draft report, which concluded that acid rain is a real problem and solutions should be sought.[26] White House Office of Science and Technology Policy reviewed the draft report and sent Fred Singers suggestions of the report, which cast doubt on the cause of acid rain.[27] The panelists revealed rejections against Singers positions and submitted the report to Nierenberg in April. In May 1983, the House of Representatives voted against legislations that aimed to control sulfur emissions. There was a debate about whether Nierenberg delayed to release the report. Nierenberg himself denied the saying about his suppression of the report and explained that the withheld of the report after the House's vote was due to the fact that the report was not ready to be published.[28]\\r\\nIn 1991, the US National Acid Precipitation Assessment Program (NAPAP) provided its first assessment of acid rain in the United States.[29] It reported that 5% of New England Lakes were acidic, with sulfates being the most common problem. They noted that 2% of the lakes could no longer support Brook Trout, and 6% of the lakes were unsuitable for the survival of many species of minnow. Subsequent Reports to Congress have documented chemical changes in soil and freshwater ecosystems, nitrogen saturation, decreases in amounts of nutrients in soil, episodic acidification, regional haze, and damage to historical monuments.\\r\\nMeanwhile, in 1990, the U.S. Congress passed a series of amendments to the Clean Air Act.[30] Title IV of these amendments established the a cap and trade system designed to control emissions of sulfur dioxide and nitrogen oxides. Title IV called for a total reduction of about 10 million tons of SO2 emissions from power plants. It was implemented in two phases. Phase I began in 1995, and limited sulfur dioxide emissions from 110 of the largest power plants to a combined total of 8.7 million tons of sulfur dioxide. One power plant in New England (Merrimack) was in Phase I. Four other plants (Newington, Mount Tom, Brayton Point, and Salem Harbor) were added under other provisions of the program. Phase II began in 2000, and affects most of the power plants in the country.\\r\\nDuring the 1990s, research continued. On March 10, 2005, the EPA issued the Clean Air Interstate Rule (CAIR). This rule provides states with a solution to the problem of power plant pollution that drifts from one state to another. CAIR will permanently cap emissions of SO2 and NOx in the eastern United States. When fully implemented, CAIR will reduce SO2 emissions in 28 eastern states and the District of Columbia by over 70% and NOx emissions by over 60% from 2003 levels.[31]\\r\\nOverall, the program's cap and trade program has been successful in achieving its goals. Since the 1990s, SO2 emissions have dropped 40%, and according to the Pacific Research Institute, acid rain levels have dropped 65% since 1976.[32][33] Conventional regulation was used in the European Union, which saw a decrease of over 70% in SO2 emissions during the same time period.[34]\\r\\nIn 2007, total SO2 emissions were 8.9 million tons, achieving the program's long-term goal ahead of the 2010 statutory deadline.[35]\\r\\nIn 2007 the EPA estimated that by 2010, the overall costs of complying with the program for businesses and consumers would be $1 billion to $2 billion a year, only one fourth of what was originally predicted.[32] Forbes says: In 2010, by which time the cap and trade system had been augmented by the George W. Bush administrations Clean Air Interstate Rule, SO2 emissions had fallen to 5.1 million tons. [36]\\r\\nThe term Citizen science can be traced back as far as January 1989 and a campaign by the Audubon Society to measure Acid rain. Scientist Muki Haklay cites in a policy report for the Wilson Center entitled 'Citizen Science and Policy: A European Perspective' a first use of the term 'citizen science' by R. Kerson in the magazine MIT Technology Review from January 1989.[37][38] Quoting from the Wilson Center report: \\"The new form of engagement in science received the name \\"citizen science\\". The first recorded example of the use of the term is from 1989, describing how 225 volunteers across the US collected rain samples to assist the Audubon Society in an acid-rain awareness raising campaign. The volunteers collected samples, checked for acidity, and reported back to the organization. The information was then used to demonstrate the full extent of the phenomenon.\\"[37][38]\\r\\nThe most important gas which leads to acidification is sulfur dioxide. Emissions of nitrogen oxides which are oxidized to form nitric acid are of increasing importance due to stricter controls on emissions of sulfur containing compounds. 70 Tg(S) per year in the form of SO2 comes from fossil fuel combustion and industry, 2.8 Tg(S) from wildfires and 7ÿ8 Tg(S) per year from volcanoes.[39]\\r\\nThe principal natural phenomena that contribute acid-producing gases to the atmosphere are emissions from volcanoes. Thus, for example, fumaroles from the Laguna Caliente crater of Pos Volcano create extremely high amounts of acid rain and fog, with acidity as high as a pH of 2, clearing an area of any vegetation and frequently causing irritation to the eyes and lungs of inhabitants in nearby settlements. Acid-producing gasses are also created by biological processes that occur on the land, in wetlands, and in the oceans. The major biological source of sulfur containing compounds is dimethyl sulfide.\\r\\nNitric acid in rainwater is an important source of fixed nitrogen for plant life, and is also produced by electrical activity in the atmosphere such as lightning.[40]\\r\\nAcidic deposits have been detected in glacial ice thousands of years old in remote parts of the globe.[14]\\r\\nSoils of coniferous forests are naturally very acidic due to the shedding of needles, and the results of this phenomenon should not be confused with acid rain.\\r\\nThe principal cause of acid rain is sulfur and nitrogen compounds from human sources, such as electricity generation, factories, and motor vehicles. Electrical power generation using coal is among the greatest contributors to gaseous pollutions that are responsible for acidic rain. The gases can be carried hundreds of kilometers in the atmosphere before they are converted to acids and deposited. In the past, factories had short funnels to let out smoke but this caused many problems locally; thus, factories now have taller smoke funnels. However, dispersal from these taller stacks causes pollutants to be carried farther, causing widespread ecological damage.\\r\\nCombustion of fuels produces sulfur dioxide and nitric oxides. They are converted into sulfuric acid and nitric acid.[41]\\r\\nIn the gas phase sulfur dioxide is oxidized by reaction with the hydroxyl radical via an intermolecular reaction:[5]\\r\\nwhich is followed by:\\r\\nIn the presence of water, sulfur trioxide (SO3) is converted rapidly to sulfuric acid:\\r\\nNitrogen dioxide reacts with OH to form nitric acid:\\r\\nWhen clouds are present, the loss rate of SO2 is faster than can be explained by gas phase chemistry alone. This is due to reactions in the liquid water droplets.\\r\\nSulfur dioxide dissolves in water and then, like carbon dioxide, hydrolyses in a series of equilibrium reactions:\\r\\nThere are a large number of aqueous reactions that oxidize sulfur from S(IV) to S(VI), leading to the formation of sulfuric acid. The most important oxidation reactions are with ozone, hydrogen peroxide and oxygen (reactions with oxygen are catalyzed by iron and manganese in the cloud droplets).[5]\\r\\nWet deposition of acids occurs when any form of precipitation (rain, snow, and so on.) removes acids from the atmosphere and delivers it to the Earth's surface. This can result from the deposition of acids produced in the raindrops (see aqueous phase chemistry above) or by the precipitation removing the acids either in clouds or below clouds. Wet removal of both gases and aerosols are both of importance for wet deposition.\\r\\nAcid deposition also occurs via dry deposition in the absence of precipitation. This can be responsible for as much as 20 to 60% of total acid deposition.[42] This occurs when particles and gases stick to the ground, plants or other surfaces.\\r\\nAcid rain has been shown to have adverse impacts on forests, freshwaters and soils, killing insect and aquatic life-forms as well as causing damage to buildings and having impacts on human health.\\r\\nBoth the lower pH and higher aluminium concentrations in surface water that occur as a result of acid rain can cause damage to fish and other aquatic animals. At pHs lower than 5 most fish eggs will not hatch and lower pHs can kill adult fish. As lakes and rivers become more acidic biodiversity is reduced. Acid rain has eliminated insect life and some fish species, including the brook trout in some lakes, streams, and creeks in geographically sensitive areas, such as the Adirondack Mountains of the United States.[43] However, the extent to which acid rain contributes directly or indirectly via runoff from the catchment to lake and river acidity (i.e., depending on characteristics of the surrounding watershed) is variable. The United States Environmental Protection Agency's (EPA) website states: \\"Of the lakes and streams surveyed, acid rain caused acidity in 75% of the acidic lakes and about 50% of the acidic streams\\".[43] Lakes hosted by silicate basement rocks are more acidic than lakes within limestone or other basement rocks with a carbonate composition (i.e. marble) due to buffering effects by carbonate minerals, even with the same amount of acid rain.[44][citation needed]\\r\\nSoil biology and chemistry can be seriously damaged by acid rain. Some microbes are unable to tolerate changes to low pH and are killed.[45] The enzymes of these microbes are denatured (changed in shape so they no longer function) by the acid. The hydronium ions of acid rain also mobilize toxins such as aluminium, and leach away essential nutrients and minerals such as magnesium.[46]\\r\\nSoil chemistry can be dramatically changed when base cations, such as calcium and magnesium, are leached by acid rain thereby affecting sensitive species, such as sugar maple (Acer saccharum).[47][48]\\r\\nAdverse effects may be indirectly related to acid rain, like the acid's effects on soil (see above) or high concentration of gaseous precursors to acid rain. High altitude forests are especially vulnerable as they are often surrounded by clouds and fog which are more acidic than rain.\\r\\nOther plants can also be damaged by acid rain, but the effect on food crops is minimized by the application of lime and fertilizers to replace lost nutrients. In cultivated areas, limestone may also be added to increase the ability of the soil to keep the pH stable, but this tactic is largely unusable in the case of wilderness lands. When calcium is leached from the needles of red spruce, these trees become less cold tolerant and exhibit winter injury and even death.[49][50]\\r\\nAcid rain has a much less harmful effect on the oceans. However, acid rain can cause the oceans acidity to rise, making it more difficult for different coastal species to create their exoskeletons that they need to survive. These coastal species link together as part of the ocean's food chain and without them being a source for other marine life to feed off of more marine life will die.[51]\\r\\nCoral's limestone skeletal is sensitive to pH drop, because the calcium carbonate, core component of the limestone dissolves in acidic (low pH) solutions.\\r\\nAcid rain does not directly affect human health. The acid in the rainwater is too dilute to have direct adverse effects. However, the particulates responsible for acid rain (sulfur dioxide and nitrogen oxides) do have an adverse effect. Increased amounts of fine particulate matter in the air do contribute to heart and lung problems including asthma and bronchitis.[52]\\r\\nAcid rain can damage buildings, historic monuments, and statues, especially those made of rocks, such as limestone and marble, that contain large amounts of calcium carbonate. Acids in the rain react with the calcium compounds in the stones to create gypsum, which then flakes off.\\r\\nThe effects of this are commonly seen on old gravestones, where acid rain can cause the inscriptions to become completely illegible. Acid rain also increases the corrosion rate of metals, in particular iron, steel, copper and bronze.[53][54]\\r\\nPlaces significantly impacted by acid rain around the globe include most of eastern Europe from Poland northward into Scandinavia,[55] the eastern third of the United States,[56] and southeastern Canada. Other affected areas include the southeastern coast of China and Taiwan.[57]\\r\\nMany coal-firing power stations use flue-gas desulfurization (FGD) to remove sulfur-containing gases from their stack gases. For a typical coal-fired power station, FGD will remove 95% or more of the SO2 in the flue gases. An example of FGD is the wet scrubber which is commonly used. A wet scrubber is basically a reaction tower equipped with a fan that extracts hot smoke stack gases from a power plant into the tower. Lime or limestone in slurry form is also injected into the tower to mix with the stack gases and combine with the sulfur dioxide present. The calcium carbonate of the limestone produces pH-neutral calcium sulfate that is physically removed from the scrubber. That is, the scrubber turns sulfur pollution into industrial sulfates.\\r\\nIn some areas the sulfates are sold to chemical companies as gypsum when the purity of calcium sulfate is high. In others, they are placed in landfill. However, the effects of acid rain can last for generations, as the effects of pH level change can stimulate the continued leaching of undesirable chemicals into otherwise pristine water sources, killing off vulnerable insect and fish species and blocking efforts to restore native life.\\r\\nFluidized bed combustion also reduces the amount of sulfur emitted by power production.\\r\\nVehicle emissions control reduces emissions of nitrogen oxides from motor vehicles.\\r\\nA number of international treaties on the long-range transport of atmospheric pollutants have been agreed for example, the 1985 Helsinki Protocol on the Reduction of Sulphur Emissions under the Convention on Long-Range Transboundary Air Pollution. Canada and the US signed the Air Quality Agreement in 1991. Most European countries and Canada have signed the treaties.\\r\\nIn this regulatory scheme, every current polluting facility is given or may purchase on an open market an emissions allowance for each unit of a designated pollutant it emits. Operators can then install pollution control equipment, and sell portions of their emissions allowances they no longer need for their own operations, thereby recovering some of the capital cost of their investment in such equipment. The intention is to give operators economic incentives to install pollution controls.\\r\\nThe first emissions trading market was established in the United States by enactment of the Clean Air Act Amendments of 1990. The overall goal of the Acid Rain Program established by the Act[58] is to achieve significant environmental and public health benefits through reductions in emissions of sulfur dioxide (SO2) and nitrogen oxides (NOx), the primary causes of acid rain. To achieve this goal at the lowest cost to society, the program employs both regulatory and market based approaches for controlling air pollution.","input":"What is the main cause of acid precipitation?"},{"output":"Amanda Barrington","context":"Anne Jeffreys (born Annie Jeffreys Carmichael; January 26, 1923 ÿ September 27, 2017)[1][2][3] was an American actress and singer.\\r\\n\\r\\n\\r\\nBorn Annie Jeffreys Carmichael on January 26, 1923 in Goldsboro, North Carolina,[4] Jeffreys entered the entertainment field at a young age, having her initial training in voice (she was an accomplished soprano). \\"She became a member of the New York Municipal Opera Company on a scholarship and sang the lead at Carnegie Hall in such things as La bohme, Traviata, and Pagliacci.\\"[5] However, she decided as a teenager to sign with the John Robert Powers agency as a junior model.\\r\\nHer plans for an operatic career were sidelined when she was cast in a staged musical review, Fun for the Money. Her appearance in that revue led to her being cast in her first movie role, in I Married an Angel (1942), starring Nelson Eddy and Jeanette MacDonald. She was under contract to both RKO and Republic Studios during the 1940s, including several appearances as Tess Trueheart in the Dick Tracy series, and the 1944 Frank Sinatra musical Step Lively. She also appeared in the horror comedy Zombies on Broadway with Wally Brown and Alan Carney in 1945 and starred in Riffraff with Pat O'Brien two years later. Jeffreys also appeared in a number of western films and as bank robber John Dillinger's moll in 1945's Dillinger\\r\\nWhen her Hollywood career faltered, she instead focused on the stage, playing lead roles on Broadway in productions such as the 1947 opera Street Scene, the 1948 Cole Porter musical Kiss Me, Kate (having replaced Patricia Morison) and the 1952 musical Three Wishes for Jamie.[6] With long-term husband Robert Sterling, she appeared in the CBS sitcom Topper (1953ÿ1955), in which she was billed in a voiceover as \\"the ghostess with the mostest\\".\\r\\nOn December 18, 1957, Jeffreys and her husband played a couple with an unusual courtship arrangement brought about by an attack of the fever in the episode \\"The Julie Gage Story\\", broadcast in the first season of NBC's Wagon Train.[citation needed]\\r\\nAfter a semi-retirement in the 1960s, she appeared on television, appearing in episodes of such series as Love, American Style (with her husband), L.A. Law and Murder, She Wrote. She was nominated for a Golden Globe for her work in The Delphi Bureau (1972). From 1984-85, she starred in the short-lived Aaron Spelling series Finder of Lost Loves.[4] She also appeared in Baywatch as David Hasselhoff's mother, and also had a recurring role in the night-time soap Falcon Crest as Amanda Croft.[citation needed]\\r\\nIn 1979, she guest starred as Siress Blassie in the Battlestar Galactica episode \\"The Man with Nine Lives\\" as a love interest of Chameleon, a part played by Fred Astaire. She was the last person to dance with him onscreen. She also guest starred as Prime Minister Dyne in the Buck Rogers in the 25th Century episode \\"Planet of the Amazon Women\\" as the leader of the titular planet.[citation needed]\\r\\nHer most recent career was in daytime television; From 1984 to 2004, she appeared on the soap opera General Hospital[4] (as well as its short-lived spinoff, Port Charles) in the recurring role of wealthy socialite Amanda Barrington, a long-time board member of both the hospital and ELQ. In her initial storyline, she was part of a blackmail scheme which led to the murder of Jimmy Lee Holt's mother, Beatrice, of whose death she was a suspect in.[7] In the last year of Port Charles, Amanda last appeared on screen in 2004 when Amanda attended Lila Quartermain's funeral.\\r\\nJeffreys' star in the Television category on the Hollywood Walk of Fame is at 1501 Vine Street. It was dedicated February 8, 1960.[8] In 1997, she was a recipient of a Golden Boot Award as one who \\"furthered the tradition of the western on film and in television.\\"[9] In 1998, she received the Living Legacy Award from the Women's International Center.[10]\\r\\nJeffreys was married twice. Her first marriage, to Joseph Serena, was annulled in 1949.[11] They had no children.\\r\\nShe married actor Robert Sterling in 1951. Sterling appeared with Jeffreys in the series Topper. In January 1958, the duo attempted to star in another series, Love That Jill. It ran only a few months, with 13 episodes shot. They had three sons: Jeffrey, Dana and Tyler. Robert Sterling died on May 30, 2006 at age 88.[citation needed]\\r\\nIn July 1956, Jeffreys' mother, Kate Jeffreys Carmichael, 67, was run down and killed by her own automobile in the driveway of the home of her daughter. Police said Carmichael was taking books from the car's trunk when the emergency brake apparently slipped. The car rolled down the sloping driveway, dragging the actress' mother 26 feet.[12]\\r\\nJeffreys died on September 27, 2017 at her home in Los Angeles at the age of 94. She was survived by her stepdaughter Tisha Sterling, her three sons, five grandchildren and two great-grandchildren.[13][14]","input":"What role did anne jeffreys play on general hospital?"},{"output":"the Tibetan Plateau in the vicinity of Lake Manasarovar","context":"\\r\\n\\r\\nThe Indus River (locally called Sindh) is one of the longest rivers in Asia. Originating in the Tibetan Plateau in the vicinity of Lake Manasarovar, the river runs a course through the Ladakh region of Jammu and Kashmir, towards Gilgit-Baltistan and the Hindukush ranges, and then flows in a southerly direction along the entire length of Pakistan to merge into the Arabian Sea near the port city of Karachi in Sindh.[1][2] It is the longest river and national river of Pakistan.[3]\\r\\n\\r\\nThe river has a total drainage area exceeding 1,165,000?km2 (450,000?sq?mi). Its estimated annual flow stands at around 243?km3 (58?cu?mi), twice that of the Nile River and three times that of the Tigris and Euphrates rivers combined, making it the twenty-first largest river in the world in terms of annual flow.[4] The Zanskar is its left bank tributary in Ladakh. In the plains, its left bank tributary is the Panjnad which itself has five major tributaries, namely, the Chenab, Jhelum, the Ravi, the Beas, and the Sutlej. Its principal right bank tributaries are the Shyok, the Gilgit, the Kabul, the Gomal, and the Kurram. Beginning in a mountain spring and fed with glaciers and rivers in the Himalayas, the river supports ecosystems of temperate forests, plains and arid countryside.\\r\\n\\r\\nThe northern part of the Indus Valley, with its tributaries, forms the Punjab region, while the lower course of the Indus is known as Sindh and ends in a large delta. The river has historically been important to many cultures of the region. The 3rd millennium BC saw the rise of a major urban civilization of the Bronze Age. During the 2nd millennium BC, the Punjab region was mentioned in the hymns of the Hindu Rigveda as Sapta Sindhu and the Zoroastrian Avesta as Hapta Hindu (both terms meaning \\"seven rivers\\"). Early historical kingdoms that arose in the Indus Valley include Gandhra, and the Ror dynasty of Sauvؐra. The Indus River came into the knowledge of the West early in the Classical Period, when King Darius of Persia sent his Greek subject Scylax of Caryanda to explore the river, ca. 515?BC.\\r\\n\\r\\nThis river was known to the ancient Indians in Sanskrit as Sindhu and the Old Iranians as Hindu, which was regarded by both of them as \\"the border river\\".[5][6][7][8][9] The variation between the two names is explained by the Old Iranian sound change *s > h, which occurred between 850ÿ600 BCE according to Asko Parpola.[10][11] From Iran, the name passed to the Greeks as Hind܇s (?Ѵ??), which later turned into Ind܇s, with a loss of the initial aspirant.[12] It was adopted by the Romans as Indus.\\r\\n\\r\\nThe meaning of Sindhu as a \\"large body of water, sea, or ocean\\" is a later meaning in Classical Sanskrit.[13] A later Persian name for the river was Darya,[14] which similarly has the connotations of large body of water and sea.[citation needed]\\r\\n\\r\\nOther variants of the name Sindhu include Assyrian Sinda (as early as the 7th century BC), Persian  Ab-e-sind,  Pashto  Abasind, Arab Al-Sind,  Chinese Sintow, and Javanese  Santri.[citation needed]\\r\\n\\r\\nIndia is a Greek and Latin term for \\"the country of the River Indus\\". The region through which the river drains into sea is called Sindh and owes its name to the river (Sanskrit Sindhu).[15]\\r\\n\\r\\nMegasthenes' book Indica derives its name from the river's Greek name, \\"Ind܇s\\" (?Ѵ??), and describes Nearchus's contemporaneous account of how Alexander the Great crossed the river. The ancient Greeks referred to the Indians (people of present-day northwest India and Pakistan) as \\"Ind܇i\\" (?Ѵ?), literally meaning \\"the people of the Indus\\".[16]\\r\\n\\r\\nRigveda also describes several mythical rivers, including one named \\"Sindhu\\". The Rigvedic \\"Sindhu\\" is thought to be the present-day Indus river and is attested 176 times in its text ÿ 95 times in the plural, more often used in the generic meaning. In the Rigveda, notably in the later hymns, the meaning of the word is narrowed to refer to the Indus river in particular, as in the list of rivers mentioned in the hymn of Nadistuti sukta. The Rigvedic hymns apply a feminine gender to all the rivers mentioned therein but \\"Sindhu\\" is the only river attributed the masculine gender which means Sindhu is the warrior and greatest among all other rivers in whole world.[citation needed]\\r\\n\\r\\nIn other languages of the region, the river is known as ?????? (Sindhu) in Hindi and Nepali, ???? (Sindhu) in Sindhi, ????? (Sindh) in Shahmukhi Punjabi, ???? ??? (Sindh Nadؐ) in Gurmukhؐ Punjabi, ?????? (Absin lit. \\"Father of Rivers\\") in Pashto, ??? ????? (Nahar al-Sind) in Arabic, ?????????????? (seng ge gtsang po lit. \\"Lion River\\" or Lion Spring) in Tibetan, CH (Ynd) in Chinese, and Nilab in Turki.[citation needed]\\r\\n\\r\\nThe Indus River provides key water resources for Pakistan's economy ÿ especially the breadbasket of Punjab province, which accounts for most of the nation's agricultural production, and Sindh. The word Punjab means \\"land of five rivers\\" and the five rivers are Jhelum, Chenab, Ravi, Beas and Sutlej, all of which finally flow into the Indus. The Indus also supports many heavy industries and provides the main supply of potable water in Pakistan.\\r\\n\\r\\nThe ultimate source of the Indus is in Tibet; the river begins at the confluence of the Sengge Zangbo and Gar Tsangpo rivers that drain the Nganglong Kangri and Gangdise Shan (Gang Rinpoche, Mt. Kailas) mountain ranges. The Indus then flows northwest through Ladakh and Baltistan into Gilgit, just south of the Karakoram range. The Shyok, Shigar and Gilgit rivers carry glacial waters into the main river. It gradually bends to the south, coming out of the hills between Peshawar and Rawalpindi. The Indus passes gigantic gorges 4,500ÿ5,200 metres (15,000ÿ17,000 feet) deep near the Nanga Parbat massif. It flows swiftly across Hazara and is dammed at the Tarbela Reservoir. The Kabul River joins it near Attock. The remainder of its route to the sea is in the plains of the Punjab[17] and Sindh, where the flow of the river becomes slow and highly braided. It is joined by the Panjnad at Mithankot. Beyond this confluence, the river, at one time, was named the Satnad River (sat = \\"seven\\", nadؐ = \\"river\\"), as the river now carried the waters of the Kabul River, the Indus River and the five Punjab rivers. Passing by Jamshoro, it ends in a large delta to the east of Thatta.\\r\\n\\r\\nThe Indus is one of the few rivers in the world to exhibit a tidal bore. The Indus system is largely fed by the snows and glaciers of the Himalayas, Karakoram and the Hindu Kush ranges of Tibet, the Indian states of Jammu and Kashmir and Himachal Pradesh and Gilgit-Baltistan region of Pakistan. The flow of the river is also determined by the seasons ÿ it diminishes greatly in the winter, while flooding its banks in the monsoon months from July to September. There is also evidence of a steady shift in the course of the river since prehistoric times ÿ it deviated westwards from flowing into the Rann of Kutch and adjoining Banni grasslands after the 1816 earthquake.[18][19] Presently, Indus water flows in to the Rann of Kutch during its floods breaching flood banks.[20]\\r\\n\\r\\nThe traditional source of the river is the Senge Khabab or \\"Lion's Mouth\\", a perennial spring, not far from the sacred Mount Kailash marked by a long low line of Tibetan chortens. There are several other tributaries nearby, which may possibly form a longer stream than Senge Khabab, but unlike the Senge Khabab, are all dependent on snowmelt. The Zanskar River, which flows into the Indus in Ladakh, has a greater volume of water than the Indus itself before that point.[21]\\r\\n\\r\\nThe major cities of the Indus Valley Civilisation, such as Harappa and Mohenjo-daro, date back to around 3300?BC, and represent some of the largest human habitations of the ancient world. The Indus Valley Civilisation extended from across northeast Afghanistan to Pakistan and northwest India,[22] with an upward reach from east of Jhelum River to Ropar on the upper Sutlej. The coastal settlements extended from Sutkagan Dor at the Pakistan, Iran border to Kutch in modern Gujarat, India. There is an Indus site on the Amu Darya at Shortughai in northern Afghanistan, and the Indus site Alamgirpur at the Hindon River is located only 28?km (17?mi) from Delhi. To date, over 1,052 cities and settlements have been found, mainly in the general region of the Ghaggar-Hakra River and its tributaries. Among the settlements were the major urban centres of Harappa and Mohenjo-daro, as well as Lothal, Dholavira, Ganeriwala, and Rakhigarhi. Only 90ÿ96 of more than 800 known Indus Valley sites have been discovered on the Indus and its tributaries.[citation needed] The Sutlej, now a tributary of the Indus, in Harappan times flowed into the Ghaggar-Hakra River, in the watershed of which were more Harappan sites than along the Indus.\\r\\n\\r\\nMost scholars believe that settlements of Gandhara grave culture of the early Indo-Aryans flourished in Gandhara from 1700?BC to 600?BC, when Mohenjo-daro and Harappa had already been abandoned.\\r\\n\\r\\nThe word \\"India\\" is derived from the Indus River. In ancient times, \\"India\\" initially referred to those regions immediately along the east bank of the Indus, but by 300?BC, Greek writers including Herodotus and Megasthenes were applying the term to the entire subcontinent that extends much farther eastward.[23][24]\\r\\n\\r\\nThe lower basin of the Indus forms a natural boundary between the Iranian Plateau and the Indian subcontinent; this region embraces all or parts of the Pakistani provinces Balochistan, Khyber Pakhtunkhwa, Punjab and Sindh and the countries Afghanistan and India. It was crossed by the invading armies of Alexander, but after his Macedonians conquered the west bankjoining it to the Hellenic Empire, they elected to retreat along the southern course of the river, ending Alexander's Asian campaign. The Indus plains were later dominated by the Persian empire and then the Kushan empire. Over several centuries Muslim armies of Muhammad bin Qasim, Mahmud of Ghazni, Mohammed Ghori, Tamerlane and Babur crossed the river to invade the inner regions of the Punjab and points farther south and east\\r\\n\\r\\nThe Indus river feeds the Indus submarine fan, which is the second largest sediment body on the Earth.[25] It consists of around 5?million cubic kilometres of material eroded from the mountains. Studies of the sediment in the modern river indicate that the Karakoram Mountains in northern Pakistan and India are the single most important source of material, with the Himalayas providing the next largest contribution, mostly via the large rivers of the Punjab (Jhelum, Ravi, Chenab, Beas and Sutlej). Analysis of sediments from the Arabian Sea has demonstrated that prior to five million years ago the Indus was not connected to these Punjab rivers which instead flowed east into the Ganga and were captured after that time.[26] Earlier work showed that sand and silt from western Tibet was reaching the Arabian Sea by 45?million years ago, implying the existence of an ancient Indus River by that time.[27] The delta of this proto-Indus river has subsequently been found in the Katawaz Basin, on the Afghan-Pakistan border.\\r\\n\\r\\nIn the Nanga Parbat region, the massive amounts of erosion due to the Indus river following the capture and rerouting through that area is thought to bring middle and lower crustal rocks to the surface.[28]\\r\\n\\r\\nIn November 2011, satellite images showed that the Indus river had re-entered India, feeding Great Rann of Kutch, Little Rann of Kutch and a lake near Ahmedabad known as Nal Sarovar.[20] Heavy rains had left the river basin along with the Lake Manchar, Lake Hemal and Kalri Lake (all in modern-day Pakistan) inundated. This happened two centuries after the Indus river shifted its course westwards following the 1819 Rann of Kutch earthquake.\\r\\n\\r\\nThe Induan Age at start of the Triassic Period of geological time is named for the Indus region.\\r\\n\\r\\nAccounts of the Indus valley from the times of Alexander's campaign indicate a healthy forest cover in the region, which has now considerably receded. The Mughal Emperor Babur writes of encountering rhinoceroses along its bank in his memoirs (the Baburnama). Extensive deforestation and human interference in the ecology of the Shivalik Hills has led to a marked deterioration in vegetation and growing conditions. The Indus valley regions are arid with poor vegetation. Agriculture is sustained largely due to irrigation works.\\r\\nThe Indus river and its watershed has a rich biodiversity. It is home to around 25 amphibian species and 147 fish species, 22 of which are only found in the Indus.[29]\\r\\n\\r\\nThe Indus River Dolphin (Platanista indicus minor) is a sub-species of dolphin found only in the Indus River. It formerly also occurred in the tributaries of the Indus river. According to the World Wildlife Fund it is one of the most threatened cetaceans with only about 1,000 still existing.[30]\\r\\n\\r\\nPalla fish Tenualosa ilisha of the river is a delicacy for people living along the river. The population of fish in the river is moderately high, with Sukkur, Thatta and Kotri being the major fishing centres ÿ all in the lower Sindh course. But damming and irrigation has made fish farming an important economic activity. Located southeast of Karachi, the large delta has been recognised by conservationists as one of the world's most important ecological regions. Here the river turns into many marshes, streams and creeks and meets the sea at shallow levels. Here marine fishes are found in abundance, including pomfret and prawns.\\r\\n\\r\\nThe Indus is the most important supplier of water resources to the Punjab and Sindh plains ÿ it forms the backbone of agriculture and food production in Pakistan. The river is especially critical since rainfall is meagre in the lower Indus valley. Irrigation canals were first built by the people of the Indus Valley Civilisation, and later by the engineers of the Kushan Empire and the Mughal Empire. Modern irrigation was introduced by the British East India Company in 1850 ÿ the construction of modern canals accompanied with the restoration of old canals. The British supervised the construction of one of the most complex irrigation networks in the world. The Guddu Barrage is 1,350?m (4,430?ft) long ÿ irrigating Sukkur, Jacobabad, Larkana and Kalat. The Sukkur Barrage serves over 20,000?km2 (7,700?sq?mi).\\r\\n\\r\\nAfter Pakistan came into existence, a water control treaty signed between India and Pakistan in 1960 guaranteed that Pakistan would receive water from the Indus River and its two tributaries the Jhelum River & the Chenab River independently of upstream control by India.[31]\\r\\n\\r\\nThe Indus Basin Project consisted primarily of the construction of two main dams, the Mangla Dam built on the Jhelum River and the Tarbela Dam constructed on the Indus River, together with their subsidiary dams.[32] The Pakistan Water and Power Development Authority undertook the construction of the Chashma-Jhelum link canal ÿ linking the waters of the Indus and Jhelum rivers ÿ extending water supplies to the regions of Bahawalpur and Multan. Pakistan constructed the Tarbela Dam near Rawalpindi ÿ standing 2,743 metres (9,000?ft) long and 143 metres (470?ft) high, with an 80-kilometre (50?mi) long reservoir. It supports the Chashma Barrage near Dera Ismail Khan for irrigation use and flood control and the Taunsa Barrage near Dera Ghazi Khan which also produces 100,000?kilowatts of electricity. The Kotri Barrage near Hyderabad is 915 metres (3,000?ft) long and provides additional water supplies for Karachi. The extensive linking of tributaries with the Indus has helped spread water resources to the valley of Peshawar, in the Khyber Pakhtunkhwa. The extensive irrigation and dam projects provide the basis for Pakistan's large production of crops such as cotton, sugarcane and wheat. The dams also generate electricity for heavy industries and urban centers.\\r\\n\\r\\nThe inhabitants of the regions are mainly Muslim as Pakistan is an Islamic country through which the Indus river passes and forms a major natural feature and resource are diverse in ethnicity, religion, national and linguistic backgrounds. On the northern course of the river in the state of Jammu and Kashmir in India, live the Buddhist people of Ladakh, of Tibetan stock, and the Dards of Indo-Aryan or Dardic stock and practising Islam. Then it descends into Baltistan, northern Pakistan passing the main Balti city of Skardu. A river from Dubair Bala also drains into it at Dubair Bazar. People living in this area are mainly Kohistani and speak the Kohistani language. Major areas through which the Indus river passes in Kohistan are Dasu, Pattan and Dubair. As it continues through Pakistan, the Indus river forms a distinctive boundary of ethnicity and cultures ÿ upon the western banks the population is largely Pashtun, Baloch, and of other Iranian stock. The eastern banks are largely populated by people of Indo-Aryan stock, such as the Punjabis and the Sindhis. In northern Punjab and the Khyber Pakhtunkhwa, ethnic Pashtun tribes live alongside Dardic people in the hills (Khowar, Kalash, Shina, etc.), Burushos (in Hunza), and Punjabi people.\\r\\n\\r\\nThe people living along the Indus river speak Punjabi and Sindhi on the eastern side (in Punjab and Sindh provinces respectively), Pushto plus Balochi as well as Barohi (in Khyber Pakhtoonkha and Baluchistan provinces). In the province of Sindh, the upper third of the river is inhabited by people speaking Saraiki; which is a somewhat transitional dialect of the Punjabi and Sindhi languages.\\r\\n\\r\\nThe Indus is a strategically vital resource for Pakistan's economy and society. After Pakistan and India declared Independence from the British Raj, the use of the waters of the Indus and its five eastern tributaries became a major dispute between India and Pakistan. The irrigation canals of the Sutlej valley and the Bari Doab were split ÿ with the canals lying primarily in Pakistan and the headwork dams in India disrupting supply in some parts of Pakistan. The concern over India building large dams over various Punjab rivers that could undercut the supply flowing to Pakistan, as well as the possibility that India could divert rivers in the time of war, caused political consternation in Pakistan. Holding diplomatic talks brokered by the World Bank, India and Pakistan signed the Indus Waters Treaty in 1960. The treaty gave India control of the three easternmost rivers of the Punjab, the Sutlej, the Beas and the Ravi, while Pakistan gained control of the three western rivers, the Jhelum, the Chenab and the Indus. India retained the right to use of the western rivers for non-irrigation projects.[33]\\r\\n\\r\\nThere are concerns that extensive deforestation, industrial pollution and global warming are affecting the vegetation and wildlife of the Indus delta, while affecting agricultural production as well. There are also concerns that the Indus river may be shifting its course westwards ÿ although the progression spans centuries. On numerous occasions, sediment clogging owing to poor maintenance of canals has affected agricultural production and vegetation. In addition, extreme heat has caused water to evaporate, leaving salt deposits that render lands useless for cultivation.\\r\\n\\r\\nOriginally, the delta used to receive almost all of the water from the Indus river, which has an annual flow of approximately 180?billion cubic metres (240?billion cubic yards), and is accompanied by 400 million tonnes of silt. Since the 1940s, dams, barrages and irrigation works have been constructed on the river Indus.[34] The Indus Basin Irrigation System is the \\"largest contiguous irrigation system developed over the past 140 years\\" anywhere in the world.[35] This has reduced the flow of water and by 2018, the average annual flow of water below the Kotri barrage was 32G10^9?m3 (1.1G10^12?cu?ft), and annual amount of silt discharged was estimated to be 100?million tonnes (98?million long tons).[36] Substantial annual chemical/dissolved load of 46 million tons in the river basin is unable to reach the sea as it is getting trapped in the irrigated areas by increasing the ground water salinity. Nearly 90% of the water from Indus River System has been harnessed already in Pakistan and India leaving rest of water to join the sea. Any further utilization of the river basin water is not economically feasible.[37][38]  The result has been catastrophic for both the environment and the local population. The reduction of freshwater due to the dams also increases salinity, making the surface and ground water available in the delta area unsuitable for the freshwater species and crops.[39][40] As a result, the 2010 Pakistan floods were considered \\"good news\\" for the ecosystem and population of the river delta as they brought much needed fresh water.[41][42] In case of the Indus dolphin, the damming of the river has isolated the delta dolphin population from those dolphins upstream.\\r\\n\\r\\nThe Tibetan Plateau contains the world's third-largest store of ice. Qin Dahe, the former head of the China Meteorological Administration, said the recent fast pace of melting and warmer temperatures will be good for agriculture and tourism in the short term, but issued a strong warning:\\r\\n\\r\\n\\"There is insufficient data to say what will happen to the Indus,\\" says David Grey, the World Bank's senior water advisor in South Asia. \\"But we all have very nasty fears that the flows of the Indus could be severely, severely affected by glacier melt as a consequence of climate change,\\" and reduced by perhaps as much as 50 percent. \\"Now what does that mean to a population that lives in a desert [where], without the river, there would be no life? I don't know the answer to that question,\\" he says. \\"But we need to be concerned about that. Deeply, deeply concerned.\\"[44]\\r\\n\\r\\nU.S. diplomat Richard Holbrooke said, shortly before his death in 2010, that he believed that falling water levels in the Indus River \\"could very well precipitate World War III.\\"[45]\\r\\n\\r\\nOver the years factories on the banks of the Indus River have increased levels of water pollution in the river and the atmosphere around it. High levels of pollutants in the river have led to the deaths of endangered Indus River Dolphin. The Sindh Environmental Protection Agency has ordered polluting factories around the river to shut down under the Pakistan Environmental Protection Act, 1997.[46] Death of the Indus River Dolphin has also been attributed to fishermen using poison to kill fish and scooping them up.[47][48] As a result, the government banned fishing from Guddu Barrage to Sukkur.[49]\\r\\n\\r\\nComing second after the Yangtze, and together with 9 other rivers, the Indus transports 90?% of all the plastic that reaches the oceans.[50][51]\\r\\n\\r\\nIn July 2010, following abnormally heavy monsoon rains, the Indus River rose above its banks and started flooding. The rain continued for the next two months, devastating large areas of Pakistan. In Sindh, the Indus burst its banks near Sukkur on 8 August, submerging the village of Mor Khan Jatoi.[52] In early August, the heaviest flooding moved southward along the Indus River from severely affected northern regions toward western Punjab, where at least 1,400,000 acres (570,000?ha) of cropland was destroyed, and the southern province of Sindh.[53] As of  September 2010[update], over two thousand people had died and over a million homes had been destroyed since the flooding began.[54][55]\\r\\n\\r\\nThe 2011 Sindh floods began during the Pakistani monsoon season in mid-August 2011, resulting from heavy monsoon rains in Sindh, eastern Balochistan, and southern Punjab.[56] The floods caused considerable damage; an estimated 434 civilians were killed, with 5.3?million people and 1,524,773 homes affected.[57] Sindh is a fertile region and often called the \\"breadbasket\\" of the country; the damage and toll of the floods on the local agrarian economy was said to be extensive. At least 1.7?million acres (690,000?ha; 2,700?sq?mi) of arable land were inundated. The flooding followed the previous year's floods, which devastated a large part of the country.[57] Unprecedented torrential monsoon rains caused severe flooding in 16 districts of Sindh.[58]\\r\\n\\r\\nIn Pakistan currently there are three barrages on the Indus: Guddu barrage, Sukkur Barrage, and Kotri barrage (also called Ghulam Muhammad barrage). There are some bridges on river Indus, such as, Dadu Moro Bridge, Larkana Khairpur Indus River Bridge, Thatta-Sujawal bridge, Jhirk-Mula Katiar bridge and recently planned Kandhkot-Ghotki bridge.[59]\\r\\n\\r\\nKala Bagh Barrage, Chasma Barrage, and Taunsa Barrage are also built in Punjab on the Indus.\\r\\n\\r\\nTarbela Dam in Pakistan is constructed on the Indus River, while the controversial Kalabagh dam is also being constructed on Indus river.\\r\\n\\r\\nVideo of River Indus at Kotri Barrage, Sindh, Pakistan.\\r\\n\\r\\nFrozen Indus, Near Nyoma\\r\\n\\r\\nIndus at Skardu","input":"What is the starting point of indus river?"},{"output":"red 1965 Sunbeam Tiger two-seat roadster","context":"Get Smart is an American comedy television series that satirizes the secret agent genre. It was created by Mel Brooks with Buck Henry and had its television premiere on September 18, 1965. The show stars Don Adams as Maxwell Smart, Agent 86, Barbara Feldon as Agent 99, and Edward Platt as Thaddeus, the Chief. Henry said that they created the show at the request of Daniel Melnick[1] to capitalize on \\"the two biggest things in the entertainment world today\\": James Bond and Inspector Clouseau.[2] Brooks said: \\"It's an insane combination of James Bond and Mel Brooks comedy.\\"[3]\\r\\nThe show generated a number of popular catchphrases during its run, including \\"Would you believe...\\", \\"Good thinking, 99\\", \\"Missed it by that much!\\", \\"Sorry about that, Chief\\", \\"The old (such-and-such) trick\\", \\"And loving it\\", and \\"I asked you not to tell me that\\".[4] The show was followed by the films The Nude Bomb (a 1980 theatrical release) and Get Smart, Again! (a 1989 made-for-TV sequel to the series), as well as a 1995 revival series, and a 2008 film remake. In 2010, TV Guide ranked Get Smart's opening title sequence at No. 2 on its list of TV's Top 10 Credits Sequences as selected by readers.[5]\\r\\nThe show ended its 5-season run on May 15, 1970, with 138 episodes. The Museum of Broadcast Communications finds the show notable for \\"broadening the parameters for the presentation of comedy on television.\\" [6]\\r\\n\\r\\n\\r\\nThe series centers on bumbling secret agent Maxwell Smart, also known as Agent 86, and his female partner, Agent 99.[7] Agents 86 and 99 work for \\"CONTROL,\\" a secret U.S. government counter-intelligence agency based in Washington, D.C. The pair investigates and thwarts various threats to the world, though Smart's bumbling nature and demands to do things by-the-book invariably cause complications. However, Smart never fails to save the day. Looking on is the long-suffering head of CONTROL, who is addressed simply as \\"Chief.\\"\\r\\nThe nemesis of CONTROL is KAOS, described as \\"an international organization of evil\\". In the series, KAOS was supposedly formed in Bucharest, Romania, in 1904.[8] Neither CONTROL nor KAOS is actually an acronym. Many guest actors appeared as KAOS agents, including William Schallert (who also had a recurring role as The Admiral, the first Chief of CONTROL). Conrad Siegfried, played by Bernie Kopell, is Smart's KAOS archenemy. King Moody (originally appearing as a generic KAOS killer) portrayed the dim-witted but burly Shtarker, Siegfried's assistant.\\r\\nThe enemies, world-takeover plots and gadgets seen in Get Smart parody the James Bond movies. \\"Do what they did except just stretch it half an inch,\\" Mel Brooks said of the methods of this TV series.[9]\\r\\nMax and 99 marry in season four, and have twins in season five. Agent 99 became the first woman on an American hit sitcom to keep her job after marriage and motherhood.[citation needed]\\r\\nTalent Associates commissioned Mel Brooks and Buck Henry to write a script about a bungling James Bond-like hero.[10] Brooks described the premise for the show which they created in an October 1965 Time magazine article:\\r\\nBrooks and Henry proposed the show to ABC, where network executives called it \\"un-American\\" and demanded a \\"lovable dog to give the show more heart\\", as well as scenes showing Maxwell Smart's mother.[10] Brooks strongly objected to the second suggestion:\\r\\nThe cast and crew contributed joke and gadget ideas, especially Adams, but dialogue was rarely ad-libbed. An exception is the third-season episode \\"The Little Black Book.\\" Don Rickles encouraged Adams to misbehave, and he ad-libbed. The result was so successful that the single episode was turned into two parts.[11]\\r\\nThe first four seasons were filmed at Sunset Bronson Studios, while the final season, shown on CBS, was filmed at CBS Studio Center.\\r\\nBrooks had little involvement with the series after the first season, but Buck Henry served as story editor through 1967. The crew of the show included:\\r\\nCONTROL is a spy agency founded at the beginning of the 20th century by Harold Harmon Hargrade, a career officer in the United States Navy's N-2 (Intelligence) Branch. Hargrade served as the first Chief of CONTROL. \\"CONTROL\\" is not an acronym, but it is always shown in all capital letters as if it were.\\r\\n\\r\\nMaxwell Smart, code number Agent 86 (portrayed by Don Adams) is the central character. Despite being a top secret government agent, he is absurdly clumsy, very naive and has occasional lapses of attention. Due to his frequent verbal gaffes and physical miscues, most of the people Smart encounters believe he is grossly incompetent. Despite these faults, Smart is also resourceful, skilled in hand-to-hand combat, a proficient marksman, and incredibly lucky. These assets have led to him having a phenomenal record of success in times of crisis in which he has often averted disaster, often on a national or global scale. This performance record means his only punishment in CONTROL for his mistakes is that he is the only agent without three weeks annual vacation time. Smart uses multiple cover identities, but the one used most often is as a greeting card salesman/executive. Owing to multiple assassination attempts, he tells his landlord he is in the insurance business, and on one occasion, that he works for the \\"Bureau of Internal Revenue\\". Smart served in the U.S. Army during the Korean War and is an ensign in the U.S. Navy Reserve. He was played by Steve Carell in the 2008 film.\\r\\nIn 1999 TV Guide ranked Maxwell Smart number 19 on its 50 Greatest TV Characters of All Time list.[13] The character appears in every episode (though only briefly in \\"Ice Station Siegfried,\\" as Don Adams was performing in Las Vegas for two weeks to settle gambling debts).[14]\\r\\nAgent 99 (Barbara Feldon) is the tall, beautiful female agent whose appearance is useful in undercover operations. Generally, Agent 99 (her actual name is never revealed) is more competent than Smart, but Smart saves her life in several episodes. \\"Snoopy Smart vs the Red Baron\\" is the introduction of 99's mother (Jane Dulo), who appears so thoroughly fooled by her daughter and Smart's cover stories that not even seeing them in combat while a prisoner of KAOS convinces her otherwise. However, at one point her mother indicates that 99's father was also a spy. Creator Buck Henry pointed out to actress Barbara Feldon on the DVD commentary for Season 3 that when he tried to add funny lines for Agent 99, \\"They didn't want you to be 'joke funny.' They wanted you to be glamorous and interesting.\\"[15] In the episode \\"99 Loses CONTROL\\", 99 tells Victor that her name is \\"Susan Hilton\\". When Max asks why she never told him what her real name was, she replies, \\"You never asked,\\" to which Max says he prefers 99. Then, at the end of the episode, she says it is not her real name.[16][17] Her name is in fact intentionally never revealed, even at their own wedding in season four. She appears in all but seven episodes. She can typically be seen slouching, leaning, or sitting in scenes with Adams to hide the fact that she was slightly taller (5' 9\\" or 1.75 m) than Adams (5' 8?\\" or 1.74 m).[18] She was played by Anne Hathaway in the 2008 film and Get Smart's Bruce and Lloyd: Out of Control.\\r\\nThe Chief (Edward Platt) is the head of CONTROL. Although sarcastic and grouchy, the Chief is intelligent, serious, and sensible. He began his career at CONTROL as \\"Agent Q.\\" (He joined the organization back when they assigned letters rather than numbers.) He is supportive of Agents 86 and 99 and rates them as his two closest friends, but he is frustrated with Smart for his frequent failures and foul-ups. As revealed in the season-one episode \\"The Day Smart Turned Chicken\\", his first name is Thaddeus, but it is rarely used. His cover identity (used primarily with 99's mom) is \\"Harold Clark\\". Another time, when KAOS arranges for the Chief to be recalled to active duty in the U.S. Navy (as a common seaman with Smart as his commanding officer), his official name is John Doe. He was played by Alan Arkin in the 2008 film.\\r\\nHymie the Robot (Richard \\"Dick\\" Gautier) is a humanoid robot built by Dr. Ratton to serve KAOS (when questioned about the curious name, Dr. Ratton replied \\"My father's name was Hymie!\\"), but in his first mission, Smart manages to turn him to the side of CONTROL. Hymie has numerous superhuman abilities, such as being physically stronger and faster than any human and being able to swallow poisons and register their name, type, and quantity, though his design does not include superhuman mental processing, most significantly characterized by an overly literal interpretation of commands. For example, when Smart tells Hymie to \\"get a hold of yourself\\", he grasps each arm with the other. Hymie also has emotions and is \\"programmed for neatness\\". He was played by Patrick Warburton in the 2008 film.\\r\\nAgent 8 (Burt Mustin) is a retired CONTROL agent who appears in episode twenty three. He is revealed to be the Chief's best friend from his days at CONTROL.\\r\\nAgent 13 (Dave Ketchum) is an agent who is usually stationed inside unlikely or unlucky places, such as cigarette machines, washing machines, lockers, trash cans, or fire hydrants. He tends to resent his assignments. Agent 13 is featured in several season-two episodes. He was played by Bill Murray in the 2008 film.\\r\\nAgent 44 (Victor French) is Agent 13's predecessor and is also stationed in tight corners. Agent 44 sometimes falls into bouts of self-pity and complaining, and he would sometimes try to keep Max chatting for the company. Agent 44 appears in several episodes in the second half of season one. In the final season, there is a new Agent 44 (played by Al Molinaro) in two episodes. (Prior to starting as 44, Victor French has a brief guest role in the season-one episode \\"Too Many Chiefs\\" as Smart's Mutual Insurance agent.)\\r\\nAgent Larabee (Robert Karvelas) is the Chief's slow-witted assistant. In a season five episode, it is reported that if anything happens to Smart, Larabee will take his place. Robert Karvelas was Don Adams' cousin. Larabee also appears in The Nude Bomb. He was played by David Koechner in the 2008 film.\\r\\nAdmiral Harold Harmon Hargrade or The Admiral (William Schallert) is the former chief. He founded CONTROL as a spy agency just after the turn of the 20th century. The admiral has a poor memory, believing the current U.S. President is still Herbert Hoover. As a 91-year-old, he has bad balance and often falls over.\\r\\nCharlie Watkins / Agent 38 (Angelique Pettyjohn) is an undercover male agent and master of disguise. Agent 38 appears as a scantily clad glamorous woman in two season 2 episodes. He also appears once in season four as a different actress (Karen Authur). He can also switch to a feminine voice as part of the disguise.\\r\\nFang/Agent K-13 (played by Red) is a poorly trained CONTROL dog, who is seen during seasons one and two. He was a very successful CONTROL agent for quite a few years. He was trained by Max, which probably explains why he does not always follow directions properly. Their relationship began in Spy School, where they were members of the same graduating class. He sometimes uses the cover name Morris and his favorite toys are a turtleneck sweater, a rubber ducky and one of Max's slippers. Fang's career ends in the second season, as he is no longer showing energy in solving his cases. In honor of his outstanding service to CONTROL, the Chief retires Fang to a desk job, burying evidence. (He has a brief role in the 2008 film, being a pet-store dog that Max is in the habit of complaining to.) Fang was written out of the series in season two. He appears in six season-one episodes and two season-two episodes. He appears first in the pilot, \\"Mr. Big\\", and his last one was the season-two episode \\"Perils in a Pet Shop\\". Shots that involved Fang ended up running long and costing the production a lot of money in overtime and wasted time. After a few episodes of this, he was written out of the series. He was handled by Bill Weatherwax.\\r\\nCarlson (Stacy Keach Sr.) is CONTROL's gadget man during season two. While inspecting the gadgets, Max usually creates minor mayhem. Carlson follows several CONTROL scientists who fulfill the same function in season one. They are the similarly named Carleton (Frank DeVol), the egotistical Windish (Robert O. Cornthwaite), and Parker (Milton Selzer).\\r\\nDr. Steele (Ellen Weston) is a CONTROL scientist who makes three appearances in season three. Dr. Steele is an intelligent, extremely attractive woman whose cover is a chorus dancer at a high-class burlesque theater. The entrance to her laboratory is through a large courier box sidestage. Dr Steele often performs complex scientific procedures while wearing her revealing performance costumes. She is often seen explaining her findings while warming up for her next dance, and then suddenly departing for her performance. Dr. Steele is replaced with the similar Dr. Simon (Ann Elder), who appears in two episodes of season four and is mentioned once in season five.\\r\\nHarry Hoo (Joey Forman) Hoo is a Hawaiian detective from Honolulu, who is depicted as a send-up of the fictional detective Charlie Chan. Hoo is not a member of CONTROL, but they work together on murder cases. Hoo's introduction usually creates confusion in the manner of Abbott and Costello's \\"Who's on First?\\" routine. Hoo always analyzes a mystery by presenting \\"two possibilities\\", of which the latter (if not both) is absurd. Max likes to upstage Hoo by jumping in with \\"two possibilities\\" of his own, which are even crazier than Hoo's. Hoo responds with \\"Amazing!\\", spoken in a tone of disbelief rather than approval, but Max is oblivious to this. Initially, the character was a lampoon of Chan, but in a later episode Hoo appeared rather more brilliant and resourceful, with Max, though helpful as always, appearing more so as a contrast.\\r\\nKAOS is a (fictional) \\"international organization of evil\\" formed in Bucharest, Romania, in 1904; like \\"CONTROL\\", \\"KAOS\\" is not an acronym. They were supposed to be, but Brooks and Henry were so busy, they forgot to have the names stand for anything. In a series episode, after making a series of demands in a recording, the speaker mentions the demands are from \\"KAOS, a Delaware Corporation\\". When Smart asks the chief about this, he mentions they did it for tax reasons.\\r\\nMr. Big (Michael Dunn) is the presumed head of KAOS and a little person. He only appears in the black-and-white pilot episode, and is killed by his own doomsday death ray. A successor is chosen in another episode but is arrested by CONTROL. A few nameless KAOS chiefs appear in subsequent episodes.\\r\\nLudwig Von Siegfried,[19] Konrad Siegfried, Count Von Siegfried,[20] simply Siegfried, or Herr Siegfried in most episodes (Bernie Kopell) is a recurring villain, and the Vice President in charge of Public Relations and Terror at KAOS[21] though his title does vary. Siegfried is Maxwell Smart's \\"opposite number\\" and nemesis, even though the two characters share similar traits and often speak fondly of one anothereven in the midst of attempting to assassinate each other. Speaking English with an exaggerated German accent, the gray-haired, mustachioed, and dueling-scarred Siegfried's catchphrase is, \\"Zis is KAOS! Ve don't [some action] here!\\" He was played by Terence Stamp in the 2008 film.\\r\\nShtarker (King Moody) is Siegfried's chief henchman. Shtarker is an overzealous lackey whose most notable trait is his abrupt personality change from sadistic villain to presumptuous child, interrupting conversations to helpfully elaborate, using silly vocal noises to imitate things such as engines or guns. This prompts Siegfried to utter his catch phrase, \\"Shtarker...Nein! Zis is KAOS! Ve don't [weakly imitates Shtarker's sound effect] here!\\" (In the DVD commentary for the first episode in which the character appears, in season two, Bernie Kopell notes that \\"shtarker\\" is a real Yiddish word meaning a person of great strength.) Although he looks rather young for it, he claims to have been track champion of the Third Reich, and the second man out of El Alamein (right behind Siegfried). He was played by Ken Davitian in the 2008 film.\\r\\nThe Claw (Leonard Strong) is a Julius No-type Asian villain representing the east-Asian branch of KAOS. In place of the Claw's left hand is a powerful magnetic prosthesis with immobile fingers and an occasional attachment, hence his name (although when Smart first meets him, the Claw asks \\"Do you know what they call me?\\" holding up his claw. Smart helpfully suggests \\"Lefty?\\"). Sometimes the Claw would accidentally nab something with it, creating confusion. He is unable to pronounce the letter L and mispronounces his name as \\"Craw\\", with Smart repeatedly referring to him as \\"The Craw\\", much to his annoyance (\\"Not The Craw, THE CRAW!\\"). Like Siegfried, he has a huge, dimwitted assistant, named Bobo.\\r\\nNatz[22] or Spinoza[23] (Ted de Corsia) is a villain who was arrested by Max at an unknown point and desires revenge for it. He attempts to exact his revenge using the KAOS robot Hymie, though Hymie ultimately defects to CONTROL. Later, Spinoza hatches a plan to destroy Hymie using a new robot named 'Groppo', though this plan, too, ultimately fails.\\r\\nDoctor Ratton (Jim Boles) is a scientist who defected to KAOS. He built the robot Hymie for KAOS, but his abuse of Hymie ultimately leads to Hymie defecting and shooting him. Doctor Ratton survived the wound to construct the robot Groppo for Spinoza. However, to insure that Doctor Ratton does not return to the side of CONTROL and create more robots to counter KAOS, Spinoza uses Groppo to kill Ratton.\\r\\nSimon the Likeable (Jack Gilford), who appears in \\"And Baby Makes 4\\" Parts 1 & 2 is a KAOS killer whose nice face mesmerizes everyone into liking himexcept 99's mother, who knocks him out with a right cross, because Simon resembles her late, much-hated, and unlamented husband. (99's father never appears in any episode.)\\r\\nDoctor Yes (Donald Davis), who appears in \\"Dr. Yes\\", is a parody of James Bond's Doctor No. When he asks questions of his four assistants, they each respond yes in their own individual languages, mainly in the order \\"Jawohl, Oui, Da, S.\\" He captures Max and 99 in this episode and accidentally kills himself. When stung by an \\"electronic mosquito\\", he scratches his face with his poisonous fingernail.\\r\\nIn Get Smart, telephones are concealed in over 50 objects, including a necktie, comb, watch, and a clock. A recurring gag is Max's shoe phone (an idea from Brooks). To use or answer it, he has to take off his shoe. There were a number of variations on the shoe phone. In \\"I Shot 86 Today\\" (season 4) his shoe phone is disguised as a golf shoe, complete with cleats, developed by the attractive armorer Dr. Simon. Smart's shoes sometimes contain other devices housed in the heels: an explosive pellet, a smoke bomb, compressed air capsules that propelled the wearer off the ground, and a suicide pill (which Max believes is for the enemy).\\r\\nAgent 99 (Barbara Feldon) had her concealed telephones as well. She had one in her makeup compact, and also one in her fingernail. To use this last device, she would pretend to bite her nail nervously, while actually talking on her \\"nail phone.\\"\\r\\nOn February 17, 2002, the prop shoe phone was included in a display titled \\"Spies: Secrets from the CIA, KGB, and Hollywood\\", a collection of real and fictional spy gear that exhibited at the Ronald Reagan Presidential Library in Simi Valley, California. Flinders University in South Australia has researched medical applications for Shoe Phone technology after being inspired by the show.[24]\\r\\nGag phones also appear in other guises. In the episode \\"Too Many Chiefs\\" (Season one), Max tells Tanya, the KAOS informer whom he is protecting, that if anyone breaks in to pick up the house phone, dial 1-1-7, and press the trigger on the handset, which converts it to a gun. The phone-gun is only used that once, but Max once carried a gun-phone, a revolver with a rotary dial built into the cylinder. In the episode \\"Satan Place\\", Max simultaneously holds conversations on seven different phones  the shoe, his tie, his belt, his wallet, a garter, a handkerchief and a pair of eyeglasses. Other unusual locations include a garden hose, a car cigarette lighter (hidden in the car phone), a bottle of perfume (Max complains of smelling like a woman), the steering wheel of his car, a painting of Agent 99, the headboard of his bed, a cheese sandwich, lab test tubes (Max grabs the wrong one and splashes himself), a Bunsen burner (Max puts out the flame anytime he pronounces a \\"p\\"), a plant in a planter beside the real working phone (operated by the dial of the working phone), and inside another full-sized working phone.\\r\\nOther gadgets include a bullet-proof invisible wall in Max's apartment that lowers from the ceiling, into which Max and others often walk; a camera hidden in a bowl of soup (Cream of Technicolor) that takes a picture (with a conspicuous flash) of the person eating the soup with each spoonful; a Mini Magnet on a belt, which turns out to be stronger than KAOS's Maxi Magnet; and a powerful miniature laser weapon in the button of a sports jacket (the \\"laser blazer\\").\\r\\nAnother of the show's recurring gags is the \\"Cone of Silence\\". Smart would pedantically insist on following CONTROL's security protocols; when in the chief's office he would insist on speaking under the Cone of Silencetwo transparent plastic hemispheres which are electrically lowered on top of Max and Chiefwhich invariably malfunction, requiring the characters to shout loudly to even have a chance of being understood by each other. Bystanders in the room could often hear them better, and sometimes relay messages back and forth. The Cone of Silence was the idea of Buck Henry, though it was preceded in an episode of the syndicated television show Science Fiction Theatre titled \\"Barrier of Silence\\", written by Lou Huston, that first aired on September 3, 1955, ten years ahead of the NBC comedy.[25]\\r\\nThe car that Smart is seen driving most frequently is a red 1965 Sunbeam Tiger two-seat roadster.[26]\\r\\nThis car had various custom features, such as a machine gun, smoke screen, radar tracking, and an ejection seat. The Sunbeam Alpine, upon which the Tiger was based, was used by customizer Gene Winfield because the Alpine's 4-cylinder engine afforded more room under the hood than the V8 in the Tiger.[27][28] AMT, Winfield's employer, made a model kit of the Tiger, complete with hidden weapons. It is the only kit of the Tiger, and has been reissued multiple times as a stock Tiger.\\r\\nDon Adams received the Sunbeam and drove it for 10 years after the end of the show - since it was wrecked and repaired several times, the current whereabouts are unknown.[29]\\r\\nA fan created a red Tiger/Alpine with a machine gun in 2002.[30]\\r\\nIn the black-and-white pilot episode only, Smart drives a 1961 Ferrari 250 GT PF Spider Cabriolet.[31]\\r\\nIn the opening credits, the Tiger was used for seasons 1ÿ2. In seasons 3-4, Smart drives a light blue Volkswagen Karmann Ghia, because Volkswagen had become a sponsor of the show.[7] The Volkswagen was never used in the body of the show.[32] In season 5 (1969ÿ1970), Buick became a show sponsor,[7] so the Tiger was replaced with a gold 1969 Opel GT, which also appears in the body of the show.\\r\\nIn season four (1968ÿ1969), Adams uses a yellow Citro?n 2CV in the wedding episode \\"With Love and Twitches\\" (Episode 4.09), and a blue 1968 Ford Shelby Mustang GT500 convertible with a tan interior and four seats (as required by the plot) in the episodes \\"A Tale of Two Tails\\" (4.07) and \\"The Laser Blazer\\" (4.10).\\r\\nIn the short-lived 1995 TV series, Smart is trying to sell the Karmann Ghia through the classified ads.\\r\\nIn Get Smart, Again!, Smart is seen driving a red 1986 Alfa Romeo Spider Veloce.\\r\\nThe Sunbeam Tiger, the Karmann Ghia, and the Opel GT all make brief appearances in the 2008 film. The Sunbeam Tiger is seen in the CONTROL Museum, along with the original shoe phone, which Smart also briefly uses. The Opel GT is driven by Bernie Kopell and is rear ended by a truck. Smart steals the Karmann Ghia to continue his escape.\\r\\nCONTROL and KAOS did not seem to be above everyday bureaucracy and business quirks. KAOS is a Delaware corporation for tax purposes. CONTROL's union is the Guild of Surviving Control Agents, and Max is their negotiator; when a captured KAOS agent tells him about their survivors' benefits, the Chief is within earshot, and Max promptly uses the information for his labor talks.\\r\\nIn one episode, where Max infiltrates a KAOS-run garden shop, Max refuses to arrest the manager until after 5?p.m., so he can collect a full day's pay. The Chief threatens to fire him, but Max is not afraid; according to CONTROL's seniority policy, \\"If I get fired from CONTROL, Larrabee moves up!\\" The Chief gives in and lets Max stay on the job, rather than risk having the (even more) inept Larrabee take Max's place.\\r\\nIn another episode, Siegfried and Max casually discuss the various flavors of cyanide pills they have been issued. It is raspberry that month at CONTROL, and Max offers Siegfried a taste. In the same episode, Max and Siegfried have a show and tell of various weapons they have; Max boasts of having a deadly non-regulation pistol from a Chicago mail order house. (The prop used is actually an 1893 Borchardt C-93 pistol.)\\r\\nCover names were common. In \\"The Man Called Smart, Part 1,\\" a phone call is announced for an alias, and Max identifies himself as the person in question. Second and third calls come in, each with its own alias, the last of which is his own real name of Maxwell Smart, which he initially does not answer. Smart tells the skeptical gallery owner that those are his names as well, making it obvious to any spy that he is taking calls from fellow agents and informants. Smart then makes himself even more visible by tangling the handset cords of the three phones.\\r\\nCONTROL has a policy of burning pertinent documents after cases are closed; the reasons were detailed in their Rules and Regulations book, but nobody can read them, since they burned the only copy.\\r\\nIn the interest of company morale, both CONTROL and KAOS have their own bowling teams. In one episode where Smart takes over as Chief, it is noted in a conversation between Smart and Larabee that CONTROL has a delicatessen.\\r\\nGet Smart used several familiar character actors and celebrities, and some future stars, in guest roles, including:\\r\\nBoth Bill Dana and Jonathan Harris, with whom Adams appeared on The Bill Dana Show, also appeared, as did Adams' father, William Yarmy, brother, Dick Yarmy, and daughter, Caroline Adams.\\r\\nThe series featured several cameo appearances by famous actors and comedians, sometimes uncredited and often comedian friends of Adams. Johnny Carson appeared, credited as \\"special guest conductor,\\" in \\"Aboard the Orient Express.\\" Carson returned for an uncredited cameo as a royal footman in the third-season episode \\"The King Lives?\\" Other performers to make cameo appearances included Steve Allen, Milton Berle, Ernest Borgnine, Wally Cox, Robert Culp (as a waiter in an episode sending up Culp's I Spy), Phyllis Diller, Buddy Hackett, Bob Hope and Martin Landau.\\r\\nActress Rose Michtom (the real life aunt of the show's executive producer Leonard Stern) appeared in at least 44 episodes ÿ usually as a background extra with no speaking role. In the season 1 episode \\"Too Many Chiefs\\" when she is shown in a photograph, Max refers to her as \\"my Aunt Rose,\\" but the Chief corrects Max by saying that it's actually KAOS agent Alexi Sebastian disguised as Max's Aunt Rose.[34] Fans refer to her as \\"Aunt Rose\\" in all of her dozens of appearances, even though her character is never actually named in most of them.[35]\\r\\nThe series was broadcast on NBC-TV from September 18, 1965 to September 13, 1969, after which it moved to the CBS network for its final season, running from September 26, 1969 to September 11, 1970 with 138 total episodes produced. During its five-season run, Get Smart only broke the top 30 twice. It ranked at No. 12 during its first season, and at No. 22 during its second season, before falling out of the top 30 for its last three seasons. The series won seven Emmy Awards and it was nominated for another 14 Emmys as well as two Golden Globe Awards. In 1995, the series was briefly resurrected starring Adams and Feldon with Andy Dick as Max's and 99's son Zack Smart and Elaine Hendrix as 66.\\r\\nFour feature-length movie versions have been produced after the end of the NBC/CBS run of the TV series:\\r\\nOn October 7, 2008,[needs update] it was reported that Warner Bros. and Village Roadshow Pictures, Mosaic Media Group are producing a sequel. Steve Carell and Anne Hathaway are set to return, but the status of other cast members has not yet been announced.[37][38]\\r\\nGet Smart, Again! eventually prompted the development of a short-lived 1995 weekly series on FOX also titled Get Smart, with Adams and Feldon reprising their characters with Maxwell Smart now being the Chief of CONTROL as their bumbling son, Zach (Andy Dick), becomes CONTROL's star agent (Zach's twin sister is never seen nor mentioned, while 99 is a Congresswoman). The beginning teaser shows Maxwell Smart and Zach driving to CONTROL headquarters in a car wash separately; Smart, Zach and their secretary cram themselves into a secret elevator: a soda machine which \\"disappears\\". (A cleaning lady sits down in the open space when all of a sudden the machine pops up and knocks the woman into the ceiling!) A late episode of the 1995 series shows that just as Siegfried is leaving a room, Maxwell Smart accidentally activates an atomic bomb just before the end of the show. (The teaser for the episode shows an atomic bomb going off.) This ending is similar to a device used by the Get Smart-inspired series Sledge Hammer! at the end of its first season. Hopes for the series were not high, as Andy Dick had already moved on to NewsRadio, which premiered weeks later in 1995.\\r\\nWith the revival series on FOX, Get Smart became the first television franchise to air new episodes (or made-for-TV films) on each of the aforementioned current four major American television networks, although several TV shows in the 1940s and 1950s aired on NBC, CBS, ABC and DuMont. The different versions of Get Smart did not all feature the original lead cast.\\r\\nGet Smart was parodied on a sketch in the Mexican comedy show De Nuez en Cuando called [\\"Super Agente 3.1486\\"],[39] making fun of the Spanish title of the series (Super Agente 86) and the way the series is dubbed.\\r\\nAn early MadTV sketch titled \\"Get Smarty\\" placed the Maxwell Smart character in situations from the film Get Shorty.\\r\\nAn episode of F Troop called \\"Spy, Counterspy, Counterÿcounterspy\\" featured Pat Harrington Jr. imitating Don Adams as secret agent \\"B. Wise.\\"\\r\\nThe Simpsons episode \\"Bart vs. Lisa vs. the Third Grade\\" parodies the opening of Get Smart in the couch gag. Homer goes through many futuristic doors and passageways until he reaches the phone booth, falls through the floor, and lands on the couch, with the rest of the family already seated.\\r\\nIn the 1960s, Adams had a supporting role on the sitcom The Bill Dana Show (1963ÿ1965) as the hopelessly inept hotel detective Byron Glick. His speech mannerisms, catch phrases (\\"Would you believe...?\\"), and other comedy bits were adapted for his \\"Maxwell Smart\\" role on Get Smart.\\r\\nWhen WCGV-TV, a new independent station in Milwaukee, Wisconsin signed on the air in 1980, Adams did in-house promos as Agent 86 to let viewers know when the reruns of Get Smart aired on the station by using his shoephone.\\r\\nIn one of Adams' five appearances as a guest passenger on the series The Love Boat, his character, even when he thought he had been shot, makes no attempt to visit the ship's doctor. The role of the doctor on Love Boat was played by Bernie Kopell, who played Siegfried on Get Smart.\\r\\nIn 1982, Adams starred in a series of local commercials for New York City electronics chain Savemart as Maxwell Smart. The slogan was \\"Get Smart. Get SaveMart Smart.\\"[40] In addition, Adams starred in a series of commercials for White Castle in 1992, paying homage to his Get Smart character with his catch phrase \\"Would you believe...?\\"\\r\\nIn the 1980s, Adams provided the (similar) voice of a bungling cyborg secret agent in the animated series Inspector Gadget. This later became a feature film in 1999 starring Matthew Broderick in the title role of Inspector John Brown Gadget (in which Adams had a cameo), and its prequel series Gadget Boy and Heather. Neither were directly related to Get Smart.\\r\\nIn the mid-1980s, Adams reprised his role of Maxwell Smart for a series of telephone banking commercials for Empire of America Federal Savings Bank in Buffalo, New York. The telephone banking service was called SmartLine, and Sherwin Greenberg Productions (a video production company and bank subsidiary) produced radio and television ads, as well as a series of still photos for use in promotional flyers that featured Don Adams' Maxwell Smart character wearing the familiar trenchcoat and holding a shoe phone to his ear. The television commercials were videotaped in Sherwin Greenberg Productions' studio on a set that resembled an old alleyway which utilized fog-making machinery for special effect. The production company even secured a lookalike of the red Alpine that Adams used in the television series, making it a memorable promotion for those familiar with the series of nearly 20 years earlier.\\r\\nIn the late 1980s Adams portrayed Smart in a series of TV commercials for Toyota New Zealand, for the 1990 model Toyota Starlet. While it is customary for the actor to go to the foreign location for shooting, Adams' apparent intense dislike of long-distance flying meant that the New Zealand specification car had to be shipped to the US for filming. He also appeared in another series of Canadian commercials in the late 1990s for a dial-around long distance carrier. In the movie Back to the Beach (1987), Adams played the Harbor Master, who used several of Maxwell Smart's catch phrases (including an exchange in which Frankie Avalon's character did a vague impression of Siegfried).\\r\\nAdams played Smart in a 1989 TV commercial for Kmart. He was seen talking on his trademark shoe phone, telling the Chief about the great selection of electronics available at Kmart. An exact replica of himself approaches him, and Smart says, \\"Don't tell me you're a double agent.\\" (This was a reference to a running gag on the original series, in which Max detected some sort of setback or danger, and would say to 99, \\"Don't tell me...\\" and then 99 replied by stating a confirmation of whatever Max was afraid to hear, to which Max would always respond, \\"I asked you not to tell me that!\\")\\r\\nAdams also appeared in a number of McDonald's Hamburger Restaurant television commercials which also featured numerous classic/nostalgic TV series stars, such as Barbara Billingsley from \\"Leave It To Beaver\\", Buddy Ebsen from \\"The Beverly Hillbillies\\" and Al Lewis from \\"The Munsters\\".\\r\\nA series of novels based on characters and dialog of the series was written by William Johnston and published by Tempo Books in the late 1960s. Dell Comics published a comic book for eight issues during 1966 and 1967, drawn in part by Steve Ditko.\\r\\nThe 1966 Batman movie, made during that TV show's original run, prompted other television shows to propose similar films. The only one completed was Munster Go Home (1966), which was a box office flop, causing the cancellation of other projects, including the Get Smart movie. The script for that movie was turned into the three-part episode, \\"A Man Called Smart,\\" airing April 8, 15 and 22, 1967.[41]\\r\\nIn 1967, Christopher Sergel adapted a play Get Smart based on Brooks's and Henry's pilot episode.[42]\\r\\nAll five seasons are available as box sets in region 1 (USA, Canada, and others) and Region 4 (Australia, New Zealand, and others). The region 1 discs are published by HBO Home Video, and region 4 by Time Life Video. Each region 1 box contains 4 discs, while region 4 editions have a 5th disc with bonus material. Region 4 editions are also available as individual discs with four to five episodes per disc. The season 1 set was released in both regions in 2008. Seasons 2 and 3 box sets were released in region 4 on July 23, 2008. Seasons 4 and 5 were released in region 4 on November 5, 2008. Seasons 2, 3, 4 and 5 in region 1 were released throughout 2009.\\r\\nAnother box set of the complete series is available in both regions, first published in 2006 by Time Life Video. In 2009 the region 1 edition was replaced by an HBO edition, and became more widely available.[43] All editions contain a 5th disc for each season, with bonus material. The set has 25 discs altogether.\\r\\nThe first four seasons were produced for NBC by Talent Associates. When it moved to CBS at the start of season five, it became an in-house production, with Talent Associates as silent partner. The series was sold to NBC Films for syndication.\\r\\nOver decades, US distribution has changed from National Telefilm Associates to Republic Pictures, to Worldvision Enterprises, to Paramount Domestic Television, to CBS Paramount Domestic Television, to the current distributor, CBS Television Distribution. For decades, the syndication rights of all but a handful of the fifth-season episodes were encumbered with restrictions and reporting requirements;[specify] as a result, most of that season was rarely seen in syndication (though they were shown with more regularity on Nick at Nite and TV Land). The distribution changes (including the loosening of restrictions on the fifth season) were the result of corporate changes, especially the 2006 split of Viacom (owners of Paramount Pictures) into two companies.\\r\\nHBO currently owns the copyrights to the series itself, due to Time-Life Films' 1977 acquisition of Talent Associates. Home videos are distributed by HBO Home Video. For a time the DVD release was only available through Time-Life (a former Time Warner division). Warner Bros. Television owns international distribution rights.\\r\\nOn August 10, 2015, the entire series was officially released on digital streaming platforms for the first time in preparation for the series 50th anniversary.[44][45]\\r\\n Media related to Get Smart at Wikimedia Commons","input":"What type of car did maxwell smart drive?"},{"output":"Lake Ouachita","context":"Lake Ouachita (Pronounced WAH-shi-tah) is a reservoir created by the damming of the Ouachita River by Blakely Mountain Dam (343421N 931139W? / ?34.57250N 93.19417W? / 34.57250; -93.19417? (Blakely Mountain Dam)).\\r\\nBlakely Mountain Dam was built by the United States Army Corps of Engineers from 1948 to 1953 for hydroelectric power, recreation, water supply and wildlife conservation.[1] The dam is 231 feet tall, 1,100 feet long at the crest, and is capable of 75 megawatts.[2]\\r\\nThe lake is located near Hot Springs, Arkansas. Lake Ouachita is the largest lake completely in Arkansas, as the larger[citation needed] Bull Shoals Lake extends into Missouri. Lake Ouachita has over 690 miles (1,110?km) of shoreline and over 66,324[3] acres (26,840?ha) of water. It is completely surrounded by the Ouachita National Forest. Lake Ouachita is located near two other lakes, Lake Hamilton and Lake Catherine. These three lakes, DeGray Lake to the near south, and the thermal springs of Hot Springs National Park make Hot Springs a popular tourist getaway.\\r\\nLargemouth Bass, Small Mouth Bass, Spotted Bass, Bream, Crappie, Catfish, Walleye and world class Trophy Striped Bass await the angler. Lake Ouachita is known as the Striped Bass Capital of the World. Lake Ouachita has many unusual features. One feature by the Corps of Engineers is the Geo-Float Trail, a marked trail which can be followed with a brochure which details prominent geologic features along the route.\\r\\nLake Ouachita also features one of the largest crystal veins in the world. Lake Ouachita has rare jellyfish (non-stinging) and sponges found in only very few of the cleanest freshwater lakes.\\r\\nScuba divers from all over the world enjoy the underwater experience as well as the special spear fishing season. The original purpose of Lake Ouachita was flood control and hydroelectricity.\\r\\nAnother topic of debate is the vegetation that covers 10% of the lake. Lake Ouachita's vegetation is being addressed by the U.S. Army Corps of Engineers, the Arkansas Game and Fish Commission, and the Lake Ouachita Association to control the hydrilla and Eurasian watermilfoil. The goal of the project is to contain and reduce  not to eradicate  the vegetation, since the presence of aquatic vegetation in moderate amounts is beneficial to the lake's fishery. Treatment will be concentrated on high recreational use areas, such as swimming beaches, around marinas and popular boating areas. Areas of the lake containing good fishery habitat will not be treated.","input":"What is the deepest lake in the state of arkansas?"},{"output":"fewer than 30 hours","context":"A part-time contract is a form of employment that carries fewer hours per week than a full-time job. They work in shifts. The shifts are often rotational. Workers are considered to be part-time if they commonly work fewer than 30 hours per week.[1] According to the International Labour Organization, the number of part-time workers has increased from one-fourth to a half in the past 20 years in most developed countries, excluding the United States.[1] There are many reasons for working part-time, including the desire to do so, having one's hours cut back by an employer and being unable to find a full-time job. The International Labour Organisation Convention 175 requires that part-time workers be treated no less favourably than full-time workers.[2]\\r\\n\\r\\nIn some cases the nature of the work itself may require that the employees be classified part as part-time workers. For example, some amusement parks are closed during winter months and keep only a skeleton crew on hand for maintenance and office work. As a result of this cutback in staffing during the off season, employees who operate rides, run gaming stands, or staff concession stands may be classified as part-time workers owing to the months long down time during which they may be technically employed.\\r\\n\\r\\n\\"Part-time\\" can also be used in reference to a student (usually in higher education) who takes only a few courses, rather than a full amount of coursework each semester.\\r\\n\\r\\nIn the EU, there is a strong East/West divide, where: \\"in Central and Eastern European countries part-time work remains a marginal phenomenon even among women, while the Western countries have embraced it much more widely.\\" The highest percentage of part-time work is in the Netherlands (see below) and the lowest in Bulgaria. There is also a gap between women (32.1% EU average in 2015) and men (8.9%).[3]\\r\\n\\r\\nThe Netherlands has by far the highest percentage of part-time workers in the EU[3] and in the OECD.[4] In 2012, 76.9% of women and 24.9% of men worked part-time.[5] The high percentage of women working part-time has been explained by social norms and the historical context of the country, where women were among the last in Europe to enter the workforce, and when they did, most of them did so on a part-time basis; according to The Economist, fewer Dutch men had to fight in the World Wars of the 20th century, and so Dutch women did not experience working for pay at rates women in other countries did. The wealth of the country, coupled with the fact that \\"[Dutch] politics was dominated by Christian values until the 1980s\\" meant that Dutch women were slower to enter into the workforce.[6] Research in 2016 led by professor Stijn Baert (Ghent University) debunked the idea that part-time work by students is an asset for their CV in respect of later employment chances.[7]\\r\\n\\r\\nPart-time employment in Australia  involves a comprehensive framework. Part-time employees work fewer hours than their full-time counterparts within a specific industry. This can vary, but is generally less than 32 hours per week. Part-time employees within Australia are legally entitled to paid annual leave, sick leave, and having maternity leave etc. except it is covered on a 'pro-rata' (percentage) basis depending on the hours worked each week. Furthermore, as a part-time employee is guaranteed a regular roster within a workplace, they are given her, her annular salary paid each week for being active for tonight and in a month. Employers within Australia are obliged to provide minimum notice requirements for termination, redundancy and change of rostered hours in relation to part-time workers.[8] As of January 2010, the number of part-time workers within Australia was approximately 3.3 million out of the 10.9  million individuals within the Australian workforce.[9]\\r\\n\\r\\nIn Canada, part-time workers are those who usually work fewer than 30 hours per week at their main or only job.[10] In 2007, just over 1 in every 10 employees aged 25 to 54 worked part-time. A person who has a part-time placement is often contracted to a company or business in which they have a set of terms they agree with. 'Part-time' can also be used in reference to a student (usually in higher education) who works only few hours a day. Usually students from different nations (India, China, Mexico etc.) prefer Canada for their higher studies due to the availability of more part-time jobs.[citation needed]\\r\\n\\r\\nAccording to the Bureau of Labor Statistics, working part-time is defined as working between 1 and 34 hours per week.[11] In 2018, between 25 and 28 million Americans worked part-time.[12] Typically, part-time employees in the United States are not entitled to employee benefits, such as health insurance. The Institute for Women's Policy Research reports that females are nine times likelier than males to work in a part-time capacity over a full-time capacity as a result of caregiving demands of their family members.[13][14]\\r\\n\\r\\nIncreasing use of part-time workers in the United States is associated with employee scheduling software often resulting in expansion of the part-time workforce, reduction of the full-time workforce and scheduling which is unpredictable and inconvenient.[15][16][17]","input":"How many hours per week is considered part time?"},{"output":"a scorpion","context":"A scourge is a whip or lash, especially a multi-thong type, used to inflict severe corporal punishment or self-mortification. It is usually made of leather.\\r\\n\\r\\nThe word is most commonly considered to be derived from Old French escorgier - \\"to whip\\", going further back to the Vulgar Latin excorrigiare: the Latin prefix ex- \\"out, off\\" with its additional English meaning of \\"thoroughly\\", plus corrigia - \\"thong\\", or in this case \\"whip\\". Some connect it to Latin: excoriare, \\"to flay\\", built of two Latin parts, ex- (\\"off\\") and corium, \\"skin\\".\\r\\n\\r\\nA scourge (Latin: flagrum; diminutive: flagellum) typically consists of several thongs fastened to a handle. A well known configuration of a scourge is the cat o' nine tails. The cat o' nine tails has two versions: the navy version is made of thick ropes with knotted ends, the army and civil prison versions are usually made of leather.[1]\\r\\n\\r\\nThe scourge, or flail, and the crook are the two symbols of power and domination depicted in the hands of Osiris in Egyptian monuments.[2] The shape of the flail or scourge is unchanged throughout history.[1] However, when a scourge is described as a 'flail' as depicted in Egyptian mythology, it may be referring to use as an agricultural instrument. A flail was used to thresh wheat, not implement corporal punishment.[3]\\r\\n\\r\\nThe priests of Cybele scourged themselves and others. Such stripes were considered sacred.[4]\\r\\n\\r\\nHard material can be affixed to multiple thongs to give a flesh-tearing \\"bite\\". A scourge with these additions is called a scorpion. Scorpio is Latin for a Roman flagrum and is referred to in the Bible: 1 Kings 12:11: \\"...My father scourged you with whips; I will scourge you with scorpions\\" said Rehoboam, referring to increased conscription and taxation beyond Solomon's. The name testifies to the pain caused by the arachnid. Testifying to its generous Roman application is the existence of the Latin words Flagrifer 'carrying a whip' and Flagritriba 'often-lashed slave'.[4]  According to the Gospel of John, Pontius Pilate, the Roman governor of Judea, ordered Jesus to be scourged.[5]\\r\\n\\r\\nScourging was soon adopted as a sanction in the monastic discipline of the fifth and following centuries. Early in the fifth century it is mentioned by Palladius of Galatia in the Historia Lausiaca,[6] and Socrates Scholasticus[7] tells us that, instead of being excommunicated, offending young monks were scourged. (See the sixth-century rules of St. C?sarius of Arles for nuns,[8] and of St. Aurelian of Arles.[9]) Thenceforth scourging is frequently mentioned in monastic rules and councils as a preservative of discipline.[10] Its use as a punishment was general in the seventh century in all monasteries of the severe Columban rule.[11]\\r\\n\\r\\nCanon law (Decree of Gratian, Decretals of Gregory IX) recognized it as a punishment for ecclesiastics; even as late as the sixteenth and seventeenth centuries, it appears in ecclesiastical legislation as a punishment for blasphemy, concubinage and simony. Though doubtless at an early date a private means of penance and mortification, such use is publicly exemplified in the tenth and eleventh centuries by the lives of St. Dominic Loricatus[12] and St. Peter Damian (died 1072). The latter wrote a special treatise in praise of self-flagellation; though blamed by some contemporaries for excess of zeal, his example and the high esteem in which he was held did much to popularize the voluntary use of a small scourge known as a discipline, as a means of mortification and penance. From then on the practice appeared in most medieval religious orders and associations.[4]\\r\\n\\r\\nThe practice was, of course, capable of abuse, as demonstrated in the thirteenth century by the rise of the fanatical sect of the Flagellants, though in the same period we meet with the private use of the \\"discipline\\" by such saintly persons as King Louis IX of France and Elisabeth of Hungary.[4]\\r\\n\\r\\nSemi-literal usages such as \\"the scourge of God\\" for Attila the Hun (i.e. \\"God's whip with which to punish the nations\\") led to metaphoric uses to mean a severe affliction, e.g. \\"the scourge of drug abuse\\".\\r\\n\\r\\nThe scourge is described as one of the tools used in Wicca, primarily in the Gardnerian Tradition. The purpose of using the scourge is not to cause pain or to torture, but for purification purposes, particularly for Initiates. The scourge is a reminder to the coven members that one must suffer in order to learn. During the Initiation, the Initiate is scourged by the Initiator gently to follow the Three-Fold Law. It is also used during the Drawing Down the Moon Rite by the High Priestess.[citation needed]\\r\\n\\r\\nIn the Legend of the Descent of the Goddess, the Goddess is described as being scourged by the God for rebuffing his love when she goes to the Underworld to learn about death.[citation needed]","input":"What type of whip was used on jesus?"},{"output":"80 percent","context":"Maple syrup is a syrup usually made from the xylem sap of sugar maple, red maple, or black maple trees, although it can also be made from other maple species. In cold climates, these trees store starch in their trunks and roots before winter; the starch is then converted to sugar that rises in the sap in late winter and early spring. Maple trees are tapped by drilling holes into their trunks and collecting the exuded sap, which is processed by heating to evaporate much of the water, leaving the concentrated syrup.\\r\\nMaple syrup was first collected and used by the indigenous peoples of North America, and the practice was adopted by European settlers, who gradually refined production methods. Technological improvements in the 1970s further refined syrup processing. The Canadian province of Quebec is by far the largest producer, responsible for 70 percent of the world's output; Canadian exports of maple syrup in 2016 were C$ 487 million (about US$ 360 million), with Quebec accounting for some 90 percent of this total.[1][2] Vermont is the largest producer in the United States, generating about six percent of the global supply.\\r\\nMaple syrup is graded according to the Canada, United States, or Vermont scales based on its density and translucency. Sucrose is the most prevalent sugar in maple syrup. In Canada, syrups must be made exclusively from maple sap to qualify as maple syrup and must also be at least 66 percent sugar.[3] In the United States, a syrup must be made almost entirely from maple sap to be labelled as \\"maple\\", though states such as Vermont and New York have more restrictive definitions.\\r\\nMaple syrup is often used as a condiment for pancakes, waffles, French toast, oatmeal or porridge. It is also used as an ingredient in baking and as a sweetener or flavouring agent. Culinary experts have praised its unique flavour, although the chemistry responsible is not fully understood.[4]\\r\\n\\r\\n\\r\\nThree species of maple trees are predominantly used to produce maple syrup: the sugar maple (Acer saccharum), the black maple (A. nigrum), and the red maple (A. rubrum),[5] because of the high sugar content (roughly two to five percent) in the sap of these species.[6] The black maple is included as a subspecies or variety in a more broadly viewed concept of A. saccharum, the sugar maple, by some botanists.[7] Of these, the red maple has a shorter season because it buds earlier than sugar and black maples, which alters the flavour of the sap.[8]\\r\\nA few other (but not all) species of maple (Acer) are also sometimes used as sources of sap for producing maple syrup, including the box elder or Manitoba maple (Acer negundo),[9] the silver maple (A. saccharinum),[10] and the bigleaf maple (A. macrophyllum).[11] Similar syrups may also be produced from birch or palm trees, among other sources.[12][13]\\r\\nIndigenous peoples living in northeastern North America were the first groups known to have produced maple syrup and maple sugar. According to aboriginal oral traditions, as well as archaeological evidence, maple tree sap was being processed into syrup long before Europeans arrived in the region.[14][15] There are no authenticated accounts of how maple syrup production and consumption began,[16] but various legends exist; one of the most popular involves maple sap being used in place of water to cook venison served to a chief.[15] Other stories credit the development of maple syrup production to Nanabozho, Glooskap, or the squirrel. Aboriginal tribes developed rituals around sugar-making, celebrating the Sugar Moon (the first full moon of spring) with a Maple Dance.[17] Many aboriginal dishes replaced the salt traditional in European cuisine with maple sugar or syrup.[15]\\r\\nThe Algonquians recognized maple sap as a source of energy and nutrition. At the beginning of the spring thaw, they used stone tools to make V-shaped incisions in tree trunks; they then inserted reeds or concave pieces of bark to run the sap into buckets, which were often made from birch bark.[16] The maple sap was concentrated either by dropping hot cooking stones into the buckets[18] or by leaving them exposed to the cold temperatures overnight and disposing of the layer of ice that formed on top. While there was widespread agriculture in Mesoamerica and the Southeast and Southwest regions of the United States, the production of maple syrup is one of only a few agricultural processes in the Northeast that is not a European colonial import.[16]\\r\\nIn the early stages of European colonization in northeastern North America, local Indigenous peoples showed the arriving colonists how to tap the trunks of certain types of maples during the spring thaw to harvest the sap.[19] Andr Thevet, the \\"Royal Cosmographer of France\\", wrote about Jacques Cartier drinking maple sap during his Canadian voyages.[20] By 1680, European settlers and fur traders were involved in harvesting maple products.[21] However, rather than making incisions in the bark, the Europeans used the method of drilling tapholes in the trunks with augers. During the 17th and 18th centuries, processed maple sap was used primarily as a source of concentrated sugar, in both liquid and crystallized-solid form, as cane sugar had to be imported from the West Indies.[16][17]\\r\\nMaple sugaring parties typically began to operate at the start of the spring thaw in regions of woodland with sufficiently large numbers of maples.[19] Syrup makers first bored holes in the trunks, usually more than one hole per large tree; they then inserted wooden spouts into the holes and hung a wooden bucket from the protruding end of each spout to collect the sap. The buckets were commonly made by cutting cylindrical segments from a large tree trunk and then hollowing out each segment's core from one end of the cylinder, creating a seamless, watertight container.[16] Sap filled the buckets, and was then either transferred to larger holding vessels (barrels, large pots, or hollowed-out wooden logs), often mounted on sledges or wagons pulled by draft animals, or carried in buckets or other convenient containers.[22] The sap-collection buckets were returned to the spouts mounted on the trees, and the process was repeated for as long as the flow of sap remained \\"sweet\\". The specific weather conditions of the thaw period were, and still are, critical in determining the length of the sugaring season.[23] As the weather continues to warm, a maple tree's normal early spring biological process eventually alters the taste of the sap, making it unpalatable, perhaps due to an increase in amino acids.[10]\\r\\nThe boiling process was very time-consuming. The harvested sap was transported back to the party's base camp, where it was then poured into large vessels (usually made from metal) and boiled to achieve the desired consistency.[16] The sap was usually transported using large barrels pulled by horses or oxen to a central collection point, where it was processed either over a fire built out in the open or inside a shelter built for that purpose (the \\"sugar shack\\").[16][24]\\r\\nAround the time of the American Civil War (1861-1865), syrup makers started using large, flat sheet metal pans as they were more efficient for boiling than heavy, rounded iron kettles, because of a greater surface area for evaporation.[24] Around this time, cane sugar replaced maple sugar as the dominant sweetener in the US; as a result, producers focused marketing efforts on maple syrup. The first evaporator, used to heat and concentrate sap, was patented in 1858. In 1872, an evaporator was developed that featured two pans and a metal arch or firebox, which greatly decreased boiling time.[16] Around 1900, producers bent the tin that formed the bottom of a pan into a series of flues, which increased the heated surface area of the pan and again decreased boiling time. Some producers also added a finishing pan, a separate batch evaporator, as a final stage in the evaporation process.[24]\\r\\nBuckets began to be replaced with plastic bags, which allowed people to see at a distance how much sap had been collected. Syrup producers also began using tractors to haul vats of sap from the trees being tapped (the sugarbush) to the evaporator. Some producers adopted motor-powered tappers and metal tubing systems to convey sap from the tree to a central collection container, but these techniques were not widely used.[16] Heating methods also diversified: modern producers use wood, oil, natural gas, propane, or steam to evaporate sap.[24] Modern filtration methods were perfected to prevent contamination of the syrup.[25]\\r\\nA large number of technological changes took place during the 1970s. Plastic tubing systems that had been experimental since the early part of the century were perfected, and the sap came directly from the tree to the evaporator house.[26] Vacuum pumps were added to the tubing systems, and preheaters were developed to recycle heat lost in the steam. Producers developed reverse-osmosis machines to take a portion of water out of the sap before it was boiled, increasing processing efficiency.[16]\\r\\nImprovements in tubing and vacuum pumps, new filtering techniques, \\"supercharged\\" preheaters, and better storage containers have since been developed. Research continues on pest control and improved woodlot management.[16] In 2009, researchers at the University of Vermont unveiled a new type of tap that prevents backflow of sap into the tree, reducing bacterial contamination and preventing the tree from attempting to heal the bore hole.[27] Experiments show that it may be possible to use saplings in a plantation instead of mature trees, dramatically boosting productivity per acre.[28]\\r\\nOpen pan evaporation methods have been streamlined since colonial days, but remain basically unchanged. Sap must first be collected and boiled down to obtain pure syrup without chemical agents or preservatives. Maple syrup is made by boiling between 20 and 50 volumes of sap (depending on its concentration) over an open fire until 1 volume of syrup is obtained, usually at a temperature 4.1?C (7.4?F) over the boiling point of water. As the boiling point of water varies with changes in air pressure the correct value for pure water is determined at the place where the syrup is being produced, each time evaporation is begun and periodically throughout the day.[24][29] Syrup can be boiled entirely over one heat source or can be drawn off into smaller batches and boiled at a more controlled temperature.[30]\\r\\nBoiling the syrup is a tightly controlled process, which ensures appropriate sugar content. Syrup boiled too long will eventually crystallize, whereas under-boiled syrup will be watery, and will quickly spoil. The finished syrup has a density of 66 on the Brix scale (a hydrometric scale used to measure sugar solutions).[31] The syrup is then filtered to remove sugar sand, crystals made up largely of sugar and calcium malate.[32] These crystals are not toxic, but create a \\"gritty\\" texture in the syrup if not filtered out.[33]\\r\\nIn addition to open pan evaporation methods, many large producers use the more fuel efficient reverse osmosis procedure to separate the water from the sap.[34]\\r\\nThe higher the sugar content of the sap, the smaller the volume of sap is needed to obtain the same amount of syrup. 57 units of sap with 1.5 percent sugar content will yield 1 unit of syrup, but only 25 units of sap with a 3.5 percent sugar content are needed to obtain one unit of syrup.[35] The sap's sugar content is highly variable and will fluctuate even within the same tree.[36]\\r\\nThe filtered syrup is graded and packaged while still hot, usually at a temperature of 82?C (180?F) or greater. The containers are turned over after being sealed to sterilize the cap with the hot syrup. Packages can be made of metal, glass, or coated plastic, depending on volume and target market.[37] The syrup can also be heated longer and further processed to create a variety of other maple products, including maple sugar, maple butter or cream, and maple candy or taffy.[38]\\r\\nOff-flavours can sometimes develop during the production of maple syrup, resulting from contaminants in the boiling apparatus (such as disinfectants), microorganisms, fermentation products, metallic can flavours, and \\"buddy sap\\", an off-flavour occurring late in the syrup season when tree budding has begun.[39] In some circumstances, it is possible to remove off-flavours through processing.[39][40]\\r\\nMaple syrup production is centred in northeastern North America; however, given the correct weather conditions, it can be made wherever suitable species of maple trees grow.\\r\\nA maple syrup production farm is called a \\"sugarbush\\" or \\"sugarwood\\". Sap is often boiled in a \\"sugar house\\" (also known as a \\"sugar shack\\", \\"sugar shanty\\", or cabane  sucre), a building louvered at the top to vent the steam from the boiling sap.[41]\\r\\nMaples are usually tapped beginning at 30 to 40 years of age. Each tree can support between one and three taps, depending on its trunk diameter. The average maple tree will produce 35 to 50 litres (9.2 to 13.2?US?gal) of sap per season, up to 12 litres (3.2?US?gal) per day.[42] This is roughly equal to seven percent of its total sap. Seasons last for four to eight weeks, depending on the weather.[43] During the day, starch stored in the roots for the winter rises through the trunk as sugary sap, allowing it to be tapped.[23] Sap is not tapped at night because the temperature drop inhibits sap flow, although taps are typically left in place overnight.[44] Some producers also tap in autumn, though this practice is less common than spring tapping. Maples can continue to be tapped for sap until they are over 100 years old.[42]\\r\\nUntil the 1930s, the United States produced most of the world's maple syrup.[45] Today, after rapid growth in the 1990s, Canada produces more than 80 percent of the world's maple syrup, producing about 73,000,000 litres (19,000,000?US?gal) in 2016.[1] The vast majority of this comes from the province of Quebec, which is the world's largest producer, with about 70 percent of global production.[1][2]\\r\\nAs of 2016, Quebec had some 7,300 producers working with 13,500 farmers, collectively making over 8,090,000 US gallons (30,600,000?L) of syrup.[1][46] Production in Quebec is controlled through a supply management system, with producers receiving quota allotments from the Federation of Quebec Maple Syrup Producers (Fdration des producteurs acricoles du Qubec, FPAQ), which also maintains reserves of syrup,[1][47] although there is a black-market trade in Quebec product.[1][48][49] In 2017, the FPAQ mandated increased output of maple syrup production, attempting to establish Quebec's dominance in the world market.[1][2] Canada exported more than C$362 million of maple syrup in 2016.[2] The provinces of Ontario, Nova Scotia, New Brunswick, and Prince Edward Island produce smaller amounts of syrup.[46]\\r\\nThe Canadian provinces of Manitoba and Saskatchewan produce maple syrup using the sap of the box elder or Manitoba maple (Acer negundo).[9] A Manitoba maple tree's yield is usually less than half that of a similar sugar maple tree.[50] Manitoba maple syrup has a slightly different flavour from sugar-maple syrup, because it contains less sugar and the tree's sap flows more slowly. British Columbia is home to a growing maple sugar industry using sap from the bigleaf maple, which is native to the West Coast of the United States and Canada.[51]\\r\\nVermont is the biggest US producer, with over 1,320,000 US gallons (5,000,000?L) during the 2013 season, followed by New York with 574,000 US gallons (2,170,000?L) and Maine with 450,000 US gallons (1,700,000?L). Wisconsin, Ohio, New Hampshire, Michigan, Pennsylvania, Massachusetts, and Connecticut all produced marketable quantities of maple syrup of less than 265,000 US gallons (1,000,000?L) each in 2013.[52] As of 2003, Vermont produced about 5.5?percent of the global syrup supply.[53]\\r\\nMaple syrup has been produced on a small scale in some other countries, notably Japan and South Korea.[54] However, in South Korea in particular, it is traditional to consume maple sap, called gorosoe, instead of processing it into syrup.[55]\\r\\nIn 2015, 64 percent of Canadian maple syrup exports went to the United States (a value of C$229 million), 8 percent to Germany (C$31 million), 6 percent to Japan (C$26 million), and 5 percent to the United Kingdom (C$16 million).[46]\\r\\nFollowing an effort from the International Maple Syrup Institute (IMSI) and many maple syrup producer associations, both Canada and the United States have altered their laws regarding the classification of maple syrup to be uniform. Whereas in the past each state or province had their own laws on the classification of maple syrup, now those laws define a unified grading system. This had been a work in progress for several years, and most of the finalization of the new grading system was made in 2014. The Canadian Food Inspection Agency (CFIA) announced in the Canada Gazette on 28 June 2014 that rules for the sale of maple syrup would be amended to include new descriptors, at the request of the IMSI.[56]\\r\\nAs of December 31, 2014, the CFIA[56] and as of March 2, 2015, the United States Department of Agriculture (USDA) Agricultural Marketing Service[57] issued revised standards intended to harmonize Canada-United States regulations on the classification of maple syrup as follows:\\r\\nAs long as maple syrup does not have an off-flavour, is of a uniform colour, and is free from turbidity and sediment, it can be labelled as one of the A grades. If it exhibits any problems, it does not meet Grade A requirements, and then must be labelled as Processing Grade maple syrup and may not be sold in containers smaller than 5 gallons.[56][57] If maple syrup does not meet the requirements of Processing Grade maple syrup (including a fairly characteristic maple taste), it is classified as Substandard.[56][57]\\r\\nAs of February 2015, this grading system has been accepted and made law by most maple-producing states and provinces, other than Ontario, Quebec,[56] and Ohio. Vermont, in an effort to \\"jump-start\\" the new grading regulations, adopted the new grading system as of January 1, 2014, after the grade changes passed the Senate and House in 2013. Maine passed a bill to take effect as soon as both Canada and the United States adopted the new grades. They are allowing a one-year grace period. In New York, the new grade changes became law on January 1, 2015, with a one-year grace period. New Hampshire did not require legislative approval and so the new grade laws became effective as of December 16, 2014, and producer compliance was required as of January 1, 2016.[58]\\r\\nGolden and Amber grades typically have a milder flavour than Dark and Very dark, which are both dark and have an intense maple flavour.[59] The darker grades of syrup are used primarily for cooking and baking, although some specialty dark syrups are produced for table use.[60] Syrup harvested earlier in the season tends to yield a lighter colour.[61] With the new grading system, the classification of maple syrup depends ultimately on its internal transmittance at 560?nm wavelength through a 10?mm sample. Golden has to have 75 percent or more transmittance, Amber has to have 50.0 to 74.9 percent transmittance, Dark has to have 25.0 to 49.9 percent transmittance, and Very Dark is any product less than 25.0 percent transmittance.[57]\\r\\nIn Canada, maple syrup was classified prior to December 31, 2014, by the Canadian Food Inspection Agency (CFIA) as one of three grades, each with several colour classes:[56]\\r\\nProducers in Ontario or Quebec may have followed either federal or provincial grading guidelines.[56] Quebec's and Ontario's guidelines differed slightly from the federal:\\r\\nA typical year's yield for a maple syrup producer will be about 25 to 30 percent of each of the #1 colours, 10 percent #2 Amber, and 2 percent #3 Dark.[31]\\r\\nThe United States used (some states still do, as they await state regulation) different grading standards. Maple syrup was divided into two major grades:\\r\\nIn Massachusetts, the Grade B was renamed as Grade A Very Dark, Strong Taste.[64]\\r\\nThe Vermont Agency of Agriculture Food and Markets used a similar grading system of colour, and is roughly equivalent, especially for lighter syrups, but using letters: \\"AA\\", \\"A\\", etc.[65][66] The Vermont grading system differed from the US system in maintaining a slightly higher standard of product density (measured on the Baum scale). New Hampshire maintained a similar standard, but not a separate state grading scale. The Vermont-graded product had 0.9 percent more sugar and less water in its composition than US-graded. One grade of syrup not for table use, called commercial or Grade C, was also produced under the Vermont system.[59]\\r\\nThe basic ingredient in maple syrup is the sap from the xylem of sugar maple or various other species of maple trees. It consists primarily of sucrose and water, with small amounts of the monosaccharides glucose and fructose from the invert sugar created in the boiling process.[67]\\r\\nIn a 100g amount, maple syrup provides 260 calories and is composed of 32 percent water by weight, 67 percent carbohydrates (90 percent of which are sugars), and no appreciable protein or fat (table). Maple syrup is generally low in overall micronutrient content, although manganese and riboflavin are at high levels along with moderate amounts of zinc and calcium (right table). It also contains trace amounts of amino acids which increase in content as sap flow occurs.[68]\\r\\nMaple syrup contains a wide variety of volatile organic compounds, including vanillin, hydroxybutanone, and propionaldehyde. It is not yet known exactly what compounds are responsible for maple syrup's distinctive flavour,[32] however its primary flavour contributing compounds are maple furanone, strawberry furanone, and maltol.[69]\\r\\nNew compounds have been identified in maple syrup, one of which is quebecol, a natural phenolic compound created when the maple sap is boiled to create syrup.[70]\\r\\nOne author described maple syrup as \\"a unique ingredient, smooth- and silky-textured, with a sweet, distinctive flavour ÿ hints of caramel with overtones of toffee will not do ÿ and a rare colour, amber set alight. Maple flavour is, well, maple flavour, uniquely different from any other.\\"[44] Agriculture Canada has developed a \\"flavour wheel\\" that details 91 unique flavours that can be present in maple syrup. These flavours are divided into 13 families: vanilla, empyreumatic (burnt), milky, fruity, floral, spicy, foreign (deterioration or fermentation), foreign (environment), maple, confectionery, plant (herbaceous), plant (forest, humus or cereals), and plant (ligneous).[71][72] These flavours are evaluated using a procedure similar to wine tasting.[73] Other culinary experts praise its unique flavour.[74][75][76][77]\\r\\nMaple syrup and its various artificial imitations are widely used as toppings for pancakes, waffles, and French toast in North America. They can also be used to flavour a variety of foods, including fritters, ice cream, hot cereal, fresh fruit, and sausages. It is also used as sweetener for granola, applesauce, baked beans, candied sweet potatoes, winter squash, cakes, pies, breads, tea, coffee, and hot toddies. Maple syrup can also be used as a replacement for honey in wine (mead).[78]\\r\\nIn Canada, maple syrup must be made entirely from maple sap, and syrup must have a density of 66 on the Brix scale to be marketed as maple syrup.[31] In the United States, maple syrup must be made almost entirely from maple sap, although small amounts of substances such as salt may be added.[79] Labeling laws prohibit imitation syrups from having \\"maple\\" in their names unless the finished product contains 10 percent or more of natural maple syrup.[79]\\r\\n\\"Maple-flavoured\\" syrups include maple syrup, but may contain additional ingredients.[79] \\"Pancake syrup\\", \\"waffle syrup\\", \\"table syrup\\", and similarly named syrups are substitutes which are less expensive than maple syrup. In these syrups, the primary ingredient is most often high-fructose corn syrup flavoured with sotolon; they have little genuine maple content, and are usually thickened above the viscosity of maple syrup.[80]\\r\\nImitation syrups are generally cheaper than maple syrup, with less natural flavour.[80] In the United States, consumers generally prefer imitation syrups, likely because of the significantly lower cost and sweeter flavour;[81][82] they typically cost about $8 per gallon (1 US gallon (3,800?ml)), whereas authentic maple syrup costs $40 to $60 per gallon (2015 prices).[82]\\r\\nIn 2016, maple syrup producers from nine US states petitioned the Food and Drug Administration (FDA) to regulate labeling of products containing maple syrup or using the word \\"maple\\" in manufactured products, indicating that imitation maple products contained insignificant amounts of natural maple syrup.[83] In September 2016, the FDA published a consumer advisory to carefully inspect the ingredient list of products labeled as \\"maple\\".[84]\\r\\nMaple products are considered emblematic of Canada, in particular Quebec, and are frequently sold in tourist shops and airports as souvenirs from Canada. The sugar maple's leaf has come to symbolize Canada, and is depicted on the country's flag.[85] Several US states, including West Virginia, New York, Vermont and Wisconsin, have the sugar maple as their state tree.[86] A scene of sap collection is depicted on the Vermont state quarter, issued in 2001.[87]\\r\\nMaple syrup and maple sugar were used during the American Civil War and by abolitionists in the years before the war because most cane sugar and molasses were produced by Southern slaves.[81][88] Because of food rationing during the Second World War, people in the northeastern United States were encouraged to stretch their sugar rations by sweetening foods with maple syrup and maple sugar,[16] and recipe books were printed to help housewives employ this alternative source.[89]","input":"How much of the world's maple syrup does canada produce?"},{"output":"Rao Deva","context":"\\r\\n\\r\\nKota (/?ko?t?/?(?listen)) formerly known as Kotah, is a city located in the southeast of northern Indian state of Rajasthan.[4] It is located about 250 kilometres (155?mi) south of the state capital, Jaipur, situated on the banks of Chambal River. With a population of over 1.2 million, it is the third most populous city of Rajasthan after Jaipur and Jodhpur, 46th most populous city of India and 53rd most populous urban agglomeration of India. It serves as the administrative headquarters for Kota district and Kota Division. Kota is a major coaching hub of the country for competitive examination preparations and has a number of engineering and medical coaching institutes.[5] Books like Revolution 2020 by Chetan Bhagat and[6] Life in a Nutshell by Nitish Rajpurohit and Harsh Agarwal highlight the life of students in the city.[7][8][9]\\r\\n\\r\\nThe city of Kota was once the part of the erstwhile Rajput kingdom of Bundi. It became a separate princely state in the 17th century. Apart from the several monuments that reflect the glory of the town, Kota is also known for its palaces and gardens.[10][11] \\r\\nMahesh Vijay of Bhartiya Janta Party is the current Mayor of Kota.[12] In 2013, Kota was ranked the second most livable city in the state (after Jaipur) and forty-first in the country among 50 cities.[13] The city was also included among 98 Indian cities for Smart Cities Mission initiated by Indian prime minister Narendra Modi in 2015[14] and was listed at 67th place after results of first round were released following which top 20 cities were further selected for funding in the immediate financial year.[15]\\r\\n\\r\\nThe history of the city dates back to the 12th century AD when Rao Deva, a Chauhan Rajput chieftain belonging to the Hada clan conquered the territory and founded Bundi and Hadoti. Later, in the early 17th century, during the reign of the Mughal Emperor Jahangir, the ruler of Bundi - Rao Ratan Singh, gave the smaller principality of Kota to his son, Madho Singh. Since then Kota became a hallmark of the Rajput gallantry and culture.[16]\\r\\n\\r\\nThe independent state of Kota became a reality in 1631 when Rao Madho Singh, the second son of Rao Ratan of Bundi was made the ruler, by the Mughal Emperor Jahangir.[17] Soon Kota outgrew its parent state to become bigger in area, richer in revenue and more powerful. Maharao Bhim Singh played a pivotal role in Kota's history, having held a 'Mansab'[17] of five thousand and being the first in his dynasty to have the title of Maharao. Zalim Singh, a diplomat and statesman, emerged as another prominent figure of the state in the 18th century. Although initially being a general of Kota's army, he rose to the regent of the kingdom after the king died leaving a minor on the throne.[16] He remained a direct administrator of the state. In 1817, a treaty of friendship was signed between him and the British on his condition of carving out a part from the existing state for his descendants resulting in Jhalawar coming into existence in 1838.[16] During the colonial period, firebrand social activist Guru Radha Kishan organised the masses against the policies of the government. He left Kota after local administration came to know about the arrest warrant issued against him for his participation in Indian Independence activities.\\r\\n\\r\\nKota city became independent in 1579, after Bundi state in Hadoti region had become weak. Then, Kota ruled the territory which now is Kota district and Baran district.\\r\\n\\r\\nKota is located along the banks of the Chambal River in the southern part of Rajasthan. It is the 3rd largest city of Rajasthan after Jaipur and Jodhpur. The cartographic coordinates are 2511N 7550E? / ?25.18N 75.83E? / 25.18; 75.83.[18] It covers an area of 527?km2.[1][19] It has an average elevation of 271?metres (889?ft). The district is bound on the north and north west by Sawai Madhopur, Tonk and Bundi districts. The Chambal River separates these districts from Kota district, forming the natural boundary.\\r\\n\\r\\nThe city of Kota is situated at a centre of the southeastern region of Rajasthan a region very widely known as Hadoti, the land of the Hadas. Kota lies along the banks of the Chambal river on a high sloping tableland forming a part of the Malwa Plateau. The general slope of city is towards the north. The comparatively rocky, barren and elevated land in southern part of city descends towards a plain agricultural land in the north. The Mokandarra hills run from southeast to northwest axis of the town. The historical places and temples are getting surrounded by signs of modern development.\\r\\n\\r\\nKota has fertile land and greenery with irrigation facilities through canals. The two main canals; called as left main canal (towards Bundi) and right main canal (towards Baran) originate from the reservoir created by Kota Barrage.[20][21] The tributaries of these canals make up a network in the city and surrounding areas of Rajasthan and Madhya Pradesh and supplements the irrigation of these areas.[21]\\r\\n\\r\\nKota has a semi arid climate (K?ppen climate classification BSh) with high temperatures throughout the year. Summers are long, hot and dry, starting in late March and lasting till the end of June. The temperatures average above 40?C in May and June and frequently exceed 45?C with temperatures as high as 48.4?C also been recorded.[22] The monsoon season follows with comparatively lower temperatures, but higher humidity and frequent, torrential downpours. The monsoons subside in October and temperatures rise again. The brief, mild winter starts in late November and lasts until the last week of February. Temperatures hover between 26.7?C (max) to 12?C (min). This can be considered the best time to visit Kota because of intense heat in the summer.[23]\\r\\n\\r\\nThe average annual rainfall in the Kota district is 660.6?mm.[19] Most of the rainfall can be attributed to the southwest monsoon which has its beginning around the last week of June and may last till mid-September. Pre-monsoon showers begin towards the middle of June with post-monsoon rains occasionally occurring in October. The winter is largely dry, although some rainfall does occur as a result of the Western Disturbance passing over the region.[23]\\r\\n\\r\\nAccording to 2011 Census of India, Kota City had a population of 1,001,694, of which male and female are 528,601 and 473,093 respectively.[3][28] The provisional results of census 2011 reported city's population as 1,001,365.[29] The urban agglomeration of Kota consists of city only.[28][30] The sex ratio was 895 and 12.14% were under six years of age. The effective literacy rate was 82.80%, with male literacy at 89.49% and female literacy at 75.33%.[28]\\r\\n\\r\\nHarauti, a dialect of Rajasthani is widely spoken in Kota with Hindi, Marwari and English being the other languages spoken.[31]\\r\\n\\r\\nAccording to 2011 census, Hinduism is the majority religion in the city practised by about 80.5% of the population. Muslims form large minorities (15.9%) followed by Jains (2.2%), Sikhs (0.9%) and Christians (0.4%).[27]\\r\\n\\r\\nGovernmental institutions in Kota include:\\r\\n\\r\\nInstrumentation Ltd is a Public Sector company based in Kota.[32] Its clientele includes public sector entities such as the Indian Railways, BSNL and VSNL.\\r\\n\\r\\nThe District court provides court and notary services.[33]\\r\\n\\r\\nThe city is the trade centre for an area in which cotton, millet, wheat, coriander and oilseeds are grown; industries include cotton and oilseed milling, textile weaving, distilling, dairying, and the manufacture of metal handcrafts.[34] Kota also has an extensive industry of stone-polishing of a stone called Kota Stone, used for the floor and walls of residential and business buildings. Since last 15 years Kota has emerged as an Education hub of the country as producing excellent results in IIT-JEE and medical entrance exams.[5][35][36]\\r\\n\\r\\nKota is known for the fine translucent muslins called Masuria Malmal. Originally, such saris were called Masuria because they were woven in Mysore. The weavers were subsequently brought to Kota by Rao Kishore Singh who was a general in the Mughal army. The weavers were brought to Kota in the late 17th and early 18th centuries, and the saris came to be known as 'Kota-Masuria'. Kota saris are popularly known as 'Masuria' in Kota and Kotadoria outside the state. 'Doria' means thread.\\r\\n\\r\\nWeaving in Kota was started by Maharana Bhimdeo in the 18th century.[37] Maharaja Bhim Singh of Kota brought some weavers from the Deccan in the early 18th Century and the craft blossomed under the royal patronage. The warp and weft use a combination of threads creating a fine chequered pattern (Khat) where the cotton portion provides firmness while the silk lends a gossamer finish to the fabric.\\r\\n\\r\\nThe Kota saris like most traditional piece of work had started becoming lost before designer Vidhi Singhania moved to Kota and started working with the workers to revive its market.[38] Many textile shops in the city sell different varieties of Kota doria. These saris have become one of the trademarks of the city.[39]\\r\\n\\r\\nThe fine-grained variety of limestone quarried from Kota district is known as Kota stone, with rich greenish-blue and brown colours. Kota stone are tough, non water-absorbent, non-slip, and non-porous. The varieties include Kota Blue Natural, Kota Blue Honed, Kota Blue Polished, Kota Blue Cobbles, Kota Brown Natural and Kota Brown Polished.[40]\\r\\n\\r\\nKota is one of the industrial hubs in northern India, with chemical, cement, engineering and power plants based there. The total number of industrial units in the district in 2010-11 stood at 12908 with 705 registered units.[41] The district power plants show annual growth of 15-20?% due to their strategic locations.[41]\\r\\n\\r\\nKota is surrounded by five power stations within its 50?km radius.\\r\\n\\r\\nThe government and private schools in the city are affiliated with either Central Board of Secondary Education or Board of Secondary Education, Rajasthan and follow a 10+2 plan. The medium of instruction is either English or Hindi.\\r\\n\\r\\nThe city is specially recognized all over India as a center for preparation of various national level competitive examinations through which the students seek admissions in various engineering and medical colleges of the country. In the past decade the city has emerged as a popular coaching destination for competitive exams preparation and for profit educational services. The education sector of Kota has become one of the major contributors to the city's economy.[45] Kota is popularly referred to as \\"the coaching capital of India\\".[5][35][46] Over 1.5 lakh students from all over the country flock every year towards the city for preparation of various exams such as IIT-JEE, NEET-UG and AIIMS etc.[47][48][49][50][51] Many hostels and PGs are located in Kota near the vicinity of coaching centres for students. Students live here for 2ÿ3 years and prepare for the exams. The annual turnover of the Kota coaching industry is about ?1500 crore.[52]\\r\\n\\r\\nKota's emergence as a coaching hub began in 1985 when Vinod Kumar Bansal, an engineer working for J. K. Synthetics Ltd, set up Bansal Classes that eventually became Bansal Classes Private Limited.[53] Some of his instructors started their own institutes making Kota a major educational center.\\r\\n\\r\\n\\r\\n\\r\\nIn the past few years, reports of students committing suicide in the city have increased. As per reports, students feel stressed and get pressurized in order to crack their target competitive exam. As per National Crime Records Bureau report of 2014, 45 suicide cases of students were reported in the city. In year 2015, 17 such cases were found.[54] For the same cause, many coaching centers have also appointed counsellors to help students.[55][56][57][58] Various recreational activities such as sports, yoga etc. have been also brought up to relieve stress in past few months.\\r\\n\\r\\nSome of the popular visitor attractions in and nearby the city include Chambal Garden, Seven Wonders Park, Kishore Sagar Lake, Jag Mandir, Garh Palace, Chatra Vilas Garden, Godavari Dham Temple, Garadia Mahadev Temple, Kota Zoological Park, Maharao Madho Singh Museum, Kota Government Museum, Brijraj Bhawan Palace, Abheda Mahal, Agamgarh Gurudwara Sahib, Hanging Rock Fountain, Royal Cenotaphs at Keshar Bagh, Kota Barrage, Adarshila Dargah, Darrah National Park and Jawahar Sagar Dam.[59][60][61][62][63]\\r\\n\\r\\nGarh Palace, Kota\\r\\n\\r\\nJagmandir Palace\\r\\n\\r\\nChambal Garden\\r\\n\\r\\nUmed Bhawan Palace\\r\\n\\r\\nGodavari Dham Temple\\r\\n\\r\\nGaradia Mahadev Temple, Kota\\r\\n\\r\\nThere are several shopping malls and complexes in Kota. City Mall and Cinemall on Jhalawar road, Centre Square Mall and Akash Mall in Gumanpura and Ahluwalia's The Great Mall of Kota near DCM road are the notable retail malls in the city.[64][65][better?source?needed]\\r\\n\\r\\nKota is well connected with road and rail to all major cities within Rajasthan as well as those located outside the state.[66]\\r\\n\\r\\nThe city is well connected with neighboring cities and districts and with major cities outside the state. National highway No.12 (JaipurJabalpur) and National Highway No.76 pass through the city.[67] National Highway No.76 is a part of East-West Corridor. The total road length in Kota district is 2,052?km. as of March 2011.\\r\\n\\r\\nKota is well connected to all the major cities of India with rail.\\r\\nKota Junction is one of the divisions in West Central Railway.[68] It is an important station on the New DelhiÿMumbai main line. There are four railway stations within Kota and in its vicinity. Another suburban station of South Kota city is Dakaniya Talav Railway station which has a stoppage of Avadh Express, Dehradun Express and Ranthambore Express.[69]\\r\\n\\r\\nThe city is a halt for over 150 trains,[70] including Mumbai Rajdhani Express, August Kranti Rajdhani Express, Mumbai New Delhi Duronto Express, \\r\\nIndoreÿJaipur Express, Udaipur SuperFast (Delhi - Udaipur City Express), Dayodaya Express (Jaipur - Jabalpur Express / Ajmer - Jabalpur Express), Jodhpur - Indore Intercity, Hazrat Nizamuddin - Indore Express, Garbha Express, Marusagar Express (Ajmer - Ernakulam Express / Ernakulam Express), Jaipur - Mysore Express, Jaipur - Chennai Express, Jaipur - Coimbatore Express, Jodhpur - Puri Express, Jodhpur - Bhopal Express.\\r\\n\\r\\nThe DelhiMumbai railway line passes through the Kota junction.\\r\\nThe district has 148.83?km of railway line in the Kota  Ruthia section, 98.72?km on NagdaMathura (Mumbai-Delhi) section and 24.26?km on Kota Chittorgarh section.\\r\\n\\r\\nA broad-gauge railway facility between Kota and Jodhpur via Jaipur exists.\\r\\n\\r\\nKota is also an originating point for many trains like Kota - Damoh Passenger (Kota - Katni Passenger) connecting Kota to Damoh in Madhya Pradesh.\\r\\nThe Kota - Indore Intercity Express connects to another major city of Madhya Pradesh, Indore Junction.\\r\\nThere is also a Jan Shatabdi Express train, from Kota to national capital Delhi.\\r\\nThe other trains include, Kota - Vadodara Passenger, Kota - Sriganganagar Express, Kota - Ajmer, Kota - Jabalpur & Kota - Bina Passenger. Patna ÿ Kota Express connects Kota and Patna cities via Agra, Kanpur, Lucknow and Varanasi.\\r\\n\\r\\nKota Airport has had no scheduled services operating since 1999.[71] The nearest international airport is Jaipur International Airport situated 250?km away from Kota.\\r\\n\\r\\nThe city is home to Jay Kaylon Cricket Stadium located in Nayapura area. Among several matches, six Ranji Trophy matches have been played in the stadium.[72][73] The stadium also hosted RCL T20 2016, an inter state cricket league with six participating teams.[74]\\r\\n\\r\\nThere are five major regional TV Channels in Kota.[75]\\r\\n\\r\\nA wide range of other Hindi, English and other language channels are accessible via cable subscription and direct-broadcast satellite services. Dish TV, Tata Sky, Radiant Digitek, Airtel Digital TV are the prominent DTH entertainment services in Kota.\\r\\n\\r\\nMajor daily newspapers in Kota[76][77][78] include:\\r\\n\\r\\nThere are five radio stations in Kota, with four broadcasting on the FM band, and one All India Radio station broadcasting on the AM band.","input":"Who was tha founder ruler of kota state?"},{"output":"My Brother's Keeper","context":"Damon Salvatore is a fictional character in The Vampire Diaries novel series. He is portrayed by Ian Somerhalder in the television series. Initially, Damon is the main antagonist in the beginning of the show and later became a protagonist. After the first few episodes, Damon begins working alongside his younger brother, Stefan Salvatore, to resist greater threats and gradually Elena begins to consider him a friend.  His transition was completed after his younger brother Stefan, who is also a vampire, convinces him to drink blood. Damon thus vows to make his brother's life sorrowful ÿ thus further causing a century-long rift between the two brothers, centering around Katherine and eventually a love triangle with Elena Gilbert. After on-again/off-agains with both brothers, Elena chooses to be with Damon in the finale episode.\\r\\n\\r\\nIan Somerhalder was cast as Damon Salvatore at the end of March 2009, six months before the premiere of the series.[1] The initial casting call for the character required an actor in his early- to mid-twenties to play a \\"darkly handsome, strong, charming, and smug vampire who can go from casual and playful to pure evil in less than a heartbeat.\\"[2] Somerhalder had not read the books until filming began.[3]\\r\\n\\r\\nDamon Salvatore is a vampire, turned by Katherine Pierce 145 years prior to the series' debut. He is the son of late Giuseppe Salvatore, ripper Lily Salvatore and older brother of Stefan Salvatore. He is portrayed as a charming, handsome and snarky person who loves tricking humans, and takes pleasure in feeding on them and killing them during the early episodes of the first season, unlike his brother, Stefan. Damon and Stefan bite humans to keep them alive since they're vampires.\\r\\n\\r\\nIn the first season, Damon appears as the frightening older brother to Stefan Salvatore, and plays as the main antagonist for the first initial episodes with a hidden agenda.[4] Slowly, Damon begins to be kinder to the other characters, showing brief moments of compassion such as erasing Jeremy's memory of vampires and removing his \\"suffering\\"[4] so Jeremy gets his life back on track.[5] Damon apologizes for turning Vicki Donovan into a vampire and admits it was wrong.[6] Later at the Gilbert house, Elena returns home. Damon admits that he came to the town wanting to destroy it but actually found himself wanting to protect it after everything that happened at the Founder's Day celebrations and says he's not a hero and doesn't do good, saying it's not in him - those traits are reserved for Stefan, Elena and Bonnie. The two begin to kiss passionately before getting interrupted - it is later revealed that it wasn't Elena he kissed, but Katherine Pierce.[6] Later in the season, it also implies that he actually feels human emotions, such as pain and love, which helps the viewer sympathize toward his character in some situations. But mostly, he likes to take care of himself and do the dirty work, in his own sadistic ways.\\r\\n\\r\\nIn season two, Katherine tells Damon that she never loved him and that it was always Stefan. Elena says something similar later, leaving Damon heartbroken. As an expression of his anger, pain, and hopelessness, he snaps Jeremy Gilbert's neck, not realizing he is wearing a ring which reverses damage done by supernatural creatures or forces. Jeremy survives because of the ring, but Damon's action incurs Elena's wrath and pain. When Bonnie also discovers it was his blood that enabled Caroline Forbes to become a vampire, the two declare their hatred for him, leaving angrier than ever.[7] After saving Elena with Stefan in episode 8 of season 2, Damon shows up in Elena's room with the vervain necklace that was ripped from her neck earlier in the episode. Before he gives it back, he tells Elena that he is in love with her, and because he is in love with her, he cannot be selfish with her. He also states that he doesn't deserve her, but that his brother does. He kisses her forehead and says he wishes she could remember this, but she can't. As the camera shows a close up of Damon's eye as he is compelling Elena to forget, a tear slips. Elena blinks and her vervain necklace is back around her neck, Damon is gone and her window is open with the curtains blowing. She had no recollection as to how the necklace was returned to her. In one episode, Damon joins Rose to find out why the originals are after Elena; after some time and clever banter, the two have sex, stating that they could rid themselves of emotion. However, when Rose, Damon's old friend who turned Katerina, suffers from a werewolf bite, he gives her the memory of her life prior to becoming a vampire, and helps her remember how good it felt to be able to walk and feel the sunlight, without it burning her. During this meaningful moment, Damon mercifully kills her, leaving him to mourn the death of his one of very few friends. Elena and Damon then begin to mend fences, and Elena gives him an affectionate hug to help comfort him after Rose's death. Damon begins showing another side of himself in small acts that help build what once was an impossible friendship between Elena and himself, after she clearly stated that he has lost her forever. After he spares Caroline's mother, Elena says how that was the person she was once friends with. And it's hard for Damon to accept that he has to change to have her in his life, which he explains to Andy Star, his compelled girlfriend a few more episodes in. Damon is bitten by Tyler the werewolf at the end of the season. Elena takes care of him, and right before he is cured by the blood of Klaus, the original hybrid, she gives him a \\"goodbye\\" kiss, because she was sure he was going to die. She even forgives him, telling him that she cares for him through grief-stricken tears.\\r\\n\\r\\nIn the third season, Damon helps Elena in bringing his brother, Stefan, back to Mystic Falls after Stefan becomes Klaus' henchman. The arrangement transpired after a bargain for his blood that would cure Damon of the werewolf bite he had received from Tyler. At first, he is reluctant to involve Elena in the rescue attempts, employing Alaric Saltzman, Elena's guardian, instead as Klaus does not know that Elena is alive after the sacrifice which frees Klaus' hybrid side. However, Elena involves herself, desperate to find Stefan. Damon, though hesitant at first, is unable to refuse her because of his love for her. He also points out to her that she once turned back from finding Stefan since she knew Damon would be in danger, clearly showing that she also has feelings for him. He tells her that \\"when (he) drag(s) (his) brother from the edge to deliver him back to (her), (he) wants her to remember the things (she) felt while he was gone.\\" When Stefan finally returns to Mystic Falls, his attitude is different from that of the first and second seasons. This causes a rift between Elena and Stefan whereas the relationship between Damon and Elena becomes closer and more intimate. A still loyal Elena, however, refuses to admit her feelings for Damon. In 'Dangerous Liaisons', Elena, frustrated with her feelings for him, tells Damon that his love for her may be a problem, and that this could be causing all their troubles. This incenses Damon, causing him to revert to the uncaring and reckless Damon seen in the previous seasons. The rocky relationship between the two continues until the sexual tension hits the fan and in a moment of heated passion, Elena ÿ for the first time in the three seasons ÿ kisses Damon of her own accord. This kiss finally causes Elena to admit that she loves both brothers and realize that she must ultimately make her choice as her own ancestress, Katherine Pierce, who turned the brothers, once did. In assessment of her feelings for Damon, she states this: \\"Damon just sort of snuck up on me. He got under my skin and no matter what I do, I can't shake him.\\" In the season finale, a trip designed to get her to safety forces Elena to make her choice: to go to Damon and possibly see him one last time; or to go to Stefan and her friends and see them one last time. She chooses the latter when she calls Damon to tell him her decision. Damon, who is trying to stop Alaric, accepts what she says and she tells him that maybe if she had met Damon before she had met Stefan, her choice may have been different. This statement causes Damon to remember the first night he did meet Elena which was, in fact, the night her parents died - before she had met Stefan. Not wanting anyone to know he was in town and after giving her some advice about life and love, Damon compels her to forget. He remembers this as he fights Alaric and seems accepting of his death when Alaric, whose life line is tied to Elena's, suddenly collapses in his arms. Damon is grief-stricken, knowing that this means that Elena has also died and yells, \\"No! You are not dead!\\" A heartbroken Damon then goes to the hospital demanding to see Elena when the doctor, Meredith Fell, tells him that she gave Elena vampire blood. The last shot of the season finale episode shows Elena in transition.\\r\\n\\r\\nDamon starts season 4 at Elena's bedside after finding out about her dying with vampire blood in her system, causing her to start the transition to Vampire. Damon decides to firstly try to kill Rebekah with a White Oak Stake, yet she overpowers him. Rebekah is shot at through the Window and Damon escapes.\\r\\n\\r\\nLater in part of a plan with the Sheriff and Meredith Fell, Damon uses Matt as bait to draw out the deputies and Pastor Young. After dispatching the deputies, Damon decides to take out some aggression on Matt and is about to snap his neck when stopped by the new vampire Elena. After Elena and Stefan go hunting on animals the next morning and Elena has her first feed on a deer she pukes the blood out. Meanwhile, it seems a new vampire hunter is in town. Elena goes to Damon for help, he pulls her with him to the bathroom and makes her drink his blood because he says \\"You need warm blood from the vein, so maybe this'll do the trick.\\" He says it's personal and Elena wonders why but no answer was given. She drinks his blood but pukes hours later. When Stefan finds out Damon has feed Elena his blood he's very angry and hits Damon who just got in a fight with the vampire hunter.\\r\\n\\r\\nDamon has decided to leave town, but through the early episodes of Season 4 seems to be looking for reasons to stay. Meredith Fell seems to be one who convinces him in 'The Rager' to stay to help Elena with her transition to Vampire. Indeed, a renewed conflict over ideology and what sort of Vampire Elena will become drives Damon and Stefan apart.\\r\\n\\r\\nThe Five, shows Damon tasking Stefan with learning more about the Vampire Hunter, Connor while Damon decides to accompany both Bonnie and Elena to College. This trip is ostensibly about teaching Elena the 'hunt': how to catch, feed and erase. After some initial problems, Elena has a Frat Party gets success and seems to enjoy herself causing friction with Bonnie. She leaves the party and later states that she doesn't want to be like Damon. In the next episode, she begins to believe that Stefan is lying to her and takes things into her own hands to kill the vampire hunter who is holding her brother, Matt, and April captive. She does, and begins to suffer from hallucinations at the end of the episode. After asking Stefan why he wants to cure Elena, Damon tells him that he loves Elena as a vampire or human.\\r\\n\\r\\nIn the episode 'We All Go a Little Mad Sometimes', Damon helps Elena in dealing with her hallucinations and saves her from committing suicide. He also helps uncover the mystery about the hunter's curse with the help of Bonnie and Professor Shane. At the end of the episode, he reveals the truth about the cure to Elena and explains how Stefan has been lying to her only to find this possible cure for vampirism. However, Elena breaks up with Stefan at the end of the episode after confessing her gradually growing feelings for Damon.\\r\\n\\r\\nIn the following episode \\"My Brother's Keeper\\", Elena tells Damon he is the reason she and Stefan broke up and at the end of the episode Damon and Elena finally have sex. After that it turns out Elena is sired with Damon, first they think it is the reason why Elena loves Damon, but in episode \\"We'll Always Have Bourbon Street\\" they found out that it only affects how you act, not how you feel. The sire-bond can only be broken when Damon leaves Elena and tells her to stop caring about him according to a witch in New Orleans named Nandi. In the following episode Damon goes with Elena to her family's lake house to help with Jeremy's Hunter instincts. In the episode Elena tries to act like a couple with Damon, but he refuses to even kiss her out of his guilt about the sire bond and worry that he's taking advantage of her. In the end of the episode Damon invokes the sire bond telling Elena to return to Mystic Falls while he trains Jeremy \\"O Come, All Ye Faithful\\". Elena kisses him goodbye.\\r\\n\\r\\nIn 'After School Special', Damon is at the Lake House training Jeremy, along with Matt Donovan. Klaus shows up and threatens Damon, wanting him to get Jeremy's mark completed earlier rather than later. Damon is shown to be reluctant, not wanting to hurt innocents for Elena's sake, but Klaus follows through with his plans regardless. Later in the episode Elena calls Damon and confesses she's in love with him and it's the 'most real thing she's ever felt in her entire life', in a moment of weakness Damon tells her to come see him. Afterward Damon is confronted with a bar of newly turned vampires for Jeremy to kill concedes that it's the quickest way, however balks when Klaus takes control and compels the newly turned vamps to kill Matt Donovan. In Catch Me If You Can Damon tells the boys to run since Jeremy isn't ready to take on all these vampires. Later when Elena arrives her and Damon argue over the killing of innocents and tells her to take Matt home while he and Jeremy take care of Klaus's newly turned vampires. However Kol shows up and has killed all the vampires, determined to stop them from finding the cure & waking Silas, and threatens Jeremy's life. Kol compels Damon to stake himself and later to kill Jeremy and to forget what Kol compelled him to do. Upon arriving back in Mystic Falls Damon begins to seek out Jeremy due to the compulsion, however when he sees him in the grill he realizes what Kol compelled him to do and tells Jeremy to run. Damon chases Jeremy throughout Mystic Falls and advises Jeremy that he is compelled and he needs to kill him. Jeremy shoots Damon in the head and when Damon awakens later starts cursing the youngest Gilbert, calling him stupid for not killing him. At the end of the episode Damon catches up with Jeremy Elena follows and urges Damon to fight it because \\"You love me and I love you\\", but he tells her that he can't, falls to his knees and urges Jeremy to kill him. Stefan shows up just in time to break Damon's neck and lock him up until they can take care of Kol. Damon spends the next episode locked up and bled dry by a jealous and snarky Stefan and engages in a conversation with Klaus about Caroline, Rebekah and Elena.\\r\\n\\r\\nWhen the group goes to the mysterious island to find the Cure, Damon continues to be suspicious of Professor Shane. When Jeremy goes missing and Bonnie and Shane stay behind to try a locator spell, Damon stays to keep an eye on Shane. He later begins torturing Shane for information, but Shane starts analyzing Damon and telling him Elena will go back to Stefan once she's cured. Elena interrupts the torture session and Damon storms out and Elena follows. She tells Damon that she's sure her feelings for him are real and asks him to become human with her, however Damon tells her he has no desire to be human and that human/vampire relationships are doomed and stalks off. Afterward he is captured by Vaughn, another member of the Five, who tortures Damon and leads him around with a noose around his neck. Damon goes with Vaughn to the cavern close to where Silas is buried and eventually overpowers him, but not before Vaughn injures Rebekah. Elena and Stefan come across the injured Damon and Rebekah, Stefan stays while Elena rushes to find Jeremy. Damon urges Stefan to go get the cure for Elena, uncaring that there is only enough for one, because he wants it for the girl he loves. After Stefan leave Rebekah comments that Damon did something selfless and remarks that he will always love Elena. An exhausted Damon admits that he can't control everything and is tired.\\r\\n\\r\\nAfter Katherine kills Jeremy in 'Down the Rabbit Hole' Damon stays behind determined to find the missing Bonnie, telling Stefan he can't come home without her. Eventually he finds Bonnie, hugging her in relief, but when the two arrive back in Mystic Falls in informs Stefan Bonnie has lost her mind. Elena, who had been in denial about Jeremy's death, comes into reality and demands Damon bring Jeremy's body downstairs. When Elena starts breaking down Stefan urges Damon to help her, indicating he should invoke the sire bond to take away her pain, however instead Damon tells Elena to shut off her emotions. In the next episode Damon begins trying to track Katherine in order to find the cure while Rebekah attempts to tag along. He finds an old friend from his past, Will, dying from a werewolf bite and kills him out of mercy. He arrives back home just in time to stop Elena from killing Caroline and takes her with to New York. While in NY Damon begins investigating Katherine's whereabouts and tries to keep that he's looking for the cure from Elena. Elena finds out and attempts to play him all the while Damon tells her and Rebekah about his time here in the 1970s. He admits that he had his emotions off and Lexi had come to help him on Stefan's behalf, however he tricks her into believing he fell in love with her only to leave her trapped on the roof during the day as revenge. He reveals that the reason he killed Lexi in season one was out of the guilt she stirred in him. Elena kisses Damon and attempts to steal Katherine's address out of his pocket, however Damon was aware she was trying to play him the entire time, and attempts to convince her to turn her emotions back on. Rebekah shows up and snaps his neck. He then calls Stefan and the brothers attempt to track down Elena. The decide to give up on the cure after Elena kills a waitress and threatens to kill people.\\r\\n\\r\\nIn 'Pictures of You' Damon, along with Stefan, decide they're going to try making Elena turn her emotions back on. The Salvatore brothers decide to take Elena to the prom, where Damon asks Elena why she told him she was in love with him and it's the most real thing she ever felt. Elena tells Damon that she only said it because of the sire bond and she feels nothing for him. However, later when Bonnie nearly kills Elena, she cries out for Damon to help her and he locks her up in the Salvatore basement. Damon then manipulates Elena's dreams in an attempt to remind how much she loves her friends in family, however when it doesn't work the Salvatore brothers (per Stefan's advice) try torturing Elena to get her to feel emotion. Elena however calls their bluff and attempts to kill herself, knowing Damon would never really hurt her and let her die. Damon realizes that Elena is smart and that torture will not work. After Katherine frees Elena Damon comes up with a plan, killing Matt in front of her (while he wore the Gilbert ring) and it works to get Elena's emotions back on. When Elena focuses her hate on Katherine Damon tells Elena where Katherine is, but tells her she shouldn't try and kill her. Damon admits he hates Katherine, however he knows once Elena kills her all her other emotions (grief & guilt) will all come flooding back in. Elena stakes Damon in the stomach when he attempts to stop her.\\r\\n\\r\\nIn the season finale 'Graduation', he tries to give the cure to Elena, but Elena refuses, which tells him that there is no more sire bond. He gets shot by Vaughn with a bullet laced with werewolf venom, and almost dies, but Klaus comes back to Mystic Falls and saves him. At the end of the episode, Elena proclaims her love for him stating that of all the decisions she has made choosing him will prove to be the worse one.\\r\\n\\r\\nNot aware of Stefan's absence and Bonnie's death, Damon and Elena are having the time of their lives before Elena leaves for Whitmore college. College brings a lot of ups and downs to the on screen romance. Katherine begs Damon to protect her as she feels someone is after her, Damon by the help of Jeremy's vampire hunter instincts that Silas is possessing as Stefan. Silas gives Damon a crash course on why he looks like Stefan and tells where was he the whole summer, shocked to know about this he starts to search Stefan with the help of Stefan. Silas mind-controlled Elena to kill Damon but Elena resists it by thinking about her worries for Stefan. Both Elena and Damon, with the help of Sheriff Forbes, finds the safe where Stefan was drowning the whole summer, but only to find a dead body.\\r\\nDue to both Elena and Katherine having same nightmare of Stefan all three, Damon, Elena and Katherine search for Stefan. Damon finally finds Stefan inside a hut where he is tied up in the chair and Qetsiyah makes a link of Stefan with Silas which fries Stefan's brain. Qetsiyah reveals to Damon that his relationship with Elena is doomed. Damon and Elena take Stefan where both of them finds out that he has memory loss and can't remember anything. Damon, to make Stefan remember about his past life, gives him his journals and spends quality time with him. Jeremy tells Damon that Bonnie is dead and Damon finally tells Elena about Bonnie. At Bonnie's funeral, Damon consoles Elena. Damon wants to help Silas so that Silas can do a spell to swap his life with Bonnie as Silas wants to die. Silas had seen Qetsiyah going to the party therefore both Damon and Silas goes to the ball party at Whitmore College. Silas needs Damon to kill Stefan, so that he can get back his power. Stefan, after waking up, tricked Damon and snapped his neck. At Salvatore's mansion they bring a desiccated Silas, to trade Silas's life with Bonnie he must become mortal(witch). The only way is by the cure so Elena and Damon calls Katherine who has the cure in her blood and after she arrives her blood is drained by Silas, but still Katherine lived. Amara is then awakened and revealed to be the mystic anchor. She then cures herself of her immortality by feeding off Silas.\\r\\n\\r\\nAt the beginning of season 6, Damon is still trapped in the 1994 snapshot with Bonnie, forced to relive the same day over and over again. As the season progresses, the duo meet Kai Parker who's provides them with clues on how to get back home. In a truly selfless act, Bonnie manages to send Damon back while she remains in 1994 with Kai. Back home, things aren't as Damon expected them to be. Elena has compelled her memories of their time together and moved on. After a few initial set backs, Damon sets his mind to wooing her back.\\r\\n\\r\\nAs the season progresses, Elena falls for Damon all over again as they search for a way to free Bonnie and she becomes a large part of his support as his good friend Liz Forbes becomes more and more ill with cancer. Kai, who escaped the Prison World without Bonnie and merged with Luke, has absorbed some of Luke's qualities and is now moved by guilt to help free Bonnie. With his help, he, along with Damon, Elena, and Jeremy, are able to visit the Prison World and remind Bonnie that there is still magic residing in Qetsiyah's headstone in Nova Scotia.\\r\\n\\r\\nAfter the death of Liz, Caroline is unable to bear the pain of losing her mother and chooses to turn off her humanity just as Bonnie returns. Bonnie brought back with her a strange video she'd caught while leaving a second Prison World she'd been moved to set in October 31, 1903. She shows the video to Damon and he recognizes his own mother, Lillian Salvatore, standing in the background. Troubled with the news that his mother is still alive after believing she'd been dead since 1858, Damon's informed by Kai that his mother was placed in a Prison World due to being a Ripper and the heinous number of deaths she'd caused. Unfortunately, Stefan is forced by Caroline to turn off his humanity and Kai, Bonnie, Damon, and Elena have to travel to Lily's 1903 Prison World to retrieve her and use her as a means to get Stefan back.\\r\\n\\r\\nDamon is disturbed to learn when he gets to Lily that she has been trapped with other vampires and they allowed her to drink their portions of blood to stay alive. She is reluctant to leave without them, but Damon threatens to leave her behind if she doesn't go. Bonnie, Damon, and Elena leave with Lily, leaving Kai behind. When they return, Bonnie gives Damon a gift she'd gotten for him during her trip to Nova Scotia in the 1994 Prison World: the cure to vampirism. He struggles with whether or not to give it to Elena and provide her with the life she'd been robbed of.\\r\\n\\r\\nAfter using Lily to get Stefan's humanity back and he is used to bring Caroline back, Lily is adamant about returning to her Prison World to retrieve what she considers to be her family. Damon confronts Bonnie, who had taken the Ascendant, and tells her that Lily is threatening to destroy the cure if he doesn't return with the means to get her \\"family\\" back. However, when he decides to let Bonnie destroy the Ascendant, he comes home to find that Lily had actually given the cure to Elena instead. He confesses that he was selfish and afraid of losing her but agrees that she should take it and that he'll take it with her.\\r\\n\\r\\nElena takes the cure and, unexpectedly, her memories return and she remembers when she'd traveled to Nova Scotia with Damon in search of the cure the first time, he'd told her that he used to miss being human, but, now, he couldn't imagine anything more miserable. She tells him he needs to think about it before making that decision and enlists Stefan to try to make sure Damon is certain of his choice to become human. Damon almost decides he'd rather stay a vampire until he witnesses an interaction between an older couple. Before Jo and Ric's wedding, he tells Elena he'd made his choice to live one lifetime with her. During the wedding, Kai shows up and stabs Jo before causing an explosion. The second to last episode ends with Elena lying unconscious on the ground.\\r\\n\\r\\nIn the last episode of the 6th season titled \\"I'm Thinking Of You All The While\\" Damon rushes Elena to the hospital after vampire blood fails to heal and awaken her. At the hospital the doctors tell him that she is medically healthy and they see no reason why she's not awake. Kai stumbles into the hospital injured. After consuming Lily's blood and killing himself, Kai's ability to siphon magic allowed him to become another Heretic (vampire with witch-like power), but he was soon bitten by a transforming Tyler, who had re-triggered his werewolf curse. Kai tells Damon and he's linked Elena's life to Bonnie's and as long as Bonnie lives, Elena will remain asleep but perfectly healthy. He also tells him that the spell is permanent and any attempt to find a loophole in the spell will result in the death of both Bonnie and Elena. Damon returns to the wedding to find Bonnie badly injured on the floor and Kai's reminder that letting Bonnie die will allow Elena to regain consciousness. Damon tells Bonnie he's sorry and leaves the room. Kai is irritated that his plan to torture Damon with an impossible choice had failed and, while he's distracted, Damon decapitates him from behind. Damon saves Bonnie's life and they go to the Salvatore boarding house to say their goodbyes to Elena, deciding that they will allow Bonnie to live her life and, when she dies, Elena will wake. Damon allows himself to enter Elena's subconscious to say his goodbye, dancing with her and telling her that he'll never be ready to live the next 60 years of his life without her. Stefan and Damon move the coffin holding Elena to a crypt and have Bonnie seal the door magically to keep away those seeking the Cure.\\r\\n\\r\\nThe season ends with the impression that quite a bit of time has passed. Mystic Falls is desolate and run down after the return of the other Heretics, Lily's \\"family\\". The last scene shows Damon looking torn standing on the clock tower he once sat on with Elena.\\r\\n\\r\\nAt the start of season 1, Damon was a self-proclaimed loner,[8] often keeps to himself. Despite his initially antagonistic relationships with humans such as Alaric Saltzman and Sheriff Elizabeth Forbes, Caroline's mother. Damon gradually involved himself into the lives of many people in Mystic Falls by developing friendships with several humans. After spending time with Elena Gilbert, Damon becomes more empathetic and falls deeply, madly and passionately in love with her. He always puts her safety first before anyone else, even his.[9][10]\\r\\n\\r\\nDamon's most prominent love, aside from Elena, was Rose. He met her while searching for Klaus and hooked up with her shortly after. Unfortunately Damon ticked off Jules, a werewolf, and she showed up on a full moon for revenge.\\r\\n\\r\\nDamon has had a challenging relationship with his younger brother Stefan Salvatore for over a century. Before they became vampires, they both loved the vampire Katherine Pierce. Damon shows that he has nurtured a long-standing desire to reunite with Katherine throughout the first season. In the first season, we learn that it was Stefan who convinced Damon to feed and complete his transformation after Katherine turned both brothers into vampires.[11] Despite the feud between the Salvatore brothers, both Damon and Stefan always have each other's backs. Damon is always there for Stefan when it really matters, e.g., saving him from being tortured, helping him through withdrawal, and working with him to kill common enemies.[12] And Stefan will still give up his own life for Damon's survival. They both actually love each other but won't admit it, however:[13]\\r\\n\\r\\nAfter learning of Katherine's deceit, Damon starts to fall for, Elena. In general, Damon is fiercely protective of Elena and always puts her safety ahead of all else. Damon comes to Elena's rescue at the Miss Mystic Falls pageant when Elena is left stranded without a partner, and the two dance. In the episode \\"Rose\\", Damon confesses his love for her only to compel her to forget about it because he doesn't believe he is worthy of her. Throughout the third season his relationship with Elena grows; she learns to fully trust him, and they begin to rely on each other as a team. They share two passionate kisses, but Elena remains in denial about her feelings for him. After a long struggle, Elena still chooses Stefan much to Damon's dismay. In the following season, however, Elena realizes that her feelings for Damon cannot be denied any longer.  She and Stefan break up, and in the following episode Damon and Elena finally get together and have sex. Damon and Elena then both individually discover that Elena is sired to Damon, making Elena's feelings unfortunately known; however, Elena insists that her love for Damon is the most real thing that she's ever felt in her entire life. Damon remains doubtful, so in \\"O Come, All Ye Faithful\\" he sets her \\"free\\". In an interview before the season finale, Julie Plec stated that \\"This year, she's had a very traumatic roller coaster of life experience and it's changed her irrevocablyand at the center of it all was the diehard belief that she loved Damon, that she loved him more than she'd ever loved anyone.\\" [14] In \\"Graduation\\", after the sire bond is broken and there remains no doubt about Elena's feelings, she reveals that she is in love with Damon.\\r\\n\\r\\nDamon and Elena spend the next few months together, having the summer of their lives. When Elena has to leave for college, Damon stays behind in Mystic Falls and they have a functional long distance relationship. However, in the episode \\"Original Sin\\", Tessa, who is revealed to be Qetsiyah, tells Damon that the doppelgangers are fated to fall in love and that he is only a bump in the road that makes their story interesting. Damon refuses to believe in this and assures Elena that he will fight for her and their future together as she is his life.  It is later revealed that there is nothing fated about Stefan and Elena, but that they were merely drawn together by a spell.  After a tumultuous, back and forth relationship, Damon and Elena get back together at the end of the season, and they choose to sacrifice themselves together to save Stefan and Alaric and their other friends on the Other Side.  When Elena makes it back but Damon is trapped on the collapsing Other Side, Elena is devastated.  Damon says his last goodbye to Elena, telling her that she is by far the best thing that has ever happened to him, and that being loved by her is \\"the epitome of a fulfilled life\\", as Elena sobs inconsolably.  In season 6, Elena is unable to move on from Damon's death months later. She pretends to be happy, but she is secretly taking witch herbs to hallucinate Damon. When the herbs make her dangerous to humans, Elena decides to have Alaric compel away her memories of Damon, because she will never be able to move on otherwise.  When Damon returns, he attempts to help her remember their love story, but the compulsion will not break. Not remembering any of the good things about Damon, Elena still decides to give him another chance.  She slowly falls in love with him again, ultimately declaring that no matter whether she has memories of him or not, she always finds her way back to him. When Bonnie returns from the prison world, she gifts Damon with the cure for vampirism, knowing that he wanted to give it to Elena.  However, Damon is afraid that this will mean losing Elena. They discuss what a human life together would be like.  Elena initially rejects the cure, but Damon decides to take it with her so that they can have a human life together, including children.  Damon always wanted Elena to have the human life she always dreamed of. Elena takes the cure, which breaks the compulsion, and her memories of Damon return to her.  She recalls a memory from season 4, where Damon declares that there would be nothing more miserable than becoming human again.  Elena is afraid that Damon would regret taking the cure, so she challenges him to think it through carefully.  Stefan attempts to convince Damon that becoming human would be a bad decision, but Damon ultimately realizes that one lifetime with Elena is infinitely better than an immortal one without her, and confidently believes her to be his soulmate.  Damon and Elena excitedly anticipate the beginning of their human future together, until Kai puts Elena under a sleeping spell, tied to Bonnie's life.\\r\\n\\r\\nDamon spends the next two seasons devoted to Elena, waiting for her to wake up.  He repeatedly states that he is miserable without her, and will spend the next 60 or so years unhappily until Bonnie dies. However, Damon is committed to staying true to Elena, and doing right by her. Elena is shown to be Damon's moral compass, and his guiding force throughout the two seasons.  When Damon is in the Phoenix Stone's version of hell, a vision of Stefan asks Damon \\"What would Elena do?\\" and this prompts Damon to forgive his mother, freeing him from hell.  The phoenix stone's influence remains, and Damon accidentally lights Elena's coffin on fire (or so he thinks).  Believing that he has unwittingly killed the love of his life, Damon becomes suicidal. When confronted with the hunter Rayna, Damon commands her to kill him because he is already in hell in a world without Elena. Enzo then reveals to Damon that Elena is still alive, renewing Damon's hope.  When Damon realizes that he is a potential danger to his friends and family because he does not believe he is good without Elena, he decides to desiccate himself next to her.  He write to Alaric that before Elena, he didn't know what it was like to be happy, fulfilled or complete, and that he doesn't want to continue living without that feeling. After Stefan wakes Damon from his desiccation, Damon continues to be devoted to his future with Elena. At the end of season 7, he is lured into a trap by a siren, hearing Elena's voice calling out to him.  When the siren takes control of Damon's mind in season 8, Damon spends a significant amount of time sleeping, seeking refuge in dreams of his memories of Elena.  When Sybil erases Elena from Damon's consciousness only to insert herself into their memories, Damon fights back, instinctively drawn back to Elena.  His love for her prevails, and he breaks the siren's mind control, regaining his memories of Elena. Julie Plec stated that \\"I think the only hope that he's holding on to is the idea of the two of them living in Tribeca in their brownstone and raising kids and having a life together as humans when this is all said and done.\\" [15] After Stefan gives Damon the cure to vampirism, turning him into a human, and Bonnie unbreaks the spell on Elena, Damon and Elena finally reunite.  They begin their life together, getting married while Elena goes to medical school and becomes a doctor.  Eventually they return to Mystic Falls to grow old together, where they died together of old age.  We last see them walking hand in hand in the afterlife before reuniting with their respective families.\\r\\n\\r\\nAlaric is a vampire hunter looking to avenge his wife by killing the vampire that killed her. It is soon revealed that the vampire that Alaric is hunting is actually Damon. Before killing Alaric, he confesses that he didn't kill Isobel but turned her. Alaric is brought back to life by the Gilbert ring. The two remain enemies but work together on occasion. Eventually, the two become best friends and drinking buddies. Even after Alaric is turned into a vampire who kills other vampires, Damon does his best to ensure that they don't have to kill him. But with Elena's death, Alaric dies as well while Damon holds him. In the episode, \\"Memorial\\", it's clear that Damon still misses his friend as he talks to Alaric at his grave. Unknown to him, Alaric listens to the whole thing and even responds with \\"I miss you too, buddy\\". Damon's best friend.\\r\\n\\r\\nBonnie first saw Damon in Friday Night Bites when he dropped Caroline off at cheerleading practice. They first interacted in Haunted, when Damon learned that Bonnie had come into possession of the Bennett Talisman. He needed this to open the tomb which Katherine was locked in (for 145 years or so he believed). At first, Bonnie didn't want to have anything to do with Damon, saving his life only for Elena's sake and soon blaming him for Caroline's transition into a vampire. However, as time went on, Bonnie was put into situations where she had to work with Damon to achieve what they both wanted (albeit reluctantly at first). Their teamwork has often proved to be beneficial for the both of them. Their relationship has even come to a point where Damon is visibly worried for Bonnie's well-being and was devastated when he found out about her death. The improvement of their relationship is seen in Damon's efforts to help bring Bonnie back from the dead. However, their unique friendship hit a speed bump when Damon reverted to his old ways. Finally, they stood side by side with each other as The Other Side collapsed, holding each other's hand and at peace with what is to come for the both of them. They later discover that they are trapped in a 1994 Prison World. During that time, they start to bond and form a close alliance to take down Kai. Before sending Damon back home, she mentions that he's not exactly the last person she would wanna be stuck with. When Damon returns home, he does everything he can to find a way to bring Bonnie back, including a long road trip to Oregon to seek the Gemini Coven, and also compelling Alaric to steal the Ascendant from Jo. They finally reunite at the Salvatore Boarding House with a hug after Sheriff Forbes's funeral. It's shown that Damon and Bonnie genuinely care about each other and have made sacrifices for each other.","input":"When did damon and elena first get together?"},{"output":"13 August 1964","context":"Capital punishment in the United Kingdom was used from ancient times until the second half of the 20th century. The last executions in the United Kingdom were by hanging, and took place in 1964, prior to capital punishment being abolished for murder (in 1965 in Great Britain and in 1973 in Northern Ireland). Although unused, the death penalty remained a legally defined punishment for certain offences such as treason until it was completely abolished in 1998. In 2004 the 13th Protocol to the European Convention on Human Rights became binding on the United Kingdom, prohibiting the restoration of the death penalty for as long as the UK is a party to the Convention.[1]\\r\\n\\r\\n\\r\\nSir Samuel Romilly, speaking to the House of Commons on capital punishment in 1810, declared that \\"[there is] no country on the face of the earth in which there [have] been so many different offences according to law to be punished with death as in England\\".[2] Known as the \\"Bloody Code\\", at its height the criminal law included some 220 crimes punishable by death, including \\"being in the company of Gypsies for one month\\", \\"strong evidence of malice in a child aged 7ÿ14 years of age\\" and \\"blacking the face or using a disguise whilst committing a crime\\". Many of these offences had been introduced to protect the property of the wealthy classes that emerged during the first half of the 18th century, a notable example being the Black Act of 1723, which created 50?capital offences for various acts of theft and poaching.[citation needed] Crimes eligible for the death penalty included shoplifting and stealing sheep, cattle, and horses, and before abolition of the death penalty for theft in 1832, \\"English law was notorious for prescribing the death penalty for a vast range of offenses as slight as the theft of goods valued at twelve pence.\\"[3]\\r\\nWhilst executions for murder, burglary and robbery were common, the death sentences for minor offenders were often not carried out. A sentence of death could be commuted or respited (permanently postponed) for reasons such as benefit of clergy, official pardons, pregnancy of the offender or performance of military or naval duty.[4] Between 1770 and 1830, an estimated 35,000 death sentences were handed down in England and Wales, of which 7,000 executions were carried out.[5]\\r\\nIn 1808 Romilly had the death penalty removed for pickpockets and lesser offenders, starting a process of reform that continued over the next 50 years. The death penalty was mandatory (although it was frequently commuted by the government) until the Judgement of Death Act 1823 gave judges the power to commute the death penalty except for treason and murder. The Punishment of Death, etc. Act 1832 reduced the number of capital crimes by two-thirds. In 1832, the death penalty was abolished for theft, counterfeiting, and forgery except for the forgery of wills and certain powers of attorney.[3][6] Gibbeting was abolished in 1832 and hanging in chains was abolished in 1834. In 1837, the death penalty for forging wills and powers of attorney was abolished. The death penalty for rape was abolished in 1841.[7] In 1861, several acts of Parliament (24 & 25 Vict; c. 94 to c. 100) further reduced the number of civilian capital crimes to five: murder, treason, espionage, arson in royal dockyards, and piracy with violence; there were other offences under military law. The death penalty remained mandatory for treason and murder unless commuted by the monarch.\\r\\nThe Royal Commission on Capital Punishment 1864ÿ66[8] concluded (with dissenting Commissioners) that there was not a case for abolition but recommended an end to public executions. This proposal was included in the Capital Punishment Amendment Act 1868. From that date executions in Great Britain were carried out only in prisons. The punishment of beheading and quartering those executed for treason was abolished in 1870.[9] The last application of that punishment had been in 1820 and the last sentence to the punishment had been in 1839.[citation needed]\\r\\nIn 1908, the Children Act 1908 banned the execution of juveniles under the age of 16. In 1922 a new offence of Infanticide was introduced to replace the charge of murder for mothers killing their children in the first year of life. In 1930 a parliamentary Select Committee recommended that capital punishment be suspended for a trial period of five years, but no action was taken. From 1931 pregnant women could no longer be hanged (following the birth of their child) although in practice since the 18th century their sentences had always been commuted.\\r\\nIn 1933 the minimum age for capital punishment was raised to 18 under the Children and Young Persons Act 1933. The last known execution by the civilian courts of a person under 18 was that of Charles Dobel, 17, hanged at Maidstone together with his accomplice William Gower, 18, in January 1889. Harold Wilkins, at 16 years old, was the last juvenile sentenced to the death penalty in the United Kingdom, in 1932 for a sexually related murder, but he was reprieved due to age.[10]\\r\\nIn 1938 the issue of the abolition of capital punishment was brought before parliament. A clause within the Criminal Justice Bill called for an experimental five-year suspension of the death penalty. When war broke out in 1939 the bill was postponed. It was revived after the war and to everyone's surprise was adopted by a majority in the House of Commons (245 to 222). In the House of Lords the abolition clause was defeated but the remainder of the bill was passed. Popular support for abolition was absent and the government decided that it would be inappropriate for it to assert its supremacy by invoking the Parliament Acts 1911 and 1949 over such an unpopular issue.\\r\\nInstead, then Home Secretary, James Chuter Ede, set up a new Royal Commission (the Royal Commission on Capital Punishment, 1949ÿ1953) with instructions to determine \\"whether the liability to suffer capital punishment should be limited or modified\\". The Commission's report discussed a number of alternatives to execution by hanging (including the US methods of electrocution and gassing, and the then-theoretical lethal injection), but rejected them. It had more difficulty with the principle of capital punishment. Popular opinion believed that the death penalty acted as a deterrent to criminals, but the statistics within the report were inconclusive. Whilst the report recommended abolition from an ethical standpoint, it made no mention of possible miscarriages of justice. The public had by then expressed great dissatisfaction with the verdict in the case of Timothy Evans, who was tried and hanged in 1950 for murdering his baby daughter. It later transpired in 1953 that John Christie had strangled at least six women in the same house; he also confessed to killing Timothy's wife. If the jury in Evans's trial had known this, Evans would probably not have been found guilty. There were other cases in the same period where doubts arose over convictions and subsequent hangings, such as the notorious case of Derek Bentley.\\r\\nThe commission concluded that unless there was overwhelming public support in favour of abolition, the death penalty should be retained.\\r\\nBetween 1900 and 1949, 621 men and 11 women were executed in England and Wales. Ten German agents were executed during the First World War under the Defence of the Realm Act 1914,[11] and 16 spies were executed during the Second World War under the Treachery Act 1940.[12]\\r\\nBy 1957 a number of controversial cases highlighted the issue of capital punishment again. Campaigners for abolition were partially rewarded with the Homicide Act 1957. The Act brought in a distinction between capital and non-capital murder. Only six categories of murder were now punishable by execution:\\r\\nThe police and the government were of the opinion that the death penalty deterred offenders from carrying firearms and it was for this reason that such offences remained punishable by death.\\r\\nIn 1965 the Labour MP Sydney Silverman, who had committed himself to the cause of abolition for more than 20 years, introduced a Private Member's Bill to suspend the death penalty for murder. It was passed on a free vote in the House of Commons by 200 votes to 98. The bill was subsequently passed by the House of Lords by 204 votes to 104.[14][15]\\r\\nThe Murder (Abolition of Death Penalty) Act 1965 suspended the death penalty in Great Britain (but not in Northern Ireland) for murder for a period of five years, and substituted a mandatory sentence of life imprisonment; it further provided that if, before the expiry of the five-year suspension, each House of Parliament passed a resolution to make the effect of the Act permanent, then it would become permanent. In 1969 the Home Secretary, James Callaghan, proposed a motion to make the Act permanent, which was carried in the Commons on 16 December 1969,[16] and a similar motion was carried in the Lords on 18 December.[17] The death penalty for murder was abolished in Northern Ireland on 25 July 1973 under the Northern Ireland (Emergency Provisions) Act 1973.\\r\\nFollowing the abolition of the death penalty for murder, the House of Commons held a vote during each subsequent parliament until 1997 to restore the death penalty. This motion was always defeated, but the death penalty still remained for other crimes:\\r\\nHowever, no executions were carried out in the United Kingdom for any of these offences after the abolition of the death penalty for murder.\\r\\nNevertheless, there remained a working gallows at HMP Wandsworth, London, until 1994, which was tested every six months until 1992. This gallows is now housed in the Galleries of Justice in Nottingham.[20]\\r\\nEngland and in the United Kingdom: on 13 August 1964, Peter Anthony Allen, at Walton Prison in Liverpool, and Gwynne Owen Evans, at Strangeways Prison in Manchester, were executed for the murder of John Alan West on 7 April that year.[21]\\r\\nScotland: Henry John Burnett, 21, on 15 August 1963 in Craiginches Prison, Aberdeen, for the murder of seaman Thomas Guyan.\\r\\nNorthern Ireland: Robert McGladdery, 26, on 20 December 1961 in Crumlin Road Gaol, Belfast, for the murder of Pearl Gamble.\\r\\nWales: Vivian Teed, 24, in Swansea on 6 May 1958, for the murder of William Williams, sub-postmaster of Fforestfach Post Office.[22]\\r\\nNorthern Ireland and in the United Kingdom: Liam Holden in 1973 in Northern Ireland, for the capital murder of a British soldier during the Troubles. Holden was removed from the death cell in May 1973.[23] In 2012 his conviction was quashed on appeal.[24]\\r\\nEngland: David Chapman, who was sentenced to hang in November 1965 for the murder of a swimming pool nightwatchman in Scarborough. He was released from prison in 1979 and later died in a car accident.\\r\\nScotland: Patrick McCarron in 1964 for shooting his wife. He committed suicide in prison in 1970.\\r\\nWales: Edgar Black, who was reprieved on 6 November 1963. He had shot his wife's lover in Cardiff.\\r\\nThe Criminal Damage Act 1971 abolished the offence of arson in royal dockyards.\\r\\nThe Naval Discipline Act 1957 reduced the scope of capital espionage from \\"all spies for the enemy\\" to spies on naval ships or bases.[25] Later, the Armed Forces Act 1981 abolished the death penalty for espionage.[26] (The Official Secrets Act 1911 had created another offence of espionage which carried a maximum sentence of fourteen years.)\\r\\nBeheading was abolished as a method of execution for treason in 1973.[27] Hanging, however, remained available until 1998 when, under a House of Lords amendment to the Crime and Disorder Act 1998, proposed by Lord Archer of Sandwell, the death penalty was abolished for treason and piracy with violence, replacing it with a discretionary maximum sentence of life imprisonment. These were the last civilian offences punishable by death.\\r\\nOn 20 May 1998 the House of Commons voted to ratify the 6th Protocol of the European Convention on Human Rights prohibiting capital punishment except \\"in time of war or imminent threat of war\\". The last remaining provisions for the death penalty under military jurisdiction (including in wartime) were removed when section 21(5) of the Human Rights Act 1998 came into force on 9 November 1998. On 10 October 2003, effective from 1 February 2004,[28] the UK acceded to the 13th Protocol, which prohibits the death penalty in all circumstances.[29]\\r\\nAs a legacy from colonial times, several states in the West Indies still had the British Judicial Committee of the Privy Council as the court of final appeal; although the death penalty has been retained in these states, the Privy Council would sometimes delay or deny executions. Some of these states severed links with the British court system in 2001 by transferring the responsibilities of the Privy Council to the Caribbean Court of Justice, to speed up executions.[30]\\r\\nAlthough not part of the United Kingdom, the Isle of Man and the bailiwicks of Guernsey and Jersey are British Crown dependencies.\\r\\nIn the Channel Islands, the last death sentence was passed in 1984; the last execution in the Channel Islands was in Jersey on 9 October 1959, when Francis Joseph Huchet was hanged for murder.[31] The Human Rights (Amendment) (Jersey) Order 2006[32] amends the Human Rights (Jersey) Law 2000[33] to give effect to the 13th Protocol of the European Convention on Human Rights providing for the total abolition of the death penalty. Both of these laws came into effect on 10 December 2006. Capital punishment was abolished in Guernsey in 2003, and the 13th Protocol was extended to Guernsey in April 2004. Sark formally retained it until January 2004, when the Chief Pleas in a 14ÿ9 vote removed it from the statutes.[34][35]\\r\\nThe last execution on the Isle of Man took place in 1872, when John Kewish was hanged for patricide. Capital punishment was not formally abolished by Tynwald (the island's parliament) until 1993.[36] Five persons were sentenced to death (for murder) on the Isle of Man between 1973 and 1992, although all sentences were commuted to life imprisonment. The last person to be sentenced to death in the UK or its dependencies was Anthony Teare, who was convicted at the Manx Court of General Gaol Delivery in Douglas for contract murder in 1992; he was subsequently retried and sentenced to life imprisonment in 1994.[37] In 2004 the 13th Protocol was adopted,[38] with an effective date of 1 November 2006.[39]\\r\\nLike the Crown dependencies, the British overseas territories are constitutionally not part of the United Kingdom. However, the British government's ultimate responsibility for good governance of the territories has led it over recent years to pursue a policy of revoking all statutory provision for the death penalty in those territories where it had up until recently been legal.\\r\\nThe last executions in an overseas territory, and indeed the last on British soil, took place in Bermuda in 1977, when two men, Larry Tacklyn and Erskine Burrows, were hanged for the 1973 murder of the territory's then Governor Sir Richard Sharples.[40]\\r\\nIn 1991, the British government extended an Order in Council to its Caribbean territories whose effect was to abolish capital punishment for murder: Anguilla, the British Virgin Islands, the Cayman Islands, Montserrat and the Turks and Caicos Islands.[41]\\r\\nThe British government was unable to extend the abolition via Order in Council to Bermuda, the UK's most autonomous overseas territory with powers of almost total self-governancebut warned that if voluntary abolition was not forthcoming it would be forced to consider the unprecedented step of \\"whether to impose abolition by means of an Act of Parliament\\".[42] As a result, the Bermudian government introduced its own domestic legislation in 1999 to rectify the problem.[43]\\r\\nFurther measures were subsequently adopted to revoke technicalities in British overseas territories' domestic legislation as regards use of the death penalty for crimes of treason and piracy. In October 2002 the British government abolished the death penalty for treason and piracy in the Turks and Caicos Islands. Since then, the death penalty has been outlawed under all circumstances in all the UK's overseas territories.[44]\\r\\nSince the death penalty's suspension in 1965, there have been continued public and media calls for its reintroduction, particularly prompted by high-profile murder cases.\\r\\nAt the same time, there have been a number of miscarriages of justice since 1965 where someone convicted of murder has later had their conviction quashed on appeal and been released from prison, strengthening the argument of those who oppose the death penalty's reintroduction. These include the Birmingham Six (cleared in 1991 of planting an IRA bomb which killed 21 people in 1974), the Guildford Four (cleared in 1989 of murdering five people in another 1974 IRA bombing), Stephen Downing (a Derbyshire man who was freed in 2001 after serving 27 years for the murder of a woman in a churchyard) and Barry George (who was freed in 2007 when his conviction for the 1999 murder of TV presenter Jill Dando was quashed on appeal).[45]\\r\\nPerhaps the first high-profile murder case which sparked widespread calls for a return of the death penalty was the Moors murders trial in 1966, the year after the death penalty's suspension, in which Ian Brady and Myra Hindley were sentenced to life imprisonment for the murders of two children and a teenager in the Manchester area (they later confessed to a further two murders).[46] Later in 1966, the murder of three policemen in West London also attracted widespread public support for the death penalty's return.[47] Other subsequent high-profile cases to have sparked widespread media and public calls for the death penalty's return include \\"Yorkshire Ripper\\" Peter Sutcliffe, convicted in 1981 of murdering 13 women and attacking seven others in the north of England,[48] Roy Whiting, who murdered a seven-year-old girl in West Sussex in 2000,[49] and Ian Huntley, a Cambridgeshire school caretaker who killed two 10-year-old girls in 2002.[50]\\r\\nA November 2009 television survey showed that 70% favoured reinstating the death penalty for at least one of the following crimes: armed robbery, rape, crimes related to paedophilia, terrorism, adult murder, child murder, child rape, treason, child abuse or kidnapping. However, respondents only favoured capital punishment for adult murder, the polling question asked by other organisations such as Gallup, by small majorities or pluralities: overall, 51% favoured the death penalty for adult murder, while 56% in Wales did, 55% in Scotland, and only 49% in England.[51]\\r\\nIn August 2011, the Internet blogger Paul Staineswho writes a political blog as Guido Fawkes and heads the Restore Justice Campaignlaunched an e-petition on the Downing Street website calling for the restoration of the death penalty for those convicted of the murder of children and police officers.[52] The petition was one of several in support or opposition of capital punishment to be published by the government with the launch of its e-petitions website. Petitions attracting 100,000 signatures would prompt a parliamentary debate on a particular topic, but not necessarily lead to any Parliamentary Bills being put forward.[53] When the petition closed on 4 February 2012 it had received 26,351 signatures in support of restoring capital punishment,[54] but a counter-petition calling to retain the ban on capital punishment received 33,455 signatures during the same time period.[55]\\r\\nAlso in August 2011, a representative survey conducted by Angus Reid Public Opinion showed that 65% of Britons support reinstating the death penalty for murder in Great Britain, while 28% oppose this course of action. Men and respondents aged over 35 are more likely to endorse the change.[56]\\r\\nIn March 2015 a survey by the NatCen British Social Attitudes Report showed that public support for the death penalty had dropped to 48 per cent.[57]\\r\\nAfter Royal Assent for the Murder (Abolition of Death Penalty) Act 1965, supporters in Parliament have made several attempts to reintroduce capital punishment. On 23 November 1966, Duncan Sandys was refused leave to bring in a Bill to restore capital punishment for the murder of police or prison officers, by a vote of 170 to 292.[58] Motions to make the five-year suspension of capital punishment under the 1965 Act permanent were opposed, but agreed by 343 to 185 in the House of Commons;[59] in the House of Lords, an amendment to continue with a temporary suspension of capital punishment until 31 July 1973 was rejected by 174 to 220.[60] In April 1973, the House of Commons voted against reintroduction.[61]\\r\\nThe deaths of civilians in several IRA bombings in 1974 prompted a renewed debate. On 11 December 1974 Brian Walden moved a motion declaring that \\"the death penalty would neither deter terrorists nor increase the safety of the public\\"; Jill Knight moved an amendment calling instead for introduction of legislation providing for death to be the penalty for acts of terrorism causing death. Her amendment was rejected by 217 to 369.[62] A year later, Ivan Lawrence's motion \\"That this House demands capital punishment for terrorist offences causing death\\" was rejected by 232 to 361.[63]\\r\\nAfter the Conservatives' victory in the 1979 general election, Eldon Griffiths (Parliamentary adviser to the Police Federation of England and Wales) moved a motion \\"that the sentence of capital punishment should again be available to the courts\\" on 19 July 1979.[64] While the motion was not expected to pass, the margin of its defeat (243 to 362) was much wider than expected.[65] Later in the same Parliament, the Criminal Justice Bill provided an opportunity on 11 May 1982 for several new clauses to be proposed which would have reinstated capital punishment. The first, which simply declared that \\"A person convicted of murder shall be liable to capital punishment\\", was tabled by Edward Gardner, and rejected by 195 to 357.[66] It was followed by an alternative under which capital punishment would be available \\"as the penalty for an act of terrorism involving the loss of human life\\"; this new clause was rejected by 176 to 332.[67] A further new clause proposing capital punishment \\"as the penalty for murder by means of firearms or explosives\\" was rejected by 176 to 343.[68] Then a new clause allowing for capital punishment \\"as the penalty for murder of a police or prison officer\\" was rejected by 208 to 332.[69] Finally a new clause allowing capital punishment \\"as the penalty for murder in the course of robbery and burglary which involves the use of offensive weapons\\" was rejected by 151 to 331.[70]\\r\\nThe new Parliament in 1983 again prompted supporters of capital punishment to put their case. Sir Edward Gardner's motion \\"That this House favours the restoration of the death penalty for murder\\" was debated on 13 July 1983, with several amendments moved to restrict capital punishment to certain categories of murder. The amendments were voted on first: capital punishment for murder \\"resulting from acts of terrorism\\" was rejected by 245 to 361, for murder \\"of a police officer during the course of his duties\\" by 263 to 344, for murder \\"of a prison officer during the course of his duties\\" by 252 to 348, for murder \\"by shooting or causing an explosion\\" by 204 to 374, and for murder \\"in the course or furtherance of theft\\" by 194 to 369. The main motion was then defeated by 223 to 368.[71] Towards the end of the Parliament, a new clause proposed to the Criminal Justice Bill proposed to return the death penalty for \\"A person convicted by the unanimous verdict of a jury of the premeditated killing of another person or of knowingly and intentionally killing another person in a manner, or for a reason, or in circumstances which a reasonable person would consider to be evil\\" was rejected by 230 to 342 on 1 April 1987.[72]\\r\\nThe Criminal Justice Bill in 1988 provided a further opportunity for a debate; the new clause proposed by Roger Gale allowed for the jury in a murder case to \\"have the power, upon reaching a verdict of guilt of murder, to recommend .. death in the manner authorised by law\\". It was rejected by 218 to 341.[73]\\r\\nThe aforementioned bills were rejected despite support from then Prime Minister Margaret Thatcher.[74]\\r\\nOn 17 December 1990 a new Criminal Justice Bill again saw amendments designed to reintroduce capital punishment. The first covered anyone over 18 \\"convicted of the murder of a police officer acting in the execution of his duty\\" and was rejected by 215 to 350;[75] a general reintroduction of death as the penalty for murder (with special provision for the Court of Appeal to decide whether to substitute a life sentence) was then rejected by 182 to 367.[76] Capital punishment for \\"murder committed by means of firearms, explosives or an offensive weapon, or for the murder of a police or prison officer\\" was rejected by 186 to 349.[77]\\r\\nThe most recent Parliamentary debate on a question proposing reintroduction of capital punishment came on 21 February 1994 when new clauses to the Criminal Justice and Public Order Bill were moved. The first, providing for death as the sentence for \\"the murder of a police officer acting in the execution of his duty\\", was rejected by 186 to 383;[78] A new clause providing for general reintroduction with power for the Court of Appeal to substitute life imprisonment was rejected by 159 to 403.[79] This would have been aimed at terrorists in the Northern Ireland conflict.[80]\\r\\nIn June 2013 a new bill for capital punishment in England and Wales was introduced. This Bill has been withdrawn and will not progress any further.[81]\\r\\nThe following parties support the reintroduction of capital punishment:","input":"When was the last person executed in uk?"},{"output":"28 driver fatalities","context":"This article lists drivers who have been fatally injured while competing in or in preparation for (testing, practice, qualifying) races sanctioned by the National Association for Stock Car Auto Racing (NASCAR). A separate list compiles drivers who have died of a medical condition while driving or shortly thereafter and another section shows non-driver deaths.\\r\\nThe premier series of NASCAR has seen 28 driver fatalities, the most recent of which occurred in February 2001 when Dale Earnhardt was killed during the Daytona 500.\\r\\nSafety in the sport has evolved through the decades. Technological advances in roll cages, window nets, seat mounts, air flaps, helmets, and driving suits as well as on-site medical facilities with helicopters, SAFER barriers,[1] and the HANS device[2] may have contributed to the prevention of further deaths.\\r\\n\\r\\n\\r\\nThis list shows NASCAR Cup Series fatalities.\\r\\nThis list covers both drivers who crashed their cars after suffering a fatal medical condition, i.e. they did not die of any injuries they may have sustained in the ensuing accident, and those who managed to stop their cars but succumbed to a medical condition a little later.\\r\\nThis section includes drivers participating in an event who were killed while on the sidelines.\\r\\nThis list shows NASCAR Cup Series fatalities.","input":"How many deaths has there been in nascar?"},{"output":"must have a CDL","context":"A commercial driver's license is a driver's license required to operate large or heavy vehicles.\\r\\n\\r\\n\\r\\nIn the United States, the Commercial Motor Vehicle Safety Act of 1986 established minimum requirements that must be met when a state issues a CDL.[1] It specifies the following types of license:\\r\\nThis includes, but is not limited to, tow trucks, tractor trailers, and buses.\\r\\nDriving commercial motor vehicles (CMVs), which are primarily tractor-trailers (or Longer Combination Vehicles (LCVs)),[2] requires advanced skills and knowledge above and beyond those required to drive a car or other light weight vehicle. Before implementation of the commercial driver's license (CDL) Program in 1986, licensing requirements for driving larger vehicles and buses varied from state to state.\\r\\nMany drivers were operating motor vehicles that they may not have been trained or qualified to drive.[citation needed] This lack of training resulted in a large number of preventable traffic deaths and accidents.[3]\\r\\n1986 when the Act became law, all drivers have been required to have a CDL in order to drive a Commercial Motor Vehicle. The Federal Highway Administration (FHWA) has developed testing standards for licensing drivers. U.S. states are able to issue CDLs only after a written and practical test have been given by the State or approved testing facility.\\r\\nA driver needs a CDL if the vehicle meets one of the following definitions of a Commercial Motor Vehicle (CMV): [4]\\r\\nClass A: Any combination of vehicles which has a gross combination weight rating or gross combination weight of 11,794 kilograms or more (26,001 pounds or more) whichever is greater, inclusive of a towed unit(s) with a gross vehicle weight rating or gross vehicle weight of more than 4,536 kilograms (10,000 pounds) whichever is greater.\\r\\nClass B: Any single vehicle which has a gross vehicle weight rating or gross vehicle weight of 11,794 or more kilograms (26,001 pounds or more), or any such vehicle towing a vehicle with a gross vehicle weight rating or gross vehicle weight that does not exceed 4,536 kilograms (10,000 pounds).\\r\\nClass C: Any single vehicle, or combination of vehicles, that does not meet the definition of Class A or Class B, but is either designed to transport 16 or more passengers, including the driver, or is transporting material that has been designated as hazardous under 49 U.S.C. 5103 and is required to be placarded under subpart F of 49 CFR Part 172 or is transporting any quantity of a material listed as a select agent or toxin in 42 CFR Part 73.[5]\\r\\nA state may also require a driver to have a CDL to operate certain other vehicles legally. A driver licensed in New Jersey must have a CDL to drive legally a bus, limousine, or van that is used for hire, and designed to transport 8 to 15 passengers.[6] A driver licensed in New York must have a CDL to legally transport passengers in school buses and other vehicles listed in Article 19-A of the state's Vehicle and Traffic Law.[7] Drivers licensed in California must have a CDL if their primary employment is driving, whether or not they actually drive a commercial vehicle. California defines a commercial vehicle as one that transports for hire either people or products.[8] In addition, possession of a CDL in California changes the threshold for a Driving Under the Influence citation from 0.08% to 0.04% Blood Alcohol Content.[9]\\r\\nProspective licensees should verify CDL requirements by referencing their state specific CDL Manual.[10]\\r\\nThe minimum age to apply for a CDL is usually 21, as required by the United States Department of Transportation, although some states allow drivers who are 18 to 20 to apply for a CDL that is valid only within the driver's state of residence. A single state CDL only restricts driving of CMVs within the holder's state (not non-commercial vehicles), and automatically converts to a 50 state CDL at the age of 21.[citation needed]\\r\\nAdditional testing is required to obtain any of the following endorsements on the CDL. These can only be obtained after a CDL has been issued to the driver:\\r\\nT, P, S, N, H and X are Federal endorsements . Any other endorsements have been promulgated at the State level. i.e. New York DMV requires a \\"W\\" endorsement to legally operate a tow truck in New York.\\r\\nDepending on your State, the education requirements vary. Some states (Ohio) for example requires 160 hours or classroom and on the road training. Training may be obtained by completing a qualified CDL training program through a truck driving school. These training programs specialize in teaching potential truck drivers the necessary skills and knowledge to properly and safely operate a truck, including map reading, trip planning, and compliance with U.S. Department of Transportation laws, as well as backing, turning, hooking a trailer, and road driving. The overall purpose of these training schools is to help truckers-to-be pass the CDL knowledge and skills tests as well as advanced driving techniques such as skid avoidance and recovery and other emergency actions for situations such as a break away trailer and hydroplaning. These classes usually go well beyond the training the typical non-commercial driver receives, such as the drivers education provided in high school. There are a number of licensed CDL training schools around the United States and many trucking companies operate their own schools as well.\\r\\nAlthough each state may add additional restrictions, there are national requirements are as follows.[13] A prospective driver must pass a written test on highway safety and a test about different parts of a truck with a minimum of 30 questions on the test. To pass this knowledge test, student drivers must answer at least 80 percent of the questions correctly. To pass the driving skills test the student driver must successfully perform a set of required driving maneuvers. The driving skill test must be taken in a vehicle that the driver operates or expects to operate. For certain endorsements, such as Air Brakes, the driving skills test must be taken in a vehicle equipped with such equipment. You will also need to show you do in fact show the characteristics of an aware and fully operative driver. This does not exclude certain disabilities, however, you must meet standard requirements, required by the safety operators.\\r\\nEmployers, training facilities, States, governmental departments, and private institutions may be permitted to administer knowledge and driving test for the State. The test must be the same as those given by the State issuing the CDL and the instructors must meet the same professional certification as State instructors.\\r\\nStates are required to conduct an inspection of any testing facility and evaluates the programs by taking an actual test as if they were testing driver at least once a year, or by taking a sample of drivers tested by the third party and then comparing pass/fail rates.\\r\\nIn addition, the State's agreement with the third party testing centers must allow the FMCSA and the State to conduct random examinations, inspections, and audits without notice.\\r\\nIn 2014, the law regarding drivers in pursuit of a CDL was modified and requires a DOT medical examiner to authorize a person with a medical issue to be able to drive. Prior to the change, a private doctor was able to authorize a driver to obtain a CDL.[14] Most CMV drivers must prove they are healthy enough to safely drive a truck. A valid medical certificate must be filled out by a medical professional listed on the National Registry of Certified Medical Examiners at the conclusion of an extensive physical exam, with a copy provided to the state Bureau (or Department) of Motor Vehicles compliance unit. Some examples of an impairment which disqualifies a driver include the inability to grasp a steering wheel or operate foot pedals, insulin use, certain cardiac and respiratory problems, markedly elevated blood pressure, epilepsy, some severe psychiatric disorders, certain color blindness, poor corrected vision in either eye (worse than 20/40), bilateral hearing loss, active alcoholism, and other conditions which significantly increase the risk of a medical emergency behind the wheel. See Physical qualifications for drivers page of the Federal Motor Carrier Safety Administration.\\r\\nNot all medical providers are able to test and complete the medical certification form.\\r\\nA CDL must contain the following information:\\r\\n(a)(1) The prominent statement that the license is a commercial drivers license or CDL, except as specified in 383.153(b);\\r\\n(a)(2) The full name, signature, and mailing address of the person to whom such license is issued;\\r\\n(a)(3) Physical and other information to identify and describe such person including date of birth (month, day, and year), sex, and height;\\r\\n(a)(4) Color photograph of the driver;\\r\\n(a)(5) The drivers State license number;\\r\\n(a)(6) The name of the State which issued the license;\\r\\n(a)(7) The date of issuance and the date of expiration of the license;\\r\\n(a)(8) The group or groups of commercial motor vehicle(s) that the driver is authorized to operate, indicated as follows:\\r\\n(a)(8)(i) A for Combination Vehicle;\\r\\n(a)(8)(ii) B for Heavy Straight Vehicle; and\\r\\n(a)(8)(iii) C for Small Vehicle.\\r\\n(a)(9) The endorsement(s) for which the driver has qualified, if any, indicated as follows:\\r\\n(a)(9)(i) T for double/triple trailers;\\r\\n(a)(9)(ii) P for passenger;\\r\\n(a)(9)(iii) N for tank vehicle;\\r\\n(a)(9)(iv) H for hazardous materials (which includes most all fireworks);\\r\\n(a)(9)(v) X for a combination of the tank vehicle and hazardous materials endorsements;\\r\\n(a)(9)(vi) S for school bus; and\\r\\n(a)(9)(vii) At the discretion of the State, additional codes for additional groupings of endorsements, as long as each such discretionary code is fully explained on the front or back of the CDL document.\\r\\n(b) If the CDL is a nonresident CDL, it shall contain the prominent statement that the license is a nonresident commercial drivers license or nonresident CDL. The word nonresident must be conspicuously and unmistakably displayed, but may be noncontiguous with the words Commercial Drivers License or CDL.\\r\\n(c) If the State has issued the applicant an air brake restriction as specified in 383.95, that restriction must be indicated on the license. [15]\\r\\nThe Commercial Driver's License Information System (CDLIS) and the National Driver Register (NDR) exchange information on traffic convictions and driver disqualifications of commercial drivers. States have to use both CDLIS and NDR to check a driver's record before a CDL can be issued. To gain permission to access to the CDLIS and NDR databases one should visit the Federal Motor Carrier Safety Administration (FMCSA) Technical Support Web site for instructions on how this information is accessed and who can access it. Trucking companies can use a commercial service that has clearance for providing this information as a means of screening prospective employees.\\r\\nAn employer is also subject to a penalty of up to US$10,000, if they knowingly permit a driver to operate a CMV without a valid CDL.\\r\\nStates can reduce certain lifetime disqualifications to a minimum disqualification period of 10 years if the driver completes a driver rehabilitation program approved by the State. Not all states do this: it is available in Idaho[4] and New York State[7] but not California[8] or New Jersey.[6]\\r\\nIf a CDL holder is disqualified from operating a CMV they can not be issued a \\"conditional\\" or \\"hardship\\" CDL, but can continue to drive non-commercial vehicles.\\r\\nAny convictions are reported to the driver's home State and Federal Highway Administration and these convictions are treated the same as convictions for violations that are committed in the home State.\\r\\nThe Commercial Drivers License Program collects and stores all convictions a driver receives and transmits this data to the home State so that any disqualification or suspension can be applied.\\r\\nThe FHWA has established 0.04% as the blood alcohol concentration (BAC) level at or above which a CMV driver is deemed to be driving under the influence of alcohol and subject to lose his/her CDL. Additionally, an operator of a CMV that is found to have 'any detectable amount of BAC above 0.0%' will be put out of service for a minimum of 24 hours.\\r\\nA driver must report any driving conviction within 30 days, except parking, to their employer regardless of the nature of the violation.\\r\\nEmployers must be notified if a driver's license is suspended, revoked, or canceled. The notification must be made by the end of the next business day following receipt of the notice of the suspension, revocation, cancellation, lost privilege or disqualification.\\r\\nEmployers cannot under any circumstances use a driver who has more than one license or whose license is suspended, revoked or canceled, or is disqualified from driving. Violation of this requirement may result in civil or criminal penalties.\\r\\nThe Bureau of Labor Statistics and additional publications identified a future need for over 90,000 truck drivers in the United States for the next 10 years.[16] In order to improve upon the shortage, full scholarships are being awarded to military veterans at CDL-A schools and truck driving companies.[17][18]\\r\\nIn the United Kingdom the PCV Licence (PCV stands for Passenger Carrying Vehicle) enables the holder to drive buses and/or minibuses, subject to what kind of Practical Driving Test the licence holder passes.\\r\\nFurther information on obtaining a PCV Licence can be found at the PCV Licence Training website\\r\\nAll places in Australia have a mostly similar driver licence system, although some things can change in each state or territory (e.g. what classes of license are available).\\r\\nGVM is the maximum recommended weight a vehicle can be when loaded. A 'Class C' Licence allows the holder to drive cars, utilities, vans, some light trucks, car-based motor tricycles, tractors and implements such as graders. You can also drive vehicles that seat up to 12 adults, including the driver.\\r\\nThe medical standards for drivers of commercial vehicles are set by the National Transport Commission and AUSTROADS, and are set out in 'Assessing Fitness to Drive' (available from the AUSTROADS website).\\r\\nFor those applying for heavy vehicle licence classes MR (Medium Rigid), HR (Heavy Rigid), HC (Heavy Combination) or MC (Multi Combination), it is strongly recommended that the applicant ensures they meet the medical requirements before commencing any training or tests for a heavy vehicle licence.\\r\\nThe driver of a vehicle carrying paying passengers (such as a school bus or tourist coach) requires an appropriate driver licence and a 'Public Passenger Vehicle Driver Authority' which is issued by the Ministry of Transport.\\r\\nIn New Zealand, driver licensing is controlled by the NZ Transport Agency. There are six classes of motor-vehicle licence[19] and nine licence endorsements. Class 1 governs vehicles with a GLW (gross laden weight) or GCW (gross combined weight) of less than 6,000?kg, and Class 6 governs motorcycles. Classes 2ÿ5 govern heavy vehicles.\\r\\nA Class 2 licence allows the holder to drive:\\r\\nClass 3 allows the holder to drive:\\r\\nClass 4 allows the holder to drive:\\r\\nClass 5 allows the holder to drive:\\r\\nBefore getting a Class 2 licence, a driver must be at least 18 years of age and have held an unrestricted Class 1 licence for at least six months. Gaining a Class 5 is not dependent on holding a Class 3. Once a driver has a Class 2 they can progress straight through to Class 4 and Class 5. Each progression (2 to 3, 2 to 4, or 4 to 5) requires having held an unrestricted licence of the preceding class for at least six months. For drivers aged 25 or over the minimum period for holding the unrestricted time is reduced to three months, or waived entirely on completion of an approved course of instruction.\\r\\nAdditional endorsements on an NZ driver's licence govern provision of special commercial services. The endorsements are:\\r\\nThe F, R, T and W endorsements are for operating special types of vehicle on the road. Where the holder also has a heavy vehicle (Class 2 or Class 4) licence, they are permitted to drive heavy special vehicles. Otherwise the limits for Class 1 (6,000?kg) apply.\\r\\nBeing granted an I, O, P and/or V endorsement requires that the applicant passes a \\"fit and proper person\\" check, to screen for people with criminal convictions or serious driving infringements. These endorsements are issued for one or five years, at the option of the applicant at the time of purchase.\\r\\nIn Hong Kong, Transport Department is responsible for issuing driver licences. Private light bus (class 4), public light bus (class 5), taxi (class 6), private bus (class 9), public bus (class 10), franchised public bus (class 17), medium goods vehicle (class 18), heavy goods vehicle (class 19), articulated vehicle (class 20) and special purpose vehicle (class 21) are vehicles requiring commercial driving licences.,[20] whereas private car (class 1), light goods vehicle (class 2), motorcycle (class 3), and motor tricycle (class 22) are considered non-commercial vehicles.\\r\\nTo apply for a commercial driving licence, a driver must: - be of age 21 or above; - have obtained a private car or light goods vehicle full driving licence for at least 3 years (2 years if converted from probationary licence) immediately before the application; - be a Hong Kong permanent resident or not subject to any condition of stay other than a limit of stay; - have not been convicted of some serious driving offences specified in law within 5 years before the application; and take a driving test of the class of vehicle the driver is going to apply.\\r\\nIn Hong Kong, driving licences are issued separately for each class of vehicle and printed on the licence, although passing a driving test of a heavier vehicle automatically gives the driver the right to apply for corresponding lighter vehicles:","input":"What is a commercial driver's license ca?"},{"output":"the east, suggesting either the Indus valley or India","context":"Melu??a or Melukhkha is the Sumerian name of a prominent trading partner of Sumer during the Middle Bronze Age. Its identification remains an open question, though most scholars associate it with the Indus Valley Civilization.\\r\\n\\r\\n\\r\\nSumerian texts repeatedly refer to three important centers with which they traded: Magan, Dilmun, and Meluhha. Magan is usually identified with Egypt in later Assyrian texts; but the Sumerian localization of Magan was probably Oman. Dilmun was a Persian Gulf civilization which traded with Mesopotamian civilizations, the current scholarly consensus is that Dilmun encompassed Bahrain, Failaka Island and the adjacent coast of Eastern Arabia in the Persian Gulf.[1][2]\\r\\nThe location of Meluhha, however, is hotly debated. There are scholars today who confidently identify Meluhha with the Indus Valley Civilization (modern South Asia) on the basis of the extensive evidence of trading contacts between Sumer and this region. Sesame oil was probably imported from the Indus River region into Sumer: the Sumerian word for this oil is illu (Akkadian: ellu). One theory is that the word is of proto-Dravidian origin: in Dravidian languages of South India, el or ellu stands for sesame. An alternative, proposed by Michael Witzel, is that it derived from a \\"para-Munda\\" language spoken in the Indus Valley Civilization.[3]\\r\\nThere is extensive presence of Harappan seals and cubical weight measures in Mesopotamian urban sites. Specific items of high volume trade are timber and specialty wood such as ebony, for which large ships were used. Luxury items also appear, such as lapis lazuli mined at a Harappan colony at Shortugai (modern Badakhshan in northern Afghanistan), which was transported to Lothal, a port city in Gujarat in western India, and shipped from there to Oman, Bahrain and Sumer.\\r\\nAlmost all scholars suggest that Meluhha was the Sumerian name for the Indus Valley Civilization. Finnish scholars Asko and Simo Parpola identify Meluhha (earlier variant Me-lah-ha) from earlier Sumerian documents with Dravidian mel akam \\"high abode\\" or \\"high country\\". Many items of trade such as wood, minerals, and gemstones were indeed extracted from the hilly regions near the Indus settlements. They further claim that Meluhha is the origin of the Sanskrit mleccha, meaning \\"barbarian, foreigner\\".[4]\\r\\nEarly texts (c. 2200 BC) seem to indicate that Meluhha is to the east, suggesting either the Indus valley or India.[citation needed] Sargon of Akkad was said to have \\"dismantled the cities, as far as the shore of the sea. At the wharf of Agade, he docked ships from Meluhha, ships from Magan.\\"\\r\\nWritings in the Ur-III period describe Meluhha as the 'land of the black mountains'. It may also be referred to by this name in a poem praising King Shulgi, reigning in about 2000 BC, in which he claims (among other accomplishments) to understand the language of men 'from the black mountains' well enough to talk to them without interpreter, and when sitting as a judge to provide them with verdicts in their own language.[5] Of five foreign languages he can speak well (one apparently the increasingly ossified Sumerian language of his homeland), this is the third to be listed.\\r\\nHowever, much later texts documenting the exploits of King Assurbanipal of Assyria (668ÿ627 BC), long after the Indus Valley civilization had ceased to exist, seem to imply that Meluhha is to be found somewhere near Egypt, in Africa.[6]\\r\\nThere is sufficient archaeological evidence for the trade between Mesopotamia and the Indus Valley. Impressions of clay seals from the Indus Valley city of Harappa were evidently used to seal bundles of merchandise, as clay seal impressions with cord or sack marks on the reverse side testify. A number of these Indus Valley seals have been found at Ur and other Mesopotamian sites.[7][8] The Persian-Gulf style of circular stamped rather than rolled seals, also known from Dilmun, that appear at Lothal in Gujarat, India, and Failaka Island (Kuwait), as well as in Mesopotamia, are convincing corroboration of the long-distance sea trade network, which G.L. Possehl has called a \\"Middle Asian Interaction Sphere\\".[9] What the commerce consisted of is less sure: timber and precious woods, ivory, lapis lazuli, gold, and luxury goods such as carnelian and glazed stone beads, pearls from the Persian Gulf, and shell and bone inlays, were among the goods sent to Mesopotamia in exchange for silver, tin, woolen textiles, perhaps oil and grains and other foods. Copper ingots, certainly, bitumen, which occurred naturally in Mesopotamia, may have been exchanged for cotton textiles and chickens, major products of the Indus region that are not native to Mesopotamiaall these have been instanced.\\r\\nIn the Assyrian and Hellenistic eras, cuneiform texts continued to use (or revive) old place names - giving a perhaps artificial sense of continuity between contemporary events and events of the distant past.[10] For example, Media is referred to as \\"the land of the Gutians\\",[11] a people who had been prominent around 2000 BC.\\r\\nMeluhha also appears in these texts, in contexts suggesting that \\"Meluhha\\" and \\"Magan\\" were kingdoms adjacent to Egypt. Assurbanipal writes about his first march against Egypt, \\"In my first campaign I marched against Magan, Meluhha, Tarka, king of Egypt and Ethiopia, whom Esarhaddon, king of Assyria, the father who begot me, had defeated, and whose land he brought under his sway.\\" In the Hellenistic period, the term is sometimes used to refer to Ptolemaic Egypt, as in its account of a festival celebrating the conclusion of the Sixth Syrian War.[12]\\r\\nThese references do not necessarily mean that early references to Meluhha also referred to Egypt. Direct contacts between Sumer and the Indus Valley had ceased even during the Mature Harappan phase when Oman and Bahrain (Magan and Dilmun) became intermediaries. After the sack of Ur by the Elamites and subsequent invasions in Sumer, its trade and contacts shifted west and Meluhha passed almost into mythological memory. The resurfacing of the name could simply reflect cultural memory of a rich and distant land, its use in records of Achaemenid and Seleucid military expeditions serving to aggrandize those kings.\\r\\nIn Indian fantasy novel series of Shiva trilogy by Amish Tripati, Meluhha is indirectly mentioned to be the same place of the Indus valley civilisation. In the opening sequence of the first book, The Immortals of Meluha (2010), Meluha is shown as a perfect empire created by Lord Rama and then ruled by his followers Suryavanshis. It was clear from its book covers and official trailers, which display the scripts of Harappan language as a reference to it.","input":"Which region was known as meluha during harappan period?"},{"output":"Indian English","context":"Indian English is any of the forms of English characteristic of India.[1] English is the only official language in some states of India and is a lingua franca in the country.[2]\\r\\n\\r\\n\\r\\nThough English is one of the two official languages of the Union Government of India, only a few hundred thousand Indians have English as their first language.[3][4][5][6]\\r\\nAccording to 2001 Census, English is known to 12.6% Indians in the 2001 census.[7] An analysis of the 2001 Census of India[8] concluded that approximately 86 million Indians reported English as their second language, and another 39 million reported it as their third language. No data was available whether these individuals were English speakers or users.\\r\\nAccording to the 2005 India Human Development Survey,[9] of the 41,554 surveyed households reported that 72 percent of men (29,918) did not speak any English, 28 percent (11,635) spoke at least some English, and 5 percent (2,077, roughly 17.9% of those who spoke at least some English) spoke fluent English. Among women, the corresponding percentages were 83 percent (34,489) speaking no English, 17 percent (7,064) speaking at least some English, and 3 percent (1,246, roughly 17.6% of those who spoke at least some English) speaking English fluently.[10] According to statistics of District Information System for Education (DISE) of National University of Educational Planning and Administration under Ministry of Human Resource Development, Government of India, enrollment in English-medium schools increased by 50% between 2008ÿ09 and 2013ÿ14. The number of English-medium school students in India increased from over 15 million in 2008ÿ09 to 29 million by 2013ÿ14.[11]\\r\\nIndia ranks 22 out of 72 countries in the 2016 EF English Proficiency Index published by the EF Education First. The index gives the country a score of 57.30 indicating \\"moderate proficiency\\". India ranks 4th out of 19 Asian countries included in the index.[12] Among Asian countries, Singapore (63.52), Malaysia (60.70) and the Philippines (60.33) received higher scores than India.\\r\\nIn December 2015, the Supreme Court of India ruled that English is the only court language.[13]\\r\\nIndian English generally uses the Indian numbering system. Idiomatic forms derived from Indian literary languages and vernaculars have been absorbed into Indian English. Nevertheless, there remains general homogeneity in phonetics, vocabulary, and phraseology between variants of the Indian English dialect.[14][15][16][17]\\r\\nEnglish language public instruction began in India in the 1830s during the rule of the East India Company (India was then, and is today, one of the most linguistically diverse regions of the world[18]). In 1835, English replaced Persian as the official language of the Company. Lord Macaulay played a major role in introducing English and western concepts to education in India. He supported the replacement of Persian by English as the official language, the use of English as the medium of instruction in all schools, and the training of English-speaking Indians as teachers.[19] Throughout the 1840s and 1850s, primary-, middle-, and high-schools were opened in many districts of British India, with most high schools offering English language instruction in some subjects. In 1857, just before the end of Company rule, universities modelled on the University of London and using English as the medium of instruction were established in Bombay, Calcutta and Madras. During subsequent Crown Rule in India, or the British Raj, lasting from 1858 to 1947, English language penetration increased throughout India. This was driven in part by the gradually increasing hiring of Indians in the civil services. At the time of India's independence in 1947, English was the only functional lingua franca in the country.\\r\\nAfter Indian Independence in 1947, Hindi was declared the first official language, and attempts were made to declare Hindi the sole national language of India. Due to protests from Tamil Nadu and other non-Hindi-speaking states, it was decided to temporarily retain English for official purposes until at least 1965. By the end of this period, however, opposition from non-Hindi states was still too strong to have Hindi declared the sole language. With this in mind, the English Language Amendment Bill declared English to be an associate language \\"until such time as all non-Hindi States had agreed to its being dropped.\\" This hasn't yet occurred, and it is still widely used. For instance, it is the only reliable means of day-to-day communication between the central government and the non-Hindi states.\\r\\nThe view of the English language among many Indians has gone from associating it with colonialism to associating it with economic progress, and English continues to be an official language of India.[20]\\r\\nWhile there is an assumption that English is readily available in India, available studies show that its usage is actually restricted to an elite,[21] because of inadequate education to large parts of the Indian population. The use of outdated teaching methods and the poor grasp of English exhibited by the authors of many guidebooks, disadvantage students who rely on these books.[22]\\r\\nIndian accents vary greatly. Most Indians speak with a more vernacular, native-tinted accent.\\r\\nIn general, the Indian English has fewer peculiarities in its vowel sounds than the consonants, especially as spoken by native speakers of languages like Hindi, the vowel phoneme system having some similarities with that of English. Among the distinctive features of the vowel-sounds employed by some Indian English speakers:\\r\\nAmong the most distinctive features of consonants in Indian English are:\\r\\nA number of distinctive features of Indian English are due to \\"the vagaries of English spelling\\".[29] Most Indian languages, unlike English, have a nearly phonetic spelling, so the spelling of a word is a highly reliable guide to its modern pronunciation. Indians' tendency to pronounce English phonetically as well can cause divergence from Western English. For example, \\"jewellery\\" is pronounced /d??el?ri?/ and \\"jewel\\" as /d??el/ where Western Anglophones might omit the final e and perhaps the second one as well, pronouncing them as /d?u(?)lri?/ and /d?u?l/ or /d?u?l/.\\r\\nEnglish is a stress-timed language, and both syllable stress and word stress, where only certain words in a sentence or phrase are stressed, are important features of received pronunciation. Indian native languages are actually syllable-timed languages, like Latin and French. Indian-English speakers usually speak with a syllabic rhythm.[31] Further, in some Indian languages, stress is associated with a low pitch,[32] whereas in most English dialects, stressed syllables are generally pronounced with a higher pitch. Thus, when some Indian speakers speak, they appear to put the stress accents at the wrong syllables, or accentuate all the syllables of a long English word. Certain Indian accents are of a \\"sing-song\\" nature, a feature seen in a few English dialects in Britain, such as Scouse and Welsh English.[33]\\r\\nThe Indian numbering system is preferred for digit grouping. When written in words, or when spoken, numbers less than 100,000/100 000 are expressed just as they are in Standard English. Numbers including and beyond 100,000 / 100 000 are expressed in a subset of the Indian numbering system. Thus, the following scale is used:\\r\\nLarger numbers are generally expressed as multiples of the above (for example, one lakh crores for one trillion).[34][35]\\r\\nIndian English, naturally, has words of Indian vernaculars that have made their way into the English language, such as jungle, tank (water, irrigation), bungalow, shampoo and verandah. It has political, sociological, and administrative terms of modern India: dharna, hartal, eve-teasing, vote bank, swaraj, swadeshi, scheduled caste, scheduled tribe, NRI; it has words of Anglo-India such as tiffin, hill station, gymkhana; and it has slang.\\r\\nSome examples unique to, or chiefly used in, standard written Indian English include:\\r\\nIndian English generally uses the same British English spelling as Commonwealth nations such as Pakistan, Australia, the United Kingdom, New Zealand, and South Africa. Nowadays due to the growing usage of internet, the American English and its spelling is rapidly gaining popularity in India. Most computers in India use en-us (American English) localisation.\\r\\nSimilarly, in common with most of the Commonwealth, the final letter of the alphabet, Z is pronounced zed. In addition, the punctuation mark at the end of a sentence is referred to as a \\"full stop\\" rather than \\"period\\".\\r\\nClick on a coloured area to see an article about English in that country or region","input":"Which type of english is spoken in india?"},{"output":"a surge of Irish Catholic immigration","context":"Nativism is the political policy or practice of preserving or reviving an indigenous culture.[1] However, this is currently more commonly described as an anti-immigrant position[2] considering the policy to be one of protecting native interests against those of immigrants. In scholarly studies nativism is a standard technical term. The term is typically not accepted by those who hold this political view, however. Dindar (2010) wrote \\"nativists... do not consider themselves as nativists. For them it is a negative term and they rather consider themselves as 'Patriots'\\".[3]\\r\\n\\r\\n\\r\\nAccording to Fetzer (2000), opposition to immigration commonly arises in many countries because of issues of national, cultural, and religious identity. The phenomenon has been studied especially in Australia, Canada, New Zealand, the United Kingdom, and the United States, as well as in Europe. Thus nativism has become a general term for \\"opposition to immigration\\" based on fears that the immigrants will distort or spoil existing cultural values.[4] In situations where immigrants greatly outnumber the original inhabitants,[5] nativistic movements can allow cultural survival. The claim that immigrants can \\"swamp\\" a local population is related to birth rate relative to nationals. Contemporary opponents of immigration blame it for such problems as unemployment, crime (especially through gangs), harm to the environment, housing shortage, and overwhelming social services such as hospitals, police.\\r\\nAnti-immigration sentiment is typically justified with one or more of the following arguments and claims about immigrants:[6]\\r\\nMany Australians opposed the influx of Chinese immigrants at time of the nineteenth-century gold rushes. When the separate Australian colonies formed the Commonwealth of Australia in 1901, the new nation adopted \\"White Australia\\" as one of its founding principles. Under the White Australia policy, entry of Chinese and other Asians remained controversial until well after World War II, although the country remained home to many long-established Chinese families dating from before the adoption of White Australia. By contrast, most Pacific Islanders were deported soon after the policy was adopted, while the remainder were forced out of the canefields where they had worked for decades.[8]\\r\\nHostility of native-born white Australians toward British and Irish immigrants in the late 19th century was manifested in a new party, the \\"Australian Natives' Association.\\"[9][10]\\r\\nSince early 2000, opposition has mounted to asylum seekers arriving in boats from Indonesia.[11]\\r\\nBrazilian elites desired the racial whitening of the country, much as what happened in Argentina and Uruguay, so that it stimulated European immigration, but non-white immigration always face huge backlash. On July 28, 1921, representatives Andrade Bezerra and Cincinato Braga proposed a law whose Article 1 provided: \\"The immigration of individuals from the black race to Brazil is prohibited.\\" On October 22, 1923, representative Fidlis Reis produced another bill on the entry of immigrants, whose fifth article was as follows: \\"The entry of settlers from the black race into Brazil is prohibited. For Asian [immigrants] there will be allowed each year a number equal to 5% of those residing in the country.(...)\\".[12]\\r\\nIn the 19th and 20th centuries, there were negative feelings toward the communities of German, Italian, Japanese, and Jewish immigrants, who conserved their language and culture instead of adopting Portuguese and Brazilian habit (so that nowadays Brazil has the biggest communities in the Americas of speakers of German and Venetian), were seen as particularly tendentious to form ghettos, had high rates of endogamy (in Brazil, it is regarded as usual for people of different backgrounds to miscegenate), among other concerns.\\r\\nIt affected more harshly the Japanese, because they were Asian, and thus seen as an obstacle of the whitening of Brazil. Oliveira Viana, a Brazilian jurist, historian and sociologist described the Japanese immigrants as follows: \\"They (Japanese) are like sulfur: insoluble\\". The Brazilian magazine \\"O Malho\\" in its edition of December 5, 1908 issued a charge of Japanese immigrants with the following legend: \\"The government of S?o Paulo is stubborn. After the failure of the first Japanese immigration, it contracted 3,000 yellow people. It insists on giving Brazil a race diametrically opposite to ours\\".[13] In 1941, the Brazilian Minister of Justice, Francisco Campos, defended the ban on admission of 400 Japanese immigrants in S?o Paulo and wrote: \\"their despicable standard of living is a brutal competition with the country's worker; their selfishness, their bad faith, their refractory character, make them a huge ethnic and cultural cyst located in the richest regions of Brazil\\".[13]\\r\\nSome years before World War II, the government of President Get~lio Vargas initiated a process of forced assimilation of people of immigrant origin in Brazil. The Constitution of 1934 had a legal provision about the subject: \\"The concentration of immigrants anywhere in the country is prohibited; the law should govern the selection, location and assimilation of the alien\\". The assimilationist project affected mainly German, Italian, Japanese and Jewish immigrants and their descendants.[14]\\r\\nDuring the World War II they were seen as more loyal to their countries of origin than to Brazil. In fact, there were violent revolts in the Japanese community of the states of S?o Paulo and Paran when Emperor Hirohito declared that Japan surrendered and he was not a deity, which was thought as a conspiracy trying to hurt Japanese honor and strength. Nevertheless, it followed hostility from the government. The Japanese Brazilian community was strongly marked by restrictive measures when Brazil declared war against Japan in August 1942. Japanese Brazilians could not travel the country without safe conduct issued by the police; over 200 Japanese schools were closed and radio equipment was seized to prevent transmissions on short wave from Japan. The goods of Japanese companies were confiscated and several companies of Japanese origin had interventions, including the newly founded Banco Amrica do Sul. Japanese Brazilians were prohibited from driving motor vehicles (even if they were taxi drivers), buses or trucks on their property. The drivers employed by Japanese had to have permission from the police. Thousands of Japanese immigrants were arrested or expelled from Brazil on suspicion of espionage. There were many anonymous denunciations because of \\"activities against national security\\" arising from disagreements between neighbours, recovery of debts and even fights between children.[13] Japanese Brazilians were arrested for \\"suspicious activity\\" when they were in artistic meetings or picnics. On July 10, 1943, approximately 10,000 Japanese and German immigrants who lived in Santos had 24 hours to close their homes and businesses and move away from the Brazilian coast. The police acted without any notice. About 90% of people displaced were Japanese. To reside in Baixada Santista, the Japanese had to have a safe conduct.[13] In 1942, the Japanese community who introduced the cultivation of pepper in Tom-A?u, in Par, was virtually turned into a \\"concentration camp\\" (expression of the time) from which no Japanese could leave. This time, the Brazilian ambassador in Washington, D.C., Carlos Martins Pereira e Sousa, encouraged the government of Brazil to transfer all the Japanese Brazilians to \\"internment camps\\" without the need for legal support, in the same manner as was done with the Japanese residents in the United States. No single suspicion of activities of Japanese against \\"national security\\" was confirmed.[13]\\r\\nNowadays, nativism in Brazil affects primarily migrants from elsewhere in the Third World, such as the new wave of Levantine Arabs (this time, mostly Muslim from Palestine instead of overwhelmingly Christian from Syria and Lebanon), South and East Asians (primarily Mainland Chinese), Spanish-speakers and Amerindians from neighboring South American countries and, especially, West Africans and Haitians. Following the 2010 Haiti earthquake and considerable illegal immigration to northern Brazil and S?o Paulo,[15] a subsequent debate in the population was concerned with the reasons why Brazil has such lax laws and enforcement concerning illegal immigration.\\r\\nAccording to the 1988's Brazilian Constitution, it is an unbailable crime to address someone in an offensive racist way, and it is illegal to discriminate someone on the basis of his or her race, skin color, national or regional origin or nationality (for more, see anti-discrimination laws in Brazil), thus nativism and opposition to multiculturalism would be too much of a polemic and delicate topic to be openly discussed as a basic ideology of even the most right-leaning modern political parties.\\r\\nNativism was common in Canada (though the term originated in the U.S.). It took several forms. Hostility to the Chinese and other Asians was intense, and involved provincial laws that hindered immigration of Chinese and Japanese and blocked their economic mobility. In 1942 Japanese Canadians were forced into detention camps in response to Japanese aggression in World War II.[16]\\r\\nThroughout the 19th century, well into the 20th, the Orange Order in Canada attacked and tried to politically defeat the Irish Catholics.[17] The Ku Klux Klan spread in the mid-1920s from the U.S. to parts of Canada, especially Saskatchewan, where it helped topple the Liberal government. The Klan creed was, historian Martin Robin argues, in the mainstream of Protestant Canadian sentiment, for it was based on \\"Protestantism, separation of Church and State, pure patriotism, restrictive and selective immigration, one national public school, one flag and one languageEnglish.\\"[18][9]\\r\\nIn World War I, Canadian naturalized citizens of German or Austrian origins were stripped of their right to vote, and tens of thousands of Ukrainians (who were born in the Austro-Hungarian Empire) were rounded up and put in internment camps.[19]\\r\\nHostility of native-born Canadians to competition from English immigrants in the early 20th century was expressed in signs that read, \\"No English Need Apply!\\" The resentment came because the immigrants identified more with England than with Canada.[20]\\r\\nIn the British Empire, traditions of anti-Catholicism in Britain led to fears that Catholics were a threat to the national (British) values. In Canada, the Orange Order (of Irish Protestants) campaigned vigorously against the Catholics throughout the 19th century, often with violent confrontations. Both sides were immigrants from Ireland and neither side claimed loyalty to Canada.[21] The Orange Order was much less influential in the U.S., especially after a major riot in New York City in 1871.[22]\\r\\nNativism in Hong Kong is often used as a synonymy with localism,[23] which strives for the autonomy of Hong Kong and resist China's authorities influence in the city. In addition to their strong anti-communist and pro-democracy tendency, It often holds a strong anti-mainland sentiments, especially the influx of the mainland tourists and immigrants, seeing them as a threat to Hong Kong identity and culture.\\r\\nFor the Poles in the mining districts of western Germany before 1914, it was nationalism (on both the German and the Polish sides), which kept Polish workers, who had established an associational structure approaching institutional completeness (churches, voluntary associations, press, even unions), separate from the host German society. Lucassen found that religiosity and nationalism were more fundamental in generating nativism and inter-group hostility than the labor antagonism.\\r\\nOnce Italian workers in France had understood the benefit of unionism and French unions were willing to overcome their fear of Italians as strikebreakers, integration was open for most Italian immigrants. The French state, which was always more of an immigration state than Prussia, Germany or Great Britain, fostered and supported family-based immigration and thus helped Italians on their immigration trajectory with minimal nativism. (Lucassen 2005)\\r\\nMany observers see the post-1950s wave of immigration in Europe was fundamentally different from the pre-1914 patterns. They debate the role of cultural differences, ghettos, race, Muslim fundamentalism, poor education and poverty play in creating nativism among the hosts and a caste-type underclass, more similar to white-black tensions in the US (Lucassen 2005). Algerian migration to France has generated nativism, characterized by the prominence of Jean-Marie Le Pen and his National Front. (Lucassen 2005)\\r\\nThe Pakistani province of Sindh has seen nativist movements, promoting control for the Sindhi people over their homeland. After the 1947 Partition of India, large numbers of Muhajir people migrating from India entered the province, becoming a majority in the provincial capital city of Karachi, which formerly had an ethnically Sindhi majority. Sindhis have also voiced opposition to the promotion of Urdu, as opposed to their native tongue, Sindhi.\\r\\nThese nativist movements are expressed through Sindhi nationalism and the Sindhudesh separatist movement. Nativist and nationalist sentiments increased greatly after the independence of Bangladesh from Pakistan in 1971.\\r\\nNativism flourished in Taiwan in the 1970s as a reaction against the influx of mainland Chinese to the island after the Kuomintang's defeat in 1949. Nativists felt that the political influence of mainland Chinese was disproportionately large. The term is especially found in the field of literature, where nativist literature was more traditionally minded than the modernist literature written largely by mainland Chinese.\\r\\nLondon was notorious for its xenophobia in the 16th century, and conditions worsened in the 1580s. Many immigrants became disillusioned by routine threats of violence and molestation, attempts at expulsion of foreigners, and the great difficulty in acquiring English citizenship. Dutch cities proved more hospitable, and many left London permanently.[24]\\r\\nRegarding the Irish in 20th-century Great Britain, Lucassen (2005) argues the deep religious divide between the Protestants and Catholics was at the core of the ongoing estrangement of the Irish in British society.\\r\\nIn the United States, nativism has a long history. The term was first used by 1844, according to the Oxford English Dictionary (under \\"Nativism\\") 1844: Whig Almanac 1845 4/2 \\"Thousands were Naturalized expressly to oppose Nativism, and voted the Polk ticket mainly to that end.\\"\\r\\nFor a while Benjamin Franklin was hostile to Germans in colonial Pennsylvania, but he reversed himself and became a supporter.[25] The Federalist Party in 1798 passed the Alien and Sedition Acts which lengthened the citizenship process to 14 years to weaken the political role of radical immigrants from France and Ireland. This became a major political issue in the 1800 election; the Jeffersonians won. They welcomed immigrants and repealed most of the restrictions.[26]\\r\\nNativism gained its name from the \\"Native American\\" parties of the 1840s and 1850s. In this context \\"Native\\" does not mean indigenous Americans or American Indians but rather those descended from the inhabitants of the original Thirteen Colonies. It impacted politics in the mid-19th century because of the large inflows of immigrants after 1845 from cultures that were different from the existing American culture. Nativists objected primarily to Irish Roman Catholics because of their loyalty to the Pope and also because of their supposed rejection of republicanism as an American ideal.[27]\\r\\nNativist movements included the Know Nothing or American Party of the 1850s, the Immigration Restriction League of the 1890s, the anti-Asian movements in the West, resulting in the Chinese Exclusion Act of 1882 and the \\"Gentlemen's Agreement of 1907\\" by which Japan's government stopped emigration to the United States. Labor unions were strong supporters of Chinese exclusion and limits on immigration, because of fears that they would lower wages and make it harder for workers to organize unions.[28]\\r\\nHistorian Eric Kaufmann has suggested that American nativism has been explained primarily in psychological and economic terms due to the neglect of a crucial cultural and ethnic dimension. Furthermore, Kauffman claims that American nativism cannot be understood without reference to an American ethnic group which took shape prior to the large-scale immigration of the mid-eighteenth century.[29]\\r\\nNativist outbursts occurred in the Northeast from the 1830s to the 1850s, primarily in response to a surge of Irish Catholic immigration. In 1836, Samuel Morse ran unsuccessfully for Mayor of New York City on a Nativist ticket, receiving 1,496 votes. In New York City, an Order of United Americans was founded as a nativist fraternity, following the Philadelphia Nativist Riots of the preceding spring and summer, in December, 1844.[30]\\r\\nIn 1849ÿ50 Charles B. Allen founded a nativist society called the Order of the Star Spangled Banner in New York City. In order to join the Order, a man had to be twenty-one, a Protestant, a believer in God, and willing to obey without question the dictates of the order. Members of the Order became known as the Know Nothings (a label applied to them because if asked they said they \\"know nothing about\\" the secret society).[30]\\r\\nThe Nativists went public in 1854 when they formed the 'American Party', which was especially hostile to the immigration of Irish Catholics and campaigned for laws to require longer wait time between immigration and naturalization. (The laws never passed.) It was at this time that the term \\"nativist\\" first appears, opponents denounced them as \\"bigoted nativists.\\" Former President Millard Fillmore ran on the American Party ticket for the Presidency in 1856. The American Party also included many ex-Whigs who ignored nativism, and included (in the South) a few Catholics whose families had long lived in America. Conversely, much of the opposition to Catholics came from Protestant Irish immigrants and German Lutheran immigrants who were not native at all and can hardly be called \\"nativists.\\"[31]\\r\\nThis form of nationalism is often identified with xenophobia and anti-Catholic sentiment (anti-Papism). In Charlestown, Massachusetts, a nativist mob attacked and burned down a Catholic convent in 1834 (no one was injured). In the 1840s, small scale riots between Catholics and nativists took place in several American cities. In Philadelphia in 1844, for example, a series of nativist assaults on Catholic churches and community centers resulted in the loss of lives and the professionalization of the police force. In Louisville, Kentucky, election-day rioters killed at least 22 people in attacks on German and Irish Catholics on Aug. 6, 1855, in what became known as \\"Bloody Monday.\\"[32] Nativist sentiment experienced a revival in the 1890s, led by Protestant Irish immigrants hostile to Catholic immigration.[33]\\r\\nFrom the 1840s to 1920 German Americans were distrusted because of their separatist social structure, their German-language schools, their attachment to their native tongue over English, and their neutrality during World War I.\\r\\nThe Bennett Law caused a political uproar in Wisconsin in 1890, as the state government passed a law that threatened to close down hundreds of German-language elementary schools. Catholic and Lutheran Germans rallied to defeat Governor William D. Hoard. Hoard attacked German American culture and religion:\\r\\nHoard, a Republican, was defeated by the Democrats. A similar campaign in Illinois regarding the \\"Edwards Law\\" led to a Republican defeat there in 1890.[34]\\r\\nIn 1917ÿ1918, a wave of nativist sentiment led to the suppression of German cultural activities in the United States, Canada and Australia. There was little violence, but many places and streets had their names changed (The city of \\"Berlin\\" in Ontario was renamed \\"Kitchener\\" after a British hero), churches switched to English for their services, and German Americans were forced to buy war bonds to show their patriotism.[35] In Australia thousands of Germans were put into internment camps.[36]\\r\\n(See also: World War I Anti-German Sentiment)\\r\\nIn the 1870s in the western states Irish Americans targeted violence against Chinese workers, driving them out of smaller towns. Denis Kearney, an immigrant from Ireland, led a mass movement in San Francisco in the 1870s that incited attacks on the Chinese there and threatened public officials and railroad owners.[37] The Chinese Exclusion Act of 1882 was the first of many nativist acts of Congress which attempted to limit the flow of immigrants into the U.S. The Chinese responded to it by filing false claims of American birth, enabling thousands of them to immigrate to California.[38] The exclusion of the Chinese caused the western railroads to begin importing Mexican railroad workers in greater numbers (\\"traqueros\\").[39]\\r\\nIn the 1890sÿ1920s era nativists and labor unions campaigned for immigration restriction. A favorite plan was the literacy test to exclude workers who could not read or write their own foreign language. Congress passed literacy tests, but presidentsresponding to business needs for workersvetoed them.[40] Senator Henry Cabot Lodge argued need for literacy tests and its implication on the new immigrants:\\r\\nResponding to these demands, opponents of the literacy test called for the establishment of an immigration commission to focus on immigration as a whole. The United States Immigration Commission, also known as the Dillingham Commission, was created and tasked with studying immigration and its effect on the United States. The findings of the commission further influenced immigration policy and upheld the concerns of the nativist movement.[40]\\r\\nFollowing World War I, nativists in the twenties focused their attention on Catholics, Jews, and south-eastern Europeans and realigned their beliefs behind racial and religious nativism.[42] The racial concern of the anti-immigration movement was linked closely to the eugenics movement that was sweeping the United States in the twenties. Led by Madison Grant's book, The Passing of the Great Race nativists grew more concerned with the racial purity of the United States. In his book, Grant argued that the American racial stock was being diluted by the influx of new immigrants from the Mediterranean, the Balkans, and the Polish ghettos. The Passing of the Great Race reached wide popularity among Americans and influenced immigration policy in the twenties.[40] In the 1920s a wide national consensus sharply restricted the overall inflow of immigrants, especially those from southern and eastern Europe. The second Ku Klux Klan, which flourished in the U.S. in the 1920s, used strong nativist rhetoric, but the Catholics led a counterattack.[43]\\r\\nAfter intense lobbying from the nativist movement the United States Congress passed the Emergency Quota Act in 1921. This bill was the first to place numerical quotas on immigration. It capped the inflow of immigrations to 357,803 for those arriving outside of the western hemisphere.[40] However, this bill was only temporary as Congress began debating a more permanent bill.\\r\\nThe Emergency Quota Act was followed with the Immigration Act of 1924, a more permanent resolution. This law reduced the number of immigrants able to arrive from 357,803, the number established in the Emergency Quota Act, to 164,687.[40] Though this bill did not fully restrict immigration, it considerably curbed the flow of immigration into the United States. During the late twenties an average of 270,000 immigrants were allowed to arrive mainly because of the exemption of Canada and Latin American countries.[42]\\r\\nFear of low-skilled immigrants flooding the labor market was an issue in the 1920s (focused on immigrants from Italy and Poland), and in the first decade of the 21st century (focused on immigrants from Mexico and Central America).\\r\\nAn immigration reductionism movement formed in the 1970s and continues to the present day. Prominent members often press for massive, sometimes total, reductions in immigration levels.\\r\\nAmerican nativist sentiment experienced a resurgence in the late 20th century, this time directed at illegal aliens, largely Mexican resulting in the passage of new penalties against illegal immigration in 1996.\\r\\nMost immigration reductionists see Illegal immigration, principally from across the United StatesÿMexico border, as the more pressing concern. Authors such as Samuel Huntington have also seen recent Hispanic immigration as creating a national identity crisis and presenting insurmountable problems for US social institutions.[44]\\r\\nNoting the large-scale Mexican immigration in the Southwest, the Cold-war diplomat George F. Kennan in 2002 saw \\"unmistakable evidences of a growing differentiation between the cultures, respectively, of large southern and southwestern regions of this country, on the one hand\\", and those of \\"some northern regions\\". In the former, he warned:\\r\\nMeyers argues that Kennan represented the \\"tradition of militant nativism\\" that resembled or even exceeded the Know Nothings of the 1850s.[46] Mayers adds that Kennan also believed American women had too much power.\\r\\nBy late 2014, the \\"Tea Party movement\\" had turned its focus away from economic issues, spending, and Obamacare, and towards President Barack Obama's immigration policies, which it saw as threatening to transform American society. It planned to defeat leading Republicans who supported immigration programs, such as Senator John McCain. A typical slogan appeared in the Tea Party Tribune: Amnesty for Millions, Tyranny for All. The New York Times reported:\\r\\nIn his 2016 bid for presidency, Republican Presidential Candidate Donald Trump has been accused of introducing nativist themes for his controversial stances on temporarily banning foreign Muslims from entering the United States and erecting a substantial wall between the US-Mexico border to halt illegal immigration. Journalist John Cassidy wrote in The New Yorker Trump is transforming the GOP into a populist, nativist party:\\r\\nDonald Brand, a professor of political science, argues:\\r\\nAmerican nativists have promoted English and deprecated the use of German and Spanish. English Only proponents in the late 20th century proposed an English Language Amendment (ELA), a Constitutional Amendment making English the official language of the United States, but it received limited political support.[50]","input":"What led to the rise of nativism in the mid 1800s?"},{"output":"Saint Catherine of Alexandria","context":"The Catherine wheel or pinwheel is a type of firework consisting of a powder-filled spiral tube, or an angled rocket mounted with a pin through its center. When ignited, it rotates quickly, producing a display of sparks and coloured flame.\\r\\n\\r\\nThe firework is named after Saint Catherine of Alexandria who, according to Christian tradition, was condemned to death by breaking on the wheel. When she touched the wheel it miraculously flew to pieces.\\r\\n\\r\\nThe largest Catherine wheel ever made was designed by the Lily Fireworks Factory of Mqabba, Malta. The Catherine wheel had a diameter of 32.044?m (105?ft 1.6?in), and was lit on 18 June 2011, the eve of the annual feast of Our Lady of the Lilies.[1][2]\\r\\n\\r\\nIn Malta, Catherine wheels are a traditional fixture during every village 'festa'. Some villages even hold competitions on the eve of the parish feast, while others display the vast work of one firework factory. Entrants display a variety of moving shapes and include various colours year after year as the technology progresses. These displays are only a small part of the firework catalogue planned throughout the week preceding the feast and on the feast day itself. The Catherine wheel displays typically end with the burning of what is called 'the carpet': the largest Catherine wheel in the display on the night. \\r\\n\\r\\nIn the Philippines, Catherine wheel is also known as trompillo and according to Republic Act 7183, it is a legal firework.[3][4]","input":"How did the catherine wheel get its name?"},{"output":"9th and 10th centuries","context":"","input":"When were the first castles built in europe?"},{"output":"in the northwest part of the Weddell Sea, extending along the east coast of the Antarctic Peninsula from Cape Longing to the area just southward of Hearst Island","context":"The Larsen Ice Shelf is a long ice shelf in the northwest part of the Weddell Sea, extending along the east coast of the Antarctic Peninsula from Cape Longing to the area just southward of Hearst Island. In 2005, it covered approximately 78500 km2 of the earth's sea with exceptionally thick ice. It is named for Captain Carl Anton Larsen, the master of the Norwegian whaling vessel Jason, who sailed along the ice front as far as 6810' South during December 1893.[1] In finer detail, the Larsen Ice Shelf is a series of shelves that occupy (or occupied) distinct embayments along the coast. From north to south, the segments are called Larsen A (the smallest), Larsen B, and Larsen C (the largest) by researchers who work in the area.[2] Further south, Larsen D and the much smaller Larsen E, F and G are also named.[3]\\r\\nThe breakup of the ice shelf since the mid-1990s has been widely reported,[4] with the collapse of Larsen B in 2002 being particularly dramatic. A large section of the Larsen C shelf was reported to have broken away in July 2017.[5]\\r\\n\\r\\n\\r\\nThe collapse of Larsen B has revealed a thriving chemotrophic ecosystem 800?m (half a mile) below the sea. The discovery was accidental. U.S. Antarctic Program scientists were in the north-western Weddell Sea investigating the sediment record in a deep glacial trough of roughly 1,000,000 square kilometres (390,000?sq?mi) (twice the size of Texas or France). Methane and hydrogen sulfide associated with cold seeps is suspected as the source of the chemical energy powering the ecosystem. The area had been protected by the overlying ice sheet from debris and sediment which was seen to be building up on the white microbial mats after the breakup of the ice sheet. Clams were observed clustered about the vents.[6]\\r\\nThe former Larsen A region, which was the farthest north and was just outside the Antarctic Circle, had previously broken up in the middle of the present interglacial and reformed only about 4,000 years ago. The former Larsen B, by contrast, had been stable for at least 10,000 years.[7] The ice of the shelf is renewed on a much shorter time-scale and the maximal ice age on the current shelf dates from only two hundred years ago. The speed of Crane Glacier increased threefold after the collapse of the Larsen B, likely due to the removal of a buttressing effect of the ice shelf.[8] Data collected in 2007 by an international team of investigators through satellite-based radar measurements suggests that the overall ice-sheet mass balance in Antarctica is increasingly negative.[9]\\r\\nThe Larsen disintegration events were unusual by past standards. Typically, ice shelves lose mass by iceberg calving and by melting at their upper and lower surfaces. The disintegration events were linked by The Independent newspaper in 2005 to ongoing climate warming in the Antarctic Peninsula, about 0.5 degrees C (0.9 degrees F) per decade since the late 1940s.[10] According to a paper published in Journal of Climate in 2006, the peninsula at Faraday station warmed by 2.94 degrees C (5.3 degrees F) from 1951 to 2004, much faster than Antarctica as a whole and faster than the global trend; this localized warming is caused by anthropogenic global warming, through a strengthening of the winds circling the Antarctic.[11]\\r\\nThe Larsen A ice shelf disintegrated in January 1995.[2]\\r\\nFrom 31 January 2002 to March 2002 the Larsen B sector partially collapsed and parts broke up, 3,250?km2 (1,250?sq?mi) of ice 220?m (720?ft) thick, an area comparable to the US state of Rhode Island.[12] In 2015, a study concluded that the remaining Larsen B ice-shelf will disintegrate by 2020, based on observations of faster flow and rapid thinning of glaciers in the area.[13]\\r\\nLarsen B was stable for at least 10,000 years, essentially the entire Holocene period since the last glacial period.[7] By contrast, Larsen A was absent for a significant part of that period, reforming about 4,000 years ago.\\r\\nDespite its great age, the Larsen B was clearly in trouble at the time of the collapse. With warm currents eating away the underside of the shelf, it had become a \\"hotspot of global warming\\".[14] It broke in a time of three weeks or less, with a factor in this fast break-up being the powerful effects of water; ponds of meltwater formed on the surface during the near 24 hours of daylight in the summertime, then the water flowed down into cracks and, acting like a multitude of wedges, levered the shelf apart.[15][16] Other likely factors in the break-up were the higher ocean temperatures and the decline of the ice of the peninsula.[17]\\r\\nAs of July 2017[update], Larsen C is the fourth largest ice shelf in Antarctica, with an area of about 44,200?km2 (17,100?sq?mi).[18]\\r\\nSatellite radar altimeter measurements show that between 1992 and 2001 the Larsen Ice Shelf lowered by up to 0.27 I 0.11 meters per year.[19] In 2004, a report concluded that although the remaining Larsen C region appeared to be relatively stable,[20] continued warming could lead to its breakup within the following decade.[21] A large iceberg broke away in July 2017 but, although noteworthy, is most likely part of a natural calving process that balances inflow of ice from glaciers into the ice sheet.\\r\\nThe breakaway process for the iceberg had begun by mid-2016.[22][23] On 10 November 2016 scientists photographed the growing rift running along the Larsen C ice shelf,[24] showing it running about 110 kilometres (68?mi) long with a width of more than 91?m (299?ft), and a depth of 500?m (1,600?ft). By December 2016, the rift had extended another 21?km (13?mi) to the point where only 20?km (12?mi) of unbroken ice remained and calving was considered to be a certainty in 2017.[25] This was predicted to cause the calving of between nine and twelve percent of the ice shelf, 6,000?km2 (2,300?sq?mi), an area greater than the US state of Delaware,[18] or twice the size of Luxembourg.[26] The calved fragment was predicted to be 350?m (1,150?ft) thick and to have an area of about 5,000?km2 (1,900?sq?mi).[18] The resulting iceberg was predicted to be among the largest icebergs ever recorded, unless it would break into multiple pieces.[25]\\r\\nOn 1 May 2017 members of MIDAS reported that satellite images showed a new crack, around 15?km (9?mi) long, branching off the main crack approximately 10?km (6?mi) behind the previous tip, heading toward the ice front.[27] Scientists with Swansea University in the UK say the crack lengthened 18?km (11?mi) from 25 May to 31 May, and that less than 13?km (8?mi) of ice is all that prevents the birth of an enormous iceberg. \\"The rift tip appears also to have turned significantly towards the ice front, indicating that the time of calving is probably very close,\\" Adrian Luckman and Martin O'Leary wrote on Wednesday in a blog post for the Impact of Melt on Ice Shelf Dynamics and Stability project, or MIDAS. \\"There appears to be very little to prevent the iceberg from breaking away completely.\\" The larger swath of the Larsen C ice shelf that sat behind the calved iceberg \\"will be less stable than it was prior to the rift\\" and may rapidly disintegrate in the same manner as Larsen B did in 2002.[28]\\r\\nIn June 2017 the speed of the imminent Larsen C iceberg accelerated, with the eastern end moving at 10 metres (33?ft) per day away from the main shelf.[29] As discussed by the Project MIDAS researchers on their site: In another sign that the iceberg calving is imminent, the soon-to-be-iceberg part of Larsen C ice shelf has tripled in speed to more than 10 meters per day between 24 and 27 June 2017. The iceberg remains attached to the ice shelf, but its outer end is moving at the highest speed ever recorded on this ice shelf.[30]\\r\\nOn 7 July the Project MIDAS blog report stated: \\"The latest data from 6th July reveal that, in a release of built-up stresses, the rift branched several times. Using data from ESA's Sentinel-1 satellites, we can see that there are multiple rift tips now within 5 km (3.10 miles) of the ice edge. We expect that these rifts will lead to the formation of several smaller icebergs.\\"[31]\\r\\nOn 12 July 2017, Project MIDAS announced that a large, 5,800-square-kilometre (2,200?sq?mi) portion of Larsen C had broken from the main ice sheet at some point between 10 and 12 July.[5][32] The iceberg, designated A-68, weighs more than a trillion tons[33][34] and is more than 200?m (700?ft) thick.[35][36]\\r\\nProject MIDAS updated their blog information on 19 July 2017 regarding Larsen C by revealing that a possible new rift appeared to be extending northwards from the point where A-68 had broken off in mid-July. The project researchers felt this questionable new rift might turn towards the shelf edge, compounding the risk that it would \\"continue on to Bawden ice rise\\" which is considered \\"a crucial point of stabilization for Larsen C Ice Shelf.[37]\\r\\nA68's departure from Antarctica did not immediately affect global sea levels. However, a number of glaciers discharge onto the shelf from the land behind it, and they may now flow faster due to reduced support from the ice shelf. If all the ice that the Larsen C shelf currently holds back were to enter the sea, it is estimated that global waters would rise by 10?cm (4?in).[38]\\r\\nThe Larsen D Ice Shelf is between Smith Peninsula in the south and Gipps Ice Rise. It is considered to be generally stable. Over roughly the past fifty years it has advanced (expanded) whereas comparable George VI, Bach, Stange, and Larsen C ice shelves have retreated (to a much greater net extent). The most recent survey of Larsen D measured it at 22,600 km2. There is fast ice along the entire front. This makes it difficult to interpret the ice front because the semi-permanent sea ice varies in thickness and may be nearly indistinguishable from shelf ice.[39]\\r\\nLarsen A and Larsen B ice shelves marked in red.\\r\\nClear view of the Antarctic Peninsula, the Larsen Ice Shelf, and the sea ice covered waters around the region.\\r\\nLarsen B area in March 2013\\r\\n2016 rift in Larsen C, detail\\r\\nImagery from NASA's Aqua MODIS showing the complete break of the ice shelf as of 12 July 2017\\r\\nRadar imagery from ESA's Sentinel-1B taken on 12 July 2017, showing the complete break\\r\\nCoordinates: 6730S 6230W? / ?67.500S 62.500W? / -67.500; -62.500","input":"Where is the larsen c ice shelf located?"},{"output":"thirteen","context":"","input":"How many states were there when the declaration of independence was signed?"},{"output":"\\"whenever employee noise exposures equal or exceed an 8-hour time-weighted average sound level (TWA) of 85 decibels (dB) measured on the A scale (slow response) or, equivalently, a dose of fifty percent.\\"","context":"Hearing conservation programs are designed to prevent hearing loss due to noise.  Regarding occupational exposures to noise, a written hearing conservation program is required by the Occupational Safety and Health Administration (OSHA) \\"whenever employee noise exposures equal or exceed an 8-hour time-weighted average sound level (TWA) of 85 decibels (dB) measured on the A scale (slow response) or, equivalently, a dose of fifty percent.\\"[1]  This 8-hour time-weighted average is known as an exposure action value.  While the Mine Safety and Health Administration (MSHA) also requires a hearing conservation program, MSHA does not require a written hearing conservation program.  MSHA's hearing conservation program requirement can be found in 30 CFR  62.150,[2] and requires has almost the same exact requirements as the OSHA hearing conservation program requirements.  Therefore, only the OSHA standard 29 CFR 1910.95 will be discussed in detail.\\r\\n\\r\\nThe OSHA standard contains a series of program requirements.\\r\\n\\r\\nA sound survey is often completed to determine areas of potential high noise exposure. A noise screening is completed initially to determine which areas are higher than 80?dB A. For these areas, an official sound survey will take place.[3] This type of survey is normally completed using a sound level meter (SLM).  There are three types of sound level meters.  Type 0 is precision instrument normally used in laboratories.  Type 1 is for precision measurements taken in the field.  Type 2 sound level meters are less precise than type 1 and are often used to take all-purpose sound level measurements.  Noise monitoring is generally completed using a noise dosimeter that integrates \\"all continuous, intermittent and impulsive sound levels\\"[4] to determine a person's noise exposure level.\\r\\n\\r\\nSurveys must be repeated when there are significant changes in machinery and/or processes that would affect the noise level.[5]\\r\\n\\r\\nEngineering controls and administrative controls are ranked as the most effective protection from noise in the hierarchy of controls.[6] Engineering controls are measures taken to reduce the intensity of noise at the source or between the source and a person exposed to the noise.[7] Administrative controls are limitations around noise sources that limit length of noise exposure.[7]\\r\\n\\r\\nIf engineering controls fail to maintain an 8-hour time-weighted average below 85 dBA, then a hearing protection device (HPD) is required.[8]  There are two general types of HPDs: earplugs and earmuffs.  Each one has its own benefits and drawbacks.  The selection of the proper HPD to be worn is commonly done by an industrial hygienist so that the proper amount of noise protection is worn.  OSHA requires that HPD be given free of charge.[9]\\r\\n\\r\\nThere are four general classes of earplugs. These include: pre-molded, formable, custom molded and semi-insert.\\r\\n\\r\\nEarmuffs are another type of HPD.  The main difference between earmuffs and earplugs, is that earmuffs are not inserted inside the ear canal.  Instead the muffs create a seal around the outside of the ear to prevent noise from reaching the inner ear.  Earmuffs are easy to wear and often provide a more consistent fit than an earplug.  There are earmuffs available that use the principle of active noise control to help reduce noise exposures. However, the protection earmuffs offer may be mitigated by large sideburns or glasses as the seal of the earmuffs may be broken by these objects.[10]\\r\\n\\r\\nThe United States Environmental Protection Agency (EPA) requires that all hearing protection devices be labeled with their associated noise reduction rating (NRR).[11]  The NRR provides the estimated attenuation of the hearing protection device.  However, it has been found that the \\"labeled manufacturers' noise reduction ratings (NRRs) substantially overestimated the actual field attenuation performance.\\"[12][13]  To determine the amount of noise reduction afforded by a hearing protection device, OSHA recommends that 7?dB be subtracted from the NRR.  The NRR is generally given in a C-weighted format, so to obtain the A-weighted reduction, one must subtract 7?dB.  OSHA also recommends a 50% safety factor, therefore the final OSHA recommended reduction would be (NRR-7)/2.[14]\\r\\n\\r\\nFit testing for hearing protection\\r\\n\\r\\nThe NRR now has some help. Fit testing devices on the market that will verify a proper fit of an HPD (hearing protection device).  The fit of a hearing protector is very important, because if the HPD is not worn properly, the NRR becomes irrelevant.  Products that will verify proper fit include: 3M EARFit Validation System, FitCheck, FitCheck Solo, INTEGRAfit, SafetyMeter, and VeriPro.  Fit-test systems provide a Personal Attenuation Rating (PAR) that is currently dependent upon the company that manufactures the fit-testing system.  Most fit test systems provide an A-weighted PAR, which means that the attenuation can be subtracted from the A-weighted noise exposure assessment of the employee or hearing protector user.[15]\\r\\n\\r\\nA-weighted Noise\\r\\n\\r\\nValidation System\\r\\n\\r\\nConfidence Interval\\r\\n\\r\\nFitCheck\\r\\n\\r\\nunder headphones\\r\\n\\r\\nFitCheck Solo\\r\\n\\r\\nunder headphones\\r\\n\\r\\nINTEGRAFIt\\r\\n\\r\\nunder headphones\\r\\n\\r\\nFit-TestSystem\\r\\n\\r\\nthen subtract directly\\r\\n\\r\\nC-weighted noise levels\\r\\n\\r\\nVeriPRO\\r\\n\\r\\nunder headphones\\r\\n\\r\\nTable: Fit-testing systems, PAR measurement method and application to estimate protected exposure level.[15]\\r\\n\\r\\nAudiometric testing is a part of the hearing conservation program that is used in the identification of significant hearing loss.  Audiometric testing can identify those who have permanent hearing loss.  This is called noise-induced permanent threshold shift (NIPTS).[16]\\r\\n\\r\\nCompleting baseline audiograms and periodically monitoring threshold levels is one way to track any changes in hearing and identify if there is a need to make improvements to the hearing conservation program.  OSHA, which monitors workplaces in the United states to ensure safe and healthful working conditions, specifies that employees should have a baseline audiogram established within 6 months of their first exposure to 85 dBA time-weighted average (TWA). If a worker is unable to obtain a baseline audiogram within 6 months of employment, HPD is required to be worn if the worker is exposed to 85 dBA or above TWA. HPD must be worn until a baseline audiogram is obtained.[17] Under the MSHA, which monitors compliance to standards within the mining industry, an existing audiogram that meets specific standards can be used for the employees baseline. Before establishing baseline, it is important that the employee limit excessive noise exposure that could potentially cause a temporary threshold shift and affect results of testing. OSHA stipulates that an employee be noise-free for at least 14 hours prior to testing.[17]\\r\\n\\r\\nPeriodic audiometric monitoring, typically completed annually as recommended by OSHA, can identify changes in hearing. There are specific criteria that the change must meet in order to require action. The criterion most commonly used is the standard threshold shift (STS), defined by a change of 10?dB or greater averaged at 2000, 3000, and 4000?Hz.[17] Age correction factors can be applied to the change in order to compensate for hearing loss that is age-related rather than work-related. If an STS is found, OSHA requires that the employee be notified of this change within 21 days.[17] Furthermore, any employee that is not currently wearing HPD is now required to wear protection. If the employee is already wearing protection, they should be refit with a new device and retrained on appropriate use.[17]\\r\\n\\r\\nAnother determination that is made includes whether an STS is recordable under OSHA standards, meaning the workplace must report the change to OSHA. In order to be recordable the employees new thresholds at 2000, 3000, and 4000?Hz must exceed an average of 25?dB HL.[17] MSHA standard differs slightly in terms of calculation and terminology. MSHA considers whether an STS is reportable by determining if the average amount of change that occurs exceeds 25?dB HL.[17] The various measures that are used in occupational audiometric testing allow consistency in standards within workplaces. Completing baseline and follow-up audiograms allows workplaces to detect hearing loss as early as possible and determine whether changes need to be made to provide a safe working environment for their employees.\\r\\n\\r\\nProper training and education of those exposed to noise is the key to preventing noise-induced hearing loss.  If employees are properly trained on how to follow a hearing conservation program, then the risk of noise-induced hearing loss is reduced. By providing information on the physiological effects of noise exposure, the importance of obtaining baseline and annual audiograms, and use of appropriate hearing protection, the program will provide a thorough knowledge base for employees involved. Providing a refresher training when appropriate will support retention of this information.[18] OSHA requires this training to be completed on an annual basis.  Proper training is imperative since \\"even with a very modest amount of instruction attenuation performance can be significantly improved.\\"[19][20]\\r\\n\\r\\nTo carry out a hearing conservation training, the program may utilize a variety of materials to relay the necessary information. An assortment if written, video, audio, and hands on experience may make the training more interactive and meaningful to employees. It is recommended that materials also be translated into languages other than English so all employees can attend and benefit from the training. Pre- and post-assessments, a safe and secure learning environment, access to training media and equipment, informational handouts/pamphlets, and examples of hearing protection devices are all resources that can contribute to successful HLPP trainings.\\r\\n\\r\\nEven with training and education, the workers need to be motivated to use hearing protection on a regular basis for the hearing conservation program to be successful.[15]  Even if workers are aware that noise can cause hearing loss, that does not guarantee that they will take the necessary actions to preserve their hearing.[15]\\r\\n\\r\\nThere are several reasons why a worker may choose not to adopt the protocols of a hearing conservation program. Employees may not follow protocol because they feel that noise induced hearing loss will not happen to them.[15]  They may believe this because they think the level of sound that they are exposed is not loud enough to cause hearing loss or that loud noise just toughens their ears. They might also think hearing loss is not a serious condition and can easily be fixed with hearing aids.[15] Another reason is the worker may believe that hearing protection does not actually work and that he/she may still develop noise-induced hearing loss even with hearing protection.[15]  If the employee feels that hearing protection may impinge his/her work, whether it be missing important warning signals or the ability to communicate, he/she is less likely to wear it.[15] Finally, the comfort of the hearing protection offered through the hearing conservation program.[21] If the hearing protection is uncomfortable, it is unlikely that the worker will adhere to the policies.[21]\\r\\n\\r\\nMotivational techniques can be implemented to promote hearing conservation program compliance and the use of hearing protection. One suggestion is continued education at the workers' audiometric screening.[21] They should be asked to bring along their current hearing protection device to the screening.  If the results are normal and the inspection of the hearing protection device is good, praise can be given for following protocol.  If there is a shift in their hearing, instruction can be given again about the proper use of hearing protection and the importance of wearing them. Audiograms can be very useful in showing workers how noise can affect their hearing. One specific way to do this is to perform two hearing test on an employee on two different days.[21]  One day the hearing test will be after wearing hearing protection all day and the other will be after not wearing hearing protection for the day.  The difference can then be discussed with the worker and he/she has a tangible way to see how noise affects hearing.  Another technique is using \\"internal triggers\\" to motivate employees to comply to the hearing conservation program.[15]  If the individual already suffers from tinnitus and/or hearing loss they are probably more likely to use hearing protection because he/she does not want that problem to progress with noise exposure.  Finally, the hearing protection offered should be comfortable so the worker will wear it. It is suggested that workers have a variety of hearing protection devices available to them, including at least one type of earmuff and two different forms of earplugs, to fit the individual needs and wants of the workers.[21]\\r\\n\\r\\nOSHA requires that records of exposure measurements and audiometric tests be maintained.  Records are also required to have the following: \\r\\n\\r\\nNoise exposure measurement records must be maintained for at least 2 years.  Audiometric test records must be retained for the duration of the affected employee's employment.  Additionally, employees, former employees, representatives designated by the individual employee and the Assistant Secretary all must have access to these records.[22]\\r\\n\\r\\nProper program evaluation is important in maintaining the health of hearing conservation program.  The National Institute for Occupational Safety and Health (NIOSH) has created a checklist to help evaluate the effectiveness of a hearing conservation program.  It can be found on their website.[23]  NIOSH recommends that fewer than 5% of exposed employees should have a 15?dB significant threshold shift in the same ear and same frequency.\\r\\n\\r\\nThe National Institute for Occupational Safety and Health is pushing a higher emphasis on a hearing loss prevention program rather than a hearing conservation program.  While this change may seem superfluous, it is important to note the advancement.  Prevention implies a response by the workplace caused by initial signs of employee hearing loss rather than instilling a new set of policies (such as \\"buy quiet\\") and thinking (such as hearing protection training and education) to decrease the possibility of occupational hearing loss from happening in the first place.\\r\\n\\r\\nThe Buy Quiet policy is an easy way to progress towards a safer work environment.  Many traditionally noisy tools and machines are now being redesigned in order to manufacture quieter running equipment, so a \\"buy quiet\\" purchase policy should not require new engineering solutions in most cases.[24]  As a part of the \\"buy quiet\\" campaign, the New York City Department of Environmental Protection released a products and vendor guidance sheet in order to assist contractors for achieving compliance with the New York City Noise Regulations.\\r\\n\\r\\nIn order to make these plans effective, employees and administration need to be educated in occupational noise-induced hearing loss prevention.  It is also necessary to identify and examine sources of noise first before being able to control the damage it may cause to hearing.  For example, the National Institute for Occupational Safety and Health has conducted a study and created a database on handheld power tools for the sound power levels they expose their operators to.   This Power Tools Database allows contractors in a trade-skill profession to monitor their exposure limits and allow them preparation to prevent permanent hearing damage.\\r\\n\\r\\nDue to increased worry among both parents and experts regarding Noise-induced hearing loss (NIHL) in children, it has been suggested that hearing conservation programs be implemented in schools as part of their studies regarding health and wellness. The necessity for these programs is supported by the following reasons: 1. Children are not sheltered from loud noises in their daily lives, and 2. Promoting healthy behaviors at a young age is critical to future application.[25] The creation of a hearing conservation program for children will strongly differ from those created for the occupational settings discussed above. While children may not be exposed to factory of industrial noise on a daily basis, they may be exposed to noise sources such as firearms, music, power tools, sports, and noisy toys. All of these encounters with noise cumulatively increases their risk for developing Noise-induced hearing loss. With NIHL being a fully preventable ailment, providing children with this type of education has the potential to reduce future incidence of this condition. There are multiple organizations in existence that provide educators with the appropriate material to teach this topic; teachers simply need to be proactive about accessing them.[26] Below are examples of hearing conservation programs that have been designed specifically for children.\\r\\n\\r\\nThis is the primary goal of most hearing conservation programs at the elementary, middle, and high school levels is to spread knowledge about hearing loss and noise exposure. When an educational program is being created or adapted for use with children, behavior change theories are often employed to increase effectiveness. Behavior theory identifies possible obstacles to change while also highlighting factors that may encourage students to change.[21] The following are elements that are also considered during the implementation of a new program for children:\\r\\n\\r\\n1.    Adaptation of the program for the specific population (age, demographic, etc.)\\r\\n\\r\\n2.    Use of interactive games, lessons, and role-playing\\r\\n\\r\\n3.    Time to apply the skills that are taught\\r\\n\\r\\n4.    Reoccurring lessons on the same topic area[21]\\r\\n\\r\\nDangerous Decibels is a program designed to teach concepts related to the prevention of noise-induced hearing loss. Proven to be effective for children in 4th through 7th grade, children are engaged in hands-on activities during this 50-minute presentation. The class will learn about what sound is, how their ears hear and detect it, and how they can protect their hearing from dangerous decibels. Throughout the program, the class focuses on three strategies: Turn it Down, Walk Away, and Protect your Ears.[27]\\r\\n\\r\\nCreated by the American Speech-Language-Hearing Association, this campaign aims to teach children and their parents about practicing safe listening routines when listening to music through personal devices, such as an iPod. With the help of sponsors, ASHA hosts an educational concert series to promote safe music listening.[28]\\r\\n\\r\\nRun by the Ear Science Institute of Australia, this school program was created to educate elementary-age children on the risks of high listening levels and the effects of hearing loss. Program has a mascot named Charlie and utilizes sound level meters, computer games, apps, and take-home packets to teach the concepts. Teachers also receive addition activities and worksheets for continued learning opportunities.[29]\\r\\n\\r\\nOrganized by the United States National Institutes of Health, this is a campaign created with the aim to increase parental awareness of both the causes and effects of noise induced hearing loss. By targeting parents instead of children, the goal is for adults to influence the behaviors of their children before bad habits are even created. Resources provided include web-based games and puzzles, downloadable graphics, and tips for school and home environments.[30]\\r\\n\\r\\nCreated by The Hearing Foundation of Canada, the Sound Sense classroom program teaches children how hearing works, how it can stop working, and offers ideas for safe listening. The classroom presentation satisfies the requirements for the science unit on sound taught in either grade 3 or 4, as well as the healthy living curriculum in grades 5 and 6. In addition, the webpage provides resources & games for children, parents, and teachers.[31]\\r\\n\\r\\nAn Australian program initiated by the HEARing Cooperative Research Centre and the National Acoustic Laboratories (NAL), HEARsmart aims to improve the hearing health of all Australians, particularly those at greatest of risk of noise-related tinnitus and hearing loss. The program has a particular focus on promoting healthy hearing habits in musicians, live music venues and patrons. Resources include: Know Your Noise - an online risk calculator and speech-in-noise test, a short video that aims to raise awareness of tinnitus in musicians, and a comprehensive website with detailed information.[32]\\r\\n\\r\\nJust as program evaluation is necessary in workplace settings, it is also an important component of educational hearing conservation programs to determine if any changes need to be made. This evaluation may consist of two main parts: assessment of students' knowledge and assessment of their skills and behaviors. To examine the level of knowledge acquired by the students, a questionnaire is often given with the expectation of an 85% competency level among students. If proficiency is too low, changes should be implemented. If the knowledge level is adequate, assessing behaviors is then necessary to see if the children are using their newfound knowledge. This evaluation can be done through classroom observation of both the students and teachers in noisy classroom environments such as music, gym, technology, etc.[33]\\r\\n\\r\\nThe Mine Safety and Health Administration (MSHA) requires that all feasible engineering and administrative controls be employed to reduce miners' exposure levels to 90 dBA TWA. The action level for enrollment in a hearing conservation program is 85 dBA 8-hour TWA, integrating all sound levels between 80 dBA to at least 130 dBA. MSHA uses a 5-dB exchange rate (the sound level in decibels that would result in halving [if an increase in sound level] or a doubling [if a decrease.in sound level] the allowable exposure time to maintain the same noise dose). At and above exposure levels of 90 dBA TWA, the miner must wear hearing protection. At and above exposure levels above 105 dBA TWA, the miner must wear dual hearing protection. Miners may not be exposed to sounds exceeding 115 dBA with or without hearing protection devices. MSHA defines an STS as an average decrease in auditory sensitivity of 10?dB HL at the frequencies 2000, 3000, and 4000?Hz. (30 CFR Part 62[34]).\\r\\n\\r\\nThe Federal Railroad Administration (FRA) encourages, but does not require, railroads to use administrative controls that reduce noise exposure duration when the worker exceeds 90 dBA TWA. The FRA defines the action level for employee enrollment in a hearing conservation program as an 8-hour TWA of 85 dBA on certain railroads, integrating all sound levels between 80 dBA and 140 dBA. FRA uses a 5-dB exchange rate. Those employees who are always at or above 90 dBA TWA are required to wear hearing protection such that sound levels are attenuated below 90 dBA TWA. (49 CFR Part 229[35]).\\r\\n\\r\\nThe U.S. Department of Defense (DOD) specifies that engineering controls are preferential when reducing the noise levels at the source. The use of hearing protective devices is considered an \\"interim protective measure\\" while engineering controls are developed. The goal of these controls is to reduce ambient steady-state noise levels to 85 dBA regardless of TWA exposure and to reduce impulse noise levels to below 140 dBP. The DOD requires that personnel be entered into a hearing conservation program when continuous and intermittent noise levels ale grs greater than or equal to 85 dBA TWA, when impulse SPL are at or in excess of 140 dBP, or when the personnel is exposed to ultrasonic frequencies. The DOD integrates all sound levels between 80 dBA to a minimum of 130 dBA when determining an individual or representative noise dose. When used, hearing protectors must be capable of attenuating worker noise exposure below 85 dBA TWA. Hearing protection is required to be carried by personnel who work in designated noise areas, such as those exposed to gunfire or ordnance tests and Service musicians. The DOD defines a significant threshold shift as a 10?dB average decrease in hearing thresholds at 2000, 3000, and 4000?Hz in either ear, with no age corrections. It is further specified that a shift in 15?dB at 1000, 2000, 3000, or 4000?Hz is an early warning sign for an STS; follow-up retraining is required in this case. (DOD Instruction 6055.12[36]).\\r\\n\\r\\nThe European Union (EU) requires a hearing conservation program be implemented when the worker exposure levels exceed 80 dBA TWA. Note that this is more strict than hearing conservation regulations in the United States. The EU specifies several different exposure action values: a \\"lower\\" value of 80 dBA at which the employer must make hearing protection devices available to the employee; an \\"upper\\" value of 85 dBA at which the employee is required to wear hearing protection; and an \\"exposure limit\\" value of 87 dBA, under which the individual's noise exposure shall be limited to preserve hearing. The directive also defines a weekly noise exposure level which is applied to individuals working in circumstances of inconstant noise exposure. Finally, the EU also recommends a variety of noise reduction methods, including administrative controls to reduce worker exposure duration, the provision of quieter equipment, and adequate maintenance of machinery and other noise sources (European Parliament and Council Directive 2003|10|EC[37]).","input":"When do you need a hearing conservation program?"},{"output":"Lake Tanganyika","context":"Lake Tanganyika is an African Great Lake.  It is the second oldest freshwater lake in the world, the second largest by volume, and the second deepest, in all cases after Lake Baikal in Siberia.[4][5] It is the world's longest freshwater lake.[4] The lake is divided among four countries ÿ Tanzania, Democratic Republic of the Congo (DRC), Burundi, and Zambia, with Tanzania (46%) and DRC (40%) possessing the majority of the lake. The water flows into the Congo River system and ultimately into the Atlantic Ocean.\\r\\n\\r\\nThe name 'Tanganyika' apparently refers to 'the great lake spreading out like a plain', or 'plain-like lake'.\\"[6]:Vol.Two,16\\r\\n\\r\\nLake Tanganyika is situated within the Albertine Rift, the western branch of the East African Rift, and is confined by the mountainous walls of the valley. It is the largest rift lake in Africa and the second largest lake by volume in the world. It is the deepest lake in Africa and holds the greatest volume of fresh water, accounting for 16% of the world's available fresh water. It extends for 676?km (420?mi) in a general north-south direction and averages 50?km (31?mi) in width. The lake covers 32,900?km2 (12,700?sq?mi), with a shoreline of 1,828?km (1,136?mi), a mean depth of 570?m (1,870?ft) and a maximum depth of 1,470?m (4,820?ft) (in the northern basin). It holds an estimated 18,900 cubic kilometres (4,500?cu?mi).[7]\\r\\n\\r\\nThe catchment area of the lake is 231,000?km2 (89,000?sq?mi). Two main rivers flow into the lake, as well as numerous smaller rivers and streams (whose lengths are limited by the steep mountains around the lake). There is one major outflow, the Lukuga River, which empties into the Congo River drainage.\\r\\n\\r\\nThe major river flowing into the lake is the Ruzizi River, formed about 10,000 years ago, which enters the north of the lake from Lake Kivu.[8] The Malagarasi River, which is Tanzania's second largest river, enters the east side of Lake Tanganyika.[8] The Malagarasi is older than Lake Tanganyika and, before the lake was formed, directly drained into the Congo River.\\r\\n\\r\\nThe lake has a complex history of changing flow patterns, due to its high altitude, great depth, slow rate of refill and mountainous location in a turbulently volcanic area that has undergone climate changes. Apparently it has rarely in the past had an outflow to the sea. It has been described as 'practically endorheic' for this reason. The lake's connection to the sea is dependent on a high water level allowing water to overflow out of the lake through the Lukunga into the Congo.[8]\\r\\n\\r\\nDue to the lake's tropical location, it has a high rate of evaporation. Thus it depends on a high inflow through the Ruzizi out of Lake Kivu to keep the lake high enough to overflow. This outflow is apparently not more than 12,000 years old, and resulted from lava flows blocking and diverting the Kivu basin's previous outflow into Lake Edward and then the Nile system, and diverting it to Lake Tanganyika. Signs of ancient shorelines indicate that at times Tanganyika may have been up to 300?m (984?ft) lower than its present surface level, with no outlet to the sea. Even its current outlet is intermittent and thus may not have been operating when first visited by Western explorers in 1858.\\r\\n\\r\\nThe lake may also have at times had different inflows and outflows: inward flows from a higher Lake Rukwa, access to Lake Malawi and an exit route to the Nile have all been proposed to have existed at some point in the lake's history.[9]\\r\\n\\r\\nLake Tanganyika is an ancient lake. Its three basins, which in periods with much lower water levels were separate lakes, are of different ages. The central began to form 912 million years ago (mya), the northern 78 mya and the southern 24 mya.[10]\\r\\n\\r\\nThere are several islands in Lake Tanganyika. The most important of them are:\\r\\n\\r\\nThe lake's water is alkaline with a pH of around 9 at depths of 0ÿ100?m (0ÿ330?ft).[11] Below this it is around 8.7, gradually decreasing to 8.38.5 in the deepest parts of Tanganyika.[11] A similar pattern can be seen in the electric conductivity, ranging from about 670 S/cm in the upper part to 690 S/cm in the deepest.[11]\\r\\n\\r\\nSurface temperatures generally range from about 24?C (75?F) in the southern part of the lake in early August to 28ÿ29?C (82ÿ84?F) in the late rainy season in MarchApril.[12] At depths greater than 400?m (1,300?ft) the temperature is very stable at 23.1ÿ23.4?C (73.6ÿ74.1?F).[13] The water has gradually warmed since the 1800s and this has accelerated with global warming since the 1950s.[14]\\r\\n\\r\\nThe lake is stratified and seasonal mixing generally does not extend beyond depths of 150?m (490?ft).[12] The mixing mainly occurs as upwellings in the south and is wind-driven, but to a lesser extent there are also up- and downwellings elsewhere in the lake.[15] As a consequence of the stratification, the deep sections contain \\"fossil water\\".[16] This also means that there is no oxygen (it is anoxic) in the deeper parts, essentially limiting fish and other aerobic organisms to the upper part. There are some geographical variations in this limit, but it is typically at depths of around 100?m (330?ft) in the northern part of the lake and 240ÿ250?m (790ÿ820?ft) in the south.[17][18] The oxygen-devoid deepest sections contain high levels of toxic hydrogen sulphide and are essentially lifeless,[4] except for bacteria.[11]\\r\\n\\r\\nLake Tanganyika and associated wetlands are home to Nile crocodiles (including famous giant Gustave), Zambian hinged terrapins, serrated hinged terrapins and pan hinged terrapins (last species not in the lake itself, but in adjacent lagoons).[19] The Storm's water cobra, a threatened subspecies of banded water cobra that feeds mainly on fish, is only found in Lake Tanganyika where it prefers rocky shores.[19][20]\\r\\n\\r\\nThe lake holds at least 250 species of cichlid fish[24] and undescribed species remain.[25] Almost all (98%) of the Tanganyika cichlids are endemic to the lake and it is thus an important biological resource for the study of speciation in evolution.[26][27] The cichlids of the African Great Lakes, including Tanganyika, represent the most diverse extent of adaptive radiation in vertebrates.[28]\\r\\n\\r\\nAlthough Tanganyika has far fewer cichlid species than Lake Malawi and Victoria which both have experienced relatively recent explosive species radiations (resulting in many closely related species),[29] its cichlids are the most morphologically and genetically diverse.[28][30] This is linked to the high age of Tanganyika, as it is far older than the other lakes.[31] Tanganyika has the largest number of endemic cichlid genera of all African lakes.[28] All Tanganyika cichlids are in the subfamily Pseudocrenilabrinae. Of the 10 tribes in this subfamily, half are largely or entirely restricted to the lake (Cyprichromini, Ectodini, Lamprologini, Limnochromini and Tropheini) and another three have species in the lake (Haplochromine, Tilapiini and Tylochromini).[32] Others have proposed splitting the Tanganyika cichlids into as many as 1216 tribes (in addition to previous mentioned, Bathybatini, Benthochromini, Boulengerochromini, Cyphotilapiini, Eretmodini, Greenwoodochromini, Perissodini and Trematocarini).[28]\\r\\n\\r\\nMost Tanganyika cichlids live along the shoreline down to a depth of 100?m (330?ft), but some deep-water species regularly descend to 200?m (660?ft).[33] Trematocara species have exceptionally been found at more than 300?m (980?ft), which is deeper than any other cichlid in the world.[34] Some of the deep-water cichlids (e.g., Bathybates, Gnathochromis, Hemibates and Xenochromis) have been caught in places virtually devoid of oxygen, but how they are able to survive there is unclear.[18] Tanganyika cichlids are generally benthic (found at or near the bottom) and/or coastal.[35] No Tanganyika cichlids are truly pelagic and offshore, except for some of the piscivorous Bathybates.[33] Two of these, B. fasciatus and B. leo, mainly feed on Tanganyika sardines.[33][18] Tanganyika cichlids differ extensively in ecology and include species that are herbivores, detritivores, planktivores, insectivores, molluscivores, scavengers, scale-eaters and piscivores.[25] Their breeding behavior fall into two main groups, the substrate spawners (often in caves or rock crevices) and the mouthbrooders.[36] Among the endemic species are two of the world's smallest cichlids, Neolamprologus multifasciatus and N. similis (both shell dwellers) at up to 4ÿ5?cm (1.6ÿ2.0?in),[37][38] and one of the largest, the giant cichlid (Boulengerochromis microlepis) at up to 90?cm (3.0?ft).[25][39]\\r\\n\\r\\nMany cichlids from Lake Tanganyika, such as species from the genera Altolamprologus, Cyprichromis, Eretmodus, Julidochromis, Lamprologus, Neolamprologus, Tropheus and Xenotilapia, are popular aquarium fish due to their bright colors and patterns, and interesting behaviors.[36] Recreating a Lake Tanganyika biotope to host those cichlids in a habitat similar to their natural environment is also popular in the aquarium hobby.[36][40]\\r\\n\\r\\nBathybatini (E): Bathybates ferox is benthic and piscivorous, but the genus also includes pelagic species.[33] The tribe is sometimes split in three, others being Hemibatini and Trematocarini[41][42]\\r\\n\\r\\nBenthochromini (E): Benthochromis horii was scientifically described in 2008, but has often been misidentifed as B. tricoti[43]\\r\\n\\r\\nBoulengerochromini (E): Boulengerochromis microlepis is one of the world's largest cichlids[39] and only member of its tribe[42]\\r\\n\\r\\nCyphotilapiini (E): Cyphotilapia frontosa, one of only two similar species in the tribe[44]\\r\\n\\r\\nCyprichromini (E): Cyprichromis microlepidotus and other members of this tribe are open-water planktivores[45][46]\\r\\n\\r\\nEctodini (E): Ophthalmotilapia nasuta (male) is sexually dimorphic, males being more colorful with longer fins and nose[47]\\r\\n\\r\\nEretmodini (E): Eretmodus cyanostictus lives near the bottom in the turbulent, coastal surf zone,[48] like other members of its tribe[46]\\r\\n\\r\\nHaplochromini: Astatotilapia burtoni is one of the few Tanganyika species,[49] unlike other African Great Lakes where most belong to this tribe[50]\\r\\n\\r\\nLamprologini (E): Julidochromis marlieri is popular in the aquarium trade where members of the genus are known as \\"Julies\\"[51]\\r\\n\\r\\nLimnochromini (E): Gnathochromis permaxillaris is a zooplanktivore with an unusual protractile mouth[52]\\r\\n\\r\\nPerissodini (E): Perissodus microlepis, a specialized scale-eating species[53]\\r\\n\\r\\nTilapiini: Oreochromis tanganicae is one of the most common coastal species found in local fish markets[54]\\r\\n\\r\\nTropheini (E): Tropheus moorii (\\"red\\" Chimba morph) is highly variable and the taxonomy of some of the morphs is questionable[55][56][57]\\r\\n\\r\\nLake Tanganyika is home to more than 80 species of non-cichlid fish and about 60% of these are endemic.[17][24][59][60]\\r\\n\\r\\nThe open waters of the pelagic zone are dominated by four non-cichlid species: Two species of \\"Tanganyika sardine\\" (Limnothrissa miodon and Stolothrissa tanganicae ) form the largest biomass of fish in this zone, and they are important prey for the forktail lates (Lates microlepis) and sleek lates (L. stappersii).[35] Two additional lates are found in the lake, the Tanganyika lates (L. angustifrons) and bigeye lates (L. mariae), but both these are primarily benthic hunters, although they also may move into open waters.[35] The four lates, all endemic to Tanganyika, have been overfished and larger individuals are rare today.[35]\\r\\n\\r\\nAmong the more unusual fish in the lake are the endemic, facultatively brood parasitic \\"cuckoo catfish\\", including at least Synodontis grandiops[61] and S. multipunctatus.[17][36] A number of others are very similar (e.g., S. lucipinnis and S. petricola) and have often been confused; it is unclear if they have a similar behavior.[17][62][63] The facultative brood parasites often lay their eggs synchronously with mouthbroding cichlids. The cichlid pick up the eggs in their mouth as if they were their own. Once the catfish eggs hatch the young eat the cichlid eggs.[17][36] Six catfish genera are entirely restricted to the lake basin: Bathybagrus, Dinotopterus, Lophiobagrus, Phyllonemus, Pseudotanganikallabes and Tanganikallabes.[49][64] Although not endemic on a genus level, six species of Chrysichthys catfish are only found in the Tanganyika basin where they live both in shallow and relatively deep waters;[49] in the latter habitat they are the primary predators and scavengers.[18] A unique evolutionary radiation in the lake is the 15 species of Mastacembelus spiny eels, all but one endemic to its basin.[59][65] Although other African Great Lakes have Synodontis catfish, endemic catfish genera and Mastacembelus spiny eels, the relatively high diversity is unique to Tanganyika, which likely is related to its old age.[65]\\r\\n\\r\\nAmong the non-endemic fish, some are widespread African species but several are only shared with the Malagarasi and Congo River basins, such as the Congo bichir (Polypterus congicus), goliath tigerfish (Hydrocynus goliath), Citharinus citharus, six-banded distichodus (Distichodus sexfasciatus) and mbu puffer (Tetraodon mbu).[49]\\r\\n\\r\\nA total of 83 freshwater snail species (65 endemic) and 11 bivalve species (8 endemic) are known from the lake.[66] Among the endemic bivalves are three monotypic genera: Grandidieria burtoni, Pseudospatha tanganyicensis and Brazzaea anceyi.[66] Many of the snails are unusual for species living in freshwater in having noticeably thickened shells and/or distinct sculpture, features more commonly seen in marine snails. They are referred to as thalassoids, which can be translated to \\"marine-like\\".[67] All the Tanganyika thalassoids, which are part of Prosobranchia, are endemic to the lake.[67] Initially they were believed to be related to similar marine snails, but they are now known to be unrelated. Their appearance is now believed to be the result of the highly diverse habitats in Lake Tanganyika and evolutionary pressure from snail-eating fish and, in particular, Platythelphusa crabs.[24][67][68] A total of 17 freshwater snail genera are endemic to the lake, such as Hirthia, Lavigeria, Paramelania, Reymondia, Spekia, Stanleya, Tanganyicia and Tiphobia.[67] There are about 30 species of non-thalassoid snails in the lake, but only five of these are endemic, including Ferrissia tanganyicensis and Neothauma tanganyicense.[67] The latter is the largest Tanganyika snail and its shell is often used by small shell-dwelling cichlids.[69]\\r\\n\\r\\nCrustaceans are also highly diverse in Tanganyika with more than 200 species, of which more than half are endemic.[24] They include 10 species of freshwater crabs (9 Platythelphusa and Potamonautes platynotus; all endemic),[70] at least 11 species of small atyid shrimp (Atyella, Caridella and Limnocaridina),[71] an endemic palaemonid shrimp (Macrobrachium moorei),[72] about 100 ostracods,[73] including many endemics,[74][75] and several copepods.[76] Among these, Limnocaridina iridinae lives inside the mantle cavity of the  unionid mussel Pleiodon spekei, making it one of only two known commensal species of freshwater shrimp (the other is a sponge-living Caridina from Lake Towuti, Indonesia).[77][78]\\r\\n\\r\\nAmong Rift Valley lakes, Lake Tanganyika far surpasses all others in terms of crustacean and freshwater snail richness (both in total number of species and number of endemics).[79] For example, the only other Rift Valley lake with endemic freshwater crabs is Lake Kivu with two species.[80]\\r\\n\\r\\nThe diversity of other invertebrate groups in Lake Tanganyika is often not well-known, but there are at least 20 described species of leeches (12 endemics),[81] 9 sponges (7 endemic), 6 bryozoa (2 endemic), 11 flatworms (7 endemic), 20 nematodes (7 endemic), 28 annelids (17 endemic)[24] and the small hydrozoan jellyfish Limnocnida tanganyicae.[82]\\r\\n\\r\\nLake Tanganyika supports a major fishery, which, depending on source, provides 25ÿ40%[83] or c. 60% of the animal protein in the diet of the people living in the region.[14][84] Currently, there are around 100,000 people directly involved in the fisheries operating from almost 800 sites. The lake is also vital to the estimated 10 million people living in the greater basin.[citation needed]\\r\\n\\r\\nLake Tanganyika fish can be found exported throughout East Africa. Major commercial fishing began in the mid-1950s and has, together with global warming (limiting the habitat of temperature sensitive species), had a heavy impact on the fish populations, causing significant declines.[14][84] In 2016, it was estimated that the total catch was up to 200,000 tonnes.[14] Former industrial fisheries, which boomed in the 1980s, have subsequently collapsed.[citation needed]\\r\\n\\r\\nTwo ferries carry passengers and cargo along the eastern shore of the lake: MV?Liemba between Kigoma and Mpulungu and MV?Mwongozo between Kigoma and Bujumbura.\\r\\n\\r\\nOn Dec. 12, 2014, the ferry MV Mutambala capsized on Lake Tanganyika, and more than 120 lives were lost.[86]\\r\\n\\r\\nIt is thought that early Homo Sapiens was making an impact on the region already during the stone age. The time period of the Middle Stone Age to Late Stone Age is described as an age of advanced hunter-gatherers. It is believed they would have caused megafaunal extinctions.[87]\\r\\n\\r\\nThere are many methods in which the native people of the area were fishing. Most of them included using a lantern as a lure for fish that are attracted to light. There were three basic forms. One called Lusenga which is a wide net used by one person from a canoe. The second one is using a lift net. This was done by dropping a net deep below the boat using two parallel canoes and then simultaneously pulling it up. The third is called Chiromila which consisted of three canoes. One canoe was stationary with a lantern while another canoe holds one end of the net and the other circles the stationary one to meet up with the net.[88]\\r\\n\\r\\nThe first known Westerners to find the lake were the British explorers Richard Burton and John Speke, in 1858.  They located it while searching for the source of the Nile River. Speke continued and found the actual source, Lake Victoria. Later David Livingstone passed by the lake. He noted the name \\"Liemba\\" for its southern part, a word probably from the Fipa language, and in 1927 this was chosen as the new name for the conquered German First World War ship Graf von G?tzen which is still serving the lake up to the present time.[89]\\r\\n\\r\\nThe lake was the scene of two celebrated battles during World War I.\\r\\n\\r\\nWith the aid of the Graf Goetzen (named after Count Gustav Adolf Graf von G?tzen, the former governor of German East Africa), the Germans had complete control of the lake in the early stages of the war. The ship was used both to ferry cargo and personnel across the lake, and as a base from which to launch surprise attacks on Allied troops.[90]\\r\\n\\r\\nIt therefore became essential for the Allied forces to gain control of the lake themselves. Under the command of Lieutenant Commander Geoffrey Spicer-Simson the British Royal Navy achieved the monumental task of bringing two armed motor boats HMS Mimi and HMS Toutou from England to the lake by rail, road and river to Albertville (since renamed Kalemie in 1971) on the western shore of Lake Tanganyika. The two boats waited until December 1915, and mounted a surprise attack on the Germans, with the capture of the gunboat Kingani. Another German vessel, the Hedwig, was sunk in February 1916, leaving the G?tzen as the only German vessel remaining to control the lake.[90]\\r\\n\\r\\nAs a result of their strengthened position on the lake, the Allies started advancing towards Kigoma by land, and the Belgians established an airbase on the western shore at Albertville. It was from there, in June 1916, that they launched a bombing raid on German positions in and around Kigoma. It is unclear whether or not the G?tzen was hit (the Belgians claimed to have hit it but the Germans denied this), but German morale suffered and the ship was subsequently stripped of its gun since it was needed elsewhere.[90]\\r\\n\\r\\nThe war on the lake had reached a stalemate by this stage, with both sides refusing to mount attacks. However, the war on land was progressing, largely to the advantage of the Allies, who cut off the railway link in July 1916 and threatened to isolate Kigoma completely. This led the German  commander, Gustav Zimmer, to abandon the town and head south. In order to avoid his prize ship falling into Allied hands, Zimmer scuttled the vessel on July 26, 1916. The vessel was later raised in 1924 and renamed MV Liemba (see transport).[90]\\r\\n\\r\\nIn 1965 Argentinian revolutionary Che Guevara used the western shores of Lake Tanganyika as a training camp for guerrilla forces in the Congo.  From his camp, Che and his forces attempted to overthrow the government, but ended up pulling out in less than a year since the National Security Agency (NSA) had been monitoring him the entire time and aided government forces in ambushing his guerrillas.[citation needed]\\r\\n\\r\\nIn 1992 Lake Tanganyika featured in the British TV documentary series Pole to Pole. The BBC documentarian Michael Palin stayed on board the MV Liemba and travelled across the lake.\\r\\n\\r\\nSince 2004 the lake has been the focus of a massive Water and Nature Initiative by the IUCN. The project is scheduled to take five years at a total cost of US$27 million. The initiative is attempting to monitor the resources and state of the lake, set common criteria for acceptable level of sediments, pollution, and water quality in general, and design and establish a lake basin management authority.[citation needed]\\r\\n\\r\\nBecause of increasing global temperature there is a direct correlation to lower productivity in Lake Tanganyika.[13] Southern winds create upwells of deep nutrient-rich water on the southern end of the lake. This happens during the cooler months (May to September). These nutrients that are in deep water are vital in maintaining the aquatic food web. The southerly winds are slowing down which limits the ability for the mixing of nutrients. This is correlating with less productivity in the lake.","input":"Which is the deepest lake in east africa?"},{"output":"Chameleon","context":"Spider-Man is a fictional superhero in the Marvel Universe debuting in the anthology comic book series issue Amazing Fantasy #15 (August 1962) in the Silver Age of Comics published by Marvel Comics. After his debut he would get his own comic book entitled The Amazing Spider-Man. The comic book series would introduce many of what would become his major supervillain adversaries. Spider-Man would then be popular enough for more Spider-Man comic spinoffs (The Spectacular Spider-Man, Marvel Team-Up, Web of Spider-Man, Peter Parker: Spider-Man etc.) which introduced more recurring enemies of the web-slinger.\\r\\nAs with Spider-Man, the villains' powers originate with scientific accidents or the misuse of scientific technology and also tend to have animal-themed costumes or powers (Vulture, Doctor Octopus, Beetle, Lizard, Rhino, Scorpion, Jackal and Black Cat). There also are supervillains with the powers over the elements (Sandman, Shocker, Electro, Molten Man and Hydro-Man), some that are horror-themed (the Goblins, Morbius, Morlun, and the Symbiotes) some that are crime lords (Kingpin, Tinkerer, Tombstone, Hammerhead, Silvermane and Mister Negative),[1] and some that are masters of trickery (Chameleon and Mysterio).[2] These villains oftentimes form teams such as the Sinister Six to oppose the superhero.\\r\\nThe rogues gallery of Spider-Man has garnered many positive reviews and has been considered as one of the greatest rogues galleries of all time by many alongside Batman's rogues gallery.\\r\\n\\r\\n\\r\\nThe majority of supervillains depicted in Spider-Man comics first appeared in The Amazing Spider-Man, while some first appeared in spinoff comics such as The Spectacular Spider-Man and Marvel Team-Up and other titles.\\r\\nMost of the supervillains of Spider-Man would be introduced in The Amazing Spider-Man comic book starting with the Chameleon.[3] The early villains would be introduced in the 1960s in the Silver Age of Comic Books,[3] and created by Stan Lee and Steve Ditko.[3] John Romita, Sr. replaced Ditko starting with the Rhino.[4] Gerry Conway later replaced Stan Lee and helped create new adversaries for the web-slinger and also helped pave the way to the Bronze Age of Comic Books with the death of Spider-Man's long time romantic interest, Gwen Stacy.[5][6][7] Many collaborators would soon take over The Amazing Spider-Man title. One of the more popular examples included Todd McFarlane's Venom in the Modern Age of Comic Books.[8]\\r\\nNote: Alter ego characters who are the most high profile in the supervillain alias but have shared that alias with others are in bold. Alter egos listed having N/A use their real name as the supervillain name. In chronological order.\\r\\nNote: In chronological order.\\r\\nNote: In chronological order.\\r\\nNote: In chronological order.\\r\\nAlmost all the characters listed first appeared in The Amazing Spider-Man with the exception of Kaine and Humbug first appearing in Web of Spider-Man. The Prowler is the oldest character appearing in The Amazing Spider-Man in the 1960s in the Silver Age. Many other anti-heroes were introduced in the 1970s in between the Silver Age and the Bronze Age while Humbug was introduced in the 1980s right around the start of the Modern Age. Kaine is the youngest debuted character while Cardiac is the second youngest. Both Kaine and Cardiac appeared around the 1990s.\\r\\nThe Burglar and Flash Thompson both appeared in the first comic book starring Spider-Man appearing in the anthology series Amazing Fantasy. The certain comic book story inspired a comic book series entitled The Amazing Spider-Man which J. Jonah Jameson would appear in the first issue. All three of the characters listed appeared in the 1960s around the Silver Age of Comics.\\r\\nDelilah first appeared in The Amazing Spider-Man #414 by Tom DeFalco and Mark Bagley.[27] The Rose's confidante as well as his chief enforcer, Delilah helped battle to maintain control of part of the New York crime scene against the threat of the Black Tarantula.[111][112]\\r\\nDuring her career, she had a role in the rebirth of two of Spider-Man's old foes during the Rose's efforts to gain extra muscle: she was the one who threw the switch of the electric chair which gave Electro his powers back, and helped set up the theft of Doctor Octopus' corpse for re-animation from the Hand. She also appears in Loners as an assassin smuggling MGH.[113][114][115][116]\\r\\nSpidercide was a major antagonist in the \\"Maximum Clonage\\" story arc. He first appeared in The Spectacular Spider-Man #222 by Tom DeFalco and Sal Buscema.[67] He is depicted as an evil foil of Spider-Man, Ben Reilly, and Kaine. Introduced as a red herring to suggest the possibility of a third individual that was the original Peter Parker, he is one of the Spider-Man clones created by Jackal, to be Jackal's enforcer and protector. However, Spidercide is actually a clone to Ben Reilly, who is a direct genetic duplicate of Spider-Man.[40]\\r\\nHe first appeared as a Peter Parker double emerging from one of the Jackal's pods that initially an amnesiac but later believed himself to be the real Peter Parker, having been kept in stasis since the first Clone Saga. He claimed that both Peter Parker and Ben Reilly were his clones. However, upon meeting Parker, Reilly and Kaine, the Jackal's programming kicked in and he went insane before shapeshifting into a freakish giant, therefore revealing his true status as a clone. In denial of the truth, he tried to kill the \\"clones\\" and to claim Peter Parker's life as his own. He was even infatuated with Parker's wife Mary Jane Watson and seeks to have her as his bride. Since their first encounter, Reilly realizes that Spidercide is twisted from the start and expresses disgust of his corrupted doppelg?nger's immorality, tauntingly refers him as \\"Freakface\\" once the villainous clone's shapeshifting powers manifest. However, this also causes Reilly to be afraid of his and Parker's capabilities for wicked if they allow themselves demoralize as Spidercide.\\r\\nThe Jackal later modified Spidercide's powers, granting him the unique ability to control his physical make-up on a molecular level; he can alter his mass, density, shape and state at will similar to the symbiotes. He was killed off in Spider-Man: Maximum Clonage: Omega #404 by being thrown off in the Daily Bugle.[40][117]\\r\\nAfter Ben Reilly's resurrection from his death, he briefly adapts a costume similar to Spidercide's after he steal it from a cosplayer before returning to his own costume style.\\r\\nNote: The common leader of the group is in bold.\\r\\nUnlike well known rivalries in comics book depictions where heroes always still have more than one enemy but usually one archenemy (e.g., Joker, to Batman in DC Comics, Red Skull to Captain America, Doctor Doom to the Fantastic Four and the Brotherhood of Mutants to the X-Men in Marvel Comics etc.), Spider-Man is known to have three archenemies and it can be debated or disputed as to which one is worse:[123]\\r\\nReaction to Spider-Man's rogues gallery has been overwhelmingly positive with many journalists citing it as one of the greatest comic book rogues galleries of all time,[133][134][135] with Batman's rogues gallery being its most rivaled contender.[136][137] Although editors such as The Hollywood Reporter's Graeme McMillan felt that only Flash's rogues gallery can compete with Spider-Man's rogues.[134] Kyle Schmidlin of What Culture! described the superhero's rogues gallery as \\"one of the most colorful in comics\\" explaining that Batman could only be debated as having a great number of enemies as good as Spider-Man.[138] IGN staff editors, Joshua Yehl and Jesse Schedeen, described the Spider-Man villains as \\"one of the most iconic and well-balanced in comics\\". They opined that the scope of their schemes, how cool their powers are, and how dramatically they have affected Spider-Man's life is what makes the Spider-Man villains so great.[1] Newsarama ranked Spider-Man's rogues gallery as number one out ten as the greatest rogues gallery of all time.[137]\\r\\nGeorge Marston of Newsarama explaining why he felt that Spider-Man rogues gallery was the best was the thematic elements that the villains of Spider-Man manifested.[137] He explained that just like the superhero they have the same concept of science gone wrong. They are \\"like him, great men with great minds, great power, and great determination.\\" But instead they fail to use their powers responsibly. Separating the thin line between being a hero from being a villain.[137]","input":"Who was the first villain spider man fought?"},{"output":"industrial targets","context":"","input":"What parts of england were bombed in ww2?"},{"output":"A panel is an individual frame, or single drawing, in the multiple-panel sequence of a comic strip or comic book. A panel consists of a single drawing depicting a frozen moment.","context":"A panel is an individual frame, or single drawing, in the multiple-panel sequence of a comic strip or comic book. A panel consists of a single drawing depicting a frozen moment.\\r\\nNewspaper daily strips typically consist of either four panels (Doonesbury, For Better or For Worse) or three panels (Garfield, Dilbert), all of the same size. The horizontal newspaper strip can also employ only a single panel, as sometimes seen in Wiley Miller's Non Sequitur.[1]\\r\\nIn Asia, a vertical four-panel arrangement (yonkoma) is common in newspapers, such as with Azumanga Daioh. In a comic book or graphic novel, the shapes of panels and the number of panels on a page may vary widely.\\r\\nThe word panel may also refer to a cartoon consisting of a single drawing; the usage is a shortened form of \\"single-panel comic\\". In contrast to multi-panel strips, which may involve extended dialogue in speech balloons, a typical panel comic has only one spoken line, printed in a caption beneath the panel itself. Many panel comics are syndicated and published daily, on a newspaper page with other syndicated cartoons that are collectively known as comic strips. Major comic strips in panel format include The Far Side, Dennis the Menace, The Family Circus, Ziggy, Herman and Ripley's Believe It or Not. In this context, panels are contrasted with the more common comic strip format, which consists of an actual \\"strip\\" of multiple drawings that tell a story in sequence.\\r\\nThere are two major styles used in newspaper comics, single panels and strips. Single panels usually, but not always, are not broken up and lack continuity. The popular Dennis the Menace and The Family Circus are both single panels. Strips on the other hand are generally longer and shaped into a rectangle. Strips include Peanuts and Garfield. J. R. Williams' long-run Out Our Way continued as a daily panel even after it expanded into a Sunday strip, Out Our Way with the Willets. Jimmy Hatlo's They'll Do It Every Time was often displayed in a two-panel format with the first panel showing some deceptive, pretentious, unwitting or scheming human behavior and the second panel revealing the truth of the situation.[2]\\r\\nEarly daily strips were large, often running the entire width of the newspaper, and were sometimes three or more inches high.[3] Initially, a newspaper page included only a single daily strip, usually either at the top or the bottom of the page. By the 1920s, many newspapers had a comics page on which many strips were collected together. Over decades, the size of daily strips became smaller and smaller; until by the year 2000, four standard daily strips could fit in an area once occupied by a single daily strip.[4]\\r\\nNEA Syndicate experimented briefly with a two-tier daily strip, Star Hawks, but after a few years, Star Hawks dropped down to a single tier.[2]\\r\\nIn Flanders, Belgium the two-tier strip is the standard publication style of most daily by:david Spike and Suzy and Nero.[5] They appear Monday through Saturday; until 2003 there were no Sunday papers in Flanders.[6] In the last decades, they have switched from black and white to color.\\r\\nSaraceni, Mario. The Language of Comics. London?; New York, N.Y: Routledge, 2003, p.7","input":"What is a panel in a graphic novel?"},{"output":"Ernest Gary Gygax","context":"Ernest Gary Gygax (/?a??ks/ GY-gaks) (July 27, 1938?ÿ March 4, 2008)[3] was an American game designer and author best known for co-creating the pioneering role-playing game Dungeons & Dragons (D&D) with Dave Arneson.\\r\\nIn the 1960s, Gygax created an organization of wargaming clubs and founded the Gen Con gaming convention. In 1971, he helped develop Chainmail, a miniatures wargame based on medieval warfare. He co-founded the company Tactical Studies Rules (TSR, Inc.) with childhood friend Don Kaye in 1973. The following year, he and Arneson created D&D, which expanded on Gygax's Chainmail and included elements of the fantasy stories he loved as a child. In the same year, he founded The Dragon, a magazine based around the new game. In 1977, Gygax began work on a more comprehensive version of the game, called Advanced Dungeons & Dragons. Gygax designed numerous manuals for the game system, as well as several pre-packaged adventures called \\"modules\\" that gave a person running a D&D game (the \\"Dungeon Master\\") a rough script and ideas on how to run a particular gaming scenario. In 1983, he worked to license the D&D product line into the successful D&D cartoon series.\\r\\nAfter leaving TSR in 1985 over issues with its new majority owner, Gygax continued to create role-playing game titles independently, beginning with the multi-genre Dangerous Journeys in 1992. He designed another gaming system called Lejendary Adventure, released in 1999. In 2005, Gygax was involved in the Castles & Crusades role-playing game, which was conceived as a hybrid between the third edition of D&D and the original version of the game conceived by Gygax.\\r\\nGygax was married twice and had six children. In 2004, Gygax suffered two strokes, narrowly avoided a subsequent heart attack, was then diagnosed with an abdominal aortic aneurysm, and died in March 2008.\\r\\n\\r\\n\\r\\nGary Gygax was born in Chicago, the son of Almina Emelie \\"Posey\\" (Burdick)[4] and Swiss immigrant and former Chicago Symphony Orchestra violinist Ernst Gygax.[5][6] He was named Ernest after his father, but he was commonly known as Gary, the middle name given to him by his mother after the actor Gary Cooper.[7]:16 The family lived on Kenmore Avenue, close enough to Wrigley Field[8] that he could hear the roar of the crowds watching the Chicago Cubs play.[7]:15 At age 7, he became a member of a small group of friends who called themselves the \\"Kenmore Pirates\\". In 1946, after the Kenmore Pirates were involved in a fracas with another gang of boys,[9] his father decided to move the family to Posey's family home in Lake Geneva, Wisconsin,[10] where Posey's family had settled in the early 19th century, and where Gary's grandparents still lived.[6][11][12]\\r\\nIn this new setting, Gygax soon made friends with several of his peers, including Don Kaye and tomboy Mary Jo Powell. During his childhood and teen years, he developed a love of games and an appreciation for fantasy and science fiction literature. When he was five, he played card games such as pinochle and then board games such as chess.[13][14] At the age of ten, he and his friends played the sort of make-believe games that eventually came to be called \\"live action role-playing games\\" with one of them acting as a referee.[15] His father introduced him to science fiction and fantasy through pulp novels.[6][14] His interest in games, combined with an appreciation of history, eventually led Gygax to begin playing miniature war games in 1953 with his best friend Don Kaye.[14] As teenagers Gygax and Kaye designed their own miniatures rules for toy soldiers with a large collection of 54 mm and 70 mm figures, where they used \\"ladyfingers\\" (small firecrackers) to simulate explosions.[16]\\r\\nBy the time he reached his teens, Gygax had a voracious appetite for pulp fiction authors such as Robert Howard, Jack Vance, Fritz Leiber, H. P. Lovecraft, and Edgar Burroughs.[7]:40 Gygax was a mediocre student, and in 1956, a few months after his father died, he dropped out of high school in his junior year.[7]:43 He briefly joined the Marines, but after being diagnosed with walking pneumonia, he was given a medical discharge and moved back home with his mother.[7]:49 From there, he commuted to a job as shipping clerk with Kemper Insurance Co. in Chicago. Shortly after his return, a friend introduced him to Avalon Hill's new wargame Gettysburg, and Gygax was soon obsessed with the game, often playing marathon sessions once a week or more.[17] It was also from Avalon Hill that he ordered the first blank hexagon mapping sheets that were available, which he then employed to design his own games.[18]\\r\\nAt about the same time that he discovered Gettysburg, his mother re-introduced him to Mary Jo Powell, who had left Lake Geneva as a child and had just returned. Gygax was smitten with the beautiful young woman, and after a short courtship, persuaded her to marry him, despite the fact that he was only 19. This caused some friction with his best friend Don Kaye, who had also been wooing Mary Jo, to the point where Kaye refused to attend Gygax's wedding.[7]:47 (Kaye and Gygax reconciled after the wedding.)\\r\\nThe young couple moved to Chicago where Gygax continued as a shipping clerk at Kemper Insurance, and also found Mary Jo a job there too. (The company laid her off when she became pregnant with their first child.) [7]:53 At Mary Jo's insistence, he also attended night classes in junior college to earn his high school diploma, and this time he excelled at his studies and made the college's Dean's List.[12] He also took anthropology classes at the University of Chicago.[5][6] Gygax also volunteered as a Republican precinct captain during the 1960 presidential election, and observed many infractions by his Democratic counterpart. When he threatened to report these, he was offered a full scholarship to the University of Chicago if he kept silent. Although Gygax ultimately did not report the infractions, since he felt nothing would be done, he also did not accept the scholarship.[7]:54\\r\\nDespite his commitments to his job, raising a family, school, and his political volunteerism, Gygax continued to play wargames. It reached the point that Mary Jo, pregnant with their second child, believed he was having an affair and confronted him in a friend's basement only to discover him and his friends sitting around a map-covered table.[7]:55\\r\\nIn 1962, Gygax got a job as an insurance underwriter at Fireman's Fund Insurance Co. His family continued to grow, and after his third child was born, he decided to move his family back to Lake Geneva.[5] Except for a few months he would spend in Clinton, Wisconsin,[19] following his divorce, and his time in Hollywood while he was the head of TSR's entertainment division, Lake Geneva would be his home for the rest of his life.\\r\\nBy 1966, Gygax was active in the wargame hobby world and was writing many magazine articles on the subject.[20] Gygax learned about H. G. Wells' Little Wars book for play of military miniatures wargames and Fletcher Pratt's Naval Wargame book. Gygax later looked for innovative ways to generate random numbers, and he used not only common, six-sided dice, but dice of all five Platonic solid shapes,[21] which he discovered in a school supply catalog.[12]\\r\\nIn 1967, Gygax co-founded the International Federation of Wargamers (IFW) with Bill Speer and Scott Duncan.[20] The IFW grew rapidly, especially by assimilating several pre-existing wargaming clubs, and aimed to promote interest in wargames of all periods. It provided a forum for wargamers, via its newsletters and societies, which enabled them to form local groups and share rules. In 1967, Gygax organized a 20-person gaming meet in the basement of his home; this event would later be referred to as \\"Gen Con 0\\".[21] In 1968, Gygax rented Lake Geneva's vine-covered Horticultural Hall for US$50 to hold the first Lake Geneva Convention, also known as the Gen Con gaming convention for short.[12] Gen Con is now one of North America's largest annual hobby-game gatherings.[22] Gygax met Dave Arneson, the future co-creator of D&D, at the second Gen Con in August 1969.[12][23]\\r\\nI'm very fond of the Medieval period, the Dark Ages in particular. We started playing in the period because I had found appropriate miniatures. I started devising rules where what the plastic figure was wearing was what he had. If he had a shield and no armor, then he just has a shield. Shields and half-armor = half-armor rules; full-armor figure = full armor rules. I did rules for weapons as well.\\r\\nTogether with Don Kaye, Mike Reese, and Leon Tucker, Gygax created a military miniatures society called Lake Geneva Tactical Studies Association (LGTSA) in 1970,[25] with its first headquarters in Gygax's basement.[14] Shortly thereafter in 1970, Robert Kuntz and Gygax founded the Castle & Crusade Society of the IFW.[26]\\r\\nLate in October 1970, Gygax lost his job at the insurance company after almost nine years. Unemployed and now with a family of five children  Ernest (\\"Ernie\\"), Lucion (\\"Luke\\"), Heidi, Cindy, and Elise[15][5]he tried to use his enthusiasm for games to make a living by designing board games for commercial sale. This clearly proved to be unsustainable when he only grossed $882 in 1971.[7]:84> He began to cobble shoes in his basement, which did provide him with steady income and gave him more time for pursuing his interest in game development.[27] In 1971, he began doing some editing work at Guidon Games, a publisher of wargames,[15] for which he produced the board games Alexander the Great and Dunkirk: The Battle of France. Early that same year, Gygax published Chainmail, a miniatures wargame that simulated medieval-era tactical combat, which he had originally written with hobby-shop owner Jeff Perren.[12][28][29] The Chainmail medieval miniatures rules were originally published in the Castle & Crusade Society's fanzine The Domesday Book. Guidon Games hired Gygax to produce a \\"Wargaming with Miniatures\\" series of games, and a new edition of Chainmail (1971) was the first book in the series.[30]:6 The first edition of Chainmail included a fantasy supplement to the rules.[29] These comprised a system for warriors, wizards, and various monsters of non-human races drawn from the works of J. R. R. Tolkien and other sources. For wizards, Gygax included six spells that could be used to affect a battle, plus two \\"missiles\\" (fire ball and lightning bolt).[31] For a small publisher like Guidon Games, Chainmail was relatively successful, selling 100 copies per month.[7]:86\\r\\nGygax also collaborated on Tractics with Mike Reese & Leon Tucker, his contribution being the change to a 20-sided spinner or a coffee can with 20 numbered poker chips (or eventually 20-sided dice) to decide combat resolutions instead of the standard 6-sided dice.[7]:87 He also collaborated with Dave Arneson on the Napoleonic naval wargame Don't Give Up the Ship![23]\\r\\nDave Arneson adopted the Chainmail rules for his fantasy Blackmoor campaign.[12] While visiting Lake Geneva in November 1972, Arneson ran his fantasy game using the new rules, and Gygax immediately saw the potential of role-playing games.[12][32]\\r\\nGygax and Arneson immediately started to collaborate on creating \\"The Fantasy Game\\", the role-playing game which would evolve into Dungeons & Dragons.[3][12][33]\\r\\nTwo weeks after Arneson's Blackmoor demonstration, Gygax had produced a 50-page set of rules, and was ready to try it on his two oldest children, Ernie and Elise, in a setting he called \\"Greyhawk\\". This group rapidly expanded to include Don Kaye, Rob Kuntz and eventually a large circle of players. Gygax sent the 50 pages of rules to his wargaming contacts and asked them to playtest the new game. Gygax and Arneson continued to trade notes about their respective campaigns, calling the amalgamation of Blackmoor and Greyhawk \\"The Great Kingdom\\". This collaboration gradually petered out as Gygax and Arneson realized their visions for the new game were diverging.[7]:100\\r\\nBased on the feedback he received, Gygax created a 150-page revision of the rules by mid-1973. Several aspects of the system governing magic in the game were inspired by The Dying Earth stories of fantasy author Jack Vance (notably the fact that magic-users in the game forget the spells that they have learned immediately upon casting them, and must re-study them in order to cast them again),[34] and the system as a whole drew upon the work of authors such as Robert E. Howard, L. Sprague de Camp, Michael Moorcock, Roger Zelazny, Poul Anderson, Tolkien, Bram Stoker, and others.[34]\\r\\nHe asked Guidon Games to publish it,[30]:7 but the 3-volume rule set in a labeled box was beyond the scope of the small publisher. Gygax attempted to pitch the game to Avalon Hill, but the largest company in wargaming did not understand the new concept of role-playing, and turned down his offer.[35]\\r\\nBy 1974, Gygax's Greyhawk group, which had started off with himself, Ernie Gygax, Don Kaye, Rob Kuntz, and Terry Kuntz, had grown to over 20 people, with Rob Kuntz becoming the co-dungeon-master so that each of them could referee groups of only a dozen players.[30]:7\\r\\nGygax left Guidon Games in 1973 and in October, with Don Kaye as a partner, founded Tactical Studies Rules, later known as TSR, Inc.[35][36] The two men each invested US$1,000 in the ventureKaye borrowed his share on his life insurance policyin order to finance the start-up of TSR.[16] This was still not enough to print their new role-playing game, so they tried to raise money by immediately publishing Cavaliers and Roundheads. But sales were poor, and they still did not have enough capital to publish Dungeons & Dragons. Worried that the other playtesters and wargamers now familiar with Gygax's rules would bring a similar product to the market first,[37] the two accepted an offer in December 1973 by game playing acquaintance Brian Blume to invest $2,000 in TSR to become an equal one-third partner.[37] (Gygax accepted Blume's offer right away. Kaye was less enthusiastic, and after a week to consider the offer, he questioned Blume closely before acquiescing.)[7]:110 Blume's investment finally brought the financing that enabled them to publish D&D.[33] Gygax worked on rules for more miniatures and tabletop battle games including Classic Warfare (Ancient Period: 1500 BC to 500 AD), and Warriors of Mars.[16]\\r\\nThe first commercial version of D&D was released by TSR in January 1974 as a boxed set.[38] A hand-assembled print run of 1,000 copies, put together in Gygax's home,[28] sold out in less than a year.[5][6]\\r\\nAt the end of 1974, with sales of D&D skyrocketing, the future looked bright for Gygax and Kaye, who were only 36 years old. But in January 1975, Kaye unexpectedly died of a heart attack. He had not made any specific provision in his will regarding his one-third share of the company, simply leaving his entire estate to his wife Donna.[39] Although she had worked briefly for TSR as an accountant, she had not shared her husband's enthusiasm for gaming, and made it clear that she would not be having anything to do with managing the company. Gygax characterized her as \\"less than personable... After Don died she dumped all the Tactical Studies Rules materials off on my front porch. It would have been impossible to manage a business with her involved as a partner.\\"[39] After Kaye's death, TSR was forced to relocate from Kaye's dining room to Gygax's basement.[30]:7 In July 1975, Gygax and Blume reorganized their company from a partnership to a corporation called TSR Hobbies. Gygax owned 150 shares, Blume owned the other 100 shares, and both had the option to buy up to 700 shares at any time in the future. But TSR Hobbies had nothing to publishD&D was still owned by the 3-way partnership of TSR, and neither Gygax nor Blume had the money to buy out the shares owned by Kaye's wife. Blume persuaded a reluctant Gygax to allow his father, Melvin Blume, to buy Donna's shares, and those were converted to 200 shares in TSR Hobbies.[40] In addition, Brian bought another 140 shares.[7]:117 These purchases reduced Gygax from the majority shareholder in control of the company to minority shareholder; he effectively became the Blumes' employee.[30]:8\\r\\nGygax wrote the supplements Greyhawk, Eldritch Wizardry, and Swords & Spells for the original D&D game. With Brian Blume, Gygax also designed the wild west-oriented role-playing game Boot Hill. In the same year, Gygax created the magazine The Strategic Review with himself as editor.[15] But wanting a more industry-wide periodical, he hired Tim Kask as TSR's first employee to change this magazine to the fantasy periodical The Dragon,[21] with Gygax as writer, columnist, and publisher (from 1978 to 1981).[41] The Dragon debuted in June 1976, and Gygax commented on its success years later: \\"When I decided that The Strategic Review was not the right vehicle, hired Tim Kask as a magazine editor for Tactical Studies Rules, and named the new publication he was to produce The Dragon, I thought we would eventually have a great periodical to serve gaming enthusiasts worldwide... At no time did I ever contemplate so great a success or so long a lifespan.\\"[42]\\r\\nIn 1976, TSR moved out of Gygax's house into its first professional home, known as \\"The Dungeon Hobby Shop\\".[30]:8 Dave Arneson was hired as part of the creative staff, but was let go after only 10 months, another sign that Gygax and Arneson still had creative differences over D&D.[7]:129\\r\\nThe Dungeons & Dragons Basic Set, released in 1977, was an introductory version of the original D&D geared towards new players and edited by J. Eric Holmes.[28] But in the same year, TSR Hobbies released a completely new and complex version of D&D, Advanced Dungeons & Dragons (AD&D). The Monster Manual, released later that year, became the first supplemental rule book of the new system, and many more followed.[33] The AD&D rules were not fully compatible with those of the D&D Basic Set and as a result, D&D and AD&D became distinct product lines.[7]:135 Splitting the game lines created a further rift between Gygax and Arneson; although Arneson received a 10% royalty on sales of all D&D products, Gygax refused to pay him royalties on AD&D books, claiming it was a new and different property. In 1979, Arneson filed a lawsuit against TSR; it was eventually settled in March 1981 with the agreement that Arneson would receive a 2.5% royalty on all AD&D products, giving him a very comfortable six-figure annual income for the next decade.[7]:139\\r\\nGygax wrote the AD&D hardcovers Players Handbook, Dungeon Masters Guide, Monster Manual, and Monster Manual II. Gygax also wrote or co-wrote numerous AD&D and basic D&D adventure modules, including The Keep on the Borderlands, Tomb of Horrors, Expedition to the Barrier Peaks, The Temple of Elemental Evil, The Forgotten Temple of Tharizdun, Mordenkainen's Fantastic Adventure, Isle of the Ape, and all seven of the modules later combined into Queen of the Spiders. In 1980, Gygax's long-time campaign setting of Greyhawk was published in the form of the World of Greyhawk Fantasy World Setting folio, which was expanded in 1983 into the World of Greyhawk Fantasy Game Setting boxed set. Sales of the D&D game reached US$8.5 million in 1980.[5] Gygax also provided assistance on the Gamma World science fantasy role-playing game in 1981 and co-authored the Gamma World adventure Legion of Gold.\\r\\nIn 1979, a Michigan State University student, James Dallas Egbert III, allegedly disappeared into the school's steam tunnels while playing a live-action version of D&D. In fact, Egbert was discovered in Louisiana several weeks later,[7]:145 but negative mainstream media attention focused on D&D as the cause. In 1982, Patricia Pulling's son killed himself. Blaming D&D for her son's suicide, Pulling formed an organization named B.A.D.D. (Bothered About Dungeons & Dragons) to attack the game and the company that produced it. Gygax defended the game on a segment of 60 Minutes,[6][43] which aired in 1985. When death threats started arriving at the TSR office, Gygax hired a bodyguard.[5][12] Despite the negative publicity, or perhaps because of it, TSR's annual D&D sales increased in 1982 to US$16 million,[12] and in January 1983, The New York Times speculated that D&D might become \\"the great game of the 1980s\\" in the same manner that Monopoly was emblematic of the Great Depression.[44]\\r\\nBrian Blume persuaded Gygax to allow Brian's brother Kevin to purchase Melvin Blume's shares. This gave the Blume brothers a controlling interest,[40] and by 1981, Gygax and the Blumes were increasingly at loggerheads over management of the company. Gygax's frustrations at work, and increased prosperity from his generous royalty cheques brought a number of changes to his personal life. He and Mary Jo had been active members of the local Jehovah's Witnesses, but others in the congregation already felt uneasy about Gygax's smoking and drinking; his connection to the \\"satanic\\" game of D&D caused enough friction that the Gygaxes finally disassociated themselves from Jehovah's Witnesses.[7]:156 Mary Jo, continuing to resent the amount of time her husband spent \\"playing games\\", had begun to drink excessively, and the couple argued frequently. Gygax, who had started smoking marijuana when he lost his insurance job in 1970, started to use cocaine, and had a number of extramarital affairs. Finally in 1983, the two had an acrimonious divorce.[7]:187\\r\\nAt the same time, the Blumes, wanting to get Gygax out of Lake Geneva so they could manage the company without his \\"interference\\", split TSR Hobbies into TSR, Inc., and TSR Entertainment, Inc. Gygax became the President of TSR Entertainment, Inc.,[16] and the Blumes sent him to Hollywood to develop TV and movie opportunities.[30]:13 He became co-producer of the licensed D&D cartoon series for CBS,[45] which led its time slot for two years.[3]\\r\\nGygax, newly single, took advantage of his time on the West Coast, renting an immense mansion, increasing his cocaine use, and spending time with several young starlets.[7]:168\\r\\nBecause he was occupied with getting a movie off the ground in Hollywood, Gygax had to leave the day-to-day operations of TSR to Kevin and Brian Blume.[12] In 1984, after months of negotiation, he reached an agreement with Orson Welles to star in a D&D movie, and John Boorman to act as producer and director. But almost at the same time, he received word that back in Lake Geneva, TSR had run into severe financial difficulties and Kevin Blume was shopping the company for US$6 million.[7]:171\\r\\nGygax immediately discarded his movie ambitionshis D&D movie would never be madeand flew back to Lake Geneva. There, he discovered to his shock that although industry leader TSR was grossing US$30 million, it was barely breaking even;[7]:171 it was in fact US$1.5 million in debt and teetering on the edge of insolvency.[12] After investigating the reasons why, Gygax brought his findings to the five other company directors. (Since 1982, TSR Inc. had conformed to the recommendations of the American Management Association by adding three \\"outside\\" directors to the board, increasing its size to six.) Gygax charged that the financial crisis was due to mismanagement by Kevin Blume: excess inventory, overstaffing, too many company cars, and some questionable (and expensive) projects such as dredging up a 19th century shipwreck.[7]:172 Gygax demanded that Kevin Blume be removed as company president, and the three outside directors agreed with him. However, the board still believed the financial problems were terminal and the company needed to be sold. In an effort to stay in control, in March 1985, Gygax exercised his 700-share stock option, giving him just over 50% control. He appointed himself president and CEO, and rather than selling the company, he took steps to produce new revenue generating products. To that end, he contacted Dave Arneson with a view to produce some Blackmoor material. He also bet heavily on a new AD&D book, Unearthed Arcana, a compilation of material culled from Dragon Magazine articles. And he quickly wrote a novel set in his Greyhawk setting, Saga of Old City, featuring a protagonist called Gord the Rogue. In order to bring some financial stability to TSR, he hired a company manager, Lorraine Williams.\\r\\nWhen Unearthed Arcana was released in July, Gygax's bet paid off, as the new book sold 90,000 copies in the first month. His novel also sold well, and he immediately published a sequel, Artifact of Evil. The financial crisis had been averted, but ironically Gygax had paved the way for his own downfall. In October 1985, the new manager, Lorraine Williams, revealed that she had purchased all of the shares of Kevin and Brian Blumeafter Brian had triggered his own 700-share option. Williams was now the majority shareholder, and replaced Gygax as president and CEO. She also made it clear that Gygax would be making no further creative contributions to TSR. Several of his projects were immediately shelved and never published. Gygax took TSR to court in a bid to block the Blumes' sale of their shares to Williams, but he lost.[46]\\r\\nSales of D&D reached US$29 million in 1985,[5] but Gygax, seeing his future at TSR as untenable,[45] resigned all positions with TSR, Inc. in October 1986, and settled his disputes with TSR in December 1986.[46] By the terms of his settlement with TSR, Gygax kept the rights to Gord the Rogue as well as all D&D characters whose names were anagrams or plays on his own name (for example, Yrag and Zagyg).[47] However, he lost the rights to all his other work, including the World of Greyhawk and the names of all the characters he had ever used in TSR material, such as Mordenkainen, Robilar, and Tenser.\\r\\nImmediately after leaving TSR, Gygax was approached by a wargaming acquaintance, Forrest Baker, who had done some consulting work for TSR in 1983 and 1984.[7]:188 Gygax, who was tired of company management, was simply looking for some way to market more of his Gord the Rogue novels, but Baker had a vision for a new gaming company. He promised that he would handle the business end, while Gygax would handle the creative projects. Baker also guaranteed that, using Gygax's name, he would be able to bring in one to two million dollars of investment.[7]:188 Gygax decided this was a good opportunity, and in October 1986, New Infinities Productions, Inc. (NIPI)[48][30] was publicly announced.[30]:237 To help him with the creative work, Gygax poached Frank Mentzer and Dragon magazine editor Kim Mohan from TSR.[46] But before a single product was released, Forrest Baker left NIPI when his promised outside investment of one to two million dollars failed to materialize.[30]:237\\r\\nAgainst his will, Gygax was back in charge again; he immediately looked for a quick product to get NIPI off the ground. He had retained the rights to Gord the Rogue as part of his severance agreement with TSR, so he licensed Greyhawk from TSR and started writing new novels beginning with Sea of Death (1987); sales were brisk, and Gygax's Gord the Rogue novels ended up keeping New Infinities in business.[30]:237\\r\\nGygax brought in Don Turnbull from Games Workshop to manage the company, then worked with Mohan and Mentzer on a science fiction-themed RPG, Cyborg Commando, which was published in 1987.[30]:237 However, sales of the new game were not brisk; NIPI was still dependent on Gord the Rogue.\\r\\nMentzer and Mohan also wrote a series of generic RPG adventures called Gary Gygax Presents Fantasy Master. They also began working on a third line of products, which began with an adventure written by Mentzer called The Convert (1987); Mentzer had written the adventure as an RPGA tournament for D&D, but TSR was not interested in publishing it. Mentzer got verbal permission to publish it with New Infinities, but since the permission was not in writing TSR filed an injunction to prevent the adventure's sale, although the injunction was later lifted.[30]:238[7]:190 The legal costs further drained NIPI of capital.\\r\\nDuring all of this drama, Gygax became a father again. Over the past year, he had formed a romantic relationship with Gail Carpenter, his former assistant at TSR. In November 1986, she gave birth to Gygax's sixth child, Alex. Biographer Michael Witwer believes the birth of Alex forced Gygax to reconsider the equation of work, gaming and family that, up until this time, had been dominated by work and gaming. \\"Gary, keenly aware that he had made mistakes as a father, and husband in the past, was determined not to make them again... Gary was also a realist, and knew what good fatherhood would demand, especially at his age.\\"[7]:189 On August 15, 1987, on what would have been his parents' 50th wedding anniversary, Gygax married Gail Carpenter.[18]\\r\\nDuring 1987 and 1988, Gygax worked with Flint Dille on the Sagard the Barbarian books,[6] as well as Role-Playing Mastery and its sequel, Master of the Game.[7]:191 He also wrote two more Gord the Rogue novels, City of Hawks (1987), and Come Endless Darkness (1988). However, by 1988, TSR had rewritten the setting for the world of Greyhawk, and Gygax was not happy with the new direction in which TSR was taking \\"his\\" creation. In a literary declaration that his old world was dead, and wanting to make a clean break with all things Greyhawk, Gygax destroyed his version of Oerth in the final Gord the Rogue novel, Dance of Demons.[49]\\r\\nWith the Gord the Rogue novels finished, NIPI's main source of steady income dried up. The company needed a new product. Gygax announced in 1988 in a company newsletter that he and Rob Kuntz, his co-Dungeon Master during the early days of the Greyhawk campaign, were working as a team again. This time they would create a new multi-genre fantasy RPG called \\"Infinite Adventures\\", which would be supported by different gamebooks for different genres.[30]:61 This line would detail the Castle and City of Greyhawk as Gygax and Kuntz had originally envisioned them, now called \\"Castle Dunfalcon\\".[30]:239\\r\\nHowever, before work on this project could commence, NIPI ran out of money, was forced into bankruptcy, and was dissolved in 1989.[30]:239\\r\\nAfter NIPI folded, Gygax decided to create an entirely new RPG called The Carpenter Project,[30]:61 one considerably more complex and \\"rule heavy\\" than his original and relatively simple D&D system, which had been encompassed by a mere 150 typewritten pages.[7]:194 He also wanted to create a horror setting for the new RPG called Unhallowed. He began working on the RPG and the setting with the help of games designer Mike McCulley.[7]:193 Game Designers Workshop became interested in publishing the new system, and it also drew the attention of JVC and NEC, who were looking for a new RPG system and setting to turn into a series of computer games.[7]:194 NEC and JVC were not interested in horror though, and work on the Unhallowed setting was shelved in favour of a fantasy setting called Mythus. JVC also wanted a name change for the RPG, favoring Dangerous Dimensions over The Carpenter Project.[30]:61ÿ62 Work progressed favourably until March 1992, when TSR filed an injunction against Dangerous Dimensions, claiming the name and initials were too similar to Dungeons & Dragons. Gygax, with the approval of NEC and JVC, quickly changed the name to Dangerous Journeys,[50] and work on the new game continued.\\r\\nThe marketing strategy for Dangerous Journeys: Mythus was multi-pronged: in addition to the RPG and setting to be published by Games Designers Workshop, and the Mythus computer game being prepared by NEC and JVC, there would also be a series of books based on the Mythus setting written by Gygax. So in addition to his work on the RPG and the Mythus setting, Gygax wrote three novels, released under publisher Penguin/Roc and later reprinted by Paizo Publishing: The Anubis Murders, The Samarkand Solution, and Death in Delhi.\\r\\nIn late 1992, the Dangerous Journeys RPG was released by Games Designer Workshop,[6][51] but TSR immediately applied for an injunction against the entire Dangerous Journeys RPG and the Mythus setting, arguing that Dangerous Journeys was based on D&D and AD&D. Although the injunction failed, TSR moved forward with litigation. Gygax believed the legal action was without merit and fuelled by Lorraine Williams' personal enmity,[7]:195 but NEC and JVC both withdrew from the project, killing the Mythus computer game.[7]:194 By 1994, the legal costs associated with many months of pretrial discovery had drained all of Gygax's resources; believing that TSR was also suffering, Gygax offered to settle. In the end, TSR paid Gygax for the complete rights to Dangerous Journeys and Mythus.[52] Although Gygax was well compensated for his years of work on Dangerous Journeys and Mythus, neither was ever publishedTSR immediately and permanently shelved them.\\r\\nIn 1995, Gygax began work on a new computer role-playing game called Lejendary Adventures.[21] In contrast to the rules-heavy Dangerous Journeys, this new system was a return to simple and basic rules. Although he was not able to successfully release a Lejendary Adventures computer game, Gygax decided to instead publish it as a tabletop game.[30]:380\\r\\nMeanwhile, in 1996 the games industry was rocked by the news that TSR had run into insoluble financial problems and had been bought by Wizards of the Coast. While WotC was busy refocussing TSR's products, Christopher Clark of Inner City Games Designs approached Gygax in 1997 to suggest that they produce some adventures to sell in game stores while TSR was otherwise occupied; the result was a pair of fantasy adventures published by Inner City Games: A Challenge of Arms (1998) and The Ritual of the Golden Eyes (1999).[30]:380 Gygax introduced some investors to Clark's publication setup, and although the investors were not willing to fund publication of Legendary Adventures, Clark and Gygax formed a partnership called Hekaforge Productions.[30]:380 Gygax was thus able to return to publish Lejendary Adventures in 1999.[6] The game was published as a three-volume set: The Lejendary Rules for All Players (1999), Lejend Master's Lore (2000) and Beasts of Lejend (2000).[30]:380\\r\\nThe new owner of TSR, WotC's Peter Adkison, clearly did not harbor any of Lorraine Williams' ill-will toward Gygax: Adkison purchased all of Gygax's residual rights to D&D and AD&D for a six-figure sum.[7]:203 Although Gygax did not write any new supplements or books for TSR or WotC, he did agree to write the preface to the 1998 adventure Return to the Tomb of Horrors, a paean to Gygax's original AD&D adventure Tomb of Horrors.[42] He also returned to the pages of Dragon Magazine, writing the \\"Up on a Soapbox\\" column from Issue #268 (January, 2000) to Issue #320 (June, 2004).[30]:282\\r\\nGygax continued to work on Lejendary Adventures which he believed was his best work. However, sales were below expectation.[7]:204\\r\\nOn June 11, 2001, Stephen Chenault and Davis Chenault of Troll Lord Games announced that Gygax would be writing books for their company.[30]:378 Gygax's early work for Troll Lord included a series of hardcover books that eventually came to be called \\"Gygaxian Fantasy Worlds\\"; the first was The Canting Crew (2002), a look at the roguish underworld. He also wrote World Builder (2003) and Living Fantasy (2003), generic game design books usable in many different settings. After the first four books in the series, Gygax stepped down from writing and took on an advisory role, though the series logo still carried his name.[30]:379 Troll Lord also published a few adventures as a result of their partnership with Gygax, including The Hermit (2002) an adventure intended for d20 and also for Lejendary Adventures.[30]:379\\r\\nBy 2002, Gygax had given Christopher Clark of Hekaforge an encyclopaedic 72,000-word text describing the Lejendary Earth. Clark split the manuscript up into five books and expanded it, with each of the final books coming to about 128,000 words, giving Hekaforge a third Lejendary Adventures line to supplement the core rules and adventures. Hekaforge managed to publish the first two of those Lejendary Earth sourcebooks, Gazetteer (2002) and Noble Kings and Great Lands (2003),[30]:380 but by 2003 the small company was having financial difficulties. Clark to ask Troll Lord Games to become an \\"angel\\" investor by publishing the three remaining Lejendary Adventures books.[30]:381\\r\\nOn October 9, 2001, Necromancer Games announced that they would be publishing a d20 version of Necropolis, an adventure originally planned by Gygax for New Infinities Productions and later printed in 1992 as a Mythus adventure by GDW; Gary Gygax's Necropolis was published a year later.[30]:366ÿ367\\r\\nGygax also performed voiceover narration for cartoons and video games. In 2000, he voiced his own cartoon self for an episode of Futurama, \\"Anthology of Interest I\\"[5][53] that also included the voices of Al Gore, Stephen Hawking and Nichelle Nichols.[7]:202 Gygax also performed as a guest Dungeon Master in the Delera's Tomb quest series of the massively multiplayer online role-playing game Dungeons & Dragons Online: Stormreach.[54]\\r\\nDuring his time with TSR, Gygax had often mentioned the mysterious Castle Greyhawk which formed the centre of his own home campaign. But despite all of his written output over the previous 30 years, Gygax had never published details of the castle. In 2003, Gygax announced that he was again partnering with Rob Kuntz to publish the original and previously unpublished details of Castle Greyhawk and the City of Greyhawk in 6 volumes, although the project would use the rules for Castles and Crusades rather than D&D. As Gygax wrote in an on-line forum: \\"I have laid out a new schematic of castle and dungeon levels based on both my original design of 13 levels plus side adjuncts, and the 'New Greyhawk Castle' that resulted when Rob and I combined our efforts and added a lot of new levels too. From that Rob will draft the level plans for the newest version of the work. Meantime, I am collecting all the most salient feature, encounters, tricks, traps, etc. for inclusion on the various levels. So the end result will be what is essentially the best of our old work in a coherent presentation usable by all DMs, the material having all the known and yet to be discussed features of the original work that are outstanding... I hope.\\"[55] Since Wizards of the Coast, which had bought TSR in 1997, still owned the rights to the name \\"Greyhawk\\", Gygax changed the name of Castle Greyhawk to \\"Castle Zagyg\\", a reverse homophone of his own name, and also changed the name of the nearby city to \\"Yggsburgh\\", a play on his initials \\"E.G.G.\\"[7]:208\\r\\nThe scale of the project was enormous: By the time Gygax and Kuntz had stopped working on their original home campaign, the castle dungeons had encompassed 50 levels of cunningly complex passages with thousands of rooms and traps. This, plus plans for the city of Yggsburgh and encounter areas outside the castle and city, would clearly be too much to fit into the proposed 6 volumes. Gygax decided he would compress the castle dungeons into 13 levels, the size of his original Castle Greyhawk in 1973[56] by amalgamating the best of what could be gleaned from binders and boxes of old notes.[57] However, neither Gygax nor Kuntz had kept careful or comprehensive plans. Because they had often made up details of play sessions on the spot,[58] they usually just scribbled a quick map as they played, with cursory notes about monsters, treasures, and traps.[59] These sketchy maps had contained just enough detail that the two could ensure their independent work would dovetail. All of these old notes now had to be deciphered, 25-year-old memories dredged up as to what had happened in each room, and a decision made whether to keep or discard each new piece.[60] Recreating the city too would be a challenge. Although Gygax still had his old maps of the original city, all of his previously published work on the city was owned by WotC, so he would have to create most of the city from scratch while still maintaining the \\"look and feel\\" of his original.[61]\\r\\nDue to creative differences, Kuntz backed out of the project, but created an adventure module that would be published at the same time as Gygax's first book.[62] Gygax continued to painstakingly put Castle Zagyg together on his own, but even this slow and laborious process came to a complete halt when Gygax suffered a serious stroke in April 2004 and then another one a few weeks later.[7]:211 Although he returned to his keyboard after a seven-month convalescence, his output was reduced from 14-hour work days to only one or two hours per day.[63] Finally in 2005, Castle Zagyg Part I: Yggsburgh, the first book in the six-book series, appeared.[30]:381 Later that year, Troll Lord Games also published Castle Zagyg: Dark Chateau (2005), the adventure module written for the Yggsburgh setting by Rob Kuntz.[30]:381 Jeff Talanian helped with the creation of the dungeon, eventually resulting in publication of the limited edition CZ9: The East Marks Gazetteer (2007).[30]:381\\r\\nThat same year, Gygax was diagnosed with a potentially deadly abdominal aortic aneurysm. Doctors concurred that surgery was needed, but their estimates of success varied from 50% to 90%. With no firm medical consensus, Gygax came to believe that he would likely die on the operating table; he refused to consider surgery, although he realized that a rupture of the aneurysm ÿ likely inevitable ÿ would be fatal.[7]:216 In one concession to his condition, he switched from cigarettes, which he had smoked since high school, to cigars.[7]:212\\r\\nIt wasn't until 2008 that Gygax was able to finish the second volume of six volumes, Castle Zagyg: The Upper Works, which described details of the castle above ground. The next two volumes were supposed to detail the dungeons beneath Castle Zagyg. However, before they could be written, Gygax died in March 2008. Three months after his death, Gygax Games ÿ a new company formed by Gary's widow, Gail ÿ withdrew all of the Gygax licenses from Troll Lord,[30]:382 and also from Hekaforge.[30]:381\\r\\nFrom an early age, Gygax hunted and was a target-shooter with both bow and gun.[64] He was also an avid gun collector, and at various times owned a variety of rifles, shotguns, and handguns.[65]\\r\\nAs the \\"father of role-playing games\\", Gygax received many awards, honors, and tributes related to gaming:","input":"Who is the creator of dungeons and dragons?"},{"output":"Ancient Greek","context":"Eureka (Greek: ?ϻҰϫ) is an interjection used to celebrate a discovery or invention. It is a transliteration of an exclamation attributed to Ancient Greek mathematician and inventor Archimedes.\\r\\n\\r\\n\\r\\n\\"Eureka\\" comes from the Ancient Greek word ?ϻҰϫ he~rka, meaning \\"I have found (it)\\", which is the first person singular perfect indicative active of the verb ?? heurisk \\"I find\\".[1] It is closely related to heuristic, which refers to experience-based techniques for problem solving, learning, and discovery.\\r\\nThe accent of the English word is on the second syllable, following Latin rules of accent, which require that a penult (next-to-last syllable) must be accented if it contains a long vowel. In the Greek pronunciation, the first syllable has a high pitch accent, because the Ancient Greek rules of accent do not force accent to the penult unless the ultima (last syllable) has a long vowel. The long vowels in the first two syllables would sound like a double stress to English ears (as in the phrase Maltese cat).\\r\\nThe initial /h/ is dropped in some European languages, including Spanish, Dutch, and English, but preserved in others, such as Finnish, Danish, and German. \\r\\nThe exclamation 'Eureka!' is famously attributed to the ancient Greek scholar Archimedes. He reportedly proclaimed \\"Eureka! Eureka!\\" (i.e. twice) after he had stepped into a bath and noticed that the water level rose, whereupon he suddenly understood that the volume of water displaced must be equal to the volume of the part of his body he had submerged. (This relation is not what is known as Archimedes' principlethat deals with the upthrust experienced by a body immersed in a fluid.[2][3]) He then realized that the volume of irregular objects could be measured with precision, a previously intractable problem. He is said to have been so eager to share his discovery that he leapt out of his bathtub and ran through the streets of Syracuse naked.\\r\\nArchimedes' insight led to the solution of a problem posed by Hiero of Syracuse, on how to assess the purity of an irregular golden votive crown; he had given his goldsmith the pure gold to be used, and correctly suspected he had been cheated by the goldsmith removing gold and adding the same weight of silver. Equipment for weighing objects with a fair amount of precision already existed, and now that Archimedes could also measure volume, their ratio would give the object's density, an important indicator of purity (as gold is nearly twice as dense as silver and has significantly greater weight for the same volume of matter at standard temperatures and pressure).\\r\\nThis story first appeared in written form in Vitruvius's books of architecture, two centuries after it supposedly took place.[4] Some scholars have doubted the accuracy of this tale, saying among other things that the method would have required precise measurements that would have been difficult to make at the time.[5] Galileo Galilei himself weighed in on the controversy, suggesting a design for a hydrostatic balance that could be used to compare the dry weight of an object with the weight of the same object submerged in water.[6] For the problem posed to Archimedes, though, there is a simple method which requires no precision equipment: balance the crown against pure gold in air, and then submerge the crown and the gold in water, separately, to determine their volumes from their respective displacements. If the volumes were identical, their densities were the same and therefore the crown must be pure gold. But if the crown's volume were greater, its density would be less than that of the gold, and therefore the crown could not be pure gold.[7]\\r\\nThe expression is also the state motto of California, referring to the momentous discovery of gold near Sutter's Mill in 1848. The California State Seal has included the word \\"eureka\\" since its original design by Robert S. Garnett in 1850; the official text from that time describing the seal states that this word's meaning applies \\"either to the principle involved in the admission of the State or the success of the miner at work\\". In 1957 the state legislature attempted to make \\"In God We Trust\\" the state motto as part of the same post WWII anti-Communist movement that successfully added the term \\"under God\\" to the American Pledge of Allegiance in 1954, but this attempt did not succeed and \\"Eureka\\" was made the official motto in 1963.[8]\\r\\nThe city of Eureka, California, founded in 1850, uses the California State Seal as its official seal. Eureka is a considerable distance from Sutter's Mill, but was the jumping off point of a smaller gold rush in nearby Trinity County, California in 1850. It is the largest of at least eleven remaining US cities and towns named for the exclamation, \\"eureka!\\". As a result of the extensive use of the exclamation dating from 1849, there were nearly 40 locales so named by the 1880s in a nation that had none in the 1840s.[9] Many places, works of culture, and other objects have since been named \\"Eureka\\"; see Eureka (disambiguation) for a list.\\r\\n\\"Eureka\\" was also associated with a gold rush in Ballarat, Victoria, Australia. The Eureka Stockade was a revolt in 1854 by gold miners against unjust mining license fees and a brutal administration supervising the miners. The rebellion demonstrated the refusal of the workers to be dominated by unfair government and laws. The Eureka Stockade has often been referred to as the \\"birth of democracy\\" in Australia.[10]\\r\\nAnother mathematician, Carl Friedrich Gauss, echoed Archimedes when in 1796 he wrote in his diary, \\"ʽ! num =  +  + \\", referring to his discovery that any positive integer could be expressed as the sum of at most three triangular numbers.[11] This result is now known as Gauss' Eureka theorem[12] and is a special case of what later became known as the Fermat polygonal number theorem.","input":"What is the origin of the word eureka?"},{"output":"the National Labor Relations Act","context":"The National Labor Relations Board (NLRB) is an independent US government agency with responsibilities for enforcing US labor law in relation to collective bargaining and unfair labor practices. Under the National Labor Relations Act of 1935 it supervises elections for labor union representation and can investigate and remedy unfair labor practices. Unfair labor practices may involve union-related situations or instances of protected concerted activity. The NLRB is governed by a five-person board and a General Counsel, all of whom are appointed by the President with the consent of the Senate. Board members are appointed to five-year terms and the General Counsel is appointed to a four-year term. The General Counsel acts as a prosecutor and the Board acts as an appellate quasi-judicial body from decisions of administrative law judges.\\r\\n\\r\\nThe NLRB is headquartered at 1015 Half St. SE, Washington, D.C., with over 30 regional, sub-regional, and residential offices throughout the U.S.\\r\\n\\r\\nThe history of the National Labor Relations Board (NLRB) can be traced to enactment of the National Industrial Recovery Act in 1933. Section 7(a) of the act protected collective bargaining rights for unions,[4] but was difficult to enforce. A massive wave of union organizing was punctuated by employer and union violence, general strikes, and recognition strikes.[5][6][7] The National Industrial Recovery Act was administered by the National Recovery Administration (NRA). At the outset, NRA Administrator Hugh S. Johnson believed that Section 7(a) would be self-enforcing, but the tremendous labor unrest proved him wrong. On August 5, 1933, President Franklin D. Roosevelt announced the establishment of the National Labor Board, under the auspices of the NRA, to implement the collective bargaining provisions of Section 7(a).[1]\\r\\n\\r\\nThe National Labor Board (NLB) established a system of 20 regional boards to handle the immense caseload. Each regional board had a representative designated by local labor unions, local employers, and a \\"public\\" representative. All were unpaid. The public representative acted as the chair. The regional boards could hold hearings and propose settlements to disputes. Initially, they lacked authority to order representation elections, but this changed after Roosevelt issued additional executive orders on February 1 and February 23, 1934.\\r\\n\\r\\nThe NLB, too, proved ineffective. Congress passed Public Resolution No. 44 on June 19, 1934, which empowered the president to appoint a new labor board with authority to issue subpoenas, hold elections, and mediate labor disputes.[8][9] On June 29, President Roosevelt abolished the NLB and in Executive Order 6763 established a new, three-member National Labor Relations Board.[10][11]\\r\\n\\r\\nLloyd K. Garrison was the first chair of the National Labor Relations Board (often referred to by scholars the \\"First NLRB\\" or \\"Old NLRB\\").[2] The \\"First NLRB\\" established organizational structures which continue at the NLRB in the 21st century. This includes the regional structure of the board; the use of administrative law judges and regional hearing officers to initially rule on cases; an appeal process to the national board; and the use of expert staff, organized into various divisions, at the national level.[12] Formally, Garrison established the:[13]\\r\\n\\r\\nWithin a year, however, most of the jurisdiction of the \\"First NLRB\\" was stripped away. Its decisions in the automobile, newspaper, textile, and steel industries proved so volatile that Roosevelt himself often removed these cases from the board's jurisdiction. Several federal court decisions further limited the board's power. Senator Robert F. Wagner (D ÿ NY) subsequently pushed legislation through Congress to give a statutory basis to federal labor policy that survived court scrutiny. On July 5, 1935, a new lawthe National Labor Relations Act (NLRA, also known as the Wagner Act)superseded the NIRA and established a new, long-lasting federal labor policy.[15] The NLRA designated the National Labor Relations Board as the implementing agency.\\r\\n\\r\\nThe first chair of the \\"new\\" NLRB was J. Warren Madden, professor of the University of Pittsburgh School of Law.[16] Madden largely confirmed the previous structure of the \\"first NLRB\\" by formally establishing five divisions within the agency:\\r\\n\\r\\nBenedict Wolf was the first Secretary of the NLRB, Charles H. Fahy the first General Counsel, and David J. Saposs the first Chief Industrial Economist.[18] Wolf resigned in mid-1937, and Nathan Witt, an attorney in the Legal Division, was named Secretary in October.[19]\\r\\n\\r\\nThe Economic Division was a critical one for the NLRB. Cause-and-effect was one of the fundamental assumptions of the National Labor Relations Act, and for the causes of labor unrest to be understood economic analysis was needed.[20] From the start, the Economic Division undertook three important tasks: 1) Gather economic data in support of cases before the courts; 2) Conduct general studies of labor relations to guide the board in formulating decisions and policies; and 3) Research the history of labor relations (the history of written agreements, whether certain issues were historically part of collective bargaining, how unions functioned internally, trends in employer activities, trends in collective bargaining, whether certain employer actions led to labor disputes, etc.) so that the board could educate itself, the courts, Congress, and the public about labor relations.[21] The first function proved critical to the survival of the NLRB. It was the Economic Division's data and analysis, more than then NLRB's legal reasoning, which proved critical in persuading the Supreme Court to sustain the Wagner Act in NLRB v. Jones & Laughlin Steel.[22][23] The Court even cited several Economic Division studies in its decision.[24] In the wake of Jones & Laughlin Steel, many labor relations experts outside the agency concluded that economic analysis was \\"an accepted fact\\" essential to the proper functioning of the agency.[25] The Economic Division did, too.  It asked Madden to pair an economist with an attorney in every important case,[26] and prepared outline of the economic data needed to support each case in case it went before the courts.[27]\\r\\n\\r\\nDuring his time on the NLRB, Madden was often opposed by the American Federation of Labor (AFL), which believed that Madden was using the NLRA and the procedures and staff of the NLRB to favor the AFL's primary competitor, the Congress of Industrial Organizations (CIO).[28][29] The NLRB and NLRA were also under intense pressure from employers, the press, congressional Republicans, and conservative Democrats.[30][31]\\r\\n\\r\\nThe NLRB's Economic Division proved critical in pushing for a congressional investigation into employer anti-union activities, and ensuring that investigation was a success. The Economic Division was deeply aware of employer use of labor spies, violence, and company unions to thwart union organizing, and quietly pressed for a congressional investigation into these and other tactics. Senator Robert M. La Follette, Jr. took up the suggestion, on June 6, 1936, the Senate Committee on Education and Labor established a Subcommittee Investigating Violations of Free Speech and the Rights of Labor chaired by La Follette.[32] Better known as the \\"La Follette Committee\\", the subcommittee held extensive hearings for five years and published numerous reports.  The committee uncovered extensive evidence of millions of company dollars used to pay for spies and fifth columnists within unions, exposed the culpability of local law enforcement in acts of violence and murder against union supporters (particularly in the Harlan County War),[33] revealed the wide extent of illegal blacklisting of union members, and exposed the use of armed strikebreakers and widespread stockpiling of tear gas, vomit gas, machine guns, mortars, and armor by corporations to use against strikers.[34] Some of the evidence the committee used was provided by the Economic Division,[35] and the investigation proved critical for a time in defending the agency from business and congressional attack.[32]\\r\\n\\r\\nThe biggest issue the NLRB faced was constitutional. The Justice Department and NLRB legal staff wanted the Supreme Court to rule as quickly as possible on the constitutionality of the NLRA. But the Board and Justice Department also realized that the Court's Lochner era legal philosophy made it unlikely for the Court to uphold the Act. Subsequently, Madden strove to resolve minor cases before they could become court challenges, and worked to delay appeals as long as possible until the best possible case could be brought to the Court.[36] This legal strategy paid off. The Supreme Court upheld the NLRA in National Labor Relations Board v. Jones & Laughlin Steel Corporation, 301 U.S. 1 (1937).[37] Afterward, Madden continued to strategically guide the NLRB's legal efforts to strengthen the federal courts' view of the NLRA and the board's actions.[36] Because of the efforts of Madden and NLRB General Counsel Charles H. Fahy, the Supreme Court reviewed only 27 cases between August 1935 and March 1941, even though the board had processed nearly 5,000 cases since its inception. The Supreme Court enforced the NLRB's rulings in 19 cases without modifying them, enforced them with modification in six more, and denied enforcement in two cases. Additionally, the Board won all 30 injunction and all 16 representation cases before the lower courts, a rate of success unequalled by any other federal agency.[38]\\r\\n\\r\\nAFL opposition to the \\"Madden Board\\" grew after decisions in Shipowners' Ass'n of the Pacific Coast, 7 NLRB 1002 (1938), enf'd American Federation of Labor v. National Labor Relations Board, 308 U.S. 401 (1940) (awarding a longshoremen's unit to the CIO rather than the AFL), and American Can Co., 13 NLRB 1252 (1939) (unit's history of collective bargaining outweighs desire of workers to form craft-only unit).[39]\\r\\n\\r\\nThe AFL began pushing for an investigation into the NLRB, and this investigation led to allegations of communist influence within the agency. In June 1938, the House Un-American Activities Committee (led by Chairman Martin Dies, Jr. [D-TX]) heard testimony from AFL leader John P. Frey, who accused Madden of staffing the NLRB with communists.[40] The allegations were true, in at least one case: Nathan Witt, the NLRB's executive secretary and the man to whom Madden had delegated most administrative functions, was a member of the Communist Party of the United States.[41][42] These allegations and discoveries significantly damaged the agency's support in Congress and with the public.\\r\\n\\r\\nA second investigation into the NLRB led to organizational changes at the board. On July 20, 1939, Republicans and conservative Democrats formed a coalition to push through the House of Representatives a resolution establishing a Special Committee to Investigate the National Labor Relations Board (the \\"Smith Committee\\"), chaired by conservative, anti-labor Rep. Howard W. Smith (D-VA).[43][44] On March 7, 1940, the Smith Committee proposed legislation to abolish the NLRB, reconstitute it, and radically amend the NLRA.[45][46][47] President Roosevelt opposed the bill, although he conceded that perhaps the Board's membership should be expanded to five from three.[48] The Smith bill won several early tests in the House, which also voted to substantially cut the NLRB's budget.[49] Smith won a vote in the House Rules Committee permitting him to bring his bill to the floor for a vote.[50] In an attempt to defuse the legislative crisis, Madden fired 53 staff and forced another five to resign, and decentralized the NLRB's trial process to give regional directors and field agents more authority.[51] But the House still passed the Smith bill by a vote of 258 to 129 on June 7, 1940.[52] To protect the NLRB, Roosevelt convinced Senator Elbert D. Thomas, chair of the Senate Committee on Education and Labor, to hold no hearings or votes on the bill, and the legislation died.[53][54]\\r\\n\\r\\nThe Smith Committee investigation had a lasting effect on labor law in the U.S., and was the basis for the Taft-Hartley Act of 1947.[55][56] Madden's term on the NLRB came to an end after just four years. On November 15, 1940, President Roosevelt nominated Harry A. Millis to the NLRB and named him chair, and nominated Madden to a seat on the U.S. Court of Claims.[57]\\r\\n\\r\\nAnother major structural change occurred at the same time that Madden left the NLRB. The Smith committee's anti-communist drive also targeted David J. Saposs, the NLRB Chief Industrial Economist. Saposs had been surreptitiously assessed by members of the Communist Party USA for membership, and rejected as a prospect.[58] But Smith and others attacked Saposs as a communist, and Congress defunded his division and his job on October 11, 1940.[59][60][61] Although the Smith committee's investigation proved critical, the disestablishment of the Economic Division was due to many reasonsboth internal and external to the NLRB, and only some of which involved allegations of communist infiltration. As historian James A. Gross observed:.[62]\\r\\n\\r\\nThe Division was eliminated for all kinds of reasons which had nothing to do with the merits and importance of its work:  political pressures and maneuverings, jealousy and empire building between and among lawyers and economists inside the Board, opposition to leftist ideologies, a personal attack on the Chief Economist, David Saposs, and a mighty hostility to the administrative process.\\r\\nThe loss of the Economic Division was a major blow to the NLRB.  It had a major tactical impact: Economic data helped the NLRB fulfill its adjudicatorial and prosecutorial work in areas such as unfair labor practices (ULPs), representation elections, and in determining remedial actions (such as reinstatement, back pay awards, and fines).[63] Economic data also undermined employer resistance to the agency by linking that opposition to employer ULPs.[64] The loss also left the board dependent on the biased information offered by the parties in dispute before it, leading to poor decision-making and far less success in the courts.[65] It also had a major strategic impact: It left the board unable to determine whether its administration of the law was effective or not.[66] Nor could the board determine whether labor unrest was a serious threat to the economy or not. As labor historian Josiah Bartlett Lambert put it: \\"Without the Economic Research Division, the NLRB could not undertake empirical studies to determine the actual impact of secondary boycotts, jurisdictional strikes, national emergency strikes, and the like.\\"[67] The Economic Division was critical to a long-range NLRB process to lead to the long-term evolution of industrial labor relations in the U.S., but that goal had to be abandoned.[26][68] Most importantly, however, the evisceration of the Economic Division struck at the fundamental purpose of federal labor law, which was to allow experts to adjudicate labor disputes rather than use a legal process. With this data and analysis, widespread skepticism about the board's expertise quickly spread through Congress and the courts.  It also left the board largely unable to engage in rule-making, forcing it to make labor law on an inefficient, time-consuming case-by-case basis.[69] As of 1981, NLRB was still the only federal agency forbidden to seek economic information about the impact of its activities.[70]\\r\\n\\r\\nThe second chair of the NLRB, Harry A. Millis, led the board in a much more moderate direction.[67] Lacking an economic division to give it ammunition to fight with Millis deliberately made the NLRB dependent on Congress and the executive branch for its survival.[71] Millis made a large number of organizational changes. He stripped the office of Secretary of its power, set up an Administrative Division to supervise the 22 regional offices, initiated a study of the Board's administrative procedures, and genuinely delegated power to the regional offices.[72] He removed casehandling and regional office communication from the jurisdiction of the Office of the Secretary and created a Field Division.[73][74] He also adopted procedures requiring the board made its decisions based solely on the trial examiner's report, authorized NLRB review attorneys to review trial examiner report, required decisions to be drafted ahead of time and distributed for review, authorized review attorneys to revise drafts before a final decision was issued, required trial examiners to emphasize findings of fact and to address points of law, and began holding board meetings when there were differences of opinion over decisions.[73]\\r\\n\\r\\nMillis eliminated the Review Division's decisive role in cases, which had been established under Madden and Witt.[75] Madden and Witt had adopted a highly centralized Board structure so that (generally speaking) only the cases most favorable to the board made it to the courts. The centralized structure meant that only the strongest cases made it to national board, so that the board could apply all its economic and legal powers to crafting the best decision possible. This strategy enabled the NLRB to defend itself very well before the Supreme Court. But Madden and Witt had held on to the centralized strategy too long, and made political enemies in the process. Millis substituted a decentralized process in which the board was less a decision-maker and more a provider of services to the regions.[75] Many of the changes Millis instituted were designed to mimic requirements placed on other agencies by the Administrative Procedure Act.[62]\\r\\n\\r\\nAmerican entry into World War II on December 8, 1941, significantly changed the NLRB. On January 12, 1942, President Roosevelt created the National War Labor Board (NWLB), which displaced the NLRB as the main focus of federal labor relations for the duration of the war. The NWLB was given the authority to \\"finally determine\\" any labor dispute which threatened to interrupt war production, and to stabilize union wages and benefits during the war. Although Roosevelt instructed the NWLB not to intrude on jurisdiction exercised by the NLRB, the War Labor Board refused to honor this request. From 1942 to 1945, Millis tried to secure a jurisdictional agreement with NWLB chair George W. Taylor. But these discussions proved fruitless, and Millis broke them off in June 1945. The NWLB also heavily raided the NLRB for staff, significantly hindering NLRB operations.[76]\\r\\n\\r\\nAdditional changes came with the passage of the War Labor Disputes Act (WLDA) on June 25, 1943. Enacted over Roosevelt's veto after 400,000 coal miners, their wages significantly lower due to high wartime inflation, struck for a $2-a-day wage increase,[77][78] the legislation (in part) required the NLRB to issue a ballot outlining all the collective bargaining proposals and counter-proposals, wait 30 days, and then hold a strike vote.[79] The War Labor Disputes Act proved very burdensome.  The NLRB processed 2,000 WLDA cases from 1943 to the end of 1945, of which 500 were strike votes. The act's strike vote procedures did little to stop strikes, however, and Millis feared unions were using the referendums to whip up pro-strike feelings among their members. Millis also believed the law's strike vote process permitted more strikes to occur than the NLRB would have allowed under its old procedures. There were so many strike vote filings in the six months after the war ended that NLRB actually shut down its long distance telephone lines, cancelled all out of town travel, suspended all public hearings, and suspended all other business to accommodate the workload.[80] By early 1945, Millis was in ill health.[81]  He resigned from the NLRB on June 7, 1945,[82] and Paul M. Herzog was named his successor.\\r\\n\\r\\nA major turning point in the history of the NLRB came in 1947 with passage of the Taft-Hartley Act. Disruptions caused by strikes during World War II as well as the huge wave of strikes that followed the end of the war fueled a growing movement in 1946 and 1947 to amend the NLRA to correct what critics saw as a pro-labor tilt in federal law.[83][84] Drafted by the powerful Republican Senator Robert A. Taft and the strongly anti-union Representative Fred A. Hartley, Jr., the Taft-Hartley Act banned jurisdictional strikes, wildcat strikes, political strikes, secondary boycotts, secondary picketing, mass picketing, union campaign donations made from dues money, the closed shop, and unions of supervisors. The act also enumerated new employer rights, defined union-committed ULPs, gave states the right to opt out of federal labor law through right-to-work laws, required unions to give an 80-days' strike notice in all cases, established procedures for the President to end a strike in a national emergency, and required all union officials to sign an anti-Communist oath. Organizationally, the act made the General Counsel a presidential appointee, independent of the board itself, and gave the General Counsel limited powers to seek injunctions without referring to the Justice Department. It also banned the NLRB from engaging in any mediation or conciliation, and formally enshrined in law the ban on hiring personnel to do economic data collection or analysis.[62]\\r\\n\\r\\nHerzog publicly admitted the need for some change in the NLRA, but privately he opposed the proposed Taft-Hartley amendments. He felt the communist oath provisions were unconstitutional, that the amendments would turn the NLRA into a management weapon, that creation of an independent General Counsel would weaken the NLRB, and that the law's dismantling of the agency's economic analysis unit deprived the NLRB of essential expertise.[85] Nonetheless, Congress overrode Truman's veto of the Taft-Hartley Act on June 23, 1947, and the bill became law.[86]\\r\\n\\r\\nThe Taft-Hartley Act fundamentally changed the nature of federal labor law, but it also seriously hindered the NLRB's ability to enforce the law. The loss of the mediation function left the NLRB unable to become involved in labor disputes, a function it had engaged in since its inception as the National Labor Board in 1933. This hindered the agency's efforts to study, analyze, and create bulwarks against bad-faith collective bargaining; reduced its ability to formulate national labor policy in this area; and left the agency making labor law on an ineffective, time-consuming case-by-case basis.[67] The separation of the General Counsel from supervision by the national board also had significant impact on the agency. This separation was enacted against the advice of the Justice Department, contradicted the policy Congress had enacted in the Administrative Procedure Act of 1946, and ignored Millis' extensive internal reforms. The change left the NLRB as the only federal agency unable to coordinate its decision-making and legal activities, and the only agency exempted in this manner under the Administrative Procedure Act. The separation of the General Counsel was not discussed by the committee or by any witnesses during the legislation's mark-up. Indeed, there was no basis for it at all in the public record.[62] It was, in the words of sociologist Robin Stryker, \\"little-noted\\" and \\"unprecedented\\".[20]\\r\\n\\r\\nThe anti-communist oath provisions generated extensive public debate, and generated disputes before the Supreme Court several times. The Taft-Hartley oath first reached the court in American Communications Ass'n v. Douds, 339 U.S. 382 (1950), in which the court held 5-to-1 that the oath did not violate the First Amendment, was not an ex post facto law or bill of attainder in violation of Article One, Section 10, and was not a \\"test oath\\" in violation of Article Six. The issue again came before the court in Garner v. Board of Public Works, 341 U.S. 716 (1951), in which the court unanimously held that a municipal loyalty oath was not an ex post facto law or bill of attainder. It came before the court yet a third time in Wieman v. Updegraff, 344 U.S. 183 (1952). This time, the outcome was radically different. The Supreme Court unanimously ruled that state loyalty oath legislation violated the due process clause of the Fourteenth Amendment. In 1965, the Supreme Court held 5-to-4 that the anti-communist oath was a bill of attainder in United States v. Brown, 381 U.S. 437 (1965).[87] The Supreme Court essentially overturned Douds, but did not formally do so.[88]\\r\\n\\r\\nThe board itself (as an adjudicating body distinct from the functions separated as a result of Taft-Harley) has a fixed seating which is assigned based on the names of [89] 5 original members.\\r\\n\\r\\nFrom December 2007 until June 2010, the five-person Board had only two members, creating a legal controversy. Three members' terms expired in December 2007, leaving the NLRB with just two membersChair Wilma B. Liebman and Member Peter Schaumber.[90] President George W. Bush refused to make some nominations to the Board and Senate Democrats refused to confirm those which he did make.[90][91][full citation needed][92]\\r\\n\\r\\nOn December 28, 2007, just before the Board lost its quorum, the four members agreed to delegate their authority to a three-person panel per the National Labor Relations Act.[92][93] Only Liebman and Schaumber remained on the Board, but the Board concluded that the two constituted a quorum of the three-person panel and thus could make decisions on behalf of the Board.[92][93] Liebman and Schaumber informally agreed to decide only those cases which were in their view noncontroversial and on which they could agree, and issued almost 400 decisions between January 2008 and September 2009.[90][91][92][94][full citation needed][95][full citation needed]\\r\\n\\r\\nThe U.S. Courts of Appeals for the First, Second, and Seventh Circuits upheld the two-member NLRB's authority to decide cases, while the D.C. Circuit Court of Appeals did not.[90][91][full citation needed][94][full citation needed][95][full citation needed] In September 2009, the Justice Department asked the U.S. Supreme Court to immediately hear arguments concerning the dispute, given the high stakes involved.[91] The Supreme Court granted certiorari in October and agreed to decide the issue.[96]\\r\\n\\r\\nIn June 2010, the Supreme Court ruled in New Process Steel, L. P. v. NLRB that the two-member Board had no authority to issue decisions, invalidating all rulings made by Liebman and Schaumber.[97][full citation needed] In 2013, the question of a legitimate quorum on the NLRB surfaced again, when the United States Court of Appeals for the District of Columbia Circuit ruled that President Obama had \\"violated the Constitution when he bypassed the Senate to fill three board vacancies\\".[98][full citation needed]\\r\\n\\r\\nIn 1947, the TaftÿHartley Act created a formal administrative distinction between the Board and the General Counsel of the NLRB. In broad terms, the General Counsel is responsible for investigating and prosecuting unfair labor practice claims and for the general supervision of the NLRB field offices.[99] The General Counsel is appointed by the President to a four-year term and independent from the Board; it has limited independence to argue for a change in the law in presenting cases to the Board. The General Counsel oversees four divisions: the Division of Operations Management, the Division of Administration, the Division of Advice, and the Division of Enforcement Litigation.\\r\\n\\r\\nThe Board, on the other hand, is the adjudicative body that decides the unfair labor practice cases brought to it. Once the Board has decided the issue, it is the General Counsel's responsibility to uphold the Board's decision, even if it is contrary to the position it advocated when presenting the case to the Board. The Board is also responsible for the administration of the Act's provisions governing the holding of elections and resolution of jurisdictional disputes.\\r\\n\\r\\nThe Board has more than thirty regional offices. The regional offices conduct elections, investigate unfair labor practice charges, and make the initial determination on those charges (whether to dismiss, settle, or issue complaints). The Board has jurisdiction to hold elections and prosecute violations of the Act in Puerto Rico and American Samoa.\\r\\n\\r\\nThe Board's jurisdiction is limited to private sector employees and the United States Postal Service; other than Postal Service employees, it has no authority over labor relations disputes involving governmental, railroad and airline employees covered by the Adamson Railway Labor Act, or agricultural employees. On the other hand, in those parts of the private sector its jurisdictional standards are low enough to reach almost all employers whose business has any appreciable impact on interstate commerce.\\r\\n\\r\\nCharges are filed by parties against unions or employers with the appropriate regional office. The regional office will investigate the complaint. If a violation is believed to exist, the region will take the case before an Administrative Law Judge who will conduct a hearing. The decision of the Administrative Law Judge may be reviewed by the five member Board. Board decisions are reviewable by United States Courts of Appeals. The Board's decisions are not self-executing: it must seek court enforcement in order to force a recalcitrant party to comply with its orders. (For greater detail on this process see the entry for unfair labor practice).\\r\\n\\r\\nLafe Solomon was named Acting General Counsel on June 21, 2010. His nomination was sent to the U.S. Senate on January 5, 2011. Solomon's authority came into question on August 13, 2013 when Judge Benjamin Settle for the United States District Court for the Western District of Washington denied a petition for injunctive relief, ruling that Solomon had not been properly appointed under the Federal Vacancies Reform Act of 1998 (FVRA).[100] Although other district courts had enforced Solomon's requests, Judge Settle's decision called into question all of Solomon's activity since June 21, 2010, focusing on subsections (a)(1) and (2) of the FVRA; some pundits claimed that Solomon's appointment was allowed under subsection (a)(3).[101] President Obama withdrew Solomon's nomination.\\r\\n\\r\\nOn July 31, 2013, President Obama nominated former NLRB nominee Richard Griffin as General Counsel\\"a kind of prosecutor at the board\\" and \\"one of the most critical roles at the agency.\\"[102] Solomon's nomination was withdrawn.[103] The Senate approved Griffin's nomination on October 29, 2013, by a vote of 55 to 44.[104]\\r\\n\\r\\nIn April 2009, President Obama nominated Craig Becker (Associate General Counsel of the Service Employees International Union), Mark Gaston Pearce (a member on the Industrial Board of Appeals, an agency of the New York State Department of Labor), and Brian Hayes (Republican Labor Policy Director for the Senate Committee on Health, Education, Labor and Pensions) to fill the three empty seats on the NLRB.[90]\\r\\n\\r\\nBecker's nomination appeared to fail on February 8, 2010, after Republican Senators (led by John McCain) threatened to filibuster his nomination.[92][108][109] President Obama said he would consider making recess appointments to the NLRB due to the Senate's failure to move on any of the three nominations.[108] On March 27, 2010, Obama recess appointed Becker and Pearce.[110]\\r\\n\\r\\nOn June 22, 2010, a voice vote in the Senate confirmed Pearce to a full term, allowing him to serve until August 27, 2013. The same day, the Senate confirmed Republican nominee Brian Hayes of Massachusetts by voice vote. Hayes' term ended on December 16, 2012.[111] Becker's term, as a recess appointee, ended on December 31, 2011.[112] Effective August 28, 2011, Pearce was named chairman to replace Democrat Wilma Liebman, whose term had expired.[113]\\r\\n\\r\\nOn January 4, 2012, Obama announced recess appointments to three seats on the board: Sharon Block, Terence F. Flynn, and Richard Griffin.[114] The appointments were criticized by Republicans, including the House Speaker John Boehner, as unconstitutional and \\"a brazen attempt to undercut the role of the Senate to advise and consent the executive branch on appointments\\".[115] Although made as recess appointments, critics questioned their legality, arguing that Congress had not officially been in recess as pro forma sessions had been held.[116] Former U.S. attorney general Edwin Meese stated that in his opinion, since the appointments were made when the Senate was \\"demonstrably not in recess\\" they represented \\"a constitutional abuse of a high order\\".[117] On January 12, 2012 the U.S. Justice Department released a memo stating that appointments made during pro forma sessions are supported by the Constitution and precedent.[118]\\r\\n\\r\\nOn January 25, 2013, in Noel Canning v. NLRB, a panel of the U.S. Court of Appeals for the District of Columbia Circuit ruled that President Obama's recess appointments were invalid as they were not made during an intersession recess of the Senate, and the President moved to fill them during the same recess.[119] On May 16, 2013, in National Labor Relations Board v. New Vista Nursing and Rehabilitation, the U.S. Court of Appeals for the Third Circuit became the second federal appellate court to rule that the recess appointments to the NLRB were unconstitutional. In a split decision, it also found that the March 27, 2010 recess appointment of Craig Becker was unconstitutional.[120] On January 14, 2014, the U.S. Supreme Court heard the case in National Labor Relations Board v. Noel Canning.[121][122]\\r\\n\\r\\nBetween January 2008 and mid-July 2013 the agency never had all five members, and not once did it operate with three confirmed members.[123] On July 14, 2013, Senate Majority Leader Harry Reid threatened to exercise the \\"nuclear option\\" and allow a simple majority (rather than a supermajority) of the Senate to end a filibuster. This threat to end the filibuster's privileged position in the Senate was intended to end Republican filibustering of NLRB nominees.[124] On July 16, 2013, President Obama and Senate Republicans reached an agreement to end the impasse over NLRB appointees. Obama withdrew the pending nominations of Block and Griffin, and submit two new nominees: Nancy Schiffer, associate general counsel at the AFL-CIO, and Kent Hirozawa, chief counsel to NLRB Chairman Mark Gaston Pearce. Republicans agreed not to oppose a fourth nominee, to be submitted in 2014.[125]\\r\\n\\r\\nOn July 30, 2013, the Senate confirmed all five of Obama's nominees for the NLRB: Kent Hirozawa, Harry I. Johnson III, Philip Miscimarra, Mark Gaston Pearce and Nancy Schiffer. Johnson and Miscimarra represented the Republican nominees for the board.[126] Pearce was confirmed for a second five-year term.[127]  Nancy Schiffer's term ended on December 15, 2014. She was succeeded by Lauren McFerran on December 16, 2014. Harry I. Johnson III's term ended on August 27, 2015.[128]\\r\\n\\r\\nOn January 25, 2017, President Donald J. Trump appointed Philip Miscimarra the acting chairman of the NLRB.[129] Miscimarra retired on December 16, 2017. Marvin Kaplan succeeded him as NLRB chair on December 21, 2017.[citation needed]","input":"What la created the national labor relations board?"},{"output":"horologists","context":"Horology (\\"the study of time\\", related to Latin horologium from Greek ??, \\"instrument for telling the hour\\", from ?ϫ h?ra \\"hour; time\\" and -o- interfix and suffix -logy)[1][2] is the study of the measurement of time. Clocks, watches, clockwork, sundials, hourglasses, clepsydras, timers, time recorders, marine chronometers and atomic clocks are all examples of instruments used to measure time.  In current usage, horology refers mainly to the study of mechanical time-keeping devices, while chronometry more broadly includes electronic devices that have largely supplanted mechanical clocks for the best accuracy and precision in time-keeping.\\r\\n\\r\\nPeople interested in horology are called horologists. That term is used both by people who deal professionally with timekeeping apparatus (watchmakers, clockmakers), as well as aficionados and scholars of horology.  Horology and horologists have numerous organizations, both professional associations and more scholarly societies. The largest horological membership organisation globally is the NAWCC, the National Association of Watch and Clock Collectors, which is USA based, but also has local chapters elsewhere.\\r\\n\\r\\nThere are many horology museums and several specialized libraries devoted to the subject. One example is the Royal Greenwich Observatory, which is also the source of the Prime Meridian (longitude 0 0' 0\\"), and the home of the first marine timekeepers accurate enough to determine longitude (made by John Harrison). Other horological museums in the London area include the Clockmakers' Museum, which re-opened at the Science Museum in October 2015, the horological collections at the British Museum, the Science Museum (London), and the Wallace Collection.\\r\\n\\r\\nOne of the more comprehensive museums dedicated to horology is the Muse international d'horlogerie in La Chaux-de-Fonds (Switzerland). The Muse d'Horlogerie du Locle is smaller but located nearby. One of the better horological museums in Germany is the Deutsches Uhrenmuseum in Furtwangen im Schwarzwald, in the Black Forest. The two leading specialised horological museums in North America are the National Watch and Clock Museum in Columbia, Pennsylvania and the American Clock and Watch Museum in Bristol, Connecticut.\\r\\n\\r\\nThe eastern French city of Besan?on has the Muse du Temps (Museum of Time) in the historic Palais Grenvelle.\\r\\n\\r\\nAn example of a museum devoted to one particular type of clock is the Cuckooland Museum in the UK, which hosts the world's largest collection of antique cuckoo clocks.\\r\\n\\r\\nOne of the most comprehensive horological libraries open to the public is the National Watch and Clock Library in Columbia, Pennsylvania. Other good horological libraries providing public access are at the Muse international d'horlogerie in Switzerland, at the Deutsches Uhrenmuseum in Germany, and at the Guildhall Library in London.\\r\\n\\r\\nAnother museum dedicated to clocks is the Willard House and Clock Museum in Grafton, Massachusetts.\\r\\n\\r\\nNotable scholarly horological organizations include:","input":"What is a person who works on clocks called?"},{"output":"5.45G39mm","context":"","input":"What size bullet does an ak 47 shoot?"},{"output":"Jeff Hanna","context":"The Nitty Gritty Dirt Band, an American country rock band, has existed in various forms since its founding in Long Beach, California in 1966. The group's membership has had at least a dozen changes over the years, including a period from 1976 to 1981 when the band performed and recorded as the Dirt Band. Constant members since the early times are singer-guitarist Jeff Hanna and drummer Jimmie Fadden. Multi-instrumentalist John McEuen was with the band from 1966 to 1986 and returned during 2001 only to depart once again in November 2017. Keyboardist Bob Carpenter joined the band in 1977. The band is often cited as instrumental to the progression of contemporary country and roots music.\\r\\n\\r\\nThe band's successes include a cover version of Jerry Jeff Walker's \\"Mr. Bojangles\\". Albums include 1972's Will the Circle be Unbroken, featuring such traditional country artists as Mother Maybelle Carter, Earl Scruggs, Roy Acuff, Doc Watson, Merle Travis, and Jimmy Martin. A follow-up album based on the same concept, Will the Circle Be Unbroken: Volume Two was released in 1989, was certified gold, won two Grammys, and was named Album of the Year at the Country Music Association Awards.\\r\\n\\r\\nThe Nitty Gritty Dirt Band was founded around 1966 in Long Beach, California by singer-guitarist Jeff Hanna and singer-songwriter guitarist Bruce Kunkel who had performed as the New Coast Two and later the Illegitimate Jug Band. Trying, in the words of the band's website, to \\"figure out how not to have to work for a living,\\" Hanna and Kunkel joined informal jam sessions at McCabe's Guitar Shop in Long Beach.[citation needed] There they met a few other musicians: guitarist/washtub bassist Ralph Barr, guitarist-clarinetist Les Thompson, harmonicist and jug player Jimmie Fadden, and guitarist-vocalist Jackson Browne. As Nitty Gritty Dirt Band, the six men started as a jug band and adopted the burgeoning southern California folk rock musical style, playing in local clubs while wearing pinstripe suits and cowboy boots. Their first paying performance was at the Golden Bear in Huntington Beach, California.[1]\\r\\n\\r\\nBrowne was in the band for only a few months before he left to concentrate on a solo career as a singer-songwriter. He was replaced by John McEuen on banjo, fiddle, mandolin, and steel guitar. McEuen's older brother, William, was the group's manager, and he helped the band get signed with Liberty Records, which released the group's debut album, The Nitty Gritty Dirt Band during 1967. The band's first single, \\"Buy for Me the Rain,\\" was a Top 40 success, and the band gained exposure on The Tonight Show Starring Johnny Carson, as well as concerts with such disparate artists as Jack Benny and The Doors.\\r\\n\\r\\nA second album, Ricochet, was released later during the year and was less successful than their first. Kunkel wanted the band to \\"go electric\\", and include more original material. Bruce left the group to form WordSalad and Of The People. He was replaced by multi-instrumentalist Chris Darrow.\\r\\n\\r\\nBy 1968, the band adopted electrical instruments anyway, and added drums. The first electric album, Rare Junk, was a commercial failure, as was their next, Alive.\\r\\n\\r\\nThe band continued to gain publicity, mainly as a novelty act, making an appearance in the 1968 film, For Singles Only, and a cameo appearance in the 1969 musical western film, Paint Your Wagon, performing \\"Hand Me Down That Can o' Beans\\". The band also played Carnegie Hall as an opening act for Bill Cosby and played in a jam session with Dizzy Gillespie.\\r\\n\\r\\nThe group was inactive for a 6-month period after Paint Your Wagon, then reformed with Jimmy Ibbotson replacing Chris Darrow. With William McEuen as producer and a renegotiated contract that gave the band more artistic freedom, the band recorded and released Uncle Charlie & His Dog Teddy, issued in 1970. Embracing a straight, traditional country and bluegrass sound, the album included the group's best-known singles; a cover version of Jerry Jeff Walker's \\"Mr. Bojangles\\", Michael Nesmith's \\"Some of Shelley's Blues\\", and four Kenny Loggins songs including \\"House at Pooh Corner\\", the first recordings of Loggins's songs. Their version of \\"Mr. Bojangles\\" became the group's first hit, peaking at #9 on Billboard's all genre Hot 100 chart, with an unusual 36 weeks on the charts.\\r\\n\\r\\nThe next album, All The Good Times, released during early 1972, had a similar style.\\r\\n\\r\\nNitty Gritty Dirt Band next sought to solidify its reputation as a country band when band member John McEuen asked Earl Scruggs if he would record with the group. Earl's \\"yes\\" was followed the next week when John asked Doc Watson the same question, receiving the same answer of 'yes'. This set in motion the further addition of other artists, and with the help of Earl and Louise Scruggs, they set to traveling to Nashville, Tennessee, and recording what was to become a triple album, Will the Circle Be Unbroken with Nashville stalwarts Roy Acuff, Earl Scruggs, and Jimmy Martin, country pioneer Mother Maybelle Carter, folk-blues guitarist Doc Watson, Merle Travis, Norman Blake, and others. The title is from the song, \\"Will the Circle Be Unbroken (By and By)\\", as adapted by A. P. Carter, and reflects the album's theme of trying to tie together three generations of musicians: long-haired boys from California and older veterans of the middle American establishment. The track \\"I Saw the Light\\" with Acuff singing, was a success, and the album received two nominations for Grammy Award. Veteran fiddler Vassar Clements was introduced to a wider audience by the album, and a new career. The band also toured Japan twice soon after this period.\\r\\n\\r\\nAfter the next album Les Thompson left the group, making the band a foursome. Stars & Stripes Forever was a live album that mixed old successes such as \\"Buy for Me the Rain\\" and \\"Mr. Bojangles\\" with Circle collaborations (fiddler Vassar Clements was a guest performer) and long storytelling spoken-word monologues. A studio album, Dream, was also released.\\r\\n\\r\\nDuring July 1974, the band was among the headline acts at the Ozark Music Festival at the Missouri State Fairgrounds in Sedalia, Missouri. Some estimates put the crowd at 350,000 people, which would make this one of the largest music events in history. At another concert, the band opened for the rock band Aerosmith.\\r\\n\\r\\nJimmy Ibbotson left the band at the end of 1976, leaving Fadden, Hanna, and McEuen to add John Cable and Jackie Clark, brought in on guitar and bass. In May 1977 the Nitty Gritty Dirt Band became the first American group allowed to tour Russia, Armenia, Georgia and Latvia  the Soviet Union  playing 28 sold-out concerts and a televised appearance that is estimated to have been watched by 145 million people. In 1977, the Nitty Gritty Dirt Band first appeared on the second season of the PBS music program Austin City Limits.\\r\\n\\r\\nAfter returning from Russia, the band released its first 'greatest successes' compilation, another now rare triple album Dirt, Silver & Gold, in 1978. After that release, the band shortened its name to The Dirt Band, and the group's sound became more pop and rock oriented. Saxophonist Al Garth, drummer Merel Bregante, and bassist Richard Hathaway were also added to the lineup in 1978 and Jeff Hanna became the group's producer for a few albums.\\r\\n\\r\\nKeyboardist Bob Carpenter (who would occasionally sit in with the band from 1975 on) contributed to their 1978 album The Dirt Band and joined the band permanently in 1979.\\r\\n\\r\\nAlbums during this period included The Dirt Band and An American Dream. The single \\"American Dream\\" with Linda Ronstadt reached No.?13 on the popular music charts. The band also appeared on Saturday Night Live in their own slot (performing the instrumental penned by John, \\"White Russia'), and separately, billed as The Toot Uncommons, provided backing for Steve Martin on his million-selling novelty tune, \\"King Tut.\\" They also played on that hit, recorded in Aspen earlier that year.\\r\\n\\r\\nIn 1980, Bregante left the group and drummer Mike Gardner replaced Bregante on stage with the group on tour, only to be succeeded by Vic Mastrianni in 1981. Al Garth moved on to Pure Prairie League and later the Eagles.\\r\\n\\r\\nThe albums Make a Little Magic and Jealousy were released in 1980 and 1981, with the single \\"Make a Little Magic\\" featuring Nicolette Larson reaching the Top 25 on the pop chart. The group also performed the song on a 1980 Steve Martin television special, All Commercials, with an added comic element in which Martin lip-synced the Larson vocal for the last segment of the song.\\r\\n\\r\\nThe band returned to its original name and its country roots in 1982. With the lineup paring down to Hanna, Fadden, McEuen and Jimmy Ibbotson rejoining for recording sessions in Nashville, Tennessee, they recorded the album Let's Go, which yielded the success \\"Dance Little Jean\\" which became a Top 10 country hit. Carpenter rejoined the band in 1983, and the next album, 1984's Plain Dirt Fashion had the band's first No.?1 success, \\"Long Hard Road (The Sharecropper's Dream)\\".\\r\\n\\r\\nThere were two more country No.?1's: \\"Modern Day Romance\\" (1985) and \\"Fishin' in the Dark\\" (1987), the latter of which became the band's biggest-selling single, eventually being certified platinum in 2014 despite never reaching the Hot 100. Other successful songs were \\"Dance Little Jean\\" (1983); \\"I Love Only You\\" (1984); \\"High Horse\\" (1985); \\"Home Again in My Heart,\\" \\"Partners, Brothers and Friends\\" and \\"Stand a Little Rain\\" (1986); \\"Fire in the Sky,\\" \\"Baby's Got a Hold on Me\\" and \\"Oh What a Love\\" (1987); \\"Workin' Man (Nowhere to Go)\\" and \\"I've Been Lookin'\\" (1988); and \\"Down That Road Tonight\\" and \\"When it's Gone\\" (1989).\\r\\n\\r\\nPerformances included the 1984 Los Angeles Olympic Games and the inaugural Farm Aid concert in Champaign, Illinois. A 20-year anniversary concert at McNichols Sports Arena in Denver, Colorado featured such guests as Ricky Skaggs, Emmylou Harris, Doc Watson, and John Prine.\\r\\n\\r\\nJohn McEuen left the band at the end of 1986, replaced by Bernie Leadon, formerly of the Eagles. He was with the Nitty Gritty Dirt Band in 1987 and 1988. The band's 19th album, Hold On featured the No.?1 singles \\"Fishin' in the Dark\\" and \\"Baby's Got a Hold on Me.\\" The band appeared on the Today Show and The Tonight Show in the same week, and toured Europe.\\r\\n\\r\\nDuring 1989, Nitty Gritty Dirt Band again returned to Nashville, to record Will the Circle Be Unbroken: Volume Two. Returnees from the first Circle included Earl Scruggs, Vassar Clements, and Roy Acuff. Johnny Cash and the Carter Family, Emmylou Harris, and Ricky Skaggs joined the sessions, as did John Prine, Levon Helm, John Denver, John Hiatt, Bruce Hornsby, and former Byrds Roger McGuinn and Chris Hillman. This album won two Grammy Awards[2] and was named Album of the Year at the Country Music Association Awards for Best Country Vocal Performance (duo or group) and the Country Music Association's Album of the Year Award in 1989.\\r\\n\\r\\nAs a foursome of Hanna, Fadden, Ibbotson and Carpenter, the band again toured the former Soviet Union, as well as Canada, Europe, and Japan. A 25th anniversary concert was recorded on Live Two Five in Red Deer, Alberta, produced by T-Bone Burnett.\\r\\n\\r\\nDuring 1992, the band collaborated with Irish folk music's The Chieftains for the Grammy Award-winning Another Country. Other efforts included the album Acoustic, spotlighting their \\"wooden\\" sound, a duet with Karla Bonoff, \\"You Believed in Me\\" for the MCA Olympic compilation, One Voice, and a cover version of Buddy Holly's \\"Maybe Baby\\" for the Decca tribute album, Not Fade Away. The Christmas Album was released in 1997, followed by Bang! Bang! Bang! in 1999.\\r\\n\\r\\nDuring April 1992, they were the unwitting subject of one of George H. W. Bush's malapropisms when he referred to the group as the \\"Nitty Ditty Nitty Gritty Great Bird\\" at a country music awards ceremony in Nashville:\\r\\n\\r\\nThis unusual phrasing was repeatedly used as an example of Bush's garbled syntax (notably, in Dave Barry's book Dave Barry Hits Below the Beltway and in Barry's only non-audiobook album, A Totally Random Evening with Dave Barry), which in turn helped publicize the band.[citation needed]\\r\\n\\r\\nJohn McEuen rejoined the band in 2001. During 2002, Nitty Gritty Dirt Band celebrated the 30th anniversary of their landmark Will the Circle Be Unbroken with a remastered CD reissue of the 1972 album and a new compilation, Will the Circle Be Unbroken: Volume III. An album of all-new material, Welcome to Woody Creek, was released in 2004. Jimmy Ibbotson again left the band a few years later.\\r\\n\\r\\nAlso during 2004, country group Rascal Flatts released a cover of \\"Bless the Broken Road,\\" which the Nitty Gritty Dirt Band had recorded on Acoustic, from 1994. Songwriters Jeff Hanna, Marcus Hummon, and Bobby Boyd won a Grammy for Best Country Song for this work in 2005.\\r\\n\\r\\nDuring 2005 the band donated use of the song \\"Soldier's Joy\\" for the benefit album, Too Many Years to benefit Clear Path International's work with landmine survivors. Also in 2005, the band was recognized by the International Entertainment Buyers Association for 40 years of contributions to the music industry.\\r\\n\\r\\nIn 2009 the band released a new album, Speed of Life. Produced by George Massenburg and Jon Randall Stewart, Speed of Life is composed of a series of live, freewheeling studio recordings that purposefully avoid overproduction and demonstrate the band's collaborative spirit and spontaneity. Of the 13 tracks on Speed of Life, 11 are new songs penned by the band, and two are classic covers: Canned Heat's Woodstock hit \\"Going Up the Country\\" and Stealers Wheel's \\"Stuck in the Middle\\".\\r\\n\\r\\nIn September 2015, Nitty Gritty Dirt Band commemorated their 50th anniversary with a sold out show at the Ryman Theater.  Taped for a PBS special which debuted in March 2016, the concert included guests John Prine, Sam Bush, Vince Gill, Jerry Jeff Walker, Alison Krauss, Rodney Crowell, Byron House, Jerry Douglas and Jackson Browne in addition to former member Ibbotson. On September 30, 2016,  Circlin Back: Celebrating 50 Years,  a live CD and DVD was released.  In a 2016 review, the Los Angeles Times wrote that the original release  \\"helped knock down barriers then separating the traditional country and rock music communities, setting the stage for the eventual emergence of what came to be known as Americana music.\\"[4] John McEuen announced his departure from the band in December 2017 at the conclusion of their 50th anniversary tour.  John currently performs as a solo artist. In 2018, Jaime Hanna (Jeff Hanna's son) and Ross Holmes joined the band on tour, along with Jim Photoglo, who began touring with the band in 2016. Jim is the co-author of \\"Fishin' in the Dark.\\"\\r\\n\\r\\nJeff Hanna and John McEuen's sons, Jaime Hanna and Jonathan McEuen, recorded for DreamWorks Records in 2005 as Hanna-McEuen.[5]","input":"Who are the original members of the nitty gritty dirt band?"},{"output":"Gopala","context":"\\r\\n\\r\\nThe Pala Empire (Bengali: ??? ?????????) was an imperial power during the Late Classical period on the Indian subcontinent,[3] which originated in the region of Bengal. It is named after its ruling dynasty, whose rulers bore names ending with the suffix of Pala (\\"protector\\" in Sanskrit). They were followers of the Mahayana and Tantric schools of Buddhism. The empire was founded with the election of Gopala as the emperor of Gauda in 750 CE.[4] The Pala stronghold was located in Bengal and Bihar, which included the major cities of Vikrampura, Pataliputra, Gauda, Monghyr, Somapura, Ramvati (Varendra), Tamralipta and Jaggadala.\\r\\n\\r\\nThe Palas were astute diplomats and military conquerors. Their army was noted for its vast war elephant corps. Their navy performed both mercantile and defensive roles in the Bay of Bengal. The Palas were important promoters of classical Indian philosophy, literature, painting and sculpture. They built grand temples and monasteries, including the Somapura Mahavihara, and patronised the great universities of Nalanda and Vikramashila. The Proto-Bengali language developed under Pala rule.  The empire enjoyed relations with the Srivijaya Empire, the Tibetan Empire and the Arab Abbasid Caliphate. Islam first appeared in Bengal during Pala rule, as a result of increased trade between Bengal and the Middle East. Abbasid coinage found in Pala archaeological sites, as well as records of Arab historians, point to flourishing mercantile and intellectual contacts. The House of Wisdom in Baghdad absorbed the mathematical and astronomical achievements of Indian civilisation during this period.[5]\\r\\n\\r\\nAt its height in the early 9th century, the Pala Empire was the dominant power in the northern Indian subcontinent, with its territory stretching across parts of modern-day eastern Pakistan, northern and northeastern India, Nepal and Bangladesh.[4][6] The empire reached its peak under Emperors Dharmapala and Devapala. The Palas also exerted a strong cultural influence under Atisa in Tibet, as well as in Southeast Asia. Pala control of North India was ultimately ephemeral, as they struggled with the Gurjara-Pratiharas and the Rashtrakutas for the control of Kannauj and were defeated. After a short lived decline, Emperor Mahipala I defended imperial bastions in Bengal and Bihar against South Indian Chola invasions. Emperor Ramapala was the last strong Pala ruler, who gained control of Kamarupa and Kalinga. The empire was considerably weakened by the 11th century, with many areas engulfed in rebellion.\\r\\n\\r\\nThe resurgent Hindu Sena dynasty dethroned the Pala Empire in the 12th century, ending the reign of the last major Buddhist imperial power in the Indian subcontinent. The Pala period is considered one of the golden eras of Bengali history.[7][8] The Palas brought stability and prosperity to Bengal after centuries of civil war between warring divisions. They advanced the achievements of previous Bengali civilisations and created outstanding works of art and architecture. They laid the basis for the Bengali language, including its first literary work, the Charyapada. The Pala legacy is still reflected in Tibetan Buddhism.\\r\\n\\r\\nAccording to the Khalimpur copper plate inscription, the first Pala king Gopala was the son of a warrior named Vapyata. The Ramacharitam attests that Varendra (North Bengal) was the fatherland (Janakabhu) of the Palas. The ethnic origins of the dynasty are unknown, although the later records claim that Gopala was a Kshatriya belonging to the legendary Solar dynasty. The Ballala-Carita states that the Palas were Kshatriyas, a claim reiterated by Taranatha in his History of Buddhism in India as well as Ghanaram Chakrabarty in his Dharmamangala (both written in the 16th century CE). The Ramacharitam also attests the fifteenth Pala emperor, Ramapala, as a Kshatriya. Claims of belonging to the legendary Solar dynasty are unreliable and clearly appear to be an attempt to cover up the humble origins of the dynasty.[8] The Pala dynasty has also been branded as ?udra in some sources such as Manjushri-Mulakalpa; this might be because of their Buddhist leanings.[9][10][11][12][13][14][15] According to Abu'l-Fazl ibn Mubarak (in Ain-i-Akbari), the Palas were Kayasthas. There are even accounts that claim Gopala may have been from a Brahmin lineage.[16][17]\\r\\n\\r\\nAfter the fall of Shashanka's kingdom, the Bengal region was in a state of anarchy. There was no central authority, and there was constant struggle between petty chieftains. The contemporary writings describe this situation as matsya nyaya (\\"fish justice\\" i.e. a situation where the big fish eat the small fish). Gopala ascended the throne as the first Pala king during these times. The Khalimpur copper plate suggests that the prakriti (people) of the region made him the king.[8] Taranatha, writing nearly 800 years later, also writes that he was democratically elected by the people of Bengal. However, his account is in form of a legend, and is considered historically unreliable. The legend mentions that after a period of anarchy, the people elected several kings in succession, all of whom were consumed by the Naga queen of an earlier king on the night following their election. Gopal, however managed to kill the queen and remained on the throne.[18] The historical evidence indicates that Gopala was not elected directly by his citizens, but by a group of feudal chieftains. Such elections were quite common in contemporary societies of the region.[8][18]\\r\\n\\r\\nGopala's ascension was a significant political event as the several independent chiefs recognised his political authority without any struggle.[7]\\r\\n\\r\\nGopala's empire was greatly expanded by his son Dharmapala and his grandson Devapala. Dharmapala was initially defeated by the Pratihara ruler Vatsaraja. Later, the Rashtrakuta king Dhruva defeated both Dharmapala and Vatsaraja. After Dhruva left for the Deccan region, Dharmapala built a mighty empire in the northern India. He defeated Indrayudha of Kannauj, and installed his own nominee Chakrayudha on the throne of Kannauj. Several other smaller states in North India also acknowledged his suzerainty. Soon, his expansion was checked by Vatsaraja's son Nagabhata II, who conquered Kannauj and drove away Chakrayudha. Nagabhata II then advanced up to Munger and defeated Dharmapala in a pitched battle. Dharmapala was forced to surrender and to seek alliance with the Rashtrakuta emperor Govinda III, who then intervened by invading northern India and defeating Nagabhata II.[19][20] The Rashtrakuta records show that both Chakrayudha and Dharmapala recognised the Rashtrakuta suzerainty. In practice, Dharmapala gained control over North India after Govinda III left for the Deccan. He adopted the title Paramesvara Paramabhattaraka Maharajadhiraja.[7]\\r\\n\\r\\nDharmapala was succeeded by his son Devapala, who is regarded as the most powerful Pala ruler.[7] His expeditions resulted in the invasion of Pragjyotisha (present-day Assam) where the king submitted without giving a fight and the Utkala (present-day Orissa) whose king fled from his capital city.[21] The inscriptions of his successors also claim several other territorial conquests by him, but these are highly exaggerated (see the Geography section below).[8][22]\\r\\n\\r\\nFollowing the death of Devapala, the Pala empire gradually started disintegrating. Vigrahapala, who was Devapala's nephew, abdicated the throne after a brief rule, and became an ascetic. Vigrahapala's son and successor Narayanapala proved to be a weak ruler. During his reign, the Rashtrakuta king Amoghavarsha defeated the Palas. Encouraged by the Pala decline, the King Harjara of Assam assumed imperial titles and the Sailodbhavas established their power in Orissa.[7]\\r\\n\\r\\nNaryanapala's son Rajyapala ruled for at least 12 years, and constructed several public utilities and lofty temples. His son Gopala II lost Bengal after a few years of rule, and then ruled only Bihar. The next king, Vigrahapala II, had to bear the invasions from the Chandelas and the Kalachuris. During his reign, the Pala empire disintegrated into smaller kingdoms like Gauda, Radha, Anga and Vanga. Kantideva of Harikela (eastern and southern Bengal) also assumed the title Maharajadhiraja, and established a separate kingdom, later ruled by the Chandra dynasty.[7] The Gauda state (West and North Bengal) was ruled by the Kamboja Pala dynasty. The rulers of this dynasty also bore names ending in the suffix -pala (e.g. Rajyapala, Narayanapala and Nayapala). However, their origin is uncertain, and the most plausible view is that they originated from a Pala official who usurped a major part of the Pala kingdom along with its capital.[7][8]\\r\\n\\r\\nMahipala I recovered northern and eastern Bengal within three years of ascending the throne in 988 CE. He also recovered the northern part of the present-day Burdwan division. During his reign, Rajendra Chola I of the Chola Empire frequently invaded Bengal from 1021 to 1023 CE to get Ganges water and in the process, succeeded to humble the rulers, acquiring considerable booty. The rulers of Bengal who were defeated by Rajendra Chola were Dharmapal, Ranasur and Govindachandra, who might have been feudatories under Mahipala I of the Pala Dynasty.[23] Rajendra Chola I also defeated Mahipala, and obtained from the Pala king \\"elephants of rare strength, women and treasure\\".[24] Mahipala also gained control of north and south Bihar, probably aided by the invasions of Mahmud of Ghazni, which exhausted the strength of other rulers of North India. He may have also conquered Varanasi and surrounding area, as his brothers Sthirapala and Vasantapala undertook construction and repairs of several sacred structures at Varanasi. Later, the Kalachuri king Gangeyadeva annexed Varanasi after defeating the ruler of Anga, which could have been Mahipala I.[7]\\r\\n\\r\\nNayapala, the son of Mahipala I, defeated the Kalachuri king Karna (son of Ganggeyadeva) after a long struggle. The two later signed a peace treaty at the mediation of the Buddhist scholar Ati?a. During the reign of Nayapala's son Vigrahapala III, Karna once again invaded Bengal but was defeated. The conflict ended with a peace treaty, and Vigrahapala III married Karna's daughter Yauvanasri. Vigrahapala III was later defeated by the invading Chalukya king Vikramaditya VI. The invasion of Vikramaditya VI saw several soldiers from South India into Bengal, which explains the southern origin of the Sena Dynasty.[25] Vigrahapala III also faced another invasion led by the Somavamsi king Mahasivagupta Yayati of Orissa. Subsequently, a series of invasions considerably reduced the power of the Palas. The Varmans occupied eastern Bengal during his reign.[7][8]\\r\\n\\r\\nMahipala II, the successor of Vigrahapala III, brought a short-lived reign of military glory. His reign is well-documented by Sandhyakar Nandi in Ramacharitam. Mahipala II imprisoned his brothers Ramapala and Surapala II, on the suspicion that they were conspiring against him. Soon afterwards, he faced a rebellion of vassal chiefs from the Kaibarta (fishermen). A chief named Divya (or Divvoka) killed him and occupied the Varendra region. The region remained under the control of his successors Rudak and Bhima. Surapala II escaped to Magadha and died after a short reign. He was succeeded by his brother Ramapala, who launched a major offensive against Divya's grandson Bhima. He was supported by his maternal uncle Mathana of the Rashtrakuta dynasty, as well as several feudatory chiefs of south Bihar and south-west Bengal. Ramapala conclusively defeated Bhima, and killing him and his family in a cruel manner.[7][8]\\r\\n\\r\\nAfter gaining control of Varendra, Ramapala tried to revive the Pala empire with limited success. He ruled from a new capital at Ramavati, which remained the Pala capital until the dynasty's end. He reduced taxation, promoted cultivation and constructed public utilities. He brought Kamarupa and Rar under his control, and forced the Varman king of east Bengal to accept his suzerainty. He also struggled with the Ganga king for control of present-day Orissa; the Gangas managed to annexe the region only after his death. Ramapala maintained friendly relations with the Chola king Kulottunga to secure support against the common enemies: the Ganas and the Chalukyas. He kept the Senas in check, but lost Mithila to a Karnataka chief named Nanyuadeva. He also held back the aggressive design of the Gahadavala ruler Govindacharndra through a matrimonial alliance.[7][8]\\r\\n\\r\\nRamapala was the last strong Pala ruler. After his death, a rebellion broke out in Kamarupa during his son Kumarapala's reign. The rebellion was crushed by Vaidyadeva, but after Kumarapala's death, Vaidyadeva practically created a separate kingdom.[7] According to Ramacharitam, Kumarapala's son Gopala III was murdered by his uncle Mandapala. During Madanapala's rule, the Varmans in east Bengal declared independence, and the Eastern Gangas renewed the conflict in Orissa. Madanapala captured Munger from the Gahadavalas, but was defeated by Vijayasena, who gained control of southern and eastern Bengal. A ruler named Govindapala ruled over the Gaya district around 1162 CE, but there is no concrete evidence about his relationship to the imperial Palas. The Pala dynasty was replaced by the Sena dynasty.[8]\\r\\n\\r\\nThe borders of the Pala Empire kept fluctuating throughout its existence. Though the Palas conquered a vast region in North India at one time, they could not retain it for long due to constant hostility from the Gurjara-Pratiharas, the Rashtrakutas and other less powerful kings.[26]\\r\\n\\r\\nNo records are available about the exact boundaries of original kingdom established by Gopala, but it might have included almost all of the Bengal region.[7] The Pala empire extended substantially under Dharmapala's rule. Apart from Bengal, he directly ruled the present-day Bihar. The kingdom of Kannauj (present-day Uttar Pradesh) was a Pala dependency at times, ruled by his nominee Chakrayudha.[7] While installing his nominee on the Kannauj throne, Dharmapala organised an imperial court. According to the Khalimpur copper plate issued by Dharmapala, this court was attended by the rulers of Bhoja (possibly Vidarbha), Matsya (Jaipur region), Madra (East Punjab), Kuru (Delhi region), Yadu (possibly Mathura, Dwarka or Simhapura in the Punjab), Yavana, Avanti, Gandhara and Kira (Kangra Valley).[8][27] These kings accepted the installation of Chakrayudha on the Kannauj throne, while \\"bowing down respectfully with their diadems trembling\\".[28] This indicates that his position as a sovereign was accepted by most rulers, although this was a loose arrangement unlike the empire of the Mauryas or the Guptas. The other rulers acknowledged the military and political supremacy of Dharmapala, but maintained their own territories.[8] The poet Soddhala of Gujarat calls Dharmapala an Uttarapathasvamin (\\"Lord of the North\\") for his suzerainty over North India.[29]\\r\\n\\r\\nThe epigraphic records credit Devapala with extensive conquests in hyperbolic language. The Badal pillar inscription of his successor Narayana Pala states that by the wise counsel and policy of his Brahmin minister Darbhapani, Devapala became the suzerain monarch or Chakravarti of the whole tract of Northern India bounded by the Vindhyas and the Himalayas. It also states that his empire extended up to the two oceans (presumably the Arabian Sea and the Bay of Bengal). It also claims that Devpala defeated Utkala (present-day Orissa), the Hunas, the Kambojas, the Dravidas, the Kamarupa (present-day Assam), and the Gurjaras:[7]\\r\\n\\r\\nThe claims about Devapala's victories are exaggerated, but cannot be dismissed entirely: there is no reason to doubt his conquest of Utkala and Kamarupa. Besides, the neighbouring kingdoms of Rashtrakutas and the Gurjara-Pratiharas were weak at the time, which might have helped him extend his empire.[22] Devapala is also believed to have led an army up to the Indus river in Punjab.[7]\\r\\n\\r\\nThe empire started disintegrated after the death of Devapala, and his successor Narayanapala lost control of Assam and Orissa. He also briefly lost control over Magadha and north Bengal. Gopala II lost control of Bengal, and ruled only from a part of Bihar. The Pala empire disintegrated into smaller kingdoms during the reign of Vigrahapala II. Mahipala recovered parts of Bengal and Bihar. His successors lost Bengal again. The last strong Pala ruler, Ramapala, gained control of Bengal, Bihar, Assam and parts of Orissa.[7] By the time of Madanapala's death, the Pala kingdom was confined to parts of central and east Bihar along with northern Bengal.[7]\\r\\n\\r\\nThe Pala rule was monarchial. The king was the centre of all power. Pala kings would adopt imperial titles like Parameshwara, Paramvattaraka, Maharajadhiraja. Pala kings appointed Prime Ministers. The Line of Garga served as the Prime Ministers of the Palas for 100 years.\\r\\n\\r\\nPala Empire was divided into separate Bhuktis (Provinces). Bhuktis were divided into Vishayas (Divisions) and Mandalas (Districts). Smaller units were Khandala, Bhaga, Avritti, Chaturaka, and Pattaka. Administration covered widespread area from the grass root level to the imperial court.[30]\\r\\n\\r\\nThe Pala copperplates mention following administrative posts:[31]\\r\\n\\r\\nThe Palas were patrons of Mahayana Buddhism. A few sources written much after Gopala's death mention him as a Buddhist, but it is not known if this is true.[32] The subsequent Pala kings were definitely Buddhists. Taranatha states that Gopala was a staunch Buddhist, who had built the famous monastery at Odantapuri.[33][not in citation given] Dharmapala made the Buddhist philosopher Haribhadra his spiritual preceptor. He established the Vikramashila monastery and the Somapura Mahavihara. Taranatha also credits him with establishing 50 religious institutions and patronising the Buddhist author Hariibhadra. Devapala restored and enlarged the structures at Somapura Mahavihara, which also features several themes from the epics Ramayana and Mahabharata. Mahipala I also ordered construction and repairs of several sacred structures at Saranath, Nalanda and Bodh Gaya.[7] The Mahipala geet (\\"songs of Mahipala\\"), a set of folk songs about him, are still popular in the rural areas of Bengal.\\r\\n\\r\\nThe Palas developed the Buddhist centres of learnings, such as the Vikramashila and the Nalanda universities. Nalanda, considered one of the first great universities in recorded history, reached its height under the patronage of the Palas. Noted Buddhist scholars from the Pala period include Atisha, Santaraksita, Saraha, Tilopa, Bimalamitra, Dansheel, Dansree, Jinamitra, Jnanasrimitra, Manjughosh, Muktimitra, Padmanava, Sambhogabajra, Shantarakshit, Silabhadra, Sugatasree and Virachan.\\r\\n\\r\\nAs the rulers of Gautama Buddha's land, the Palas acquired great reputation in the Buddhist world. Balaputradeva, the Sailendra king of Java, sent an ambassador to him, asking for a grant of five villages for the construction of a monastery at Nalanda.[34] The request was granted by Devapala. He appointed the Brahmin Viradeva (of Nagarahara, present-day Jalalabad) as the head of the Nalanda monastery. The Budhdist poet Vajradatta (the author of Lokesvarashataka), was in his court.[7] The Buddhist scholars from the Pala empire travelled from Bengal to other regions to propagate Buddhism. Atisha, for example, preached in Tibet and Sumatra, and is seen as one of the major figures in the spread of 11th-century Mahayana Buddhism.\\r\\n\\r\\nThe Palas also supported the Saiva ascetics, typically the ones associated with the Golagi-Math.[35] Narayana Pala himself established a temple of Shiva, and was present at the place of sacrifice by his Brahmin minister.[36] Queen of King Madanapaladeva, namely Chitramatika, made a gift of land to a Brahmin named Bateswara Swami as his remuneration for chanting the Mahabharata at her request, according to the principle of the Bhumichhidranyaya.[citation needed] Besides the images of the Buddhist deities, the images of Vishnu, Siva and Sarasvati were also constructed during the Pala dynasty rule.[37]\\r\\n\\r\\nThe Palas patronised several Sanskrit scholars, some of whom were their officials. The Gauda riti style of composition was developed during the Pala rule. Many Buddhist Tantric works were authored and translated during the Pala rule. Besides the Buddhist scholars mentioned in the Religion section above, Jimutavahana, Sandhyakar Nandi, Madhava-kara, Suresvara and Chakrapani Datta are some of the other notable scholars from the Pala period.[7]\\r\\n\\r\\nThe notable Pala texts on philosophy include Agama Shastra by Gaudapada, Nyaya Kundali by Sridhar Bhatta and Karmanushthan Paddhati by Bhatta Bhavadeva. The texts on medicine include\\r\\n\\r\\nSandhyakar Nandi's semi-fictional epic Ramacharitam (12th century) is an important source of Pala history.\\r\\n\\r\\nA form of the proto-Bengali language can be seen in the Charyapadas composed during the Pala rule.[7]\\r\\n\\r\\nThe Pala school of sculptural art is recognised as a distinct phase of the Indian art, and is noted for the artistic genius of the Bengal sculptors.[38] It is influenced by the Gupta art.[39]\\r\\n\\r\\nA basalt statue of Lalita flanked by Ga?e?a and Krttikeya\\r\\n\\r\\nCarved shankhas\\r\\n\\r\\nSculpture of Khasarpana Lokesvara from Nalanda\\r\\n\\r\\nSculpture of Varaha avatar of Lord Vishnu\\r\\n\\r\\nAs noted earlier, the Palas built a number of monasteries and other sacred structures. The Somapura Mahavihara in present-day Bangladesh is a World Heritage Site. It is a monastery with 21 acre (85,000 m2) complex has 177 cells, numerous stupas, temples and a number of other ancillary buildings. The gigantic structures of other Viharas, including Vikramashila, Odantapuri, and Jagaddala are the other masterpieces of the Palas. These mammoth structures were mistaken by the forces of Bakhtiyar Khalji as fortified castles and were demolished.[citation needed] The art of Bihar and Bengal during the Pala and Sena dynasties influenced the art of Nepal, Burma, Sri Lanka and Java.[40]\\r\\n\\r\\nSomapura Mahavihara, a World Heritage Site, was built by Dharmapala\\r\\n\\r\\nCentral shrine decor at Somapura\\r\\n\\r\\nA model of the Somapura Mahavihara by Ali Naqi\\r\\n\\r\\nRuins of Vikramashila\\r\\n\\r\\nMost of the Pala inscriptions mention only the regnal year as the date of issue, without any well-known calendar era. Because of this, the chronology of the Pala kings is hard to determine.[41] Based on their different interpretations of the various epigraphs and historical records, different historians estimate the Pala chronology as follows:[42]\\r\\n\\r\\nNote:[42]\\r\\n\\r\\nThe highest military officer in the Pala empire was the Mahasenapati (commander-in-chief). The Palas recruited mercenary soldiers from a number of kingdoms, including Malava, Khasa, Huna, Kulika, Kanrata, Lata, Odra and Manahali. According to the contemporary accounts, the Rashtrakutas had the best infantry, the Gurjara-Pratiharas had the finest cavalry and the Palas had the largest elephant force. The Arab merchant Sulaiman states that the Palas had an army bigger than those of the Balhara (possibly the Rashtrakutas) and the king of Jurz (possibly the Gurjara-Pratiharas). He also states that the Pala army employed 10,000ÿ15,000 men for fuelling and washing clothes. He further claims that during the battles, the Pala king would lead 50,000 war elephants. Sulaiman's accounts seem to be based on exaggerated reports; Ibn Khaldun mentions the number of elephants as 5,000.[47]\\r\\n\\r\\nSince Bengal did not have a good native breed of horses, the Palas imported their cavalry horses from the foreigners, including the Kambojas. They also had a navy, used for both mercantile and defence purposes.[48]\\r\\n\\r\\nThe main sources of information about the Pala empire include:[49]","input":"Who was the first ruler of pala dynasty?"},{"output":"Michael the Archangel","context":"An archangel /??rk?e?nd??l/ is an angel of high rank. The word \\"archangel\\" itself is usually associated with the Abrahamic religions, but beings that are very similar to archangels are found in a number of religious traditions.\\r\\nThe English word archangel is derived from the Greek ??ۚ? (arch- + angel, literally chief angel or angel of origin).[1] It appears only once in the New Testament in the phrase 'the archangel Michael' (Jude 9). The corresponding Hebrew word in the Hebrew Scripture (Old Testament) is found in two places as in \\"Michael, one of the chief princes\\" (Dan 10:13) and in \\"Michael, the great prince\\" (Dan 12:1).\\r\\n\\r\\n\\r\\nMichael and Gabriel are recognized as archangels in Judaism, Islam, the Baha'i Faith and by most Christians. Protestants recognize Gabriel as an angel but consider Michael to be the only archangel. Raphaelmentioned in the deuterocanonical Book of Tobitis also recognized as an archangel in the Catholic and Orthodox churches. Gabriel, Michael, and Raphael are venerated in the Roman Catholic Church with a feast on September 29 (between 1921 and 1969, March 24 for Gabriel and October 24 for Raphael), and in the Eastern Orthodox Church on November 8 (if the Julian calendar is used, this corresponds to November 21 in the Gregorian). The named archangels in Islam are Gabriel, Michael, Israfil and Azrael. Jewish literature, such as the Book of Enoch, also mentions Metatron as an archangel, called the \\"highest of the angels\\", though the acceptance of this angel is not canonical in all branches of the faith.\\r\\nSome branches of the faiths mentioned have identified a group of seven Archangels, but the named angels vary, depending on the source. Gabriel, Michael, and Raphael are always mentioned; the other archangels vary, but most commonly include Uriel, who is mentioned in 2 Esdras.\\r\\nIn Zoroastrianism, sacred texts allude to the six great Amesha Spenta (literally \\"Bounteous/Holy Immortals\\")[2] of Ahura Mazda.\\r\\nAn increasing number of experts in anthropology, theology and philosophy, believe that Zoroastrianism contains the earliest distillation of prehistoric belief in angels.[3]\\r\\nThe Amesha Spentas of Zoroastrianism are likened to archangels. They individually inhabit immortal bodies that operate in the physical world to protect, guide, and inspire humanity and the spirit world. The Avesta explains the origin and nature of archangels or Amesha Spentas.[3]\\r\\nTo maintain equilibrium, Ahura Mazda engaged in the first act of creation, distinguishing his Holy Spirit Spenta Mainyu, the Archangel of righteousness. Ahura Mazda also distinguished from himself six more Amesha Spentas, who, along with Spenta Mainyu, aided in the creation of the physical universe. Then he oversaw the development of sixteen lands, each imbued with a unique cultural catalyst calculated to encourage the formation of distinct human populations. The Amesha Spentas were charged with protecting these holy lands and through their emanation, also believed to align each respective population in service to God.[4]\\r\\nThe Amesha Spentas (amesha meaning eternal and spenta meaning brilliance and beneficence) as attributes of God are:\\r\\nThe Hebrew Bible uses the term ????? ?????? (malakhi Elohim; Angels of God),[5] The Hebrew word for angel is \\"malach,\\" which means messenger, for the angels ????? ?? (malakhi Adonai; Angels of the Lord) are God's messengers to perform various missions - e.g. 'angel of death';[6] ??? ?????? (b'nei elohim; sons of God) and ??????? (ha-q'doshim; the holy ones) to refer to beings traditionally interpreted as angelic messengers. Other terms are used in later texts, such as ???????? (ha-elyonim, the upper ones, or the supreme ones). References to angels are uncommon in Jewish literature except in later works such as the Book of Daniel, though they are mentioned briefly in the stories of Jacob (who according to one interpretation wrestled with an angel) and Lot (who was warned by angels of the impending destruction of the cities of Sodom and Gomorrah). Daniel is the first biblical figure to refer to individual angels by name.[7] It is therefore widely speculated that Jewish interest in angels developed during the Babylonian captivity.[8] According to Rabbi Simeon ben Lakish of Tiberias (230ÿ270 CE), specific names for the angels were brought back by the Jews from Babylon.\\r\\nThere are no explicit references to archangels in the canonical texts of the Hebrew Bible (Old Testament). In post-Biblical Judaism, certain angels came to take on a particular significance and developed unique personalities and roles. Though these archangels were believed to have ranked amongst the heavenly host, no systematic hierarchy ever developed. Metatron is considered one of the highest of the angels in Merkavah and Kabbalist mysticism and often serves as a scribe. He is briefly mentioned in the Talmud,[9] and figures prominently in Merkavah mystical texts. Michael, who serves as a warrior and advocate for Israel,[10] is looked upon particularly fondly. Gabriel is mentioned in the Book of Daniel[11] and briefly in the Talmud,[12] as well as many Merkavah mystical texts. The earliest references to archangels are in the literature of the intertestamental periods (e.g., 4 Esdras 4:36).\\r\\nIn the Kabbalah there are ten archangels, each assigned to one sephira: Metatron, Raziel (other times Jophiel), Tzaphkiel, Tzadkiel, Khamael, Raphael, Haniel, Michael, Gabriel, and Sandalphon. Chapter 20 of the Book of Enoch mentions seven holy angels who watch, that often are considered the seven archangels: Michael, Raphael, Gabriel, Uriel, Saraqael, Raguel, and Remiel.[13] The Life of Adam and Eve lists the archangels as well: Michael, Gabriel, Uriel, Raphael and Joel. Medieval Jewish philosopher Maimonides made a Jewish angelic hierarchy.\\r\\nThe New Testament makes several references to angels, but uses the word \\"archangel\\" only twice, at Thessalonians 4:16 (\\"For the Lord himself shall descend from heaven with a shout, with the voice of the archangel, and with the trump of God: and the dead in Christ shall rise first\\", KJV) and Jude 1:9 (\\"Yet Michael the archangel, when contending with the devil he disputed about the body of Moses, durst not bring against him a railing accusation, but said, The Lord rebuke thee\\", KJV).\\r\\nIn Roman Catholicism, three are honored by name:\\r\\nThe last-named of these identifies himself in Tobit 12:15(NAB) thus: \\"I am Raphael, one of the seven angels who stand and serve before the Glory of the Lord.\\"\\r\\nThe Fourth Book of Esdras, which mentions the angel Uriel, was popular in the West and was frequently quoted by Church Fathers, especially Ambrose, but was never considered part of the Catholic biblical canon.[14]\\r\\nThe Catholic Church gives no official recognition to the names given in some apocryphal sources, such as Raguel, Saraqael and Remiel (Book of Enoch) or Izidkiel, Hanael, and Kepharel (other such sources).[15]\\r\\nEastern Orthodox Tradition mentions \\"thousands of archangels;[16] however, only seven archangels are venerated by name.[17] Uriel is included, and the other three are most often named Selaphiel, Jegudiel, and Barachiel (an eighth, Jeremiel, is sometimes included as archangel).[18] The Orthodox Church celebrates the Synaxis of the Archangel Michael and the Other Bodiless Powers on November 8 of Stencyl the Eastern Orthodox liturgical calendar (for those churches which follow the Julian Calendar, November 8 falls on November 21 of the modern Gregorian Calendar). Other feast days of the Archangels include the Synaxis of the Archangel Gabriel on March 26 (April 8), and the Miracle of the Archangel Michael at Colossae on September 6 (September 19). In addition, every Monday throughout the year is dedicated to the Angels, with special mention being made in the church hymns of Michael and Gabriel. In Orthodox iconography, each angel has a symbolic representation:[18]\\r\\nIn the canon of the Ethiopian Orthodox Tewahedo Church, 1 Enoch describes Saraqael as one of the angels that watch over \\"the spirits that sin in the spirit.\\" (20:7, 8).\\r\\nThe Protestant Bible provides names for three angels: \\"Michael the archangel\\", the angel Gabriel, who is called \\"the man Gabriel\\" in Daniel 9:21 and third \\"Abaddon\\" / \\"Apollyon\\" in Revelation 9:11. Within Protestantism, the Anglican and Methodist tradition recognizes four angels as archangels: Michael the Archangel, Raphael the Archangel, Gabriel the Archangel, and Uriel the Archangel.[21][22] They are commemorated on 29?September, Michaelmas, in the church calendar.[23] The evangelist Billy Graham wrote that in Sacred Scripture, there is only one individual explicitly described as an archangelMichael in Jude 1:9.[24][25]\\r\\nSeventh-day Adventists hold that titles \\"Michael\\" and \\"archangel\\" are in reference to Jesus. However, they only signify his role as the chief of angels and have no reference to the nature of Jesus, who is fully divine. Adventists credit nonconformist minister Matthew Henry as supporting this view.[26]\\r\\nJehovah's Witnesses, citing a reference to \\"an archangel's voice\\" at 1 Thessalonians 4:16, also believe that \\"Michael\\" is another name for Jesus in heaven. They believe Jesus is archangel in the true sense of the word - the highest spiritual creature.[27]\\r\\nThe Church of Jesus Christ of Latter-day Saints (LDS Church) interprets the term archangel as meaning \\"Chief Angel\\",[28] Michael is the only individual so-designated in the Latter Day Saints canon.[29] It is believed that he is the head of all of the angels.[28] LDS Church doctrine also states that the archangel Michael was the first man, Adam.[30] Though no other being is identified as an \\"archangel,\\" Joseph Smith taught that the angel Gabriel was known in mortality as Noah[31] and the angel Raphael is a being of significant standing, even though he has never been identified with any mortal prophet.[32]\\r\\nIn Islam, the mentioned archangels[33] in the Qur'an include:\\r\\nOccultists sometimes associate archangels in Kabbalistic fashion with various seasons or elements, or even colors. In some Kabbalah-based systems of ceremonial magic, all four of the main archangels (Gabriel, Michael, Raphael and Uriel) are invoked as guarding the four quarters, or directions, and their corresponding colors are associated with magical properties.[36] Lucifer or Sataniel in Judeo-Christian traditions, or Iblis in Islam, is considered an archangel by Satanists and many non-Satanists, but non-Satanists consider him evil and fallen from God's grace.\\r\\nIn art, archangels are sometimes depicted with larger wings. Some of the more commonly represented archangels are Gabriel, Michael, Raphael, and Uriel.[37]\\r\\nIn the lesser ritual of the pentagram, the invocation includes the words \\"Before me Raphael; Behind me Gabriel; On my right hand Michael; On my left hand Auriel [Uriel]...\\"[38]","input":"Who are the four archangels created by god?"},{"output":"February 1958","context":"\\r\\n\\r\\nOloibiri Oilfield is an onshore oilfield located in Oloibiri in Ogbia LGA of Bayelsa State, Nigeria, about 45 miles (72?km) east of Port Harcourt in the Niger Delta. Oloibiri field is about 13.75 square kilometres (5.31?sq?mi) and lies in a swamp within OML 29. Oloibiri Oilfield is named after Oloibiri, a small, remote creek community, where it is located. In Nigeria, oilfields are usually named after the host community where it is located or a local landmark. Sometimes, oilfields are also given names taken from indigenous languages. \\r\\n\\r\\nThe field is currently operated by Shell Petroleum Development Company of Nigeria Limited (SPDC).The field was originally operated by Shell Darcy. On 30 April 1956, Shell Darcy changed its name to Shell-BP Petroleum Development Company of Nigeria Limited to reflect BP's interest. In 1979, it changed its name again to Shell Petroleum Development Company of Nigeria Limited (SPDC) following the nationalisation of BP's interest by the government.\\r\\n\\r\\nOloibiri Oilfield was discovered on Sunday 15 January 1956 by Shell Darcy. It was the first commercial oil discovery in Nigeria; this discovery ended 50 years of unsuccessful oil exploration in the country by various international oil companies and launched Nigeria into the limelight of the Petro-State.\\r\\n\\r\\nFollowing the discovery of oil in commercial quantities in Oloibiri, Shell stepped up exploration in the Niger Delta and By 1958 Shell Darcy had discovered oil in twelve areas in the Niger Delta of which Oloibiri, Afam and Bomu were the most promising.\\r\\n\\r\\nThe discovery well Oloibiri ?1 was spudded on 3 August 1955 and drilled vertical to a total depth of 12008 feet (3660m). The well was tested and it flowed at the rate of about 5,000 barrels (790?m3) of oil per day and it was deemed to be a commercial discovery. Some gas was also discovered with the oil. The oil discovery was made in the Tertiary Agbada.\\r\\n\\r\\n.\\r\\n\\r\\nBetween 26 June 1956 and 28 October 1958, 11 appraisal wells were drilled vertical to appraisal the extension of the reservoir to different sections of the field. The first appraisal well was Oloibiri-2, it was spudded on 26 June 1956 and drilled vertically to a total depth of 2932m and it encountered oil in the Agbada Formation. Six of these appraisal wells were a success and encountered oil pay.\\r\\n\\r\\nAn appraisal well Oloibiri-17 was spudded on 9 June 1967 after 9 years of production and drilled deviated to a measured depth of 12520 feet (3816 mD) but the result was not encouraging. Oloibiri-17 was plugged and abandoned. The field production was on depletion from its peak production and the well was drilled to appraisal another section of the field so as to increase production. \\r\\n\\r\\nAnother appraisal well Oloibiri-18 was spudded on 21 April 1979 and drilled to a vertical depth of 9616 feet (2931 m) but the result was also discouraging. The field was almost depleted at that time. The main objective of the Oloibiri-18 was to appraise a new section and improve the drainage of the reservoir but the well was dry with shows and so it was plugged and abandoned.\\r\\n\\r\\nFollowing the successful completion of the appraisal of the field, four development wells were drilled in 1958 (between 17 June 1958 and 27 November 1958) for the development of the field. The four development wells and the six successful appraisal wells were completed as oil production wells.\\r\\n\\r\\nThe discovery well, Oloibiri-1 was completed on 5 June 1956 as a commercial oil production well. Thus, Oloibiri-1 made history as the first truly commercial oil well in Nigeria. This brings the number of completed production wells on field to eleven.\\r\\n\\r\\nThe field started oil production between late 1957 and early 1958 and the first oil production from the field came at the rate of 4,928 barrels per day (783.5?m3/d). The field produced at an average rate of 5,100 barrels (810?m3) of oil per day for the first year. The production increased thereafter as more wells were completed and put onto production and reached its peak in 1964. The field was drained from eleven production wells. The oil produced from the field is sour and heavy and has an API of 20.6. The gas produced with the oil was flared off as a result of lack of gas processing and utilisation facility in the country then, so the gas was not considered necessary.\\r\\n\\r\\nRoyal Dutch Shell laid the first crude oil pipeline in the country from the Oloibiri field to Port Harcourt on Bonny River to access export facilities. Nigeria exported its first crude oil in February 1958 from the Oloibiri oil field, initially at the rate of 5,100 barrels per day (810?m3/d). The oil was being pumped from the field via the country's first pipeline, laid by Shell.\\r\\n\\r\\nThe Oloibiri oilfield produced over 20 million barrels (3,200,000?m3) of oil during its 20 years life cycle. Oil production finally stopped in 1978 and the field was abandoned the same year. The Oloibiri oilfield was abandoned without any improved recovery to drain some of the 21.26 million barrels (3,380,000?m3) of hydrocarbon still left on the field.\\r\\n\\r\\n?\\tChuks Onyems, Nigeria Oilfields Encyclopedia.\\r\\n\\r\\n?\\tHISTORY OF THE NIGERIAN PETROLEUM INDUSTRY [1]\\r\\n\\r\\n?\\tThe History of Shell in Nigeria [2]\\r\\n\\r\\n?\\tNigeria ÿ History of Oil Exploration[3]","input":"When did nigeria export her first crude oil?"},{"output":"William Hale Thompson","context":"William Hale Thompson (May 14, 1869 ÿ March 19, 1944) was an American politician, mayor of Chicago for three terms, from 1915 to 1923 and again from 1927 to 1931. Known as \\"Big Bill\\" Thompson,[2] he is the last Republican to have served as mayor of Chicago to date. Historians rank Thompson among the most unethical mayors in American history, mainly for his open alliance with Al Capone.[3] However, others recognize the effectiveness of his political methods and publicity-oriented campaigning, acknowledging him as a \\"Political Chameleon\\" and an effective political machine.[4] TIME magazine said in 1931, \\"chief credit for creating 20th Century Politics Chicago Style\\" should go to William Thompson.[5]\\r\\n\\r\\nThompson was known for his over-the-top campaigning and uncensored language that, along with his towering height and weight, earned him the nickname \\"Big Bill\\".[6] Though Thompson was a popular figure, his popularity escalated after his death, when two safe-deposit boxes were found in his name containing nearly $1.8 million in cash and bonds.[6] Prior to his death in 1944, Thompson, upon his reelection in 1919, was at the forefront of the movement for Chicago Public Libraries and education officials to censor and ban many texts and historical recollections coming from the United Kingdom.[7]\\r\\n\\r\\nThompson was born in Boston, Massachusetts to William Hale and Mary Ann Thompson, but his family moved to Chicago when he was nine days old. Despite having been born in Boston, Thompson had strong roots in Chicago. His father, Colonel William Hale Thompson Sr., was a popular businessman within Chicago and served as colonel in the Second Illinois Guard who came to Chicago after serving in the United States Navy during the American Civil War. His maternal grandfather, Stephen F. Hale, the first chief of the Chicago Fire Department, played a large part in drawing up the city's corporation charter in 1837, earning him regard as a \\"Chicago pioneer\\" by some academic journalists.\\r\\n\\r\\nThompson was meant to attend Yale University but instead moved to Wyoming at the age of 14, where he became a cowboy and cattle owner and traveled across Europe, taking up ranching in Texas and New Mexico later on in his life. The experiences influenced him to add Western touches into his campaign, including his sombrero, which became a symbol for his campaign. By the age of twenty-one, he had accumulated a stake of $30,000. He returned to Chicago in 1892 after his father's death to manage his estates. Shortly after returning to Chicago, Thompson joined the Illinois Athletic Club and the Sportsmen's Club of America and quickly was appointed director-general and captain of the water polo and football teams. His six-foot frame and athletic prowess earned him the nickname \\"Big Bill,\\" which stuck with him throughout his career as a politician.[4][8] In 1901, Thompson married Miss Mary \\"Maysie\\" Walker Wyse a secretary in his father's office, but the two of them never had children.[9][10]\\r\\n\\r\\nThompson began his political career in 1900, when he ran for and narrowly won the position as alderman of the 2nd Ward, his home district.[11] Two years later, he was named a member of the Cook County Board of Commissioners. During this period, Thompson formed a political alliance with Fred Lundin, a Republican city clerk who worked under William Lorimer, a U.S. Representative from Illinois who was known for corrupt election methods. The political duo, according to most citizens, worked very well together earning them the title the \\"Gallagher and Shean of Chicago Politics\\". Thompson with his outgoing and charismatic personality paired with his towering stature and gentlemanly appearance gave him an undeniable public presence, which was completed by Lundin's cunning political ideas and projects.[8]\\r\\n\\r\\nIn 1915, Thompson was elected as the 41st Mayor of Chicago, beating County Clerk Robert M. Sweitzer, John H. Hill, Seymour Steadman, and Charles Thompson. He was the last Republican to be elected into office since, aside from his third term in 1928. As Thompson entered the first term of his mayorship, he appointed Fred Lundin as chairman on the committee of patronage.[8] Early in his mayoral career, Thompson began to amass a war chest to support an eventual run for the Presidency, by charging city drivers and inspectors $3 per month.\\r\\n\\r\\nThompson gained national attention and condemnation for his neutral attitude toward the events of World War I. By declining the visit of the French Mission to Chicago and refusing to control or act out against anti-war or anti-conscription meetings, Thompson is \\"credited with characterizing Chicago as the sixth German city of the world.\\" Also earning the nickname \\"Kaiser\\" Bill Thompson. These facts later went on to hurt his chances in his 1918 Senatorial Campaign.[8][10]\\r\\n\\r\\nIn his Inaugural Address, given April 26, 1915, Thompson spoke of his ambitions for Chicago to become \\"the greatest in the world\\", but also that his acts as mayor should not be swayed by corruption. He also emphasized the importance of public safety (as enforced by the Chicago Police Department), the improvement of public transit, secure and permanently lowered gas prices, Chicago being allowed to have Home rule and more efforts being placed into Chicago's commercial interests in order to create jobs and improve the city's economy. His efforts to expand and publicly improve the streets of Chicago earned him another nickname of \\"Big Bill the Builder\\". In his time as mayor, he oversaw the completion of the Michigan Avenue link bridge, the Twelfth Street widening, and the extension and widening of Ogden Avenue. Along with his big dreams for Chicago's geographical expansion, he wished for Chicago to expand politically and economically. He believed that Chicago should be able to enforce laws on their own terms, particularly without the interference of British government or totalitarian rule. He ended his Inaugural speech by stating:\\r\\n\\r\\n\\"I am a firm believer in the separation of the three co-ordinate branches of government--Executive, Legislative and Judicial--peculiar to our American system, and that one should not intrude upon or violate, the prerogatives of the other. I do not intend to exceed the rights and privileges of the executive nor transgress upon the legislative or judicial functions. I shall impartially execute the laws made by the proper legislative authorities and interpreted by the judiciary.\\" [12]\\r\\n\\r\\nHe was reelected mayor during the Chicago Race Riot of 1919, beating out Robert Sweitzer once again along with Adolph S. Carm, John Collins, John Fitzpatrick, and Maclay Hoyne. Thompson was said to have had control of the 75,000 black voters in his day. In his campaign he claimed to be an advocate for the people against public utility companies and the rich who avoided taxes. This inspired Thompson to enforce a five-cent streetcar fare to promote his campaign, which was also used to threaten the action of streetcar companies. Eventually, however, despite his protests, the fare was raised to seven cents.\\r\\n\\r\\nIn his Inaugural Address on April 28, 1919, Thompson looked towards drastically expanding Chicago, saying that \\"Chicago is greater than some nations\\". This expansion included the extension and widening of streets to cross over more of the city, new post offices, freight terminals, playgrounds, bridges, and more. Also, due to the rapidly changing city, Thompson proposed a zoning bill to regulate and create commercial, industrial, and residential areas. Among the other issues he claimed he would address were telephone prices and service quality, the expansion of the Chicago Police Department, Jobs for returning soldiers, lowering the cost of living, and restoring the jobs of Public School representatives who were removed by the Supreme Court.[13]\\r\\n\\r\\nThompson declined to run for reelection in 1923 and he was succeeded by William Emmett Dever. While out of office, Thompson was appointed chairman of the Illinois Waterways Commission. He used his position to remain relevant in the media, involving himself in civic suits and campaigning for the Lakes-to-Gulf waterway project: to build a waterway from the Great Lakes to the Gulf of Mexico. Promoting both the project and himself, Thompson set off on a \\"scientific\\" expedition (to be extensively covered by the media), which he set off to the South Seas to find a tree-climbing fish on July 5, 1924. Attracting more attention, Thompson placed a $25,000 bet on his success, but no one participated.[8][14]\\r\\n\\r\\nThompson ran again in 1927 during citywide gang war. Always a flamboyant campaigner, Thompson held a debate between himself and two live rats which he used to portray his opponents. Pledging to clean up Chicago and remove the crooks, Thompson instead turned his attention to the reformers, whom he considered the real criminals. According to Thompson, the biggest enemy the United States had was King George V of the United Kingdom. Thompson promised his supporters that if they ever met, Thompson would punch the king in the nose.[2] Upon his victory in 1927, Thompson's floating speakeasy outwardly known as the Fish Fans Club docked at Belmont Harbor, was flooded with his supporters, so many so, that the boat itself sunk beneath the weight.[15]\\r\\n\\r\\nIn his Inaugural Address, Thompson addressed the importance of remedying crime in Chicago, saying:\\r\\n\\r\\n\\"Our new Superintendent of Police has my positive instructions to drive the crooks and thieves and lawbreakers out of Chicago in ninety days, so that the people, their homes and their property may again be secure.\\" [16]\\r\\n\\r\\nThompson expressed his desire to remove Superintendent William McAndrew from the public schooling system, and restore what he calls the \\"true history of George Washington\\" while exposing \\"the treason and propaganda which insidiously have been injected into our schools and other educational institutions\\". He also went on to enforce other issues he'd addressed in previous speeches, like the issue of public transit, playgrounds, and the general upkeep and expansion of Chicago in an effort to aid property owners and increase residential income and revenue for the city as a whole.\\r\\n\\r\\nAl Capone's support was pivotal to Thompson's return to the mayor's office, using such tactics as the \\"Pineapple Primary\\" which occurred April 10, 1928, so-called because of the hand grenades thrown at polling places to disrupt voting. The St. Valentine's Day Massacre also took place while Thompson was mayor.\\r\\n\\r\\nThompson blamed Ruth Hanna McCormick's lack of support for his loss at the 1928 Republican National Convention, and he returned the favor during her 1930 campaign for the United States Senate.[17] Thompson had had a longstanding rivalry with the McCormicks. He intensely disliked Robert Rutherford McCormick who published the Chicago Tribune. U.S. Senator Joseph Medill McCormick was the publisher's brother,[17] and after his death, his widow ran against Thompson for the vacant seat. Caricature in the Chicago Tribune, 1920\\r\\n\\r\\nAmid growing discontent with Thompson's leadership, particularly in the area of cleaning up Chicago's reputation as the capital of organized crime, he was defeated in 1931 by Democrat Anton Cermak. Cermak was an immigrant from Bohemia, and Thompson used this fact to belittle him with ethnic slurs such as:\\r\\n\\r\\nCermak replied, \\"He doesn't like my name...It's true I didn't come over on the Mayflower, but I came over as soon as I could,\\" which was a sentiment to which ethnic Chicagoans could relate, so Thompson's slurs largely backfired.[18]\\r\\n\\r\\nAfter Thompson's defeat, the Chicago Tribune wrote:\\r\\n\\r\\nFor Chicago Thompson has meant filth, corruption, obscenity, idiocy and bankruptcy.... He has given the city an international reputation for moronic buffoonery, barbaric crime, triumphant hoodlumism, unchecked graft, and a dejected citizenship. He nearly ruined the property and completely destroyed the pride of the city. He made Chicago a byword for the collapse of American civilization. In his attempt to continue this he excelled himself as a liar and defamer of character.[18]\\r\\n\\r\\nYears later, in 1936, Thompson ran for office as Illinois governor as an independent against Henry Horner. He received only 3% of the vote. In 1939, he ran in the Republican primary for mayor of Chicago and was soundly defeated by a 77% to 23% margin against future Governor Dwight Green.[19]\\r\\n\\r\\nWilliam Hale Thompson died on March 19, 1944, at the Blackstone Hotel at the age of 74.[20] He was buried in Oak Woods Cemetery in a solid bronze casket.\\r\\n\\r\\nDespite the fact that many loved Thompson and enjoyed his various political antics, it was reported that very few people attended his funeral, and one reporter noted that there was not \\"a flower nor a fern to be seen\\".[19]\\r\\n\\r\\nUpon Thompson's death, two safe deposit boxes in his name were discovered to contain nearly $1.84 million in cash.[21][22] Once the money was uncovered, the Internal Revenue Service took their share in taxes, and Maysie Thompson lived off of the rest until her passing in 1958.[10]","input":"Who was the last republican mayor in chicago?"},{"output":"15 seasons","context":"CSI: Crime Scene Investigation, also referred to as CSI and CSI: Las Vegas, is an American procedural forensics crime drama television series which ran on CBS from October 6, 2000, to September 27, 2015, spanning 15 seasons. The series, starring William Petersen, Marg Helgenberger, Ted Danson, Laurence Fishburne, Elisabeth Shue, and Jorja Fox, is the first in the CSI franchise. The series concluded with a feature-length finale titled \\"Immortality\\".\\r\\n\\r\\n\\r\\nMixing deduction and character-driven drama, CSI: Crime Scene Investigation follows a team of crime-scene investigators, employed by the Las Vegas Police Department, as they use physical evidence to solve murders. The team is originally led by Gil Grissom (Petersen), a socially awkward forensic entomologist and career criminalist who is promoted to CSI supervisor following the death of a trainee investigator. Grissom's second-in-command, Catherine Willows (Marg Helgenberger), is a single mother with a cop's instinct. Born and raised in Las Vegas, Catherine was a stripper before being recruited into law enforcement and training as a blood-spatter specialist. Following Grissom's departure during the ninth season of the series, Catherine is promoted to supervisor. After overseeing the training of new investigator Raymond Langston (Fishburne), Willows is replaced by D.B. Russell (Danson), and recruited to the FBI shortly thereafter. Russell is a family man, a keen forensic botanist, and a veteran of the Seattle Crime Lab. In the series' 12th season, Russell is reunited with his former partner Julie Finlay (Elisabeth Shue), who like Catherine, is a blood-spatter expert with an extensive knowledge of criminal psychology. With the rest of the team, they work to tackle Las Vegas' growing crime rate and are on the job 24/7, scouring the scene, collecting the evidence, and finding the missing pieces that will solve the mystery.\\r\\nDuring the 1990s, Anthony Zuiker caught producer Jerry Bruckheimer's attention after writing his first movie script. Zuiker was convinced that a series was in the concept; Bruckheimer agreed and began developing the series with Touchstone Pictures.[1] The studio's head at the time liked the spec script and presented it to ABC, NBC, and Fox executives, who decided to pass. The head of drama development at CBS saw potential in the script, and the network had a pay-or-play contract with actor William Petersen, who said he wanted to do the CSI pilot. The network's executives liked the pilot so much, they decided to include it in their 2000 schedule immediately, airing on Fridays after The Fugitive. After CBS picked up the show, the Disney owned Touchstone decided to pull out of the project, since they didn't want to spend so much money producing a show for another network (ABC is also owned by Disney).[1] Instead of the intended effect of making CBS cancel the show (since it no longer had a producer), Bruckheimer was able to convince Alliance Atlantis to step in as a producer, saving the show and adding CBS as another producer.[1] Initially, CSI was thought to benefit from The Fugitive (a remake of the 1960s series), which was expected to be a hit, but by the end of 2000, CSI had a much larger audience.[2]\\r\\nCSI: Crime Scene Investigation was produced by Jerry Bruckheimer Television and CBS Productions, which became CBS Paramount Television in the fall of 2006 and CBS Television Studios three years later. Formerly a co-production with the now-defunct Alliance Atlantis Communications, that company's interest was later bought by the investment firm GS Capital Partners, an affiliate of Goldman Sachs.[3] CBS acquired AAC's international distribution rights to the program, though the non-US DVD distribution rights did not change (for example, Momentum Pictures continues to own UK DVD rights). The series is currently in syndication, and reruns are broadcast in the U.S. on Oxygen, Syfy and the USA Network on cable, with Ion Television holding the broadcast syndication rights. The show has aired in reruns on the USA Network since January 14, 2011.[4] The CSI catalog has been exclusive to the whole NBC Universal portfolio since September 2014, after several years with Viacom Media Networks' Spike and TV Land.[4]\\r\\nCSI was shot at Rye Canyon, a corporate campus owned by Lockheed Martin situated in the Valencia area of Santa Clarita, California,[5] but after episode 11, filming shifted to the Santa Clarita Studios, originally chosen for its similarity to the outskirts of Las Vegas. Occasionally, the cast still shot on location in Las Vegas (the season-four DVD set revealed that the episode \\"Suckers\\" was mostly shot during December 2003 in Las Vegas, where they filmed a Gothic club scene on location for rent, and in January 2004, some scenes were filmed at Caesars Palace), although primarily Las Vegas was used solely for second unit photography such as exterior shots of streets.[6] Other California locations include Verdugo Hills High School, UCLA's Royce Hall, Pasadena City Hall, and California State University, Los Angeles. While shooting took place primarily at Universal Studios in Universal City, California, Santa Clarita's surroundings had proven so versatile, CSI still shot some outdoor scenes there.[7]\\r\\nCSI's theme song was, since the last episode of season one, \\"Who Are You\\", written by Pete Townshend with vocals by lead singer Roger Daltrey of The Who. Daltrey made a special appearance in the season-seven episode \\"Living Legend\\", which also contained many musical references such as the words \\"Who's next\\" on a dry-erase board in the episode's opening sequence. In certain countries, to avoid music licensing fees, a unique theme was used, instead.\\r\\nThroughout the series, music played an important role; artists such as Ozzy Osbourne, The Wallflowers, John Mayer, and Akon (with Obie Trice) performed onscreen in the episodes \\"Skin in the Game\\", \\"The Accused Is Entitled\\", \\"Built To Kill, Part 1\\", and \\"Poppin' Tags\\", respectively. Mogwai was often heard during scenes showing forensic tests in progress, as were Radiohead and Cocteau Twins, but several other artists lent their music to CSI, including Rammstein and Linkin Parkused heavily in Lady Heather's story arc. Sigur R܇s can be heard playing in the background in the episode \\"Slaves of Las Vegas\\", The Turtles in \\"Grave Danger\\", and Marilyn Manson in \\"Suckers\\". A cover of the Tears for Fears song \\"Mad World\\", arranged by Michael Andrews and featuring vocals by Gary Jules, was used in the pilot episode and during three episodes of season six (\\"Room Service\\", \\"Killer\\", and \\"Way to Go\\"). Industrial rock band Nine Inch Nails was also featured multiple times throughout the three series. One episode started with The Velvet Underground's excited rendition of \\"Sweet Jane\\" and ended with the downbeat version of Cowboy Junkies' revision of the song. Character David Hodges' good luck has, on occasion, been accompanied by Electric Light Orchestra's \\"Mr. Blue Sky\\". This song was first used in the season-seven episode \\"Lab Rats\\", and last used during season 10's \\"Field Mice\\".\\r\\nDuring the course of the series, 337 episodes of CSI: Crime Scene Investigation aired?over 15 seasons.\\r\\nFrom CSI, CBS produced a franchise starting in 2002 with a spin-off entitled CSI: Miami. Set in Miami, Florida, and starring David Caruso and Emily Procter, Miami later launched CSI: NY in 2004. Starring Gary Sinise, Sela Ward, and Melina Kanakaredes, NY was set in New York City and was based upon the idea that \\"Everything is Connected\\". In 2015, a fourth CSI series, entitled CSI: Cyber, starring Patricia Arquette and Ted Danson, was created. It focuses on the FBI's elite Cyber Crime Division. The CSI series exists within the same fictional \\"universe\\" as fellow CBS police dramas Without a Trace and Cold Case. A number of comic books, video games, and novels based on the series have been made.\\r\\nIn 2006, the Fort Worth Museum of Science and History developed a traveling museum exhibit called \\"CSI: The Experience\\". On May 25, 2007, Chicago's Museum of Science and Industry was the first museum to host the exhibit, and the exhibit's opening featured stars from the TV series.[10] Also a supporting website designed for the benefit of people who cannot visit the exhibit was developed,[11] designed by Rice University's Center for Technology in Teaching and Learning and Left Brain Media.[12] \\"CSI: The Experience\\" also has an interactive attraction at the MGM Grand Las Vegas in Las Vegas, and the Mall of America in Minneapolis, Minnesota aldo has an interactive attraction.[13]\\r\\nDuring its 15 years in production, CSI secured an estimated world audience of over 73.8 million viewers (in 2009),[14] commanded, as of the fall of 2008, an average cost of $262,600 for a 30-second commercial,[15] and reached milestone episodes including the 100th (\\"Ch-Ch-Changes\\"), the 200th (\\"Mascara\\") and the 300th (\\"Frame by Frame\\"). CSI spawned three spin-off series, a book series, several video games, and an exhibit at Chicago's Museum of Science and Industry. At the time of its cancellation, CSI was the seventh-longest running scripted U.S. primetime TV series overall and had been recognized as the most popular dramatic series internationally by the Festival de Tlvision de Monte-Carlo, which awarded the series the International Television Audience Award (Best Television Drama Series) three times.[14][16] CSI became the second-most watched show on American television by 2002,[17] finally taking the top position for the 2002-2003 season. It was later named the most-watched show in the world for the sixth time in 2016, making it the most-watched show for more years than any other show.[18]\\r\\nCritical reception to the show has been positive, with an IMDB score of 7.8/10,[19] while early reviews showed a mixed to favorable review of the opening season. The Hollywood Reporter noted of the pilot \\"...the charismatic William Petersen and the exquisite Marg Helgenberger, lend credibility to the portrayals that might be indistinct in lesser hands. There's also a compelling, pulsating edge at the outset of CSI that commands instant attention, thanks in part to dynamic work from director Danny Cannon.\\".[20] Entertainment Weekly gave the opening two seasons \\"B+\\" and \\"A-\\" ratings, respectively, noting: \\"The reason for CSIs success is that it combines a few time-tested TV elements in a fresh way. Each episode presents a murder case and a group of lovable heroes armed with cool, high-tech gadgets who do the sleuthing and wrap things up in an hour.\\"[21][22] The show has won six Primetime Emmy awards (out of 39 nominations) and four People's Choice awards (out of six nominations) and was nominated for six Golden Globe Awards, among other awards.\\r\\nCSI was often criticized for its level and explicitness of graphic violence, images, and sexual content. The CSI series and its spin-off shows have been accused of pushing the boundary of what is considered acceptable viewing for primetime network television. The series had numerous episodes on sexual fetishism and other forms of sexual pleasure (notably the recurring character of Lady Heather, a professional dominatrix). CSI was ranked among the worst primetime shows by the Parents Television Council from its second through sixth seasons,[23][24][25][26] being ranked the worst show for family prime-time viewing after the 2002ÿ2003[27] and 2005ÿ2006[28] seasons. The PTC also targeted certain CSI episodes for its weekly \\"Worst TV Show of the Week\\" feature.[29][30][31][32][33][34] In addition, the episode \\"King Baby\\" that aired in February 2005, which the PTC named the most offensive TV show of the week,[34] also led the PTC to start a campaign to file complaints with the FCC with the episode;[35] to date, nearly 13,000 PTC members complained to the Federal Communications Commission about the episode.[36] The PTC also asked Clorox to pull their advertisements from CSI and CSI: Miami because of the graphically violent content on those programs.[37]\\r\\nA grassroots campaign started on August 2007, upon rumors of Jorja Fox leaving the show,[38] organized by the online forum Your Tax Dollars At Work. Many of its 19,000 members donated to the cause, collecting over $8,000 for gifts and stunts targeted at CBS executives and CSI's producers and writers. The stunts included a wedding cake delivery to Carol Mendelsohn, 192 chocolate-covered insects with the message \\"CSI Without Sara Bugs Us\\" to Naren Shankar, and a plane flying several times over the Universal Studios of Los Angeles with a \\"Follow the evidence keep Jorja Fox on CSI\\" banner.[39][40] Other protests included mailing the show's producers a dollar, to save Fox's contract \\"one dollar at a time\\". By October?16, 2007, according to the site's tally, more than 20,000 letters with money or flyers had been mailed to the Universal Studios and to CBS headquarters in New York from 49 different countries since the campaign started on September 29, 2007.[41][42][43] Fox and Mendelsohn chose to donate the money to Court Appointed Special Advocate, a national association that supports and promotes court-appointed advocates for abused or neglected children.[44]\\r\\nOn September 27, 2007, after CSI's season eight premiered, a miniature model of character Gil Grissom's office (which he was seen building during season seven) was put up on eBay. The auction ended October 7, with the prop being sold for $15,600; CBS donated the proceeds to the National Court Appointed Special Advocate Association.[45]\\r\\nReal-life crime scene investigators and forensic scientists warn that popular television shows like CSI (often specifically citing CSI) do not give a realistic picture of the work, wildly distorting the nature of crime-scene investigators' work, and exaggerating the ease, speed, effectiveness, drama, glamour, influence, scope, and comfort level of their jobs, which they describe as far more mundane, tedious, limited, and boring, and very commonly failing to solve a crime.[46][47][48][49]\\r\\nAnother criticism of the show is the depiction of police procedure, which some[50] consider to be decidedly lacking in realism.[51] For instance, the show's characters not only investigate (\\"process\\") crime scenes, but they also conduct raids, engage in suspect pursuit and arrest, interrogate suspects, and solve cases, all of which falls under the responsibility of uniformed officers and detectives, not CSI personnel. Although 'some' detectives are also registered CSIs, this is exceedingly rare in actual life. It is considered an inappropriate and improbable practice to allow CSI personnel to be involved in detective work, as it would compromise the impartiality of scientific evidence and would be impracticably time-consuming. Additionally, it is inappropriate for the CSIs who process a crime scene to be involved in the examination and testing of any evidence collected from that scene. CSI shares this characteristic with similar British drama series Silent Witness.\\r\\nHowever, not all law enforcement agencies have been as critical; many CSIs have responded positively to the show's influence and enjoy their new reputation. In the UK, scenes of crime officers now commonly refer to themselves as CSIs. Some constabularies, such as Norfolk, have even gone so far as to change the name of the unit to Crime Scene Investigation.[52] Also, recruitment and training programs have seen a massive increase in applicants, with a far wider range of people now interested in something previously regarded as a scientific backwater.[53]\\r\\nThe \\"CSI effect\\" is a reference to the alleged phenomenon of CSI raising crime victims' and jury members' real-world expectations of forensic science, especially crime-scene investigation and DNA testing.[54] This is said to have changed the way many trials are presented today, in that prosecutors are pressured to deliver more forensic evidence in court.[55] Victims and their families are coming to expect instant answers from showcased techniques such as DNA analysis and fingerprinting, when actual forensic processing often takes days or weeks, with no guarantee of revealing a \\"smoking gun\\" for the prosecution's case. District attorneys state that the conviction rate in cases with little physical evidence has decreased, largely due to the influence of CSI on jury members.[56] Some police and district attorneys have criticized the show for giving members of the public an inaccurate perception of how police solve crimes.\\r\\nIn 2006, the evidence cited in support of the supposed effect was mainly anecdotes from law enforcement personnel and prosecutors, and allegedly little empirical examination of the effect had been done, and the one study published by then suggested the phenomenon may be an urban myth.[57]\\r\\nHowever, more recent research suggests that these modern TV shows do have an influence on public pereceptions and expectations, and juror behavior.[58][59]\\r\\nCiting the \\"CSI effect\\", at least one researcher has suggested screening jurors for their level of influence from such TV programs.[59]\\r\\nThe show ranked number three in DVR playback (3.07?million viewers), according to Nielsen prime DVR lift data from September 22 to November 23, 2008.[60]\\r\\nThe U.S. box sets are released by CBS DVD (distributed by Paramount), while the Canadian box sets are released by Alliance Atlantis (distributed by Universal Studios). The first season DVD release differs from all subsequent seasons in that it is available only in 1.33:1 or 4:3 full frame, rather than the subsequent aspect ratio of 1.78:1 or 16:9 widescreen, which is the HDTV standard aspect ratio.\\r\\nThe first season is also the only DVD release of the series not to feature Dolby Digital 5.1 surround audio, instead offering Dolby Digital stereo sound.\\r\\nThe Blu-ray disc release of Season One is 7.1 DTS sound and 1.78:1 widescreen.\\r\\nRegions 2 releases have followed a pattern whereby each season is progressively released in two parts (each of 11 or 12 episodes [except for Season 8, in which part 1 contained 8 episodes and the Without a Trace crossover and part 2 contained the remaining 9 episodes] with special features split up) before finally being sold as a single box set. After having been almost 12?months behind region 2 releases after the first four series, region 4 releases are speeding up, with distributors simply releasing season five as a complete box set.\\r\\n* = Re-released in slimline full-season packaging. Seasons 1ÿ8 were released in 2 parts between 2003 and 2009.\\r\\nnone\\r\\nCBS Home Entertainment (distributed by Paramount) released the first season on High Definition Blu-ray disc on May 12, 2009.[65] Unlike its DVD counterpart CSI: Crime Scene Investigation#DVD releases, this release is in its original 16:9 widescreen format and feature 7.1 surround sound. Features on the Season 1 BR set are also in High Def.\\r\\nSeason 10 was released on November 18, 2011, in Region B. Like the Season 1 Blu-ray release, it features a 16:9 widescreen transfer, but it only has DTS-HD 5.1 sound.[66]\\r\\nSeason 9 was released on September 1, 2009. Like the Season 1 Blu-ray release, it features a 16:9 widescreen transfer with DTS-HD Master Audio 7.1 surround sound. Extras include commentaries, featurettes and BD-Live functionality.[67]\\r\\nSeason 8 was released on Blu-ray on May 29, 2009, in Region B.[68]\\r\\nCSI has also been released as a series of mobile games. In Fall 2007, CBS teamed up with game developer Gameloft to bring CSI to mobile phones. The first of the series to be published was CSI: Miami. The game features actual cast members such as Alexx Woods and Calleigh Duquesne who are trying to solve a murder in South Beach with the player's assistance.[69] The game is also available for download on various iPod devices.[70]\\r\\nIn spring 2008, Gameloft and CBS released \\"CSI: Crime Scene Investigation?ÿ The Mobile Game\\" which is based on the original series in Las Vegas. This game introduces the unique ability to receive calls during the game to provide tips and clues about crime scenes and evidence. As for the storyline, the game developers collaborated with Anthony E. Zuiker (the series creator) to ensure that the plot and dialogue were aligned with the show's style.[71]\\r\\nCSI airs on the Nine Network and TVHits (formerly TV1) in Australia, on Channel 5 in United Kingdom, on CTV in Canada, on Italia 1 in Italy, on Prime in New Zealand, on RT2 in Ireland, on TF1 in France, AXN in Asia and Latin America, Skai TV in Greece, on HOT Zone in Israel, on TV3 in Estonia and on Kanal 5 in Sweden and Denmark.\\r\\nThe use of forensic pathology in the investigation of crime has been the central theme of several other TV mystery-suspense dramas, including:","input":"How many seasons does csi las vegas have?"},{"output":"three to five years","context":"Civil engineering is a professional engineering discipline that deals with the design, construction, and maintenance of the physical and naturally built environment, including works like roads, bridges, canals, dams, and buildings.[1][2] Civil engineering is traditionally broken into a number of sub-disciplines. It is the second-oldest engineering discipline after military engineering,[3] and it is defined to distinguish non-military engineering from military engineering.[4] Civil engineering takes place in the public sector from municipal through to national governments, and in the private sector from individual homeowners through to international companies.\\r\\n\\r\\n\\r\\nEngineering has been an aspect of life since the beginnings of human existence. The earliest practice of civil engineering may have commenced between 4000 and 2000 BC in ancient Egypt, the Indus Valley Civilization, and Mesopotamia (ancient Iraq) when humans started to abandon a nomadic existence, creating a need for the construction of shelter. During this time, transportation became increasingly important leading to the development of the wheel and sailing.\\r\\nUntil modern times there was no clear distinction between civil engineering and architecture, and the term engineer and architect were mainly geographical variations referring to the same occupation, and often used interchangeably.[5] The construction of pyramids in Egypt (circa 2700ÿ2500 BC) were some of the first instances of large structure constructions. Other ancient historic civil engineering constructions include the Qanat water management system (the oldest is older than 3000 years and longer than 71?km,[6]) the Parthenon by Iktinos in Ancient Greece (447ÿ438 BC), the Appian Way by Roman engineers (c. 312 BC), the Great Wall of China by General Meng T'ien under orders from Ch'in Emperor Shih Huang Ti (c. 220 BC)[7] and the stupas constructed in ancient Sri Lanka like the Jetavanaramaya and the extensive irrigation works in Anuradhapura. The Romans developed civil structures throughout their empire, including especially aqueducts, insulae, harbors, bridges, dams and roads.\\r\\nIn the 18th century, the term civil engineering was coined to incorporate all things civilian as opposed to military engineering.[4] The first self-proclaimed civil engineer was John Smeaton, who constructed the Eddystone Lighthouse.[3][7] In 1771 Smeaton and some of his colleagues formed the Smeatonian Society of Civil Engineers, a group of leaders of the profession who met informally over dinner. Though there was evidence of some technical meetings, it was little more than a social society.\\r\\nIn 1818 the Institution of Civil Engineers was founded in London, and in 1820 the eminent engineer Thomas Telford became its first president. The institution received a Royal Charter in 1828, formally recognising civil engineering as a profession. Its charter defined civil engineering as:\\r\\nthe art of directing the great sources of power in nature for the use and convenience of man, as the means of production and of traffic in states, both for external and internal trade, as applied in the construction of roads, bridges, aqueducts, canals, river navigation and docks for internal intercourse and exchange, and in the construction of ports, harbours, moles, breakwaters and lighthouses, and in the art of navigation by artificial power for the purposes of commerce, and in the construction and application of machinery, and in the drainage of cities and towns.[8]\\r\\nThe first private college to teach civil engineering in the United States was Norwich University, founded in 1819 by Captain Alden Partridge.[9] The first degree in civil engineering in the United States was awarded by Rensselaer Polytechnic Institute in 1835.[10][11] The first such degree to be awarded to a woman was granted by Cornell University to Nora Stanton Blatch in 1905.[12]\\r\\nIn the UK during the early 19th century, the division between civil engineering and military engineering (served by the Royal Military Academy, Woolwich), coupled with the demands of the Industrial Revolution, spawned new engineering education initiatives: the Royal Polytechnic Institution was founded in 1838, the private College for Civil Engineers in Putney was established in 1839, and the UK's first Chair of Engineering was established at the University of Glasgow in 1840.\\r\\nCivil engineering is the application of physical and scientific principles for solving the problems of society, and its history is intricately linked to advances in understanding of physics and mathematics throughout history. Because civil engineering is a wide-ranging profession, including several specialized sub-disciplines, its history is linked to knowledge of structures, materials science, geography, geology, soils, hydrology, environment, mechanics and other fields.\\r\\nThroughout ancient and medieval history most architectural design and construction was carried out by artisans, such as stonemasons and carpenters, rising to the role of master builder. Knowledge was retained in guilds and seldom supplanted by advances. Structures, roads and infrastructure that existed were repetitive, and increases in scale were incremental.[13]\\r\\nOne of the earliest examples of a scientific approach to physical and mathematical problems applicable to civil engineering is the work of Archimedes in the 3rd century BC, including Archimedes Principle, which underpins our understanding of buoyancy, and practical solutions such as Archimedes' screw. Brahmagupta, an Indian mathematician, used arithmetic in the 7th century AD, based on Hindu-Arabic numerals, for excavation (volume) computations.[14]\\r\\nCivil engineers typically possess an academic degree in civil engineering. The length of study is three to five years, and the completed degree is designated as a bachelor of engineering, or a bachelor of science in engineering. The curriculum generally includes classes in physics, mathematics, project management, design and specific topics in civil engineering. After taking basic courses in most sub-disciplines of civil engineering, they move onto specialize in one or more sub-disciplines at advanced levels. While an undergraduate degree (BEng/BSc) normally provides successful students with industry-accredited qualification, some academic institutions offer post-graduate degrees (MEng/MSc), which allow students to further specialize in their particular area of interest.[15]\\r\\nIn most countries, a bachelor's degree in engineering represents the first step towards professional certification, and a professional body certifies the degree program. After completing a certified degree program, the engineer must satisfy a range of requirements (including work experience and exam requirements) before being certified. Once certified, the engineer is designated as a professional engineer (in the United States, Canada and South Africa), a chartered engineer (in most Commonwealth countries), a chartered professional engineer (in Australia and New Zealand), or a European engineer (in most countries of the European Union). There are international agreements between relevant professional bodies to allow engineers to practice across national borders.\\r\\nThe benefits of certification vary depending upon location. For example, in the United States and Canada, \\"only a licensed professional engineer may prepare, sign and seal, and submit engineering plans and drawings to a public authority for approval, or seal engineering work for public and private clients.\\"[16] This requirement is enforced under provincial law such as the Engineers Act in Quebec.[17]\\r\\nNo such legislation has been enacted in other countries including the United Kingdom. In Australia, state licensing of engineers is limited to the state of Queensland. Almost all certifying bodies maintain a code of ethics which all members must abide by.[18]\\r\\nEngineers must obey contract law in their contractual relationships with other parties. In cases where an engineer's work fails, he may be subject to the law of tort of negligence, and in extreme cases, criminal charges.[19] An engineer's work must also comply with numerous other rules and regulations such as building codes and environmental law.\\r\\nIn general, civil engineering is concerned with the overall interface of human created fixed projects with the greater world. General civil engineers work closely with surveyors and specialized civil engineers to design grading, drainage, pavement, water supply, sewer service, dams, electric and communications supply. General civil engineering is also referred to as site engineering, a branch of civil engineering that primarily focuses on converting a tract of land from one usage to another. Site engineers spend time visiting project sites, meeting with stakeholders, and preparing construction plans. Civil engineers apply the principles of geotechnical engineering, structural engineering, environmental engineering, transportation engineering and construction engineering to residential, commercial, industrial and public works projects of all sizes and levels of construction.\\r\\nCoastal engineering is concerned with managing coastal areas. In some jurisdictions, the terms sea defense and coastal protection mean defense against flooding and erosion, respectively. The term coastal defense is the more traditional term, but coastal management has become more popular as the field has expanded to techniques that allow erosion to claim land.\\r\\nConstruction engineering involves planning and execution, transportation of materials, site development based on hydraulic, environmental, structural and geotechnical engineering. As construction firms tend to have higher business risk than other types of civil engineering firms do, construction engineers often engage in more business-like transactions, for example, drafting and reviewing contracts, evaluating logistical operations, and monitoring prices of supplies.\\r\\nControl engineering (or control systems engineering) is the branch of civil engineering discipline that applies control theory to design systems with desired behaviors. The practice uses sensors to measure the output performance of the device being controlled (often a vehicle) and those measurements can be used to give feedback to the input actuators that can make corrections toward desired performance. When a device is designed to perform without the need of human inputs for correction it is called automatic control (such as cruise control for regulating a car's speed). Multidisciplinary in nature, control systems engineering activities focus on implementation of control systems mainly derived by mathematical modeling of systems of a diverse range.\\r\\nEarthquake engineering involves designing structures to withstand hazardous earthquake exposures. Earthquake engineering is a sub-discipline of structural engineering. The main objectives of earthquake engineering are[20] to understand interaction of structures on the shaky ground; foresee the consequences of possible earthquakes; and design, construct and maintain structures to perform at earthquake in compliance with building codes.\\r\\nEnvironmental engineering is the contemporary term for sanitary engineering, though sanitary engineering traditionally had not included much of the hazardous waste management and environmental remediation work covered by environmental engineering. Public health engineering and environmental health engineering are other terms being used.\\r\\nEnvironmental engineering deals with treatment of chemical, biological, or thermal wastes, purification of water and air, and remediation of contaminated sites after waste disposal or accidental contamination. Among the topics covered by environmental engineering are pollutant transport, water purification, waste water treatment, air pollution, solid waste treatment, and hazardous waste management. Environmental engineers administer pollution reduction, green engineering, and industrial ecology. Environmental engineers also compile information on environmental consequences of proposed actions.\\r\\nForensic engineering is the investigation of materials, products, structures or components that fail or do not operate or function as intended, causing personal injury or damage to property. The consequences of failure are dealt with by the law of product liability. The field also deals with retracing processes and procedures leading to accidents in operation of vehicles or machinery. The subject is applied most commonly in civil law cases, although it may be of use in criminal law cases. Generally the purpose of a Forensic engineering investigation is to locate cause or causes of failure with a view to improve performance or life of a component, or to assist a court in determining the facts of an accident. It can also involve investigation of intellectual property claims, especially patents.\\r\\nGeotechnical engineering studies rock and soil supporting civil engineering systems. Knowledge from the field of soil science, materials science, mechanics, and hydraulics is applied to safely and economically design foundations, retaining walls, and other structures. Environmental efforts to protect groundwater and safely maintain landfills have spawned a new area of research called geoenvironmental engineering.[21][22]\\r\\nIdentification of soil properties presents challenges to geotechnical engineers. Boundary conditions are often well defined in other branches of civil engineering, but unlike steel or concrete, the material properties and behavior of soil are difficult to predict due to its variability and limitation on investigation. Furthermore, soil exhibits nonlinear (stress-dependent) strength, stiffness, and dilatancy (volume change associated with application of shear stress), making studying soil mechanics all the more difficult.[21]\\r\\nMaterials science is closely related to civil engineering. It studies fundamental characteristics of materials, and deals with ceramics such as concrete and mix asphalt concrete, strong metals such as aluminum and steel, and thermosetting polymers including polymethylmethacrylate (PMMA) and carbon fibers.\\r\\nMaterials engineering involves protection and prevention (paints and finishes). Alloying combines two types of metals to produce another metal with desired properties. It incorporates elements of applied physics and chemistry. With recent media attention on nanoscience and nanotechnology, materials engineering has been at the forefront of academic research. It is also an important part of forensic engineering and failure analysis.\\r\\n\\"Outside plant engineering\\" or OSP engineering is related to both Civil engineering and Telecommunications engineering. It is concerned with the design of the aerial and underground structures that interconnect communications nodes. Some of the typical components of outside plant are cables, poles, messenger wire, down guys, pole anchors, underground vaults, service boxes/hand-holes, and conduit.\\r\\nStructural engineering is concerned with the structural design and structural analysis of buildings, bridges, towers, flyovers (overpasses), tunnels, off shore structures like oil and gas fields in the sea, aerostructure and other structures. This involves identifying the loads which act upon a structure and the forces and stresses which arise within that structure due to those loads, and then designing the structure to successfully support and resist those loads. The loads can be self weight of the structures, other dead load, live loads, moving (wheel) load, wind load, earthquake load, load from temperature change etc. The structural engineer must design structures to be safe for their users and to successfully fulfill the function they are designed for (to be serviceable). Due to the nature of some loading conditions, sub-disciplines within structural engineering have emerged, including wind engineering and earthquake engineering.[23]\\r\\nDesign considerations will include strength, stiffness, and stability of the structure when subjected to loads which may be static, such as furniture or self-weight, or dynamic, such as wind, seismic, crowd or vehicle loads, or transitory, such as temporary construction loads or impact. Other considerations include cost, constructability, safety, aesthetics and sustainability.\\r\\nSurveying is the process by which a surveyor measures certain dimensions that occur on or near the surface of the Earth. Surveying equipment, such as levels and theodolites, are used for accurate measurement of angular deviation, horizontal, vertical and slope distances. With computerisation, electronic distance measurement (EDM), total stations, GPS surveying and laser scanning have to a large extent supplanted traditional instruments. Data collected by survey measurement is converted into a graphical representation of the Earth's surface in the form of a map. This information is then used by civil engineers, contractors and realtors to design from, build on, and trade, respectively. Elements of a structure must be sized and positioned in relation to each other and to site boundaries and adjacent structures. Although surveying is a distinct profession with separate qualifications and licensing arrangements, civil engineers are trained in the basics of surveying and mapping, as well as geographic information systems. Surveyors also lay out the routes of railways, tramway tracks, highways, roads, pipelines and streets as well as position other infrastructure, such as harbors, before construction.\\r\\nIn the United States, Canada, the United Kingdom and most Commonwealth countries land surveying is considered to be a separate and distinct profession. Land surveyors are not considered to be engineers, and have their own professional associations and licensing requirements. The services of a licensed land surveyor are generally required for boundary surveys (to establish the boundaries of a parcel using its legal description) and subdivision plans (a plot or map based on a survey of a parcel of land, with boundary lines drawn inside the larger parcel to indicate the creation of new boundary lines and roads), both of which are generally referred to as Cadastral surveying.\\r\\nConstruction surveying is generally performed by specialised technicians. Unlike land surveyors, the resulting plan does not have legal status. Construction surveyors perform the following tasks:\\r\\nTransportation engineering is concerned with moving people and goods efficiently, safely, and in a manner conducive to a vibrant community. This involves specifying, designing, constructing, and maintaining transportation infrastructure which includes streets, canals, highways, rail systems, airports, ports, and mass transit. It includes areas such as transportation design, transportation planning, traffic engineering, some aspects of urban engineering, queueing theory, pavement engineering, Intelligent Transportation System (ITS), and infrastructure management.\\r\\nMunicipal engineering is concerned with municipal infrastructure. This involves specifying, designing, constructing, and maintaining streets, sidewalks, water supply networks, sewers, street lighting, municipal solid waste management and disposal, storage depots for various bulk materials used for maintenance and public works (salt, sand, etc.), public parks and cycling infrastructure. In the case of underground utility networks, it may also include the civil portion (conduits and access chambers) of the local distribution networks of electrical and telecommunications services. It can also include the optimizing of waste collection and bus service networks. Some of these disciplines overlap with other civil engineering specialties, however municipal engineering focuses on the coordination of these infrastructure networks and services, as they are often built simultaneously, and managed by the same municipal authority. Municipal engineers may also design the site civil works for large buildings, industrial plants or campuses (i.e. access roads, parking lots, potable water supply, treatment or pretreatment of waste water, site drainage, etc.)\\r\\nWater resources engineering is concerned with the collection and management of water (as a natural resource). As a discipline it therefore combines elements of hydrology, environmental science, meteorology, conservation, and resource management. This area of civil engineering relates to the prediction and management of both the quality and the quantity of water in both underground (aquifers) and above ground (lakes, rivers, and streams) resources. Water resource engineers analyze and model very small to very large areas of the earth to predict the amount and content of water as it flows into, through, or out of a facility. Although the actual design of the facility may be left to other engineers.\\r\\nHydraulic engineering is concerned with the flow and conveyance of fluids, principally water. This area of civil engineering is intimately related to the design of pipelines, water supply network, drainage facilities (including bridges, dams, channels, culverts, levees, storm sewers), and canals. Hydraulic engineers design these facilities using the concepts of fluid pressure, fluid statics, fluid dynamics, and hydraulics, among others.","input":"How long the course of civil engineering is?"},{"output":"20.95%","context":"The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. The atmosphere of Earth protects life on Earth by creating pressure allowing for liquid water to exist on the Earth's surface, absorbing ultraviolet solar radiation, warming the surface through heat retention (greenhouse effect), and reducing temperature extremes between day and night (the diurnal temperature variation).\\r\\nBy volume, dry air contains 78.09% nitrogen, 20.95% oxygen,[2] 0.93% argon, 0.04% carbon dioxide, and small amounts of other gases. Air also contains a variable amount of water vapor, on average around 1% at sea level, and 0.4% over the entire atmosphere. Air content and atmospheric pressure vary at different layers, and air suitable for use in photosynthesis by terrestrial plants and breathing of terrestrial animals is found only in Earth's troposphere and in artificial atmospheres.\\r\\nThe atmosphere has a mass of about 5.15G1018?kg,[3] three quarters of which is within about 11?km (6.8?mi; 36,000?ft) of the surface. The atmosphere becomes thinner and thinner with increasing altitude, with no definite boundary between the atmosphere and outer space. The Krmn line, at 100?km (62?mi), or 1.57% of Earth's radius, is often used as the border between the atmosphere and outer space. Atmospheric effects become noticeable during atmospheric reentry of spacecraft at an altitude of around 120?km (75?mi). Several layers can be distinguished in the atmosphere, based on characteristics such as temperature and composition.\\r\\nThe study of Earth's atmosphere and its processes is called atmospheric science (aerology). Early pioneers in the field include Lon Teisserenc de Bort and Richard Assmann.[4]\\r\\n\\r\\n\\r\\nThe three major constituents of Earth's atmosphere, are nitrogen, oxygen, and argon. Water vapor accounts for roughly 0.25% of the atmosphere by mass. The concentration of water vapor (a greenhouse gas) varies significantly from around 10 ppm by volume in the coldest portions of the atmosphere to as much as 5% by volume in hot, humid air masses, and concentrations of other atmospheric gases are typically quoted in terms of dry air (without water vapor).[5] The remaining gases are often referred to as trace gases,[6] among which are the greenhouse gases, principally carbon dioxide, methane, nitrous oxide, and ozone. Filtered air includes trace amounts of many other chemical compounds. Many substances of natural origin may be present in locally and seasonally variable small amounts as aerosols in an unfiltered air sample, including dust of mineral and organic composition, pollen and spores, sea spray, and volcanic ash. Various industrial pollutants also may be present as gases or aerosols, such as chlorine (elemental or in compounds), fluorine compounds and elemental mercury vapor. Sulfur compounds such as hydrogen sulfide and sulfur dioxide (SO2) may be derived from natural sources or from industrial air pollution.\\r\\n(A) volume fraction is equal to mole fraction for ideal gas only,\\r\\n????also see volume (thermodynamics)\\r\\n(B) ppmv: parts per million by volume\\r\\n(C) Water vapor is about 0.25% by mass over full atmosphere\\r\\n(D) Water vapor strongly varies locally[5]\\r\\nThe relative concentration of gasses remains constant until about 10,000?m (33,000?ft).[9]\\r\\nIn general, air pressure and density decrease with altitude in the atmosphere. However, temperature has a more complicated profile with altitude, and may remain relatively constant or even increase with altitude in some regions (see the temperature section, below). Because the general pattern of the temperature/altitude profile is constant and measurable by means of instrumented balloon soundings, the temperature behavior provides a useful metric to distinguish atmospheric layers. In this way, Earth's atmosphere can be divided (called atmospheric stratification) into five main layers. Excluding the exosphere, the atmosphere has four primary layers, which are the troposphere, stratosphere, mesosphere, and thermosphere.[10] From highest to lowest, the five main layers are:\\r\\nThe exosphere is the outermost layer of Earth's atmosphere (i.e. the upper limit of the atmosphere). It extends from the exobase, which is located at the top of the thermosphere at an altitude of about 700?km above sea level, to about 10,000?km (6,200?mi; 33,000,000?ft) where it merges into the solar wind.\\r\\nThis layer is mainly composed of extremely low densities of hydrogen, helium and several heavier molecules including nitrogen, oxygen and carbon dioxide closer to the exobase. The atoms and molecules are so far apart that they can travel hundreds of kilometers without colliding with one another. Thus, the exosphere no longer behaves like a gas, and the particles constantly escape into space. These free-moving particles follow ballistic trajectories and may migrate in and out of the magnetosphere or the solar wind.\\r\\nThe exosphere is located too far above Earth for any meteorological phenomena to be possible. However, the aurora borealis and aurora australis sometimes occur in the lower part of the exosphere, where they overlap into the thermosphere. The exosphere contains most of the satellites orbiting Earth.\\r\\nThe thermosphere is the second-highest layer of Earth's atmosphere. It extends from the mesopause (which separates it from the mesosphere) at an altitude of about 80?km (50?mi; 260,000?ft) up to the thermopause at an altitude range of 500ÿ1000?km (310ÿ620?mi; 1,600,000ÿ3,300,000?ft). The height of the thermopause varies considerably due to changes in solar activity.[11] Because the thermopause lies at the lower boundary of the exosphere, it is also referred to as the exobase. The lower part of the thermosphere, from 80 to 550 kilometres (50 to 342?mi) above Earth's surface, contains the ionosphere.\\r\\nThe temperature of the thermosphere gradually increases with height. Unlike the stratosphere beneath it, wherein a temperature inversion is due to the absorption of radiation by ozone, the inversion in the thermosphere occurs due to the extremely low density of its molecules. The temperature of this layer can rise as high as 1500?C (2700?F), though the gas molecules are so far apart that its temperature in the usual sense is not very meaningful. The air is so rarefied that an individual molecule (of oxygen, for example) travels an average of 1 kilometre (0.62?mi; 3300?ft) between collisions with other molecules.[13] Although the thermosphere has a high proportion of molecules with high energy, it would not feel hot to a human in direct contact, because its density is too low to conduct a significant amount of energy to or from the skin.\\r\\nThis layer is completely cloudless and free of water vapor. However, non-hydrometeorological phenomena such as the aurora borealis and aurora australis are occasionally seen in the thermosphere. The International Space Station orbits in this layer, between 350 and 420?km (220 and 260?mi).\\r\\nThe mesosphere is the third highest layer of Earth's atmosphere, occupying the region above the stratosphere and below the thermosphere. It extends from the stratopause at an altitude of about 50?km (31?mi; 160,000?ft) to the mesopause at 80ÿ85?km (50ÿ53?mi; 260,000ÿ280,000?ft) above sea level.\\r\\nTemperatures drop with increasing altitude to the mesopause that marks the top of this middle layer of the atmosphere. It is the coldest place on Earth and has an average temperature around ?85?C (?120?F; 190?K).[14][15]\\r\\nJust below the mesopause, the air is so cold that even the very scarce water vapor at this altitude can be sublimated into polar-mesospheric noctilucent clouds. These are the highest clouds in the atmosphere and may be visible to the naked eye if sunlight reflects off them about an hour or two after sunset or a similar length of time before sunrise. They are most readily visible when the Sun is around 4 to 16 degrees below the horizon. Lightning-induced discharges known as transient luminous events (TLEs) occasionally form in the mesosphere above tropospheric thunderclouds. The mesosphere is also the layer where most meteors burn up upon atmospheric entrance. It is too high above Earth to be accessible to jet-powered aircraft and balloons, and too low to permit orbital spacecraft. The mesosphere is mainly accessed by sounding rockets and rocket-powered aircraft.\\r\\nThe stratosphere is the second-lowest layer of Earth's atmosphere. It lies above the troposphere and is separated from it by the tropopause. This layer extends from the top of the troposphere at roughly 12?km (7.5?mi; 39,000?ft) above Earth's surface to the stratopause at an altitude of about 50 to 55?km (31 to 34?mi; 164,000 to 180,000?ft).\\r\\nThe atmospheric pressure at the top of the stratosphere is roughly 1/1000 the pressure at sea level. It contains the ozone layer, which is the part of Earth's atmosphere that contains relatively high concentrations of that gas. The stratosphere defines a layer in which temperatures rise with increasing altitude. This rise in temperature is caused by the absorption of ultraviolet radiation (UV) radiation from the Sun by the ozone layer, which restricts turbulence and mixing. Although the temperature may be ?60?C (?76?F; 210?K) at the tropopause, the top of the stratosphere is much warmer, and may be near 0?C.[16]\\r\\nThe stratospheric temperature profile creates very stable atmospheric conditions, so the stratosphere lacks the weather-producing air turbulence that is so prevalent in the troposphere. Consequently, the stratosphere is almost completely free of clouds and other forms of weather. However, polar stratospheric or nacreous clouds are occasionally seen in the lower part of this layer of the atmosphere where the air is coldest. The stratosphere is the highest layer that can be accessed by jet-powered aircraft.\\r\\nThe troposphere is the lowest layer of Earth's atmosphere. It extends from Earth's surface to an average height of about 12?km, although this altitude varies from about 9?km (30,000?ft) at the poles to 17?km (56,000?ft) at the equator,[12] with some variation due to weather. The troposphere is bounded above by the tropopause, a boundary marked in most places by a temperature inversion (i.e. a layer of relatively warm air above a colder one), and in others by a zone which is isothermal with height.[17][18]\\r\\nAlthough variations do occur, the temperature usually declines with increasing altitude in the troposphere because the troposphere is mostly heated through energy transfer from the surface. Thus, the lowest part of the troposphere (i.e. Earth's surface) is typically the warmest section of the troposphere. This promotes vertical mixing (hence the origin of its name in the Greek word ??, tropos, meaning \\"turn\\"). The troposphere contains roughly 80% of the mass of Earth's atmosphere.[19] The troposphere is denser than all its overlying atmospheric layers because a larger atmospheric weight sits on top of the troposphere and causes it to be most severely compressed. Fifty percent of the total mass of the atmosphere is located in the lower 5.6?km (18,000?ft) of the troposphere.\\r\\nNearly all atmospheric water vapor or moisture is found in the troposphere, so it is the layer where most of Earth's weather takes place. It has basically all the weather-associated cloud genus types generated by active wind circulation, although very tall cumulonimbus thunder clouds can penetrate the tropopause from below and rise into the lower part of the stratosphere. Most conventional aviation activity takes place in the troposphere, and it is the only layer that can be accessed by propeller-driven aircraft.\\r\\nWithin the five principal layers that are largely determined by temperature, several secondary layers may be distinguished by other properties:\\r\\nThe average temperature of the atmosphere at Earth's surface is 14?C (57?F; 287?K)[22] or 15?C (59?F; 288?K),[23] depending on the reference.[24][25][26]\\r\\nThe average atmospheric pressure at sea level is defined by the International Standard Atmosphere as 101325 pascals (760.00?Torr; 14.6959?psi; 760.00?mmHg). This is sometimes referred to as a unit of standard atmospheres (atm). Total atmospheric mass is 5.1480G1018 kg (1.135G1019 lb),[28] about 2.5% less than would be inferred from the average sea level pressure and Earth's area of 51007.2 megahectares, this portion being displaced by Earth's mountainous terrain. Atmospheric pressure is the total weight of the air above unit area at the point where the pressure is measured. Thus air pressure varies with location and weather.\\r\\nIf the entire mass of the atmosphere had a uniform density from sea level, it would terminate abruptly at an altitude of 8.50?km (27,900?ft). It actually decreases exponentially with altitude, dropping by half every 5.6?km (18,000?ft) or by a factor of 1/e every 7.64?km (25,100?ft), the average scale height of the atmosphere below 70?km (43?mi; 230,000?ft). However, the atmosphere is more accurately modeled with a customized equation for each layer that takes gradients of temperature, molecular composition, solar radiation and gravity into account.\\r\\nIn summary, the mass of Earth's atmosphere is distributed approximately as follows:[29]\\r\\nBy comparison, the summit of Mt. Everest is at 8,848?m (29,029?ft); commercial airliners typically cruise between 10?km (33,000?ft) and 13?km (43,000?ft) where the thinner air improves fuel economy; weather balloons reach 30.4?km (100,000?ft) and above; and the highest X-15 flight in 1963 reached 108.0?km (354,300?ft).\\r\\nEven above the Krmn line, significant atmospheric effects such as auroras still occur. Meteors begin to glow in this region, though the larger ones may not burn up until they penetrate more deeply. The various layers of Earth's ionosphere, important to HF radio propagation, begin below 100?km and extend beyond 500?km. By comparison, the International Space Station and Space Shuttle typically orbit at 350ÿ400?km, within the F-layer of the ionosphere where they encounter enough atmospheric drag to require reboosts every few months. Depending on solar activity, satellites can experience noticeable atmospheric drag at altitudes as high as 700ÿ800?km.\\r\\nThe division of the atmosphere into layers mostly by reference to temperature is discussed above. Temperature decreases with altitude starting at sea level, but variations in this trend begin above 11?km, where the temperature stabilizes through a large vertical distance through the rest of the troposphere. In the stratosphere, starting above about 20?km, the temperature increases with height, due to heating within the ozone layer caused by capture of significant ultraviolet radiation from the Sun by the dioxygen and ozone gas in this region. Still another region of increasing temperature with altitude occurs at very high altitudes, in the aptly-named thermosphere above 90?km.\\r\\nBecause in an ideal gas of constant composition the speed of sound depends only on temperature and not on the gas pressure or density, the speed of sound in the atmosphere with altitude takes on the form of the complicated temperature profile (see illustration to the right), and does not mirror altitudinal changes in density or pressure.\\r\\nThe density of air at sea level is about 1.2?kg/m3 (1.2?g/L, 0.0012 g/cm3). Density is not measured directly but is calculated from measurements of temperature, pressure and humidity using the equation of state for air (a form of the ideal gas law). Atmospheric density decreases as the altitude increases. This variation can be approximately modeled using the barometric formula. More sophisticated models are used to predict orbital decay of satellites.\\r\\nThe average mass of the atmosphere is about 5 quadrillion (5G1015) tonnes or 1/1,200,000 the mass of Earth. According to the American National Center for Atmospheric Research, \\"The total mean mass of the atmosphere is 5.1480G1018?kg with an annual range due to water vapor of 1.2 or 1.5G1015?kg, depending on whether surface pressure or water vapor data are used; somewhat smaller than the previous estimate. The mean mass of water vapor is estimated as 1.27G1016?kg and the dry air mass as 5.1352 I0.0003G1018?kg.\\"\\r\\nSolar radiation (or sunlight) is the energy Earth receives from the Sun. Earth also emits radiation back into space, but at longer wavelengths that we cannot see. Part of the incoming and emitted radiation is absorbed or reflected by the atmosphere. In May 2017, glints of light, seen as twinkling from an orbiting satellite a million miles away, were found to be reflected light from ice crystals in the atmosphere.[31][32]\\r\\nWhen light passes through Earth's atmosphere, photons interact with it through scattering. If the light does not interact with the atmosphere, it is called direct radiation and is what you see if you were to look directly at the Sun. Indirect radiation is light that has been scattered in the atmosphere. For example, on an overcast day when you cannot see your shadow there is no direct radiation reaching you, it has all been scattered. As another example, due to a phenomenon called Rayleigh scattering, shorter (blue) wavelengths scatter more easily than longer (red) wavelengths. This is why the sky looks blue; you are seeing scattered blue light. This is also why sunsets are red. Because the Sun is close to the horizon, the Sun's rays pass through more atmosphere than normal to reach your eye. Much of the blue light has been scattered out, leaving the red light in a sunset.\\r\\nDifferent molecules absorb different wavelengths of radiation. For example, O2 and O3 absorb almost all wavelengths shorter than 300 nanometers. Water (H2O) absorbs many wavelengths above 700?nm. When a molecule absorbs a photon, it increases the energy of the molecule. This heats the atmosphere, but the atmosphere also cools by emitting radiation, as discussed below.\\r\\nThe combined absorption spectra of the gases in the atmosphere leave \\"windows\\" of low opacity, allowing the transmission of only certain bands of light. The optical window runs from around 300?nm (ultraviolet-C) up into the range humans can see, the visible spectrum (commonly called light), at roughly 400ÿ700?nm and continues to the infrared to around 1100?nm. There are also infrared and radio windows that transmit some infrared and radio waves at longer wavelengths. For example, the radio window runs from about one centimeter to about eleven-meter waves.\\r\\nEmission is the opposite of absorption, it is when an object emits radiation. Objects tend to emit amounts and wavelengths of radiation depending on their \\"black body\\" emission curves, therefore hotter objects tend to emit more radiation, with shorter wavelengths. Colder objects emit less radiation, with longer wavelengths. For example, the Sun is approximately 6,000?K (5,730?C; 10,340?F), its radiation peaks near 500?nm, and is visible to the human eye. Earth is approximately 290?K (17?C; 62?F), so its radiation peaks near 10,000?nm, and is much too long to be visible to humans.\\r\\nBecause of its temperature, the atmosphere emits infrared radiation. For example, on clear nights Earth's surface cools down faster than on cloudy nights. This is because clouds (H2O) are strong absorbers and emitters of infrared radiation. This is also why it becomes colder at night at higher elevations.\\r\\nThe greenhouse effect is directly related to this absorption and emission effect. Some gases in the atmosphere absorb and emit infrared radiation, but do not interact with sunlight in the visible spectrum. Common examples of these are CO2 and H2O.\\r\\nThe refractive index of air is close to, but just greater than 1. Systematic variations in refractive index can lead to the bending of light rays over long optical paths. One example is that, under some circumstances, observers onboard ships can see other vessels just over the horizon because light is refracted in the same direction as the curvature of Earth's surface.\\r\\nThe refractive index of air depends on temperature,[33] giving rise to refraction effects when the temperature gradient is large. An example of such effects is the mirage.\\r\\nAtmospheric circulation is the large-scale movement of air through the troposphere, and the means (with ocean circulation) by which heat is distributed around Earth. The large-scale structure of the atmospheric circulation varies from year to year, but the basic structure remains fairly constant because it is determined by Earth's rotation rate and the difference in solar radiation between the equator and poles.\\r\\nThe first atmosphere consisted of gases in the solar nebula, primarily hydrogen. There were probably simple hydrides such as those now found in the gas giants (Jupiter and Saturn), notably water vapor, methane and ammonia.[34]\\r\\nOutgassing from volcanism, supplemented by gases produced during the late heavy bombardment of Earth by huge asteroids, produced the next atmosphere, consisting largely of nitrogen plus carbon dioxide and inert gases.[34] A major part of carbon-dioxide emissions dissolved in water and reacted with metals such as calcium and magnesium during weathering of crustal rocks to form carbonates that were deposited as sediments. Water-related sediments have been found that date from as early as 3.8 billion years ago.[35]\\r\\nAbout 3.4 billion years ago, nitrogen formed the major part of the then stable \\"second atmosphere\\". The influence of life has to be taken into account rather soon in the history of the atmosphere, because hints of early life-forms appear as early as 3.5 billion years ago.[36] How Earth at that time maintained a climate warm enough for liquid water and life, if the early Sun put out 30% lower solar radiance than today, is a puzzle known as the \\"faint young Sun paradox\\".\\r\\nThe geological record however shows a continuous relatively warm surface during the complete early temperature record of Earth ÿ with the exception of one cold glacial phase about 2.4 billion years ago. In the late Archean Eon an oxygen-containing atmosphere began to develop, apparently produced by photosynthesizing cyanobacteria (see Great Oxygenation Event), which have been found as stromatolite fossils from 2.7 billion years ago. The early basic carbon isotopy (isotope ratio proportions) strongly suggests conditions similar to the current, and that the fundamental features of the carbon cycle became established as early as 4 billion years ago.\\r\\nAncient sediments in the Gabon dating from between about 2,150 and 2,080 million years ago provide a record of Earth's dynamic oxygenation evolution. These fluctuations in oxygenation were likely driven by the Lomagundi carbon isotope excursion.[37]\\r\\nThe constant re-arrangement of continents by plate tectonics influences the long-term evolution of the atmosphere by transferring carbon dioxide to and from large continental carbonate stores. Free oxygen did not exist in the atmosphere until about 2.4 billion years ago during the Great Oxygenation Event and its appearance is indicated by the end of the banded iron formations.\\r\\nBefore this time, any oxygen produced by photosynthesis was consumed by oxidation of reduced materials, notably iron. Molecules of free oxygen did not start to accumulate in the atmosphere until the rate of production of oxygen began to exceed the availability of reducing materials that removed oxygen. This point signifies a shift from a reducing atmosphere to an oxidizing atmosphere. O2 showed major variations until reaching a steady state of more than 15% by the end of the Precambrian.[40] The following time span from 541 million years ago to the present day is the Phanerozoic Eon, during the earliest period of which, the Cambrian, oxygen-requiring metazoan life forms began to appear.\\r\\nThe amount of oxygen in the atmosphere has fluctuated over the last 600 million years, reaching a peak of about 30% around 280 million years ago, significantly higher than today's 21%. Two main processes govern changes in the atmosphere: Plants use carbon dioxide from the atmosphere, releasing oxygen. Breakdown of pyrite and volcanic eruptions release sulfur into the atmosphere, which oxidizes and hence reduces the amount of oxygen in the atmosphere. However, volcanic eruptions also release carbon dioxide, which plants can convert to oxygen. The exact cause of the variation of the amount of oxygen in the atmosphere is not known. Periods with much oxygen in the atmosphere are associated with rapid development of animals. Today's atmosphere contains 21% oxygen, which is great enough for this rapid development of animals.[41]\\r\\nAir pollution is the introduction into the atmosphere of chemicals, particulate matter or biological materials that cause harm or discomfort to organisms.[42] Stratospheric ozone depletion is caused by air pollution, chiefly from chlorofluorocarbons and other ozone-depleting substances.\\r\\nThe scientific consensus is that the anthropogenic greenhouse gases currently accumulating in the atmosphere are the main cause of global warming.[43]\\r\\nOn October 19, 2015 NASA started a website containing daily images of the full sunlit side of Earth on http://epic.gsfc.nasa.gov/. The images are taken from the Deep Space Climate Observatory (DSCOVR) and show Earth as it rotates during a day.[44]","input":"How much oxygen is in the earth's atmosphere?"},{"output":"a silent protest against Nazi occupation","context":"The Paper Clips Project, by middle school students from the small southeastern Tennessee town of Whitwell, created a monument for the Holocaust victims of Nazi Germany. It started in 1998 as a simple 8th-grade project to study other cultures, and then evolved into one gaining worldwide attention. At last count, over 30?million paper clips had been received. Paper Clips, an award-winning documentary film about the project, was released in 2004 by Miramax Films.[1]\\r\\n\\r\\nIn 1998, Linda M. Hooper, principal of Whitwell Middle School in Whitwell, Tennessee, asked Assistant Principal David Smith to find a voluntary after-school project to teach the children about tolerance. David Smith and Sandra Roberts started a Holocaust education program and held the first class in the fall of 1998.  Soon the students were overwhelmed with the massive scale of the Holocaust and asked Mrs. Hooper if they could collect something to represent the lives that were exterminated during the Holocaust.  Mrs. Hooper responded that they could if they could find something that related to the Holocaust or to World War II.  Through Internet research, the students discovered that Johan Vaaler, a Norwegian, designed a loop of metal, and the Norwegians wore paperclips on their lapels during World War II as a silent protest against Nazi occupation. The students decided to collect 6,000,000?paper clips to represent the estimated 6,000,000?Jews killed between 1939 and 1945 under the authority of the Nazi government of Adolf Hitler.\\r\\n\\r\\nAt first the project went slowly, as it did not gain much publicity. Students created a website and sent out letters to friends, family and celebrities. The project began to snowball after it received attention from Peter and Dagmar Schroeder, journalists who were born in Germany during World War II and who covered the White House for German newspapers. They published some articles as well as a book, Das Broklammer-Projekt (The Paper Clip Project) published in September 2000, that promoted the project in Germany. The big break in the US came with an article in the Washington Post on April 7, 2001, written by Dita Smith.\\r\\n\\r\\nAlmost all observers note the unexpected location of the project. The small rural town of Whitwell has about 1,600?residents and, according to the U.S. census, 97.35 percent of them are white. There was not a single Jew among the population of 425?students when the project began. Out of the 425?students that attend the school, there are only five African Americans and one Hispanic person.\\r\\n\\r\\nAbout 40 miles away is the Rhea County Courthouse, where, in 1925, a teacher was convicted for teaching evolution during the Scopes \\"Monkey\\" Trial. The trial upheld a statute which outlawed teaching any theory that denies the Divine Creation. A hundred miles from Whitwell, in Pulaski, Tennessee, the infamous Ku Klux Klan was reportedly born.\\r\\n\\r\\nThe city is quite poor, as its main business, coal mining, started to decline after an accident 30?years ago; the last mine was shut down completely in 1997. About half of the students at the middle school qualify for the free lunch program, which is a benefit for lower-income American school children.\\r\\n\\r\\nPaper clips were chosen in part because Norwegians wore them on their lapels as a symbol of resistance against Nazi occupation during World War II. (Norwegian Johan Vaaler is often credited with the invention of a progenitor of the modern paper clip.)\\r\\n\\r\\nThe paper clips were sent by various people by mail; the letters came from about 20?different countries. Some celebrities, like George W. Bush, Bill Clinton, Bill Cosby, Steven Spielberg, Tom Bosley and Tom Hanks were among those mailing in the clips. As of the summer of 2004, the school had collected about 24?million paper clips. As of 2005, more were still coming in. Most letters contain a story or a dedication of the attached paper clips to a certain person. Some of these stories are shared in the film.\\r\\n\\r\\nThe Children's Holocaust Memorial consists of an authentic German transport car (which arrived in the Baltimore seaport on September 9, 2001) surrounded by a small garden. The railcar is filled with 11?million paper clips (6?million for murdered Jews and 5?million for Roma, Catholics, homosexuals, Jehovah's Witnesses, and other groups). The monument was uncovered on the anniversary of the Kristallnacht, November 9, 2001.[2]\\r\\n[3]\\r\\n\\r\\nLinda Pickett sculpted eighteen butterflies of twisted copper which are embedded in concrete around the railcar. Butterflies came from a poem written by a child who lived in Terezin concentration camp in 1942 (I Never Saw Another Butterfly) and the number 18 in Hebrew symbolizes life (in Gematria, 18 is the numerical value of the word ??, pronounced Chai, meaning life). Inside the railcar, besides the paper clips, there are the Schroeders book and a suitcase filled with letters of apology to Anne Frank by a class of German schoolchildren.\\r\\n\\r\\nA sculpture designed by an artist from Ooltewah, Tennessee stands next to the car, memorializing the 1.5?million children murdered by the Nazis, and incorporating another 11?million paper clips.\\r\\n\\r\\nThe 1990 documentary film Paper Clips was directed by Elliot Berlin and Joe Fab. It was made to describe the project and highlight what was done.\\r\\n\\r\\nIn 2006 the Jewish Motorcyclists Alliance and Yidden on Wheels, a Toronto-based Jewish motorcycle club, organized a ride from points across North America to Whitwell, TN to commemorate the Paperclip Project and in honor of the Holocaust's victims. The ride was also a fundraiser for that school, with over $35,000 raised to help the school buy interactive blackboards.\\r\\n\\r\\nMitchell Belman, a Toronto-based filmmaker, captured the essence of this ride in his documentary Paper Clips: A Ride to Remember.[citation needed]","input":"What did paper clips represent during the holocaust?"},{"output":"14 January 1960","context":"The Reserve Bank of Australia (RBA), on 14 January 1960, became the Australian central bank and banknote issuing authority, when the Reserve Bank Act 1959 (23 April 1959) removed the central banking functions from the Commonwealth Bank.[2]\\r\\nThe bank has the responsibility of providing services to the Government of Australia in addition to also providing services to other central banks and official institutions.[3] It currently consists of the Payments System Board, which governs the payments system policy of the bank, and the Reserve Bank Board, which governs all other monetary and banking policies of the bank.[4]\\r\\nBoth boards consist of members of both the bank, the Treasury, other Australian government agencies, and leaders of other institutions that are part of the economy.[4][5] The structure of the Reserve Bank Board has remained consistent ever since 1951, with the exception of the change in the number of members of the board.[2] The governor of the Reserve Bank of Australia is appointed by the Treasurer and chairs both the Payment Systems and Reserve Bank Boards and when there are disagreements between both boards, the governor resolves them.[4][6]\\r\\nFrom the middle of the 19th century into the 1890s, the prospects of a national bank forming grew. In 1911, the Commonwealth Bank was established, but did not have the authority to print notes, which was a power that was still reserved to the Treasury. A movement toward reestablishing the gold standard occurred after World War I, with John Garvan leading various boards in contracting the money supply on the route to doing so, and the gold standard was instituted for both the British pound sterling and the Australian pound in 1925.[7]\\r\\nDuring the Great Depression, the Australian pound became devalued, no longer worth the pound sterling, and formally departed from the gold standard with the Commonwealth Bank Act of 1932.[8] Legislation in 1945 led to regulation of private banks which H.C. Coombs was opposed to, and when he became governor in 1949, he gave them more overall control over their institutions.[2][7] When the monetary authorities implemented the advice of Coombs to have a flexible interest rate, it allowed the bank to rely more on open market operations.[7] In 1980 the issue of short term government bonds ÿ Treasury notes of 13 and 26 weeks duration ÿ changed from a tap system, in which the price was set, to a tender system in which the volume of stock was set and the price determined by the market. Soon afterwards the tender system was extended to the issue of longer term government bonds.\\r\\nThe float of the Australian dollar happened in 1983, around the same period of time that the financial system in Australia was deregulated. Administration of the banks was transferred in 1998 from the bank to the Australian Prudential Regulation Authority and the Payments System Board was created, while the bank was given power within the said Board in the same year.[2] The current Governor of the Reserve Bank is Philip Lowe, who succeeded Glenn Stevens as governor on 18 September 2016.[9]\\r\\n\\r\\n\\r\\nThe proposition of a national bank in Australia began to be raised in the middle of the 19th century. This interest accelerated significantly in the 1890s due to an austere collapse of the financial and banking sectors at the beginning of that decade. The Australian Labor Party consequently formed during the same decade and proposed a bank should be formed, which would be a protected and cheap way of having financial services. The party designed a platform in 1908 for a \\"Commonwealth Bank\\", which would be a combination of both a commercial and central bank.[7]\\r\\nRegardless, Fisher's Labor government introduced legislation in 1911 for a government-owned commercial bank, without a complete central banking component. He stated that \\"Time and experience will show how its functions for usefulness may be extended [towards central banking].\\" The only function at the time that made the bank characteristic of a central one was that it was the banker to the Australian government, in addition to it being the same for the states. For the time being, the Treasury of Australia maintained the role of issuing bank notes through the Notes Act of 1910.[7]\\r\\nThe Commonwealth Bank of Australia gradually developed into the central bank of Australia. In response to the disruption of trade during World War I (1914ÿ1918) the Commonwealth Bank began to manage the debt of the Australian government. Nevertheless, at the end of the war, the bank continued to have a primary role as a savings and trading bank. World War I had caused the currency of Australia to move away from the gold standard, in order to fund a great increase of government spending, as did the United Kingdom and other parts of the British Empire.\\r\\nThe value of the Australian pound remained tied to the pound sterling. Inflation in Australia thus increased, less than in Britain, but more than in the United States. The case for a central bank was increased by the need for the government to cut spending after the war to reduce its debt. Commonwealth Bank Governor Denison Miller had been arguing for the issue of Australian currency to be switched from the treasury to the bank, as it had more staff and more monetary knowledge.[7]\\r\\nThe Australian Notes Board (ANB) was created in 1920 and partially acceded to the request of Miller, in having four directors, with the governor of the bank being an ex officio member.[2] The ANB began to follow a policy of Board member John Garvan, in contracting the money supply, with the goal of reducing prices so that free convertibility of the Australian pound to gold could be re-established at pre-war rates, that is return to the former gold standard.\\r\\nThis was accomplished by refusing the exchange of notes for gold and it was hoped that this would lower domestic prices and raise the exchange rate for the Australian pound. When gold arrived from New York, U.S. the government sold securities in order to diminish the effect of monetary expansion, therefore executing the first open market operations in the history of Australia and thus the first attempt of central banking.[7]\\r\\nThe Department of Treasury issued notes until 1924, when this responsibility was transferred to the Commonwealth Bank.[2] The ANB was abolished by the Commonwealth Bank Act 1924, due to Treasurer and Country Party Leader Earle Page wanting to end the monetary contraction which particularly hurt his farming constituents, who were as a result receiving reduced export prices.[7] The new Board of Directors replacing it,[2] which was composed of various areas of the industry, soon appointed Garvan chairman, and thus he continued his policies. In 1925, both the pound sterling and Australian pound returned to the pre-war gold standard. The primary role of the Commonwealth Bank continued to be a savings and trading bank, even though the government attempted to make the bank into a central bank through its actions in 1924.[7]\\r\\nLegislation was introduced to the Parliament at the climax of the Great Depression, in May 1930, by Treasurer E.G. Theodore, to transfer central banking powers from the Commonwealth Bank to a new central bank, but this failed.[7] The Australian pound was devalued in 1931 and it ceased to be tied to the pound sterling. The Reserve Bank departed from the gold standard with the Commonwealth Bank Act 1932, which made the notes no longer exchangeable into gold and allowed the bank not to keep any gold reserves.[8] The monetary policy of the bank from 1931 until the early 1970s had been to keep a stable exchange rate with the pound sterling.[7]\\r\\nThrough the new Commonwealth Bank Act and the Banking Act 1945, the board was replaced by a six-member council, consisting of bank and treasury officials. It additionally formalised the bank's administrative powers of monetary and banking policy and exchange control and also stated the governor was responsible for managing the bank.[2] Highly debated legislation in 1945 caused high amounts of regulation on private banks, which later-Governor H.C. Coombs was opposed to, along with his opposition to bank nationalisation in 1947.[7] When he became governor in 1949, he allowed private banks to have more control over their liquidity and attempted to introduce market-based monetary policy.[2][7] He also warned of the possibility of stagflation in 1959.[7]\\r\\nLegislation in 1951, substituted the council by a 10-member board which included the governor, deputy governor and the secretary to the treasury. The board took over the management of the bank from the governor. The Reserve Bank Act 1959 (23 April 1959) took out the part of the Commonwealth Bank that executed central bank functions and placed it into the new Reserve Bank, while the commercial and savings bank functions stayed with the Commonwealth Bank.[2] This finally created a separate central bank for Australia in 1959, which took effect 14 January 1960, many years after several other nations already had one and similar to the early proposal by Treasurer Theodore.[2][7]\\r\\nIn the mid-1960s, monetary authorities accepted Coombs' conclusions and allowed a flexible interest rate, making it easier for the bank to rely on open market operations.[7] The Exchange Control was abolished after the float of the Australian dollar occurred in 1983. In the five years after the Campbell Committee probe, 1979ÿ1984, the financial system in Australia became deregulated. Another probe was the Wallis Committee in 1996, which took effect in 1998. The effects were the transfer of overseeing the banks from the RBA to the Australian Prudential Regulation Authority (APRA) and the creation of the Payments System Board (PSB), which would attempt to maintain the safety and performance of the payments system. The bank was given powers within the PSB through additional legislation in 1998.[2]\\r\\nIn August 1996, then Governor-designate Ian Macfarlane and the Treasurer issued a Statement on the Conduct of Monetary Policy which restated the roles of the Reserve Bank and the Government of Australia. It affirmed government endorsement of the Reserve Bank's inflation objective, which was introduced in 1993. A change of government in December 2007 led to another Statement, which was issued by both former Treasurer Wayne Swan and Reserve Bank Governor Glenn Stevens. This amends previous statements by giving the bank independence and encourages transparency and communication.[2]\\r\\nSince 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. Australian press coverage, which has continued into late 2011, reflects concerns with the apparent laxity and tardiness of corrective actions undertaken by relevant RBA board members and officials. The matters were not referred to the Federal Police in 2007, although they are now, while in 2011 it has been revealed that the RBA had to correct evidence given to Parliamentary committees. In July 2014, WikiLeaks released a secret censorship order prohibiting publication throughout Australia of information that \\"reveals, implies, suggests or alleges\\" corruption involving a number of past and present high-ranking Malaysian, Indonesian, and Vietnamese officials.[10]\\r\\nIt is currently governed by the Reserve Bank Act 1959, which was approved by Parliament. The Reserve Bank Board's duty stated in the Act, within its outlined boundaries, is to ensure that the bank's monetary and banking policy is used to help the Australian population. This should be accomplished through consultation with the government and so in the Reserve Bank Board's opinion that its powers are used to help with:[3]\\r\\nIn practice the Reserve Bank concentrates on the first objective, that is to control inflation through monetary policy. The current objective is a policy of inflation targeting aimed at maintaining the annual inflation rate at between \\"2ÿ3 per cent, on average, over the cycle\\". This target was first set in 1993 by the then Reserve Bank Governor Bernie Fraser and was then formalised in 1996 by the then Treasurer Peter Costello and incoming Reserve Bank Governor Ian Mcfarlane.[2]\\r\\nThe Reserve Bank gives banking and registry services to agencies of the government, to other central banks, and other official institutions. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion.\\r\\nNearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site. The remainder of the total 926 staff work in Adelaide, South Australia; Brisbane, Queensland; Canberra, Australian Capital Territory; Melbourne, Victoria; Perth, Western Australia; London and New York City. A wholly owned subsidiary of the bank is Note Printing Australia, which employs 257 other workers, and which manufactures the Australian dollar and other securities, for markets both in and outside of Australia.[3]\\r\\nThe Payments System Board fills the role of deciding on the bank's payments system policy and the Reserve Bank Board is responsible for all other monetary and banking policies of the bank. Conflicts between the two Boards do not occur often and when they do, they are resolved by the governor.[4]\\r\\nThe Reserve Bank Board consists of nine members in total. These members include the three ex officio members of the board, consisting of the governor of the reserve bank, who is chairman of the board, the deputy governor of the reserve bank, who is the deputy chairman of the board, and the secretary to the treasury.\\r\\nIn addition, the board is composed of six external members who are appointed by the Treasurer for a period of five years. According to section 17(1) of the Reserve Bank Act, members of the board are not allowed to be a director, officer, or employee of an institution that is authorised to take in deposits.[5] Excluding changes in the number of directors, the structure of the board of directors has remained unchanged since 1951.[2]\\r\\nThe current members of the board of directors are:[5]\\r\\nThe board normally meets eleven times each year, on the first Tuesday of each month except January. Every year, the board meets at least once in Melbourne, usually in the first six months of the year. The board occasionally also meets in other Australian capitals. Five members of the board must meet in order to constitute a quorum, and the meeting must be chaired by the governor, or the deputy governor in his absence.\\r\\nThe board usually forms a consensus without a need for structured voting on the issues at hand. Meetings of the board are held in the boardroom of the Reserve Bank's Head Office in Sydney or the equivalent in other regional offices of the bank. The meetings begin at 9.00 am and continue for three and a half hours, with minutes published two weeks after the meeting is held.[5]\\r\\nThe Reserve Bank Act 1959 allows the Payments System Board to decide the Reserve Bank's payment systems policy. This is done so it can command risk and to aid in competitiveness and balance in the financial system. The bank's power through the Payment Systems Act 1998 allows it to regulate any payment system and can create binding rules for security and performance in the system. If members of a payment system are at odds over issues of market risk, admission, safety, and rivalry, the RBA can additionally administer arbitration with the consent of those involved. The Reserve Bank is also permitted to gather information from a payment system or participants thereof. The bank was also given the power to regulate the competition of transactions in August 2001.[4]\\r\\nThe Payment Systems and Netting Act 1998 gives the board power in areas of the law that were previously uncertain. It removed the zero hour rule that allowed a bankruptcy to date a bankruptcy the previous midnight and the Act made it so payments the same day could not be undone. Before the removal of the zero hour rule, the Real Time Gross Settlement system had been violated because payments in the system should inherently not be reversed. Some payments systems had previously agreed to pay and receive obligations to the whole system, rather than merely maintaining their own. But in the event of a bankruptcy, the bankrupt institution did not pay what it owed back to the solvent parties, while they had to pay their dues to the failed bank. This was later changed, when cheques were deemed void if the bankrupt institution doesn't have the funds to back them up, after the Cheques Act 1986 was amended in 1998. The Trade Practices Act 1974 generally does not allow competitors to make cooperative agreements, but if the Australian Competition and Consumer Commission (ACCC) is permitted to make exceptions for competitors making agreements among themselves. The ACCC and the Payments Systems Board are encouraged to work together regarding access and rivalry through the Payment Systems (Regulation) Act 1998.[4]\\r\\nMembers of the Payment Systems Board are defined by Section 25A of the Reserve Bank Act 1959, with three of the members being ex officio or representatives of another organisation. The governor of the Reserve Bank of Australia is the Chairman of the Payments System Board, there is one representative of the RBA, and there is one representative of the Australian Prudential Regulation Authority (APRA). In addition, there are up to five other members of the board that are appointed by the Treasurer for a term up to five years in length. They meet once per quarter, with five members forming a quorum, and one meeting per year is generally held in Melbourne, while the rest are held in Sydney. The Chairman is to meet with the Chairman of the ACCC at least once annually on issues of interest to both parties in the payments system, in addition to members of both organisations consulting over issues that are mutually important.[4]\\r\\nThe current members of the Payments System Board are:[4]\\r\\nThe governor of the Reserve Bank of Australia is the most senior position in the Reserve Bank of Australia. The governor of the Commonwealth Bank of Reserve Bank of Australia was both an ex officio member of the Notes Board from 1920 to 1924 and of the eight directors of the Commonwealth Bank from 1924 to 1945. The Commonwealth Bank and Bank Acts in 1945 clearly stated the governor's responsibilities of managing the bank. In 1951, legislation established a 10-member board which the governor is a member of. The bank has maintained a similar structure ever since the 1951 legislation.[2]\\r\\nThe governor is required by the Reserve Bank Act 1959 to keep in contact with the Secretary on matters concerning both the Treasury and Reserve Bank and vice versa. It is also mandated that the board inform the government of the bank's monetary and banking policy, which is often accomplished through the governor's meetings with the Treasurer. Since 1996, the governor and other senior members of the bank have appeared twice annually before the House of Representatives Standing Committee on Economics to explain the conduct of the bank.[11] The Reserve Bank governor is appointed to a term of up to seven years by the Treasurer and are eligible to be reappointed at the end of their term.[6] The governor is the chairman of both the Payment Systems Board and the Reserve Bank Board and therefore resolves any disputes that occur between the two entities.[4]\\r\\nThe longest-serving governor, if his service to both the Commonwealth Bank and the Reserve Bank of Australia are included, is H.C. Coombs, who served nineteen years and six months combined.[9] He is regarded by some as one of the most committed anti-inflationists in government throughout the 1950s and 1960s.[7] The longest-serving Commonwealth Bank governor is Sir Ernest Riddle, who served eleven years and four months, while the longest-serving Reserve Bank governor is Ian Macfarlane, who served ten years. The shortest-serving governor by many years is James Kell, who served 2 years for the Commonwealth Bank.[9]","input":"When was the reserve bank of australia established?"},{"output":"26 May 1967","context":"","input":"When was sgt pepper released in the uk?"},{"output":"George Hotz","context":"George Francis Hotz (born October 2, 1989), alias geohot, is an American hacker and creative consumer known for unlocking the iPhone, allowing the phone to be used with other wireless carriers, contrary to AT&T's and Apple's intentions.[1][2] He developed the limera1n jailbreak tool and bootrom exploit for iOS. He is also noted for his technical efforts and publicity with reverse engineering the PlayStation 3 video game console, and for subsequently being sued by and settling with Sony. As of September 2015, he is working on his vehicle automation machine learning company comma.ai.[3]\\r\\n\\r\\n\\r\\nHe attended the Bergen County Academies, a magnet public high school in Hackensack, New Jersey. He attended Academy for Engineering and Design Technology.[4] Hotz is an alumnus of the Johns Hopkins Center for Talented Youth program.[5] Hotz also briefly attended Rochester Institute of Technology[6] and Carnegie Mellon University.\\r\\nIn August 2007, seventeen-year-old George Hotz became the first person reported to carrier-unlock an iPhone.[7][8][9][10] According to Hotz's blog, he traded his second unlocked 8 GB iPhone to Terry Daidone, the founder of Certicell, for a Nissan 350Z and three 8 GB iPhones.[11]\\r\\nIn September 2007, an anonymous group achieved a software-only unlocking method to complement Hotz's hardware-based unlocking method.[12]\\r\\nOn July 13, 2010, Hotz announced the discontinuation of his jailbreaking activities, citing demotivation over the technology and the unwanted personal attention.[13] Nevertheless, he continued to release new software-based jailbreak techniques until October 2010.[14]\\r\\nIn December 2009, Hotz announced his initial intentions to breach security on the Sony PlayStation 3. Five weeks later, on January 22, 2010, he announced that he had performed his first theoretical achievement. This consists of the initial read and write access to the machine's system memory as well as hypervisor level access to the machine's CPU.[15]\\r\\nOn January 26, 2010, Hotz released the exploit to the public. On March 28, 2010, Sony responded by announcing their intention to release a PlayStation 3 firmware update that would remove the OtherOS feature from all models,[16] a feature that was already absent on the newer Slim revisions of the machine.[citation needed]\\r\\nOn July 13, 2010, never having achieved any method of reading, installing, or modifying software on the PS3, Hotz posted a message on his Twitter account stating that he had abandoned his efforts of trying to crack the PS3 any further due to the system security's extreme difficulty.[17]\\r\\nOn December 29, 2010, notable hacking group fail0verflow, known for the reverse engineering of security models found in consumer electronics devices, performed an academic presentation at the 27th Chaos Communications Congress technical conference, of their accomplishments with the PlayStation 3. They presented the methods they'd devised for having successfully penetrated the device's security model, yielding the root signing and encryption keys. These keys are the essential element of a full (and even minimally usable) breach, capable of installing and running any new software on any PlayStation 3 unit.[18][19]\\r\\nOn January 2, 2011, Hotz posted a copy of the root keys of the PlayStation 3 on his website.[20] These keys were later removed from his website as a result of legal action by Sony against fail0verflow and Hotz. In response to his continued publication of PS3 exploit information, Sony filed on January 11, 2011 for an application for a temporary restraining order (TRO) against him in the US District Court of Northern California.[21] On January 14, 2011, Hotz appeared in an interview on G4's The Loop, where he explained his involvement with the PlayStation 3.[22][23]\\r\\nAfter the root keys of the console were published, Sony initiated litigation against George Hotz and predecessor PlayStation 3 hacking group known as fail0verflow. Hotz published his commentary on the case, including a song about the \\"disaster\\" of Sony.[24] Sony in turn has demanded social media sites, including YouTube, to hand over IP addresses of people who visited Geohot's social pages and videos; the latter being the case only for those who \\"watched the video and 'documents reproducing all records or usernames and IP addresses that have posted or published comments in response to the video\\".[25]\\r\\nPayPal has granted Sony access to Geohot's PayPal account,[26] and the judge of the case granted Sony permission to view the IP addresses of everyone who visited geohot.com. In April 2011, it was revealed that Sony and Hotz had settled the lawsuit out of court, on the condition that Hotz would never again resume any hacking work on Sony products.[27]\\r\\nAt the end of April 2011, an anonymous hacker broke into the PlayStation Network and stole personal information of some 77 million users. Hotz denied any responsibility for the attack, and said \\"Running homebrew and exploring security on your devices is cool; hacking into someone else's server and stealing databases of user info is not cool\\".[25]\\r\\nIn June 2014, Hotz[28] published a root exploit software hack for Samsung Galaxy S5 devices used in the US market.[29] The exploit is itself built around Linux kernel CVE-2014-3153,[30][31] which was discovered by hacker Pinkie Pie, and it involves an issue in the Futex subsystem that in turn allows for privilege escalation. The exploit, known as towelroot, was designated a \\"one-click Android rooting tool\\"[31] by the hacking community because it was designed to be installed quickly like an App; other rooting hacks were typically uploaded from a nearby PC with a cable and necessitated rebooting the device with a special set of key presses.\\r\\nAlthough originally released for the Verizon Galaxy S5, the root exploit was made compatible with most Android devices available at that time. For example, it was tested and found to work with the AT&T Galaxy S5, Nexus 5, and Galaxy S4 Active. Updates continued to be applied to the root exploit to increase its capabilities with other devices running Android.[32] Updates to the Android operating system closed the source of the exploit. Samsung officially responded to the towelroot exploit by releasing updated software designed to be immune from the exploit.[33]\\r\\nIn addition to having made a meaningful side income from public donations solicited for his exploits,[8] Hotz has been employed at Facebook and Google.\\r\\nOn June 27, 2011, ZDNet freelance reporter, Emil Protalinski reported that according to a Facebook spokesman, Hotz had been hired by the company in an unknown role.[34] However, according to a CNET article, he had actually been employed since May, which was confirmed by Facebook.[35] In January 2012, Hotz was no longer employed by Facebook.[8][36]\\r\\nOn July 16, 2014, Google hired Hotz to work in their software security auditing team called Project Zero, which \\"hopes to find zero-day vulnerabilities before the NSA\\".[37] Hotz worked in Project Zero for 5 months where he developed Qira - an open source program for dynamically analysing application binaries.[citation needed]\\r\\nIn January 2015, Vicarious.com hired Hotz to develop AI algorithms where he worked for 7 months.[citation needed]\\r\\nSince September 2015, Hotz has been working on his own AI startup called comma.ai.[38] In an interview with Bloomberg, Hotz revealed he is building vehicular automation technology based on artificial intelligence algorithms. Hotz has built a working self-driving 2016 Acura ILX, which he demonstrated on the I-280 in a video.[3] The video prompted a cease and desist letter from the California Department of Motor Vehicles.[39] Hotz wants to sell his technology to Tesla Motors and he has reported to have talked to CEO Elon Musk and is working on proving his technology to be superior to that of Mobileye, which, at the time, was used for Tesla Autopilot.[3][3] [40][41] Hotz claims that Musk offered him $12 million (minus $1 million for every month it took Hotz to work on the task) to create a driving system that could replace the MobilEye solution currently used in Tesla vehicles.[42] Tesla later released a statement on their website citing corrections to the Bloomberg article, stressing that their autopilot system was developed in-house, with a vision chip component from MobilEye, instead of one separate autopilot system manufactured by MobilEye, as suggested by Hotz in the interview with Bloomberg.[40] Tesla CEO Elon Musk offered advice on Hotz's self-driving car project in a December 2015 interview.[43]\\r\\nOn October 27, 2016, the NHTSA informed Hotz that this product was legally required to comply with Federal Motor Vehicle Safety Standards, and requested information that would confirm such compliance.[44] A day later, George Hotz tweeted from Shenzhen that the comma one was cancelled.[45] Kristen Lee stated on Jalopnik that the NHTSA was simply trying to open a dialog, and commented that \\"Instead, they got the worst attitude possible from Silicon Valley: try and regulate us, thought leaders, and well take our ball and go home.\\"[46]\\r\\ncomma.ai open sourced their self driving car software on November 30, 2016, emphasising its intended use for research without any warranty.[47]\\r\\nHotz was a finalist at the 2004 ISEF competition in Portland, Oregon with his project \\"The Mapping Robot\\". Recognition included interviews on the Today Show and Larry King.[48] Hotz was a finalist at the 2005 ISEF competition, with his project \\"The Googler\\".[49] Continuing with robots, Hotz competed in his school's highly successful Titanium Knights battlebots team.\\r\\nHotz competed in the 2007 Intel International Science and Engineering Fair, a science competition for high school students, where his 3D imaging project, entitled \\"I want a Holodeck\\", received awards and prizes in several categories including a $20,000 Intel scholarship.[50] He travelled to Sweden to speak about the project at the Stockholm International Youth Science Seminar.[51]\\r\\nHotz has received considerable attention in mainstream media, including interviews on the Today Show, Fox, CNN, NBC, CBS, G4, ABC,[52] CNBC,[2] and articles in several magazines, newspapers, and websites, including Forbes,[53] and BBC.[54]\\r\\nIn March 2008, PC World magazine listed Hotz as one of the top 10 Overachievers under 21.[55]\\r\\nIn August 2013, Hotz attended DEF CON with Carnegie Mellon's Plaid Parliament of Pwning (PPP). PPP placed first in the DEF CON Capture the Flag (CTF) tournament.[56] Later in 2013, Hotz also competed in CSAW 2013. Working alone, Hotz took first place under the pseudonym tomcr00se.[57]\\r\\nIn August 2014, Hotz once again competed as part of the eight person team making up Carnegie Mellon's Plaid Parliament of Pwning (PPP) at DEF CON. PPP won the DEF CON CTF tournament for a second year in a row and also placed first in the DEF CON \\"Crack Me If You Can\\" tournament.[58]","input":"Who was the first person to unlock iphone?"},{"output":"Texas","context":"Brooklyn and Bailey McKnight (born December 31, 1999)[1] are American social media entertainers, musicians, and entrepreneurs. They are twin sisters.\\r\\n\\r\\nThe Texas-based identical twins originally surfaced on YouTube in 2009 as models for their mother Mindy McKnights DIY channel \\"Cute Girls Hairstyles\\", a video series of hair design tutorials.[2]\\r\\n\\r\\nIn 2013 the twins launched their own YouTube channel, Brooklyn and Bailey, with a focus on teen interests, fashion, beauty, and \\"all things fun\\".[3]\\r\\n\\r\\nIn 2015 the twins were listed by Business Insider as one of \\"13 up-and-coming YouTube stars you should be following\\",[4] and their YouTube channel was nominated for a Streamy Award in the Fashion category.[5]\\r\\n\\r\\nIn November 2015, the sisters launched Squared, a YouTube channel and daily web series described by Variety as being \\"dedicated to all things twins\\".[2] Seven sets of twins from North America, the UK, and Australia contribute episodes to the series.[6]\\r\\n\\r\\nIn early 2017, Brooklyn and Bailey announced their entrance into the music industry.[7] The pair partnered with music producer Benny Cassette, and their first track, Dance Like Me\\", debuted March 3, 2017.[8] The track charted at #26 for most popular song and #12 for pop US song on iTunes. On April 28, 2017, the twins released their second single, \\"Simple Things\\". They released their third song \\"What We're Made Of\\" July 13, 2017. Brooklyn and Bailey had previously collaborated with Peter Hollens for a cover of Lennon and Maisy's \\"A Life That's Good\\" in August 2015.[9]\\r\\n\\r\\nIn 2017 the twins also launched their own merchandise line,[10] and they were on Forbes list of Top Influencers ÿ Kids.[11][12][13] In 2018 they were finalists in the YouTube Musician category for the 10th annual Shorty Awards.[14][15][16][17]\\r\\n\\r\\nIn April 2018, they both announced that they were going to attend Baylor University in Waco, Texas.[18]","input":"What state do brooklyn and bailey live in?"},{"output":"22 December 609 CE","context":"","input":"When was the first part of the quran first revealed?"},{"output":"June 1348","context":"The Black Death was a pneumonic plague pandemic, which reached England in June 1348. It was the first and most severe manifestation of the Second Pandemic, caused by Yersinia pestis bacteria. The term \\"Black Death\\" was not used until the late 17th century.\\r\\nOriginating in China, it spread west along the trade routes across Europe and arrived on the British Isles from the English province of Gascony. The plague seems to have been spread by flea-infected rats, as well as individuals who had been infected on the continent. Rats were the reservoir hosts of the Y. pestis bacteria and the Oriental rat flea was the primary vector.\\r\\nThe first known case in England was a seaman who arrived at Weymouth, Dorset, from Gascony in June 1348.[1] By autumn, the plague had reached London, and by summer 1349 it covered the entire country, before dying down by December. Low estimates of mortality in the early twentieth century have been revised upwards due to re-examination of data and new information, and a figure of 40ÿ60% of the population is widely accepted.\\r\\nThe English government handled the crisis well, and the country did not experience the extreme reactions that were seen elsewhere in Europe. The most immediate consequence was a halt to the campaigns of the Hundred Years' War. In the long term, the decrease in population caused a shortage of labour, with subsequent rise in wages, resisted by the landowners, which caused deep resentment among the lower classes. The Peasants' Revolt of 1381 was largely a result of this resentment, and even though the rebellion was suppressed, in the long term serfdom was ended in England. The Black Death also affected artistic and cultural efforts, and may have helped advance the use of the vernacular.\\r\\nIn 1361ÿ62 the plague returned to England, this time causing the death of around 20% of the population. After this the plague continued to return intermittently throughout the 14th and 15th centuries, in local or national outbreaks. From this point on its effect became less severe, and one of the last outbreaks of the plague in England was the Great Plague of London in 1665ÿ66.\\r\\n\\r\\n\\r\\nIt is impossible to establish with any certainty the exact number of inhabitants in England at the eve of the Black Death, and estimates range from 3 to 7 million.[2] The number is probably in the higher end, and an estimate of around 6 million inhabitants seems likely.[3] Earlier demographic crises ? in particular the Great Famine of 1315ÿ1317 ? had resulted in great numbers of deaths, but there is no evidence of any significant decrease in the population prior to 1348.[4] England was still a predominantly rural and agrarian society; close to 90% of the population lived on the countryside.[5] Of the major cities, London was in a class of its own, with perhaps as many as 70,000 inhabitants.[6] Further down the scale were Norwich, with around 12,000 people, and York with around 10,000.[5] The main export, and the source of the nation's wealth, was wool. Until the middle of the century the export had consisted primarily of raw wool to cloth makers in Flanders. Gradually though, the technology for cloth making used on the Continent was appropriated by English manufacturers, who started an export of cloths around mid-century that would boom over the following decades.[7]\\r\\nPolitically, the kingdom was evolving into a major European power, through the youthful and energetic kingship of Edward III.[8] In 1346, the English had won a decisive battle over the Scots at the Battle of Neville's Cross,[9] and it seemed that Edward III would realise his grandfather Edward I's ambition of bringing the Scots under the suzerainty of the English crown.[10] The English were also experiencing military success on the continent. Less than two months before the Battle of Neville's Cross, a numerically inferior English army led by the king himself won a spectacular victory over the French royal forces at the Battle of Crcy.[11] The victory was immediately followed by Edward laying siege to the port city of Calais. When the city fell the next year, this provided the English with a strategically important enclave that would remain in their possession for over two centuries.[12]\\r\\nThe term \\"Black Death\\"?ÿ  which refers to the first and most serious outbreak of the Second Pandemic?ÿ  was not used by contemporaries, who preferred such names as the \\"Great Pestilence\\" or the \\"Great Mortality\\".[13] It was not until the seventeenth century that the term under which we know the outbreak today became common , probably derived from Scandinavian languages.[14] It is generally agreed today that the disease in question was plague, caused by Yersinia pestis bacteria.[15] These bacteria are carried by fleas, which can be transferred to humans through contact with rats. Flea bites carry the disease into the lymphatic system, through which it makes its way to the lymph nodes. Here the bacteria multiply and form swellings called buboes, from which the term bubonic plague is derived.[16] After three or four days the bacteria enter the bloodstream, and infect organs such as the spleen and the lungs. The patient will then normally die after a few days.[17] A different strain of the disease is pneumonic plague, where the bacteria become airborne and enter directly into the patient's lungs. This strain is far more virulent, as it spreads directly from person to person. These types of infection probably both played a significant part in the Black Death, while a third strain was more rare. This is the septicaemic plague, where the flea bite carries the bacteria directly into the blood stream, and death occurs very rapidly.[18]\\r\\nA study reported in 2011 of skeletons exhumed from the \\"Black Death\\" cemetery in East Smithfield London found Yersina Pestis DNA. An archeological dig in the vicinity of Thornton Abbey in Lincolnshire was reported in the science section of The Guardian for Nov.30 2016 not only confirming evidence of Yersina Pestis in the DNA of the human remains exhumed there but dating it to mid-1349.\\r\\nGenotyping showed that it was [at that time] a newly evolved strain, ancestor of all modern strains and proved the \\"Black Death\\" was caused by bubonic plague. Modern medical knowledge would suggest that because it was a new mutation meant immune systems would have had little or no defence against it, which helps to explain its virulence.[19]\\r\\nThe \\"Black Death\\" seems to have originated in Central Asia, where Yersina Pestis bacterium is endemic in the rodent population. It is unknown exactly what caused the outbreak, but a series of natural occurrences likely brought humans into contact with the infected rodents.[20] The epidemic reached Constantinople in the late spring of 1347, through Genoese merchants trading in the Black Sea.[21] From here it reached Sicily in October that same year, and by early 1348 it had spread all over the Italian mainland.[22] It spread rapidly through France, and had reached as far north as Paris in June 1348. Moving simultaneously westward, it arrived in the English province of Gascony around the same time.[23]\\r\\nAccording to the chronicle of the grey friars at King's Lynn, the plague arrived by ship from Gascony to Melcombe in Dorset?ÿ  today normally referred to as Weymouth?ÿ  shortly before \\"the Feast of St. John The Baptist\\" on 24 June 1348.[25] Other sources mention different points of arrival, including Bristol and Southampton.[26] Though the plague might have arrived independently at Bristol at a later point, the Grey Friars' Chronicle is considered the most authoritative account.[27] If it is assumed that the chronicle reports the first outbreak of the plague, rather than its actual arrival, then the arrival most likely happened around 8 May.[28]\\r\\nFrom Weymouth the disease spread rapidly across the south-west. The first major city to be struck was Bristol.[29] London was reached in the autumn of 1348, before most of the surrounding countryside. This had certainly happened by November, though according to some accounts as early as 29 September.[30] Arrival in London happened by three principal roads: overland from Weymouth?ÿ  through Salisbury and Winchester?ÿ  overland from Gloucester, and along the coast by ship.[31] The full effect of the plague was felt in the capital early the next year.[32] Conditions in London were ideal for the plague: the streets were narrow and flowing with sewage, and houses were overcrowded and poorly ventilated.[33] By March 1349 the disease was spreading in a haphazard way across all of southern England.[34]\\r\\nDuring the first half of 1349 the Black Death spread northwards. A second front opened up when the plague arrived by ship at the Humber, wherefrom it spread both south and north.[35] In May it reached York, and during the summer months of June, July and August, it ravaged the north.[36] Certain northern counties, like Durham and Cumberland, had been the victim of violent incursions from the Scots, and were therefore left particularly vulnerable to the devastations of the plague.[37] Pestilence is less virulent during the winter months, and spreads less rapidly.[38] The Black Death in England had survived the winter of 1348ÿ49, but during the following winter it gave in, and by December 1349 conditions were returning to relative normalcy.[39] It had taken the disease approximately 500 days to traverse the entire country.[40]\\r\\nIn order to treat patients infected with the plague, various methods were used including sweating, bloodletting, forced vomiting, and urinating.[41] Several symptoms of the illness included blotches, hardening of the glands under the groin and underarms, and dementia.[42] Within the initial phase of the disease, bloodletting was performed on the same side of where the physical manifestations of the buboes or risings appeared. For instance, if a rising appeared on the right side of the groin the physician would bleed a vein in the ankle on the same side.[43] In the case of sweating, it was achieved with such medicines as Mithridate, Venice-Treacle, Matthiolus, Bezoar-Water, Serpentary Roots and Electuarium de Ovo.[44] Sweating was used when measures were desperate; if a patient had tokens, a severe version of risings, the physician would wrap the naked patient in a blanket drenched in cold water. This measure was only performed while the patient still had natural heat in his system. The desired effect was to make the patient sweat violently and thus purge all corruption from the blood which was caused by the disease.[45]\\r\\nAnother practice was the use of pigeons when treating swellings. Swellings which were white in appearance and deep were unlikely to break and must be anointed with Oil of Lillies or Camomil.[46] Once the swelling rises to a head and is red in appearance and not deep in the flesh, it can be broken with the use of a feather from a young pigeon's tail. The feather's fundament was held to the swelling and would draw out the venom. However, if the swelling dropped and became black in appearance since it had taken in coldness, the physician had to be cautious when drawing the cold from the swelling. If it was too late to prevent, the physician would take the young pigeon, cut her open from breast to back, break her open and apply the pigeon (while still alive) over the cold swelling. The cupping therapy was an alternative method which was heated and then placed over the swellings. Once the sore was broken, the physician would apply Mellilot Plaister with Linimentum Arcei and heal the sore with digence.[47]\\r\\nAlthough historical records for England were more extensive than those of any other European country,[48] it is still extremely difficult to establish the death toll with any degree of certainty. Difficulties involve uncertainty about the size of the total population, as described above, but also issues regarding the proportion of the population that died from the plague. Contemporary accounts are often grossly inflated, stating numbers as high as 90%.[49] Modern historians give estimates of death rates ranging from around 25% to over 60% of the total population.\\r\\nThe pioneering work in the field was made by Josiah William Russell in his 1948 British Medieval Population. Russell looked at inquisitions post mortem (IPMs)?ÿ  taken by the crown to assess the wealth of the greatest landowners after their death?ÿ  to assess the mortality caused by the Black Death, and from this arrived at an estimate of 23.6% of the entire population.[50] He also looked at episcopal registers for the death toll among the clergy, where the result was between 30ÿ40%.[51] Russell believed the clergy was at particular risk of contagion, and eventually concluded with a low mortality level of only 20%.[52]\\r\\nSeveral of Russell's assumptions have been challenged, and the tendency since has been to adjust the assessment upwards.[53] Philip Ziegler, in 1969, estimated the death rate to be at around one third of the population.[54] Jeremy Goldberg, in 1996, believed a number closer to 45% would be more realistic.[55] A 2004 study by Ole J?rgen Benedictow suggests the exceptionally high mortality level of 62.5%.[56] Assuming a population of 6 million, this estimate would correspond to 3,750,000 deaths. Such a high percentage would place England above the average that Benedictow estimates for Western Europe as a whole, of 60%.[56] A death rate at such a high level has not been universally accepted in the historical community.[57]\\r\\nIn 2016, Carenza Lewis reported the results of a new method of assessing the death toll. She argues that pottery before and after the Black Death is datable because there was a change at that time from the high medieval to the late medieval style, and that counts of pottery of each type therefore provide a useful proxy for long term changes in population. She and her colleagues analysed pottery sherds from test pits in over fifty continuously occupied rural settlements in eastern England, and found a decline in the number of pottery producing pits of 45%. Norfolk had the greatest drop of 65%, while there was no drop in 10% of settlements, mostly commercial centres.[58]\\r\\nArchbishop Zouche of York issued a warning throughout the diocese in July 1348 (when the epidemic was raging further south) of great mortalities, pestilences and infections of the air.\\r\\nThe Great Mortality, as it was then known, entered Yorkshire around February 1349 and quickly spread through the diocese. The clergy were on the front line of the disease, bringing comfort to the dying, hearing final confessions and organising burials. This, almost by necessity, put them at a greater risk of infection.\\r\\nEstimates suggest that the death rate of clergy in some parts of the archdiocese could have been as high as 48%. This is reflected in the Ordination Register, which shows a massive rise in ordained clergy over the period ÿ some being recruited before the arrival of plague in a clerical recruitment drive, but many once plague had arrived, replacing those who had been killed. The nation's population decreased by a third causing a labor shortage and giving the lower class negotiating power against their overlords.[59] In 1346, 111 priests and 337 acolytes were recruited. In 1349, 299 priests and 683 acolytes are named, with 166 priests being ordained in one session alone in February 1350.[60]\\r\\nRussell trusted the IPMs to give a true picture of the national average, because he assumed death rates to be relatively equal across the social spectrum.[61] This assumption has later been proven wrong, and studies of peasant plague mortality from manor rolls have returned much higher rates. This could be a consequence of the elite's ability to avoid infection by escaping plague-infected areas. It could also result from lower post-infection mortality among those more affluent, due to better access to care and nursing.[62] If so, this would also mean that the mortality rates for the clergy?ÿ  who were normally better off than the general population?ÿ  were no higher than the average.[63]\\r\\nThe manorial records offer a good opportunity to study the geographical distribution of the plague. Its effect seems to have been about the same all over England,[65] though a place like East Anglia, which had frequent contact with the Continent, was severely affected.[66] On a local level, however, there were great variations. A study of the Bishop of Worcester's estates reveal that, while his manors of Hartlebury and Hambury had a mortality of only 19%, the manor of Aston lost as much as 80% of its population.[67] The manor rolls are less useful for studying the demographic distribution of the mortality, since the rolls only record the heads of households, normally an adult male.[68] Here the IPMs show us that the most vulnerable to the disease were infants and the elderly.[69]\\r\\nThere seem to have been very few victims of the Black Death at higher levels of society.[70] The only member of the royal family who can be said with any certainty to have died from the Black Death was in France at the time of her infection. Edward III's daughter Joan was residing in Bordeaux on her way to marry Pedro of Castile in the summer of 1348. When the plague broke out in her household she was moved to a small village nearby, but she could not avoid infection, and died there on 2 September.[71] It is possible that the popular religious author Richard Rolle, who died on 30 September 1349, was another victim of the Black Death.[72] The English philosopher William of Ockham has been mentioned as a plague victim.[73] This, however, is an impossibility. Ockham was living in Munich at the time of his death, on 10 April 1347, two years before the Black Death reached that city.[74]\\r\\nAmong the most immediate consequences of the Black Death in England was a shortage of farm labour, and a corresponding rise in wages. The medieval world-view was unable to interpret these changes in terms of socio-economic development, and it became common to blame degrading morals instead.[75] The landowning classes saw the rise in wage levels as a sign of social upheaval and insubordination, and reacted with coercion. In 1349, King Edward III passed the Ordinance of Labourers, fixing wages at pre-plague levels. The ordinance was reinforced by Parliament's passing of the Statute of Labourers in 1351.[76] The labour laws were enforced with ruthless determination over the following decades.[77]\\r\\nThese legislative measures proved largely inefficient at regulating the market, but the government's repressive measures to enforce them caused public resentment.[78] These conditions were contributing factors to the Peasants' Revolt in 1381. The revolt started in Kent and Essex in late May, and once the rebels reached London they burnt down John of Gaunt's Savoy Palace, and killed both the Chancellor and the Treasurer. They then demanded the complete abolition of serfdom, and were not pacified until the young King Richard II personally intervened.[79] The rebellion was eventually suppressed, but the social changes it promoted were already irreversible. By around 1400 serfdom was virtually extinct in England, replaced by the form of tenure called copyhold.[80]\\r\\nIt is conspicuous how well the English government handled the crisis of the mid-fourteenth century, without descending into chaos and total collapse in the manner of the Valois government of France.[81] To a large extent this was the accomplishment of administrators such as Treasurer William de Shareshull and Chief Justice William Edington, whose highly competent leadership guided the governance of the nation through the crisis.[81] The plague's greatest effect on the government was probably in the field of war, where no major campaigns were launched in France until 1355.[82]\\r\\nAnother notable consequence of the Black Death was the raising of the real wage of England (due to the shortage of labour as a result of the reduction in population), a trait shared across Western Europe, which in general led to a real wage in 1450 that was unmatched in most countries until the 19th or 20th century.[83] The higher wages for workers combined with sinking prices on grain products led to a problematic economic situation for the gentry. As a result, they started to show an increased interest for offices like justice of the peace, sheriff and member of parliament. The gentry took advantage of their new positions and a more systematic corruption than before spread. A result of this was that the gentry as a group became highly disliked by commoners.[84]\\r\\nThe omnipresence of death also inspired greater piety in the upper classes, which can be seen in the fact that three Cambridge colleges were founded during or shortly after the Black Death.[85] England did not experience the same trend of roving bands of flagellants, common on the continent.[86] Neither were there any pogroms against the Jews, since the Jews had been expelled by Edward I in 1290.[86] In the long run, however, the increase in public participation may have served to challenge the absolute authority of the church hierarchy, and thus possibly helped pave the way for the Protestant Reformation.[citation needed]\\r\\nThe high rate of mortality among the clergy naturally led to a shortage of priests in many parts of the country.[72] The clergy were seen to have an elevated status among ordinary people and this was partly due to their closeness with God, being his envoys on earth. However, as the church itself had given the cause of the Black Death to be the impropriety of the behaviour of men, the higher death rate among the clergy led the people to lose faith in the Church as an institution ? it had proved as ineffectual against the horror of Y. Pestis as every other medieval institution. The corruption within the Catholic priesthood also angered the English people. Many priests abandoned the terrified people. Others sought benefits from the rich families who needed burials. The dissatisfaction led to anti-clericalism and the rise of John Wycliffe, an English priest. His ideas paved a path for the Christian reformation in England. Some people didn't lose their Christian faith, if anything it was renewed; they began to long for a more personal relationship with God ? around the time after the Black Death many chantries (private chapels) began to spread in use from not just the nobility, but to among the well to do.[87] This change in the power of the papacy in England is demonstrated by the statutes of Praemunire.\\r\\nThe Black Death also affected arts and culture significantly. It was inevitable that a catastrophe of such proportions would affect some of the greater building projects, as the amount of available labour fell sharply. The building of the cathedrals of Ely and Exeter was temporarily halted in the years immediately following the first outbreak of the plague.[88] The shortage of labour also helped advance the transition from the Decorated style of building to the less elaborate Perpendicular style.[89] The Black Death may also have promoted the use of vernacular English, as the number of teachers proficient in French dwindled. This, in turn, would have contributed to the late-fourteenth century flowering of English literature, represented by writers such as Geoffrey Chaucer and John Gower.[90]\\r\\nThe Black Death was the first occurrence of the Second Pandemic,[91] which would continue to strike England and the rest of Europe more or less regularly until the eighteenth century. The first serious recurrence in England came in the years 1361?62. We know less about the death rates caused by these later outbreaks,[92] but this so-called pestis secunda may have had a mortality of around 20%.[93] This epidemic was also particularly devastating for the population's ability to recover, since it disproportionately affected infants and young men.[94] This was also the case with the next occurrence, in 1369, where the death rate was around 10?15%.[93]\\r\\nOver the following decades the plague would return?ÿ  on a national or a regional level?ÿ  at intervals of five to twelve years, with gradually dwindling death tolls. Then, in the decades from 1430 to 1480, the disease returned in force. An outbreak in 1471 took as much as 10ÿ15% of the population, while the death rate of the plague of 1479ÿ80 could have been as high as 20%.[93] From this point on outbreaks became fewer and more manageable. This was to a large extent the result of conscious efforts by central and local governments?ÿ  from the late fifteenth century onwards?ÿ  to curtail the disease.[95] By the seventeenth century the Second Pandemic was over. One of its last occurrences in England was the famous Great Plague of London in 1665ÿ66.[96]","input":"When did the black plague start in england?"},{"output":"\\"East Bay\\"","context":"","input":"What part of the bay area is oakland?"},{"output":"in the Edwards Plateau at the crossroads of West Texas, Central Texas, and South Texas","context":"\\r\\n\\r\\nThe Texas Hill Country is a geographic region located in the Edwards Plateau at the crossroads of West Texas, Central Texas, and South Texas. Given its location, climate, terrain, and vegetation, the Hill Country can be considered the border between the American Southwest and Southeast. \\r\\n\\r\\nThe region is notable for its karst topography and tall rugged hills of limestone or granite.[1] Many of the hills rise to a height of 400-500 feet above the surrounding plains and valleys, with Packsaddle Mountain rising to a height of 800 feet above the Llano River in Kingsland.[2] The Hill Country also includes the Llano Uplift and the second-largest granite dome in the United States, Enchanted Rock. The terrain throughout the region is punctuated by a thin layer of topsoil and a large number of exposed rocks and boulders, making the region very dry and prone to flash flooding. Native vegetation in the region includes various yucca, prickly pear cactus, desert spoon, and wildflowers in the Llano Uplift. The predominant trees in the region are ashe juniper and Texas live oak.[3]\\r\\n\\r\\nBound on the east by the Balcones Escarpment, the Hill Country reaches into the far northern portions of San Antonio and the western portions of Austin. As a result of springs discharging water stored in the Edwards Aquifer, several cities such as Austin, San Marcos, and New Braunfels were settled at the base of the Balcones Escarpment. The region's economy is one of the fastest growing in the United States.[4][5]\\r\\n\\r\\nAccording to the Texas Parks and Wildlife Department, the following 25 counties are included in the Hill Country Wildlife District:[6]\\r\\n\\r\\nDuring the American Civil War, due to its large, pro-Union, German immigrant population, the Texas Hill Country was opposed to Texas seceding from the Union.[7] Subsequently, in the three quarters of a century following Reconstruction, the core of the Hill Country generally provided the solitary support base for the Republican Party in what became a one-party Democratic state.\\r\\n\\r\\nEven when there were no Republicans in the Texas Legislature during the 1930s and 1940s, Gillespie and Kendall Counties backed every Republican Presidential nominee barring Herbert Hoovers failed 1932 re-election campaign, and Republicans continued to control local government. Guadalupe and Comal Counties were less Republican, but still did not vote for Democratic nominees outside the 1912, 1932, 1936 and 1964 landslides. The region was also the only one in antebellum slave states to back the insurgent candidacy of Robert La Follette in 1924: in fact Comal was La Follettes top county in the nation with 73.96 percent of the vote, and it and Gillespie were the only counties south of the Mason-Dixon Line to give a plurality to his Progressive ticket.\\r\\n\\r\\nBecause of its karst topography, the area also features a number of caverns, such as Inner Space Caverns, Natural Bridge Caverns, Bracken Cave, Longhorn Cavern State Park, Cascade Caverns, Caverns of Sonora and Cave Without a Name. The deeper caverns of the area form several aquifers which serve as a source of drinking water for the residents of the area. Wonder Cave in San Marcos was formed by an earthquake along the Balcones Fault.\\r\\n\\r\\nSeveral tributaries of the Colorado River of Texas  including the Llano and Pedernales rivers, which cross the region west to east and join the Colorado as it cuts across the region to the southeast ÿ drain a large portion of the Hill Country. The Guadalupe, San Antonio, Frio, Medina, and Nueces rivers originate in the Hill Country.\\r\\n\\r\\nThis region is a dividing line for certain species occurrence. For example, the California Fan Palm (Washingtonia filifera) is the only species of palm tree that is native to the continental United States west of the Hill Country's Balcones Fault.[8]\\r\\n\\r\\nThe region has hot summers, particularly in July and August, and even the nighttime temperatures remain high, as the elevation is modest despite the hilly terrain. Winter temperatures are sometimes[specify] as much as ten degrees cooler than in other parts of Texas to the east.[citation needed]\\r\\n\\r\\nAs seen from near Interstate 10\\r\\n\\r\\nView of the Texas Hill Country, from Garner State Park, located in Uvalde County\\r\\n\\r\\nAnother scene from near Garner State Park\\r\\n\\r\\nWindmill in the Hill Country\\r\\n\\r\\nHouse atop hill in Texas Hill Country north of Bandera\\r\\n\\r\\nA view of the Texas Hill Country from a rural road in Hays County\\r\\n\\r\\nThe area is also unique[citation needed] for its fusion of Spanish and German influences in food, beer, architecture, and music that form a distinctively \\"Texan\\" culture separate from the state's Southern and Southwestern influences.[1] For example, the accordion was popularized in Tejano music in the 19th century due to cultural exposure to German settlers.\\r\\n\\r\\nDevil's Backbone appeared in a 1996 episode of NBC's Robert Stack anthology series Unsolved Mysteries, featuring ghosts of Spanish monks, Comanche as well as Lipan Apache Native Americans, Confederate soldiers on their horses, and a spirit of a wolf. It later re-aired when this series was hosted by Dennis Farina.\\r\\n\\r\\nThe region has emerged as the center of the Texas wine industry.[citation needed] Three American Viticultural Areas are located in the areas: Texas Hill Country AVA, Fredericksburg in the Texas Hill Country AVA, and Bell Mountain AVA.\\r\\n\\r\\nThe Hill Country is also known for its tourism. In 2008, The New York Times listed the Hill Country in an article about North American vacation destinations.[9] Hill Country has also made Texas second to Florida as the most popular retirement destination in the United States. The region has attracted Baby Boomers as they near retirement age.[10]\\r\\n\\r\\nFrederick Day, a demographer with Texas State University, said that the Hill Country life-style reminds one of the small towns of the recent past. \\"Like old America . . . [the] cost of living is pretty low. To people who have spent their work life in Houston or Dallas, the Hill Country is very attractive.\\"[10]","input":"What part of texas is the hill country?"},{"output":"poet Muhammad Iqbal","context":"Sare Jahan se Accha (Urdu: ???? ???? ?? ?????; Sre Jahn? se Acch), formally known as Tarnah-i-Hindi (Urdu: ????? ?????; Anthem of the People of India), is an Urdu language patriotic song written for children by poet Muhammad Iqbal in the ghazal style of Urdu poetry.[a] The poem was published in the weekly journal Ittehad on 16 August 1904.[1] Publicly recited by Iqbal the following year at Government College, Lahore, British India (now in Pakistan) it quickly became an anthem of opposition to the British Raj. The song, an ode to Hindustanthe land comprising present-day Bangladesh, India and Pakistan, was later published in 1924 in the Urdu book Bang-i-Dara.[2]\\r\\nThe song has remained popular, especially in India. An abridged version is sung and played frequently as a patriotic song and as a marching song of the Indian Armed Forces. A satirical version of the same from a 1958 Hindi movie also remains popular.[3]\\r\\n\\r\\n\\r\\nIqbal was a lecturer at the Government College, Lahore at that time, and was invited by a student Lala Har Dayal to preside over a function. Instead of delivering a speech, Iqbal sang Saare Jahan Se Achcha. The song, in addition to embodying yearning and attachment to the land of Hindustan, expressed \\"cultural memory\\" and had an elegiac quality. In 1905, the 27-year-old Iqbal viewed the future society of the subcontinent as both a pluralistic and composite Hindu-Muslim culture. Later that year he left for Europe for a three-year sojourn that was to transform him into an Islamic philosopher and a visionary of a future Islamic society.[2]\\r\\nIn 1910, Iqbal wrote another song for children, Tarana-e-Milli (Anthem of the Religious Community), which was composed in the same metre and rhyme scheme as Saare Jahan Se Achcha, but which renounced much of the sentiment of the earlier song.[4] The sixth stanza of Saare Jahan Se Achcha (1904), which is often quoted as proof of Iqbal's secular outlook:\\r\\nMaz?hab nahؐn? sikht pas men? bair rakhn\\r\\nHindؐ hain? ham, wat?an hai Hindstn? hamr\\r\\nReligion does not teach us to bear ill-will among ourselves\\r\\nWe are of Hind, our homeland is Hindustan.\\r\\ncontrasted significantly with the first stanza of Tarana-e-Milli (1910) reads:[4]\\r\\nCؐn o-?Arab hamr, Hindstn? hamr\\r\\nMuslim hain? ham, wat?an hai sr jahn? hamr\\r\\nCentral Asia[5] and Arabia are ours, Hindustan is ours\\r\\nWe are Muslims, the whole world is our homeland.[4]\\r\\nIqbal's world view had now changed; it had become both global and Islamic. Instead of singing of Hindustan, \\"our homeland,\\" the new song proclaimed that \\"our homeland is the whole world.\\"[6] Two decades later, in his presidential address to the Muslim League annual conference in Allahabad in 1930, he supported a separate nation-state in the Muslim majority areas of the sub-continent, an idea that inspired the creation of Pakistan.[7]\\r\\n???? ???? ?? ???? ???????? ?????\\r\\n?? ?????? ??? ?? ??? ?? ?????? ?????\\r\\n???? ??? ??? ??? ??? ???? ?? ?? ??? ???\\r\\n????? ???? ???? ??? ?? ?? ???? ?????\\r\\n???? ?? ?? ?? ?????? ?????? ????? ??\\r\\n?? ????? ?????? ?? ?????? ?????\\r\\n???? ??? ?????? ??? ?? ?? ?????? ?????\\r\\n???? ?? ?? ?? ?? ?? ???? ???? ?????\\r\\n?? ??? ???? ????! ?? ?? ??? ??? ??? ???\\r\\n???? ??? ????? ?? ?????? ?????\\r\\n???? ???? ?????? ??? ??? ??? ?????\\r\\n???? ??? ??? ??? ?? ???????? ?????\\r\\n????? ? ??? ? ???? ?? ?? ??? ???? ??\\r\\n?? ?? ??? ?? ???? ??? ? ???? ?????\\r\\n??? ??? ?? ?? ???? ???? ???? ?????\\r\\n????? ??? ?? ???? ???? ???? ?????\\r\\n?????! ???? ???? ???? ???? ???? ???\\r\\n????? ??? ??? ?? ???? ???? ?????!?\\r\\n???? ???? ?? ????? ??????????? ?????\\r\\n?? ???????? ??? ???? ?? ???????? ?????\\r\\n??????? ??? ??? ??? ??, ???? ?? ??? ??? ???\\r\\n???? ???? ???? ?? ??? ?? ???? ?????\\r\\n???? ?? ???? ????, ??????? ????? ??\\r\\n?? ????? ?????, ?? ?????? ?????\\r\\n???? ??? ????? ??? ???? ??????? ??????\\r\\n?????? ?? ????? ?? ?? ????-?-???? ?????\\r\\n? ??-?-???-?-????! ?? ??? ??? ??? ??????\\r\\n???? ???? ?????? ?? ?????? ?????\\r\\n?????? ???? ?????? ??? ??? ??? ????\\r\\n????? ??? ??, ??? ?? ??????????? ?????\\r\\n?????-?-?????-?-???? ?? ??? ?? ???? ??\\r\\n?? ?? ??? ?? ????? ???-?-????? ?????\\r\\n??? ??? ?? ?? ????? ????? ???? ?????\\r\\n?????? ??? ?? ?????? ???-?-????? ?????\\r\\n???????! ??? ???? ???? ???? ???? ???\\r\\n????? ???? ???? ?? ????-?-????? ?????!\\r\\nSre jahn? se acch, Hindositn?[8] hamr\\r\\nHam bulbulen? hain? is kؐ, yih gulsitn?[8] hamr\\r\\nG?h?urbat men? hon? agar ham, raht hai dil wat?an men?\\r\\nSamjho wuhؐn? hamen? bhؐ dil ho jahn? hamr\\r\\nParbat wuh sab se n?ch, hamsyah smn? k\\r\\nWuh santarؐ hamr, wuh psbn? hamr\\r\\nGodؐ men? kheltؐ hain? is kؐ hazron? nadiyn?\\r\\nGuls?h?an hai jin ke dam se ras?h?k-i jann? hamr\\r\\nAi b-i rd-i Gang! wuh din hain? yd tujh ko?\\r\\nUtr tire[9] kinre jab krwn? hamr\\r\\nMaz?hab nahؐn? sikht pas men? bair rakhn\\r\\nHindؐ hain? ham, wat?an hai Hindositn? hamr\\r\\nYnn o-Mi?r o-Rm, sab mi? ga'e jahn? se\\r\\nAb tak magar hai bqؐ, nm o-nis?h?an? hamr\\r\\nKuch bt hai kih hastؐ, mi?tؐ nahؐn? hamrؐ\\r\\n?adiyon? rah hai dus?h?man daur-i zamn? hamr\\r\\nIqbl! ko'ؐ ma?ram apn nahؐn? jahn? men?\\r\\nMa?lm ky kisؐ ko dard-i nihn? hamr!\\r\\nBetter than the entire world, is our Hindustan,\\r\\nWe are its nightingales, and it (is) our garden abode\\r\\nIf we are in an alien place, the heart remains in the homeland,\\r\\nKnow us to be only there where our heart is.\\r\\nThat tallest mountain, that shade-sharer of the sky,\\r\\nIt (is) our sentry, it (is) our watchman\\r\\nIn its lap where frolic thousands of rivers,\\r\\nWhose vitality makes our garden the envy of Paradise.\\r\\nO the flowing waters of the Ganges, do you remember that day\\r\\nWhen our caravan first disembarked on your waterfront?\\r\\nReligion does not teach us to bear animosity among ourselves\\r\\nWe are of Hind, our homeland is Hindustan.\\r\\nIn a world in which ancient Greece, Egypt, and Rome have all vanished\\r\\nOur own attributes (name and sign) live on today.\\r\\nThere is something about our existence for it doesn't get wiped\\r\\nEven though, for centuries, the time-cycle of the world has been our enemy.\\r\\nIqbal! We have no confidant in this world\\r\\nWhat does any one know of our hidden pain?","input":"Who wrote saare jahan se achchca hindustan hamara?"},{"output":"February 2009","context":"\\r\\n\\r\\nThe American Recovery and Reinvestment Act of 2009 (ARRA) (Pub.L. 111ÿ5), nicknamed the Recovery Act, was a stimulus package enacted by the 111th U.S. Congress and signed into law by President Barack Obama in February 2009. Developed in response to the Great Recession, the ARRA's primary objective was to save existing jobs and create new ones as soon as possible. Other objectives were to provide temporary relief programs for those most affected by the recession and invest in infrastructure, education, health, and renewable energy.\\r\\n\\r\\nThe approximate cost of the economic stimulus package was estimated to be $787 billion at the time of passage, later revised to $831 billion between 2009 and 2019.[1] The ARRA's rationale was based on the Keynesian economic theory that, during recessions, the government should offset the decrease in private spending with an increase in public spending in order to save jobs and stop further economic deterioration. \\r\\n\\r\\nSince its inception, the impact of the stimulus has been a subject of disagreement. Studies on its effects have produced a range of conclusions, from strongly positive to strongly negative and all reactions in between. In 2012, the IGM Forum poll conducted by the University of Chicago Booth School of Business found 80% of leading economists agree unemployment was lower at the end of 2010 than it would have been without the stimulus. Regarding whether the benefits of the stimulus outweighed its costs: 46% \\"agreed\\" or \\"strongly agreed\\" that the benefits outweighed the costs, 27% were uncertain, and 12% disagreed or strongly disagreed.[2] IGM Forum asked the same question to leading economists in 2014. This new poll found 82% of leading economists strongly agreed or agreed that unemployment was lower in 2010 than it would have been without the stimulus. Revisiting the question about the benefits outweighing the costs, 56% strongly agreed or agreed that it did, 23% were uncertain, and 5% disagreed.[3]\\r\\n\\r\\nBoth the House and the Senate versions of the bills were primarily written by Democratic Congressional committee leaders and their staffs. Because work on the bills started before President Obama officially took office on January 20, 2009, top aides to President-Elect Obama held multiple meetings with committee leaders and staffers. On January 10, 2009, President-Elect Obama's administration released a report[4] that provided a preliminary analysis of the impact to jobs of some of the prototypical recovery packages that were being considered.\\r\\n\\r\\nThe House version of the bill, H.R. 1, was introduced on January 26, 2009.[5] It was sponsored by Democrat David Obey, the House Appropriations Committee chairman, and was co-sponsored by nine other Democrats. On January 23, Speaker of the House Nancy Pelosi said that the bill was on track to be presented to President Obama for him to sign into law before February 16, 2009.[6] Although 206 amendments were scheduled for floor votes, they were combined into only 11, which enabled quicker passage of the bill.[7]\\r\\n\\r\\nOn January 28, 2009, the House passed the bill by a 244ÿ188 vote.[8] All but 11 Democrats voted for the bill, and 177 Republicans voted against it (one Republican did not vote).[9]\\r\\n\\r\\nThe senate version of the bill, S. 1, was introduced on January 6, 2009, and later substituted as an amendment to the House bill, S.Amdt. 570. It was sponsored by Harry Reid, the Majority Leader, co-sponsored by 16 other Democrats and Joe Lieberman, an independent who caucused with the Democrats.\\r\\n\\r\\nThe Senate then began consideration of the bill starting with the $275 billion tax provisions in the week of February 2, 2009.[6] A significant difference between the House version and the Senate version was the inclusion of a one-year extension of revisions to the alternative minimum tax, which added $70 billion to the bill's total.\\r\\n\\r\\nRepublicans proposed several amendments to the bill directed at increasing the share of tax cuts and downsizing spending as well as decreasing the overall price.[10] President Obama and Senate Democrats hinted that they would be willing to compromise on Republican suggestions to increase infrastructure spending and to double the housing tax credit proposed from $7,500 to $15,000 and expand its application to all home buyers, not just first-time buyers.[11]\\r\\nOther considered amendments included the Freedom Act of 2009, an amendment proposed by Senate Finance Committee members Maria Cantwell (D) and Orrin Hatch (R) to include tax incentives for plug-in electric vehicles.[12]\\r\\n\\r\\nThe Senate called a special Saturday debate session for February 7 at the urging of President Obama. The Senate voted, 61ÿ36 (with 2 not voting) on February 9 to end debate on the bill and advance it to the Senate floor to vote on the bill itself.[13] On February 10, the Senate voted 61ÿ37 (with one not voting)[14]\\r\\nAll the Democrats voted in favor, but only three Republicans voted in favor (Susan Collins, Olympia Snowe, and Arlen Specter).[15] Specter switched to the Democratic Party later in the year. At one point, the Senate bill stood at $838 billion.[16]\\r\\n\\r\\nSenate Republicans forced a near unprecedented level of changes (near $150 billion) in the House bill, which had more closely followed the Obama plan. A comparison of the $827 billion economic recovery plan drafted by Senate Democrats with an $820 billion version passed by the House and the final $787 billion conference version shows huge shifts within these similar totals. Additional debt costs would add about $350 billion or more over 10 years. Many provisions were set to expire in two years.[17]\\r\\n\\r\\nThe main funding differences between the Senate bill and the House bill were: More funds for health care in the Senate ($153.3 vs $140 billion), renewable energy programs ($74 vs. $39.4 billion), for home buyers tax credit ($35.5 vs. $2.6 billion), new payments to the elderly and a one-year increase in AMT limits. The House had more funds appropriated for education ($143 vs. $119.1 billion), infrastructure ($90.4 vs. $62 billion) and for aid to low income workers and the unemployed ($71.5 vs. $66.5 billion).[16]\\r\\n\\r\\nCongressional negotiators said that they had completed the Conference Report on February 11.[27] On February 12, House Majority Leader Steny Hoyer scheduled the vote on the bill for the next day, before wording on the bill's content had been completed and despite House Democrats having previously promised to allow a 48-hour public review period before any vote. The Report with final handwritten provisions was posted on a House website that evening.[28][29] On February 13, the Report passed the House, 246-183, largely along party lines with all 246 Yes votes given by Democrats and the Nay vote split between 176 Republicans and 7 Democrats.[30][31]\\r\\n\\r\\nThe Senate passed the bill, 60-38, with all Democrats and Independents voting for the bill along with three Republicans. On February 17, 2009, President Barack Obama signed the Recovery Act into law.\\r\\n\\r\\n[32][33][34][35]\\r\\n\\r\\nSection 3 of ARRA listed the basic intent behind crafting the law. This Statement of Purpose included the following:\\r\\n\\r\\nThe Act specifies that 37% of the package is to be devoted to tax incentives equaling $288 billion and $144 billion, or 18%, is allocated to state and local fiscal relief (more than 90% of the state aid is going to Medicaid and education). The remaining 45%, or $357 billion, is allocated to federal spending programs such as transportation, communication, waste water and sewer infrastructure improvements; energy efficiency upgrades in private and federal buildings; extension of federal unemployment benefits; and scientific research programs.\\r\\nThe following are details to the different parts of the final bill:[36][37][38][39]\\r\\n\\r\\nTotal: $237 billion\\r\\n\\r\\nTotal: $51 billion\\r\\n\\r\\nARRA included the enactment of the Health Information Technology for Economic and Clinical Health Act, also known as the HITECH Act.[41]\\r\\n\\r\\nTotal health care spending: $155.1 billion[42]\\r\\n\\r\\nTotal: $100 billion\\r\\n\\r\\nTotal: $82.2 billion\\r\\n\\r\\nTotal: $105.3 billion\\r\\n\\r\\nTotal: $48.1 billion,[44] some in the form of Transportation Income Generating Economic Recovery (TIGER) Grants\\r\\n\\r\\nTotal: $18 billion[45][46][47][48][49]\\r\\n\\r\\nTotal: $7.2 billion\\r\\n\\r\\nTotal: $10.5 billion\\r\\n\\r\\nTotal: $21.5 billion[50][51]\\r\\n\\r\\nTotal: $27.2 billion\\r\\n\\r\\nTotal: $14.7 billion[54]\\r\\n\\r\\nTotal: $7.6 billion[citation needed]\\r\\n\\r\\nTotal: $10.6 billion\\r\\n\\r\\nARRA included a protectionist 'Buy American' provision, which imposed a general requirement that any public building or public works project funded by the new stimulus package must use only iron, steel and other manufactured goods produced in the United States.\\r\\n\\r\\nA May 15, 2009, Washington Post article reported that the 'Buy American' provision of the stimulus package caused outrage in the Canadian business community, and that the government in Canada \\"retaliated\\" by enacting its own restrictions on trade with the U.S.[57]  On June 6, 2009, delegates at the Federation of Canadian Municipalities conference passed a resolution that would potentially shut out U.S. bidders from Canadian city contracts, in order to help show support for Prime Minister Stephen Harper's opposition to the \\"Buy American\\" provision.  Sherbrooke Mayor Jean Perrault, president of the federation, stated, \\"This U.S. protectionist policy is hurting Canadian firms, costing Canadian jobs and damaging Canadian efforts to grow in the world-wide recession.\\" On February 16, 2010, the United States and Canada agreed on exempting Canadian companies from Buy American provisions, which would have hurt the Canadian economy.[58][59]\\r\\n\\r\\nEconomists such as Martin Feldstein, Daron Acemo?lu, National Economic Council director Larry Summers, and Nobel Memorial Prize in Economic Sciences winners Joseph Stiglitz[60] and Paul Krugman[61] favored a larger economic stimulus to counter the economic downturn. While in favor of a stimulus package, Feldstein expressed concern over the act as written, saying it needed revision to address consumer spending and unemployment more directly.[62] Just after the bill was enacted, Krugman wrote that the stimulus was too small to deal with the problem, adding, \\"And it's widely believed that political considerations led to a plan that was weaker and contains more tax cuts than it should have ÿ that Mr. Obama compromised in advance in the hope of gaining broad bipartisan support.\\"[63] Conservative economist John Lott was more critical of the government spending.[64]\\r\\n\\r\\nOn January 28, 2009, a full-page advertisement with the names of approximately 200 economists who were against Obama's plan appeared in The New York Times and The Wall Street Journal.  This included Nobel Memorial Prize in Economic Sciences laureates Edward C. Prescott, Vernon L. Smith, and James M. Buchanan. The economists denied the quoted statement by President Obama that there was \\"no disagreement that we need action by our government, a recovery plan that will help to jumpstart the economy\\". Instead, the signers believed that \\"to improve the economy, policymakers should focus on reforms that remove impediments to work, saving, investment and production. Lower tax rates and a reduction in the burden of government are the best ways of using fiscal policy to boost growth.\\"[65] The funding for this advertisement came from the Cato Institute.[66]\\r\\n\\r\\nOn February 8, 2009, a letter to Congress signed by about 200 economists in favor of the stimulus, written by the Center for American Progress Action Fund, said that Obama's plan \\"proposes important investments that can start to overcome the nation's damaging loss of jobs\\", and would \\"put the United States back onto a sustainable long-term-growth path\\".[67]  This letter was signed by Nobel Memorial laureates Kenneth Arrow, Lawrence R. Klein, Eric Maskin, Daniel McFadden, Paul Samuelson and Robert Solow. The New York Times published projections from IHS Global Insight, Moodys.com, Economy.com and Macroeconomic Advisers that indicated that the economy may have been worse without the ARRA.[68][69]\\r\\n\\r\\nThe CBO estimated ARRA would positively impact GDP and employment. It projected an increase in the GDP of between 1.4?percent and 3.8?percent by the end of 2009, between 1.1?percent and 3.3?percent by the end of 2010, between 0.4?percent and 1.3?percent by the end of 2011, and a decrease of between zero and 0.2?percent beyond 2014.[70] The impact to employment would be an increase of 0.8?million to 2.3?million by the end of 2009, an increase of 1.2?million to 3.6?million by the end of 2010, an increase of 0.6?million to 1.9?million by the end of 2011, and declining increases in subsequent years as the U.S. labor market reaches nearly full employment, but never negative.[70] Decreases in GDP in 2014 and beyond are accounted for by crowding out, where government debt absorbs finances that would otherwise go toward investment.[70] A 2013 study by economists Stephen Marglin and Peter Spiegler found the stimulus had boosted GDP in line with CBO estimates.[71]\\r\\n\\r\\nA February 4, 2009, report by the Congressional Budget Office (CBO) said that while the stimulus would increase economic output and employment in the short run, the GDP would, by 2019, have an estimated net decrease between 0.1% and 0.3% (as compared to the CBO estimated baseline).[72]\\r\\n\\r\\nThe CBO estimated that enacting the bill would increase federal budget deficits by $185 billion over the remaining months of fiscal year 2009, by $399 billion in 2010, and by $134 billion in 2011, or $787 billion over the 2009ÿ2019 period.[73]\\r\\n\\r\\nIn a February 11 letter, CBO Director Douglas Elmendorf noted that there was disagreement among economists about the effectiveness of the stimulus, with some skeptical of any significant effects while others expecting very large effects.[70] Elmendorf said the CBO expected short term increases in GDP and employment.[70] In the long term, the CBO expects the legislation to reduce output slightly by increasing the nation's debt and crowding out private investment, but noted that other factors, such as improvements to roads and highways and increased spending for basic research and education may offset the decrease in output and that crowding out was not an issue in the short term because private investment was already decreasing in response to decreased demand.[70]\\r\\n\\r\\nA May 21, 2009, article in The Washington Post stated, \\"To build support for the stimulus package, President Obama vowed unprecedented transparency, a big part of which, he said, would be allowing taxpayers to track money to the street level on Recovery.gov...\\" But three months after the bill was signed, Recovery.gov offers little beyond news releases, general breakdowns of spending, and acronym-laden spreadsheets and timelines.\\" The same article also stated, \\"Unlike the government site, the privately run Recovery.org is actually providing detailed information about how the $787 billion in stimulus money is being spent.\\"[74]\\r\\n\\r\\nReports regarding errors in reporting on the Web site made national news. News stories circulated about Recovery.gov reporting fund distribution to congressional districts that did not exist.[75][76]\\r\\n\\r\\nA new Recovery.gov website was redesigned at a cost estimated to be $9.5 million through January 2010.[77] The section of the act that was intended to establish and regulate the operation of Recovery.gov was actually struck prior to its passage into law.  Section 1226, which laid out provisions for the structure, maintenance, and oversight of the website were struck from the bill. Organizations that received stimulus dollars were directed to provide detailed reports regarding their use of these funds; these reports were posted on recovery.gov[citation needed].\\r\\n\\r\\nOn July 20, 2009, the Drudge Report published links to pages on Recovery.gov that Drudge alleged were detailing expensive contracts awarded by the U.S. Department of Agriculture for items such as individual portions of mozzarella cheese, frozen ham and canned pork, costing hundreds of thousands to over a million dollars. A statement released by the USDA the same day corrected the allegation, stating that \\"references to '2 pound frozen ham sliced' are to the sizes of the packaging. Press reports suggesting that the Recovery Act spent $1.191 million to buy \\"2 pounds of ham\\" are wrong. In fact, the contract in question purchased 760,000 pounds of ham for $1.191 million, at a cost of approximately $1.50 per pound.\\"[78]\\r\\n\\r\\nAs of 2016, the servers for recovery.gov have been shut down and the site is unavailable. [79]\\r\\n\\r\\nThe Congressional Budget Office reported in October 2009 the reasons for the changes in the 2008 and 2009 deficits, which were approximately $460 billion and $1.41 trillion, respectively. The CBO estimated that ARRA increased the deficit by $200 billion for 2009, split evenly between tax cuts and additional spending, excluding any feedback effects on the economy.[80]\\r\\n\\r\\nOn February 12, 2010, the Bureau of Labor Statistics, which regularly issues economic reports, published job-loss data on a month-by-month basis since 2000.[81] Organizing for America, a community organizing project of the Democratic National Committee, prepared a chart presenting the BLS data for the period beginning in December 2007. OFA used the chart to argue, \\"As a result [of the Recovery Act], job losses are a fraction of what they were a year ago, before the Recovery Act began.\\"[82] Others argue that job losses always grow early in a recession and naturally slow down with or without government stimulus spending, and that the OFA chart was mis-leading.\\r\\n\\r\\n\\r\\nIn the primary justification for the stimulus package, the Obama administration and Democratic proponents presented a graph in January 2009 showing the projected unemployment rate with and without the ARRA.[4] The graph showed that if ARRA was not enacted the unemployment rate would exceed 9%; but if ARRA was enacted it would never exceed 8%. After ARRA became law, the actual unemployment rate exceeded 8% in February 2009, exceeded 9% in May 2009, and exceeded 10% in October 2009. The actual unemployment rate was 9.2% in June 2011 when it was projected to be below 7% with the ARRA. However, supporters of the ARRA claim that this can be accounted for by noting that the actual recession was subsequently revealed to be much worse than any projections at the time when the ARRA was drawn up.[citation needed]\\r\\nAccording to a March 2009 Industry Survey of and by the National Association of Business Economists, 60.3% of their economists who had reviewed the fiscal stimulus enacted in February 2009 projected it would have a modest impact in shortening the recession, with 29.4% anticipating little or no impact as well as 10.3% predicting a strong impact.  The aspects of the stimulus expected by the NABE to have the greatest effectiveness were physical infrastructure, unemployment benefits expansion, and personal tax-rate cuts.[83]\\r\\n\\r\\nOne year after the stimulus, several independent macroeconomic firms, including Moody's and IHS Global Insight, estimated that the stimulus saved or created 1.6 to 1.8 million jobs and forecast a total impact of 2.5 million jobs saved by the time the stimulus is completed.[84] The Congressional Budget Office considered these estimates conservative.[84] The CBO estimated according to its model 2.1 million jobs saved in the last quarter of 2009, boosting the economy by up to 3.5 percent and lowering the unemployment rate by up to 2.1 percent.[85] The CBO projected that the package would have an even greater impact in 2010.[85] The CBO also said, \\"It is impossible to determine how many of the reported jobs would have existed in the absence of the stimulus package.\\"[86] The CBO's report on the first quarter of 2010 showed a continued positive effect, with an employment gain in that quarter of up to 2.8 million and a GDP boost of up to 4.2 percent.[87]  Economists Timothy Conley of the University of Western Ontario and Bill Dupor of the Ohio State University found that while the stimulus' effects on public sector job creation were unambiguously positive, the effects on private sector job creation were ambiguous. [88] Economist Dan Wilson of the Federal Reserve,  who used similar methodology, without the same identified errors, estimates that \\"ARRA spending created or saved about 2 million jobs in its first year and over 3 million by March 2011.\\"[89]\\r\\n\\r\\nThe CBO also revised its assessment of the long-term impact of the bill. After 2014, the stimulus is estimated to decrease output by zero to 0.2%.  The stimulus is not expected to have a negative impact on employment in any period of time.[90]\\r\\n\\r\\nIn 2011, the Department of Commerce revised some of its previous estimates.  Economist Dean Baker commented:\\r\\n\\r\\n[T]he revised data ... showed that the economy was plunging even more rapidly than we had previously recognised in the two quarters following the collapse of Lehman. Yet, the plunge stopped in the second quarter of 2009 ÿ just as the stimulus came on line. This was followed by respectable growth over the next four quarters. Growth then weakened again as the impact of the stimulus began to fade at the end of 2010 and the start of this year.\\r\\nIn other words, the growth pattern shown by the revised data sure makes it appear that the stimulus worked. The main problem would seem to be that the stimulus was not big enough and it wasn't left in place long enough to lift the economy to anywhere near potential output.[91]\\r\\nThe Democratic Congressional Campaign Committee (DCCC) established a \\"Hypocrisy Hall of Fame\\" to list Republican Representatives who had voted against ARRA but who then sought or took credit for ARRA programs in their districts.  As of September 2011, the DCCC was listing 128 House Republicans in this category.[92] Newsweek reported that many of the Republican legislators who publicly argued that the stimulus would not create jobs were writing letters seeking stimulus programs for their districts on the grounds that the spending would create jobs.[93]\\r\\n\\r\\nThe stimulus has been criticized as being too small.  In July 2010, a group of 40 prominent economists issued a statement calling for expanded stimulus programs to reduce unemployment.  They also challenged the view that the priority should be reducing the deficit: \\"Making deficit reduction the first target, without addressing the chronic underlying deficiency of demand, is exactly the error of the 1930s.\\"[94]\\r\\n\\r\\nIn July 2010, the White House Council of Economic Advisers (CEA) estimated that the stimulus had \\"saved or created between 2.5 and 3.6 million jobs as of the second quarter of 2010\\".[95]  At that point, spending outlays under the stimulus totaled $257 billion and tax cuts totaled $223 billion.[96] In July 2011, the CEA estimated that as of the first quarter of  2011,[97] the ARRA raised employment relative to what it otherwise would have been by between 2.4 and 3.6 million. The sum of outlays and tax cuts up to this point was $666 billion. Using a straight mathematical calculation, critics reported that the ARRA cost taxpayers between $185,000 to $278,000 per job that was created, though this computation does not include the permanent infrastructure that resulted.\\r\\n\\r\\nIn August 2010, Republican Senators Tom Coburn and John McCain released a report listing 100 projects it described as the \\"most wasteful projects\\" funded by the Act.  In total, the projects questioned by the two senators amounted to about $15 billion, or less than 2% of the $862 billion.  The two senators did concede that the stimulus has had a positive effect on the economy, though they criticized it for failing to give \\"the biggest bang for our buck\\" on the issue of job creation.  CNN noted that the two senators' stated objections were brief summaries presenting selective accounts that were unclear, and the journalists pointed out several instances where they created erroneous impressions.[98]\\r\\n\\r\\nOne of the primary purposes and promises of the Act was to launch a large number of \\"shovel-ready\\" projects that would generate jobs.[99] However, a sizable number of these projects, most of which pertained to infrastructure, took longer to implement than they had expected by most.[100][101] This was largely attributed to the regulatory process that is involved in such projects.[citation needed]\\r\\n\\r\\nSome of the tax incentives in the Act, including those related to the American opportunity tax credit and Earned Income Tax Credit, were extended for a further two years by the Tax Relief, Unemployment Insurance Reauthorization, and Job Creation Act of 2010.[102]\\r\\n\\r\\nIn November 2011, the Congressional Budget Office (CBO) updated its earlier reports concerning the Act.  The CBO stated that \\"the employment effects began to wane at the end of 2010 and have continued to do so throughout 2011.\\"  Nevertheless, in the third quarter of 2011, the CBO estimated that the Act had increased the number of full-time equivalent jobs by 0.5 million to 3.3 million.[103] Section 1513 of the Recovery Act stated that reports on the impact of the act were to be submitted quarterly, however the last report issued occurred for the second quarter of 2011.[104] As of December 2012, 58.6% of Americans are employed.[105][106]\\r\\n\\r\\nIn 2013, the Reason Foundation, an American libertarian group, conducted a study of the results of the ARRA. Only 23% of the 8,381 sampled companies hired new workers and kept all of them when the project was completed. Also, just 41% of sampled companies hired workers at all, while 30% of sampled companies did hire but laid off all workers once the government money stopped funding.[107] These results cast doubt on previously stated estimates of job creation numbers, which do not factor those companies that did not retain their workers or hire any at all.\\r\\n\\r\\nIn February 2014, the White House stated in a release that the stimulus measure saved or created an average of 1.6 million jobs a year between 2009 and 2012, thus averting having the recession descend into another Great Depression. Republicans, such as House Speaker John Boehner of Ohio, criticized the report since, in their views, the Act cost too much for too little result.[108]\\r\\n\\r\\nIn addition to the Vice President Biden's oversight role, a high-level advisory body, the President's Economic Recovery Advisory Board (later renamed and reconstituted as the \\"President's Council on Jobs and Competitiveness\\"), was named concurrent to the passage of the act.\\r\\n\\r\\nAs well, the President named Inspector General of the United States Department of the Interior Earl Devaney and the Recovery Accountability and Transparency Board (RATB) to monitor administration of the Act.[109] Eleven other inspectors general served on the RATB, and the board also had a Recovery Independent Advisory Panel.\\r\\n\\r\\nIn late 2011, Devaney and his fellow inspectors general on RATB, and more who were not, were credited with avoiding any major scandals in the administration of the Act, in the eyes of one Washington observer.[110]\\r\\n\\r\\nIn May 2016, the chairman of the U.S. Senate Finance Committee, Senator Orrin Hatch (R-UT), launched the first steps of an investigation into a part of the stimulus law that gave grants to solar and green energy companies. Hatch sent a letter to the IRS and Treasury Department with a list of questions about the program. According to the Wall Street Journal, letters from senior senators who chair committees can lead to formal investigations by Congress.[111]\\r\\n\\r\\nOne part of the stimulus law, section 1603, gave cash grants to solar companies to encourage investment in solar technology. Because many companies didn't yet make a profit in 2009 in that industry, they were offered cash instead of tax credits. In September 2015, the U.S. government asked that a Spanish company return $1 million it had received from the program. The company issued a statement saying it fully complied with the request.[111]","input":"When was the american recovery and reinvestment act passed?"},{"output":"7.6 billion people as of May 2018","context":"\\r\\n\\r\\nIn demographics, the world population is the total number of humans currently living, and was estimated to have reached 7.6 billion people as of May 2018.[1]\\r\\n\\r\\nWorld population has experienced continuous growth since the end of the Great Famine of 1315ÿ17 and the Black Death in 1350, when it was near 370?million.[2] \\r\\nThe highest population growth rates ÿ global population increases above 1.8% per year ÿ occurred between 1955 and 1975, peaking to 2.06% between 1965 and 1970.[3] The growth rate has declined to 1.18% between 2010 and 2015 and is projected to decline further in the course of the 21st century.[3]\\r\\n\\r\\nTotal annual births were highest in the late 1980s at about 139?million,[4] and as of 2011 were expected to remain essentially constant at a level of 135?million,[5] while deaths numbered 56?million per year and were expected to increase to 80?million per year by 2040.[6] \\r\\nThe median age of the world's population was estimated to be 30.4 years in 2018.[7]\\r\\n\\r\\nSix of the Earth's seven continents are permanently inhabited on a large scale. Asia is the most populous continent, with its 4.54 billion inhabitants accounting for 60% of the world population. The world's two most populated countries, China and India, together constitute about 36% of the world's population. Africa is the second most populated continent, with around 1.28 billion people, or 16% of the world's population. Europe's 742 million people make up 10% of the world's population as of 2018, while the Latin American and Caribbean regions are home to around 651 million (9%). Northern America, primarily consisting of the United States and Canada, has a population of around 363 million (5%), and Oceania, the least-populated region, has about 41 million inhabitants (0.5%).[9] Though it is not permanently inhabited by any fixed population, Antarctica has a small, fluctuating international population based mainly in polar science stations. This population tends to rise in the summer months and decrease significantly in winter, as visiting researchers return to their home countries.[10]\\r\\n\\r\\nEstimates of world population by their nature are an aspect of modernity, possible only since the Age of Discovery. Early estimates for the population of the world[12] date to the 17th century: William Petty in 1682 estimated world population at  320 million (modern estimates ranging close to twice this number); by the late 18th century, estimates ranged close to one billion (consistent with modern estimates).[13] More refined estimates, broken down by continents, were published in the first half of the 19th century, at 600 to 1000 million in the early 1800s and at 800 to 1000 million in the 1840s.[14]\\r\\n\\r\\nEstimates of the population of the world at the time agriculture emerged in around 10,000 BC have ranged between 1 million and 15 million.[15][16]  Even earlier, genetic evidence suggests humans may have gone through a population bottleneck of between 1,000 and 10,000 people about 70,000 BC, according to the Toba catastrophe theory. By contrast, it is estimated that around 50ÿ60 million people lived in the combined eastern and western Roman Empire in the 4th century AD.[17]\\r\\n\\r\\nThe Plague of Justinian, which first emerged during the reign of the Roman emperor Justinian, caused Europe's population to drop by around 50% between the 6th and 8th centuries AD.[18] The population of Europe was more than 70 million in 1340.[19] The Black Death pandemic of the 14th century may have reduced the world's population from an estimated 450 million in 1340 to between 350 and 375 million in 1400;[20] it took 200 years for population figures to recover.[21] The population of China decreased from 123 million in 1200 to 65 million in 1393,[22] presumably due to a combination of Mongol invasions, famine, and plague.[23]\\r\\n\\r\\nStarting in AD 2, the Han Dynasty of ancient China kept consistent family registers in order to properly assess the poll taxes and labor service duties of each household.[24] In that year, the population of Western Han was recorded as 57,671,400 individuals in 12,366,470 households, decreasing to 47,566,772 individuals in 9,348,227 households by AD 146, towards the End of the Han Dynasty.[24] At the founding of the Ming Dynasty in 1368, China's population was reported to be close to 60 million; toward the end of the dynasty in 1644, it may have approached 150 million.[25] England's population reached an estimated 5.6 million in 1650, up from an estimated 2.6 million in 1500.[26] New crops that were brought to Asia and Europe from the Americas by Portuguese and Spanish colonists in the 16th century are believed to have contributed to population growth.[27][28][29] Since their introduction to Africa by Portuguese traders in the 16th century,[30] maize and cassava have similarly replaced traditional African crops as the most important staple food crops grown on the continent.[31]\\r\\n\\r\\nThe pre-Columbian North American population probably numbered somewhere between 2 million and 18 million.[32] Encounters between European explorers and populations in the rest of the world often introduced local epidemics of extraordinary virulence.[33] According to the most extreme scholarly claims, as many as 90% of the Native American population of the New World died due to Old World diseases such as smallpox, measles and influenza.[34] Over the centuries, the Europeans had developed high degrees of immunity to these diseases, while the indigenous peoples had no such immunity.[35]\\r\\n\\r\\nDuring the European Agricultural and Industrial Revolutions, the life expectancy of children increased dramatically.[38] The percentage of the children born in London who died before the age of five decreased from 74.5% in 1730ÿ1749 to 31.8% in 1810ÿ1829.[39][40] Between 1700 and 1900, Europes population increased from about 100 million to over 400 million.[41] Altogether, the areas populated by people of European descent comprised 36% of the world's population in 1900.[42]\\r\\n\\r\\nPopulation growth in the West became more rapid after the introduction of vaccination and other improvements in medicine and sanitation.[43] Improved material conditions led to the population of Britain increasing from 10 million to 40 million in the 19th century.[44] The population of the United Kingdom reached 60 million in 2006.[45] The United States saw its population grow from around 5.3 million in 1800 to 106 million in 1920, exceeding 307 million in 2010.[46]\\r\\n\\r\\nThe first half of the 20th century in Imperial Russia and the Soviet Union was marked by a succession of major wars, famines and other disasters which caused large-scale population losses (approximately 60 million excess deaths).[47][48] After the collapse of the Soviet Union, Russia's population declined significantly ÿ from 150 million in 1991 to 143 million in 2012[49] ÿ but by 2013 this decline appeared to have halted.[50]\\r\\n\\r\\nMany countries in the developing world have experienced extremely rapid population growth since the early 20th century, due to economic development and improvements in public health. China's population rose from approximately 430 million in 1850 to 580 million in 1953,[51] and now stands at over 1.3 billion. The population of the Indian subcontinent, which was about 125 million in 1750, increased to 389 million in 1941;[52] today, India, Pakistan and Bangladesh are collectively home to about 1.63 billion people.[53] Java had about 5 million inhabitants in 1815; its present-day successor, Indonesia, now has a population of over 140 million.[54] In just one hundred years, the population of Brazil decupled (x10), from about 17 million in 1900, or about 1% of the world population in that year, to about 176 million in 2000, or almost 3% of the global population in the very early 21st century. Mexico's population grew from 13.6 million in 1900 to about 112 million in 2010.[55][56] Between the 1920s and 2000s, Kenya's population grew from 2.9 million to 37 million.[57]\\r\\n\\r\\nIt is estimated that the world population reached one billion for the first time in 1804. It was another 123 years before it reached two billion in 1927, but it took only 33 years to reach three billion in 1960.[58] Thereafter, the global population reached four billion in 1974, five billion in 1987, six billion in 1999 and, according to the United States Census Bureau, seven billion in March 2012.[59] The United Nations, however, estimated that the world population reached seven billion in October 2011.[60][61][62]\\r\\n\\r\\nAccording to current projections, the global population will reach eight billion by 2024, and is likely to reach around nine billion by 2042. Alternative scenarios for 2050 range from a low of 7.4 billion to a high of more than 10.6 billion.[63] Projected figures vary depending on underlying statistical assumptions and the variables used in projection calculations, especially the fertility variable. Long-range predictions to 2150 range from a population decline to 3.2 billion in the \\"low scenario\\", to \\"high scenarios\\" of 24.8 billion.[63] One extreme scenario predicted a massive increase to 256 billion by 2150, assuming the global fertility rate remained at its 1995 level of 3.04 children per woman; however, by 2010 the global fertility rate had declined to 2.52.[64][65]\\r\\n\\r\\nThere is no estimation for the exact day or month the world's population surpassed one or two billion. The points at which it reached three and four billion were not officially noted, but the International Database of the United States Census Bureau placed them in July 1959 and April 1974 respectively. The United Nations did determine, and commemorate, the \\"Day of 5 Billion\\" on July 11, 1987, and the \\"Day of 6 Billion\\" on October 12, 1999. The Population Division of the United Nations declared the \\"Day of 7 Billion\\" to be October 31, 2011.[66]\\r\\n\\r\\nAs of 2012, the global sex ratio is approximately 1.01 males to 1 female. The greater number of men is possibly due to the significant sex imbalances evident in the Indian and Chinese populations.[68][69] Approximately 26.3% of the global population is aged under 15, while 65.9% is aged 15ÿ64 and 7.9% is aged 65 or over.[68] The median age of the world's population was estimated to be 29.7 years in 2014,[70] and is expected to rise to 37.9 years by 2050.[71]\\r\\n\\r\\nAccording to the World Health Organization, the global average life expectancy is 71.4 years as of 2015, with women living an average of 74 years and men approximately 69 years.[67] In 2010, the global fertility rate was estimated at 2.52 children per woman.[65] In June 2012, British researchers calculated the total weight of Earth's human population as approximately 287 million tonnes, with the average person weighing around 62 kilograms (137?lb).[72]\\r\\n\\r\\nThe CIA estimated nominal 2013 gross world product at US$74.31 trillion, giving an annual global per capita figure of around US$10,500.[73] Around 1.29 billion people (18.4% of the world population) live in extreme poverty, subsisting on less than US$1.25 per day;[74] approximately 870 million people (12.25%) are undernourished.[75] 83% of the world's over-15s are considered literate.[68] In June 2014, there were around 3.03 billion global Internet users, constituting 42.3% of the world population.[76]\\r\\n\\r\\nThe Han Chinese are the world's largest single ethnic group, constituting over 19% of the global population in 2011.[77] The world's most-spoken first languages are Mandarin Chinese (spoken by 12.44% of the world's population), Spanish (4.85%), English (4.83%), Arabic (3.25%) and Hindustani (2.68%).[68] The world's largest religion is Christianity, whose adherents account for 31% of the global population; Islam is the second-largest religion, accounting for 24.1%, and Hinduism the third, accounting for 13.78%.[68] In 2005, around 16% of the global population were reported to be non-religious.[78]\\r\\n\\r\\nApproximately 4.3 billion people live in these ten countries, representing around 58% of the world's population as of March 2016. Approximately 3.7 billion people, or half of the world population, live in the six most populous countries.[89]\\r\\n\\r\\nThe tables below list the world's most densely populated countries, both in absolute terms and in comparison to their total populations.\\r\\n\\r\\nPopulation size fluctuates at differing rates in differing regions. Nonetheless, population growth is the long-standing trend on all inhabited continents, as well as in most individual states. During the 20th century, the global population saw its greatest increase in known history, rising from about 1.6 billion in 1900 to over 6 billion in 2000. A number of factors contributed to this increase, including the lessening of the mortality rate in many countries by improved sanitation and medical advances, and a massive increase in agricultural productivity attributed to the Green Revolution.[91][92][93]\\r\\n\\r\\nIn 2000, the United Nations estimated that the world's population was growing at an annual rate of 1.14% (equivalent to around 75 million people),[94] down from a peak of 88 million per year in 1989. By 2000, there were approximately ten times as many people on Earth as there had been in 1700. Globally, the population growth rate has been steadily declining from its peak of 2.19% in 1963, but growth remains high in Latin America, the Middle East, and Sub-Saharan Africa.[95]\\r\\n\\r\\nDuring the 2010s, Japan and some countries in Europe began to encounter negative population growth (i.e. a net decrease in population over time), due to sub-replacement fertility rates.[90]\\r\\n\\r\\nIn 2006, the United Nations stated that the rate of population growth was visibly diminishing due to the ongoing global demographic transition. If this trend continues, the rate of growth may diminish to zero by 2050, concurrent with a world population plateau of 9.2 billion.[96] However, this is only one of many estimates published by the UN; in 2009, UN population projections for 2050 ranged between around 8 billion and 10.5 billion.[97] An alternative scenario is given by the statistician Jorgen Randers, who argues that traditional projections insufficiently take into account the downward impact of global urbanization on fertility. Randers' \\"most likely scenario\\" reveals a peak in the world population in the early 2040s at about 8.1 billion people, followed by decline.[98] Adrian Raftery, a University of Washington professor of statistics and of sociology, states that \\"theres a 70 percent probability the world population will not stabilize this century. Population, which had sort of fallen off the worlds agenda, remains a very important issue.\\"[99]\\r\\n\\r\\nEstimated world population figures, 10,000?BCÿAD 2000\\r\\n\\r\\nEstimated world population figures, 10,000?BCÿAD 2000 (in log y scale)\\r\\n\\r\\nWorld population figures, 1950ÿ2000\\r\\n\\r\\nEstimated global growth rates, 1950ÿ2050\\r\\n\\r\\nEstimated and projected populations of the world and its continents (except Antarctica) from 1950 to 2100. The shaded regions correspond to the range of projections by the United Nations Department of Economic and Social Affairs.\\r\\n\\r\\nThe table below shows historical and predicted regional population figures in millions.[100][101][102] The availability of historical population figures varies by region.\\r\\n\\r\\nThe following table gives estimates, in millions, of population in the past. The data for 1750 to 1900 are from the UN report \\"The World at Six Billion\\"[106] whereas the data from 1950 to 2015 are from a UN data sheet.[8]\\r\\n\\r\\nUsing the above figures, the change in population from 2010 to 2015 was:\\r\\n\\r\\nLong-term global population growth is difficult to predict. The United Nations and the US Census Bureau both give different estimates ÿ according to the UN, the world population reached seven billion in late 2011,[100] while the USCB asserted that this occurred in March 2012.[111] The UN has issued multiple projections of future world population, based on different assumptions. From 2000 to 2005, the UN consistently revised these projections downward, until the 2006 revision, issued on March 14, 2007, revised the 2050 mid-range estimate upwards by 273 million.\\r\\n\\r\\nAverage global birth rates are declining fast, but vary greatly between developed countries (where birth rates are often at or below replacement levels) and developing countries (where birth rates typically remain high). Different ethnicities also display varying birth rates. Death rates can change rapidly due to disease epidemics, wars and other mass catastrophes, or advances in medicine.\\r\\n\\r\\n2012 United projections show a continued increase in population in the near future with a steady decline in population growth rate; the global population is expected to reach between 8.3?and 10.9?billion by 2050.[112][113] 2003 UN Population Division population projections for the year 2150 range between 3.2 and 24.8 billion.[64] One of many independent mathematical models supports the lower estimate,[114] while a 2014 estimate forecasts between 9.3 and 12.6 billion in 2100, and continued growth thereafter.[115][116] Some analysts have questioned the sustainability of further world population growth, highlighting the growing pressures on the environment, global food supplies, and energy resources.[117][118][119]\\r\\n\\r\\nIn 1975, Sebastian von Hoerner proposed a formula for population growth which represented hyperbolic growth with an infinite population in 2025.[122] The hyperbolic growth of the world population observed until the 1970s was later correlated to a non-linear second order positive feedback between demographic growth and technological development. This feedback can be described as follows: technological advance L increase in the carrying capacity of land for people L demographic growth L more people L more potential inventors L acceleration of technological advance L accelerating growth of the carrying capacity L faster population growth L accelerating growth of the number of potential inventors L faster technological advance L hence, the faster growth of the Earth's carrying capacity for people, and so on.[123] The transition from hyperbolic growth to slower rates of growth is related to the demographic transition.\\r\\n\\r\\nAccording to the Russian demographer Sergey Kapitsa,[124] the world population grew between 67,000 BC and 1965 according to the following formula:\\r\\n\\r\\nwhere\\r\\n\\r\\nAccording to linear interpolation and extrapolation of UNDESA population estimates, the world population has doubled, or will double, in the years listed in the tables below (with two different starting points). During the 2nd millennium, each doubling took roughly half as long as the previous doubling, fitting the hyperbolic growth model mentioned above. However, after 2024, it is unlikely that there will be another doubling of the global population in the 21st century.[125]\\r\\n\\r\\nIn his 1798 work An Essay on the Principle of Population, the British scholar Thomas Malthus incorrectly predicted that continued population growth would exhaust the global food supply by the mid-19th century. Malthus wrote the essay to refute what he considered the unattainable utopian ideas of William Godwin and Marquis de Condorcet, as presented in Political Justice and The Future Progress of the Human Mind. In 1968, Paul R. Ehrlich reprised Malthus' argument in The Population Bomb, predicting that mass global famine would occur in the 1970s and 1980s.[127]\\r\\n\\r\\nThe predictions of Ehrlich and other neo-Malthusians were vigorously challenged by a number of economists, notably Julian Lincoln Simon, and advances in agriculture, collectively known as the Green Revolution, forestalled any potential global famine in the late 20th century. Between 1950 and 1984, as the Green Revolution transformed agriculture around the world, grain production increased by over 250%.[128] The world population has grown by over four billion since the beginning of the Green Revolution, but food production has so far kept pace with population growth. Most scholars believe that, without the Revolution, there would be greater levels of famine and malnutrition than the UN presently documents.[129] However, neo-Malthusians point out that fossil fuels provided the energy for the Green Revolution, in the form of natural gas-derived fertilizers, oil-derived pesticides, and hydrocarbon-fueled irrigation, and that many crops have become so genetically uniform that a crop failure in any one country could potentially have global repercussions.[130]\\r\\n\\r\\nIn 2004, a meta-analysis of 70 quantitative studies estimating a sustainable limit to the world population generated a meta-estimate of 7.7 billion people.[131]\\r\\n\\r\\nIn May 2008, the price of grain was pushed up severely by the increased cultivation of biofuels, the increase of world oil prices to over $140 per barrel ($880/m3),[132] global population growth,[133] the effects of climate change,[134] the loss of agricultural land to residential and industrial development,[135][136] and growing consumer demand in the population centres of China and India.[137][138] Food riots subsequently occurred in some countries.[139][140] However, oil prices then fell sharply. Resource demands are expected to ease as population growth declines, but it is unclear whether mass food wastage and rising living standards in developing countries will once again create resource shortages.[141][142]\\r\\n\\r\\nDavid Pimentel, professor of ecology and agriculture at Cornell University, estimates that the sustainable agricultural carrying capacity for the United States is about 200 million people; its population as of 2015 is over 300 million.[143] In 2009, the UK government's chief scientific advisor, Professor John Beddington, warned that growing populations, falling energy reserves and food shortages would create a \\"perfect storm\\" of shortages of food, water, and energy by 2030.[126][144] According to a 2009 report by the United Nations Food and Agriculture Organisation (FAO), the world will have to produce 70% more food by 2050 to feed a projected extra 2.3 billion people.[145]\\r\\n\\r\\nThe observed figures for 2007 showed an actual increase in absolute numbers of undernourished people in the world, with 923 million undernourished in 2007, versus 832 million in 1995.[146] The 2009 FAO estimates showed an even more dramatic increase, to 1.02 billion.[147]\\r\\n\\r\\nA number of scientists have argued that the current global population expansion and accompanying increase in resource consumption threatens the world's ecosystem.[148][149]\\r\\nThe InterAcademy Panel Statement on Population Growth, which was ratified by 58 member national academies in 1994, states that \\"unprecedented\\" population growth aggravates many environmental problems, including rising levels of atmospheric carbon dioxide, global warming, and pollution.[150] Indeed, some analysts claim that overpopulation's most serious impact is its effect on the environment.[118]\\r\\nThe situation has continued to worsen, as at the time of the 1994 IAP statement, the world population stood at 5.5 billion and lower-bound scenarios predicted a peak of 7.8 billion by 2050, a number that current estimates state will be reached in the late 2020s.\\r\\n\\r\\nScientists contend that human overpopulation, continued human population growth and overconsumption, particularly by the wealthy, are the primary drivers of mass species extinction.[151][152][153][154] By 2050 population growth, along with profligate consumption, could result in oceans containing more plastic than fish by weight.[153] In November 2017, a statement by 15,364 scientists from 184 countries asserted that rapid human population growth is the \\"primary driver behind many ecological and even societal threats.\\"[155]\\r\\n\\r\\nA July 2017 study published in Environmental Research Letters argued that the most significant way individuals could mitigate their own carbon footprint is to have fewer children, followed by living without a vehicle, forgoing air travel and adopting a plant-based diet.[156]\\r\\n\\r\\nHuman population control is the practice of intervening to alter the rate of population growth. Historically, human population control has been implemented by limiting a region's birth rate, by voluntary contraception or by government mandate. It has been undertaken as a response to factors including high or increasing levels of poverty, environmental concerns, and religious reasons. The use of abortion in some population control strategies has caused controversy,[157] with religious organizations such as the Roman Catholic Church explicitly opposing any intervention in the human reproductive process.[158]\\r\\n\\r\\nThe University of Nebraska publication Green Illusions argues that population control to alleviate environmental pressures need not be coercive. It states that \\"Women who are educated, economically engaged, and in control of their own bodies can enjoy the freedom of bearing children at their own pace, which happens to be a rate that is appropriate for the aggregate ecological endowment of our planet.\\"[159] The book Fatal Misconception by Matthew Connelly similarly points to the importance of supporting the rights of women in bringing population levels down over time.[160]\\r\\n\\r\\nLists:\\r\\n\\r\\nHistorical:\\r\\n\\r\\nFurther reading\\r\\n\\r\\nOrganizations\\r\\n\\r\\nStatistics and maps\\r\\n\\r\\nPopulation clocks","input":"How many population in the world at present?"},{"output":"1200 BC","context":"The origins of Western astronomy can be found in Mesopotamia, and all Western efforts in the exact sciences are descendants in direct line from the work of the late Babylonian astronomers.[1] Modern knowledge of Sumerian astronomy is indirect, via the earliest Babylonian star catalogues dating from about 1200 BC. The fact that many star names appear in Sumerian suggests a continuity reaching into the Early Bronze Age.\\r\\nThe history of astronomy in Mesopotamia, and the world, begins with the Sumerians who developed the earliest writing systemknown as cuneiformaround 3500ÿ3200 BC. The Sumerians developed a form of astronomy that had an important influence on the sophisticated astronomy of the Babylonians. Astrolatry, which gave planetary gods an important role in Mesopotamian mythology and religion, began with the Sumerians. They also used a sexagesimal (base 60) place-value number system, which simplified the task of recording very great and very small numbers. The modern practices of dividing a circle into 360 degrees, of 60 minutes each, began with the Sumerians.\\r\\nDuring the 8th and 7th centuries BC, Babylonian astronomers developed a new empirical approach to astronomy. They began studying philosophy dealing with the ideal nature of the universe and began employing an internal logic within their predictive planetary systems. This was an important contribution to astronomy and the philosophy of science, and some scholars have thus referred to this new approach as the first scientific revolution.[2] This new approach to astronomy was adopted and further developed in Greek and Hellenistic astronomy. Classical Greek and Latin sources frequently use the term Chaldeans for the astronomers of Mesopotamia, who were, in reality, priest-scribes specializing in astrology and other forms of divination.\\r\\nOnly fragments of Babylonian astronomy have survived, consisting largely of contemporary clay tablets containing astronomical diaries, ephemerides and procedure texts, hence current knowledge of Babylonian planetary theory is in a fragmentary state.[3] Nevertheless, the surviving fragments show that Babylonian astronomy was the first \\"successful attempt at giving a refined mathematical description of astronomical phenomena\\" and that \\"all subsequent varieties of scientific astronomy, in the Hellenistic world, in India, in Islam, and in the West  depend upon Babylonian astronomy in decisive and fundamental ways.\\"[4]\\r\\n\\r\\n\\r\\n\\"Old\\" Babylonian astronomy was practiced during and after the First Babylonian Dynasty (ca. 1830 BC) and before the Neo-Babylonian Empire (ca. 626 BC).\\r\\nThe Babylonians were the first to recognize that astronomical phenomena are periodic and apply mathematics to their predictions. Tablets dating back to the Old Babylonian period document the application of mathematics to the variation in the length of daylight over a solar year. Centuries of Babylonian observations of celestial phenomena were recorded in the series of cuneiform tablets known as the En?ma Anu Enlilthe oldest significant astronomical text that we possess is Tablet 63 of the En?ma Anu Enlil, the Venus tablet of Ammisaduqa, which lists the first and last visible risings of Venus over a period of about 21 years. It is the earliest evidence that planetary phenomena were recognized as periodic.\\r\\nThe MUL.APIN contains catalogues of stars and constellations as well as schemes for predicting heliacal risings and settings of the planets, and lengths of daylight as measured by a water clock, gnomon, shadows, and intercalations. The Babylonian GU text arranges stars in 'strings' that lie along declination circles and thus measure right-ascensions or time intervals, and also employs the stars of the zenith, which are also separated by given right-ascensional differences.[5][6][7] There are dozens of cuneiform Mesopotamian texts with real observations of eclipses, mainly from Babylonia.\\r\\nThe Babylonians were the first civilization known to possess a functional theory of the planets.[7] The oldest surviving planetary astronomical text is the Babylonian Venus tablet of Ammisaduqa, a 7th-century BC copy of a list of observations of the motions of the planet Venus that probably dates as early as the second millennium BC. The Babylonian astrologers also laid the foundations of what would eventually become Western astrology.[8] The Enuma anu enlil, written during the Neo-Assyrian period in the 7th century BC,[9] comprises a list of omens and their relationships with various celestial phenomena including the motions of the planets.[10]\\r\\nIn contrast to the world view presented in Mesopotamian and Assyro-Babylonian literature, particularly in Mesopotamian and Babylonian mythology, very little is known about the cosmology and world view of the ancient Babylonian astrologers and astronomers.[11] This is largely due to the current fragmentary state of Babylonian planetary theory,[3] and also due to Babylonian astronomy being independent from cosmology at the time.[12] Nevertheless, traces of cosmology can be found in Babylonian literature and mythology.\\r\\nIn Babylonian cosmology, the Earth and the heavens were depicted as a \\"spatial whole, even one of round shape\\" with references to \\"the circumference of heaven and earth\\" and \\"the totality of heaven and earth\\". Their worldview was not exactly geocentric either. The idea of geocentrism, where the center of the Earth is the exact center of the universe, did not yet exist in Babylonian cosmology, but was established later by the Greek philosopher Aristotle's On the Heavens. In contrast, Babylonian cosmology suggested that the cosmos revolved around circularly with the heavens and the earth being equal and joined as a whole.[13] The Babylonians and their predecessors, the Sumerians, also believed in a plurality of heavens and earths. This idea dates back to Sumerian incantations of the 2nd millennium BC, which refers to there being seven heavens and seven earths, linked possibly chronologically to the creation by seven generations of gods.[14]\\r\\nNeo-Babylonian astronomy refers to the astronomy developed by Chaldean astronomers during the Neo-Babylonian, Achaemenid, Seleucid, and Parthian periods of Mesopotamian history. A significant increase in the quality and frequency of Babylonian observations appeared during the reign of Nabonassar (747ÿ734 BC). The systematic records of ominous phenomena in Babylonian astronomical diaries that began at this time allowed for the discovery of a repeating 18-year Saros cycle of lunar eclipses, for example.[15] The Greco-Egyptian astronomer Ptolemy later used Nabonassar's reign to fix the beginning of an era, since he felt that the earliest usable observations began at this time.\\r\\nThe last stages in the development of Babylonian astronomy took place during the time of the Seleucid Empire (323ÿ60 BC). In the 3rd century BC, astronomers began to use \\"goal-year texts\\" to predict the motions of the planets. These texts compiled records of past observations to find repeating occurrences of ominous phenomena for each planet. About the same time, or shortly afterwards, astronomers created mathematical models that allowed them to predict these phenomena directly, without consulting past records.\\r\\nThough there is a lack of surviving material on Babylonian planetary theory,[3] it appears most of the Chaldean astronomers were concerned mainly with ephemerides and not with theory. It had been thought that most of the predictive Babylonian planetary models that have survived were usually strictly empirical and arithmetical, and usually did not involve geometry, cosmology, or speculative philosophy like that of the later Hellenistic models,[16] though the Babylonian astronomers were concerned with the philosophy dealing with the ideal nature of the early universe.[2] Babylonian procedure texts describe, and ephemerides employ, arithmetical procedures to compute the time and place of significant astronomical events.[17] More recent analysis of previously unpublished cuneiform tablets in the British Museum, dated between 350 and 50 BC, demonstrates that Babylonian astronomers sometimes used geometrical methods, prefiguring the methods of the Oxford Calculators, to describe the motion of Jupiter over time in an abstract mathematical space.[18][19]\\r\\nIn contrast to Greek astronomy which was dependent upon cosmology, Babylonian astronomy was independent from cosmology.[12] Whereas Greek astronomers expressed \\"prejudice in favor of circles or spheres rotating with uniform motion\\", such a preference did not exist for Babylonian astronomers, for whom uniform circular motion was never a requirement for planetary orbits.[20] There is no evidence that the celestial bodies moved in uniform circular motion, or along celestial spheres, in Babylonian astronomy.[21]\\r\\nContributions made by the Chaldean astronomers during this period include the discovery of eclipse cycles and saros cycles, and many accurate astronomical observations. For example, they observed that the Sun's motion along the ecliptic was not uniform, though they were unaware of why this was; it is today known that this is due to the Earth moving in an elliptic orbit around the Sun, with the Earth moving swifter when it is nearer to the Sun at perihelion and moving slower when it is farther away at aphelion.[22]\\r\\nChaldean astronomers known to have followed this model include Naburimannu (fl. 6thÿ3rd century BC), Kidinnu (d. 330 BC), Berossus (3rd century BCE), and Sudines (fl. 240 BCE). They are known to have had a significant influence on the Greek astronomer Hipparchus and the Egyptian astronomer Ptolemy, as well as other Hellenistic astronomers.\\r\\nThe only surviving planetary model from among the Chaldean astronomers is that of the Hellenistic Seleucus of Seleucia (b. 190 BC), who supported the Greek Aristarchus of Samos' heliocentric model.[23][24][25] Seleucus is known from the writings of Plutarch, Aetius, Strabo, and Muhammad ibn Zakariya al-Razi. The Greek geographer Strabo lists Seleucus as one of the four most influential astronomers, who came from Hellenistic Seleuceia on the Tigris, alongside Kidenas (Kidinnu), Naburianos (Naburimannu), and Sudines. Their works were originally written in the Akkadian language and later translated into Greek.[26] Seleucus, however, was unique among them in that he was the only one known to have supported the heliocentric theory of planetary motion proposed by Aristarchus,[27][28][29] where the Earth rotated around its own axis which in turn revolved around the Sun. According to Plutarch, Seleucus even proved the heliocentric system through reasoning, though it is not known what arguments he used.[30]\\r\\nAccording to Lucio Russo, his arguments were probably related to the phenomenon of tides.[31] Seleucus correctly theorized that tides were caused by the Moon, although he believed that the interaction was mediated by the Earth's atmosphere. He noted that the tides varied in time and strength in different parts of the world. According to Strabo (1.1.9), Seleucus was the first to state that the tides are due to the attraction of the Moon, and that the height of the tides depends on the Moon's position relative to the Sun.[26]\\r\\nAccording to Bartel Leendert van der Waerden, Seleucus may have proved the heliocentric theory by determining the constants of a geometric model for the heliocentric theory and by developing methods to compute planetary positions using this model. He may have used trigonometric methods that were available in his time, as he was a contemporary of Hipparchus.[32]\\r\\nNone of his original writings or Greek translations have survived, though a fragment of his work has survived only in Arabic translation, which was later referred to by the Persian philosopher Muhammad ibn Zakariya al-Razi (865-925).[33]\\r\\nMany of the works of ancient Greek and Hellenistic writers (including mathematicians, astronomers, and geographers) have been preserved up to the present time, or some aspects of their work and thought are still known through later references. However, achievements in these fields by earlier ancient Near Eastern civilizations, notably those in Babylonia, were forgotten for a long time. Since the discovery of key archaeological sites in the 19th century, many cuneiform writings on clay tablets have been found, some of them related to astronomy. Most known astronomical tablets have been described by Abraham Sachs and later published by Otto Neugebauer in the Astronomical Cuneiform Texts (ACT).\\r\\nSince the rediscovery of the Babylonian civilization, it has been theorized that there was significant information exchange between classical and Hellenistic astronomy and Chaldean. The best documented borrowings are those of Hipparchus (2nd century BCE) and Claudius Ptolemy (2nd century CE).\\r\\nSome scholars support that the Metonic cycle may have been learned by the Greeks from Babylonian scribes. Meton of Athens, a Greek astronomer of the 5th century BCE, developed a lunisolar calendar based on the fact that 19 solar years is about equal to 235 lunar months, a period relation that perhaps was also known to the Babylonians.\\r\\nIn the 4th century BCE, Eudoxus of Cnidus wrote a book on the fixed stars. His descriptions of many constellations, especially the twelve signs of the zodiac show similarities to Babylonian. The following century Aristarchus of Samos used an eclipse cycle called the Saros cycle to determine the year length. However, the position that there was an early information exchange between Greeks and Chaldeans are weak inferences; possibly, there had been a stronger information exchange between the two after Alexander the Great established his empire over Persia in the latter part of the 4th century BCE.\\r\\nIn 1900, Franz Xaver Kugler demonstrated that Ptolemy had stated in his Almagest IV.2 that Hipparchus improved the values for the Moon's periods known to him from \\"even more ancient astronomers\\" by comparing eclipse observations made earlier by \\"the Chaldeans\\", and by himself. However Kugler found that the periods that Ptolemy attributes to Hipparchus had already been used in Babylonian ephemerides, specifically the collection of texts nowadays called \\"System B\\" (sometimes attributed to Kidinnu). Apparently Hipparchus only confirmed the validity of the periods he learned from the Chaldeans by his newer observations. Later Greek knowledge of this specific Babylonian theory is confirmed by 2nd-century papyrus, which contains 32 lines of a single column of calculations for the Moon using this same \\"System B\\", but written in Greek on papyrus rather than in cuneiform on clay tablets.[34]\\r\\nIt is clear that Hipparchus (and Ptolemy after him) had an essentially complete list of eclipse observations covering many centuries. Most likely these had been compiled from the \\"diary\\" tablets: these are clay tablets recording all relevant observations that the Chaldeans routinely made. Preserved examples date from 652 BC to AD 130, but probably the records went back as far as the reign of the Babylonian king Nabonassar: Ptolemy starts his chronology with the first day in the Egyptian calendar of the first year of Nabonassar; i.e., 26 February 747 BC.\\r\\nThis raw material by itself must have been tough to use, and no doubt the Chaldeans themselves compiled extracts of e.g., all observed eclipses (some tablets with a list of all eclipses in a period of time covering a saros have been found). This allowed them to recognise periodic recurrences of events. Among others they used in System B (cf. Almagest IV.2):\\r\\nThe Babylonians expressed all periods in synodic months, probably because they used a lunisolar calendar. Various relations with yearly phenomena led to different values for the length of the year.\\r\\nSimilarly various relations between the periods of the planets were known. The relations that Ptolemy attributes to Hipparchus in Almagest IX.3 had all already been used in predictions found on Babylonian clay tablets.\\r\\nOther traces of Babylonian practice in Hipparchus' work are\\r\\nAll this knowledge was transferred to the Greeks probably shortly after the conquest by Alexander the Great (331 BC). According to the late classical philosopher Simplicius (early 6th century), Alexander ordered the translation of the historical astronomical records under supervision of his chronicler Callisthenes of Olynthus, who sent it to his uncle Aristotle. It is worth mentioning here that although Simplicius is a very late source, his account may be reliable. He spent some time in exile at the Sassanid (Persian) court, and may have accessed sources otherwise lost in the West. It is striking that he mentions the title tresis (Greek: guard) which is an odd name for a historical work, but is in fact an adequate translation of the Babylonian title massartu meaning \\"guarding\\" but also \\"observing\\". Anyway, Aristotle's pupil Callippus of Cyzicus introduced his 76-year cycle, which improved upon the 19-year Metonic cycle, about that time. He had the first year of his first cycle start at the summer solstice of 28 June 330 BC (Julian proleptic date), but later he seems to have counted lunar months from the first month after Alexander's decisive battle at Gaugamela in fall 331 BC. So Callippus may have obtained his data from Babylonian sources and his calendar may have been anticipated by Kidinnu. Also it is known that the Babylonian priest known as Berossus wrote around 281 BC a book in Greek on the (rather mythological) history of Babylonia, the Babyloniaca, for the new ruler Antiochus I; it is said that later he founded a school of astrology on the Greek island of Kos. Another candidate for teaching the Greeks about Babylonian astronomy/astrology was Sudines who was at the court of Attalus I Soter late in the 3rd century BC.\\r\\nIn any case, the translation of the astronomical records required profound knowledge of the cuneiform script, the language, and the procedures, so it seems likely that it was done by some unidentified Chaldeans. Now, the Babylonians dated their observations in their lunisolar calendar, in which months and years have varying lengths (29 or 30 days; 12 or 13 months respectively). At the time they did not use a regular calendar (such as based on the Metonic cycle like they did later), but started a new month based on observations of the New Moon. This made it very tedious to compute the time interval between events.\\r\\nWhat Hipparchus may have done is transform these records to the Egyptian calendar, which uses a fixed year of always 365 days (consisting of 12 months of 30 days and 5 extra days): this makes computing time intervals much easier. Ptolemy dated all observations in this calendar. He also writes that \\"All that he (=Hipparchus) did was to make a compilation of the planetary observations arranged in a more useful way\\" (Almagest IX.2). Pliny states (Naturalis Historia II.IX(53)) on eclipse predictions: \\"After their time (=Thales) the courses of both stars (=Sun and Moon) for 600 years were prophesied by Hipparchus, ...\\". This seems to imply that Hipparchus predicted eclipses for a period of 600 years, but considering the enormous amount of computation required, this is very unlikely. Rather, Hipparchus would have made a list of all eclipses from Nabonasser's time to his own.","input":"How long ago were the ancient babylonians charting positions of the planets and stars?"},{"output":"John Roberts","context":" \\r\\n\\r\\n\\r\\n\\r\\nThe Chief Justice of the United States is the chief judge of the Supreme Court of the United States. As such, he is head of the United States federal court system, which functions as the judicial branch of the nation's federal government. The Chief Justice is one of nine Supreme Court justices; the other eight have the title Associate Justice.\\r\\nThe Chief Justice, as the highest judicial officer in the country, serves as a spokesperson for the federal government's judicial branch, and acts as a chief administrative officer for the federal courts. He is also head of the Judicial Conference of the United States, and in that capacity appoints the director of the Administrative Office of the United States Courts. By law, he is also a member of the Board of Regents of the Smithsonian Institution, and by custom is elected chancellor of the board.\\r\\nThe Chief Justice leads the business of the Supreme Court and presides over oral arguments. When the court renders an opinion, the Chief Justicewhen in the majoritydecides who writes the court's opinion. The Chief Justice also has significant agenda-setting power over the court's meetings. In the case of an impeachment of a President of the United States, which has occurred twice, the Chief Justice presides over the trial in the U.S. Senate. Additionally, the presidential oath of office is typically administered by the Chief Justice (although the Constitution does not assign this duty to anyone in particular).\\r\\nSince the Supreme Court was established in 1789, 17 persons have served as chief justice. The first was John Jay (1789ÿ1795). The current chief justice is John Roberts (since 2005). FourEdward Douglass White, Charles Evans Hughes, Harlan Fiske Stone, and William Rehnquistwere previously confirmed for associate justice and subsequently confirmed for chief justice separately.\\r\\n\\r\\n\\r\\nThe United States Constitution does not explicitly establish an office of Chief Justice, but presupposes its existence with a single reference in Article I, Section 3, Clause 6: \\"When the President of the United States is tried, the Chief Justice shall preside.\\" Nothing more is said in the Constitution regarding the office. Article III, Section 1, which authorizes the establishment of the Supreme Court, refers to all members of the Court simply as \\"judges.\\" The Judiciary Act of 1789 created the distinctive titles of Chief Justice of the Supreme Court of the United States and Associate Justice of the Supreme Court of the United States.\\r\\nIn 1866, at the urging of Salmon P. Chase, Congress restyled the chief justice's title to the current Chief Justice of the United States. The first person whose Supreme Court commission contained the modified title was Melville Fuller in 1888.[1] The associate justices' title was not altered in 1866, and remains as originally created.\\r\\nThe chief justice, like all federal judges, is nominated by the President and confirmed to office by the U.S. Senate. Article III, Section 1 of the Constitution specifies that they \\"shall hold their Offices during good Behavior\\". This language means that the appointments are effectively for life, and that, once in office, a justice's tenure ends only when they die, retire, resign, or are removed from office through the impeachment process.\\r\\nThe salary of the chief justice is set by Congress; the current (2017) annual salary is $263,300, which is slightly higher than that of associate justices, which is $251,800.[2] The practice of appointing an individual to serve as chief justice is grounded in tradition; while the Constitution mandates that there be a chief justice, it is silent on the subject of how one is chosen and by whom. There is no specific constitutional prohibition against using another method to select the chief justice from among those justices properly appointed and confirmed to the Supreme Court. Constitutional law scholar Todd Pettys has proposed that presidential appointment of chief justices should be done away with, and replaced by a process that permits the Justices to select their own chief justice.[3]\\r\\nThree incumbent associate justices have been nominated by the president and confirmed by the Senate as chief justice: Edward Douglass White in 1910, Harlan Fiske Stone in 1941, and William Rehnquist in 1986. A fourth, Abe Fortas, was nominated to the position in 1968, but not confirmed. As an associate justice does not have to resign his or her seat on the Court in order to be nominated as chief justice, Fortas remained an associate justice. Similarly, when associate justice William Cushing was nominated and confirmed as chief justice in January 1796, but declined the office, he too remained on the Court. Additionally, two former associate justices subsequently returned to service on the Court as chief justice. John Rutledge was the first. President Washington gave him a recess appointment in 1795. However, his subsequent nomination to the office was not confirmed by the Senate, and he left office and the Court. In 1933, former associate justice Charles Evans Hughes was confirmed as chief justice.\\r\\nAlong with his general responsibilities as a member of the Supreme Court, the Chief Justice has several unique duties to fulfill.\\r\\nArticle I, section 3 of the U.S. Constitution stipulates that the Chief Justice shall preside over impeachment trials of the President of the United States in the U.S. Senate. Two Chief Justices, Salmon P. Chase and William Rehnquist, have presided over the trial in the Senate that follows an impeachment of the president ÿ Chase in 1868 over the proceedings against President Andrew Johnson and Rehnquist in 1999 over the proceedings against President Bill Clinton. Both presidents were subsequently acquitted.\\r\\nMany of the procedures and inner workings of the Court turn on the seniority of the justices. Traditionally, the chief justice has been regarded as primus inter pares (first among equals)that is, the chief justice is the highest-ranking and foremost member of the Court, regardless of that officeholder's length of service when compared against that of any associate justice. This seniority and added prestige enables a chief justice to define the Court's culture and norms, and thus influence how it functions. The chief justice sets the agenda for the weekly meetings where the justices review the petitions for certiorari, to decide whether to hear or deny each case. The Supreme Court agrees to hear less than one percent of the cases petitioned to it. While associate justices may append items to the weekly agenda, in practice this initial agenda-setting power of the chief justice has significant influence over the direction of the court. Nonetheless, a chief justice's influence may be limited by circumstances and the associate justices' understanding of legal principles; it is definitely limited by the fact that he has only a single vote of nine on the decision whether to grant or deny certiorari.[4][5]\\r\\nDespite the chief justice's elevated stature, his vote carries the same legal weight as the vote of each associate justice. Additionally, he has no legal authority to overrule the verdicts or interpretations of the other eight judges or tamper with them.[4] The task of assigning who shall write the opinion for the majority falls to the most senior justice in the majority. Thus, when the chief justice is in the majority, he always assigns the opinion.[6] Early in his tenure, Chief Justice John Marshall insisted upon holdings which the justices could unanimously back as a means to establish and build the Court's national prestige. In doing so, Marshall would often write the opinions himself, and actively discouraged dissenting opinions. Associate Justice William Johnson eventually persuaded Marshall and the rest of the Court to adopt its present practice: one justice writes an opinion for the majority, and the rest are free to write their own separate opinions or not, whether concurring or dissenting.[7]\\r\\nThe chief justice's formal prerogativewhen in the majorityto assign which justice will write the Court's opinion is perhaps his most influential power,[5] as this enables him to influence the historical record.[4] He \\"may assign this task to the individual justice best able to hold together a fragile coalition, to an ideologically amenable colleague, or to himself.\\" Opinion authors can have a big influence on the content of an opinion; two justices in the same majority, given the opportunity, might write very different majority opinions.[5] A chief justice who knows well the associate justices can therefore do muchby the simple act of selecting the justice who writes the opinion of the courtto affect the general character or tone of an opinion, which in turn can affect the interpretation of that opinion in cases before lower courts in the years to come.\\r\\nAdditionally, the chief justice chairs the conferences where cases are discussed and tentatively voted on by the justices. He normally speaks first and so has influence in framing the discussion. Although the chief justice votes firstthe Court votes in order of seniorityhe may strategically pass in order to ensure membership in the majority if desired.[5] It is reported that:\\r\\nChief Justice Warren Burger was renowned, and even vilified in some quarters, for voting strategically during conference discussions on the Supreme Court in order to control the Courts agenda through opinion assignment. Indeed, Burger is said to have often changed votes to join the majority coalition, cast \\"phony votes\\" by voting against his preferred position, and, declined to express a position at conference.[8]\\r\\nThe Chief Justice typically administers the oath of office at the inauguration of the President of the United States. This is a tradition, rather than a constitutional responsibility of the Chief Justice; the Constitution does not require that the oath be administered by anyone in particular, simply that it be taken by the president. Law empowers any federal and state judge, as well as notaries public (such as John Calvin Coolidge, Sr., to administer oaths and affirmations.\\r\\nIf the Chief Justice is ill or incapacitated, the oath is usually administered by the next senior member of the Supreme Court. Seven times, someone other than the Chief Justice of the United States administered the oath of office to the President.[9] Robert Livingston, as Chancellor of the State of New York (the state's highest ranking judicial office), administered the oath of office to George Washington at his first inauguration; there was no Chief Justice of the United States, nor any other federal judge prior to their appointments by President Washington in the months following his inauguration. William Cushing, an associate justice of the Supreme Court, administered Washington's second oath of office in 1793. Calvin Coolidge's father, a notary public, administered the oath to his son after the death of Warren Harding.[10] This, however, was contested upon Coolidge's return to Washington and his oath was re-administered by Judge Adolph A. Hoehling, Jr. of the U.S. District Court for the District of Columbia.[11] John Tyler and Millard Fillmore were both sworn in on the death of their predecessors by Chief Justice William Cranch of the Circuit Court of the District of Columbia.[12] Chester A. Arthur and Theodore Roosevelt's initial oaths reflected the unexpected nature of their taking office. On November 22, 1963, after the assassination of President John F. Kennedy, Judge Sarah T. Hughes, a federal district court judge of the United States District Court for the Northern District of Texas, administered the oath of office to then Vice President Lyndon B. Johnson aboard the presidential airplane.\\r\\nIn addition, the Chief Justice ordinarily administers the oath of office to newly appointed and confirmed associate justices, whereas the senior associate justice will normally swear in a new Chief Justice or vice president.\\r\\nSince the tenure of William Howard Taft, the office of the Chief Justice has moved beyond just first among equals.[13] The Chief Justice also:\\r\\nUnlike Senators and Representatives who are constitutionally prohibited from holding any other \\"office of trust or profit\\" of the United States or of any state while holding their congressional seats, the Chief Justice and the other members of the federal judiciary are not barred from serving in other positions. Chief Justice John Jay served as a diplomat to negotiate the so-called Jay Treaty (also known as the Treaty of London of 1794), Justice Robert H. Jackson was appointed by President Truman to be the U.S. Prosecutor in the Nuremberg trials of leading Nazis, and Chief Justice Earl Warren chaired The President's Commission on the Assassination of President Kennedy. As described above, the Chief Justice holds office in the Smithsonian Institution and the Library of Congress.\\r\\nUnder 28 USC,[15] when the Chief Justice is unable to discharge his functions, or that office is vacant, his duties are carried out by the most senior associate justice who is able to act, until the disability or vacancy ends, as chief justice.[3] As of February 13, 2016, Anthony Kennedy is the most senior associate justice.\\r\\nSince the Supreme Court was established in 1789, the following 17 persons have served as Chief Justice:[16]","input":"Who is chief justice of the supreme court?"},{"output":"Princess Princep Shah of Nepal","context":"Nepal Red Cross Society (NRCS)(Devnagari: ????? ??????? ???????) is an independent, volunteer-based and nonprofit-humanitarian organization that delivers humanitarian service and support to the vulnerable people in an impartial and neutral manner. It came into being on 4 September 1963.\\r\\nNepal Red Cross Society was officially registered in Nepal after Nepal Government acceded to the Geneva Conventions (August 12, 1949). Having been recognized by the International Committee of the Red Cross (ICRC) and affiliated to International Federation of Red Cross and Red Crescent Societies (IFRC) on 1 October 1964.\\r\\n\\r\\nNRCS has, over the years, grown to be the largest humanitarian organization in Nepal, with its network of District Chapters (DCs) extended in each of the 77 districts of the country. District Chapters receive organizational support from more than 1,508 Sub-Chapters, 5,410 Junior and 865 Youth Red Cross Circles and Co-operation Committees under them. In addition, NRCS has been providing its services from 2 eye hospital, extended eye care centres, 106 blood transfusion centers, 210 ambulance service stations and 12 warehouses within the country.\\r\\n\\r\\nNearly after 100 years of establishment of red cross in the world. By observing the need of establishment of the Red Cross in Nepal, in the chairmanship of then Health Minister Dr. Nageshwar Prasad Singh a meeting was called at Singha Durbar, after Nepal Government acceded to the Geneva Conventions. Nepal Red Cross Society came into being on 4 September 1963. Princess Princep Shah of Nepal helped found the Nepal Red Cross and was its first President.\\r\\n\\r\\nNepal Red Cross Society (NRCS) has District Chapters (DC) in each district of the country. Which receives organizational support from Sub-Chapters, Youth/Junior Red Cross Circles and Co-operation Committees under them.\\r\\n\\r\\nCentral Committees provide guidance to bringing effectiveness in programme having National Network.\\r\\n\\r\\nThere are five regional committees and other committees related to management and technical areas. District chapter and sub-chapter have separate committees working in local level.\\r\\n\\r\\nNepal Red Cross Society has Regional Coordination Committees in each 5 development regions.\\r\\n\\r\\nThe first provincial assembly elections in Nepal was held in two phase on 26 November 2017 and on 7 December 2017. As the government changed its structure through the constitution of Nepal. Nepal Red Cross Society also needed to change its structure as per the government's setup. Thus, NRCS reformed its statute on 47th General Convention of the central assembly held at Biratnagar. As per the new statue NRCS has changed its structure into four levels ÿ local, district, provincial and central levels.[5]\\r\\n\\r\\nNepal Red Cross Society has district chapters in all 77 districts of the country. These district chapters receive organizational support from Sub-Chapters at local level, Junior/ Youth Red Cross Circles in district level and coordinating committees under them.\\r\\n\\r\\nSub-Chapters are the local level committees reaching every ward of the district. The working area of sub-chapters are divided into various wards of the Village / Municipality / Metropolitan City. These sub-chapters receives organizational support from Junior/ Youth Red Cross Circles based on schools and coordinating committees at communities.\\r\\n\\r\\nNRCS has District Chapter in each district within the country. And more than 10 Sub-Chapters are established in each district.\\r\\n\\r\\nBlood Transfusion Service of Nepal Red Cross Society was established in the year 1966 i.e. 3 years after the inception of the Society itself. The government of Nepal, in its policy declaration of 1991, has mandated Nepal Red Cross Society as the sole authority in conducting blood programmes in Nepal.\\r\\n\\r\\nThe Central Blood Transfusion Service Center (CBTSC) in Kathmandu is responsible for management of services in the Kathmandu valley, and for supervising and monitoring the technical standards of the district centers, providing guidance to ensure the collection and supply of safe blood.\\r\\n\\r\\nFour of the five regions have blood transfusion service centers at Biratnagar, Pokhra, Nepalganj and Chitwan. Those provide local services, and thus there is no distinct functioning management structure at the regional level.\\r\\n\\r\\nThe district BTSCs are managed by NRCS district chapters. These centres are supposed to comply with guidelines provided under the 1983 NRCS regulations and the 1998 Standard Operating Procedures.\\r\\n\\r\\nNepal Red Cross Society has been managing eye care services as a key component of health service in Mid-West Region (Province no 6) since 1990s through eye care centers (Surkhet, Dailekh, Jajarkot and Bardia) and outreach program with the support of Swiss Red Cross. NRCS is operating 2 eye hospitals and extended eye care centers within the country.\\r\\n\\r\\nThe Nepal Red Cross Society has its National Training Center, Human Resource Development Institute (HRDI) at Budol, Banepa, Kavre, Nepal.\\r\\n\\r\\n?Afghanistan \\r\\n?Albania \\r\\n?Algeria \\r\\n?Andorra \\r\\n?Angola \\r\\n?Antigua and Barbuda \\r\\n?Argentina \\r\\n?Armenia \\r\\n?Australia \\r\\n?Austria \\r\\n?Azerbaijan \\r\\n?The Bahamas \\r\\n?Bahrain \\r\\n?Bangladesh \\r\\n?Barbados \\r\\n?Belarus \\r\\n?Belgium \\r\\n?Belize \\r\\n?Benin \\r\\n?Bolivia \\r\\n?Bosnia and Herzegovina \\r\\n?Botswana \\r\\n?Brazil \\r\\n?Brunei Darussalam \\r\\n?Bulgaria \\r\\n?Burkina Faso \\r\\n?Burundi \\r\\n?Cambodia \\r\\n?Cameroon \\r\\n?Canada \\r\\n?Cape Verde \\r\\n?Central African Republic \\r\\n?Chad \\r\\n?Chile \\r\\n?China \\r\\n?Colombia \\r\\n?Comoros \\r\\n?Congo \\r\\n?Congo, Democratic Republic of \\r\\n?Cook Islands \\r\\n?Costa Rica \\r\\n?C?te d'Ivoire \\r\\n?Croatia \\r\\n?Cuba \\r\\n?Cyprus \\r\\n?Czech Republic \\r\\n?Denmark \\r\\n?Djibouti \\r\\n?Dominica \\r\\n\\r\\n?Dominican Republic \\r\\n?Ecuador \\r\\n?Egypt \\r\\n?El Salvador \\r\\n?Equatorial Guinea \\r\\n?Eritrea (pending recognition and admission) \\r\\n?Estonia \\r\\n?Ethiopia \\r\\n?Fiji \\r\\n?Finland \\r\\n?France \\r\\n?Gabon \\r\\n?Gambia \\r\\n?Georgia \\r\\n?Germany \\r\\n?Ghana \\r\\n?Greece \\r\\n?Grenada \\r\\n?Guatemala \\r\\n?Guinea \\r\\n?Guinea-Bissau \\r\\n?Guyana \\r\\n?Haiti \\r\\n?Honduras \\r\\n?Hong Kong \\r\\n?Hungary \\r\\n?Iceland \\r\\n?India \\r\\n?Indonesia \\r\\n?Iran, Islamic Republic of \\r\\n?Iraq \\r\\n?Ireland \\r\\n?Israel \\r\\n?Italy \\r\\n?Jamaica \\r\\n?Japan \\r\\n?Jordan \\r\\n?Kazakhstan \\r\\n?Kenya \\r\\n?Kiribati \\r\\n?Korea, Democratic People's Republic of \\r\\n?Korea, the Republic of \\r\\n?Kuwait \\r\\n?Kyrgyzstan \\r\\n?Lao People's Democratic Republic \\r\\n?Latvia \\r\\n?Lebanon \\r\\n?Lesotho \\r\\n\\r\\n?Liberia \\r\\n?Libyan Arab Jamahiriya \\r\\n?Liechtenstein \\r\\n?Lithuania \\r\\n?Luxembourg \\r\\n?Macedonia \\r\\n?Madagascar \\r\\n?Malawi \\r\\n?Malaysia \\r\\n?Mali \\r\\n?Malta \\r\\n?Mauritania \\r\\n?Mauritius \\r\\n?Mexico \\r\\n?Micronesia, Federated States of \\r\\n?Moldova \\r\\n?Monaco \\r\\n?Mongolia \\r\\n?Montenegro \\r\\n?Morocco \\r\\n?Mozambique \\r\\n?Myanmar \\r\\n?Namibia \\r\\n?Nepal \\r\\n?Netherlands \\r\\n?New Zealand \\r\\n?Nicaragua \\r\\n?Niger \\r\\n?Nigeria \\r\\n?Norway \\r\\n?Pakistan \\r\\n?Palau \\r\\n?Palestine \\r\\n?Panama \\r\\n?Papua New Guinea \\r\\n?Paraguay \\r\\n?Peru \\r\\n?Philippines\\r\\n?Poland \\r\\n?Portugal \\r\\n?Qatar \\r\\n?Romania \\r\\n?Russian Federation \\r\\n?Rwanda \\r\\n?Sahrawi Arab Democratic Republic (pending recognition and admission) \\r\\n?Saint Kitts and Nevis \\r\\n?Saint Lucia \\r\\n?Saint Vincent and the Grenadines \\r\\n\\r\\n?Samoa \\r\\n?San Marino, Republic of \\r\\n?Sao Tome and Principe \\r\\n?Saudi Arabia \\r\\n?Senegal \\r\\n?Serbia \\r\\n?Seychelles \\r\\n?Sierra Leone \\r\\n?Singapore \\r\\n?Slovakia \\r\\n?Slovenia \\r\\n?Solomon Islands \\r\\n?Somalia \\r\\n?South Africa \\r\\n?Spain \\r\\n?Sri Lanka \\r\\n?Sudan \\r\\n?Suriname \\r\\n?Swaziland \\r\\n?Sweden \\r\\n?Switzerland \\r\\n?Syria \\r\\n?Taiwan\\r\\n?Tajikistan \\r\\n?Tanzania, United Republic of \\r\\n?Thailand \\r\\n?Timor-Leste \\r\\n?Togo \\r\\n?Tonga \\r\\n?Trinidad and Tobago \\r\\n?Tunisia \\r\\n?Turkey \\r\\n?Turkmenistan \\r\\n?Tuvalu \\r\\n?Uganda \\r\\n?Ukraine \\r\\n?United Arab Emirates \\r\\n?United Kingdom \\r\\n?United States \\r\\n?Uruguay \\r\\n?Uzbekistan \\r\\n?Vanuatu \\r\\n?Venezuela \\r\\n?Viet Nam \\r\\n?Yemen \\r\\n?Zambia \\r\\n?Zimbabwe","input":"Who was the founder of nepal red cross society?"},{"output":"Pangasinan","context":"Pangasinan (Pangasinan: Luyag na Pangasinan; Ilocano: Probinsia ti Pangasinan; Filipino: Lalawigan ng Pangasinan) is a province in the Philippines. Its provincial capital is Lingayen. Pangasinan is located on the western area of the island of Luzon along the Lingayen Gulf and South China Sea. It has a total land area of 5,451.01 square kilometres (2,104.65?sq?mi).[1] According to the 2015 census, it has a population of 2,956,726 people.[2] The official number of registered voters in Pangasinan is 1,651,814.[3]\\r\\nPangasinan is the name for the province, the people, and the language spoken in the province. Indigenous Pangasinan speakers are estimated to number at least 2 million. The Pangasinan language, which is official in the province, is also one of the officially recognized regional languages in the Philippines. In Pangasinan, there were several ethnic groups who enriched the cultural fabric of the province. Almost all of the people are Pangasinans and the rest are descendants of Bolinao and Ilocano, who settled the eastern and western parts of the province.[4] Pangasinan is also spoken as a second-language by many of the ethnic minorities in Pangasinan. The secondary ethnic groups are the Bolinaos and the Ilocanos.\\r\\nThe name Pangasinan pronounced as \\"Pang-ASINan\\" It means \\"place of salt\\" or \\"place of salt-making\\"; it is derived from the prefix pang, meaning \\"for\\", the root word asin, meaning \\"salt, and suffix an, signifying \\"location\\". At present it is pronounced Pa?gasinan based on the Spanish pronunciation due to their inability to utter or pronounce the nasal sound <nga> /?/. The province is a major producer of salt in the Philippines. Its major products include \\"bagoong\\" (\\"salted-krill\\") and \\"alamang\\" (\\"shrimp-paste\\")\\r\\nPangasinan was first founded by Austronesian peoples who called themselves Anakbanwa by at least 2500 BC. A kingdom called Luyag na Caboloan, which expanded to incorporate much of northwestern Luzon, existed in Pangasinan before the Spanish conquest that began in the 16th century.[5] The Kingdom of Luyag na Kaboloan was known as the Wangdom of Pangasinan in Chinese records. The ancient Pangasinan people were skilled navigators and the maritime trade network that once flourished in ancient Luzon connected Pangasinan with other peoples of Southeast Asia, India, China, Japan and the rest of the Pacific. The ancient kingdom of Luyag na Caboloan was in fact mentioned in Chinese and Indian records as being an important kingdom on ancient trade routes.[5]\\r\\nPopular tourist attractions in Pangasinan include the Hundred Islands National Park in Alaminos City and the white-sand beaches of Bolinao and Dasol. Dagupan City is known for its Bangus Festival (\\"Milkfish Festival\\"). Pangasinan is also known for its delicious mangoes and ceramic oven-baked Calasiao puto (\\"native rice cake\\"). Pangasinan occupies a strategic geo-political position in the central plain of Luzon, known as the rice granary of the Philippines. Pangasinan has been described as a gateway to northern Luzon and as the heartland of the Philippines.\\r\\nThe Pangasinan people, like most of the people in the Malay Archipelago, are descendants of the Austronesian-speakers who settled in Southeast Asia since prehistoric times. Comparative genetics, linguistics and archaeological studies locate the origin of the Austronesian languages in Sundaland, which was populated as early as 50,000 years ago by modern humans.[6][7][8] The Pangasinan language is one of many languages that belongs to the Malayo-Polynesian languages branch of the Austronesian languages family.\\r\\nA vast maritime trade network connected the distant Austronesian settlements in Southeast Asia, the Pacific and the Indian Ocean. The Pangasinan people were part of this ancient Austronesian civilization.\\r\\nThe ancient Austronesian-speakers were expert navigators. Their outrigger canoes and sailboats were capable of crossing the distant seas. The Malagasy sailed from the Malay archipelago to Madagascar, an island across the Indian Ocean, and probably reached Africa. As the possible predecessors of the Polynesians, large seagoing canoes called \\"bangka\\" (\\"vaka\\" in several Polynesian dialects and \\"waka\\" in Maori) were first developed by Austronesians in the Philippine archipelago which were then used to settle and establish long-distance trade networks with distant Pacific islands from the Micronesian island nations of Guam and Palau as far away as Hawaii and Easter Island and probably reached the Pacific coastline of the Americas. Proof of these trade exchanges are the prevalence of \\"kumara\\" or sweet potato in the Pacific Islands which is endemic to South America, and the abundance of chicken bones in ancient South American archaeological dig sites whose closest genetic relatives are those of chickens from Asia. At least three hundred years before the arrival of Europeans, the Makasar and the Bugis from Sulawesi, in what is now Indonesia, as well as the Sama-Bajaus of the Malay Archipelago, carried out long-distance commerce with their prau or paraw (\\"sailboat\\") and established settlements in north Australia, which they called Marege.[9]\\r\\nPangasinan was founded by Austronesian peoples who called themselves Anakbanwa during the Austronesian expansion from Taiwan and Southern China in about 5000 - 2500 BC or the Austronesian dispersal from Sundaland at least 7,000 years ago after the last Ice Age. Anakbanwa means child of banwa. Banwa (also spelled banua or vanua) is an Austronesian concept that could mean territory, homeland, habitat, society, civilization or cosmos. The Pangasinan people identified or associated banwa with the sun, which was their symbol for their banwa. The Pangasinan people are closely related to the Ibaloi in the neighboring province of Benguet and other peoples of Luzon. The Anakbanwa established their settlements in the banks of the Agno River and the coasts of Lingayen Gulf. The coastal area came to be known as Pangasinan, and the interior area came to be known as Kaboloan. Eventually, the whole region, its people and the used language came to be known as Pangasinan. Archaeological evidence and early Chinese and Indian records show that the inhabitants of Pangasinan traded with India, Arabia, China and Japan as early as the 8th century A.D.\\r\\nThe Wangdom of Pangasinan (As known in Chinese records) and locally known as the ancient kingdom or state called Luyag na Caboloan (also spelled Kaboloan), with Binalatongan as its capital, existed in the fertile Agno River valley. Around the same period, the Srivijaya and Majapahit empires arose in Indonesia that extended their influence to much of the Malay Archipelago. Urduja/Udaya, a legendary woman warrior, is believed to have ruled in Pangasinan around the 14th century. The Luyag na Caboloan expanded the territory and influence of Pangasinan to what are now the neighboring provinces of Tarlac, La Union, Zambales, Nueva Ecija and Benguet. Pangasinan enjoyed full independence until the Spanish conquest.\\r\\nThe ancient Pangasinan people, like other Austronesian peoples, practiced anito-worship. An anito was believed to be the spirit or divine power of an ancestor or the god or divine power in nature or natural phenomena. They believed in mana, an Austronesian concept which can be described as the divine power or vital or spiritual essence of every being and everything that exists. To the Pangasinan people, mana can be transferred, inherited or acquired, like from an ancestor, nature, or natural phenomena. Their belief or practice is similar to Shamanist or animist beliefs and rituals. They worshipped a pantheon of anito (\\"spirit\\" or \\"deity\\"). Their temples or altars were dedicated to a chief anito called Ama Kaoley (Supreme Father), who communicated through mediums or priests called manag-anito. These manag-anito wore special costumes when serving an anito and they made offerings of oils, ointments, essences, and perfumes in exquisite vessels.\\r\\nIn the sixteenth-century Pangasinan was called the \\"Port of Japan\\" by the Spanish. The locals wore native apparel typical of other maritime Southeast Asian ethnic groups in addition to Japanese and Chinese silks. Even common people were clad in Chinese and Japanese cotton garments. They also blackened their teeth and were disgusted by the white teeth of foreigners, which were likened to that of animals. Also, used porcelain jars typical of Japanese and Chinese households. Japanese-style gunpowder weapons were also encountered in naval battles in the area.[10] In exchange for these goods, traders from all over Asia would come to trade primarily for gold and slaves, but also for deerskins, civet and other local products. Other than a notably more extensive trade network with Japan and China, they were culturally similar to other Luzon groups to the south.\\r\\nPangasinans were also described as a warlike people who were long known for their resistance to Spanish conquest. Bishop Domingo Salazar described them as really the worst people, the fiercest and cruelest in the land. There was evidence of Christian influence even before Spanish colonization; they used vintage wine in small quantities for their sacramental practices. The church bragged that they won the northern part of the Philippines for Spain not Spanish military. They were also unusually strict against adulterers, with the punishment being death for both offending parties. Pangasinans were also known to take defeated Zambal and Negrito warriors to sell as slaves to Chinese traders.[11]\\r\\nIn 1324, Odoric of Pordenone, a Franciscan missionary from Friuli, Italy, is believed by some to have celebrated a Catholic Mass and baptized natives at Bolinao, Pangasinan. In July 2007, memorial markers were set up in Bolinao to commemorate Odoric's journey based on a publication by Luigi Malamocco, an Italian priest from Friuli, Italy, who claimed that Odoric of Perdenone held the first Catholic Mass in the Philippines in Bolinao, Pangasinan. That 1324 mass would have predated the mass held in 1521 by Ferdinand Magellan, which is generally regarded as the first mass in the Philippines, by some 197 years. However, historian William Henry Scott concluded after examining Oderic's writings about his travels that he likely never set foot on Philippine soil and, if he did, there is no reason to think that he celebrated mass.[12]\\r\\nOn April 27, 1565, the Spanish conquistador Miguel L܇pez de Legazpi arrived in the Philippine islands with about 500 soldiers to establish a Spanish settlement and begin the conquest of the archipelago. On May 24, 1570, the Spanish forces defeated Rajah Sulayman and other rulers of Manila and later declared Manila as the new capital of the Spanish East Indies. After securing Manila, the Spanish forces continued to conquer the rest of the island of Luzon, including Pangasinan.\\r\\nIn 1571, the Spanish conquest of Pangasinan began with an expedition by the Spanish conquistador Martn de Goiti, who came from the Spanish settlement in Manila through Pampanga. About a year later, another Spanish conquistador, Juan de Salcedo, sailed to Lingayen Gulf and landed at the mouth of the Agno River. Limahong, a Chinese pirate, fled to Pangasinan after his fleet was driven away from Manila in 1574. Limahong failed to establish a colony in Pangasinan, as an army led by Juan de Salcedo chased him out of Pangasinan after a seven-month siege.\\r\\nThe province of Pangasinan dates its actual beginnings as an administrative and judicial district, with Lingayen as the capital, to as early as 1580, but its territorial boundaries were first delineated in 1611. Lingayen has remained the capital of the province except for a brief period during the revolutionary Era when San Carlos served as temporary administrative headquarters, and during the slightly longer Japanese Occupation when Dagupan was the capital.[13]\\r\\nThe province of Pangasinan was formerly classified as an alcaldia mayor de termino, or first class civil province, during the Spanish regime and has, in fact, remained a first class-A province up to the present. Its territorial jurisdiction once included the entire province of Zambales and portions of what are now Tarlac and La Union provinces.[13]\\r\\nAndres Malong, a native chief of the town of Binalatongan (now named San Carlos City), liberated the province from Spanish rule in December 1660. The people of Pangasinan proclaimed Andres Malong Ari na Pangasinan (\\"King of Pangasinan\\"). Pangasinan armies attempted to liberate the neighboring provinces of Pampanga and Ilocos, but were repelled by a Spanish-led coalition of loyalist tribal warriors and mercenaries. In February 1661, the newly independent Kingdom of Pangasinan fell to the Spanish.\\r\\nOn November 3, 1762, the people of Pangasinan proclaimed independence from Spain after a rebellion led by Juan de la Cruz Palaris overthrew Spanish rule in Pangasinan. The Pangasinan revolt was sparked by news of the fall of Manila to the British on October 6, 1762. However, after the Treaty of Paris on March 1, 1763 that closed the Seven Years' War between Britain, France and Spain, the Spanish colonial forces made a counter-attack. On January 16, 1765, Juan de la Cruz Palaris was captured and Pangasinan independence was again lost.\\r\\nThe Katipunan, a nationalist secret society, was founded on July 7, 1892 with the aim of uniting the peoples of the Philippines and fighting for independence and religious freedom. The Philippine Revolution began on August 26, 1896 and was led by Andres Bonifacio, the leader of the Katipunan. On November 18, 1897, a Katipunan council was formed in western Pangasinan with Roman Manalang as Presidente Generalisimo and Mauro Ortiz as General. General Emilio Aguinaldo proclaimed Philippine independence on June 12, 1898. Dagupan City, the major commercial center of Pangasinan, was surrounded by Katipunan forces by July 18, 1898. The Battle of Dagupan lasted from July 18 to July 23 of that year with the surrender of 1,500 soldiers of the Spanish forces under Commander Federico J. Ceballos and Governor Joaquin de Orengochea.\\r\\nThe Battle of Dagupan, fought fiercely by local Katipuneros under the overall command of General Francisco Makabulos, chief of the Central and Directive Committee of Central and Northern Luzon, and the last remnants of the once mighty Spanish Army under General Francisco Ceballos, led to the liberation of Pangasinan from the Spaniards. The five-day battle was joined by three local heroes: Don Daniel Maramba from Santa Barbara, Don Vicente Prado from San Jacinto and Don Juan Quezada from Dagupan. Their armies massed in Dagupan to lay siege on the Spanish forces, making a last stand at the brick-walled Catholic Church.\\r\\nMaramba led the liberation of the town of Santa Barbara on March 7, 1898 following a signal for simultaneous attack from Makabulos. Hearing that Santa Barbara fell into rebel hands, the Spanish forces in Dagupan attempted to retake the town, but were repulsed by Maramba's forces. Thus, after the setback, the Spaniards decided to concentrate their forces in Lingayen to protect the provincial capital. This enabled Maramba to expand his operations to Malasiqui, Urdaneta and Mapandan, taking them one after the other. He took one more town, Mangaldan, before proceeding to Dagupan to lay siege on the last Spanish garrison. Also on March 7, 1898, the rebels under the command of Prado and Quesada attacked convents in a number of towns in Zambales province, located west of Lingayen, which now constitute the western parts of Pangasinan.\\r\\nAttacked and brought under Filipino control were Alaminos, Agno, Anda, Alos, Bani, Balincaguin, Bolinao, Dasol, Eguia and Potot. The revolt then spread to Labrador, Sual, Salasa and many other towns in the west. The towns of Sual, Labrador, Lingayen, Salasa and Bayambang were occupied first by the forces of Prado and Quesada before they proceeded to attack Dagupan.\\r\\nAt an assembly convened to organize a central governing body for Central and Northern Luzon on April 17, 1898, General Makabulos appointed Prado as politico-military governor of Pangasinan, with Quesada as his second in command. His appointment came a few days before the return of General Emilio Aguinaldo in May 1898 from his exile in Hong Kong following the signing of the Pact of Biac-na-Bato in December 1897. Aguinaldo's return gave fresh impetus to the renewal of the flame of the revolution. Thus, on June 3, 1898, General Makabulos entered Tarlac and from that day on, the fires of revolution spread.\\r\\nSo successful were the Filipinos in their many pitched battles against the Spaniards that on June 30, 1898, Spanish authorities decided to evacuate all their forces to Dagupan where a last stand against the rebels was to be made. Also ordered to go to Dagupan were all civilian and military personnel, including members of the volunteer locales of towns not yet in rebel hands. Those who heeded this order were the volunteer forces of Mangaldan, San Jacinto, Pozorrubio, Manaoag, and Villasis. Among those brought to Dagupan was the image of the Most Holy Rosary of the Virgin of Manaoag, which at that time was already the patron saint of Pangasinan.\\r\\nWhen the forces of Maramba from the east and Prado from the west converged in Dagupan on July 18, 1898, the siege began. The arrival of General Makabulos strengthened the rebel forces until the Spaniards, holed up inside the Catholic Church, waved the flag of surrender five days later. Armed poorly, the Filipinos were no match at the very start with Spanish soldiers holed inside the Church. They just became mere sitting ducks to Spanish soldiers shooting with their rifles from a distance. But the tempo of battle changed when the attackers, under Don Vicente Prado, devised a crude means of protection to shield them from Spanish fire while advancing. This happened when they rolled trunks of bananas, bundled up in sawali, that enabled them to inch their way to the Church.\\r\\nPangasinan and other parts of the Spanish East Indies were ceded to the Americans after the Treaty of Paris that closed the SpanishÿAmerican War. During the PhilippineÿAmerican War, Lieutenant Col. Jose Torres Bugallon from the town of Salasa fought together with Gen. Antonio Luna to defend the First Philippine Republic against American colonization of Northern Luzon. Bugallon was killed in battle on February 5, 1899. The First Philippine Republic was abolished in 1901. In 1907, the Philippine Assembly was established and for the first time, five residents of Pangasinan were elected as its district representatives. In 1921, Mauro Navarro, representing Pangasinan in the Philippine Assembly, sponsored a law to rename the town of Salasa to Bugallon in order to honor General Bugallon.\\r\\nDuring the Philippine Commonwealth regime, Manuel L. Quezon was inaugurated as the first president of the Commonwealth of the Philippines under the collaboration from the United States of America on November 15, 1935.\\r\\nThe 21st Infantry Division, Philippine Commonwealth Army, USAFFE was found military establishment and built of the general headquarters was active on July 26, 1941 to June 30, 1946 and they stationed in Pangasinan during the pre-World War II era. From the conflict engagements of the Anti-Japanese Imperial military operations included the fall of Bataan and Corregidor and aiding the USAFFE ground force from January to May 1942 and the Japanese Insurgencies and Allied Liberation in Pangasinan from 1942 to 1945 and some parts in North-Central Luzon and helps local guerrillas and American forces against the Japanese.\\r\\nAfter the declaration of Independence in Manila on July 4, 1946, Eugenio Perez, a Liberal Party congressman representing the fourth district of Pangasinan, was elected Speaker of the lower Legislative House. He led the House until 1953, when the Nacionalista Party became the dominant party.\\r\\nPangasinan, which was historically part of the Central Luzon Region, was made part of the Ilocos Region (Region I) in the gerrymandering of the Philippines by Ferdinand Marcos, despite the fact that Pangasinan has its distinct primary language, which is Pangasinan. The political classification of Pangasinan as part of the Ilocos Region has generated confusion among some Filipinos that the residents of Pangasinan are Ilocanos, even though Ilocanos only constitute a significant minority in the province. Pangasinan has a distinct primary language, ethnic group and culture, its economy is bigger than the predominantly Ilocano provinces of Ilocos Norte, Ilocos Sur and La Union and its population is more than 50 percent of the population of Region 1. Many Pangasinans prefer to have their own Pangasinan Region or be returned to Central Luzon.\\r\\nIn February 1986, Vice Chief of Staff General Fidel V. Ramos, head of the Philippine Integrated National Police and a native of Lingayen, Pangasinan, became one of the instrumental figures of the EDSA people power revolution that led to the overthrow of President Ferdinand Marcos.\\r\\nAfter the downfall of Marcos, all local government unit executives in the Philippines were ordered by President Corazon Aquino to vacate their posts. Some local executives were ordered to return to their seats as in the case of Mayor Ludovico Espinosa of Dasol, where he claims he joined the UNIDO, Mrs. Aquino's party during the height of the EDSA Revolution. Fidel Ramos was appointed as AFP Chief of Staff and later as Defense Secretary replacing Juan Ponce Enrile. Oscar Orbos, a congressman from Bani, Pangasinan, was appointed by Aquino as head of the Department of Transportation and Communications and later as Executive Secretary.\\r\\nOn May 11, 1992, Fidel V. Ramos ran for the position of President. He was elected and became the first Pangasinan President of the Philippines. Through his leadership, the Philippines recovered from a severe economy after the oil and power crisis of 1991. His influence also sparked the economic growth of Pangasinan when it hosted the 1995 Palarong Pambansa (Philippine National Games).\\r\\nJose de Venecia, who represented the same district as Eugenio Perez, was the second Pangasinan to be Speaker of the House of Representatives in 1992. He was reelected for the same position in 1995. De Venecia was selected by the Ramos' administration party Lakas NUCD to be its presidential candidate in 1998. De Venecia ran but lost to Vice President Joseph Estrada. Oscar Orbos, who served as Pangasinan governor from 1995, ran for Vice President, but lost to Senator Gloria Macapagal-Arroyo, whose mother, former First Lady Evangelina Macaraeg-Macapagal, hails from Binalonan, Pangasinan.\\r\\nArroyo later ascended to the presidency after the second EDSA Revolution when President Joseph Estrada was overthrown.\\r\\nIn May 2004, actor-turned-politician Fernando Poe, Jr., whose family is from San Carlos City, Pangasinan, ran for President against incumbent Gloria Macapagal-Arroyo during the Philippine general election in 2004. The Pangasinan vote was almost evenly split by the two presidential candidates who both have Pangasinan roots. Arroyo was elected President, but her victory was tainted by charges of electoral fraud and vote-buying.\\r\\nThe state of crisis of the national government in Manila, corruption in Malaca?ang, widespread poverty and the slow pace of economic development is forcing many Pangasinans to seek opportunities in Metro Manila or other richer provinces, work in other nations or emigrate to wealthier nations, like the United States, Japan, Saudi Arabia or Italy.\\r\\nPangasinan is located on the west central area of the island of Luzon in the Philippines. It is bordered by La Union to the north, Benguet and Nueva Vizcaya to the northeast, Nueva Ecija to the southeast, and Zambales and Tarlac to the south. To the west of Pangasinan is the South China Sea. The province also encloses the Lingayen Gulf.\\r\\nThe province has a land area of 5,451.01 square kilometres (2,104.65?sq?mi).[14] It is 170 kilometres (110?mi) north of Manila, 50 kilometres (31?mi) south of Baguio City, 115 kilometres (71?mi) north of Subic International Airport and Seaport, and 80 square kilometres (31?sq?mi) north of Clark International Airport. At the coast of Alaminos, the Hundred islands have become a famous tourist spot.\\r\\nThe terrain of the province is typically flat, with a few being mountainous. The northeastern municipalities of San Manuel, San Nicolas, Natividad, San Quintin and Umingan have hilly to mountainous areas, situated at the tip of the Cordillera mountains. The Zambales mountains extend to the province's western towns of Labrador, Mabini, Bugallon, Aguilar, Mangatarem, Dasol, and Infanta forming the mountainous portions of those towns.\\r\\nThe Philippine Institute of Volcanology and Seismology (PHIVOLCS) reported several inactive volcanoes in the province: Amorong, Balungao, Cabaluyan, Cahelietan, Candong, and Malabobo. PHIVOLCS reported no active or potentially active volcanoes in Pangasinan. A caldera-like landform is located between the towns of Malasiqui and Villasis with a center at about 15 55 N and 120 30 E near the Cabaruan Hills.\\r\\nSeveral rivers traverse the province. The longest is the Agno River, which originates from the Cordillera mountains of Benguet, eventually emptying its waters into the Lingayen Gulf. Other major rivers include the Bued River, Angalacan River, Sinocalan River, Patalan River and the Cayanga River.\\r\\nThe province of Pangasinan is subdivided into 44 municipalities, 4 cities, and 1,364 barangay (which means \\"village\\" or \\"community\\"). There are six congressional districts in the province.\\r\\nThe capital of the province is Lingayen. In ancient times, the capital of Pangasinan was Binalatongan, now San Carlos City.\\r\\nPangasinan has 1,364 barangays comprising its 44 municipalities and 4 cities, ranking the province at 3rd with the most number of barangays in a Philippine province, only behind Leyte and Iloilo.\\r\\nThe most populous barangay in the province is Bonuan Gueset in Dagupan City, with a population of 22,042 in 2010. If cities are excluded, Poblacion in the municipality of Lingayen has the highest population at 12,642. Iton in Bayambang has the lowest with only 99 in the census of 2010.[15]\\r\\nThe population of Pangasinan in the 2015 census was 2,956,726 people,[2] with a density of 540 inhabitants per square kilometre or 1,400 inhabitants per square mile.\\r\\nThe Pangasinan people (Totoon Pangasinan) are called Pangasinan or the Hispanicized name Pangasinense, or simply taga-Pangasinan, which means \\"from Pangasinan\\". Pangasinan people were known as traders, businesspeople, farmers and fishers. Pangasinan is the third most-populated province in the Philippines. The estimated population of the indigenous speakers of the Pangasinan language in the province of Pangasinan is almost 2 million and is projected to double in about 30 years. According to the 2000 census, 47 percent of the population are native Pangasinan and 44 percent are Ilocanos. Sambal settlers from Zambales also predominate in the westernmost municipalities of Bolinao and Anda. The Pangasinan people are closely related to the Austronesian-speaking peoples of the other parts of the Philippines, as well as Indonesia and Malaysia.\\r\\nThe Pangasinan language is an agglutinative language. It belongs to the Malayo-Polynesian languages branch of the Austronesian language family and is the primary language of the province of Pangasinan, as well as northern Tarlac and southwestern La Union. The Pangasinan language is similar to the other Malayo-Polynesian languages of the Philippines, as well as Indonesia and Malaysia. It is closely related to the Ibaloi language spoken in the neighboring province of Benguet, located northwest of Pangasinan. The Pangasinan language along with Ibaloi are classified under the Pangasinic group of languages. The other Pangasinic languages are:\\r\\nAside from their native language, some educated Pangasinans are also highly proficient in Ilocano, English and Filipino. Pangasinan is mostly spoken in the central part of the province in the 2nd, 3rd, 4th, and is the second language in other parts of Pangasinan. Ilocano is widely spoken in the westernmost and easternmost parts of Pangasinan in the 1st, 5th and 6th districts, and is the second language in other parts of Pangasinan. Ilocanos and Pangasinans speak Ilocano with a Pangasinan accent, as descendants of Ilocanos from first generation who lived within Pangasinan population learned Pangasinan language. Bolinao, a Sambalic language is widely spoken in the western tip of the province in the towns of Bolinao and Anda.\\r\\nThe religion of the people of Pangasinan is predominantly Christianity with Roman Catholicism as the overwhelming majority at 80% affiliation in the population. The second major denomination in the province is the Aglipayan Church with at least 15% of the population. Other religious denominations are divided with other Christian groups such as Members Church of God International, Iglesia Ni Cristo, Baptist, Methodist, Church of Christs of Latter Day Saints (Mormon), Jehovah's Witnesses and Seventh-day Adventist. Few are strict believers and continue to practice their indigenous anito beliefs and rituals, like most of the people of the Philippines.\\r\\nSpanish and American missionaries introduced Christianity to Pangasinan. Prior to the Spanish conquest in 1571, the predominant religion of the people of Pangasinan was similar to the indigenous religion of the highland Igorot or the inhabitants of the Cordillera Administrative Region on the island of Luzon, who mostly retained their indigenous culture and religion. A translation of the New Testament (excluding Revelation) in the Pangasinan language by Fr. Nicolas Manrique Alonzo Lallave, a Spanish Dominican friar assigned in Urdaneta, was the first ever translation of a complete portion of the Bible in a Philippine language. Pangasinan was also influenced by Hinduism, Buddhism and Islam to a lesser extent, before the introduction of Christianity.\\r\\nPangasinan is the richest province in Ilocos Region of the Philippines.[19]\\r\\nThe 1200 megawatt Sual Coal-Fired Power Plant, and 345 megawatt San Roque Multi-Purpose Dam, located in the municipalities of Sual and San Manuel respectively, are the primary sources of energy of the province.\\r\\nPangasinan is a major fish supplier in Luzon, and a major producer of salt in the Philippines. It has extensive fishponds, mostly for raising bangus or \\"milkfish\\", along the coasts of the Lingayen Gulf and the South China Sea. Pangasinan's aquaculture includes oyster and sea urchin farms.\\r\\nSalt is also a major industry here. In salt evaporation ponds seawater is mixed with Sodium-Bicarbonate until the water evaporates and the salt remains. This is their ancient tradition inspired from Egypt.\\r\\nThe major crops in Pangasinan are rice, mangoes, corn, and sugar cane. Pangasinan has a land area of 536,819 hectares, and 44 percent[citation needed] of the total land area of Pangasinan is devoted to agricultural production.\\r\\nPangasinan has 593 banking and financing institutions.[citation needed]\\r\\nPangasinan has a labor force of about 1.52 million, and 87 percent of the labor force are gainfully employed.[citation needed]\\r\\nThere are thousands of public schools and hundreds of private schools across the province for primary and secondary education. Many Pangasinans go to Metro Manila, Baguio City, and the United States for tertiary and higher education.\\r\\nPangasinan has 51 hospitals and clinics and 68 rural health units (as of July 2002). Although some residents go to other parts of the Philippines, Metro Manila, Europe and the United States for extensive medical tests and treatment, almost all Pangasinans go to the major medical centers in the cities of Dagupan, San Carlos and Urdaneta.\\r\\nThe culture of Pangasinan is a blend of the indigenous Malayo-Polynesian and western Hispanic culture, with some Indian and Chinese influences and minor American influences. Today, Pangasinan is very much westernized, yet retains a strong, native Austronesian background.\\r\\nThe main centers of Pangasinan culture are Dagupan City, Lingayen, Manaoag, Calasiao, and San Carlos City.\\r\\nThe current governor of Pangasinan is Amado \\"Pogi\\" Espino, III, son of former governor Amado T. Espino, Jr., and the current vice governor is Jose Ferdinand Calimlim, Jr. Among those who served as Governor of Pangasinan include Tito Primicias, Vicente Millora and Daniel Maramba.\\r\\nNotable people either born or residing in Pangasinan include:","input":"What is the salt capital of the philippines?"},{"output":"pizza","context":"The history of pizza begins in antiquity, when various ancient cultures produced flatbreads with toppings.\\r\\nThe precursor of pizza was probably the focaccia, a flat bread known to the Romans as panis focacius,[1] to which toppings were then added.[2] Modern pizza developed in Naples, when tomato was added to the focaccia in the late 18th century.\\r\\nThe word pizza was first documented in AD 997?in Gaeta[3] and successively in different parts of Central and Southern Italy. Pizza was mainly eaten in the country of Italy and by emigrants from there. This changed after World War II, when Allied troops stationed in Italy came to enjoy pizza along with other Italian foods.\\r\\n\\r\\n\\r\\nFoods similar to pizza have been made since the neolithic age. Records of people adding other ingredients to bread to make it more flavorful can be found throughout ancient history.\\r\\nSome commentators have suggested that the origins of modern pizza can be traced to pizzarelle, which were kosher for Passover cookies eaten by Roman Jews after returning from the synagogue on that holiday, though some also trace its origins to other Italian paschal breads.[9] Abba Eban has suggested that modern pizza \\"was first made more than 2000 years ago when Roman soldiers added cheese and olive oil to matzah\\".[10]\\r\\nOther examples of flatbreads that survive to this day from the ancient Mediterranean world are focaccia (which may date back as far as the ancient Etruscans); Mankoucheh in Lebanon, coca (which has sweet and savory varieties) from Catalonia; Valencia and the Balearic Islands; the Greek Pita; Lepinja in the Balkans; or Piadina in the Romagna part of Emilia-Romagna in Italy.[11]\\r\\nFoods similar to flatbreads in other parts of the world include Chinese bing (a wheat flour-based Chinese food with a flattened or disk-like shape); the Indian paratha (in which fat is incorporated); the Central and South Asian naan (leavened) and roti (unleavened); the Sardinian carasau, spianata, guttiau, pistoccu; and Finnish rieska. Also worth noting is that throughout Europe there are many similar pies based on the idea of covering flat pastry with cheese, meat, vegetables and seasoning such as the Alsatian flammkuchen, German zwiebelkuchen, and French quiche.\\r\\nIn 16th-century Naples, a galette flatbread was referred to as a pizza. Known as the dish for poor people, it was sold in the street and was not considered a kitchen recipe for a long time.[12] This was later replaced by oil, tomatoes (after Europeans came into contact with the Americas) or fish. In 1843, Alexandre Dumas, pre, described the diversity of pizza toppings.[13] An often recounted story holds that on 11 June 1889, to honour the Queen consort of Italy, Margherita of Savoy, the Neapolitan pizzamaker Raffaele Esposito created the \\"Pizza Margherita\\", a pizza garnished with tomatoes, mozzarella, and basil, to represent the national colours of Italy as on the Italian flag.[14][15][16]\\r\\nPizza is now a type of bread and tomato dish, often served with cheese. However, until the late nineteenth or early twentieth century, the dish was sweet, not savory, and earlier versions which were savory more resembled the flat breads now known as schiacciata.[17] Pellegrino Artusi's classic early-twentieth-century cookbook, La Scienza in cucina e l'Arte di mangiar bene gives three recipes for pizza, all of which are sweet.[18] However, by 1927, Ada Boni's collection of regional cooking includes a recipe using tomatoes and mozzarella.[19]\\r\\nThe innovation that led to flat bread pizza was the use of tomato as a topping. For some time after the tomato was brought to Europe from the Americas in the 16th century, it was believed by many Europeans to be poisonous (as some other fruits of the nightshade family are). However, by the late 18th century, it was common for the poor of the area around Naples to add tomato to their yeast-based flat bread, and so the pizza began.[citation needed] The dish gained popularity, and soon pizza became a tourist attraction as visitors to Naples ventured into the poorer areas of the city to try the local specialty.\\r\\nUntil about 1830, pizza was sold from open-air stands and out of pizza bakeries, and pizzerias keep this old tradition alive today. It is possible to enjoy paper-wrapped pizza and a drink sold from open-air stands outside the premises. Antica Pizzeria Port'Alba in Naples is widely regarded as the city's first pizzeria.[20]\\r\\nPurists, like the famous pizzeria \\"Da Michele\\" in Via C. Sersale (founded 1870),[21] consider there to be only two true pizzasthe marinara and the margheritaand that is all they serve. These two \\"pure\\" pizzas are the ones preferred by many Italians today.\\r\\nThe marinara is the older of the two and has a topping of tomato, oregano, garlic, and extra virgin olive oil. It is named marinara because it was traditionally the food prepared by \\"la marinara\\", the seaman's wife, for her seafaring husband when he returned from fishing trips in the Bay of Naples.\\r\\nThe margherita is topped with modest amounts of tomato sauce, mozzarella cheese and fresh basil. It is widely attributed to baker Raffaele Esposito, who worked at \\"Pizzeria di Pietro\\", established in 1880. Though recent research casts doubt on this legend,[22] the tale holds that, in 1889, he baked three different pizzas for the visit of King Umberto I and Queen Margherita of Savoy. The Queen's favorite was a pizza evoking the colors of the Italian flaggreen (basil leaves), white (mozzarella), and red (tomatoes).[23] According to the tale, this combination was named Pizza Margherita in her honor. Although those were the most preferred, today there are many variations of pizzas.\\r\\n\\"Associazione Verace Pizza Napoletana\\"[24] (\\"True Neapolitan Pizza Association\\"), which was founded in 1984, has set the very specific rules that must be followed for an authentic Neapolitan pizza. These include that the pizza must be baked in a wood-fired, domed oven; that the base must be hand-kneaded and must not be rolled with a pin or prepared by any mechanical means (i pizzaiolithe pizza makersmake the pizza by rolling it with their fingers) and that the pizza must not exceed 35 centimetres in diameter or be more than one-third of a centimetre thick at the centre. The association also selects pizzerias all around the world to produce and spread the verace pizza napoletana philosophy and method.\\r\\nThere are many famous pizzerias in Naples where these traditional pizzas can be found such as Da Michele, Port'Alba, Brandi, Di Matteo, Sorbillo, Trianon, and Umberto (founded: 1916).[25] Most of them are in the ancient historical centre of Naples. These pizzerias will go even further than the specified rules by, for example, using only San Marzano tomatoes grown on the slopes of Mount Vesuvius and drizzling the olive oil and adding tomato topping in only a clockwise direction.\\r\\nThe pizza bases in Naples are soft and pliable. In Rome they prefer a thin and crispy base. Another popular form of pizza in Italy is \\"pizza al taglio\\", which is pizza baked in rectangular trays with a wide variety of toppings and sold by weight.\\r\\nIn 1962, the \\"Hawaiian\\" pizza, a pizza topped with pineapple and ham, was invented in Canada by restaurateur Sam Panopoulis at the Satellite Restaurant in Chatham, Ontario.[26]\\r\\nIn December 2009, the pizza napoletana was granted Traditional Speciality Guaranteed status by the European Union.[27]\\r\\nIn 2012, the world's largest pizza was made in Rome, and was measured to be 1261.65 square metres.[28]\\r\\nIn 2016, robotics company BeeHex, widely covered in the media, was building robots that 3D-printed pizza.[29]\\r\\nIn December 2017, the pizza napoletana was inscribed on the UNESCO Intangible Cultural Heritage Lists.[30]\\r\\nCanada was first introduced to pizza in the late 1950s, with the first pizza ovens entering the country.[31] It gained popularity throughout the 1960s, with many pizzerias and restaurants opening across the country. Pizza was mostly served in restaurants and small pizzerias. Most pizza restaurants across Canada also serve popular Italian cuisine in addition to pizza, such as pasta, salad, soups and sandwiches. Fast-food pizza chains also provide other side options for customers to choose from, in addition to ordering pizza, including chicken wings, fries and poutine, salad, and calzones. Pizza chains across Canada can be found in shopping centres, schools, and neighbourhood plazas, with the majority of these chains offering a sit-and-dine facility for customers.\\r\\nThe most distinct pizza in Canada is the \\"Canadian\\" pizza. A Canadian pizza is usually prepared with tomato sauce, mozzarella cheese, mushrooms and bacon. Many variations of this pizza exist, but the two standout ingredients that make this pizza distinctly Canadian are bacon and mushrooms. Pizzas in Canada are almost never served with \\"Canadian bacon\\", or back bacon as it's referred to in Canada. Rather, side bacon is the standard pork topping on pizza.\\r\\nIn Canada, pizza is served on a variety of crust types, including a traditional-style pan crust, a thin crust, multi-grain crust, whole-grain crust, and a gluten-free crust. Stuffed-crust pizza is also a popular pizza alternative for Canadian customers. It contains pizza toppings of the customers choice on a mozzarella-filled crust.\\r\\nIn the province of Quebec Pizza-ghetti is a combination meal commonly found in fast food or family restaurants. It consists of a pizza, sliced in half, accompanied by a small portion of spaghetti with a tomato based sauce. Although both pizza and spaghetti are considered staples of Italian cuisine, combining them in one dish is completely unknown in Italy. A popular variant involves using spaghetti as a pizza topping, under the pizza's mozzarella cheese\\r\\nSome of Canadas successful pizza brands include: Boston Pizza, Pizza Pizza, and Vanellis. Boston Pizza, also known as BPs in Canada, and \\"Boston'sthe Gourmet Pizza\\" in the United States and Mexico, is one of Canadas largest franchising restaurants.[32] The brand has opened over 325 locations across Canada and 50 locations in Mexico and the US.[32] The first Boston Pizza location was opened in Edmonton, Alberta, in 1964, and operated under the name \\"Boston Pizza & Spaghetti House\\", with locations still opening across the nation. It is the first Canadian restaurant to introduce the heart-shaped pizza on Valentines Day, a 22-year tradition, where a dollar from each pizza ordered supports Boston Pizza Foundation Future Prospects.[33] Pizza Pizza, and its subsidiary chain Pizza 73 in Western Canada, are among Canadas largest domestic brands based in Ontario.[citation needed] To date, they have over 500 locations nationwide, and fill more than 29 million orders annually.[34] Vanellis is an international pizza chain that is based in Mississauga, Ontario.[35] The chain first opened in 1981, serving both pizza and other fresh Italian cuisine, such as pasta and Italian sandwiches.[35] In 1995, the brand opened its first international location in Bahrain and became an international success. The brand continued to open additional locations across the Middle East, with chains now opened in the United Arab Emirates, Lebanon, and Morocco.[36] There are over 110 locations worldwide; making Vanellis the first pizza brand in Canada to open locations internationally.\\r\\nWith pizza gaining popularity across the nation, major American pizza chains such as Pizza Hut, Dominos Pizza and Little Caesars have expanded their locations in Canada, competing against the domestic Canadian brands. The major American pizza chains have brought their signature classic pizza recipes and toppings into their Canadian chains, offering their traditional classic pizzas to Canadian customers. However, the American chains have also created Canadian specialty pizzas that are available only in Canada. Pizzas that have been made exclusively for Canada by the American chain Pizza Hut for a limited time, included the following:\\r\\nPizza first made its appearance in the United States with the arrival of Italian immigrants in the late 19th century and was very popular among large Italian populations in New York City, Chicago, Philadelphia, and Saint Louis. In the late 19th century, pizza was introduced by peddlers who walked up and down the streets with a metal washtub of pizzas on their heads, selling their pizzas at two cents a slice. It was not long until small cafes and groceries began offering pizzas to their Italian American communities.\\r\\nThe first printed reference to \\"pizza\\" served in the US is a 1904 article in The Boston Journal.[38] Giovanni and Gennaro Bruno came to America from Naples, Italy in 1903 to introduce the Neapolitan Pizza.[clarification needed] Vincent (Jimmy) Bruno (Giovanni's son) went on to open the first pizzeria in The Loop in Chicago at 421 S. Wabash Avenue, the Yacht Club. Gennaro Lombardi opened a grocery store in 1897 which was later established as the \\"said\\" first pizzeria in America in 1905 with New York's issuance of the mercantile license. An employee of his, Antonio Totonno Pero, began making pizza for the store to sell that same year. The price for a pizza was five cents, but since many people could not afford the cost of a whole pie, they would instead say how much they could pay and they were given a slice corresponding to the amount offered. In 1924, Totonno left Lombardi's to open his own pizzeria on Coney Island called Totonno's. While the original Lombardi's closed its doors in 1984, it was reopened in 1994 just down the street and is run by Lombardi's grandson.\\r\\nPizza was brought to the Trenton area of New Jersey with Joe's Tomato Pies opening in 1910, followed soon by Papa's Tomato Pies in 1912. In 1936, De Lorenzo's Tomato Pies was opened. While Joe's Tomato Pies has closed, both Papa's and Delorenzo's have been run by the same families since their openings and remain among the most popular pizzas in the area. Frank Pepe Pizzeria Napoletana in New Haven, Connecticut, was another early pizzeria which opened in 1925 (after the owner served pies from local carts and bakeries for 20ÿ25 years) and is famous for its New Havenÿstyle Clam Pie. Frank Pepe's nephew Sal Consiglio opened a competing store, Sally's Apizza, on the other end of the block, in 1938. Both establishments are still run by descendants of the original family. When Sal died, over 2,000 people attended his wake, and The New York Times ran a half-page memoriam. The D'Amore family introduced pizza to Los Angeles in 1939.\\r\\nBefore the 1940s, pizza consumption was limited mostly to Italian immigrants and their descendants. The international breakthrough came after World War II. Allied troops occupying Italy, weary of their rations, were constantly on the lookout for good food. They discovered the pizzeria and local bakers were hard-pressed to satisfy the demand from the soldiers. The American troops involved in the Italian campaign took their appreciation for the dish back home, touted by \\"veterans ranging from the lowliest private to Dwight D. Eisenhower\\".[this quote needs a citation] By the 1960s, it was popular enough to be featured in an episode of Popeye the Sailor.[39]\\r\\nTwo entrepreneurs, Ike Sewell and Ric Riccardo, invented Chicago-style deep-dish pizza, in 1943. They opened their own restaurant on the corner of Wabash and Ohio, Pizzeria Uno.\\r\\nChain restaurants sprang up with pizza's popularity rising. Leading early pizza chains were Shakey's Pizza, founded in 1954 in Sacramento, California; Pizza Hut, founded in 1958 in Wichita, Kansas; and Josey's Pizza founded in Newnan, Georgia, in 1943. Later entrant restaurant chains to the dine-in pizza market were Bertucci's, Happy Joe's, Monical's Pizza, California Pizza Kitchen, Godfather's Pizza, and Round Table Pizza.[40]","input":"What popular food is thought to have originated in naples italy?"},{"output":"an axe","context":"","input":"What weapon did jack use in the shining?"},{"output":"Mount Mitchell","context":"Mount Mitchell is the highest peak of the Appalachian Mountains and the highest peak in mainland eastern North America. It is located near Burnsville in Yancey County, North Carolina, in the Black Mountain subrange of the Appalachians, and about 19 miles (31?km) northeast of Asheville. It is protected by Mount Mitchell State Park and surrounded by the Pisgah National Forest. Mount Mitchell's elevation is 6,684 feet (2,037?m) above sea level.[1]\\r\\n\\r\\n\\r\\nThe peak is the highest mountain in the United States east of the Mississippi River, and the highest in all of eastern North America south of the Arctic Cordillera. The nearest higher peaks are in the Black Hills of South Dakota and the highland foothills of Colorado.\\r\\nThe mountain, previously known as Black Dome for its rounded shape, was named after Elisha Mitchell, a professor at the University of North Carolina, who first explored the Black Mountain region in 1835, and determined that the height of the range exceeded by several hundred feet that of Mount Washington in New Hampshire, commonly thought at the time to be the highest point east of the Rocky Mountains. Mitchell fell to his death at nearby Mitchell Falls in 1857, having returned to verify his earlier measurements.\\r\\nA 4.6-mile (7.4?km) road (NC 128) connects the scenic Blue Ridge Parkway to a parking lot where a steep paved 980-foot (300?m) trail leads through a conifer forest to the summit. The 40-foot (12?m) stone observation tower on the summit was torn down in late 2006. A new observation deck was constructed and opened to visitors in January 2009.[3] Also on the summit is the tomb of Dr. Mitchell.\\r\\nMount Mitchell was formed during the Precambrian when marine deposits were metamorphosed into gneiss and schist. These metasedimentary rocks were later uplifted during the Alleghenian orogeny.[4] The soils are well drained, dark brown and stony with fine-earth material ranging in texture from sandy clay loam to loam or sandy loam; Burton and Craggey are the most common series around the summit.[5]\\r\\nThe mountain's summit is coated in a dense stand of Southern Appalachian spruce-fir forest, which consists primarily of two evergreen species the red spruce and the Fraser fir. Most of the mature Fraser firs, however, were killed off by the non-native Balsam woolly adelgid in the latter half of the 20th century. The high elevations also expose plant life to high levels of pollution, including acid precipitation in the form of rain, snow, and fog. These acids damage the red spruce trees in part by releasing natural metals from the soil like aluminum, and by leaching important minerals. To what extent this pollution harms the high-altitude ecosystem is debatable.[7]\\r\\nWhile the mountain is still mostly lush and green in the summer, many dead Fraser fir trunks can be seen due to these serious problems. Repairing the damage is a difficult issue, as the pollutants are often carried in from long distances. Sources can be local or hundreds of miles or kilometers away, requiring cooperation from as far away as the Midwest.\\r\\nWildflowers are abundant all summer long. Young fir and spruce trees do well in the subalpine climate, and their pine cones feed the birds along with wild blueberry and blackberry shrubs.\\r\\nThe second highest point in eastern North America, Mount Craig at 6,647 feet (2,026?m), is roughly a mile to the north of Mount Mitchell.\\r\\nThe summit area of Mount Mitchell is marked by a humid continental climate (K?ppen Dfb) bordering extremely close to a subalpine climate (k?ppen climate classification Dfc), with mild summers and long, moderately cold winters, being more similar to southeastern Canada than the southeastern U.S.. The monthly daily average temperature ranges from 25.2?F (?3.8?C) in January to 59.1?F (15.1?C) in July. The coldest temperature ever recorded in the state occurred there on January 21, 1985 when it fell to ?34?F (?37?C), during a severe cold spell that brought freezing temperatures as far south as Miami. It is also the coldest average reporting station in the state at 43.8?F (6.6?C) (based on data collected from 1971 to 2000) which is well below any other station.[8] Unlike the lower elevations in the surrounding regions, heavy snows often fall from December to March, with 50 inches (127?cm) accumulating in the Great Blizzard of 1993 and 66 inches (168?cm) in the January 2016 blizzard.[9][8] Snow flurries have been reported on the summit even in the summer months of June, July, and August. Due to the high elevation, precipitation is heavy and reliable year-round, averaging 74.7 inches (1,900?mm) for the year, with no month receiving less than 5?in (127?mm) of average precipitation. The summit is often windy, with gusts that can blow up to 178?mph (286?km/h).[10]\\r\\n?\\r\\nSign atop Mt. Mitchell\\r\\nMount Mitchell; View From the Top.\\r\\nMount Gibbes, Clingman's Peak, and Potato Knob from the southwest on the Blue Ridge Parkway\\r\\nBlack Mountains from the Blue Ridge Parkway\\r\\nForest floor high on Mount Mitchell\\r\\nExample of the spruce-fir forest near the top of Mount Mitchell","input":"What is the tallest mountain east of the mississippi river?"},{"output":"1847 Colt Walker","context":"The Colt Walker, sometimes known as the Walker Colt, was a single-action revolver with a revolving cylinder holding six charges of black powder behind six bullets (typically .44 caliber lead balls). It was designed in 1846 as a collaboration between Captain Samuel Hamilton Walker and American firearms inventor Samuel Colt.\\r\\n\\r\\n\\r\\nThe 1847 Colt Walker was the largest and most powerful black powder repeating handgun ever made. It was created in the mid-1840s in a collaboration between Texas Ranger Captain Samuel Hamilton Walker (1817ÿ47) and American firearms inventor Samuel Colt (1814ÿ62), building upon the earlier Colt Paterson design. Walker wanted a handgun that was extremely powerful at close range.[1]\\r\\nSamuel Walker carried two of his namesake revolvers in the MexicanÿAmerican War.[2] He was killed in battle the same year his famous handgun was invented, 1847, shortly after he had received them. Only 1100 of these guns were originally made, 1000 as part of a military contract and an additional 100 for the civilian market, making original Colt Walker revolvers extremely rare and expensive to acquire. On October 9, 2008, one specimen that had been handed down from a Mexican War veteran was sold at auction for US$920,000.[3]\\r\\nThe Republic of Texas had been the major purchaser of the early Paterson Holster Pistol (No. 5 model), a five shot cal .36 revolver, and Samuel Walker became familiar with it during his service as a Texas Ranger. In 1847, Walker was engaged in the Mexican-American War as a captain in the United States Mounted Rifles. He approached Colt, requesting a large revolver to replace the single-shot Aston Johnson holster pistols then in use. The desired .44-.45 caliber revolver would be carried in saddle mounted holsters and would be large enough to dispatch horses as well as enemy soldiers. The Colt Walker was used in the Mexican-American War and on the Texas frontier.[1]\\r\\nMedical officer John \\"Rip\\" Ford took a special interest in the Walkers when they arrived at Veracruz. He obtained two examples for himself and is the primary source for information about their performance during the war and afterward. His observation that the revolver would carry as far and strike with the same or greater force than the .54 caliber Mississippi Rifle seems to have been based on a single observation of a Mexican soldier hit at a distance of well over one hundred yards. The Walker, unlike most succeeding martial pistols and revolvers, was a practical weapon out to about 100 yards.[1]\\r\\nThe Colt Walker holds a powder charge of 60 grains (3.9?g) in each chamber, more than twice what a typical black powder revolver holds. It weighs 4?1?2 pounds (2?kg) unloaded, has a 9-inch (230?mm) barrel, and fires a .44 caliber (0.454?in (11.5?mm) diameter) conical and round ball. The initial contract called for 1,000 of the revolvers and accoutrements. Colt commissioned Eli Whitney Junior to fill the contract and produced an extra 100 revolvers for private sales and promotional gifts.[4] Notable recipients include John Coffee Hays.[5]\\r\\nColt commissioned New York engraver Waterman Ormsby to etch a scene on the cylinder that was based on Walker's description of the 1844 battle.[6]\\r\\nIn addition to its large size and weight, problems with the Walker included ruptured cylinders after firing. This has been attributed to primitive metallurgy, soldiers allowing powder to spill across the mouths of the chambers, and even loading the original conical bullets backwards into the chambers. Under 300 of the original 1,000 were returned for repair due to a ruptured cylinder. Lard was loaded into the mouths of the cylinders on top of each bullet after loading to prevent the spark from igniting all chambers at once, a practice which continues to this day among black-powder revolver shooters, and although each chamber held 60 grains of powder, Colt recommended no more than 50 grains in each.[5]\\r\\nThe Walker had an inadequate loading lever catch that often allowed the loading lever to drop during recoil, preventing fast follow-up shots. Period-correct fixes for this often included placing a rawhide loop around both the barrel and loading lever, to prevent the loading lever from dropping under recoil and locking the action.[7]\\r\\nThe Whitneyville-Hartford Dragoon is known as the first transitional model from the Walker to the Dragoon series, as it was largely built from leftover Walker parts. Subsequent contracts beginning in 1848 followed, for what is today known among collectors as the First, Second and Third Dragoon Models that were all based on the Colt Walker, enabling a rapid evolution of the basic revolver design. These improvements included shorter 7?1?2-inch (190?mm) barrels, shorter chambers, typically loaded only to 50 grains instead of 60 grains, thereby reducing the occurrence of ruptured cylinders, and the addition of an improved catch at the end of the loading lever to prevent the dropping of the loading lever under recoil.[1]\\r\\nThe Colt Walker was quite powerful, with modern replicas firing modern FFFg black powder producing energy levels in excess of 500 foot-pounds (680?J) muzzle-energy with both picket bullets and 0.454-inch-diameter (11.5?mm), 141-grain (9.1?g) round ball bullets. The black powder Colt Walker is often regarded as the most powerful commercially manufactured repeating handgun from 1847 until the introduction of the .357 Magnum in 1935, having a muzzle energy nearly exactly the same as a 4-inch-barreled (10?cm) handgun firing a .357 Magnum.[8] The Colt Walker has long maintained a unique position and mystique among handgun users, and its name is often used as a common expression of any overly large generic handgun example.\\r\\nIn the 1968 book True Grit, 14-year-old Mattie carries a Colt Dragoon. However, possibly due to the Walker's bigger size, a cartridge-converted Colt Walker was used as Mattie's weapon in the 1969 film based on the book, though Wayne's character referred to it as a Colt Dragoon nonetheless. In the 2010 remake of the film by the Coen Brothers, she carries a Dragoon, as originally described in the book\\r\\nModern replicas chambered in the .45 Black Powder Magnum wildcat cartridge have been offered by the Colt Blackpowder shop, Cimarron Firearms, Armi San Marco, and Uberti Firearms.[9]","input":"What kind of gun did walker texas ranger carry?"},{"output":"his second season","context":"","input":"When did tom brady when his first super bowl?"},{"output":"Rajendra Prasad","context":"The President of India is the head of state and first citizen of India. The President is also the Commander-in-chief of the Indian Armed Forces.[1] Although the president is vested such powers by the Constitution of India, the position is largely a ceremonial role and the executive powers are de facto exercised by the Prime Minister.[2] The post of President is known in Hindi as Rashtrapati, a Sanskrit neologism meaning \\"lord of the realm\\". The President is elected by the Electoral College composed of elected members of the parliament houses, the Lok Sabha and the Rajya Sabha, and also members of the Vidhan Sabha, the state legislative assemblies.[1]\\r\\nThere have been 14 presidents of India since the introduction of the post in 1950 (the current tenure is 5 years of an Indian President's term). The post was established when India was declared as a republic with the adoption of the Indian constitution.[3] Apart from these thirteen, three acting presidents have also been in office for short periods of time. Varahagiri Venkata Giri became Indian Acting President in 1969 following the death of Zakir Husain, who died in office. Giri was elected President a few months later. He remains the only person to have held office both as a president and acting president. Giri was the only person to be elected as an independent candidate.[4] The President may remain in office for a tenure of five years, as stated by article 56, part V, of the constitution of India. In the case where a president's term of office is terminated early or during the absence of the president, the vice president assumes office. By article 70 of part V, the parliament may decide how to discharge the functions of the president where this is not possible, or in any other unexpected contingency.[1] Rajendra Prasad, the first President of India, is the only person to have held office for two terms.[5]\\r\\nSeven presidents have been members of a political party before being elected. Six of these were active party members of the Indian National Congress. The Janata Party has had one member, Neelam Sanjiva Reddy, who later became president, he was born in Anantapur District (now Andhra Pradesh). Two presidents, Zakir Husain and Fakhruddin Ali Ahmed, have died in office. Their vice-presidents functioned as acting president until a new president was elected. Following Zakir Husain's death, two acting presidents held office until the new president, V. V. Giri, was elected. Varahagiri Venkata Giri himself, Zakir Husain's vice president, was the first acting president. When Giri resigned to take part in the presidential elections, he was succeeded by Mohammad Hidayatullah as acting president.[6] The 12th president, Pratibha Patil, is the first woman to serve as President of India, elected in 2007.[7]\\r\\nThe current President is Ram Nath Kovind, elected on 25 July 2017.\\r\\n\\r\\n\\r\\nThis list is numbered based on Presidents elected after winning an Indian Presidential election. The terms of Varahagiri Venkata Giri, Mohammad Hidayatullah, and Basappa Danappa Jatti, who have functioned as acting presidents, are therefore not numbered. The President of India does not represent any political party. The colours used in the table indicate the following:\\r\\nBasappa Danappa Jatti (1974ÿ1977)\\r\\nMuhammad Hidayatullah (1979ÿ1982)\\r\\nRamaswamy Venkataraman (1984ÿ1987)\\r\\nBhairon Singh Shekhawat (2002ÿ2007)\\r\\nVenkaiah Naidu","input":"Who is the the first president of india?"},{"output":"lifetime","context":"The Former Presidents Act (known also as FPA; 3 U.S.C.  102) is a 1958 U.S. federal law that provides several lifetime benefits to former presidents of the United States who have not been removed from office.[1]\\r\\n\\r\\n\\r\\nBefore 1958, the U.S. federal government provided no pension or other retirement benefits to former United States presidents. Andrew Carnegie offered to endow a US$25,000 annual pension for former Chief Executives in 1912, but congressmen questioned the propriety of such a private pension. That prompted legislation to provide benefits to former presidents.[1]\\r\\nWhen the Former Presidents Act took effect, there were two living former presidents: Herbert Hoover and Harry S. Truman. Dwight D. Eisenhower was the first president to fall under the act upon leaving office.\\r\\nThe original act provided for lifetime Secret Service protection for former presidents. In 1997, it was reduced to 10 years for presidents taking office after 1997. The 1997 amendment was reverted by the Former Presidents Protection Act of 2012 (Pub.L. 112ÿ257).[2] All living former presidents and their spouses are now entitled to receive lifetime Secret Service protection.[3]\\r\\nBy law, former presidents are entitled to a pension, staff and office expenses, medical care or health insurance, and Secret Service protection.\\r\\nThe Secretary of the Treasury pays a taxable pension to the president. Former presidents receive a pension equal to the pay that the head of an executive department (Executive Level I) would be paid, as of 2015[update] $203,700 per year.[4] The pension begins immediately after a president's departure from office.[5] A former president's spouse may also be paid a lifetime annual pension of $20,000 if they relinquish any other statutory pension.[1]\\r\\nWashington Transition funding for the expenses of leaving office is available for seven months. It covers office space, staff compensation, communications services, and printing and postage associated with the transition.[1]\\r\\nPrivate office staff and related funding is provided by the Administrator of the General Services Administration. Persons employed under this subsection are selected by and responsible only to the former president for the performance of their duties. Each former president fixes basic rates of compensation for persons employed for him, not exceeding an annualized total of $150,000 for the first 30 months and $96,000 thereafter.[1]\\r\\nFormer presidents are entitled to medical treatment in military hospitals; they pay for this at interagency rates set by the Office of Management and Budget. Two-term presidents may buy health insurance under the Federal Employees Health Benefits Program; a GSA legal opinion ruled Jimmy Carter and George H. W. Bush ineligible.[1][6]\\r\\nFormer presidents were entitled from 1965 to 1996 to lifetime Secret Service protection, for themselves, spouses, and children under 16. A 1994 statute, (Pub.L. 103ÿ329), limited post-presidential protection to ten years for presidents inaugurated after January 1, 1997.[7] Under this statute, Bill Clinton would still be entitled to lifetime protection, and all subsequent presidents would have been entitled to ten years' protection.[8] On January 10, 2013, President Barack Obama signed the Former Presidents Protection Act of 2012, reinstating lifetime Secret Service protection for his predecessor George W. Bush, himself, and all subsequent presidents.[9]\\r\\nRichard Nixon relinquished his Secret Service protection in 1985, the only president to do so.[10]","input":"How long do former presidents receive secret service protection?"},{"output":"in 2002","context":"Combatives is a term for hand-to-hand combat training and techniques.\\r\\n\\r\\nSometimes called Close Quarters Combat (CQC or close combat), World War II-era American combatives were largely developed by Britain's William E. Fairbairn and Eric A. Sykes. Also known for their eponymous Fairbairn-Sykes Fighting Knife, Fairbairn and Sykes had worked in the British Armed Forces and helped teach the Shanghai Municipal Police (SMP)[1] quick, effective, and simple techniques for fighting with or without weapons in melee situations. Similar training was provided to British Commandos, the First Special Service Force, Office of Strategic Services, Army Rangers, and Marine Raiders. Fairbairn at one point called this system Defendu and published on it, as did their American colleague Rex Applegate. Fairbairn often referred to the technique as \\"gutter fighting,\\" a term which Applegate used, along with \\"the Fairbairn system.\\"\\r\\n\\r\\nOther combatives systems having their origins in the modern military include Chinese Sanshou, Soviet Bojewoje (Combat) Sambo, and Israeli Kapap. The prevalence and style of combatives training often changes based on perceived need, and even in times of peace, special forces and commando units tend to have a much higher emphasis on close combat than most personnel, as may embassy guards or paramilitary units such as police SWAT teams.\\r\\n\\r\\nDe-emphasized in the United States after World War II, insurgency conflicts such as the  Vietnam War,  low intensity conflict, and urban warfare tend to encourage more attention to combatives. While the United States Marine Corps replaced its LINE combat system with Marine Corps Martial Arts Program in 2002, The United States Army adopted the Modern Army Combatives (MAC) program the same year with the publishing of Field Manual 3-25.150. MAC draws from systems such as Brazilian Jiu-Jitsu, Judo, Muay Thai, Boxing and Eskrima, which could be trained \\"live\\" and can be fully integrated into current Close Quarters Battle tactics and training methods.\\r\\n\\r\\nIn August 2007, MAC training became required in every Army unit by Army regulation 350-1. The Modern Army Combatives Program was adopted as the basis for the Air Force Combatives Program in January 2008.[2][2]\\r\\n\\r\\nIn recent years the major tenets of MAC, namely \\"live\\" training and using competitions as a tool to motivate Soldiers and units to higher levels of training,  have been adopted by many of the major Combatives Systems such as Krav Maga and the Russian military hand-to-hand combat system.[3][4]\\r\\n\\r\\nIn 2001, Matt Larsen, then a Sergeant First Class, established the United States Army Combatives School at Fort Benning. Students are taught techniques from the 2002 and 2009 versions of FM 3-25.150 (Combatives), also written by Larsen. The aim of the regimen is to teach soldiers how to train rather than attempting to give them the perfect techniques for any given situation. The main idea is that all real ability is developed after the initial training and only if training becomes routine. The initial techniques are simply a learning metaphor useful for teaching more important concepts, such as dominating an opponent with superior body position during ground grappling or how to control someone during clinch fighting. They are taught as small, easily repeatable drills, in which practitioners could learn multiple related techniques rapidly. For example, Drill One teaches several techniques: escaping blows, maintaining the mount, escaping the mount, maintaining the guard, passing the guard, assuming side control, maintaining side control, preventing and assuming the mount. The drill can be completed in less than a minute and can be done repeatedly with varying levels of resistance to maximize training benefits.\\r\\n\\r\\nNew soldiers begin their Combatives training on day three of Initial Military Training, at the same time that they are first issued their rifle. The training begins with learning to maintain control of your weapon in a fight. Soldiers are then taught how to gain control of a potential enemy at the farthest possible range in order to maintain their tactical flexibility, what the tactical options are and how to implement them.\\r\\n\\r\\nThe three basic options upon encountering a resistant opponent taught are:[citation needed]\\r\\n\\r\\nDuring the graduation exercises the trainee must react to contact from the front or rear in full combat equipment and execute whichever of the three tactical options is appropriate and to take part in competitive bouts using the basic rules.\\r\\n\\r\\nThe Combatives School teaches four instructor certification courses. Students of the first course are not expected to have any knowledge of combatives upon arrival. They are taught fundamental techniques which are designed to illuminate the fundamental principles of combatives training. The basic techniques form a framework upon which the rest of the program can build and are taught as a series of drills, which can be performed as a part of daily physical training. While the course is heavy on grappling, it does not lose sight of the fact that it is a course designed for soldiers going into combat. It is made clear that while combatives can be used to kill or disable, the man that typically wins a hand-to-hand fight in combat is the one whose allies arrive with guns first.\\r\\n\\r\\nSubsequent courses build upon the framework by adding throws and takedowns from Wrestling and Judo, striking skills from Boxing and Muay Thai, ground fighting from Brazilian Jiu-Jitsu and Sambo and melee weapons fighting from Eskrima and the western martial arts, all of that combined with how to conduct scenario training and referee the various levels of Combatives competitions.\\r\\n\\r\\nThere are several reasons that the combatives course is taught:\\r\\n\\r\\nLarsen recognized in the development of the Modern Army Combatives Program that previous programs had suffered from the same problems. Invariably, the approach had been to pick a small set of what were deemed simple, effective, easy to learn techniques and train them in whatever finite amount of time was granted on a training calendar. This \\"terminal training\\" approach, which offered no follow-on training plan other than continued practice of the same limited number of techniques, had failed in the past because it did not provide an avenue or the motivation for continued training.\\r\\n\\r\\nInstead, his approach was to use the limited amount of institutional training time to lay a foundation for training around the Army. Techniques were put together in a series of simple drills so that through repetition, such as during daily physical training or as a warm-up exercise, soldiers could be expected to not only memorize but master the basic techniques.\\r\\n\\r\\nDrills were designed to rapidly teach core concepts to students. The first and most widely taught drill is known as Drill One and is as follows:\\r\\n\\r\\nSuch drills serve many pedagogical functions. They instill basic movement patterns and so internalize the concept of a hierarchy of dominant positions. When used as a part of a warm-up they maximize the use of available training time, allowing instructors to review the details of the basic techniques without taking time away from more advanced training. New techniques can be taught in context, for example a new choke can be practiced every time the appropriate position is reached. They allow students of different levels to work together. An advanced student will not necessarily pass the guard or achieve the mount in the same way as a beginner but the drill still functions as a framework for practice. The drills also allow Combatives training to become a routine part of every soldier's day. During physical training for instance soldiers could be asked to perform the drills interchangeable with callisthenic exercises.\\r\\n\\r\\nThe most beneficial category of submission technique is the chokehold. Students are taught a variety of different chokes and are taught how a properly applied choke feels so that they know the difference between a choke that they must break or submit to immediately and one that they can safely ignore if they have an opening for a submission hold of their own. A properly applied blood choke will prevent the flow of blood to and from the brain, resulting in unconsciousness in approximately 4ÿ10 seconds. The best known example of this is the rear naked choke.\\r\\n\\r\\nLess preferred, but also effective techniques are joint locks. Joint locks are not the preferred method for attacking an enemy, because they do not completely disable the enemy. Joints locks do inflict large amounts of pain and can secure compliance from the enemy. This makes them especially useful in controlling opponents during crowd control operations or when someone is being clearly threatening, but the rules of engagement prohibit killing them (if the opponent is easily given to surrender under pain). If compliance cannot be secured or is not desired, the joint lock can be extended fully, breaking the applicable joint. Students are taught the difference between pain that signals a joint lock is in progress and simple discomfort.\\r\\n\\r\\nLarsen founded US Army Combatives School in 2001 in building 69 at Fort Benning, Georgia.\\r\\n\\r\\nAfter years of developing the elite 75th Ranger Regiment's hand to hand program, he was assigned to the Ranger Training Brigade, the Combatives proponent at the time, to rewrite the Field Manual FM 21-150. Upon finishing this, it was published in 2002 as FM 3-25.150 (Combatives). He was asked by the 11th Infantry Regiment (a TRADOC unit) to develop a training course for their cadre. Advocacy for the Combatives doctrine was transferred to the 11th Infantry Regiment to follow him. An old, disused warehouse in Fort Benning, Georgia became the site of the school. Soon, units from around the Army were sending Soldiers to this course. Over the next several years, the program was developed around the idea of building virtually self-sustaining Combatives programs within units by training cadres of instructors indigenous to each unit. With the continued success of this approach, the school became the recognized source of instruction for the entire US Army.\\r\\n\\r\\nThere are four different courses taught at the Combatives Center:\\r\\n\\r\\nTrainers at skill level 3 or higher are certified to teach all courses lower than their certification level.  Skill level 1 and 2 courses are now usually taught and participants certified at the unit level.  Skill level 3 and 4 courses are usually held at Ft. Benning, GA.  A Soldier who has a level 3 certification can certify other Soldiers to be skill level 1.  Soldiers who are skill level 4 can certify other Soldiers to be skill level 1 or 2.\\r\\n\\r\\nOne of the fundamental aspects of Modern Army Combatives training is the use of competitions as a tool to motivate Soldiers to train. Realizing the inherent problem with competitive systems, that competitors will focus their training on winning and therefore only train the techniques that are allowed in competition, Larsen designed a system of graduated rules that, combined with scenario based training, demand that Soldiers train on all aspects of fighting.\\r\\n\\r\\nThere are four levels of competition;\\r\\n\\r\\nIn 2010 Larsen initiated a belt system for Modern Army Combatives at the Army Championships by promoting the first three Combatives Black Belts.[5]\\r\\n\\r\\nDamien Stelly L Andrew Chappelle[6] L Tim Kennedy (fighter)[5][7]\\r\\n\\r\\nThe United States Air Force has at times in its history been at the forefront of Combatives Training. Soon after the establishment of the Air Force as a separate service in September 1947, General Curtis Lemay was appointed as the Commanding General of the Strategic Air Command (SAC). General Lemay, who had masterminded the US air attacks on the Japanese mainland during World War II, knew that US bomber groups in Europe had suffered more combat casualties than the US Marine Corps had in the Pacific. Many of the lost airmen ended up as German prisoners of war. He was determined that all of his flying personnel would have a working knowledge of hand-to-hand combat to aid in escape and evasion.\\r\\n\\r\\nIn 1951, General Lemay appointed Emilio \\"Mel\\" Bruno, his judo teacher, a former national American Athletic Union wrestling champion and fifth degree black belt in judo, to direct a command wide judo and combative measures program. Bruno devised a program combining techniques from aikido, judo, and karate. In 1952 the Air Training Command took over the program. The Commanding General was General Thomas Power. Because of the deficiency in qualified instructors, Power sent two classes of twenty four airmen to train at the Kodokan for several weeks. Based upon the success of this trial and after an official delegation from the Kodokan toured SAC bases in the United States, Bruno set up an eight-week training course at the Kodokan. Students trained eight hours a day, five days a week, and upon return to the United States were assigned throughout SAC. The course was a Japanese designed mix of judo, aikido, karate, and taihojutsu.\\r\\n\\r\\nFrom 1959 to 1966 the Air Force Combative Measures (Judo) Instructors Course was taught at Stead Air Force Base in Reno, Nevada. The 155-hour course consisted of: 36 hours of fundamentals of judo, 12 hours of aikido, 12 hours of karate, 12 hours of Air Police techniques, 12 hours of aircrew self-defense, 18 hours of judo tournament procedures, 5 hours on code of conduct, and 48 hours on training methods. There were also a 20-hour Combative Methods course and a 12-hour Combative Survival course for aircrew members.[8]\\r\\n\\r\\nThe program was dropped in 1966 in an effort to save money and reduce aircrew training time. \\r\\n\\r\\nWith the wars in Iraq and Afghanistan, the demand for airmen with the ground troops on the battlefield grew significantly over their historic role. In response, commanders around the Air Force started independent training programs to both teach hand-to-hand combat and instill a warrior ethos in deploying airmen. Because of the decentralized nature of the training, approaches varied wildly.\\r\\n\\r\\nIn 2007 the Chief of Staff of the Air Force read an article in the Air Force Times about airmen training in one of the systems that was being widely used, the LINE system]], which had previously been used and replaced in both the Marine Corps and the Special Forces, and ordered a review of all hand-to-hand combat in the Air Force.[9][10] He tasked the Air Education and Training Command (AETC) to form a study committee to plan a way forward. \\r\\n\\r\\nThe AETC included Larsen and Dave Durnil, who had run the Combatives program for the US Armys 1st Infantry Division at Fort Riley Kansas and a program for both Army and Air Force ROTC at Kansas State University (KSU). Also on the AETC were Ed Weichers Jr. who had been the Air Force Academy's boxing coach for more than 30 years, and representatives from each command in the Air Force who were currently conducting combatives training of various sorts, including the Air Force Security Forces and the Air Force Special Operations Command.\\r\\n\\r\\nThe committee was led by Lt. Col. Kevin Adelsen from AETC Headquarters and hosted by Col. Billy Walker, Head of the Physical Education Department, Directorate of Athletics at the Air Force Academy. before the first meeting, Lt. Col. Adelson visited Ron DonVito to witness and investigate LINE training, Matt Larsen at the Army Combatives School, and the Marine Corps Martial Arts Center of Excellence (MACE).  After the first meeting Col. Walker led several of the Academy cadre to KSU to attend the Army Combatives courses. The result of all of this was the Air Force deciding to adopt a program based upon the Army Combatives Program but modified to fit the needs and culture of the Air Force.[2] In 2009 Dave Durnil was hired to work at the Air Force Academy, which was designated the Combatives Center of Excellence with Col. Walker as its director.\\r\\n\\r\\nCombatives courses have been taught by the United States Military Academy for its entire history. The National Defense University's combatives program includes a course in Jigo Tensin-Ryu Jujutsu, also known as Combat Jujutsu.[11]  The Virginia Military Institute also has full-time civilian instructors for Level 1 Combatives that is offered to all students in addition to their mandatory boxing class. In 2005 the Modern Army Combatives Program began to spread to academia with its adoption at Kansas State University, where there are courses specifically tailored to military personnel (active duty and ROTC) and university athletes, in addition to those available to the general student body.[12][13]  The Kansas program is currently defunct.[14]","input":"When was the first combatives field manual written?"},{"output":"Himalaya mountains","context":"The Spiti Valley is a cold desert mountain valley located high in the Himalaya mountains in the north-eastern part of the Indian state of Himachal Pradesh. The name \\"Spiti\\" means \\"The Middle Land\\", i.e. the land between Tibet and India.[1]\\r\\nLocal population follow Vajrayana Buddhism similar to that found in the nearby Tibet Autonomous Region and the Ladakh region of India. The valley and surrounding region is one of the least populated regions in India and is the gateway to the northernmost reaches of the nation. Along the northern route from Manali, Himachal Pradesh or Keylong via the Rohtang Pass or Kunzum Pass respectively, the valley lies in the North Eastern section of the Indian state Himachal Pradesh, and forms part of the Lahaul and Spiti district. The sub-divisional headquarters (capital) is Kaza, Himachal Pradesh[2] which is situated along the Spiti River at an elevation of about 12,500 feet (3,800?m) above mean sea level.\\r\\nLahaul and Spiti is surrounded by high mountain ranges. The Rohtang Pass, at 13,054 feet (3,979?m), separates Lahul and Spiti from the Kullu Valley. Lahul and Spiti are cut off from each other by the higher Kunzum Pass, at 15,059 feet (4,590?m).[2] A road connects the two divisions, but is cut off frequently in winter and spring due to heavy snow. The valley is likewise cut off from the north up to eight months of the year by heavy snowfalls and thick icing conditions. A southern route to India proper is periodically closed for brief periods in the winter storms of November through June, but road access is usually restored a few days after storms end via Shimla and the Sutlej in the Kinnaur district.\\r\\n\\r\\n\\r\\nSpiti valley is a research and cultural centre for Buddhists. Highlights include Key Monastery and Tabo Monastery, one of the oldest monasteries in the world and a favourite of the Dalai Lama.[3] It was the location of the scenery and cinematography in the Indian films Paap, Highway and Milarepa, a biographical adventure tale about one of Buddhism's most famous Tibetan saints. The Buddhist monastery in the valley served as the locus of the set and some of the monks appeared in the film.\\r\\nThe Pin Valley of Spiti is home to the few surviving Buchen Lamas of the Nyingmapa sect of Buddhism.\\r\\nThe small town of Manali was the beginning of an ancient trade route to Ladakh and, from there, over the Karakoram Pass on to Yarkand and Khotan in the Tarim Basin. Spiti is summer home to hundreds of semi-nomadic Gaddi sheep and goat herders who come to this valley for grazing their animals from the surrounding villages and sometimes as far as 250?km. They enter the valley during summer as the snow melts and leave just a few days before first snowfall of the season.\\r\\nSpiti valley is accessible throughout year via Kinnaur from Shimla route on a difficult 412-kilometre-long (256?mi) road. Tourists from outside India need inner line permits to enter Spiti through Kinnaur. Spiti's border start at Samdo [74?km from Kaza] which is quite near to India-China border. In summer it can be reached via Manali through Rohtang pass and Kunzum pass. Manali is 201?km away from Kaza headquarter of Spiti subdivision. Due to high elevation one is likely to feel altitude sickness in Spiti.\\r\\nA strategic 8.8km tunnel in Rohtang gives all weather access to Spiti and reduce the travel distance by 48-kilometer.[4]\\r\\nThe Spiti River originates from Kunzum range and Tegpo and Kabzian streams are its tributaries. Water draining the famous Pin valley area are also a part of the Spiti river system. Its position across the main Himalayan range deprives it from the benefit of the South-West monsoons that causes widespread rain in most parts of India from June to September. The river attains peak discharge in late summers due to glacier melting. After flowing through Spiti valley, the Spiti River meets Satluj at Namgia in Kinnaur district traversing a length of about 150?km. from the North-West beyond that it flows in South-West direction in the Pradesh. Huge mountain rise to very high ele-vations on either sides of the Spiti River and its numerous tributaries. The mountains are barren and largely devoid of a vegetative cover. The main settlements along the Spiti River and its tributaries are Hansi and Dhankar Gompa.\\r\\nSpiti River\\r\\nWelcome gate at Lossar, 60?km from Kaza\\r\\nKey Monastery\\r\\nCoordinates: 3217N 7800E? / ?32.283N 78.000E? / 32.283; 78.000","input":"Which mountain range separates kinnaur and spiti from tibet?"},{"output":"over 40 million albums","context":"American singer-songwriter Taylor Swift's career began with a record deal with Big Machine Records in 2005 and the release of her eponymous debut album the following year. In the United States, Taylor Swift peaked at number five on the Billboard 200 and stayed the longest on the chart during the 2000s.[1] All of its singles\\"Tim McGraw\\", \\"Teardrops on My Guitar\\", \\"Our Song\\", \\"Picture to Burn\\", and \\"Should've Said No\\"charted within the top forty in the United States and were certified platinum by the RIAA.[2][3] Swift followed with the release of the EPs Sounds of the Season: The Taylor Swift Holiday Collection and Beautiful Eyes, which peaked at number twenty and number nine on the Billboard 200, respectively.[4]\\r\\nSwift released her second studio album, Fearless, in 2008, which topped the charts in the United States, Canada, and New Zealand. It became the best-selling album of 2009 in the United States,[5] and thirteen of its songs charted within the top forty of the Billboard Hot 100, breaking the record for the most top forty entries from a single album.[6] Its songs \\"Love Story\\", \\"You Belong with Me\\", and \\"Fearless\\" reached the top ten in the United States while \\"Love Story\\" became her first number-one single in Australia. She obtained her first number-one single in Canada with \\"Today Was a Fairytale\\" from the Valentine's Day soundtrack (2010).[7] Swift's third studio album, Speak Now (2010), peaked at number-one in the United States, Australia, Canada, and New Zealand. Three of its singles\\"Mine\\", \\"Back to December\\", and \\"Mean\\"peaked within the top ten in Canada.[3]\\r\\nSwift's fourth studio album, Red (2012), became her first number one album in the United Kingdom, and also topped the charts in Australia, Canada, Ireland, New Zealand, and United States. It spawned the internationally successful singles \\"We Are Never Ever Getting Back Together\\" and \\"I Knew You Were Trouble\\", with the former reaching number-one in Canada, New Zealand, and the United States.[8] Swift's fifth studio album, 1989 (2014), debuted atop the Billboard 200 with sales of 1.287 million copies, making her the first artist to release three albums (after Speak Now and Red) with sales of one million within a single week.[9] The album reached number-one in several other countries, including Australia, Canada and the United Kingdom; as of 2016, it has sold a total of 10.1 million copies worldwide. The singles \\"Shake It Off\\", \\"Blank Space\\", and \\"Bad Blood\\" all reached number one in the United States, Australia, and Canada.[10] A track she recorded with Zayn titled \\"I Don't Wanna Live Forever\\" for the Fifty Shades Darker soundtrack reached number one in Sweden and number two in the US. Her sixth album Reputation (2017) and its lead single \\"Look What You Made Me Do\\" reached number one in Australia, Canada, Ireland, New Zealand, the United Kingdom, and the United States.\\r\\nAccording to RIAA, Swift is the second-best-selling digital singles artist in the United States, with cumulative single certifications of 106.5 million digital downloads and on-demand streaming.[11] Meanwhile, US total album sales stand at 31.4 million copies.[12] With estimated sales of over 40 million albums and 130 million singles worldwide, Swift is one of the best-selling music artists.[13]","input":"How many albums has taylor swift sold overall?"},{"output":"splash erosion","context":"Soil erosion is the displacement of the upper layer of soil, one form of soil degradation. This natural process is caused by the dynamic activity of erosive agents, that is, water, ice (glaciers), snow, air (wind), plants, animals, and humans. In accordance with these agents, erosion is sometimes divided into water erosion, glacial erosion, snow erosion, wind (aeolean) erosion, zoogenic erosion, and anthropogenic erosion[1]. Soil erosion may be a slow process that continues relatively unnoticed, or it may occur at an alarming rate causing a serious loss of topsoil. The loss of soil from farmland may be reflected in reduced crop production potential, lower surface water quality and damaged drainage networks.\\r\\nHuman activities have increased by 10ÿ40 times the rate at which erosion is occurring globally. Excessive (or accelerated) erosion causes both \\"on-site\\" and \\"off-site\\" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, the eventual end result is desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems worldwide.[2][3]\\r\\nIntensive agriculture, deforestation, roads, anthropogenic climate change and urban sprawl are amongst the most significant human activities in regard to their effect on stimulating erosion.[4] However, there are many prevention and remediation practices that can curtail or limit erosion of vulnerable soils.\\r\\n\\r\\n\\r\\nRainfall, and the surface runoff which may result from rainfall, produces four main types of soil erosion: splash erosion, sheet erosion, rill erosion, and gully erosion. Splash erosion is generally seen as the first and least severe stage in the soil erosion process, which is followed by sheet erosion, then rill erosion and finally gully erosion (the most severe of the four).[5][6]\\r\\nIn splash erosion, the impact of a falling raindrop creates a small crater in the soil,[7] ejecting soil particles.[8] The distance these soil particles travel can be as much as 0.6 m (two feet) vertically and 1.5 m (five feet) horizontally on level ground.\\r\\nIf the soil is saturated, or if the rainfall rate is greater than the rate at which water can infiltrate into the soil, surface runoff occurs. If the runoff has sufficient flow energy, it will transport loosened soil particles (sediment) down the slope.[9] Sheet erosion is the transport of loosened soil particles by overland flow.[9]\\r\\nRill erosion refers to the development of small, ephemeral concentrated flow paths which function as both sediment source and sediment delivery systems for erosion on hillslopes. Generally, where water erosion rates on disturbed upland areas are greatest, rills are active. Flow depths in rills are typically of the order of a few centimeters (about an inch) or less and along-channel slopes may be quite steep. This means that rills exhibit hydraulic physics very different from water flowing through the deeper, wider channels of streams and rivers.[10]\\r\\n Gully erosion occurs when runoff water accumulates and rapidly flows in narrow channels during or immediately after heavy rains or melting snow, removing soil to a considerable depth.[11][12][13]\\r\\nValley or stream erosion occurs with continued water flow along a linear feature. The erosion is both downward, deepening the valley, and headward, extending the valley into the hillside, creating head cuts and steep banks. In the earliest stage of stream erosion, the erosive activity is dominantly vertical, the valleys have a typical V cross-section and the stream gradient is relatively steep. When some base level is reached, the erosive activity switches to lateral erosion, which widens the valley floor and creates a narrow floodplain. The stream gradient becomes nearly flat, and lateral deposition of sediments becomes important as the stream meanders across the valley floor. In all stages of stream erosion, by far the most erosion occurs during times of flood, when more and faster-moving water is available to carry a larger sediment load. In such processes, it is not the water alone that erodes: suspended abrasive particles, pebbles and boulders can also act erosively as they traverse a surface, in a process known as traction.[14]\\r\\nBank erosion is the wearing away of the banks of a stream or river. This is distinguished from changes on the bed of the watercourse, which is referred to as scour. Erosion and changes in the form of river banks may be measured by inserting metal rods into the bank and marking the position of the bank surface along the rods at different times.[15]\\r\\nThermal erosion is the result of melting and weakening permafrost due to moving water.[16] It can occur both along rivers and at the coast. Rapid river channel migration observed in the Lena River of Siberia is due to thermal erosion, as these portions of the banks are composed of permafrost-cemented non-cohesive materials.[17] Much of this erosion occurs as the weakened banks fail in large slumps. Thermal erosion also affects the Arctic coast, where wave action and near-shore temperatures combine to undercut permafrost bluffs along the shoreline and cause them to fail. Annual erosion rates along a 100-kilometre (62-mile) segment of the Beaufort Sea shoreline averaged 5.6 metres (18 feet) per year from 1955 to 2002.[18]\\r\\nAt extremely high flows, kolks, or vortices are formed by large volumes of rapidly rushing water. Kolks cause extreme local erosion, plucking bedrock and creating pothole-type geographical features called Rock-cut basins. Examples can be seen in the flood regions result from glacial Lake Missoula, which created the channeled scablands in the Columbia Basin region of eastern Washington.[19]\\r\\nWind erosion is a major geomorphological force, especially in arid and semi-arid regions. It is also a major source of land degradation, evaporation, desertification, harmful airborne dust, and crop damageespecially after being increased far above natural rates by human activities such as deforestation, urbanization, and agriculture.[20][21]\\r\\nWind erosion is of two primary varieties: deflation, where the wind picks up and carries away loose particles; and abrasion, where surfaces are worn down as they are struck by airborne particles carried by wind. Deflation is divided into three categories: (1) surface creep, where larger, heavier particles slide or roll along the ground; (2) saltation, where particles are lifted a short height into the air, and bounce and saltate across the surface of the soil; and (3) suspension, where very small and light particles are lifted into the air by the wind, and are often carried for long distances. Saltation is responsible for the majority (50ÿ70%) of wind erosion, followed by suspension (30ÿ40%), and then surface creep (5ÿ25%).[22][23] Silty soils tend to be the most affected by wind erosion; silt particles are relatively easily detached and carried away.[24]\\r\\nWind erosion is much more severe in arid areas and during times of drought. For example, in the Great Plains, it is estimated that soil loss due to wind erosion can be as much as 6100 times greater in drought years than in wet years.[25]\\r\\nMass movement is the downward and outward movement of rock and sediments on a sloped surface, mainly due to the force of gravity.[26][27]\\r\\nMass movement is an important part of the erosional process, and is often the first stage in the breakdown and transport of weathered materials in mountainous areas.[28] It moves material from higher elevations to lower elevations where other eroding agents such as streams and glaciers can then pick up the material and move it to even lower elevations. Mass-movement processes are always occurring continuously on all slopes; some mass-movement processes act very slowly; others occur very suddenly, often with disastrous results. Any perceptible down-slope movement of rock or sediment is often referred to in general terms as a landslide. However, landslides can be classified in a much more detailed way that reflects the mechanisms responsible for the movement and the velocity at which the movement occurs. One of the visible topographical manifestations of a very slow form of such activity is a scree slope.[citation needed]\\r\\nSlumping happens on steep hillsides, occurring along distinct fracture zones, often within materials like clay that, once released, may move quite rapidly downhill. They will often show a spoon-shaped isostatic depression, in which the material has begun to slide downhill. In some cases, the slump is caused by water beneath the slope weakening it. In many cases it is simply the result of poor engineering along highways where it is a regular occurrence.[citation needed]\\r\\nSurface creep is the slow movement of soil and rock debris by gravity which is usually not perceptible except through extended observation. However, the term can also describe the rolling of dislodged soil particles 0.5 to 1.0?mm (0.02 to 0.04?in) in diameter by wind along the soil surface.[citation needed]\\r\\nThe amount and intensity of precipitation is the main climatic factor governing soil erosion by water. The relationship is particularly strong if heavy rainfall occurs at times when, or in locations where, the soil's surface is not well protected by vegetation. This might be during periods when agricultural activities leave the soil bare, or in semi-arid regions where vegetation is naturally sparse. Wind erosion requires strong winds, particularly during times of drought when vegetation is sparse and soil is dry (and so is more erodible). Other climatic factors such as average temperature and temperature range may also affect erosion, via their effects on vegetation and soil properties. In general, given similar vegetation and ecosystems, areas with more precipitation (especially high-intensity rainfall), more wind, or more storms are expected to have more erosion.\\r\\nIn some areas of the world (e.g. the mid-western USA), rainfall intensity is the primary determinant of erosivity, with higher intensity rainfall generally resulting in more soil erosion by water. The size and velocity of rain drops is also an important factor. Larger and higher-velocity rain drops have greater kinetic energy, and thus their impact will displace soil particles by larger distances than smaller, slower-moving rain drops.[29]\\r\\nIn other regions of the world (e.g. western Europe), runoff and erosion result from relatively low intensities of stratiform rainfall falling onto previously saturated soil. In such situations, rainfall amount rather than intensity is the main factor determining the severity of soil erosion by water.[30]\\r\\nThe composition, moisture, and compaction of soil are all major factors in determining the erosivity of rainfall. Sediments containing more clay tend to be more resistant to erosion than those with sand or silt, because the clay helps bind soil particles together.[31] Soil containing high levels of organic materials are often more resistant to erosion, because the organic materials coagulate soil colloids and create a stronger, more stable soil structure.[32] The amount of water present in the soil before the precipitation also plays an important role, because it sets limits on the amount of water that can be absorbed by the soil (and hence prevented from flowing on the surface as erosive runoff). Wet, saturated soils will not be able to absorb as much rain water, leading to higher levels of surface runoff and thus higher erosivity for a given volume of rainfall.[32][33] Soil compaction also affects the permeability of the soil to water, and hence the amount of water that flows away as runoff. More compacted soils will have a larger amount of surface runoff than less compacted soils.[32]\\r\\nVegetation acts as an interface between the atmosphere and the soil. It increases the permeability of the soil to rainwater, thus decreasing runoff. It shelters the soil from winds, which results in decreased wind erosion, as well as advantageous changes in microclimate. The roots of the plants bind the soil together, and interweave with other roots, forming a more solid mass that is less susceptible to both water and wind erosion. The removal of vegetation increases the rate of surface erosion.[34]\\r\\nThe topography of the land determines the velocity at which surface runoff will flow, which in turn determines the erosivity of the runoff. Longer, steeper slopes (especially those without adequate vegetative cover) are more susceptible to very high rates of erosion during heavy rains than shorter, less steep slopes. Steeper terrain is also more prone to mudslides, landslides, and other forms of gravitational erosion processes.[35][36][37]\\r\\nUnsustainable agricultural practices are the single greatest contributor to the global increase in erosion rates.[38] The tillage of agricultural lands, which breaks up soil into finer particles, is one of the primary factors. The problem has been exacerbated in modern times, due to mechanized agricultural equipment that allows for deep plowing, which severely increases the amount of soil that is available for transport by water erosion. Others include mono-cropping, farming on steep slopes, pesticide and chemical fertilizer usage (which kill organisms that bind soil together), row-cropping, and the use of surface irrigation.[39][40] A complex overall situation with respect to defining nutrient losses from soils, could arise as a result of the size selective nature of soil erosion events. Loss of total phosphorus, for instance, in the finer eroded fraction is greater relative to the whole soil.[41] Extrapolating this evidence to predict subsequent behaviour within receiving aquatic systems, the reason is that this more easily transported material may support a lower solution P concentration compared to coarser sized fractions.[42] Tillage also increases wind erosion rates, by dehydrating the soil and breaking it up into smaller particles that can be picked up by the wind. Exacerbating this is the fact that most of the trees are generally removed from agricultural fields, allowing winds to have long, open runs to travel over at higher speeds.[43] Heavy grazing reduces vegetative cover and causes severe soil compaction, both of which increase erosion rates.[44]\\r\\nIn an undisturbed forest, the mineral soil is protected by a layer of leaf litter and an humus that cover the forest floor. These two layers form a protective mat over the soil that absorbs the impact of rain drops. They are porous and highly permeable to rainfall, and allow rainwater to slow percolate into the soil below, instead of flowing over the surface as runoff.[45] The roots of the trees and plants[46] hold together soil particles, preventing them from being washed away.[45] The vegetative cover acts to reduce the velocity of the raindrops that strike the foliage and stems before hitting the ground, reducing their kinetic energy.[47] However it is the forest floor, more than the canopy, that prevents surface erosion. The terminal velocity of rain drops is reached in about 8 metres (26 feet). Because forest canopies are usually higher than this, rain drops can often regain terminal velocity even after striking the canopy. However, the intact forest floor, with its layers of leaf litter and organic matter, is still able to absorb the impact of the rainfall.[47][48]\\r\\nDeforestation causes increased erosion rates due to exposure of mineral soil by removing the humus and litter layers from the soil surface, removing the vegetative cover that binds soil together, and causing heavy soil compaction from logging equipment. Once trees have been removed by fire or logging, infiltration rates become high and erosion low to the degree the forest floor remains intact. Severe fires can lead to significant further erosion if followed by heavy rainfall.[49]\\r\\nGlobally one of the largest contributors to erosive soil loss in the year 2006 is the slash and burn treatment of tropical forests. In a number of regions of the earth, entire sectors of a country have been rendered unproductive. For example, on the Madagascar high central plateau, comprising approximately ten percent of that country's land area, virtually the entire landscape is sterile of vegetation, with gully erosive furrows typically in excess of 50 metres (160?ft) deep and 1 kilometre (0.6 miles) wide. Shifting cultivation is a farming system which sometimes incorporates the slash and burn method in some regions of the world. This degrades the soil and causes the soil to become less and less fertile.[citation needed]\\r\\nUrbanization has major effects on erosion processesfirst by denuding the land of vegetative cover, altering drainage patterns, and compacting the soil during construction; and next by covering the land in an impermeable layer of asphalt or concrete that increases the amount of surface runoff and increases surface wind speeds.[50] Much of the sediment carried in runoff from urban areas (especially roads) is highly contaminated with fuel, oil, and other chemicals.[51] This increased runoff, in addition to eroding and degrading the land that it flows over, also causes major disruption to surrounding watersheds by altering the volume and rate of water that flows through them, and filling them with chemically polluted sedimentation. The increased flow of water through local waterways also causes a large increase in the rate of bank erosion.[52]\\r\\nThe warmer atmospheric temperatures observed over the past decades are expected to lead to a more vigorous hydrological cycle, including more extreme rainfall events.[53] The rise in sea levels that has occurred as a result of climate change has also greatly increased coastal erosion rates.[54][55]\\r\\nStudies on soil erosion suggest that increased rainfall amounts and intensities will lead to greater rates of soil erosion. Thus, if rainfall amounts and intensities increase in many parts of the world as expected, erosion will also increase, unless amelioration measures are taken. Soil erosion rates are expected to change in response to changes in climate for a variety of reasons. The most direct is the change in the erosive power of rainfall. Other reasons include: a) changes in plant canopy caused by shifts in plant biomass production associated with moisture regime; b) changes in litter cover on the ground caused by changes in both plant residue decomposition rates driven by temperature and moisture dependent soil microbial activity as well as plant biomass production rates; c) changes in soil moisture due to shifting precipitation regimes and evapo-transpiration rates, which changes infiltration and runoff ratios; d) soil erodibility changes due to decrease in soil organic matter concentrations in soils that lead to a soil structure that is more susceptible to erosion and increased runoff due to increased soil surface sealing and crusting; e) a shift of winter precipitation from non-erosive snow to erosive rainfall due to increasing winter temperatures; f) melting of permafrost, which induces an erodible soil state from a previously non-erodible one; and g) shifts in land use made necessary to accommodate new climatic regimes.[citation needed]\\r\\nStudies by Pruski and Nearing indicated that, other factors such as land use unconsidered, it is reasonable to expect approximately a 1.7% change in soil erosion for each 1% change in total precipitation under climate change.[56] In recent studies, there are predicted increasex of rainfall erosivity by 17% in the United States[57] and by 18% in Europe.[58]\\r\\nDue to the severity of its ecological effects, and the scale on which it is occurring, erosion constitutes one of the most significant global environmental problems we face today.[3]\\r\\nWater and wind erosion are now the two primary causes of land degradation; combined, they are responsible for 84% of degraded acreage.[2]\\r\\nEach year, about 75 billion tons of soil is eroded from the landa rate that is about 13ÿ40 times as fast as the natural rate of erosion.[61] Approximately 40% of the world's agricultural land is seriously degraded.[62] According to the United Nations, an area of fertile soil the size of Ukraine is lost every year because of drought, deforestation and climate change.[63] In Africa, if current trends of soil degradation continue, the continent might be able to feed just 25% of its population by 2025, according to UNU's Ghana-based Institute for Natural Resources in Africa.[64]\\r\\nRecent modeling developments have quantified rainfall erosivity at global scale using high temporal resolution(<30?min) and high fidelity rainfall recordings. The results is an extensive global data collection effort produced the Global Rainfall Erosivity Database (GloREDa) which includes rainfall erosivity for 3,625 stations and covers 63 countries. This first ever Global Rainfall Erosivity Database was used to develop a global erosivity map [65] at 30 arc-seconds(~1?km) based on sophisticated geostatistical process. According to a new study[66] published in Nature Communications, almost 36 billion tons of soil is lost every year due to water, and deforestation and other changes in land use make the problem worse.?The study investigates global soil erosion dynamics by means of high-resolution spatially distributed modelling (ca. 250?G?250?m cell size). The geo-statistical approach allows, for the first time, the thorough incorporation into a global soil erosion model of land use and changes in land use, the extent, types, spatial distribution of global croplands and the effects of different regional cropping systems.\\r\\nThe loss of soil fertility due to erosion is further problematic because the response is often to apply chemical fertilizers, which leads to further water and soil pollution, rather than to allow the land to regenerate.[67]\\r\\nSoil erosion (especially from agricultural activity) is considered to be the leading global cause of diffuse water pollution, due to the effects of the excess sediments flowing into the world's waterways. The sediments themselves act as pollutants, as well as being carriers for other pollutants, such as attached pesticide molecules or heavy metals.[68]\\r\\nThe effect of increased sediments loads on aquatic ecosystems can be catastrophic. Silt can smother the spawning beds of fish, by filling in the space between gravel on the stream bed. It also reduces their food supply, and causes major respiratory issues for them as sediment enters their gills. The biodiversity of aquatic plant and algal life is reduced, and invertebrates are also unable to survive and reproduce. While the sedimentation event itself might be relatively short-lived, the ecological disruption caused by the mass die off often persists long into the future.[69]\\r\\nOne of the most serious and long-running water erosion problems worldwide is in the People's Republic of China, on the middle reaches of the Yellow River and the upper reaches of the Yangtze River. From the Yellow River, over 1.6 billion tons of sediment flows into the ocean each year. The sediment originates primarily from water erosion in the Loess Plateau region of the northwest.[citation needed]\\r\\nSoil particles picked up during wind erosion of soil are a major source of air pollution, in the form of airborne particulates\\"dust\\". These airborne soil particles are often contaminated with toxic chemicals such as pesticides or petroleum fuels, posing ecological and public health hazards when they later land, or are inhaled/ingested.[70][71][72][73]\\r\\nDust from erosion acts to suppress rainfall and changes the sky color from blue to white, which leads to an increase in red sunsets[citation needed]. Dust events have been linked to a decline in the health of coral reefs across the Caribbean and Florida, primarily since the 1970s.[74] Similar dust plumes originate in the Gobi desert, which combined with pollutants, spread large distances downwind, or eastward, into North America.[75]\\r\\nMonitoring and modeling of erosion processes can help people better understand the causes of soil erosion, make predictions of erosion under a range of possible conditions, and plan the implementation of preventative and restorative strategies for erosion. However, the complexity of erosion processes and the number of scientific disciplines that must be considered to understand and model them (e.g. climatology, hydrology, geology, soil science, agriculture, chemistry, physics, etc.) makes accurate modelling challenging.[76][77][78] Erosion models are also non-linear, which makes them difficult to work with numerically, and makes it difficult or impossible to scale up to making predictions about large areas from data collected by sampling smaller plots.[79]\\r\\nThe most commonly used model for predicting soil loss from water erosion is the Universal Soil Loss Equation (USLE). This was developed in the 1960s and 1970s. It estimates the average annual soil loss A on a plot-sized area as:[80]\\r\\nwhere R is the rainfall erosivity factor,[81][82] K is the soil erodibility factor,[83] L and S are topographic factors[84] representing length and slope,[85] C is the cover and management factor[86] and P is the support practices factor.[87]\\r\\nDespite the USLE's plot-scale spatial focus, the model has often been used to estimate soil erosion on much larger areas, such as watersheds or even whole continents. For example, RUSLE has recently been used to quantify soil erosion across the whole of Europe. One major problem is that the USLE cannot simulate gully erosion, and so erosion from gullies is ignored in any USLE-based assessment of erosion. Yet erosion from gullies can be a substantial proportion (10ÿ80%) of total erosion on cultivated and grazed land.[88]\\r\\nDuring the 50 years since the introduction of the USLE, many other soil erosion models have been developed.[89] But because of the complexity of soil erosion and its constituent processes, all erosion models can give unsatisfactory results when validated i.e. when model predictions are compared with real-world measurements of erosion.[90][91] Thus new soil erosion models continue to be developed. Some of these remain USLE-based, e.g. the G2 model.[92][93] Other soil erosion models have largely (e.g. the Water Erosion Prediction Project model) or wholly (e.g. the Rangeland Hydrology and Erosion Model [94]) abandoned usage of USLE elements.\\r\\nThe most effective known method for erosion prevention is to increase vegetative cover on the land, which helps prevent both wind and water erosion.[95] Terracing is an extremely effective means of erosion control, which has been practiced for thousands of years by people all over the world.[96] Windbreaks (also called shelterbelts) are rows of trees and shrubs that are planted along the edges of agricultural fields, to shield the fields against winds.[97] In addition to significantly reducing wind erosion, windbreaks provide many other benefits such as improved microclimates for crops (which are sheltered from the dehydrating and otherwise damaging effects of wind), habitat for beneficial bird species,[98] carbon sequestration,[99] and aesthetic improvements to the agricultural landscape.[100][101] Traditional planting methods, such as mixed-cropping (instead of monocropping) and crop rotation have also been shown to significantly reduce erosion rates.[102][103] Crop residues play a role in the mitigation of erosion, because they reduce the impact of raindrops breaking up the soil particles.[104] There is a higher potential for erosion when producing potatoes than when growing cereals, or oilseed crops.[105] Forages have a fibrous root system, which helps combat erosion by anchoring the plants to the top layer of the soil, and covering the entirety of the field, as it is a non-row crop.[106] In tropical coastal systems, properties of mangroves have been examined as a potential means to reduce soil erosion. Their complex root structures are known to help reduce wave damage from storms and flood impacts while binding and building soils. These roots can slow down water flow, leading to the deposition of sediments and reduced erosion rates. However, in order to maintain sediment balance, adequate mangrove forest width needs to be present.[107]","input":"What are the four types of soil erosion?"},{"output":"twice","context":"The ICC Women's Cricket World Cup is the oldest and most prestigious international women's cricket tournament.\\r\\nThe Women's World Cup is currently organised by the International Cricket Council (ICC). Until 2005, when the two organisations merged, it was administered by a separate body, the International Women's Cricket Council (IWCC). The first World Cup was held in England in 1973, two years before the inaugural men's tournament. The event's early years were marked by funding difficulties, which meant several teams had to decline invitations to compete and caused gaps of up to six years between tournaments. However, since 2005 World Cups have been hosted at regular four-year intervals.\\r\\nThe eleven World Cups played to date have been held in five different countries, with India and England having hosted the event three times. The number of teams has been fixed at eight since the 2000 event, with the preceding tournament in 1997 having been contested by a record eleven teams, the most to date. Australia are the most successful team, having won six titles and failed to make the final on only three occasions. England (four titles) and New Zealand (one title) are the only other teams to have won the event, while India (twice) and the West Indies (once) have each reached the final without going on to win.\\r\\n\\r\\n\\r\\nWomen's international cricket was first played in 1934, when a party from England toured Australia and New Zealand. The first Test match was played on 28ÿ31 December 1934, and was won by England.[1] The first Test against New Zealand followed early the following year. These three nations remained the only Test playing teams in women's cricket until 1960, when South Africa played a number of matches against England.[1] Limited overs cricket was first played by first-class teams in England in 1962.[2] Nine years later, the first international one day match was played in men's cricket, when England took on Australia at the Melbourne Cricket Ground.[3]\\r\\nTalks began in 1987 about holding a World Cup for women's cricket, led by Jack Hayward.Heyhoe Flint & Rheinberg (1976), p. 168.</ref> South Africa, under pressure from the world for their apartheid laws, were not invited to take part in the competition.[4] Both of the other two Test playing nations, Australia and New Zealand were invited. Hayward had previously organised tours of the West Indies by England women, and it was from this region that the other two competing nations were drawn; Jamaica and Trinidad & Tobago. To make up the numbers, England also fielded a \\"Young England\\" team, and an \\"International XI\\" was also included.[5] Five South Africans were invited to play for the International XI as a means of compensation for the team not being invited, but these invitations were later withdrawn.[4]\\r\\nThe inaugural tournament was held at a variety of venues across Australia in June and July 1988,[6] two years before the first men's Cricket World Cup was played.[7] The competition was played as a round-robin tournament, and the last scheduled match was England against Australia. Australia went into the game leading the table by a solitary point: they had won four matches and had one abandoned. England had also won four matches, but they had lost to New Zealand.[6][8] As a result, the match also served as a de facto final for the competition. England won the match, held at Edgbaston, Birmingham by 92 runs to win the tournament.[9]\\r\\nThirteen nations have qualified for the Women's Cricket World Cup at least once (excluding qualification tournaments). Five teams have competed in every finals tournament, three of which have won the title.\\r\\n?No longer exists.\\r\\nThe table below provides an overview of the performances of teams over past World Cups, as of the end of group stage of the 2017 tournament. Teams are sorted by best performance, then by appearances, total number of wins, total number of games, and alphabetical order respectively.\\r\\n?No longer exists.","input":"How many times india won womens cricket world cup?"},{"output":"1887ÿ89","context":"The Eiffel Tower (/?a?f?l ?ta?.?r/ EYE-f?l TOW-?r; French: tour Eiffel, pronounced?[tu???f?l] ?listen) is a wrought iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\\r\\nConstructed from 1887ÿ89 as the entrance to the 1889 World's Fair, it was initially criticized by some of France's leading artists and intellectuals for its design, but it has become a global cultural icon of France and one of the most recognisable structures in the world.[3] The Eiffel Tower is the most-visited paid monument in the world; 6.91?million people ascended it in 2015.\\r\\nThe tower is 324 metres (1,063?ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410?ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17?ft). Excluding transmitters, the Eiffel Tower is the second-tallest structure in France after the Millau Viaduct.\\r\\nThe tower has three levels for visitors, with restaurants on the first and second levels. The top level's upper platform is 276?m (906?ft) above the ground ÿ the highest observation deck accessible to the public in the European Union. Tickets can be purchased to ascend by stairs or lift (elevator) to the first and second levels. The climb from ground level to the first level is over 300 steps, as is the climb from the first level to the second. Although there is a staircase to the top level, it is usually accessible only by lift.\\r\\n\\r\\n\\r\\nThe design of the Eiffel Tower was the product of Maurice Koechlin and mile Nouguier, two senior engineers working for the Compagnie des tablissements Eiffel, after discussion about a suitable centrepiece for the proposed 1889 Exposition Universelle, a world's fair to celebrate the centennial of the French Revolution. Eiffel openly acknowledged that inspiration for a tower came from the Latting Observatory built in New York City in 1853.[4] In May 1884, working at home, Koechlin made a sketch of their idea, described by him as \\"a great pylon, consisting of four lattice girders standing apart at the base and coming together at the top, joined together by metal trusses at regular intervals\\".[5] Eiffel initially showed little enthusiasm, but he did approve further study, and the two engineers then asked Stephen Sauvestre, the head of company's architectural department, to contribute to the design. Sauvestre added decorative arches to the base of the tower, a glass pavilion to the first level, and other embellishments.\\r\\nThe new version gained Eiffel's support: he bought the rights to the patent on the design which Koechlin, Nougier, and Sauvestre had taken out, and the design was exhibited at the Exhibition of Decorative Arts in the autumn of 1884 under the company name. On 30 March 1885, Eiffel presented his plans to the Socit des Ingnieurs Civils; after discussing the technical problems and emphasising the practical uses of the tower, he finished his talk by saying the tower would symbolise,\\r\\nNot only the art of the modern engineer, but also the century of Industry and Science in which we are living, and for which the way was prepared by the great scientific movement of the eighteenth century and by the Revolution of 1789, to which this monument will be built as an expression of France's gratitude.[6]\\r\\nLittle progress was made until 1886, when Jules Grvy was re-elected as president of France and douard Lockroy was appointed as minister for trade. A budget for the exposition was passed and, on 1 May, Lockroy announced an alteration to the terms of the open competition being held for a centrepiece to the exposition, which effectively made the selection of Eiffel's design a foregone conclusion, as entries had to include a study for a 300?m (980?ft) four-sided metal tower on the Champ de Mars.[6] (A 300-meter tower was then considered a herculean engineering effort). On 12 May, a commission was set up to examine Eiffel's scheme and its rivals, which, a month later, decided that all the proposals except Eiffel's were either impractical or lacking in details.\\r\\nAfter some debate about the exact location of the tower, a contract was signed on 8 January 1887. This was signed by Eiffel acting in his own capacity rather than as the representative of his company, and granted him 1.5 million francs toward the construction costs: less than a quarter of the estimated 6.5 million francs. Eiffel was to receive all income from the commercial exploitation of the tower during the exhibition and for the next 20 years. He later established a separate company to manage the tower, putting up half the necessary capital himself.[7]\\r\\nThe proposed tower had been a subject of controversy, drawing criticism from those who did not believe it was feasible and those who objected on artistic grounds. These objections were an expression of a long-standing debate in France about the relationship between architecture and engineering. It came to a head as work began at the Champ de Mars: a \\"Committee of Three Hundred\\" (one member for each metre of the tower's height) was formed, led by the prominent architect Charles Garnier and including some of the most important figures of the arts, such as Adolphe Bouguereau, Guy de Maupassant, Charles Gounod and Jules Massenet. A petition called \\"Artists against the Eiffel Tower\\" was sent to the Minister of Works and Commissioner for the Exposition, Charles Alphand, and it was published by Le Temps on 14 February 1887:\\r\\nWe, writers, painters, sculptors, architects and passionate devotees of the hitherto untouched beauty of Paris, protest with all our strength, with all our indignation in the name of slighted French taste, against the erection  of this useless and monstrous Eiffel Tower  To bring our arguments home, imagine for a moment a giddy, ridiculous tower dominating Paris like a gigantic black smokestack, crushing under its barbaric bulk Notre Dame, the Tour Saint-Jacques, the Louvre, the Dome of les Invalides, the Arc de Triomphe, all of our humiliated monuments will disappear in this ghastly dream. And for twenty years  we shall see stretching like a blot of ink the hateful shadow of the hateful column of bolted sheet metal.[8]\\r\\nGustave Eiffel responded to these criticisms by comparing his tower to the Egyptian pyramids: \\"My tower will be the tallest edifice ever erected by man. Will it not also be grandiose in its way? And why would something admirable in Egypt become hideous and ridiculous in Paris?\\"[9] These criticisms were also dealt with by douard Lockroy in a letter of support written to Alphand, ironically saying,[10] \\"Judging by the stately swell of the rhythms, the beauty of the metaphors, the elegance of its delicate and precise style, one can tell this protest is the result of collaboration of the most famous writers and poets of our time\\", and he explained that the protest was irrelevant since the project had been decided upon months before, and construction on the tower was already under way.\\r\\nIndeed, Garnier was a member of the Tower Commission that had examined the various proposals, and had raised no objection. Eiffel was similarly unworried, pointing out to a journalist that it was premature to judge the effect of the tower solely on the basis of the drawings, that the Champ de Mars was distant enough from the monuments mentioned in the protest for there to be little risk of the tower overwhelming them, and putting the aesthetic argument for the tower: \\"Do not the laws of natural forces always conform to the secret laws of harmony?\\"[11]\\r\\nSome of the protesters changed their minds when the tower was built; others remained unconvinced.[12] Guy de Maupassant supposedly ate lunch in the tower's restaurant every day because it was the one place in Paris where the tower was not visible.[13]\\r\\nBy 1918, it had become a symbol of Paris and of France after Guillaume Apollinaire wrote a nationalist poem in the shape of the tower (a calligram) to express his feelings about the war against Germany.[14] Today, it is widely considered to be a remarkable piece of structural art, and is often featured in films and literature.\\r\\nWork on the foundations started on 28 January 1887.[15] Those for the east and south legs were straightforward, with each leg resting on four 2?m (6.6?ft) concrete slabs, one for each of the principal girders of each leg. The west and north legs, being closer to the river Seine, were more complicated: each slab needed two piles installed by using compressed-air caissons 15?m (49?ft) long and 6?m (20?ft) in diameter driven to a depth of 22?m (72?ft)[16] to support the concrete slabs, which were 6?m (20?ft) thick. Each of these slabs supported a block of limestone with an inclined top to bear a supporting shoe for the ironwork.\\r\\nEach shoe was anchored to the stonework by a pair of bolts 10?cm (4?in) in diameter and 7.5?m (25?ft) long. The foundations were completed on 30 June, and the erection of the ironwork began. The visible work on-site was complemented by the enormous amount of exacting preparatory work that took place behind the scenes: the drawing office produced 1,700 general drawings and 3,629 detailed drawings of the 18,038 different parts needed.[17] The task of drawing the components was complicated by the complex angles involved in the design and the degree of precision required: the position of rivet holes was specified to within 0.1?mm (0.0039?in) and angles worked out to one second of arc. The finished components, some already riveted together into sub-assemblies, arrived on horse-drawn carts from a factory in the nearby Parisian suburb of Levallois-Perret and were first bolted together, with the bolts being replaced with rivets as construction progressed. No drilling or shaping was done on site: if any part did not fit, it was sent back to the factory for alteration. In all, 18,038 pieces were joined together using 2.5?million rivets.[15]\\r\\nAt first the legs were constructed as cantilevers, but about halfway to the first level, construction was paused in order to create a substantial timber scaffold. This renewed concerns about the structural integrity of the tower, and sensational headlines such as \\"Eiffel Suicide!\\" and \\"Gustave Eiffel Has Gone Mad: He Has Been Confined in an Asylum\\" appeared in the tabloid press.[18] At this stage, a small \\"creeper\\" crane designed to move up the tower was installed in each leg. They made use of the guides for the lifts which were to be fitted in the four legs. The critical stage of joining the legs at the first level was completed by the end of March 1888.[15] Although the metalwork had been prepared with the utmost attention to detail, provision had been made to carry out small adjustments in order to precisely align the legs; hydraulic jacks were fitted to the shoes at the base of each leg, capable of exerting a force of 800 tonnes, and the legs were intentionally constructed at a slightly steeper angle than necessary, being supported by sandboxes on the scaffold. Although construction involved 300 on-site employees,[15] only one person died thanks to Eiffel's stringent safety precautions and the use of movable gangways, guardrails and screens.\\r\\nThe start of the erection of the metalwork.\\r\\n7 December 1887: Construction of the legs with scaffolding.\\r\\n20 March 1888: Completion of the first level.\\r\\n15 May 1888: Start of construction on the second stage.\\r\\n21 August 1888: Completion of the second level.\\r\\n26 December 1888: Construction of the upper stage.\\r\\n15 March 1889: Construction of the cupola.\\r\\nEquipping the tower with adequate and safe passenger lifts was a major concern of the government commission overseeing the Exposition. Although some visitors could be expected to climb to the first level, or even the second, lifts clearly had to be the main means of ascent.[19]\\r\\nConstructing lifts to reach the first level was relatively straightforward: the legs were wide enough at the bottom and so nearly straight that they could contain a straight track, and a contract was given to the French company Roux, Combaluzier & Lepape for two lifts to be fitted in the east and west legs.[20] Roux, Combaluzier & Lepape used a pair of endless chains with rigid, articulated links to which the car was attached. Lead weights on some links of the upper or return sections of the chains counterbalanced most of the car's weight. The car was pushed up from below, not pulled up from above: to prevent the chain buckling, it was enclosed in a conduit. At the bottom of the run, the chains passed around 3.9?m (12?ft 10?in) diameter sprockets. Smaller sprockets at the top guided the chains.[20]\\r\\nInstalling lifts to the second level was more of a challenge because a straight track was impossible. No French company wanted to undertake the work. The European branch of Otis Brothers & Company submitted a proposal but this was rejected: the fair's charter ruled out the use of any foreign material in the construction of the tower. The deadline for bids was extended but still no French companies put themselves forward, and eventually the contract was given to Otis in July 1887.[21] Otis were confident they would eventually be given the contract and had already started creating designs.\\r\\nThe car was divided into two superimposed compartments, each holding 25 passengers, with the lift operator occupying an exterior platform on the first level. Motive power was provided by an inclined hydraulic ram 12.67?m (41?ft 7?in) long and 96.5?cm (38.0?in) in diameter in the tower leg with a stroke of 10.83?m (35?ft 6?in): this moved a carriage carrying six sheaves. Five fixed sheaves were mounted higher up the leg, producing an arrangement similar to a block and tackle but acting in reverse, multiplying the stroke of the piston rather than the force generated. The hydraulic pressure in the driving cylinder was produced by a large open reservoir on the second level. After being exhausted from the cylinder, the water was pumped back up to the reservoir by two pumps in the machinery room at the base of the south leg. This reservoir also provided power to the lifts to the first level.\\r\\nThe original lifts for the journey between the second and third levels were supplied by Lon Edoux. A pair of 81?m (266?ft) hydraulic rams were mounted on the second level, reaching nearly halfway up to the third level. One lift car was mounted on top of these rams: cables ran from the top of this car up to sheaves on the third level and back down to a second car. Each car only travelled half the distance between the second and third levels and passengers were required to change lifts halfway by means of a short gangway. The 10-ton cars each held 65 passengers.[22]\\r\\nThe main structural work was completed at the end of March 1889 and, on 31 March, Eiffel celebrated by leading a group of government officials, accompanied by representatives of the press, to the top of the tower.[12] Because the lifts were not yet in operation, the ascent was made by foot, and took over an hour, with Eiffel stopping frequently to explain various features. Most of the party chose to stop at the lower levels, but a few, including the structural engineer, mile Nouguier, the head of construction, Jean Compagnon, the President of the City Council, and reporters from Le Figaro and Le Monde Illustr, completed the ascent. At 2:35?pm, Eiffel hoisted a large Tricolour to the accompaniment of a 25-gun salute fired at the first level.[23]\\r\\nThere was still work to be done, particularly on the lifts and facilities, and the tower was not opened to the public until nine days after the opening of the exposition on 6 May; even then, the lifts had not been completed. The tower was an instant success with the public, and nearly 30,000 visitors made the 1,710-step climb to the top before the lifts entered service on 26 May.[24] Tickets cost 2 francs for the first level, 3 for the second, and 5 for the top, with half-price admission on Sundays,[25] and by the end of the exhibition there had been 1,896,987 visitors.[3]\\r\\nAfter dark, the tower was lit by hundreds of gas lamps, and a beacon sent out three beams of red, white and blue light. Two searchlights mounted on a circular rail were used to illuminate various buildings of the exposition. The daily opening and closing of the exposition were announced by a cannon at the top.\\r\\nOn the second level, the French newspaper Le Figaro had an office and a printing press, where a special souvenir edition, Le Figaro de la Tour, was made. There was also a patisserie.\\r\\nAt the top, there was a post office where visitors could send letters and postcards as a memento of their visit. Graffitists were also catered for: sheets of paper were mounted on the walls each day for visitors to record their impressions of the tower. Gustave Eiffel described some of the responses as vraiment curieuse (\\"truly curious\\").[26]\\r\\nFamous visitors to the tower included the Prince of Wales, Sarah Bernhardt, \\"Buffalo Bill\\" Cody (his Wild West show was an attraction at the exposition) and Thomas Edison.[24] Eiffel invited Edison to his private apartment at the top of the tower, where Edison presented him with one of his phonographs, a new invention and one of the many highlights of the exposition.[27] Edison signed the guestbook with this message:\\r\\nTo M Eiffel the Engineer the brave builder of so gigantic and original specimen of modern Engineering from one who has the greatest respect and admiration for all Engineers including the Great Engineer the Bon Dieu, Thomas Edison.\\r\\nEiffel had a permit for the tower to stand for 20 years. It was to be dismantled in 1909, when its ownership would revert to the City of Paris. The City had planned to tear it down (part of the original contest rules for designing a tower was that it should be easy to dismantle) but as the tower proved to be valuable for communication purposes, it was allowed to remain after the expiry of the permit.\\r\\nEiffel made use of his apartment at the top of the tower to carry out meteorological observations, and also used the tower to perform experiments on the action of air resistance on falling bodies.[28]\\r\\nFor the 1900 Exposition Universelle, the lifts in the east and west legs were replaced by lifts running as far as the second level constructed by the French firm Fives-Lille. These had a compensating mechanism to keep the floor level as the angle of ascent changed at the first level, and were driven by a similar hydraulic mechanism to the Otis lifts, although this was situated at the base of the tower. Hydraulic pressure was provided by pressurised accumulators located near this mechanism.[21] At the same time the lift in the north pillar was removed and replaced by a staircase to the first level. The layout of both first and second levels was modified, with the space available for visitors on the second level. The original lift in the south pillar was removed 13 years later.\\r\\nOn 19 October 1901, Alberto Santos-Dumont, flying his No.6 airship, won a 100,000-franc prize offered by Henri Deutsch de la Meurthe for the first person to make a flight from St. Cloud to the Eiffel Tower and back in less than half an hour.[29]\\r\\nMany innovations took place at the Eiffel Tower in the early 20th century. In 1910, Father Theodor Wulf measured radiant energy at the top and bottom of the tower. He found more at the top than expected, incidentally discovering what are known today as cosmic rays.[30] Just two years later, on 4 February 1912, Austrian tailor Franz Reichelt died after jumping from the first level of the tower (a height of 57 metres) to demonstrate his parachute design.[31] In 1914, at the outbreak of World War?I, a radio transmitter located in the tower jammed German radio communications, seriously hindering their advance on Paris and contributing to the Allied victory at the First Battle of the Marne.[32] From 1925 to 1934, illuminated signs for Citro?n adorned three of the tower's sides, making it the tallest advertising space in the world at the time.[citation needed] In April 1935, the tower was used to make experimental low-resolution television transmissions, using a shortwave transmitter of 200 watts power. On 17 November, an improved 180-line transmitter was installed.[33]\\r\\nOn two separate but related occasions in 1925, the con artist Victor Lustig \\"sold\\" the tower for scrap metal.[34] A year later, in February 1926, pilot Leon Collet was killed trying to fly under the tower. His aircraft became entangled in an aerial belonging to a wireless station.[35] A bust of Gustave Eiffel by Antoine Bourdelle was unveiled at the base of the north leg on 2 May 1929.[36] In 1930, the tower lost the title of the world's tallest structure when the Chrysler Building in New York City was completed.[37] In 1938, the decorative arcade around the first level was removed.[38]\\r\\nUpon the German occupation of Paris in 1940, the lift cables were cut by the French. The tower was closed to the public during the occupation and the lifts were not repaired until 1946.[39] In 1940, German soldiers had to climb the tower to hoist a swastika-centered Reichskriegsflagge,[40] but the flag was so large it blew away just a few hours later, and was replaced by a smaller one.[41] When visiting Paris, Hitler chose to stay on the ground. When the Allies were nearing Paris in August 1944, Hitler ordered General Dietrich von Choltitz, the military governor of Paris, to demolish the tower along with the rest of the city. Von Choltitz disobeyed the order.[42] On 25 June, before the Germans had been driven out of Paris, the German flag was replaced with a Tricolour by two men from the French Naval Museum, who narrowly beat three men led by Lucien Sarniguet, who had lowered the Tricolour on 13 June 1940 when Paris fell to the Germans.[39]\\r\\nA fire started in the television transmitter on 3 January 1956, damaging the top of the tower. Repairs took a year, and in 1957, the present radio aerial was added to the top.[43] In 1964, the Eiffel Tower was officially declared to be a historical monument by the Minister of Cultural Affairs, Andr Malraux.[44] A year later, an additional lift system was installed in the north pillar.[45]\\r\\nAccording to interviews, in 1967, Montreal Mayor Jean Drapeau negotiated a secret agreement with Charles de Gaulle for the tower to be dismantled and temporarily relocated to Montreal to serve as a landmark and tourist attraction during Expo 67. The plan was allegedly vetoed by the company operating the tower out of fear that the French government could refuse permission for the tower to be restored in its original location.[46]\\r\\nIn 1982, the original lifts between the second and third levels were replaced after 97 years in service. These had been closed to the public between November and March because the water in the hydraulic drive tended to freeze. The new cars operate in pairs, with one counterbalancing the other, and perform the journey in one stage, reducing the journey time from eight minutes to less than two minutes. At the same time, two new emergency staircases were installed, replacing the original spiral staircases. In 1983, the south pillar was fitted with an electrically driven Otis lift to serve the Jules Verne restaurant.[citation needed] The Fives-Lille lifts in the east and west legs, fitted in 1899, were extensively refurbished in 1986. The cars were replaced, and a computer system was installed to completely automate the lifts. The motive power was moved from the water hydraulic system to a new electrically driven oil-filled hydraulic system, and the original water hydraulics were retained solely as a counterbalance system.[45] A service lift was added to the south pillar for moving small loads and maintenance personnel three years later.\\r\\nRobert Moriarty flew a Beechcraft Bonanza under the tower on 31 March 1984.[47] In 1987, A.J. Hackett made one of his first bungee jumps from the top of the Eiffel Tower, using a special cord he had helped develop. Hackett was arrested by the police.[48] On 27 October 1991, Thierry Devaux, along with mountain guide Herv Calvayrac, performed a series of acrobatic figures while bungee jumping from the second floor of the tower.[49] Facing the Champ de Mars, Devaux used an electric winch between figures to go back up to the second floor. When firemen arrived, he stopped after the sixth jump.[citation needed]\\r\\nFor its \\"Countdown to the Year 2000\\" celebration on 31 December 1999, flashing lights and high-powered searchlights were installed on the tower. Fireworks were set off all over it. An exhibition above a cafeteria on the first floor commemorates this event. The searchlights on top of the tower made it a beacon in Paris's night sky, and 20,000 flashing bulbs gave the tower a sparkly appearance for five minutes every hour on the hour.[50]\\r\\nThe lights sparkled blue for several nights to herald the new millennium On 31 December 2000. The sparkly lighting continued for 18 months until July 2001. The sparkling lights were turned on again on 21 June 2003, and the display was planned to last for 10 years before they needed replacing.[51]\\r\\nThe tower received its 200,000,000th guest on 28 November 2002.[52] The tower has operated at its maximum capacity of about 7?million visitors since 2003.[53] In 2004, the Eiffel Tower began hosting a seasonal ice rink on the first level.[54] A glass floor was installed on the first level during the 2014 refurbishment.[55]\\r\\nThe puddled iron (wrought iron) of the Eiffel Tower weighs 7,300 tons,[56] and the addition of lifts, shops and antennae have brought the total weight to approximately 10,100?tons.[57] As a demonstration of the economy of design, if the 7,300?tons of metal in the structure were melted down, it would fill the square base, 125 metres (410?ft) on each side, to a depth of only 6.25?cm (2.46?in) assuming the density of the metal to be 7.8?tons per cubic metre.[58] Additionally, a cubic box surrounding the tower (324?m x 125?m x 125?m) would contain 6,200?tons of air, weighing almost as much as the iron itself. Depending on the ambient temperature, the top of the tower may shift away from the sun by up to 18?cm (7?in) due to thermal expansion of the metal on the side facing the sun.[59]\\r\\nWhen it was built, many were shocked by the tower's daring form. Eiffel was accused of trying to create something artistic with no regard to the principles of engineering. However, Eiffel and his team ÿ experienced bridge builders ÿ understood the importance of wind forces, and knew that if they were going to build the tallest structure in the world, they had to be sure it could withstand them. In an interview with the newspaper Le Temps published on 14 February 1887, Eiffel said:\\r\\nIs it not true that the very conditions which give strength also conform to the hidden rules of harmony?  Now to what phenomenon did I have to give primary concern in designing the Tower? It was wind resistance. Well then! I hold that the curvature of the monument's four outer edges, which is as mathematical calculation dictated it should be  will give a great impression of strength and beauty, for it will reveal to the eyes of the observer the boldness of the design as a whole.[60]\\r\\nHe used graphical methods to determine the strength of the tower and empirical evidence to account for the effects of wind, rather than a mathematical formula. Close examination of the tower reveals a basically exponential shape.[61] All parts of the tower were over-designed to ensure maximum resistance to wind forces. The top half was even assumed to have no gaps in the latticework.[62] In the years since it was completed, engineers have put forward various mathematical hypotheses in an attempt to explain the success of the design. The most recent, devised in 2004 after letters sent by Eiffel to the French Society of Civil Engineers in 1885 were translated into English, is described as a non-linear integral equation based on counteracting the wind pressure on any point of the tower with the tension between the construction elements at that point.[61]\\r\\nThe Eiffel Tower sways by up to 9?centimetres (3.5?in) in the wind.[63]\\r\\nWhen originally built, the first level contained three restaurantsone French, one Russian and one Flemishand an \\"Anglo-American Bar\\". After the exposition closed, the Flemish restaurant was converted to a 250-seat theatre. A promenade 2.6-metre (8?ft 6?in) wide ran around the outside of the first level. At the top, there were laboratories for various experiments, and a small apartment reserved for Gustave Eiffel to entertain guests, which is now open to the public, complete with period decorations and lifelike mannequins of Eiffel and some of his notable guests.[64]\\r\\nIn May 2016, an apartment was created on the first level to accommodate four competition winners during the UEFA Euro 2016 football tournament in Paris in June. The apartment has a kitchen, two bedrooms, a lounge, and views of Paris landmarks including the Seine, the Sacre Coeur, and the Arc de Triomphe.[65]\\r\\nThe arrangement of the lifts has been changed several times during the tower's history. Given the elasticity of the cables and the time taken to align the cars with the landings, each lift, in normal service, takes an average of 8 minutes and 50 seconds to do the round trip, spending an average of 1 minute and 15 seconds at each level. The average journey time between levels is 1 minute. The original hydraulic mechanism is on public display in a small museum at the base of the east and west legs. Because the mechanism requires frequent lubrication and maintenance, public access is often restricted. The rope mechanism of the north tower can be seen as visitors exit the lift.[citation needed]\\r\\nGustave Eiffel engraved on the tower the names of 72 French scientists, engineers and mathematicians in recognition of their contributions to the building of the tower. Eiffel chose this \\"invocation of science\\" because of his concern over the artists' protest. At the beginning of the 20th century, the engravings were painted over, but they were restored in 1986ÿ87 by the Socit Nouvelle d'exploitation de la Tour Eiffel, a company operating the tower.[66]\\r\\nThe tower is painted in three shades: lighter at the top, getting progressively darker towards the bottom to perfectly complement the Parisian sky.[67] It was originally reddish brown; this changed in 1968 to a bronze colour known as \\"Eiffel Tower Brown\\".[68]\\r\\nThe only non-structural elements are the four decorative grill-work arches, added in Sauvestre's sketches, which served to make the tower look more substantial and to make a more impressive entrance to the exposition.[69]\\r\\nOne of the great Hollywood movie clichs is that the view from a Parisian window always includes the tower. In reality, since zoning restrictions limit the height of most buildings in Paris to seven storeys, only a small number of tall buildings have a clear view of the tower.[citation needed]\\r\\nMaintenance of the tower includes applying 60?tons of paint every seven years to prevent it from rusting. The tower has been completely repainted at least 19 times since it was built. Lead paint was still being used as recently as 2001 when the practice was stopped out of concern for the environment.[51]\\r\\nThe nearest Paris Mtro station is Bir-Hakeim and the nearest RER station is Champ de Mars-Tour Eiffel.[70] The tower itself is located at the intersection of the quai Branly and the Pont d'Ina.\\r\\nMore than 250?million people have visited the tower since it was completed in 1889.[3] In 2015, there were 6.91?million visitors.[71] The tower is the most-visited paid monument in the world.[72] An average of 25,000 people ascend the tower every day which can result in long queues.[73] Tickets can be purchased online to avoid the long queues.\\r\\nThe tower has two restaurants: Le 58 Tour Eiffel on the first level, and Le Jules Verne, a gourmet restaurant with its own lift on the second level. This restaurant has one star in the Michelin Red Guide. It is run by the multi-Michelin star chef Alain Ducasse[74] and owes its name to the famous science-fiction writer Jules Verne. Additionally, there is a champagne bar at the top of the Eiffel Tower.\\r\\nAs one of the most iconic landmarks in the world, the Eiffel Tower has been the inspiration for the creation of many replicas and similar towers. An early example is Blackpool Tower in England. The mayor of Blackpool, Sir John Bickerstaffe, was so impressed on seeing the Eiffel Tower at the 1889 exposition that he commissioned a similar tower to be built in his town. It opened in 1894 and is 158.1?metres (518?ft) tall.[75] Tokyo Tower in Japan, built as a communications tower in 1958, was also inspired by the Eiffel Tower.[76]\\r\\nThere are various scale models of the tower in the United States, including a half-scale version at the Paris Las Vegas, Nevada, one in Paris, Texas built in 1993, and two 1:3 scale models at Kings Island, Ohio, and Kings Dominion, Virginia, amusement parks opened in 1972 and 1975 respectively. Two 1:3 scale models can be found in China, one in Durango, Mexico that was donated by the local French community, and several across Europe.[77]\\r\\nIn 2011, the TV show Pricing the Priceless on the National Geographic Channel speculated that a full-size replica of the tower would cost approximately US$480?million to build.[78]\\r\\n\\r\\nThe tower has been used for making radio transmissions since the beginning of the 20th century. Until the 1950s, sets of aerial wires ran from the cupola to anchors on the Avenue de Suffren and Champ de Mars. These were connected to longwave transmitters in small bunkers. In 1909, a permanent underground radio centre was built near the south pillar, which still exists today. On 20 November 1913, the Paris Observatory, using the Eiffel Tower as an aerial, exchanged wireless signals with the United States Naval Observatory, which used an aerial in Arlington, Virginia. The object of the transmissions was to measure the difference in longitude between Paris and Washington, D.C.[79] Today, radio and digital television signals are transmitted from the Eiffel Tower.\\r\\nA television antenna was first installed on the tower in 1957, increasing its height by 18.7?m (61.4?ft). Work carried out in 2000 added a further 5.3?m (17.4?ft), giving the current height of 324?m (1,063?ft).[51] Analogue television signals from the Eiffel Tower ceased on 8 March 2011.\\r\\nThe tower and its image have long been in the public domain.[80] In June 1990 a French court ruled that a special lighting display on the tower in 1989 to mark the tower's 100th anniversary was an \\"original visual creation\\" protected by copyright. The Court of Cassation, France's judicial court of last resort, upheld the ruling in March 1992.[81] The Socit d'Exploitation de la Tour Eiffel (SETE) now considers any illumination of the tower to be a separate work of art that falls under copyright.[82] As a result, the SNTE alleges that it is illegal to publish contemporary photographs of the lit tower at night without permission in France and some other countries for commercial use.[83][84]\\r\\nThe imposition of copyright has been controversial. The Director of Documentation for what was then called the Socit Nouvelle d'exploitation de la Tour Eiffel (SNTE), Stphane Dieu, commented in 2005: \\"It is really just a way to manage commercial use of the image, so that it isn't used in ways [of which] we don't approve\\".[85] SNTE made over ?1?million from copyright fees in 2002.[86] However, it could also be used to restrict the publication of tourist photographs of the tower at night, as well as hindering non-profit and semi-commercial publication of images of the illuminated tower.[80]\\r\\nFrench doctrine and jurisprudence allows pictures incorporating a copyrighted work as long as their presence is incidental or accessory to the subject being represented,[87] a reasoning akin to the de minimis rule. Therefore, SETE may be unable to claim copyright on photographs of Paris which happen to include the lit tower.\\r\\nThe Eiffel Tower was the world's tallest structure when completed in 1889, a distinction it retained until 1929 when the Chrysler Building in New York City was topped out.[88] The tower has lost its standing both as the world's tallest structure and the world's tallest lattice tower but retains its status as the tallest freestanding (non-guyed) structure in France.","input":"When was the eiffel tower built what year?"},{"output":"Gerald Ford","context":"The following is a list of Presidents of the United States by date of death, plus additional lists of presidential death related statistics. Forty-four persons have served as President of the United States since the office came into existence in 1789. Of these, 38 have died?ÿ eight died while in office.\\r\\nJohn F. Kennedy, assassinated at the age of 7004169780000000000?46?years, 177?days, was the nation's shortest-lived president; the youngest to have died by natural causes was James K. Polk, who died of cholera at the age of 7004195830000000000?53?years, 225?days. The oldest president at the time of death was Gerald Ford, who died at the age of 7004341330000000000?93?years, 165?days.\\r\\n\\r\\n\\r\\nLiving presidents as of February 11, 2018 (in order of service) are: Jimmy Carter, George H. W. Bush, Bill Clinton, George W. Bush, Barack Obama, and Donald Trump.\\r\\n3rd President Thomas Jefferson (July 4, 1826)\\r\\n5th President James Monroe (died July 4, 1831)\\r\\n7th President Andrew Jackson (died June 8, 1845)\\r\\n9th President William Henry Harrison (died April 4, 1841)\\r\\n10th President John Tyler (died January 18, 1862)\\r\\n11th President James K. Polk (died June 15, 1849)\\r\\n12th President Zachary Taylor (died July 9, 1850)\\r\\n14th President Franklin Pierce (died October 8, 1869)\\r\\n15th President James Buchanan (died June 1, 1868)\\r\\n16th President Abraham Lincoln (died April 15, 1865)\\r\\n20th President James A. Garfield (died September 19, 1881)\\r\\n21st President Chester A. Arthur (died November 19, 1886)\\r\\n25th President William McKinley (died September 14, 1901)\\r\\n28th President Woodrow Wilson (died February 3, 1924)\\r\\n29th President Warren Harding (died August 2, 1923)\\r\\n32nd President Franklin D. Roosevelt (died April 12, 1945)\\r\\n34th President Dwight D. Eisenhower (died March 28, 1969)\\r\\n35th President John F. Kennedy (died November 22, 1963)\\r\\n40th President Ronald Reagan (died June 5, 2004)","input":"Who was the last american president to die?"},{"output":"before the 1958 season","context":"The Los Angeles Dodgers are an American professional baseball team based in Los Angeles, California. The Dodgers compete in Major League Baseball (MLB) as a member club of the National League (NL) West division. Established in 1883 in Brooklyn, New York,[1][2] the team moved to Los Angeles before the 1958 season.[3] They played for four seasons at the Los Angeles Memorial Coliseum before moving to their current home of Dodger Stadium in 1962.\\r\\nThe Dodgers as a franchise have won six World Series titles and 21 National League pennants. 11 NL MVP award winners have played for the Dodgers, winning a total of 13 MVP Awards, Eight Cy Young Award winners have pitched for the Dodgers, winning a total of twelve Cy Young Awards. The team has also produced 17 Rookie of the Year Award winners, including four consecutive from 1979 to 1982 and five consecutive from 1992 to 1996.\\r\\n\\r\\n\\r\\nIn the early 20th century, the team, then known as the Robins, won league pennants in 1916 and 1920, losing the World Series both times, first to Boston and then Cleveland. In the 1930s, the team changed its name to the Dodgers, named after the Brooklyn pedestrians who dodged the streetcars in the city.[4] In 1941, the Dodgers captured their third National League pennant, only to lose to the New York Yankees. This marked the onset of the DodgersÿYankees rivalry, as the Dodgers would face them in their next six World Series appearances. Led by Jackie Robinson, the first black Major League Baseball player of the modern era; and three-time National League Most Valuable Player Roy Campanella, also signed out of the Negro Leagues, the Dodgers captured their first World Series title in 1955 by defeating the Yankees for the first time, a story notably described in the 1972 book The Boys of Summer.\\r\\nFollowing the 1957 season the team left Brooklyn. In just their second season in Los Angeles, the Dodgers won their second World Series title, beating the Chicago White Sox in six games in 1959. Spearheaded by the dominant pitching style of Sandy Koufax and Don Drysdale, the Dodgers captured three pennants in the 1960s and won two more World Series titles, sweeping the Yankees in four games in 1963, and edging the Minnesota Twins in seven in 1965. The 1963 sweep was their second victory against the Yankees, and their first against them as a Los Angeles team. The Dodgers won four more pennants in 1966, 1974, 1977 and 1978, but lost in each World Series appearance. They went on to win the World Series again in 1981, thanks in part to pitching sensation Fernando Valenzuela. The early 1980s were affectionately dubbed \\"Fernandomania.\\" In 1988, another pitching hero, Orel Hershiser, again led them to a World Series victory, aided by one of the most memorable home runs of all time, by their injured star outfielder Kirk Gibson coming off the bench to pinch hit with two outs in the bottom of the ninth inning of game 1, in his only appearance of the series.\\r\\nThe Dodgers share a fierce rivalry with the San Francisco Giants, the oldest rivalry in baseball, dating back to when the two franchises played in New York City. Both teams moved west for the 1958 season. The Brooklyn Dodgers and Los Angeles Dodgers have collectively appeared in the World Series 18 times, while the New York Giants and San Francisco Giants have collectively appeared 20 times and have been invited 21 times. The Giants have won two more World Series (8); the Dodgers have won 21 National League pennants, while the Giants hold the record with 23. Although the two franchises have enjoyed near equal success, the city rivalries are rather lopsided and in both cases, a team's championships have predated to the other's first one in that particular location. When the two teams were based in New York, the Giants won five World Series championships, and the Dodgers one. After the move to California, the Dodgers have won five in Los Angeles, the Giants have won three in San Francisco.\\r\\nThe Dodgers were founded in 1883 as the Brooklyn Atlantics, taking the name of a defunct team that had played in Brooklyn before them. The team joined the American Association in 1884 and won the AA championship in 1889 before joining the National League in 1890. They promptly won the NL Championship their first year in the League. The team was known alternatively as the Bridegrooms[5], Grooms, Superbas, Robins, and Trolley Dodgers before officially becoming the Dodgers in the 1930s.\\r\\nIn Brooklyn, the Dodgers won the NL pennant several times (1890, 1899, 1900, 1916, 1920, 1941, 1947, 1949, 1952, 1953, 1955, 1956) and the World Series in 1955. After moving to Los Angeles, the team won National League pennants in 1959, 1963, 1965, 1966, 1974, 1977, 1978, 1981, and 1988, with World Series championships in 1959, 1963, 1965, 1981, 1988. In all, the Dodgers have appeared in 18 World Series: 9 in Brooklyn and 9 in Los Angeles.\\r\\nFor most of the first half of the 20th century, no Major League Baseball team employed an African American player. Jackie Robinson became the first African American to play for a Major League Baseball team when he played his first major league game on April 15, 1947, as a member of the Brooklyn Dodgers. This was mainly due to general manager Branch Rickey's efforts. The deeply religious Rickey's motivation appears to have been primarily moral, although business considerations were also a factor. Rickey was a member of The Methodist Church, the antecedent denomination to The United Methodist Church of today, which was a strong advocate for social justice and active later in the American Civil Rights Movement.[6]\\r\\nThis event was the harbinger of the integration of professional sports in the United States, the concomitant demise of the Negro Leagues, and is regarded as a key moment in the history of the American Civil Rights movement. Robinson was an exceptional player, a speedy runner who sparked the team with his intensity. He was the inaugural recipient of the Rookie of the Year award, which is now named the Jackie Robinson Award in his honor. The Dodgers' willingness to integrate, when most other teams refused to, was a key factor in their 1947ÿ1956 success. They won six pennants in those 10 years with the help of Robinson, three-time MVP Roy Campanella, Cy Young Award winner Don Newcombe, Jim Gilliam and Joe Black. Robinson would eventually go on to become the first African-American elected to the Baseball Hall of Fame in 1962.\\r\\nReal estate businessman Walter O'Malley had acquired majority ownership of the Dodgers in 1950, when he bought the shares of his co-owners, Branch Rickey and the estate of James L. Smith. Before long he was working to buy new land in Brooklyn to build a more accessible and better arrayed ballpark than Ebbets Field. Beloved as it was, Ebbets Field was no longer well-served by its aging infrastructure and the Dodgers could no longer sell out the park even in the heat of a pennant race, despite largely dominating the National League from 1946 to 1957.\\r\\nO'Malley wanted to build a new, state of the art stadium in Brooklyn. But City Planner Robert Moses and New York politicians refused to grant him the eminent domain authority required to build pursuant to O'Malley's plans. To put pressure on the city, during the 1955 season, O'Malley announced that the team would play seven regular season games and one exhibition game at Jersey City's Roosevelt Stadium in 1956.[7] Moses and the City considered this an empty threat, and did not believe O'Malley would go through with moving the team from New York City.\\r\\nAfter teams began to travel to and from games by air instead of train, it became possible to include locations in the far west. Los Angeles officials attended the 1956 World Series looking to the Washington Senators to move to the West Coast. When O'Malley heard that LA was looking for a club, he sent word to the Los Angeles officials that he was interested in talking. LA offered him what New York would not: a chance to buy land suitable for building a ballpark, and own that ballpark, giving him complete control over all revenue streams. When the news came out, NYC Mayor Robert F. Wagner, Jr. and Moses made an offer to build a ballpark on the World's Fair Grounds in Queens that would be shared by the Giants and Dodgers. However, O'Malley was interested in his park only under his conditions, and the plans for a new stadium in Brooklyn seemed like a pipe dream. O'Malley decided to move the Dodgers to California, convincing Giants owner Horace Stoneham to move to San Francisco instead of Minneapolis to keep another team on the West Coast to ease approval of the moves. There was no turning back: the Dodgers were heading for Hollywood.[7]\\r\\nThe Dodgers played their final game at Ebbets Field on September 24, 1957, which the Dodgers won 2ÿ0 over the Pittsburgh Pirates.\\r\\nNew York would remain a one-team town with the New York Yankees until 1962, when Joan Payson founded the New York Mets and brought National League baseball back to the city. The blue background used by the Dodgers, would be adopted by the Mets, honoring their New York NL forebears with a blend of Dodgers blue and Giants orange.[8]\\r\\nThe Dodgers were the first Major League Baseball team to ever play in Los Angeles. On April 18, 1958, the Dodgers played their first LA game, defeating the former New York and now new San Francisco Giants, 6ÿ5, before 78,672 fans at the Los Angeles Memorial Coliseum. Catcher Roy Campanella, left partially paralyzed in an off-season accident, was never able to play in Los Angeles.\\r\\nConstruction on Dodger Stadium was completed in time for Opening Day 1962. With its clean, simple lines and its picturesque setting amid hills and palm trees, the ballpark quickly became an icon of the Dodgers and their new California lifestyle. O'Malley was determined that there would not be a bad seat in the house, achieving this by cantilevered grandstands that have since been widely imitated. More importantly for the team, the stadium's spacious dimensions, along with other factors, gave defense an advantage over offense and the Dodgers moved to take advantage of this by assembling a team that would excel with its pitching.\\r\\nSince moving to Los Angeles, the Dodgers have won nine more National League Championships and five World Series rings.\\r\\nThe Dodgers' official history reports that the term \\"Trolley Dodgers\\" was attached to the Brooklyn ballclub due to the complex maze of trolley cars that weaved its way through the borough of Brooklyn.[9]\\r\\nIn 1892, the city of Brooklyn (Brooklyn was an independent city until annexed by New York City in 1898) began replacing its slow-moving, horse-drawn trolley lines with the faster, more powerful electric trolley lines.[10] Within less than three years, by the end of 1895, electric trolley accidents in Brooklyn had resulted in more than 130 deaths and maimed well over 500 people.[11] Brooklyn's high-profile, the significant number of widely reported accidents, and a trolley strike in early 1895, combined to create a strong association in the public's mind between Brooklyn and trolley dodging.[10]\\r\\nSportswriters started using the name \\"trolley dodgers\\" to refer to the Brooklyn team early in the 1895 season.[12] The name was shortened to, on occasion, the \\"Brooklyn Dodgers\\" as early as 1898.[13]\\r\\nSportswriters in the early 20th century began referring to the Dodgers as the \\"Bums\\", in reference to the team's fans and possibly because of the \\"street character\\" nature of Jack Dawkins, the \\"Artful Dodger\\" in Charles Dickens' Oliver Twist.\\r\\nOther team names used by the franchise were the Atlantics, Grays, Grooms, Bridegrooms, Superbas and Robins. All of these nicknames were used by fans and sportswriters to describe the team, but not in any official capacity. The team's legal name was the Brooklyn Base Ball Club.[14] However, the Trolley Dodger nickname was used throughout this period, simultaneously with these other nicknames, by fans and sportswriters of the day. The team did not use the name in any formal sense until 1932, when the word \\"Dodgers\\" appeared on team jerseys.[1] The \\"conclusive shift\\" came in 1933, when both home and road jerseys for the team bore the name \\"Dodgers\\".[2]\\r\\nExamples of how the many popularized names of the team were used are available from newspaper articles before 1932. A New York Times article describing a game in 1916 starts out: \\"Jimmy Callahan, pilot of the Pirates, did his best to wreck the hopes the Dodgers have of gaining the National League pennant\\", but then goes on to comment: \\"the only thing that saved the Superbas from being toppled from first place was that the Phillies lost one of the two games played\\".[15] What is interesting about the use of these two nicknames is that most baseball statistics sites and baseball historians generally now refer to the pennant-winning 1916 Brooklyn team as the Robins. A 1918 New York Times article uses the nickname in its title: \\"Buccaneers Take Last From Robins\\", but the subtitle of the article reads: \\"Subdue The Superbas By 11 To 4, Making Series An Even Break\\".[16]\\r\\nAnother example of the use of the many nicknames is found on the program issued at Ebbets Field for the 1920 World Series which identifies the matchup in the series as \\"Dodgers vs. Indians\\" despite the fact that the Robins nickname had been in consistent use for around six years.[17] The \\"Robins\\" nickname was derived from the name of their Hall of Fame manager, Wilbert Robinson, who led the team from 1914 to 1931.[18]\\r\\nThe Dodgers' uniform has remained relatively unchanged since the 1930s. The home jersey is white with \\"Dodgers\\" written in script across the chest in Dodger Blue. The road jersey is grey with \\"Los Angeles\\" written in script across the chest in Dodger Blue. The word \\"Dodgers\\" was first used on the front of the team's home jersey in 1933; the uniform was then white with red pinstripes and a stylized \\"B\\" on the left shoulder.[19] The Dodgers also wore green outlined uniforms and green caps throughout the 1937 season but reverted to blue the following year.\\r\\nThe current design was created in 1939, and has remained the same ever since with only cosmetic changes. In 1952, the home uniform added a red uniform number under the \\"Dodgers\\" script. The road jersey also has a red uniform number under the script. When the franchise moved from Brooklyn to Los Angeles, the city name on the road jersey changed, and the stylized \\"B\\" was replaced with the interlocking \\"LA\\" on the caps in 1958. In 1970, the Dodgers removed the city name from the road jerseys and had \\"Dodgers\\" on both the home and away uniforms. The city script returned to the road jerseys in 1999, and the tradition-rich Dodgers flirted with an alternate uniform for the first time since 1944 (when all-blue satin uniforms were introduced). These 1999 alternate jerseys had a royal blue top with the \\"Dodgers\\" script in white across the chest, and the red number on the front. These were worn with white pants and a new cap with silver brim, top button and Dodger logo. These alternates proved unpopular and the team abandoned them after only one season. In 2014, the Dodgers introduced an alternate road jersey: a grey version with the \\"Dodgers\\" script instead of the city name.\\r\\nCurrent logo using \\"Dodgers\\" Script\\r\\nLos Angeles Dodgers Script on Dodger Blue\\r\\nThe Dodgers have been groundbreaking in their signing of players from Asia; mainly, Japan, South Korea, and Taiwan. Former owner Peter O'Malley began reaching out in 1980 by starting clinics in China and South Korea, building baseball fields in two Chinese cities, and in 1998 becoming the first major league team to open an office in Asia. The Dodgers were the second team to start a Japanese player in recent history, pitcher Hideo Nomo, the first team to start a South Korean player, pitcher Chan Ho Park, and the first Taiwanese player, Chin-Feng Chen. In addition, they were the first team to send out three Asian pitchers, from different Asian countries, in one game: Park, Hong-Chih Kuo of Taiwan, and Takashi Saito of Japan. In the 2008 season, the Dodgers had the most Asian players on its roster of any major league team with five. They included Japanese pitchers Takashi Saito and Hiroki Kuroda; South Korean pitcher Chan Ho Park; and Taiwanese pitcher Hong-Chih Kuo and infielder Chin-Lung Hu. In 2005, the Dodgers' Hee Seop Choi became the first Asian player to compete in the Home Run Derby.[20] For the 2013 season, the Dodgers signed starting pitcher Hyun-Jin Ryu with a six-year, $36 million contract, after posting a bid of nearly $27 million to acquire him from the KBO's Hanhwa Eagles. For the 2016 season, the Dodgers signed starting pitcher Kenta Maeda with an eight-year, $25 million contract, after posting a bid of $20 million to acquire him from the NPB's Hiroshima Toyo Carp.\\r\\nThe Dodgers' rivalry with the San Francisco Giants dates back to the 19th century, when the two teams were based in New York; the rivalry with the New York Yankees took place when the Dodgers were based in New York, but was revived with their East Coast/West Coast World Series battles in 1963, 1977, 1978, and 1981. The Dodgers rivalry with the Philadelphia Phillies also dates back to their days in New York, but was most fierce during the 1970s, 1980s, and 2000s. The Dodgers also had a heated rivalry with the Cincinnati Reds during the 1970s, 1980s and early 1990s. The rivalry with the Los Angeles Angels of Anaheim and the San Diego Padres dates back to the Angels' and Padres' respective inaugural seasons (Angels in 1961, Padres in 1969). Regional proximity is behind the rivalries with both the Angels and the Padres.\\r\\nThe DodgersÿGiants rivalry is one of the longest-standing rivalries in American baseball.[21][22]\\r\\nThe feud between the Dodgers and the San Francisco Giants began in the late 19th century when both clubs were based in New York City, with the Dodgers playing in Brooklyn and the Giants playing at the Polo Grounds in Manhattan. After the 1957 season, Dodgers owner Walter O'Malley moved the team to Los Angeles for financial and other reasons.[23] Along the way, he managed to convince Giants owner Horace Stonehamwho was considering moving his team to Minnesotato preserve the rivalry by bringing his team to California as well.[23] New York baseball fans were stunned and heartbroken by the move.[23][24] Given that the cities of Los Angeles and San Francisco have been bitter rivals in economic, cultural, and political arenas for over a century and a half, the new venue in California became fertile ground for its transplantation.\\r\\nEach team's ability to endure for over a century while moving across an entire continent, as well as the rivalry's leap from a cross-city to a cross-state engagement, have led to the rivalry being considered one of the greatest in sports history.[25][26][27]\\r\\nUnlike many other historic baseball match-ups in which one team remains dominant for most of their history, the DodgersÿGiants rivalry has exhibited a persistent balance in the respective successes of the two teams. While the Giants have more wins in franchise history, and lead all NL teams with 23 National League pennants, the Dodgers are second, having won 21;[28] the Giants have won eight World Series titles, while the Dodgers have won six. The 2010 World Series was the Giants' first championship since moving to California, while the Dodgers' last title came in the 1988 World Series.\\r\\nThis rivalry refers to a series of games played with the Los Angeles Angels of Anaheim. The series takes its name from the massive freeway system in the greater Los Angeles metropolitan area, the home of both teams; one could travel from one team's stadium to the other simply by traveling along Interstate 5. The term is akin to Subway Series which refers to meetings between New York City baseball teams. The term \\"Freeway Series\\" also inspired the official name of the regions' NHL rivalry: the Freeway Face-Off\\r\\nThe DodgersÿYankees rivalry is one of the most well-known rivalries in Major League Baseball.[29] The two teams have met eleven times in the World Series, more times than any other pair from the American and National Leagues.[29] The initial significance was embodied in the two teams' proximity in New York City, when the Dodgers initially played in Brooklyn. After the Dodgers moved to Los Angeles in 1958, the rivalry retained its significance as the two teams represented the dominant cities on each coast of the United States, and since the 1980s, the two largest cities in the United States.\\r\\nAlthough the rivalry's significance arose from the two teams' numerous World Series meetings,[29] the Yankees and Dodgers have not met in the World Series since 1981.[29] They would not play each other in a non-exhibition game until 2004, when they played a three-game interleague series.[29] Their last meeting was in September 2016, when the Dodgers won two out of three games in New York.\\r\\nThe Dodgers have a loyal fanbase, evidenced by the fact that the Dodgers were the first MLB team to attract more than 3 million fans in a season (in 1978), and accomplished that feat six more times before any other franchise did it once.[30] The Dodgers drew at least 3 million fans for 15 consecutive seasons from 1996 to 2010, the longest such streak in all of MLB.[30] On July 3, 2007, Dodgers management announced that total franchise attendance, dating back to 1901, had reached 175?million, a record for all professional sports.[31] In 2007, the Dodgers set a franchise record for single-season attendance, attracting over 3.8?million fans.[32] In 2009, the Dodgers led MLB in total attendance.[33] The Dodger baseball cap is consistently in the top three in sales.[34] During the 2011-2012 season, Frank McCourt, the owner of the Dodgers at that time, was going through a rough divorce with his wife over who should be the owner of the Dodger team. Instead, Frank McCourt paid $131 million to his wife as part of the divorce settlement.[35] As a result, the team payroll was financially low for a big-budget team crippling the Dodgers in the free-agent market. Collectively, the team performance waned due to the distracting drama in the front office resulting in low attendance numbers.[36]\\r\\nGiven the team's proximity to Hollywood, numerous celebrities can often be seen attending home games at Dodger Stadium. Celebrities such as co-owner Magic Johnson, Mary Hart, Larry King, Tiger Woods, Alyssa Milano and Shia LaBeouf are known to sit at field box seats behind home plate where they sign autographs for fellow Dodger fans. Actor Bryan Cranston is a lifelong Dodger fan.\\r\\nThe Dodgers set the world record for the largest attendance for a single baseball game during an exhibition game against the Boston Red Sox on March 28, 2008 at the Los Angeles Memorial Coliseum in honor of the Dodgers 50th anniversary, with 115,300 fans in attendance. All proceeds from the game benefited the official charity of the Dodgers, ThinkCure! which supports cancer research at Children's Hospital Los Angeles and City of Hope. Mainly Dodgers fans are from their own location in southern California and also parts of southern Nevada. The Dodger fans also have a tradition of waving their towels in the air after a home run.\\r\\nVin Scully had called Dodgers games from 1950 to 2016.[37] His longtime partners were Jerry Doggett (1956ÿ1987) and Ross Porter (1977ÿ2004).[37] In 1976, he was selected by Dodgers fans as the Most Memorable Personality (on the field or off) in the team's history. He is also a recipient of the Baseball Hall of Fame's Ford C. Frick Award for broadcasters (inducted in 1982). Unlike the modern style in which multiple sportscasters have an on-air conversation (usually with one functioning as play-by-play announcer and the other[s] as color commentator), Scully, Doggett and Porter generally called games solo, trading with each other inning-by-inning. In the 1980s and 1990s, Scully would call the entire radio broadcast except for the third and seventh inning, allowing the other Dodger commentators to broadcast an inning.\\r\\nWhen Doggett retired after the 1987 season, he was replaced by Hall-of-Fame Dodgers pitcher Don Drysdale, who previously broadcast games for the California Angels and Chicago White Sox.[37] Drysdale died in his hotel room following a heart attack before a game in Montreal in 1993. This was a difficult broadcast for Scully and Porter who could not mention it on-air until Drysdale's family had been notified and the official announcement made.[38] He was replaced by former Dodgers outfielder Rick Monday.[37] Porter's tenure ended after the 2004 season, after which the format of play-by-play announcers and color commentators was installed, led by Monday and newcomer Charley Steiner.[37] Scully, however, continued to announce solo.\\r\\nScully called roughly 100 games per season (all home games and road games in California and Arizona)[39] for both flagship radio station KLAC and on television for SportsNet LA. Scully was simulcast for the first three innings of each of his appearances, then announced only for the TV audience. If Scully was calling the game, Steiner took over play-by-play on radio beginning with the fourth inning, with Monday as color commentator.[39] If Scully was not calling the game, Steiner and Orel Hershiser called the entire game on television while Monday and Kevin Kennedy did the same on radio. In the event the Dodgers were in post-season play, Scully called the first three and last three innings of the radio broadcast alone and Steiner and Monday handled the middle innings.[40] Vin Scully retired from calling games in 2016. His tenure with the Dodgers was the longest with any single sports team at 67 years.\\r\\nThe Dodgers also broadcast on radio in Spanish, and the play-by-play is voiced by another Frick Award winner, Jaime Jarrn, who has been with the Dodgers since 1959. The color analyst for some games is former Dodger pitcher Fernando Valenzuela, for whom Jarrin once translated post-game interviews. The Spanish-language radio flagship station is KTNQ.\\r\\nDave Bancroft\\r\\nDan Brouthers\\r\\nRoy Campanella\\r\\nMax Carey1\\r\\nKiki Cuyler\\r\\nLeo Durocher2\\r\\nBurleigh Grimes1\\r\\nNed Hanlon\\r\\nBilly Herman\\r\\nWaite Hoyt\\r\\nHughie Jennings\\r\\nWillie Keeler\\r\\nJoe Kelley\\r\\nGeorge Kelly\\r\\nTony Lazzeri\\r\\nFreddie Lindstrom\\r\\nErnie Lombardi\\r\\nAl L܇pez\\r\\nHeinie Manush\\r\\nRabbit Maranville\\r\\nRube Marquard\\r\\nTommy McCarthy\\r\\nJoe McGinnity\\r\\nJoe Medwick\\r\\nPee Wee Reese\\r\\nJackie Robinson\\r\\nWilbert Robinson?\\r\\nDuke Snider\\r\\nCasey Stengel2\\r\\nDazzy Vance\\r\\nArky Vaughan\\r\\nLloyd Waner\\r\\nPaul Waner\\r\\nJohn Montgomery Ward1\\r\\nZack Wheat\\r\\nHack Wilson\\r\\nWalter Alston\\r\\nJim Bunning\\r\\nGary Carter\\r\\nDon Drysdale\\r\\nRickey Henderson\\r\\nSandy Koufax\\r\\nTommy Lasorda2\\r\\nGreg Maddux\\r\\nJuan Marichal\\r\\nPedro Martnez\\r\\nEddie Murray\\r\\nWalter O'Malley?\\r\\nMike Piazza\\r\\nFrank Robinson\\r\\nDon Sutton\\r\\nJoe Torre\\r\\nHoyt Wilhelm\\r\\nRed Barber\\r\\nErnie Harwell\\r\\nJaime Jarrn\\r\\nVin Scully\\r\\nKoufax, Campanella, and Robinson were the first Dodgers to have their numbers retired, in a ceremony at Dodger Stadium on June 4, 1972. This was the year in which Koufax was inducted into the Baseball Hall of Fame; Robinson and Campanella were already Hall-of-Famers.\\r\\nAlston's number was retired in the year following his retirement as the Dodgers manager, six years before he was inducted into the Hall of Fame.\\r\\nGilliam died suddenly in 1978 after a 28-year career with the Dodgers organization. The Dodgers retired his number two days after his death, prior to Game 1 of the 1978 World Series. He is the only non-Hall-of-Famer to have his number retired by the Dodgers.\\r\\nBeginning in 1980, the Dodgers have retired the numbers of longtime Dodgers (Snider, Reese, Drysdale, Lasorda, and Sutton) during the seasons in which each was inducted into the Hall of Fame.\\r\\nIn 1997, 50 years after he broke the color barrier and 25 years after the Dodgers retired his number, Robinson's No.42 was retired throughout Major League Baseball. Robinson is the only major league baseball player to have this honor bestowed upon him. Starting in the 2007 season, Jackie Robinson Day (April 15, commemorating Opening Day of Robinson's rookie season of 1947) has featured many or all players and coaches wearing the number 42 as a tribute to Robinson.\\r\\nThe Dodgers have not issued the number 34 since the departure of Fernando Valenzuela in 1991, although it has not been officially retired.\\r\\nPitchers\\r\\nStarting rotation\\r\\nBullpen\\r\\nCloser\\r\\nCatchers\\r\\nInfielders\\r\\nOutfielders\\r\\n\\r\\nPitchers\\r\\n\\r\\nInfielders\\r\\nOutfielders\\r\\n\\r\\nManager\\r\\nCoaches\\r\\n60-day disabled list\\r\\n\\r\\n 7- or 10-day disabled list\\r\\n Suspended list\\r\\n# Personal leave\\r\\nRoster and coaches updated October 6, 2017\\r\\nTransactions ? Depth chart\\r\\nSince 1884, the Dodgers have used a total of 31 Managers, the most current being Dave Roberts, who was appointed following the 2015 postseason, after the departure of Don Mattingly.\\r\\nOver the nearly 43 years from 1954 to mid-1996, the Dodgers employed only two managers, Walter Alston and Tommy Lasorda, both of whom are in the Hall of Fame. During this entire time period of extraordinary stability, the Dodgers were family owned by Walter O'Malley and then his son Peter O'Malley. It was during this era that the Dodgers won 11 of their 21 pennants, and all six of their World Series championships.\\r\\nThe managers of the Los Angeles Dodgers (1958ÿpresent) are as follows:\\r\\nFrom the Dodgers' move to Los Angeles from Brooklyn in 1958, the Dodgers employed a handful of well-known public address announcers; the most famous of which was John Ramsey, who served as the PA voice of the Dodgers from 1958 until his retirement in 1982; as well as announcing at other venerable Los Angeles venues, including the Los Angeles Memorial Coliseum and Sports Arena, and the Forum. Ramsey died in 1990.\\r\\nFrom 1958 to 1982, Doug Moore, a local businessman; Philip Petty, an Orange County Superior Court Judge; and Dennis Packer; served as back-up voices for John Ramsey for the Dodgers, California Angels, Los Angeles Chargers, USC football and Los Angeles Rams. Packer was Ramsey's primary backup for the Los Angeles Lakers and Los Angeles Kings until Ramsey's retirement from the Forum in 1978. Thereafter, Packer became the public address announcer for the Lakers, Kings, indoor soccer and indoor tennis events at the Forum.\\r\\nNick Nickson, a radio broadcaster for the Los Angeles Kings, replaced John Ramsey as the Dodger Stadium public address announcer in 1983 and served in that capacity through the 1989 season to work with the Kings full-time.\\r\\nDennis Packer and Pete Arbogast were emulators of John Ramsey, using the same stentorian style of announcing Ramsey was famous for. Packer and Arbogast shared the stadium announcing chores for the 1994 FIFA World Cup matches at the Rose Bowl. Arbogast won the Dodgers job on the day that Ramsey died on January 25, 1990, by doing a verbatim imitation of Ramsey's opening and closing remarks that were standard at each game. His replacement, in 1993 was Mike Carlucci, who remained as the Dodgers' PA voice until 2003 to concentrate on his voiceover and acting career along with his Olympics announcing duties.\\r\\nThrough 2014, the Dodgers public address announcer was Eric Smith, who also announces for the Los Angeles Clippers and USC Trojans.[41]\\r\\nOn April 3, 2015 the Dodgers announced that former radio broadcaster Todd Leitz would become their new public address announcer. Leitz was an anchor and news reporter in Los Angeles at KNX 1070 AM for 10 years, and a news reporter at KABC 790 for two years.[42]\\r\\nVin Scully is permanently honored in the Hall's \\"Scribes & Mikemen\\" exhibit as a result of winning the Ford C. Frick Award in 1982. As with all Frick Award recipients, he is not officially considered an inducted member of the Hall of Fame.\\r\\nSue Falsone, served as the first female physical therapist in Major League baseball, and from 2012 to 2013, was the first female head athletic trainer.","input":"When did the brooklyn dodgers become the los angeles dodgers?"},{"output":"Paul Warfield Tibbets Jr.","context":"World War II:\\r\\nPaul Warfield Tibbets Jr. (23 February 1915 ÿ 1 November 2007) was a brigadier general in the United States Air Force. He is best known as the pilot who flew the Enola Gay (named after his mother) when it dropped Little Boy, the first of two atomic bombs used in warfare, on the Japanese city of Hiroshima.\\r\\nTibbets enlisted in the United States Army in 1937 and qualified as a pilot in 1938. After the Japanese attack on Pearl Harbor, he flew anti-submarine patrols over the Atlantic. In February 1942, he became the commanding officer of the 340th Bombardment Squadron of the 97th Bombardment Group, which was equipped with the Boeing B-17. In July 1942 the 97th became the first heavy bombardment group to be deployed as part of the Eighth Air Force, and Tibbets became deputy group commander. He flew the lead plane in the first American daylight heavy bomber mission against Occupied Europe on 17 August 1942, and the first American raid of more than 100 bombers in Europe on 9 October 1942. Tibbets was chosen to fly Major General Mark W. Clark and Lieutenant General Dwight D. Eisenhower to Gibraltar. After flying 43 combat missions, he became the assistant for bomber operations on the staff of the Twelfth Air Force.\\r\\nTibbets returned to the United States in February 1943 to help with the development of the Boeing B-29 Superfortress. In September 1944, he was appointed the commander of the 509th Composite Group, which would conduct the bombings of Hiroshima and Nagasaki. After the war, he participated in the Operation Crossroads nuclear weapon tests at Bikini Atoll in mid-1946, and was involved in the development of the Boeing B-47 Stratojet in the early 1950s. He commanded the 308th Bombardment Wing and 6th Air Division in the late 1950s, and was military attach in India from 1964 to 1966. After leaving the Air Force in 1966, he worked for Executive Jet Aviation, serving on the founding board and as its president from 1976 until his retirement in 1987.\\r\\n\\r\\n\\r\\nPaul Warfield Tibbets Jr. was born in Quincy, Illinois, on 23 February 1915, the son of Paul Warfield Tibbets Sr. and his wife, Enola Gay Tibbets. When he was five years old the family moved to Davenport, Iowa, and then to Iowa's capital, Des Moines, where he was raised, and where his father became a confections wholesaler. When he was eight, his family moved to Hialeah, Florida, to escape from harsh midwestern winters. As a boy he was very interested in flying. One day his mother agreed to pay one dollar to get him into an airplane at the local carnival. In 1927, when he was 12 years old, he flew in a plane piloted by barnstormer Doug Davis, dropping candy bars with tiny parachutes to the crowd of people attending the races at the Hialeah Park Race Track.[1][2]\\r\\nIn the late 1920s, business issues forced Tibbets's family to return to Alton, Illinois, where he graduated from Western Military Academy in 1933. He then attended the University of Florida in Gainesville,[1] and became an initiated member of the Epsilon Zeta Chapter of Sigma Nu fraternity in 1934.[3] During that time, Tibbets took private flying lessons at Miami's Opa-locka Airport with Rusty Heard, who later became a captain at Eastern Airlines.[3] After his undergraduate work, Tibbets had planned on becoming an abdominal surgeon. He transferred to the University of Cincinnati after his second year to complete his pre-med studies there, because the University of Florida had no medical school at the time. However, he attended for only a year and a half as he changed his mind about wanting to become a doctor. Instead, he decided to enlist in the United States Army and become a pilot in the United States Army Air Corps.[1]\\r\\nBecause he went to a military school, attended some college, and had some flight experience, Tibbets qualified for the Aviation Cadet Training Program.[4] On 25 February 1937, he enlisted in the army at Fort Thomas, Kentucky, and was sent to Randolph Field in San Antonio, Texas, for primary and basic flight instruction. During his training, he showed himself to be an above-average pilot. He was commissioned as a second lieutenant and received his pilot rating in 1938 at Kelly Field in San Antonio.[1]\\r\\nAfter graduation, Tibbets was assigned to the 16th Observation Squadron, which was based at Lawson Field, Georgia, with a flight supporting the Infantry School at nearby Fort Benning.[1] It was at Fort Benning that Tibbets met Lucy Frances Wingate, then a clerk at a department store in Columbus, Georgia. The two quietly married in a Roman Catholic seminary in Holy Trinity, Alabama on June 19, 1938. Tibbets did not inform his family or his commanding officer, and the couple arranged for the notice to be kept out of the local newspaper.[5] They had two sons. Paul III was born in 1940, in Columbus, Georgia, and graduated from Huntingdon College and Auburn University. He was a colonel in the United States Army Reserves and worked as a hospital pharmacist. He died in West Monroe, Louisiana, in 2016.[6] The younger son, Gene Wingate Tibbets, was born in 1944, and was at the time of his death in 2012 residing in Georgiana in Butler County in southern Alabama.[7][8]\\r\\nWhile Tibbets was stationed at Fort Benning, he was promoted to first lieutenant[9] and served as a personal pilot for Brigadier General George S. Patton, Jr., in 1940 and 1941.[1] In June 1941, Tibbets transferred to the 9th Bombardment Squadron of the 3d Bombardment Group at Hunter Field, Savannah, Georgia, as the engineering officer, and flew the A-20 Havoc.[10] While there he was promoted to captain. In December 1941, he received orders to join the 29th Bombardment Group at MacDill Field, Florida, for training on the Boeing B-17 Flying Fortress. On 7 December 1941, Tibbets heard about the Japanese attack on Pearl Harbor while listening to the radio during a routine flight.[9] Due to fears that German U-Boats might enter Tampa Bay and bombard MacDill Field, the 29th Bombardment Group moved to Savannah.[11] Tibbets remained on temporary duty with the 3d Bombardment Group, forming an anti-submarine patrol at Pope Army Airfield, North Carolina, with 21 B-18 Bolo medium bombers.[1] The B-18s were used as an intermediate trainer, which pilots flew after basic flight training in a Cessna UC-78 and before qualifying in the B-17.[12]\\r\\nIn February 1942, Tibbets reported for duty with the 29th Bombardment Group as its engineering officer. Three weeks later he was named the commanding officer of the 340th Bombardment Squadron of the 97th Bombardment Group, equipped with the B-17D.[13] It was initially based at MacDill, and then Sarasota Army Airfield, Florida, before moving to Godfrey Army Airfield in Bangor, Maine.[14]\\r\\nIn July 1942 the 97th became the first heavy bombardment group of the Eighth Air Force to be deployed to England, where it was based at RAF Polebrook.[15] It had been hastily assembled to meet demands for an early deployment, and arrived without any training in the basics of high altitude daylight bombing. In the first weeks of August 1942, under the tutelage of Royal Air Force veterans, the group received intensive training for its first mission. The group commander, Lieutenant Colonel Cornelius W. Cousland,[16] was replaced by Colonel Frank A. Armstrong Jr., who appointed Tibbets as his deputy.[17]\\r\\nTibbets flew the lead bomber Butcher Shop[18] for the first American daylight heavy bomber mission on 17 August 1942, a shallow penetration raid against a marshalling yard in Rouen in Occupied France, with Armstrong as his co-pilot. This was not Tibbets's regular aircraft, Red Gremlin, nor his regular crew, which included bombardier Thomas Ferebee and navigator Theodore Van Kirk, who later flew with him in Enola Gay.[19] On 9 October 1942, Tibbets led the first American raid of more than 100 bombers in Europe, attacking industrial targets in the French city of Lille. Poor bombing accuracy resulted in numerous civilian casualties and less damage to the rail installations than hoped, but the mission was hailed an overall success because it reached its target against heavy and constant fighter attack. Of the 108 aircraft in the raid, 33 were shot down or had to turn back due to mechanical problems.[20][21]\\r\\nOn that first mission, Tibbets saw in real-time that his bombs were falling on innocent civilians. At the time, he thought to himself, \\"People are getting killed down there that don't have any business getting killed. Those are not soldiers.\\" But then he thought back to a lesson he had learned during his time at medical school from his roommate who was a doctor. This doctor explained to him about his former classmates who failed the program and ended up in drug sales. The reason why they had failed the program was because \\"they had too much sympathy for their patients\\", which \\"destroyed their ability to render the medical necessities\\". It dawned on Tibbets that:\\r\\nI am just like that if I get to thinking about some innocent person getting hit on the ground. I am supposed to be a bomber pilot and destroy a target. I wont be worth anything if I do that... I made up my mind then that the morality of dropping that bomb was not my business. I was instructed to perform a military mission to drop the bomb. That was the thing that I was going to do the best of my ability. Morality, there is no such thing in warfare. I dont care whether you are dropping atom bombs, or 100-pound bombs, or shooting a rifle. You have got to leave the moral issue out of it.[22]\\r\\nIn the leadup to Operation Torch, the Allied invasion of North Africa, the commander of the Eighth Air Force, Major General Carl Spaatz was ordered to provide his best two pilots for a secret mission. He chose Tibbets and Major Wayne Connors. Tibbets flew Major General Mark W. Clark from Polebook to Gibraltar while Connors flew Clark's chief of staff, Brigadier General Lyman Lemnitzer.[23] A few weeks later Tibbets flew the Supreme Allied Commander, Lieutenant General Dwight D. Eisenhower, there.[24] \\"By reputation\\", historian Stephen Ambrose wrote, Tibbets was \\"the best flier in the Army Air Force [sic].\\"[25]\\r\\nTibbets had flown 25 combat missions against targets in France[13] when the 97th Bomb Group was transferred to North Africa as part of Major General Jimmy Doolittle's Twelfth Air Force. For Tibbets, the war in North Africa introduced him to the realities of aerial warfare. He claimed that he saw the real effects of bombing civilians and the trauma of losing his brothers in arms. In January 1943, Tibbets, who had now flown 43 combat missions,[26] was assigned as the assistant for bomber operations to Colonel Lauris Norstad, Assistant Chief of Staff of Operations (A-3) of the Twelfth Air Force.[13] Tibbets had recently been given a battlefield promotion to colonel, but did not receive it, as such promotions had to be confirmed by a panel of officers. He was told that Norstad had vetoed the promotion, saying \\"there's only going to be one colonel in operations.\\"[27]\\r\\nTibbets did not get along well with Norstad, or with Doolittle's chief of staff, Brigadier General Hoyt Vandenberg. In one planning meeting, Norstad wanted an all-out raid on Bizerte to be flown at 6,000 feet (1,800?m). Tibbets protested that flak would be most effective at that altitude. When challenged by Norstad, Tibbets said he would lead the mission himself at 6,000 feet if Norstad would fly as his co-pilot. Norstad backed down, and the mission was successfully flown at 20,000 feet (6,100?m).[28]\\r\\nWhen General Henry H. \\"Hap\\" Arnold, the Chief of United States Army Air Forces, requested an experienced bombardment pilot to help with the development of the Boeing B-29 Superfortress bomber, Doolittle recommended Tibbets.[29] Tibbets returned to the United States in February 1943. At the time, the B-29 program was beset by a host of technical problems, and the chief test pilot, Edmund T. Allen, had been killed in a crash of the prototype aircraft.[30]\\r\\nWorking with the Boeing plant in Wichita, Kansas, Tibbets test-flew the B-29 and soon accumulated more flight time in it than any other pilot. He found that without defensive armament and armor plating, the aircraft was 7,000 pounds (3,200?kg) lighter, and its performance was much improved. In simulated combat engagements against a P-47 fighter at the B-29's cruising altitude of 30,000 feet (9,100?m), he discovered that the B-29 had a smaller turning radius than the P-47, and could avoid it by turning away.[31][32]\\r\\nAfter a year of developmental testing of the B-29, Tibbets was assigned in March 1944 as director of operations of the 17th Bombardment Operational Training Wing (Very Heavy), a B-29 training unit based at Grand Island Army Air Field, Nebraska, and commanded by Armstrong. Its role was to transition pilots to the B-29.[13] Tibbets taught two Women Airforce Service Pilots, Dora Dougherty and Dorothea (Didi) Moorman, to fly the B-29 as demonstration pilots.[33]\\r\\nOn 1 September 1944, Tibbets reported to Colorado Springs Army Airfield, the headquarters of the Second Air Force, where he met with its commander, Major General Uzal Ent, and three representatives of the Manhattan Project, Lieutenant Colonel John Lansdale Jr., Captain William S. Parsons, and Norman F. Ramsey Jr., who briefed him on the project.[34] Tibbets was told that he would be in charge of the 509th Composite Group, a fully self-contained organization of about 1,800 men, which would have 15 B-29s and a high priority for all kinds of military stores. Ent gave Tibbets a choice of three possible bases: Great Bend Army Airfield, Kansas; Mountain Home Army Airfield, Idaho; or Wendover Army Air Field, Utah.[35] Tibbets selected Wendover for its remoteness.[36]\\r\\nWhen the operation was still in its development stages, Armstrong and Colonel Roscoe C. Wilson were the leading candidates to command the group who was designated to drop the atomic bomb. Wilson was the Army Air Force project officer who provided liaison support to the Manhattan Project. Armstrong was an experienced combat veteran against German targets, but he was in his forties and had been severely injured in a fire in the summer of 1943. Wilson had no combat experience and was qualified primarily because of his engineering background and association with the project. Tibbets was considerably younger than both men and had experience in both staff and command duties in heavy bomber combat operations. He was already an experienced B-29 pilot, which made him an ideal candidate for the top-secret project.[37]\\r\\nTibbets was promoted to colonel in January 1945[38] and brought his wife and family along with him to Wendover. He felt that allowing married men in the group to bring their families would improve morale, although it put a strain on his own marriage. In order to disguise all the civilian engineers on base who were working on the Manhattan Project, Tibbets was forced to lie to his wife; he told her that the engineers were \\"sanitary workers.\\" At one point, Tibbets found that Lucy had co-opted a scientist to unplug a drain.[39]\\r\\nOn 6 March 1945 (concurrent with the activation of Project Alberta), the 1st Ordnance Squadron, Special (Aviation) was activated at Wendover, again using Army Air Forces personnel on hand or already at Los Alamos. Its purpose was to provide \\"skilled machinists, welders and munitions workers\\"[40] and special equipment to the group to enable it to assemble atomic weapons at its operating base, thereby allowing the weapons to be transported more safely in their component parts. A rigorous candidate selection process was used to recruit personnel, reportedly with an 80% rejection rate. The 509th Composite Group reached full strength in May 1945.[41]\\r\\nWith the addition of the 1st Ordnance Squadron to its roster in March 1945, the 509th Composite Group had an authorized strength of 225 officers and 1,542 enlisted men, almost all of whom deployed to Tinian, an island in the northern Marianas within striking distance of Japan, in May and June 1945. The 320th Troop Carrier Squadron kept its base of operations at Wendover. In addition to its authorized strength, the 509th had attached to it on Tinian all 51 civilian and military personnel of Project Alberta. Furthermore, two representatives from Washington, D.C. were present on the island:[42] the deputy director of the Manhattan Project, Brigadier General Thomas Farrell, and Rear Admiral William R. Purnell of the Military Policy Committee.[43]\\r\\nThe ground support echelon of the 509th Composite Group received movement orders and moved by rail on 26 April 1945, to its port of embarkation at Seattle, Washington. On May 6 the support elements sailed on the SS Cape Victory for the Marianas, while the group's materiel was shipped on the SS Emile Berliner.[44] An advance party of the air echelon flew by C-54 to North Field, Tinian, between May 15 and 22,[45] where it was joined by the ground echelon on 29 May 1945.[46] Project Alberta's \\"Destination Team\\" also sent most of its members to Tinian to supervise the assembly, loading, and dropping of the bombs under the administrative title of 1st Technical Services Detachment, Miscellaneous War Department Group.[47][48]\\r\\nOn 5 August 1945, Tibbets formally named his B-29 Enola Gay after his mother.[49] Enola Gay had been personally selected by him while it was still on the assembly line at the Glenn L. Martin Company plant in Bellevue, Nebraska.[50] The regularly assigned aircraft commander, Robert A. Lewis, was unhappy to be displaced by Tibbets for this important mission, and became furious when he arrived at the aircraft on the morning of August 6 to see the aircraft he considered his painted with the now-famous nose art. Lewis would fly the mission as Tibbets's co-pilot.[49][51]\\r\\nAt 02:45 the next dayin accordance with the terms of Operations Order No. 35the Enola Gay departed North Field for Hiroshima, Japan, with Tibbets at the controls. Tinian was approximately 2,000 miles (3,200?km) away from Japan, so it took six hours to reach Hiroshima. The atomic bomb, code-named \\"Little Boy\\", was dropped over Hiroshima at 08:15 local time. Tibbets recalled that the city was covered with a tall mushroom cloud after the bomb was dropped.[52]\\r\\nTibbets was awarded the Distinguished Service Cross by Spaatz immediately after landing on Tinian.[53] He became a celebrity, with pictures and interviews of his wife and children in the major American newspapers. He was seen as a national hero who had ended the war with Japan. Tibbets later received an invitation from President Harry S. Truman to visit the White House.[54] The 509th Composite Group was awarded an Air Force Outstanding Unit Award in 1999.[55]\\r\\nTibbets was interviewed extensively by Mike Harden of the Columbus Dispatch, and profiles appeared in the newspaper on anniversaries of the first dropping of an atomic bomb. In a 1975 interview he said: \\"I'm proud that I was able to start with nothing, plan it and have it work as perfectly as it did?... I sleep clearly every night.\\"[56][57] \\"I knew when I got the assignment,\\" he told a reporter in 2005, \\"it was going to be an emotional thing. We had feelings, but we had to put them in the background. We knew it was going to kill people right and left. But my one driving interest was to do the best job I could so that we could end the killing as quickly as possible.\\"[58]\\r\\nThe 509th Composite Group returned to the United States on 6 November 1945, and was stationed at Roswell Army Airfield, New Mexico.[59] Colonel William H. Blanchard replaced Tibbets as group commander on 22 January 1946, and also became the first commander of the 509th Bombardment Wing, the successor to the 509th Composite Group.[60] Tibbets was a technical advisor to the 1946 Operation Crossroads nuclear tests at Bikini Atoll in the Pacific, but he and his Enola Gay crew were not chosen to drop another atomic bomb.[61]\\r\\nTibbets then attended the Air Command and Staff School at Maxwell Air Force Base, Alabama. On graduating in 1947 he was posted to the Directorate of Requirements at Air Force Headquarters at the Pentagon.[13] When the head of the directorate, Brigadier General Thomas S. Power, was posted to London as air attach, he was replaced by Brigadier General Carl Brandt. Brandt appointed Tibbets as director of Directorate of Requirements's Strategic Air Division, which was responsible for drawing up requirements for future bombers. Tibbets was convinced that the bombers of the future would be jet aircraft and thus became involved in the Boeing B-47 Stratojet program.[62] He subsequently served as B-47 project officer at Boeing in Wichita from July 1950 until February 1952. He then became commander of the Proof Test Division at Eglin Air Force Base in Valparaiso, Florida, where flight testing of the B-47 was conducted.[13]\\r\\nTibbets returned to Maxwell Air Force Base, where he attended the Air War College. After he graduated in June 1955, he became Director of War Plans at the Allied Air Forces in Central Europe Headquarters at Fontainebleau, France.[13] He left Lucy and his sons behind in Alabama,[63] and he and Lucy divorced that year.[64] During his posting to France, he met a French divorcee named Andrea Quattrehomme, who became his second wife. He returned to the United States in February 1956 to command the 308th Bombardment Wing at Hunter Air Force Base, Georgia, and married her in the base chapel on 4 May 1956.[65] They had a son, James Tibbets.[66]\\r\\nIn January 1958, Tibbets became commander of the 6th Air Division at MacDill Air Force Base, Florida.[13] and was promoted to brigadier general in 1959.[67] This was followed by another tour of duty at the Pentagon as director of Management Analysis. In July 1962, he was assigned to the Joint Chiefs of Staff as deputy director for operations, and then, in June 1963, as deputy director for the National Military Command System.[13] In 1964, Tibbets was named military attach in India. He spent 22 months there on this posting, which ended in June 1966.[67] He retired from the United States Air Force (USAF) on 31 August 1966.[68]\\r\\nAfter his retirement from the Air Force, Tibbets worked for Executive Jet Aviation (EJA), an air taxi company based in Columbus, Ohio, and now called NetJets. He was one of the founding board members and attempted to extend the company's operations to Europe, but was unsuccessful. He retired from the company in 1968, and returned to Miami, Florida, where he had spent part of his childhood. The banks foreclosed on EJA in 1970, and Bruce Sundlun became president. Sundlun lured Tibbets back to EJA that year. Tibbets succeeded Sundlun as president on 21 April 1976, and remained in the role until 1986. He served for a year as a consultant before his second and final retirement from EJA in 1987.[8][57][69]\\r\\nBarry Nelson played Tibbets in the film The Beginning or the End (1947).[70] Above and Beyond (1952) depicted the World War II events that involved Tibbets; Robert Taylor starred as Tibbets and Eleanor Parker played the role of his first wife Lucy.[71] Tibbets was also the model for screenwriter Sy Bartlett's fictional character \\"Major Joe Cobb\\" in the film Twelve O'Clock High (1949), and for a brief period in February 1949 was slated to be the film's technical advisor until his replacement at the last minute by Colonel John H. deRussy.[72] Enola Gay: The Men, the Mission, the Atomic Bomb, a 1980 made-for-television movie, somewhat fictionalized, told the story of Tibbets crew. Patrick Duffy played Tibbets and Kim Darby played Lucy.[73]\\r\\nIn other fictional portrayals, Nicholas Kilbertus was Tibbets in the film Day One (1989),[74] David Gow played him in the TV movie Hiroshima (1995),[75] and Ian Shaw played the part in the BBC's TV docudrama Hiroshima (2005), for which Tibbets was also interviewed on camera.[76] An interview with Tibbets also appeared in the movie Atomic Cafe (1982),[77] as well as was in the 1970s British documentary series The World at War,[78] and the \\"Men Who Brought the Dawn\\" episode of the Smithsonian Networks' War Stories (1995).[79] Tibbets figured largely in the 2000 book Duty: A Father, His Son and the Man Who Won the War by Bob Greene of the Chicago Tribune.[80]\\r\\nIn 1976, the United States government apologized to Japan after Tibbets re-enacted the bombingcomplete with a mushroom cloudin a restored B-29 at an air show in Texas. He said that he had not intended for the re-enactment to insult the Japanese people.[56][81] In 1995, he denounced the 50th anniversary exhibition of the Enola Gay at the Smithsonian Institution, which attempted to present the bombing in context with the destruction it caused, as a \\"damn big insult\\",[56] due to its focus on the Japanese casualties rather than the brutality of the Japanese government.[56] He was inducted into the National Aviation Hall of Fame in 1996.[68]\\r\\nTibbets's grandson Paul W. Tibbets IV graduated from the United States Air Force Academy in 1989, and in April 2006 became commander of the 393d Bomb Squadron, flying the B-2 Spirit at Whiteman AFB, Missouri. The squadron was one of the two operational squadrons that had formed part of the 509th Composite Group when Tibbets commanded it. Paul Tibbets IV was promoted to brigadier general in 2014, and became Deputy Director for Nuclear Operations at the Global Operations Directorate of the United States Strategic Command at Offutt Air Force Base in Nebraska. As such, he was responsible for America's strategic nuclear forces.[82] On 5 June 2015, he assumed command of the 509th Bomb Wing.[83]\\r\\nTibbets died in his Columbus, Ohio, home on 1 November 2007, at the age of 92.[56][84] He had suffered small strokes and heart failure during his final years and had been in hospice care.[8][85] He was survived by his French-born wife, Andrea,[81] and two sons from his first marriage, Paul III and Gene as well as his son, James, from his second marriage.[8][85] Tibbets had asked for no funeral or headstone, because he feared that opponents of the bombing might use it as a place of protest or destruction. In accordance with his wishes, his body was cremated,[86] and his ashes were scattered over the English Channel;[87] he had flown over the Channel many times during the war.[85]\\r\\nSource: Ohio History Central.[88]","input":"Who was the first person to drop the atomic bomb?"},{"output":"Eugene H. Peterson","context":"The Message: The Bible in Contemporary Language was created and translated by Eugene H. Peterson and published in segments from 1993 to 2002. It is an idiomatic translation of the original languages of the Bible.[1] The Message was translated by Peterson from the original languages.[2] It is a highly idiomatic translation, using contemporary slang from the US rather than a more neutral International English, and it falls on the extreme dynamic end of the dynamic and formal equivalence spectrum.\\r\\n\\r\\n\\r\\nAccording to the Introduction to the New Testament of The Message, its contemporary idiom keeps the language of the Message (Bible) current and fresh and understandable.[1] Peterson notes that in the course of the project, he realized this was exactly what he had been doing in his thirty-five years as a pastor, always looking for an English way to make the biblical text relevant to the conditions of the people.[1]\\r\\nThe Message was published piecemeal over a nine-year period. The New Testament was published in 1993. The Hebrew Bible Wisdom Books were published in 1998. The Hebrew Bible Prophets were published in 2000. The Hebrew Bible Pentateuch were released in 2001. The Books of History came out in 2002. The entire Bible was released the same year and follows the traditional Protestant Biblical canon.\\r\\nThe Message was translated by Peterson from the original languages.[2] It is a highly idiomatic translation, using contemporary slang from the US rather than a more neutral International English, and it falls on the extreme dynamic end of the dynamic and formal equivalence spectrum. Some scholars, like Michael J. Gorman, consider some of Peterson's idiomatic renderings unconventional.[3]\\r\\n1 The Lord is my shepherd, I lack nothing. 2 He makes me lie down in green pastures, he leads me beside quiet waters, 3 he refreshes my soul. He guides me along the right paths for his names sake. 4 Even though I walk through the darkest valley, I will fear no evil, for you are with me; your rod and your staff, they comfort me.\\r\\n1 The Lord is my shepherd; I shall not want. 2 He maketh me to lie down in green pastures: he leadeth me beside the still waters. 3 He restoreth my soul: he leadeth me in the paths of righteousness for his name's sake. 4 Yea, though I walk through the valley of the shadow of death, I will fear no evil: for thou art with me; thy rod and thy staff they comfort me.\\r\\n1-3 God, my shepherd! I dont need a thing. You have bedded me down in lush meadows, you find me quiet pools to drink from. True to your word, you let me catch my breath and send me in the right direction. 4 Even when the way goes through Death Valley, Im not afraid when you walk at my side. Your trusty shepherds crook makes me feel secure.\\r\\n9 This, then, is how you should pray: Our Father in heaven, hallowed be your name, 10 your kingdom come, your will be done, on earth as it is in heaven. 11 Give us today our daily bread. 12 And forgive us our debts, as we also have forgiven our debtors. 13 And lead us not into temptation, but deliver us from the evil one.\\r\\n9 After this manner therefore pray ye: Our Father which art in heaven, Hallowed be thy name. 10 Thy kingdom come, Thy will be done in earth, as it is in heaven. 11 Give us this day our daily bread. 12 And forgive us our debts, as we forgive our debtors. 13 And lead us not into temptation, but deliver us from evil: For thine is the kingdom, and the power, and the glory, for ever. Amen.\\r\\n9-17 Our Father in heaven, Reveal who you are. Set the world right; Do whats best as above, so below. Keep us alive with three square meals. Keep us forgiven with you and forgiving others. Keep us safe from ourselves and the Devil. Youre in charge! You can do anything you want! Youre ablaze in beauty! Yes. Yes. Yes.","input":"Who is the author of the message bible?"},{"output":"Western","context":"","input":""}]`),B={name:"App",components:{PoemCard:A},data(){return{visibleCount:20,poemsData:I}},computed:{visiblePoems(){return this.poemsData.slice(0,this.visibleCount)},hasMorePoems(){return this.visibleCount<this.poemsData.length}},methods:{loadMore(){this.visibleCount+=20}}},x={class:"card-container"};function M(h,t,n,c,u,o){const m=p("PoemCard");return a(),i(l,null,[t[1]||(t[1]=e("section",null,[e("div",{class:"top-Banner"},[e("div",{class:"top-Banner-Title"},[e("div",{class:"top-Banner-Title-Text"},"🎉Q&A Life🥳")])])],-1)),e("section",null,[e("div",x,[(a(!0),i(l,null,g(o.visiblePoems,(r,f)=>(a(),y(m,{key:f,poem:r},null,8,["poem"]))),128))]),o.hasMorePoems?(a(),i("button",{key:0,class:"load-more-button",onClick:t[0]||(t[0]=(...r)=>o.loadMore&&o.loadMore(...r))},"See more")):w("",!0)])],64)}const D=d(B,[["render",M]]),H=JSON.parse('{"title":"","description":"","frontmatter":{"page":true},"headers":[],"relativePath":"qapage/49.md","filePath":"qapage/49.md"}'),P={name:"qapage/49.md"},G=Object.assign(P,{setup(h){return(t,n)=>(a(),i("div",null,[b(D)]))}});export{H as __pageData,G as default};
