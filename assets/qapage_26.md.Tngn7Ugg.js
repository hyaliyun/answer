import{_ as d,o as a,c as o,a as e,t as s,C as p,F as l,p as g,e as y,f as w,q as b}from"./chunks/framework.DulMeQy4.js";const v={name:"PoemCard",props:{poem:{type:Object,required:!0}}},k={class:"card"},T={class:"question"},A={class:"answer"};function S(h,t,n,c,u,i){return a(),o("div",k,[e("div",T,s(n.poem.input),1),t[0]||(t[0]=e("div",{class:"separator"},null,-1)),e("div",A,s(n.poem.output)+"🚨"+s(n.poem.context),1)])}const C=d(v,[["render",S],["__scopeId","data-v-d163389c"]]),M=JSON.parse(`[{"output":"In 1913","context":"the first line","input":"was inscribed on the wall of the chapel of the Royal Military Academy Sandhurst.[3] In the final stanza of his poem"},{"output":"The style of \\"\\"Dulce et Decorum est\\"\\" is similar to the French ballade poetic form.[5] By referencing this formal poetic form and then breaking the conventions of pattern and rhyming","context":"Owen accentuates the disruptive and chaotic events being told. Each of the stanzas has a traditional rhyming scheme","input":"that of which is closest to casual talking speed"},{"output":"The poem is in two parts","context":"each of 14 lines. The first part of the poem (the first 8 line and the second 6 line stanzas) is written in the present as the action happens and everyone is reacting to the events around them. In second part (the third 2 line and the last 12 line stanzas)","input":"as though standing back watching the events or even recalling them. Another interpretation is to read the lines literally. \\"\\"In all my dreams\\"\\" surely means this sufferer of shell shock is haunted by his friend drowning in his own blood and cannot sleep without revisiting the horror nightly. The second part looks back to draw a lesson from what happened at the start. The two 14 line parts of the poem again echoes a formal poetic style"},{"output":"The second half of this poem","context":"has the narrator reminded by seeing the soldier who didn't get his helmet on fast enough to offer some dark and harsh advice to readers about how quick and impartial thinking can get you thinking irrationally and can and will ultimately get you killed. It includes a broken sonnet","input":"to sounds produced by the body - or a movement from the visual to the visceral.[6] In the opening lines"},{"output":"In May 1917 Owen was diagnosed with neurasthenia (shell-shock) and sent to Craiglockhart hospital near Edinburgh to recover. Whilst receiving treatment at the hospital","context":"Owen became the editor of the hospital magazine","input":"and met the poet Siegfried Sassoon"},{"output":"Only five of Owens poems were published throughout his lifetime. However","context":"after his death his heavily worked manuscript drafts were brought together and published in two different editions by Siegfried Sassoon with the assistance of Edith Sitwell (in 1920) and Edmund Blunden (in 1931).[7]\\"","input":"Who wrote dulce et decorum est pro patria mori?"},{"output":"by boat or a 20-minute ferry ride from Steilacoom","context":"Anderson Island is the southernmost island in Puget Sound and a census-designated place of Pierce County, Washington, United States. It is accessible by boat or a 20-minute ferry ride from Steilacoom. Anderson Island lies just south of McNeil Island. To the northwest Key Peninsula lies across Drayton Passage. The south basin of Puget Sound separates the island from the mainland to the southeast, while to the southwest the Nisqually Reach of Puget Sound separates the island from the mainland.\\r\\n\\r\\n\\r\\nAnderson Island has a land area of 7.75 square miles (20.1?km2), and reported a population of 1,037 persons as of the 2010 census. The island had been a retirement destination since the late 1960s, with a median age of 54 years (for comparison, the median age of Washington state as a whole is 37 years[1]).[2] The population booms every summer to approximately 4,000. The Island is also home to a sizable population of deer.\\r\\nThe island was named in 1841 by Charles Wilkes of the United States Exploring Expedition. Given a warm reception at Fort Nisqually by Mr. Anderson and Captain McNeill, and assistance to aid his operations, Wilkes repaid their kindness by naming the two nearby islands after these two men.\\r\\nIn 1870, Andrew N. Christensen, a Dane, and his brother, Christian F. Christensen, were the first European settlers to stay at the island. Andrew's wife had a strong hand in the development of the island community. Christian was the only Christensen brother to reside permanently on Anderson Island. The primary industry was the sale of wood to the wood-burning steamers that came into Amsterdam Bay. Other early industries included brick making, farming and fishing.\\r\\nThe only General Store on the island is run by Dr. and Mrs. Lake of Steilacoom.\\r\\nIn 2004, National Recreational Properties, Inc. of Irvine, California purchased more than 400 vacant lots on the island, paying roughly $4,000 to $7,000 per lot. They created an infomercial and sold to out-of-state investors, mostly from California. Residents speculated that the lots would be sold for about $25,000.[3] Eventually more than 300 lots were sold, most selling for over $40,000.\\r\\nAccessible only by ferry or private boat, Anderson Island is served by the Steilacoom / Anderson Island / Ketron Island run, the only ferry run belonging to Pierce County.[4] The ferry Steilacoom II was put into service in January 2007 to work with the aging ferry Christine Anderson. The ferry runs many times per day, starting at 5:45 in the morning, and going to 10:30 pm on Fridays, Saturdays and Sundays (8:00 pm other nights).\\r\\nThe Anderson Island Citizens Advisory Board (AICAB) is a governing advisory board reporting to the Pierce County Council, established by the Pierce County Council in 2004. Examples of its past actions include banning of boats with internal combustion engines from Lake Josephine, road repair and speed recommendations, as well as other matters common to governing Anderson Island.[5]\\r\\nFire District #27 and the Anderson Island Parks District are taxing districts that serve only Anderson Island.[6]\\r\\nThe Steilacoom Historical School District serves Anderson Island. Children in grades Kÿ5 attend school on the island, while children in grades 6ÿ12 commute to the mainland each day. The Anderson Island School is designated a \\"remote and necessary\\" school by the State of Washington, and is one of the few remaining such schools in the state.\\r\\nTanner Electric Co-op provides electrical power to Anderson Island via a submarine cable. It extends across Nisqually Reach on the south end of the island and was replaced in 2010.[7]\\r\\nLaw enforcement is provided by the Pierce County Sheriff's office.\\r\\nThe Island Sounder, published by the Anderson Island Association, is the island's monthly newsletter. The News Tribune from Tacoma is available to subscribers.\\r\\nIn the movie WarGames, Matthew Broderick and Ally Sheedy take a ferry to Anderson Island, named \\"Goose Island, Oregon\\" in the film. They go to a log cabin owned by a person called \\"Stephen Falken.\\" [8]\\r\\nCoordinates: 4710N 12243W? / ?47.16N 122.71W? / 47.16; -122.71","input":"How do you get to anderson island wa?"},{"output":"an individual who provides preventive, curative, promotional or rehabilitative health care services in a systematic way to people, families or communities","context":"A health professional, health practitioner or healthcare provider (sometimes simply \\"provider\\") is an individual who provides preventive, curative, promotional or rehabilitative health care services in a systematic way to people, families or communities.\\r\\n\\r\\nA health professional may operate within all branches of health care, including medicine, surgery, dentistry, midwifery, pharmacy, psychology, nursing or allied health professions.  A health professional may also be a public/community health expert working for the common good of the society.\\r\\n\\r\\nHealthcare practitioners include\\r\\n\\r\\nand a wide variety of other human resources trained to provide some type of health care service.\\r\\n\\r\\nThey often work in hospitals, healthcare centres and other service delivery points, but also in academic training, research and administration. Some provide care and treatment services for patients in private homes. Many countries have a large number of community health workers who work outside formal healthcare institutions. Managers of healthcare services, health information technicians, and other assistive personnel and support workers are also considered a vital part of health care teams.[1]\\r\\n\\r\\nHealthcare practitioners are commonly grouped into health professions.\\r\\nWithin each field of expertise, practitioners are often classified according to skill level and skill specialization. Health professionals are highly skilled workers, in professions that usually require extensive knowledge including university-level study leading to the award of a first degree or higher qualification.[2] This category includes physicians, physician assistants, dentists, midwives, radiographers, registered nurses, pharmacists, physiotherapists, optometrists, operating department practitioners and others. Allied health professionals, also referred to as \\"health associate professionals\\" in the International Standard Classification of Occupations, support implementation of health care, treatment and referral plans usually established by medical, nursing, and other health professionals, and usually require formal qualifications to practice their profession. In addition, unlicensed assistive personnel assist with providing health care services as permitted.\\r\\n\\r\\nAnother way to categorize healthcare practitioners is according to the sub-field in which they practice, such as mental health care, pregnancy and childbirth care, surgical care, rehabilitation care, or public health.\\r\\n\\r\\nA mental health practitioner is a health worker who offers services for the purpose of improving the mental health of individuals or treating mental illness. These include psychiatrists, clinical psychologists, clinical social workers, psychiatric-mental health nurse practitioners, marriage and family therapists, mental health counselors, as well as other health professionals and allied health professions. These health care providers often deal with the same illnesses, disorders, conditions, and issues; however their scope of practice often differs. The most significant difference across categories of mental health practitioners is education and training.[3]\\r\\n\\r\\nA maternal and newborn health practitioner is a health worker who deals with the care of women and their children before, during and after pregnancy and childbirth. Such health practitioners include obstetricians, midwives, obstetrical nurses and many others. One of the main differences between these professions is in the training and authority to provide surgical services and other life-saving interventions.[4] In some developing countries, traditional birth attendants, or traditional midwives, are the primary source of pregnancy and childbirth care for many women and families, although they are not certified or licensed.\\r\\n\\r\\nA geriatric care practitioner plans and coordinates the care of the elderly and/or disabled to promote their health, improve their quality of life, and maintain their independence for as long as possible. They include geriatricians, adult-gerontology nurse practitioners, clinical nurse specialists, geriatric clinical pharmacists, geriatric nurses, geriatric care managers, geriatric aides, Nursing aides, Caregivers and others who focus on the health and psychological care needs of older adults.\\r\\n\\r\\nA surgical practitioner is a healthcare professional who specializes in the planning and delivery of a patient's perioperative care, including during the anaesthetic, surgical and recovery stages. They may include general and specialist surgeons, surgeon's assistant, assistant surgeon, surgical assistant, anesthesiologists, anesthesiologist assistant, nurse anesthetists, surgical nurses, clinical officers, operating department practitioners, anaesthetic technicians, perioperative nursing, surgical technologists, and others.\\r\\n\\r\\nA rehabilitation care practitioner is a health worker who provides care and treatment which aims to enhance and restore functional ability and quality of life to those with physical impairments or disabilities. These include physiatrists, rehabilitation nurses, clinical nurse specialists, nurse practitioners, physiotherapists, orthotists, prosthetists, occupational therapists, recreational therapists, audiologists, speech and language pathologists, respiratory therapists, rehabilitation counsellors, physical rehabilitation therapists, athletic trainers, physiotherapy technicians, orthotic technicians, prosthetic technicians, personal care assistants, and others.[5]\\r\\n\\r\\nCare and treatment for the eye and the adnexa may be delivered by ophthalmologists specializing in surgical/medical care, or optometrists specializing in refractive management and medical/therapeutic care.\\r\\n\\r\\nMedical diagnosis providers are health workers responsible for the process of determining which disease or condition explains a person's symptoms and signs. It is most often referred to as diagnosis with the medical context being implicit. This usually involves a team of healthcare providers in various diagnostic units. These include radiographers, radiologists, medical laboratory scientists, pathologists, and related professionals.\\r\\n\\r\\nA dental care practitioner is a health worker who provides care and treatment to promote and restore oral health. These include dentists and dental surgeons, dental assistants, dental auxiliaries, dental hygienists, dental nurses, dental technicians, dental therapists, and related professionals.\\r\\n\\r\\nCare and treatment for the foot, ankle, and lower leg may be delivered by podiatrists, pedorthists, foot health practitioners, podiatric medical assistants, podiatric nurse and others.\\r\\n\\r\\nA public health practitioner focuses on improving health among individuals, families and communities through the prevention and treatment of diseases and injuries, surveillance of cases, and promotion of healthy behaviors. This category includes community and preventive medicine specialists, public health nurses, clinical nurse specialists, dietitians, environmental health officers, paramedics, epidemiologists, health inspectors, and others.\\r\\n\\r\\nIn many societies, practitioners of alternative medicine have contact with a significant number of people, either as integrated within or remaining outside the formal health care system. These include practitioners in acupuncture, Ayurveda, herbalism, homeopathy, naturopathy, Reiki, Shamballa Reiki energy healing, Siddha medicine, traditional Chinese medicine, traditional Korean medicine, Unani, and Yoga. In some countries such as Canada, chiropractors and osteopaths (not to be confused with doctors of osteopathic medicine in the United States) are considered alternative medicine practitioners.\\r\\n\\r\\n\\r\\n\\r\\nMany jurisdictions report shortfalls in the number of trained health human resources to meet population health needs and/or service delivery targets, especially in medically underserved areas. For example, in the United States, the 2010 federal budget invested $330 million to increase the number of doctors, nurses, and dentists practicing in areas of the country experiencing shortages of trained health professionals. The Budget expands loan repayment programs for physicians, nurses, and dentists who agree to practice in medically underserved areas. This funding will enhance the capacity of nursing schools to increase the number of nurses. It will also allow states to increase access to oral health care through dental workforce development grants. The Budgets new resources will sustain the expansion of the health care workforce funded in the Recovery Act.[6] There were 15.7 million health care professionals in the US as of 2011.[7]\\r\\n\\r\\nIn Canada, the 2011 federal budget announced a Canada Student Loan forgiveness program to encourage and support new family physicians, nurse practitioners and nurses to practice in underserved rural or remote communities of the country, including communities that provide health services to First Nations and Inuit populations.[8]\\r\\n\\r\\nIn Uganda, the Ministry of Health reports that as many as 50% of staffing positions for health workers in rural and underserved areas remain vacant. As of early 2011, the Ministry was conducting research and costing analyses to determine the most appropriate attraction and retention packages for medical officers, nursing officers, pharmacists, and laboratory technicians in the countrys rural areas.[9]\\r\\n\\r\\nAt the international level, the World Health Organization estimates a shortage of almost 4.3 million doctors, midwives, nurses, and support workers worldwide to meet target coverage levels of essential primary health care interventions.[10] The shortage is reported most severe in 57 of the poorest countries, especially in sub-Saharan Africa.\\r\\n\\r\\nOccupational stress and occupational burnout are highly prevalent among health professionals.[11] Some studies suggest that workplace stress is pervasive in the health care industry because of inadequate staffing levels, long work hours, exposure to infectious diseases and hazardous substances leading to illness or death, and in some countries threat of malpractice litigation. Other stressors include the emotional labor of caring for ill people and high patient loads. The consequences of this stress can include substance abuse, suicide, major depressive disorder, and anxiety, all of which occur at higher rates in health professionals than the general working population. Elevated levels of stress are also linked to high rates of burnout, absenteeism and diagnostic errors, and to reduced rates of patient satisfaction.[12] In Canada, a national report (Canada's Health Care Providers) also indicated higher rates of absenteeism due to illness or disability among health care workers compared to the rest of the working population, although those working in health care reported similar levels of good health and fewer reports of being injured at work.[13] There is some evidence that cognitive-behavioral therapy, relaxation training and therapy (including meditation and massage), and modifying schedules can reduce stress and burnout among multiple sectors of health care providers. Research is ongoing in this area, especially with regards to physicians, whose occupational stress and burnout is less researched compared to other health professions.[14]\\r\\n\\r\\nExposure to respiratory infectious diseases like tuberculosis (caused by Mycobacterium tuberculosis) and influenza can be reduced with the use of respirators; this exposure is a significant occupational hazard for health care professionals.[15] Exposure to dangerous chemicals, including chemotherapy drugs, is another potential occupational risk. These drugs can cause cancer and other health conditions.[16] Healthcare workers are also at risk for diseases that are contracted through extended contact with a patient, including scabies.[17] Health professionals are also at risk for contracting blood-borne diseases like hepatitis B, hepatitis C, and HIV/AIDS through needlestick injuries or through contact with bodily fluids.[18][19] This risk can be mitigated with vaccination when there is a vaccine available, like with hepatitis B.[19] In epidemic situations, such as the 2014-2016 West African Ebola virus epidemic or the 2003 SARS outbreak, healthcare workers are at even greater risk, and were disproportionately affected in both the Ebola and SARS outbreaks. In general, appropriate personal protective equipment (PPE) is the first-line mode of protection for healthcare workers from infectious diseases. For it to be effective against highly contagious diseases, personal protective equipment must be watertight and prevent the skin and mucous membranes from contacting infectious material. Different levels of personal protective equipment created to unique standards are used in situations where the risk of infection is different. Practices such as triple gloving and multiple respirators do not provide a higher level of protection and present a burden to the worker, who is additionally at increased risk of exposure when removing the PPE. Compliance with appropriate personal protective equipment rules may be difficult in certain situations, such as tropical environment or low-resource settings. A 2016 Cochrane systematic review found low quality evidence that using more breathable fabric in PPE, double gloving, and active training reduce the risk of contamination.[20]\\r\\n\\r\\nFemale health care workers may face specific types of workplace-related health conditions and stress. According to the World Health Organization, women predominate in the formal health workforce in many countries, and are prone to musculoskeletal injury (caused by physically demanding job tasks such as lifting and moving patients) and burnout. Female health workers are exposed to hazardous drugs and chemicals in the workplace which may cause adverse reproductive outcomes such as spontaneous abortion and congenital malformations. In some contexts, female health workers are also subject to gender-based violence including from coworkers and patients.[21][22]\\r\\n\\r\\nHealthcare workers are at higher risk of on-the-job injury due to violence. Drunk, confused, and hostile patients and visitors are a continual threat to providers attempting to treat patients. Frequently, assault and violence in a healthcare setting goes unreported and is wrongly assumed to be part of the job.[23] Violent incidents typically occur during one-on-one care; being alone with patients increases healthcare workers' risk of assault.[24] In the United States, healthcare workers suffer ? of nonfatal workplace violence incidents.[23] Psychiatric units represent the highest proportion of violent incidents, at 40%; they are followed by geriatric units (20%) and the emergency department (10%). Workplace violence can also cause psychological trauma.[24]\\r\\n\\r\\nThe Occupational Health Safety Network is a system developed by the National Institute for Occupational Safety and Health (NIOSH) to address health and safety risks among health care providers. Hospitals and other healthcare facilities can upload the occupational injury data they already collect to the secure database for analysis and benchmarking with other de-identified facilities from throughout the U.S. NIOSH works with OHSN participants in identifying and implementing timely and targeted interventions. OHSN modules currently focus on three high risk and preventable events that can lead to injuries or musculoskeletal disorders among healthcare providers: musculoskeletal injuries from patient handling activities; slips, trips, and falls; and workplace violence.[23] Slips, trips, and falls are the second-most common cause of worker's compensation claims in the US, and cause 21% of work absences due to injury. These injuries most commonly result in strains and sprains; women, those older than 45, and those who have been working less than a year in a healthcare setting are at the highest risk.[7]\\r\\n\\r\\nHealth care professionals are also likely to experience sleep deprivation due to their jobs. Many health care professionals are on a shift work schedule, and therefore experience misalignment of their work schedule and their circadian rhythm. In 2007, 32% of healthcare workers were found to get fewer than 6 hours of sleep a night. Sleep deprivation also predisposes healthcare professionals to make mistakes that may potentially endanger a patient.[25]\\r\\n\\r\\nPracticing without a license that is valid and current is typically illegal. In most jurisdictions, the provision of health care services is regulated by the government. Individuals found to be providing medical, nursing or other professional services without the appropriate certification or license may face sanctions and criminal charges leading to a prison term. The number of professions subject to regulation, requisites for individuals to receive professional licensure, and nature of sanctions that can be imposed for failure to comply vary across jurisdictions.\\r\\n\\r\\nIn the United States, under Michigan state laws, an individual is guilty of felony if identified as practicing in the health profession without a valid personal license or registration. Health professionals can also be imprisoned if found guilty of practicing beyond the limits allowed by their licences and registration. The state laws define the scope of practice for medicine, nursing, and a number of allied health professions.[26][unreliable source?] In Florida, practicing medicine without the appropriate license is a crime classified as a third degree felony,[27] which may give imprisonment up to five years. Practicing a health care profession without a license which results in serious bodily injury classifies as a second degree felony,[27] providing up to 15 years' imprisonment.\\r\\n\\r\\nIn the United Kingdom, healthcare professionals are regulated by the state; the UK Health and Care Professions Council (HCPC) protects the 'title' of each profession it regulates. For example, it is illegal for someone to call himself an Occupational Therapist or Radiographer if they are not on the register held by the HCPC.","input":"What is the definition of a health care professional?"},{"output":"23 January 1565","context":"\\r\\n\\r\\nDeccan sultanates\\r\\n\\r\\nThe Battle of Talikota (23 January 1565) was a watershed battle fought between the  Vijayanagara Empire and the Deccan sultanates. The battle took place at Talikota, today a town in northern Karnataka, about 80 kilometres (50?mi) to the southeast from the city of Bijapur. The treacherous defeat of Vijayanagara Empire, followed subsequent destruction and looting which became short lived before the  successors of Rama Raya.\\r\\n\\r\\nThe Muslim Sultanates to the north of Vijayanagara united and attacked Rama Raya's army, on 23 January 1565, in an engagement known as the Battle of Talikota.[2] The armies clashed on the plains near the villages of Rakkasagi and Tangadigi (it is also known as the Battle of Rakkasa-Tangadi).[3]\\r\\n\\r\\nThe Vijayanagara army was winning the battle, state Hermann Kulke and Dietmar Rothermund, but suddenly two Muslim generals of the Vijayanagara army switched sides and turned their loyalty to the united Sultanates. They captured Rama Raya and beheaded him on the spot, with Sultan Hussain on the Sultanates side joining them.[4][5] The beheading of Rama Raya created confusion and havoc and in the still loyal portions of the Vijayanagara army, which were then completely routed. The Sultanates' army plundered Hampi and reduced it into ruins.[6]\\r\\n\\r\\nAccording to Shastri, the greatest factor was the betrayal of the Vijaynagara Army by two Muslim commanders (Gilani Brothers).  At the critical point of the war, Muslim officers in the Vijayanagara army launched a subversive attack. Suddenly Rama Raya found himself surprised when the two Muslim divisions in his ranks turned against him.[8]\\r\\n\\r\\nRobert Sewell, in his book The Forgotten Empire, concludes thus ÿ \\"With fire and sword, with crowbars and axes, they carried on day after day their work of destruction. Never perhaps in the history of the world has such havoc been wrought, and wrought so suddenly, on so splendid a city; teeming with a wealthy and industrious population in the full plenitude of prosperity one day, and on the next seized, pillaged, and reduced to ruins, amid scenes of savage massacre and horrors beggaring description.\\"[9]","input":"When did the rakkasa tangadi war take place?"},{"output":"Harvard University","context":"First university in the United States is a status asserted by more than one U.S. university. Historically, when the Philippines was still a United States territory, the University of Santo Tomas (established in 1611) was considered as the oldest university under the American flag.[1] Presently in the United States, there is no official definition of what entitles an institution to be considered a university versus a college, and the common understanding of university has evolved over time. The 1911 Encyclop?dia Britannica tells the story of the gradual emergence of U.S. \\"universities\\" thus:[2]\\r\\nIn the United States the word university has been applied to institutions of the most diverse character, and it is only since 1880 or thereabouts that an effort has been seriously made to distinguish between collegiate and university instruction; nor has that effort yet completely succeeded. Harvard, William and Mary, and Yale . . . were organized . . . on the plans of the English colleges which constitute the universities of Oxford and Cambridge. Graduates of Harvard and Yale carried these British traditions to other places, and similar colleges grew up in New York, New Jersey, Pennsylvania, New Hampshire and Rhode Island.... Around or near these nuclei, during the course of the 19th century, one or more professional schools were frequently attached, and so the word university was naturally applied to a group of schools associated more or less closely with a central school or college. Harvard, for example, most comprehensive of all, has seventeen distinct departments, and Yale has almost as many. Columbia and Penn have a similar scope. In the latter part of the 19th century Yale, Columbia, Princeton and Brown, in recognition of their enlargement, formally changed their titles from colleges to universities.\\r\\nThe issue is further confused by the fact that at time of founding of many of the institutions in question, the United States didn't exist as a sovereign nation. Moreover, questions of institutional continuity sometimes make it difficult to determine the true \\"age\\" of any institution.\\r\\n\\r\\n\\r\\nSeveral universities claim to be the first university in the United States:\\r\\nAdditionally, Johns Hopkins University opened in 1876 and claims to be \\"America's first research university\\" (emphasis added).[9]\\r\\nHarvard University calls itself \\"the oldest institution of higher learning in the United States\\" and this claim is rarely challenged. It is possible to disagree what year should be taken as Harvard's \\"real\\" founding date (Harvard uses the earliest possible one, 1636, when the institution was chartered by the Massachusetts Bay Colony). However, Harvard has operated since 1650 under the same corporation, the \\"President and Fellows of Harvard College\\"; it thus has an unbroken institutional history dating back to the mid seventeenth century (an official Harvard web page for the School of Engineering and Applied Sciences [10] claims, \\"Founded in 1636, Harvard is America's oldest university\\").\\r\\nWilliam & Mary calls itself \\"America's second-oldest college\\", acknowledging Harvard's claim but adding that William & Mary itself is the nation's oldest college in its \\"antecedents,\\" the College of Henricopolis or University of Henrico established by the Virginia Company near Richmond, Virginia. This institution received a royal charter in 1618 and operated a school for several years before being destroyed with the town during the Indian Massacre of 1622, but it never offered college-level instruction. The following year, King James I dissolved the Virginia Company, converting the Colony of Virginia to a crown colony. William and Mary was founded under a new charter in 1693.\\r\\nThe founding date of the University of Pennsylvania is associated with more subjectivity and institutional debate than the more straightforward dates used by the eight other colonial era colleges. Harvard University uses as its founding date 1636, the year in which the legislature of the Massachusetts Bay Colony formally voted to budget funds for the creation of a college in Newtowne, later called Cambridge. The seven remaining colonial era colleges consider their founding dates to be the year in which they were first granted charters and thus became legal corporations.\\r\\nPenn's claim as the first university in the United States is three-fold: the 1765 founding of the first medical school in America made Penn the first institution to offer both \\"undergraduate\\" and professional education; the 1779 charter made it the first American institution of higher learning to take the name of \\"University\\"; and existing colleges were established as seminaries (although, as detailed in its own article, Penn adopted a traditional seminary curriculum as well).[11] Harvard and Yale were officially affiliated with the Congregational Church. Although officially nonsectarian, Princeton was founded by Presbyterians. Similarly, though Penn was officially nonsectarian, it was established by a board composed of Church of England and Methodist members, with a curriculum consistent with those religions.\\r\\nThe first charter for an institution of higher learning in Philadelphia was granted in 1755 to the College of Philadelphia, a new undertaking of the Academy of Philadelphia, which had previously taught only secondary students. In 1779, a charter was granted to a separate institution called the \\"University of the State of Pennsylvania\\"[12] which in 1791 was merged with the College of Philadelphia and issued a new charter as the \\"University of Pennsylvania\\".\\r\\nDespite the three charter dates of 1755, 1779 and 1791, the University used for more than a century the founding date of 1749, the year in which founder Benjamin Franklin first convened a board of trustees to organize the new institution. In 1899, the University's board of trustees voted to change the founding date by nine years to 1740, the year in which a group of Philadelphia citizens established a trust for a charity school requested by traveling evangelist George Whitefield. A frame of a building was erected, but the citizens discovered that they lacked the funds to furnish the interior chapel or open the charity school.\\r\\nThe unfinished edifice lay vacant for roughly a decade until Franklin's nascent Academy of Philadelphia was looking for space to begin operations and purchased the still unused building in 1750. The Academy of Philadelphia operated a charity school for a few years and this brief period was the basis for the trustees' claims of institutional continuity to the earlier date, as the Academy had assumed the trust of the charity school for local orphans planned but not begun by the original fundraisers of the building.\\r\\nParenthetically, the University of Pennsylvania calls itself the fourth oldest institution of higher learning in the United States, comparing the legal charter dates of Princeton University (1746) and Columbia University (1754) with the 1740 date in which the trust had been established and fundraising had begun for the building it would ultimately purchase in 1750.\\r\\nPerhaps not surprisingly, Princeton University and Columbia University do not follow the same train of thought in their own institutional histories. Princeton and Columbia consider themselves the fourth and fifth oldest institutions of higher learning in the country, respectively, comparing the three collegiate charter dates of 1746, 1754 and 1755.\\r\\nThis seemingly minor difference of opinion assumes greater importance in the world of academia. Formal academic processions such as those at graduation ceremonies place visiting dignitaries and other officials in the order of their institution's founding dates, explaining why universities have sometimes used strained rationales to claim and defend dates as early as possible. The University of Pennsylvania changed its founding date in 1899, four years after elite universities in the United States agreed that academic processions would follow this age-based hierarchy. The revision in founding date was the result of a three-year campaign initiated by the University's \\"Alumni Register\\" magazine to make it older than Princeton for these processions.\\r\\nThe argument used is that it is the common legal practice to date the founding of an institution from the date of founding for the oldest trust it administers. In this case, the oldest trust that the University of Pennsylvania administers was established in 1740. Historian Edward Potts Cheyney states that, \\"it might be considered a lawyer's date; it is a familiar legal practice in considering the date of any institution to seek out the oldest trust it administers.\\" (The University still administers this trust in the funding of the Sadie Tanner Mossell Alexander University of Pennsylvania Partnership School.) He also points out that Harvard's founding date is merely the year in which the Massachusetts General Court resolved to establish a fund in a year's time for a \\"School or College\\". As well, Princeton claims its founding date as 1746the date of its first charter. However, the exact words of the charter are unknown, the number and names of the trustees in the charter are unknown, and no known copy is extant. Though it is a common practice to use the dates of charter as the official date, the majority of the American Colonial Colleges do not have clear-cut dates of foundation.[13]\\r\\nIn brief, in 1779 the College of Philadelphia was directed by provost William Smith. One might have expected it to evolve into the \\"University of the State of Pennsylvania\\" but this did not occur. \\"Since the Revolutionary state legislature felt that the board of trustees led by Provost Smith contained too many suspected loyalist sympathizers, they created a new board of trustees.\\" Thus, the University of the State of Pennsylvania was created de novo. A schism occurred, with an attenuated College of Philadelphia continuing under Dr. Smith's direction. In 1791 Pennsylvania adopted a new state constitution which merged the College of Philadelphia and the University of the State of Pennsylvania into the \\"University of Pennsylvania,\\" with a board of trustees made up of twelve men from each of the two parent institutions. \\"It is this institution and this board of trustees that has continued to this day.\\"\\r\\nOn December 4, 1779, just seven days after the founding of the \\"University of the Commonwealth of Pennsylvania\\", an event occurred which William and Mary describes thus:[14]\\r\\nUnder the leadership of Thomas Jefferson, then governor of Virginia and a member of the Board of Visitors, William and Mary became a university. The grammar and divinity schools were discontinued, and a professorship of anatomy and medicine, and the first American chairs of law and police and modern languages were established. The elective system of studies was introduced at this time, the first such program in the United States.\\r\\n(For historical reasons, The College of William and Mary, like Dartmouth College and Boston College, has continued to use \\"college\\" rather than \\"university\\" in its official name.)\\r\\nWilliam and Mary has a published list of its first graduates (by Swem) available through its library.\\r\\nThe Constitution of Massachusetts, submitted by James Bowdoin, Samuel Adams, and John Adams to the full Convention on October 28, 1779[15] and ratified on June 15, 1780, contains this language:[16]\\r\\nThe word \\"university\\" is used a total of five times in reference to Harvard in the Massachusetts Constitution.\\r\\n(It is not clear from context, either above or in the paragraphs that follow, that the constitution meant to draw any semantic distinction between \\"college\\" and \\"university.\\" )\\r\\nIn George Washington's honorary Doctor of Laws degree, conferred by Harvard on April 30, 1776, the text of the degree refers to Harvard twice as \\"our University\\".[17]\\r\\nIf a university is defined as an institution that awards doctoral degrees, then there are a number of contenders for the title of oldest United States university based on that criteria, as well. Among the conflicting interpretations is whether the date the first doctoral degree is awarded should be the determining factor, or the date a doctoral program was first attempted is the determinant.\\r\\nHarvard has awarded honorary \\"doctorates\\" since the 17th century, such as the Doctor of Sacred Theology degree to Increase Mather in 1692[18] (the first honorary degree in the New World).[19]\\r\\nKing's College (now Columbia University) organized a medical faculty in 1767, and in 1769 became the first institution in the North American Colonies to confer the degree of Doctor of Medicine, according to the College of Physicians and Surgeons.[20]\\r\\nPenn founded the first medical school in America in 1765, according to Penn's archivist.[21]\\r\\nYale's website refers to the establishment of \\"the Graduate School of Arts and Sciences\\" in 1847.[22]\\r\\nGeorgetown's website references 1820 as the year it first established its graduate school, issuing its first advanced degree in 1820.[23]\\r\\n\\r\\nYale's website states that in 1861, Yale \\"awarded the first Ph.D. in the United States\\".[22]","input":"Which is the oldest university in the usa?"},{"output":"16 November 2003","context":"","input":"When did messi started playing for barca first team?"},{"output":"38 years and 3 days","context":"Creme Puff (August 3, 1967 ÿ August 6, 2005) was a domestic cat, owned by Jake Perry of Austin, Texas, who died aged 38 years and 3 days. She was the oldest cat ever recorded, according to the 2010 edition of Guinness World Records.[1][2][3] Perry had another cat, Granpa, who was claimed to have been born in Paris in 1964 and died in 1998, aged 34 years and 2 months. Granpa was posthumously awarded 1999 Cat of the Year by Cats & Kittens magazine.[4][5] Granpa was featured in an earlier edition of Guinness World Records.[6] The co-authors of at least one book have pondered whether the longevity of Perry's cats may have had something to do with an unusual diet of, among other things, bacon and eggs, asparagus, broccoli, and coffee with heavy cream, concluding that Perry \\"must be doing something right.\\"[7]","input":"How old is the oldest cat that ever lived?"},{"output":"Cuban","context":"The flag of Puerto Rico represents and symbolizes the island of Puerto Rico and its people.\\r\\nThe origins of the current flag of Puerto Rico, adopted by the commonwealth of Puerto Rico in 1952, can be traced to 1868, when the first Puerto Rican flag, \\"The Revolutionary Flag of Lares\\", was conceived by Dr. Ram܇n Emeterio Betances and embroidered by Mariana \\"Brazos de Oro\\" Bracetti. This flag was used in the short-lived Puerto Rican revolt against Spanish rule in the island, known as \\"El Grito de Lares\\".[1][2]\\r\\nJuan de Mata Terreforte, an exiled veteran of \\"El Grito de Lares\\" and Vice-President of the Cuban Revolutionary Committee, in New York City, adopted the flag of Lares as the flag of Puerto Rico until 1895, when the current design, modeled after the Cuban flag, was unveiled and adopted by the 59 Puerto Rican exiles of the Cuban Revolutionary committee.[3] The new flag, which consisted of five equal horizontal bands of red (top and bottom) alternating with white; a blue isosceles triangle based on the hoist side bears a large, white, five-pointed star in the center, was first flown in Puerto Rico on March 24, 1897, during the \\"Intentona de Yauco\\" revolt. The use and display of the Puerto Rican flag was outlawed and the only flags permitted to be flown in Puerto Rico were the Spanish flag (1492 to 1898) and the flag of the United States (1898 to 1952).\\r\\nIn 1952, the Commonwealth of Puerto Rico adopted the same flag design, which was unveiled in 1895 by the Puerto Rican exiles within the Cuban Revolutionary Committee, as its official standard. The color of the triangle that was used by the administration of Luis Mu?oz Marn was the dark blue.[4] In 1995, the government of Puerto Rico issued a regulation regarding the use of the Puerto Rican flag titled: \\"Reglamento sobre el Uso en Puerto Rico de la Bandera del Estado Libre Asociado de Puerto Rico\\", in which the government specifies the colors to be used but does not specify any official color tones or shades. Therefore, it is not uncommon to see the flag of Puerto Rico with different shades of blue displayed in the island.[5] Several Puerto Rican flags, with darker shades than sky blue were aboard the Space Shuttle Discovery during its flight into outer space on March 15, 2009.[6][7]\\r\\n\\r\\n\\r\\nThe introduction of a flag in Puerto Rico can be traced to when Christopher Columbus landed on the island's shore and with the flag appointed to him by the Spanish Crown claimed the island, which he named \\"San Juan Bautista\\", in the name of Spain. Columbus wrote in his logbook that on October 12, 1492, he used the Royal Flag, and that his captains used two flags which the Admiral carried in all the ships as ensign, each white with a green cross in the middle and an 'F' and 'Y', both green and crowned with golden, open royal crowns, for Ferdinand II of Aragon and Ysabel (Isabel I).[8] The conquistadores under the command of Juan Ponce de Le܇n proceeded to conquer and settle the island. They carried as their military standard the \\"Spanish Expedition Flag\\". After the island was conquered and colonized, the flag of Spain was used in Puerto Rico, same as it was used in all of its other colonies.[9]\\r\\nOnce the Spanish armed forces established themselves on the island they began the construction of military fortifications such as La Fortaleza, Fort San Felipe del Morro, Fort San Crist܇bal and San Ger܇nimo. The Spanish Army designed the \\"Cross of Burgundy Flag\\" and adopted it as their standard. This flag flew wherever there was a Spanish military installation.[10]\\r\\nThe independence movement in Puerto Rico gained momentum with the liberation successes of Sim܇n Bolvar and Jos de San Martn in South America. In 1868, local independence leader Ram܇n Emeterio Betances urged Mariana Bracetti to knit a revolutionary flag using the flag of the Dominican Republic as an example, promoting the then popular ideal of uniting the three caribbean islands into an Antillean Confederation. The materials for the flag were provided by Eduvigis Beauchamp Sterling, named Treasurer of the revolution by Betances.[11] The flag was divided in the middle by a white Latin cross, the two lower corners were red and the two upper corners were blue with a white star in the upper left blue corner. According to Puerto Rican poet Luis Llorns Torres the white cross on it stands for the yearning for homeland redemption; the red squares, the blood poured by the heroes of the rebellion and the white star in the blue solitude square, stands for liberty and freedom.[12] The \\"Revolutionary Flag of Lares\\" was used in the short-lived rebellion against Spain in what became known as El Grito de Lares (The Cry of Lares).[13] The flag was proclaimed the national flag of the \\"Republic of Puerto Rico\\" by Francisco Ramrez Medina, who was sworn in as Puerto Rico's first president, and placed on the high altar of the Catholic Church of Lares, thus becoming the first Puerto Rican Flag.[1] The original Lares flag was taken by a Spanish army officer as a war prize. Many years later it was returned and transferred to the Puerto Rican people. It is now exhibited in the University of Puerto Rico's Museum.[1]\\r\\nIn 1873, following the abdication of Amadeus, Duke of Aosta, as King (1870ÿ1873) and with Spain's change from Kingdom to Republic, the Spanish government issued a new colonial flag for Puerto Rico. The new flag, which was used until 1873, resembled the flag of Spain, with the difference that it had the coat of arms of Puerto Rico in the middle. Spain's flag once more flew over Puerto Rico with the restoration of the Spanish kingdom in 1873, until 1898 the year that the island became a possession of the United States under the terms of the Treaty of Paris (1898) in the aftermath of the SpanishÿAmerican War.[14]\\r\\nJuan de Mata Terreforte, a leader of the Grito de Lares revolt who fought alongside Manuel Rojas, was exiled to New York City. He joined the Puerto Rican Revolutionary Committee and was named its Vice-President.[3] Terreforte and the members of the Revolutionary committee adopted the Flag of Lares as their standard. In 1892, the Committee was presented with the design of the current flag of Puerto Rico. The new flag's design has been attributed to various Puerto Ricans who were members of the Puerto Rican Revolutionary Committee in New York City.\\r\\nSome sources document Francisco Gonzalo Marn with presenting a Puerto Rican flag prototype in 1895 for adoption by the Puerto Rican Revolutionary Committee in New York City. Marn has since been credited by some with the flag's design.[15] There is a letter written by Juan de Mata Terreforte which gives credit to Marin. The original contents of the letter in Spanish are the following:[16]\\r\\nWhich translated in English states the following: The adaptation of the Cuban flag with the colors inverted was suggested by the patriot Francisco Gonzalo Marn in a letter which he wrote from Jamaica. I made the proposition to various Puerto Rican patriots during a meeting at Chimney Hall and it was approved unanimously.[16]\\r\\nAccording to other accounts on June 12, 1892, disputed by scholar Armando Mart,[17] Antonio Vlez Alvarado was at his apartment at 219 Twenty-Third Street in Manhattan, when he stared at a Cuban flag for a few minutes, and then took a look at the blank wall in which it was being displayed. Vlez suddenly perceived an optical illusion, in which he perceived the image of the Cuban flag with the colors in the flag's triangle and stripes inverted. Almost immediately he visited a nearby merchant, Domingo Peraza, from whom he bought some crepe paper to build a crude prototype. He later displayed his prototype in a dinner meeting at his neighbor's house, where the owner, Micaela Dalmau vda. de Carreras, had invited Jos Mart as a guest. Mart was pleasantly impressed by the prototype, and made note of it in a newspaper article published in the Cuban revolutionary newspaper Patria, published on July 2 of that year. Acceptance of the prototype was slow in coming, but grew with time. Francisco Gonzalo Marn, who decided to have a proper flag sewn based on the prototype, presented the new flag's design in New York's \\"Chimney Corner Hall\\" a gathering place of independence advocates two years later. The Puerto Rican Flag (with the light blue triangle) soon came to symbolize the ideals of the Puerto Rican independence movement.[18]\\r\\nIn a letter written by Maria Manuela (Mima) Besosa, the daughter of the Puerto Rican Revolutionary Committee member Manuel Besosa, she stated that she sewed the flag. This created a belief that her father could have been its designer. In her letter she described the flag as one which consists of five stripes that alternate from red to white. Three of the stripes are red, and the other two are white. To the left of the flag is a light blue triangle that houses one white five-pointed star. Each part of this flag has its own meaning. The three red stripes represent the blood from the brave warriors. The two white stripes represent the victory and peace that they would have after gaining independence. The white star represented the island of Puerto Rico. The blue represents the sky and blue coastal waters. The triangle represents the three branches of government.[19] Finally, it is also believed by some that it was Lola Rodrguez de Ti܇ who suggested that Puerto Ricans use the Cuban flag with its colors reversed as the model for their own standard.[20] The color of the Cuban flag's blue stripes, however, were a darker shade of blue, according to Professor Mart.\\r\\nEven though the local newspaper \\"El Imparcial\\" on January 17, 1948, that Vlez Alvarado was the \\"Pr܇cer Que Cre܇ Bandera Patria\\" (The Father of the Puerto Rican Flag)[21] it may never be known who really designed the current flag, however what is known is that on December 22, 1895, the Puerto Rican Revolutionary Committee officially adopted the design which represents the current flag. In 1897, Antonio Mattei Lluberas visited the Puerto Rican Revolutionary Committee in New York City to plan an uprising in Yauco. He returned to Puerto Rico with a Puerto Rican flag[22] and on March 24, 1897, a group of men, led by Fidel Vlez, carried the Puerto Rican flag and attacked the barracks of Spanish Civil Guard of the town Yauco during the revolt against Spanish rule which became known as the \\"Intentona de Yauco\\" (Attempted Coup of Yauco). The revolt, which was the second and last major attempt against the Spaniards in the island, was the first time that the flag of Puerto Rico was used on Puerto Rican soil.[23][24]\\r\\nFrom December 10, 1898 (the date of the annexation of Puerto Rico by the United States) up until 1952, it was considered a felony to display the Puerto Rican flag in public; the only flag permitted to be flown on the island was the flag of the United States.[25] However, the Puerto Rican flag was often used in the political assemblies of the pro-independence Liberal Party of Puerto Rico and in defiance by the Puerto Rican Nationalist Party. In 1932, the Nationalist Party used the flag as its emblem during the elections and in their parades. The Puerto Rico legislature presided by then President of the Puerto Rican Senate Luis Mu?oz Marn, passed a bill on May 21, 1948, known as Law 53, making it illegal to display the Puerto Rico Flag, sing a Puerto Rican patriotic song and talk of independence for the islands of Puerto Rico. On June 10, 1948, the United States-appointed Governor of Puerto Rico, Jes~s T. Pi?ero, a member of the ruling Popular Democratic Party (PDP), signed the bill which became known as the \\"Ley de la Mordaza\\" (Gag Law).[26] Later that same year Puerto Ricans were permitted to elect a governor and they elected Luis Mu?oz Marn. During the Jayuya Uprising of 1950 against United States rule, members of the Nationalist party placed the Puerto Rican flag on top of the town hall; the flag was later taken down by a soldier.\\r\\nIn 1952, Governor Luis Mu?oz Marn and his administration adopted the Puerto Rican flag which was originally designed in 1892, and proclaimed it the official flag of Puerto Rico. The official adaptation of the flag has been interpreted by some as a ploy by Mu?oz Marin to neutralize the independence movement in his own party.[27] There were some differences between the original flag of 1892 and the one of 1952 and the meaning of the colors was officially changed. Now the white bars stood for the republican form of government, rather than representing the victory and peace that Puerto Ricans were supposed to have after gaining independence.[28] The sky-blue of the triangle in the original flag was changed to dark blue, resembling that of the flag of the United States, to keep it distanced from its revolutionary roots. For nationalist leader Pedro Albizu Campos, having the flag represent the government was a desecration,[29] while the independence party accused the government of \\"corrupting beloved symbols\\".[27] In 1995, the government of Puerto Rico began to use the sky-blue version once more.[30][31] The government of Puerto Rico issued a regulation in regard to the use of the Puerto Rican flag titled: \\"Reglamento sobre el Uso en Puerto Rico de la Bandera del Estado Libre Asociado de Puerto Rico; Reglamento N~m. 5282.\\" (Regulations in regard to the use in Puerto Rico of the flag of Commonwealth of Puerto Rico; Regulation No. 5282). In the regulation's \\"Artculo 2: Definiciones\\" and \\"Artculo 2: Descripci܇n y simbolismo\\" (Article 2: Description and Article 2: Description and symbolism) the government specifies the colors to be used but does not specify any official color tones or shades and as such it is not unusual to see the flag with either tone of blue flown in official settings in Puerto Rico.[5]\\r\\nAmong the many occasions in which the flag has been used as a symbol of pride was when the flag arrived in South Korea during the Korean War. On August 13, 1952, while the men of Puerto Rico's 65th Infantry Regiment (United States) were being attacked by enemy forces on Hill 346, the regiment unfurled the Puerto Rican Flag for the first time in history in a foreign combat zone. During the ceremony Regimental Chaplain Daniel Wilson stated the following:[32][33]\\r\\nThe Commanding Officer Colonel Juan Csar Cordero Dvila was quoted as saying:[32][33]\\r\\nOn various occasions the flag has been used as a symbol of defiance and protest. In the 1954 attack of the United States House of Representatives in a protest against United States rule of the island, Nationalist leader Lolita Lebr܇n shouted \\"?Viva Puerto Rico Libre!\\" (\\"Long live a Free Puerto Rico!\\") and unfurled the flag of Puerto Rico.[34] On November 5, 2000, Alberto De Jesus Mercado, better known as Tito Kayak, and five other Vieques activists stepped onto the top deck of the Statue of Liberty in New York City, then placed a Puerto Rican flag, with the triangle darker than the light-blue version[35] on the statue's crown, reenacting an earlier protest in the 1970s asking for the release of Puerto Rican prisoners, this time in protest of the United States Navy usage of the island of Vieques as a bombing range.[36]\\r\\nOn March 15, 2009, several Puerto Rican flags were aboard the Space Shuttle Discovery during its flight into outer space. Joseph M. Acaba, the first astronaut of Puerto Rican descent, who is assigned to the crew of STS-119 as a Mission Specialist Educator, carried on his person the flag as a symbol of his Puerto Rican heritage.[6] Acaba presented Governor Luis Fortu?o and Secretary of State Kenneth McClintock with two of the flags during his visit in June 2009. The two flags' triangles had a darker blue hue.[37]\\r\\nThe flag is also the subject of the song \\"Que Bonita Bandera\\" (What a beautiful flag) written in 1968 and made popular by Puerto Rican folksinger Florencio \\"Ramito\\" Morales Ramos. Astronaut Acaba, requested that the crew be awakened on March 19, 2009 (Day 5), with the Puerto Rico folklore song, sung by Jose Gonzalez and Banda Criolla, during their space flight.[38]\\r\\nIn the 1950s Puerto Rico contacted Norway's Foreign Ministry in an attempt to have Norwegian shipping company Norled stop using a flag that has a significant[39] likeness to Puerto Rico's flag. Norway has not legally challenged the shipping company's position, that their flag is older than Puerto Rico's.[39] The shipping company's flag is still in use, as of 2014[update].[39]\\r\\nFlag of Province of Puerto Rico (1873ÿ1898)\\r\\nLares revolutionary flag of 1868\\r\\nSpanishÿAmerican War flag: flag of the Batall܇n Provisional No. 3 de Puerto Rico (3rd Provisional Battalion of Puerto Rico).\\r\\nFlag of Spain (1873ÿ1874) First Spanish Republic.\\r\\nOriginal Puerto Rican flag design of 1895\\r\\nPuerto Rican flag aboard the Discovery Space Shuttle (March 15, 2009)","input":"Which flag was made first cuba or puerto rico?"},{"output":"Love Me Tender","context":"Elvis Presley (1935ÿ1977) was an American entertainer who achieved initial success as a singer, expressing an early career goal of following in the footsteps of his role models James Dean and Marlon Brando to become a top dramatic actor.[1] His manager Colonel Tom Parker's persistent lobbying of William Morris Agency president Abe Lastfogel for a Presley screen test paid off on March 26, 1956, when the singer auditioned at Paramount for a supporting role in The Rainmaker.[2] Although not chosen for the part, he signed a contract with Paramount producer Hal Wallis on April 25 that also allowed him to make films with other studios.[3]\\r\\nHis feature debut was in Love Me Tender for 20th Century Fox, with the commercial success of the soundtrack EP being a bellwether for the next three Presley films. Loving You, Jailhouse Rock and King Creole were dramatic storylines written around Presley in the role of a musical entertainer.[4] He would later state that King Creole was his favorite of all his films.[5] Flaming Star and Wild in the Country were rarities in his career, non-musicals focused on dramatic storylines. According to music historian Peter Guralnick, the sluggish financial returns of those two films became the justification for ignoring Presley's wishes and limiting him to the more profitable musical format.[6]\\r\\nPresley became bitter that his hopes for dramatic roles were not coming to fruition,[7] stating that Clambake was his worst film. He began to complain about the deteriorating quality of the films and his belief that his manager's objectives were more monetary than anything else.[8] At the expiration of all studio contracts, he returned to live entertaining. The two concert documentaries Elvis: That's the Way It Is in 1970 and Elvis on Tour in 1972 were the final theatrical releases for Presley.[9]","input":"What was the name of elvis presley's first movie?"},{"output":"1955 to 1975","context":"The role of the United States in the Vietnam War began after World War II and escalated into full commitment during the Vietnam War from 1955 to 1975. The U.S. involvement in South Vietnam stemmed from 20 long years of political and economic action. These had the common incentive of ending the growing communist domination in Vietnam. At the time, French forces, allies of the U.S., were backed by America  President Harry S. Truman provided progressively increasing amounts of financial and military assistance to French forces fighting in Vietnam. From the spring of 1950, their involvement increased from just assisting French troops to providing direct military assistance to the associated states (Vietnam, Laos, Cambodia). Eventually, U.S. missions were carried out at a more constant rate by sending out increasing number of military assistance from the United States. Their main intent was to restrict the Communist domination that was present in the government of Vietnam as it would soon lead to a chain of neighbouring countries adopting the same. This would have resulted in a change in balance of power throughout Southeast Asia. Essentially, the U.S. saw their major security interests being disturbed due to the rise of the communist expansion and strived to take any measure to end it[1]. Estimates of the number of Vietnamese soldiers and civilians killed vary from 966,000[2] to 3,812,000.[3] The conflict also resulted in 58,318 US soldiers dead.[4]\\r\\n\\r\\n\\r\\nFeb 1965 - Operation Rolling Thunder begins\\r\\n\\r\\nIn 1961 the new administration of President John F. Kennedy remained essentially committed to the bi-partisan, anti-communist foreign policies inherited from the administrations of Presidents Truman and Eisenhower. During 1961, his first year in office, Kennedy found himself faced with a three-part crisis: The failure of the Bay of Pigs invasion in Cuba; the construction of the Berlin Wall by the Soviets; and a negotiated settlement between the pro-Western government of Laos and the Pathet Lao communist movement. Fearing that another failure on the part of the U.S. to stop communist expansion would fatally damage U.S. credibility with its allies, Kennedy realized, \\"Now we have a problem in making our power credible... and Vietnam looks like the place.\\"[15] The commitment to defend South Vietnam was reaffirmed by Kennedy on May 11 in National Security Action Memorandum 52, which became known as \\"The Presidential Program for Vietnam\\". Its opening statement reads:\\r\\nU.S. objectives and concept of operations [are] to prevent communist domination of South Vietnam; to create in that country a viable and increasingly democratic society, and to initiate, on an accelerated basis, a series of mutually supporting actions of a military, political, economic, psychological, and covert character designed to achieve this objective.[16]\\r\\nKennedy was intrigued by the idea of utilizing United States Army Special Forces for counterinsurgency conflicts in Third World countries threatened by the new \\"wars of national liberation\\". Originally intended for use behind front lines after a conventional invasion of Europe, Kennedy believed that the guerrilla tactics employed by Special Forces would be effective in the \\"brush fire\\" war in South Vietnam. He saw British success in using such forces during the Malayan Emergency as a strategic template. Thus in May 1961 Kennedy sent detachments of Green Berets to South Vietnam to train South Vietnamese soldiers in guerrilla warfare.\\r\\nThe Di?m regime had been initially able to cope with the insurgency of the National Front for the Liberation of South Vietnam (NLF, or derogatively, Viet Cong) in South Vietnam with the aid of U.S. matriel and advisers, and, by 1962, seemed to be gaining the upper hand. Senior U.S. military leaders received positive reports from the U.S. commander, General Paul D. Harkins of the Military Assistance Command, Vietnam, or MACV. By the following year, however, cracks began to appear in the fa?ade of success. In January a possible victory that was turned into a stunning defeat for government forces at the Battle of Ap Bac caused consternation among both the military advisers in the field and among politicians in Washington, D.C. JFK also indicated to Walter Cronkite that the war may be unwinnable, and that it was ultimately a Vietnamese war, not an American war.[17]\\r\\nDi?m was already growing unpopular with many of his countrymen because of his administration's nepotism, corruption, and its apparent bias in favor of the Catholic minorityof which Di?m was a partat the expense of the Buddhist majority. This contributed to the impression of Di?m's rule as an extension of the French Colonial regime. Promised land reforms were not instituted, and Di?m's strategic hamlet program for village self-defense (and government control) was a disaster. The Kennedy administration grew increasingly frustrated with Di?m. In 1963, a crackdown by Di?m's forces was launched against Buddhist monks protesting discriminatory practices and demanding a political voice. Di?m's repression of the protests sparked the so-called Buddhist Revolt, during which several monks committed self-immolation, which was covered in the world press. The communists took full advantage of the situation and fueled anti-Di?m sentiment to create further instability.\\r\\nOn July 27, 1964, 5,000 additional U.S. military advisers were ordered to the Republic of Vietnam (RVN or South Vietnam), bringing the total American troop level to 21,000. Shortly thereafter an incident occurred off the coast of the Democratic Republic of Vietnam (North Vietnam) that was destined to escalate the conflict to new levels and lead to the full scale Americanization of the war.\\r\\nOn the evening of August 2, 1964, the destroyer USS?Maddox was conducting an electronic intelligence collection mission in international waters (even as claimed by North Vietnam) in the Gulf of Tonkin when it was attacked by three P-4 torpedo boats of the North Vietnamese Navy.[18] Reports later reached the Johnson administration saying that the Maddox was under attack. Two nights later, after being joined by the destroyer C. Turner Joy, the Maddox again reported that both vessels were under attack (this event, which took place under adverse weather conditions, in fact never occurred).[citation needed] Regardless, President Johnson addressed Congress asking for more political power to utilize American military forces in South Vietnam, using the attack on the Maddox as cause to get what he wanted.\\r\\nThere was rampant confusion in Washington, but the incident was seen by the administration as the perfect opportunity to present Congress with \\"a pre-dated declaration of war\\" in order to strengthen weakening morale in South Vietnam through reprisal attacks by the U.S. on the North.[19] Even before confirmation of the phantom attack had been received in Washington, President Johnson had decided that an attack could not go unanswered.\\r\\nJust before midnight he appeared on television and announced that retaliatory air strikes were underway against North Vietnamese naval and port facilities. Neither Congress nor the American people learned the whole story about the events in the Gulf of Tonkin until the publication of the Pentagon Papers in 1969. It was on the basis of the administration's assertions that the attacks were \\"unprovoked aggression\\" on the part of North Vietnam, that the United States Congress approved the Southeast Asia Resolution (also known as the Gulf of Tonkin Resolution) on August 7. The law gave the President broad powers to conduct military operations without an actual declaration of war. The resolution passed unanimously in the House of Representatives and was opposed in the Senate by only two members.\\r\\nNational Security Council members, including United States Secretary of Defense Robert McNamara, Secretary of State Dean Rusk, and General Maxwell Taylor, agreed on November 28 to recommend that Johnson adopt a plan for a two-stage escalation of the bombing of North Vietnam.\\r\\nIn February 1965, a U.S. air base at Pleiku, in the Central Highlands of South Vietnam, was attacked twice by the NLF, resulting in the deaths of over a dozen U.S. personnel. These guerrilla attacks prompted the administration to order retaliatory air strikes against North Vietnam.\\r\\nOperation Rolling Thunder was the code name given to a sustained strategic bombing campaign targeted against the North by aircraft of the U.S. Air Force and Navy that was inaugurated on March 2, 1965. Its original purpose was to bolster the morale of the South Vietnamese and to serve as a signaling device to Hanoi. U.S. airpower would act as a method of \\"strategic persuasion\\", deterring the North Vietnamese politically by the fear of continued or increased bombardment. Rolling Thunder gradually escalated in intensity, with aircraft striking only carefully selected targets. When that did not work, its goals were altered to destroying North Vietnam's will to fight by destroying the nation's industrial base, transportation network, and its (continually increasing) air defenses. After more than a million sorties were flown and three-quarters of a million tons of bombs were dropped, Rolling Thunder was ended on November 11, 1968.[20]\\r\\nOther aerial campaigns (Operation Barrel Roll, Operation Steel Tiger, Operation Tiger Hound, and Operation Commando Hunt) were directed to counter the flow of men and material down the PAVN logistical system that flowed from North Vietnam through southeastern Laos, and into South Vietnam known as the Ho Chi Minh Trail.\\r\\nPresident Johnson had already appointed General William C. Westmoreland to succeed General Harkins as Commander of MACV in June 1964. Under Westmoreland, the expansion of American troop strength in South Vietnam took place. American forces rose from 16,000 during 1964 to more than 553,000 by 1969. With the U.S. decision to escalate its involvement, ANZUS Pact allies Australia and New Zealand agreed to contribute troops and matriel to the conflict. They were quickly joined by the Republic of Korea (second only to the Americans in troop strength), Thailand, and the Philippines. The U.S. paid for (through aid dollars) and logistically supplied all of the allied forces.\\r\\nMeanwhile, political affairs in Saigon were finally settling down  at least as far as the Americans were concerned. On February 14 the most recent military junta, the National Leadership Committee, installed Air Vice-Marshal Nguy?n Cao K? as prime minister. In 1966, the junta selected General Nguy?n V?n Thi?u to run for president with Ky on the ballot as the vice-presidential candidate in the 1967 election. Thieu and Ky were elected and remained in office for the duration of the war. In the presidential election of 1971, Thieu ran for the presidency unopposed. With the installation of the Thieu and Ky government (the Second Republic), the U.S. had a pliable, stable, and semi-legitimate government in Saigon with which to deal.\\r\\nWith the advent of Rolling Thunder, American airbases and facilities needed to be constructed and manned for the aerial effort. The defense of those bases would not be entrusted to the South Vietnamese. So, on March 8, 1965, 3,500 United States Marines came ashore at Da Nang as the first wave of U.S. combat troops into South Vietnam, adding to the 25,000 U.S. military advisers already in place. On May 5 the U.S. 173rd Airborne Brigade became the first U.S. Army ground unit committed to the conflict in South Vietnam. On August 18, Operation Starlite began as the first major U.S. ground operation, destroying an NLF stronghold in Qu?ng Ng?i Province. The NLF learned from their defeat and subsequently tried to avoid fighting an American-style ground war by reverting to small-unit guerrilla operations.\\r\\nThe North Vietnamese had already sent units of their regular army into southern Vietnam beginning in late 1964. Some officials in Hanoi had favored an immediate invasion of the South, and a plan was developed to use PAVN units to split southern Vietnam in half through the Central Highlands. The two imported adversaries first faced one another during Operation Silver Bayonet, better known as the Battle of the Ia Drang. During the savage fighting that took place, both sides learned important lessons. The North Vietnamese, who had taken horrendous casualties, began to adapt to the overwhelming American superiority in air mobility, supporting arms, and close air support by moving in as close as possible during confrontations, thereby negating the effects of the above. The Americans learned that PAVN (which was basically a light infantry force) was not a rag-tag band of guerrillas, but was instead a highly disciplined, proficient, and well motivated force.\\r\\nOn November 27, 1965, the Pentagon declared that if the major operations needed to neutralize North Vietnamese and NLF forces were to succeed, U.S. troop levels in South Vietnam would have to be increased from 120,000 to 400,000. In a series of meetings between Westmoreland and the President held in Honolulu in February 1966, Westmoreland argued that the U.S. presence had succeeded in preventing the immediate defeat of the South Vietnamese government but that more troops would be necessary if systematic offensive operations were to be conducted. The issue then became in what manner American forces would be used.\\r\\nThe nature of the American military's strategic and tactical decisions made during this period would color the conduct and nature of the conflict for the duration of the American commitment. Classical military logic demanded that the U.S. attack the locus of PAVN/NLF in the North. If that country could not be invaded, then the enemy's logistical system in Laos and Cambodia should be cut by ground forces, isolating the southern battlefield. However, political considerations limited U.S. military actions, mainly because of the memory of communist reactions during the Korean War. Ever present in the minds of diplomats, military officers, and politicians was the possibility of a spiraling escalation of the conflict into a superpower confrontation and the possibility of a nuclear exchange. Therefore, there would be no invasion of North Vietnam, the \\"neutrality\\" of Laos and Cambodia would be respected, and Rolling Thunder would not resemble the bombing of Germany and Japan during the Second World War.\\r\\nThese limitations were not foisted upon the military as an afterthought. Before the first U.S. soldiers came ashore at Da Nang, the Pentagon was cognizant of all of the parameters that would be imposed by their civilian leaders, yet they still agreed that the mission could be accomplished within them. Westmoreland believed that he had found a strategy that would either defeat North Vietnam or force it into serious negotiations. Attrition was to be the key. The general held that larger offensive operations would grind down the communists and eventually lead to a \\"crossover point\\" in PAVN/NLF casualties after which a decisive (or at least political) victory would be possible.\\r\\nIt is widely held that the average U.S. serviceman was nineteen years old, as evidenced by the casual reference in a pop song (\\"19\\" by Paul Hardcastle); the figure is cited by Lt. Col. Dave Grossman ret. of the Killology Research Group in his 1995 book On Killing: The Psychological Cost of Learning to Kill in War and Society (p.?265). However, it is disputed by the[21] Vietnam Helicopter Flight Crew Network Website, which claims the average age of MOS 11B personnel was 22. This compares with 26 years of age for those who participated in World War II. Soldiers served a one-year tour of duty. The average age of the U.S. military men who died in Vietnam was 22.8 years old.[22]\\r\\nThe one-year tour of duty deprived units of experienced leadership. As one observer put it, \\"we were not in Vietnam for 10 years, but for one year 10 times.\\"[23] As a result, training programs were shortened. Some NCOs were referred to as \\"Shake 'N' Bake\\" to highlight their accelerated training. Unlike soldiers in World War II and Korea, there were no secure rear areas in which to get rest and relaxation.[citation needed] One unidentified soldier said to United Press International that there was nothing to do in Vietnam and therefore many of the men smoked marijuana. He said, \\"One of the biggest reasons that a lot of GIs do get high over here is there is nothing to do. This place is really a drag; it's a bore over here. Like right now sitting around here, we are getting loaded. Whereas, it doesn't really get you messed up; that's I guess the main reason why we smoke it.\\"[24]\\r\\nAmerican forces would conduct operations against PAVN forces, pushing them further back into the countryside away from the heavily populated coastal lowlands. In the backcountry the U.S. could fully utilize its superiority in firepower and mobility to bleed the enemy in set-piece battles. The cleaning-out of the NLF and the pacification of the villages would be the responsibility of the South Vietnamese military. The adoption of this strategy, however, brought Westmoreland into direct conflict with his Marine Corps commander, General Lewis W. Walt, who had already recognized the security of the villages as the key to success. Walt had immediately commenced pacification efforts in his area of responsibility, but Westmoreland was unhappy, believing that the Marines were being underutilized and fighting the wrong enemy. In the end, MACV won out and Westmoreland's search and destroy concept, predicated on the attrition of enemy forces, won the day.\\r\\nBoth sides chose similar strategies. PAVN, which had been operating a more conventional, large-unit war, switched back to small-unit operations in the face of U.S. military capabilities. The struggle moved to the villages, where the \\"hearts and minds\\" of the South Vietnamese peasants, whose cooperation was absolutely necessary to military success, would be won or lost. The U.S. had given responsibility for this struggle to the Army of the Republic of Vietnam (ARVN), whose troops and commanders were notoriously unfit for the task.\\r\\nFor the American soldier, whose doctrine was one of absolute commitment to total victory, this strategy led to a frustrating small-unit war. Most of the combat was conducted by units smaller than battalion-size (the majority at the platoon level). Since the goal of the operations was to kill the enemy, terrain was not taken and held as in previous wars. Savage fighting and the retreat of the communists was immediately followed by the abandonment of the terrain just seized. Combined with this was the anger and frustration engendered among American troops by the effective tactics of the NLF, who conducted a war of sniping, booby traps, mines, and terror against the Americans.\\r\\nAs a result of the conference held in Honolulu, President Johnson authorized an increase in troop strength to 429,000 by August 1966. The large increase in troops enabled MACV to carry out numerous operations that grew in size and complexity during the next two years. For U.S. troops participating in these operations (Operation Masher/White Wing, Operation Attleboro, Operation Cedar Falls, Operation Junction City and dozens of others) the war boiled down to hard marching through some of the most difficult terrain on the planet and weather conditions that were alternately hot and dry, or cold and wet. It was the PAVN/NLF that actually controlled the pace of the war, fighting only when their commanders believed that they had the upper hand and then disappearing when the Americans and/or ARVN brought their superiority in numbers and firepower to bear. North Vietnam, utilizing the Ho Chi Minh and Sihanouk Trails, matched the U.S. at every point of the escalation, funneling manpower and supplies to the southern battlefields.\\r\\nDuring the Vietnam War, the use of the helicopter, known as \\"Air Mobile\\", was an essential tool for conducting the war. In fact, the whole conduct and strategy of the war depended on it. Vietnam was the first time the helicopter was used on a major scale, and in such important roles. Search and destroy missions, for example, would have been nearly impossible without it. Helicopters allowed American commanders to move large numbers of troops to virtually anywhere, regardless of the terrain or roads. Troops could also be easily resupplied in remote areas. The helicopter also provided another new and vital capability: medical evacuation. It could fly wounded soldiers to aid stations very quickly, usually within the critical first hour. This gave wounded soldiers a higher chance of survival in Vietnam than in any previous war. The helicopter was also adapted for many other roles in Vietnam, including ground attack, reconnaissance, and electronic warfare. Without the helicopter, the war would have been fought very differently.[25]\\r\\nBy mid-1967, Westmoreland said that it was conceivable that U.S. forces could be phased out of the war within two years, turning over progressively more of the fighting to the ARVN.[26] That fall, however, savage fighting broke out in the northern provinces. Beginning below the DMZ at Con Tien and then spreading west to the Laotian border near Dak To, large PAVN forces began to stand their ground and fight. This willingness of the communists to remain fixed in place inspired MACV to send reinforcements from other sectors of South Vietnam. The Border Battles had begun.\\r\\nMost of the PAVN/NLF operational capability was possible only because of the unhindered movement of men along the Ho Chi Minh Trail. To threaten this flow of supplies, the Marine Corps established a combat base on the South Vietnamese side of the Laotian frontier, near the village of Khe Sanh. The U.S. used the base as a border surveillance position overlooking Route 9, the only east-west road that crossed the border in the province. Westmoreland also hoped to use the base as a jump-off point for any future incursion against the Trail system in Laos. During the spring of 1967, a series of small-unit actions near Khe Sanh prompted MACV to increase its forces. These small unit actions and increasing intelligence information indicated that the PAVN was building up significant forces just across the border.\\r\\nIndeed, PAVN was doing just that. Two regular divisions (and later elements of a third) were moving toward Khe Sanh, eventually surrounding the base and cutting off its only road access. Westmoreland, contrary to the advice of his Marine commanders, reinforced the outpost. As far as he was concerned, if the communists were willing to mass their forces for destruction by American air power, so much the better. He described the ideal outcome as a \\"Dien Bien Phu in reverse\\". MACV then launched the largest concentrated aerial bombardment effort of the conflict (Operation Niagara) to defend Khe Sanh. Another massive aerial effort was undertaken to keep the beleaguered Marines supplied. There were many comparisons (by the media, Americans military and political officials, and the North Vietnamese) to the possibility of PAVN staging a repeat of its victory at Dien Bien Phu, but the differences outweighed the similarities in any comparison.\\r\\nMACV used this opportunity to field its latest technology against the North Vietnamese. A sensor-driven, anti-infiltration system known as Operation Igloo White was in the process of being field tested in Laos as the siege of Khe Sanh began. Westmoreland ordered that it be employed to detect PAVN troop movements near the Marine base and the system worked well. By March, the long-awaited ground assault against the base had failed to materialize and communist forces began to melt back toward Laos. MACV (and future historians) were left with only questions. What was the goal of the PAVN? Was the siege a real attempt to stage another Dien Bien Phu? Or had the battles near the border (which eventually drew in half of MACV's maneuver battalions) been a diversion, meant to pull forces away from the cities, where another PAVN offensive would soon commence?\\r\\nGeneral Westmoreland's public reassurances that \\"the light at the end of the tunnel\\" was near were countered when, on January 30, 1968, PAVN and NLF forces broke the truce that accompanied the T?t holiday and mounted their largest offensive thus far, in hopes of sparking a general uprising among the South Vietnamese. These forces, ranging in size from small groups to entire regiments, attacked nearly every city and major military installation in South Vietnam. The Americans and South Vietnamese, initially surprised by the scope and scale of the offensive, quickly responded and inflicted severe casualties on their enemies. The NLF was essentially eliminated as a fighting force and the places of the dead within its ranks were increasingly filled by North Vietnamese.\\r\\nThe PAVN/NLF attacks were speedily and bloodily repulsed in virtually all areas except Saigon, where the fighting lasted for three days, and in the old imperial capital of Hu?, where it continued for a month. During the occupation of the historic city, 2,800 South Vietnamese were murdered by the NLF in the single worst massacre of the conflict. The hoped-for uprising never took place; indeed, the offensive drove some previously apathetic South Vietnamese to fight for the government. Another surprise for the communists was that the ARVN did not collapse under the onslaught, instead turning in a performance that pleased even its American patrons.\\r\\nAfter the Tet Offensive, influential news magazines and newspapers, including the Wall Street Journal, Time and The New York Times, increasingly began to characterize the war as a stalemate. What shocked and dismayed the American public was the realization that either it had been lied to or that the American military command had been dangerously overoptimistic in its appraisal of the situation in Vietnam. The public could not understand how such an attack was possible after being told for several years that victory was just around the corner. The Tet Offensive came to embody the growing credibility gap at the heart of U.S. government statements. These realizations and changing attitudes forced the American public (and politicians) to face hard realities and to reexamine their position in Southeast Asia. Moreover, the U.S. media coverage made it even more clear that an overall victory in Vietnam was not imminent. It also massively weakened the domestic support for the Johnson administration at the time[27]. The days of an open-ended commitment to the conflict were over.\\r\\nThe psychological impact of the Tet Offensive effectively ended the political career of Lyndon Johnson. On March 11, Senator Eugene McCarthy won 42 percent of the vote in the Democratic New Hampshire primary. Although Johnson was not on the ballot, commentators viewed this as a defeat for the President. Shortly thereafter, Senator Robert Kennedy announced his intention to seek the Democratic nomination for the 1968 presidential election. On March 31, in a speech that took America and the world by surprise, Johnson announced that \\"I shall not seek, and I will not accept the nomination of my party for another term as your President\\" and pledged himself to devoting the rest of his term in office to the search for peace in Vietnam.[28] Johnson announced that he was limiting bombing of North Vietnam to just north of the Demilitarized Zone and that U.S. representatives were prepared to meet with North Vietnamese counterparts in any suitable place \\"to discuss the means to bring this ugly war to an end\\". A few days later, much to Johnson's surprise, North Vietnam agreed to contacts between the two sides. On May 13, what became known as the Paris peace talks began.[29]\\r\\nOn March 16, 1968, three companies of Task Force Barker, part of the Americal Division, took part in a search and destroy operation near the village of My Lai, in Qu?ng Nam Province. Although not all of the members of the company participated, a significant number of them, led by Calley, did. He personally ordered the executions of hundreds of villagers in large groups. The killings ended only when an American helicopter crew, headed by Warrant Officer Hugh Thompson, Jr., discovered Calley's unit in the act and threatened to attack them with his aircraft's weapons unless they stopped. One of the soldiers on the scene was Ron Haeberle, a photographer for the newspaper Stars and Stripes, who took unobtrusive official black-and-white photos of the operation through the lens of his military-issued camera and color shots of the massacre with his personal camera. Although the operation appeared suspicious to Calley's superiors, it was forgotten.\\r\\nIn 1969, investigative journalist Seymour Hersh exposed the My Lai massacre in print, and the Haeberle photos were released to the world media. The Pentagon launched an investigation headed by General William R. Peers to look into the allegations. After a flurry of activity, the Peers Commission issued its report. It declared that \\"an atmosphere of atrocity\\" surrounded the event, concluding that a massacre had taken place and the crime had been covered up by the commander of the Americal Division and his executive officer. Perhaps 400 Vietnamese civilians, mostly old men, women, and children had been killed by Charlie company. Several men were charged in the killings, but only Calley was convicted. He was given a life sentence by a court-martial in 1970, but after numerous appeals he was finally set free; he had served just over three years of house arrest.\\r\\nAlthough My Lai generated a lot of civilian recriminations and bad publicity for the military, it was not the only massacre. The Vietnam War Crimes Working Group Files made public in 1994 by the \\"Freedom of Information Act\\" reveal seven, albeit much smaller, massacres previously unacknowledged by the Pentagon, in which at least 137 civilians had died.[1] Cover-ups may have occurred in other cases, as detailed in the Pulitzer Prize-winning series of articles concerning the Tiger Force of the 101st Airborne Division by the Toledo Blade in 2003.\\r\\nRichard Nixon had campaigned in the 1968 presidential election under the slogan that he would end the war in Vietnam and bring \\"peace with honor\\". However, there was no plan to do this, and the American commitment continued for another five years. The goal of the American military effort was to buy time, gradually building up the strength of the South Vietnamese armed forces, and re-equipping it with modern weapons so that they could defend their nation on their own. This policy became the cornerstone of the so-called Nixon Doctrine. As applied to Vietnam, it was labeled Vietnamization.\\r\\nNixon's papers show that in 1968, as a presidential candidate, he ordered Anna Chennault, his liaison to the South Vietnam government, to persuade them to refuse a cease-fire being brokered by President Lyndon Johnson. This action violated the Logan Act, banning private citizens from intruding into official government negotiations with a foreign nation, and has been said to constitute treason.[30]\\r\\nSoon after Tet, General Westmoreland was promoted to Army Chief of Staff and he was replaced by his deputy, General Creighton W. Abrams. Because of the change in American strategy posed by Vietnamization, Abrams pursued a very different approach. The U.S. was gradually withdrawing from the conflict, and Abrams favored smaller-scale operations aimed at PAVN/NLF logistics, more openness with the media, less indiscriminate use of American firepower, elimination of the body count as the key indicator of battlefield success, and more meaningful cooperation with South Vietnamese forces.\\r\\nVietnamization of the war, however, created a dilemma for U.S. forces: the strategy required that U.S. troops fight long enough for the ARVN to improve enough to hold its own against Communist forces. Morale in the U.S. ranks rapidly declined during 1969ÿ1972, as evidenced by declining discipline, worsening drug use among soldiers, and increased \\"fraggings\\" of U.S. officers by disgruntled troops.\\r\\nOne of Nixon's main foreign policy goals had been the achievement of a breakthrough in U.S. relations with the People's Republic of China and the Soviet Union. An avowed anti-communist since early in his political career, Nixon could make diplomatic overtures to the communists without being accused of being \\"soft on communism\\". The result of his overtures was an era of dtente that led to nuclear arms reductions by the U.S. and Soviet Union and the beginning of a dialogue with China. In this context, Nixon viewed Vietnam as simply another limited conflict forming part of the larger tapestry of superpower relations; however, he was still determined to preserve South Vietnam until such time as he could not be blamed for what he saw as its inevitable collapse (or a \\"decent interval\\", as it was known). To this end he and National Security Advisor Henry Kissinger employed Chinese and Soviet foreign policy gambits to successfully defuse some of the anti-war opposition at home and secured movement at the negotiations that had begun in Paris.\\r\\nChina and the Soviet Union had been the principal backers of North Vietnam's effort through large-scale military and financial aid. The two communist superpowers had competed with one another to prove their \\"fraternal socialist links\\" with the regime in Hanoi. The North Vietnamese had become adept at playing the two nations off against one another. Even with Nixon's rapprochement, their support of North Vietnam increased significantly in the years leading up to the U.S. departure in 1973, enabling the North Vietnamese to mount full-scale conventional offensives against the South, complete with tanks, heavy artillery, and the most modern surface-to-air missiles.\\r\\nThe credibility of the U.S. government again suffered in 1971 when The New York Times, The Washington Post and other newspapers serially published The Pentagon Papers (actually U.S.-Vietnam Relations, 1945ÿ1967). This top-secret historical study of the American commitment in Vietnam, from the Franklin Roosevelt administration until 1967, had been contracted to the RAND Corporation by Secretary of Defense McNamara. The documents were leaked to the press by Daniel Ellsberg, a former State Department official who had worked on the study.\\r\\nThe Pentagon Papers laid out the missteps taken by four administrations in their Vietnam policies. For example, they revealed the Johnson administration's obfuscations to Congress concerning the Gulf of Tonkin incidents that had led to direct U.S. intervention; they exposed the clandestine bombing of Laos that had begun in 1964; and they detailed the American government's complicity in the death of Ng? ?nh Di?m. The study presented a continuously pessimistic view of the likelihood of victory and generated fierce criticism of U.S. policies.\\r\\nThe importance of the actual content of the papers to U.S. policy-making was disputed, but the window that they provided into the flawed decision-making process at the highest levels of the U.S. government opened the issue for other questions. Their publication was a news event and the government's legal (Nixon lost to the Supreme Court) and extra-legal efforts (the \\"Plumbers\\" break-in at the office of Ellsberg's psychiatrist committed to gain material to discredit him, was one of the first steps on the road to Watergate) carried out to prevent their publicationmainly on national security groundsthen went on to generate yet more criticism and suspicion of the government by the American public.\\r\\nBy 1969 the policy of non-alignment and neutrality had worn thin for Prince Sihanouk, ruler of Cambodia. Pressures from the right in Cambodia caused the prince to begin a shift away from the pro-left position he had assumed in 1965ÿ1966. He began to make overtures for normalized relations with the U.S. and created a Government of National Salvation with the assistance of the pro-American General Lon Nol. Seeing a shift in the prince's position, President Nixon ordered the launching of a top-secret bombing campaign, targeted at the PAVN/NLF Base Areas and sanctuaries along Cambodia's eastern border.\\r\\nOn March 18, 1970, Sihanouk, who was out of the country on a state visit, was deposed by a vote of the National Assembly and replaced by General Lon Nol. Cambodia's ports were immediately closed to North Vietnamese military supplies, and the government demanded that PAVN/NLF forces be removed from the border areas within 72 hours. On March 29, 1970, the Vietnamese had taken matters into their own hands and launched an offensive against the Cambodian army. A force of North Vietnamese quickly overran large parts of eastern Cambodia reaching to within 15 miles (24?km) of Phnom Penh allowing their allies, the Chinese-supported Khmer Rouge to extend their power. Nixon ordered a military incursion into Cambodia by U.S. and ARVN troops in order to both destroy PAVN/NLF sanctuaries bordering South Vietnam and to buy time for the U.S. withdrawal. During the Cambodian Campaign, U.S. and ARVN forces discovered and removed or destroyed a huge logistical and intelligence haul in Cambodia.\\r\\nThe incursion also sparked large-scale demonstrations on and closures of American college campuses. The expansion of the conflict into Cambodia was seen as an expansion of the conflict into yet another country, nullifying Nixon's promises of de-escalating the war. During the ensuing protests, four students were killed and a score were wounded by Ohio National Guardsmen during a demonstration at Kent State University. Two other students were killed at Jackson State University in Mississippi. In an effort to lessen opposition to the U.S. commitment, Nixon announced on October 12 that the U.S. would withdraw 40,000 more troops from Vietnam before Christmas.\\r\\nFollowing the coup, Sihanouk arrived in Beijing, where he established and headed a government in exile, throwing his substantial personal support behind the Khmer Rouge, the North Vietnamese, and the Laotian Pathet Lao.\\r\\nIn 1971 the U.S. authorized the ARVN to carry out an offensive operation aimed at cutting the Ho Chi Minh Trail in southeastern Laos. Besides attacking the PAVN logistical system (which would buy time for the U.S. withdrawal) the incursion would be a significant test of Vietnamization. Backed by U.S. air and artillery support (American troops were forbidden to enter Laos), the ARVN moved across the border along Route 9, utilizing the abandoned Marine outpost of Khe Sanh as a jumping-off point. At first, the incursion went well, but unlike the Cambodian operation of 1970, the PAVN decided to stand and fight, finally mustering around 60,000 men on the battlefield.\\r\\nThe North Vietnamese first struck the flanks of the ARVN column, smashed its outposts, and then moved in on the main ARVN force. Unlike previous encounters during the conflict, the PAVN fielded armored formations, heavy artillery, and large amounts of the latest anti-aircraft artillery. After two months of savage fighting, the ARVN retreated back across the border, closely pursued by the North Vietnamese. One half of the invasion force was killed or captured during the operation, and Vietnamization was seen as a failure.\\r\\nOn August 18, Australia and New Zealand decided to withdraw their troops from the conflict. The total number of U.S. forces in South Vietnam dropped to 196,700 on October 29, 1971, the lowest level since January 1966. On November 12, 1971, Nixon set a February 1, 1972 deadline for the removal of another 45,000 troops.\\r\\nVietnamization received another severe test in the spring of 1972 when the North Vietnamese launched a massive conventional offensive across the Demilitarized Zone. Beginning on March 30, the Easter Offensive (known as the Nguy?n Hu? Offensive to the North Vietnamese) quickly overran the three northernmost provinces of South Vietnam, including the provincial capital of Qu?ng Tr? City. PAVN forces then drove south toward Hu?.\\r\\nEarly in April, PAVN opened two additional operations. The first, a three-division thrust supported by tanks and heavy artillery, advanced out of Cambodia on April 5. The North Vietnamese seized the town of Loc Ninh and advanced toward the provincial capital of An L?c in Bnh Long Province. The second new offensive, launched from the tri-border region into the Central Highlands, seized a complex of ARVN outposts near Dak To and then advanced toward Kon Tum, threatening to split South Vietnam in two.\\r\\nThe U.S. countered with a buildup of American airpower to support ARVN defensive operations and to conduct Operation Linebacker, the first offensive bombing of North Vietnam since Rolling Thunder had been terminated in 1968. The PAVN attacks against Hu?, An L?c, and Kon Tum were contained and the ARVN launched a counteroffensive in May to retake the lost northern provinces. On September 10, the South Vietnamese flag once again flew over the ruins of the Citadel of Qu?ng Tr? City, but the ARVN offensive then ran out of steam, conceding the rest of the occupied territory to the North Vietnamese. South Vietnam had countered the heaviest attack since Tet, but it was very evident that it was totally dependent on U.S. airpower for its survival. Meanwhile, the withdrawal of American troops, who numbered less than 100,000 at the beginning of the year, was continued as scheduled. By June only six infantry battalions remained. On August 12, the last American ground combat division left the country. However, the U.S. continued to operate the base At Long Binh. Combat patrols continued there until November 11 when the U.S. handed over the base to the South Vietnamese. After this, only 24,000 American troops remained in Vietnam and President Nixon announced that they would stay there until all U.S. POW's were freed.\\r\\nAt the beginning of the North Vietnamese invasion, the media, including conservative commentator William F. Buckley, predicted the downfall of the Republic of Vietnam; Buckley even called for the firing of General Creighton Abrams as an incompetent military leader. But the ARVN succeeded in defeating General Giap and his huge invading army. His forces were shattered at the Battle of An L?c, where he threw several divisions at the entrenched South Vietnamese forces, ultimately losing over half of his army as casualties. General Giap's loss and subsequent retreat was viewed as so great a failure by the North Vietnamese Communist Party that Giap was relieved of his command. Although ARVN troops withstood and repelled the massive PAVN attack at An L?c, American air power seems to have been a key to the ARVN success, just as it had been a key factor in supporting U.S. ground forces when they operated in South Vietnam prior to 1972. Thus, the 1973 withdrawal of U.S. military support and passage of Congressional resolutions cutting off U.S. funding for combat activities in Indochina (H.R. 9055 and H.J.Res. 636) opened the way for the 1975 defeat of the Republic of Vietnam.\\r\\nDuring the run-up to the 1972 presidential election, the war was once again a major issue. An antiwar Democrat, George McGovern, ran against President Nixon. The president ended Operation Linebacker on October 22 after the negotiating deadlock was broken and a tentative agreement had been hammered out by U.S. and North Vietnamese representatives at the peace negotiations in Paris. The head of the U.S. negotiating team, Henry Kissinger, declared that \\"peace is at hand\\" shortly before election day, dealing a death blow to McGovern's already doomed campaign. Kissinger had not, however, counted on the intransigence of South Vietnamese President Thieu, who refused to accept the agreement and demanded some 90 changes in its text. These the North Vietnamese refused to accept, and Nixon was not inclined to put too much pressure on Thieu just before the election, even though his victory was all but assured. The mood between the U.S. and North further turned sour when Hanoi went public with the details of the agreement. The Nixon Administration claimed that North Vietnamese negotiators had used the pronouncement as an opportunity to embarrass the President and to weaken the United States. White House Press Secretary Ron Ziegler told the press on November 30 that there would be no more public announcements concerning U.S. troop withdrawals from Vietnam since force levels were down to 27,000.\\r\\nBecause of Thieu's unhappiness with the agreement, primarily the stipulation that North Vietnamese troops could remain \\"in place\\" on South Vietnamese soil, the negotiations in Paris stalled as Hanoi refused to accept Thieu's changes and retaliated with amendments of its own. To reassure Thieu of American resolve, Nixon ordered a massive bombing campaign against North Vietnam utilizing B-52s and tactical aircraft in Operation Linebacker II, which began on December 18 with large raids against both Hanoi and the port of Haiphong. Nixon justified his actions by blaming the impasse in negotiations on the North Vietnamese, causing one commentator to describe his actions as \\"War by tantrum\\". Although this heavy bombing campaign caused protests, both domestically and internationally, and despite significant aircraft losses over North Vietnam, Nixon continued the operation until December 29. He also exerted pressure on Thieu to accept the terms of the agreement reached in October.\\r\\nOn January 15, 1973, citing progress in peace negotiations, Nixon announced the suspension of all offensive actions against North Vietnam, to be followed by a unilateral withdrawal of all U.S. troops. The Paris Peace Accords on \\"Ending the War and Restoring Peace in Vietnam\\" were signed on January 27, officially ending direct U.S. involvement in the Vietnam War.\\r\\nThe agreement called for the withdrawal of all U.S. personnel and an exchange of prisoners of war. Within South Vietnam, a cease-fire was declared (to be overseen by a multi-national, 1,160-man International Control Commission force) and both ARVN and PAVN/NLF forces would remain in control of the areas they then occupied, effectively partitioning South Vietnam. Both sides pledged to work toward a compromise political solution, possibly resulting in a coalition government. To maximize the area under their control, both sides in South Vietnam almost immediately engaged in land-grabbing military operations, which turned into flashpoints. The signing of the Accords was the main motivation for the awarding of the 1973 Nobel Peace Prize to Henry Kissinger and to leading North Vietnamese negotiator Le Duc Tho. A separate cease-fire had been installed in Laos in February. Five days before the signing of the agreement in Paris, President Lyndon Johnson, whose presidency had been tainted with the Vietnam issue, died.\\r\\nThe first U.S. prisoners of war were released by North Vietnam on February 11, and all U.S. military personnel were ordered to leave South Vietnam by March 29. As an inducement for Thieu's government to sign the agreement, Nixon had promised that the U.S. would provide financial and limited military support (in the form of air strikes) so that the South would not be overrun. But Nixon was fighting for his political life in the growing Watergate scandal and facing an increasingly hostile Congress that withheld funding. The President was able to exert little influence on a hostile public long sick of the Vietnam War.\\r\\nThus, Nixon (or his successor Gerald Ford) was unable to fulfill his promises to Thieu. At the same time, aid to North Vietnam from the Soviet Union increased. With the U.S. no longer heavily involved, both the U.S. and the Soviet Union no longer saw the war as significant to their relations. The balance of power shifted decisively in North Vietnam's favor, and the North subsequently launched a major military offensive, the Ho Chi Minh Campaign, against the South that culminated in the surrender of the Republic of Vietnam to PAVN forces on April 30, 1975.\\r\\nThe Office of the Secretary of Defense & Joint Staff, FOIA Requester Service Center\\r\\nForeign Relations Series\\r\\nUnder Eisenhower\\r\\nUnder Kennedy\\r\\nUnder Johnson\\r\\nUnder Nixon\\r\\nUnder Ford","input":"When were the us involved in the vietnam war?"},{"output":"the defence of Australia","context":"","input":"What is the role of the australian defence force?"},{"output":"chromosomal translocation","context":"Fusion proteins or chimeric (\\\\kؐ-?mir-ik) proteins (literally, made of parts from different sources) are proteins created through the joining of two or more genes that originally coded for separate proteins. Translation of this fusion gene results in a single or multiple polypeptides with functional properties derived from each of the original proteins. Recombinant fusion proteins are created artificially by recombinant DNA technology for use in biological research or therapeutics. Chimeric or chimera usually designate hybrid proteins made of polypeptides having different functions or physico-chemical patterns. Chimeric mutant proteins occur naturally when a complex mutation, such as a chromosomal translocation, tandem duplication, or retrotransposition creates a novel coding sequence containing parts of the coding sequences from two different genes. Naturally occurring fusion proteins are commonly found in cancer cells, where they may function as oncoproteins. The bcr-abl fusion protein is a well-known example of an oncogenic fusion protein, and is considered to be the primary oncogenic driver of chronic myelogenous leukemia.\\r\\n\\r\\n\\r\\nSome fusion proteins combine whole peptides and therefore contain all functional domains of the original proteins. However, other fusion proteins, especially those that occur naturally, combine only portions of coding sequences and therefore do not maintain the original functions of the parental genes that formed them.\\r\\nMany whole gene fusions are fully functional and can still act to replace the original peptides. Some, however, experience interactions between the two proteins that can modify their functions. Beyond these effects, some gene fusions may cause regulatory changes that alter when and where these genes act. For partial gene fusions, the shuffling of different active sites and binding domains have potential to result in new proteins with novel functions.\\r\\nA recombinant fusion protein is a protein created through genetic engineering of a fusion gene. This typically involves removing the stop codon from a cDNA sequence coding for the first protein, then appending the cDNA sequence of the second protein in frame through ligation or overlap extension PCR. That DNA sequence will then be expressed by a cell as a single protein. The protein can be engineered to include the full sequence of both original proteins, or only a portion of either.\\r\\nIf the two entities are proteins, often linker (or \\"spacer\\") peptides are also added, which make it more likely that the proteins fold independently and behave as expected. Especially in the case where the linkers enable protein purification, linkers in protein or peptide fusions are sometimes engineered with cleavage sites for proteases or chemical agents that enable the liberation of the two separate proteins. This technique is often used for identification and purification of proteins, by fusing a GST protein, FLAG peptide, or a hexa-his peptide (6xHis-tag), which can be isolated using affinity chromatography with nickel or cobalt resins. Di- or multimeric chimeric proteins can be manufactured through genetic engineering by fusion to the original proteins of peptide domains that induce artificial protein di- or multimerization (e.g., streptavidin or leucine zippers). Fusion proteins can also be manufactured with toxins or antibodies attached to them in order to study disease development.\\r\\nThe purpose of creating fusion proteins in drug development is to impart properties from each of the \\"parent\\" proteins to the resulting chimeric protein. Several chimeric protein drugs are currently available for medical use.\\r\\nMany chimeric protein drugs are monoclonal antibodies whose specificity for a target molecule was developed using mice and hence were initially \\"mouse\\" antibodies. As non-human proteins, mouse antibodies tend to evoke an immune reaction if administered to humans. The chimerization process involves engineering the replacement of segments of the antibody molecule that distinguish it from a human antibody. For example, human constant domains can be introduced, thereby eliminating most of the potentially immunogenic portions of the drug without altering its specificity for the intended therapeutic target. Antibody nomenclature indicates this type of modification by inserting -xi- into the non-proprietary name (e.g., abci-xi-mab). If parts of the variable domains are also replaced by human portions, humanized antibodies are obtained. Although not conceptually distinct from chimeras, this type is indicated using -zu- such as in dacli-zu-mab. See the list of monoclonal antibodies for more examples.\\r\\nIn addition to chimeric and humanized antibodies, there are other pharmaceutical purposes for the creation of chimeric constructs. Etanercept, for example, is a TNFϫ blocker created through the combination of a tumor necrosis factor receptor (TNFR) with the immunoglobulin G1 Fc segment. TNFR provides specificity for the drug target and the antibody Fc segment is believed to add stability and deliverability of the drug.\\r\\nNaturally occurring fusion genes are most commonly created when a chromosomal translocation replaces the terminal exons of one gene with intact exons from a second gene. This creates a single gene that can be transcribed, spliced, and translated to produce a functional fusion protein. Many important cancer-promoting oncogenes are fusion genes produced in this way.\\r\\nExamples include:\\r\\nAntibodies are fusion proteins produced by V(D)J recombination.","input":"What type of mutation produces the bcr-abl chimeric protein?"},{"output":"approximately 78% nitrogen, 21% oxygen, and 1%","context":"Liquid air is air that has been cooled to very low temperatures (cryogenic temperatures), so that it has condensed into a pale blue mobile liquid.[1] To protect it from room temperature, it must be kept in a vacuum insulated flask. Liquid air can absorb heat rapidly and revert to its gaseous state. It is often used for condensing other substances into liquid and/or solidifying them, and as an industrial source of nitrogen, oxygen, argon, and other inert gases through a process called air separation.\\r\\n\\r\\n\\r\\nLiquid air has a density of approximately 870?kg/m3 (0.87 g/cm3), though the density may vary depending on the elemental composition of the air. Since dry gaseous air contains approximately 78% nitrogen, 21% oxygen, and 1% argon, the density of liquid air at standard composition is calculated by the percentage of the components and their respective liquid densities (see liquid nitrogen and liquid oxygen). Although air contains trace amounts of carbon dioxide (about 0.040%), this gas sublimates (transfers directly between gas and solid, and therefore does not exist as a liquid) at pressures less than 5.1 atmospheres.\\r\\nThe boiling point of liquid air is -194.35?C, intermediate between the boiling points of liquid nitrogen and liquid oxygen. However, it can be difficult to keep at a stable temperature as the liquid boils, since the nitrogen will boil off first, leaving the mixture oxygen-rich and changing the boiling point. This may also occur in some circumstances due to the liquid air condensing oxygen out of the atmosphere.[2]\\r\\nLiquid air freezes at approximately 58 K (-215?C)(-355 F), also at standard atmospheric pressure.[citation needed]\\r\\nThe constituents of air were once known as \\"permanent gases\\", as they could not be liquified solely by compression at room temperature. A compression process will raise the temperature of the gas. This heat is removed by cooling to the ambient temperature in a heat exchanger, and then expanding by venting into a chamber. The expansion causes a lowering of the temperature, and by counter-flow heat exchange of the expanded air, the pressurized air entering the expander is further cooled. With sufficient compression, flow, and heat removal, eventually droplets of liquid air will form, which may then be employed directly for low temperature demonstrations.\\r\\nThe main constituents of air were liquefied for the first time by Polish scientists Zygmunt Florenty Wr܇blewski and Karol Olszewski in 1883.\\r\\nDevices for the production of liquid air are simple enough to be fabricated by the experimenter using commonly available materials.\\r\\nThe most common process for the preparation of liquid air is the two-column HampsonÿLinde cycle using the JouleÿThomson effect. Air is fed at high pressure (>60 psig, or 520 kPa) into the lower column, in which it is separated into pure nitrogen and oxygen-rich liquid. The rich liquid and some of the nitrogen are fed as reflux into the upper column, which operates at low pressure (<10 psig, or 170 kPa), where the final separation into pure nitrogen and oxygen occurs. A raw argon product can be removed from the middle of the upper column for further purification.[3]\\r\\nIn manufacturing processes, the liquid air product is fractionated into its constituent gases in either liquid or gaseous form, as the oxygen is especially useful for fuel gas welding and cutting, and the argon is useful as an oxygen-excluding shielding gas in gas tungsten arc welding. Liquid nitrogen is useful in various low-temperature applications, being nonreactive at normal temperatures (unlike oxygen), and boiling at 77?K (?196?C; ?321?F).\\r\\nDuring World War II, Nazi Germany's nuclear scientists reportedly experimented with a bomb made from liquid air and coal dust.[4]\\r\\nBetween 1899 and 1902, the automobile Liquid Air was produced and demonstrated by a joint American/English company, with the claim that they could construct a car that would run a hundred miles on liquid air.\\r\\nOn 2 October 2012, the Institution of Mechanical Engineers said liquid air could be used as a means of storing energy. This was based on a technology that was developed by Peter Dearman, a garage inventor in Hertfordshire, England to power vehicles.[5]","input":"What is the ratio of gases in air?"},{"output":"English","context":"Coordinates: 2415N 7600W? / ?24.250N 76.000W? / 24.250; -76.000\\r\\nThe Bahamas (/b??h?m?z/?(?listen)), known officially as the Commonwealth of The Bahamas,[11] is an archipelagic state within the Lucayan Archipelago. It consists of more than 700 islands, cays, and islets in the Atlantic Ocean, and is located north of Cuba and Hispaniola (Haiti and the Dominican Republic), northwest of the Turks and Caicos Islands, southeast of the United States state of Florida, and east of the Florida Keys. The capital is Nassau on the island of New Providence. The designation of \\"the Bahamas\\" can refer either to the country or to the larger island chain that it shares with the Turks and Caicos Islands. As stated in the mandate/manifesto of the Royal Bahamas Defence Force, the Bahamas territory encompasses 470,000?km2 (180,000?sq?mi) of ocean space.\\r\\nThe Bahamas is the site of Columbus' first landfall in the New World in 1492. At that time, the islands were inhabited by the Lucayan, a branch of the Arawakan-speaking Taino people. Although the Spanish never colonised The Bahamas, they shipped the native Lucayans to slavery in Hispaniola. The islands were mostly deserted from 1513 until 1648, when English colonists from Bermuda settled on the island of Eleuthera.\\r\\nThe Bahamas became a British crown colony in 1718, when the British clamped down on piracy. After the American War of Independence, the Crown resettled thousands of American Loyalists in the Bahamas; they brought their slaves with them and established plantations on land grants. Africans constituted the majority of the population from this period. The slave trade was abolished by the British in 1807; slavery in the Bahamas was abolished in 1834. The Bahamas became a haven for freed African slaves; the Royal Navy resettled Africans here liberated from illegal slave ships, American slaves and Seminoles escaped here from Florida, and the government freed American slaves carried on United States domestic ships that had reached the Bahamas due to weather. Today, Afro-Bahamians make up nearly 90% of the population.\\r\\nThe Bahamas became an independent Commonwealth realm in 1973, retaining the British monarch, then and currently Queen Elizabeth II, as its head of state. In terms of gross domestic product per capita, The Bahamas is one of the richest countries in the Americas (following the United States and Canada), with an economy based on tourism and finance.[12]\\r\\n\\r\\n\\r\\nThe name Bahamas is mostly likely derived from either the Tano ba ha ma (\\"big upper middle land\\"), which was a term for the region used by the indigenous Native Americans,[13] or possibly from the Spanish baja mar (\\"shallow water or sea\\" or \\"low tide\\") reflecting the shallow waters of the area. Alternatively, it may originate from Guanahani, a local name of unclear meaning.[14]\\r\\nA peculiarity of the name is that the word The is a formal part of the abbreviated name and is, therefore, capitalised. So in contrast to \\"the Congo\\" and \\"the United Kingdom\\", it is proper to write \\"The Bahamas\\".\\r\\nTaino people moved into the uninhabited southern Bahamas from Hispaniola and Cuba around the 11th century, having migrated there from South America. They came to be known as the Lucayan people. An estimated 30,000 Lucayan inhabited the Bahamas at the time of Christopher Columbus' arrival in 1492.\\r\\nColumbus's first landfall in the New World was on an island he named San Salvador (known to the Lucayan as Guanahani). Some researchers believe this site to be present-day San Salvador Island (formerly known as Watling's Island), situated in the southeastern Bahamas. An alternative theory holds that Columbus landed to the southeast on Samana Cay, according to calculations made in 1986 by National Geographic writer and editor Joseph Judge, based on Columbus's log. Evidence in support of this remains inconclusive. On the landfall island, Columbus made first contact with the Lucayan and exchanged goods with them.\\r\\nThe Spanish forced much of the Lucayan population to Hispaniola for use as forced labour. The slaves suffered from harsh conditions and most died from contracting diseases to which they had no immunity; half of the Taino died from smallpox alone.[16] The population of the Bahamas was severely diminished.[17]\\r\\nIn 1648, the Eleutherian Adventurers, led by William Sayle, migrated from Bermuda. These English Puritans established the first permanent European settlement on an island which they named Eleutherathe name derives from the Greek word for freedom. They later settled New Providence, naming it Sayle's Island after one of their leaders. To survive, the settlers salvaged goods from wrecks.\\r\\nIn 1670, King Charles II granted the islands to the Lords Proprietors of the Carolinas in North America. They rented the islands from the king with rights of trading, tax, appointing governors, and administering the country.[18] In 1684 Spanish corsair Juan de Alcon raided the capital, Charles Town (later renamed Nassau). In 1703, a joint Franco-Spanish expedition briefly occupied the Bahamian capital during the War of the Spanish Succession.\\r\\nDuring proprietary rule, the Bahamas became a haven for pirates, including the infamous Blackbeard (circa 1680ÿ1718). To put an end to the 'Pirates' republic' and restore orderly government, Britain made the Bahamas a crown colony in 1718 under the royal governorship of Woodes Rogers. After a difficult struggle, he succeeded in suppressing piracy.[19] In 1720, Rogers led local militia to drive off a Spanish attack.\\r\\nDuring the American War of Independence in the late 18th century, the islands became a target for American naval forces under the command of Commodore Esek Hopkins. US Marines occupied the capital of Nassau for a fortnight.\\r\\nIn 1782, following the British defeat at Yorktown, a Spanish fleet appeared off the coast of Nassau. The city surrendered without a fight. Spain returned possession of the Bahamas to Britain the following year, under the terms of the Treaty of Paris. Before the news was received, however, the islands were recaptured by a small British force led by Andrew Deveaux.\\r\\nAfter American independence, the British resettled some 7,300 Loyalists with their slaves in the Bahamas, and granted land to the planters to help compensate for losses on the continent. These Loyalists, who included Deveaux, established plantations on several islands and became a political force in the capital. European Americans were outnumbered by the African-American slaves they brought with them, and ethnic Europeans remained a minority in the territory.\\r\\nIn 1807, the British abolished the slave trade, followed by the United States the next year. During the following decades, the Royal Navy intercepted the trade; they resettled in the Bahamas thousands of Africans liberated from slave ships.\\r\\nIn the 1820s during the period of the Seminole Wars in Florida, hundreds of American slaves and African Seminoles escaped from Cape Florida to the Bahamas. They settled mostly on northwest Andros Island, where they developed the village of Red Bays. From eyewitness accounts, 300 escaped in a mass flight in 1823, aided by Bahamians in 27 sloops, with others using canoes for the journey. This was commemorated in 2004 by a large sign at Bill Baggs Cape Florida State Park.[20][21] Some of their descendants in Red Bays continue African Seminole traditions in basket making and grave marking.[22]\\r\\nThe United States' National Park Service, which administers the National Underground Railroad Network to Freedom, is working with the African Bahamian Museum and Research Center (ABAC) in Nassau on development to identify Red Bays as a site related to American slaves' search for freedom. The museum has researched and documented the African Seminoles' escape from southern Florida. It plans to develop interpretive programs at historical sites in Red Bay associated with the period of their settlement in the Bahamas.[23]\\r\\nIn 1818,[24] the Home Office in London had ruled that \\"any slave brought to the Bahamas from outside the British West Indies would be manumitted.\\" This led to a total of nearly 300 slaves owned by US nationals being freed from 1830 to 1835.[25] The American slave ships Comet and Encomium used in the United States domestic coastwise slave trade, were wrecked off Abaco Island in December 1830 and February 1834, respectively. When wreckers took the masters, passengers and slaves into Nassau, customs officers seized the slaves and British colonial officials freed them, over the protests of the Americans. There were 165 slaves on the Comet and 48 on the Encomium. Britain finally paid an indemnity to the United States in those two cases in 1855, under the Treaty of Claims of 1853, which settled several compensation cases between the two nations.[26][27]\\r\\nSlavery was abolished in the British Empire on 1 August 1834. After that British colonial officials freed 78 American slaves from the Enterprise, which went into Bermuda in 1835; and 38 from the Hermosa, which wrecked off Abaco Island in 1840.[28] The most notable case was that of the Creole in 1841: as a result of a slave revolt on board, the leaders ordered the American brig to Nassau. It was carrying 135 slaves from Virginia destined for sale in New Orleans. The Bahamian officials freed the 128 slaves who chose to stay in the islands. The Creole case has been described as the \\"most successful slave revolt in U.S. history\\".[29]\\r\\nThese incidents, in which a total of 447 slaves belonging to US nationals were freed from 1830 to 1842, increased tension between the United States and Great Britain. They had been co-operating in patrols to suppress the international slave trade. But, worried about the stability of its large domestic slave trade and its value, the United States argued that Britain should not treat its domestic ships that came to its colonial ports under duress, as part of the international trade. The United States worried that the success of the Creole slaves in gaining freedom would encourage more slave revolts on merchant ships.\\r\\nIn August 1940, the Duke of Windsor was appointed Governor of the Bahamas. He arrived in the colony with his wife, the Duchess. Although disheartened at the condition of Government House, they \\"tried to make the best of a bad situation\\".[30] He did not enjoy the position, and referred to the islands as \\"a third-class British colony\\".[31]\\r\\nHe opened the small local parliament on 29 October 1940. The couple visited the \\"Out Islands\\" that November, on Axel Wenner-Gren's yacht, which caused controversy;[32] the British Foreign Office strenuously objected because they had been advised (mistakenly) by United States intelligence that Wenner-Gren was a close friend of the Luftwaffe commander Hermann G?ring of Nazi Germany.[32][33]\\r\\nThe Duke was praised at the time for his efforts to combat poverty on the islands. A 1991 biography by Philip Ziegler, however, described him as contemptuous of the Bahamians and other non-European peoples of the Empire. He was praised for his resolution of civil unrest over low wages in Nassau in June 1942, when there was a \\"full-scale riot\\".[34] Ziegler said that the Duke blamed the trouble on \\"mischief makers ÿ communists\\" and \\"men of Central European Jewish descent, who had secured jobs as a pretext for obtaining a deferment of draft\\".[35]\\r\\nThe Duke resigned the post on 16 March 1945.[36][37]\\r\\nModern political development began after the Second World War. The first political parties were formed in the 1950s. The British Parliament authorised the islands as internally self-governing in 1964, with Sir Roland Symonette, of the United Bahamian Party, as the first Premier.\\r\\nA new constitution granting the Bahamas internal autonomy went into effect on 7 January 1964.[38] In 1967, Lynden Pindling of the Progressive Liberal Party, became the first native born Premier of the majority native Bahamian colony; in 1968 the title of the position was changed to Prime Minister. In 1968, Pindling announced that the Bahamas would seek full independence.[39] A new constitution giving the Bahamas increased control over its own affairs was adopted in 1968.[40]\\r\\nThe British House of Lords voted to give the Bahamas its independence on 22 June 1973.[41] Prince Charles delivered the official documents to Prime Minister Lynden Pindling, officially declaring the Bahamas a fully independent nation on 10 July 1973.[42] It joined the Commonwealth of Nations on the same day.[43] Sir Milo Butler was appointed the first Governor-General of the Bahamas (the official representative of Queen Elizabeth II) shortly after independence. The Bahamas joined the International Monetary Fund and the World Bank on 22 August 1973,[44] and it joined the United Nations on 18 September 1973.[45]\\r\\nBased on the twin pillars of tourism and offshore finance, the Bahamian economy has prospered since the 1950s. Significant challenges in areas such as education, health care, housing, international narcotics trafficking and illegal immigration from Haiti continue to be issues.\\r\\nThe University of The Bahamas (UB) is the national higher education/tertiary system. Offering baccalaureate, masters and associate degrees, UB has three campuses, and teaching and research centres throughout the Bahamas. The University of the Bahamas was chartered on November 10, 2016.\\r\\nThe country lies between latitudes 20 and 28N, and longitudes 72 and 80W.\\r\\nIn 1864, the Governor of the Bahamas reported that there were 29 islands, 661 cays, and 2,387 rocks in the colony.[46]\\r\\nThe closest island to the United States is Bimini, which is also known as the gateway to the Bahamas. The island of Abaco is to the east of Grand Bahama. The southeasternmost island is Inagua. The largest island is Andros Island. Other inhabited islands include Eleuthera, Cat Island, Rum Cay, Long Island, San Salvador Island, Ragged Island, Acklins, Crooked Island, Exuma, Berry Islands and Mayaguana. Nassau, capital city of the Bahamas, lies on the island of New Providence.\\r\\nAll the islands are low and flat, with ridges that usually rise no more than 15 to 20?m (49 to 66?ft). The highest point in the country is Mount Alvernia (formerly Como Hill) on Cat Island. It has an elevation of 63 metres (207?ft).\\r\\nTo the southeast, the Turks and Caicos Islands, and three more extensive submarine features called Mouchoir Bank, Silver Bank and Navidad Bank, are geographically a continuation of the Bahamas.\\r\\nDisney has its own private island in the Bahamas called Castaway Cay. It is located near Great Abaco Island and was formerly known as Gorda Cay. In 1997, The Walt Disney Company purchased a 99-year land lease for the cay from the Bahamian government, set to expire in 2096.\\r\\nThe climate of the Bahamas is tropical savannah climate or Aw according to K?ppen climate classification. The low latitude, warm tropical Gulf Stream, and low elevation give the Bahamas a warm and winterless climate. As such, there has never been a frost or freeze reported in the Bahamas, although every few decades low temperatures can fall below 10?C (50?F) for a few hours when a severe cold outbreak comes off the North American mainland. There is only an 8?C difference between the warmest month and coolest month in most of the Bahama islands. As with most tropical climates, seasonal rainfall follows the sun, and summer is the wettest season. The Bahamas are often sunny and dry for long periods of time, and average more than 3,000 hours or 340 days[47] of sunlight annually.\\r\\nTropical storms and hurricanes can on occasion impact the Bahamas. In 1992, Hurricane Andrew passed over the northern portions of the islands, and Hurricane Floyd passed near the eastern portions of the islands in 1999.\\r\\n73?F\\r\\n73?F\\r\\n75?F\\r\\n79?F\\r\\n81?F\\r\\n82?F\\r\\n82?F\\r\\n82?F\\r\\n82?F\\r\\n81?F\\r\\n79?F\\r\\n75?F\\r\\nThe Bahamas is part of the Lucayan Archipelago, which continues into the Turks and Caicos Islands, the Mouchoir Bank, the Silver Bank, and the Navidad Bank.[50]\\r\\nThe Bahamas Platform, which includes the Bahamas, Southern Florida, Northern Cuba, the Turks and Caicos, and the Blake Plateau, formed about 150 Ma, not long after the formation of the North Atlantic. The 6.4?km thick limestones, which predominately make up The Bahamas, date back to the Cretaceous. These limestones would have been deposited in shallow seas, assumed to be a stretched and thinned portion of the North American continental crust. Sediments were forming at about the same rate as the crust below was sinking due to the added weight. Thus, the entire area consisted of a large marine plain with some islands. Then, at about 80 Ma, the area became flooded by the Gulf Stream. This resulted in the drowning of the Blake Plateau, the separation of The Bahamas from Cuba and Florida, the separation of the southeastern Bahamas into separate banks, the creation of the Cay Sal Bank, plus the Little and Great Bahama Banks. Sedimentation from the \\"carbonate factory\\" of each bank, or atoll, continues today at the rate of about 2?cm per kyr. Coral reefs form the \\"retaining walls\\" of these atolls, within which oolites and pellets form.[51]\\r\\nCoral growth was greater through the Tertiary, until the start of the Ice Ages, and hence those deposits are more abundant below a depth of 36 m. In fact, an ancient extinct reef exists half a km seaward of the present one, 30 m below sea level. Oolites form when oceanic water penetrate the shallow banks, increasing the temperature about 3?C and the salinity by 0.5 per cent. Cemented ooids are referred to as grapestone. Additionally, giant stromatolites are found off the Exuma Cays.[51]:22,29ÿ30\\r\\nSea level changes resulted in a drop in sea level, causing wind blown oolite to form sand dunes with distinct cross-bedding. Overlapping dunes form oolitic ridges, which become rapidly lithified through the action of rainwater, called eolianite. Most islands have ridges ranging from 30 to 45 m, though Cat Island has a ridge 60 m in height. The land between ridges is conducive to the formation of lakes and swamps.[51]:41ÿ59,61ÿ64\\r\\nSolution weathering of the limestone results in a \\"Bahamian Karst\\" topography. This includes potholes, Blue holes such as Dean's Blue Hole, sinkholes, beachrock such as the Bimini Road (\\"pavements of Atlantis\\"), limestone crust, caves due to the lack of rivers, and sea caves. Several blue holes are aligned along the South Andros Fault line. Tidal flats and tidal creeks are common, but the more impressive drainage patterns are formed by troughs and canyons such as Great Bahama Canyon with the evidence of turbidity currents and turbidite deposition.[51]:33ÿ40,65,72ÿ84,86\\r\\nThe stratigraphy of the islands consists of the Middle Pleistocene Owl's Hole Formation, overlain by the Late Pleistocene Grotto Beach Formation, and then the Holocene Rice Bay Formation. However, these units are not necessarily stacked on top of each other but can be located laterally. The oldest formation, Owl's Hole, is capped by a terra rosa paleosoil, as is the Grotto Beach, unless eroded. The Grotto Beach Formation is the most widespread.[50]\\r\\nThe Bahamas is a parliamentary constitutional monarchy headed by Queen Elizabeth II in her role as Queen of the Bahamas. Political and legal traditions closely follow those of the United Kingdom and the Westminster system. The Bahamas is a member of the Commonwealth of Nations as a Commonwealth realm, retaining the Queen as head of state (represented by a Governor-General).\\r\\nLegislative power is vested In a bicameral parliament, which consists of a 38-member House of Assembly (the lower house), with members elected from single-member districts, and a 16-member Senate, with members appointed by the Governor-General, including nine on the advice of the Prime Minister, four on the advice of the Leader of Her Majesty's Loyal Opposition, and three on the advice of the Prime Minister after consultation with the Leader of the Opposition. The House of Assembly carries out all major legislative functions. As under the Westminster system, the Prime Minister may dissolve Parliament and call a general election at any time within a five-year term.[52]\\r\\nThe Prime Minister is the head of government and is the leader of the party with the most seats in the House of Assembly. Executive power is exercised by the Cabinet, selected by the Prime Minister and drawn from his supporters in the House of Assembly. The current Governor-General is Dame Marguerite Pindling, and the current Prime Minister is The Rt. Hon. Hubert Minnis M.P..\\r\\nConstitutional safeguards include freedom of speech, press, worship, movement and association. The Judiciary of the Bahamas is independent of the executive and the legislature. Jurisprudence is based on English law.\\r\\nThe Bahamas has a two-party system dominated by the centre-left Progressive Liberal Party and the centre-right Free National Movement. A handful of splinter parties have been unable to win election to parliament. These parties have included the Bahamas Democratic Movement, the Coalition for Democratic Reform, Bahamian Nationalist Party and the Democratic National Alliance.\\r\\nThe Bahamas has strong bilateral relationships with the United States and the United Kingdom, represented by an ambassador in Washington and High Commissioner in London. The Bahamas also associates closely with other nations of the Caribbean Community (CARICOM).\\r\\nIts military is the Royal Bahamas Defence Force (the RBDF), the navy of the Bahamas which includes a land unit called Commando Squadron (Regiment) and an Air Wing (Air Force). Under the Defence Act, the RBDF has been mandated, in the name of the Queen, to defend the Bahamas, protect its territorial integrity, patrol its waters, provide assistance and relief in times of disaster, maintain order in conjunction with the law enforcement agencies of the Bahamas, and carry out any such duties as determined by the National Security Council. The Defence Force is also a member of the Caribbean Community (CARICOM)'s Regional Security Task Force.\\r\\nThe RBDF came into existence on 31 March 1980. Their duties include defending the Bahamas, stopping drug smuggling, illegal immigration and poaching, and providing assistance to mariners. The Defence Force has a fleet of 26 coastal and inshore patrol craft along with 3 aircraft and over 1,100 personnel including 65 officers and 74 women.\\r\\nThe districts of the Bahamas provide a system of local government everywhere except New Providence (which holds 70% of the national population), whose affairs are handled directly by the central government. In 1996, the Bahamian Parliament passed the \\"Local Government Act\\" to facilitate the establishment of Family Island Administrators, Local Government Districts, Local District Councillors and Local Town Committees for the various island communities. The overall goal of this act is to allow the various elected leaders to govern and oversee the affairs of their respective districts without the interference of Central Government. In total, there are 32 districts, with elections being held every five years. There are 110 Councillors and 281 Town Committee members are elected to represent the various districts.[53]\\r\\nEach Councillor or Town Committee member is responsible for the proper use of public funds for the maintenance and development of their constituency.\\r\\nThe Bahamas uses drive-on-the-Left traffic rules throughout the Commonwealth.\\r\\nThe districts other than New Providence are:\\r\\nThe colors embodied in the design of the Bahamian flag symbolism the strength of the Bahamian people; the design reflects aspects of the natural environment (sun and sea) and the economic and social development. The flag is a black equilateral triangle against the mast, superimposed on a horizontal background made up of two colors on three equal stripes of aquamarine, gold and aquamarine.\\r\\nThe coat of arms of the Bahamas contains a shield with the national symbols as its focal point. The shield is supported by a marlin and a flamingo, which are the national animals of the Bahamas. The flamingo is located on the land, and the marlin on the sea, indicating the geography of the islands.\\r\\nOn top of the shield is a conch shell, which represents the varied marine life of the island chain. The conch shell rests on a helmet. Below this is the actual shield, the main symbol of which is a ship representing the Santa Mara of Christopher Columbus, shown sailing beneath the sun. Along the bottom, below the shield appears a banner upon which is the national motto:[54]\\r\\n\\"Forward, Upward, Onward Together.\\"\\r\\nThe yellow elder was chosen as the national flower of the Bahamas because it is native to the Bahama islands, and it blooms throughout the year.\\r\\nSelection of the yellow elder over many other flowers was made through the combined popular vote of members of all four of New Providence's garden clubs of the 1970sthe Nassau Garden Club, the Carver Garden Club, the International Garden Club and the Y.W.C.A. Garden Club.\\r\\nThey reasoned that other flowers grown theresuch as the bougainvillea, hibiscus and poincianahad already been chosen as the national flowers of other countries. The yellow elder, on the other hand, was unclaimed by other countries (although it is now also the national flower of the United States Virgin Islands) and also the yellow elder is native to the family islands.[55]\\r\\nBy the terms of GDP per capita, the Bahamas is one of the richest countries in the Americas.[56] It was revealed in the Panama Papers that The Bahamas is the jurisdiction with the most offshore entities or companies.[57]\\r\\nThe Bahamas relies on tourism to generate most of its economic activity. Tourism as an industry not only accounts for over 60% of the Bahamian GDP, but provides jobs for more than half the country's workforce.[58] The Bahamas attracted 5.8 million visitors in 2012, more than 70% of whom were cruise visitors.\\r\\nAfter tourism, the next most important economic sector is banking and international financial services, accounting for some 15% of GDP.\\r\\nThe government has adopted incentives to encourage foreign financial business, and further banking and finance reforms are in progress. The government plans to merge the regulatory functions of key financial institutions, including the Central Bank of the Bahamas (CBB) and the Securities and Exchange Commission.[citation needed] The Central Bank administers restrictions and controls on capital and money market instruments. The Bahamas International Securities Exchange consists of 19 listed public companies. Reflecting the relative soundness of the banking system (mostly populated by Canadian banks), the impact of the global financial crisis on the financial sector has been limited.[citation needed]\\r\\nThe economy has a very competitive tax regime. The government derives its revenue from import tariffs, VAT, licence fees, property and stamp taxes, but there is no income tax, corporate tax, capital gains tax, or wealth tax. Payroll taxes fund social insurance benefits and amount to 3.9% paid by the employee and 5.9% paid by the employer.[59] In 2010, overall tax revenue as a percentage of GDP was 17.2%.[1]\\r\\nAgriculture is the third largest sector of the Bahamian economy, representing 5ÿ7% of total GDP. An estimated 80% of the Bahamian food supply is imported. Major crops include onions, okra, tomatoes, oranges, grapefruit, cucumbers, sugar cane, lemons, limes, and sweet potatoes.\\r\\nThe Bahamas has an estimated population of 391,232, of which 25.9% are under 14, 67.2% 15 to 64 and 6.9% over 65. It has a population growth rate of 0.925% (2010), with a birth rate of 17.81/1,000 population, death rate of 9.35/1,000, and net migration rate of ?2.13 migrant(s)/1,000 population.[60] The infant mortality rate is 23.21 deaths/1,000 live births. Residents have a life expectancy at birth of 69.87 years: 73.49 years for females, 66.32 years for males. The total fertility rate is 2.0 children born/woman (2010).[1]\\r\\nThe most populous islands are New Providence, where Nassau, the capital and largest city, is located;[61] and Grand Bahama, home to the second largest city of Freeport.[62]\\r\\nAccording to the 99% response rate obtained from the race question on the 2010 Census questionnaire, 90.6% of the population identified themselves as being Black, 4.7% White and 2.1% of a mixed race (Black and White).[63] Three centuries prior, in 1722 when the first official census of the Bahamas was taken, 74% of the population was White and 26% Black.[63]\\r\\nSince the colonial era of plantations, Africans or Afro-Bahamians have been the largest ethnic group in the Bahamas, whose primary ancestry was based in West Africa. The first Africans to arrive to the Bahamas were freed slaves from Bermuda; they arrived with the Eleutheran Adventurers looking for new lives.\\r\\nThe Haitian community in the Bahamas is also largely of African descent and numbers about 80,000. Due to an extremely high immigration of Haitians to the Bahamas, the Bahamian government started deporting illegal Haitian immigrants to their homeland in late 2014.[64]\\r\\nThe White Bahamian population are mainly the descendants of the English Puritans looking to flee religious persecution in England and American Loyalists escaping the American Revolution who arrived in 1649 and 1783, respectively.[65] Many Southern Loyalists went to the Abaco Islands, half of whose population was of European descent as of 1985.[66] The term white is usually used to identify Bahamians with Anglo ancestry, as well as \\"light-skinned\\" Afro-Bahamians. Sometimes Bahamians use the term Conchy Joe to describe people of Anglo descent.[67]\\r\\nA small portion of the Euro-Bahamian population is descended from Greek labourers who came to help develop the sponging industry in the 1900s. They make up less than 1% of the nation's population, but have still preserved their distinct Greek Bahamian culture.[citation needed]\\r\\nBahamians typically identify themselves simply as either black or white.[67]\\r\\nThe official language of the Bahamas is English. Many people speak an English-based creole language called Bahamian dialect (known simply as \\"dialect\\") or \\"Bahamianese.\\" [68] Laurente Gibbs, a Bahamian writer and actor was the first to coin the latter name in a poem and has since promoted its usage.[69][70] Both are used as autoglossonyms.[71] Haitian Creole, a French-based creole language is spoken by Haitians and their descendants, who make up of about 25% of the total population. It is known simply as Creole[1] to differentiate languages.[72] Also note that the Bahamas was once under British rule and therefore the English taught in the Bahamian schools is still \\"British-based\\".\\r\\nReligion in the Bahamas (2010)[73]\\r\\nAccording to International Religious Freedom Report 2008 prepared by United States Bureau of Democracy, Human Rights and Labor, the islands' population is predominantly Christian. Protestant denominations are widespread and collectively account for more than 70% of the population, with Baptists representing 35% of the population, Anglicans 15%, Pentecostals 8%, Church of God 5%, Seventh-day Adventists 5% and Methodists 4%. There is also a significant Roman Catholic community accounting for about 14%.[74] There are also smaller communities of Jews, Muslims, Baha'is, Hindus, Rastafarians and practitioners of Obeah.\\r\\nIn the less developed outer islands (or Family Islands), handicrafts include basketry made from palm fronds. This material, commonly called \\"straw\\", is plaited into hats and bags that are popular tourist items. Another use is for so-called \\"Voodoo dolls\\", even though such dolls are the result of the American imagination and not based on historic fact.[75]\\r\\nA form of folk magic (obeah) is practiced by some Bahamians, mainly in the Family Islands (out-islands) of the Bahamas.[76] The practice of obeah is illegal in the Bahamas and punishable by law.[77]\\r\\nJunkanoo is a traditional Afro-Bahamian street parade of 'rushing', music, dance and art held in Nassau (and a few other settlements) every Boxing Day and New Year's Day. Junkanoo is also used to celebrate other holidays and events such as Emancipation Day.\\r\\nRegattas are important social events in many family island settlements. They usually feature one or more days of sailing by old-fashioned work boats, as well as an onshore festival.\\r\\nMany dishes are associated with Bahamian cuisine, which reflects Caribbean, African and European influences. Some settlements have festivals associated with the traditional crop or food of that area, such as the \\"Pineapple Fest\\" in Gregory Town, Eleuthera or the \\"Crab Fest\\" on Andros. Other significant traditions include story telling.\\r\\nBahamians have created a rich literature of poetry, short stories, plays and short fictional works. Common themes in these works are (1) an awareness of change, (2) a striving for sophistication, (3) a search for identity, (4) nostalgia for the old ways and (5) an appreciation of beauty. Some contributing writers are Susan Wallace, Percival Miller, Robert Johnson, Raymond Brown, O.M. Smith, William Johnson, Eddie Minnis and Winston Saunders.[78][79]\\r\\nBahamas culture is rich with beliefs, traditions, folklore and legend. The most well-known folklore and legends in the Bahamas includes Lusca in Andros Bahamas, Pretty Molly on Exuma Bahamas, the Chickcharnies of Andro Bahamas, and the Lost City of Atlantis on Bimini Bahamas.\\r\\nSport is a significant part of Bahamian culture. The national sport is cricket. Cricket has been played in the Bahamas from 1846.[80] It is the oldest sport being played in the country today. The Bahamas Cricket Association was formed in 1936 as an organised body. From the 1940s to the 1970s, cricket was played amongst many Bahamians. Bahamas is not a part of the West Indies Cricket Board, so players are not eligible to play for the West Indies cricket team. The late 1970s saw the game begin to decline in the country as teachers, who had previously come from the United Kingdom with a passion for cricket were replaced by teachers who had been trained in the United States. The Bahamian Physical education teachers had no knowledge of the game and instead taught track & field, basketball, baseball, softball,[81] volleyball[82] and football[83] where primary and high schools compete against each other. Today cricket is still enjoyed by a few locals and immigrants in the country usually from Jamaica, Guyana, Haiti and Barbados. Cricket is played on Saturdays and Sundays at Windsor Park and Haynes Oval.\\r\\nThe only other sporting event that began before cricket was horse racing, which started in 1796. The most popular spectator sports are those imported from United States, such as basketball,[84] American football[85] and baseball[86] rather than Great Britain due to the country's close proximity to the United States. Unlike their other Caribbean counterparts, cricket, rugby, and netball have proven to be more popular.\\r\\nDexter Cambridge, Rick Fox, Ian Lockhart and Buddy Hield are a few Bahamians who joined Bahamian Mychal Thompson of the Los Angeles Lakers in the NBA ranks,[87][88] Over the years American football has become much more popular than association football, though not implemented in the high school system yet. Leagues for teens and adults have been developed by the Bahamas American Football Federation.[89] However association football, commonly known as 'soccer' in the country, is still a very popular sport amongst high school pupils. Leagues are governed by the Bahamas Football Association. Recently the Bahamian government has been working closely with Tottenham Hotspur of London to promote the sport in the country as well as promoting the Bahamas in the European market. In 2013 'Spurs' became the first Premier League club to play an exhibition match in the Bahamas to face the Jamaica national football team. Joe Lewis, the owner of the Tottenham Hotspur club, is based in the Bahamas.[90]\\r\\nOther popular sports are swimming,[91] tennis[92] and boxing[93] where Bahamians have enjoyed some degree of success at the international level. Other sports such as golf,[94] rugby league,[95] rugby union[96] beach soccer[97] and netball are considered growing sports. Athletics commonly known as track and field in the country is the most successful sport by far amongst Bahamians. Bahamians have a strong tradition in the sprints and jumps. Track and field is probably the most popular spectator sport in the country next to basketball due to their success over the years. Triathlons are gaining popularity in Nassau and the Family Islands.\\r\\nBahamians have gone on to win numerous track and field medals at the Olympic Games, IAAF World Championships in Athletics, Commonwealth Games and Pan American Games. Frank Rutherford is the first athletics olympic medalist for the country. He won a bronze medal for triple jump during the 1992 Summer Olympics.[98] Pauline Davis-Thompson, Debbie Ferguson, Chandra Sturrup, Savatheda Fynes and Eldece Clarke-Lewis teamed up for the first athletics Olympic Gold medal for the country when they won the 4 G 100 m relay at the 2000 Summer Olympics. They are affectionately known as the \\"Golden Girls\\".[99] Tonique Williams-Darling became the first athletics individual Olympic gold medalist when she won the 400m sprint in 2004 Summer Olympics.[100] In 2007, with the disqualification of Marion Jones, Pauline Davis-Thompson was advanced to the gold medal position in the 200 metres at the 2000 Olympics, predating William-Darling.\\r\\nThe Bahamas were hosts of the first men's senior FIFA tournament to be staged in the Caribbean, the 2017 FIFA Beach Soccer World Cup.[101]\\r\\nAccording to 1995 estimates 98.2% of the adult population is literate.[citation needed]\\r\\nClick on a coloured area to see an article about English in that country or region","input":"What is the primary language in the bahamas?"},{"output":"from 1775ÿ1783","context":"The history of guerrilla warfare stretches back to ancient history. While guerrilla tactics can be viewed as a natural continuation of prehistoric warfare,[1] the Chinese general and strategist Sun Tzu, in his The Art of War (6th century BCE), was the earliest to propose the use of guerrilla warfare.[2] This directly inspired the development of modern guerrilla warfare.;[2][3] Communist leaders like Mao Zedong and North Vietnamese Ho Chi Minh both implemented guerrilla warfare in the style of Sun Tzu,[2] which served as a model for similar strategies elsewhere, such as the Cuban \\"foco\\" theory and the anti-Soviet Mujahadeen in Afghanistan.[4] While the tactics of modern guerrilla warfare originate in the 20th century, irregular warfare, using elements later characteristic of modern guerrilla warfare, has existed throughout the battles of many ancient civilizations.\\r\\nThe Chinese general and strategist Sun Tzu, in his The Art of War (6th century BC), was one of the first proponents of the use of guerrilla warfare.[2] The earliest description of guerrilla warfare is an alleged battle between Emperor Huang and the Miao in China.[5] Guerrilla warfare was not unique to China; nomadic and migratory tribes such as the Scythians, Goths, Vandals, and Huns used elements of guerrilla warfare to fight the Persian Empire, the Roman Empire, and Alexander the Great.[6] Quintus Fabius Maximus Verrucosus, widely regarded as the \\"father of guerrilla warfare\\" of his time, devised the Fabian strategy which was used to great effect against Hannibal Barca's army.[7][8] Guerrilla warfare was also a common strategy of the various Celtic, Iberian and Germanic tribes that the Romans faced. Caratacus, the British war chief, employed guerrilla warfare against the Romans for approximately 8 years, mixed in with occasional set piece battles. Despite ultimately being captured by the Romans, Tacitus writes that many Romans respected him. Other leaders of the time who employed guerrilla warfare to some effect included Viriathus, Arminius and Vercingetorix. In the Classic Ancient world, this kind of warfare was indirectly mentioned by the Greeks in Homeric stories, but usually as hit and run acts of foraging or booty in enemy territory, pretty much as later Vikings piracy. The Romans and Carthaginians learned of these tactics more as intended warfare by the Iberians before Viriathus and Hamilcar Barca in campaigns in Sicily against them.\\r\\nDuring the Mongol invasion of Europe, guerrilla warfare and stiff resistance helped many Europeans, particularly those at Croatia and Dzurdzuketia, in preventing the Mongols from setting a permanent hold of their territory and driving them off.[9][10] In the 15th century, Vietnamese leader L L?i launched a guerrilla war against Chinese.[11]\\r\\nOne of the most successful guerrilla wars was led by George Kastrioti Skanderbeg against the invading Ottomans. In 1443 he rallied Albanian forces and drove the Turks from his homeland. Skanderbeg fought a guerrilla war against invading armies up to 20 times larger than his, by using the mountainous terrain to his advantage. He harassed the vast Ottoman army with small \\"hit and run\\" units, as well as using feint retreats followed by sudden counterattacks, and other tactics unknown in warfare up to then. For 25 years Skanderbeg kept the Turks from retaking Albania, which due to its proximity to Italy, could easily have served as a springboard to the rest of Europe.[12]\\r\\nIn 1462, the Ottomans were driven back by Wallachian prince Vlad III Dracula. Vlad was unable to stop the Turks from entering Wallachia, so he resorted to guerrilla war, constantly organizing small attacks and ambushes on the Turks.[13] During The Deluge in Poland guerrilla tactics were applied.[14] In the 100 years war between England and France, commander Bertrand du Guesclin used guerrilla tactics to pester the English invaders. The Frisian warlord and freedom fighter Pier Gerlofs Donia fought a guerrilla against Philip I of Castile[15] and with his co-commander Wijerd Jelckama against Charles V.[16][17]\\r\\nDuring the Dutch Revolt of the 16th century, the Geuzen waged a guerrilla war against the Spanish Empire.[18] During the Scanian War, a pro-Danish guerrilla group known as the Snapphane fought against the Swedes. Chhatrapati Shivaji Maharaj started guerrilla warfare against the Mughals and other powers in 1645 leading to establishment of the Maratha state in 1674, sowing seeds of what would become the last great empire (Maratha empire) in free India. In 17th century Ireland, Irish irregulars called tories and rapparees used guerrilla warfare in the Irish Confederate Wars and the Williamite war in Ireland. Finnish guerrillas, sissis, fought against Russian occupation troops in the Great Northern War, 1710ÿ1721. The Russians retaliated brutally against the civilian populace; the period is called Isoviha (Grand Hatred) in Finland.\\r\\nIn North America, one of the earliest recorded instances of guerrilla warfare was Apalachee resistance to the Spanish during the Narvez expedition in 1528 in present-day Florida.\\r\\nIn the mid 17th century the Colonists of New France were in conflict with the Iroquois Confederacy. Iroquois forces used hit and run tactics, harassment and avoided costly pitched battles. The colonists of New France began calling these Indian tactics La Petite Guerre because the tactics were meant for raiding as opposed to pitched battles. Under the tutelage of Wendake, Wobanaki, Algonquin and Ottawa tutors the habitants of New France learned La Petite Guerre and successfully used them against the Iroquois.\\r\\nLed by Major Benjamin Church, New Englanders had also been adopting Indian scouting and raiding tactics since King Philip's War. Throughout the four French and Indian Wars, starting in the late 17th century Canadiens, the Wabanaki Confederacy, and some Acadians brought La Petite Guerre to New England and the Ohio Valley. In present-day Maine, Father Sebastian Rale led the Wabanaki Confederacy in a petite guerre along the New England/ Acadia border. A generation later, in Nova Scotia, Father Jean-Louis Le Loutre led the Mi'kmaq and the Acadians in a petite guerre behind Anglo-American lines in the lead up to the last French and Indian War.[19]\\r\\nDuring the French and Indian War La Petite Guerre came to front stage when the Ohio valley Indians defeated Braddock's expedition near the forks of the Ohio in the Battle of the Monongahela. In Nova Scotia, French Officer Charles Deschamps de Boishbert led the Mi'kmaq and the Acadians in a guerrilla war while the British expelled the Acadians from the region.[20] In the Northeast, a New Hampshire backwoodsman, Robert Rogers, began to make a stir in the British military establishment for his success using the tactics of the \\"little war\\". British military leaders like Jeffery Amherst, John Forbes and Henry Bouquet understood they needed to learn and adopt the techniques and tactics of the little war, or be consumed, like Braddock. The British military establishment began adopting some of the tactics of La Petite Guerre as \\"light infantry.\\"[21]\\r\\nAlthough many of the engagements of the American Revolution were conventional, guerrilla warfare was used to a certain extent during this conflict from 1775ÿ1783, which made a significant impact. Guerrilla tactics were first used at the Battles of Lexington and Concord by the Patriots at April 19, 1775. George Washington sometimes used some sort of unconventional methods to fight the British. During the Forage War, George Washington sent militia units with limited Continental Army support to launch raids and ambushes on British detachments and forage parties, the militia and Continental Army support would skirmish with British detachments in small scale battles and engagements. Throughout the Forage War, British casualties exceeded past 900. The Forage War raised morale for the Patriots as their guerrilla operations against the British were very effective. Next, there are other Americans that used hit and run raids, ambushes, and surprise attacks against the British such as William R. Davie, David Wooster, Francis Marion, Shadrach Inman, Daniel Morgan, Morgan's riflemen, and the Overmountain Men. All these American guerrilla fighters did their part by using unconventional tactics to fight the British and loyalists. Nathanael Greene used a guerrilla strategy very effectively against Lord Cornwallis. First, Nathanael Greene would keep retreating to lure the British far from their supply lines, then send out his forces to fight in small skirmishes and engagements with British detachments to weaken them. Then fighting the conventional battle, Nathanael Greene fought Lord Cornwallis at Guilford Court House and gave him a severe blow. Although Lord Cornwallis was the victor, his victory was pyrrhic as he had too many casualties that he could ill afford. After the British surrender at Yorktown and America gaining their independence, many of these Americans who used guerrilla tactics and strategies became immortalized and romanticized as time passed. Although guerrilla warfare was frequently used when avoiding battles, the Americans fought in conventional linear formations in decisive battles against the British. The American Revolution could be seen as a hybrid war since both conventional and guerrilla warfare were used throughout its duration.[citation needed]\\r\\nFrom 1793ÿ1796 a revolt broke out against the French Revolution by Catholic royalists in the Department of the Vende. This movement was intended to oppose the persecution endured by the Roman Catholic Church in revolutionary France (see Dechristianisation of France during the French Revolution#The Revolution and the Church) and ultimately to restore the monarchy. Though ill-equipped and untrained in conventional military tactics, the Vendan counter-revolution, known as the \\"Royal Catholic Army,\\" relied heavily on guerrilla tactics, taking full advantage of their intimate knowledge of the marsh filled, heavily forested countryside. Though the Revolt in the Vende was eventually \\"pacified\\" by government troops, their successes against the larger, better equipped republican army were notable.\\r\\nWorks such as \\"La Vende\\" by Anthony Trollope,[22] G.A. Henty's \\"No Surrender! A Tale of Rising in the Vende\\"[23] detail the history of the revolt.\\r\\n\\"Wherever we arrived, they disappeared, whenever we left, they arrived  they were everywhere and nowhere, they had no tangible center which could be attacked.\\"\\r\\nIn the Napoleonic Wars many of the armies lived off the land. This often led to some resistance by the local population if the army did not pay fair prices for produce they consumed. Usually this resistance was sporadic, and not very successful, so it is not classified as guerrilla action. There are three notable exceptions, though:\\r\\nIn Napoleon's invasion of Russia of 1812 two actions could be seen as initiating guerrilla tactics. The burning of Moscow after it had been occupied by Napoleon's Grand Army, depriving the French of shelter in the city, resembled guerrilla action insofar as it was an attack on the available resources rather than directly on the troops (and insofar as it was a Russian action rather than an inadvertent consequence of nineteenth-century troops' camping in a largely abandoned city of wooden buildings). In a different sense, the imperial command that the Russian serfs should attack the French resembled guerrilla tactics in its reliance on partisans rather than army regulars. This did not so much spark a guerrilla war as encourage a revengeful slaughter of French deserters by Russian peasants.[25] Meanwhile, Fieldmarshal Kutuzov permitted than-Hussar Lieutenant-Colonel Denis Davydov to open the Partisan War against the French communications. Davydov, Seslavin, Figner and others are since known in Russia as the 'Partisan Rangers of the Year '12' (Russian: ҽ [ҿۿ־ ־񳭷 18] '12-̾ ̾). They were successful in their operations making the French troops unable to fight or even move, because of food and ammunition shortage, and not just because of the Russian Winter as is usually stated.\\r\\nIn the Peninsular War Spanish guerrillas tied down tens of thousands of French troops and killed hundreds of thousands. The continual losses of troops caused Napoleon to describe this conflict as his \\"Spanish ulcer\\". This was one of the most successful partisan wars in history and was where the word guerrilla was first used in this context. The Oxford English Dictionary lists Wellington as the oldest known source, speaking of \\"Guerrillas\\" in 1809. Poet William Wordsworth showed a surprising early insight into guerrilla methods in his pamphlet on the Convention of Cintra:\\r\\nThis war saw British and Portuguese forces using Portugal as a secure position to launch campaigns against the French army, while Spanish guerrilleros bled the occupiers. Gates notes that much of the French army \\"was rendered unavailable for operations against Wellington because innumerable Spanish contingents kept materialising all over the country. In 1810, for example, when Massena invaded Portugal, the Imperial forces in the Peninsula totaled a massive 325,000 men, but only about one quarter of these could be spared for the offensive ÿ the rest were required to contain the Spanish insurgents and regulars. This was the greatest single contribution that the Spaniards were to make and, without it, Wellington could not have maintained himself on the continent for longlet alone emerge victorious from the conflict\\".[26] Combined, the regular and irregular allied forces prevented Napoleon's Marshals from subduing the rebellious Spanish provinces.[27]\\r\\nIrregular warfare in the American Civil War followed the patterns of irregular warfare in 19th century Europe. Structurally, irregular warfare can be divided into three different types conducted during the Civil War: 'People's War', 'partisan warfare', and 'raiding warfare'. The concept of 'People's war,' first described by Carl von Clausewitz in On War, was the closest example of a mass guerrilla movement in the era. In general, this type of irregular warfare was conducted in the hinterland of the Border States (Missouri, Arkansas, Tennessee, Kentucky, and northwestern Virginia), and was marked by a vicious neighbor-against-neighbor conflict. One such example was the opposing irregular forces operating in Missouri and northern Arkansas from 1862 to 1865, most of which were pro-Confederate or pro-Union in name only and preyed on civilians and isolated military forces of both sides with little regard of politics. From these semi-organized guerrillas, several groups formed and were given some measure of legitimacy by their governments. Quantrill's Raiders, who terrorized pro-Union civilians and fought Federal troops in large areas of Missouri and Kansas, was one such unit. Another notorious unit, with debatable ties to the Confederate military, was led by Champ Ferguson along the Kentucky-Tennessee border. Ferguson became one of the only figures of Confederate cause to be executed after the war. Dozens of other small, localized bands terrorized the countryside throughout the border region during the war, bringing total war to the area that lasted until the end of the Civil War and, in some areas, beyond.\\r\\nPartisan warfare, in contrast, more closely resembles Commando operations of the 20th century. Partisans were small units of conventional forces, controlled and organized by a military force for operations behind enemy lines. The 1862 Partisan Ranger Act passed by the Confederate Congress authorized the formation of these units and gave them legitimacy, which placed them in a different category than the common 'bushwhacker' or 'guerrilla'. John Singleton Mosby formed a partisan unit which was very effective in tying down Federal forces behind Union lines in northern Virginia in the last two years of the war.\\r\\nLastly, deep raids by conventional cavalry forces were often considered 'irregular' in nature. The \\"Partisan Brigades\\" of Nathan Bedford Forrest and John Hunt Morgan operated as part of the cavalry forces of the Confederate Army of Tennessee in 1862 and 1863. They were given specific missions to destroy logistical hubs, railroad bridges, and other strategic targets to support the greater mission of the Army of Tennessee. By mid-1863, with the destruction of Morgan's raiders during the Great Raid of 1863, the Confederacy conducted few deep cavalry raids in the latter years of the war, mostly because of the losses in experienced horsemen and the offensive operations of the Union army. Federal cavalry conducted several successful raids during the war but in general used their cavalry forces in a more conventional role. A good exception was the 1863 Grierson's Raid, which did much to set the stage for General Ulysses S. Grant's victory during the Vicksburg Campaign.\\r\\nFederal counter-guerrilla operations were very successful in preventing the success of Confederate guerrilla warfare. In Arkansas, Federal forces used a wide variety of strategies to defeat irregulars. These included the use of Arkansas Unionist forces as anti-guerrilla troops, the use of riverine forces such as gunboats to control the waterways, and the provost marshal military law enforcement system to spy on suspected guerrillas and to imprison those captured. Against Confederate raiders, the Federal army developed an effective cavalry themselves and reinforced that system by numerous blockhouses and fortification to defend strategic targets.\\r\\nHowever, Federal attempts to defeat Mosby's Partisan Rangers fell short of success because of Mosby's use of very small units (10ÿ15 men) operating in areas considered friendly to the Rebel cause. Another regiment known as the \\"Thomas Legion\\", consisting of white and anti-Union Cherokee Indians, morphed into a guerrilla force and continued fighting in the remote mountain back-country of western North Carolina for a month after Lee's surrender at Appomattox. That unit was never completely suppressed by Union forces, but voluntarily ceased hostilities after capturing the town of Waynesville on May 10, 1865.\\r\\nIn the late 20th century several historians have focused on the non-use of guerrilla warfare to prolong the war. Near the end of the war, there were those in the Confederate government, notably Jefferson Davis who advocated continuing the southern fight as a guerrilla conflict. He was opposed by generals such as Robert E. Lee who ultimately believed that surrender and reconciliation were better than guerrilla warfare.\\r\\nSee also Bushwhackers (Union and Confederate) and Jayhawkers (Union).\\r\\nGuerrilla tactics were used extensively by the forces of the Boer republics in the First and Second Boer Wars in South Africa (1880ÿ1881; 1899ÿ1902) against the invading British Army. In the First Boer War, the Boer commandos wore their everyday dull-coloured farming clothes. The Boers relied more on stealth and speed than discipline and formation and, being expert marksmen using smokeless ammunition, the Boer were able to easily snipe at British troops from a distance. So the British Army relaxed their close-formation tactics. The British Army had changed to Khaki uniforms, first used by the British Indian Army, a decade earlier, and officers were soon ordered to dispense with gleaming buttons and buckles which made them conspicuous to snipers.\\r\\nIn the third phase of the Second Boer War, after the British defeated the Boer armies in conventional warfare and occupied their capitals of Pretoria and Bloemfontein, Boer commandos reverted to mobile warfare. Units led by leaders such as Jan Smuts and Christiaan de Wet harassed slow-moving British columns and attacked railway lines and encampments. The Boers were almost all mounted and possessed long range magazine loaded rifles. This gave them the ability to attack quickly and cause many casualties before retreating rapidly when British reinforcements arrived. In the early period of the guerrilla war, Boer commandos could be very large, containing several thousand men and even field artillery. However, as their supplies of food and ammunition gave out, the Boers increasingly broke up into smaller units and relied on captured British arms, ammunition, and uniforms.\\r\\nTo counter these tactics, the British under Kitchener interned Boer civilians into concentration camps and built hundreds of blockhouses all over the Transvaal and Orange Free State. Kitchener also enacted a scorched earth policy, destroying Boer homes and farms. Eventually, the Boer guerrillas surrendered in 1902, but the British granted them generous terms in order to bring the war to an end. This showed how effective guerrilla tactics could be in extracting concessions from a militarily more powerful enemy.\\r\\nAt the start of the PhilippineÿAmerican War, even with the recommendation of the able General Antonio Luna, guerrilla warfare strategy was viewed by the Philippine side only as a tactical option of final recourse. This led to subsequent defeat of the Filipino forces in the early stages of the war mainly due to superior American weaponry and troops. Guerrilla warfare was only used as a main strategy on November 13, 1899 which made American occupation of the Philippine archipelago all the more difficult over the next few years. This can be greatly seen by the Moro insurrection at the southern province of the Philippines wherein Moro rebels will conceal themselves in the thick Philippine jungle and will charge American troops with only bolo knives in overwhelming numbers at the opportune time. These led the American weapons manufacturers to develop the famed M1911 pistol.\\r\\nIn the Mexican Revolution from 1910 to 1920, the populist revolutionary leader Emiliano Zapata employed the use of predominantly guerrilla tactics. His forces, composed entirely of peasant farmers turned soldiers, wore no uniform and would easily blend into the general population after an operation's completion. They would have young soldiers, called \\"dynamite boys\\", hurl cans filled with explosives into enemy barracks, and then a large number of lightly armed soldiers would emerge from the surrounding area to attack it. Although Zapata's forces met considerable success, his strategy backfired as government troops, unable to distinguish his soldiers from the civilian population, waged a broad and brutal campaign against the latter.\\r\\nAfter the Italian unification in 1860, many bands composed mainly by peasants emerged in Southern Italy. The sources of the trouble were the carelessness of the new government toward the problems of the southern laborers, higher taxes and higher prices of basic necessities, mandatory military service who subtracted youths from the workforce and the economical benefits reserved only for the bourgeois society. In this period thousands of poors took the way of brigandage. The most well known brigand was Carmine Crocco, a former soldier in the service of Giuseppe Garibaldi who formed an army of two thousand men. Crocco was renowned for his guerrilla tactics, which were enhanced by the same royal soldiers who chased him. His warfare included cutting water supplies, destroying flour-mills, cutting telegraph wires and ambushing stragglers.[28]\\r\\nThe wars between Ireland and the British state have been long, and over the centuries have covered the full spectrum of the types of warfare. The Irish fought the first successful 20th century war of independence against the British Empire and the United Kingdom. After the military failure of the Easter Rising in 1916, the Irish Republican Army (IRA) used guerrilla tactics involving both urban guerrilla warfare and flying columns in the countryside during the Irish War of Independence of 1919 to 1922. Many were inspired by the fabled exploits of the 1799ÿ1803 guerilla campaign by Michael Dwyer after the failed 1798 rebellion.\\r\\nThe chief IRA commanders in the localities during this period were Tom Barry, Seamus Robinson, Liam Lynch, Sen Mac Eoin, and Tom Maguire.\\r\\nThe IRA guerrilla was of considerable intensity in parts of the country, notably in Dublin and in areas such as County Cork, County Kerry and County Mayo in the south and west. Despite this, the Irish fighters were never in a position to either hold territory or take on British forces in a conventional manner. Even the largest engagements of the conflict, such as the Kilmichael Ambush or Crossbarry Ambush constituted mere skirmishes by the standards of a conventional war. Another aspect of the war, particularly in the north-eastern part of the province of Ulster, was communal violence. The Unionist majority there, who were largely Protestant and loyal to Britain were granted control over the security forces there, in particular the Ulster Special Constabulary and used them to attack the Nationalist (and largely Catholic) population in reprisal for IRA actions. Elsewhere in Ireland, where Unionists were in a minority, they were sometimes attacked by the IRA for aiding the British forces. The extent to which the conflict was an inter-communal one as well as war of national liberation is still strongly debated in Ireland. The total death toll in the war came to a little over 2000 people.\\r\\nBy mid-1921, the military and political costs of maintaining the British security forces in Ireland eventually proved too heavy for the British government. In July 1921, the UK government agreed to a truce with the IRA and agreed to meet representatives of the Irish First Dail, who since the 1918 General Election held seventy-three of the one hundred and five parliamentary seats for the island. Negotiations led to a settlement, the Anglo-Irish Treaty. It created the Irish Free State of 26 counties as a dominion within the British Empire; the other 6 counties remained part of the UK as Northern Ireland.\\r\\nSinn Fin and the Irish Republican Army split into pro- and anti-Treaty factions with the Anti-Treaty IRA forces losing the Irish Civil War (1922ÿ23) which followed. The partition of Ireland laid the seeds for the later Troubles. The Irish Civil War is a striking example of the failure of guerrilla tactics when used against a relatively popular native regime. Following their failure to hold fixed positions against an Irish Free State offensive in the summer of 1922, the IRA re-formed \\"flying columns\\" and attempted to use the same tactics they had successfully used against the British. However, against Irish troops, who knew them and the terrain and faced with the hostility of the Roman Catholic Church and the majority of Irish nationalist opinion, they were unable to sustain their campaign. In addition, the Free State government, confident of its legitimacy among the Irish population, sometimes used more ruthless and effective measures of repression than the British had felt able to employ. Whereas the British executed 14 IRA men in 1919ÿ1922, the Free State executed 77 anti-treaty prisoners officially and its troops killed another 150 prisoners or so in the field (see Executions during the Irish Civil War). The Free State also interned 12,000 republicans, compared with the British figure of 4,500. The last anti-Treaty guerrillas abandoned their military campaign against the Free State after nine months in March 1923.\\r\\nIn a successful campaign in German East Africa, the German commander Paul Emil von Lettow-Vorbeck fought against the numerically superior allied forces. Even though he was cut off from Germany and had few Germans under his command (most of his fighters were African askaris), he won multiple victories during the East Africa Campaign and managed to exhaust and trouble the Allies; he was undefeated up until his acceptance of a cease-fire in Northern Rhodesia three days after the end of the war in Europe. He returned to Germany as a hero.\\r\\nA major guerrilla war was fought by the Arabs against the Ottoman Turks during the Arab Revolt (1916ÿ1918). Attacking the Hejaz Railway to disrupt Ottman forces is a strategy often credited to the British officer T.E. Lawrence.[29]\\r\\nAnother guerrilla war opposed the German Occupation of Ukraine in 1918 and partisan and guerrilla forces fought against both the Bolsheviks and the Whites during the Russian Civil War. This fighting continued into 1921 in Ukraine, in Tambov province, and in parts of Siberia. Other guerrillas opposed the Japanese occupation of the Russian Far East.\\r\\nDespite a common misconception, both Nationalist and Communist forces maintained active underground resistance in Japanese-occupied areas during the Second Sino-Japanese War. Even before the outbreak of total war in 1937, partisans were already present in Manchuria hampering Japan's occupation of the region. After the initial phases of the war, when large swaths of the North China Plain rapidly fell to the Japanese, underground resistance, supported by either Communist sympathizers or composed of disguised Nationalist soldiers, would soon rise up to combat the garrison forces. They were quite successful, able to sabotage railroad routes and ambush reinforcements. Many major campaigns, such as the four failed invasions of Changsha, were caused by overly-stretched supply lines, lack of reinforcements, and ambushes by irregulars. The Communist cells, many having decades of prior experience in guerrilla warfare against the Nationalists, usually fared much better, and many Nationalist underground groups were subsequently absorbed into Communist ones. Usually in Japanese-occupied areas, the IJA only controlled the cities and railroad routes, with most of them countryside either left alone or with active guerrilla presence. The People's Republic of China has emphasized their contribution to the Chinese war effort, going as far to say that in addition to a \\"overt theatre\\", which in many cases they deny was effective, there was also a \\"covert theatre\\", which they claim did much to stop the Japanese advance.\\r\\nMany clandestine organizations (often known as resistance movements) operated in the countries occupied by German Reich during the Second World War. These organizations began forming as early as 1939 when, after the defeat of Poland, the members of what would become the Polish Home Army began to gather. In March 1940, a partisan unit of the first guerrilla commanders in the Second World War in Europe under Major Henryk Dobrzaski \\"Hubal\\" completely destroyed a battalion of German infantry in a skirmish near the village of Huciska.[31]\\r\\nA guerrilla movement in Ethiopia was formed to rout out Italian forces as early as 1935. Other clandestine organizations operated in Denmark, Belgium, Norway, France (Resistance), France (Maquis), Czechoslovakia, Slovakia, Yugoslavia (Royalist Chetniks), Yugoslavia (Partisans), Soviet Union, Italy, Albania and Greece. From the second half of 1944, the total forces of the Yugoslav Partisans numbered over 500,000 men organized in four field armies, which engaged in conventional warfare.[32] By 1944 the Polish resistance was thought to number 600,000.[33] Many of these organizations received help from the British operated Special Operations Executive (SOE) which along with the commandos was initiated by Winston Churchill to \\"set Europe ablaze.\\" The SOE was originally designated as 'Section D' of MI6 but its aid to resistance movements to start fires clashed with MI6's primary role as an intelligence-gathering agency. When Britain was under threat of invasion, SOE trained Auxiliary Units to conduct guerrilla warfare in the event of invasion. Even the Home Guard were trained in guerrilla warfare in the case of invasion of England.\\r\\nOsterly Park was the first of 3 such schools established to train the Home Guard. Not only did SOE help the resistance to tie down many German units as garrison troops, so directly aiding the conventional war effort, but also guerrilla incidents in occupied countries were useful in the propaganda war, helping to repudiate German claims that the occupied countries were pacified and broadly on the side of the Germans. Despite these minor successes, many historians believe that the efficacy of the European resistance movements has been greatly exaggerated in popular novels, films and other media.[citation needed]\\r\\nContrary to popular belief, in the Western and Southern Europe the resistance groups were only able to seriously counter the German in areas that offered the protection of rugged terrain.[citation needed] In relatively flat, open areas, such as France, the resistance groups were all too vulnerable to decimation by German regulars and pro-German collaborators. Only when operating in concert with conventional Allied units were the resistance groups to prove indispensable.[citation needed]\\r\\nAll the clandestine resistance movements and organizations in the occupied Europe were dwarfed by the partisan warfare that took place on the vast scale of the Eastern Front combat between Soviet partisans and the German Reich forces. The strength of the partisan units and formations can not be accurately estimated, but in Belorussia alone is thought to have been in excess of 300,000.[34] This was a planned and closely coordinated effort by the STAVKA which included insertion of officers and delivery of equipment, as well as coordination of operational planning with the regular Red Army forces such as Operation Concert in 1943 (commenced 19 September) and the massive sabotage of German logistics in preparation for commencement of Operation Bagration in the summer of 1944.[35]\\r\\nGuerrilla tactics were employed in the war in the Pacific as well. When Japanese forces invaded the island of Timor on 20 February 1942, they were resisted by a small, under-equipped force of Allied military personnel known as Sparrow Forcepredominantly from Australia, United Kingdom, and the Netherlands East Indies. Although Portugal was not a combatant, many East Timorese civilians and some Portuguese colonists fought with the Allies as guerrillas (criados), or provided food, shelter and other assistance. Some Timorese continued a resistance campaign following the Australian withdrawal.\\r\\nWhen the United States entered the war, the US Office of Strategic Services (OSS) co-operated and enhanced the work of SOE as well as working on its own initiatives in the Far East. Colonel Wendell Fertig in 1942 organized a large guerrilla force which harassed the Japanese occupation forces on the Philippine Island of Mindanao all the way up to the liberation of the Philippines in 1945. After the surrender of Bataan and Corregidor which was the last organized resistance against the Imperial Japanese Army, Filipino guerillas banded together and fought the Japanese throughout the war. They became a very important force during the liberation of the Philippines.\\r\\nOthers included Col. Aaron Bank, Col. Russell Volckmann, and Col. William R. Peers.[36] Volckmann commanded a guerrilla force which operated out of the Cordillera of Northern Luzon in the Philippines from the beginning of World War II to its conclusion. He remained in radio contact with US Forces, prior to the invasion of Lingayen Gulf.[37] Peers, who later became a general, commanded OSS Detachment 101 in Burma. Because it was never larger than a few hundred Americans, it relied on support from various Burmese tribal groups. In particular, the vigorously anti-Japanese Kachin people were vital to the unit's success.[36][38]\\r\\nThe Chindits ÿ officially in 1943 77th Indian Infantry Brigade and in 1944 3rd Indian Infantry Division ÿ were a British India \\"Special Force\\" that served in Burma and India in 1943 and 1944 during the Burma Campaign. They were formed to put into effect Orde Wingate's newly developed guerilla warfare tactic of long range penetration.\\r\\nThe Japanese military themselves also used guerrilla warfare during the later part of the Pacific War, when Japan's resource was already dwindling and the Allies have started invading. Tadamichi Kuribayashi famously used guerrilla warfare during the Battle of Iwo Jima, where the general used network of tunnels and caves to attack American forces. His tactic was somewhat successfully, delaying the Americans from taking Iwo Jima for 36 days. The same tactic was used during the Battle of Okinawa.\\r\\nAfter World War II, during the 1940s and 1950s, thousands of fighters in Estonia, Latvia and Lithuania (see Forest Brothers, Latvian national partisans, Lithuanian partisans (1944ÿ1953)) participated in unsuccessful guerrilla warfare against Soviet occupation.[39] In Lithuania guerrilla warfare was massive until 1958 and the last fighter in Estonia was discovered and killed in 1978.\\r\\nWithin the United States, the Vietnam War is commonly thought of as a guerrilla war. However, this is a simplification of a much more complex situation which followed the pattern outlined by Maoist theory.[citation needed]\\r\\nThe National Liberation Front (NLF), drawing its ranks from the South Vietnamese peasantry and working class, used guerrilla tactics in the early phases of the war. However, by 1965 when U.S. involvement escalated, the National Liberation Front was in the process of being supplanted by regular units of the North Vietnamese Army.[citation needed]\\r\\nThe NVA regiments organized along traditional military lines, were supplied via the Ho Chi Minh trail rather than living off the land, and had access to weapons such as tanks and artillery which are not normally used by guerrilla forces. Furthermore, parts of North Vietnam were \\"off-limits\\" by American bombardment for political reasons, giving the NVA personnel and their material a haven that does not usually exist for a guerrilla army.[citation needed]\\r\\nOver time, more of the fighting was conducted by the North Vietnamese Army and the character of the war become increasingly conventional. The final offensive into South Vietnam in 1975 was a mostly conventional military operation in which guerrilla warfare played a minor, supporting role.[citation needed]\\r\\nThe Cu Chi Tunnels (D?a ??o C? Chi) was a major base for guerrilla warfare during the Vietnam War. Located about 60?km northwest of Saigon (Ho Chi Minh City), the Viet Cong (NLF) used the complex system tunnels to hide and live during the day and come up to fight at night.[citation needed]\\r\\nThroughout the Vietnam War, the Communist Party closely supervised all levels of the conflict. The bulk of the VC/NLF were initially southerners, with some distinctive southern issues and sensibilities. Nevertheless, the VC/NLF was associated with the Northern Lao Dong Party which furnished it with supplies, weaponry and trained cadres, including regular NVA/PAVN troops. The Southern Communist party, the Peoples Revolutionary Party (PRP) organized in 1962, to participate in the insurgency, and COVSN, Central Office for Southern Vietnam, which partially controlled military activity. The general replacement of CV irregulars with NVA troops supplanted the original VC goals with those proposed by the NVA. As the 1968 Tet Offensive was primarily a VC operation in which large numbers of VC fighters were killed, increasing the role of the NVA in the war effort.[citation needed]\\r\\nThis is a set of tactics which were used frequently in the Vietnam War by the NVA.[citation needed]\\r\\nThe Central Intelligence Agency raised a guerrilla army to oppose PAVN invaders of the Kingdom of Laos. Consisting principally Hmong hill tribesmen, L'Armee Clandestine under General Vang Pao was the only guerrilla army to ever enjoy air supremacy. It fought the Vietnamese regulars from 1961ÿ1975 before reduced numbers and dwindling American support led to their defeat.[40]\\r\\nThe Soviet invasion of Afghanistan started with a rapid takeover of the major cities but then turned into a decade-long guerilla resistance. The Afghan side was a collection of tribes who initially fought with obsolete weapons such as rifles from the 19th century or the First World War. The resistance fighters were known collectively as the Mujahideen. The United States started to support the Afghanistan resistance with gradually more potent weapons and eventually anti-tank and anti-aircraft missiles which then would cause so much damage to the far larger Soviet army that the Soviet Union abandoned its occupation and retreated back to the Soviet Union.\\r\\nPakistan Army Regulars disguised as locals together with local militias carried out a 6 months long Guerrilla campaign in Indian Occupied Kashmir for the Independence of The State of Kashmir, it came to an end after an all out war between Pakistan and India in September 1965.\\r\\nMukti Bahini (Bengali: ?????? ?????? \\"Liberation Army\\") collectively refers to the armed organizations who fought against the Pakistan Army during the Bangladesh Liberation War. It was dynamically formed by (mostly) Bengali regulars and civilians after the proclamation of independence for Bangladesh (formerly East Pakistan) on March 26, 1971. Subsequently, by mid-April 1971 the former members of East Pakistan armed forces formed the \\"Bangladesh Armed Forces\\" and M A G Osmani assumed the command of the same. The civilian groups continued to assist the armed forces during the war. After the war \\"Mukti Bahini\\" became the general term to refer to all forces (military and civilian) of former East Pakistani origin fighting against the Pakistani armed forces during the Bangladesh Liberation War. Often Mukti Bahini operated as an effective guerrilla force to keep their enemies on the run. It has been compared to the French Maquis, the Viet Cong, and the guerrillas of Josip Broz Tito in their tactics and effectiveness.[41]\\r\\nIn the late 1960s the Troubles began again in Northern Ireland. They had their origins in the partition of Ireland during the Irish War of Independence. They came to an end with the signing of the Good Friday Agreement in 1998. The violence was characterised by an armed campaign against the British presence in Northern Ireland by the Provisional Irish Republican Army, British counter-insurgency policy, and attacks on civilians by both loyalists and republicans. There were also allegations of collusion between loyalist paramilitaries and British security forces, and to a lesser extent, republicans and both British and Irish security forces.[42][43][44][45][46]\\r\\nAlthough both loyalist and republican paramilitaries carried out terrorist atrocities against civilians which were often tit-for-tat, a case can be made for saying that attacks such as the Provisional IRA carried out on British soldiers at Warrenpoint in 1979 was a well planned guerrilla ambush.[47] Anti-Good Friday Agreement splinter groups could be called guerrillas but are usually called terrorists or dissidents by governments of both the British and Irish governments. The news media such as the BBC and CNN will often use the term \\"gunmen\\" as in \\"IRA gunmen\\"[48] or \\"Loyalist gunmen\\".[49] Since 1995 CNN also uses guerrilla as in \\"IRA guerrilla\\" and \\"Protestant guerrilla\\".[50] Reuters, in accordance with its principle of not using the word terrorist except in direct quotes, refers to \\"guerrilla groups\\".[51]\\r\\nIn the 1960s, 1970s, and 1980s, Latin America had several urban guerrilla movements whose strategy was to destabilize regimes and provoke a counter-reaction by the military. The theory was that a harsh military regime would oppress the middle classes who would then support the guerrillas and create a popular uprising.\\r\\nWhile these movements did destabilize governments, such as Argentina, Uruguay, Guatemala, and Peru to the point of military intervention, the military generally proceeded to completely wipe out the guerrilla movements, usually committing several atrocities among both civilians and armed insurgents in the process.\\r\\nSeveral other left-wing guerrilla movements, sometimes backed by Cuba, attempted to overthrow US-backed governments or right-wing military dictatorships. US-backed Contra guerrillas attempted to overthrow the left-wing Sandinista government of Nicaragua. The Sandinista Revolution saw the involvement of Women and the Armed Struggle in Nicaragua.\\r\\nDuring the eight-year IranÿIraq war, irregular warfare was used against Iraqi military. The Iranian Irregular Warfare Headquarters, the 65th Airborne Special Forces Brigade of Iranian Army, and Peshmerga of Iraqi Kurdistan were involved.\\r\\nThe Greek Marxist 17 November disbanded around 2002 following the capture and imprisonment of much of its leadership.\\r\\nThe ongoing war between pro-independence groups in Chechnya and the Russian government is currently the most active guerrilla war in Europe. Most of the incidents reported by the Western news media are very gory terrorist acts against Russian civilians committed by Chechen separatists outside Chechnya. However, within Chechnya the war has many of the characteristics of a classic guerrilla war. See the article History of Chechnya for more details.\\r\\nIn Northern Ireland, the Real Irish Republican Army and the Continuity Irish Republican Army, two small, radical splinter groups who broke with the Provisional Irish Republican Army, continue to exist. They are dwarfed in size by the Provisional IRA and have been less successful in terms of both popularity among Irish republicans and guerrilla activity: The Continuity IRA has failed to carry out any killings, while the Real IRA's only attacks resulting in deaths were the 1998 Omagh bombing, which killed 29 civilians, a booby trap torch bomb in Derry which killed a former Ulster Defence Regiment soldier, and a 2009 attack on a Northern Ireland military installation which killed 2 British soldiers and wounded several others.\\r\\nAfter 1979 Revolution, the Iranian Defence Minister Mostafa Chamran established the Irregular Warfare Headquarters as part of the Iranian Armed Forces. He employed the force against Iraqi military during the IranÿIraq war. The unit was later disbanded.\\r\\nMany guerrilla tactics are used by the Iraqi insurgency against the U.S.-led coalition. Such tactics include the bombing of vehicles and human targets, suicide bombings, ambushes, sniper attacks, and traditional hit and run raids. Although it is unclear how many U.S. casualties can be attributed to insurgent guerrilla action because of the high numbers of non-combat related injuries and deaths being included in all available statistics of total coalition casualties,[citation needed] it is estimated that they have injured more than 18,000 coalition troops and killed over 3,900, including more than 3,000 U.S. soldiers. In addition the Sunni insurgents established de facto control over the Al Anbar Governorate and Diyala Governorate, over a third of Iraq's land.[52] Insurgent control was maintained despite a series of coalition campaigns; the worsening violence in Baghdad led to the recall of coalition forces, ensuring continued insurgent control.[53][54][55]\\r\\nEuropean Jews fleeing from anti-Semitic violence (especially Russian pogroms) immigrated in increasing numbers to Palestine. When the British restricted Jewish immigration to the region (see White Paper of 1939), Jewish immigrants began to use guerrilla warfare against the British for two purposes: to bring in more Jewish refugees, and to turn the tide of British sentiment at home. Jewish groups such as the Lehi and the Irgun ÿ many of whom had experience in the Warsaw Ghetto battles against the Nazis, fought British soldiers whenever they could, including the bombing of the King David Hotel. They also conducted attacks against the Arabs, and prepared the infrastructure for the coming 1948 conflict.\\r\\nThe Jewish irregular forces were fighting the British Empire, which had just emerged victorious from World War II. Some of these groups were amalgamated into the Israel Defense Forces and subsequently fought in the 1948 War of Independence.\\r\\nThe Naxal insurgency in West Bengal was the beginning of the rising of Maoists in eastern India. The Naxals, begun their People's War through radical students in the city of Calcutta, however it continues today, having its bases in rural India and top universities. The area under maoist control has been viewed as a war zone and the group itself has been called the biggest threat to Indian Security by the Prime Minister.\\r\\nKhalistan movement was a movement initiated by the Sikhs of the Indian Punjab. The Punjab region is of historical and religious significance for Sikhs and was contested during the separation of United India. Though it ended in India in the 1980s, the Khalistan movement still has supporters across the world, mainly in Canada, and the British Sikh Community.\\r\\nOne of the proponents of the ideology are the Khalistan Zindabad Force\\r\\nThe Taliban uprising took place after Afghanistan's invasion by Allied forces in 2001. As in the earlier wars against the British and Soviets, Afghan resistance to the NATO intervention took the traditional form of a Muslim \\"holy war (Jihad) against the infidels\\".[56] As with the Soviet invasion of Afghanistan 20 years earlier, the Taliban took refuge in the Pakistani Mountain areas and continue to move across the border between Afghanistan and Pakistan, often evading Pakistani and NATO forces. The Taliban have now become a dominant role in the Afghan life once again.[citation needed] The Pakistani Government have been accused of supporting and/or turning a blind eye to the Afghan Taliban, while the Pakistani Government has accused NATO of doing the same.","input":"When was guerrilla warfare used in the revolutionary war?"},{"output":"southern, eastern and central England","context":"The United Kingdom straddles the higher mid-latitudes between 49 and 61?N. It is on the western seaboard of Afro-Eurasia, the world's largest land mass. Since the UK is always in or close to the path of the polar front jet stream, frequent changes in pressure and unsettled weather are typical. Many types of weather can be experienced in a single day. In general the climate of the UK is cool and often cloudy, and hot temperatures are infrequent.\\r\\nThe climate in the United Kingdom is defined as a temperate oceanic climate, or Cfb on the K?ppen climate classification system, a classification it shares with most of north-west Europe.[1] Regional climates are influenced by the Atlantic Ocean and latitude. Northern Ireland, Wales and western parts of England and Scotland, being closest to the Atlantic Ocean, are generally the mildest, wettest and windiest regions of the UK, and temperature ranges here are seldom extreme. Eastern areas are drier, cooler, less windy and also experience the greatest daily and seasonal temperature variations. Northern areas are generally cooler, wetter and have slightly larger temperature ranges than southern areas.\\r\\nThe UK is mostly under the influence of the maritime polar air mass from the north-west. Northern Ireland and the west of Scotland are the most exposed to the maritime polar air mass which brings cool moist air; the east of Scotland and north-east England are more exposed to the continental polar air mass which brings cold dry air. South and south-east of England are the least exposed to Polar air masses from the north-west, and on occasion see continental tropical air mass from the south, which brings warm dry air in the summer.\\r\\nIf the air masses are strong enough in their respective areas during the summer, there can sometimes be a large difference in temperature between the far north of Scotland (including the Islands) and south-east of England ÿ often a difference of 10ÿ15?C (18-27?F) but sometimes of as much as 20?C (36?F) or more. In the height of summer the Northern Isles could have temperatures around 15?C (59?F) and areas around London could reach 30?C (86?F).\\r\\n\\r\\n\\r\\nEngland generally has higher maximum & minimum temperatures than the other areas of the UK, though Wales has higher minima from November to February, and Northern Ireland has higher maxima from December to February. England is also sunnier throughout the year, but unlike Wales, Northern Ireland & Scotland, the sunniest month is July, totalling 193.5 hours. It rains on fewer days in every month throughout the year than the rest of the UK, and rainfall totals are less in every month, with the driest month, May, averaging 58.4?mm (2.30?in).[2] The climate of south-west England displays a seasonal temperature variation, although it is less extreme than most of the United Kingdom. Gales are less common in England compared to Scotland; however on some occasions there can be strong winds, and rarely, the remains of Atlantic hurricanes and tropical storms. Some events such as the Great Storm of 1987 occurred near to the UK and caused damage in England. The prevailing wind direction for England is from the south-west.\\r\\n\\r\\nNorthern Ireland is warmer than Scotland throughout the year. Maximum temperatures are milder than in Wales from December to April, and milder than in England from December to February, but Northern Ireland is cooler during the rest of the year. Sunshine totals in every month are more than those of Scotland, but less than those of the rest of Great Britain. Northern Ireland is drier and has fewer rainy days than Scotland throughout the year, except in May, when it rains on more days. Northern Ireland is also drier than Wales in every month, yet it rains on more days. The rainiest month is January, when 17.8 days have more than 1?mm (0.04?in) of rain on average.[11]\\r\\nScotland has the coolest weather of any country in the United Kingdom throughout the year (with the climate at altitude varying into Cfc), with average minimum temperatures in January of ?0.2?C (31.6?F).[12] Scotland is also the wettest country in every month, apart from May, June and December, when Wales is wetter. The wettest month is January, with 170.5?mm (6.71?in) on average.[12] Scotland is also the cloudiest country throughout the year, apart from June and July, when Northern Ireland is.\\r\\nWales has warmer temperatures throughout the year than Scotland, and has milder winter minima than England, but cooler winter maxima than Northern Ireland. Wales is wetter throughout the year than Northern Ireland and England, but has fewer rainy days than Northern Ireland; meaning that rainfall tends to be more intense. Wales is also drier than Scotland in every month apart from May, June and December, and there are fewer days with rain than in Scotland. Sunshine totals throughout the year are more than that of Scotland and Northern Ireland, but less than that of neighbouring England. May is the sunniest month, averaging 186.8 hours.[17]\\r\\nSpring is the period from March to May. Spring is generally a calm, cool season, particularly because the Atlantic has lost much of its heat throughout the autumn and winter. As the sun rises higher in the sky and the days get longer, temperatures slowly rise, but the solar effect is mitigated somewhat by the effect of the cool ocean waters and westerly winds that blow across them.\\r\\nThere is a fair chance of snow earlier in the season when temperatures are colder - often in March. Some of the country's heaviest snowfalls of recent years have happened in the first half of March, and snow showers can occur infrequently until mid-April. They have been known to develop as late as mid-May over some areas of the country, such as in 2013 when snow was recorded on 14 May over parts of Staffordshire, Herefordshire and Wales. Snow was also recorded at lower levels in early June 1975. More recently, there was a disruptive snow event between 26 and 29 April 2016 across much of Northern England and Scotland, which was unusually the only significant snow event of the winter 2015/16. Snow, frost and ice can be disruptive and damaging to flowering plants, particularly later in the spring.\\r\\nEarly spring can be quite cold, and occasionally the lowest temperatures of the year can occur in March, as it did at Heathrow Airport on 5 March 2001, 4 March 2006 and 8 March 2011. Temperatures below freezing are not unusual in March, even in the south of the UK. On the other hand, high temperatures above 30?C are generally rare but can occur on occasion; most recently on 25 May 2012. It was even hotter on 27 May 2005, when 31.9?C was recorded in London. Rarely, the hottest day of the year can be in spring. As stated below, 27 May was the hottest day of the year in 2012 in most parts of the UK. In Aberdaron, the hottest day of 2011 was very early on in the year on 21 April. Temperatures in March seldom reach 20?C, as they did in 1990, 1993, 2012 and 2017, and this temperature is usually reached for the first time in April or May. Throughout spring, there can be very dramatic temperature swings between day night. On 9 April 2017, night-time temperatures fell to just 3?C at Northolt, but 25?C was reached in the afternoon. Warmth in Spring depends almost entirely on the strength of the sun, and can trigger thunderstorms and downpours.\\r\\nMean temperatures in Spring are markedly influenced by latitude. Most of Scotland and the mountains of Wales and northern England are the coolest areas of the UK, with average temperatures ranging from ?0.6 to 5.8?C (30.9 to 42.4?F).[18] The southern half of England experiences the warmest spring temperatures of between 8.8 and 10.3?C (47.8 and 50.5?F).[18]\\r\\nSummer lasts from June to August and is the warmest and usually the sunniest season. Rainfall totals can have a wide local variation due to localised thundershowers. These thundershowers mainly occur in southern, eastern, and central England and are less frequent and severe in the north and west.[19] Climatic differences at this time of year are more influenced by latitude and proximity to the ocean. Temperatures are the highest in southern and central areas and lowest in the north. Hot weather above 27?C in most places and in most years occurs on multiple days per year, but more frequently in London and south-east England and less so in parts of Scotland.[20] The record maximum is 38.5?C (101.3?F) recorded in Faversham, Kent on 10 August 2003.[21]\\r\\nAutumn in the United Kingdom lasts from September to November.[22] The season is notorious for being unsettledas cool polar air moves southwards following the sun, it meets the warm air of the tropics and produces an area of great disturbance along which the country lies. This combined with the warm ocean due to heating throughout the spring and summer, produces the unsettled weather of autumn. In addition, when the air is particularly cold temperatures on land may be colder than the ocean, resulting in significant amounts of condensation and clouds which bring rain to the country.\\r\\nAtlantic depressions during this time can become intense and winds of hurricane force (greater than 119?km/h or 74?mph) can be recorded. Western areas, being closest to the Atlantic, experience these severe conditions to a significantly greater extent than eastern areas. As such, autumn, particularly the latter part, is often the stormiest time of the year. One particularly intense depression was the Great Storm of 1987. A very severe storm affected the UK on 27 October 2002 which, at Mumbles head near Swansea, recorded maximum sustained wind speeds of over 123?km/h, equivalent to a category 1 hurricane.[23] The autumn of 2013 was also littered with severe storms, including the St. Jude's Storm on 28 October 2013.\\r\\nAutumn can also be a cold season at times - in recent years, very low temperatures and heavy snowfall have been recorded during November 1985, November 1993 & November 2010, which set a new record low of -18.0?C in Wales on 28 November 2010. At Northolt, the coldest temperature of the year 2016 was set on 30 November. Snow also fell rather widely across the UK on 28 & 29 October 2008, causing traffic problems where it settled on the M4. Even further south, low temperatures can be recorded, with temperatures well below freezing as far south as Heathrow Airport between 29 & 31 October 1997 - for context, the low of 30 October 1997 recorded was lower than any recorded at this station in March, November or December 1997 and even the following January, 1998 - only the low temperatures on 2 & 4 February 1998 prevented it from being the lowest temperature of the winter at this station. The first frosts of the winter are usually recorded between October & December, but they are quite unusual in September except on high ground when the surrounding ocean is at or near its warmest. It is not particularly unusual for September to be warmer than June, as it was in 1999.[24]\\r\\nHowever, the United Kingdom sometimes experiences an 'Indian Summer', where temperatures particularly by night can be very mild and rarely fall below 10?C (50?F). Such events are aided by the surrounding Atlantic Ocean and seas being at their warmest, keeping the country in warm air, despite the relatively weak sun. Examples of this were in 1985, 1999, 2005, 2006, 2011[25] and 2016 where September saw above average temperatures which felt more like a continuation of summer than autumn. Autumns since 2000 have generally been very mild with notable extremes of precipitation; the UK has seen some of its wettest and driest autumns since the millennium. 2011 and 2016 were notable as many areas of the country recorded their highest temperatures of the year in September and October (for example, 28.2?C at Hawarden on 1 October, 26.3?C at St. Athan on 2 October 2011 and the UK's highest temperature of 2016 on 13 September with 34.4?C at Gravesend).[26]\\r\\nCoastal areas in the southern half of England have on average the warmest autumns, with mean temperatures of 10.7 to 13.0?C (51.3 to 55.4?F).[27] Mountainous areas of Wales and northern England, and almost all of Scotland, experience mean temperatures between 1.7 and 7.5?C (35.1 and 45.5?F).[27]\\r\\nWinter in the UK is defined as lasting from December to February. The season is generally cool, wet, windy, and cloudy. Temperatures at night rarely drop below ?10?C (14?F) and in the day rarely rise above 15?C (59?F). Precipitation is plentiful throughout the season, though snow is relatively infrequent despite the country's high latitude: The only areas with significant snowfall are the Scottish Highlands and the Pennines, where at higher elevations a colder climate determines the vegetation, mainly temperate coniferous forest, although deforestation has severely decreased forest area. For a majority of the landmass snow is possible but not frequent, apart from the higher altitudes, where snow can lie 1ÿ5 months or even beyond 6 months.\\r\\nTowards the later part of the season the weather usually stabilises with less wind, less precipitation and lower temperatures. This change is particularly pronounced near the coasts mainly because the Atlantic ocean is often at its coldest during this time after being cooled throughout the autumn and the winter. The early part of winter however is often unsettled and stormy; often the wettest and windiest time of the year.\\r\\nSnow falls intermittently and mainly affects northern and eastern areas, high ground in Wales and especially the mountains of Scotland, where there is often enough snow lying to permit skiing at some of the five Scottish ski resorts. These resorts usually operate between December and April, depending on the snowfall. Frequently in the mountains potent depressions may move in from the north in the form of 'polar lows', introducing heavy snow and often blizzard-like conditions to parts of the United Kingdom, particularly Scotland. Blizzards have become rarer in the 21st century, although much of England was affected by one on 30 January 2003. During periods of light winds and high pressure frost and fog can become a problem and can pose a major hazard for drivers on the roads.\\r\\nMean winter temperatures in the UK are most influenced by proximity to the sea. The coldest areas are the mountains of Wales and northern England, and inland areas of Scotland, averaging ?3.6 to 2.3?C (25.5 to 36.1?F).[28] Coastal areas, particularly those in the south and west, experience the mildest winters, on average 5 to 8.7?C (41.0 to 47.7?F).[28] Hardiness zones in the UK are high, ranging from zone 7 in the Scottish Highlands, the Pennines and Snowdonia, to zone 10 on the Isles of Scilly. Most of the UK lies in zones 8 or 9.[29] In zone 7, the average lowest temperature each year is between ?17.7 and ?12.3?C (0.1 and 9.9?F), and in zone 10, this figure is between ?1.1 and 4.4?C (30.0 and 39.9?F).[30]\\r\\nSnow in the UK falls almost every year, but in small quantities. The UK can suffer extreme winters like 1684, 1740, 1795 (when London received its record lowest temperature of ?21.1?C (?6.0?F)), 1947 and 1963. In 1963 it snowed on Boxing Day, and snow lasted in most areas until 6 March, with blizzards through February, which had significant and documented effects on the FA Cup - Wrexham were forced to play on sand for one tie. In modern times snow has generally become rarer, but the UK can still get heavy falls, such as in 1978/79, 1981/82, 1986/87 and 1990/91. The winter of 2008/09 produced the heaviest snowfall since 1991 between 1 and 3 February, and the winter of 2009-10 was even more severe, with many parts of the United Kingdom experiencing the coldest and snowiest winters since 1978/79; temperatures plummeted to ?22.3?C (?8.1?F) at Altnaharra, Sutherland ÿ close to the ?22.9?C (?9.2?F) recorded at the southernmost part of the globe[South Pole?] in the same period. The lowest temperature ever recorded in the UK was ?27.2?C (?17.0?F) which was recorded on 10 January 1982 and 11 February 1895 in Braemar, Scotland and on 30 December 1995 in Altnaharra, Scotland. December 2010 was the coldest December in 120 years; the CET (Central England Temperature) was -0.7?C; it was the coldest month since February 1986, and the coldest December since 1890. Many places had heavy snowfall and extreme cold, temperatures regularly fell below ?10.0?C (14.0?F)) across many areas. However, the cold subsided after Christmas Day, 2010. November 2010 saw an extremely severe cold snap, with lows of ?18.0?C (?0.4?F)) in Llysdinam on 28 November. The month saw temperatures below average, despite what was actually a very mild first half. Spring 2013 was also notoriously cold: March 2013 was the coldest month of the winter (and indeed 2013 as a whole), which is quite striking given that December 2012, January and February 2013 were all also below average in terms of temperature. The following winter was the opposite - in many places, only on 11 and 12 January was any snow recorded (some places having no snow at all), and the entire country was battered by a series of severe depressions and storms. The St Jude's Day storm first affected the UK on 26 October 2013, and many places saw no respite until a high swept across the country on 2 March 2014. Parts of the Somerset levels remained under water for most of the winter and well into spring. Record-equalling gusts of 142?mph were recorded off the north coast of Scotland on 5 December 2013, with notably severe storms also recorded on 2 November 2013, 24 December 2013, 3 January 2014 and 14 February 2014.\\r\\nIn the 1990s and 2000s, most of the winters were milder and usually wetter than average with daytime temperatures going below freezing a rare occurrence. In fact, the winter of 1995/1996 was the only one which was defined as below average in terms of the UK as a whole, although February 1991 saw heavy snowfall & January 1997 was cold in the South. The winters of 2008/09, 2009/10 and 2010/11 have however seen a different pattern with these three winters being defined as below or well below average with large snowfall amounts widespread and very low temperatures; this was the first time three consecutive cold winters in the UK have occurred since the 1960s. Since the winter of 2012/2013, winters have been mild (exceptionally so in 2013/2014 and 2015/2016), although exceptionally wet. The winter of 2014/2015 was an oddity, in that it was generally quiet and sunny. December 2014 & January 2015 were a little milder than the average, February 2015 was close to normal. The winter of 2016/17 was very nearly a very cold winter owing to the presence and position of high pressure, although ultimately only November 2016 was cold widely as a whole. Early December 2016 was cool and January 2017 was cold in the south-east, with much of the rest of England and Wales near the 1961-1990 average. At Northolt, the average minimum for January 2017 was below freezing for the first time since December 2010.\\r\\nDecember 2015 became the wettest calendar month ever recorded in the United Kingdom, with January 2016 becoming the second wettest. In these months, some northern and western parts had 2 to 4 times as much rainfall as normal.[31] December 2015 was also the warmest December averaged over the whole UK, and had the highest positive anomaly for any month in the Central England temperature series which began in 1659 (CET was 9.7?C, this is warmer than even any March[32]). Most areas of southern England had average monthly temperatures 5-6?C above normal. Some plants flowered that would normally do so in the Spring or even Summer.[33] Hardly any stations in Wales and Southern England recorded any air frosts and temperatures were often comparable to those of April or May. The maximum recorded temperature was 17.2?C at Teignmouth in Devon and Plockton and Achnagart in the highlands of Scotland on 16th. The lowest daily mean temperature during December 2015 at Heathrow Airport was still 8.2?C on 9 December, comparable to the average daily high for the calendar month. Remarkably, December 2015 did not break any national records for high temperatures, just failing to reach the maximum England temperature of 17.7?C recorded on 2 December 1985 in Chivenor, Devon and on 11 December 1994 in Penkridge, Staffordshire.[34] Despite the warmth, it was the dullest December since 1989.[35]\\r\\nThe average total annual sunshine in the United Kingdom is 1339.7 hours, which is just under 30% of the maximum possible (The maximum hours of sunshine possible in one year is approximately 4476 hours).[36] Generally the United Kingdom sees frequent cloudy skies due to its high latitude and oceanic controlled climate. The lowest sunshine hours are found in northern parts of the country and the highest in the southern parts and southern coast of England. The counties of Dorset, Hampshire, Sussex and Kent are the sunniest areas, which have annual average totals of around 1,750 hours of sunshine per year.[37] Northern, western and mountainous areas are generally the cloudiest areas of the UK, with some mountainous areas receiving fewer than 1,000 hours of sunshine a year.[37]\\r\\nValley areas such as the South Wales Valleys, due to their north-south orientation, receive less sunshine than lowland areas because the mountains on either side of the valley obscure the sun in the early morning and late evening. This is noticeable in winter where there are only a few hours of sunshine. The mountains of Wales, northern England and Scotland can be especially cloudy with extensive mist and fog. Near the coast, sea fog may develop in the spring and early summer. Radiation fog may develop over inland areas of Great Britain and can persist for hours or even days in the winter and can pose a major hazard for drivers and aircraft.\\r\\nOn occasions blocking anticyclones (high pressure systems) may move over the United Kingdom, which can persist for weeks or even months. The subsided, dry air often results in clear skies and few clouds, bringing frosty nights in winter and warm days in the summer.\\r\\nAverage hours of sunshine in winter range from 38ÿ108 hours in some mountainous areas and western Scotland, up to 217 hours in the south and east of England;[38] while average hours of sunshine in summer range from 294ÿ420 hours in northern Scotland and Northern Ireland, to 600ÿ760 hours in southern English coastal counties.[39] The most sunshine recorded in one month was 383.9 hours at Eastbourne (East Sussex) in July 1911.[37]\\r\\nOne of the greatest influences on the climate of the UK is the Atlantic Ocean and especially the Gulf Stream, which carries warm water up from lower latitudes and modifies the high latitude air masses that pass across the UK. This thermohaline circulation has a powerful moderating and warming effect on the country's climate. This warm water current warms the climate to such a great extent that if the current did not exist then temperatures in winter would be about 10?C (18?F) lower than they are today and similar to eastern Russia or Canada near the same latitude. The current allows England to have vineyards at the same latitude that Canada has polar bears. These warm ocean currents also bring substantial amounts of humidity which contributes to the notoriously wet climate that western parts of the UK experience.\\r\\nThe extent of the Gulf Stream's contribution to the actual temperature in western Europe is a matter of dispute.[40][41] It has been argued that atmospheric waves that bring warm air northwards contribute to the warmer temperatures than thermohaline circulation.[40]\\r\\nThe high latitude and proximity to a large ocean to the west means that the United Kingdom experiences strong winds. The prevailing wind is from the south-west, but it may blow from any direction for sustained periods of time. Winds are strongest near westerly facing coasts and exposed headlands.\\r\\nGales  which are defined as winds with speeds of 51 to 101?km/h (32 to 63?mph) are strongly associated with the passage of deep depressions across the country. The Hebrides experience on average 35 days of gale a year (a day where there are gale-force winds) while inland areas in England and Wales receive fewer than 5 days of gale a year.[37] Areas of high elevation tend to have higher wind speeds than low elevations, and Great Dun Fell in Cumbria (at 857?m or 2,812?ft) averaged 114 days of gale a year during the period 1963 to 1976. The highest gust recorded at a low level in England was 191?km/h (119?mph) at Gwennap Head in Cornwall on 15 December 1979,[37] and a 115?mph gust was also recorded at Shoreham-By-Sea on 16 October 1987. A disputed 122?mph gust was recorded on 16 October 1987 at Gorleston in Norfolk during the Great Storm of 1987. In Scotland, Fraserburgh in Aberdeenshire recorded 229?km/h (142?mph) on 13 February 1989, which was equalled during Cyclone Xaver on 5 December 2013. Wales' highest wind speed gust of 200?km/h (124?mph) was set at Rhoose, Vale of Glamorgan on 28 October 1989. Especially potent storm systems typically affect the UK during autumn and winter, with the winters of 1989/1990 and 2013/2014 particularly notable for the frequency and potency of storm systems.\\r\\nAn unofficial gust of 194?mph was recorded on the Shetland Isles during the New Year's Day Storm on 1 January 1992, and an equal unofficial 194?mph wind gust is claimed to have been set in the Cairngorm Mountains on 19 December 2008.[42]\\r\\nBarometric pressure plays a role in storm systems. For the United Kingdom, record figures for barometric pressure recordings are:[43]\\r\\nHighest - 1053.6mb (Aberdeen, 31 January 1902)\\r\\nLowest - 925.6mb (Ochtertyre, 26 January 1884)\\r\\nNotably a low pressure storm system affected the UK with a central pressure of 914.0mb on 10 January 1993, however this figure is not recorded over the UK but out in the Atlantic, despite the system affecting the UK.\\r\\nRainfall amounts can vary greatly across the United Kingdom and generally the further west and the higher the elevation, the greater the rainfall. The mountains of Wales, Scotland, the Pennines in Northern England and the moors of South West England are the wettest parts of the country, and in some of these places as much as 4,577 millimetres (180.2?in) of rain can fall annually,[44] making these locations some of the wettest in Europe. The wettest spot in the United Kingdom is Crib Goch, in Snowdonia, which has averaged 4,473 millimetres (176.1?in) rain a year over the past 30 years.[45][46] Most rainfall in the United Kingdom comes from North Atlantic depressions which roll into the country throughout the year from the west or southwest and are particularly frequent and intense in the autumn and winter. They can on occasions bring prolonged periods of heavy rain, and flooding is quite common.\\r\\nParts of England are surprisingly dry, which is contrary to the stereotypical viewLondon receives just below 650 millimetres (25.6?in) per annum,[47] which is less than Rome, Sydney, or New York City. In East Anglia it typically rains on about 113 days per year.[48] Most of the south, south-east and East Anglia receive less than 700 millimetres (27.6?in) of rain per year.[37] The English counties of Essex, Cambridgeshire - as well as parts of North Yorkshire, the East Riding of Yorkshire, Suffolk and Norfolk - are amongst the driest in the UK, with an average annual rainfall of around 600 millimetres (23.6?in). This is due to a mild rainshadow effect, due to mountainous parts of the South West, Wales and Cumbria blocking the moist airflow across the country to the east. In some years rainfall totals in Essex and South Suffolk can be below 450 millimetres (17.7?in) (especially areas around Colchester, Clacton and Ipswich) - less than the average annual rainfall in Jerusalem, Beirut and even some semi-arid parts of the world.\\r\\nParts of the United Kingdom have had drought problems in recent years, particularly in 2004-2006. Fires broke out in some areas, even across the normally damp higher ground of north-west England and Wales. The landscape in much of England and east Wales became very parched, even near the coast; water restrictions were in place in some areas.\\r\\nJuly 2006 was the hottest month on record for the United Kingdom and much of Europe,[49] however England has had warmer spells of 31 days which did not coincide with a calendar monthin 1976 and 1995. As well as low rainfall, drought problems were made worse by the fact that the driest parts of England also have the highest population density, and therefore highest water consumption. The drought problems ended in the period from October 2006 to January 2007, which had well above average rainfall.\\r\\nDecember 2015 was the wettest month ever recorded in the United Kingdom.[50] The average rainfall for the month was almost doubled.[51]\\r\\nGenerally the United Kingdom has cool to mild winters and warm summers with moderate variation in temperature throughout the year. In England the average annual temperature varies from 8.5?C (47.3?F) in the north to 11?C (51.8?F) in the south, but over the higher ground this can be several degrees lower.[37] This small variation in temperature is to a large extent due to the moderating effect the Atlantic ocean haswater has a much greater specific heat capacity than air and tends to heat and cool slowly throughout the year. This has a warming influence on coastal areas in winter and a cooling influence in summer.\\r\\nThe ocean is at its coldest in February or early March, thus around coastal areas February is often the coldest month, but inland there is little to choose between February and January as the coldest.[37] Temperatures tend to drop lowest on late winter nights inland, in the presence of high pressure, clear skies, light winds and when there is snow on the ground. On occasions, cold polar or continental air can be drawn in over the United Kingdom to bring very cold weather.\\r\\nThe floors of inland valleys away from warming influence of the sea can be particularly cold as cold, dense air drains into them. A temperature of ?26.1?C (?15.0?F) was recorded under such conditions at Edgmond in Shropshire on 10 January 1982, the coldest temperature recorded in England and Wales. The following day the coldest maximum temperature in England, at ?11.3?C (11.7?F), was recorded at the same site.[37]\\r\\nOn average the warmest winter temperatures occur on the south and west coasts, however, warm temperatures occasionally occur due to a foehn wind warming up downwind after the crossing the mountains. Temperatures in these areas can rise to 15?C (59?F) in winter on rare occasions[52] This is a particularly notable event in northern Scotland, mainly Aberdeenshire, where these high temperatures can occur in midwinter when the sun only reaches about 10 above the horizon.\\r\\nJuly is on average the warmest month, and the highest temperatures tend to occur away from the Atlantic in southern, eastern and central England, where summer temperatures can rise above 30?C (86?F). It soared to 38.5?C (101.3?F) in Faversham, Kent on 10 August 2003: the highest temperature ever recorded in the United Kingdom.[53]\\r\\nWhile the United Kingdom is not particularly noted for extreme weather, it does sometimes occur, and events such as floods and drought may be experienced. The summer of 1976, for example, experienced temperatures as high as 35?C (95?F), and it was so dry the country suffered drought and water shortages.[54]\\r\\nExtended periods of extreme weather, such as the droughts of 1975ÿ1976, summer 2006, and spring 2012, the long hot summers of 1911, 1976, 2003 and 2006, and the winters of 1946ÿ1947, 1962ÿ1963, 2009ÿ2010, and 2010ÿ2011 are often caused by blocking anti-cyclones which can persist for several days, weeks, or even months. In winter they can bring long periods of cold dry weather and in summer long periods of hot dry weather.\\r\\nThere have also been occurrences of severe flash floods caused by intense rainfall; the most severe was the Lynmouth disaster of 1952 in which 34 people died and 38 houses and buildings were completely destroyed. In the summer of 2004, a severe flash flood devastated the town of Boscastle in Cornwall. However, the worst floods in the United Kingdom in modern times occurred in the North Sea flood of 1953. A powerful storm from the Atlantic moved around Scotland and down the east coast of England. As it moved south it produced a storm surge which was magnified as the North Sea became narrower further south. By the time the storm affected south-east England and the Netherlands, the surge had reached the height of 3.6 metres (12?ft). Over 300 people were killed by the floods in eastern England.\\r\\nThunderstorms are most common in southern and eastern England, and least common in the north and west.[55] In London, thunderstorms occur on average 14ÿ19 days a year, while in most of Northern Ireland and the west of Scotland thunderstorms occur on around 3 days a year.[55] Occasionally, thunderstorms can be severe and produce large hailstones as seen in Ottery St Mary, Devon in October 2008, where drifts reached 1.8 metres (5?ft 11?in).[56]\\r\\nStrong winds occur mainly in the autumn and winter months associated with low pressure systems and Scotland experiences hurricane-force winds in most winters. The Gale of January 1976, Great Storm of 1987 (23?fatalities) and the Burns' Day storm of 1990 (97?fatalities) are particularly severe examples; Scotland saw winds of 142?mph during Cyclone Xaver in 2013.[57]\\r\\nThe most rain recorded to fall on a single day was 279?mm at Martinstown (Dorset) on 18 July 1955,[37] but also 243?mm fell at Bruton, Somerset on 28 June 1917.[58] Heavy rain also fell between 20 and 25 June in 2007; some areas experienced a month's rainfall in one day. Four people died in the flooding and over S1.5?billion of damage to businesses and properties was caused. On 19 August 1993, London Heathrow Airport recorded 257mm of rainfall.\\r\\nTropical cyclones themselves do not affect the UK due to the seas being too cold ÿ they need temperatures above 26.5?C (79.7?F) to remain active. The waters near the UK, the Atlantic Ocean, only have temperatures of 2 to 18?C (36 to 64?F),[59] so any tropical cyclone that does come anywhere near the UK has said to have undergone a process called extratropical transition. This now means it is an extratropical cyclone, which the UK frequently experiences. The Great Storm of 1987 was a very deep depression which formed in the Bay of Biscay, which also contained the remnants of Hurricane Floyd.[60] Hurricane Lili of 1996 and Hurricane Gordon of 2006 both crossed the UK as strong extratropical cyclones with tropical storm-force winds, causing transport closures, power-cuts and flooding in Northern Ireland, Scotland and South West England. In 2011, the remnants of Hurricane Katia passed over northwestern Scotland with winds near 70?mph (110?km/h).\\r\\nIt is internationally recognised that the United Kingdom has a higher incidence of tornadoes, measured by unit area of land, than any other country in the world. Dr T. Theodore Fujita (inventor of the Fujita scale), an American meteorologist, was the first to recognise the UK as the top site for tornadoes in 1973.[61][62] The United Kingdom has at least 33 tornadoes per year,[63] more than any other country in the world relative to its land area.[64] Although most tornadoes are weak, there are occasional destructive events, for example, the Birmingham tornado of 2005 and the London tornado of 2006. Both registered F2 on the Fujita scale and both caused significant damage and injury. The largest ever recorded was thought to have been an F4, again in London in 1091. The most deadly occurred on 28 December 1879. All 74 lives were lost when a passenger train plunged from the Tay Bridge (Tayside) into the Tay Estuary, when the middle section of the bridge collapsed. Although the bridge was poorly constructed and had already been weakened in earlier gales (including the pre-existing winds at the time of the tragedy), the ultimate failure is believed to have been caused by two or three waterspouts which were sighted close to the bridge immediately before the accident.[65] A tornado also developed in London on 3 July 2007.\\r\\nThe UK also holds the title for the highest known 'outbreak' of tornadoes outside of the United States. The largest tornado outbreak in Britain is also the largest tornado outbreak known anywhere in Europe. On 23 November 1981, 105 tornadoes were spawned by a cold front in the space of 5.25 hours. Excepting Derbyshire, every county in a triangular area from Gwynedd to Humberside to Essex was hit by at least one tornado, while Norfolk was hit by at least 13. Very fortunately most tornadoes were short-lived and also weak (the strongest was around T5 on the TORRO Tornado Scale) and no deaths occurred.[65]\\r\\nThe climate of the United Kingdom has not always been the way it is today. During some periods it was much warmer and in others it was much colder. The last glacial period was a period of extreme cold weather that lasted for tens of thousands of years and ended about 10,000 years ago. During this period the temperature was so low that much of the surrounding ocean froze and a great ice sheet extended over all of the United Kingdom except the south of England (connected to mainland Europe via the dry English Channel) and southern coastal areas of Wales.\\r\\nThe cold period from the 16th to the mid-19th centuries is known as the Little Ice Age.\\r\\nThe temperature records in England are continuous back to the mid 17th century. The Central England temperature (CET) record is the oldest in the world, and is a compound source of cross-correlated records from several locations in central England. Precipitation records date back to the eighteenth century and the modern England and Wales Precipitation series begins in 1766.\\r\\nA detailed narrative account of the weather of every year from 1913 to 1942, with photographs of plants taken on the same day in each of those years, may be found in Willis (1944).[66]\\r\\nAs with many parts of the world, over the last century the United Kingdom has reported a warming trend in temperatures. While some of this may be due to a recovery from the cooler period of climate mid 20th century (particularly the 1960s) the last 20 years has nonetheless seen an unprecedented level of warm weather. This rise in temperatures is illustrated by the most recent dataset (1981ÿ2010) for Belfast and Cambridge Botanical Gardens, and the same data 50 years previous (1931ÿ1960).\\r\\nAs the above tables show, all months except December at Belfast exhibit warming when both maximum and minimum temperatures are taken into account.\\r\\nAgain, a similar warming trend is shown for the South East of England, albeit slightly more pronounced with no month recording a fall in overall mean temperatures.\\r\\nA disputed temperature of 42?C was set at an airfield in Wisley, Surrey on 18 July 2006. It has been suggested that the reading for this temperature should in fact have been 32?C. It is worth noting that the Met Office expected temperatures to surpass the August 2003 record during the July 2006 heatwave, and it is still speculated that both heatwaves did set higher temperatures than those officially recorded.\\r\\nCentral estimates produced by the Met Office predict average annual temperature to increase by 2?C (4?F) and the warmest summer day to increase by 3?C (6?F) by the 2050s. Average winter rainfall is also likely to increase and most areas will see a slight decrease in annual rainfall.[72]\\r\\nAccording to the Met Office, in the UK, the decade from 2000-2009 was the warmest since instrumental record dating started in 1850.[73]","input":"What is the hottest place in the british isles?"},{"output":"the ceiling decoration","context":"\\r\\n\\r\\nThe Sistine Chapel ceiling, painted by Michelangelo between 1508 and 1512, is a cornerstone work of High Renaissance art.\\r\\n\\r\\nThe ceiling is that of the Sistine Chapel, the large papal chapel built within the Vatican between 1477 and 1480 by Pope Sixtus IV, for whom the chapel is named. It was painted at the commission of Pope Julius II. The chapel is the location for papal conclaves and many other important services.[1]\\r\\n\\r\\nThe ceiling's various painted elements form part of a larger scheme of decoration within the Chapel, which includes the large fresco The Last Judgment on the sanctuary wall, also by Michelangelo, wall paintings by several leading painters of the late 15th century including Sandro Botticelli, Domenico Ghirlandaio and Pietro Perugino, and a set of large tapestries by Raphael, the whole illustrating much of the doctrine of the Catholic Church.[2][3]\\r\\n\\r\\nCentral to the ceiling decoration are nine scenes from the Book of Genesis of which The Creation of Adam is the best known, having an iconic standing equaled only by Leonardo da Vinci's Mona Lisa, the hands of God and Adam being reproduced in countless imitations. The complex design includes several sets of individual figures, both clothed and nude, which allowed Michelangelo to fully demonstrate his skill in creating a huge variety of poses for the human figure and which have provided an enormously influential pattern book of models for other artists ever since.\\r\\n\\r\\nPope Julius II was a \\"warrior pope\\" who in his papacy undertook an aggressive campaign for political control, to unite and empower Italy under the leadership of the Church. He invested in symbolism to display his temporal power, such as his procession, in the Classical manner, through a triumphal arch in a chariot after one of his many military victories. It was Julius who began the rebuilding of St. Peter's Basilica in 1506, as the most potent symbol of the source of papal power.[4]\\r\\n\\r\\nIn the same year 1506, Pope Julius conceived a program to paint the ceiling of the Sistine Chapel.[5] The walls of the chapel had been decorated twenty years earlier. The lowest of three levels is painted to resemble draped hangings and was (and sometimes still is) hung on special occasions with the set of tapestries designed by Raphael. The middle level contains a complex scheme of frescoes illustrating the Life of Christ on the right side and the Life of Moses on the left side. It was carried out by some of the most renowned Renaissance painters: Botticelli, Ghirlandaio, Perugino, Pinturicchio, Signorelli and Cosimo Rosselli.[6] The upper level of the walls contains the windows, between which are painted pairs of illusionistic niches with representations of the first thirty-two popes.[7] A draft by Matteo d'Amelia indicates that the ceiling was painted blue like that of the Arena Chapel and decorated with gold stars, possibly representing the zodiacal constellations. It is probable that, because the chapel was the site of regular meetings and Masses of an elite body of officials known as the Papal Chapel who would observe the decorations and interpret their theological and temporal significance, it was Pope Julius' intention and expectation that the iconography of the ceiling was to be read with many layers of meaning.[8]\\r\\n\\r\\nMichelangelo, who was not primarily a painter but a sculptor, was reluctant to take on the work. Also, he was occupied with a very large sculptural commission for the pope's own tomb. The pope was adamant, leaving Michelangelo no choice but to accept.[9] But a war with the French broke out, diverting the attention of the pope, and Michelangelo fled from Rome to continue sculpting. The tomb sculptures, however, were never to be finished because in 1508 the pope returned to Rome victorious and summoned Michelangelo to begin work on the ceiling. The contract was signed on 10 May 1508.[5]\\r\\n\\r\\nThe scheme proposed by the pope was for twelve large figures of the Apostles to occupy the pendentives.[10][11] However, Michelangelo negotiated for a grander, much more complex scheme and was finally permitted, in his own words, \\"to do as I liked\\".[12] His scheme for the ceiling eventually comprised some three hundred figures and took four years to execute, being completed and shown to the public on All Saints Day in 1512 after a preliminary showing and papal Mass on August 14, 1511.[5][9] It is unknown and is the subject of much speculation among art historians whether Michelangelo was really able to \\"do as he liked\\".[11] It has been suggested that the Augustinian friar and cardinal, Giles of Viterbo, was a consultant for the theological aspect of the work.[13] Many writers consider that Michelangelo had the intellect, the Biblical knowledge, and the powers of invention to have devised the scheme himself. This is supported by Ascanio Condivi's statement that Michelangelo read and reread the Old Testament while he was painting the ceiling, drawing his inspiration from the words of the scripture, rather than from the established traditions of sacral art.[14]\\r\\nA total of 343 figures were painted on the ceiling.\\r\\n\\r\\nTo reach the chapel's ceiling, Michelangelo designed his own scaffold, a flat wooden platform on brackets built out from holes in the wall near the top of the windows, rather than being built up from the floor. Mancinelli speculates that this was in order to cut the cost of timber.[15] According to Michelangelo's pupil and biographer Ascanio Condivi, the brackets and frame that supported the steps and flooring were all put in place at the beginning of the work and a lightweight screen, possibly cloth, was suspended beneath them to catch plaster drips, dust, and splashes of paint.[16] Only half the building was scaffolded at a time and the platform was moved as the painting was done in stages.[15] The areas of the wall covered by the scaffolding still appear as unpainted areas across the bottom of the lunettes. The holes were re-used to hold scaffolding in the latest restoration.\\r\\n\\r\\nContrary to popular belief, he painted in a standing position, not lying on his back. According to Vasari, \\"The work was carried out in extremely uncomfortable conditions, from his having to work with his head tilted upwards\\".[9] Michelangelo described his physical discomfort in a humorous sonnet accompanied by a little sketch.\\r\\n\\r\\nThe painting technique employed was fresco, in which the paint is applied to damp plaster. Michelangelo had been an apprentice in the workshop of Domenico Ghirlandaio, one of the most competent and prolific of Florentine fresco painters, at the time that the latter was employed on a fresco cycle at Santa Maria Novella and whose work was represented on the walls of the Sistine Chapel.[17] At the outset, the plaster, intonaco, began to grow mold because it was too wet. Michelangelo had to remove it and start again. He then tried a new formula created by one of his assistants, Jacopo l'Indaco, which resisted mold and entered the Italian building tradition.[16]\\r\\n\\r\\nBecause he was painting fresco, the plaster was laid in a new section every day, called a giornata. At the beginning of each session, the edges would be scraped away and a new area laid down.[15] The edges between giornate remain slightly visible; thus, they give a good idea of how the work progressed. It was customary for fresco painters to use a full-sized detailed drawing, a cartoon, to transfer a design onto a plaster surfacemany frescoes show little holes made with a stiletto, outlining the figures. Here Michelangelo broke with convention; once confident the intonaco had been well applied, he drew directly onto the ceiling. His energetic sweeping outlines can be seen scraped into some of the surfaces,[nb 1] while on others a grid is evident, indicating that he enlarged directly onto the ceiling from a small drawing.\\r\\n\\r\\nMichelangelo painted onto the damp plaster using a wash technique to apply broad areas of colour, then as the surface became drier, he revisited these areas with a more linear approach, adding shade and detail with a variety of brushes. For some textured surfaces, such as facial hair and woodgrain, he used a broad brush with bristles as sparse as a comb. He employed all the finest workshop methods and best innovations, combining them with a diversity of brushwork and breadth of skill far exceeding that of the meticulous Ghirlandaio.[nb 2]\\r\\n\\r\\nThe work commenced at the end of the building furthest from the altar, with the latest of the narrative scenes, and progressed towards the altar with the scenes of the Creation.[13] The first three scenes, from the story of Noah, contain a much larger number of small figures than the later panels. This is partly because of the subject matter, which deals with the fate of Humanity, but also because all the figures at that end of the ceiling, including the prophets and Ignudi, are smaller than in the central section.[18] As the scale got larger, Michelangelo's style became broader; the final narrative scene of God in the act of Creation was painted in a single day.[19]\\r\\n\\r\\nThe bright colours and broad, cleanly defined outlines make each subject easily visible from the floor. Despite the height of the ceiling, the proportions of the Creation of Adam are such that when standing beneath it, \\"it appears as if the viewer could simply raise a finger and meet those of God and Adam\\". Vasari tells us that the ceiling is \\"unfinished\\", that its unveiling occurred before it could be reworked with gold leaf and vivid blue lapis lazuli as was customary with frescoes and in order to better link the ceiling with the walls below it which were highlighted with a great deal of gold. But this never took place, in part because Michelangelo was reluctant to set up the scaffolding again, and probably also because the gold and particularly the intense blue would have distracted from his painterly conception.[9]\\r\\n\\r\\nSome areas were, in fact, decorated with gold: the shields between the Ignudi and the columns between the Prophets and Sibyls. It seems very likely that the gilding of the shields was part of Michelangelo's original scheme, since they are painted to resemble a certain type of parade shield, a number of which still exist and are decorated in a similar style with gold.\\r\\n\\r\\nSection reference.[9][15][16][20]\\r\\n\\r\\nMichelangelo wrote a poem describing the arduous conditions under which he worked[21]\\r\\n\\r\\nThe overt subject matter of the ceiling is the doctrine of humanity's need for Salvation as offered by God through Jesus. It is a visual metaphor of Humankind's need for a covenant with God. The Old Covenant of the Children of Israel through Moses and the New Covenant through Christ had already been represented around the walls of the chapel.[2] Some experts, including Benjamin Blech and Vatican art historian Enrico Bruschini, have also noted less overt subject matter, which they describe as being \\"concealed\\" and \\"forbidden.\\"[22][23]\\r\\n\\r\\nThe main components of the design are nine scenes from the Book of Genesis, of which five smaller ones are each framed and supported by four naked youths or Ignudi. At either end, and beneath the scenes are the figures of twelve men and women who prophesied the birth of Jesus. On the crescent-shaped areas, or lunettes, above each of the chapel's windows are tablets listing the Ancestors of Christ and accompanying figures. Above them, in the triangular spandrels, a further eight groups of figures are shown, but these have not been identified with specific Biblical characters. The scheme is completed by four large corner pendentives, each illustrating a dramatic Biblical story.[18]\\r\\n\\r\\nThe narrative elements of the ceiling illustrate that God made the World as a perfect creation and put humanity into it, that humanity fell into disgrace and was punished by death and by separation from God. Humanity then sank further into sin and disgrace, and was punished by the Great Flood. Through a lineage of Ancestors ÿ from Abraham to Joseph ÿ God sent the saviour of humanity, Christ Jesus. The coming of the Saviour was prophesied by Prophets of Israel and Sibyls of the Classical world. The various components of the ceiling are linked to this Christian doctrine.[18] Traditionally, the Old Testament was perceived as a prefiguring of the New Testament. Many incidents and characters of the Old Testament were commonly understood as having a direct symbolic link to some particular aspect of the life of Jesus or to an important element of Christian doctrine or to a sacrament such as Baptism or the Eucharist. Jonah, for example, was readily recognisable by his attribute of the large fish and was commonly seen to symbolise Jesus' death and resurrection.[3]\\r\\n\\r\\nWhile much of the symbolism of the ceiling dates from the early church, the ceiling also has elements that express the specifically Renaissance thinking that sought to reconcile Christian theology with the philosophy of Renaissance Humanism.[24] During the 15th century in Italy, and in Florence in particular, there was a strong interest in Classical literature and the philosophies of Plato, Socrates and other Classical writers. Michelangelo, as a young man, had spent time at the Humanist academy established by the Medici family in Florence. He was familiar with early Humanist-inspired sculptural works such as Donatello's bronze David and had himself responded by carving the enormous nude marble David, which was placed in the piazza near the Palazzo Vecchio, the home of Florence's council.[25] The Humanist vision of humanity was one in which people responded to other people, to social responsibility, and to God in a direct way, not through intermediaries, such as the Church.[26] This conflicted with the Church's emphasis. While the Church emphasized humanity as essentially sinful and flawed, Humanism emphasized humanity as potentially noble and beautiful.[nb 3] These two views were not necessarily irreconcilable to the Church, but only through a recognition that the unique way to achieve this \\"elevation of spirit, mind and body\\" was through the Church as the agent of God. To be outside the Church was to be beyond Salvation. In the ceiling of the Sistine Chapel, Michelangelo  presented both Catholic and Humanist elements in a way that does not appear visually conflicting. The inclusion of \\"non-biblical\\" figures such as the Sibyls or Ignudi is consistent with the rationalising of Humanist and Christian thought of the Renaissance. This rationalisation was to become a target of the Counter Reformation.\\r\\n\\r\\nThe iconography of the ceiling has had various interpretations in the past, some elements of which have been contradicted by modern scholarship.[nb 4] Others, such as the identity of the figures in the lunettes and spandrels, continue to defy interpretation.[27] Modern scholars have sought, as yet unsuccessfully, to determine a written source of the theological program of the ceiling and have questioned whether or not it was entirely devised by the artist himself, who was both an avid reader of the Bible and a genius.[28] Also of interest to some modern scholars is the question of how Michelangelo's own spiritual and psychological state is reflected in the iconography and the expression of the ceiling. One such speculation is that Michelangelo was tormented by conflict between homosexual desires and passionate Christian beliefs.[nb 5]\\r\\n\\r\\nThe Sistine Chapel is 40.9?metres long and 14?metres wide. The ceiling rises to 13.4?metres above the main floor of the chapel. The vault is of quite a complex design and it is unlikely that it was originally intended to have such elaborate decoration. Pier Matteo d'Amelia provided a plan for its decoration with the architectural elements picked out and the ceiling painted blue and dotted with gold stars, similar to that of the Arena Chapel decorated by Giotto at Padua.[29]\\r\\n\\r\\nThe chapel walls have three horizontal tiers with six windows in the upper tier down each side. There were also two windows at each end, but these have been closed up above the altar when Michelangelo's Last Judgement was painted, obliterating two lunettes. Between the windows are large pendentives which support the vault. Between the pendentives are triangularly shaped arches or spandrels cut into the vault above each window. Above the height of the pendentives, the ceiling slopes gently without much deviation from the horizontal.[29] This is the real architecture. Michelangelo has elaborated it with illusionary or fictive architecture.\\r\\n\\r\\nThe first element in the scheme of painted architecture is a definition of the real architectural elements by accentuating the lines where spandrels and pendentives intersect with the curving vault. Michelangelo painted these as decorative courses that look like sculpted stone moldings.[nb 6] These have two repeating motifs, a formula common in Classical architecture.[nb 7] Here, one motif is the acorn, the symbol of the family of both Pope Sixtus IV, who built the chapel, and Pope Julius II, who commissioned Michelangelo's work.[nb 8][30] The other motif is the scallop shell, one of the symbols of the Madonna, to whose assumption the chapel was dedicated in 1483.[nb 9][31] The crown of the wall then rises above the spandrels, to a strongly projecting painted cornice that runs right around the ceiling, separating the pictorial areas of the biblical scenes from the figures of Prophets, Sibyls, and Ancestors, who literally and figuratively support the narratives. Ten broad painted crossribs of travertine cross the ceiling and divide it into alternately wide and narrow pictorial spaces, a grid that gives all the figures their defined place.[32]\\r\\n\\r\\nA great number of small figures are integrated with the painted architecture, their purpose apparently purely decorative. These include two faux marble putti below the cornice on each rib, each one a male and female pair; stone rams-heads are placed at the apex of each spandrel; copper-skinned nude figures in varying poses, hiding in the shadows, propped between the spandrels and the ribs like animated bookends; and more putti, both clothed and unclothed strike a variety of poses as they support the nameplates of the Prophets and Sibyls.[33] Above the cornice and to either side of the smaller scenes are an array of round shields, or medaillons. They are framed by a total of twenty more figures, the so-called Ignudi, which are not part of the architecture but sit on inlaid plinths, their feet planted convincingly on the fictive cornice. Pictorially, the Ignudi appear to occupy a space between the narrative spaces and the space of the chapel itself. (see below)\\r\\n\\r\\nAlong the central section of the ceiling, Michelangelo depicted nine scenes from the Book of Genesis, the first book of the Bible. The pictures are organized into three groups of three alternating large and small panels.[34]\\r\\n\\r\\nThe first group shows God creating the Heavens and the Earth. The second group shows God creating the first man and woman, Adam and Eve, and their disobedience of God and consequent expulsion from the Garden of Eden where they have lived and where they walked with God. The third group of three pictures shows the plight of Humanity and in particular the family of Noah.\\r\\n\\r\\nThe pictures are not in strictly chronological order. If they are perceived as three groups, then the pictures in each of the three units inform upon each other, in the same way as was usual in Medieval paintings and stained glass.[35] The three sections of Creation, Downfall, and Fate of Humanity appear in reverse order, when read from the entrance of the chapel. However, each individual scene is painted to be viewed when looking toward the altar.[34] This is not easily apparent when viewing a reproduced image of the ceiling but becomes clear when the viewer looks upward at the vault. Paoletti and Radke suggest that this reversed progression symbolises a return to a state of grace.[34] However, the three sections are generally described in the order of Biblical chronology.\\r\\n\\r\\nThe scenes, from the altar toward the main door, are ordered as follows:\\r\\n\\r\\nThe three Creation pictures show scenes from the first chapter of Genesis, which relates that God created the Earth and all that is in it in six days, resting on the seventh day.  In the first scene, the First Day of Creation, God creates light and separates light from darkness.[Fig 1] Chronologically, the next scene takes place in the third panel, in which, on the Second Day, God divides the waters from the heavens.[Fig 2] In the central panel, the largest of the three, there are two representations of God. On the  Third Day, God creates the Earth and makes it sprout plants. On the Fourth Day, God puts the Sun and the Moon in place to govern the night and the day, the time and the seasons of the year.[Fig 3] According to Genesis, on the Fifth Day, God created the birds of the air and fish and creatures of the deep, but we are not shown this. Neither do we see God's creation of the creatures of the earth on the Sixth Day.[5][Src 1]\\r\\n\\r\\nThese three scenes, completed in the third stage of painting, are the most broadly conceived, the most broadly painted and the most dynamic of all the pictures. Of the first scene Vasari says \\"...?Michelangelo depicted God dividing Light from Darkness, showing him in all his majesty as he rests self-sustained with arms outstretched, in a revelation of love and creative power.\\"[9]\\r\\n\\r\\nFor the central section of the ceiling, Michelangelo has taken four episodes from the story of Adam and Eve as told in the first, second and third chapters of Genesis. In this sequence of three, two of the panels are large and one small.\\r\\n\\r\\nIn the first of the pictures, and one of the most widely recognised images in the history of painting, Michelangelo shows God reaching out to touch Adam, who, in the words of Vasari, is \\"a figure whose beauty, pose and contours are such that it seems to have been fashioned that very moment by the first and supreme creator rather than by the drawing and brush of a mortal man.\\"[9] From beneath the sheltering arm of God, Eve looks out, a little apprehensively.[18] The \\"glory\\" of God, represented by a dark shaded area around him, has the same anatomical geometry as a human brain.\\r\\n\\r\\nThe central scene, of God creating Eve from the side of the sleeping Adam[Fig 4] has been taken in its composition directly from another Creation sequence, the relief panels that surround the door of the Basilica of San Petronio, Bologna by Jacopo della Quercia whose work Michelangelo had studied in his youth.[36][37]\\r\\n\\r\\nIn the final panel of this sequence Michelangelo combines two contrasting scenes into one panel,[Fig 5] that of Adam and Eve taking fruit from the forbidden tree, Eve trustingly taking it from the hand of the Serpent and Adam eagerly picking it for himself; and their banishment from the Garden of Eden, where they have lived in the company of God, to the world outside where they have to fend for themselves and experience death.[5][Src 2]\\r\\n\\r\\nAs with the first sequence of pictures, the three panels concerning Noah, taken from the sixth to ninth chapters of Genesis are thematic rather than chronological. In the first scene is shown the sacrifice of a sheep.[Fig 6] Vasari, in writing about this scene mistakes it for the sacrifices by Cain and Abel, in which Abel's sacrifice was acceptable to God and Cain's was not. What this image almost certainly depicts is the sacrifice made by the family of Noah, after their safe deliverance from the Great Flood which destroyed the rest of Humankind.\\r\\n\\r\\nThe central, larger, scene shows the Great Flood.[Fig 7] The Ark in which Noah's family escaped floats at the rear of the picture while the rest of humanity tries frantically to scramble to some point of safety. This picture, which has a large number of figures, conforms the most closely to the format of the paintings that had been done around the walls.\\r\\n\\r\\nThe final scene is the story of Noah's drunkenness.[Fig 8] After the Flood, Noah tills the soil and grows vines. He is shown doing so, in the background of the picture. He becomes drunk and inadvertently exposes himself. His youngest son, Ham, brings his two brothers Shem and Japheth to see the sight but they discreetly cover their father with a cloak. Ham is later cursed by Noah and told that the descendants of Ham's son Canaan will serve Shem and Japheth's descendants forever. Taken together, these three pictures serve to show that Humankind had moved a long way from God's perfect creation. However, it is through Shem and his descendants, the Israelites, that Salvation will come to the world.[Src 3]\\r\\n\\r\\nSince Michelangelo executed the nine Biblical scenes in reverse chronological order, some analyses of the frescoes of the vault commence with the Drunkenness of Noah. Tolnay's Neoplatonic interpretation sees the story of Noah at the beginning and the act of Creation by God as the conclusion of the process of deificatio and the return from physical to spiritual being.[38]\\r\\n\\r\\nAdjacent to the smaller Biblical scenes and supported by the Ignudi are ten circular parade shields, sometimes described as being painted to resemble bronze. Known examples are actually of lacquered and gilt wood.[39] Each is decorated with a picture drawn from the Old Testament or the Book of Maccabees from the Apocrypha.\\r\\n\\r\\nThe subjects are the more gruesome or shameful of Biblical episodes, the only exception seeming to be that of Elijah being swept up to Heaven in a Chariot of Fire, leaving his mantle to fall on Elisha. However, Elijah's role as a prophet was one marked by accusation and warnings to repent, and the purpose of his translation into Heaven was traditionally seen as so that he might stand before God to condemn Israel for its sins.[Src 4] In four of the five most highly finished \\"medallions\\" the space is crowded with figures in violent action, similar to Michelangelo's cartoon for the Battle of Cascina.[nb 10]\\r\\n\\r\\nThe application of gold on the shields, in contrast to its absence on the rest of the ceiling, serves to link the ceiling to some extent with the frescoes around the walls. In the latter, gold leaf has been applied lavishly to many details and in some of the frescoes, notably those by Perugino, has been most expertly used not just to detail the robes but to highlight the folds by subtle graduation in the density of golden flecks. It is this technique that Michelangelo has picked up on and carried a step further, inspired also perhaps by the medallions that appear on a Roman triumphal arch in Botticelli's episode from the Life of Moses, showing the Punishment of the Rebels.\\r\\n\\r\\nThe medallions represent:\\r\\n\\r\\nSection references[5][40]\\r\\n\\r\\nOn the five pendentives along each side and the two at either end, Michelangelo painted the largest figures on the ceiling: twelve people who prophesied or represented some aspect of the Coming of Christ. Of those twelve, seven were Prophets of Israel and were male. The remaining five were prophets of the Classical World, called Sibyls and were female. The prophet Jonah is placed above the altar and Zechariah at the further end. The other male and female figures alternate down each side, each being identified by an inscription on a painted marble panel supported by a putto.\\r\\n\\r\\nThe seven prophets of Israel chosen for depiction on the ceiling include the four so-called Major prophets: Isaiah, Jeremiah, Ezekiel and Daniel. Of the remaining possibilities among the Twelve Minor Prophets, the three represented are Joel, Zechariah and Jonah.\\r\\nAlthough the prophets Joel and Zechariah are considered \\"minor\\" because of the comparatively small number of pages that their prophecy occupies in the Bible, each one produced prophesies of profound significance.\\r\\n\\r\\nThey are often quoted, Joel for his \\"Your sons and your daughters shall prophesy, your elderly shall dream dreams and your youth shall see visions\\".[Src 5] These words are significant for Michelangelo's decorative scheme, where women take their place among men and the youthful Daniel sits across from the brooding Jeremiah with his long white beard.\\r\\n\\r\\nZechariah prophesied, \\"Behold! Your King comes to you, humble and riding on a donkey\\".[Src 6][41] His place in the chapel is directly above the door through which the Pope is carried in procession on Palm Sunday, the day on which Jesus fulfilled the prophecy by riding into Jerusalem on a donkey and being proclaimed King.[42]\\r\\n\\r\\nJonah is of symbolic and prophetic significance, which was commonly perceived and had been represented in countless works of art including manuscripts and stained glass windows.[35] Through his reluctance to obey God, he was swallowed by a \\"mighty fish\\".[nb 11] He spent three days in its belly and was eventually spewed up on dry land where he went about God's business.[Src 7] Jonah was thus seen as presaging Jesus, who having died by crucifixion, spent part of three days in a tomb and was raised on the third day.[Src 8] So, on the ceiling of the Sistine Chapel, Jonah, with the \\"great fish\\" beside him and his eyes turned towards God the Creator,[Fig 11] represents a \\"portent\\" of the Passion[43] and Resurrection of Christ.[41] The Jonah figure placed right over the altar activated the Passion motif. \\"When Perugino's altar painting was removed and?... Last Judgement fresco came to cover the altar wall\\",[43] after at least twenty five years Michelangelo depicted Christ just below Jonah: not only for his role as precursor of Christ, Christianity and Christocentrism, but also because his powerful torsion of the body, bent backwards from the bust to the eyes and with his forefingers that now point the glorious Jesus to the characters of the ceiling, assumes a function of link between the Old and New Testament.\\r\\n\\r\\nIn Vasari's description of the Prophets and Sibyls he is particularly high in his praise of the portrayal of Isaiah:[Fig 19] \\"Anyone who studies this figure, copied so faithfully from nature, the true mother of the art of painting, will find a beautifully composed work capable of teaching in full measure all the precepts to be followed by a good painter.\\"[9]\\r\\n\\r\\nThe Sibyls were prophetic women who were resident at shrines or temples throughout the Classical World. The five depicted here are each said to have prophesied the birth of Christ. The Cumaean Sibyl, for example, is quoted by Virgil in his Fourth Eclogue as declaring that \\"a new progeny of Heaven\\" would bring about a return of the \\"Golden Age\\". This was interpreted as referring to Jesus.[44]\\r\\n\\r\\nIn Christian doctrine, Christ came not just to the Jews but also to the Gentiles. It was understood that, prior to the Birth of Christ, God prepared the world for his coming. To this purpose, God used Jews and Gentiles alike. Jesus would not have been born in Bethlehem (where it had been prophesied that his birth would take place),[Src 9] except for the fact that the pagan Roman Emperor Augustus decreed that there should be a census.[Src 10] Likewise, when Jesus was born, the announcement of his birth was made to rich and to poor, to mighty and to humble, to Jew and to Gentile. The Three Wise Men (the \\"Magi\\" of the Bible) who sought out the infant King with precious gifts were pagan foreigners.[Src 11]\\r\\n\\r\\nIn the Roman Catholic Church, where there was an increasing interest in the remains of the city's pagan past, where scholars turned from reading Medieval Church Latin to Classical Latin and the philosophies of the Classical world were studied along with the writings of St Augustine, the presence, in the Sistine Chapel of five pagan prophets is not surprising.[45]\\r\\n\\r\\nIt is not known why Michelangelo selected the five particular Sibyls that were depicted, given that, as with the Minor Prophets, there were ten or twelve possibilities. It is suggested by John O'Malley that the choice was made for a wide geographic coverage, with the Sibyls coming from Africa, Asia, Greece and Ionia.[44]\\r\\n\\r\\nVasari says of the Erythraean Sibyl[Fig 15] \\"Many aspects of this figure are of exceptional loveliness: the expression of her face, her headdress and the arrangement of her draperies: and her arms, which are bared, are as beautiful as the rest.\\" [9]\\r\\n\\r\\nIn each corner of the chapel is a triangular pendentive filling the space between the walls and the arch of the vault and forming the spandrel above the windows nearest the corners. On these curving shapes Michelangelo has painted four scenes from Biblical stories that are associated with the salvation of Israel by four great male and female heroes of the Jews: Moses, Esther, David and Judith.[46]\\r\\n\\r\\nThe first two stories were both seen in Medieval- and Renaissance theology as prefiguring the Crucifixion of Jesus. In the story of the Brazen Serpent, the people of Israel become dissatisfied and grumble at God. As punishment they receive a plague of venonous snakes. God offers the people relief by instructing Moses to make a snake of brass and set it up on a pole, the sight of which gives miraculous healing.[Src 12] Michelangelo chooses a crowded composition, depicting a dramatic mass of suffering men, women, and writhing snakes, separated from redeemed worshipers by the snake before an epiphanic light.[Fig 23]\\r\\n\\r\\nIn the Book of Esther it is related that Haman, a public servant, plots to get Esther's husband, the King of Persia, to slay all the Jewish people in his land. The King, who is going over his books during a sleepless night, realises something is amiss. Esther, discovering the plot, denounces Haman, and her husband orders his execution on a scaffold he has built. The King's eunuchs promptly carry this out.[Src 13] Michelangelo shows Haman crucified with Esther looking at him from a doorway, the King giving orders in the background.[Fig 24]\\r\\n\\r\\nThe other two stories, those of David and Judith, were often linked in Renaissance art, particularly by Florentine artists as they demonstrated the overthrow of tyrants, a popular subject in the Republic. In this image, the shepherd boy, David, has brought down the towering Goliath with his sling, but the giant is alive and is trying to rise as David forces his head down to chop it off.[47][Fig 25]\\r\\n\\r\\nThe depiction of Judith and Holofernes has an equally gruesome detail. As Judith loads the enemy's head onto a basket carried by her maid and covers it with a cloth, she looks towards the tent,[47] apparently distracted by the limbs of the decapitated corpse flailing about.[Fig 26]\\r\\n\\r\\nThere are obvious connections in the design of the Slaying of Holofernes and the Slaying of Haman at the opposite end of the chapel. Although in the Holofernes picture the figures are smaller and the space less filled, both have the triangular space divided into two zones by a vertical wall, allowing us to see what is happening on both sides of it. There are actually three scenes in the Haman picture because as well as seeing Haman punished, we see him at the table with Esther and the King and get a view of the King on his bed.[47] Mordechai sits on the steps, making a link between the scenes.[48]\\r\\n\\r\\nWhile the Slaying of Goliath is a relatively simple composition with the two protagonists centrally placed and the only other figures being dimly seen observers, the Brazen Serpent picture is crowded with figures and separate incidents as the various individuals who have been attacked by snakes struggle and die or turn toward the icon that will save them. This is the most Mannerist of Michelangelo's earlier compositions at the Sistine Chapel,[47] picking up the theme of human distress begun in the Great Flood scene and carrying it forward into the torment of lost souls in the Last Judgement, which was later painted below.\\r\\n\\r\\nBetween the large pendentives that support the vault are windows, six on each side of the chapel. There were two more windows in each end of the chapel, now closed, and those above the High Altar covered by the Last Judgement. Above each window is an arched shape, referred to as a lunette and above eight of the lunettes at the sides of the chapel are triangular spandrels filling the spaces between the side pendentives and the vault, the other eight lunettes each being below one of the corner pendentives.\\r\\n\\r\\nMichelangelo was commissioned to paint these areas as part of the work on the ceiling. The structures form visual bridges between the walls and the ceiling, and the figures which are painted on them are midway in size (approximately 2 metres high) between the very large prophets and the much smaller figures of Popes which had been painted to either side of each window in the 15th century.[49] Michelangelo chose the Ancestors of Christ as the subject of these images,[50] thus portraying Jesus' physical lineage, while the  papal portraits are his spiritual successors, according to Church doctrine.[51] (see gallery)\\r\\n\\r\\nCentrally placed above each window is a faux marble tablet with a decorative frame. On each is painted the names of the male line by which Jesus, through his Earthly father, Joseph, is descended from Abraham, according to the Gospel of Matthew.[nb 12] However, the genealogy is now incomplete, since the two lunettes of the windows in the Altar wall were destroyed by Michelangelo when he returned to the Sistine Chapel in 1537 to paint The Last Judgment.[52] Only engravings, based on a drawing that has since been lost, remain of them.[Fig 27] The sequence of tablets seems a little erratic as one plaque has four names, most have three or two, and two plaques have only one. Moreover, the progression moves from one side of the building to the other, but not consistently, and the figures the lunettes contain do not coincide closely with the listed names. These figures vaguely suggest various family relationships; most lunettes contain one or more infants, and many depict a man and a woman, often sitting on opposing sides of the painted plaque that separates them. O'Malley describes them as \\"simply representative figures, almost ciphers\\".[50]\\r\\n\\r\\nThere is also an indeterminate relationship between the figures in the spandrels and the lunettes beneath them. Because of the constraints of the triangular shape, in each spandrel the figures are seated on the ground. In six of the eight spandrels the compositions resemble traditional depictions of the Flight into Egypt. Of the two remaining, one shows a woman with shears trimming the neck of a garment she is making while her toddler looks on.[Fig 28] The Biblical woman who is recorded as making a new garment for her child is Hannah, the mother of Samuel, whose child went to live in the temple, and indeed, the male figure in the background is wearing a distinctive hat that might suggest that of a priest.[Src 14] The other figure who differs from the rest is a young woman who sits staring out of the picture with prophetic intensity. Her open eyes have been closed in the restoration.[Fig 29]\\r\\n\\r\\nSection References[5][15]\\r\\n\\r\\nMichelangelo's  depiction of the Genealogy of Jesus departs from an artistic tradition for this topic that was common in medieval times, especially in stained-glass windows. This so-called Jesse Tree shows Jesse lying prone and a tree growing from his side with the ancestors on each branch, in a visual treatment of a biblical verse.[Src 15]\\r\\n\\r\\nThe figures in the lunettes appear to be families, but in every case they are families that are divided. The figures in them are physically divided by the name tablet but they are also divided by a range of human emotions that turn them outward or in on themselves and sometimes towards their partner with jealousy, suspicion, rage or simply boredom. In them Michelangelo has portrayed the anger and unhappiness of the human condition, painting \\"the daily round of merely domestic life as if it were a curse\\".[53] In their constraining niches, the ancestors \\"sit, squat and wait\\".[54] Of the fourteen lunettes, the two that were probably painted first, the families of Eleazar and Mathan and of Jacob and Joseph are the most detailed. They become progressively broader towards the altar end, one of the last being painted in only two days.[nb 14]\\r\\n\\r\\nThe Eleazar and Mathan picture contains two figures with a wealth of costume detail that is not present in any other lunette.\\r\\n[Fig 30] The female to the left has had as much care taken with her clothing as any of the Sibyls. Her skirt is turned back showing her linen petticoat and the garter that holds up her mauve stockings and cuts into the flesh. She has a reticule and her dress is laced up under the arms. On the other side of the tablet sits the only male figure among those on the lunettes who is intrinsically beautiful. This blonde young man, elegantly dressed in white shirt and pale green hose, with no jerkin but a red cloak, postures with an insipid and vain gesture, in contrast to the Ignudi which he closely resembles.\\r\\n\\r\\nPrior to restoration, of all the paintings in the Sistine Chapel, the lunettes and spandrels were the dirtiest.[55] Added to this, there has always been a problem of poor daytime visibility of the panels nearest the windows because of halination.[nb 15] Consequently, they were the least well known of all Michelangelo's publicly accessible works. The recent restoration has made these masterly studies of human nature and inventive depiction of the human form known once more.\\r\\n\\r\\nSection References[3][15]\\r\\n\\r\\n(For images, see gallery)\\r\\n\\r\\nThe Ignudi[nb 16] are the 20 athletic, nude males that Michelangelo painted as supporting figures at each corner of the five smaller narrative scenes that run along the centre of the ceiling. The figures hold or are draped with or lean on a variety of items which include pink ribbons, green bolsters and enormous garlands of acorns.[nb 8]\\r\\n\\r\\nThe Ignudi, although all seated, are less physically constrained than the Ancestors of Christ. While the pairs of the monochrome male and female figures above the spandrels are mirrors of each other, these Ignudi are all different. In the earliest paintings, they are paired, their poses being similar but with variation. These variations become greater with each pair until the postures of the final four bear no relation to each other whatsoever.\\r\\n\\r\\nThe meaning of these figures has never been clear. They are certainly in keeping with the Humanist acceptance of the classical Greek view that \\"the man is the measure of all things\\".[56] But Michelangelo knew the Bible well.[11] He would have been well aware of the fact that although seraphim and cherubim are described as being winged creatures, they are described as looking like men.[Src 16] When Michelangelo later painted the altar wall of the chapel, he included a great number of angels, particularly in the lunettes which are decorated with scenes of angels carrying the symbols of the Passion. Other angels are employed sounding the trumpets which call forth the dead, displaying books in which the names of the saved and the damned are written and casting sinners down to Hell. In all, the Last Judgement contains more than forty angels, all closely resembling the Ignudi. It is reasonable to conclude that the Ignudi represent angels.[11][57]  If the Ignudi are indeed angels, they are the ever-present attendants and messengers of God, impassively watching and waiting on the fate of Humankind.\\r\\n\\r\\nTheir painting demonstrates, more than any other figures on the ceiling, Michelangelo's mastery of anatomy and foreshortening and his enormous powers of invention.[nb 17] In their reflection of classical antiquity they resonate with Pope Julius' aspirations to lead Italy towards a new 'age of gold'; at the same time, they staked Michelangelo's claim to greatness.[58] However, a number of critics were angered by their presence and nudity, including Pope Adrian VI who wanted the ceiling stripped.\\r\\n\\r\\nMichelangelo was the artistic heir to the great 15th-century sculptors and painters of Florence. He learned his trade first under the direction of a masterly fresco painter, Domenico Ghirlandaio, known for two great fresco cycles in the Sassetti Chapel and Tornabuoni Chapel, and for his contribution to the cycle of paintings on the walls of the Sistine Chapel. As a student Michelangelo studied and drew from the works of the two most renowned Florentine fresco painters of the early Renaissance, Giotto and Masaccio.[59]  Masaccio's figures of Adam and Eve being expelled from the Garden of Eden had a profound effect on the depiction of the nude in general, and in particular on the use of the nude figure to convey human emotion.[Fig 31] Helen Gardner says that in the hands of Michelangelo \\"the body is simply the manifestation of the soul, or of a state of mind and character\\".[59]\\r\\n\\r\\nMichelangelo was also almost certainly influenced by the paintings of Luca Signorelli[59] whose paintings, particularly the Death and Resurrection Cycle in Orvieto Cathedral contain a great number of nudes and inventive figurative compositions.[Fig 32] In Bologna, Michelangelo saw the relief sculptures of Jacopo della Quercia around the doors of the cathedral. In Michelangelo's depiction of the Creation of Eve the whole composition, the form of the figures and the relatively conservative concept of the relationship between Eve and her Creator adheres closely to Jacopo's design.[13] Other panels on the ceiling, most particularly the iconic Creation of Adam show \\"...?unprecedented invention\\".[13]\\r\\n\\r\\nThe ceiling of the Sistine Chapel was to have a profound effect upon other artists, even before it was completed. Vasari, in his Life of Raphael, tells us that Bramante, who had the keys to the chapel, let Raphael in to examine the paintings in Michelangelo's absence. On seeing Michelangelo's prophets, Raphael went back to the picture of the Prophet Isaiah that he was painting on a column in the Church of Sant'Agostino and, according to Vasari, although it was finished, he scraped it off the wall and repainted it in a much more powerful manner, in imitation of Michelangelo.[9] John O'Malley points out that even earlier than the Isaiah is Raphael's inclusion of the figure of Heraclitus in the School of Athens, a brooding figure similar to Michelangelo's Jeremiah, but with the countenace of Michelangelo himself, and leaning on a block of marble.[60][Fig 33]\\r\\n\\r\\nThere was hardly a design element on the ceiling that was not subsequently imitated: the fictive architecture, the muscular anatomy, the foreshortening, the dynamic motion, the luminous colouration, the haunting expressions of the figures in the lunettes, the abundance of putti.\\r\\nGabriele Bartz and Eberhard K?nig have said of the Ignudi, \\"There is no image that has had a more lasting effect on following generations than this. Henceforth similar figures disported themselves in innumerable decorative works, be they painted, formed in stucco or even sculpted.\\"[61]\\r\\n\\r\\nWithin Michelangelo's own work, the chapel ceiling led to the later and more Mannerist painting of the Last Judgement in which the crowded compositions  gave full rein to his inventiveness in painting contorted and foreshortened figures expressing despair or jubilation. Among the artists in whose work can be seen the direct influence of Michelangelo are Pontormo, Andrea del Sarto, Correggio, Tintoretto, Annibale Carracci, Paolo Veronese and El Greco.\\r\\n\\r\\nIn January 2007, it was claimed that as many as 10,000 visitors passed through the Vatican Museums in a day and that the ceiling of the Sistine Chapel is the biggest attraction. The Vatican, anxious at the possibility that the newly restored frescoes will suffer damage, announced plans to reduce visiting hours and raise the price in an attempt to discourage visitors.[62]\\r\\n\\r\\nFive hundred years earlier Vasari had said \\"The whole world came running when the vault was revealed, and the sight of it was enough to reduce them to stunned silence.\\"[9]\\r\\n\\r\\nThe frescoes of the Sistine Chapel were restored between June 1980 and December 1999, with preliminary tests taking place in 1979.\\r\\n\\r\\nThe first stage of restoration, the work upon Michelangelo's lunettes, was achieved in October 1984. The work then proceeded on the ceiling, completed December 1989 and from there to the Last Judgement. The restoration was unveiled by Pope John Paul II on 8 April 1994. The restoration team comprised Gianluigi Colalucci, Maurizio Rossi, Piergiorgio Bonetti, Bruno Baratti and others. The final stage was the restoration of the wall frescoes by Botticelli, Domenico Ghirlandaio, Perugino and others, This was unveiled on 11 December 1999.[63]\\r\\n\\r\\nThe colours, which now appear so fresh and spring-like with pale pink, apple green, vivid yellow and sky blue against a background of warm pearly grey, were so discoloured by candle smoke as to make the pictures seem almost monochrome. The restoration has removed the filter of grime to reveal the colours again.[63] However, the restoration was met with both praise and criticism. Critics assert that much original work  by Michelangelo ÿ in particular pentimenti, highlights and shadows, and other detailing painted a secco ÿ was lost in the removal of various accretions.[64]\\r\\n\\r\\nVasari\\r\\n\\r\\nJohann Wolfgang Goethe\\r\\n\\r\\nWaldemar Januszczak\\r\\nThe art critic and television producer Waldemar Januszczak wrote that when the Sistine Chapel ceiling was recently cleaned, he \\"was able to persuade the man at the Vatican who was in charge of Japanese TV access to let me climb the scaffold while the cleaning was in progress.\\"\\r\\n\\r\\nGabriele Bartz and  Eberhard K?nig\\r\\n\\r\\nPope John Paul II","input":"What is the most famous part of the sistine chapel?"},{"output":"three","context":"Coordinates: 1930N 8030W? / ?19.500N 80.500W? / 19.500; -80.500\\r\\nThe Cayman Islands (/?ke?m?n/ or /ke??m?n/) is an autonomous British Overseas Territory in the western Caribbean Sea. The 264-square-kilometre (102-square-mile) territory comprises the three islands of Grand Cayman, Cayman Brac and Little Cayman located south of Cuba, northeast of Costa Rica, north of Panama, east of Mexico and northwest of Jamaica. Its population is approximately 60,765[7], and its capital is George Town.\\r\\nThe Cayman Islands are considered to be part of the geographic Western Caribbean Zone as well as the Greater Antilles. The territory is often considered a major world offshore financial haven for many wealthy individuals.[8]\\r\\n\\r\\n\\r\\nThe Cayman Islands remained largely uninhabited until the 17th century. While there is no archaeological evidence for an indigenous people on the islands, a variety of settlers from various backgrounds made their home on the islands, including pirates, shipwrecked sailors, and deserters from Oliver Cromwell's army in Jamaica.[9]\\r\\nThe first recorded permanent inhabitant of the Cayman Islands, Isaac Bodden, was born on Grand Cayman around 1661. He was the grandson of the original settler named Bodden who was probably one of Oliver Cromwell's soldiers at the taking of Jamaica in 1655.[10]\\r\\nEngland took formal control of the Cayman Islands, along with Jamaica, as a result of the Treaty of Madrid of 1670. Following several unsuccessful attempts at settlement, a permanent English-speaking population in the islands dates from the 1730s. With settlement, after the first royal land grant by the Governor of Jamaica in 1734, came the perceived need for slaves.[11] Many were brought to the islands from Africa; this is evident today with the majority of native Caymanians being of African and English descent. The results of the first census taken in the islands in 1802 showed the population on Grand Cayman to be 933 with 545 of those inhabitants being enslaved. Slavery was abolished in the Cayman Islands in 1833. At the time of abolition, there were over 950 Blacks of African ancestry enslaved by 116 white families of English ancestry.[12]\\r\\nThe islands continued to be governed as part of the Colony of Jamaica until 1962, when they became a separate Crown colony while Jamaica became an independent Commonwealth realm.[13]\\r\\nThe Cayman Islands historically have been a tax-exempt destination. On 8 February 1794, the Caymanians rescued the crews of a group of ten merchant ships, including HMS Convert, an incident that has since become known as the Wreck of the Ten Sail. The ships had struck a reef and run aground during rough seas.[14] Legend has it that King George III rewarded the island with a promise never to introduce taxes as compensation for their generosity, as one of the ships carried a member of the King's own family. While this remains a popular legend, the story is not true.[15]\\r\\nThe government of the Cayman Islands has always relied on indirect and not direct taxes. The islands have never levied income tax, capital gains tax, or any wealth tax, making them a popular tax haven.[16]\\r\\nOn 11 September 2004 the island of Grand Cayman, which lies largely unprotected at sea level, was hit by Hurricane Ivan, creating an 8-ft storm surge which flooded many areas of Grand Cayman. An estimated 83% of the dwellings on the island were damaged including 4% requiring complete reconstruction. A reported 70% of all dwellings suffered severe damage from flooding or wind. Another 26% sustained minor damage from partial roof removal, low levels of flooding, or impact with floating or wind driven hurricane debris.[17] Power, water and communications were disrupted for months in some areas as Ivan was the worst hurricane to hit the islands in 86 years.[18] Grand Cayman began a major rebuilding process and within two years its infrastructure was nearly returned to pre-hurricane status. Due to the tropical location of the islands, more hurricanes or tropical systems have affected the Cayman Islands than any other region in the Atlantic basin; it has been brushed or directly hit, on average, every 2.23 years.[19]\\r\\nThe Cayman Islands are in the western Caribbean Sea and are the peaks of a massive underwater ridge, known as the Cayman Ridge (or Cayman Rise). This ridge flanks the Cayman Trough, 6,000?m (20,000?ft) deep[20] which lies 6?km (3.7?mi) to the south.[21] The islands lie in the northwest of the Caribbean Sea, east of Quintana Roo, Mexico and Yucatn State, Mexico, northeast of Costa Rica, north of Panama, south of Cuba and west of Jamaica. They are situated about 700?km (430?mi) south of Miami,[22] 750?km (470?mi) east of Mexico,[23] 366?km (227?mi) south of Cuba,[24] and about 500?km (310?mi) northwest of Jamaica.[25] Grand Cayman is by far the largest, with an area of 197?km2 (76?sq?mi).[26] Grand Cayman's two \\"Sister Islands\\", Cayman Brac and Little Cayman, are about 120?km (75?mi) east north-east of Grand Cayman and have areas of 38 and 28.5?km2 (14.7 and 11.0?sq?mi)[27] respectively.\\r\\nAll three islands were formed by large coral heads covering submerged ice age peaks of western extensions of the Cuban Sierra Maestra range and are mostly flat. One notable exception to this is The Bluff on Cayman Brac's eastern part, which rises to 43?m (141?ft) above sea level, the highest point on the islands.[28]\\r\\nTerrain is mostly a low-lying limestone base surrounded by coral reefs.\\r\\nThe mammalian species in the islands include the introduced Central American agouti[29] and eight species of bats. At least three now extinct native rodent species were present up until the discovery of the islands by Europeans. A number of cetaceans are found in offshore waters.\\r\\nCayman avian fauna includes two endemic subspecies of Amazona parrots: A. l. hesterna Bangs, 1916 or Cuban amazon, now restricted to the island of Cayman Brac, but formerly also on Little Cayman, and Amazona leucocephala caymanensis or Grand Cayman parrot, which is native to the Cayman Islands, forested areas of Cuba, and the Isla de la Juventud. Little Cayman and Cayman Brac are also home to red-footed and brown boobies.[30][31] There are five endemic subspecies of butterflies on the islands.[32]\\r\\nAmong other notable fauna is the endangered blue iguana, which is endemic to Grand Cayman.[33]\\r\\nThe Cayman Islands have a tropical wet and dry climate, with a wet season from May to October, and a dry season that runs from November to April. Seasonally, there is little temperature change.[34]\\r\\nA major natural hazard is the tropical cyclones that form during the Atlantic hurricane season from June to November.\\r\\nOn 11 and 12 September 2004, Hurricane Ivan struck the Cayman Islands. The storm resulted in two deaths and caused great damage to the infrastructure on the islands. The total economic impact of the storms was estimated to be $3.4 billion.[35]\\r\\nThe Cayman Islands have more registered businesses than people.[36] In 2016 the Cayman Islands had an estimated population of about 60,765,[7] representing a mix of more than 100 nationalities. Out of that number, about half are of Caymanian descent. About 60% of the population is of mixed race (mostly mixed African-Caucasian). The islands are almost exclusively Christian, with large numbers of Baptists, Presbyterians and Catholics, but also hosts Jewish,[37] Muslim and Hindu communities. The vast majority of the population resides on Grand Cayman, followed by Cayman Brac and Little Cayman, respectively.[4] The population is projected to rise to 60,000 by 2020. The capital of the Cayman Islands is George Town, on the southwest coast of Grand Cayman.\\r\\nAccording to the Cayman Islands 2010 census the estimated resident population is 54,878 people,[38] broken down as follows:\\r\\nWith an average income of around KYD$47,000, Caymanians have the highest standard of living in the Caribbean. According to the CIA World Factbook, the Cayman Islands GDP per capita is the 14th highest in the world.[39] The islands print their own currency, the Cayman Islands dollar (KYD), which is pegged to the US dollar 1.227 USD to 1 KYD. However, in many retail stores throughout the island, the KYD is typically traded at 1.25 USD.[40] The government has established a Needs Assessment Unit to relieve poverty in the islands.[41]\\r\\nThe government's primary source of income is indirect taxation: there is no income tax, capital gains tax, or corporation tax.[16] An import duty of 5% to 22% (automobiles 29.5% to 100%) is levied against goods imported into the islands. Few goods are exempt; notable exemptions include books, cameras, and infant formula.[citation needed]\\r\\nOn 15 July 2012 the Cayman Islands premier McKeeva Bush announced the intended introduction of a \\"community enhancement fee\\" in the form of a payroll tax to be paid solely by expatriate workers. Caymanians themselves were to remain exempt from this tax. This would have been the first direct tax on income in the Cayman Islands' history.[42] Bush also announced a five percent fee on \\"certain categories of employment\\" to be payable by businesses. However, the payroll tax was scrapped before it had been implemented.[43]\\r\\nOne of Grand Cayman's main attractions is Seven Mile Beach, site of a number of the island's hotels and resorts. Named one of the Ultimate Beaches by Caribbean Travel and Life, Seven Mile Beach is on the western shore of Grand Cayman Island. It is a public property and possible to walk the full length of the beach, past all the hotels, resorts, and public beach bars.[44] Historical sites in Grand Cayman, such as Pedro St James Castle in Savannah, also attract visitors.[45] Tourists also visit the Sister Islands, Little Cayman[46] and Cayman Brac.[47]\\r\\nAll three islands offer scuba diving, and the Cayman Islands are home to several snorkelling locations where tourists can swim with stingrays. The most popular area to do this is Stingray City, Grand Cayman. Stingray City is a top attraction in Grand Cayman and originally started in the 1980s, when divers started feeding squid to stingrays. The stingrays started to associate the sound of the boat motors with food, and thus visit this area year round.[48]\\r\\nThere are two shipwrecks off the shores of Cayman Brac, including the MV Captain Keith Tibbetts;[49] Grand Cayman also has several shipwrecks off its shores, including one deliberate one. On 30 September 1994 the USS?Kittiwake was decommissioned and struck from the Naval Vessel Register. In November 2008 her ownership was transferred for an undisclosed amount to the government of the Cayman Islands, which had decided to sink the Kittiwake in June 2009 to form a new artificial reef off Seven Mile Beach, Grand Cayman. Following several delays, the ship was finally scuttled according to plan on 5 January 2011. The Kittiwake has become a dynamic environment for marine life. While visitors are not allowed to take anything, there are endless sights. Each of the five decks of the ship offers squirrelfish, rare sponges, Goliath groupers, urchins, and more. Experienced and beginner divers are invited to swim around the Kittiwake.[50]  Pirates Week, an annual 11-day November festival, was started in 1977 by Jim Bodden, then Minister of Tourism, to boost tourism during the country's tourism slow season.[51]\\r\\nOther Grand Cayman tourist attractions include the Ironshore landscape of Hell, the 23-acre (93,000?m2) marine theme park Boatswain's Beach, also home of the Cayman Turtle Farm, the production of gourmet sea salt, and the Mastic Trail, a hiking trail through the forests in the centre of the island. The National Trust for the Cayman Islands provides guided tours weekly on the Mastic Trail and other locations.[52]\\r\\nAnother attraction to visit on Grand Cayman is the Observation Tower, located in Camana Bay. The Observation Tower is 75 feet tall and provides 360-degree views across Seven Mile Beach, George Town, the North Sound, and beyond. It is free to the public and climbing the tower has become a popular thing to do in the Cayman Islands.[53]\\r\\nPoints of interest include the East End Light (sometimes called Gorling Bluff Light), a lighthouse at the east end of Grand Cayman island. The lighthouse is the centrepiece of East End Lighthouse Park, managed by the National Trust for the Cayman Islands; the first navigational aid on the site was the first lighthouse in the Cayman Islands.\\r\\nThe merchant marine total is 123 ships (1,000 GRT or over) totalling 2,402,058 GRT/3,792,094 metric tons deadweight (DWT). The fleet includes 22 bulk carriers, 5 cargo ships, 31 chemical tankers, 2 container ships, 1 liquefied gas transport, 21 petroleum tankers, 35 refrigerated cargo ships, 5 roll-on/roll-off vessels and 1 specialised tanker. (Note: some foreign ships register in the Cayman Islands as a flag of convenience. In 2002 ships from eleven countries took advantage of this option, including 15 from Greece, 5 from the United States, 5 from the United Kingdom, 2 from Cyprus, 2 from Denmark and 3 from Norway.)\\r\\nThe Cayman Islands are a major international financial centre. The largest sectors are \\"banking, hedge fund formation and investment, structured finance and securitisation, captive insurance, and general corporate activities\\".[54] Regulation and supervision of the financial services industry is the responsibility of the Cayman Islands Monetary Authority (CIMA).\\r\\nThe Cayman Islands are the fifth-largest banking centre in the world,[55] with $1.5 trillion in banking liabilities.[54] In March 2017 there were 158 banks, 11 of which were licensed to conduct banking activities with domestic (Cayman-based) and international clients, and the remaining 147 were licensed to operate on an international basis with only limited domestic activity.[56] Financial services generated CI$1.2 billion of GDP in 2007 (55% of the total economy), 36% of all employment and 40% of all government revenue. In 2010, the country ranked fifth internationally in terms of value of liabilities booked and sixth in terms of assets booked. It has branches of 40 of the world's 50 largest banks. The Cayman Islands are the second largest captive domicile (Bermuda is largest) in the world with more than 700 captives, writing more than US$7.7 billion of premiums and with US$36.8 billion of assets under management.[57]\\r\\nThere are a number of service providers. These include global financial institutions including HSBC, Deutsche Bank, UBS, and Goldman Sachs; over 80 administrators, leading accountancy practices (incl. the Big Four auditors), and offshore law practices including Maples & Calder.[58] They also include wealth management such as Rothschilds private banking and financial advice.[59]\\r\\nSince the introduction of the Mutual Funds Law in 1993, which has been copied by jurisdictions around the world, the Cayman Islands have grown to be the world's leading offshore hedge fund jurisdiction.[58] In June 2008, it passed 10,000 hedge fund registrations, and over the year ending June 2008 CIMA reported a net growth rate of 12% for hedge funds.[60]\\r\\nStarting in the mid-late 1990s, offshore financial centres, such as the Cayman Islands, came under increasing pressure from the OECD for their allegedly harmful tax regimes, where the OECD wished to prevent low-tax regimes from having an advantage in the global marketplace. The OECD threatened to place the Cayman Islands and other financial centres on a \\"black list\\" and impose sanctions against them.[61] However, the Cayman Islands successfully avoided being placed on the OECD black list in 2000 by committing to regulatory reform to improve transparency and begin information exchange with OECD member countries about their citizens.[61]\\r\\nIn 2004, under pressure from the UK, the Cayman Islands agreed in principle to implement the European Union Savings Directive (EUSD), but only after securing some important benefits for the financial services industry in the Cayman Islands. As the Cayman Islands are not subject to EU laws, the implementation of the EUSD is by way of bilateral agreements between each EU member state and the Cayman Islands. The government of the Cayman Islands agreed on a model agreement, which set out how the EUSD would be implemented with the Cayman Islands.[62]\\r\\nA report published by the International Monetary Fund (IMF), in March 2005, assessing supervision and regulation in the Cayman Islands' banking, insurance and securities industries, as well as its money laundering regime, recognised the jurisdiction's comprehensive regulatory and compliance frameworks. \\"An extensive program of legislative, rule and guideline development has introduced an increasingly effective system of regulation, both formalizing earlier practices and introducing enhanced procedures\\", noted IMF assessors. The report further stated that \\"the supervisory system benefits from a well-developed banking infrastructure with an internationally experienced and qualified workforce as well as experienced lawyers, accountants and auditors\\", adding that, \\"the overall compliance culture within Cayman is very strong, including the compliance culture related to AML (anti-money laundering) obligations\\".[63][64]\\r\\nOn 4 May 2009, the United States President, Barack Obama, declared his intentions to curb the use of financial centres by multinational corporations. In his speech, he singled out the Cayman Islands as a tax shelter.[65] The next day, the Cayman Island Financial Services Association submitted an open letter to the president detailing the Cayman Islands' role in international finance and its value to the US financial system.[66]\\r\\nThe Cayman Islands were ranked as the world's second most significant tax haven on the Tax Justice Network's \\"Financial Secrecy Index\\" from 2011, scoring slightly higher than Luxembourg and falling behind only Switzerland.[67] In 2013, the Cayman Islands were ranked by the Financial Secrecy Index as the fourth safest tax haven in the world, behind Hong Kong but ahead of Singapore. In the first conviction of a non-Swiss financial institution for US tax evasion conspiracy, two Cayman Islands financial institutions pleaded guilty in Manhattan Federal Court in 2016 to conspiring to hide more than $130 million in Cayman Islands bank accounts. The companies admitted to helping US clients hide assets in offshore accounts, and agreed to produce account files of non-compliant US taxpayers.[68]\\r\\nOn 30 June 2014, The tax jurisdiction of the Cayman Islands was deemed to have an Inter- Governmental Agreement (IGA) with the United States of America with respect to the \\"Foreign Account Tax Compliance Act\\" of the United States of America.[69]\\r\\nThe Model 1 Agreement recognizes:[69]\\r\\nOn 26 March 2017, the US Treasury site disclosed that the Model 1 agreement and related agreement were \\"In Force\\" on 1 July 2014.\\r\\nThe Cayman Islands have a small population and therefore a limited workforce. Work permits may, therefore, be granted to foreigners. On average, there have been more than 21,000 foreigners holding valid work permits.[70]\\r\\nTo work in the Cayman Islands as a non-citizen, a work permit is required. This involves passing a police background check and a health check. A prospective immigrant worker will not be granted a permit unless certain medical conditions are present which include testing negative for syphilis and HIV. A permit may be granted to individuals on special work.\\r\\nA foreigner must first have a job to move to the Cayman Islands. The employer applies and pays for the work permit.[71] Work permits are not granted to foreigners who are in the Cayman Islands (unless it is a renewal). The Cayman Islands Immigration Department requires foreigners to remain out of the country until their work permit has been approved.[72]\\r\\nThe Cayman Islands presently imposes a controversial \\"rollover\\" in relation to expatriate workers who require a work permit. Non-Caymanians are only permitted to reside and work within the territory for a maximum of nine years unless they satisfy the criteria of key employees. Non-Caymanians who are \\"rolled over\\" may return to work additional nine-year periods, subject to a one-year gap between their periods of work. The policy has been the subject of some controversy within the press. Law firms have been particularly upset by the recruitment difficulties that it has caused.[73] Other less well-remunerated employment sectors have been affected as well. Concerns about safety have been expressed by diving instructors, and realtors have also expressed concerns. Others support the rollover as necessary to protect Caymanian identity in the face of immigration of large numbers of expatriate workers.[74]\\r\\nConcerns have been expressed that in the long term, the policy may damage the preeminence of the Cayman Islands as an offshore financial centre by making it difficult to recruit and retain experienced staff from onshore financial centres. Government employees are no longer exempt from this \\"rollover\\" policy, according to this report in a local newspaper.[75] The governor has used his constitutional powers, which give him absolute control over the disposition of civil service employees, to determine which expatriate civil servants are dismissed after seven years service and which are not.[citation needed]\\r\\nThis policy is incorporated in the Immigration Law (2003 revision), written by the United Democratic Party government, and subsequently enforced by the People's Progressive Movement Party government. Both governments agree to the term limits on foreign workers, and the majority of Caymanians also agree it is necessary to protect local culture and heritage from being eroded by a large number of foreigners gaining residency and citizenship.[76]\\r\\nIn recognition of the CARICOM (Free Movement) Skilled Persons Act which came into effect in July 1997 in some of the CARICOM countries such as Jamaica and which has been adopted in other CARICOM countries, such as Trinidad and Tobago [77] it is possible that CARICOM nationals who hold the \\"A Certificate of Recognition of Caribbean Community Skilled Person\\" may be allowed to work in the Cayman Islands [78] under normal working conditions.\\r\\nThe Cayman Islands are a British overseas territory, listed by the UN Special Committee of 24 as one of the 16 non-self-governing territories. The current Constitution, incorporating a Bill of Rights, was ordained by a statutory instrument of the United Kingdom in 2009.[79] A 20-seat Legislative Assembly is elected by the people every four years to handle domestic affairs.[80] Of the elected Members of the Legislative Assembly (MLAs), seven are chosen to serve as government ministers in a Cabinet headed by the governor. The premier is appointed by the governor.[81]\\r\\nA governor is appointed by the Queen of the United Kingdom on the advice of the British Government to represent the monarch.[82] Governors can exercise complete legislative and executive authority if they wish through blanket powers reserved to them in the constitution.[83] Bills which have passed the Legislative Assembly require Royal Assent before becoming effective. The Constitution empowers the governor to withhold Royal Assent in cases where the legislation appears to him or her to be repugnant to or inconsistent with the Constitution or affects the rights and privileges of the Legislative Assembly or the Royal Prerogative, or matters reserved to the governor by article 55.[84] The executive authority of the Cayman Islands is vested in the Queen and is exercised by the Government, consisting of the governor and the Cabinet.[85] There is an office of the deputy governor, who must be a Caymanian and have served in a senior public office. The deputy governor is the acting governor when the office of governor is vacant, or the governor is not able to discharge his duties or is absent from the Cayman Islands.[86] The current governor of the Cayman Islands is Her Excellency Helen Kilpatrick, CBE, and the current deputy governor is Franz Manderson, MBE.\\r\\nThe Cabinet is composed of two official members and seven elected members, called ministers; one of whom is designated premier.\\r\\nThe official members are the deputy governor and the attorney general. They are appointed by the governor in accordance with Her Majesty's instructions, and although they have seats in the Legislative Assembly, under the 2009 Constitution, they do not vote.\\r\\nThe seven ministers are voted into office by the 18 elected members of the Legislative Assembly of the Cayman Islands. One of the ministers, the leader of the majority political party, is appointed premier by the governor.\\r\\nAfter consulting the premier, the governor allocates a portfolio of responsibilities to each Cabinet member. Under the principle of collective responsibility, all ministers are obliged to support in the Assembly any measures approved by Cabinet.\\r\\nAlmost 80 departments, sections and units carry out the business of government, joined by a number of statutory boards and authorities set up for specific purposes, such as the Port Authority, the Civil Aviation Authority, the Immigration Board, the Water Authority, the University College Board of Governors, the National Pensions Board and the Health Insurance Commission.\\r\\nSince 2000, there have been two official major political parties: Cayman Democratic Party (CDP) and the People's Progressive Movement (PPM). While there has been a shift to political parties, many contending for an office still run as independents.\\r\\nThe defence of the Cayman Islands is the responsibility of the United Kingdom. Law enforcement in the country is provided chiefly by the Royal Cayman Islands Police Service and the Cayman Islands Customs Department. These two agencies co-operate in aspects of law enforcement, including their joint marine unit. The Cayman Islands Cadet Corps was formed in March 2001 and carries out military-type training with teenage citizens of the country.\\r\\nNo direct taxation is imposed on residents and Cayman Islands companies. The government receives the majority of its income from indirect taxation. Duty is levied against most imported goods, which is typically in the range of 22% to 25%. Some items are exempted, such as baby formula, books, cameras and certain items are taxed at 5%. Duty on automobiles depends on their value. The duty can amount to 29.5% up to $20,000.00 KYD CIF (cost, insurance and freight) and up to 42% over $30,000.00 KYD CIF for expensive models. The government charges flat licensing fees on financial institutions that operate in the islands and there are work permit fees on foreign labour. A 13% government tax is placed on all tourist accommodations in addition to US$37.50 airport departure tax which is built into the cost of an airline ticket. There are no taxes on corporate profits, capital gains, or personal income. There are no estate or death inheritance taxes payable on Cayman Islands real estate or other assets held in the Cayman Islands.[87]\\r\\nForeign policy is controlled by the United Kingdom, as the islands remain an overseas territory of the United Kingdom. Although in its early days, the Cayman Islands' most important relationships were with Britain and Jamaica, in recent years, as a result of economic dependence, a relationship with the United States has developed.\\r\\nThough the Cayman Islands are involved in no major international disputes, they have come under some criticism due to the use of their territory for narcotics trafficking and money laundering. In an attempt to address this, the government entered into the Narcotics Agreement of 1984 and the Mutual Legal Assistance Treaty of 1986 with the United States, to reduce the use of their facilities associated with these activities. In more recent years, they have stepped up the fight against money laundering, by limiting banking secrecy, introducing requirements for customer identification and record keeping, and requiring banks to co-operate with foreign investigators.\\r\\nDue to their status as an overseas territory of the UK, the Cayman Islands have no representation either in the United Nations or in most other international organisations. However, the Cayman Islands still participates in some international organisations, being an associate member of Caricom and UNESCO, and a member of a sub-bureau of Interpol.[88]\\r\\nThe defence and internal security of the Cayman Islands is the responsibility of the United Kingdom.\\r\\nGeorge Town is the port capital of Grand Cayman. There are no berthing facilities for cruise ships, but up to 4 cruise ships can anchor in designated anchorages. There are three cruise terminals in George Town, the North, South, and Royal Watler Terminals. The ride from the ship to the terminal is about 5 minutes.[89]\\r\\nThe Cayman Islands Education Department operates state schools. Caymanian children are entitled to free primary and secondary education. There are two public high schools on Grand Cayman, John Gray High School and Clifton Hunter High School, and one on Cayman Brac, Layman E. Scott High School. Various churches and private foundations operate several private schools.\\r\\nThe University College of the Cayman Islands has campuses on Grand Cayman and Cayman Brac and is the only government-run university on the Cayman Islands.[90] The International College of the Cayman Islands is a private college in Grand Cayman. The college was established in 1970 and offers associate's, bachelor's and master's degree programmes.[91] Grand Cayman is also home to St. Matthew's University, which includes a medical school and a school of veterinary medicine.[92] The Cayman Islands Law School, a branch of the University of Liverpool, is based on Grand Cayman.[93]\\r\\nThe Cayman Islands Civil Service College, a unit of Cayman Islands government organised under the Portfolio of the Civil Service, is in Grand Cayman. Co-situated with University College of the Cayman Islands, it offers both degree programs and continuing education units of various sorts. The college opened in 2007 and is also used as a government research centre.\\r\\nThere are four hospitals in the Cayman Islands. Grand Cayman is home to the private Health City Cayman Islands as well as the Chrissie Tomlinson Memorial Hospital. The public hospitals include the Cayman Islands Hospital (commonly known as the George Town Hospital); and Faith Hospital on Cayman Brac.[94]\\r\\nIn 2007, a magnetic resonance imaging (MRI) unit was installed at the Chrissie Tomlinson Memorial Hospital, replacing the one destroyed by Hurricane Ivan in 2004. In 2009, a stand-alone open MRI facility was opened. This centre provides MRI, CT, X-ray and DEXA (bone density) scanning. Also housed in this building is the Heart Health Centre, which provides ultrasound, nuclear medicine, echocardiography and cardiac stress testing.[95]\\r\\nFor divers and others in need of hyperbaric oxygen therapy, there is a two-person recompression chamber at the Cayman Islands Hospital on Grand Cayman, run by Cayman Hyperbaric Services. Hyperbaric Services has also built a hyperbaric unit at Faith Hospital in Cayman Brac.[96][97]\\r\\nIn 2003, the Cayman Islands became the first country in the world to mandate health insurance for all residents.[98]\\r\\nThe Royal Cayman Islands Police Service (RCIPS) provides law enforcement for the three islands. Regular off-shore marine and air patrols are conducted by the RCIP using a small fleet of vessels and a helicopter. Grand Cayman is a port of call for Britain's Royal Navy and the United States Coast Guard who often assist with sea rescues when their resources are in the Cayman Islands area. The Cayman Islands Fire Service provides fire prevention, fire fighting and rescue.[99] Its headquarters are in George Town and has substations in Frank Sound, West Bay, Cayman Brac and Little Cayman.[100] Emergency Medical Services are provided by paramedics and Emergency Medical Technicians using ambulances based in George Town, West Bay and North Side in Grand Cayman and in Cayman Brac. EMS is managed by the Government's Health Services Authority.\\r\\nAccess to Emergency Services is available using 9-1-1, the Emergency telephone number, the same number as is used in Canada and the United States. The Cayman Islands Department of Public Safety's Communications Centre processes 9-1-1 and non-emergency law enforcement, EMS, fire, and Search and Rescue calls for all three islands. The Communications Centre dispatches RCIP and EMS units directly, however, the Cayman Islands Fire Service maintains their own dispatch room at the airport fire station.[citation needed]\\r\\nTruman Bodden Sports Complex is a multi-use complex in George Town. The complex is separated into an outdoor, six-lane 25-metre (82?ft) swimming pool, full purpose track and field and basketball/netball courts. The field surrounded by the track is used for association football matches as well as other field sports. The track stadium holds 3,000 people.\\r\\nAssociation football is the national and most popular sport, with the Cayman Islands national football team representing the Cayman Islands in FIFA.[citation needed]\\r\\nThe Cayman Islands Basketball Federation joined the international basketball governing body FIBA in 1976.[101] The country's national team showed up at the official 2011 Caribbean Basketball Championship for the first time.\\r\\nRugby union is a developing sport, and has its own national men's team, women's team, and Sevens team. The Cayman Men's Rugby 7s team is second in the region after the 2011 NACRA 7s Championship.\\r\\nThe Cayman Islands are members of FIFA, the International Olympic Committee and the Pan American Sports Organisation, and also compete in the biennial Island Games.[102]\\r\\nThe Cayman Islands are members of the International Cricket Council which they joined in 1997 as an Affiliate, before coming an Associate member in 2002. The Cayman Islands national cricket team represents the islands in international cricket. The team has previously played the sport at first-class, List A and Twenty20 level. It competes in Division Five of the World Cricket League.[103]\\r\\nSquash is popular in the Cayman Islands with a vibrant community of mostly ex-pats playing out of the 7 court South Sound Squash Club. In addition, the women's professional squash association hosts one of their major events each year in an all glass court being set up in Camana Bay. In December 2012, the former Cayman Open will be replaced by the Women's World Championships, the largest tournament in the world. The top Cayman men's player, Cameron Stafford is No. 2 in the Caribbean and ranked top 200 on the men's professional circuit.\\r\\nFlag football (CIFFA) has men's, women's and co-ed leagues.\\r\\nOther organised sports leagues include softball, beach volleyball, Gaelic football and ultimate frisbee.\\r\\nThe Cayman Islands Olympic Committee was founded in 1973 and was recognised by the IOC (International Olympic Committee) in 1976.\\r\\nIn the 21st century, skateboarding has become popular among the youth.[citation needed]\\r\\nIn February 2010, the first purpose built track for kart racing in the Cayman Islands was opened.[104] Corporate karting Leagues at the track have involved widespread participation with 20 local companies and 227 drivers taking part in the 2010 Summer Corporate Karting League.[105]\\r\\nThe Cayman National Cultural Foundation manages the F.J. Harquail Cultural Centre and the US$4?million Harquail Theatre. The Cayman National Cultural Foundation, established in 1984, helps to preserve and promote Cayman folk music, including the organisation of festivals such as Cayman Islands International Storytelling Festival, the Cayman JazzFest, Seafarers Festival and Cayfest.[citation needed]\\r\\nThere are two print newspapers currently in circulation throughout the islands: the Caymanian Compass and Cayman Reporter. There are numerous online news services including Cayman News Service and the Cayman Compass online edition. A local television station, CITN ÿ Cayman 27, shows Cayman Islands news.[106] Local radio stations are broadcast throughout the islands.\\r\\nFeature films that have been filmed in the Cayman Islands include: The Firm, Haven, Cayman Went[107] and Zombie Driftwood.[108]\\r\\nClick on a coloured area to see an article about English in that country or region","input":"How many islands are in the cayman islands?"},{"output":"1752 began on 1 January","context":"The Calendar (New Style) Act 1750 (c.23) (also known as Chesterfield's Act after Philip Stanhope, 4th Earl of Chesterfield) was an Act of the Parliament of Great Britain. The Act had two parts: first, it reformed the calendar of England[a] and the British Dominions so that the new legal year began on 1 January rather than 25 March (Lady Day); and, second, Great Britain and its Dominions adopted (in effect)[b] the Gregorian calendar, as already used in most of western Europe.\\r\\n\\r\\n\\r\\nThe Parliament held that the Julian calendar then in use, and the start of the year on 25 March, were\\r\\nIn England and Wales, the legal year 1751 was a short year of 282 days, running from 25 March to 31 December. 1752 began on 1 January. To align the calendar in use in England to that on the continent, the Gregorian calendar was adopted: and the calendar was advanced by 11 days: Wednesday 2 September 1752 was followed by Thursday 14 September 1752.[c] The year 1752 was thus a short year (355 days) as well.\\r\\nAs well as adopting the Gregorian rule for leap years, Pope Gregory's rules for the date of Easter were also adopted. However, with religious strife still on their minds, the British could not bring themselves to adopt the Catholic system explicitly: the Annexe to the Act established a computation for the date of Easter that achieved the same result as Gregory's rules, without actually referring to him.[2] The algorithm, set out in the Book of Common Prayer as required by the Act, includes calculation of the Golden Number and the Sunday Letter, which (in the Easter section of the Book) were presumed to be already known. The Annexe to the Act includes the definition: \\"Easter-day (on which the rest depend) is always the first Sunday after the Full Moon, which happens upon, or next after the Twenty-first Day of March. And if the Full Moon happens upon a Sunday, Easter-day is the Sunday after.\\" The Annexe subsequently uses the terms \\"Paschal Full Moon\\" and \\"Ecclesiastical Full Moon\\", making it clear that they only approximate to the real Full Moon.[3]\\r\\nScotland had already partly made the change: its calendar year had begun on 1 January since 1600.[4] The remainder of the act applied equally to Scotland, a part of the Kingdom of Great Britain since the Acts of Union 1707.\\r\\nAt the time Ireland was an Independent kingdom in a personal union with the Crown of Great Britain. So that the calendar in Ireland would remain harmonised with Great Britain, the Parliament of Ireland passed similarly worded legislation as the \\"Calendar (New Style) Act, 1750\\".[5]\\r\\nSome history books say that some people rioted after the calendar change, asking that their \\"eleven days\\" be returned. However this is very likely a myth, based on only two primary sources: The World, a satirical journal of Lord Chesterfield; and a painting by William Hogarth.[6]\\r\\nChesterfield was behind the Act. He wrote to his son, \\"Every numerous assembly is a mob, let the individuals who compose it be what they will. Mere sense is never to be talked to a mob; their passions, their sentiments, their senses and their seeming interests alone are to be applied to. Understanding have they collectively none.\\" Here, he was boasting of his skill in having the Bill passed through the Lords; the 'mob' in question was his fellow peers.[citation needed]\\r\\nWhen the son of the Earl of Macclesfield (who had been influential in passing the Act) stood for Parliament in Oxfordshire as a Whig in 1754, dissatisfaction with the calendar reform was one of a number of issues raised by his Tory opponents. In 1755, William Hogarth produced a painting (and an engraved print from the painting) loosely based on these elections, entitled An Election Entertainment, which shows a placard carrying the slogan \\"Give us our Eleven Days\\" (on floor at lower right). An example of the resulting incorrect history is by Ronald Paulson, author of Hogarth, His Life, Art and Times, who wrote that \\"...the Oxfordshire people...are specifically rioting, as historically the London crowd did, to preserve the 'Eleven Days' the government stole from them in September 1752 by changing the calendar\\".[6]\\r\\nThus the \\"calendar riot\\" fiction was born. The election campaign depicted concluded in 1754, after a very lengthy contest between Court Whigs and Jacobite Tories. Every issue between the two factions was brought up, including the question of calendar reform. The Tories attacked the Whigs for every deviation, including their alleged favouritism towards foreign Jews and the \\"Popish\\" calendar. Hogarth's placard, part of a satire on the character of the debate, was not an observation of actual crowd behaviour.[6]\\r\\nThere were, however, legitimate concerns about tax and other payments under the new calendar. Provision 6 (Times of Payment of Rents, Annuities) of the Act stipulated that monthly or yearly payments would not become due until the dates that they originally would have in the Julian calendar, or in the words of the Act \\"[Times of Payment of Rents, Annuities] at and upon the same respective natural days and times as the same should and ought to have been payable or made or would have happened in case this Act had not been made\\".[1]\\r\\nSeveral theories have been proposed for the odd beginning of the British tax year on 6 April.[7] One is that from 1753 until 1799, the tax year began on 5 April, which corresponded to 25 March Old Style. After the twelfth skipped Julian leap day in 1800, it was changed to 6 April, which still corresponded to 25 March Old Style. However it was not changed when a thirteenth Julian leap day was skipped in 1900, so the tax year in the United Kingdom still begins on 6 April.[8][9] However Poole thought that quarter days, such as Lady Day on 25 March, marked the end of the quarters of the financial year.[10] Thus, although 25 March Old Style marked the beginning of the civil year, the next day, 26 March Old Style was until 1752 the beginning of the tax year. After removing eleven days in 1752, this corresponded to 6 April New Style, where it remains today. Although Poole's theory is supported by one dictionary,[11] the Oxford English Dictionary as well as other sources state that quarter days mark the beginning of their respective quarters.[d][12]\\r\\nIn Appalachia, some Scots-Irish settlers resisted the changeover mandated by the Calendar Act by continuing to celebrate Christmas on January 6 (N.S.), referring to the day as Old Christmas.[13]\\r\\nPrimary sources","input":"When did england switch to the gregorian calendar?"},{"output":"Afrikaans","context":"Cape Town (Afrikaans: Kaapstad, [?k?pstat]) is a coastal city in South Africa. It is the second-most populous urban area in South Africa after Johannesburg.[6] It is also the capital and primate city of the Western Cape province.[7]\\r\\nAs the seat of the Parliament of South Africa, it is also the legislative capital of the country.[8] It forms part of the City of Cape Town metropolitan municipality. The city is famous for its harbour, for its natural setting in the Cape Floristic Region, and for such well-known landmarks as Table Mountain and Cape Point. As of 2014[update], it is the 10th most populous city[clarification needed] in Africa and home to 64% of the Western Cape's population.[9] It is one of the most multicultural cities in the world, reflecting its role as a major destination for immigrants and expatriates[10] to South Africa. The city was named the World Design Capital for 2014 by the International Council of Societies of Industrial Design.[11] In 2014, Cape Town was named the best place in the world to visit by both the American New York Times[12] and the British Daily Telegraph.[13]\\r\\nLocated on the shore of Table Bay, Cape Town was first developed by the Dutch East India Company as a victualling (supply) station for Dutch ships sailing to East Africa, India, and the Far East. Jan van Riebeeck's arrival on 6 April 1652 established the first permanent European settlement in South Africa. Cape Town quickly outgrew its original purpose as the first European outpost at the Castle of Good Hope, becoming the economic and cultural hub of the Cape Colony. Until the Witwatersrand Gold Rush and the development of Johannesburg, Cape Town was the largest city in South Africa.\\r\\n\\r\\n\\r\\nThe earliest known remnants in the region were found at Peers Cave in Fish Hoek and date to between 15,000 and 12,000 years ago.[14] Little is known of the history of the region's first residents, since there is no written history from the area before it was first mentioned by Portuguese explorer Bartolomeu Dias in 1486 who was the first European to reach the area and named it \\"Cape of Storms\\" (Cabo das Tormentas). It was later renamed by John II of Portugal as \\"Cape of Good Hope\\" (Cabo da Boa Esperan?a) because of the great optimism engendered by the opening of a sea route to India and the East. Vasco da Gama recorded a sighting of the Cape of Good Hope in 1497. In the late 16th century, Portuguese, French, Danish, Dutch and English but mainly Portuguese ships regularly stopped over in Table Bay en route to the Indies. They traded tobacco, copper and iron with the Khoikhoi in exchange for fresh meat.\\r\\nIn 1652, Jan van Riebeeck and other employees of the Dutch East India Company (Dutch: Verenigde Oost-indische Compagnie, VOC) were sent to the Cape to establish a way-station for ships travelling to the Dutch East Indies, and the Fort de Goede Hoop (later replaced by the Castle of Good Hope). The settlement grew slowly during this period, as it was hard to find adequate labour. This labour shortage prompted the authorities to import slaves from Indonesia and Madagascar. Many of these became ancestors of the first Cape Coloured communities.[15][16] Under Van Riebeeck and his successors as VOC commanders and later governors at the Cape, an impressive range of useful plants were introduced to the Cape ÿ in the process changing the natural environment forever. Some of these, including grapes, cereals, ground nuts, potatoes, apples and citrus, had an important and lasting influence on the societies and economies of the region.[17]\\r\\nThe Dutch Republic being transformed in Revolutionary France's vassal Batavian Republic, Great Britain moved to take control of its colonies. Britain captured Cape Town in 1795, but the Cape was returned to the Dutch by treaty in 1803. British forces occupied the Cape again in 1806 following the Battle of Blaauwberg. In the Anglo-Dutch Treaty of 1814, Cape Town was permanently ceded to Britain. It became the capital of the newly formed Cape Colony, whose territory expanded very substantially through the 1800s. With expansion came calls for greater independence from Britain, with the Cape attaining its own parliament (1854) and a locally accountable Prime Minister (1872). Suffrage was established according to the non-racial, but sexist Cape Qualified Franchise.[18][19]\\r\\nThe discovery of diamonds in Griqualand West in 1867, and the Witwatersrand Gold Rush in 1886, prompted a flood of immigrants to South Africa.[20] Conflicts between the Boer republics in the interior and the British colonial government resulted in the Second Boer War of 1899ÿ1902, which Britain won. In 1910, Britain established the Union of South Africa, which unified the Cape Colony with the two defeated Boer Republics and the British colony of Natal. Cape Town became the legislative capital of the Union, and later of the Republic of South Africa.\\r\\nIn the 1948 national elections, the National Party won on a platform of apartheid (racial segregation) under the slogan of \\"swart gevaar\\". This led to the erosion and eventual abolition of the Cape's multiracial franchise, as well as to the Group Areas Act, which classified all areas according to race. Formerly multi-racial suburbs of Cape Town were either purged of unlawful residents or demolished. The most infamous example of this in Cape Town was District Six. After it was declared a whites-only region in 1965, all housing there was demolished and over 60,000 residents were forcibly removed.[21] Many of these residents were relocated to the Cape Flats and Lavender Hill. Under apartheid, the Cape was considered a \\"Coloured labour preference area\\", to the exclusion of \\"Bantus\\", i.e. Africans.\\r\\nSchool students from Langa, Gugulethu and Nyanga in Cape Town reacted to the news of protests against Bantu Education in Soweto in June 1976 and organised gatherings and marches which were met with resistance from the police. A number of school buildings were burnt down.[22][23]\\r\\nCape Town was home to many leaders of the anti-apartheid movement. On Robben Island, a former penitentiary island 10 kilometres (6 miles) from the city, many famous political prisoners were held for years. In one of the most famous moments marking the end of apartheid, Nelson Mandela made his first public speech since his imprisonment, from the balcony of Cape Town City Hall hours after being released on 11 February 1990. His speech heralded the beginning of a new era for the country, and the first democratic election, was held four years later, on 27 April 1994. Nobel Square in the Victoria & Alfred Waterfront features statues of South Africa's four Nobel Peace Prize winners: Albert Luthuli, Desmond Tutu, F. W. de Klerk and Nelson Mandela. Since 1994, the city has struggled with problems such as drugs, a surge in violent drug-related crime and more recently gang violence. At the same time, the economy has surged to unprecedented levels due to the boom in the tourism and the real estate industries.[citation needed] With a Gini coefficient of 0.67, Cape Town has the highest rate of equality in South Africa.[24]\\r\\nCape Town is located at latitude 33.55 S (approx. the same as Sydney and Buenos Aires and equivalent to Casablanca and Los Angeles in the northern hemisphere) and longitude 18.25 E. Table Mountain, with its near vertical cliffs and flat-topped summit over 1,000?m (3,300?ft) high, and with Devil's Peak and Lion's Head on either side, together form a dramatic mountainous backdrop enclosing the central area of Cape Town, the so-called City Bowl. A thin strip of cloud, known colloquially as the \\"tablecloth\\", sometimes forms on top of the mountain. To the immediate south, the Cape Peninsula is a scenic mountainous spine jutting 40 kilometres (25?mi) southwards into the Atlantic Ocean and terminating at Cape Point. There are over 70 peaks above 300?m (980?ft) within Cape Town's official city limits. Many of the city's suburbs lie on the large plain called the Cape Flats, which extends over 50 kilometres (30?mi) to the east and joins the peninsula to the mainland. The Cape Flats is situated on what is known as a rising marine plain, consisting mostly of sandy geology and confirming that at one point Table Mountain was itself an island.[citation needed] The Cape Town region generally, with its Mediterranean climate, extensive coastline, rugged mountain ranges, coastal plains, inland valleys and semi-desert fringes, has much in common with Southern California.\\r\\nRobben Island\\r\\nUnesco declared Robben Island in the Western Cape a World Heritage Site in 1999. Robben Island is located in Table Bay, some 6km west of Bloubergstrand in Cape Town, and stands some 30m above sea level. Robben Island has been used as prison where people were isolated, banished and exiled to for nearly 400 years. It was also used as a leper colony, a post office, a grazing ground, a mental hospital, and an outpost. [25]\\r\\nCurrently visitors can only access the island via the Robben Island Museum boat service, which run three times daily until the beginning of the peak season (01 September). The ferries depart from the Nelson Mandela Gateway at the V&A Waterfront.\\r\\nCape Town has a warm-summer Mediterranean climate (K?ppen Csb),[26][27][28] with mild, moderately wet winters and dry, warm summers. Winter, which lasts from the beginning of June to the end of August, may see large cold fronts entering for limited periods from the Atlantic Ocean with significant precipitation and strong north-westerly winds. Winter months in the city average a maximum of 18.0?C (64?F) and minimum of 8.5?C (47?F) [29] Total annual rainfall in the city averages 515 millimetres (20.3?in). Summer, which lasts from early December to March, is warm and dry with an average maximum of 26.0?C (79?F) and minimum of 16.0?C (61?F). The region can get uncomfortably hot when the Berg Wind, meaning \\"mountain wind\\", blows from the Karoo interior for a couple of weeks in February or early March. Late spring and early summer generally feature a strong wind from the south-east, known locally as the south-easter or the Cape Doctor, so called because it blows air pollution away. This wind is caused by a high-pressure system which sits in the South Atlantic to the west of Cape Town, known as the South Atlantic High. Cape Town receives 3,100 hours of sunshine per year.[30]\\r\\nWater temperatures range greatly, between 10?C (50?F) on the Atlantic Seaboard, to over 22?C (72?F) in False Bay. Average annual Ocean temperatures are between 13?C (55?F) on the Atlantic Seaboard (similar to Californian waters, such as San Francisco or Big Sur), and 17?C (63?F) in False Bay (similar to Northern Mediterranean temperatures, such as Nice or Monte Carlo).\\r\\nFrom 2015 Cape Town started experiencing the worst drought in one hundred years.[31][32]\\r\\nLocated in a CI Biodiversity hotspot as well as the unique Cape Floristic Region, the city of Cape Town has one of the highest levels of biodiversity of any equivalent area in the world.[35] These protected areas are a World Heritage Site, and an estimated 2,200 species of plants are confined to Table Mountain ÿ more than exist in the whole of the United Kingdom which has 1200 plant species and 67 endemic plant species.[36][37][38] Many of these species, including a great many types of proteas, are endemic to the mountain and can be found nowhere else.[39]\\r\\nIt is home to a total of 19 different vegetation types, of which several are completely endemic to the city and occur nowhere else in the world.[40] It is also the only habitat of hundreds of endemic species,[41] and hundreds of others which are severely restricted or threatened. This enormous species diversity is mainly because the city is uniquely located at the convergence point of several different soil types and micro-climates.\\r\\nTable Mountain has an unusually rich biodiversity. Its vegetation consists predominantly of several different types of the unique and rich Cape Fynbos. The main vegetation type is endangered Peninsula Sandstone Fynbos, but critically endangered Peninsula Granite Fynbos, Peninsula Shale Renosterveld and Afromontane forest occur in smaller portions on the mountain.\\r\\nUnfortunately, rapid population growth and urban sprawl has covered much of these ecosystems with development. Consequently, Cape Town now has over 300 threatened plant species and 13 which are now extinct. The Cape Peninsula, which lies entirely within the city of Cape Town, has the highest concentration of threatened species of any continental area of equivalent size in the world.[42] Tiny remnants of critically endangered or near extinct plants often survive on road sides, pavements and sports fields.[43] The remaining ecosystems are partially protected through a system of over 30 nature reserves ÿ including the massive Table Mountain National Park.\\r\\nCape Town's urban geography is influenced by the contours of Table Mountain, its surrounding peaks, the Durbanville Hills, and the expansive lowland region known as the Cape Flats. These geographic features in part divide the city into several commonly known groupings of suburbs (equivalent to districts outside South Africa), many of which developed historically together and share common attributes of language and culture.\\r\\nThe City Bowl is a natural amphitheatre-shaped area bordered by Table Bay and defined by the mountains of Signal Hill, Lion's Head, Table Mountain and Devil's Peak.\\r\\nThe area includes the central business district of Cape Town, the harbour, the Company's Garden, and the residential suburbs of De Waterkant, Devil's Peak, District Six, Zonnebloem, Gardens, Bo-Kaap, Higgovale, Oranjezicht, Schotsche Kloof, Tamboerskloof, University Estate, Vredehoek, Walmer Estate and Woodstock.\\r\\nThe Atlantic Seaboard lies west of Cape Town and Table Mountain, and is characterised by its beaches, cliffs, promenade and hillside communities. The area includes, from north to south, the neighbourhoods of Green Point, Mouille Point, Three Anchor Bay, Sea Point, Fresnaye, Bantry Bay, Clifton, Camps Bay, Llandudno, and Hout Bay. The Atlantic Seaboard has some of the most expensive real estate in South Africa particularly on Nettleton and Clifton Roads in Clifton, Ocean View Drive and St Leon Avenue in Bantry Bay, Theresa Avenue in Bakoven and Fishermans Bend in Llandudno. Camps Bay is home to the highest concentration of multimillionaires in Cape Town and has the highest number of high-priced mansions in South Africa with more than 155 residential units exceeding R20 million (or $US1.8 million).[when?][44]\\r\\nThe West Coast suburbs lie along the beach to the north of the Cape Town city centre, and include Bloubergstrand, Milnerton, Tableview, West Beach, Big Bay, Sunset Beach, Sunningdale and Parklands, as well as the exurbs of Atlantis and Melkbosstrand. The Koeberg Nuclear Power Station is located within this area and maximum housing density regulations are enforced in much of the area surrounding the nuclear plant.\\r\\nThe Northern Suburbs are Afrikaans-speaking, and include Bellville, Kanonberg, Bothasig, Brooklyn, Burgundy Estate, Durbanville, Edgemead, Elsie's River, Factreton, Goodwood, Kensington, Maitland, Monte Vista, Panorama, Parow, Richwood, Table View, and Welgemoed.[45] The Northern Suburbs are home to Tygerberg Hospital, the largest hospital in the Western Cape and second largest in South Africa[46]\\r\\nThe Southern Suburbs hug along the eastern slopes of Table Mountain, southeast of the city centre. This area has mixed languages but is predominantly English-speaking, and includes, from north to south, Rondebosch, Pinelands, Thornton, Newlands, Mowbray, Observatory, Bishopscourt, Claremont, Lansdowne, Wynberg, Plumstead, Hout Bay, Ottery, and Bergvliet. West of Wynberg lies Constantia which, in addition to being a wealthy neighbourhood, is a notable wine-growing region within the City of Cape Town. Constantia not only offers a luscious suburban living lifestyle, but also attracts tourists for its well-known wine farms and Cape Dutch architecture.\\r\\nThe South Peninsula is generally regarded as the area south of Muizenberg on False Bay and Noordhoek on the Atlantic Ocean, all the way to Cape Point. Until recently quite rural, the population of the area is growing quickly as new coastal developments proliferate and larger plots are subdivided to provide more compact housing. It includes Capri Village, Clovelly, Fish Hoek, Glencairn, Kalk Bay, Kommetjie, Masiphumelele, Muizenberg, Noordhoek, Ocean View, Scarborough, Simon's Town, St James, Sunnydale, Sun Valley, and Steenberg. South Africa's largest naval base is located at Simon's Town harbour, and close by is Boulders Beach, the site of a large colony of African penguins.[47]\\r\\nThe Eastern Suburbs lie southeast of the Afrikaans-speaking neighbourhoods in the Northern Suburbs, beyond the airport, and notably are the site of several new subsidized housing projects and are also Afrikaans-speaking. Communities include Fairdale, Brackenfell, Kraaifontein, Kuils River, Blue Downs, Belhar, Delft, Mfuleni and Protea Hoogte.\\r\\nThe Cape Flats (Die Kaapse Vlakte in Afrikaans) is an expansive, low-lying, flat Afrikaans-speaking area situated to the southeast of the central business district of Cape Town. From the 1950s the area became home to people the apartheid government designated as non-White and has been described by some as 'Apartheid's dumping ground'. Race-based legislation such as the Group Areas Act and pass laws either forced non-white people out of more central urban areas designated for white people and into government-built townships in the Flats or made living in the area illegal, forcing many people designated as Black and Coloured into informal settlements elsewhere in the Flats.\\r\\nSince then the Flats have been home to much of the population of Greater Cape Town. This area includes the neighbourhoods of Mitchell's Plain, Athlone, Elsie's River, Hanover Park, Bishop Lavis, Manenberg, Strandfontein, Gugulethu, Nyanga, Langa, and Khayelitsha.\\r\\nThe Helderberg consists of Somerset West, Strand, Gordons Bay and a few other towns. The district takes its name from the imposing Helderberg Mountain, which is Afrikaans for \\"clear mountain\\", and culminates at a height of 1,137 metres (3,730 feet) as The Dome.\\r\\nCape Town's local government is the City of Cape Town, which is a metropolitan municipality. Cape Town is governed by a 221-member city council. The city is divided into 111 electoral wards; each ward directly elects one member of the council, whilst the other 110 councillors are elected by a system of party-list proportional representation. The Executive Mayor and Executive Deputy Mayor are chosen by the city council.\\r\\nIn the local government elections of 18 May 2011, the Democratic Alliance (DA) won an outright majority, taking 135 of the 221 council seats. The African National Congress, the national ruling party, received 73 seats.[48] As a result of this victory Patricia de Lille, the DA mayoral candidate, was inaugurated as Executive Mayor on 1 June.\\r\\n1996,[51] 2001, and 2011 Census;[52]\\r\\nAccording to the South African National Census of 2011, the population of the City of Cape Town metropolitan municipality?ÿ an area that includes suburbs and exurbs not always considered as part of Cape Town?ÿ is 3,740,026 people. This represents an annual growth rate of 2.6% compared to the results of the previous census in 2001 which found a population of 2,892,243 people.[54] :54 The sex ratio is 96, meaning that there are slightly more women than men.[54]:55 45.4% of the population described themselves as \\"Coloured\\", 42.7% as \\"White\\", 8.6% as \\"Black African\\", and 1.4% as \\"Indian or Asian\\".[54]:56ÿ59 In 1944, 47% of the city's population was White, 46% was Coloured, less than 6% was Black African and 1% was Asian.[55] Of those residents who were asked about their first language, 35.7% spoke Afrikaans, 29.8% spoke Xhosa and 28.4% spoke English. 24.8% of the population is under the age of 15, while 5.5% is 65 or older.[54]:64\\r\\nOf those residents aged 20 or older, 1.8% have no schooling, 8.1% have some schooling but did not finish primary school, 4.6% finished primary school but have no secondary schooling, 38.9% have some secondary schooling but did not finish Grade 12, 29.9% finished Grade 12 but have no higher education, and 16.7% have higher education. Overall, 46.6% have at least a Grade 12 education.[54]:74 Of those aged between 5 and 25, 67.8% are attending an educational institution.[54]:78 Amongst those aged between 15 and 65 the unemployment rate is 23.7%.[54]:79 The average annual household income is R161,762.[54]:88\\r\\nThere are 1,068,573 households in the municipality, giving an average household size of 3.3 people.[54]:80 Of those households, 78.4% are in formal structures (houses or flats), while 20.5% are in informal structures (shacks).[54]:81 94.0% of households use electricity for lighting.[54]:84 87.3% of households have piped water to the dwelling, while 12.0% have piped water through a communal tap.[54]:85 94.9% of households have regular refuse collection service.[54]:86 91.4% of households have a flush toilet or chemical toilet, while 4.5% still use a bucket toilet.[54]:87 82.1% of households have a refrigerator, 87.3% have a television and 70.1% have a radio. Only 34.0% have a landline telephone, but 91.3% have a cellphone. 37.9% have a computer, and 49.3% have access to the Internet (either through a computer or a cellphone).[54]:83\\r\\nCape Town is the economic hub of the Western Cape Province, South Africa's second main economic centre and Africa's third main economic hub city. It serves as the regional manufacturing centre in the Western Cape. In 2011 the city's GDP was US$56.8?billion with a GDP per capita of US$15,721.[5] In the five years preceding 2014 Cape Town GDP grew at an average of 3.7% a year. As a proportion of GDP the agriculture and manufacturing sectors have declined whilst finance, business services, transport and logistics have grown reflecting the growth in specialised services sectors of the local economy. Fishing, clothing and textiles, wood product manufacturing, electronics, furniture, hospitality, finance and business services are industries in which Cape Town's economy has the largest comparative advantage.[9]\\r\\nBetween 2001 and 2010 the city's Gini coefficient, a measure of inequality, improved by dropping from 0.59 in 2007 to 0.57 in 2010 only to increase to 0.67 by 2011/12.[9]\\r\\nCape Town has recently enjoyed a booming real estate and construction market, because of the 2010 World Cup as well as many people buying summer homes in the city or relocating there permanently. Cape Town hosted nine World Cup matches: Six first-round matches, one second-round match, one quarter final and one semifinal. The central business district is under an extensive urban renewal programme, with numerous new buildings and renovations taking place under the guidance of the Cape Town Partnership.[56]\\r\\nCape Town has four major commercial nodes, with Cape Town Central Business District containing the majority of job opportunities and office space. Century City, the Bellville/TygerValley strip and Claremont commercial nodes are well established and contain many offices and corporate headquarters as well. Most companies headquartered in the city are insurance companies, retail groups, publishers, design houses, fashion designers, shipping companies, petrochemical companies, architects and advertising agencies.[57] The most notable companies headquartered in the city are food and fashion retailer Woolworths,[58] supermarket chain Pick n Pay Stores and Shoprite,[59] New Clicks Holdings Limited, fashion retailer Foschini Group,[60] isp MWEB, Mediclinic International, etv, multi-national mass media giant Naspers, and financial services giant Sanlam.[61] Other notable companies include Belron (vehicle glass repair and replacement group operating worldwide), CapeRay (develops, manufactures and supplies medical imaging equipment for the diagnosis of breast cancer), Ceres Fruit Juices (produces fruit juice and other fruit based products), Coronation Fund Managers (third-party fund management company), ICS (was one of the largest meat processing and distribution companies in the world), Vida e Caff (chain of coffee retailers), Capitec Bank (commercial bank in the Republic of South Africa). The city is a manufacturing base for several multi-national companies including, Johnson & Johnson, GlaxoSmithKline, Levi Strauss & Co., Adidas, Bokomo Foods, and Nampak.\\r\\nMuch of the produce is handled through the Port of Cape Town or Cape Town International Airport. Most major shipbuilding companies have offices and manufacturing locations in Cape Town.[62] The Province is also a centre of energy development for the country, with the existing Koeberg nuclear power station providing energy for the Western Cape's needs.\\r\\nThe Western Cape is an important tourist region in South Africa; the tourism industry accounts for 9.8% of the GDP of the province and employs 9.6% of the province's workforce. In 2010, over 1.5?million international tourists visited the area.[63]\\r\\nWith the highest number of successful Information Technology companies in Africa, Cape Town is an important centre for the industry on the continent. Growing at an annual rate of 8.5% and an estimated worth of R77?billion in 2010 nationwide the IT industry in Cape Town is becoming increasingly important to the city's economy.[64]\\r\\nThe city was recently named as the most entrepreneurial city in South Africa, with the percentage of Capetonians pursuing business opportunities almost three times higher than the national average. Those aged between 18 and 64 were 190% more likely to pursue new business, whilst in Johannesburg, the same demographic group was only 60% more likely than the national average to pursue a new business.[65]\\r\\nCape Town is not only a popular international tourist destination in South Africa, but Africa as a whole. This is due to its good climate, natural setting, and well-developed infrastructure. The city has several well-known natural features that attract tourists, most notably Table Mountain,[66] which forms a large part of the Table Mountain National Park and is the back end of the City Bowl. Reaching the top of the mountain can be achieved either by hiking up, or by taking the Table Mountain Cableway. Cape Point is recognised as the dramatic headland at the end of the Cape Peninsula.[67] Many tourists also drive along Chapman's Peak Drive, a narrow road that links Noordhoek with Hout Bay, for the views of the Atlantic Ocean and nearby mountains. It is possible to either drive or hike up Signal Hill for closer views of the City Bowl and Table Mountain.[68]\\r\\nMany tourists also visit Cape Town's beaches, which are popular with local residents.[69] Due to the city's unique geography, it is possible to visit several different beaches in the same day, each with a different setting and atmosphere. Though the Cape's water ranges from cold to mild, the difference between the two sides of the city is dramatic. While the Atlantic Seaboard averages annual water temperatures barely above that of coastal California around 13?C (55?F), the False Bay coast is much warmer, averaging between 16 and 17?C (61 and 63?F) annually. This is similar to water temperatures in much of the Northern Mediterranean (for example Nice). In summer, False Bay water averages slightly over 20?C (68?F), with 22?C (72?F) a common high. Beaches located on the Atlantic Coast tend to have very cold water due to the Benguela current which originates from the Southern Ocean, whilst the water at False Bay beaches may be warmer by up to 10?C (18?F) at the same moment due to the influence of the warm Agulhas current, and the surface warming effects of the South Easter wind.[69] It is a common misconception that False Bay is part of the Indian Ocean, with Cape Point being both the meeting point of the Indian and Atlantic Oceans, and the southernmost tip of Africa. The oceans in fact meet at the actual southernmost tip, Cape Agulhas, which lies approximately 150 kilometres (93 miles) to the south east. The misconception is fuelled by the relative warmth of the False Bay water to the Atlantic Seaboard water, and the many confusing instances of \\"Two Oceans\\" in names synonymous with Cape Town, such as the Two Oceans Marathon, the Two Oceans Aquarium, and places such as Two Oceans wine farm.\\r\\nBoth coasts are equally popular, although the beaches in affluent Clifton and elsewhere on the Atlantic Coast are better developed with restaurants and cafs, with a strip of restaurants and bars accessible to the beach at Camps Bay. The Atlantic seaboard, known as Cape Town's Rivera, is regarded as one of the most scenic routes in South Africa. The majestic slopes of the Twelve Apostles to the unspoilt boulders and white sand beaches of Llandudno, which the route ending in Hout Bay - a diverse bustling suburb with a harbour and a seal island. This fishing village is flanked by the luscious Constantia valley and the picturesque Chapmans Peak drive. Boulders Beach near Simon's Town is known for its colony of African penguins.[70] Surfing is popular and the city hosts the Red Bull Big Wave Africa surfing competition every year.\\r\\nThe city has several notable cultural attractions. The Victoria & Alfred Waterfront, built on top of part of the docks of the Port of Cape Town, is the city's most visited tourist attraction. It is also one of the city's most popular shopping venues, with several hundred shops and the Two Oceans Aquarium.[71][72] The V&A also hosts the Nelson Mandela Gateway, through which ferries depart for Robben Island.[73] It is possible to take a ferry from the V&A to Hout Bay, Simon's Town and the Cape fur seal colonies on Seal and Duiker Islands. Several companies offer tours of the Cape Flats, a mostly Coloured township, and Khayelitsha, a mostly black township.[74]\\r\\nCape Town is noted for its architectural heritage, with the highest density of Cape Dutch style buildings in the world. Cape Dutch style, which combines the architectural traditions of the Netherlands, Germany, France and Indonesia, is most visible in Constantia, the old government buildings in the Central Business District, and along Long Street.[75][76] The annual Cape Town Minstrel Carnival, also known by its Afrikaans name of Kaapse Klopse, is a large minstrel festival held annually on 2 January or \\"Tweede Nuwe Jaar\\" (Afrikaans: Second New Year). Competing teams of minstrels parade in brightly coloured costumes, performing Cape Jazz, either carrying colourful umbrellas or playing an array of musical instruments. The Artscape Theatre Centre is the largest performing arts venue in Cape Town.[77]\\r\\nThe city also encloses the 36 hectare Kirstenbosch National Botanical Garden that contains protected natural forest and fynbos along with a variety of animals and birds. There are over 7,000 species in cultivation at Kirstenbosch, including many rare and threatened species of the Cape Floristic Region. In 2004 this Region, including Kirstenbosch, was declared a UNESCO World Heritage Site.[78]\\r\\nCape Town's transport system links it to the rest of South Africa; it serves as the gateway to other destinations within the province. The Cape Winelands and in particular the towns of Stellenbosch, Paarl and Franschhoek are popular day trips from the city for sightseeing and wine tasting.[79][80] Whale watching is popular amongst tourists: southern right whales and humpback whales are seen off the coast during the breeding season (August to November) and Bryde's whales and killer whale can be seen any time of the year.[81] The nearby town of Hermanus is known for its Whale Festival, but whales can also be seen in False Bay.[81] Heaviside's dolphins are endemic to the area and can be seen from the coast north of Cape Town; dusky dolphins live along the same coast and can occasionally be seen from the ferry to Robben Island.[81]\\r\\nThe only complete windmill in South Africa is Mostert's Mill, Mowbray. It was built in 1796 and restored in 1935 and again in 1995.\\r\\nThe most popular areas for visitors to stay include Camps Bay, Sea Point, the V&A Waterfront, the City Bowl, Hout Bay, Constantia, Rondebosch, Newlands, Somerset West, Hermanus and Stellenbosch.[82]\\r\\nIn November 2013, Cape Town was voted the best global city in The Daily Telegraph's annual Travel Awards.[83]\\r\\nThe City of Cape Town works closely with Cape Town Tourism to promote the city both locally and internationally. The primary focus of Cape Town Tourism is to represent Cape Town as a tourist destination.[84][85] Cape Town Tourism receives a portion of its funding from the City of Cape Town while the remainder is made up of membership fees and own-generated funds.[86]\\r\\nCape of Good Hope\\r\\nClifton's 4th Beach\\r\\nPanoramic view across the Victoria Basin at the Victoria & Alfred Waterfront, with Table Mountain in the background\\r\\nThe distinctive Cape Malay Bo-Kaap is one of the most visited areas in Cape Town.\\r\\nKirstenbosch National Botanical Garden\\r\\nMostert's Mill\\r\\nGroote Kerk, Cape Town\\r\\nSeveral newspapers, magazines and printing facilities have their offices in the city. Independent News and Media publishes the major English language papers in the city, the Cape Argus and the Cape Times. Naspers, the largest media conglomerate in South Africa, publishes Die Burger, the major Afrikaans language paper.[87]\\r\\nCape Town has many local community newspapers. Some of the largest community newspapers in English are the Athlone News from Athlone, the Atlantic Sun, the Constantiaberg Bulletin from Constantiaberg, the City Vision from Bellville, the False Bay Echo from False Bay, the Helderberg Sun from Helderberg, the Plainsman from Michells Plain, the Sentinel News from Hout Bay, the Southern Mail from the Southern Peninsula, the Southern Suburbs Tatler from the Southern Suburbs, Table Talk from Table View and Tygertalk from Tygervalley/Durbanville. Afrikaans language community newspapers include the Landbou-Burger and the Tygerburger. Vukani, based in the Cape Flats, is published in Xhosa.[88]\\r\\nCape Town is a centre for major broadcast media with several radio stations that only broadcast within the city. 94.5 Kfm (94.5?MHz FM) and Good Hope FM (94ÿ97 MHz FM) mostly play pop music. Heart FM (104.9?MHz FM), the former P4 Radio, plays jazz and R&B, while Fine Music Radio (101.3 FM) plays classical music and jazz. Bush Radio is a community radio station (89.5?MHz FM). The Voice of the Cape (95.8?MHz FM) and Cape Talk (567 kHz MW) are the major talk radio stations in the city.[89] Bokradio (98.9?MHz FM) is an Afrikaans music station.[90] The University of Cape Town also runs its own radio station, UCT Radio (104.5?MHz FM).\\r\\nThe SABC (South African Broadcasting Corporation) has a small presence in the city, with satellite studios located at Sea Point. e.tv has a greater presence, with a large complex located at Longkloof Studios in Gardens. M-Net is not well represented with infrastructure within the city. Cape Town TV is a local TV station, supported by numerous organisation and focusing mostly on documentaries. Numerous productions companies and their support industries are located in the city, mostly supporting the production of overseas commercials, model shoots, TV-series and movies.[91] The local media infrastructure remains primarily in Johannesburg.\\r\\nCape Town's most popular sports by participation are cricket, association football, swimming, and rugby union.[92] In rugby union, Cape Town is the home of the Western Province side, who play at Newlands Stadium and compete in the Currie Cup. In addition, Western Province players (along with some from Wellington's Boland Cavaliers) comprise the Stormers in the Southern Hemisphere's Super Rugby competition. Cape Town also regularly hosts the national team, the Springboks, and hosted matches during the 1995 Rugby World Cup, including the opening ceremony and game, as well as the semi-final between New Zealand and England that saw Jonah Lomu run in four tries.\\r\\nAssociation football, which is better known as soccer in South Africa, is also popular. Two clubs from Cape Town play in the Premier Soccer League (PSL), South Africa's premier league. These teams are Ajax Cape Town, which formed as a result of the 1999 amalgamation of the Seven Stars and the Cape Town Spurs and resurrected Cape Town City F.C.. Cape Town was also the location of several of the matches of the FIFA 2010 World Cup including a semi-final,[93] held in South Africa. The Mother City built a new 70,000 seat stadium (Cape Town Stadium) in the Green Point area.\\r\\nIn cricket, the Cape Cobras represent Cape Town at the Newlands Cricket Ground. The team is the result of an amalgamation of the Western Province Cricket and Boland Cricket teams. They take part in the Supersport and Standard Bank Cup Series. The Newlands Cricket Ground regularly hosts international matches.\\r\\nCape Town has had Olympic aspirations. For example, in 1996, Cape Town was one of the five candidate cities shortlisted by the IOC to launch official candidatures to host the 2004 Summer Olympics. Although the games ultimately went to Athens, Cape Town came in third place. There has been some speculation that Cape Town was seeking the South African Olympic Committee's nomination to be South Africa's bid city for the 2020 Summer Olympic Games.[94] That however was quashed when the International Olympic Committee awarded the 2020 games to Tokyo.\\r\\nThe city of Cape Town has vast experience in hosting major national and international sports events.\\r\\nThe Cape Town Cycle Tour is the world's largest individually timed cycle race?ÿ and the first event outside Europe to be included in the International Cycling Union's Golden Bike Series. It sees over 35,000 cyclists tackling a 109?km (68?mi) route around Cape Town. The Absa Cape Epic is the largest full-service mountain bike stage race in the world.\\r\\nSome notable events hosted by Cape Town have included the 1995 Rugby World Cup, 2003 ICC Cricket World Cup, and World Championships in various sports such as athletics, fencing, weightlifting, hockey, cycling, canoeing, gymnastics and others.\\r\\nCape Town was also a host city to the 2010 FIFA World Cup from 11 June to 11 July 2010, further enhancing its profile as a major events city. It was also one of the host cities of the 2009 Indian Premier League cricket tournament.\\r\\nPublic primary and secondary schools in Cape Town are run by the Western Cape Education Department. This provincial department is divided into seven districts; four of these are \\"Metropole\\" districts?ÿ Metropole Central, North, South, and East?ÿ which cover various areas of the city.[95] There are also many private schools, both religious and secular, in Cape Town.\\r\\nCape Town has a well-developed higher system of public universities. Cape Town is served by three public universities: the University of Cape Town (UCT), the University of the Western Cape (UWC) and the Cape Peninsula University of Technology (CPUT). Stellenbosch University, while not in the city itself, is 50?kilometres from the City Bowl and has additional campuses, such as the Tygerberg Faculty of Medicine and Health Sciences and the Bellville Business Park closer to the City.\\r\\nBoth the University of Cape Town and Stellenbosch University are leading universities in South Africa. This is due in large part to substantial financial contributions made to these institutions by both the public and private sector. UCT is an English-speaking institution. It has over 21,000 students and has an MBA programme that is ranked 51st by the Financial Times in 2006.[96] It is also the top-ranked university in Africa, being the only African university to make the world's Top 200 university list at number 146.[97] Since the African National Congress has come into governmental power, some restructuring of Western Cape universities has taken place and as such, traditionally non-white universities have seen increased financing, which has benefitted the University of the Western Cape.[98][99]\\r\\nThe public Cape Peninsula University of Technology was formed on 1 January 2005, when two separate institutions ÿ Cape Technikon and Peninsula Technikon ÿ were merged. The new university offers education primarily in English, although one may take courses in any of South Africa's official languages. The institution generally awards the National Diploma.\\r\\nCape Town has also become a popular study abroad destination for many international college students. Many study abroad providers offer semester, summer, short-term, and internship programs in partnership with Cape Town universities as a chance for international students to gain intercultural understanding.\\r\\nCape Town International Airport serves both domestic and international flights. It is the second-largest airport in South Africa and serves as a major gateway for travellers to the Cape region. Cape Town has direct flights to most cities in South Africa as well as a number of international destinations.[100]\\r\\nCape Town International Airport recently opened a brand new central terminal building that was developed to handle an expected increase in air traffic as tourism numbers increased in the lead-up to the 2010 FIFA World Cup.[101] Other renovations include several large new parking garages, a revamped domestic departure terminal, a new Bus Rapid Transit system station and a new double-decker road system. The airport's cargo facilities are also being expanded and several large empty lots are being developed into office space and hotels.\\r\\nThe Cape Town International Airport was among the winners of the World Travel Awards for being Africa's leading airport.[102]\\r\\nCape Town has a long tradition as a port city. The Port of Cape Town, the city's main port, is in Table Bay directly to the north of the central business district. The port is a hub for ships in the southern Atlantic: it is located along one of the busiest shipping corridors in the world. It is also a busy container port, second in South Africa only to Durban. In 2004, it handled 3,161 ships and 9.2?million tonnes of cargo.[103]\\r\\nSimon's Town Harbour on the False Bay coast of the Cape Peninsula is the main operational base of the South African Navy.\\r\\nThe Shosholoza Meyl is the passenger rail operations of Spoornet and operates two long-distance passenger rail services from Cape Town: a daily service to and from Johannesburg via Kimberley and a weekly service to and from Durban via Kimberley, Bloemfontein and Pietermaritzburg. These trains terminate at Cape Town railway station and make a brief stop at Bellville. Cape Town is also one terminus of the luxury tourist-oriented Blue Train as well as the five-star Rovos Rail.\\r\\nMetrorail operates a commuter rail service in Cape Town and the surrounding area. The Metrorail network consists of 96 stations throughout the suburbs and outskirts of Cape Town.\\r\\nCape Town is the origin of three national roads. The N1 and N2 begin in the foreshore area near the city centre.\\r\\nThe N1 runs ENE as a highway through Edgemead, Parow, Bellville, and Brackenfell. It connects Cape Town to Paarl and the major cities in the interior - Bloemfontein, Johannesburg, Pretoria and Zimbabwe. An older at-grade road, the R101, runs parallel to the N1 from Bellville.\\r\\nThe N2 runs ESE as a highway through Rondebosch, Guguletu, Khayelitsha, Macassar to Somerset West. It becomes a multiple-carriageway at-grade road from the intersection with the R44 onwards. The N2 continues east along the coast, linking Cape Town to the coastal cities of Port Elizabeth, East London and Durban. An older at-grade road, the R101, runs parallel to the N1 initially, before veering south at Bellville, to join the N2 at Somerset West via the suburbs of Kuils River and Eerste River.\\r\\nThe N7 originates from the N1 at Wingfield Interchange near Edgemead. It runs north, initially as a highway, but becoming an at-grade road from the intersection with the M5 (Potsdam Rd) onwards. It links Cape Town with the Northern Cape Province and Namibia.\\r\\nThere are also a number of two- and three-digit regional routes linking Cape Town with surrounding areas. The R27 originates from the N1 near the Foreshore and runs north parallel to the N7, but nearer to the coast. It passes through the suburbs of Milnerton, Table View and Bloubergstrand and links the City to the West Coast, ending at the town of Velddrif. The R44 enters the east of the metro from the north, from Stellenbosch. It connects Stellenbosch to Somerset West, then crosses the N2 to Strand and Gordon's Bay. It exits the metro heading south hugging the coast, leading to the towns of Betty's Bay and Kleinmond.\\r\\nOf the three-digit routes, the R300, which is informally known as the Cape Flats Freeway, is a highway linking the N1 at Brackenfell to the N2 near Mitchells Plain and the Cape Town International Airport. The R302 runs from the R102 in Bellville, heading north across the N1 through Durbanville leaving the metro to Malmesbury. The R304 enters the northern limits of the metro from Stellenbosch, running NNW before veering west to cross the N7 at Philadelphia to end at Atlantis at a junction with the\\\\sR307. This R307 starts north of Koeberg from the R27 and, after meeting the R304, continues north to Darling, Western Cape, Darling. The R310 originates from Muizenberg and runs along the coast, to the south of Mitchell's Plain and Khayelitsha, before veering north-east, crossing the N2 west of Macassar, and exiting the metro heading to Stellenbosch.\\r\\nCape Town, like most South African cities, uses Metropolitan or \\"M\\" routes for important intra-city routes, a layer below National (N) roads and Regional (R) routes. Each city's M roads are independently numbered. Most are at-grade roads. However, the M3 splits from the N2 and runs to the south along the eastern slopes of Table Mountain, connecting the City Bowl with Muizenberg. Except for a section between Rondebosch and Newlands that has at-grade intersections, this route is a highway. The M5 splits from the N1 further east than the M3, and links the Cape Flats to the CBD. It is a highway as far as the interchange with the M68 at Ottery, before continuing as an at-grade road.\\r\\nCape Town suffers from the worst traffic congestion in South Africa.[104][105]\\r\\n\\r\\nGolden Arrow Bus Services operates scheduled bus services throughout the Cape Town metropolitan area. Several companies run long-distance bus services from Cape Town to the other cities in South Africa.\\r\\nCape Town has a significantly enhanced public transport system in about 10% of the City, running north to south along the west coastline of the City, comprising Phase 1 of the IRT system. This is known as the MyCiTi service.\\r\\nMyCiTi Phase 1 includes services linking the Airport to the Cape Town inner city, as well as the following areas: Blouberg / Table View, Dunoon, Atlantis and Melkbosstrand, Milnerton, Paarden Eiland, Century City, Salt River and Walmer Estate, and all suburbs of the City Bowl and Atlantic Seaboard all the way to Llandudno and Hout Bay.\\r\\nThe MyCiTi N2 Express service consists of two routes each linking the Cape Town inner city and Khayelitsha and Mitchells Plain on the Cape Flats.\\r\\nThe service use high floor articulated and standard size buses in dedicated busways, low floor articulated and standard size buses on the N2 Express service, and smaller 9-metre (30-foot) Optare buses in suburban and inner city areas. It offers universal access through level boarding and numerous other measures, and requires cashless fare payment using the EMV compliant smart card system, called myconnect. Headway of services (i.e. the time between buses on the same route) range from 3 mins to 20 mins in peak times to 60 minutes during quiet off-peak periods.\\r\\nCape Town has two kinds of taxis: metered taxis and minibus taxis. Unlike many cities, metered taxis are not allowed to drive around the city to solicit fares and instead must be called to a specific location.\\r\\nCape Town metered taxi cabs mostly operate in the city bowl, suburbs and Cape Town International Airport areas. Large companies that operate fleets of cabs can be reached by phone and are cheaper than the single operators that apply for hire from taxi ranks and Victoria and Alfred Waterfront. There are about one thousand meter taxis in Cape Town. Their rates vary from R8 per kilometre to about R15 per kilometre. The larger taxi companies in Cape Town are Excite Taxis, Cabnet and Intercab and single operators are reachable by cellular phone. The seven seated Toyota Avanza are the most popular with larger Taxi companies. Meter cabs are mostly used by tourists and are safer to use than minibus taxis.\\r\\nMinibus taxis are the standard form of transport for the majority of the population who cannot afford private vehicles.[107] Although essential, these taxis are often poorly maintained and are frequently not road-worthy. These taxis make frequent unscheduled stops to pick up passengers, which can cause accidents.[108][109] With the high demand for transport by the working class of South Africa, minibus taxis are often filled over their legal passenger allowance. Minibuses are generally owned and operated in fleets.[110]\\r\\nTable Mountain from the harbour\\r\\nMetrorail train leaving Kalk Bay station\\r\\nN2 highway, entering the City Bowl\\r\\nTaxi rank above Cape Town railway station\\r\\nCape Town has nine twin towns and sister cities:","input":"What is the main language spoken in cape town?"},{"output":"September 22, 2005","context":"\\r\\n\\r\\nThe first season of Criminal Minds premiered on CBS on September 22, 2005 and ended May 10, 2006.\\r\\n\\r\\nIn the pilot episode, \\"Extreme Aggressor\\", Andrew Jackson guest-starred as Timothy Vogel. Chelah Horsdal guest-starred as his victim, Heather Woodland. In the episode \\"Won't Get Fooled Again\\", Tim Kelleher guest-starred as Adrian Bale, a serial bomber responsible for the deaths of six FBI agents. In the episode \\"Plain Sight\\", Kirk B. R. Woller guest-starred as serial rapist Franklin Graney. In the episode \\"Broken Mirror\\", Matt Letscher guest-starred as Vincent Shyer, an erotomaniacal stalker who abducts one of the twin daughters of Executive Assistant District Attorney Evan Davenport, played by Robin Thomas. Elisabeth Harnois guest-starred in a dual role as Davenport's daughters, Patricia and Cheryl.\\r\\n\\r\\nIn the episode \\"L.D.S.K.\\", Marcus Giamatti guest-starred as Barry Landman, a narcissistic trauma surgeon suspected of committing several shootings. Paula Newsome portrays Detective Shea Calvin, who leads the investigation of the shootings. In the episode \\"The Fox\\", Neal Jones guest-starred as one of the series' most notorious criminals, Karl Arnold, aka \\"The Fox\\", a serial killer who murders entire families. Tony Todd guest-starred as Eric Miller, a man who was wrongfully imprisoned for the murder of his family. In the episode \\"Natural Born Killer\\", Patrick Kilpatrick guest-starred as Vincent Perotta, a professional hitman who abducts FBI agent Josh Cramer of the Organized Crime Unit. Francesco Quinn guest-starred as Michael Russo, a mob boss who hires Perotta to abduct Cramer. \\r\\n\\r\\nIn the episode \\"Derailed\\", Chris Bauer guest-starred as Dr. Theodore Bryar, a paranoid schizophrenic who held several passengers hostage, including Elle Greenaway, on a train. Jeff Kober guest-starred as Bryar's imaginary friend, Leo, and M. C. Gainey guest-starred as Detective Frank Moretti, who leads the investigation of the hostage situation. In the episode \\"The Popular Kids\\", Will Rothhaar guest-starred as Cory Bridges, a cult killer who murdered two high school students. In the episode \\"Blood Hungry\\", Kris Lemche guest-starred as cannibalistic spree killer, Eddie Mays, and Lindsay Crouse played his mother, Mary. In the episode \\"What Fresh Hell?\\", Ned Vaughn guest-starred as Donald Curtis, a pedophile who abducts an eleven-year-old girl named Belinda Copeland. \\r\\n\\r\\nIn the episode \\"Poison\\", Nick Jameson guest-starred as Edward Hill, a serial killer who murders people with poisonous drugs. In the episode \\"Riding the Lightning\\", Jeannetta Arnette guest-starred as Sarah Jean Mason, an inmate on death row who is determined to make sure her son never finds out the truth of his parentage. Michael Massee guest-starred as Jacob Dawes, a serial killer who murdered several teenage girls. In the episode \\"Unfinished Business\\", Aaron Lustig guest-starred as Walter Kern, aka \\"The Keystone Killer\\", and Geoff Pierson guest-starred as Max Ryan, a retired FBI Agent who is determined to find the killer. \\r\\n\\r\\nIn the episode \\"The Tribe\\", Chad Allen guest-starred as Jackson Cally, a cult leader who tortures and murders college students. In the episode \\"A Real Rain\\", Ethan Phillips guest-starred as schizophrenic vigilante killer Marvin Doyle. David Aaron Baker played Will Sykes, an attempted copycat of Doyle who wanted to be famous, and Tonya Pinkins played Detective Nora Bennett, who leads the investigation of the killings. In the episode \\"Somebody's Watching\\", Katheryn Winnick guest-starred as Maggie Lowe, a serial killer and stalker who obsesses over actress Lila Archer. Ian Anthony Dale guest-starred as Detective Owen Kim, who leads the investigation of the murders. \\r\\n\\r\\nIn the episode \\"Charm and Harm\\", Andy Comeau guest-starred as Mark Gregory, a serial killer and abductor who murders his victims by drowning them. In the episode, \\"Secrets and Lies\\", Ray Baker guest-starred as rogue CIA Agent Bruno Hawks. In the season finale \\"The Fisher King (Part I)\\", Charles Haid guest-starred as one of the series most notorious criminals, Randall Garner, aka \\"The Fisher King\\", a serial killer and abductor responsible for the attempted murder of Elle Greenaway. The incident proved to be so traumatizing, she resigned from the BAU the following season.","input":"When did criminal minds first air on tv?"},{"output":"edible seaweed species of the red algae genus Pyropia, including P. yezoensis and P. tenera","context":"Nori (J) is the Japanese name for edible seaweed species of the red algae genus Pyropia, including P. yezoensis and P. tenera. It is used chiefly as an ingredient (wrap) of sushi. Finished products are made by a shredding and rack-drying process that resembles papermaking.\\r\\n\\r\\n\\r\\nOriginally, the term nori was generic and referred to seaweeds, including hijiki.[1] One of the oldest descriptions of nori is dated to around the 8th century. In the Taih Code enacted in 701, nori was already included in the form of taxation.[2] Local people have been described as drying nori in Hitachi Province Fudoki (721ÿ721), and nori was harvested in Izumo Province Fudoki (713ÿ733), showing that nori was used as food from ancient times.[3] In Utsubo Monogatari, written around 987, nori was recognized as a common food. Nori had been consumed as paste form until the sheet form was invented in Asakusa, Edo (contemporary Tokyo), around 1750 in the Edo period through the method of Japanese paper-making.[4][5][6][7]\\r\\nThe word \\"nori\\" first appeared in an English-language publication in C.P. Thunberg's Trav., published in 1796.[8] It was used in conjugation as \\"Awa nori\\", probably referring to what is now called aonori.[8]\\r\\nThe Japanese nori industry was in decline after WWII, when Japan was in need of all food that could be produced. The decline was due to a lack of understanding of nori's three-stage life cycle, such that local people did not understand why traditional cultivation methods were not effective. The industry was rescued by knowledge deriving from the work of British phycologist Kathleen Mary Drew-Baker, who had been researching the organism Porphyria umbilicalis, which grew in the seas around Wales and was harvested for food, as in Japan. Her work was discovered by Japanese scientists who applied it to artificial methods of seeding and growing the nori, rescuing the industry. Kathleen Baker was hailed as the \\"Mother of the Sea\\" in Japan and a statue erected in her memory; she is still revered as the savior of the Japanese nori industry.\\r\\nIn the 21st century, the Japanese nori industry faces a new decline due to increased competition from seaweed producers in China and Korea and domestic sales tax hikes.[9]\\r\\nThe word nori started to be used widely in the United States, and the product (imported in dry form from Japan) became widely available at natural food stores and Asian-American grocery stores in the 1960s due to the macrobiotic movement[10] and in the 1970s with the increase of sushi bars and Japanese restaurants.[11]\\r\\nIn one study by Jan-Hendrik Hehemann, subjects of Japanese descent have been shown to be able to digest the polysaccharide of the seaweed, after gut microbes developed the enzyme from marine bacteria. Gut microbes from the North American subjects lacked these enzymes.[12]\\r\\nProduction and processing of nori is an advanced form of agriculture. The biology of Pyropia, although complicated, is well understood, and this knowledge is used to control the production process. Farming takes place in the sea where the Pyropia plants grow attached to nets suspended at the sea surface and where the farmers operate from boats. The plants grow rapidly, requiring about 45 days from \\"seeding\\" until the first harvest. Multiple harvests can be taken from a single seeding, typically at about ten-day intervals. Harvesting is accomplished using mechanical harvesters of a variety of configurations. Processing of raw product is mostly accomplished by highly automated machines that accurately duplicate traditional manual processing steps, but with much improved efficiency and consistency. The final product is a paper-thin, black, dried sheet of approximately 18?cm G?20?cm (7?in G?8?in) and 3 grams (0.11?oz) in weight.\\r\\nSeveral grades of nori are available in the United States. The most common, and least expensive, grades are imported from China, costing about six cents per sheet. At the high end, ranging up to 90 cents per sheet, are \\"delicate shin-nori\\" (nori from the first of the year's several harvests) cultivated in Ariake Sea, off the island of Kyushu in Japan.[13]\\r\\nIn Japan, over 600 square kilometres (230?sq?mi) of coastal waters are given to producing 350,000 tonnes (340,000 long tons) of nori, worth over a billion dollars. China produces about a third of this amount.[14]\\r\\nNori is commonly used as a wrap for sushi and onigiri. It is also a garnish or flavoring in noodle preparations and soups. It is most typically toasted prior to consumption (yaki-nori). A common secondary product is toasted and flavored nori (ajitsuke-nori), in which a flavoring mixture (variable, but typically soy sauce, sugar, sake, mirin, and seasonings) is applied in combination with the toasting process.[15] It is also eaten by making it into a soy sauce-flavored paste, nori no tsukudani (Jq).\\r\\nNori is sometimes used as a form of food decoration.\\r\\nA related product, prepared from the unrelated green algae Monostroma and Enteromorpha, is called aonori (J literally blue/green nori) and is used like herbs on everyday meals, such as okonomiyaki and yakisoba.\\r\\nSince nori sheets easily absorb water from the air and degrade, a desiccant is indispensable when storing it for any significant time.\\r\\nWhile seaweed has by far the highest proportion of iodine by weight of any food,[16] Pyropia yezoensis has less than any other type of seaweed; it is nonetheless an excellent source of iodine.[17]\\r\\nThough nori has long been considered to be an important source of vitamin B12 for vegans,[18][19] its vitamin B12 may actually not be biologically available to humans. It may contain cobalamin analogues which block absorption of B12.[20][21] A study showed that in humans both dried and raw nori reduced the vitamin B12 status.[22][23]","input":"What kind of seaweed is used in sushi?"},{"output":"Jule sugarman","context":"The Early Childhood Education Act is the name of various landmark laws passed by the United States Congress outlining federal programs and funding for childhood education from pre-school through kindergarten. The first such act was introduced in the United States House of Representatives by Congresswoman Patsy Mink of Hawai?i in the 1960s. The theory behind the act is that the years before a child reaches kindergarten are the most critical to influence learning. Many children do not have access to early education before entering kindergarten.[1] The goal of the act is to provide a comprehensive set of services for children from birth until they enter kindergarten.[2]\\r\\n\\r\\n\\r\\nSince the Early Childhood Education Act was initiated in the 60s, various laws have been passed and continue to be passed as part of the Early Childhood Education Act to better prepare young children for school.\\r\\nHead start\\r\\nFounded in 1965 by Jule sugarman, Head start was one of the first programs initiated as a result of the Early Childhood Education Act. Its goal is to enhance the social and cognitive development of children offering services in the area of education, health, social and nutrition.[3]\\r\\nNational Academy of Early Childhood Programs\\r\\nIn 1985 the National Association for the Education of Young Children established the National Academy of Early Childhood Programs for voluntary accreditation according to health, safety and education standards. This program was intended to create a more reliable standard of accreditation for early childhood education programs.[3]\\r\\nEven Start Program\\r\\nIn 1988, The U.S Department of Education established the Even Start Program to improve parent and family literacy at home. This program was designed to improve parents literacy so they can ultimately help their children become literate and reach their full potential as learners. It integrates early childhood education, adult education and family literacy.[3]\\r\\nNo Child Left Behind Act\\r\\nThe No Child Left Behind Act was proposed by George W. Bush and passed by United States House of Representatives in 2001. The Act requires that all public schools receive federal funding to administer a standardized test annually to assess if students have made Adequate Yearly Progress (AYP). Schools must provide services to students who do not meet AYP in order to help them succeed and pass AYP the following year.[3]\\r\\nPreschool for All Initiative\\r\\nIn 2013, President Obama proposed the Preschool for All initiative. The goal of this program is to expand funding in all fifty states to allow low and mid-income families the opportunity to provide their four-year-old children with high quality preschool.[3]\\r\\nLaws under the Early Childhood Education Act offer comprehensive services for children from birth through age five.[2] Programs should meet one the following goals: {Provide access to high-quality infant and toddler care [1]\\r\\n{Expand voluntary home visit early learning program s[1]\\r\\n{Develop partnerships with states to provide high-quality preschool for low and middle-income families [1]\\r\\nEarly Reading First was established as part of the No Child Left Behind Act. It provides competitive grants to fund the development of model programs that aim to prepare children for school.[4] The Special Education Preschool Grants program provides grants to states to fund special educational services to children 3 to 5 with disabilities. The Special Education Grants for Infants and Families grant program assists states in implementing services for children with disabilities from birth to 2 years old.[2] The Early Childhood Educator Professional Development Program is a competitive grant program that gives the opportunity to professionally develop skills to educators and caregivers working in low-income areas.[2]\\r\\nResearch\\r\\nThe Preschool Curriculum Evaluation Research program evaluates the efficiency current preschool curricula in order to address the lack of systematic evaluations currently used. The data collected includes child assessments, parent interviews, teacher interviews and classroom observations.[2]\\r\\nEvaluations\\r\\nThe 'Even Start Classroom Literacy Interventions and Outcomes Study is a controlled study that assesses the contribution of the enhanced parenting component of the program. It focuses on evaluating whether focused literacy instruction combined with parent education will provide better outcomes than current programs.[2]\\r\\nThe Early Reading First National Evaluation assesses the impact of the program on childrens language, literacy outcomes and preschools literacy instruction. The study compares schools programs who received funding from the Early reading grant and those who did not.[2]","input":"Who founded the first early childhood education program?"},{"output":"19.6 meters","context":"A set of equations describe the resultant trajectories when objects move owing to a constant gravitational force under normal Earth-bound conditions. For example, Newton's law of universal gravitation simplifies to F = mg, where m is the mass of the body. This assumption is reasonable for objects falling to earth over the relatively short vertical distances of our everyday experience, but is untrue over larger distances, such as spacecraft trajectories.\\r\\n\\r\\nGalileo was the first to demonstrate and then formulate these equations. He used a ramp to study rolling balls, the ramp slowing the acceleration enough to measure the time taken for the ball to roll a known distance.[1][2] He measured elapsed time with a water clock, using an \\"extremely accurate balance\\" to measure the amount of water.[note 1]\\r\\n\\r\\nThe equations ignore air resistance, which has a dramatic effect on objects falling an appreciable distance in air, causing them to quickly approach a terminal velocity. The effect of air resistance varies enormously depending on the size and geometry of the falling object  for example, the equations are hopelessly wrong for a feather, which has a low mass but offers a large resistance to the air. (In the absence of an atmosphere all objects fall at the same rate, as astronaut David Scott demonstrated by dropping a hammer and a feather on the surface of the Moon.) \\r\\n\\r\\nThe equations also ignore the rotation of the Earth, failing to describe the Coriolis effect for example. Nevertheless, they are usually accurate enough for dense and compact objects falling over heights not exceeding the tallest man-made structures.\\r\\n\\r\\nNear the surface of the Earth, the acceleration due to gravity g?=?9.81?m/s2 (meters per second squared; which might be thought of as \\"meters per second, per second\\", or 32.2?ft/s2 as \\"feet per second per second\\") approximately. For other planets, multiply g by the appropriate scaling factor. A coherent set of units for g, d, t and v is essential. Assuming SI units, g is measured in meters per second squared, so d must be measured in meters, t in seconds and v in meters per second. \\r\\n\\r\\nIn all cases, the body is assumed to start from rest, and air resistance is neglected. Generally, in Earth's atmosphere, all results below will therefore be quite inaccurate after only 5 seconds of fall (at which time an object's velocity will be a little less than the vacuum value of 49?m/s?(9.8?m/s2?G?5?s) due to air resistance).  Air resistance induces a drag force on any body that falls through any atmosphere other than a perfect vacuum, and this drag force increases with velocity until it equals the gravitational force, leaving the object to fall at a constant terminal velocity. \\r\\n\\r\\nAtmospheric drag, the coefficient of drag for the object, the (instantaneous) velocity of the object, and the area presented to the airflow determine terminal velocity.\\r\\n\\r\\nApart from the last formula, these formulas also assume that g negligibly varies with height during the fall (that is, they assume constant acceleration). The last equation is more accurate where significant changes in fractional distance from the center of the planet during the fall cause significant changes in g. This equation occurs in many applications of basic physics.\\r\\n\\r\\nThe first equation shows that, after one second, an object will have fallen a distance of 1/2 G 9.8 G 12 = 4.9 meters. After two seconds it will have fallen 1/2 G 9.8 G 22 = 19.6 meters; and so on. The second to last equation becomes grossly inaccurate at great distances. If an object fell 10,000 meters to Earth, then the results of both equations differ by only 0.08%; however, if it fell from geosynchronous orbit, which is 42,164 km, then the difference changes to almost 64%. \\r\\n\\r\\nBased on wind resistance, for example, the terminal velocity of a skydiver in a belly-to-earth (i.e., face down) free-fall position is about 195 km/h (122 mph or 54 m/s). This velocity is the asymptotic limiting value of the acceleration process, because the effective forces on the body balance each other more and more closely as the terminal velocity is approached. In this example, a speed of 50% of terminal velocity is reached after only about 3 seconds, while it takes 8 seconds to reach 90%, 15 seconds to reach 99% and so on.  \\r\\n\\r\\nHigher speeds can be attained if the skydiver pulls in his or her limbs (see also freeflying). In this case, the terminal velocity increases to about 320 km/h (200 mph or 90 m/s), which is almost the terminal velocity of the peregrine falcon diving down on its prey. The same terminal velocity is reached for a typical .30-06 bullet dropping downwardswhen it is returning to earth having been fired upwards, or dropped from a toweraccording to a 1920 U.S. Army Ordnance study.\\r\\n\\r\\nCompetition speed skydivers fly in the head down position and reach even higher speeds. The current world record is 1,357.6 km/h (843.6 mph/Mach 1.25) by Felix Baumgartner who skydived from 38,969.4 m (127,852.4 ft) above earth on 14 October 2012. The record was set due to the high altitude where the lesser density of the atmosphere decreased drag. \\r\\n\\r\\nFor astronomical bodies other than Earth, and for short distances of fall at other than \\"ground\\" level, g in the above equations may be replaced by G(M+m)/r2 where G is the gravitational constant, M is the mass of the astronomical body, m is the mass of the falling body, and r is the radius from the falling object to the center of the body. \\r\\n\\r\\nRemoving the simplifying assumption of uniform gravitational acceleration provides more accurate results. We find from the formula for radial elliptic trajectories: \\r\\n\\r\\nThe time t taken for an object to fall from a height r to a height x, measured from the centers of the two bodies, is given by: \\r\\n\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n=\\r\\nG\\r\\n(\\r\\n\\r\\nm\\r\\n\\r\\n1\\r\\n\\r\\n\\r\\n+\\r\\n\\r\\nm\\r\\n\\r\\n2\\r\\n\\r\\n\\r\\n)\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\mu =G(m_{1}+m_{2})}\\r\\n\\r\\n is the sum of the standard gravitational parameters of the two bodies. This equation should be used whenever there is a significant difference in the gravitational acceleration during the fall.\\r\\n\\r\\nCentripetal force causes the acceleration measured on the rotating surface of the Earth to differ from the acceleration that is measured for a free-falling body: the apparent acceleration in the rotating frame of reference is the total gravity vector minus a small vector toward the north-south axis of the Earth, corresponding to staying stationary in that frame of reference.","input":"How far do you fall in two seconds?"},{"output":"the early 1930s","context":"A child safety seat (infant safety seat, child restraint system, child seat, baby seat, restraining car seat, car seat, etc.) is a seat designed specifically to protect children from injury or death during collisions. Most commonly these seats are purchased and installed by consumers, but car manufacturers may integrate them directly into their vehicle's design and generally are required to provide anchors and to ensure seat belt compatibility. Many jurisdictions require children defined by age, weight, and/or height to use a government-approved child safety seat when riding in a vehicle. Child safety seats provide passive restraints and must be properly used to be effective. However, research indicates many child safety restraints are often not used properly.[1] To tackle this negative trend, health officials and child safety experts produce child safety videos to teach proper car seat installation to parents and caregivers.\\r\\nBaby car seats are legally required in many countries, including most Western developed countries, to safely transport children up to the age of 2 or more years in cars and other vehicles.\\r\\nOther car seats, also known as \\"booster seats,\\" are required until the child is large enough to use an adult seat belt. This is usually, but not always, when the child is 1.45m (4?ft 9 in) tall. The child needs to meet five criteria before moving out of the booster seat, including the child's seating position, shoulder belt position, lap belt position, knee position, and ability to sit properly for the length of the trip.\\r\\nGenerally, countries that regulate passenger safety have child safety laws that require a child to be restrained appropriately depending on their age and weight. These regulations and standards are often minimums, and with each graduation to the next kind of safety seat, there is a step down in the amount of protection a child has in a collision.[2] Some countries, such as Australia and the United States, forbid rear-facing child seats in a front seat that has an airbag. A rear-facing infant restraint put in the front seat of a vehicle places an infant's head close to the airbag, which can cause severe head injuries or death if the airbag deploys. Some modern cars include a switch to disable the front passenger airbag for child-supporting seat use.\\r\\nIn 2003, the American Academy of Pediatrics (AAP) suggested that infants should spend minimal time in car seats (when not a passenger in a vehicle) or other seating that maintains supine positioning to avoid developing positional plagiocephaly (\\"flat head syndrome\\").[3]\\r\\nIn 1990, the ISO standard ISOFIX[4] was launched in an attempt to provide a standard for fixing car seats into different makes of car. The standard now includes a top tether; the U.S. version of this system is called LATCH. Generally, the ISOFIX system can be used with Groups 0, 0+ and 1.\\r\\nIn 2013, a new car seat regulation was introduced: i-Size is the name of a new European safety regulation that affects car seats for children under 15 months of age. It came into effect in July 2013 and provides extra protection in several ways, most notably by providing rearward facing travel for children up to 15 months instead of 9 to 12 months, which the previous EU regulation advised.\\r\\n\\r\\n\\r\\nSince the first car was manufactured and put on the market in the early 1900s, many modifications and adjustments have been implemented to protect those that drive and ride in motorized vehicles. Most restraints were put into place to protect adults without regard for young children. Though child seats were beginning to be manufactured in the early 1930s, their purpose was not the safety of children. The purpose was to act as booster seats to bring the child to a height easier for the driving parent to see them. It was not until 1962 that two designs with the purpose of protecting a child were developed independently.[5] British inventor Jean Ames created a rear-facing child seat with a Y-shaped strap similar to today's models.[6] American Leonard Rivkin, of Denver Colorado, designed a forward-facing seat with a metal frame to protect the child.[7] It is noted that seat belts for adults were not standard equipment in automobiles until the 1960s.\\r\\nThere are several types of car seats, which vary in the position of the child and size of the seat. The United Nations standard ECE R44/04[8] categorizes these into 4 groups: 0-3. Many car seats combine the larger groups 1, 2 and 3. Some new car models includes stock restraint seats by default.\\r\\nGroup 0 baby seats, or infant carriers, keep the baby locked up in a rear-facing position and are secured in place by a standard adult seat belt and/or an ISOFIX fitting.\\r\\nGroup 0 carrycots hold the baby lying on its back.\\r\\nCarrycots are secured by both seat belts in the rear seat of the car. Both types have handles to allow them to be easily moved into and out of the car.\\r\\nCar Seat - Middle Back Seat\\r\\nCar Seat - Not in Front Seat\\r\\nCarrycots or infant car beds are used for children that cannot sit in a regular baby seat, such as premature infants or infants that suffer from apnea. A carrycot is a restraint system intended to accommodate and restrain the child in a supine or prone position with the child's spine perpendicular to the median longitudinal plane of the vehicle. Carrycots are designed to distribute the restraining forces over the child's head and body, excluding its limbs, in the event of a big crash. It must be put on the rear seat of the car. Some models can be changed to face forward after the baby has reached the weight limit which is normally about 15-20 kilograms.\\r\\nCarrycots generally include a stomach belt and a connection to the (three points) safety belt.\\r\\n'Infant carrier' means a restraint system intended to accommodate the child in a rearward-facing semi-recumbent position. This design distributes the restraining forces over the child's head and body, excluding its limbs, in the event of the frontal collision.\\r\\nFor young infants, the seat used is an infant carrier with typical weight recommendations of 5-20?lb. Most infant seats made in the US can now be used up to at least 22 pounds (10.0?kg) and 29 inches (74?cm), with some going up to 35 pounds (16?kg). In the past, most infant seats in the US went to 20 pounds (9.1?kg) and 26 inches (66?cm). Infant carriers are often also called \\"Bucket Seats\\" as they resemble a bucket with a handle. Some (but not all) seats can be used with the base secured, or with the carrier strapped in alone. Some seats do not have bases. Infant carriers are mounted rear-facing and are designed to \\"cocoon\\" against the back of the vehicle seat in the event of a collision, with the impact being absorbed in the outer shell of the restraint. Rear-facing seats are deemed the safest, and in the US children must remain in this position until they are at least 1 year of age and at least 20 pounds (9.1?kg). although it is recommended to keep them rear-facing until at least 2 years old or until they outgrow the rear-facing car seat height and weight, whichever is longer.\\r\\nGroup 0+ car seats commonly have a chassis permanently fixed into the car by an adult seat belt and can be placed into some form of baby transport using the integral handle if it is the specific model. Rear-facing child seats are inherently safer than forward-facing child seats because they provide more support for the child's head in the event of a sudden deceleration. Although some parents are eager to switch to a forward-facing child seat because it seems more \\"grown up,\\" various countries and car seat manufacturers recommend that children continue to use a rear-facing child seat for as long as physically possible[9]\\r\\nConvertible seats can be used throughout many stages. Many convertible seats will transition from a rear-facing seat, to a forward-facing seat, and some then can be used as a booster seat. Many convertible seats allow for 2.3ÿ18?kg (5-40?lb.) rear-facing, allowing children to be in the safer rear-facing position up to a weight of 18?kg (40?lbs).\\r\\nConvertible safety seats can be installed as either rear-facing or forward-facing. There is a large selection available to choose from and weight limits, height limits, and extra features vary from seat to seat and by manufacturer. Seats with a 5-point harness are considered safer than those with an overhead shield[10]\\r\\nConvertibles aren't considered the best choice for a newborn because the bottom harness slots are often above the shoulders of most newborns. A seat with low bottom harness slots can be used if it is desired to use a convertible from birth.\\r\\nRear-facing weight limits range from 20 to 50?lb (9.1 to 22.7?kg) depending on the manufacturer and country of origin. Forward-facing limits range from 20 to 90?lb (9.1 to 40.8?kg) depending on the seat model and the manufacturer and country of origin.\\r\\nMost convertible seats in the U.S. have at least a 35 pounds (16?kg) rear-facing weight limit, most now to go to 40 pounds (18?kg), some 45 pounds (20?kg) and a few 50 pounds (23?kg). The American Academy of Pediatrics (AAP) recommends that children remain rear-facing until they outgrow their convertible seat, regardless of how old they are. Children can remain in a rear-facing seat until they have either outgrown the weight limit for their seat, or the top of their head is within 1 inch (25?mm) of the top of the shell of the car seat.[11]\\r\\nA permanent fixture in the car using an adult seat belt to hold it in place and a five-point baby harness to hold the infant.\\r\\nIt is recommended that children sit rear-facing for as long as possible. In Scandinavian countries, for example, children sit rear-facing until around 4 years old. Rear-facing car seats are significantly safer in frontal collisions, which are the most likely to cause severe injury and death.[12][13][14][15][16][17][18][19][20][21][22] Rear-facing group 1 car seats are becoming more widespread but are still difficult to source in many countries.\\r\\nA larger seat than the Group 1 design. These seats use an adult seat belt to hold the child in place.\\r\\nAlso known as booster seats, these position the child so that the adult seat belt is held in the correct position for safety and comfort.\\r\\nBooster seats are recommended for children until they are big enough to properly use a seat belt. Seat belts are engineered for adults, and are thus too big for small children. In the United States, for children under the age of 4 and/or under 40 pounds (18?kg), a seat with a 5-point harness is suggested instead of a booster seat.[23]\\r\\nBooster seats lift the child and allow the seat belt to sit firmly across the collar bone and chest, with the lap portion fitted to the hips. If the seat belt is not across the collar bone and the hips, it will ride across the neck and the stomach and cause internal injuries in the event of a collision.\\r\\nThere are two main types of boosters: high back (some of which have energy absorbing foam) and no back. A new generation of booster seats comes with rigid Isofix (Latch) connectors that secure to the vehicle's anchors, improving the seat's stability in the event of a collision.\\r\\nThe consumer group Which? is calling on manufacturers and retailers to phase out backless boosters, as it says they don't provide enough protection in side-impact crashes and could put children at risk.[24] So while backless booster cushions are better than using no child seat at all, they do not provide adequate protection in all circumstances.\\r\\nUsed for Groups I, II and III.\\r\\nAfter reaching one year of age and 20 pounds (9.1?kg), children may travel in forward-facing seats. Most Scandinavian countries require children to sit rear-facing until at least the age of 4 years. This has contributed to Sweden having the lowest rate of children killed in traffic in international comparisons.[25]\\r\\nBy law (in Canada and some US states), children need to be restrained until they are 4-years old and 40 pounds (18?kg). After the requirement is met, they can move into a booster seat.\\r\\nAll child restraints have an expiration date. On average, most seats expire 6 years from the date of manufacture, although this can vary by manufacturer. Expiration dates are highly debated, with proponents and manufacturers claiming that older carseats can degrade over time to be less effective and that changing laws and regulations necessitate an expiration date. In addition, maintenance and parts are often not available for older models. Opponents argue that it is simply for their legal protection and to sell more carseats, and point out that manufacturers have noted that the plastics in most carseats long outlast the expiration date.\\r\\nLike motorcycle and race car helmets, child restraints are tested for use in just one crash event. This means that if the restraint is compromised in any way (with or without the child in it), owners are strongly suggested to replace it. This is due to the uncertainty with how a compromised child restraint will perform in subsequent crashes.[citation needed]\\r\\nThe National Highway Traffic Safety Administration (NHTSA) provides guidance on the reuse of child restraint systems after a crash. Replacement of child restraints is recommended following a moderate or severe crash in order to ensure a continued high level of protection for child passengers. However, recent studies demonstrate that child restraints can withstand minor crash impacts without any documented degradation in subsequent performance.[26]\\r\\nA minor crash is defined by the NHTSA as one in which all of the following apply:\\r\\nCrashes that meet all of these criteria are much less severe than the dynamic testing requirement for compliance with Federal Motor Vehicle Safety Standard (FMVSS) 213 and are highly unlikely to affect future child safety seat performance.[26]\\r\\nChild restraints are sometimes the subject of manufacturing recalls.[27] Recalls vary in severity; sometimes the manufacturer will send an additional part for the seat, other times they will provide an entirely new seat.\\r\\nThe purchase of a used seat is not recommended. Due to the aforementioned concerns regarding expiry dates, crash testing, and recalls, it is often impossible to determine the history of the child restraint when it is purchased second-hand.\\r\\nChildren traveling by plane are safer in a child safety seat than in a parent's arms. The FAA and the AAP recommend that all children under 40?lb use a child safety seat on a plane. Booster seats cannot be used on airplanes because they don't have shoulder belts.\\r\\nParents should not put children into safety seats with thick winter coats on. The coat will flatten in an accident and the straps will not be snug enough to keep the child safe.[28] An alternative would be placing a coat on the child backwards after buckling the child in.\\r\\nStraps on the harness should be snug on the child, parents should not be able to pinch the straps away from the shoulders of the child. The straps also need to be placed at the proper height for the child.\\r\\nA study of car crash data from 16 U.S. states found that children under the age of 3 were 43% less likely to be injured in a car crash if their car seat was fastened in the center of the back seat rather than on one side. Results were based on data from 4,790 car crashes involving children aged 3 and younger between 1998 and 2006. According to data, the center position was the safest but least used position. However, economist Steven Levitt (see below) has demonstrated that car seats do not reduce fatalities when compared to regular seat belts.[29]\\r\\nThe move from having car seats in the front passenger seat to having them in the back seat, facing backwards, may make it easier for a busy, distracted parent to leave an infant in the car.[30] Each year, between 30 and 50 infants die of heat illness and hypothermia in the United States after being left in a car.[30]\\r\\nDirective 2003/20/EC of the European Parliament and the Council[31] has mandated the use of child-restraint systems in vehicles effective May 5, 2006. Children less than 135 centimetres (53?in) tall in vehicles must be restrained by an approved child restraint system suitable for the child's size.[32] In practice, child restraint systems must be able to be fitted to the front, or other rows of seats. Children may not be transported using a rearward-facing child restraint system in a passenger seat protected by a front air bag, unless the air bag has been deactivated.[citation needed]\\r\\nFor a child restraint to be sold or used within any of the 56 UNECE member states it must be approved by the standards of UNECE Regulation 44/04, Directive 77/541/EEC or any other subsequent adaptation thereto. In order to be granted ECE R44 approval the child restraint must comply with several design, construction and production conformity standards.[33] If approval is granted the seat can display an orange label with the unique approval license number, the type of approval, the mass group approved for and the details of the manufacturer.\\r\\nHowever, until May 9, 2008 member states may have permitted the use of child restraint systems approved in accordance with their national standards. EuroNCAP has developed a child-safety-protection rating to encourage improved designs. Points are awarded for universal child-restraint anchorages ISOFIX, the quality of warning labels and deactivation systems for front-passenger airbags.\\r\\n2013: New EU I-Size regulation is introduced: i-Size is the name of a new European safety regulation, UNECE Regulation 129 that affects car seats for children under 15 months of age. It came into effect in July 2013 and provides extra protection in several ways, most notably by providing rearward facing travel for children up to 15 months instead of 9 to 12 months, which the previous EU regulation advised. Read more about I-Size. This new regulation is to be phased in between 2013 and 2018 and will be run in parallel to UNECE R44/04 until 2018 when it completely supersedes it.\\r\\nAustralian laws regarding infants in motor vehicles were revised on November 9, 2009.[citation needed]\\r\\nBy law every child restraint sold in Australia must carry the Australian Standard AS/NZ1754 sticker (pictured right). Most overseas child restraints, including restraints from Europe and the USA, do not comply with these Standards and cannot legally be used in Australia. This also applies for ISOFIX child restraints imported from Europe or the USA.\\r\\nIn Australia there are six different types (Type A to Type F) of child restraints under the mandatory standard. Note: these restraints are NOT based on weight but on HEIGHT. All car seats with the AS/NZ1754 sticker will have height markers. These markers show clearly for what height the seat is appropriate.\\r\\nThe six types are:\\r\\nCombination Type A/B: Child restraints can also be a combination of the above types. For example, a Type A/B converter seat.\\r\\nThe responsibility for children under the age of 16 using restraints or safety belts correctly rests with the driver. In Queensland, penalties for drivers not ensuring that passengers under the age of 16 are properly restrained involve a fine of A$300 and three demerit points. In Victoria the penalty is a fine of A$234 and three demerit points.[citation needed] Possible suspension or cancellation of license may also apply.\\r\\nThe Israeli regulation states that a Sal Kal (he:?? ?? lit. easy basket) is equal to European group 0 and group 0+ regulations[38]\\r\\nAn Urban legend[39] in Israel states that nursery homes and hospitals will not allow exit with an infant if a SalKal (infant carry one safety seat) is not presented.[40]\\r\\nNZ Transport Agency governs the rules and sets standards for the health and safety aspects with respect to child restraints in New Zealand. Their guidelines dictate the minimum legal requirements for a New Zealand vehicle from the safety perspective. The correct fitting of a car seat can protect individuals and can be a life saver. This page provides details on qualified seat installation processes and approved standardized marks to look out for in child restraints. The Agency trains and certifies NZTA certified child restraint technicians who are authorized to install child safety seats.[41]\\r\\nThe NZ Transport Agency, as of March 16, 2012[42] stated that it is mandatory for the passengers to obey few below stated laws while travelling in a vehicle. These rules are regulations are set as per the age of the passengers. As of November 1, 2013, the rules are changing to mandate the use of approved child restraints for children aged 0ÿ6. For children aged 7 a restraint must be used when it is available in the vehicle.[43]\\r\\nSource[44]\\r\\nIn all cases, children not in child safety seats must use a seat belt. Special rules apply to children travelling in vehicles first registered (in New Zealand or elsewhere) before 1 November 1979, since these vehicles are not required to be fitted with seat belts on all seats.\\r\\nAll child restraints must meet the standards set by the NZ Transport Agency. There are different marks to indicate this approval from the safety perspective. Approved marks/symbols are shown in the table below:[45]\\r\\nThe number after 'E' in the ECE 44 standard indicates as to which country certifies the child restraint. Hence the number differs between countries. The EU (European Union) also has similar symbols to indicate safety standards for children travelling in a vehicle.\\r\\nFrom September 18, 2006, All children under the age of 12 have to use some form of child car seat, unless they are taller than 135?cm (4?ft 5in).[46][47]\\r\\nThough there are hundreds of variations of makes and models in the world of child safety seats, the materials used in the manufacturing process are basically the same. Factories in which the seats are put together receive loads of polypropylene pellets.[49] Foam makes up the padding of the individual seats, while vinyl and fabrics are used to make up the covers for the seats as well as the harnesses.\\r\\nA safety seat increases the safety of a properly restrained child in the case of a motor vehicle accident. The safety seat includes foam padding, fabric covers, a harness, and buckles or attaching mechanisms. Labels and instructions are also attached. Every child safety seat will have an expiration date on it. The Safe Kids USA organization does not recommend using a child safety seat that is more than 6 years old[citation needed]. Periodically, child safety seats are recalled by manufacturers for safety reasons. The National Highway Traffic Safety Administration posts a link to recent recall information at nhtsa.gov.\\r\\nThere are different types of child safety seats for children of different sizes and ages.\\r\\nManufacturers have quality controls to ensure seats are properly put together and packaged. However, it is not guaranteed that the included instructions are always adhered to and correctly followed. Up to 95% of the safety seats that are installed may not be the right seat for the child, may be hooked into the vehicle loosely, may be hooked with an incompatible belt in the vehicle, may have harnesses incorrectly fastened in some way, or may be incorrectly placed in front of air bags. In 1997, six out of ten children who were killed in vehicle crashes were not correctly restrained.[49]\\r\\nAlong with the problem of instructions not being followed properly, there are other hazards that can affect children involving these safety seats. A recent study[clarification needed] attributed many cases of sudden infant death syndrome (SIDS) to the prolonged sitting or lying position these infants are in when putting the safety seats to use. When researchers reviewed more than 500 infant deaths, it was found that 17 of these deaths occurred while the infant was in a device such as a child safety seat. The age of the most occurring rates of death by SIDS in a child safety device was found to be under one month, having six of the 17 deaths happen in this age group. Although SIDS has been found to be a high risk regarding child safety seats, a coroner in Quebec also stated that putting infants in car seatscauses breathing problems and should be discouraged.\\"[52] His warning came after the death of a two-month-old boy who was left to nap in a child safety seat positioned inside his crib rather than the crib itself. The death was linked to positional asphyxiation.[52] This means that the child was in a position causing him to slowly lose his supply of oxygen. Coroner Jacques Robinson said it's common for a baby's head to slump forward while in a car seat that is not properly installed in a car and that can diminish a baby's ability to take in oxygen. \\"The car seat is for the car,\\" he said. \\"It's not for a bed or sleeping.\\" Robinson added, however, he has nothing against car seats when they are properly used. The coroner said that it is common for a babys head to slump forward while in a car seat and that it diminishes oxygen.[52]\\r\\nThe American Academy of Pediatrics says to make sure the seat is at the correct angle so your infants head does not flop forward. Many seats have angle indicators or adjusters that can help prevent this. If your seat does not have an angle adjuster, tilt the car safety seat back by putting a rolled towel or other firm padding (such as a pool noodle) under the base near the point where the back and bottom of the vehicle seat meet. Safety seats come with an instruction booklet with additional information on the appropriate angle for the seat.\\r\\nThere has been some criticism of forward-facing child safety seats, in particular by the economist Steven D. Levitt, author of the popular book Freakonomics. In a 2005 article in the New York Times, Levitt suggests that the available data does not support the necessity of forward-facing child safety seats for children over two years old, arguing that the cheaper and simpler alternative of seat belts offers similar protection as forward-facing seats.[53] Levitt was a guest at the TED conference in the same year, and gave a lecture making the same case.[29] Levitt's study and findings have been criticized and refuted by subsequent peer reviewed studies, which found child safety seats offer a considerable safety advantage over seat belts alone.[54]","input":"When was the first child car seat made?"},{"output":"April 18, 1994","context":"","input":"When was beauty and the beast musical written?"},{"output":"Marthasville","context":"The history of Atlanta dates back to 1836, when Georgia decided to build a railroad to the U.S. Midwest and a location was chosen to be the line's terminus. The stake marking the founding of \\"Terminus\\" was driven into the ground in 1837 (called the Zero Mile Post). In 1839, homes and a store were built there and the settlement grew. Between 1845 and 1854, rail lines arrived from four different directions, and the rapidly growing town quickly became the rail hub for the entire Southern United States. During the American Civil War, Atlanta, as a distribution hub, became the target of a major Union campaign, and in 1864 Union William Sherman's troops set on fire and destroyed the city's assets and buildings, save churches and hospitals. After the war the population grew rapidly, as did manufacturing, while the city retained its role as a rail hub. Coca-Cola was launched here in 1886 and grew into an Atlanta-based world empire. Electric streetcars arrived in 1889,[1] and the city added new \\"streetcar suburbs\\".\\r\\nThe city's elite black colleges were founded between 1865 and 1885, and despite disenfranchisement and the later imposition of Jim Crow laws in the 1910s, a prosperous black middle class and upper class emerged. By the early 20th century, \\"Sweet\\" Auburn Avenue was called \\"the most prosperous Negro street in the nation\\". In the 1950s blacks started moving into city neighborhoods that had previously kept them out, while Atlanta's first freeways enabled large numbers of whites to move to, and commute from, new suburbs. Atlanta was home to Dr. Martin Luther King, Jr., and a major center for the Civil Rights Movement. Resulting desegregation occurred in stages over the 1960s. Slums were razed and the new Atlanta Housing Authority built public housing projects.\\r\\nFrom the mid-60s to mid-70s, nine suburban malls opened, and the downtown shopping district declined. But just north of it, gleaming office towers and hotels rose, and in 1976 the new Georgia World Congress Center signaled Atlanta's rise as a major convention city. In 1973 the city elected its first black mayor, Maynard Jackson, and in ensuing decades, black political leaders worked successfully with the white business community to promote business growth, while still empowering black businesses. From the mid-70s to mid-80s most of the MARTA rapid transit system was built. While the suburbs grew rapidly, much of the city itself deteriorated and the city lost 21% of its population between 1970 and 1990.\\r\\nIn 1996 Atlanta hosted the Summer Olympics, for which new facilities and infrastructure were built. Hometown airline Delta continued to grow, and by 1998-9, Atlanta's airport was the busiest in the world. Since the mid-90s, gentrification has given new life to many of the city's intown neighborhoods. The 2010 census showed blacks leaving the city, whites moving to the city, and a much more diverse metro area with heaviest growth in the exurbs at its outer edges.\\r\\nThe region where Atlanta and its suburbs were built was originally Creek and Cherokee Native American territory. In 1813, the Creeks, who had been recruited by the British to assist them in the War of 1812, attacked and burned Fort Mims in southwestern Alabama. The conflict broadened and became known as the Creek War. In response, the United States built a string of forts along the Ocmulgee and Chattahoochee Rivers, including Fort Daniel on top of Hog Mountain near present-day Dacula, Georgia, and Fort Gilmer. Fort Gilmer was situated next to an important Indian site called Standing Peachtree, named after a large tree which is believed to have been a pine tree (the name referred to the pitch or sap that flowed from it). The word \\"pitch\\" was misunderstood for \\"peach,\\" thus the site's name. The site traditionally marked a Native American meeting place at the boundary between Creek and Cherokee lands, at the point where Peachtree Creek flows into the Chattahoochee. The fort was soon renamed Fort Peachtree. A road was built linking Fort Peachtree and Fort Daniel following the route of existing trails.[2]\\r\\nAs part of the systematic removal of Native Americans from northern Georgia from 1802 to 1825,[3] the Creek ceded the area that is now Metro Atlanta in 1821. Four months later, the Georgia Land Lottery Act created five new counties in the area that would later become Atlanta.[4] Dekalb County was created in 1822, from portions of Henry, Fayette, and Gwinnett Counties, and Decatur was created as its county seat the following year.[5] As part of the land lottery, Archibald Holland received a grant of 202.5 acres where downtown Atlanta would later be built.[6][7] Holland farmed the land and operated a blacksmith shop. However, the land was low-lying and wet, so his cows often became mired in the mud. He left the area in 1833 to farm in Paulding County.[8]\\r\\nIn 1830 an inn was established which would be known as Whitehall due to the then-unusual fact that it had a coat of white paint when most other buildings were of washed or natural wood. Later, Whitehall Street would be built as the road from Atlanta to Whitehall. The Whitehall area would be renamed West End in 1867 and is the oldest intact Victorian neighborhood of Atlanta.\\r\\nIn 1835, some leaders of the Cherokee Nation ceded their territory to the United States without the consent of the majority of the Cherokee people in exchange for land out west under the Treaty of New Echota, an act that led to the Trail of Tears.\\r\\nIn 1836, the Georgia General Assembly voted to build the Western and Atlantic Railroad to provide a link between the port of Savannah and the Midwest.[9] The initial route of that state-sponsored project was to run from Chattanooga, Tennessee, to a spot east of the Chattahoochee River, in present-day Fulton County. The plan was to eventually link up with the Georgia Railroad from Augusta, and with the Macon and Western Railroad, which ran between Macon and Savannah. A U.S. Army engineer, Colonel Stephen Harriman Long, was asked to recommend the location where the Western and Atlantic line would terminate. He surveyed various possible routes, then in the autumn of 1837 drove a stake into the ground between what are now Forsyth Street and Andrew Young International Boulevard, about 3-4 blocks northwest of today's Five Points.[10][11] The zero milepost was later placed to mark that spot.[12][13]\\r\\nIn 1839, John Thrasher built homes and a general store in this vicinity, and the settlement was nicknamed Thrasherville. A marker identifies the location of Thrasherville at 104 Marietta Street, N.W., in front of the State Bar of Georgia Building, between Spring and Cone Streets.[14] (3345.409N 8423.542W? / ?33.756817N 84.392367W? / 33.756817; -84.392367? (Thrasherville marker))[15] It was at this point that Thrasher built the Monroe Embankment, an earthen embankment that was to carry the Monroe Railway to meet the W&A at the terminus. This is the oldest existing man-made structure in Downtown Atlanta.[10]\\r\\nIn 1842, the planned terminus location was moved, four blocks southeast (2-3 blocks southeast of Five Points), to what would become State Square, on Wall Street between Central Avenue and Pryor Street. (3345.141N 8423.317W? / ?33.752350N 84.388617W? / 33.752350; -84.388617? (Zero milepost marker)). It is at this location that the zero milepost can now be found, adjacent to the southern entrance of Underground Atlanta.[13] As the settlement grew, it became known as \\"Terminus,\\" literally meaning \\"end of the line\\". By 1842, the settlement at Terminus had six buildings and 30 residents.\\r\\nMeanwhile, settlement began at what would become the Buckhead section of Atlanta, several miles north of today's downtown. In 1838, Henry Irby started a tavern and grocery at what would become the intersection of Paces Ferry and Roswell Roads.\\r\\nIn 1842, when a two-story brick depot was built, the locals asked that the settlement of Terminus be called Lumpkin, after Governor Wilson Lumpkin. Gov. Lumpkin asked them to name it after his young daughter instead, and Terminus became Marthasville. In 1845, the chief engineer of the Georgia Railroad, (J. Edgar Thomson) suggested that Marthasville be renamed \\"Atlantica-Pacifica\\", which was quickly shortened to \\"Atlanta.\\" The residents approved, apparently undaunted by the fact that not a single train had yet visited. The town of Atlanta was incorporated in 1847.\\r\\nThe first Georgia Railroad freight and passenger trains from Augusta (to the east of Atlanta), arrived in September 1845 and in that year the first hotel, the Atlanta Hotel, was opened.\\r\\nIn 1846, a second railroad company, the Macon & Western (orig. \\"Monroe Railroad\\"), completed tracks to Terminus/Atlanta, connecting the little settlement with Macon to the south and Savannah to the southeast. The town then began to boom. In late 1846, the Washington Hall hotel was opened. By 1847, the population had reached 2,500. In 1848, the town elected its first mayor and appointed its first town marshal, German M. Lester,[16] coinciding with the first homicide and the first jail built. A new city council approved the building of wooden sidewalks and banned conducting business on Sundays. In 1849, Atlanta's third and largest antebellum hotel was built, the Trout House, and the Daily Intelligencer became the town's first successful daily newspaper. In 1850 Oakland Cemetery was founded southeast of town, where it remains today within the city limits.\\r\\nIn 1851 a third rail line, the Western and Atlantic Railroad - for which the site of Atlanta had been identified as a terminus - finally arrived, connecting Atlanta to Chattanooga in the northwest and opening up Georgia to trade with the Tennessee and Ohio River Valleys, and the American Midwest. The union depot was completed in 1853 on State Square. That year, the depot's architect Edward A. Vincent also delivered Atlanta's first official map to the city council.\\r\\nFulton County was established in 1853 from the western section of DeKalb, and in 1854 a combination Fulton County Court House and Atlanta City Hall was builtÿ which would be razed thirty years later to make way for today's State Capitol building. (After the Civil War, the Georgia General Assembly decided to move the state capital from Milledgeville to Atlanta.)[10]:370\\r\\nIn 1854, a fourth rail line, the Atlanta and LaGrange Rail Road (later Atlanta & West Point Railroad) arrived, connecting Atlanta with LaGrange, Georgia to the southwest, sealing Atlanta's role as a rail hub for the entire South, with lines to the northwest, east, southeast, and southwest.\\r\\nBy 1855, the town had grown to 6,025 residents[17]:86 and had a bank, a daily newspaper, a factory to build freight cars, a new brick depot, property taxes, a gasworks, gas street lights, a theater, a medical college, and juvenile delinquency.\\r\\nThe first true manufacturing establishment was opened in 1844, when Jonathan Norcross, who would later become mayor of Atlanta, arrived in Marthasville and built a sawmill. Richard Peters, Lemuel Grant, John Mims built a three-story flour mill, which was used as a pistol factory during the Civil War. In 1848, Austin Leyden started the town's first foundry and machine shop, which would later become the Atlanta Machine Works.[18]\\r\\nThe Atlanta Rolling Mill (later the \\"Confederate\\" Rolling Mill) was built in 1858 near Oakland Cemetery. It soon became the South's second most productive rolling mill. During the American Civil War it rolled out cannon, iron rail, and 2-inch-thick (51?mm) sheets of iron to clad the CSS Virginia for the Confederate navy. The mill was destroyed by the Union Army in 1864.[10]:427\\r\\nThe city became a busy center for cotton distribution. As an example, in 1859 the Georgia Railroad alone sent 3,000 empty rail cars to the city to be loaded with cotton.[19]:18\\r\\nBy 1860 the city had four large machine shops, two planing mills, three tanneries, two shoe factories, a soap factory, and clothing factories employing 75 people.[18]\\r\\nIn 1850, out of 2,572 people, 493 were enslaved African Americans, and 18 were free blacks, for a total black population of 20%.[20] The black proportion of Atlanta's population would become much higher after the Civil War, when freed slaves would come to Atlanta in search of opportunity.\\r\\nThere were several slave auction houses in the town, which advertised in the newspapers and many of which also traded in manufactured goods.\\r\\nDuring the American Civil War, Atlanta served as an important railroad and military supply hub. (See also: Atlanta in the Civil War.) In 1864, the city became the target of a major Union invasion (the setting for the 1939 film Gone with the Wind). The area now covered by Atlanta was the scene of several battles, including the Battle of Peachtree Creek, the Battle of Atlanta, and the Battle of Ezra Church. General Sherman cut the last supply line to Atlanta at the Battle of Jonesboro fought on August 31-September 1.[21] With all of his supply lines cut, Confederate General John Bell Hood was forced to abandon Atlanta. On the night of September 1, his troops marched out of the city to Lovejoy, Georgia. General Hood ordered that the 81 rail cars filled with ammunition and other military supplies be destroyed. The resulting fire and explosions were heard for miles.[22] The next day, Mayor James Calhoun surrendered the city,[23] and on September 7 Sherman ordered the civilian population to evacuate.[24][25] He then ordered Atlanta burned to the ground on November 11 in preparation for his punitive march south.\\r\\nAfter a plea by Father Thomas O'Reilly of Immaculate Conception Catholic Church, Sherman did not burn the city's churches or hospitals. The remaining war resources were then destroyed in the aftermath, and in Sherman's March to the Sea. The fall of Atlanta was a critical point in the Civil War. Its much publicized fall gave confidence to the Northerners. Together with the Battle of Mobile Bay, the fall of Atlanta led to the re-election of Abraham Lincoln and the eventual surrender of the Confederacy.\\r\\nThe city emerged from the ashes ÿ hence the city's symbol, the phoenix ÿ and was gradually rebuilt, as its population increased rapidly after the war. Atlanta received migrants from surrounding counties and states: from 1860 to 1870 Fulton County more than doubled in population, from 14,427 to 33,446. In a pattern seen across the South after the Civil War, many freedmen moved from plantations to towns or cities for work, including Atlanta; Fulton County went from 20.5% black in 1860 to 45.7% black in 1870.[26][27]\\r\\nFood supplies were erratic due to poor harvests, which were a result of the turmoil in the agricultural labor supply after emancipation of the slaves. Many refugees were destitute without even proper clothing or shoes; the AMA helped fill the gap with food, shelter, and clothing, and the federally-sponsored Freedmen's Bureau also offered much help, though erratically.[28]\\r\\nThe destruction of the housing stock by the Union army, together with the massive influx of refugees, resulted in a severe housing shortage. 1?8-acre (510?m2) to 1?4-acre (1,000?m2) lots with a small house rented for $5 per month, while those with a glass pane rented for $20. High rents rather than laws led to de facto segregation, with most blacks settling in three shantytown areas at the city's edge. There, housing was substandard; an AMA missionary remarked that many houses were \\"rickety shacks\\" rented at inflated rates. Two of the three shantytowns sat in low-lying areas, prone to flooding and sewage overflows, which resulted in outbreaks of disease in the late 19th century.[28] A shantytown named Tight Squeeze developed at Peachtree at what is now 10th Street in Midtown Atlanta. It was infamous for vagrancy, desperation, robberies of merchants transiting the settlement.[29][30]\\r\\nA smallpox epidemic hit Atlanta in December 1865 and there were not enough doctors or hospital facilities. Another epidemic hit in Fall, 1866; hundreds died.[28]\\r\\nConstruction created many new jobs, employment boomed. Atlanta soon became the industrial and commercial center of the South. From 1867 until 1888, U.S. Army soldiers occupied McPherson Barracks (later renamed Fort McPherson) in southwest Atlanta to ensure Reconstruction era reforms. In 1868, Atlanta became the Georgia state capital, taking over from Milledgeville.\\r\\nAtlanta quickly became a center of black education. Atlanta University was established in 1865, the forerunner of Morehouse College in 1867, Clark University in 1869, what is now Spelman College in 1881, and Morris Brown College in 1885. This would be one of several factors aiding the establishment of one of the nation's oldest and best-established African American elite in Atlanta.\\r\\nHenry W. Grady, the editor of the Atlanta Constitution, promoted the city to investors as a city of the \\"New South,\\" by which he meant a diversification of the economy away from agriculture, and a shift from the \\"Old South\\" attitudes of slavery and rebellion. As part of the effort to modernize the South, Grady and many others also supported the creation of the Georgia School of Technology (now the Georgia Institute of Technology), which was founded on the city's northern outskirts in 1885. With Grady's support, the Confederate Soldiers' Home was built in 1889.\\r\\nIn 1880, Sister Cecilia Carroll, RSM, and three companions traveled from Savannah, Georgia to Atlanta to minister to the sick. With just 50 cents in their collective purse, the sisters opened the Atlanta Hospital, the first medical facility in the city after the Civil War. This later became known as Saint Joseph's Hospital.\\r\\nStarting in 1871 horse-drawn, and later, starting in 1888, electric streetcars fueled real estate development and the city's expansion. Washington Street south of downtown, and Peachtree Street north of the central business district, became wealthy residential areas.\\r\\nIn the 1890s, West End became the suburb of choice for the city's elite, but Inman Park, planned as a harmonious whole, soon overtook it in prestige. Peachtree Street's mansions reached ever further north into what is now Midtown Atlanta, including Amos G. Rhodes' (founder of the Rhodes Furniture Company in 1875) mansion, Rhodes Hall, which can still be visited.\\r\\nAtlanta surpassed Savannah as Georgia's largest city by 1880.\\r\\nAs Atlanta grew, ethnic and racial tensions mounted. Late 19th and early 20th-century immigration added a very small number of new Europeans to the mix. After Reconstruction, whites had used a variety of tactics, including militias and legislation, to re-establish political and social supremacy throughout the South. Starting with a poll tax in 1877, by the turn of the century, Georgia passed a variety of legislation that completed the disfranchisement of blacks. Not even college-educated men could vote. Nonetheless, African Americans in Atlanta had been developing their own businesses, institutions, churches, and a strong, educated middle class.\\r\\nThe identities of Atlanta and Coca-Cola have been intertwined since 1886, when John Pemberton developed the soft drink in response to Atlanta and Fulton County going \\"dry\\". The first sales were at Jacob's Pharmacy in Atlanta. Asa Griggs Candler acquired a stake in Pemberton's company in 1887 and incorporated it as the Coca Cola Company in 1888.[31] In 1892 Candler incorporated a second company, The Coca-Cola Company, the current corporation. By the time of its 50th anniversary, the drink had reached the status of a national icon in the USA. Coca-Cola's world headquarters have remained in Atlanta ever since. In 1991 the company opened the World of Coca-Cola, which has remained one of the city's top visitor attractions.\\r\\nIn 1895 the Cotton States and International Exposition was held at what is now Piedmont Park. Nearly 800,000 visitors attended the event. The exposition was designed to promote the region to the world and showcase products and new technologies as well as to encourage trade with Latin America. The exposition featured exhibits from several states including various innovations in agriculture and technology. President Grover Cleveland presided over the opening of the exposition. But the event is best remembered for the both hailed and criticized \\"Atlanta Compromise\\" speech given by Booker T. Washington in which Southern blacks would work meekly and submit to white political rule, while Southern whites guaranteed that blacks would receive basic education and due process in law.\\r\\nCompetition between working-class whites and black for jobs and housing gave rise to fears and tensions. In 1906, print media fueled these tensions with hearsay about alleged sexual assaults on white women by black men, triggering the Atlanta Race Riot, which left at least 27 people dead[32] (25 of them black) and over 70 injured.[33]\\r\\nBlack businesses started to move from previously integrated business district downtown to the relative safety of the area around the Atlanta University Center west of downtown, and to Auburn Avenue in the Fourth Ward east of downtown. \\"Sweet\\" Auburn Avenue became home to Alonzo Herndon's Atlanta Mutual, the city's first black-owned life insurance company, and to a celebrated concentration of black businesses, newspapers, churches, and nightclubs. In 1956, Fortune magazine called Sweet Auburn \\"the richest Negro street in the world\\", a phrase originally coined by civil rights leader John Wesley Dobbs.[34] Sweet Auburn and Atlanta's elite black colleges formed the nexus of a prosperous black middle class and upper class which arose despite enormous social and legal obstacles.\\r\\nJim Crow laws were passed in swift succession in the years after the riot. The result was in some cases segregated facilities, with nearly always inferior conditions for black customers, but in many cases it resulted in no facilities at all available to blacks, e.g. all parks were designated whites-only (although a private park, Joyland, did open in 1921). In 1910, the city council passed an ordinance requiring that restaurants be designated for one race only, hobbling black restaurant owners who had been attracting both black and white customers. In the same year, Atlanta's streetcars were segregated, with black patrons required to sit in the rear. If not enough seats were available for all white riders, the blacks sitting furthest forward in the trolley were required to stand and give their seats to whites. In 1913, the city created official boundaries for white and black residential areas. And in 1920, the city prohibited black-owned salons from serving white women and children.[35]\\r\\nBeyond this, blacks were subject to the South's racial protocol, whereby, according to the New Georgia Encyclopedia:[36]\\r\\n\\"all blacks were required to pay obeisance to all whites, even those whites of low social standing. And although they were required to address whites by the title \\"sir,\\" blacks rarely received the same courtesy themselves. Because even minor breaches of racial etiquette often resulted in violent reprisals, the region's codes of deference transformed daily life into a theater of ritual, where every encounter, exchange, and gesture reinforced black inferiority.\\"\\r\\nIn 1913, Leo Frank, a Jewish supervisor at a factory in Atlanta, was put on trial for raping and murdering a thirteen-year-old white employee from Marietta, a suburb of Atlanta. After doubts about Frank's guilt led his death sentence to be commuted in 1915, riots broke out in Atlanta among whites. They kidnapped Frank from the State Prison Farm in the city of Milledgeville, with the collusion of prison guards, and took him to Marietta, where he was lynched. Later that year the Klan was reborn in Atlanta.[citation needed]\\r\\nMany Appalachian people came to Atlanta to work in the cotton mills and brought their music with them. Starting with a 1913 fiddler's convention, Atlanta was to become the center of a thriving country music scene. Atlanta would become an important center for country music recording and talent recruiting in the 1920s and 1930s, and live music center for an additional two decades after that.\\r\\nIn 1914, Asa Griggs Candler, the founder of The Coca-Cola Company and brother to former Emory President Warren Candler, persuaded the Methodist Episcopal Church South to build the new campus of Emory University in the emerging affluent suburb of Druid Hills, which borders northeastern Atlanta.\\r\\nOn May 21, 1917, the Great Atlanta Fire destroyed 1,938 buildings, mostly wooden, in what is now the Old Fourth Ward. The fire resulted in 10,000 people becoming homeless. Only one person died, a woman who died of a heart attack when seeing her home in ashes.\\r\\nIn the 1930s, the Great Depression hit Atlanta. With the city government nearing bankruptcy, the Coca-Cola Company had to help bail out the city's deficit. The federal government stepped in to help Atlantans by establishing Techwood Homes, the nation's first federal housing project in 1935.\\r\\nOn December 15, 1939 Atlanta hosted the premiere of Gone with the Wind, the movie based on Atlanta resident Margaret Mitchell's best-selling novel. Stars Clark Gable, Vivien Leigh, and Olivia de Havilland were in attendance. The premiere was held at Loew's Grand Theatre, at Peachtree and Forsyth Streets, current site of the Georgia-Pacific building. An enormous crowd, numbering 300,000 people according to the Atlanta Constitution, filled the streets on this ice-cold night in Atlanta. A rousing ovation greeted a group of Confederate veterans who were guests of honor.\\r\\nNoticeably absent was Hattie McDaniel, who would win the Academy Award for Best Supporting Actress for her role as Mammy, as well as Butterfly McQueen (Prissy). The black actors were barred from attending the premiere, from appearing in the souvenir program, and from all the film's advertising in the South. Director David Selznick had attempted to bring McDaniel to the premiere, but MGM advised him not to. Clark Gable angrily threatened to boycott the premiere, but McDaniel convinced him to attend anyway.[37] McDaniel did attend the Hollywood debut thirteen days later, and was featured prominently in the program.[38]\\r\\nMartin Luther King, Jr. sang at the gala as part of a children's choir of his father's church, Ebenezer Baptist.[39] The boys dressed as pickaninnies and the girls wore \\"Aunt Jemima\\"-style bandanas, dress seen by many blacks as humiliating.[40][41] John Wesley Dobbs tried to dissuade Rev. King, Sr. from participating at the whites-only event, and Rev. King, Sr. was harshly criticized in the black community.\\r\\nIn 1941, Delta Air Lines moved its headquarters to Atlanta. Delta would become the world's largest airline in 2008 after acquiring Northwest Airlines.\\r\\nWith the entry of the United States into World War II, soldiers from around the Southeastern United States went through Atlanta to train and later be discharged at Fort McPherson. War-related manufacturing such as the Bell Aircraft factory in the suburb of Marietta helped boost the city's population and economy. Shortly after the war in 1946, the Communicable Disease Center, later called the Centers for Disease Control and Prevention (CDC) was founded in Atlanta from the old Malaria Control in War Areas offices and staff.\\r\\nIn 1951, the city received the All-America City Award, due to its rapid growth and high standard of living in the southern U.S.\\r\\nAnnexation was the central strategy for growth. In 1952, Atlanta annexed Buckhead, as well as vast areas of what are now northwest, southwest and south Atlanta, adding 82 square miles (210?km2) And tripling its area. By doing so, 100,000 new affluent white residents were added, preserving white political power as well as expanding the city's property tax base And enlarging the traditional leadership upper-middle-class white class. That class now had to room to expand inside the city limits.\\r\\nFederal court decisions in 1962-63 ended the county-unit system thus greatly reducing rural Georgia control over the state legislature, enabling Atlanta, and other cities, to gain proportional political power. The Federal courts opened the Democratic Party primary to black voters, who surged in numbers and became increasingly well organized through the Atlanta Negro Voters League.[42]\\r\\nIn the late 1950s, after forced-housing patterns were outlawed, violence, intimidation and organized political pressure was used in some white neighborhoods to discourage blacks from buying homes there. However, by the late 1950s, such efforts proved futile as blockbusting drove whites to sell their homes in neighborhoods such as Adamsville, Center Hill, Grove Park in northwest Atlanta, and white sections of Edgewood and Kirkwood on the east side. In 1961, the city attempted to thwart blockbusting by erecting road barriers in Cascade Heights, countering the efforts of civic and business leaders to foster Atlanta as the \\"city too busy to hate.\\"[43][44] But efforts to stop transition in Cascade failed too. Neighborhoods of new black homeowners took root, helping alleviate the enormous strain of the lack of housing available to African Americans. Atlanta's western and southern neighborhoods transitioned to majority black  between 1960 and 1970 the number of census tracts that were at least 90% black, tripled. East Lake, Kirkwood, Watts Road, Reynoldstown, Almond Park, Mozley Park, Center Hill and Cascade Heights underwent an almost total transition from white to black. The black proportion of the city's population rose from 38 to 51%. Meanwhile, during the same decade, the city lost 60,000 white residents, a 20% decline.[45]\\r\\nWhite flight and the building of malls in the suburbs triggered a slow decline of the central business district. Meanwhile, conservatism grew rapidly in the suburbs, and white Georgians were increasingly willing to vote for Republicans, most notably Newt Gingrich.[46]\\r\\nIn the wake of the landmark U.S. Supreme Court decision Brown v. Board of Education, which helped usher in the Civil Rights Movement, racial tensions in Atlanta erupted in acts of violence. For example, on October 12, 1958, a Reform Jewish temple on Peachtree Street was bombed. The \\"Confederate Underground\\" claimed responsibility. Many believed that Jews, especially those from the northeast, were advocates of the Civil Rights Movement.\\r\\nIn the 1960s, Atlanta was a major organizing center of the Civil Rights Movement, with Dr. Martin Luther King and students from Atlanta's historically black colleges and universities playing major roles in the movement's leadership. On October 19, 1960, a sit-in at the lunch counters of several Atlanta department stores led to the arrest of Dr. King and several students. This drew attention from the national media and from presidential candidate John F. Kennedy.\\r\\nDespite this incident, Atlanta's political and business leaders fostered Atlanta's image as \\"the city too busy to hate.\\" While the city mostly avoided confrontation, minor race riots did occur in 1965 and in 1968.\\r\\nDesegregation of the public sphere came in stages, with buses and trolleybuses desegregated in 1959,[47] restaurants at Rich's department store in 1961,[48] (though Lester Maddox's Pickrick restaurant famously remained segregated through 1964),[49] and movie theaters in 1962-3.[50][51] While in 1961, Mayor Ivan Allen Jr. became one of the few Southern white mayors to support desegregation of his city's public schools, initial compliance was token, and in reality desegregation occurred in stages from 1961 to 1973.[52]\\r\\nIn 1962, Atlanta in general and its arts community in particular were shaken by the deaths of 106 people on Air France charter flight 007, which crashed. The Atlanta Art Association had sponsored a month-long tour of the art treasures of Europe. 106[53] of the tour members were heading home to Atlanta on the flight. The group included many of Atlanta's cultural and civic leaders. Atlanta mayor Ivan Allen Jr. went to Orly, France to inspect the crash site where so many important Atlantans perished.[54] The loss was a catalyst for the arts in Atlanta and helped create the Woodruff Arts Center, originally called the Memorial Arts Center, as a tribute to the victims, and led to the creation of the Atlanta Arts Alliance. The French government donated a Rodin sculpture, The Shade, to the High in memory of the victims of the crash.[55]\\r\\nThe crash occurred during the Civil Rights Movement and affected it as well. Martin Luther King, Jr. and Harry Belafonte announced cancellation of a sit-in in downtown Atlanta as a conciliatory gesture to the grieving city, while Nation of Islam leader Malcolm X gained widespread national attention for the first time by expressing joy over the deaths of the all-white group.[56]\\r\\nAtlanta's freeway system was completed in the 1950s and 1960s, with the Perimeter completed in 1969. Historic neighborhoods such as Washington-Rawson and Copenhill were damaged or destroyed in the process. Additional proposed freeways were never built due to the protests of city residents. The opposition lasted three decades, with then-governor Jimmy Carter playing a key role in stopping I-485 through Morningside and Virginia Highland to Inman Park in 1973, but pushing hard in the 1980s for a \\"Presidential Parkway\\" between Downtown, the new Carter Center and Druid Hills/Emory.\\r\\nIn the 1960s slums such as Buttermilk Bottom near today's Civic Center were razed, in principle to build better housing, but much of the land would remain empty until the 1980s when mixed-income communities were built in what was renamed Bedford Pine. The African-American community east of downtown suffered as the center of the black economy moved squarely to southwestern Atlanta. During the 1960s African-American citizens rights groups such as U-Rescue emerged to address the lack of housing for poor blacks.\\r\\n The first major mall built in Atlanta was Lenox Square in Buckhead, opening in August 1959. From 1964 until 1973, nine major malls opened, most at the Perimeter freeway: Cobb Center in 1963, Columbia Mall in 1964, North DeKalb and Greenbriar malls in 1965, South DeKalb Mall in 1968, Phipps Plaza (near Lenox Square) in 1969, Perimeter and Northlake malls in 1971, and Cumberland Mall in 1973. Downtown Atlanta became less and less a shopping destination for the area's shoppers. Rich's closed its flagship store downtown in 1991, leaving government offices the major presence in the South Downtown area around it.\\r\\nOn the north side of Five Points, Downtown continued as the largest concentration of office space in Metro Atlanta, though it began to compete with Midtown, Buckhead, and the suburbs. The first 4 towers of Peachtree Center were built in 1965-1967, including the Hyatt Regency Atlanta, designed by John Portman, with its 22-story atrium. In total, seventeen buildings of more than fifteen floors were built in the 1960s.[57] The center of gravity of Downtown Atlanta correspondingly moved north from the Five Points area towards Peachtree Center.\\r\\nAtlanta's convention and hotel facilities would also grow immensely. John C. Portman, Jr. designed and opened what is now the AmericasMart merchandise mart in 1958; the Sheraton Atlanta, the city's first convention hotel, was built in the 1960s; the Atlanta Hilton opened in 1971; as did two Portman-designed hotels: the Peachtree Plaza Hotel now owned by Westin in 1976, and the Marriott in 1985. The Omni Coliseum opened in 1976, as did the Georgia World Congress Center (GWCC). The GWCC expanded multiple times in succeeding decades and helped make Atlanta one of the country's top convention cities.\\r\\nIn 1960, whites comprised 61.7% of the city's population.[58] African Americans became a majority in the city by 1970, and exercised new-found political influence by electing Atlanta's first black mayor, Maynard Jackson, in 1973.\\r\\nDuring Jackson's first term as the Mayor, much progress was made in improving race relations in and around Atlanta, and Atlanta acquired the motto \\"A City Too Busy to Hate.\\" As mayor, he led the beginnings and much of the progress on several huge public-works projects in Atlanta and its region. He helped arrange for the rebuilding of the airport's huge terminal to modern standards, and this airport was renamed the Hartsfield-Jackson Atlanta International Airport in his honor shortly after his death, also named after him is the new Maynard Holbrook Jackson, Jr. International Terminal which opened in May 2012. He also fought against the construction of freeways through intown neighborhoods.\\r\\nIn 1965, an act of the Georgia General Assembly created the Metropolitan Atlanta Rapid Transit Authority, or MARTA. MARTA was to provide rapid transit for the five largest metro counties: DeKalb, Fulton, Clayton, Gwinnett, and Cobb, but a referendum authorizing participation in the system failed in Cobb County. A 1968 referendum to fund MARTA failed, but in 1971, Fulton and DeKalb Counties passed a 1% sales tax increase to pay for operations, while Clayton and Gwinnett counties overwhelmingly rejected the tax in referendum, fearing the introduction of crime and \\"undesirable elements\\".[59] In 1972, the agency bought the existing, bus-only Atlanta Transit Company.[60] Construction began on the new rail system in 1975, and service commenced on June 30, 1979, running east-west from Georgia State University downtown to Avondale. The Five Points downtown hub opened later that year. A short north-south line opened in 1981, which by 1984 had been extended to reach from Brookhaven to Lakewood/Fort McPherson. In 1988 the line was extended to a station inside the airport terminal.[60] A line originally envisioned to run to Emory University is still under consideration.[61]\\r\\nAtlanta was rocked by a series of murders of children from the summer of 1979 until the spring of 1981. Over the two-year period, at least 18 children, adolescents and adults were killed, all of them black. Atlanta native Wayne Williams, also black and 23 years old at the time of the last murder, was convicted of two of the murders and sent to prison for life.\\r\\nIn 1981, after being urged by a number of people, including Coretta Scott King, the widow of Martin Luther King Jr., Democratic Congressman Andrew Young ran for mayor of Atlanta. He was elected later that year with 55% of the vote, succeeding Maynard Jackson. As mayor of Atlanta, he brought in $70 billion of new private investment.[citation needed] He continued and expanded Maynard Jackson's programs for including minority and female-owned businesses in all city contracts. The Mayor's Task Force on Education established the Dream Jamboree College Fair that tripled the college scholarships given to Atlanta public school graduates. In 1985, he was involved in privatizing the Atlanta Zoo, which was renamed Zoo Atlanta. The then-moribund zoo was overhauled, making ecological habitats specific to different animals.[citation needed]\\r\\nYoung was re-elected as Mayor in 1985 with more than 80% of the vote. Atlanta hosted the 1988 Democratic National Convention during Young's tenure. He was prohibited by term limits from running for a third term. He was succeeded by Maynard Jackson who returned as mayor from 1990 to 1994. Bill Campbell succeeded Jackson as mayor in 1994 and served through 2002.\\r\\nIn November 1994, the Atlanta Empowerment Zone was established, a 10-year, $250 million federal program to revitalize Atlanta's 34 poorest neighborhoods including The Bluff. Scathing reports from both the U.S. Department of Housing and Urban Development and the Georgia Department of Community Affairs revealed corruption, waste, bureaucratic incompetence, and specifically called out interference by mayor Bill Campbell.[62][63]\\r\\nIn 1993-1996 about 250,000 people attended Freaknik, an annual Spring Break gathering for African Americans which was not centrally organized and which resulted in much traffic gridlock and increased crime. After a 1996 crackdown annual attendance dissipated and the event moved to other cities.\\r\\nIn 1990, the International Olympic Committee selected Atlanta as the site for the Centennial Olympic Games 1996 Summer Olympics. Following the announcement, Atlanta undertook several major construction projects to improve the city's parks, sports facilities, and transportation, including the completion of long-contested Freedom Parkway. Former Mayor Bill Campbell allowed many \\"tent cities\\" to be built, creating a carnival atmosphere around the games. Atlanta became the third American city to host the Summer Olympics, after St. Louis (1904 Summer Olympics) and Los Angeles (1932 and 1984). The games themselves were notable in the realm of sporting events, but they were marred by numerous organizational inefficiencies. A dramatic event was the Centennial Olympic Park bombing, in which two people died, one from a heart attack, and several others were injured. Eric Robert Rudolph was later convicted of the bombing as an anti-government and pro-life protest.\\r\\nShirley Franklin's 2001 run for mayor was her first run for public office. She won, succeeding Mayor Bill Campbell after winning 50 percent of the vote. Facing a massive and unexpected budget deficit, Franklin slashed the number of government employees and increased taxes to balance the budget as quickly as possible.[64]\\r\\nFranklin made repairing the Atlanta sewer system a main focus of her office. Prior to Franklin's term, Atlanta's combined sewer system violated the federal Clean Water Act and burdened the city government with fines from the Environmental Protection Agency. In 2002, Franklin announced an initiative called \\"Clean Water Atlanta\\" to address the problem and begin improving the city's sewer system.[65]\\r\\nShe has been lauded for efforts to make the City of Atlanta \\"green.\\" Under Franklin's leadership Atlanta has gone from having one of the lowest percentages of LEED certified buildings to one of the highest.\\r\\nIn 2005, TIME Magazine named Franklin of the five best big-city American mayors.[64] In October of that same year, she was included in the U.S. News & World Report \\"Best Leaders of 2005\\" issue.[66] With solid popular support and strong backing from the business sector, Franklin was reelected Atlanta Mayor in 2005, garnering more than 90 percent of the vote.[67]\\r\\n\\r\\nOn March 14, 2008, a tornado ripped through downtown Atlanta, the first since weather has been recorded in 1880. There was minor damage to many downtown skyscrapers. However, two holes were torn into the roof of the Georgia Dome, tearing down catwalks and the scoreboard as debris rained onto the court in the middle of an SEC game. The Omni Hotel suffered major damage, along with Centennial Olympic Park and the Georgia World Congress Center. Fulton Bag and Cotton Mills and Oakland Cemetery were also damaged.\\r\\nIn 2005, the $2.8 billion BeltLine project was adopted, with the stated goals of converting a disused 22-mile freight railroad loop that surrounds the central city into an art-filled multi-use trail and increasing the city's park space by 40%.[68]\\r\\nSince 2000, Atlanta has undergone a profound transformation culturally, demographically, and physically. Much of the city's change during the decade was driven by young, college-educated professionals: from 2000 to 2009, the three-mile radius surrounding Downtown Atlanta gained 9,722 residents aged 25 to 34 holding at least a four-year degree, an increase of 61%.[69][70] Meanwhile, as gentrification spread throughout the city, Atlanta's cultural offerings expanded: the High Museum of Art doubled in size; the Alliance Theatre won a Tony Award; and numerous art galleries were established on the once-industrial Westside.[71]\\r\\nThe black population in the Atlanta area rapidly suburbanized in the 1990s and 2000s. From 2000 to 2010, the city of Atlanta's black population shrunk by 31,678 people, dropping from 61.4% to 54.0% of the population.[72] While blacks exited the city and DeKalb County, the black population increased sharply in other areas of Metro Atlanta by 93.1%.[73] During the same period, the proportion of whites in the city's population grew dramatically - faster than that of any other major U.S. city between 2000-2006. Between 2000 and 2010, Atlanta added 22,763 whites, and the white proportion of the population increased from 31% to 38%. By 2009, a white mayoral candidate, Mary Norwood, lost by just 714 votes (out of over 84,000 cast) to Kasim Reed. This represented a historic change from the perception until that time that Atlanta was \\"guaranteed\\" to elect a black mayor.[74]\\r\\nIn 2009 the Atlanta Public Schools cheating scandal began, which ABC News called the \\"worst in the country\\",[75] resulting in the 2013 indictment of superintendent Beverly Hall.\\r\\nStarting in October 2011, Occupy Atlanta staged demonstrations against banks and AT&T to protest alleged greed by those companies.","input":"What was atlanta named before the civil war?"},{"output":"125 thousand broiler chickens, or 82 thousand laying hens or pullets","context":"A concentrated animal feeding operation (CAFO), as defined by the United States Department of Agriculture (USDA) is an animal feeding operation (AFO)a farm in which animals are raised in confinementthat has over 1000 \\"animal units\\" confined for over 45 days a year. An animal unit is \\"an animal equivalent of 1000 pounds live weight and equates to 1000 head of beef cattle, 700 dairy cows, 2500 swine weighing more than 55 lbs, 125 thousand broiler chickens, or 82 thousand laying hens or pullets\\".[1]\\r\\n\\r\\nA CAFO is also an animal feeding operation of any size that discharges its waste into a waterway. For the most part, there are regulations that restrict how much can be distributed and for what the quality of the materials has to be.[1] As of 2016 there were around 212,000 AFOs in the United States,[2]:1.2 19,496 of which were CAFOS.[3][a]\\r\\n\\r\\nLivestock production has become increasingly dominated by CAFOs in the United States and other parts of the world.[4] Most poultry was raised in CAFOs starting in the 1950s, and most cattle and pigs by the 1970s and 1980s.[5] By the mid-2000s CAFOs dominated livestock and poultry production in the United States, and the scope of their market share is steadily increasing. In 1966, it took one million farms to house 57 million pigs; by the year 2001, it took only 80,000 farms to house the same number.[6][7]\\r\\n\\r\\nThere are roughly 212,000 AFOs in the United States,[2]:1.2 of which 19,496 met the more narrow criteria for CAFOs in 2016.[3] The Environmental Protection Agency (EPA) has delineated three categories of CAFOs, ordered in terms of capacity: large, medium and small.[8] The relevant animal unit for each category varies depending on species and capacity. For instance, large CAFOs house 1,000 or more cattle, medium CAFOs can have 300ÿ999 cattle, and small CAFOs harbor no more than 300 cattle.[8]\\r\\n\\r\\nThe table below provides some examples of the size thresholds for CAFOs:\\r\\n\\r\\nThe categorization of CAFOs affects whether a facility is subject to regulation under the Clean Water Act (CWA). According to the 2008 rule adopted by the EPA, \\"large CAFOs are automatically subject to EPA regulation; medium CAFOs must also meet one of two 'method of discharge' criteria to be defined as a CAFO (or may be designated as such); and small CAFOs can only be made subject to EPA regulations on a case-by-case basis.\\"[8] A small CAFO will also be designated a CAFO for purposes of the CWA if it discharges pollutants into waterways of the United States through a man-made conveyance such as a road, ditch or pipe. Alternatively, a small CAFO may be designated an ordinary animal feeding operation (AFO) once its animal waste management system is certified at the site.\\r\\n\\r\\nSince it first coined the term, the EPA has changed the definition (and applicable regulations) for CAFOs on several occasions. Private groups and individuals use the term CAFO colloquially to mean many types of both regulated and unregulated facilities, both inside and outside the United States. The definition used in everyday speech may thus vary considerably from the statutory definition in the CWA. CAFOs are commonly characterized as having large numbers of animals crowded into a confined space, a situation that results in the concentration of manure in a small area.\\r\\n\\r\\nThe EPA has focused on regulating CAFOs because they generate millions of tons of manure every year. When improperly managed, the manure can pose substantial risks to the environment and public health.[9] In order to manage their waste, CAFO operators have developed agricultural wastewater treatment plans. The most common type of facility used in these plans, the anaerobic lagoon, has significantly contributed to environmental and health problems attributed to the CAFO.[10]\\r\\n\\r\\n\\r\\nThe large amounts of animal waste from CAFOs present a risk to water quality and aquatic ecosystems.[11] According to the EPA, states with high concentrations of CAFOs experience on average 20 to 30 serious water quality problems per year as a result of manure management issues.[12]\\r\\nAnimal waste includes a number of potentially harmful pollutants. According to the EPA, pollutants associated with CAFO waste principally include: \\r\\n\\r\\nThe two main contributors to water pollution caused by CAFOs are soluble nitrogen compounds and phosphorus. The eutrophication of water bodies from such waste is harmful to wildlife and water quality in aquatic system like streams, lakes, and oceans.[14]\\r\\n\\r\\nBecause groundwater and surface water are closely linked, water pollution from CAFOs can affect both sources if one or the other is contaminated.[12] Surface water may be polluted by CAFO waste through the runoff of nutrients, organics, and pathogens from fields and storage. Waste can be transmitted to groundwater through the leaching of pollutants.[15] Some facility designs, such as lagoons, can reduce the risk of groundwater contamination, but the microbial pathogens from animal waste may still pollute surface and groundwater, causing adverse effects on wildlife and human health.[16]\\r\\n\\r\\nA CAFO is responsible for one of the biggest environmental spills in U.S. history. In 1995, a 120,000-square-foot (11,000?m2) lagoon ruptured in North Carolina, releasing 25.8?million US gallons (98,000?m3) of effluvium into the New River.[17] The spill resulted in the killing of 10 million fish in local water bodies. The spill also contributed to an outbreak of Pfiesteria piscicida, which caused health problems for humans in the area including skin irritations and short term cognitive problems.[18]\\r\\n\\r\\n\\r\\nCAFOs contribute to the reduction of ambient air quality. CAFOs release several types of gas emissionsammonia, hydrogen sulfide, methane, and particulate matterall of which bear varying human health risks. The amount of gas emissions depends largely on the size of the CAFO. The primary cause of gas emissions from CAFOs is the decomposition of animal manure being stored in large quantities.[12] Additionally, CAFOs emit strains of antibiotic resistant bacteria into the surrounding air, particularly downwind from the facility. Levels of antibiotics measured downwind from swine CAFOs were three times higher than those measured upwind.[19] While it is not widely known what is the source of these emissions, the animal feed is suspected.[20]\\r\\nGlobally, ruminant livestock are responsible for about 115 Tg/a of the 330 Tg/a (35%) of anthropogenic greenhouse gas emissions released per year.[21] Livestock operations are responsible for about 18% of greenhouse gas emissions globally and over 7% of greenhouse gas emissions in the U.S.[22] Methane is the second most concentrated greenhouse gas contributing to global climate change,[23] with livestock contributing nearly 30% of anthropogenic methane emissions.[24] Only 17% of these livestock emissions are due to manure management, with the majority resulting from enteric fermentation, or gases produced during digestion.[24] With regards to antibiotic resistant bacteria, Staphylococcus Aureus accounts for 76% of bacteria grown within a swine CAFO.[19] Group A Streptococci, and Fecal Coliforms were the two next most prevalent bacteria grown within the ambient air inside of swine CAFO.[19]\\r\\n\\r\\nThe Intergovernmental Panel on Climate Change (IPCC) acknowledges the significant effect livestock has on methane emissions, antibiotic resistance, and climate change, and thus, recommends eliminating environmental stressors and modifying feeding strategies, including sources of feed grain, amount of forage, and amount of digestible nutrients as strategies for reducing emissions.[25] The Humane Society of the United States (HSUS) advocates for minimizing the use of non-therapeutic antibiotics, especially those that are widely used in human medicine, at the advice of over 350 organizations including the American Medical Association.[26] If no change is made and methane emissions continue increasing in direct proportion to the number of livestock, global methane production is predicted to increase 60% by 2030.[27] Greenhouse gases and climate change affect the air quality with adverse health effects including respiratory disorders, lung tissue damage, and allergies.[28] Reducing the increase of greenhouse gas emissions from livestock could rapidly curb global warming.[29] In addition, people who live near CAFOs frequently complain of the odors, which come from a complex mixture of ammonia, hydrogen sulfide, carbon dioxide, and volatile and semi-volatile organic compounds.\\r\\n\\r\\nThe economic role of CAFOs has expanded significantly in the U.S. in the past few decades, and there is clear evidence that CAFOs have come to dominate animal production industries. The rise in large-scale animal agriculture began in the 1930s with the modern mechanization of swine slaughterhouse operations.[30]\\r\\n\\r\\nThe growth of corporate contracting has also contributed to a transition from a system of many small-scale farms to one of relatively few large industrial-scale farms. This has dramatically changed the animal agricultural sector in the United States. According to the National Agricultural Statistics Service, \\"In the 1930s, there were close to 7 million farms in the United States and as of the 2002 census, just over 2 million farms remain.\\"[31] From 1969 to 2002, the number of family farms dropped by 39%,[32] yet the percentage of family farms has remained high.  As of 2004, 98% of all U.S. farms were family-owned and -operated.[33]  Most meat and dairy products are now produced on large farms with single-species buildings or open-air pens.[34]\\r\\n\\r\\nCAFOs can be very beneficial when properly located, managed and monitored. Due to their increased efficiency, CAFOs provide a source of low cost animal products: meat, milk and eggs.  CAFOs may also stimulate local economies through increased employment and use of local materials in their production.[35] The development of modern animal agriculture has increased the efficiency of raising meat and dairy products. Improvements in animal breeding, mechanical innovations, and the introduction of specially formulated feeds (as well as animal pharmaceuticals) have contributed to the decrease in cost of animal products to consumers.[36] The development of new technologies has also helped CAFO owners reduce production cost and increase business profits with less resources consumption. The growth of CAFOs has corresponded with an increase in the consumption of animal products in the United States. According to author Christopher L. Delgado, \\"milk production has doubled, meat production has tripled, and egg production has increased fourfold since 1960\\" in the United States.[37]\\r\\n\\r\\nAlong with the noted benefits, there are also criticisms regarding CAFOs' impact on the economy. Many farmers in the United States find that it is difficult to earn a high income due to the low market prices of animal products.[38]  Such market factors often lead to low profit margins for production methods and a competitive disadvantage against CAFOs. Alternative animal production methods, like \\"free range\\" or \\"family farming\\" operations[39] are losing their ability to compete, though they present few of the environmental and health risks associated with CAFOs.\\r\\n\\r\\nCritics have long argued that the \\"retail prices of industrial meat, dairy, and egg products omit immense impacts on human health, the environment, and other shared public assets.\\"[40] The negative production externalities of CAFOs have been described as including \\"massive waste amounts with the potential to heat up the atmosphere, foul fisheries, pollute drinking water, spread disease, contaminate soils, and damage recreational areas\\"[40] that are not reflected in the price of the meat product. Environmentalists contend that \\"citizens ultimately foot the bill with hundreds of billions of dollars in taxpayer subsidies, medical expenses, insurance premiums, declining property values, and mounting cleanup costs.\\"[40] Some economists agree that CAFOs \\"operate on an inefficient scale.\\"[41] It has been argued, for instance, that \\"diminishing returns to scale quickly lead to costs of animal confinement that overwhelm any benefits of CAFOs.\\"[41] These economists claim that CAFOs are at an unfair competitive advantage because they shift the costs of animal waste from CAFOs to the surrounding region (an unaccounted for \\"externality\\").\\r\\n\\r\\nThe evidence shows that CAFOs may be contributing to the drop in nearby property values. There are many reasons for the decrease in property values, such as loss of amenities, potential risk of water contamination, odors, air pollution, and other health related issues. One study shows that property values on average decrease by 6.6% within a 3-mile (4.8?km) radius of a CAFO and by 88% within 1/10 of a mile from a CAFO.[42] Proponents of CAFOs, including those in farm industry, respond by arguing that the negative externalities of CAFOs are limited. One executive in the pork industry, for instance, claims that any odor or noise from CAFOs is limited to an area within a quarter-mile of the facility.[43]  Proponents also point to the positive effect they believe CAFOs have on the local economy and tax base. CAFOs buy feed from and provide fertilizer to local farmers.[44] And the same executive claims that farmers near CAFOs can save $20 per acre by using waste from CAFOs as a fertilizer.[45]\\r\\n\\r\\nEnvironmentalists contend that \\"sustainable livestock operations\\" present a \\"less costly alternative.\\"[46] These operations, it is argued, \\"address potential health and environmental impacts through their production methods.\\" And though \\"sustainably produced foods may cost a bit more, many of their potential beneficial environmental and social impacts are already included in the price.\\"[46] In other words, it is argued that if CAFO operators were required to internalize the full costs of production, then some CAFOs might be less efficient than the smaller farms they replace.[47]\\r\\n\\r\\nCritics of CAFOs also maintain that CAFOs benefit from the availability of industrial and agricultural tax breaks/subsidies and the \\"vertical integration of giant agribusiness firms.\\"[41]  The U.S. Department of Agriculture (USDA), for instance, spent an average of $16 billion annually between FY 1996 to FY 2002 on commodity based subsidies.[48]  Some allege that the lax enforcement of anti-competitive practices may be contributing to the formulation of market monopoly. Critics also contend that CAFOs reduce costs and maximize profits through the overuse of antibiotics.[49]\\r\\n\\r\\nThe direct discharge of manure from CAFOs and the accompanying pollutants (including nutrients, antibiotics, pathogens, and arsenic) is a serious public health risk.[50] The contamination of groundwater with pathogenic organisms from CAFOs can threaten drinking water resources, and the transfer of pathogens through drinking water contamination can lead to widespread outbreaks of illness. The EPA estimates that about 53% of people in the United States rely on groundwater resources for drinking water.[51]\\r\\n\\r\\nThere are numerous effects on human health due to water contaminated by CAFOs.  Accidental ingestion of contaminated water can result in diarrhea or other gastrointestinal illnesses and dermal exposure can result in irritation and infection of the skin, eyes or ear.[52]  High levels of nitrate also pose a threat to high-risk populations such as young children, pregnant women or the elderly.  Several studies have shown that high levels of nitrate in drinking water are associated with increased risk of hyperthyroidism,  insulin dependent diabetes and central nervous system malformations.[52]\\r\\n\\r\\nThe exposure to chemical contaminates, such as antibiotics, in drinking water also creates problems for public health.[11] In order to maximize animal production, CAFOs have used an increasing number of antibiotics, which in turn, increases bacterial resistance. This resistance threatens the efficiency of medical treatment for humans fighting bacterial infections.  Contaminated surface and groundwater is especially concerning, due to its role as a pathway for the dissemination of antibiotic resistant bacteria.[53]   Due to the various antibiotics and pharmaceutical drugs found at a high density in contaminated water, antibiotic resistance can result due to DNA mutations, transformations and conjugations.[53]\\r\\n\\r\\nAntibiotics are used heavily in CAFOs to both treat and prevent illness in individual animals as well as groups. The close quarters inside CAFOs promote the sharing of pathogens between animals and thus, the rapid spread of disease. Even if their stock are not sick, CAFOs will incorporate low doses of antibiotics into feed to reduce the chance for infection and to eliminate the need for animals to expend energy fighting off bacteria, with the assumption that saved energy will be translated into growth.[35] This practice is an example of a non-therapeutic use of antibiotics. Such antibiotic use is thought to allow animals to grow faster and bigger, consequently maximizing production for that CAFO. Regardless, the World Health Organization has recommended that the non-therapeutic use of antibiotics in animal husbandry be reevaluated, as it contributes to the overuse of antibiotics and thus the emergence of resistant bacteria that can spread to humans.[54][55][56] When bacteria naturally occurring in the animals environment and/or body are exposed to antibiotics, natural selection results in bacteria, who have genetic variations that protect them from the drugs, to survive and spread their advantageously resistant traits to other bacteria present in the ecosystem.[57] This is how the problem of antimicrobial resistance increases with the continued use of antibiotics by CAFOs. This is of concern to public health because resistant bacteria generated by CAFOs can be spread to the surrounding environment and communities via waste water discharge or aerosolization of particles.[58]\\r\\n\\r\\nConsequences of the air pollution caused by CAFO emissions include asthma, headaches, respiratory problems, eye irritation, nausea, weakness, and chest tightness. These health effects are felt by farm workers and nearby residents, including children.[59] The risks to nearby residents was highlighted in a study evaluating health outcomes of more than 100,000 individuals living in regions with high densities of CAFOs, finding a higher prevalence of pneumonia and unspecified infectious diseases in those with high exposures compared to controls.[60] Furthermore, a Dutch cross-sectional study 2,308 adults found decreases in residents' lung function to be correlated with increases particle emissions by nearby farms.[61]  In regards to workers, multiple respiratory consequences should be noted. Although \\"in many big CAFOs, it takes only a few workers to run a facility housing thousands of animals,\\"[62] the long exposure and close contact to animals puts CAFO employees at an increased risk. This includes a risk of contracting diseases like Novel H1N1 flu, which erupted globally in spring of 2009,[63] or MRSA, a strain of antibiotic resistant bacteria.[55] For instance, livestock-associated MRSA has been found in the nasal passages of CAFO workers, on the walls of the facilities they work in, and in the animals they tend.[55] In addition, individuals working in CAFOs are at risk for chronic airway inflammatory diseases secondary to dust exposure, with studies suggesting the possible benefits to utilizing inhaler treatments empirically.[64] Studies conducted by the University of Iowa show that the asthma rate of children of CAFO operators is higher than that of children from other farms.[65]\\r\\n\\r\\nCAFO practices have raised concerns over animal welfare from an ethics standpoint. Some view such conditions as neglectful to basic animal welfare. Many people believe that the harm to animals before their slaughter should be addressed through public policy.[66] Laws regarding animal welfare in CAFOs have already been passed in the United States. For instance, in 2002, the state of Florida passed an amendment to the state's constitution banning the confinement of pregnant pigs in gestation crates.[67]  As a source for comparison, the use of battery cages for egg-laying hens and battery cage breeding methods have been completely outlawed in the European Union since 2012.[68]\\r\\n\\r\\nWhereas some people are concerned with animal welfare as an end in itself, others are concerned about animal welfare because of the effect of living conditions on consumer safety. Animals in CAFOs have lives that do not resemble those of animals found in the wild.[69] Although CAFOs help secure a reliable supply of animal products, the quality of the goods produced is debated, with many arguing that the food produced is unnatural. For instance, confining animals into small areas requires the use of large quantities of antibiotics to prevent the spread of disease. There are debates over whether the use of antibiotics in meat production is harmful to humans.[70]\\r\\n\\r\\nThe command-and-control permitting structure of the Clean Water Act (CWA) provides the basis for nearly all regulation of CAFOs in the United States. Generally speaking, the CWA prohibits the discharge of pollution to the \\"waters of the United States\\" from any \\"point source\\", unless the discharge is authorized by a National Pollutant Discharge Elimination System (NPDES) permit issued by the EPA (or a state delegated by the EPA). CAFOs are explicitly listed as a point source in the CWA.[71] Unauthorized discharges made from CAFOs (and other point sources) violate the CWA, even if the discharges are \\"unplanned or accidental.\\"[72] CAFOs that do not apply for NPDES permits \\"operate at their own risk because any discharge from an unpermitted CAFO (other than agricultural stormwater) is a violation of the CWA subject to enforcement action, including third party citizen suits.\\"[73]\\r\\n\\r\\nThe benefit of an NPDES permit is that it provides some level of certainty to CAFO owners and operators. \\"Compliance with the permit is deemed compliance with the CWA... and thus acts as a shield against EPA or State CWA enforcement or against citizen suits under... the CWA.\\"[73] In addition, the \\"upset and bypass\\" provisions of the permit can give permitted CAFO owners a legal defense when \\"emergencies or natural disasters cause discharges beyond their reasonable control.\\"[73]\\r\\n\\r\\nUnder the CWA, the EPA specifies the maximum allowable amounts of pollution that can be discharged by facilities within an industrial category (like CAFOs). These general \\"effluent limitations guidelines\\" (ELG) then dictate the terms of the specific effluent limitations found in individual NPDES permits. The limits are based on the performance of specific technologies, but the EPA does not generally require the industry to use these technologies. Rather, the industry may use \\"any effective alternatives to meet the pollutant limits.\\"[74]\\r\\n\\r\\nThe EPA places minimum ELG requirements into each permit issued for CAFOs. The requirements can include both numeric discharge limits (the amount of a pollutant that can be released into waters of the United States) and other requirements related to ELGs (such as management practices, including technology standards).[75]\\r\\n\\r\\nThe major CAFO regulatory developments occurred in the 1970s and in the 2000s. The EPA first promulgated ELGs for CAFOs in 1976.[72] The 2003 rule issued by the EPA updated and modified the applicable ELGs for CAFOs, among other things. In 2005, the court decision in Waterkeeper Alliance v. EPA (see below) struck down parts of the 2003 rule. The EPA responded by issuing a revised rule in 2008.\\r\\n\\r\\nA complete history of EPAs CAFO rulemaking activities is provided on the CAFO Rule History page.[76]\\r\\n\\r\\nThe Federal Water Pollution Control Act of 1948 was one of the first major efforts of the U.S. federal government to establish a comprehensive program for mitigating pollution in public water ways. The writers of the act aimed to improve water quality for the circulation of aquatic life, industry use, and recreation. Since 1948, the Act has been amended many times to expand programming, procedures, and standards.[77]\\r\\n\\r\\nPresident Richard Nixons executive order, Reorganization Plan No. 3, created the EPA in 1970. The creation of the EPA was an effort to create a more comprehensive approach to pollution management. As noted in the order, a single polluter may simultaneously degrade a local environments air, water, and land. President Nixon noted that a single government entity should be monitoring and mitigating pollution and considering all effects. As relevant to CAFO regulation, the EPA became the main federal authority on CAFO pollution monitoring and mitigation.[78]\\r\\n\\r\\nCongress passed the CWA in 1972 when it reworked the Federal Water Pollution Control Amendments.[79] It specifically defines CAFOs as point source polluters and required operations managers and/or owners to obtain NPDES permits in order to legally discharge wastewater from its facilities.[80]\\r\\n\\r\\nThe EPA began regulating water pollution from CAFOs starting in the 1970s. The EPA first created effluent limitation guidelines (ELGs) for feedlot operations in 1974, placing emphasis on best available technology in the industry at the time.[81] In 1976, under the ELGs, the EPA began requiring all CAFOs to be first defined as AFOs. From that point, if the specific AFO met the appropriate criteria, it would then be classified as a CAFO and subject to appropriate regulation. That same year, EPA defined livestock and poultry CAFO facilities and established a specialized permitting program.[82] NPDES permits specifications for CAFOs were also promulgated by the EPA in 1976.[83]\\r\\n\\r\\nPrior to 1976, size had been the main defining criteria of CAFOs. However, after the 1976 regulations came into effect, the EPA stipulated some exceptions. Operations that were identified as particularly harmful to federal waterways could be classified as CAFOs, even if the facilities sizes fall under AFOs standards. Additionally, some CAFOs were not required to apply for wastewater discharge permits if they met the two major operational-based exemptions. The first exception applied to operations that discharge wastewater only during a 25-year, 24-hour storm event. (The operation only discharges during a 24-hour rainfall period that occurs once every 25 years or more on average.) The second exception was when operations apply animal waste onto agricultural land.[82]\\r\\n\\r\\nIn 1989, the Natural Resources Defense Council and Public Citizen filed a lawsuit against the EPA (and Administrator of the EPA, William Reilly). The plaintiffs claimed the EPA had not complied with the CWA with respect to CAFOs.[82] The lawsuit, Natural Resources Defense Council v. Reilly (D.D.C. 1991), resulted in a court order mandating the EPA update its regulations. They did so in what would become the 2003 Final Rule.[84]\\r\\n\\r\\nIn 1995, the EPA released a \\"Guide Manual on NPDES Regulations for Concentrated Animal Feeding Operations\\" to provide more clarity to the public on NPDES regulation after the EPAs report \\"Feedlots Case Studies of Selected States\\" revealed there was uncertainty in the public regarding CAFO regulatory terminology and criteria.[80] Although the document is not a rule, it did offer insight and furthered public understanding of previous rules.\\r\\n\\r\\nIn his 1998 Clean Water Action Plan, President Bill Clinton directed the USDA and the EPA to join forces to develop a framework for future actions to improve national water quality standards for public health. The two federal agencies specific responsibility was to improve the management of animal waste runoff from agricultural activities. In 1998, the USDA and the EPA hosted eleven public meetings across the country to discuss animal feeding operations (AFOs).[85]\\r\\n\\r\\nOn March 9, 1999 the agencies released the framework titled the Unified National Strategy for Animal Feeding Operations.[86] In the framework, the agencies recommended six major activities to be included in operations Comprehensive Nutrient Management Plans (CNMPs):\\r\\n\\r\\nThe framework also outlined two types of related programs. First, voluntary programs were designed to assist AFO operators with addressing public health and water quality problems.[87] The framework outlines three types of voluntary programs available: locally led conservation, environmental education, and financial and technical assistance.[87] The framework explained that those that participate in voluntary programs are not required to have a comprehensive nutrient management plan (CNMP). The second type of program outlined by the framework was regulatory, which includes command-and-control regulation with NPDES permitting.[87]\\r\\n\\r\\nAccording to the EPA, the purpose of the 2003 rule was to update decades-old policies to reflect new technology advancements and increase the expected pollution mitigation from CAFOs.[88] The EPA was also responding to a 1991 court order based on the district court's decision in Natural Resources Defense Council v. Reilly.[82] The final rule took effect on April 14, 2003 and responded to public comments received following the issuance of the proposed rule in 2000.[89] The EPA allowed authorized NPDES states until February 2005 to update their programs and develop technical standards.[89]\\r\\n\\r\\nThe 2003 rule[90] established \\"non-numerical best management practices\\" (BMPs) for CAFOs that apply both to the \\"production areas\\" (e.g. the animal confinement area and the manure storage area) and, for the first time ever, to the \\"land application area\\" (land to which manure and other animal waste is applied as fertilizer).[91] The standards for BMPs in the 2003 rule vary depending on the regulated area of the CAFO: \\r\\n\\r\\nThe 2003 rule also requires CAFOs to submit an annual performance report to the EPA and to develop and implement a comprehensive nutrient management plan (NMP) for handling animal waste.[91] Lastly, in an attempt to broaden the scope of regulated facilities, the 2003 rule expanded the number of CAFOs required to apply for NPDES permits by making it mandatory for all CAFOs (not just those who actually discharge pollutants into waters of the United States).[91] Many of the provisions of the rule were affected by the Second Circuit's decision issued in Waterkeeper Alliance v. EPA.\\r\\n\\r\\nEnvironmental and farm industry groups challenged the 2003 final rule in court, and the Second Circuit Court of Appeals issued a decision in the consolidated case Waterkeeper Alliance, Inc. v. EPA, 399 F.3d 486 (2nd Cir. 2005). The Second Circuit's decision reflected a \\"partial victory\\" for both environmentalists and industry, as all parties were \\"unsatisfied to at least some extent\\" with the court's decision.[92] The court's decision addressed four main issues with the 2003 final rule promulgated by the EPA:\\r\\n\\r\\nThe EPA published revised regulations that address the Second Circuit courts decision in Waterkeeper Alliance, Inc. v. EPA on November 20, 2008 (effective December 22, 2008).[100] The 2008 final rule revised and amended the 2003 final rule.\\r\\n\\r\\nThe 2008 rule addresses each point of the court's decision in Waterkeeper Alliance v. EPA. Specifically, the EPA adopted the following measures:\\r\\n\\r\\nThe 2008 final rule also specifies two approaches that a CAFO may use to identify the \\"annual maximum rates of application of manure, litter, and process wastewater by field and crop for each year of permit coverage.\\" The linear approach expresses the rate in terms of the \\"amount of nitrogen and phosphorus from manure, litter, and process wastewater allowed to be applied.\\" The narrative rate approach expresses the amount in terms of a \\"narrative rate prescribing how to calculate the amount of manure, litter, and process wastewater allowed to be applied.[73] The EPA believes that the narrative approach gives CAFO operators the most flexibility. Normally, CAFO operators are subject to the terms of their permit for a period of 5 years. Under the narrative approach, CAFO operators can use \\"real time\\" data to determine the rates of application. As a result, CAFO operators can more easily \\"change their crop rotation, form and source of manure, litter, and process wastewater, as well as the timing and method of application\\" without having to seek a revision to the terms of their NPDES permits.[73]\\r\\n\\r\\nThe EPA points to several tools available to assist CAFO operators in meeting their obligations under the CWA. First, the EPA awards federal grants to provide technical assistance to livestock operators for preventing discharges of water pollution (and reducing air pollution). The EPA claims that CAFOs can obtain an NMP for free under these grants.[104] Recently, the annual amount of the grant totaled $8 million.[73] Second, a Manure Management Planner (MMP) software program has been developed by Purdue University in conjunction with funding by a federal grant. The MMP is tailored to each state's technical standards (including Phosphorus Indexes and other assessment tools).[73] The MMP program provides free assistance to both permitting authorities and CAFO operators and can be found at the Purdue University website.[105] Lastly, the EPA notes that the USDA offers a \\"range of support services,\\" including a long-term program that aims to assist CAFOs with NMPs.[73]\\r\\n\\r\\nEnvironmentalists argue that the standards under the CWA are not strong enough. Researchers have identified regions in the country that have weak enforcement of regulations and, therefore, are popular locations for CAFO developers looking to reduce cost and expand operations without strict government oversight.[106] Even when laws are enforced, there is the risk of environmental accidents. The massive 1995 manure spill in North Carolina highlights the reality that contamination can happen even when it is not done maliciously.[107] The question of whether such a spill could have been avoided is a contributing factor in the debate for policy reform.\\r\\n\\r\\nEnvironmental groups have criticized the EPA's regulation of CAFOs on several specific grounds, including the following.[108]\\r\\n\\r\\nConversely, industry groups criticize the EPA's rules as overly stringent. Industry groups vocally opposed the requirement in the 2008 rule (since struck down by the Fifth Circuit) that required CAFOs to seek a permit if they \\"propose to discharge\\" into waters of the United States.[113] Generally speaking, the farm industry disputes the presumption that CAFOs do discharge pollutants and it therefore objects to the pressure that the EPA places on CAFOs to voluntarily seek an NPDES permit.[113] As a starting point, farm industry groups \\"emphasize that most farmers are diligent stewards of the environment, since they depend on natural resources of the land, water, and air for their livelihoods and they, too, directly experience adverse impacts on water and air quality.\\"[114] Some of the agricultural industry groups continue to maintain that the EPA should have no authority to regulate any of the runoff from land application areas because they believe this constitutes a nonpoint source that is outside the scope of the CWA.[108] According to this viewpoint, voluntary programs adequately address any problems with excess manure.[108]\\r\\n\\r\\nThe role of the federal government in environmental issues is generally to set national guidelines and the state governments role is to address specific issues. The framework of federal goals is as such that the responsibility to prevent, reduce, and eliminate pollution are the responsibility of the states.[115]\\r\\n\\r\\nThe management of water and air standards follows this authoritative structure. States that have been authorized by the EPA to directly issue permits under NPDES (also known as \\"NPDES states\\"[116]) have received jurisdiction over CAFOs. As a result of this delegation of authority from the EPA, CAFO permitting procedures and standards may vary from state to state.\\r\\n\\r\\nSpecifically for water pollution, the federal government establishes federal standards for wastewater discharge and authorized states develop their own wastewater policies to fall in compliance. More specifically, what a state allows an individual CAFO to discharge must be as strict or stricter than the federal government's standard.[117] This protection includes all waterways, whether or not the water body can safely sustain aquatic life or house public recreational activities. Higher standards are upheld in some cases of pristine publicly owned waterways, such as parks. They keep higher standards in order to maintain the pristine nature of the environment for preservation and recreation. Exceptions are in place for lower water quality standards in certain waterways if it is deemed economically significant.[115] These policy patterns are significant when considering the role of state governments in CAFO permitting.\\r\\n\\r\\nFederal law requires CAFOs to obtain NPDES permits before wastewater may be discharged from the facility. The state agency responsible for approving permits for CAFOs in a given state is dependent on the authorization of that state. The permitting process is divided into two main methods based on a states authorization status. As of 2017, EPA has authorized 46 states to issue NPDES permits. Although they have their own state-specific permitting standards, permitting requirements in authorized states must be at least as stringent as the federal standards.[80]:13 In the remaining states and territories, an EPA regional office issues NPDES permits.[116]\\r\\n\\r\\nA states authority and the states environmental regulatory framework will determine the permit process and the state offices involved. Below are two examples of states permitting organization.\\r\\n\\r\\nArizona issues permits through a general permitting process. CAFOs must obtain both a general Arizona Pollutant Discharge Elimination System (AZPDES) Permit and a general Aquifer Protection Permit.[118] The Arizona state agency tasked with managing permitting is the Arizona Department of Environmental Quality (ADEQ).\\r\\n\\r\\nFor the Aquifer Protection Permit, CAFOs are automatically permitted if they comply with the states BMP outlined in the relevant state rule, listed on the ADEQs website. Their compliance is evaluated through agency CAFO Inspection Programs onsite inspections. If a facility is found to be unlawfully discharging, then the agency may issue warnings and, if necessary, file suit against the facility. For the AZPDES permit, CAFOs are required to submit a Notice of Intent to the ADEQ. In addition, they must complete and submit a Nutrient Management Plan (NMP) for the states annual report.[118]\\r\\n\\r\\nEven in an authorized state, the EPA maintains oversight of state permitting programs. This would be most likely to happen in the event that a complaint is filed with the EPA by a third party. For instance, in 2008, Illinois Citizens for Clean Air & Water filed a complaint with the EPA arguing that the state was not properly implementing its CAFO permitting program. The EPA responded with an \\"informal\\" investigation. In a report released in 2010, the agency sided with the environmental organization and provided a list of recommendations and required action for the state to meet.\\r\\n\\r\\nIn unauthorized states, the EPA has the authority for issuing NPDES permits. In these states, such as Massachusetts, CAFOs communicate and file required documentation through an EPA regional office. In Massachusetts, the EPA issues a general permit for the entire state. The states Department of Agricultural Resources (MDAR) has an agreement with the EPA for the implementation of CAFO rules. MDARs major responsibility is educational. The agency assists operators in determining if their facility qualifies as a CAFO. Specifically they do onsite evaluations of facilities, provide advice on best practices, and provide information and technical assistance.[119]\\r\\n\\r\\nIf a state has additional state specific rules for water quality standards, the state government maintains the authority for permitting. For instance, New Mexico, also unauthorized, requires CAFOs and AFOs to obtain a Groundwater Permit if the facilities discharge waste in a manner that might affect local groundwater. The EPA is not involved in the issuing of this state permit.[119] Massachusetts, however, does not have additional state permit requirements.[119]\\r\\n\\r\\nState planning laws and local zoning ordinances represent the main policy tools for regulating land use. Many states have adopted legislation that specifically exempt CAFOs (and other agricultural entities) from zoning regulations.[120] The promulgation of so-called \\"right to farm\\" statutes have provided, in some instances, a shield from liability for CAFOs (and other potential nuisances in agricultural).[120] More specifically, the right-to-farm statutes seek to \\"limit the circumstances under which agricultural operations can be deemed nuisances.\\"\\r\\n\\r\\nThe history of these agricultural exemptions dates back to the 1950s. Right-to-farm statutes expanded in the 1970s when state legislatures became increasingly sensitive to the loss of rural farmland to urban expansion.[121] The statutes were enacted at a time when CAFOs and \\"modern confinement operations did not factor into legislator's perceptions of the beneficiaries of [the] generosity\\" of such statutes.[120] Forty-three (43) states now have some sort of statutory protection for farmers from nuisance. Some of these states (such as Iowa, Oklahoma, Wyoming, Tennessee, and Kansas) also provide specific protection to animal feeding operations (AFOs) and CAFOs.[121] Right-to-farm statutes vary in form. Some states, for instance, require agricultural operation be located \\"within an acknowledged and approved agricultural district\\" in order to receive protection; other states do not.[121]\\r\\n\\r\\nOpponents of CAFOs have challenged right-to-farm statutes in court, and the constitutionality of such statutes is not entirely clear. The Iowa Supreme Court, for instance, struck down a right-to-farm statute as a \\"taking\\" (in violation of the 5th and 14th Amendments of the U.S. Constitution) because the statute stripped neighboring landowners of property rights without compensation.[122]\\r\\n\\r\\nCAFOs are potentially subject to regulation under the Clean Air Act (CAA), but the emissions from CAFOs generally do not exceed established statutory thresholds.[123] In addition, the EPA's regulations do not provide a clear methodology for measuring emissions from CAFOs, which has \\"vexed both regulators and the industry.\\"[124] Negotiations between the EPA and the agricultural industry did, however, result in an Air Compliance Agreement in January 2005.[123] According to the agreement, certain animal feeding operations (AFOs) received a covenant not to sue from the EPA in exchange for payment of a civil penalty for past violations of the CAA and an agreement to allow their facilities to be monitored for a study on air pollution emissions in the agricultural sector.[123] Results and analysis of the EPA's study are scheduled to be released later in 2011.[123]\\r\\n\\r\\nEnvironmental groups have formally proposed to tighten EPA regulation of air pollution from CAFOs. A coalition of environmental groups petitioned the EPA on April 6, 2011 to designate ammonia as a \\"criteria pollutant\\" and establish National Ambient Air Quality Standards (NAAQS) for ammonia from CAFOs.[123] The petition alleges that \\"CAFOs are leading contributors to the nations ammonia inventory; by one EPA estimate livestock account for approximately 80 percent of total emissions. CAFOs also emit a disproportionately large share of the ammonia in certain states and communities.[125] If the EPA adopts the petition, CAFOs and other sources of ammonia would be subject to the permitting requirements of the CAA.","input":"Approximately how many chickens does a cafo (factory farm) house per building?"},{"output":"hormones secreted by the hypothalamus","context":"A major organ of the endocrine system, the anterior pituitary (also called the adenohypophysis or pars anterior), is the glandular, anterior lobe that together with the posterior lobe (posterior pituitary, or the neurohypophysis) makes up the pituitary gland (hypophysis). The anterior pituitary regulates several physiological processes including stress, growth, reproduction and lactation. Proper functioning of the anterior pituitary and of the organs it regulates can often be ascertained via blood tests that measure hormone levels.\\r\\n\\r\\nThe pituitary gland is a pea-sized gland that sits in a protective bony enclosure called the sella turcica (Turkish chair/saddle). It is composed of three lobes: the anterior, intermediate, and posterior lobes. In many animals, these lobes are distinct. However, in humans, the intermediate lobe is but a few cell layers thick and indistinct; as a result, it is often considered as part of the anterior pituitary. In all animals, the fleshy, glandular anterior pituitary is distinct from the neural composition of the posterior pituitary.\\r\\n\\r\\nThe anterior pituitary is composed of three regions:\\r\\n\\r\\nNota bene: The term \\"Basophil\\" and \\"Acidophil\\" is used by some books, whereas others prefer to not use these terms. This is due to the possible confusion with white blood cells, where one may also find Basophils and Acidophils.\\r\\n\\r\\nThe anterior pituitary is derived from the ectoderm, more specifically from that of Rathkes pouch, part of the developing hard palate in the embryo.\\r\\n\\r\\nThe pouch eventually loses its connection with the pharynx, giving rise to the anterior pituitary. The anterior wall of Rathke's pouch proliferates, filling most of the pouch to form the pars distalis and the pars tuberalis. The posterior wall of the anterior pituitary forms the pars intermedia. Its formation from the soft tissues of the upper palate contrasts with the posterior pituitary, which originates from neuroectoderm.[5]\\r\\n\\r\\nThe anterior pituitary contains five types of endocrine cell, and  they  are defined by the hormones they secrete: somatotropes (GH); Lactotropes (PRL); gonadotropes (LH and FSH); corticotropes (ACTH) and thyrotropes (TSH).[6] It also contains non-endocrine folliculostellate cells which are thought to stimulate and support the endocrine cell populations.\\r\\n\\r\\nHormones secreted by the anterior pituitary are trophic hormones (Greek: trophe, nourishment)   and tropic hormones. Trophic hormones directly affect growth either as hyperplasia or hypertrophy on the tissue it is stimulating. Tropic hormones are named for their ability to act directly on target tissues or other endocrine glands to release hormones, causing numerous cascading physiological responses.[5]\\r\\n\\r\\n[7][8]\\r\\n\\r\\nHormone secretion from the anterior pituitary gland is regulated by hormones secreted by the hypothalamus. Neuroendocrine cells in the hypothalamus project axons to the median eminence, at the base of the brain. At this site, these cells can release substances into small blood vessels that travel directly to the anterior pituitary gland (the hypothalamo-hypophyseal portal vessels).\\r\\n\\r\\nAside from hypothalamic control of the anterior pituitary, other systems in the body have been shown to regulate the anterior pituitarys function. GABA can either stimulate or inhibit the secretion of luteinizing hormone (LH) and growth hormone (GH) and can stimulate the secretion of thyroid-stimulating hormone (TSH). Prostaglandins are now known to inhibit adrenocorticotropic hormone (ACTH) and also to stimulate TSH, GH and LH release.[9] GABA, through action with the hypothalamus, has been shown experimentally to influence the level of GH secretion. Clinical evidence supports the experimental findings of the excitatory and inhibitory effects GABA has on GH secretion, dependent on GABAs site of action within the hypothalamic-pituitary unit.[10]\\r\\n\\r\\nThe homeostatic maintenance of the anterior pituitary is crucial to our physiological well being. Increased plasma levels of TSH induce hyperthermia through a mechanism involving increased metabolism and cutaneous vasodilation. Increased levels of LH also result in hypothermia but through a decreased metabolism action. ACTH increase metabolism and induce cutaneous vasoconstriction, increased plasma levels also result in hyperthermia and  prolactin decreases with decreasing temperature values. follicle-stimulating hormone (FSH) also may cause hypothermia if increased beyond homeostatic levels through an increased metabolic mechanism only.[11]\\r\\n\\r\\nGonadotropes, primarily luteinising hormone (LH) secreted from the anterior pituitary stimulates the ovulation cycle in female mammals, whilst in the males, LH stimulates the synthesis of androgen which drives the ongoing will to mate together with a constant production of sperm.[5]\\r\\n\\r\\nMain article Hypothalamic-pituitary-adrenal axis\\r\\n\\r\\nThe anterior pituitary plays a role in stress response. Corticotropin releasing hormone (CRH) from the hypothalamus stimulates ACTH release in a cascading effect that ends with the production of glucocorticoids from the adrenal cortex.[5]\\r\\n\\r\\nHyperpituitarism is the condition where the pituitary secretes excessive amounts of hormones. This hypersecretion often results in the formation of a pituitary adenoma (tumour), which are benign apart from a tiny fraction. There are mainly three types of anterior pituitary tumors and their associated disorders. For example, acromegaly results from excessive secretion of growth hormone (GH) often being released by a pituitary adenoma. This disorder can cause disfigurement and possibly death[19] and can lead to gigantism, a hormone disorder shown in giants such as Andr the Giant, where it occurs before the epiphyseal plates in bones close in puberty.[12] The most common type of pituitary tumour is a prolactinoma which hypersecretes prolactin.[20] A third type of pituitary adenoma secretes excess ACTH, which in turn, causes an excess of cortisol to be secreted and is the cause of Cushing's disease.[12]\\r\\n\\r\\nHypopituitarism is characterized by a decreased secretion of hormones released by the anterior pituitary. For example, hypo-secretion of GH prior to puberty can be a cause of dwarfism. In addition,  secondary adrenal insufficiency can be caused by hypo-secretion of ACTH which, in turn, does not signal the adrenal cortex to produce a sufficient amount  of cortisol.  This is a life-threatening condition. Hypopituitarism could be caused by the destruction or removal of the anterior pituitary tissue through traumatic brain injury, tumor, tuberculosis, or syphilis, among other causes. This disorder used to be referred to as Simmonds' disease but now according to the Diseases Database it is called Sheehan syndrome.[21] If the hypopituitarism is caused by the blood loss associated with childbirth, the disorder is referred to as Sheehan syndrome.\\r\\n\\r\\nThe anterior pituitary is also known as the adenohypophysis, meaning \\"glandular undergrowth\\", from the Greek adeno- (\\"gland\\"), hypo (\\"under\\"), and physis (\\"growth\\").\\r\\n\\r\\nThe anterior pituitary is the anterior, glandular lobe of the pituitary gland.","input":"What controls hormone release from the anterior pituitary gland?"},{"output":"Adam and Eve's rebellion in Eden","context":"\\r\\n\\r\\n\\r\\nOriginal sin, also called ancestral sin,[1] is a Christian belief of the state of sin in which humanity exists since the fall of man, stemming from Adam and Eve's rebellion in Eden, namely the sin of disobedience in consuming the forbidden fruit from the tree of the knowledge of good and evil.[2] This condition has been characterized in many ways, ranging from something as insignificant as a slight deficiency, or a tendency toward sin yet without collective guilt, referred to as a \\"sin nature\\", to something as drastic as total depravity or automatic guilt of all humans through collective guilt.[3]\\r\\n\\r\\nThe concept of original sin was first alluded to in the 2nd century by Irenaeus, Bishop of Lyon in his controversy with certain dualist Gnostics.[4] Other church fathers such as Augustine also developed the doctrine,[2] seeing it as based on the New Testament teaching of Paul the Apostle (Romans 5:12ÿ21 and 1 Corinthians 15:21-22) and the Old Testament verse of Psalms 51:5.[5][6][7][8][9] Tertullian, Cyprian, Ambrose and Ambrosiaster considered that humanity shares in Adam's sin, transmitted by human generation. Augustine's formulation of original sin was popular among Protestant reformers, such as Martin Luther and John Calvin, who equated original sin with concupiscence (or \\"hurtful desire\\"), affirming that it persisted even after baptism and completely destroyed freedom, although Augustine said that free will was weakened but not destroyed by original sin.[2] The Jansenist movement, which the Catholic Church declared to be heretical, also maintained that original sin destroyed freedom of will.[10] Instead the Catholic Church declares \\"Baptism, by imparting the life of Christ's grace, erases original sin and turns a man back towards God, but the consequences for nature, weakened and inclined to evil, persist in man and summon him to spiritual battle.\\"[11] \\"Weakened and diminished by Adam's fall, free will is yet not destroyed in the race.\\"[12]\\r\\n\\r\\nThe doctrine of ancestral fault (? ??϶ϫ progonikon hamartema), i.e. the sins of the forefathers leading to punishment of their descendants, was presented as a tradition of immemorial antiquity in ancient Greek religion by Celsus in his True Doctrine, a polemic attacking Christianity.\\r\\nCelsus is quoted as attributing to \\"a priest of Apollo or of Zeus\\" the saying that \\"the mills of the gods grind slowly, even to children's children, and to those who are born after them\\".[13] The idea of divine justice taking the form of collective punishment is also ubiquitous in the Hebrew Bible.[14]\\r\\n\\r\\nSt Paul's idea of redemption hinged upon the contrast between the sin of Adam and the death and resurrection of Jesus. \\"Therefore, just as sin entered the world through one man, and death through sin, and in this way death came to all people, because all sinned.\\"[15] \\"For as in Adam all die, so in Christ all will be made alive.\\"[16] Up till then the transgression in the Garden of Eden had not been given great significance. According to the Jesus scholar Geza Vermes:\\r\\n\\r\\nPaul believed that Adam's transgression in a mysterious way affected the nature of the human race. The primeval sin, a Pauline creation with no biblical or post-biblical Jewish precedent, was irreparable by ordinary human effort.[17]\\r\\n\\r\\nThe formalized Christian doctrine of original sin was first developed in the 2nd century by Irenaeus, the Bishop of Lyon, in his struggle against Gnosticism.[2] Irenaeus contrasted their doctrine with the view that the Fall was a step in the wrong direction by Adam, with whom, Irenaeus believed, his descendants had some solidarity or identity.[18]  However, Irenaeus did not believe that Adam's sin had tremendously grave consequences for humanity as the later tradition would hold, nor that his sin was the source of universal human sinfulness.[19] That all human beings participate in Adam's sin and share his guilt are totally foreign concepts for Irenaeus; Adam's sin belonged to Adam alone. Adam in his transgression is likened to a child who merely partook of the tree ahead of his time.[20] For Irenaeus, knowing good and evil was an integral aspect of human nature; the 'sin' of Adam was snatching at the fruit of the tree rather than waiting for it as a gift from God.[21]\\r\\n\\r\\nOther Greek Fathers would come to emphasize the cosmic dimension of the Fall, namely that since Adam human beings are born into a fallen world, but held fast to belief that man, though fallen, is free.[2] They thus did not teach that human beings are deprived of free will and involved in total depravity, which is one understanding of original sin among the leaders of the Reformation.[22][23] During this period the doctrines of human depravity and the inherently sinful nature of human flesh were taught by Gnostics, and orthodox Christian writers took great pains to counter them.[24][25] Christian apologists insisted that God's future judgment of humanity implied humanity must have the ability to live righteously.[26][27]\\r\\n\\r\\nHistorian Robin Lane Fox argues that the foundation of the doctrine of original sin as accepted by the Church was ultimately based on a mistranslation of Paul the Apostle's Epistle to the Romans  (Romans 5:12ÿ21) by Augustine, in his On the Grace of Christ, and on Original Sin\\".[28]\\r\\n\\r\\nThe original sin doctrine can be found fourth Book of Esdras, which refers Adam being responsible for the Fall of man whose offspring inherited the disease and evil.\\r\\n\\r\\nO Adam, what have you done? For though it was you who sinned, the fall was not yours alone, but ours also who are your descendants. 4 Esdras 7:48(118)[29]\\r\\n\\r\\nFor the first Adam, burdened with an evil heart, transgressed and was overcome, as were also all who were descended from him. Thus the disease became permanent; the law was in the hearts of the people along with the evil root; but what was good departed, and the evil remained.  4 Esdras 3:21-22[30]\\r\\n\\r\\nFor a grain of evil seed was sown in Adams heart from the beginning, and how much ungodliness it has produced until nowand will produce until the time of threshing comes!  4 Esdras 4:30[31]\\r\\n\\r\\nAugustine of Hippo (354ÿ430) taught that Adam's sin[32] is transmitted by concupiscence, or \\"hurtful desire\\",[33][34] resulting in humanity becoming a massa damnata (mass of perdition, condemned crowd), with much enfeebled, though not destroyed, freedom of will.[2] When Adam sinned, human nature was thenceforth transformed. Adam and Eve, via sexual reproduction, recreated human nature. Their descendants now live in sin, in the form of concupiscence, a term Augustine used in a metaphysical, not a psychological sense.[35] Augustine insisted that concupiscence was not a being but a bad quality, the privation of good or a wound.[36] He admitted that sexual concupiscence (libido) might have been present in the perfect human nature in paradise, and that only later it became disobedient to human will as a result of the first couple's disobedience to God's will in the original sin.[37] In Augustine's view (termed \\"Realism\\"), all of humanity was really present in Adam when he sinned, and therefore all have sinned. Original sin, according to Augustine, consists of the guilt of Adam which all humans inherit. Justo Gonzalez interprets Augustine's teaching that humans are utterly depraved in nature and grace is irresistible, results in conversion, and leads to perseverance.[38]\\r\\n\\r\\nAugustine articulated his explanation in reaction to Pelagianism, which insisted that humans have of themselves, without the necessary help of God's grace, the ability to lead a morally good life, and thus denied both the importance of baptism and the teaching that God is the giver of all that is good. Pelagius claimed that the influence of Adam on other humans was merely that of bad example. Augustine held that the effects of Adam's sin are transmitted to his descendants not by example but by the very fact of generation from that ancestor. A wounded nature comes to the soul and body of the new person from his/her parents, who experience libido (or concupiscence). Augustine's view was that human procreation was the way the transmission was being effected. He did not blame, however, the sexual passion itself, but the spiritual concupiscence present in human nature, soul and body, even after baptismal regeneration.[39] Christian parents transmit their wounded nature to children, because they give them birth, not the \\"re-birth\\".[40] Augustine used Ciceronian Stoic concept of passions, to interpret St. Paul's doctrine of universal sin and redemption. In that view, also sexual desire itself as well as other bodily passions were consequence of the original sin, in which pure affections were wounded by vice and became disobedient to human reason and will. As long as they carry a threat to the dominion of reason over the soul they constitute moral evil, but since they do not presuppose consent, one cannot call them sins. Humanity will be liberated from passions, and pure affections will be restored only when all sin has been washed away and ended, that is in the resurrection of the dead.[41][42]\\r\\n\\r\\nAugustine believed that unbaptized infants go to hell as a consequence of original sin.[43][44] The Latin Church Fathers who followed Augustine adopted his position, which became a point of reference for Latin theologians in the Middle Ages.[45] In the later medieval period, some theologians continued to hold Augustine's view, others held that unbaptized infants suffered no pain at all: unaware of being deprived of the beatific vision, they enjoyed a state of natural, not supernatural happiness. Starting around 1300, unbaptized infants were often said to inhabit the \\"limbo of infants\\".[46] The Catechism of the Catholic Church, 1261 declares: \\"As regards children who have died without Baptism, the Church can only entrust them to the mercy of God, as she does in her funeral rites for them. Indeed, the great mercy of God who desires that all men should be saved, and Jesus' tenderness toward children which caused him to say: 'Let the children come to me, do not hinder them',[47] allow us to hope that there is a way of salvation for children who have died without Baptism. All the more urgent is the Church's call not to prevent little children coming to Christ through the gift of holy Baptism.\\" But the theory of Limbo, while it \\"never entered into the dogmatic definitions of the Magisterium ... remains ... a possible theological hypothesis\\".[48]\\r\\n\\r\\nIn the works of John Cassian (c. 360 ÿ 435), Conference XIII recounts how the wise monk Chaeremon, of whom he is writing, responded to puzzlement caused by his own statement that \\"man even though he strive with all his might for a good result, yet cannot become master of what is good unless he has acquired it simply by the gift of Divine bounty and not by the efforts of his own toil\\" (chapter 1). In chapter 11, Cassian presents Chaeremon as speaking of the cases of Paul the persecutor and Matthew the publican as difficulties for those who say \\"the beginning of free will is in our own power\\", and the cases of Zaccheus and the good thief on the cross as difficulties for those who say \\"the beginning of our free will is always due to the inspiration of the grace of God\\", and as concluding: \\"These two then; viz., the grace of God and free will seem opposed to each other, but really are in harmony, and we gather from the system of goodness that we ought to have both alike, lest if we withdraw one of them from man, we may seem to have broken the rule of the Church's faith: for when God sees us inclined to will what is good, He meets, guides, and strengthens us: for 'At the voice of thy cry, as soon as He shall hear, He will answer thee'; and: 'Call upon Me', He says, 'in the day of tribulation and I will deliver thee, and thou shalt glorify Me'. And again, if He finds that we are unwilling or have grown cold, He stirs our hearts with salutary exhortations, by which a good will is either renewed or formed in us.\\"[49]\\r\\n\\r\\nCassian did not accept the idea of total depravity, on which Martin Luther was to insist.[50] He taught that human nature is fallen or depraved, but not totally. Augustine Casiday states that, at the same time, Cassian \\"baldly asserts that God's grace, not human free will, is responsible for 'everything which pertains to salvation' ÿ even faith\\".[51] Cassian pointed out that people still have moral freedom and one has the option to choose to follow God. Colm Luibhid says that, according to Cassian, there are cases where the soul makes the first little turn,[52] but in Cassian's view, according to Casiday, any sparks of goodwill that may exist, not directly caused by God, are totally inadequate and only direct divine intervention ensures spiritual progress;[53] and Lauren Pristas says that \\"for Cassian, salvation is, from beginning to end, the effect of God's grace\\".[54]\\r\\n\\r\\nOpposition to Augustine's ideas about original sin, which he had developed in reaction to Pelagianism, arose rapidly.[55] After a long and bitter struggle several councils, especially the Second Council of Orange in 529, confirmed the general principles of Augustine's teaching within Western Christianity.[2] However, while the western Church condemned Pelagius, it did not endorse Augustine entirely[56] and, while Augustine's authority was accepted, he was interpreted in the light of writers such as Cassian.[57] Some of the followers of Augustine identified original sin with concupiscence[58] in the psychological sense, but Saint Anselm of Canterbury challenged this identification in the 11th-century, defining original sin as \\"privation of the righteousness that every man ought to possess\\", thus separating it from concupiscence. In the 12th century the identification of original sin with concupiscence was supported by Peter Lombard and others,[2] but was rejected by the leading theologians in the next century, most notably by Thomas Aquinas. Aquinas distinguished the supernatural gifts of Adam before the Fall from what was merely natural, and said that it was the former that were lost, privileges that enabled man to keep his inferior powers in submission to reason and directed to his supernatural end. Even after the fall, man thus kept his natural abilities of reason, will and passions. Rigorous Augustine-inspired views persisted among the Franciscans, though the most prominent Franciscan theologians, such as Duns Scotus and William of Ockham, eliminated the element of concupiscence and identified original sin with the loss of sanctifying grace.\\r\\n\\r\\nEastern Orthodox theology has questioned Western Christianity's ideas on original sin from the outset and does not promote the idea of inherited guilt.[59]\\r\\n\\r\\nMartin Luther (1483ÿ1546) asserted that humans inherit Adamic guilt and are in a state of sin from the moment of conception. The second article in Lutheranism's Augsburg Confession presents its doctrine of original sin in summary form:\\r\\n\\r\\nIt is also taught among us that since the fall of Adam all men who are born according to the course of nature are conceived and born in sin. That is, all men are full of evil lust and inclinations from their mothers' wombs and are unable by nature to have true fear of God and true faith in God. Moreover, this inborn sickness and hereditary sin is truly sin and condemns to the eternal wrath of God all those who are not born again through Baptism and the Holy Spirit. Rejected in this connection are the Pelagians and others who deny that original sin is sin, for they hold that natural man is made righteous by his own powers, thus disparaging the sufferings and merit of Christ.[60]\\r\\n\\r\\nLuther, however, also agreed with the Roman Catholic doctrine of the Immaculate Conception (that Mary was conceived free from original sin) by saying:\\r\\n\\r\\n[Mary] is full of grace, proclaimed to be entirely without sin. God's grace fills her with everything good and makes her devoid of all evil. God is with her, meaning that all she did or left undone is divine and the action of God in her. Moreover, God guarded and protected her from all that might be hurtful to her.[61]\\r\\n\\r\\nProtestant Reformer John Calvin (1509ÿ1564) developed a systematic theology of Augustinian Protestantism by interpretation of Augustine of Hippo's notion of original sin. Calvin believed that humans inherit Adamic guilt and are in a state of sin from the moment of conception. This inherently sinful nature (the basis for the Calvinistic doctrine of \\"total depravity\\") results in a complete alienation from God and the total inability of humans to achieve reconciliation with God based on their own abilities. Not only do individuals inherit a sinful nature due to Adam's fall, but since he was the federal head and representative of the human race, all whom he represented inherit the guilt of his sin by imputation. Redemption by Jesus Christ is the only remedy.\\r\\n\\r\\nJohn Calvin defined original sin in his Institutes of the Christian Religion as follows:\\r\\n\\r\\nOriginal sin, therefore, seems to be a hereditary depravity and corruption of our nature, diffused into all parts of the soul, which first makes us liable to God's wrath, then also brings forth in us those works which Scripture calls \\"works of the flesh\\" (Gal 5:19). And that is properly what Paul often calls sin. The works that come forth from it ÿ such as adulteries, fornications, thefts, hatreds, murders, carousings ÿ he accordingly calls \\"fruits of sin\\" (Gal 5:19ÿ21), although they are also commonly called \\"sins\\" in Scripture, and even by Paul himself.[62]\\r\\n\\r\\nThe Council of Trent (1545ÿ1563), while not pronouncing on points disputed among Catholic theologians, condemned the teaching that in baptism the whole of what belongs to the essence of sin is not taken away, but is only cancelled or not imputed, and declared the concupiscence that remains after baptism not truly and properly \\"sin\\" in the baptized, but only to be called sin in the sense that it is of sin and inclines to sin.[63]\\r\\n\\r\\nIn 1567, soon after the close of the Council of Trent, Pope Pius V went beyond Trent by sanctioning Aquinas's distinction between nature and supernature in Adam's state before the Fall, condemned the identification of original sin with concupiscence, and approved the view that the unbaptized could have right use of will.[2] The Catholic Encyclopedia refers: \\"Whilst original sin is effaced by baptism concupiscence still remains in the person baptized; therefore original sin and concupiscence cannot be one and the same thing, as was held by the early Protestants (see Council of Trent, Sess. V, can. v).\\".[64]\\r\\n\\r\\nThe Catechism of the Catholic Church says:\\r\\n\\r\\nBy his sin Adam, as the first man, lost the original holiness and justice he had received from God, not only for himself but for all humans.\\r\\n\\r\\nAdam and Eve transmitted to their descendants human nature wounded by their own first sin and hence deprived of original holiness and justice; this deprivation is called \\"original sin\\".\\r\\n\\r\\nAs a result of original sin, human nature is weakened in its powers, subject to ignorance, suffering and the domination of death, and inclined to sin (this inclination is called \\"concupiscence\\").[65]\\r\\n\\r\\nSt. Anselm refers: \\"the sin of Adam was one thing but the sin of children at their birth is quite another, the former was the cause, the latter is the effect\\"[66] In a child original sin is distinct from the fault of Adam, it is one of its effects. The effects of Adam's sin according to the Catholic Encyclopedia are:\\r\\n\\r\\nThe Catholic Church teaches that every human person born on this earth is made in the image of God.[67][68] Within man \\"is both the powerful surge toward the good because we are made in the image of God, and the darker impulses toward evil because of the effects of Original Sin\\".[69] Furthermore, it explicitly denies that we inherit guilt from anyone, maintaining that instead we inherit our fallen nature. In this it differs from the Calvinist position that each person actually inherits Adam's guilt, and teaches instead that \\"original sin does not have the character of a personal fault in any of Adam's descendants ... but the consequences for nature, weakened and inclined to evil, persist in man\\".[70] \\"In other words, human beings do not bear any 'original guilt' from Adam and Eve's particular sin.\\"[71]\\r\\n\\r\\nThe Church has always held baptism to be for the remission of sins including the original sin, and, as mentioned in Catechism of the Catholic Church, 403, infants too have traditionally been baptized, though not guilty of any actual personal sin. The sin that through baptism is remitted for them could only be original sin. Baptism confers original sanctifying grace which erases original sin and any actual personal sin. The first comprehensive theological explanation of this practice of baptizing infants, guilty of no actual personal sin, was given by Saint Augustine of Hippo, not all of whose ideas on original sin have been adopted by the Catholic Church. Indeed, the Church has condemned the interpretation of some of his ideas by certain leaders of the Protestant Reformation.\\r\\n\\r\\nThe Catechism of the Catholic Church explains that in \\"yielding to the tempter, Adam and Eve committed a personal sin, but this sin affected the human nature that they would then transmit in a fallen state ... original sin is called \\"sin\\" only in an analogical sense: it is a sin \\"contracted\\" and not \\"committed\\"a state and not an act\\" (Catechism of the Catholic Church, 404). This \\"state of deprivation of the original holiness and justice ... transmitted to the descendants of Adam along with human nature\\" (Compendium of the Catechism of the Catholic Church, 76) involves no personal responsibility or personal guilt on their part (cf. Catechism of the Catholic Church, 405). Personal responsibility and guilt were Adam's, who because of his sin, was unable to pass on to his descendants a human nature with the holiness with which it would otherwise have been endowed, in this way implicating them in his sin. The doctrine of original sin thus does not impute the sin of the father to his children, but merely states that they inherit from him a \\"human nature deprived of original holiness and justice\\", which is \\"transmitted by propagation to all mankind\\".[72]\\r\\n\\r\\nIn the theology of the Catholic Church, original sin is the absence of original holiness and justice into which humans are born, distinct from the actual sins that a person commits. The absence of sanctifying grace or holiness in the new-born child is an effect of the first sin, for Adam, having received holiness and justice from God, lost it not only for himself but also for us.[64] This teaching explicitly states that \\"original sin does not have the character of a personal fault in any of Adam's descendants\\".[70] In other words, human beings do not bear any \\"original guilt\\" from Adam's particular sin, which is his alone. The prevailing view, also held in Eastern Orthodoxy, is that human beings bear no guilt for the sin of Adam. The Catholic Church teaches: \\"By our first parents' sin, the devil has acquired a certain domination over man, even though man remains free.\\"[73]\\r\\n\\r\\nThe Catholic doctrine of the Immaculate Conception of Mary is that Mary was conceived free from original sin: \\"the most Blessed Virgin Mary was, from the first moment of her conception, by a singular grace and privilege of almighty God and by virtue of the merits of Jesus Christ, Savior of the human race, preserved immune from all stain of original sin\\".[74] The doctrine sees her as an exception to the general rule that human beings are not immune from the reality of original sin.\\r\\n\\r\\nSoon after the Second Vatican Council, biblical theologian Herbert Haag raised the question: Is original sin in Scripture?[75] According to his exegesis, Genesis 2:25 would indicate that Adam and Eve were created from the beginning naked of the divine grace, an originary grace that, then, they would never have had and even less would have lost due to the subsequent events narrated. On the other hand, while supporting a continuity in the Bible about the absence of preternatural gifts (Latin: dona praeternaturalia)[76] with regard to the ophitic event, Haag never makes any reference to the discontinuity of the loss of access to the tree of life.\\r\\n\\r\\nThe Lutheran Churches teach that original sin \\"is a root and fountain-head of all actual sins.\\"[77] The stain of original sin is removed through the sacrament of baptism.[78]\\r\\n\\r\\nThe Eastern Orthodox version of original sin is the view that sin originates with the Devil, \\"for the devil sinneth from the beginning (1 John iii. 8)\\".[79] They acknowledge that the introduction of ancestral sin[80][better?source?needed] into the human race affected the subsequent environment for humanity (see also traducianism). However, they never accepted Augustine of Hippo's notions of original sin and hereditary guilt.[81][better?source?needed]\\r\\n\\r\\nOrthodox Churches accept the teachings of John Cassian, as do Catholic Churches eastern and western,[50] in rejecting the doctrine of total depravity, by teaching that human nature is \\"fallen\\", that is, depraved, but not totally. Augustine Casiday states that Cassian \\"baldly asserts that God's grace, not human free will, is responsible for 'everything which pertains to salvation' ÿ even faith\\".[51] Cassian points out that people still have moral freedom and one has the option to choose to follow God. Colm Luibhid says that, according to Cassian, there are cases where the soul makes the first little turn,[52] while Augustine Casiday says that, in Cassian's view, any sparks of goodwill that may exist, not directly caused by God, are totally inadequate and only direct divine intervention ensures spiritual progress.[53] and Lauren Pristas says that \\"for Cassian, salvation is, from beginning to end, the effect of God's grace\\".[54]\\r\\n\\r\\nEastern Orthodoxy accepts the doctrine of ancestral sin: \\"Original sin is hereditary. It did not remain only Adam and Eve's. As life passes from them to all of their descendants, so does original sin.\\"[82] \\"As from an infected source there naturally flows an infected stream, so from a father infected with sin, and consequently mortal, there naturally proceeds a posterity infected like him with sin, and like him mortal.\\"[83]\\r\\n\\r\\nThe Orthodox Church in America makes clear the distinction between \\"fallen nature\\" and \\"fallen man\\" and this is affirmed in the early teaching of the Church whose role it is to act as the catalyst that leads to true or inner redemption. Every human person born on this earth bears the image of God undistorted within themselves.[84] In the Orthodox Christian understanding, they explicitly deny that humanity inherited guilt from anyone. Rather, they maintain that we inherit our fallen nature. While humanity does bear the consequences of the original, or first, sin, humanity does not bear the personal guilt associated with this sin. Adam and Eve are guilty of their willful action; we bear the consequences, chief of which is death.\\"[85]\\r\\n\\r\\nThe view of the Eastern Orthodox Church varies on whether Mary is free of all actual sin or concupiscence. Some Patristic sources imply that she was cleansed from sin at the Annunciation, while the liturgical references are unanimous that she is all-holy from the time of her conception.[86][87]\\r\\n\\r\\nThe original formularies of the Church of England also continue in the Reformation understanding of original sin. In the Thirty-Nine Articles, Article IX \\"Of Original or Birth-sin\\" states:\\r\\n\\r\\nOriginal Sin standeth not in the following of Adam, (as the Pelagians do vainly talk); but it is the fault and corruption of the Nature of every man, that naturally is ingendered of the offspring of Adam; whereby man is very far gone from original righteousness, and is of his own nature inclined to evil, so that the flesh lusteth always contrary to the spirit; and therefore in every person born into this world, it deserveth God's wrath and damnation. And this infection of nature doth remain, yea in them that are regenerated; whereby the lust of the flesh, called in the Greek, ϫ ϫϰ?, which some do expound the wisdom, some sensuality, some the affection, some the desire, of the flesh, is not subject to the Law of God. And although there is no condemnation for them that believe and are baptized, yet the Apostle doth confess, that concupiscence and lust hath of itself the nature of sin.[88]\\r\\n\\r\\nHowever, more recent doctrinal statements (e.g. the 1938 report Doctrine in the Church of England) permit a greater variety of understandings of this doctrine. The 1938 report summarizes:\\r\\n\\r\\nMan is by nature capable of communion with God, and only through such communion can he become what he was created to be. \\"Original sin\\" stands for the fact that from a time apparently prior to any responsible act of choice man is lacking in this communion, and if left to his own resources and to the influence of his natural environment cannot attain to his destiny as a child of God.[89]\\r\\n\\r\\nThe Methodist Church upholds Article VII in the Articles of Religion in the Book of Discipline of the United Methodist Church:\\r\\n\\r\\nOriginal sin standeth not in the following of Adam (as the Pelagians do vainly talk), but it is the corruption of the nature of every man, that naturally is engendered of the offspring of Adam, whereby man is very far gone from original righteousness, and of his own nature inclined to evil, and that continually.[90]\\r\\n\\r\\nMethodist theology teaches that a believer is made free from original sin when he/she is entirely sanctified:[91]\\r\\n\\r\\nWe believe that entire sanctification is that act of God, subsequent to regeneration, by which believers are made free from original sin, or depravity, and brought into a state of entire devotement to God, and the holy obedience of love made perfect. It is wrought by the baptism with or infilling of the Holy Spirit, and comprehends in one experience the cleansing of the heart from sin and the abiding, indwelling presence of the Holy Spirit, empowering the believer for life and service. Entire sanctification is provided by the blood of Jesus, is wrought instantaneously by grace through faith, preceded by entire consecration; and to this work and state of grace the Holy Spirit bears witness.[91]\\r\\n\\r\\nSeventh-day Adventists believe that humans are inherently sinful due to the fall of Adam,[92] but they do not totally accept the Augustinian/Calvinistic understanding of original sin, taught in terms of original guilt, but hold more to what could be termed the \\"total depravity\\" tradition.[93] Seventh-day Adventists have historically preached a doctrine of inherited weakness, but not a doctrine of inherited guilt.[94] According to Augustine and Calvin, humanity inherits not only Adam's depraved nature but also the actual guilt of his transgression, and Adventists look more toward the Wesleyan model.[95]\\r\\n\\r\\nIn part, the Adventist position on original sin reads:\\r\\n\\r\\nThe nature of the penalty for original sin, i.e., Adam's sin, is to be seen as literal, physical, temporal, or actual death ÿ the opposite of life, i.e., the cessation of being. By no stretch of the scriptural facts can death be spiritualised as depravity. God did not punish Adam by making him a sinner. That was Adams own doing. All die the first death because of Adams sin regardless of their moral character ÿ children included.[95]\\r\\n\\r\\nEarly Adventists Pioneers (such as George Storrs and Uriah Smith) tended to de-emphasise the morally corrupt nature inherited from Adam, while stressing the importance of actual, personal sins committed by the individual. They thought of the \\"sinful nature\\" in terms of physical mortality rather than moral depravity.[95] Traditionally, Adventists look at sin in terms of willful transgressions, and that Christ triumphed over sin. \\r\\n\\r\\nThough believing in the concept of inherited sin from Adam, there is no dogmatic Adventist position on original sin.\\r\\n\\r\\nAccording to the theology of the Christian Congregation of Jehovah's Witnesses, all humans are born sinners, because of inheriting sin, corruption, and death from Adam. They teach that Adam was originally created perfect and sinless, but with free will; that the Devil, who was originally a perfect angel, but later developed feelings of pride and self-importance, seduced Eve, and then through her, persuaded Adam to disobey God, and to obey the Devil instead, rebelling against God's sovereignty, thereby making themselves sinners, and because of that, transmitting a sinful nature to all of their future offspring.[96][97] Instead of destroying the Devil right away, as well as destroying the disobedient couple, God decided to test the loyalty of the rest of humankind, and to prove that man cannot be independent of God successfully, that man is lost without God's laws and standards, and can never bring peace to the earth, and that Satan was a deceiver, murderer, and liar.[98]\\r\\n\\r\\nJehovah's Witnesses believe that all men possess \\"inherited sin\\" from the \\"one man\\" Adam and they teach that verses such as Romans 5:12-22, Psalm 51:5, Job 14:4, and 1st Corinthians 15:22 show that man is born corrupt, and dies because of inherited sin and imperfection, that inherited sin is the reason and cause for sickness and suffering, made worse by the Devil's wicked influence. They believe Jesus is the \\"second Adam\\", being the sinless Son of God and the Messiah, and that he came to undo Adamic sin; and that salvation and everlasting life can only be obtained through faith and obedience to the second Adam.[96][97][98][99][100][101] They believe that \\"sin\\" is \\"missing the mark\\" of God's standard of perfection, and that everyone is born a sinner, due to being the offspring of sinner Adam.[102]\\r\\n\\r\\nThe Book of Mormon, a text sacred to members of The Church of Jesus Christ of Latter-day Saints, explains that the opportunity to live here in a world where we can learn good and bad is a gift from God, and not a punishment for Adam's and Eve's choice.[103] As the Church's founder Joseph Smith taught, humans had an essentially godlike nature, and were not only holy in a premortal state, but had the potential to progress eternally to become like God.[104] He wrote as one of his church's Articles of Faith, \\"We believe that men will be punished for their own sins, and not for Adams transgression.\\"[105] Overtime Latter-day Saints took this creed as a rejection of the doctrine of original sin and any notion of inherited sinfulness.[104] Thus, while modern members of The Church of Jesus Christ of Latter-day Saints will agree that the fall of Adam brought consequences to the world, including the possibility of sin, they generally reject the idea that any culpability is automatically transmitted to Adam and Eve's offspring.[106] Children under the age of eight are regarded as free of all sin and therefore do not require baptism.[107] Children who die prior to age eight are believed to be saved in the highest degree of heaven.[108]\\r\\n\\r\\nIn Swedenborgianism, exegesis of the first 11 chapters of Genesis from The First Church, has a view that Adam is not an individual person. Rather, he is a symbolic representation of the \\"Most Ancient Church\\", having a more direct contact with heaven than all other successive churches.[109][110] Swedenborg's view of original sin is referred to as hereditary evil, which passes from generation to generation.[111] It cannot be completely abolished by an individual man, but can be tempered when someone reforms their own life,[112] and are thus held accountable only for their own sins.[113]\\r\\n\\r\\nMost Quakers (also known as the Religious Society of Friends), including the founder of Quakerism, George Fox, believe in the doctrine of Inward light, a doctrine which states that there is \\"that of God in everyone\\".[114] This has led to a common belief among many liberal and universalist Quakers affiliated with the Friends General Conference and Britain Yearly Meeting, based on the ideas of Quaker Rufus Jones among others, that rather than being burdened by original sin, human beings are inherently good, and the doctrine of universal reconciliation, that is, that all people will eventually be saved and reconciled with God.\\r\\n\\r\\nHowever, this rejection of the doctrine of original sin or the necessity of salvation is not something that most conservative or evangelical Quakers affiliated with Friends United Meeting or Evangelical Friends Church International tend to agree with. Although the more conservative and evangelical Quakers also believe in the doctrine of inward light, they interpret it in a manner consistent with the doctrine of original sin, namely, that people may or may not listen to the voice of God within them and be saved, and people who do not listen will not be saved.\\r\\n\\r\\nThe doctrine of \\"inherited sin\\" is not found in most of mainstream Judaism. Although some in Orthodox Judaism place blame on Adam and Eve for overall corruption of the world, and though there were some Jewish teachers in Babylon[115] who believed that mortality was a punishment brought upon humanity on account of Adam's sin, that is not the dominant view in most of Judaism today. Modern Judaism generally teaches that humans are born sin-free and untainted, and choose to sin later and bring suffering to themselves.[116]\\r\\n\\r\\nJewish theologians are divided in regard to the cause of what is called \\"original sin\\". Others teach that it was due to Adam's yielding to temptation in eating of the forbidden fruit and has been inherited by his descendants; the majority of chazalic opinions, however, do not hold Adam responsible for the sins of humanity,[117] teaching that, in Genesis 8:21 and 6:5-8, God recognized that Adam did not willfully sin. However, Adam is recognized by some[115] as having brought death into the world by his disobedience. Because of his sin, his descendants will live a mortal life, which will end in death of their bodies.[118] According to book Legends of the Jews, in Judgement Day, Adam will disavow any complaints of all men who accuse him as the cause of death of every human on earth. Instead, Adam will reproach their mortality because of their sins.[119]\\r\\n\\r\\nThe concept of inherited sin does not exist in Islam.[120][121] Islam teaches that Adam and Eve sinned, but then sought forgiveness and thus were forgiven by God.[122][123] Quotes from the Qur'an:\\r\\n\\r\\nBut Satan caused them to slip out of it and removed them from that [condition] in which they had been. And We said, \\"Go down, [all of you], as enemies to one another, and you will have upon the earth a place of settlement and provision for a time.\\" Then Adam received from his Lord [some] words, and He accepted his repentance. Indeed, it is He who is the Accepting of repentance, the Merciful.\\r\\nThey said: \\"Our Lord, we have wronged ourselves souls. If You forgive us not and bestow not upon us Your mercy, we shall certainly be of the losers.\\r\\nThus did Adam disobey his Lord, so he went astray. Then his Lord chose him, and turned to him with forgiveness, and gave him guidance.\\r\\nThe Qur'an further says about individual responsibility:[124]\\r\\n\\r\\nThat no burdened person (with sins) shall bear the burden (sins) of another. And that man can have nothing but what he does (of good and bad). And that his deeds will be seen, Then he will be recompensed with a full and the best [fair] recompense.","input":"What was the original sin in the bible?"},{"output":"Anna Chandy","context":"Justice Anna Chandy (1905-1996), also known as Anna Chandi, was the first female judge in India and also the first woman in India to become a high court judge. In fact, she was the first woman judge in the entire Anglo-Saxon world[1], decades before Elizabeth Lane.[1]\\r\\nAnna Chandy was born in 1905 and raised in Trivandrum. She was a Syrian Christian. After obtaining a post-graduate degree in 1926, she then became the first woman in her state to get a law degree. She practised as a barrister from 1929 while simultaneously promoting the cause of women's rights, most notably in Shrimati, a magazine that she both founded and edited.[2]\\r\\nOften described as a \\"first generation feminist\\",[2][3] Chandy campaigned for election to the Shree Mulam Popular Assembly in 1931. She met with hostility from both her competition and newspapers[4] but was elected for the period 1932-34.\\r\\nChandy was appointed as a munsif in Travancore by Sir C.P. Ramaswami Iyer, the Dewan of Travancore, in 1937. This made her the first female judge in India and, in 1948, she was raised to the position of District Judge.[2][5] She became the first female judge in an Indian high court when she was appointed to the Kerala High Court on 9 February 1959. She remained in that office until 5 April 1967.[6]\\r\\nIn her retirement, Chandy served on the Law Commission of India and also wrote an autobiography titled Atmakatha (1973). She died in 1996.[2]\\r\\n((1. http://keralawomen.gov.in/view_page.php?type=11&id=262))","input":"Who was the first lady magistrate of india?"},{"output":"Zion, Illinois","context":"Cancer Treatment Centers of America (CTCA), headquartered in Boca Raton, Florida, is a national, for-profit network of five hospitals that serves cancer patients throughout the United States. CTCA follows an integrative approach to cancer care that uses conventional approaches like surgery, chemotherapy, radiation and immunotherapy to treat the cancer, while also offering integrative therapies to help manage side effects like pain, nausea, fatigue, lymphedema, malnutrition, depression and anxiety.\\r\\nCTCA was originally headquartered in Schaumburg, Illinois. In January 2015, the corporate office was moved to Boca Raton, Florida, and was renamed Cancer Treatment Centers of America Global, Inc.[1]\\r\\n\\r\\n\\r\\nCTCA was founded by Richard J Stephenson after his mother, who had cancer, died. Stephenson was not satisfied with the treatment options which were then available to his mother and opened the first CTCA hospital in 1988.[2] The first hospital to open was CTCA at Midwestern Regional Medical Center (Midwestern) in Zion, Illinois. Four other hospitals opened between 2005 and 2012.\\r\\nCTCA opened the organizations first international patient concierge and information office in the Lomas de Chapultepec neighborhood of Mexico City on April 20, 2015. CTCA also maintains an active brand presence in the Middle East, the Caribbean and Latin America, offering patients in these regions the opportunity to pursue treatment at one of the hospital systems five U.S. cancer centers:\\r\\nCTCA hospitals have earned Full Standards Compliance from the Joint Commission, as well as the Top Performer on Key Quality Measures and the Magnet Award.[4][5][6][7][8] CTCA has also been recognized for strong patient satisfaction scores, with four CTCA hospitals (Eastern, Midwestern, Southeastern and Southwestern) earning Five Star quality ratings by the U.S. Centers for Medicare & Medicaid Services (CMS) and recognition by various leading health care organizations, including the Association of Community Cancer Centers and the American College of Radiology.\\r\\nAnother accreditation comes from the National Accreditation Program for Breast Centers, which has awarded three-year full accreditations for the breast programs at four CTCA hospitals (Southwestern, Eastern, Western and Midwestern). The NABPC has established 27 standards that must be met, including: breast center leadership, research, community outreach, professional education, clinical management and quality improvement.\\r\\nCancer Treatment Centers of America was the subject of a Federal Trade Commission (FTC) complaint in 1993. The FTC alleged that CTCA made false claims regarding the success rates of certain cancer treatments in CTCA's marketing and promotional materials. This claim was settled in March 1996, requiring CTCA to discontinue use of any unsubstantiated claims in its advertising.[9] CTCA is also required to have proven, scientific evidence for all statements regarding the safety, success rates, endorsements, and benefits of its cancer treatments. CTCA was also required to follow various steps in order to report compliance to the FTC per the settlement.\\r\\nA 2013 Reuters special report stated that CTCA continues to make misleading survival rate claims on its website. Reuters asked cancer experts to review CTCA's claims that its survival rates were better than national averages. CTCA compared its outcomes with the National Cancer Institute's Surveillance, Epidemiology, and End Results (SEER) database. The experts said that CTCA's patients and SEER's patients were not compatible, and that the comparison was biased in favor of CTCA. For example, CTCA's patients are younger, wealthier, better-insured, and more likely to be diagnosed early. Reuters said that CTCA screens patients for income and ability to pay, and refuses those who are on Medicare, Medicaid, or uninsured.[10]\\r\\nIn 2001, the Food and Drug Administration (FDA) issued CTCA a Warning Letter concerning three clinical trials that were conducted in violation of FDA requirements.[11]\\r\\nL. Kirk Hagen, humanities professor at the University of Houston-Downtown, points out that in CTCA's Web site is a disclaimer that reads [The CTCA] makes no claims about the efficacy of specific treatments, the delivery of care, nor the meaning of the CTCA and SEER analysis.\\"[12]\\r\\nIn 2013, oncologist David Gorski, writing for Science Blogs, published an article that criticized CTCA for using pseudoscientific treatments (e.g., homeopathy) in addition to mainstream treatments. He stated that some \\"otherwise talented doctors\\" are now \\"complicit in the blurring of the line between science and pseudoscience in medicine while believing that they are doing good for the patient by giving them 'holistic care'. \\"[13]","input":"Where are cancer treatment centers of america located?"},{"output":"nineteen","context":"Arsenal Football Club is an English professional football club based in Holloway, North London. The club's first European football match was played against Copenhagen XI on 25 September 1963, and it has since participated in European club competitions on several occasions, most of which organised by the Union of European Football Associations (UEFA). Arsenal has won two European honours: the Inter-Cities Fairs Cup in 1970 and the Cup Winners' Cup in 1994 ÿ the latter title recognised by the European confederation. The club played the 1994 European Super Cup and repeated its presence in the following year's Cup Winners' Cup final. Arsenal also reached the final of the UEFA Cup in 2000, and became the first London team to appear in a UEFA Champions League final, in 2006.\\r\\nQualification for European club competitions is determined by a team's position in its domestic league, as well as how successfully a team fares in domestic cup competitions in the previous season. Following the Heysel Stadium disaster in 1985, UEFA placed an indefinite ban on all English teams from competing in Europe; the ban was lifted in the 1990-91 season and Arsenal entered in 1991ÿ92 season, giving Arsenal the opportunity to play in the European Cup. Between 1998ÿ99 and 2016ÿ17, Arsenal qualified in nineteen successive UEFA Champions League seasons, an English football record, and is only surpassed in Europe by Real Madrid.\\r\\nFrench striker Thierry Henry holds the club record for most appearances with 89, and is the club's record goalscorer in European competitions with 42 goals. Arsenal's biggest winning margin in Europe is a 7ÿ0 scoreline, a feat achieved twice: firstly away at Standard Lige, during their successful Cup Winners' Cup campaign, and secondly at home against Slavia Prague, for the 2007ÿ08 UEFA Champions League. Arsenal hold the European club competition record for the most consecutive clean sheets with ten, set between September 2005 and May 2006.\\r\\n\\r\\n\\r\\nClub competitions between teams from different European countries can trace their origins as far back as 1897, when the Challenge Cup was created for clubs in the Austro-Hungarian Empire, who did not meet under normal circumstances. The Sir Thomas Lipton Trophy, named after entrepreneur and sportsman Thomas Lipton, was established in 1909 and was contested between clubs from Italy, Great Britain, Germany and Switzerland; the competition lasted for two years.[1] The earliest attempt to create a cup for national champion clubs of Europe was made by Swiss club FC Servette. Founded in 1930, the Coupe des Nations featured clubs of ten major European football leagues and was deemed a success. Due to financial reasons, the competition was abandoned.[2]\\r\\nIn December 1954, French sports magazine L'Equipe published an article by journalist and former professional footballer Gabriel Hanot, who proposed the introduction of a European club competition.[4] He initially suggested that each country should nominate a club to play in a mid-week European league; many clubs favoured a cup competition, which required less matches to play.[4] A year later, L'Equipe sent out invitations to 18 clubs, selected by Hanot, Jacques Ferran and Jacques Goddet, with UEFA agreeing to administrate the competition named as the European Champion Clubs' Cup.[5] The European Cup Winners' Cup, later retitled the UEFA Cup Winners' Cup, was founded in 1960 and involved the winning clubs of national cup competitions in Europe. Arsenal, in the First Division at the time, were ineligible for both competitions, given that the club did not win a league championship or domestic cup for almost two decades.[6] They however were invited to participate in the Inter-Cities Fairs Cup, an annual European club competition which was set up to promote international trade fairs; where a club finished in their domestic league had no relevance to qualification as teams were selected from cities holding trade fairs. The Inter-Cities Fairs Cup was regarded as the predecessor to the UEFA Cup, rebranded as the UEFA Europa League in 2008.[7] Each competition round was staged over a two-legged tie, with the winner determined by the aggregate score. The away goals rule is activated if the aggregate score is equal.[8]\\r\\nTo reinvigorate the European Champion Clubs' Cup, the competition was expanded and rebranded as the UEFA Champions League in 1992. From the 1997ÿ98 season, it was further expanded to include eight domestic league runners-up selected by a UEFA coefficient and preliminary spots the following season were awarded to the third placed team; in some leagues fourth from 2002ÿ03. The expansion and constant growth of the competition led to the decline of the Cup Winners' Cup, abolished in 1999 and by which point instigated proposals for a European Super League. Arsne Wenger has, on numerous occasions predicted the latter,[9][10] arguing the pressure of television companies will force it to happen: \\"It's all about money. More games equal more money through TV revenue and I think the next few years will see not just two, but three or four teams from the top countries competing against each other. It's what television wants ÿ big teams in big matches. That is why the Champions' League was introduced.\\"[11] Although Arsenal qualified for a fifteenth successive season of Champions League football in May 2012, this coincided with the club not winning a domestic honour since 2005, which led to open criticism over the competition's present format.[12] Wenger however has gone on to defend the club policy, stating a trophy for Arsenal is winning the Premier League or the Champions League; \\"Would you like to finish tenth in the league but win the League Cup and say you have won a trophy? Certainly not.\\"[13]\\r\\nArsenal first participated in European football during the 1963ÿ64 season, via the Inter-Cities Fairs Cup. The competition was set up to promote international trade fairs in European cities, featuring clubs from cities playing in matches that hosted trade fairs. As London's representative, Arsenal was paired with Copenhagen team Copenhagen XI in the first round, played over two matches.[14] The first match ended in a 7ÿ1 victory for Arsenal, with Geoff Strong and Joe Baker both scoring hat-tricks.[15] Copenhagen XI won the second match 3ÿ2, but lost 9ÿ4 on aggregate. Arsenal faced Royal Football Club de Lige in the second round; the Belgian club won 4ÿ2 on aggregate to progress into the quarter-finals.[16]\\r\\nIn the 1969ÿ70 season, Arsenal again participated in the Inter-Cities Fairs Cup, after a six-year absence. Having beaten Glentoran of Northern Ireland, Portugal's Sporting Lisbon and Rouen of France, Arsenal played Romanian club Dinamo Bac?u in the quarter-finals. A 1ÿ9 victory on aggregate saw the club progress into the last four, where they faced Ajax of Amsterdam.[17] The pairing of both clubs pleased Arsenal manager Bertie Mee, who wanted to play Ajax in the semi-finals to set up a possibility of meeting Internazionale in the final.[17] At Highbury in the first leg, Arsenal won 3ÿ0 and restricted Ajax to a 1ÿ0 win at the Olympisch Stadion to reach the final of the Fairs Cup.[18] It was the fourth successive year the final featured an English club and the first for a London club.[18] Arsenal played Belgian opposition Anderlecht in the 1970 Inter-Cities Fairs Cup Final, played in the space of a week. Anderlecht won the first leg 3ÿ1, with Arsenal midfielder Ray Kennedy scoring a crucial away goal, seven minutes from the final whistle.[19] An early goal scored by Eddie Kelly helped Arsenal to what earlier looked to be an improbable victory; John Radford and Jon Sammels overturned Anderlecht's advantage to win 3ÿ0 on the night and 4ÿ3 on aggregate.[20] The result ended Arsenal's 17-year wait for a trophy and ensured the club became the third successive English club to win the honour.[21]\\r\\nArsenal entered the Inter-Cities Fairs Cup the following season as holders of the competition, but did not progress further than the semi-finals, losing on away goals to 1. FC K?ln of Germany.[22] The club did however win the league championship for the first time in 18 years, ensuring qualification for the European Champions Clubs' Cup in the 1971ÿ72 season.[23] Arsenal reached the quarter-finals, where the team lost to holders Ajax, who went on to retain the trophy.[24]\\r\\nArsenal finished second in the 1972ÿ73 Football League but did not play in the UEFA Cup 1973ÿ74, because the Football League continued to apply the one-team-per-city rule from the old Fairs Cup, and Tottenham Hotspur qualified as League cup winners.[25] In subsequent seasons, the departure of Mee and lack of domestic honours meant that the club did not contest in European football.\\r\\nMee was succeeded by Terry Neill in July 1976. Arsenal returned to European club football in the 1978ÿ79 season, having finished fifth in the previous league campaign. The club contested in the UEFA Cup for the first time and won their opening leg 3ÿ0 against 1. FC Lokomotive Leipzig; a commanding performance away from home in the second leg allowed Arsenal to win 1ÿ4 at the Bruno-Plache-Stadion and 7ÿ1 on aggregate.[26] Arsenal progressed past the third round, winning on aggregate against Hajduk Split but were eliminated by Red Star Belgrade in the third round after striker Du?an Savi? scored an away goal, two minutes from the end of the match.[27]\\r\\nAs winners of the 1979 FA Cup Final, Arsenal entered the European Cup Winners' Cup in the 1979ÿ80 season. The club defeated Fenerbah?e, 1. FC Magdeburg and IFK G?teborg, before facing Juventus in the semi-finals. After conceding an early penalty scored by Antonio Cabrini, Arsenal defender David O'Leary was injured and substituted in the 20th minute, when Juventus striker Roberto Bettega tackled him.[28] Marco Tardelli was later sent off for a foul on Liam Brady and in the 85th minute, Arsenal managed to score an equaliser through a mix-up between Frank Stapleton and Bettega; the Italian put the ball into his goal net.[28] Neill in his post-match comments expressed his anger over Bettega's tackle after the game: \\"I was shocked by a most vicious foul. I was shocked because I have always had the greatest admiration for him.\\"[28] A headed goal by substitute Paul Vaessen two minutes from the end, in the second leg was enough to take Arsenal into the 1980 European Cup Winners' Cup Final, where they faced Valencia in Brussels.[29] A goalless draw after normal and extra time meant the final was to be decided on a penalty shootout, with Valencia winning 5ÿ4.[30]\\r\\nArsenal competed in the UEFA Cup in the 1981ÿ82 and 1982ÿ83 seasons and departed in the first and second round to FC Winterslag[31] and Spartak Moscow respectively. The Heysel Stadium disaster of May 1985, during the 1985 European Cup Final between Liverpool and Juventus resulted in UEFA, and later FIFA, imposing a 'worldwide' ban on English teams from participating in European club competitions, initially for an indefinite period.[32] Under George Graham, Arsenal returned to the European Cup in the 1991ÿ92 season, having won the league championship a season earlier.[33] They went out in the second round to Portuguese team Benfica in November 1991.[34] The ban arising from the Heysel disaster had prevented Arsenal from competing in the European Cup when they won the league title two years previously, as well as preventing them from competing in the UEFA Cup on two occasions.\\r\\nIn the 1993ÿ94 season, Arsenal contested in the European Cup Winners' Cup, having won the 1993 FA Cup Final. The club beat Odense BK and Standard Lige to reach the quarter-finals, with the latter described as a \\"breathtaking performance\\" by Graham, after winning 7ÿ0 at the Stade Maurice Dufrasne.[35] Arsenal defeated Torino of Italy and French representative Paris Saint-Germain to reach the 1994 European Cup Winners' Cup Final alongside Parma, staged at Copenhagen. Without top goalscorer Ian Wright and markers John Jensen and Martin Keown, Arsenal went into the final as outsiders.[36] Although Parma began the match the strongest of both teams, Arsenal opened the scoring through a well taken volley by striker Alan Smith. Defending in numbers, the team held on to record an improbable victory and win the club's second European trophy, after a 24-year wait.[37] After the match Graham praised his team's performance and defended his pragmatic approach; \\"Sometimes we could go forward a little bit more and entertain a bit more, but we play to our strengths, like we did in this match. There's nothing wrong with having a very, very good defence, believe me. We've proved it, and it's a big plus.\\"[38]\\r\\nAs holders of the competition, Arsenal was admitted into the Cup Winners' Cup for the 1994ÿ95 season. They moreover contested in the 1994 European Super Cup, losing to Milan 2ÿ0 on aggregate.[39] In February 1995, Graham was sacked by Arsenal after it emerged he accepted an illegal S425,000 payment from Norwegian agent Rune Hauge for two of his clients: Jensen and P?l Lydersen.[40] He was replaced by caretaker manager Stewart Houston (Bruce Rioch in the close season), who managed to take Arsenal into the 1995 UEFA Cup Winners' Cup Final after beating Sampdoria on penalties in the semi-finals.[41] They however, did not retain the trophy after Real Zaragoza midfielder Nayim scored an extra-time goal, lobbing Arsenal goalkeeper David Seaman.[42]\\r\\nIn August 1996, Rioch was dismissed by Arsenal. He was replaced by Arsne Wenger, who became the club's first manager born outside the British Isles. Wenger had creditable experience in UEFA club competitions; at Monaco he reached the final of the Cup Winners' Cup in 1992, losing 2ÿ0 to Werder Bremen and took the club into the semi-finals of the European Cup in 1993ÿ94. Wenger wanted Arsenal to become one of the biggest clubs in Europe, emphasising on buying talent from all over the world and patience shown by the club's board and supporters.[43] His first involvement in a European match for Arsenal was against Borussia M?nchengladbach on 26 September 1996 in the UEFA Cup; Arsenal lost 6ÿ4 on aggregate.[44] Having watched the game from the stands in the first half, he assumed control in the second, suggesting the formation should accommodate four defenders instead of five.[45]\\r\\nArsenal finished third in the 1996ÿ97 league season, missing out on qualification for the UEFA Champions League by goal difference.[46] They, however qualified for the UEFA Cup first round, but lost to PAOK Salonika of Greece over two legs in September 1997.[47] Arsenal completed the double in the 1997ÿ98 season, and winning the league ensured the club participated in the Champions League for the first time since its rebranding in 1992.[48] To benefit from increased revenue and higher attendances, Arsenal was granted permission from the Football Association and UEFA to host their home Champions League matches at Wembley Stadium.[49]\\r\\nThe club faced French champions Lens, Ukraine's Dynamo Kiev and Panathinaikos of Greece in the group stages of the competition.[50] Although they began the campaign in good stead, with two draws and a win, Arsenal lost 3ÿ1 to Dynamo Kiev and at home to Lens ÿ watched by a record crowd of 73,707, meaning the club could not reach higher than third place, failing to make the quarter-finals.[51] Arsenal ended the 1998ÿ99 league season as runners-up, qualifying for the group stages of the Champions League for the second successive year.[52] Again, Arsenal finished in third spot in their group, this time behind Barcelona and Fiorentina.[53] The team, however advanced into the UEFA Cup third round and Arsenal chose to revert to playing their home matches at Highbury, on the advice of the players.[54] Arsenal beat Nantes and Deportivo de La Coru?a over two legs and defeated Werder Bremen in the quarter-final; midfielder Ray Parlour scored a hat-trick in the second leg.[55] In the semi-final against Lens, Arsenal secured a 3ÿ1 aggregate win to face Turkish opposition Galatasaray in the final, who beat Leeds United.[56]\\r\\nAt Copenhagen, the venue for the 2000 UEFA Cup Final, both Arsenal and Galatasaray played out to a goalless draw in normal and in extra time. Arsenal lost 4ÿ1 in a penalty shootout, with striker Davor ?uker and midfielder Patrick Vieira hitting the post and underside of the crossbar respectively.[57] Wenger reflected on the defeat by saying, \\"We did not play well in the first half, but we were much better afterwards. It is very disappointing.\\"[57] The final was overshadowed by events at the city centre, where Arsenal supporter Paul Dineen was stabbed in the back.[58] Referred to as the \\"Battle of Copenhagen\\", the incident escalated into a riot between English and Turkish fans, forcing the Danish police to use tear gas in order to restore calm.[58][59]\\r\\nArsenal qualified for the group stages of the Champions League in the 2000ÿ01 season, having ended the previous league season in second.[60] The club won their first three matches in Group B, against Sparta Prague, Shakhtar Donetsk and Lazio.[61] A draw away to Lazio at the Stadio Olimpico ensured qualification into the second group stage, where they were partnered with Bayern Munich, Lyon and Spartak Moscow.[62] In spite of defender Sylvinho scoring an early goal in their opening game against Spartak Moscow, Arsenal plummeted to a 4ÿ1 defeat, leaving Wenger to assess that \\"as a team, we didn't look as solid as we are used to.\\"[63] Wins at Lyon and at home to Spartak Moscow helped Arsenal to qualify for the quarter-finals as the French club failed to capitalise on Arsenal's defeat at Bayern Munich.[64] They faced Spanish club Valencia, winning 2ÿ1 at Highbury but the team were beaten 1ÿ0 at the Estadio Mestalla, knocked-out on aggregate.[65]\\r\\nIn the 2001ÿ02 season, Arsenal played in the Champions League. The club qualified for the second group stage on goal difference but did not reach the quarter-finals, losing their final two matches against Deportivo La Coru?a and Juventus.[66] Having won the domestic league for the first time in four years, Wenger revealed the club's and his own intent to win the Champions League, telling French newspaper L'Equipe \\"I can't imagine finishing my life without winning the European Cup\\".[67] Arsenal began the following season impressively, winning 0ÿ4 at PSV Eindhoven.[68] The match set a new club record, as midfielder Gilberto Silva scored the fastest goal, in 20.07 seconds.[69] Although Arsenal lost their last two matches against Borussia Dortmund and Auxerre, coinciding with a blip in form domestically, they qualified for the second group stage for the third consecutive season.[70] Striker Thierry Henry scored his first hat-trick in Europe for Arsenal against Roma on 27 November 2002 with the player stating; \\"It's wonderful to score a hat-trick but it's even more important that I did so in a game we've won.\\"[71] Arsenal failed to replicate their form at Roma, drawing their next four matches and losing to Valencia in the final match to finish third in their group and thus, out of the competition.[72]\\r\\nArsenal entered the Champions League group stage in the 2003ÿ04 season and faced Dynamo Kiev, Internazionale and Lokomotiv Moscow. Without a win in their first three matches, Arsenal faced an early exit from the competition but managed a victory against Dynamo Kiev, after defender Ashley Cole scored via a header.[73] At the San Siro, Arsenal beat Internazionale 1ÿ5, in a performance described as \\"one of the greatest results in [the club's] history\\".[74] A win in their final group game against Lokomotiv Moscow was enough for Arsenal to top their group and play an unseeded team in the last 16. Arsenal eliminated Celta Vigo and faced fellow English club Chelsea at the quarter-final stage. Going into the first leg, Arsenal were favourites, having played their London rivals three times during the course the season, winning each occasion.[75] Former Dutch international Johan Cruyff backed Arsenal to win the competition, saying \\"If Arsenal win it playing football the way only they know how then Europe would be proud to have such champions\\".[76] In spite of Robert Pirs scoring a vital away goal at Stamford Bridge, Chelsea beat Arsenal 1ÿ2 at Highbury to progress into the semi-finals.[77] A year later, Arsenal exited the Champions League after losing 2ÿ3 to Bayern Munich on aggregate, in the last 16 stage.[78]\\r\\nArsenal qualified for the group stages of the Champions League in the 2005ÿ06 season, finishing first in a group containing Ajax, Sparta Prague and Thun. The club faced Real Madrid in the last 16; a solo goal by Henry at the Estadio Santiago Bernabu in the first leg inflicted the home team's first defeat in 18 Champions League matches.[79] Arsenal produced a disciplined display at home a fortnight after to reach the quarter-finals and become the sole English representative left in the competition.[80] At home to Juventus, Arsenal won 2ÿ0, and a goalless draw at the Stadio delle Alpi meant the club progressed into the semi-finals against Villarreal.[81] In the club's final European match at Higbhury, Kolo Tour scored a first-half winner to give Arsenal a 1ÿ0 win.[82] A late penalty save by goalkeeper Jens Lehmann in the second leg sent Arsenal into the 2006 UEFA Champions League Final, staged at the Stade de France, Paris.[83] The result, another goalless draw, was Arsenal's tenth clean sheet in a row ÿ a new competition record.[84] Defender Sol Campbell, returning from injury praised the team performance in his post-match interview: \\"It's brilliant for us. It's also great for the manager Arsne Wenger to get to the final in France ÿ I'm sure he will get a great reception.\\"[85]\\r\\nIn the final against Barcelona, Lehmann was sent off in 18th minute for a professional foul on striker Samuel Eto'o.[86] Wenger reacted by substituting Robert Pirs for goalkeeper Manuel Almunia, thus altering the formation.[86] In spite of the disadvantage, Arsenal took the lead in the 37th minute, after Henry's free kick was headed in by Campbell.[86] Henry missed a chance in the second half to give Arsenal a two-nil lead before Eto'o equalised with 14 minutes left.[86] Substitute Henrik Larsson set up Juliano Belletti to score the winner for Barcelona.[86] Wenger criticised referee Terje Hauge for sending off Lehmann, a view shared by club captain Henry and FIFA president Sepp Blatter.[87]\\r\\nAs Arsenal finished fourth in the league, in the following season the club needed to play a third qualifying round, against Dinamo Zagreb in order to participate in the Champions League group stages. The team won 1ÿ5 on aggregate, including a 3ÿ0 victory in the first European match at the Emirates Stadium.[88] Arsenal was eliminated in the Round of 16 stage, losing on the away goal ruling to PSV Eindhoven.[89] In the 2007ÿ08 season, Arsenal equalled their biggest home win in European football, scoring seven against Slavia Prague.[90] The club beat holders Milan in the subsequent round, earning critical acclaim for their style of football, not least from Marcello Lippi: \\"It would be good for football if Arsenal could win. They play on the ground, they manoeuvre the ball, very, very well. It's very fast and very technical.\\"[91] At the quarter-final stage, Liverpool defeated Arsenal 5ÿ3 on aggregate to set up a semi-final tie against Chelsea.[92]\\r\\nArsenal progressed past the group stages of the 2008ÿ09 Champions League season and beat Roma and Villarreal to face Manchester United in the semi-finals.[93] A 1ÿ0 defeat at Old Trafford meant Arsenal needed to win by two clear goals to progress, but goals from Park Ji-sung and Cristiano Ronaldo in the first eleven minutes ended the club's chances of reaching the 2009 UEFA Champions League Final.[94] Wenger in his post-match press conference described the match as \\"the most disappointing night of my career\\", adding \\"I felt the fans were really up for a big night and to disappoint people who stand behind the team so much hurts.\\"[95] Arsenal lost to holders Barcelona 5ÿ3 on aggregate in the quarter-finals the following season, and in spite of beating the Spanish club 2ÿ1 at the Emirates Stadium in 2010ÿ11, Arsenal again were eliminated, this time at the Round of 16.[96] Arsenal exited at the same stage of the competition for the second consecutive season, against Milan. Having lost the away leg 4ÿ0, the team gave a valiant performance in the second leg at home, winning 3ÿ0 on the night, but unable to find the final goal that would have taken the game to extra time.\\r\\nIn the 2012ÿ13 season, Arsenal fell at the last 16 stage for the third time in three years, losing 3ÿ1 to Bayern Munich at home,[97] but managing to win 2ÿ0 in the return leg, meaning they went out on the away goals rule.[98] They were once again eliminated by Bayern Munich in the 2013ÿ14 season after losing 2ÿ0 at home,[99] and drawing 1ÿ1 away at Munich.[100] They were eliminated by Monaco in Round of 16 in the 2014ÿ15 season on away goals,[101][102] and by Barcelona 5ÿ1 on aggregate in 2015ÿ16.[103][104] Arsenal exited at the last 16 for the seventh consecutive time to Bayern Munich, losing 10ÿ2 on aggregate.[105][106]\\r\\nArsenal was the first British side to defeat Real Madrid and Juventus away from home. The club was also the first to win against both Milanese teams: Internazionale and Milan at the San Siro.[107] Goalkeeper Jens Lehmann kept ten consecutive clean sheets in the run-in to the 2006 UEFA Champions League Final; the defence went 995 minutes until conceding a goal.[108] Against Hamburg in the UEFA Champions League group stage on 13 September 2006, Arsenal became the first team in the competition's history to field a first eleven of different nationalities.[109]\\r\\nKey to colours and symbols:","input":"How many years were arsenal in the champions league?"},{"output":"17 January 1981","context":"Proclamation  1081 was the proclamation of Martial Law in the Philippines by President Ferdinand E. Marcos. It was announced to the public on 23 September 1972, and was formally lifted on 17 January 1981.\\r\\n\\r\\n\\r\\nPhilippine Military Academy instructor Lt Victor Corpuz led New People's Army rebels in a raid on the PMA armory, capturing rifles, machine guns, grenade launchers, a bazooka and thousands of rounds of ammunition in 1970.[1] In 1972, China, which was then actively supporting and arming communist insurgencies in Asia as part of Mao Zedong's People's War Doctrine, transported 1,200 M-14 and AK-47 rifles [2] for the NPA to speed up NPA's campaign to defeat the government.[3][4] Prior to the 1975, the Philippine government maintained a close relationship with the Kuomintang-ruled Chinese government which fled to Taiwan (Republic of China), despite the Chinese Communist Victory in 1949, and saw the People's Republic of China as a security threat due to its financial and military support of Communist rebels in the country.[5]\\r\\nCiting an intensifying Communist insurgency,[6] a series of bombings, and the staged[7] fake [8][9] assassination attempt on then-Defense Minister Juan Ponce Enrile, President Marcos enacted the Proclamation which enabled him to rule by military power.\\r\\nHe initially signed the Proclamation on 17 September 1972, but it was postdated to 21 September because of his superstitions and numerological beliefs concerning the number seven.[citation needed] Marcos formally announced the Proclamation in a live television and radio broadcast from Malaca?ang Palace a further two days later on the evening of 23 September 1972.\\r\\nMartial law was ratified by 90.77% of the voters during the controversial Philippine Martial Law referendum, 1973.[10][11]\\r\\nAfter the constitution was approved by 95% of the voters in the Philippine constitutional plebiscite, the 1935 Constitution was replaced with a new one that changed the system of government from a presidential to a parliamentary one, with Marcos remaining in power as both head of state (with the title \\"President\\") and head of government (titled \\"Prime Minister\\").[citation needed] Under the new government, President Marcos formed his political coalitionÿthe Kilusang Bagong Lipunan (KBL; English: New Society Movement)ÿcontrol the unicameral legislature he created, known as the Batasang Pambansa.\\r\\nIn an effort to isolate the local communist movement, President Marcos went to China in 1975 to normalize diplomatic relations. In return for recognizing the People's Republic of China as the legitimate government of China, and that Taiwan is part of Chinese territory, Chinese Premier Zhou Enlai pledged to stop supporting the Philippine communist rebels.[12]\\r\\nThe government subsequently captured NPA leaders Bernabe Buscayno in 1976 and Jose Maria Sison in 1977.[13] The Washington Post in an interview with former Philippine Communist Party Officials, revealed that, \\"they (local communist party officials) wound up languishing in China for 10 years as unwilling \\"guests\\" of the (Chinese) government, feuding bitterly among themselves and with the party leadership in the Philippines\\".[14]\\r\\nPresident Marcos formally lifted Martial Law on 17 January 1981, several weeks before the first pastoral visit of Pope John Paul II to the Philippines for the beatification of Lorenzo Ruiz. After the lifting of Martial Law, the CPP-NPA was able to return to urban areas and form relationships with legal opposition organizations, and became increasingly successful attacks against the government throughout the country.[15].\\r\\nBased on interviews of The Washington Post with former officials of the Communist Party of the Philippines, it was revealed that \\"the (Communist) party leadership planned ÿ and three operatives carried out ÿ the (Plaza Miranda) attack in an attempt to provoke government repression and push the country to the brink of revolution... (Communist Party) Chairman Sison had become convinced by early 1971 ÿ less than three years after the party was founded ÿ that it would take only a well-timed incident to spark a great upheaval leading to an early Communist victory. Sison had calculated that Marcos could be provoked into cracking down on his opponents, thereby driving thousands of political activists into the underground, the former party officials said. Recruits were urgently needed, they said, to make use of a large influx of weapons and financial aid that China had already agreed to provide.\\" [16]\\r\\nGeneral Order  1 - The President proclaimed that he shall direct the entire government, including all its agencies and instrumentalities, and exercise all powers of his office including his role as the Commander-in-Chief of the Armed Forces of the Philippines.\\r\\nGeneral Order  2 ÿ The President directed the Minister of National Defense to arrest or cause the arrest and take into his custody the individuals named in the attached list and to hold them until otherwise so ordered by the President or by his duly designated representative, as well as to arrest or cause the arrest and take into his custody and to hold them otherwise ordered released by him or by his duly authorized representative such persons who may have committed crimes described in the Order.\\r\\nGeneral Order  3 ÿ The President ordered that all executive departments, bureaus, offices, agencies and instrumentalities of the National Government, government owned or controlled corporations, as well all governments of all the provinces, cities, municipalities and barrios should continue to function under their present officers and employees, until otherwise ordered by the President or by his duly designated representatives. The President further ordered that the Judiciary should continue to function in accordance with its present organization and personnel, and should try to decide in accordance with existing laws all criminal and civil cases, except certain cases enumerated in the Order.\\r\\nGeneral Order  4 ÿ The President ordered that a curfew be maintained and enforced throughout the Philippines from twelve oclock midnight until four oclock in the morning.\\r\\nGeneral Order  5 ÿ All rallies, demonstrations and other forms of group actions including strikes and picketing in vital industries such as in companies engaged in manufacture or processing as well as in production or processing of essential commodities or products for exports, and in companies engaged in banking of any kind, as well as in hospitals and in schools and colleges are prohibited.\\r\\nGeneral Order  6 ÿ No person shall keep, possess or carry outside of his residence any firearm unless such person is duly authorized to keep, possess or carry any such firearm except to those who are being sent abroad in the service of the Philippines.","input":"When was martial law lifted in the philippines?"},{"output":"violet","context":"Gram stain or Gram staining, also called Gram's method, is a method of staining used to distinguish and classify bacterial species into two large groups (gram-positive and gram-negative). The name comes from the Danish bacteriologist Hans Christian Gram, who developed the technique.\\r\\nGram staining differentiates bacteria by the chemical and physical properties of their cell walls by detecting peptidoglycan, which is present in the cell wall of Gram-positive bacteria. Gram-negative cells also contain peptidoglycan, but a very small layer of it that is dissolved when the alcohol is added. This is why the cell loses its initial colour from the primary stain.[1] Gram-positive bacteria retain the crystal violet dye, and thus are stained violet, while the Gram-negative bacteria do not; after washing, a counterstain is added (commonly safranin or fuchsine) that will stain these Gram-negative bacteria a pink color. Both Gram-positive bacteria and Gram-negative bacteria pick up the counterstain. The counterstain, however, is unseen on Gram-positive bacteria because of the darker crystal violet stain.\\r\\nThe Gram stain is almost always the first step in the preliminary identification of a bacterial organism. While Gram staining is a valuable diagnostic tool in both clinical and research settings, not all bacteria can be definitively classified by this technique. This gives rise to gram-variable and gram-indeterminate groups.\\r\\n\\r\\n\\r\\nThe method is named after its inventor, the Danish scientist Hans Christian Gram (1853ÿ1938), who developed the technique while working with Carl Friedl?nder in the morgue of the city hospital in Berlin in 1884. Gram devised his technique not for the purpose of distinguishing one type of bacterium from another but to make bacteria more visible in stained sections of lung tissue.[2] He published his method in 1884, and included in his short report the observation that the typhus bacillus did not retain the stain.[3]\\r\\nGram staining is a bacteriological laboratory technique[4] used to differentiate bacterial species into two large groups (gram-positive and gram-negative) based on the physical properties of their cell walls.[5][page?needed] Gram staining is not used to classify archaea, formerly archaeabacteria, since these microorganisms yield widely varying responses that do not follow their phylogenetic groups.[6]\\r\\nThe Gram stain is not an infallible tool for diagnosis, identification, or phylogeny, and it is of extremely limited use in environmental microbiology. It is used mainly to make a preliminary morphologic identification or to establish that there are significant numbers of bacteria in a clinical specimen. It cannot identify bacteria to the species level, and for most medical conditions, it should not be used as the sole method of bacterial identification. In clinical microbiology laboratories, it is used in combination with other traditional and molecular techniques to identify bacteria. Some organisms are gram-variable (meaning they may stain either negative or positive); some are not stained with either dye used in the Gram technique and are not seen. In a modern environmental or molecular microbiology lab, most identification is done using genetic sequences and other molecular techniques, which are far more specific and informative than differential staining.\\r\\nGram staining has been suggested to be as effective a diagnostic tool as PCR in one primary research report regarding gonococcal urethritis.[7][non-primary source needed]\\r\\nGram stains are performed on body fluid or biopsy when infection is suspected. Gram stains yield results much more quickly than culturing, and is especially important when infection would make an important difference in the patient's treatment and prognosis; examples are cerebrospinal fluid for meningitis and synovial fluid for septic arthritis.[4][8]\\r\\nGram-positive bacteria have a thick mesh-like cell wall made of peptidoglycan (50ÿ90% of cell envelope), and as a result are stained purple by crystal violet, whereas gram-negative bacteria have a thinner layer (10% of cell envelope), so do not retain the purple stain and are counter-stained pink by safranin. There are four basic steps of the Gram stain:\\r\\nCrystal violet (CV) dissociates in aqueous solutions into CV+ and chloride (Cl?) ions. These ions penetrate through the cell wall and cell membrane of both gram-positive and gram-negative cells. The CV+ ion interacts with negatively charged components of bacterial cells and stains the cells purple.[11]\\r\\nIodide (I? or I?\\r\\n3) interacts with CV+ and forms large complexes of crystal violet and iodine (CVÿI) within the inner and outer layers of the cell. Iodine is often referred to as a mordant, but is a trapping agent that prevents the removal of the CVÿI complex and, therefore, color the cell.[12]\\r\\nWhen a decolorizer such as alcohol or acetone is added, it interacts with the lipids of the cell membrane.[13] A gram-negative cell loses its outer lipopolysaccharide membrane, and the inner peptidoglycan layer is left exposed. The CVÿI complexes are washed from the gram-negative cell along with the outer membrane.[14][citation needed] In contrast, a gram-positive cell becomes dehydrated from an ethanol treatment. The large CVÿI complexes become trapped within the gram-positive cell due to the multilayered nature of its peptidoglycan.[14][citation needed] The decolorization step is critical and must be timed correctly; the crystal violet stain is removed from both gram-positive and negative cells if the decolorizing agent is left on too long (a matter of seconds).[15][citation needed]\\r\\nAfter decolorization, the gram-positive cell remains purple and the gram-negative cell loses its purple color.[15][citation needed] Counterstain, which is usually positively charged safranin or basic fuchsine, is applied last to give decolorized gram-negative bacteria a pink or red color.[16][17]\\r\\nGram-positive bacteria generally have a single membrane (monoderm) surrounded by a thick peptidoglycan. This rule is followed by two phyla: Firmicutes (except for the classes Mollicutes and Negativicutes) and the Actinobacteria.[5][18] In contrast, members of the Chloroflexi (green non-sulfur bacteria) are monoderms but possess a thin or absent (class Dehalococcoidetes) peptidoglycan and can stain negative, positive or indeterminate; members of the Deinococcus-Thermus group, stain positive but are diderms with a thick peptidoglycan.[5][page?needed] [18]\\r\\nHistorically, the gram-positive forms made up the phylum Firmicutes, a name now used for the largest group. It includes many well-known genera such as Bacillus, Listeria, Staphylococcus, Streptococcus, Enterococcus, and Clostridium.[19][citation needed] It has also been expanded to include the Mollicutes, bacteria like Mycoplasma that lack cell walls and so cannot be stained by Gram, but are derived from such forms.[20][citation needed]\\r\\nSome bacteria have cell walls which are particularly adept at retaining stains. These will appear positive by Gram stain even though they are not closely related to other gram-positive bacteria. These are called acid fast bacteria, and can only be differentiated from other gram-positive bacteria by special staining procedures.[21][citation needed]\\r\\nGram-negative bacteria generally possess a thin layer of peptidoglycan between two membranes (diderms). Most bacterial phyla are gram-negative, including the cyanobacteria, spirochaetes, and green sulfur bacteria, and most Proteobacteria (exceptions being some members of the Rickettsiales and the insect-endosymbionts of the Enterobacteriales).[5][page?needed][18]\\r\\nSome bacteria, after staining with the Gram stain, yield a gram-variable pattern: a mix of pink and purple cells are seen.[14][citation needed] In cultures of Bacillus, Butyrivibrio, and Clostridium, a decrease in peptidoglycan thickness during growth coincides with an increase in the number of cells that stain gram-negative.[22] In addition, in all bacteria stained using the Gram stain, the age of the culture may influence the results of the stain.[23]\\r\\nGram-indeterminate bacteria do not respond predictably to Gram staining and, therefore, cannot be determined as either gram-positive or gram-negative. Examples include many species of Mycobacterium, including M. tuberculosis and M. leprae.[24][25]\\r\\nThe term Gram staining is derived from the surname of Hans Christian Gram, the eponym (Gram) is therefore capitalized but not the common noun (stain) as is usual for scientific terms.[26] The adjectives 'gram-positive' and 'gram-negative'; as eponymous adjectives, their initial letter can be either lowercase 'g' or capital 'G', depending on whose style guide (if any) governs the document being written. Lowercase style is used by the US Centers for Disease Control and Prevention and other style regimens such as the AMA style.[27] Dictionaries may use lowercase,[28][29] uppercase,[30][31][32][33] or both.[34][35] Uppercase 'Gram-positive' or 'Gram-negative' usage is also common in many scientific journal articles and publications.[35][36][37] When articles are submitted to journals, each journal may or may not apply house style to the postprint version. Preprint versions contain whichever style the author happened to use. Even style regimens that use lowercase for the adjectives 'gram-positive' and 'gram-negative' still use capital for 'Gram stain'.","input":"What is the colour of gram positive bacteria?"},{"output":"Amber Hagerman, a 9-year-old abducted and murdered in Arlington, Texas, in 1996","context":"An AMBER Alert or a Child Abduction Emergency (SAME code: CAE) is a child abduction alert system. It originated in the United States in 1996.\\r\\nAMBER is officially a contrived acronym for America's Missing: Broadcast Emergency Response, but was named after Amber Hagerman, a 9-year-old abducted and murdered in Arlington, Texas, in 1996. Alternative regional alert names were once used; in Georgia, \\"Levi's Call\\"[1] (in memory of Levi Frady); in Hawaii, \\"Maile Amber Alert\\"[2] (in memory of Maile Gilbert); and Arkansas, \\"Morgan Nick Amber Alert\\"[3] (in memory of Morgan Nick).\\r\\nIn the United States, AMBER Alerts are distributed via commercial radio stations, Internet radio, satellite radio, television stations, and cable TV by the Emergency Alert System and NOAA Weather Radio[4][5] (where they are termed \\"Child Abduction Emergency\\" or \\"Amber Alerts\\"). The alerts are also issued via e-mail, electronic traffic-condition signs, commercial electronic billboards,[6][7] or through wireless device SMS text messages. AMBER Alert has also teamed up with Google,[8] Bing,[9] and Facebook[10] to relay information regarding an AMBER Alert to an ever-growing demographic: AMBER Alerts are automatically displayed if citizens search or use map features on Google or Bing. With the Google Child Alert (also called Google AMBER Alert in some countries), citizens see an AMBER Alert if they search for related information in a particular location where a child has recently been abducted and an alert was issued. This is a component of the AMBER Alert system that is already active in the US (there are also developments in Europe). Those interested in subscribing to receive AMBER Alerts in their area via SMS messages can visit Wireless Amber Alerts, which are offered by law as free messages.[11] In some states, the display scrollboards in front of lottery terminals are also used.\\r\\nThe decision to declare an AMBER Alert is made by each police organization (in many cases, the state police or highway patrol) that investigates each of the abductions. Public information in an AMBER Alert usually consists of the name and description of the abductee, a description of the suspected abductor, and a description and license plate number of the abductor's vehicle, if available.\\r\\n\\r\\n\\r\\nThe alerts are broadcast using the Emergency Alert System, which had previously been used primarily for weather bulletins, civil emergencies, or national emergencies.[12] Alerts usually contain a description of the child and of the likely abductor.[13] To avoid both false alarms and having alerts ignored as a \\"wolf cry\\", the criteria for issuing an alert are rather strict. Each state's or province's AMBER alert plan sets its own criteria for activation, meaning that there are differences between alerting agencies as to which incidents are considered to justify the use of the system. However, the U.S. Department of Justice issues the following \\"guidance\\", which most states are said to \\"adhere closely to\\" (in the U.S.):[14]\\r\\nMany law enforcement agencies have not used #2 as a criterion, resulting in many parental abductions triggering an Amber Alert, where the child is not known or assumed to be at risk of serious injury or death. In 2013, West Virginia passed Skylar's Law to eliminate #1 as a criterion for triggering an Amber Alert.\\r\\nIt is recommended that AMBER Alert data immediately be entered into the Federal Bureau of Investigation (FBI) National Crime Information Center. Text information describing the circumstances surrounding the abduction of the child should be entered, and the case flagged as child abduction.\\r\\nThe Royal Canadian Mounted Police's (RCMP) requirements in Canada are nearly identical to the above list, with the exception that the RCMP instead of the FBI is normally notified.[16] One organization might notify the other if there is reason to suspect that the border may be crossed.\\r\\nWhen investigators believe that a child is in danger of being taken across the border to either Canada or Mexico, U.S. Customs and Border Protection, United States Border Patrol and the Canada Border Services Agency are notified and are expected to search every car coming through a border checkpoint. If the child is suspected to be taken to Canada, a Canadian Amber Alert can also be issued, and a pursuit by Canadian authorities usually follows.\\r\\nFor incidents which do not meet AMBER Alert criteria, the United States Department of Justice developed the Child Abduction Response Teams (CART) program to assist local agencies. This program can be used in all missing children's cases and can be used as part of an AMBER alert or when an abduction or disappearance does not meet AMBER Alert criteria. CART can also be used to help recover runaway children under the age of 18 and who are in danger. As of 2010, 225 response teams have been trained in 43 states, Washington, D.C., Puerto Rico, the Bahamas, and Canada.[17]\\r\\nOn January 13, 1996 nine-year-old Amber Rene Hagerman (November 25, 1986 ÿ January 17, 1996) was abducted while riding her bike in Arlington, Texas.[18] A neighbor who witnessed the abduction called the police, and Amber's brother, Ricky, went home to tell his mother and grandparents what happened. On hearing the news, Hagerman's father, Richard, called Marc Klaas, whose daughter, Polly, had been abducted and murdered in Petaluma, California, on October 1, 1993. It is often believed[by whom?] that Hagerman's murderer kept her alive for at least two days. Richard and Amber's mother, Donna Whitson (now Donna Norris), called the news media and the FBI. They and their neighbors began searching for Amber. Four days after the abduction, near midnight, her body was found in a creek behind an apartment complex ÿ with cut wounds to her neck. The site of the discovery was less than five miles from where she went missing. There are no suspects to her abduction and homicide.[19]\\r\\nWithin days of Amber's death, Donna Whitson was \\"calling for tougher laws governing kidnappers and sex offenders\\".[20] Amber's parents soon established People Against Sex Offenders (P.A.S.O.). They collected signatures hoping to force the Texas Legislature into passing more stringent laws to protect children.[citation needed]\\r\\nGod's Place International Church donated the first office space for the organization, and as the search for Amber's killer continued, P.A.S.O. received almost-daily coverage in local media. Companies donated various office supplies, including computer and Internet service. Congressman Martin Frost, with the help of Marc Klaas, drafted the Amber Hagerman Child Protection Act. Both of Hagerman's parents were present when President Bill Clinton signed the bill into law, creating the national sex offender registry. Whitson and Richard Hagerman then began collecting signatures in Texas, which they planned to present to then-Governor George W. Bush as a sign that people wanted more stringent laws for sex offenders.[21]\\r\\nIn July 1996, Bruce Seybert[clarification needed] and Richard Hagerman attended a media symposium in Arlington. Although Hagerman had remarks prepared, on the day of the event the organizers asked Seybert to speak instead. In his 20-minute speech, he spoke about efforts that local police could take quickly to help find missing children and how the media could facilitate those efforts. C.J. Wheeler, a reporter from radio station KRLD, approached the Dallas police chief shortly afterward with Seybert's ideas and launched the first ever Amber Alert.[22]\\r\\nWhitson testified in front of the U.S. Congress in June 1996, asking legislators to create a nationwide registry of sex offenders. Representative Martin Frost, the Congressman who represents Whitson's district, proposed an \\"Amber Hagerman Child Protection Act.\\" Among the sections of the bill was one that would create a national sex offender registry.[23]\\r\\nFor the next two years, alerts were made manually to participating radio stations. In 1998, the Child Alert Foundation created the first fully automated Alert Notification System (ANS) to notify surrounding communities when a child was reported missing or abducted. Alerts were sent to radio stations as originally requested but included television stations, surrounding law enforcement agencies, newspapers and local support organizations. These alerts were sent all at once via pagers, faxes, emails, and cell phones with the information immediately posted on the Internet for the general public to view.[citation needed]\\r\\nFollowing the automation of the AMBER Alert with ANS technology created by the Child Alert Foundation, the National Center for Missing and Exploited Children (NCMEC) expanded its role in 2002 to promote the AMBER Alert, although in 1996 now CEO of the NCMEC declined to come in and further assist the AMBER Alert when asked to by Bruce Seybert and Richard Hagerman and has since worked actively to see alerts distributed using the nation's existing emergency radio and TV response network.[citation needed]\\r\\nIn October 2000, the United States House of Representatives adopted H.Res. 605 which encouraged communities nationwide to implement the AMBER Plan. In October 2001, the National Center for Missing and Exploited Children that had declined to be a part of the Amber Alert in February 1996, launched a campaign to have AMBER Alert systems established nationwide. In February 2002, the Federal Communications Commission officially endorsed the system. In 2002, several children were abducted in cases that drew national attention. One such case, the kidnapping and murder of Samantha Runnion, prompted California to establish an AMBER Alert system on July 24, 2002.[12] According to Senator Dianne Feinstein, in its first month California issued 13 AMBER alerts; 12 of the children were recovered safely and the remaining alert was found to be a misunderstanding.[24]\\r\\nBy September 2002, 26 states had established AMBER Alert systems that covered all or parts of the state. A bipartisan group of US Senators, led by Kay Bailey Hutchison and Dianne Feinstein, proposed legislation to name an AMBER Alert coordinator in the U.S. Justice Department who could help coordinate state efforts. The bill also provided $25 million in federal matching grants for states to establish AMBER Alert programs and necessary equipment purchases, such as electronic highway signs. A similar bill was sponsored in the U.S. House of Representatives by Jennifer Dunn and Martin Frost.[24] The bill passed the Senate unanimously within a week of its proposal.[13] At an October 2002 conference on missing, exploited, and runaway children, President George W. Bush announced changes to the AMBER Alert system, including the development of a national standard for issuing AMBER Alerts.[25] A similar bill passed the House several weeks later on a 390ÿ24 vote.[26] A related bill finally became law in April 2003.[27]\\r\\nThe alerts were offered digitally beginning in November 2002, when America Online began a service allowing people sign up to receive notification via computer, pager, or cell phone. Users of the service enter their ZIP code, thus allowing the alerts to be targeted to specific geographic regions.[28]\\r\\nBy 2005, all fifty states had operational programs and today the program operates across state and jurisdictional boundaries.[29] As of January 1, 2013, AMBER Alerts are automatically sent through the Wireless Emergency Alerts (WEA) program.[30]\\r\\nCanada's system began in December 2002, when Alberta launched the first province-wide system. At the time, Alberta Solicitor-General Heather Forsyth said \\"We anticipate an Amber Alert will only be issued once a year in Alberta. We hope we never have to use it, but if a child is abducted Amber Alert is another tool police can use to find them and help them bring the child home safely.\\"[31] The Alberta government committed to spending more than CA$1 million to expanding the province's emergency warning system so that it could be used effectively for Amber Alerts.[31] Other Canadian provinces soon adopted the system, and by May 2004, Saskatchewan was the only province that had not established an Amber Alert system.[32] Within the next year, the program was in use throughout the country.\\r\\nAmber Alerts may also be distributed via the Alert Ready emergency alert system, which disrupts programming on all radio, television stations, and television providers in the relevant region to display and play audio of Amber Alert information.[33][34]\\r\\nTranslink, the corporation responsible for the regional transportation network of Metro Vancouver in British Columbia, Canada, displays Amber alerts on all their buses' digital signs reading \\"AMBER ALERT | Listen to radio | Bus #\\". Details of the Amber alert information are also available on screens at transit stations.\\r\\nThe program was introduced in Quebec on May 26, 2003. The name AMBER alert was then adapted in French to Alerte Mdiatique But Enfant Recherch, which directly translates as \\"Media Alert for Child Recovery\\". In order to launch an AMBER alert, police authorities need to meet 4 criteria simultaneously and with no exceptions:\\r\\nOnce all 4 conditions are met, the police service may call an AMBER alert. Simultaneously, all of Quebec's Ministry of transport message boards will broadcast the police's messages. The Socit de l'assurance automobile du Qubec (SAAQ) road traffic controllers also help with the search. Television and radio stations broadcast a description of the child, the abductor and/or the abductor's car. On the radio, the information is broadcast every 20 minutes for two hours or less if the child is found. On the television, the information is broadcast on a ticker tape at the bottom of the screen for two hours with no interruptions. After this, the ticker tape is withdrawn, but the police continue to inform the public through the usual means of communication.\\r\\nOver the years, the program gathered more partners in order for the alert to be communicated on different media platforms. As in Ontario, lottery crown corporation Loto-Qubec puts to the disposition of the police forces their 8500 terminals located throughout the province. Some of these terminals are equipped with a screen that faces the customer which makes it the largest network of its kind to operate in Canada. The technology employed enables them to broadcast the message on the entire network in under 10 minutes. In addition, The Canadian Wireless Telecommunications Association (CWTA) offers to most Canadians, upon free subscription, the possibility to receive, via text message, on their mobile devices AMBER alert notices.\\r\\nSince its introduction in Quebec, every AMBER alert has had positive results.[36][37]\\r\\nOntario furthered its reach beyond media and highway signs by offering Amber Alerts on the province's 9,000 lottery terminal screens.[38]\\r\\nAfter the abduction and murder of Victoria Stafford, an online petition was started by Suzie Pereira, a single mother of 2 children who gathered over 61,000 signatures, prompting a review of the Amber Alert. There was some concern regarding the strict criteria for issuing the alerts?ÿ criteria that was not met in the Stafford case?ÿ that resulted in an alert not being issued. Ontario Provincial Police have since changed their rules for issuing an alert from having to confirm an abduction and confirm threat of harm, to believe that a child has been abducted and believe is at risk of harm.[39][40]\\r\\nMexico joined international efforts to spread the use of the AMBER alert at an official launch ceremony on April 28, 2011.[41][42]\\r\\nThe Australian state of Queensland implemented a version of the AMBER Alerts in May 2005.[43] Other Australian states joined Queensland in Facebook's Amber Alert program in June 2017.[44]\\r\\nCurrently, there are alert systems active in 18 EU countries: Belgium, Bulgaria, Cyprus, the Czech Republic, France, Germany, Greece, Ireland, Italy, Luxembourg, Malta, the Netherlands, Poland, Portugal, Romania, Slovakia, Spain and the United Kingdom.[45][46] AMBER Alert Europe offers an EU wide response to the EU objective (DG Justice) on Child Alerts, which states that an early warning system for child abductions, with cross-border interoperability, should be established in all 28 EU countries. AMBER Alert Europe uses the same technology as the Dutch AMBER Alert plan.[47]\\r\\nAMBER Alert Europe\\r\\nAMBER Alert Europe is an international non-profit organisation with 25 members (law enforcement, ministries & NGOs) in 17 countries. Its Police Network consists of over 40 experts representing law enforcement from 14 EU countries. The goals of AMBER Alert Europe are backed by 465 Members of the European Parliament.[48] The ultimate goal of AMBER Alert Europe is to save the lives of endangered missing children in Europe. Therefore, AMBER Alert Europe suggests the following 5 key points to the European Commission and the European Parliament:\\r\\nFor more information on the goals and key points of AMBER Alert Europe, see: AMBER Alert Europes Memorandum to the European Commission and European Parliament.[49]\\r\\nPolice Network\\r\\nIn 2014, AMBER Alert Europe launched the Police Expert Network on Missing Children. Goal of the network is to allow missing children police experts to quickly and informally contact their colleagues in other European member states and exchange best practices.[50]\\r\\nAMBER Alerts\\r\\nAn AMBER Alert reaches millions of people within minutes. When an AMBER Alert is issued by law enforcement, the picture of the AMBER Alert child is instantly visible everywhere via dozens of different media. The AMBER Alert system exists of the following components: TV and radio, highway signs, Google Child Alert (also called Google AMBER Alert in some countries ÿ already active in the US; there are developments in Europe), missing children maps with active AMBER Alerts and endangered missing children, online banners and advertisements, large TV screens, text messages with photo, PC pop-ups, Facebook, Twitter, apps, website pop-ups and banners, PC screensaver, email, posters, RSS news feed, mobile websites, screens in public transport (buses and trains), screens in railway stations, airports, shopping malls, supermarkets and cinemas.[51]\\r\\nThe first cross-border AMBER Alert was issued in the early morning of May 8, 2013 for two Dutch brothers. The boys' photo was displayed on large screens in the Belgian province of Limbourg and in North Rhine-Westphalia (Germany) and has received extensive media attention in the Netherlands, Belgium and Germany. The bodies of the children were found on May 19, 2013 near Cothen (the Netherlands).[52][53][54][55]\\r\\nIn February 2006, France's Justice ministry launched an apparatus based on the AMBER alerts named Alerte-Enlvement?(fr) (abduction alert) or Dispositif Alerte-Enlvement?(fr) (abduction alert apparatus) with the help of most media and railroad and motorway companies.\\r\\nIn April 2009, it was announced that an AMBER Alert system would be set up in Ireland, In May 2012, the Child Rescue Ireland (CRI) Alert was officially introduced.[56] Ireland's first AMBER alert was issued upon the disappearance of two boys,[57] Eoghan (10) and Ruari Chada (5).\\r\\nThe Dutch AMBER Alert was launched in 2008 by the Dutch National Police,[58] the Dutch minister of Justice at the time, Ernst Hirsch Ballin,[59][60] and social enterprise Netpresenter.[61] On February 14, 2009, the first Dutch AMBER Alert was issued when a 4-year-old boy went missing in Rotterdam. He was found safe and sound after being recognized by a person who saw his picture on an electronic billboard in a fast food restaurant. He was recovered so quickly, that the transmission of the AMBER Alert was halted before all recipients received it. Since 2008, the AMBER Alert system has been deployed for 23 AMBER Alerts and thousands of Missing Child Alerts.[62]\\r\\nCurrently, AMBER Alert has more than 2.9 million participants including thousands of large organizations.[63] In addition, the last AMBER Alert that was issued, was seen by almost 12 million Dutch citizens (88 percent of the Dutch population).[64] With a success rate of 64 percent,[65] the Dutch AMBER Alert system is an example of effective citizen sourcing.[66]\\r\\nAn AMBER Alert is issued when a child is missing or abducted and the Dutch police fear that the life or health of the child is in imminent danger. The system enables the police to immediately alert press and public nationwide, by means of electronic highway signs, TV, radio, social media, PCs, large advertising screens (digital signage), email, text messages, apps, printable posters, RSS news feeds, website banners and pop-ups.[59] There are four key criteria in The Netherlands to be met before an AMBER Alert is issued:\\r\\nParts of the Dutch AMBER Alert system are being used for Missing Child Alerts. A Missing Child Alert is issued when there is an immediate and significant risk of harm for the missing child but the case does not reach the criteria for an AMBER Alert. The Dutch police can decide to publicize information and ask the help of citizens to recover the child.[67] AMBER Alert Netherlands is a founding member of AMBER Alert Europe, the European Child Rescue Alert and Police Network on Missing Children.[68]\\r\\nOn April 1, 2007, the AMBER Alert system became active in Northwest England.[69] An implementation across the rest of Britain was planned at that time. This was realized on May 25, 2010 with the nationwide launch of the Child Rescue Alert, based on the AMBER Alert system. The first system in the UK of this kind was created in Sussex on November 14, 2002. This was followed by versions in Surrey and Hampshire. By 2005, every local jurisdiction in England and Wales had its own form of alert system.[70] The system was first used in the UK on October 3, 2012, with regard to missing 5 year-old April Jones in Wales.\\r\\nIn September 2007, Malaysia implemented the Nurin Alert. Based on the AMBER alert, it is named for a missing eight-year-old girl, Nurin Jazlin.\\r\\nAccording to the U.S. Department of Justice, of the children abducted and murdered by strangers, 75% are killed within the first three hours in the USA.[12] Amber Alerts are designed to inform the general public quickly when a child has been kidnapped and is in danger so \\"the public [would be] additional eyes and ears of law enforcement\\".[12] As of August 2013, the National Center for Missing and Exploited Children estimates that 657 children have been successfully recovered as a result of the existence of the AMBER Alert program.[71]\\r\\nA Scripps Howard study of the 233 AMBER Alerts issued in the United States in 2004 found that most issued alerts did not meet the Department of Justice's criteria. Fully 50% (117 alerts) were categorized by the National Center for Missing & Exploited Children as being \\"family abductions\\", very often a parent involved in a custody dispute. There were 48 alerts for children who had not been abducted at all, but were lost, ran away, involved in family misunderstandings (for example, two instances where the child was with grandparents), or as the result of hoaxes. Another 23 alerts were issued in cases where police did not know the name of the allegedly abducted child, often as the result of misunderstandings by witnesses who reported an abduction.\\r\\nSeventy of the 233 AMBER Alerts issued in 2004 (30%) were actually children taken by strangers or who were unlawfully travelling with adults other than their legal guardians.[72]\\r\\nAccording to the 2014 Amber Alert Report, 186 Amber Alerts were issued in the US, involving 239 children. 60 (25%) were taken by strangers or people other than their legal guardians.\\r\\nSome outside scholars examining the system in depth disagree with the \\"official\\" results.[73][74][75] A research team led by criminologist Timothy Griffin reviewed hundreds of abduction cases that occurred between 2003 and 2006 and found that AMBER Alerts actually had little apparent role in the eventual return of abducted children. The AMBER Alerts tended to be \\"successful\\" in relatively mundane abductions, such as when the child was taken by a noncustodial parent or other family member. There was little evidence that AMBER Alerts routinely \\"saved lives\\", although a crucial research constraint was the impossibility of knowing with certainty what would have happened if no alert had been issued in a particular case.[76]\\r\\nGriffin and coauthor Monica Miller articulated the limits to AMBER Alert in a subsequent research article. They stated that alerts are inherently constrained, because to be successful in the most menacing cases there needs to be a rapid synchronization of several events (rapid discovery that the child is missing and subsequent alert, the fortuitous discovery of the child or abductor by a citizen, and so forth). Furthermore, there is a contradiction between the need for rapid recovery and the prerogative to maintain the strict issuance criteria to reduce the number of frivolous alerts, creating a dilemma for law enforcement officials and public backlash when alerts are not issued in cases ending as tragedies. Finally, the implied causal model of alert (rapid recovery can save lives) is in a sense the opposite of reality: In the worst abduction scenarios, the intentions of the perpetrator usually guarantee that anything public officials do will be \\"too slow\\".\\r\\nBecause the system is publicly praised for saving lives despite these limitations, Griffin and Miller argue that AMBER Alert acts as \\"crime control theater\\" in that it \\"creates the appearance but not the fact of crime control\\".[77] AMBER Alert is thus a socially constructed \\"solution\\" to the rare but intractable crime of child-abduction murder. Griffin and Miller have subsequently applied the concept to other emotional but ineffective legislation such as safe-haven laws and polygamy raids, and continue their work in developing the concept of \\"crime control theater\\" and on the AMBER Alert system.\\r\\nGriffin considers his findings preliminary, reporting his team examined only a portion of the Amber Alerts issued over the three-year period they focused on, so he recommends taking a closer look at the evaluation of the program and its intended purpose, instead of simply promoting the program.\\r\\nThe 4 a.m. timing of a July 2013 New York child abduction alert sent through the Wireless Emergency Alerts system raised concerns that many cellphone users will now disable WEA alerts.[78]\\r\\nAdvocates for missing children are concerned that the public is becoming desensitized to AMBER Alerts because of a large number of false alarms, where police issue an AMBER Alert without strictly adhering to the U.S. Department of Justice's activation guidelines.[79]\\r\\nAMBER alerts are often displayed on electronic message signs. The Federal Highway Administration has instructed states to display AMBER alerts on highway signs sparingly, citing safety concerns from distracted drivers and the negative impacts of traffic congestion.[80]\\r\\nMany states have policies in place that limit the use of AMBER alerts on freeway signs. In Los Angeles, an AMBER alert issued in October 2002 that was displayed on area freeway signs caused significant traffic congestion. As a result, the California Highway Patrol elected not to display the alerts during rush hour, citing safety concerns.[81] The state of Wisconsin only displays AMBER alerts on freeway signs if it is deemed appropriate by the transportation department and a public safety agency. AMBER alerts do not preempt messages related to traffic safety.[82]\\r\\nThe United States Postal Service issued a postage stamp commemorating AMBER Alerts in May 2006. The 39-cent stamp features a chalk pastel drawing by artist Vivienne Flesher of a reunited mother and child, with the text \\"AMBER ALERT saves missing children\\" across the pane. The stamp was released as part of the observance of National Missing Children's Day.[83][84]\\r\\nIn 2006, a TV movie, Amber's Story, was broadcast on Lifetime. It stars Elisabeth R?hm and Sophie Hough.\\r\\nA comic book entitled Amber Hagerman Deserves Justice: A Night Owl Story was published by Wham Bang Comics in 2009. Geared toward a young audience by teen author Jake Tinsley and Manga artist Jason Dube, it tells Amber's story, recounts the investigation into her murder, and touches on the effect her death has had on young children and parents everywhere. It was created to promote what was then a reopened investigation into her murder.[85]","input":"What is the origin of the amber alert?"},{"output":"Donna-Marie Quinn","context":"Lucy-Jo Hudson (born 4 May 1983) is an English  actress, best known for her roles as  Katy Harris in Coronation Street, Donna-Marie Quinn in Hollyoaks and Rosie Trevanion in the ITV drama Wild at Heart from 2006ÿ09. Her recurring role of Rhiannon Davis in Doctors in 2016 earned her 2017 British Soap Award for Villain of the Year.\\r\\n\\r\\nHudson attended Garforth Community College in Leeds, England, now known as Garforth Academy.[citation needed]\\r\\n\\r\\nBefore landing her role in Coronation Street she appeared in theatre including West Yorkshire Playhouse. She was a regular panellist on Loose Women during 2005.\\r\\n\\r\\nWild at Heart debuted in January 2006 and Hudson starred in it until departing during Series 4 in 2009. She rejoined the cast for Series 7 and the show's finale, which was broadcast on 30 December 2012.[1]\\r\\n\\r\\nHudson's brother, Ryan is a former rugby league footballer, and former captain of the Castleford Tigers. She has a younger sister, Amy-Lou, who is a self-employed dance teacher. Her parents separated before her teens and she lived with her mother in Garforth, moving there from nearby Rothwell. Her father was adopted and is not aware of his true background. She is close friends with X Factor contestant Carolynne Poole.\\r\\n\\r\\nHudson is married to Coronation Street actor Alan Halsall who plays the role of Tyrone Dobbs.[2] On 18 February 2013, the couple announced via Twitter that they were expecting their first child.[3] On 8 September 2013, Hudson gave birth to their daughter, Sienna Rae.[4] The couple announced they were splitting up in March 2016, however they rekindled their relationship several weeks later.[5]","input":"Who did lucy jo hudson play in hollyoaks?"},{"output":"May 10, 1869","context":"","input":"When did the east and west railroads meet?"},{"output":"plantation","context":"A plantation is a large-scale farm that specializes in cash crops. The crops grown include cotton, coffee, tea, cocoa, sugar cane, sisal, oil seeds, oil palms, rubber trees, and fruits. Protectionist policies and natural comparative advantage have sometimes contributed to determining where plantations were located.\\r\\n A plantation house is the main house of a plantation, often a substantial farmhouse, which often serves as a symbol for the plantation as a whole. Plantation houses in the Southern United States and in other areas were often quite grand and expensive architectural works.\\r\\nAmong the earliest examples of plantations were the latifundia of the Roman Empire, which produced large quantities of wine and olive oil for export. Plantation agriculture grew rapidly with the increase in international trade and the development of a worldwide economy that followed the expansion of European colonial empires. Like every economic activity, it has changed over time. Earlier forms of plantation agriculture were associated with large disparities of wealth and income, foreign ownership and political influence, and exploitative social systems such as indentured labor and slavery\\r\\n\\r\\n\\r\\nIndustrial plantations are established to produce a high volume of wood in a short period of time. Plantations are grown by state forestry authorities (for example, the Forestry Commission in Britain) and/or the paper and wood industries and other private landowners (such as Weyerhaeuser, Rayonier and Sierra Pacific Industries in the United States, Asia Pulp & Paper in Indonesia). Christmas trees are often grown on plantations as well. In southern and southeastern Asia, teak plantations have recently replaced the natural forest.\\r\\nIndustrial plantations are actively managed for the commercial production of forest products. Industrial plantations are usually large-scale. Individual blocks are usually even-aged and often consist of just one or two species. These species can be exotic or indigenous. The plants used for the plantation are often genetically altered for desired traits such as growth and resistance to pests and diseases in general and specific traits, for example in the case of timber species, volumic wood production and stem straightness. Forest genetic resources are the basis for genetic alteration. Selected individuals grown in seed orchards are a good source for seeds to develop adequate planting material.\\r\\nWood production on a tree plantation is generally higher than that of natural forests. While forests managed for wood production commonly yield between 1 and 3 cubic meters per hectare per year, plantations of fast-growing species commonly yield between 20 and 30 cubic meters or more per hectare annually; a Grand Fir plantation at Craigvinean in Scotland has a growth rate of 34 cubic meters per hectare per year (Aldhous & Low 1974), and Monterey Pine plantations in southern Australia can yield up to 40 cubic meters per hectare per year (Everard & Fourt 1974). In 2000, while plantations accounted for 5% of global forest, it is estimated that they supplied about 35% of the world's roundwood.[1]\\r\\nSome plantation trees, such as pines and eucalyptus, can be at high risk of fire damage because their leaf oils and resins are flammable to the point of a tree being explosive under some conditions[citation needed]. Conversely, an afflicted plantation can in some cases be cleared of pest species cheaply through the use of a prescribed burn, which kills all lesser plants but does not significantly harm the mature trees.\\r\\nMany forestry experts claim that the establishment of plantations will reduce or eliminate the need to exploit natural forest for wood production. In principle this is true because due to the high productivity of plantations less land is needed. Many point to the example of New Zealand, where 19% of the forest area provides 99% of the supply of industrial round wood. It has been estimated that the world's demand for fiber could be met by just 5% of the world forest (Sedjo & Botkin 1997). However, in practice, plantations are replacing natural forest, for example in Indonesia. According to the FAO, about 7% of the natural closed forest being lost in the tropics is land being converted to plantations. The remaining 93% of the loss is land being converted to agriculture and other uses. Worldwide, an estimated 15% of plantations in tropical countries are established on closed canopy natural forest.\\r\\nIn the Kyoto Protocol, there are proposals encouraging the use of plantations to reduce carbon dioxide levels (though this idea is being challenged by some groups on the grounds that the sequestered CO2 is eventually released after harvest).\\r\\nIn contrast to a naturally regenerated forest, plantations are typically grown as even-aged monocultures, primarily for timber production.\\r\\nIn the 1970s, Brazil began to establish high-yield, intensively managed, short rotation plantations. These types of plantations are sometimes called fast-wood plantations or fiber farms and often managed on a short-rotation basis, as little as 5 to 15 years. They are becoming more widespread in South America, Asia and other areas. The environmental and social impacts of this type of plantation has caused them to become controversial. In Indonesia, for example, large multi-national pulp companies have harvested large areas of natural forest without regard for regeneration. From 1980 to 2000, about 50% of the 1.4 million hectares of pulpwood plantations in Indonesia have been established on what was formerly natural forest land.\\r\\nThe replacement of natural forest with tree plantations has also caused social problems. In some countries, again, notably Indonesia, conversions of natural forest are made with little regard for rights of the local people. Plantations established purely for the production of fiber provide a much narrower range of services than the original natural forest for the local people. India has sought to limit this damage by limiting the amount of land owned by one entity and, as a result, smaller plantations are owned by local farmers who then sell the wood to larger companies. Some large environmental organizations are critical of these high-yield plantations and are running an anti-plantation campaign, notably the Rainforest Action Network and Greenpeace. ==\\r\\nFarm or home plantations are typically established for the production of timber and fire wood for home use and sometimes for sale. Management may be less intensive than with Industrial plantations. In time, this type of plantation can become difficult to distinguish from naturally regenerated forest.\\r\\nTeak and bamboo plantations in India have given good results and an alternative crop solution to farmers of central India, where conventional farming was popular. But due to rising input costs of farming many farmers have done teak and bamboo plantations which require very little water (only during first two years). Teak and bamboo have legal protection from theft. Bamboo, once planted, gives output for 50 years till flowering occurs. Teak requires 20 years to grow to full maturity and fetch returns.\\r\\nThese may be established for watershed or soil protection. They are established for erosion control, landslide stabilization and windbreaks. Such plantations are established to foster native species and promote forest regeneration on degraded lands as a tool of environmental restoration.\\r\\nProbably the single most important factor a plantation has on the local environment is the site where the plantation is established. If natural forest is cleared for a planted forest then a reduction in biodiversity and loss of habitat will likely result. In some cases, their establishment may involve draining wetlands to replace mixed hardwoods that formerly predominated with pine species. If a plantation is established on abandoned agricultural land, or highly degraded land, it can result in an increase in both habitat and biodiversity. A planted forest can be profitably established on lands that will not support agriculture or suffer from lack of natural regeneration.\\r\\nThe tree species used in a plantation is also an important factor. Where non-native varieties or species are grown, few of the native fauna are adapted to exploit these and further biodiversity loss occurs. However, even non-native tree species may serve as corridors for wildlife and act as a buffer for native forest, reducing edge effect.\\r\\nOnce a plantation is established, how it is managed becomes the important environmental factor. The single most important factor of management is the rotation period. Plantations harvested on longer rotation periods (30 years or more) can provide similar benefits to a naturally regenerated forest managed for wood production, on a similar rotation. This is especially true if native species are used. In the case of exotic species, the habitat can be improved significantly if the impact is mitigated by measures such as leaving blocks of native species in the plantation, or retaining corridors of natural forest. In Brazil, similar measures are required by government regulation\\r\\nSugar plantations were highly valued in the Caribbean by the British and French colonists in the 17th and 18th centuries and the use of sugar in Europe rose during this period. Sugarcane is still an important crop in Cuba. Sugar plantations also arose in countries such as Barbados and Cuba because of the natural endowments that they had. These natural endowments included soil that was conducive to growing sugar and a high marginal product of labor realized through the increasing number of slaves.\\r\\nPlantings of para rubber, the tree Hevea brasiliensis, are usually called plantations.\\r\\nOil palm agriculture is rapidly expanding across wet tropical regions, and is usually developed at plantation scale.\\r\\nFruit orchards are sometimes considered to be plantations.\\r\\nThese include tobacco, sugarcane, pineapple, and cotton, especially in historical usage.\\r\\nBefore the rise of cotton in the American South, indigo and rice were also sometimes called plantation crops.\\r\\nWhen Newfoundland was colonized by England in 1610, the original colonists were called \\"Planters\\" and their fishing rooms were known as \\"fishing plantations\\". These terms were used well into the 20th century.\\r\\nThe following three plantations are maintained by the Government of Newfoundland and Labrador as provincial heritage sites:\\r\\nOther fishing plantations:\\r\\nAfrican slave labour was used extensively to work on early plantations (such as tobacco, rice, cotton, and sugar plantations) in the American colonies and the United States, throughout the Caribbean, the Americas, and in European-occupied areas of Africa. Several notable historians and economists such as Eric Williams, Walter Rodney, and Karl Marx contend that the global capitalist economy was largely founded upon the creation and produce of thousands of slave labor camps based in colonial plantations, exploiting tens of millions of purchased Africans.\\r\\nIn modern times, the low wages typically paid to plantation workers are the basis of plantation profitability in some areas.\\r\\nIn more recent times, overt slavery has been replaced by para-slavery or slavery-in-kind, including the sharecropping system. At its most extreme, workers are in \\"debt bondage\\": they must work to pay off a debt at such punitive interest rates that it may never be paid off. Others work unreasonably long hours and are paid subsistence wages that (in practice) may only be spent in the company store.\\r\\nIn Brazil, a sugarcane plantation was termed an engenho (\\"engine\\"), and the 17th-century English usage for organized colonial production was \\"factory.\\" Such colonial social and economic structures are discussed at Plantation economy.\\r\\nSugar workers on plantations in Cuba and elsewhere in the Caribbean lived in company towns known as bateyes.\\r\\nIn the American South, antebellum plantations were centered on a \\"plantation house,\\" the residence of the owner, where important business was conducted. Slavery and plantations had different characteristics in different regions of the South. As the Upper South of the Chesapeake Bay colonies developed first, historians of the antebellum South defined planters as those who held 20 or more slaves. Major planters held many more, especially in the Deep South as it developed.[3] The majority of slaveholders held 10 or fewer slaves, often just a few to labor domestically. By the late 18th century, most planters in the Upper South had switched from exclusive tobacco cultivation to mixed-crop production, both because tobacco had exhausted the soil and because of changing markets. The shift away from tobacco meant they had slaves in excess of the number needed for labor, and they began to sell them in the internal slave trade.\\r\\nThere was a variety of domestic architecture on plantations. The largest and wealthiest planter families, for instance, those with estates fronting on the James River in Virginia, constructed mansions in brick and Georgian style, e.g. Shirley Plantation. Common or smaller planters in the late 18th and 19th century had more modest wood frame buildings, such as Southall Plantation in Charles City County.\\r\\nIn the Lowcountry of South Carolina, by contrast, even before the American Revolution, planters holding large rice plantations typically owned hundreds of slaves. In Charleston and Savannah, the elite also held numerous slaves to work as household servants. The 19th-century development of the Deep South for cotton cultivation depended on large plantations with much more acreage than was typical of the Upper South; and for labor, planters held hundreds of slaves.\\r\\nUntil December 1865 slavery was legal in parts of the United States. Most slaves were employed in agriculture, and planter was a term commonly used to describe a farmer with many slaves.\\r\\nThe term planter has no universally-accepted definition, but academic historians have defined it to identify the elite class, \\"a landowning farmer of substantial means.\\"[3] In the \\"Black Belt\\" counties of Alabama and Mississippi, the terms \\"planter\\" and \\"farmer\\" were often synonymous.[4] Robert Fogel and Stanley Engerman define large planters as owning over 50 slaves, and medium planters as owning between 16 and 50 slaves.[5]\\r\\nIn his study of Black Belt counties in Alabama, Jonathan Wiener defines planters by ownership of real property, rather than of slaves. A planter, for Wiener, owned at least $10,000 worth of real estate in 1850 and $32,000 worth in 1860, equivalent to about the top 8 percent of landowners.[6] In his study of southwest Georgia, Lee Formwalt also defines planters in size of land holdings rather than slaves. Formwalt's planters are in the top 4.5 percent of land owners, translating into real estate worth $6,000 or more in 1850, $24,000 or more in 1860, and $11,000 or more in 1870.[7] In his study of Harrison County, Texas, Randolph B. Campbell classifies large planters as owners of 20 slaves, and small planters as owners of between ten and 19 slaves.[8] In Chicot and Phillips counties, Arkansas, Carl H. Moneyhon defines large planters as owners of twenty or more slaves, and six hundred or more acres.[9]","input":"Where are rubber and palm oil crops usually grown?"},{"output":"20 years and older","context":"A classic car is an older automobile; the exact definition varies around the world. The common theme is of an older car with enough historical interest to be collectable and worth preserving or restoring rather than scrapping.\\r\\nCars 20 years and older typically fall into the classic class.\\r\\nOrganizations such as the Classic Car Club of America (CCCA) and the Antique Automobile Club of America (AACA) maintain a list of eligible unmodified cars that are called \\"classic\\". These are described as \\"fine\\" or \\"distinctive\\" automobile, either American or foreign built, produced between 1915ÿ1998\\r\\nIn the UK, 'classic cars' range from veteran (preÿFirst World War), to vintage (1919ÿ1930), to post-vintage (1930s).\\r\\nPostÿSecond World War \\"classic cars\\" are not precisely defined and the term is often applied to any older vehicle.\\r\\n\\r\\n\\r\\nCars 100 years and older typically fall into the antique class and this includes the \\"Brass Era car\\" that are defined by the Horseless Carriage Club of America (HCCA) as \\"any pioneer gas, steam and electric motor vehicle built or manufactured prior to January 1, 1916.\\"[1]\\r\\nThe \\"classic\\" term is often applied loosely by owners to any car.[2]\\r\\nLegally, most states have time-based rules for the definition of \\"historic\\" or \\"classic\\" for purposes such as antique vehicle registration. For example, Maryland defines historic vehicles as 20 calendar years old or older and they \\"must not have been substantially altered, remodeled or remanufactured from the manufacturers original design\\"[3] while West Virginia defines motor vehicles manufactured at least 25 years prior to the current year as eligible for \\"classic\\" car license plates.[4]\\r\\nDespite this, at many American classic car shows, automobiles typically range from the 1920s to the 1970s. Recently, many 1980s and even early 1990s cars are considered being \\"classic automobiles\\". Examples of cars at such shows include the Chevrolet Bel-Air, Ford Model T, Dodge Charger, Ford Deuce Coupe, and 1949 Ford. Meanwhile, the Concours d'Elegance car shows feature prestigious automobiles such as the Cadillac V16 or pre-1940 Rolls-Royce models. There are also terms as \\"modern customs\\", \\"exotics\\", or \\"collectibles\\" that cover cars such as the AMC Gremlin or Ford Pinto.\\r\\nThere are differences in the exact identification of a \\"classic car\\". Division by separate eras include: horseless carriages (19th-century experimental automobiles such as the Daimler Motor Carriage), antique cars (brass era cars such as the Ford Model T), and classic cars (typically 1930s cars such as the Cord 812). Some also include muscle cars, with the 1974 model year as the cutoff.\\r\\nThe Classic Car Club of America describes a CCCA Classic as a \\"fine\\" or \\"distinctive\\" automobile, either American or foreign built, produced between 1915 and 1948.\\r\\nThe CCCA is dedicated to the preservation and enjoyment of select cars that \\"are distinguished by their respective fine design, high engineering standards and superior workmanship.\\"[6] Other differentiating factors - including engine displacement, custom coachwork, and luxury accessories such as power brakes, power clutch, and \\"one-shot\\" or automatic lubrication systems - help determine whether a car is considered a CCCA Classic.[7] The cars on their list \\"represent the pinnacle of engineering, styling and design for their era.\\"[8]\\r\\nAny CCCA member may petition for a vehicle to join the list.[9] Such applications are carefully scrutinized, but rarely is a new vehicle type admitted.[10] Moreover, no commercial vehicles such as hearses, ambulances, or race cars are accepted as a Full Classic.[9]\\r\\nThe CCCA maintains this definition of \\"classic car\\" and uses terms such as CCCA Classic or the trademarked Full Classic.[11] The CCCA has estimated that 1,366,843 \\"American Classics\\" were built.[12]\\r\\nThe Antique Automobile Club of America (AACA) recognizes \\"motorized vehicles 25 years old or older, which were built in factories and specifically designed and manufactured for transportation use on public roadways and highways.\\"[13] Judging by the AACA evaluates such vehicles to be in historic or that have \\"been restored to the same state as the dealer could have prepared the vehicle for delivery to the customer.\\" Specified AACA classic vehicles include \\"fine or unusual domestic or foreign automobiles primarily built between and including the years 1925 and 1942.\\"[14]\\r\\nThere is no fixed definition of a classic car. Two taxation issues do impact however, leading to some people using them as cutoff dates. All cars built before January 1, 1977, are exempted from paying the annual road tax vehicle excise duty. This is then entered on the licence disc displayed on the windscreen as \\"historic vehicle\\" (if a car built before this date has been first registered in 1977 or later, then its build date would have to be verified by a recognised body such as British Motor Heritage Foundation to claim tax-free status). HM Revenue and Customs define a classic car for company taxation purposes as being over 15 years old and having a value in excess of S15,000.[15] Additionally, popular acclaim through a large number of classic car magazines plays an important role in whether a car comes to be regarded as a classic. It is all subjective and a matter of opinion. The elimination of depreciation is a reason for buying a classic car; this is a major cost of owning a modern car. Picking 'future classics' that are current 'bangers' is a pastime of people into classic cars in the UK. Successfully picking and buying one can result in a profit for the buyer as well as providing transport. An immaculate well cared for prestige model with high running costs that impacts its value, but is not yet old enough to be regarded as a classic, could be a good buy, for example.[16]\\r\\nThere was a worldwide change in styling trends in the immediate years after the end of World War II. The 1946 Crosley and Kaiser-Frazer, for example, changed the traditional discrete replaceable-fender treatment. From this point on, automobiles of all kinds became envelope bodies in basic plan. The CCCA term, \\"antique car\\" has been confined to \\"the functionally traditional designs of the earlier period\\" (mostly pre-war). They tended to have removable fenders, trunk, headlights, and a usual vertical grill treatment. In a large vehicle, such as a Duesenberg, Pierce-Arrow, or in a smaller form, the MG TC, with traditional lines, might typify the CCCA term. Another vehicle might be a classic example of a later period but not a car from the \\"classic period of design\\", in the opinion of the CCCA.\\r\\nThese vehicles are generally older, ranging from 15 to 25 years, but are usually not accepted as classics according to the Antique Automobile Club of America.[citation needed] The German term youngtimer describes older vehicles which have not yet become \\"old timer\\" classic cars.[17]\\r\\nIn the United Kingdom, the modern classic definition is open to the discretion often by Insurance Brokers and Insurance Companies who regard a Modern Classic as a vehicle that is considered collectible regardless of age.[18] The usage of the vehicle limited to recreational purposes or restricted mileage is also taken into account.\\r\\nDrivers of classic cars must be especially careful. Classic cars often lack what are now considered basic safety features, including seat belts, crumple zones or rollover protection. On September 10, 2009, ABC News 'Good Morning America' and 'World News' showed a U.S. Insurance Institute of Highway Safety crash test of a 2009 Chevrolet Malibu in an offset head-on collision with a 1959 Chevrolet Bel Air sedan. It dramatically demonstrated the effectiveness of modern car safety design, over 1950s X-frame design, particularly of rigid passenger safety cells and crumple zones.[19] [20] The 1959 Chevrolets used an X frame design which lacked structural rigidity; had the IIHS used a pre-1958 Chevrolet with a Unibody design, the results would have been much better.[21] Vehicle handling characteristics (particularly steering and suspension) and brake performance are likely to be poorer than current standards, hence requiring greater road-awareness on the part of the driver. In certain areas of the United States, using a classic car as a daily vehicle is strongly discouraged and may even be considered illegal in some places.[22]\\r\\nThe British AA motoring association has urged motorists using or driving near classic cars to pay particular attention to safety. The issue received particular public attention following a 2013 case in which a driver in a hire 1963 MGB was killed immediately in a collision with a taxi.[23][24]\\r\\nRetro-styled (color-coded with chromed buckles) 2-point and 3-point seat (safety) belts are manufactured according to Federal Motor Vehicle Safety Standards (FMVSS). However, most classic car bodies (manufactured before the late 1960s) did not include safety belts as standard equipment, and do not include readily available reinforced mounting points, on the vehicle body, therefore it can be problematic to install such equipment properly: specific studies and calculations should be performed before any attempts. Proper installation is critical, which means locating attachment points on the body/frame, assuring the strength by proper reinforcement, and following the seat belt installation instructions properly to reduce the risk of malfunction or failure.[25] Some classic car owners are reluctant to retrofit seat belts for the loss of originality this modification implies. There have also been instances of cars losing points at shows for being retrofitted with seat belts.[26]\\r\\nFitting modern tires is also a suggestion to improve the handling.[27] However, most modern tires may be much wider and have a lower profile than those used on classic cars when new, therefore they may interfere with suspension elements and the tire walls may become damaged. The suspension of a classic car may not be suitable for radial ply tyres, having been designed to only accommodate bias ply tires. Narrow classic car wheels may have been designed for narrow high-profile tube tires and not be suitable for modern tubeless radial tires. Another problem with modern tires on classic cars is that increased grip requires increased steering effort; many classic cars do not come with power steering. Many major tire companies have dedicated classic car tire marketing departments and will be able to give expert technical advice to address all these issues. It is important to know how radial tires will affect the performance of a car originally fitted with bias-ply tires, and the considerations needed to compensate for the differences.[28]\\r\\nUpgrading braking using either bespoke parts, parts produced by the vehicle's manufacturer, from later versions of the same model or later models that may be compatible with minor modification, is an effective method of improving safety. Popular examples include drum brake to disc brake conversions, or adding a vacuum servo to cars with front disc brakes that did not originally have one.\\r\\nAlthough they lack such advanced safety features as air bags, antilock braking systems, and other electronic controls, most US-market cars built 1966 and later have basic safety features such as padded dashboards, seat belts, dual-circuit braking systems, and safety glass.\\r\\nDespite these concerns, classic cars are involved in significantly fewer accidents.[22][unreliable source?]","input":"How old does car have to be a classic?"},{"output":"Judge Wapner","context":"\\r\\n\\r\\nRain Man is a 1988 American comedy-drama[2] road movie directed by Barry Levinson and written by Barry Morrow and Ronald Bass. It tells the story of an abrasive, selfish young wheeler-dealer Charlie Babbitt (Tom Cruise), who discovers that his estranged father has died and bequeathed all of his multimillion-dollar estate to his other son, Raymond (Dustin Hoffman), an autistic savant, of whose existence Charlie was unaware. Charlie is left with only his father's car and collection of rose bushes. In addition to the two leads, Valeria Golino stars as Charlie's girlfriend, Susanna.\\r\\n\\r\\nMorrow created the character of Raymond after meeting Kim Peek, a real-life savant; his characterization was based on both Peek and Bill Sackter, a good friend of Morrow who was the subject of Bill, an earlier film that Morrow wrote.[3]\\r\\n\\r\\nRain Man received overwhelmingly positive reviews, praising Hoffman's performance and the wit and sophistication of the screenplay, and was the highest-grossing film of 1988. The film won four Oscars at the 61st Academy Awards (March 1989), including Best Picture, Best Original Screenplay, Best Director, and Best Actor in a Leading Role for Hoffman. Its crew received an additional four nominations.[4] The film also won the Golden Bear at the 39th Berlin International Film Festival.[5]\\r\\n\\r\\nCharlie Babbitt is in the middle of importing four Lamborghinis to Los Angeles for resale. He needs to deliver the vehicles to impatient buyers who have already made down payments in order to repay the loan he took out to buy the cars, but the EPA is holding the cars at the port due to the cars failing emissions regulations. Charlie directs an employee to lie to the buyers while he stalls his creditor.\\r\\n\\r\\nWhen Charlie learns that his estranged father has died, he and his girlfriend Susanna travel to Cincinnati, Ohio, in order to settle the estate. He learns he is receiving the classic 1949 Buick Roadmaster convertible which he and his father fought over, but the bulk of the $3 million estate is going to an unnamed trustee. Through social engineering, he learns the money is being directed to a mental institution, where he meets his older brother, Raymond Babbitt, of whom he was previously unaware.\\r\\n\\r\\nRaymond has savant syndrome and adheres to strict routines. He has superb recall, but he shows little emotional expression except when in distress. Charlie spirits Raymond out of the mental institution and into a hotel for the night. Susanna becomes upset with the way Charlie treats his brother and leaves. Charlie asks Raymond's doctor, Dr. Gerald R. Bruner, for half the estate in exchange for Raymond's return, but he refuses. Charlie decides to attempt to gain custody of his brother in order to get control of the money.\\r\\n\\r\\nAfter Raymond refuses to fly back to Los Angeles, they set out on a cross-country road trip together. During the course of the journey, Charlie learns more about Raymond, including that he is a mental calculator with the ability to instantly count hundreds of objects at once, far beyond the normal range of human subitizing abilities. He also learns that Raymond actually lived with the family when Charlie was young and he realizes that the comforting figure from his childhood, whom he falsely remembered as an imaginary friend named \\"Rain Man\\", was actually Raymond.\\r\\n\\r\\nThey make slow progress because Raymond insists on sticking to his routines, which include watching Judge Wapner on television every day and getting to bed by 11:00 PM. He also objects to traveling on the interstate after they pass a bad accident.\\r\\n\\r\\nAfter the Lamborghinis are seized by his creditor, Charlie finds himself $80,000 in the hole and hatches a plan to return to Las Vegas, which they passed the night before, and win money at blackjack by counting cards. Though the casino bosses are skeptical that anyone can count cards with a six deck shoe, after reviewing security footage they ask Charlie and Raymond to leave. Charlie has made enough to cover his debts and has reconciled with Susanna who rejoined them in Las Vegas.\\r\\n\\r\\nBack in Los Angeles, Charlie meets with Dr. Bruner, who offers him $250,000 to walk away from Raymond. Charlie refuses and says that he is no longer upset about what his father left him, but he wants to have a relationship with his brother. At a meeting with a court-appointed psychiatrist Raymond is shown to be unable to decide for himself what he wants. Charlie stops the questioning and tells Raymond he is happy to have him as his brother.\\r\\n\\r\\nCharlie takes Raymond to the train station where he boards an Amtrak train with Dr. Bruner to return to the mental institution. Charlie promises Raymond that he will visit in two weeks.\\r\\n\\r\\nRoger Birnbaum was the first studio executive to give the film a green light; he did so immediately after Barry Morrow pitched the story. Birnbaum received \\"special thanks\\" in the film's credits.[4]\\r\\n\\r\\nAgents at CAA sent the script to Hoffman and Bill Murray, envisioning Murray in the title role and Hoffman in the role eventually portrayed by Cruise.[3] Martin Brest, Steven Spielberg, and Sydney Pollack were directors also involved in the film.[6] Mickey Rourke was also offered a role but he turned it down.[7]\\r\\n\\r\\nPrincipal photography included nine weeks of filming on location.[8] Other portions were shot in the desert near Palm Springs, California.[9]:168ÿ71\\r\\n\\r\\nAlmost all of the principal photography occurred during the 1988 Writers Guild of America strike; one key scene that was affected by the lack of writers was the film's final scene.[3]  Bass delivered his last rough cut of the script only hours before the strike started and spent no time on the set.[6]\\r\\n\\r\\nThe film has an approval rating of 89% on Rotten Tomatoes, with an average rating of 7.9/10, based on 73 reviews. The website's critical consensus states: \\"This road-trip movie about an autistic savant and his callow brother is far from seamless, but Barry Levinson's direction is impressive, and strong performances from Tom Cruise and Dustin Hoffman add to its appeal.\\"[10] Metacritic gave the film a score of 65 out of 100 based on 18 critical reviews, indicating \\"generally favorable reviews\\".[11]\\r\\n\\r\\nVincent Canby of The New York Times called Rain Man a \\"becomingly modest, decently thought-out, sometimes funny film\\"; Hoffman's performance was a \\"display of sustained virtuosity . . . [which] makes no lasting connections with the emotions. Its end effect depends largely on one's susceptibility to the sight of an actor acting nonstop and extremely well, but to no particularly urgent dramatic purpose.\\"[12] Canby considered the \\"film's true central character\\" to be \\"the confused, economically and emotionally desperate Charlie, beautifully played by Mr. Cruise.\\"[12]\\r\\n\\r\\nAmy Dawes of Variety wrote that \\"one of the year's most intriguing film premises ... is given uneven, slightly off-target treatment\\"; she called the road scenes \\"hastily, loosely written, with much extraneous screen time,\\" but admired the last third of the film, calling it a depiction of \\"two very isolated beings\\" who \\"discover a common history and deep attachment.\\"[8]\\r\\n\\r\\nOne of the film's harshest reviews came from New Yorker magazine critic Pauline Kael, who said, \\"Everything in this movie is fudged ever so humanistically, in a perfunctory, low-pressure way. And the picture has its effectiveness: people are crying at it. Of course they're crying at itÿit's a piece of wet kitsch.[13]\\r\\n\\r\\nRoger Ebert gave the film three and a half stars out of four.[14]\\r\\n\\r\\nRain Man debuted on December 16, 1988, and was the second highest-grossing film at the weekend box office (behind Twins), with $7 million.[15] It reached the first spot on the December 30 ÿ January 2 weekend, finishing 1988 with $42 million.[16] The film would end up as the highest-grossing U.S. film of 1988 by earning over $172 million. The film grossed over $354 million worldwide.[1]\\r\\n\\r\\nRain Man won Academy Awards for Best Picture, Best Actor in a Leading Role (Dustin Hoffman), Best Director and Best Writing, Original Screenplay. It was nominated for Best Art Direction (Art Direction: Ida Random; Set Decoration: Linda DeScenna), Best Cinematography (John Seale), Best Film Editing, and Best Original Score (Hans Zimmer).[17]\\r\\n\\r\\nThe film was nominated for twenty-four other ceremonies, including the Golden Globes, in which it won Best Motion Picture in the drama genre and Best Actor (Dustin Hoffman), and was nominated for Best Director (Barry Levinson) and Best Screenplay (Ronald Bass and Barry Morrow). Valeria Golino received a nomination for Best Supporting Actress at the Silver Ribbon.\\r\\n\\r\\nRain Man's portrayal of the main character's condition has been seen as inaugurating a common but mistaken media stereotype that people on the autism spectrum typically have savant skills, and references to Rain Man, in particular Dustin Hoffman's performance, have become a popular shorthand for autism and savantism. Conversely, Rain Man has also been seen as dispelling a number of other misconceptions about autism, and improving public awareness of the failure of many agencies to accommodate autistic people and make use of the abilities they do have, regardless of whether they have savant skills or not.[18]\\r\\n\\r\\nThe film is also known for popularizing the misconception that card counting is illegal in the United States.[19]\\r\\n\\r\\nDuring June 1989, at least fifteen major airlines showed edited versions of Rain Man that omitted a scene involving Raymond's refusal to fly, except on Australia-based Qantas. Those criticizing this move included film director Barry Levinson, co-screenwriter Ronald Bass, and George Kirgo (at the time the President of the Writers Guild of America, West). \\"I think it's a key scene to the entire movie,\\" Levinson said in a telephone interview. \\"That's why it's in there. It launches their entire odyssey across country ÿ because they couldn't fly.\\" While some of those airlines cited as justification avoiding having airplane passengers feel uncomfortable in sympathy with Raymond during the in-flight entertainment, the scene was shown intact on flights of Qantas, and commentators noted that Raymond mentions it as the only airline whose planes have \\"never crashed\\".[20][21] The film is in fact credited with introducing Qantas' safety record to U.S. consumers.[22][23]","input":"What tv show did rainman have to watch?"},{"output":"Vlade Divac","context":"The 1996ÿ97 NBA season was the 9th season for the Charlotte Hornets in the National Basketball Association.[1] During the offseason, the Hornets acquired Anthony Mason from the New York Knicks,[2] and Vlade Divac from the Los Angeles Lakers.[3] Under new head coach Dave Cowens, the new-look Hornets played better than expected: Divac and Matt Geiger provided the best center combo in the league, Mason averaged a double-double and earned All-NBA Third Team honors, and Glen Rice had the finest season of his career, finishing third in the league in scoring with a career high of 26.8 points per game, and earning All-NBA Second Team honors. Rice also set several scoring records in the 1997 NBA All-Star Game, and was selected the game's MVP.[4] At midseason, the Hornets traded Scott Burrell to the Golden State Warriors while acquiring Ricky Pierce from the Denver Nuggets. The Hornets went on a nine-game winning streak in April, and finished fourth in the Central Division with a franchise best record at 54ÿ28, making it back to the playoffs after a one-year absence.\\r\\nIn the first round of the playoffs, they were swept by the New York Knicks in three straight games. The Hornets led the NBA in attendance for the eighth and final time during their history in Charlotte. They also had the best three-point percentage in NBA history shooting 42.8% from beyond the arch. Following the season, Pierce re-signed as a free agent with the Milwaukee Bucks.\\r\\n\\r\\n\\r\\nIn the 1996 NBA Draft, the Hornets selected Kobe Bryant with the 13th overall pick. Before he was chosen by the Hornets, the 17-year-old Bryant had made a lasting impression on then-Lakers general manager Jerry West, who immediately foresaw potential in Bryant's basketball ability during pre-draft workouts. West even went on to state that Bryant's workouts were some of the best he had seen. Immediately after the draft, Dave Cowens expressed that the Hornets had no use for him. Fifteen days later, West traded his starting center, Vlade Divac to the Hornets for the young Kobe Bryant.\\r\\nNote: Statistics are correct through the end of the 2015ÿ16?season.\\r\\n\\r\\nReleased Michael Adams.\\r\\nTraded Kobe Bryant to the Los Angeles Lakers for Vlade Divac.\\r\\nReleased Robert Parish.\\r\\nTraded Larry Johnson to the New York Knicks for Brad Lohaus and Anthony Mason.\\r\\nSigned Bob McCann as a free agent.\\r\\nOctober 19, 1996\\r\\nSigned Tony Smith as a free agent.\\r\\nWaived Brad Lohaus.\\r\\nSigned Jamie Feick to the first of two 10-day contracts.\\r\\nSigned Eric Leckner to a 10-day contract.\\r\\nSigned Tom Chambers to a contract for the rest of the season.\\r\\nTraded Scott Burrell to the Golden State Warriors for Donald Royal.\\r\\nTraded Anthony Goldwire and George Zidek to the Denver Nuggets for Ricky Pierce.\\r\\nWaived Tom Chambers.","input":"Who did the charlotte hornets trade kobe bryant for?"},{"output":"Just under two hours after the Titanic sank","context":"","input":"How long did it take for titanic survivors to be rescued?"},{"output":"Second Lieutenant Frank Luke","context":"Luke Air Force Base (IATA: LUF,?ICAO: KLUF,?FAA LID: LUF) is a United States Air Force base located seven miles (11?km) west of the central business district of Glendale, in Maricopa County, Arizona, United States.[2] It is also about 15 miles (24?km) west of Phoenix, Arizona.\\r\\nLuke AFB is a major training base of the Air Education and Training Command (AETC), training pilots in the F-16 Fighting Falcon. On 31 March 2011 it was announced that the F-35 Lightning II would replace the F-16 as the primary training aircraft at Luke, although the date of deployment of the new aircraft to Luke and reorganization plans were not announced. On 16 July 2013, the Air Force announced that Luke AFB will house a total of 144 F-35A Lightning IIs.[3]\\r\\nIt is a designated Superfund site due to a number of soil and groundwater contaminants.\\r\\n\\r\\n\\r\\nLuke Air Force Base is an active-duty F-16 Fighting Falcon training base with 170 F-16s assigned. The host command at Luke is the 56th Fighter Wing (56 FW), under Air Education and Training Command's 19th Air Force.\\r\\nThe 56th FW is composed of four groups, 27 squadrons, including six training squadrons. There are several tenant units on base, including the 944th Fighter Wing, assigned to 10th Air Force and the Air Force Reserve. The 56th Fighter Wing also trains more than 700 maintenance technicians each year.\\r\\nThe base population includes about 7500 military members and 15,000 family members. With about 80,000 retired military members living in greater Phoenix, the base services a total population of more than 100,000 people.\\r\\nAn integral part of Luke's F-16 fighter pilot training mission is the Barry M. Goldwater Air Force Range. The range consists of 1,900,000 acres (7,700?km2) of relatively undisturbed Sonoran Desert southwest of Luke Air Force Base between Yuma and Tucson south of Interstate 8. Overhead are 57,000 cubic miles (240,000?km3) of airspace where pilots practice air-to-air maneuvers and engage simulated battlefield targets on the ground. Roughly the size of Connecticut, the immense size of the complex allows for simultaneous training activities on nine air-to-ground and two air-to-air ranges. The Luke Air Force Base Range Management Office manages the eastern range activities and Marine Corps Air Station Yuma oversees operations on the western portion.\\r\\nIn addition to flying and maintaining the F-16, Luke airmen also deploy to support on-going operations in Iraq, Afghanistan and to combatant commanders in other locations around the world. In 2004, more than 900 Luke airmen deployed, with most supporting Operation Iraqi Freedom.\\r\\nSince June 2012, Luke AFB has been the permanent home of Naval Operational Support Center (NOSC) Phoenix of the US Navy. A NOSC is a facility used to provide operational support for training and administrative services to Navy Reserve Units. NOSC Phoenix supports over 750 Navy Reservists in sixteen Navy Reserve units. The new 32,055 square foot, one-story facility is located on a 1.85 acre site at Luke AFB with sufficient parking and a secured perimeter to meet current anti-terrorism and force protection standards. NOSC Phoenix serves a full-time command and administrative staff, a medical unit, and reservists during drill weekends. It also has a 4800 square foot drill hall, command staff offices, reserve unit administration spaces, medical and dental examination areas, six classrooms, a distance learning center, a physical fitness room, and a quarterdeck. The $11.2 million facility is the first LEED Platinum certified building of the US Navy Reserve Force.\\r\\nThe host unit, the 56th Fighter Wing, is tasked to train F-35 and F-16 fighter pilots and maintainers. Historically, the wing graduated more than 400 F-16 pilots and 470 crew chiefs annually.\\r\\nGroups:\\r\\nTenant Units:\\r\\nAutonomous Units:\\r\\nThe public has been more accommodating to the military operations at Luke Air Force base compared to other Arizona installations like the Davis-Monthan Air Force Base, according to a 2015 study. This is due to a buffer of public land around it, that helps against encroachment and land use conflicts. Also, the private sector in Glendale has been helping to maintain the buffer of public land, and with it the Arizona defense economy. This is because if encroachment impacts a sites mission, it loses value for the military operation, and base closure is more likely to occur.[4]\\r\\nLuke Air Force Base was named after Second Lieutenant Frank Luke (1897ÿ1918). Lt Luke is a posthumous Medal of Honor recipient and the number two United States ace in World War I.\\r\\nBorn in Phoenix in 1897, the \\"Arizona Balloon Buster\\" scored 18 aerial victories during World War I (14 of these German observation balloons) in the skies over France . Lieutenant Luke was shot down at Murvaux between Verdun and Stenay, France, on 29 Sep 1918, after he had destroyed three enemy balloons. Surviving the crash of his Spad, Lieutenant Luke drew two pistols and fired on German soldiers, killing several of them before he was killed.\\r\\nLuke Field, Oahu, Hawaii Territory (now the Naval Air Station Ford Island) was previously named in his honor.\\r\\nIn 1940, the U.S. Army sent a representative to Arizona to choose a site for an Army Air Corps training field for advanced training in conventional fighter aircraft. The city of Phoenix bought 1,440 acres (5.8?km2) of land which they leased to the government at $1 a year effective 24 March 1941. On 29 March 1941, the Del. E. Webb Construction Co. began excavation for the first building at what was known then as Litchfield Park Air Base. Another base known as Luke Field, in Pearl Harbor, Hawaii, released its name so the Arizona base could be called Luke Field. Advanced flight training in the AT-6 began at Luke in June that same year. The first class of 45 students, Class 41 F, arrived 6 June 1941 to begin advanced flight training in the AT-6, although a few essential buildings had been completed. Flying out of Sky Harbor Airport until the Luke runways were ready, pilots received 10 weeks of instruction and the first class graduated 15 August 1941. Then-Captain Barry Goldwater served as director of ground training the following year.\\r\\nDuring World War II, Luke Field was the largest fighter training base in the Army Air Forces, graduating more than 12,000 fighter pilots from advanced and operational courses earning the nickname, Home of the Fighter Pilot.\\r\\nThe base was under the control of the 37th Flying Training Wing (Advanced Single-Engine), Western Flying Training Command, AAF Flying Training Command. During the years of World War II, more than 17,000 pilots trained at Luke Field, making it the largest single engine advanced flying training school in the U.S. More than a million hours of flying were logged, primarily in the AT-6 Texan, along with some transitioning to P-40 Warhawk fighters and later the P-51 Mustang and P-47 Thunderbolt.\\r\\nAlthough continually modified during the war years, the course of advanced flight training at Luke averaged about 10 weeks and included both flight training and ground school. Approximately 60 hours of flying instruction covered formation flying, navigation, and instrument flying, as well as a bit of aerial acrobatics. About 20 additional hours of flight practice concentrated on aerial and gunnery training.\\r\\nGround school, or classroom training for the advanced flying course, varied from about 100 to 130 hours and was intermingled with flight time in the aircraft. Cadets flew in the morning and attended ground school in the afternoons, or flew training missions in the afternoon after a morning of ground school. At the peak of the training program at Luke, some students were required to attend night classes. Ground school included instruction in navigation, flight planning, radio equipment, maintenance, and weather.\\r\\nBy 7 February 1944, pilots at Luke had achieved a million hours of flying time. A World War II film \\"A Guy Named Joe\\" included some footage filmed at Luke. By 1946, however, the number of pilots trained dropped to 299 and the base was deactivated 30 November that year.\\r\\nSoon after combat started in Korea, Luke field was reactivated on 1 February 1951 as Luke Air Force Base, part of the Air Training Command (ATC) under the reorganized United States Air Force. A steady pipeline of trained bomber-escort pilots was needed by Strategic Air Command, and the mission of Luke AFB was to augment the jet fighter combat crew training in operation at Nellis AFB. The school at Luke was designated by ATC as the USAF Air Crew School (Fighter Bomber/Escort).\\r\\nThe program was to be conducted by the Federalized Michigan Air National Guard 127th Fighter Group, which had transferred from Continental Air Command to ATC, effective 10 February. The wing moved from Romulus Airport, Michigan, to Luke on 23 February, and on 1 March ATC established the USAF Air Crew School (Fighter-Bomber/Escort) at Luke. Fighter-bomber training began on 1 March 1951 in the P-51 Mustang, being replaced by early-model F-84C Thunderjets.\\r\\nEffective 5 March, the 127th was redesignated as the 127th Pilot Training Wing. On 1 November 1952, the active-duty 3600th Flying Training Wing (Fighter) replaced the Air National Guardsmen. ATC flying training squadrons at Luke included:\\r\\nThe 3600th FTW became the dedicated training organization for both USAF and NATO pilots in the F-84. The F-84D began having electrical problems with the hot, dry Arizona air which dried out the aircraft's electrical insulation. They were replaced by F-84E, and shortly afterwards to the F-84G which was then in use by SAC. In October 1954, ATC re-designated the 3600th as a \\"Combat Crew Training Wing\\" to describe its mission better.\\r\\nIn January 1954, the swept-wing F-84F Thunderstreak began to arrive, and three additional dedicated squadrons were activated:\\r\\nF-84F's replaced the straight-winged earlier models in the original four squadrons by the end of 1956, giving the wing seven squadrons of twenty-one aircraft each, or about 150 aircraft. Thirty more were received in 1957 as some of the older production blocks were transferred to Air National Guard units or to reclamation at Davis-Monthan AFB.\\r\\nFor several years, the Armed Forces Special Weapons Project at Sandia Base, New Mexico, had provided all atomic, biological, and chemical (ABC) warfare training for the Air Force. Beginning in October 1954, ATC added ABC instruction to its fighter pilot programs at Luke and Nellis. In addition, ATC established six general ABC courses to train aircrews already in the field, using mobile training teams.\\r\\nOn 25 May 1953 the 3600th Air Demonstration Team was officially organized and established at Luke, still officially carrying this designation, now known as the United States Air Force Thunderbirds. At Luke, the squadron initially operated F-84G Thunderjets, as the aircraft had to be able to show how good training made a typical aircraft easy to handle. The aircraft had to be stable for maneuvers in formation, reliable enough to meet show schedules, rugged for the demonstration team. In addition, the F-84G was the first fighter in the Air Force with mid-air refueling capability. To convert the aircraft from combat to demonstration, technicians removed the guns and plugged the gun ports.\\r\\nIn 1955, the Air Force selected the swept-wing F-84F Thunderstreak as their second aircraft. The Thunderstreak was modified for the team by adding smoke tanks for the first time, and red, white, and blue drag chutes. In addition, the extreme heat from the lead aircraft, 1,500?F (820?C), required moving the slot's radio antenna from the jet's fin. For the first time, a solo was added to the diamond displays, increasing the show time to 19 minutes.\\r\\nThe unit was reassigned to Nellis AFB, Nevada on 23 June 1956.\\r\\nF-100 Super Sabre era\\r\\nBy the end of 1957, ATC basing structure had changed considerably as the result of tactical commitments, decreased student load, and fund shortages. During 1958 ATC discontinued its Flying Training and Technical Training Air Force. As a result, Luke AFB was transferred to Tactical Air Command. This reassignment came about as the result of a USAF-directed study of the feasibility of putting combat crew training under the appropriate zone of interior operational commands.\\r\\nWith the transfer to TAC, the ATC 3600th FTW was re-designated as the 4510th Combat Crew Training Wing, and flying training at Luke was changed to the F-100 Super Sabre. F-100 training squadrons were:\\r\\nDuring the 1960s, thousands of American fighter pilots left Luke to carve their niche in the annals of Air Force history in the skies over Vietnam in the F-100. In July 1968, the first \\"LA\\" tail codes were placed on the tails of Luke-based aircraft.\\r\\nF-4 Phantom II era\\r\\nThe 58th Tactical Fighter Training Wing replaced the provisional 4510th CCTW on 15 October 1969. Although Luke remained under the jurisdiction of Tactical Air Command, the HQ USAF-controlled (AFCON) 58th TFTW gave the wing at Luke a permanent lineage and history that the TAC provisional wing could not carry.\\r\\nThe provisional squadrons of the 4510th were re-designated as follows:\\r\\n* Assigned to the 58th TFTW with the inactivation of the 4540th Combat Crew Training Group (see below)\\r\\nUpon activation of the 310th TFTS, the squadron began receiving new A-7D Corsair II ground attack aircraft from Ling-Temco-Vought, with a mission to train USAF pilots in the new aircraft. Its F-100s were reassigned to other squadrons which flew the F-100s of the 4510th CCTS. The 310th TFTS sent its A-7Ds to the 333d TFS at D-M in July 1971, and became an F-4C RTU.\\r\\nThe 425th TFTS was assigned to the 58th as a Geographically Separated Unit in 1969, assigned to Williams AFB. The squadron was established in December 1963 as the 4441st CCTS, with a mission to train Republic of Vietnam Air Force pilots on the Northrup F-5A Freedom Fighter. The F-5 training continued at Williams after the end of the Vietnam War, becoming a squadron to train Military Assistance Program (MAP) pilots from over 20 nations on the F-5. It was discontinued in 1989 and the 425th was inactivated.\\r\\nIn the summer of 1971, the 58th TFTW received F-4C Phantom IIs, and the wing assumed the F-4 pilot training role that was formerly done by the 4453d CCTW at Davis-Monthan AFB, when D-M was converted to an operational A-7D base by the arrival of the 355th TFW from Takhli RTAFB, Thailand.\\r\\nF-15 Eagle era\\r\\nIn November 1974, the Air Forces newest air superiority fighter, the F-15 Eagle, came to Luke. To accommodate the F-15, the 555th Tactical Fighter Training Squadron was activated. The early F-15A's, however, were quite troublesome, with engine problems limiting their effectiveness and also their availability.\\r\\nIt was not until June 1976 that a second F-15 training squadron was established, with the 4461st Tactical Fighter Training Squadron sanding up on 23 June. The assets of the 4461st TFTS were re-designated as: 461st Tactical Fighter Training Squadron: 1 July 1977. The 550th TFTS traded in its F-4s in August 1977 becoming the third F-15 training squadron. The F-15As, which remained troublesome throughout the 1970s, were replaced in 1982 with the updated F-15D.\\r\\nOn 25 August 1979, the 405th Tactical Training Wing was activated at Luke AFB, Arizona by Tactical Air Command to consolidate the F-15 Eagle Replacement Training Unit (RTU) operations. It took over the 425th, 461st 550th and 555th Tactical Fighter Training Squadrons\\r\\nThe 426th Tactical Fighter Training Squadron converted from F-4 Phantom II to F-15 training in January 1981 specifically to support the TAC Air Defense Command (ADTAC) training mission inherited from the inactivated Aerospace Defense Command which was merged into TAC. On 19 November 1990, the 555th TFTS changed its course from air superiority combat training with the Eagle to air defense interceptor training with the F-15C/D when TAC began assigning F-15s to interceptor duty, the 426th being inactivated.\\r\\nThe 461st TFTS received first F-15E Strike Eagle, July 1988, and the 550th TFTS became the second F-15E Strike Eagle training squadron in March 1989.\\r\\nOn 1 October 1991, due to the implementation of the Objective Wing at Luke and the \\"One base, one wing\\" policy, the 405th TTW was shut down and the F-15s were reassigned back to the 58th TTW.\\r\\nIn 1993, 1st Lt Jeannie M. Flynn became the first female to complete training in the F-15E Strike Eagle at Luke. After earning a master's degree in aerospace engineering from Stanford University, she graduated first in her UPT class at Laughlin AFB in December 1992, and chose the F-15 after Chief of Staff General Merrill McPeak opened the door for women to fly combat aircraft.\\r\\nF-16 Falcon era\\r\\nThe 310th and 311th TFTS retained their F-4Cs until April 1982, ending the Phantom era at Luke, receiving Block 1 F-16A Fighting Falcons in November 1982 and April 1983. Luke-based F-16s began carrying tail codes \\"LF\\". 310th TFTS officially began training fighter pilots 2 February 1983.\\r\\nIn 1990 Luke AFB was placed on the National Priorities List, often called the Superfund list in 1990. After many years of cleanup and remediation, on 22 April 2002 became the first Air Force base to be removed from the list, after satisfying the requirement to remove pollution dating back as far as World War II.\\r\\nThe end of the Cold War in the early 1990s brought significant changes to the base. On 1 October 1991, the 58th Tactical Training Wing adopted the Air Force Objective Organization Plan, and was re-designated simply as the 58th Fighter Wing (58 FW). All operational fighter training squadrons were reassigned to the new 58th Operations Group (58 OG). Training units also re-designated as \\"Fighter Squadrons\\". Units assigned to the 58 OG were:\\r\\nIn 1991, the Base Realignment and Closure (BRAC) commission ordered that all flightline activities cease at MacDill AFB by 1993. The host unit at MacDill AFB, the 56th Fighter Wing, would move its F-16 training to Luke AFB, and Luke would be an exclusive F-16 Fighting Falcon training base. The F-15s would be reassigned to Seymour Johnson AFB, North Carolina in order to accommodate additional F-16 training at Luke.\\r\\nIn addition, the 58th Fighter Wing would be inactivated and moved to Kirtland AFB, New Mexico, with the historical senior 56th FW taking over all assets at Luke. At Kirtland, the wing would be re designated as the 58th Special Operations Wing, leaving all aircraft and equipment at Luke, and be reassigned to Air Force Special Operations Command, replacing the Air Training Command 542d Crew Training Wing.\\r\\nOn 1 June 1992, Tactical Air Command was inactivated, and the new Air Combat Command (ACC) replaced it, assuming jurisdiction of Luke AFB.\\r\\nOn 30 December 1992, the 425th Fighter Squadron was activated at Luke AFB. The mission of the 425th was to provide advanced weapons and tactics continuation for Republic of Singapore Air Force's F-16 pilots and maintenance personnel. Aircraft had already arrived for the squadron in October and shortly after in the new year pilot training began in January 1993.\\r\\nOn 1 April 1994, after 24 years at Luke AFB, the 58th Fighter Wing was replaced by the 56th Fighter Wing (56 FW), relocated from MacDill AFB, Floridas due to Base Realignment and Closure Commission action, as part of the Air Force Heritage Program. With the reassignment, jurisdiction of Luke AFB was transferred to Air Education and Training Command (AETC), Nineteenth Air Force (19 AF) as a result of the Air Force deciding to consolidate all Air Force training programs under AETC. The 56th Operations Group assumed control over all operational fighter squadrons.\\r\\nThe transfer of Luke to Air Education and Training Command gave the command front-line aircraft, bases and facilities that could be used for realistic operational training. With the return of AETC to Luke, it was possible to produce a task-certified or more mission ready apprentice, operational units could reduce the amount of on-the-job training provided to new airmen.\\r\\nWithin a year, the wing realignment to make the 56 OG an exclusive F-16 group took place. The 555th Fighter Squadron was reassigned to USAFE on 25 March 1994 as part of a realignment of Aviano AB, Italy; its F-15C/D Eagles being sent to Tyndall AFB, Florida where F-15 air defense interceptor training was being consolidated under First Air Force. The F-15E Strike Eagle squadrons (461st, 550th) were also inactivated, with their Strike Eagles being sent to Seymour Johnson AFB under the 4th Fighter Wing.\\r\\nF-15 training ended with the last \\"LA\\" tail coded F-15 (Luke Arizona) leaving on 26 September 1995 when the 550th Fighter Squadron inactivated, 21 years after the first TF-15A arrived at Luke.\\r\\nWith the transfer of the Eagles, additional F-16 training units were assigned to the 56 OG, all tail-coded \\"LF\\" (Luke Falcons):\\r\\nThe 21st Fighter Squadron was activated on 8 August 1996 to train Republic of China Air Force F-16A/B crews at Luke AFB. Empty hangars were refurbished and aircrews were pulled in from other units on base. By January 1997 several ROCAF F-16A/B block 20s had been delivered and the first training flights began for their crews. Despite being A/B models, the aircraft were new construction from General Dynamics, with modern avionics and engines, and were considered to be more advanced than the F-16C/Ds being flown from Luke AFB. The aircraft carry USAF markings and serial numbers, also the \\"LF\\" tail code.\\r\\nOn 20 September 1999, an F-16D crashed at Luke AFB, marking the 56th Fighter Wings seventh Class A mishap in FY99. In all cases, the pilots ejected safely. Engine problems caused most of the mishaps. The 56th Fighter Wing commander, Brig Gen John Barry, grounded the wings F-16s after the second mishap. Maintenance personnel discovered that engine augmentor ducts had failed in both cases. They developed a new inspection procedure to identify cracks, which was subsequently used throughout the Air Force. A manufacturing defect in turbine blades was responsible for many of the mishaps, and General Barry grounded the fleet a second time to allow maintainers to upgrade the turbine blades, which improved safety.\\r\\nWhen 1st Lt Joshua Padgett completed the F-16 basic course on 8 March 2000, he became the 50,000th fighter pilot to graduate from Luke AFB, Arizona, since the Army Air Forces started training there in July 1941\\r\\nAfter the 9/11/2001 terrorist attacks, Luke suspended routine flying training operations, as the Federal Aviation Administration shut down the nations airways to all but select military flights. Aircraft of the 56th Fighter Wing were deployed to fly Combat Air Patrols over New York City and Washington, D.C. in the immediate aftermath of the attacks in support of Operation Noble Eagle. Although the 56th Fighter Wing does not deploy aircraft to United States Air Forces Central Command Expeditionary units as part of the Global War on Terrorism, Luke Airmen routinely deploy to USAFCENT in AEF deployment cycles, engaging in combat in support of Operation Enduring Freedom (OEF); Operation Iraqi Freedom (OIF), and other expeditionary operations as tasked.\\r\\nIn 2002 the 56th Fighter Wing became responsible for the nearby Barry M. Goldwater Training Range, became concerned that urban development near the base would curtail flying training if left unchecked. In addition, the Munitions Storage Area (MSA) stood outside of the base compound, adding a burden to the Security Forces Squadron. In October 2002, Senator John McCain of Arizona shepherded a MILCON funding insert of $13 million to purchase 273 acres (1.10?km2) needed to incorporate the MSA into the base perimeter and to acquire additional land in order to preserve access to the Goldwater Range.\\r\\nBRAC 2005 directed that the older Block 25 F-16s be sent to Air National Guard units, this change reduced the number of fighter squadrons, with the 61st and 63d Fighter Squadrons inactivating in 2009 and 2010.\\r\\nIn 1959 Air Defense Command established a Semi Automatic Ground Environment (SAGE) Data Center (DC-21) at Luke AFB. The SAGE system was a network linking Air Force (and later FAA) General Surveillance Radar stations into a centralized center for Air Defense, intended to provide early warning and response for a Soviet nuclear attack. It was initially under the Phoenix Air Defense Sector (PhADS), established on 15 June 1959. PhADS was inactivated on 1 April 1966, and re-designated as the 27th Air Division. DC-21 with its AN/FSQ-7 computer remained under the 27th AD until 19 November 1969 it was inactivated and its assets absorbed by the 26th Air Division. DC-21 was inactivated on 9 December 1983 when technology advances made SAGE obsolete.\\r\\nAir Force Reserve training began at Luke AFB in 1960 with the activation of the 302d Air Rescue Squadron. The 302d had a distinguished heritage and lineage, being formed as the 302d Fighter Squadron, one of four African-American fighter squadrons to enter combat during World War II. It saw combat in the European Theater of Operations (ETO) and Mediterranean Theater of Operations (MTO) from 17 February 1944 ÿ 20 February 1945.\\r\\nFor many years the 302d operated a variety of Air Rescue helicopters from the base, training for and performing search and rescue (SAR) missions, in addition to some medical air evacuation missions. In 1974, its mission changed to training for a combat SAR role, while continuing to perform some search and rescue.\\r\\nThe squadron's mission changed again, in 1987, to a fighter role as the 302d Tactical Fighter Squadron, being assigned to the AFRES (now AFRC) 944th Fighter Wing. The 302d TFS was equipped with block 25/32 F-16C Fighting Falcons, carrying tail code \\"LR\\". The 302d TFS trained for counterair, interdiction, and close air support missions. It deployed several times since late 1992 to Turkey to help enforce the no-fly zone over Iraq and to Italy to support UN air operations in the Balkans, The 302d FS was moved to Holloman AFB, New Mexico and converted to F-22A Raptors on 2 October 2007.\\r\\nThe 69th Fighter Squadron was activated at Luke on 1 Feb 2010, equipped with Block 42 F-16Cs, tail code \\"LF\\", 69th FS carrying a black tail band. The 69th had formerly been assigned to Luke as an active-duty squadron from 1969ÿ1983, flying Lockheed F-104G Starfighters training pilots from the West German Air Force (See below).\\r\\nFrom 1957 to 1965 830 pilots from the West German air force were trained on the F-84 at Luke AFB under Air Training Command. Since Northern European weather and operational restrictions placed severe limitations on the amount of training, Luke AFB was chosen, where flying conditions were ideal for most of the time.\\r\\nOn 4 April 1963 the USAF and the Federal Republic of Germany signed contracts for a unique pilot training program. One agreement called for undergraduate pilot training for West German Air Force (GAF) and West German Navy (GN) students in Cessna T-37 Tweet and Northrop T-38 Talon jet aircraft at Williams AFB, Arizona. The second agreement provided for advanced fighter training in the Lockheed Lockheed F-104G Starfighter at Luke AFB. The two programs were interrelated. Graduates of the basic flight training at Williams were programmed for the advanced training at Luke, resulting in an almost two-year tour of duty in the United States for the young German pilots. The advanced training at Luke was the unique aspect of the program.\\r\\nThe host 4510th Combat Crew Training Wing (CCTW) at Luke was tasked with providing the advanced flying training. On 20 February 1964, the 4540th Combat Crew Training Group (CCTG) was organized and designated to conduct GAF training at Luke. The group was activated on 1 April. Prior to designating the 4540th CCTG, the 4518th Combat Crew Training Squadron was activated on 1 March 1964 and was reassigned to the 4540th CCTG upon the later's activation. A second squadron, the 4519th Combat Crew Training Squadron, was assigned to the group, effective 1 July 1964. The German unit was named \\"2. Deutsche Luftwaffen-Ausbildungsstaffel F-104 USA (2. DtLwAusbStff F-104 USA)\\" (2nd German Air Force Training Squadron F-104 USA). Although remaining German property, the Starfighters carried USAF insignia and were assigned American serial numbers.\\r\\nBy mid July 1964, 23 TF-104G and 12 F-104G were assigned to Luke. On 26 August 1964 a total of 14 USAF F-104 instructor pilots graduated in the second class conducted at Luke. With a sufficient number of aircraft and instructor pilots, preparations were on target to receive the first advanced training class scheduled for October 1964. Aircraft inventories at Luke peaked in 1967 and 1968. In 1967, 100 aircraft were assigned, 62 F-104G and 38 TF-104G: The total increased to 102 in 1968, 61 F-104G models and 41 TF-104G models.\\r\\nMajor changes occurred in organization on 1 October 1969 when the 58th Tactical Fighter Training Wing (TFTW) was activated, replacing the 4510th CCTW as the host unit at Luke. Concurrently, the 69th Tactical Fighter Training Squadron and the 418th Tactical Fighter Training Squadron were activated as F-104 training units, replacing the 4518th CCTS and 4519th CCTS.\\r\\nBy 1975, a decrease in training requirements was accompanied by a corresponding decrease in the fleet size. The two squadrons were consolidated in 1976 with the 418th TFTS inactivating on 1 October 1976. Also a storage program was started to preserve the lifespan of the aircraft. As of 30 September 1975 some 13 aircraft were in flyable storage. Training of West German Air Force pilots in the F-104G continued until late 1982. The Germans flew more than 900 Starfighters totaling an excess of 269,750 hours and produced 1,868 F-104 pilots. The 69th TFTS inactivated on 16 March 1983.\\r\\nNATO F-104 Pilot Training\\r\\nA third F-104G squadron at Luke, the 4443d Combat Crew Training Squadron, differed from the West German squadrons in that it was associated with the Military Assistance Program (MAP) with students from NATO and other friendly nations being trained in the Starfighter. On 22 May 1964, TAC relieved the 4443d CCTS from its assignment to the 831st Air Division at George AFB, California, and reassigned it to the 4540th CCTG, effective 1 August 1964. The move consolidated all F-104 training at one location. The F-104s that purchased with MAP funds and were assigned USAF serial numbers for record-keeping purposes although they never carried USAF insignia. On 15 June 1969 the 4443rd CCTS was inactivated.\\r\\nThe facility was placed on temporary reduced activity status, 6 July 1946; temporarily inactivated, 31 October 1946. It became a sub-installation of Williams Air Force Base, Arizona, 3 Dec 1946 ÿ 5 Mar 1951. It was removed from inactive status, placed on active status, 1 January 1951.\\r\\nNote: * Operated DC-21 ADCOM/ADTAC SAGE blockhouse\\r\\n3600th Flying Training Wing\\r\\n4510th Combat Crew Training Group\\r\\nFile:58th Tactical Training Wing\\r\\nPhoenix Air Defense Sector\\r\\n26th Air Division\\r\\n27th Air Division\\r\\n832d Air Division\\r\\n944th Fighter Wing (AFRC)","input":"Who is luke air force base named after?"},{"output":"seating capacity of approximately 12,000 spectators","context":"The Denny Sanford Premier Center is a large, multi-use  indoor arena in Sioux Falls, South Dakota.  The building is located at 1201 North West Avenue, and is connected to the Sioux Falls Arena and Sioux Falls Convention Center, and is adjacent to Howard Wood Field, and Sioux Falls Stadium. The arena's naming rights partners, and largest sponsors, are Sanford Health, First Premier Bank and Premier Bankcard.[6]\\r\\n\\r\\nCompleted in 2014, it has a seating capacity of approximately 12,000 spectators and replaces the DakotaDome and the Rushmore Plaza Civic Center as the largest indoor venue in South Dakota.[7] The Sioux Falls Arena remains and hosts smaller concerts and events, while the Denny Sanford Premier Center hosts large scale concerts and sporting events.[8]\\r\\n\\r\\nA replacement of the Sioux Falls Arena had been discussed since 1999, with numerous task forces formed and studies completed to determine the need for a new events center.[2]  The Sioux Falls Arena was built in 1961 when the population of Sioux Falls was 65,000.[9]  By 2000, the population had nearly doubled to 124,000[9] while updates to the Arena were few and far between.  After years of arguments and meetings, the new events center was put to a public vote in a special election on November 8, 2011.  By a vote of 23,284 to 16,807, Sioux Falls citizens passed the events center special ballot, allowing design and construction of a new events center to begin.[4]\\r\\n\\r\\nThe first concert held at the arena was held on October 3, 2014 and featured Jason Aldean and Florida Georgia Line with Tyler Farr in front of a sold-out crowd of over 11,000 fans.[10]\\r\\n\\r\\nSlipknot, along with guests Korn and opening band King 810, performed at the Premier Center as part of the \\"Prepare for hell\\" tour on November 9, 2014.[11] Eric Church and Dwight Yoakam performed at the venue on December 6, 2014 as part of The Outsiders World Tour.[12]\\r\\n\\r\\nOther artists and acts that have performed at the venue are Luke Bryan, Demi Lovato,[13] Christina Perri,[13] Carrie Underwood (who holds the highest attendance), and Varekai - a Cirque du Soleil production.[14]\\r\\n\\r\\nEvents in 2015 included Chris Tomlin, Nickelback, Kenny Chesney, Def Leppard, Rod Stewart, The Eagles, Ed Sheeran, Lady Antebellum, Shania Twain, Elton John, and M?tley Cre. Paul McCartney will be appearing on May 2, 2016.\\r\\n\\r\\nThe Premier Center hosts The Summit League Men's Basketball Tournament and The Summit League Women's Basketball Tournament every year in March.  The winner receives an automatic berth to the NCAA Men's Division I Basketball Championship and the NCAA Women's Division I Basketball Championship, respectively.\\r\\n\\r\\nThe Denny Sanford Premier Center also plays host to the home contests of the Sioux Falls Stampede of the United States Hockey League and the Sioux Falls Storm of the Indoor Football League.\\r\\n\\r\\nSince 2015, the Professional Bull Riders (PBR) association has hosted an annual Built Ford Tough Series event at the Premier Center, known as the First Premier Bank/Premier Bankcard Invitational.\\r\\n\\r\\nCountry-pop Canadian singer, Shania Twain brought her Rock This Country Tour to the arena on September 23, 2015 to play a sold-out show of 9,925 patrons, grossing over $1 million from the single-night show. She returned three years later during her Shania Now Tour on May 16, 2018.","input":"How big is the denny sanford premier center?"},{"output":"seventeen","context":"Christine is a 1983 American horror film directed by John Carpenter and starring Keith Gordon, John Stockwell, Alexandra Paul, and Harry Dean Stanton. The film also features supporting performances from Roberts Blossom and Kelly Preston. Written by Bill Phillips and based on the novel of the same name by Stephen King, the plot follows a sentient and violent vintage Plymouth Fury named Christine, and its effects on the car's new teenage owner.\\r\\nUpon its release, the film has grossed $21 million at the US box office. Despite a lukewarm reception among critics, the film has become a cult classic.[3]\\r\\n\\r\\n\\r\\nIn 1978, Arnold \\"Arnie\\" Cunningham (Keith Gordon) is an awkward and unpopular teenager, in Rockbridge, California, with only one friend, Dennis Guilder (John Stockwell). Arnie's life begins to change when he buys a used, badly battered red-and-white 1958 Plymouth Fury, named \\"Christine,\\" in need of extensive repairs. Arnie begins to restore Christine at a local repair shop and junkyard, Darnell's Autobody, but as he spends more of his time working on the car, he discards his glasses, dresses more like a 1950s greaser, and develops an arrogant personality. Dennis and Arnie's new girlfriend, Leigh Cabot (Alexandra Paul), discover the car's previous owner was obsessed with Christine and committed suicide in it by carbon monoxide poisoning.\\r\\nA group of bullies at schoolangry with Arnie after a shop class confrontation results in the lead bully, Buddy Repperton (William Ostrander), being expelledvandalize Christine. Arnie is devastated and determined to repair Christine. As he examines the ruined car, he hears the creaking of metal and notices the engine is now fully restored. Arnie tells the car, \\"Show me.\\" Christine flips on its lights and restores itself to showroom quality, then, driving itself, seeks out the vandals. Moochie Wells (Malcolm Danare) is targeted first and crushed to death in an alley. Richie and Don are caught in a gas station explosion (which sets Christine on fire); and Buddy is run over and burned by the flaming car. Darnell (Robert Prosky), owner of the garage and junkyard where Arnie restored and keeps his Plymouth Fury, is killed in the garage when he sits in the car and is crushed between the seat the steering wheel.\\r\\nOn New Year's Eve, Dennis and Leigh reason that the only way to stop Christine and save Arnie is to destroy the car. Dennis scratches \\"Darnell's Tonight\\"referencing the name of the junkyardinto Christine's hood, then makes his way there with Leigh. Dennis waits in a bulldozer while Leigh heads to the office so that she can shut the door after Christine arrives, trapping the car. Christine, who has been lying in wait the entire time, shines the headlights from under a pile of trash and the car charges after Leigh. Christine crashes into Darnell's office in an attempt to kill Leigh, and Arnie (revealed to have been driving the car himself) is thrown through Christine's windshield. He is impaled on a shard of glass and dies, reaching out to touch Christine one last time. Christine continues to attack Dennis and Leigh, repeatedly sustaining damage and regenerating. Dennis pulls Leigh into the cab of the bulldozer; the two then smash Christine, driving back and forth over the car with the bulldozer as it mocks them by playing \\"Rock and Roll Is Here To Stay\\" over the radio until at last it is too shredded to regenerate again.\\r\\nDennis and Leigh survive and leave behind the remains of the car. The closing shot of the film is of Christine, now having been crushed into a cube by a car crusher, as a piece of the grille slowly begins to straighten.\\r\\nProducer Richard Kobritz had previously produced the miniseries Salem's Lot, also based on a Stephen King novel; through producing the miniseries, Kobritz became acquainted with King, who sent him manuscripts of two of his novels, Cujo, and Christine.[4] Kobritz purchased the rights to Christine after finding himself attracted to the novel's \\"celebration of America's obsession with the motorcar.\\"[4]\\r\\nAccording to John Carpenter, Christine was not a film he had planned on directing, saying that he directed the film as \\"a job\\" as opposed to a \\"personal project.\\"[5] He had previously directed The Thing (1982), which had done poorly at the box office and led to critical backlash.[4] In retrospect, Carpenter stated that upon reading Christine, he felt that \\"It just wasn't very frightening. But it was something I needed to do at that time for my career.\\"[5]\\r\\nKing's novel, the source material for Carpenter's film, made it clear that the car was possessed by the evil spirit of its previous owner, Roland D. LeBay, whereas the film version of the story shows that the evil spirit surrounding the car was present on the day it was built.[6] Other elements from the novel were altered for the film, particularly the execution of the death scenes, which the filmmakers opted for a more \\"cinematic approach.\\"[7]\\r\\nInitially, Columbia Pictures had wanted to cast Brooke Shields in the role of Leigh due to her publicity after the release of The Blue Lagoon (1980), and Scott Baio as Arnie.[4] The filmmakers declined the suggestion, opting to cast young actors who were still fairly unknown. Kevin Bacon auditioned for the role, but opted out when offered a part in Footloose (1984).[4] Carpenter cast Keith Gordon in the role of Arnie after an audition in New York City; Gordon had some experience in film, and was also working in theater at the time; John Stockwell was cast at an audition in Los Angeles.[4]\\r\\nNineteen-year-old Alexandra Paul was cast in the film after audition in New York City; according to Carpenter, Paul was an \\"untrained, young actress\\" at the time, but brought a \\"great quality\\" about the character of Leigh.[4] According to Paul, she had not read any of King's books or seen Carpenter's films, and read the novel in preparation.[4]\\r\\nChristine was shot largely in Los Angeles, California, while the location for Darnell's garage was located in Santa Clarita.[7] Filming began in April 1983, merely days after the King novel had been published.[8] The film's stunts were primarily completed by stunt coordinator Terry Leonard, who was behind the wheel of the car during the high-speed chase scenes, as well as the scene in which the car drives down a highway engulfed in flames.[7]\\r\\nAlthough the car in the film is identified as a 1958 Plymouth Fury[9]and in 1983 radio ads promoting the film, voiceover artists announced, \\"she's a '57 Fury\\"two other Plymouth models, the Belvedere and the Savoy, were also used to portray the malevolent automobile onscreen. John Carpenter placed ads throughout Southern California searching for models of the car, and was able to purchase twenty-four of them in various states of disrepair, which were used to build a total of seventeen models of the Fury.[8]\\r\\nTotal production for the 1958 Plymouth Fury was only 5,303, and they were difficult to find and expensive to buy at the time. In addition, the real-life Furys only came in one color, \\"Buckskin Beige\\", seen on the other Furys on the assembly line during the initial scenes of the movie.[10] The Fury also got anodized gold trim on the body and Fury script on the rear fender. In order to bypass the problem of obtaining the rare trim, the cars featured the more common Belvedere \\"Dartline\\" trim. Several vehicles were destroyed during filming, but most of the cars were Savoy and Belvedere models dressed to look like the Fury. At least one '57 Savoy was used, its front end modified to look like a '58.\\r\\nOriginally, Carpenter had not planned to film the car's regeneration scenes, but decided after the shoot had finished to include them. The shots of the car regenerating itself were shot in post-production and done using hydraulics.[7]\\r\\nOf the twenty cars used in the film, only two still exist. One is a stunt vehicle with a manual transmission and now resides in the hands of a private California collector.[11] The other vehicle was rescued from a junkyard and restored by collector Bill Gibson of Pensacola, Florida.[12]\\r\\nChristine was released in North America on December 9, 1983, to 1,045 theaters.[13]\\r\\nIn its opening weekend Christine brought in $3,408,904 landing at #4. The film dropped 39.6% in its second weekend, grossing $2,058,517 slipping from fourth to eighth place. In its third weekend, it grossed $1,851,909 dropping to #9. The film remained at #9 its fourth weekend, grossing $2,736,782. In its fifth weekend, it returned to #8, grossing $2,015,922. Bringing in $1,316,835 it its sixth weekend, the film dropped out of the box office top ten to twelfth place. In its seventh and final weekend, the film brought in $819,972 landing at #14, bringing the total gross for Christine to $21,017,849.[2]\\r\\nBased on 25 reviews collected by Rotten Tomatoes, Christine has an overall 68% approval rating from critics and an average score of 5.9 out of 10.[14] Variety gave the film a negative review, stating: \\"Christine seems like a retread. This time its a fire-engine red, 1958 Plymouth Fury thats possessed by the Devil, and this deja-vu premise [from the novel by Stephen King] combined with the crazed-vehicle format, makes Christine appear pretty shop worn.\\"[15]\\r\\nRoger Ebert gave the movie three out of four stars, saying: \\"by the end of the movie, Christine has developed such a formidable personality that we are actually taking sides during its duel with a bulldozer. This is the kind of movie where you walk out with a silly grin, get in your car, and lay rubber halfway down the Eisenhower.\\"[16] Janet Maslin of The New York Times gave the film a middling review, saying: \\"The early parts of the film are engaging and well acted, creating a believable high-school atmosphere. Unfortunately, the later part of the film is slow in developing, and it unfolds in predictable ways.\\"[17] Time Out said of the film: \\"Carpenter and novelist Stephen King share not merely a taste for genre horror but a love of '50's teenage culture; and although set in the present, Christine reflects the second taste far more effectively than the first.\\"[18]\\r\\nThe film was released on VHS by Columbia Pictures, and later in a special edition DVD in 2004.[19] On March 12, 2013, Twilight Time video released the film on Blu-ray for the first time in a limited edition run numbered at 3,000 copies.[20] On September 29, 2015, Sony Pictures Home Entertainment re-released the film on Blu-ray.[21]\\r\\nTwo soundtracks were released, one consisting purely of the music written and composed by John Carpenter and Alan Howarth, the other consisting of the contemporary pop songs used in the film.[22]\\r\\nThe soundtrack album containing songs used in the film was entitled Christine: Original Motion Picture Soundtrack and was released on LP and cassette on Motown Records.[23] It contained 10 (of the 15) songs listed in the film's credits, plus one track from John Carpenter and Alan Howarth's own score. The track listing was as follows:\\r\\nThe following tracks were not included on this LP release, but were used in the film and listed in the film's credits:","input":"How many cars were used to film christine?"},{"output":"metamorphic","context":"Igneous rock (derived from the Latin word ignis meaning fire), or magmatic rock, is one of the three main rock types, the others being sedimentary and metamorphic. Igneous rock is formed through the cooling and solidification of magma or lava. The magma can be derived from partial melts of existing rocks in either a planet's mantle or crust. Typically, the melting is caused by one or more of three processes: an increase in temperature, a decrease in pressure, or a change in composition. Solidification into rock occurs either below the surface as intrusive rocks or on the surface as extrusive rocks. Igneous rock may form with crystallization to form granular, crystalline rocks, or without crystallization to form natural glasses.\\r\\n\\r\\n\\r\\nIgneous and metamorphic rocks make up 90ÿ95% of the top 16?km of the Earth's crust by volume.[1] Igneous rocks form about 15% of the Earth's current land surface.[note 1] Most of the Earth's oceanic crust is made of igneous rock.\\r\\nIgneous rocks are also geologically important because:\\r\\nIn terms of modes of occurrence, igneous rocks can be either intrusive (plutonic and hypabyssal) or extrusive (volcanic).\\r\\nIntrusive igneous rocks are formed from magma that cools and solidifies within the crust of a planet, surrounded by pre-existing rock (called country rock); the magma cools slowly and, as a result, these rocks are coarse-grained. The mineral grains in such rocks can generally be identified with the naked eye. Intrusive rocks can also be classified according to the shape and size of the intrusive body and its relation to the other formations into which it intrudes. Typical intrusive formations are batholiths, stocks, laccoliths, sills and dikes. When the magma solidifies within the earth's crust, it cools slowly forming coarse textured rocks, such as granite, gabbro, or diorite.\\r\\nThe central cores of major mountain ranges consist of intrusive igneous rocks, usually granite. When exposed by erosion, these cores (called batholiths) may occupy huge areas of the Earth's surface.\\r\\nIntrusive igneous rocks that form at depth within the crust are termed plutonic (or abyssal) rocks and are usually coarse-grained. Intrusive igneous rocks that form near the surface are termed subvolcanic or hypabyssal rocks and they are usually medium-grained. Hypabyssal rocks are less common than plutonic or volcanic rocks and often form dikes, sills, laccoliths, lopoliths, or phacoliths.\\r\\nExtrusive igneous rocks, also known as volcanic rocks, are formed at the crust's surface as a result of the partial melting of rocks within the mantle and crust. Extrusive igneous rocks cool and solidify quicker than intrusive igneous rocks. They are formed by the cooling of molten magma on the earth's surface. The magma, which is brought to the surface through fissures or volcanic eruptions, solidifies at a faster rate. Hence such rocks are smooth, crystalline and fine-grained. Basalt is a common extrusive igneous rock and forms lava flows, lava sheets and lava plateaus. Some kinds of basalt solidify to form long polygonal columns. The Giant's Causeway in Antrim, Northern Ireland is an example.\\r\\nThe molten rock, with or without suspended crystals and gas bubbles, is called magma. It rises because it is less dense than the rock from which it was created. When magma reaches the surface from beneath water or air, it is called lava. Eruptions of volcanoes into air are termed subaerial, whereas those occurring underneath the ocean are termed submarine. Black smokers and mid-ocean ridge basalt are examples of submarine volcanic activity.\\r\\nThe volume of extrusive rock erupted annually by volcanoes varies with plate tectonic setting. Extrusive rock is produced in the following proportions:[3]\\r\\nMagma that erupts from a volcano behaves according to its viscosity, determined by temperature, composition, crystal content and the amount of silica. High-temperature magma, most of which is basaltic in composition, behaves in a manner similar to thick oil and, as it cools, treacle. Long, thin basalt flows with pahoehoe surfaces are common. Intermediate composition magma, such as andesite, tends to form cinder cones of intermingled ash, tuff and lava, and may have a viscosity similar to thick, cold molasses or even rubber when erupted. Felsic magma, such as rhyolite, is usually erupted at low temperature and is up to 10,000 times as viscous as basalt. Volcanoes with rhyolitic magma commonly erupt explosively, and rhyolitic lava flows are typically of limited extent and have steep margins, because the magma is so viscous.\\r\\nFelsic and intermediate magmas that erupt often do so violently, with explosions driven by the release of dissolved gasestypically water vapour, but also carbon dioxide. Explosively erupted pyroclastic material is called tephra and includes tuff, agglomerate and ignimbrite. Fine volcanic ash is also erupted and forms ash tuff deposits, which can often cover vast areas.\\r\\nBecause lava usually cools and crystallizes rapidly, it is usually fine-grained. If the cooling has been so rapid as to prevent the formation of even small crystals after extrusion, the resulting rock may be mostly glass (such as the rock obsidian). If the cooling of the lava happened more slowly, the rock would be coarse-grained.\\r\\nBecause the minerals are mostly fine-grained, it is much more difficult to distinguish between the different types of extrusive igneous rocks than between different types of intrusive igneous rocks. Generally, the mineral constituents of fine-grained extrusive igneous rocks can only be determined by examination of thin sections of the rock under a microscope, so only an approximate classification can usually be made in the field.\\r\\nIgneous rocks are classified according to mode of occurrence, texture, mineralogy, chemical composition, and the geometry of the igneous body.\\r\\nThe classification of the many types of different igneous rocks can provide us with important information about the conditions under which they formed. Two important variables used for the classification of igneous rocks are particle size, which largely depends on the cooling history, and the mineral composition of the rock. Feldspars, quartz or feldspathoids, olivines, pyroxenes, amphiboles, and micas are all important minerals in the formation of almost all igneous rocks, and they are basic to the classification of these rocks. All other minerals present are regarded as nonessential in almost all igneous rocks and are called accessory minerals. Types of igneous rocks with other essential minerals are very rare, and these rare rocks include those with essential carbonates.\\r\\nIn a simplified classification, igneous rock types are separated on the basis of the type of feldspar present, the presence or absence of quartz, and in rocks with no feldspar or quartz, the type of iron or magnesium minerals present. Rocks containing quartz (silica in composition) are silica-oversaturated. Rocks with feldspathoids are silica-undersaturated, because feldspathoids cannot coexist in a stable association with quartz.\\r\\nIgneous rocks that have crystals large enough to be seen by the naked eye are called phaneritic; those with crystals too small to be seen are called aphanitic. Generally speaking, phaneritic implies an intrusive origin; aphanitic an extrusive one.\\r\\nAn igneous rock with larger, clearly discernible crystals embedded in a finer-grained matrix is termed porphyry. Porphyritic texture develops when some of the crystals grow to considerable size before the main mass of the magma crystallizes as finer-grained, uniform material.\\r\\nIgneous rocks are classified on the basis of texture and composition. Texture refers to the size, shape, and arrangement of the mineral grains or crystals of which the rock is composed.\\r\\nTexture is an important criterion for the naming of volcanic rocks. The texture of volcanic rocks, including the size, shape, orientation, and distribution of mineral grains and the intergrain relationships, will determine whether the rock is termed a tuff, a pyroclastic lava or a simple lava.\\r\\nHowever, the texture is only a subordinate part of classifying volcanic rocks, as most often there needs to be chemical information gleaned from rocks with extremely fine-grained groundmass or from airfall tuffs, which may be formed from volcanic ash.\\r\\nTextural criteria are less critical in classifying intrusive rocks where the majority of minerals will be visible to the naked eye or at least using a hand lens, magnifying glass or microscope. Plutonic rocks also tend to be less texturally varied and less prone to gaining structural fabrics. Textural terms can be used to differentiate different intrusive phases of large plutons, for instance porphyritic margins to large intrusive bodies, porphyry stocks and subvolcanic dikes (apophyses). Mineralogical classification is most often used to classify plutonic rocks. Chemical classifications are preferred to classify volcanic rocks, with phenocryst species used as a prefix, e.g. \\"olivine-bearing picrite\\" or \\"orthoclase-phyric rhyolite\\".\\r\\nIgneous rocks can be classified according to chemical or mineralogical parameters.\\r\\nChemical: total alkali-silica content (TAS diagram) for volcanic rock classification used when modal or mineralogic data is unavailable:\\r\\nChemical classification also extends to differentiating rocks that are chemically similar according to the TAS diagram, for instance:\\r\\nAn idealized mineralogy (the normative mineralogy) can be calculated from the chemical composition, and the calculation is useful for rocks too fine-grained or too altered for identification of minerals that crystallized from the melt. For instance, normative quartz classifies a rock as silica-oversaturated; an example is rhyolite. In an older terminology, silica oversaturated rocks were called silicic or acidic where the SiO2 was greater than 66% and the family term quartzolite was applied to the most silicic. A normative feldspathoid classifies a rock as silica-undersaturated; an example is nephelinite.\\r\\nIn 1902, a group of American petrographers proposed that all existing classifications of igneous rocks should be discarded and replaced by a \\"quantitative\\" classification based on chemical analysis. They showed how vague, and often unscientific, much of the existing terminology was and argued that as the chemical composition of an igneous rock was its most fundamental characteristic, it should be elevated to prime position.\\r\\nGeological occurrence, structure, mineralogical constitutionthe hitherto accepted criteria for the discrimination of rock specieswere relegated to the background. The completed rock analysis is first to be interpreted in terms of the rock-forming minerals which might be expected to be formed when the magma crystallizes, e.g., quartz feldspars, olivine, akermannite, Feldspathoids, magnetite, corundum, and so on, and the rocks are divided into groups strictly according to the relative proportion of these minerals to one another.[5][6]\\r\\nFor volcanic rocks, mineralogy is important in classifying and naming lavas. The most important criterion is the phenocryst species, followed by the groundmass mineralogy. Often, where the groundmass is aphanitic, chemical classification must be used to properly identify a volcanic rock.\\r\\nMineralogic contents ÿ felsic versus mafic\\r\\nFor intrusive, plutonic and usually phaneritic igneous rocks (where all minerals are visible at least via microscope), the mineralogy is used to classify the rock. This usually occurs on ternary diagrams, where the relative proportions of three minerals are used to classify the rock.\\r\\nThe following table is a simple subdivision of igneous rocks according to both their composition and mode of occurrence.\\r\\nFor a more detailed classification see QAPF diagram.\\r\\nGranite is an igneous intrusive rock (crystallized at depth), with felsic composition (rich in silica and predominately quartz plus potassium-rich feldspar plus sodium-rich plagioclase) and phaneritic, subeuhedral texture (minerals are visible to the unaided eye and commonly some of them retain original crystallographic shapes).\\r\\nThe Earth's crust averages about 35 kilometers thick under the continents, but averages only some 7ÿ10 kilometers beneath the oceans. The continental crust is composed primarily of sedimentary rocks resting on a crystalline basement formed of a great variety of metamorphic and igneous rocks, including granulite and granite. Oceanic crust is composed primarily of basalt and gabbro. Both continental and oceanic crust rest on peridotite of the mantle.\\r\\nRocks may melt in response to a decrease in pressure, to a change in composition (such as an addition of water), to an increase in temperature, or to a combination of these processes.\\r\\nOther mechanisms, such as melting from a meteorite impact, are less important today, but impacts during the accretion of the Earth led to extensive melting, and the outer several hundred kilometers of our early Earth was probably an ocean of magma. Impacts of large meteorites in the last few hundred million years have been proposed as one mechanism responsible for the extensive basalt magmatism of several large igneous provinces.\\r\\nDecompression melting occurs because of a decrease in pressure.[7]\\r\\nThe solidus temperatures of most rocks (the temperatures below which they are completely solid) increase with increasing pressure in the absence of water. Peridotite at depth in the Earth's mantle may be hotter than its solidus temperature at some shallower level. If such rock rises during the convection of solid mantle, it will cool slightly as it expands in an adiabatic process, but the cooling is only about 0.3?C per kilometer. Experimental studies of appropriate peridotite samples document that the solidus temperatures increase by 3?C to 4?C per kilometer. If the rock rises far enough, it will begin to melt. Melt droplets can coalesce into larger volumes and be intruded upwards. This process of melting from the upward movement of solid mantle is critical in the evolution of the Earth.\\r\\nDecompression melting creates the ocean crust at mid-ocean ridges. It also causes volcanism in intraplate regions, such as Europe, Africa and the Pacific sea floor. There, it is variously attributed either to the rise of mantle plumes (the \\"Plume hypothesis\\") or to intraplate extension (the \\"Plate hypothesis\\").[8]\\r\\nThe change of rock composition most responsible for the creation of magma is the addition of water. Water lowers the solidus temperature of rocks at a given pressure. For example, at a depth of about 100 kilometers, peridotite begins to melt near 800?C in the presence of excess water, but near or above about 1,500?C in the absence of water.[9] Water is driven out of the oceanic lithosphere in subduction zones, and it causes melting in the overlying mantle. Hydrous magmas composed of basalt and andesite are produced directly and indirectly as results of dehydration during the subduction process. Such magmas, and those derived from them, build up island arcs such as those in the Pacific Ring of Fire. These magmas form rocks of the calc-alkaline series, an important part of the continental crust.\\r\\nThe addition of carbon dioxide is relatively a much less important cause of magma formation than the addition of water, but genesis of some silica-undersaturated magmas has been attributed to the dominance of carbon dioxide over water in their mantle source regions. In the presence of carbon dioxide, experiments document that the peridotite solidus temperature decreases by about 200?C in a narrow pressure interval at pressures corresponding to a depth of about 70?km. At greater depths, carbon dioxide can have more effect: at depths to about 200?km, the temperatures of initial melting of a carbonated peridotite composition were determined to be 450?C to 600?C lower than for the same composition with no carbon dioxide.[10] Magmas of rock types such as nephelinite, carbonatite, and kimberlite are among those that may be generated following an influx of carbon dioxide into mantle at depths greater than about 70?km.\\r\\nIncrease in temperature is the most typical mechanism for formation of magma within continental crust. Such temperature increases can occur because of the upward intrusion of magma from the mantle. Temperatures can also exceed the solidus of a crustal rock in continental crust thickened by compression at a plate boundary. The plate boundary between the Indian and Asian continental masses provides a well-studied example, as the Tibetan Plateau just north of the boundary has crust about 80 kilometers thick, roughly twice the thickness of normal continental crust. Studies of electrical resistivity deduced from magnetotelluric data have detected a layer that appears to contain silicate melt and that stretches for at least 1,000 kilometers within the middle crust along the southern margin of the Tibetan Plateau.[11] Granite and rhyolite are types of igneous rock commonly interpreted as products of the melting of continental crust because of increases in temperature. Temperature increases also may contribute to the melting of lithosphere dragged down in a subduction zone.\\r\\nMost magmas only entirely melt for small parts of their histories. More typically, they are mixes of melt and crystals, and sometimes also of gas bubbles. Melt, crystals, and bubbles usually have different densities, and so they can separate as magmas evolve.\\r\\nAs magma cools, minerals typically crystallize from the melt at different temperatures (fractional crystallization). As minerals crystallize, the composition of the residual melt typically changes. If crystals separate from the melt, then the residual melt will differ in composition from the parent magma. For instance, a magma of gabbroic composition can produce a residual melt of granitic composition if early formed crystals are separated from the magma. Gabbro may have a liquidus temperature near 1,200?C, and the derivative granite-composition melt may have a liquidus temperature as low as about 700?C. Incompatible elements are concentrated in the last residues of magma during fractional crystallization and in the first melts produced during partial melting: either process can form the magma that crystallizes to pegmatite, a rock type commonly enriched in incompatible elements. Bowen's reaction series is important for understanding the idealised sequence of fractional crystallisation of a magma.\\r\\nMagma composition can be determined by processes other than partial melting and fractional crystallization. For instance, magmas commonly interact with rocks they intrude, both by melting those rocks and by reacting with them. Magmas of different compositions can mix with one another. In rare cases, melts can separate into two immiscible melts of contrasting compositions.\\r\\nThere are relatively few minerals that are important in the formation of common igneous rocks, because the magma from which the minerals crystallize is rich in only certain elements: silicon, oxygen, aluminium, sodium, potassium, calcium, iron, and magnesium. These are the elements that combine to form the silicate minerals, which account for over ninety percent of all igneous rocks. The chemistry of igneous rocks is expressed differently for major and minor elements and for trace elements. Contents of major and minor elements are conventionally expressed as weight percent oxides (e.g., 51% SiO2, and 1.50% TiO2). Abundances of trace elements are conventionally expressed as parts per million by weight (e.g., 420 ppm Ni, and 5.1 ppm Sm). The term \\"trace element\\" is typically used for elements present in most rocks at abundances less than 100 ppm or so, but some trace elements may be present in some rocks at abundances exceeding 1,000 ppm. The diversity of rock compositions has been defined by a huge mass of analytical dataover 230,000 rock analyses can be accessed on the web through a site sponsored by the U. S. National Science Foundation (see the External Link to EarthChem).\\r\\nThe word \\"igneous\\" is derived from the Latin ignis, meaning \\"of fire\\". Volcanic rocks are named after Vulcan, the Roman name for the god of fire. Intrusive rocks are also called \\"plutonic\\" rocks, named after Pluto, the Roman god of the underworld.\\r\\nVolcanic rocks:\\r\\nSubvolcanic rocks:\\r\\nPlutonic rocks:\\r\\nKomatiite, Picrite basalt\\r\\nKimberlite, Lamproite\\r\\nPeridotite\\r\\nBasalt\\r\\nDiabase (Dolerite)\\r\\nGabbro\\r\\nAndesite\\r\\nMicrodiorite\\r\\nDiorite\\r\\nDacite\\r\\nMicrogranodiorite\\r\\nGranodiorite\\r\\nRhyolite\\r\\nMicrogranite, Aplite\\r\\nGranite","input":"What rock is found 10 kilometers beneath the earth's surface?"},{"output":"the \\"liberation of Palestine\\" through armed struggle","context":"The Palestine Liberation Organization (PLO; Arabic: ????? ??????? ???????????, ?Muna??amat at-Ta?rؐr al-Filas?ؐniyyah?(help{info)) is an organization founded in 1964 with the purpose of the \\"liberation of Palestine\\" through armed struggle, with much of its violence aimed at Israeli civilians.[5][6][7][8][9][7][10][11] It is recognized as the \\"sole legitimate representative of the Palestinian people\\" by over 100 states with which it holds diplomatic relations,[12][13] and has enjoyed observer status at the United Nations since 1974.[14][15][16] The PLO was considered by the United States and Israel to be a terrorist organization[17][18] until the Madrid Conference in 1991. In 1993, the PLO recognized Israel's right to exist in peace, accepted UN Security Council resolutions 242 and 338, and rejected \\"violence and terrorism\\". In response, Israel officially recognized the PLO as the representative of the Palestinian people.[19] However, the PLO has employed violence in the years since 1993, particularly during the 2000-2005 Second Intifada.\\r\\n\\r\\n\\r\\nAt its first summit meeting in Cairo in 1964, the Arab League initiated the creation of an organization representing the Palestinian people.[20] The Palestinian National Council convened in Jerusalem on 28 May 1964. Concluding this meeting the PLO was founded on 2 June 1964. Its stated goal was the \\"liberation of Palestine\\" through armed struggle.[21]\\r\\nThe ideology of the PLO was formulated in the founding year 1964 in the Palestinian National Covenant.[21] The document is a combative anti-Zionist statement dedicated to the \\"restoration of the Palestinian homeland\\". It has no reference to religion. In 1968, the Charter was replaced by a comprehensively revised version.[22]\\r\\nUntil 1993, the only promoted option was armed struggle. From the signing of the Oslo Accords, negotiation and diplomacy became the only official policy. In April 1996, a large number of articles, which were inconsistent with the Oslo Accords, were wholly or partially nullified.[23]\\r\\nAt the core of the PLO's ideology is the belief that Zionists had unjustly expelled the Palestinians from Palestine and established a Jewish state in place under the pretext of having historic and Jewish ties with Palestine. The PLO demanded that Palestinian refugees be allowed to return to their homes. This is expressed in the National Covenant:\\r\\nArticle 2 of the Charter states that Palestine, with the boundaries it had during the British mandate, is an indivisible territorial unit,[22] meaning that there is no place for a Jewish state. This article was adapted in 1996 to meet the Oslo Accords.[23]\\r\\nArticle 20 states: The Balfour Declaration, the Mandate for Palestine, and everything that has been based upon them, are deemed null and void. Claims of historical or religious ties of Jews with Palestine are incompatible with the facts of history and the true conception of what constitutes statehood. Judaism, being a religion, is not an independent nationality. Nor do Jews constitute a single nation with an identity of its own; they are citizens of the states to which they belong.[22] This article was nullified in 1996.\\r\\nArticle 3 reads: The Palestinian Arab people possess the legal right to their homeland and have the right to determine their destiny after achieving the liberation of their country in accordance with their wishes and entirely of their own accord and will.\\r\\nThe PLO has always labelled the Palestinian people as Arabs. This was a natural consequence of the fact that the PLO was an offshoot of the Arab League. It also has a tactical element, as to keep the backing of Arab states. Over the years, the Arab identity remained the stated nature of the Palestinian State.[24] It is a reference to the Arab State envisioned in the UN Partition Plan.\\r\\nThe PLO and its dominating faction Fatah are often contrasted to more religious orientated factions like Hamas and the Palestinian Islamic Jihad (PIJ). All, however, represent a predominant Muslim population. Practically the whole population of the Territories is Muslim, most of them Sunni. Only some 50,000 (ca 1%) of the 4.6 million Palestinians in the occupied Palestinian territories (OPT) are Palestinian Christian.[25][26]\\r\\nThe National Charter has no reference to religion. Under President Arafat, the Fatah-dominated Palestinian Authority adopted the 2003 Amended Basic Law, which stipulates Islam as the sole official religion in Palestine and the principles of Islamic sharia as a principal source of legislation.[24] The draft Constitution, which never materialized, contains the same provisions.[27][28] At the time, the Palestine Legislative Council (PLC) did not include a single Hamas member. The draft Constitution was formulated by the Constitutional Committee, appointed with the approval of the PLO.[29][30]\\r\\nThe PLO incorporates a range of generally secular ideologies of different Palestinian movements \\"committed to the struggle for Palestinian independence and liberation,\\" hence the name of the organization. It formally is an umbrella organization that includes \\"numerous organizations of the resistance movement, political parties, and popular organizations.\\"[31] From the beginning, the PLO was designed as a government in exile, with a parliament, the Palestine National Council (PNC), chosen by the Palestinian people, as the highest authority in the PLO, and an executing government (EC), elected by the PNC.[31] In practice, however, the organization was rather a hierarchic one with a military-like character, needed for its function as liberation organization, the \\"liberation of Palestine\\".[20]\\r\\nBeside a Palestinian National Charter, which describes the ideology of the PLO, a constitution, named Fundamental Law, was adopted, which dictates the inner structure of the organization and the representation of the Palestinian people. A draft Constitution was written in 1963, to rule the PLO until free general elections among all the Palestinians in all the countries in which they resided could be held.[32] The Constitution was revised in 1968.[33]\\r\\nThe Palestinian National Council has 740 members and the Executive Committee or ExCo has 18 members. The Palestinian Central Council or CC or PCC, established by the PNC in 1973, is the second leading body of the PLO.[34] The CC consists of 124 members[35] from the PLO Executive Committee, PNC, PLC and other Palestinian organizations.[36] The EC includes 15 representatives of the PLC.[31] The CC functions as an intermediary body between the PNC and the EC. The CC makes policy decisions when PNC is not in session, acting as a link between the PNC and the PLO-EC. The CC is elected by the PNC and chaired by the PNC speaker.[37]\\r\\nThe PNC serves as the parliament for all Palestinians inside and outside of the Occupied Palestinian Territory, including Jerusalem. The PLO is governed internally by its Fundamental Law, which describes the powers and the relations between the organs of the PLO.[34]\\r\\nAhmad Shukeiri was the first Chairman of the PLO Executive Committee from 1964 to 1967.[38] In 1967, he was replaced by Yahia Hammuda. Yasser Arafat occupied the function from 1969 until his death in 2004.[39] He was succeeded by Mahmoud Abbas (also known as Abu Mazen).[40][41]\\r\\nAccording to an internal PLO document, the current PNC remains in function if elections are not possible. In absence of elections, most of the members of the PNC are appointed by the Executive Committee. The document further states that \\"the PNC represents all sectors of the Palestinian community worldwide, including numerous organizations of the resistance movement, political parties, popular organizations and independent personalities and figures from all sectors of life, including intellectuals, religious leaders and businessmen\\".[34]\\r\\nAs of 2015, there have not been elections for many years, neither for the PNC, nor for the EC, the PCC and the President of the State of Palestine. The Executive Committee has formally 18 members, including its Chairman, but in past years many vacant seats in the Executive remained empty. Moreover, Hamas, the largest representative of the inhabitants of the Palestinian Territories alongside Fatah, is not represented in the PLO at all. The results of the last parliamentary elections for the PLC, held in the Territories in 2006, with Hamas as the big winner while not even a member of the PLO, \\"underlined the clear lack of a popular mandate by the PLO leadership\\", according to PASSIA.[42] Individual elected members of the PLC representing Hamas, however, are automatically members of the PNC.\\r\\nThe representative status of the PLO has often been challenged in the past.[20] It was for example doubted in 2011 by a group of Palestinian lawyers, jurists and legal scholars, due to lack of elections. They questioned the PLO's legitimacy to alter the status and role of the Organisation in respect of their status within the UN. They demanded immediate and direct elections to the Palestine National Council to activate representative PLO institutions in order to preserve, consolidate, and strengthen the effective legal representation of the Palestinian people as a whole, before changing the status within the UN.[43]\\r\\nThe 1993-1995 Oslo Accords deliberately detached the Palestinian population in the Occupied Palestinian Territories from the PLO and the Palestinians in exile by creating a Palestinian Authority (PA) for the Territories. A separate parliament and government were established. Mahmoud Abbas was one of the architects of the Oslo Accords.[44][45]\\r\\nAlthough many in the PLO opposed the Oslo Agreements, the Executive Committee and the Central Council approved the Accords. It marked the beginning of the PLOs decline, as the PA came to replace the PLO as the prime Palestinian political institution. Political factions within the PLO that had opposed the Oslo process were marginalized. Only during the Hamas-led PA Government in 2006-2007, the PLO resurfaced. After Hamas had taken over Gaza in 2007, Abbas issued a decree suspending the PLC and some sections of the Palestinian Basic Law, and appointing Salam Fayyad as Prime Minister.[20]\\r\\nThe PLO managed to overcome the separation by keeping the power in PLO and PA in one hand, upheld by Yasser Arafat. In 2002, Arafat held the functions Chairman of the PLO/Executive Committee and Chairman of Fatah, the dominating faction within the PLO, as well as President of the Palestinian National Authority. He also controlled the Palestinian National Security Forces.[46]\\r\\nOn 4 February 1969, Fatah founder Arafat was elected Chairman of the PLO in Cairo.[47][48] Since, Fatah has been the dominant factor within the PLO, which still continues in 2015.\\r\\nUnder pressure from the international community led by Israel and US, and from inside his own party Fatah, Arafat partially transferred some of his strongly centralized power in 2003,[28][46][49] causing strong tensions within the Palestinian leadership. Arafat appointed Mahmoud Abbas as prime minister, but this resulted in disputes about the transfer of tasks and responsibilities. Abbas was strongly supported by the US and the international community, because he was supposed to be more willing to give far-reaching concessions to Israel.[46] While Arafat had retained most of his power and a power struggle within Fatah continued, the leadership was criticised for corruption and nepotism.[50][51]\\r\\nAfter Arafat's death, Abbas increasingly gained exclusive powers within both PLO and PA as well as in Fatah, until he had acquired the same power as was previously held by Arafat.[52] Critics say that Abbas even got more powers than Arafat.[53] Abbas is criticized for his autocratic rule and refusal to share powers and plans with other Palestinians. In the absence of a functioning parliament and Executive, he even began to issue his own laws. Senior representative of Abbas' Fatah faction and former Fatah minister of prisoner affairs Sufian Abu Zaida complained that Abbas appointed himself as the chief judge and prosecutor, making a mockery of the Palestinian judicial system.[53] There appeared reports of widespread corruption and nepotism within the Palestinian Authority.[52][54] Only Hamas-ruled Gaza has a more or less functioning parliament.[55]\\r\\nWith a de facto defunct parliament and Executive, Mahmoud Abbas increasingly gained exclusive powers within both PLO and PA as well as in Fatah. After the announcement in August 2015 of Abbas' resignation as Chairman of the Executive Committee and of nine other members as well, many Palestinians saw the move as just an attempt to replace some members in the Executive Committee, or to force a meeting of the PNC and remain in their jobs until the PNC decides whether to accept or to reject their resignations.[56][57] Met with fierce criticism by many Palestinian factions, a session of the PNC, who had to approve the resignations, was postponed indefinitely.[58]\\r\\nThe Palestine Liberation Organization is recognized by the Arab League as \\"the sole and legitimate representative of the Palestinian people\\",[12][34] and by the United Nations as \\"the representative of the Palestinian people\\".[59]\\r\\nThe PLO was designated a terrorist organization by the United States in 1987,[17][60] but in 1988 a presidential waiver was issued which permitted contact with the organization.[18] Most of the rest of the world recognized the PLO as the legitimate representatives of the Palestinian people from the mid-1970s onwards (after the PLO's admission to the UN as an observer.)[61]\\r\\nIsrael considered the PLO to be a terrorist organization until the Madrid Conference in 1991.[18] In 1993, PLO chairman Yasser Arafat recognized the State of Israel in an official letter to its prime minister, Yitzhak Rabin. In response to Arafat's letter, Israel decided to revise its stance toward the PLO and to recognize the organization as the representative of the Palestinian people.[62][63] This led to the signing of the Oslo Accords in 1993.\\r\\nThe United Nations General Assembly recognized the PLO as the \\"representative of the Palestinian people\\" in Resolution 3210 and Resolution 3236, and granted the PLO observer status on 22 November 1974 in Resolution 3237. On 12 January 1976 the UN Security Council voted 11ÿ1 with 3 abstentions to allow the Palestinian Liberation Organization to participate in a Security Council debate without voting rights, a privilege usually restricted to UN member states. It was admitted as a full member of the Asia group on 2 April 1986.[64][65][66]\\r\\nAfter the Palestinian Declaration of Independence the PLO's representation was renamed Palestine.[67] On 7 July 1998, this status was extended to allow participation in General Assembly debates, though not in voting.[68]\\r\\nWhen President Mahmoud Abbas submitted an application for UN state membership, in September 2011, Palestinian lawyers, jurists and legal scholars expressed their concern that the change of Palestine's status in the UN (since 1988 designated as \\"Palestine\\" in place of \\"Palestine Liberation Organization\\") could have negative implications on the legal position of the Palestinian people. They warned for the risk of fragmentation, where the State of Palestine would represent the people within the UN and the PLO represent the people outside the UN, the latter including the Palestinians in exile, where refugees constitute more than half of the Palestinian people. They were also afraid of the loss of representation of the refugees in the UN.[43] In Resolution 67/19 of November 2012, Palestine was at last awarded non-member observer State status, but the General Assembly maintained the status of the PLO.\\r\\nBy September 2012, with their application for full membership stalled due to the inability of Security Council members to 'make a unanimous recommendation', the PLO had decided to pursue an upgrade in status from \\"observer entity\\" to \\"non-member observer state\\". On 29 November 2012, Resolution 67/19 passed, upgrading Palestine to \\"non-member observer State\\" status in the United Nations.[69][70][71] The new status equates Palestine's with that of the Holy See.[72]\\r\\nThe Palestine Information Office was registered with the Justice Department of the United States as a foreign agent until 1968, when it was closed. It was reopened in 1989 as the Palestine Affairs Center.[73] The PLO Mission office, in Washington D.C was opened in 1994, and represented the PLO in the United States. On 20 July 2010, the United States Department of State agreed to upgrade the status of the PLO Mission in the United States to \\"General Delegation of the PLO\\".[74]\\r\\nInitially, as a guerrilla organization, the PLO performed actions against Israel in the 1970s and early 1980s, regarded as terroristic activities by Israel and regarded as a war of liberation by the PLO. In 1988, however, the PLO officially endorsed a two-state solution, contingent on terms such as making East Jerusalem capital of the Palestinian state and giving Palestinians the right of return to land occupied by Palestinians prior to 1948, as well as the right to continue armed struggle until the end of \\"The Zionist Entity.\\"[75] In 1996, the PLO nullified the articles of the PLO's Charter, or parts of it, which called for the destruction of Israel and for armed resistance.[76]\\r\\nFollowing the failure of the armies of Egypt and Syria to defeat Israel in the October 1973 Yom Kippur War, which broke the status quo existing since the June 1967 Six Day War, the PLO began formulating a strategic alternative.[77] Now, they intended to establish a national authority over every territory they would be able to reconquer. From 1 to 9 June 1974, the Palestine National Council held its 12th meeting in Cairo. On 8 June, the Ten Point Program was adopted. The Program stated:\\r\\nThe Liberation Organization will employ all means, and first and foremost armed struggle, to liberate Palestinian territory and to establish the independent combatant national authority for the people over every part of Palestinian territory that is liberated. This will require further changes being effected in the balance of power in favour of our people and their struggle.[78]\\r\\nBy every part of Palestinian territory that is liberated was implicitly meant the West Bank and Gaza Strip, albeit presented as an interim goal.[77] The final goal remained completing the liberation of all Palestinian territory and recover all their national rights and, first and foremost, their rights to return and to self-determination on the whole of the soil of their homeland.[79] Also UN Resolution 242 was still rejected.[78]\\r\\nWhile clinging to armed struggle as the prime means, the PLO no longer excluded peaceful means.Therefore, the Ten Point Program was considered the first attempt by the PLO at peaceful resolution. In October 1974, the Arab League proclaimed the PLO the sole legitimate representative of the Palestinian people in any Palestinian territory that is liberated, and also the UN recognized the PLO. From then, the diplomatic road was prepared. On the other hand, the Program was rejected by more radical factions and eventually caused a split in the movement.[77]\\r\\nIn 1987, the First Intifada broke out in the West Bank and Gaza Strip. The Intifada caught the PLO by surprise,[80] and the leadership abroad could only indirectly influence the events. A new local leadership emerged, the Unified National Leadership of the Uprising (UNLU), comprising many leading Palestinian factions. After King Hussein of Jordan proclaimed the administrative and legal separation of the West Bank from Jordan in 1988,[81] the Palestine National Council adopted the Palestinian Declaration of Independence in Algiers, proclaiming an independent State of Palestine. The declaration made reference to UN resolutions without explicitly mentioning Security Council Resolutions 242 and 338.\\r\\nA month later, Arafat declared in Geneva that the PLO would support a solution of the conflict based on these Resolutions. Effectively, the PLO recognized Israel's right to exist within pre-1967 borders, with the understanding that the Palestinians would be allowed to set up their own state in the West Bank and Gaza. The United States accepted this clarification by Arafat and began to allow diplomatic contacts with PLO officials. The Proclamation of Independence did not lead to statehood, although over 100 states recognised the State of Palestine.\\r\\nIn 1993, the PLO secretly negotiated the Oslo Accords with Israel.[82] The accords were signed on 20 August 1993.[82] There was a subsequent public ceremony in Washington D.C. on 13 September 1993 with Yasser Arafat and Yitzhak Rabin.[83] The Accords granted Palestinians the right to self-government on the Gaza Strip and the city of Jericho in the West Bank through the creation of the Palestinian Authority. Yasser Arafat was appointed head of the Palestinian Authority and a timetable for elections was laid out. The headquarters of the PLO were moved to Ramallah on the West Bank.[2][3]\\r\\nThe PLO has been sued in the United States by families of those killed or injured in attacks by Palestinians. One of those lawsuits was settled prior to going to trial,[84][85] while another went to trial. The PLO was found liable and ordered to pay a judgment of $655.5 million US dollars, however that verdict was overturned on appeal for a lack of US federal jurisdiction over actions committed overseas.[86]\\r\\nThe PLO began their militancy campaign from its inception with an attack on Israel's National Water Carrier in January 1965.[18] The group used guerrilla tactics to attack Israel from their bases in Jordan (including the West Bank), Lebanon, Egypt (Gaza Strip), and Syria.[87]\\r\\nThe most notable of what were considered terrorist acts committed by member organizations of the PLO were:\\r\\nFrom 1967 to September 1970 the PLO, with passive support from Jordan, fought a war of attrition with Israel. During this time, the PLO launched artillery attacks on the moshavim and kibbutzim of Bet Shean Valley Regional Council, while fedayeen launched numerous attacks on Israeli forces. Israel raided the PLO camps in Jordan, including Karameh, withdrawing only under Jordanian military pressure.[88]\\r\\nThis conflict culminated in Jordan's expulsion of the PLO to Lebanon in July 1971.\\r\\nThe PLO suffered a major reversal with the Jordanian assault on its armed groups in the events known as Black September in 1970. The Palestinian groups were expelled from Jordan, and during the 1970s, the PLO was effectively an umbrella group of eight organizations headquartered in Damascus and Beirut, all devoted to armed struggle against Zionism or Israeli occupation, using methods which included direct clashing and guerrilla warfare against Israel. After Black September, the Cairo Agreement led the PLO to establish itself in Lebanon.\\r\\nIn the late 1960s, and especially after the expulsion of the Palestinian militants from Jordan in Black September events in 1970ÿ1971, Lebanon had become the base for PLO operations. Palestinian militant organizations relocated their headquarters to South Lebanon, and relying on the support in Palestinian refugee camps, waged a campaign of attacks on the Galilee and on Israeli and Jewish targets worldwide. Increasing penetration of Palestinians into Lebanese politics and Israeli retaliations gradually deteriorated the situation.\\r\\nBy the mid-1970s, Arafat and his Fatah movement found themselves in a tenuous position.[citation needed] Arafat increasingly called for diplomacy, perhaps best symbolized by his Ten Points Program and his support for a UN Security Council resolution proposed in 1976 calling for a two-state settlement on the pre-1967 borders.[citation needed] But the Rejectionist Front denounced the calls for diplomacy, and a diplomatic solution was vetoed by the United States.[citation needed] In 1975, the increasing tensions between Palestinian militants and Christian militias exploded into the Lebanese Civil War, involving all factions. On 20 January 1976, the PLO took part in the Damour massacre in retaliation to the Karantina massacre. The PLO and Lebanese National Movement attacked the Christian town of Damour, killing 684 civilians and forcing the remainder of the towns population to flee. In 1976 Syria joined the war by invading Lebanon, which began the 29?year Syrian occupation of Lebanon, and in 1978 Israel invaded South Lebanon, in response to the Coastal Road Massacre, executed by Palestinian militants based in Lebanon.\\r\\nThe population in the West Bank and Gaza Strip saw Arafat as their best hope for a resolution to the conflict.[citation needed] This was especially so in the aftermath of the Camp David Accords of 1978 between Israel and Egypt, which the Palestinians saw as a blow to their aspirations to self-determination.[citation needed] Abu Nidal, a sworn enemy of the PLO since 1974,[citation needed] assassinated the PLO's diplomatic envoy to the European Economic Community, which in the Venice Declaration of 1980 had called for the Palestinian right of self-determination to be recognized by Israel.\\r\\nOpposition to Arafat was fierce not only among radical Arab groups, but also among many on the Israeli right.[citation needed] This included Menachem Begin, who had stated on more than one occasion that even if the PLO accepted UN Security Council Resolution 242 and recognized Israel's right to exist, he would never negotiate with the organization.[89][verification needed] This contradicted the official United States position that it would negotiate with the PLO if the PLO accepted Resolution 242 and recognized Israel, which the PLO had thus far been unwilling to do. Other Arab voices had recently called for a diplomatic resolution to the hostilities in accord with the international consensus, including Egyptian leader Anwar Sadat on his visit to Washington, DC in August 1981, and Crown Prince Fahd of Saudi Arabia in his 7 August peace proposal; together with Arafat's diplomatic maneuver, these developments made Israel's argument that it had \\"no partner for peace\\" seem increasingly problematic. Thus, in the eyes of Israeli hard-liners, \\"the Palestinians posed a greater challenge to Israel as a peacemaking organization than as a military one\\".[90]\\r\\nAfter the appointment of Ariel Sharon to the post of Minister of defence in 1981, the Israeli government policy of allowing political growth to occur in the occupied West Bank and Gaza strip changed. The Israeli government tried, unsuccessfully, to dictate terms of political growth by replacing local pro-PLO leaders with an Israeli civil administration.[91]\\r\\nIn 1982, after an attack on a senior Israeli diplomat by Lebanon-based Palestinian militants in Lebanon, Israel invaded Lebanon in a much larger scale in coordination with the Lebanese Christian militias, reaching Beirut and eventually resulting in ousting of the PLO headquarters in June that year. Low-level Palestinian insurgency in Lebanon continued in parallel with the consolidation of Shia militant organizations, but became a secondary concern to Israeli military and other Lebanese factions. With ousting of the PLO, the Lebanese Civil War gradually turned into a prolonged conflict, shifting from mainly PLO-Christian conflict into involvement of all Lebanese factions ÿ whether Sunni, Shia, Druze, and Christians.\\r\\nIn 1982, the PLO relocated to Tunis, Tunisia after it was driven out of Lebanon by Israel during Israel's six-month invasion of Lebanon. Following massive raids by Israeli forces in Beirut, it is estimated that 8,000 PLO fighters evacuated the city and dispersed.[92]\\r\\nOn 1 October 1985, in Operation Wooden Leg, Israeli Air Force F-15s bombed the PLO's Tunis headquarters, killing more than 60 people.\\r\\nIt is suggested that the Tunis period (1982ÿ1991) was a negative point in the PLO's history, leading up to the Oslo negotiations and formation of the Palestinian Authority (PA). The PLO in exile was distant from a concentrated number of Palestinians and became far less effective.[93] There was a significant reduction in centres of research, political debates or journalistic endeavours that had encouraged an energised public presence of the PLO in Beirut. More and more Palestinians were abandoned, and many felt that this was the beginning of the end.[94]\\r\\nThe Second or Al-Aqsa Intifada started concurrently with the breakdown of July 2000 Camp David talks between Palestinian Authority Chairman Yasser Arafat and Israeli Prime Minister Ehud Barak. The Intifada never ended officially, but violence hit relatively low levels during 2005. The death toll, including both military personnel and civilians, of the entire conflict in 2000ÿ2004 is estimated to be 3,223 Palestinians and 950 Israelis, although this number is criticized for not differentiating between combatants and civilians.[citation needed] Members of the PLO have claimed responsibility for a number of attacks against Israelis during the Second Intifada.[citation needed]\\r\\nIn February 2015 in a civil case considered by a US federal court the Palestinian Authority and Palestine Liberation Organization were found liable for the death and injuries of US citizens in a number of terrorist attacks in Israel from 2001 to 2004. The damages are to be $655.5 million.[95]\\r\\nAccording to a 1993 report by the British National Criminal Intelligence Service, the PLO was \\"the richest of all terrorist organizations\\", with $8ÿ$10 billion in assets and an annual income of $1.5-$2 billion from \\"donations, extortion, payoffs, illegal arms dealing, drug trafficking, money laundering, fraud, etc.\\"[96]\\r\\nPresent members include:\\r\\nFormer member groups of the PLO include:","input":"What is the goal of the palestine liberation organization?"},{"output":"2:26.65","context":"The Belmont Stakes is an American Grade I stakes Thoroughbred horse race held on the first or second Saturday in June at Belmont Park in Elmont, New York. It is a 1.5-mile-long (2.4?km) horse race, open to three-year-old Thoroughbreds. Colts and geldings carry a weight of 126 pounds (57?kg); fillies carry 121 pounds (55?kg). The race, nicknamed The Test of the Champion, and The Run for the Carnations, is the third and final leg of the Triple Crown and is held five weeks after the Kentucky Derby and three weeks after the Preakness Stakes. The 1973 Belmont Stakes and Triple Crown winner Secretariat holds the mile and a half stakes record (which is also a track and world record on dirt) of 2:24.\\r\\n\\r\\nThe attendance at the Belmont Stakes is among the American thoroughbred racing top-attended events. The 2004 Belmont Stakes drew a television audience of 21.9 million viewers, and had the highest household viewing rate since 1977 when Seattle Slew won the Triple Crown.[1]\\r\\n\\r\\nThe 150th Belmont Stakes took place on Saturday, June 9, 2018.  Justify won the race and became the second horse in four years to win the Triple Crown.\\r\\n\\r\\nThe first Belmont Stakes was held at Jerome Park Racetrack in The Bronx, built in 1866 by stock market speculator Leonard Jerome (1817ÿ1891) and financed by August Belmont Sr. (1816ÿ1890), for whom the race was named. The first race in 1867 saw the filly Ruthless win, while the following year was won by General Duke.[2] The race continued to be held at Jerome Park until 1890, when it was moved to the nearby facility, Morris Park Racecourse.[3] The 1895 race was almost not held because of new laws that banned bookmaking in New York: it was eventually rescheduled for November 2.[4] The race remained at Morris Park Racecourse until the May 1905 opening of the new Belmont Park, 430-acre (1.7?km2) racetrack in Elmont, New York on Long Island, just outside the New York City borough of Queens.[3] When anti-gambling legislation was passed in New York State, Belmont Racetrack was closed, and the race was cancelled in 1911 and 1912.[5]\\r\\n\\r\\nThe first winner of the Triple Crown was Sir Barton, in 1919, before the series was recognized as such.[6] In 1920, the Belmont was won by the great Man o' War, who won by 20 lengths, setting a new stakes and American record.[7]\\r\\n\\r\\nStarting in 1926, the winner of the Belmont Stakes has been presented with August Belmont Trophy. The owner may keep the trophy for one year, and also receives a silver miniature for permanent use.[3]\\r\\n\\r\\nThe term Triple Crown was first used when Gallant Fox won the three races in 1930, but the term did not enter widespread use until 1935 when his son Omaha repeated the feat. Sir Barton was then honored retroactively.[8] Since 1931, the order of Triple Crown races has been the Kentucky Derby first, followed by the Preakness Stakes, and then the Belmont Stakes. Prior to 1931, the Preakness was run before the Derby eleven times. On May 12, 1917 and again on May 13, 1922, the Preakness and the Derby were run on the same day. On eleven occasions, the Belmont Stakes was run before the Preakness Stakes.[9] The date of each event is now set by the Kentucky Derby, which is always held on the first Saturday in May. The Preakness Stakes is currently held two weeks later; and the Belmont Stakes is held three weeks after the Preakness (five weeks after the Derby). The earliest possible date for the Derby is May 1, and the latest is May 7; the earliest possible date for the Belmont is thus June 5, and the latest is June 11.[10]\\r\\n\\r\\nIn 1937, War Admiral became the fourth Triple Crown winner after winning the Belmont in a new track record time of 2:28 3/5.[11] In the 1940s, four Triple Crown winners followed: Whirlaway in 1941, Count Fleet in 1943, Assault in 1946 and Citation in 1948. Count Fleet won the race by a then-record margin of twenty-five lengths.[12] He also set a stakes record of 2:28 1/5, a record tied by Citation. In 1957, the stakes record was smashed when Gallant Man ran the Belmont in 2:26 3/5 in a year when the Triple Crown series was split three ways.[13]\\r\\n\\r\\nThe Belmont Stakes race was held at Aqueduct Racetrack from 1963 to 1967, while the track at Belmont was restored and renovated.\\r\\n\\r\\nThe largest crowd of the 20th century was in 1971 with over 80,000 people, supplemented by the city's Latino community, there to cheer on their new hero, Ca?onero II, the Venezuelan colt who had won the Kentucky Derby and Preakness Stakes and was poised to win the U.S. Triple Crown. However, due to a foot infection that had bothered the horse for several days, Ca?onero II failed to win the Triple Crown when he struggled across the finish line in 4th place behind Pass Catcher, ridden by Walter Blum. Despite this loss, Ca?onero II was named the winner of the first Eclipse Award for Outstanding Three-Year-Old Male Horse.[14]\\r\\n\\r\\nOn June 9, 1973, Secretariat won the Belmont Stakes by thirty-one lengths in a record time of 2:24, becoming a Triple Crown champion, ending a 25-year gap between Citation, the Belmont and Triple Crown winner in 1948. Secretariat's record still stands as the fastest running of the Belmont Stakes and an American record for 1? miles on the dirt.[15] In 1977, Seattle Slew became the first horse to win the Triple Crown while undefeated. Affirmed was the last winner of the Triple Crown in the 20th century, taking the Belmont Stakes in 2:26 4/5 on June 10, 1978. Ridden by eighteen-year-old Steve Cauthen, Affirmed defeated rival Alydar with Jorge Velasquez in the saddle. At the time the race was the third-slowest start and the third-fastest finish with the quarter in 25, the half in 50, 3/4 in 1:14, the mile in 1:37 2/5.[16]\\r\\n\\r\\nIn 1988, Secretariat's son Risen Star won the Belmont in 2:26 2/5, then the second-fastest time in the history of the race. The next year, Easy Goer lowered the mark for second-fastest time to 2:26. Easy Goer also holds a Beyer Speed Figure of 122 for the race, the best of any Triple Crown race since these ratings were first published in 1987.[17]\\r\\n\\r\\nFor three years in a row, horses came to the Belmont Stakes with a Triple Crown on the line only to fail. In 2002, Belmont Park hosted what was then the largest crowd in its history when 103,222 saw War Emblem lose to longshot Sarava after stumbling at the start. In 2003, 101,864 watched Funny Cide finish third behind Empire Maker. In 2004, the attendance record was shattered when 120,139 people saw Smarty Jones upset by Birdstone.[18]\\r\\n\\r\\nIn 2007, Rags to Riches became the first filly to win the race since Tanya in 1905. Three more failed Triple Crown bids followed: in 2008, Big Brown lost to Da' Tara; in 2012, I'll Have Another was withdrawn due to injury; and in 2014, California Chrome was beaten by Tonalist. This fueled debate about whether the series needed to be changed, for example by lengthening the period between races.[19]\\r\\n\\r\\nAmerican Pharoah won the 2015 race, becoming the 12th horse in history to win the Triple Crown and the first in 37 years. The crowd that year was limited for the first time, to 90,000.[20] His time of 2:26.65 was the sixth-fastest in Belmont Stakes history, and the second-fastest time for a Triple Crown winner.[21] In 2018, Justify became the 13th Triple Crown winner and only the second horse to do so while undefeated.[22]\\r\\n\\r\\nThe Belmont Stakes has been run at a mile and a half since 1926, having been run at that distance in 1874ÿ1889.\\r\\n\\r\\nThe race has also been run at the following distances: a mile and five furlongs in 1867ÿ1873; a mile and a quarter in 1890ÿ1892, 1895, and 1904ÿ1905; a mile and a furlong in 1893ÿ1894; and a mile and three furlongs from 1896ÿ1903 and 1906ÿ1925.\\r\\n\\r\\nThe purse for the first running in 1867 was $1,500 added,[23] meaning the purse was supplemented by nomination and entry fees. This made the total purse $2,500, with the winner receiving $1,850. The purse increased sharply in the Roaring Twenties, from Man O'War's earnings of $7,950 in 1920 to Gallant Fox's take of $66,040 in 1930. Purses declined as a result of the Great Depression, with War Admiral earning only $28,020 in 1937, then began to recover. Throughout the sixties and early seventies, the value to the winner was roughly $100,000, depending on the added money generated by entry fees (larger fields thus leading to higher prize money). The purse was repeatedly raised in the eighties and nineties, reaching $500,000 added, with the winner receiving roughly $400,000.[2] In 1998, the purse was changed to $1,000,000 guaranteed, with the winner receiving $600,000. In 2014, the purse was raised to $1,500,000.[24]\\r\\n\\r\\nWith one exception, the race has been run at a level weight of 126 pounds (with a 5-pound allowance for fillies) since 1900. The 126 pounds comes from the English Classics, where the standard weight is 9 stone, with one stone equaling 14 pounds. In 1913, the Belmont was run as a handicap with the winner carrying only 109 pounds compared to the runner-up carrying 126 pounds. Races run prior to 1900 had varied weight conditions.[2]\\r\\n\\r\\nThe first post parade in the United States was at the 14th Belmont, in 1880. Before 1921, the race was run in the clockwise tradition of English racing. Since then, the race has been run in the American, or counter-clockwise, direction. Because of its length (one lap around the enormous Belmont main track), and because it is the final race of the Triple Crown, it is called the \\"Test of the Champion\\". Most three-year-olds are unaccustomed to the distance, and lack the experience, if not the stamina, to maintain a winning speed for so long. In a long race such as the Belmont, positioning of the horse and the timing of the move to chase for the lead can be critical.\\r\\n\\r\\nThe Belmont Stakes is traditionally called \\"The Test of the Champion\\" because of its 1.5 mile lengthby far the longest of the three Triple Crown races, and one of the longest for a first-class race in the United States on the dirt. It is also known as \\"The Run for the Carnations\\" because the winning horse is draped with a blanket of white carnations after the race, in similar fashion to the blanket of roses and black-eyed Susans for the Derby and Preakness, respectively. The winning owner is ceremonially presented with the silver winner's trophy, designed by Paulding Farnham for Tiffany and Co. It was first presented to August Belmont Jr. in 1896 and donated by the Belmont family for annual presentation in 1926.\\r\\n\\r\\nDespite the fact that the Belmont Stakes is the oldest of the Triple Crown races, its traditions have been more subject to change. Until 1996, the post parade song was \\"The Sidewalks of New York\\". From 1997 to 2009, the song was changed to broadcast a recording by Frank Sinatra of the \\"Theme from New York, New York\\" in an attempt to appeal to younger fans.[25] In 2010, the song was changed to Jay-Z's \\"Empire State of Mind\\" sung by Jasmine V[26] before reverting to \\"Theme from New York, New York\\" from 2011[27] through the present. This tradition is similar to the singing of the state song at the post parades of the first two Triple Crown races: \\"My Old Kentucky Home\\" at the Kentucky Derby and \\"Maryland, My Maryland\\" at the Preakness Stakes.[3] The change of song gave rise to \\"the myth of Mamie O'Rourke,\\" a reference to a character in the lyrics of \\"The Sidewalks of New York.\\" Before American Pharoah won the Triple Crown in 2015, some claimed that changing the official Belmont song \\"cursed\\" the Triple Crown and was why no horse had won since Affirmed in 1978. Others note that there was no Triple Crown winner between 1979 and 1996, even though \\"Sidewalks\\" was still played.[28]\\r\\n\\r\\nAlong with the change of song in 1997, the official drink was also changed, from the \\"White Carnation\\" to the \\"Belmont Breeze.\\"[29] The New York Times reviewed both cocktails unfavorably, calling the Belmont Breeze \\"a significant improvement over the nigh undrinkable White Carnation\\" despite the fact that it \\"tastes like a refined trashcan punch.\\"[30] In 2011, the Belmont Breeze was again changed to the current official drink known as the \\"Belmont Jewel.\\"\\r\\n\\r\\nWhile the origin of the white carnation as the official flower of the Belmont Stakes is unknown, traditionally, pure white carnations stand for love and luck. It takes approximately 700 \\"select\\" carnations imported from Colombia to create the 40-pound blanket draped over the winner of the Belmont Stakes. The NYRA has long used The Pennock Company, a wholesale florist based in Philadelphia, Pennsylvania to import the carnations used for the mantle.[31]\\r\\n\\r\\nFrom 1986 until 2005, the Triple Crown television rights comprised a single package. In late 2004, the New York Racing Association withdrew from that agreement to negotiate independently.[32] As a result of this NBC, who was the rights holder for all three events, was only able to keep its broadcast rights to the Kentucky Derby and Preakness Stakes. ABC regained the rights to the Belmont Stakes as part of a five-year contract that expired following the 2010 race; NBC has since regained the rights to the race through 2020.\\r\\n\\r\\nSpeed record:[37][a]\\r\\n\\r\\nMargin of Victory:[37]\\r\\n\\r\\nMost wins by a jockey:[37]\\r\\n\\r\\nMost wins by a trainer:[37]\\r\\n\\r\\nMost wins by an owner:[37]\\r\\n\\r\\nOnly 23 fillies have run in the Belmont; three of which have won:\\r\\n\\r\\nThis gives them a respectable 13% win rate when entered.[39] For context, three fillies have won the Kentucky Derby while five have won the Preakness Stakes. On average, fillies have won between 2% and 3% of the Triple Crown races, with similar numbers for geldings; while about 95% of these races have been won by colts. The last filly as of November 2017 to run in the Belmont was in 2013 when Unlimited Budget ran six behind the winner Palace Malice.\\r\\n\\r\\nA ? designates a Triple Crown Winner.A ? designates a filly.\\r\\n\\r\\nLegend - ? = Triple Crown Winners, ? = Filly","input":"What was the winning time for american pharoah in the belmont stakes?"},{"output":"Limestone","context":"The architecture of ancient Greece is the architecture produced by the Greek-speaking people (Hellenic people) whose culture flourished on the Greek mainland, the Peloponnese, the Aegean Islands, and in colonies in Anatolia and Italy for a period from about 900 BC until the 1st century AD, with the earliest remaining architectural works dating from around 600 BC.[1]\\r\\nAncient Greek architecture is best known from its temples, many of which are found throughout the region, mostly as ruins but many substantially intact. The second important type of building that survives all over the Hellenic world is the open-air theatre, with the earliest dating from around 525-480 BC. Other architectural forms that are still in evidence are the processional gateway (propylon), the public square (agora) surrounded by storied colonnade (stoa), the town council building (bouleuterion), the public monument, the monumental tomb (mausoleum) and the stadium.\\r\\nAncient Greek architecture is distinguished by its highly formalised characteristics, both of structure and decoration. This is particularly so in the case of temples where each building appears to have been conceived as a sculptural entity within the landscape, most often raised on high ground so that the elegance of its proportions and the effects of light on its surfaces might be viewed from all angles.[2] Nikolaus Pevsner refers to \\"the plastic shape of the [Greek] temple.....placed before us with a physical presence more intense, more alive than that of any later building\\".[3]\\r\\nThe formal vocabulary of ancient Greek architecture, in particular the division of architectural style into three defined orders: the Doric Order, the Ionic Order and the Corinthian Order, was to have profound effect on Western architecture of later periods. The architecture of ancient Rome grew out of that of Greece and maintained its influence in Italy unbroken until the present day. From the Renaissance, revivals of Classicism have kept alive not only the precise forms and ordered details of Greek architecture, but also its concept of architectural beauty based on balance and proportion. The successive styles of Neoclassical architecture and Greek Revival architecture followed and adapted Ancient Greek styles closely.\\r\\n\\r\\n\\r\\nThe mainland and islands of Greece are rocky, with deeply indented coastline, and rugged mountain ranges with few substantial forests. The most freely available building material is stone. Limestone was readily available and easily worked.[4] There is an abundance of high quality white marble both on the mainland and islands, particularly Paros and Naxos. This finely grained material was a major contributing factor to precision of detail, both architectural and sculptural, that adorned ancient Greek architecture.[5] Deposits of high quality potter's clay were found throughout Greece and the Islands, with major deposits near Athens. It was used not only for pottery vessels, but also roof tiles and architectural decoration.[6]\\r\\nThe climate of Greece is maritime, with both the coldness of winter and the heat of summer tempered by sea breezes. This led to a lifestyle where many activities took place outdoors. Hence temples were placed on hilltops, their exteriors designed as a visual focus of gatherings and processions, while theatres were often an enhancement of a naturally occurring sloping site where people could sit, rather than a containing structure. Colonnades encircling buildings, or surrounding courtyards provided shelter from the sun and from sudden winter storms.[5]\\r\\nThe light of Greece may be another important factor in the development of the particular character of ancient Greek architecture. The light is often extremely bright, with both the sky and the sea vividly blue. The clear light and sharp shadows give a precision to the details of landscape, pale rocky outcrops and seashore. This clarity is alternated with periods of haze that varies in colour to the light on it. In this characteristic environment, the ancient Greek architects constructed buildings that were marked by precision of detail.[5] The gleaming marble surfaces were smooth, curved, fluted, or ornately sculpted to reflect the sun, cast graded shadows and change in colour with the ever-changing light of day.\\r\\nHistorians divide ancient Greek civilization into two eras, the Hellenic period (from around 900 BC to the death of Alexander the Great in 323 BC), and the Hellenistic period (323 BC to 30 AD).[7] During the earlier Hellenic period, substantial works of architecture began to appear around 600 BC. During the later (Hellenistic) period, Greek culture spread widely, initially as a result of Alexander's conquest of other lands, and later as a result of the rise of the Roman Empire, which adopted much of Greek culture.[1][8]\\r\\nBefore the Hellenic era, two major cultures had dominated the region: the Minoan (c. 2800ÿ1100 BC), and the Mycenaean (c. 1500ÿ1100 BC). Minoan is the name given by modern historians to the culture of the people of ancient Crete, known for its elaborate and richly decorated palaces, and for its pottery painted with floral and marine motifs. The Mycenaean culture, which flourished on the Peloponnesus, was quite different in character. Its people built citadels, fortifications and tombs rather than palaces, and decorated their pottery with bands of marching soldiers rather than octopus and seaweed. Both these civilizations came to an end around 1100 BC, that of Crete possibly because of volcanic devastation, and that of Mycenae because of an invasion by the Dorian people who lived on the Greek mainland.[9] Following these events, there was a period from which few signs of culture remain. This period is thus often referred to as a Dark Age.\\r\\nThe art history of the Hellenic era is generally subdivided into four periods: the Protogeometric (1100ÿ900 BC), the Geometric (900ÿ700 BC), the Archaic (700 ÿ 500 BC) and the Classical (500 ÿ 323 BC)[10] with sculpture being further divided into Severe Classical, High Classical and Late Classical.[1] The first signs of the particular artistic character that defines ancient Greek architecture are to be seen in the pottery of the Dorian Greeks from the 10th century BC. Already at this period it is created with a sense of proportion, symmetry and balance not apparent in similar pottery from Crete and Mycenae. The decoration is precisely geometric, and ordered neatly into zones on defined areas of each vessel. These qualities were to manifest themselves not only through a millennium of Greek pottery making, but also in the architecture that was to emerge in the 6th century.[11] The major development that occurred was in the growing use of the human figure as the major decorative motif, and the increasing surety with which humanity, its mythology, activities and passions were depicted.[1]\\r\\nThe development in the depiction of the human form in pottery was accompanied by a similar development in sculpture. The tiny stylised bronzes of the Geometric period gave way to life-sized highly formalised monolithic representation in the Archaic period. The Classical period was marked by a rapid development towards idealised but increasingly lifelike depictions of gods in human form.[12] This development had a direct effect on the sculptural decoration of temples, as many of the greatest extant works of ancient Greek sculpture once adorned temples,[13] and many of the largest recorded statues of the age, such as the lost chryselephantine statues of Zeus at the Temple of Zeus at Olympia and Athena at the Parthenon, Athens, both over 40 feet high, were once housed in them.[14]\\r\\nThe religion of ancient Greece was a form of nature worship that grew out of the beliefs of earlier cultures. However, unlike earlier cultures, man was no longer perceived as being threatened by nature, but as its sublime product.[8] The natural elements were personified as gods of completely human form, and very human behaviour.[5]\\r\\nThe home of the gods was thought to be Olympus, the highest mountain in Greece. The most important deities were: Zeus, the supreme god and ruler of the sky; Hera, his wife and goddess of marriage; Athena, goddess of wisdom; Poseidon, god of the sea; Demeter, goddess of the harvest; Apollo, god of the sun, law, healing, plague, reason, music and poetry; Artemis, goddess of the moon, the hunt and the wilderness; Aphrodite, goddess of love; Ares, God of war; Hermes, god of commerce and travelers, Hephaestus, god of fire and metalwork, and Dionysus, god of wine and fruit-bearing plants.[5] Worship, like many other activities, was done in community, in the open. However, by 600 BC, the gods were often represented by large statues and it was necessary to provide a building in which each of these could be housed. This led to the development of temples.[15]\\r\\nThe ancient Greeks perceived order in the universe, and in turn, applied order and reason to their creations. Their humanist philosophy put mankind at the centre of things, and promoted well-ordered societies and the development of democracy.[8] At the same time, the respect for human intellect demanded reason, and promoted a passion for enquiry, logic, challenge, and problem solving. The architecture of the ancient Greeks, and in particular, temple architecture, responds to these challenges with a passion for beauty, and for order and symmetry which is the product of a continual search for perfection, rather than a simple application of a set of working rules.\\r\\nThere is a clear division between the architecture of the preceding Mycenaean culture and Minoan cultures and that of the ancient Greeks, the techniques and an understanding of their style being lost when these civilisations fell.[4]\\r\\nMycenaean art is marked by its circular structures and tapered domes with flat-bedded, cantilevered courses.[9] This architectural form did not carry over into the architecture of ancient Greece, but reappeared about 400 BC in the interior of large monumental tombs such as the Lion Tomb at Cnidos (c. 350 BC). Little is known of Mycenaean wooden or domestic architecture and any continuing traditions that may have flowed into the early buildings of the Dorian people.\\r\\nThe Minoan architecture of Crete, was of trabeated form like that of ancient Greece. It employed wooden columns with capitals, but the columns were of very different form to Doric columns, being narrow at the base and splaying upward.[9] The earliest forms of columns in Greece seem to have developed independently. As with Minoan architecture, ancient Greek domestic architecture centred on open spaces or courtyards surrounded by colonnades. This form was adapted to the construction of hypostyle halls within the larger temples. The evolution that occurred in architecture was towards public building, first and foremost the temple, rather than towards grand domestic architecture such as had evolved in Crete.[2]\\r\\nThe Greek word for the family or household, oikos, is also the name for the house. Houses followed several different types. It is probable that many of the earliest houses were simple structures of two rooms, with an open porch or \\"pronaos\\" above which rose a low pitched gable or pediment.[7] This form is thought to have contributed to temple architecture.\\r\\nThe construction of many houses employed walls of sun dried clay bricks or wooden framework filled with fibrous material such as straw or seaweed covered with clay or plaster, on a base of stone which protected the more vulnerable elements from damp.[4] The roofs were probably of thatch with eaves which overhung the permeable walls. Many larger houses, such as those at Delos, were built of stone and plastered. The roofing material for substantial house was tile. Houses of the wealthy had mosaic floors and demonstrated the Classical style.\\r\\nMany houses centred on a wide passage or \\"pasta\\" which ran the length of the house and opened at one side onto a small courtyard which admitted light and air. Larger houses had a fully developed peristyle courtyard at the centre, with the rooms arranged around it. Some houses had an upper floor which appears to have been reserved for the use of the women of the family.[16]\\r\\nCity houses were built with adjoining walls and were divided into small blocks by narrow streets. Shops were sometimes located in the rooms towards the street. City houses were inward-facing, with major openings looking onto the central courtyard, rather than the street.[7]\\r\\nThe rectangular temple is the most common and best-known form of Greek public architecture. This rectilinear structure borrows from the Late Helladic, Mycenaean Megaron, which contained a central throne room, vestibule, and porch.[17] The temple did not serve the same function as a modern church, since the altar stood under the open sky in the temenos or sacred precinct, often directly before the temple. Temples served as the location of a cult image and as a storage place or strong room for the treasury associated with the cult of the god in question, and as a place for devotees of the god to leave their votive offerings, such as statues, helmets and weapons. Some Greek temples appear to have been oriented astronomically.[18] The temple was generally part of a religious precinct known as the acropolis. According to Aristotle, '\\"the site should be a spot seen far and wide, which gives good elevation to virtue and towers over the neighbourhood\\".[2] Small circular temples, tholos were also constructed, as well as small temple-like buildings that served as treasuries for specific groups of donors.[19]\\r\\nDuring the late 5th and 4th centuries BC, town planning became an important consideration of Greek builders, with towns such as Paestum and Priene being laid out with a regular grid of paved streets and an agora or central market place surrounded by a colonnade or stoa. The completely restored Stoa of Attalos can be seen in Athens. Towns were also equipped with a public fountain where water could be collected for household use. The development of regular town plans is associated with Hippodamus of Miletus, a pupil of Pythagoras.[20][21][22]\\r\\nPublic buildings became \\"dignified and gracious structures\\", and were sited so that they related to each other architecturally.[21] The propylon or porch, formed the entrance to temple sanctuaries and other significant sites with the best-surviving example being the Propylaea on the Acropolis of Athens. The bouleuterion was a large public building with a hypostyle hall that served as a court house and as a meeting place for the town council (boule). Remnants of bouleuterion survive at Athens, Olympia and Miletus, the latter having held up to 1200 people.[23]\\r\\nEvery Greek town had an open-air theatre. These were used for both public meetings as well as dramatic performances. The theatre was usually set in a hillside outside the town, and had rows of tiered seating set in a semicircle around the central performance area, the orchestra. Behind the orchestra was a low building called the skn, which served as a store-room, a dressing-room, and also as a backdrop to the action taking place in the orchestra. A number of Greek theatres survive almost intact, the best known being at Epidaurus, by the architect Polykleitos the Younger.[20]\\r\\nGreek towns of substantial size also had a palaestra or a gymnasium, the social centre for male citizens which included spectator areas, baths, toilets and club rooms.[23] Other buildings associated with sports include the hippodrome for horse racing, of which only remnants have survived, and the stadium for foot racing, 600 feet in length, of which examples exist at Olympia, Delphi, Epidarus and Ephesus, while the Panathinaiko Stadium in Athens, which seats 45,000 people, was restored in the 19th century and was used in the 1896, 1906 and 2004 Olympic Games.[23][24]\\r\\nThe architecture of ancient Greece is of a trabeated or \\"post and lintel\\" form, i.e. it is composed of upright beams (posts) supporting horizontal beams (lintels). Although the existent buildings of the era are constructed in stone, it is clear that the origin of the style lies in simple wooden structures, with vertical posts supporting beams which carried a ridged roof. The posts and beams divided the walls into regular compartments which could be left as openings, or filled with sun dried bricks, lathes or straw and covered with clay daub or plaster. Alternately, the spaces might be filled with rubble. It is likely that many early houses and temples were constructed with an open porch or \\"pronaos\\" above which rose a low pitched gable or pediment.[7]\\r\\nThe earliest temples, built to enshrine statues of deities, were probably of wooden construction, later replaced by the more durable stone temples many of which are still in evidence today. The signs of the original timber nature of the architecture were maintained in the stone buildings.[25]\\r\\nA few of these temples are very large, with several, such as the Temple of Zeus Olympus and the Olympians at Athens being well over 300 feet in length, but most were less than half this size. It appears that some of the large temples began as wooden constructions in which the columns were replaced piecemeal as stone became available. This, at least was the interpretation of the historian Pausanias looking at the Temple of Hera at Olympia in the 2nd century AD.[2]\\r\\nThe stone columns are made of a series of solid stone cylinders or \\"drums\\" that rest on each other without mortar, but were sometimes centred with a bronze pin. The columns are wider at the base than at the top, tapering with an outward curve known as \\"entasis\\". Each column has a capital of two parts, the upper, on which rests the lintels, being square and called the \\"abacus\\". The part of the capital that rises from the column itself is called the \\"echinus\\". It differs according to the order, being plain in the Doric Order, fluted in the Ionic and foliate in the Corinthian. Doric and usually Ionic capitals are cut with vertical grooves known as \\"fluting\\". This fluting or grooving of the columns is a retention of an element of the original wooden architecture.[25]\\r\\nThe columns of a temple support a structure that rises in two main stages, the entablature and the pediment.\\r\\nThe entablature is the major horizontal structural element supporting the roof and encircling the entire building. It is composed of three parts. Resting on the columns is the architrave made of a series of stone \\"lintels\\" that spanned the space between the columns, and meet each other at a joint directly above the centre of each column.\\r\\nAbove the architrave is a second horizontal stage called the \\"frieze\\". The frieze is one of the major decorative elements of the building and carries a sculptured relief. In the case of Ionic and Corinthian architecture, the relief decoration runs in a continuous band, but in the Doric Order, it is divided into sections called \\"metopes\\" which fill the spaces between vertical rectangular blocks called \\"triglyphs\\". The triglyphs are vertically grooved like the Doric columns, and retain the form of the wooden beams that would once have supported the roof.\\r\\nThe upper band of the entablature is called the \\"cornice\\", which is generally ornately decorated on its lower edge. The cornice retains the shape of the beams that would once have supported the wooden roof at each end of the building. At the front and rear of each temple, the entablature supports a triangular structure called the \\"pediment\\". The triangular space framed by the cornices is the location of the most significant sculptural decoration on the exterior of the building.\\r\\nEvery temple rested on a masonry base called the crepidoma, generally of three steps, of which the upper one which carried the columns was the stylobate. Masonry walls were employed for temples from about 600 BC onwards. Masonry of all types was used for ancient Greek buildings, including rubble, but the finest ashlar masonry was usually employed for temple walls, in regular courses and large sizes to minimise the joints.[7] The blocks were rough hewn and hauled from quarries to be cut and bedded very precisely, with mortar hardly ever being used. Blocks, particularly those of columns and parts of the building bearing loads were sometimes fixed in place or reinforced with iron clamps, dowels and rods of wood, bronze or iron fixed in lead to minimise corrosion.[4]\\r\\nDoor and window openings were spanned with a lintel, which in a stone building limited the possible width of the opening. The distance between columns was similarly affected by the nature of the lintel, columns on the exterior of buildings and carrying stone lintels being closer together than those on the interior, which carried wooden lintels.[26][27] Door and window openings narrowed towards the top.[27] Temples were constructed without windows, the light to the naos entering through the door. It has been suggested that some temples were lit from openings in the roof.[26] A door of the Ionic Order at the Erechtheion (17 feet high and 7.5 feet wide at the top) retains many of its features intact, including mouldings, and an entablature supported on console brackets. (See Architectural Decoration, below)[27][28][29]\\r\\nThe widest span of a temple roof was across the cella, or internal space. In a large building, this space contains columns to support the roof, the architectural form being known as hypostyle. It appears that, although the architecture of ancient Greece was initially of wooden construction, the early builders did not have the concept of the diagonal truss as a stabilising member. This is evidenced by the nature of temple construction in the 6th century BC, where the rows of columns supporting the roof the cella rise higher than the outer walls, unnecessary if roof trusses are employed as an integral part of the wooden roof. The indication is that initially all the rafters were supported directly by the entablature, walls and hypostyle, rather than on a trussed wooden frame, which came into use in Greek architecture only in the 3rd century BC.[7]\\r\\nAncient Greek buildings of timber, clay and plaster construction were probably roofed with thatch. With the rise of stone architecture came the appearance of fired ceramic roof tiles. These early roof tiles showed an S-shape, with the pan and cover tile forming one piece. They were much larger than modern roof tiles, being up to 90?cm (35.43?in) long, 70?cm (27.56?in) wide, 3ÿ4?cm (1.18ÿ1.57?in) thick and weighing around 30?kg (66?lb) apiece.[30][31] Only stone walls, which were replacing the earlier mudbrick and wood walls, were strong enough to support the weight of a tiled roof.[32]\\r\\nThe earliest finds of roof tiles of the Archaic period in Greece are documented from a very restricted area around Corinth, where fired tiles began to replace thatched roofs at the temples of Apollo and Poseidon between 700 and 650 BC.[33] Spreading rapidly, roof tiles were within fifty years in evidence for a large number of sites around the Eastern Mediterranean, including Mainland Greece, Western Asia Minor, Southern and Central Italy.[33] Being more expensive and labour-intensive to produce than thatch, their introduction has been explained by the fact that their fireproof quality would have given desired protection to the costly temples.[33] As a side-effect, it has been assumed that the new stone and tile construction also ushered in the end of overhanging eaves in Greek architecture, as they made the need for an extended roof as rain protection for the mudbrick walls obsolete.[32]\\r\\nVaults and arches were not generally used, but begin to appear in tombs (in a \\"beehive\\" or cantilevered form such as used in Mycenaea) and occasionally, as an external feature, exedrae of voussoired construction from the 5th century BC. The dome and vault never became significant structural features, as they were to become in ancient Roman architecture.[7]\\r\\nMost ancient Greek temples were rectangular, and were approximately twice as long as they were wide, with some notable exceptions such as the enormous Temple of Olympian Zeus, Athens with a length of nearly 2? times its width. A number of surviving temple-like structures are circular, and are referred to as tholos.[34] The smallest temples are less than 25 metres (approx. 75 feet) in length, or in the case of the circular tholos, in diameter. The great majority of temples are between 30ÿ60 metres (approx. 100ÿ200 feet) in length. A small group of Doric temples, including the Parthenon, are between 60ÿ80 metres (approx. 200ÿ260 feet) in length. The largest temples, mainly Ionic and Corinthian, but including the Doric Temple of the Olympian Zeus, Agrigento, were between 90ÿ120 metres (approx. 300ÿ390 feet) in length.\\r\\nThe temple rises from a stepped base or \\"stylobate\\", which elevates the structure above the ground on which it stands. Early examples, such as the Temple of Zeus at Olympus, have two steps, but the majority, like the Parthenon, have three, with the exceptional example of the Temple of Apollo at Didyma having six.[35] The core of the building is a masonry-built \\"naos\\" within which is a cella, a windowless room originally housing the statue of the god. The cella generally has a porch or \\"pronaos\\" before it, and perhaps a second chamber or \\"antenaos\\" serving as a treasury or repository for trophies and gifts. The chambers were lit by a single large doorway, fitted with a wrought iron grill. Some rooms appear to have been illuminated by skylights.[35]\\r\\nOn the stylobate, often completely surrounding the naos, stand rows of columns. Each temple is defined as being of a particular type, with two terms: one describing the number of columns across the entrance front, and the other defining their distribution.[35]\\r\\nExamples:\\r\\nThe ideal of proportion that was used by ancient Greek architects in designing temples was not a simple mathematical progression using a square module. The math involved a more complex geometrical progression, the so-called Golden mean. The ratio is similar to that of the growth patterns of many spiral forms that occur in nature such as rams' horns, nautilus shells, fern fronds, and vine tendrils and which were a source of decorative motifs employed by ancient Greek architects as particularly in evidence in the volutes of capitals of the Ionic and Corinthian Orders.[36]\\r\\nThe ancient Greek architects took a philosophic approach to the rules and proportions. The determining factor in the mathematics of any notable work of architecture was its ultimate appearance. The architects calculated for perspective, for the optical illusions that make edges of objects appear concave and for the fact that columns that are viewed against the sky look different from those adjacent that are viewed against a shadowed wall. Because of these factors, the architects adjusted the plans so that the major lines of any significant building are rarely straight.[36] The most obvious adjustment is to the profile of columns, which narrow from base to top. However, the narrowing is not regular, but gently curved so that each columns appears to have a slight swelling, called entasis below the middle. The entasis is never sufficiently pronounced as to make the swelling wider than the base; it is controlled by a slight reduction in the rate of decrease of diameter.[7]\\r\\nThe Parthenon, the Temple to the Goddess Athena on the Acropolis in Athens, is referred to by many as the pinnacle of ancient Greek architecture. Helen Gardner refers to its \\"unsurpassable excellence\\", to be surveyed, studied and emulated by architects of later ages. Yet, as Gardner points out, there is hardly a straight line in the building.[37] Banister Fletcher calculated that the stylobate curves upward so that its centres at either end rise about 2.6?inches above the outer corners, and 4.3?inches on the longer sides. A slightly greater adjustment has been made to the entablature. The columns at the ends of the building are not vertical but are inclined towards the centre, with those at the corners being out of plumb by about 2.6?inches.[7] These outer columns are both slightly wider than their neighbours and are slightly closer than any of the others.[38]\\r\\nAncient Greek architecture of the most formal type, for temples and other public buildings, is divided stylistically into three \\"orders\\", first described by the Roman architectural writer Vitruvius. These are: the Doric Order, the Ionic Order and the Corinthian Order, the names reflecting their regional origins within the Greek world. While the three orders are most easily recognizable by their capitals, the orders also governed the form, proportions, details and relationships of the columns, entablature, pediment and the stylobate.[2] The different orders were applied to the whole range of buildings and monuments.\\r\\nThe Doric Order developed on mainland Greece and spread to Magna Graecia (Italy). It was firmly established and well-defined in its characteristics by the time of the building of the Temple of Hera at Olympia, c.?600 BC. The Ionic order co-existed with the Doric, being favoured by the Greek cities of Ionia, in Asia Minor and the Aegean Islands. It did not reach a clearly defined form until the mid 5th?century BC.[25] The early Ionic temples of Asia Minor were particularly ambitious in scale, such as the Temple of Artemis at Ephesus.[11] The Corinthian Order was a highly decorative variant not developed until the Hellenistic period and retaining many characteristics of the Ionic. It was popularised by the Romans.[7]\\r\\nThe Doric order is recognised by its capital, of which the echinus is like a circular cushion rising from the top of the column to the square abacus on which rest the lintels. The echinus appears flat and splayed in early examples, deeper and with greater curve in later, more refined examples, and smaller and straight-sided in Hellenistc examples.[39] A refinement of the Doric column is the entasis, a gentle convex swelling to the profile of the column, which prevents an optical illusion of concavity.[39] This is more pronounced in earlier examples.\\r\\nDoric columns are almost always cut with grooves, known as \\"fluting\\", which run the length of the column and are usually 20 in number, although sometimes fewer. The flutes meet at sharp edges called arrises. At the top of the columns, slightly below the narrowest point, and crossing the terminating arrises, are three horizontal grooves known as the hypotrachelion. Doric columns have no bases, until a few examples in the Hellenistic period.[39]\\r\\nThe columns of an early Doric temple such as the Temple of Apollo at Syracuse, Sicily, may have a height to base diameter ratio of only 4:1 and a column height to entablature ratio of 2:1, with relatively crude details. A column height to diameter of 6:1 became more usual, while the column height to entablature ratio at the Parthenon is about 3:1. During the Hellenistic period, Doric conventions of solidity and masculinity dropped away, with the slender and unfluted columns reaching a height to diameter ratio of 7.5:1.[39]\\r\\nThe Doric entablature is in three parts, the architrave, the frieze and the cornice. The architrave is composed of the stone lintels which span the space between the columns, with a joint occurring above the centre of each abacus. On this rests the frieze, one of the major areas of sculptural decoration. The frieze is divided into triglyphs and metopes, the triglyphs, as stated elsewhere in this article, are a reminder of the timber history of the architectural style. Each triglyph has three vertical grooves, similar to the columnar fluting, and below them, seemingly connected, are guttae, small strips that appear to connect the triglyphs to the architrave below.[39] A triglyph is located above the centre of each capital, and above the centre of each lintel. However, at the corners of the building, the triglyphs do not fall over the centre the column. The ancient architects took a pragmatic approach to the apparent \\"rules\\", simply extending the width of the last two metopes at each end of the building.\\r\\nThe cornice is a narrow jutting band of complex moulding which overhangs and protects the ornamented frieze, like the edge of an overhanging wooden-framed roof. It is decorated on the underside with projecting blocks, mutules, further suggesting the wooden nature of the prototype. At either end of the building the pediment rises from the cornice, framed by moulding of similar form.[39]\\r\\nThe pediment is decorated with figures that are in relief in the earlier examples, though almost freestanding by the time of the sculpture on the Parthenon. Early architectural sculptors found difficulty in creating satisfactory sculptural compositions in the tapering triangular space.[40] By the Early Classical period, with the decoration of the Temple of Zeus at Olympia, (486-460 BC) the sculptors had solved the problem by having a standing central figure framed by rearing centaurs and fighting men who are falling, kneeling and lying in attitudes that fit the size and angle of each part of the space.[37] The famous sculptor Phidias fills the space at the Parthenon (448-432 BC) with a complex array of draped and undraped figures of deities who appear in attitudes of sublime relaxation and elegance.\\r\\nThe Ionic Order is recognized by its voluted capital, in which a curved echinus of similar shape to that of the Doric Order, but decorated with stylised ornament, is surmounted by a horizontal band that scrolls under to either side, forming spirals or volutes similar to those of the nautilus shell or ram's horn. In plan, the capital is rectangular. It is designed to be viewed frontally but the capitals at the corners of buildings are modified with an additional scroll so as to appear regular on two adjoining faces. In the Hellenistic period, four-fronted Ionic capitals became common.[41]\\r\\nLike the Doric Order, the Ionic Order retains signs of having its origins in wooden architecture. The horizontal spread of a flat timber plate across the top of a column is a common device in wooden construction, giving a thin upright a wider area on which to bear the lintel, while at the same time reinforcing the load-bearing strength of the lintel itself. Likewise, the columns always have bases, a necessity in wooden architecture to spread the load and protect the base of a comparatively thin upright.[41] The columns are fluted with narrow, shallow flutes that do not meet at a sharp edge but have a flat band or fillet between them. The usual number of flutes is twenty-four but there may be as many as forty-four. The base has two convex mouldings called torus, and from the late Hellenic period stood on a square plinth similar to the abacus.[41]\\r\\nThe architrave of the Ionic Order is sometimes undecorated, but more often rises in three outwardly-stepped bands like overlapping timber planks. The frieze, which runs in a continuous band, is separated from the other members by rows of small projecting blocks. They are referred to as dentils, meaning \\"teeth\\", but their origin is clearly in narrow wooden slats which supported the roof of a timber structure.[41] The Ionic Order is altogether lighter in appearance than the Doric, with the columns, including base and capital, having a 9:1 ratio with the diameter, while the whole entablature was also much narrower and less heavy than the Doric entablature. There was some variation in the distribution of decoration. Formalised bands of motifs such as alternating forms known as \\"egg and dart\\" were a feature of the Ionic entablatures, along with the bands of dentils. The external frieze often contained a continuous band of figurative sculpture or ornament, but this was not always the case. Sometimes a decorative frieze occurred around the upper part of the naos rather than on the exterior of the building. These Ionic-style friezes around the naos are sometimes found on Doric buildings, notably the Parthenon. Some temples, like the Temple of Artemis at Ephesus, had friezes of figures around the lower drum of each column, separated from the fluted section by a bold moulding.[41]\\r\\nCaryatids, draped female figures used as supporting members to carry the entablature, were a feature of the Ionic order, occurring at several buildings including the Siphnian Treasury at Delphi in 525 BC and at the Erechtheion, about 410 BC.[42]\\r\\nThe Corinthian Order does not have its origin in wooden architecture. It grew directly out of the Ionic in the mid 5th century BC, and was initially of much the same style and proportion, but distinguished by its more ornate capitals.[43] The capital was very much deeper than either the Doric or the Ionic capital, being shaped like a large krater, a bell-shaped mixing bowl, and being ornamented with a double row of acanthus leaves above which rose voluted tendrils, supporting the corners of the abacus, which, no longer perfectly square, splayed above them. According to Vitruvius, the capital was invented by a bronze founder, Callimachus of Corinth, who took his inspiration from a basket of offerings that had been placed on a grave, with a flat tile on top to protect the goods. The basket had been placed on the root of an acanthus plant which had grown up around it.[43] The ratio of the column height to diameter is generally 10:1, with the capital taking up more than 1/10 of the height. The ratio of capital height to diameter is generally about 1.16:1.[43]\\r\\nThe Corinthian Order was initially used internally, as at the Temple of Apollo Epicurius at Bassae (c.450-425 BC). In 334 BC it appeared as an external feature on the Choragic Monument of Lysicrates in Athens, and then on a huge scale at the Temple of Zeus Olympia in Athens, (174 BC - AD 132).[43] It was popularised by the Romans, who added a number of refinements and decorative details. During the Hellenistic period, Corinthian columns were sometimes built without fluting.[43]\\r\\nEarly wooden structures, particularly temples, were ornamented and in part protected by fired and painted clay revetments in the form of rectangular panels, and ornamental discs. Many fragments of these have outlived the buildings that they decorated and demonstrate a wealth of formal border designs of geometric scrolls, overlapping patterns and foliate motifs.[44] With the introduction of stone-built temples, the revetments no longer served a protective purpose and sculptured decoration became more common.\\r\\nThe clay ornaments were limited to the roof of buildings, decorating the cornice, the corners and surmounting the pediment. At the corners of pediments they were called acroteria and along the sides of the building, antefixes. Early decorative elements were generally semi-circular, but later of roughly triangular shape with moulded ornament, often palmate.[44][45] Ionic cornices were often set with a row of lion's masks, with open mouths that ejected rainwater.[26][45] From the Late Classical period, acroteria were sometimes sculptured figures.See \\"Architectural sculpture\\"[46]\\r\\nIn the three orders of ancient Greek architecture, the sculptural decoration, be it a simple half round astragal, a frieze of stylised foliage or the ornate sculpture of the pediment, is all essential to the architecture of which it is a part. In the Doric order, there is no variation in its placement. Reliefs never decorate walls in an arbitrary way. The sculpture is always located in several predetermined areas, the metopes and the pediment.[44] In later Ionic architecture, there is greater diversity in the types and numbers of mouldings and decorations, particularly around doorways, where voluted brackets sometimes occur supporting an ornamental cornice over a door, such as that at the Erechtheion.[26][28][44] A much applied narrow moulding is called \\"bead and reel\\" and is symmetrical, stemming from turned wooden prototypes. Wider mouldings include one with tongue-like or pointed leaf shapes, which are grooved and sometimes turned upward at the tip, and \\"egg and dart\\" moulding which alternates ovoid shapes with narrow pointy ones.[26][44][47]\\r\\nArchitectural sculpture showed a development from early Archaic examples through Severe Classical, High Classical, Late Classical and Hellenistic.[1] Remnants of Archaic architectural sculpture (700 - 500 BC) exist from the early 6th century BC with the earliest surviving pedimental sculpture being fragments of a Gorgon flanked by heraldic panthers from the centre of the pediment of the Artemis Temple of Corfu.[48] A metope from a temple known as \\"Temple C\\" at Selinus, Sicily, shows, in a better preserved state, Perseus slaying the Gorgon Medusa.[40] Both images parallel the stylised depiction of the Gorgons on the black figure name vase decorated by the Nessos painter (c. 600 BC), with the face and shoulders turned frontally, and the legs in a running or kneeling position. At this date images of terrifying monsters have predominance over the emphasis on the human figure that developed with Humanist philosophy.[48]\\r\\nThe Severe Classical style (500 ÿ 450 BC) is represented by the pedimental sculptures of the Temple of Zeus at Olympia, (470 ÿ 456 BC). The eastern pediment shows a moment of stillness and \\"impending drama\\" before the beginning of a chariot race, the figures of Zeus and the competitors being severe and idealised representations of the human form.[49] The western pediment has Apollo as the central figure, \\"majestic\\" and \\"remote\\", presiding over a battle of Lapiths and Centaurs, in strong contrast to that of the eastern pediment for its depiction of violent action, and described by D. E. Strong as the \\"most powerful piece of illustration\\" for a hundred years.[49]\\r\\nThe shallow reliefs and three-dimensional sculpture which adorned the frieze and pediments, respectively, of the Parthenon, are the lifelike products of the High Classical style (450 ÿ 400 BC) and were created under the direction of the sculptor Phidias.[50] The pedimental sculpture represents the Gods of Olympus, while the frieze shows the Panathenaic procession and ceremonial events that took place every four years to honour the titular Goddess of Athens.[50] The frieze and remaining figures of the eastern pediment show a profound understanding of the human body, and how it varies depending upon its position and the stresses that action and emotion place upon it. Benjamin Robert Haydon described the reclining figure of Dionysus as \\"....the most heroic style of art, combined with all the essential detail of actual life\\".[51]\\r\\nThe names of many famous sculptors are known from the Late Classical period (400 ÿ 323 BC), including Timotheos, Praxiteles, Leochares and Skopas, but their works are known mainly from Roman copies.[1] Little architectural sculpture of the period remains intact. The Temple of Asclepius at Epidauros had sculpture by Timotheos working with the architect Theodotos. Fragments of the eastern pediment survive, showing the Sack of Troy. The scene appears to have filled the space with figures carefully arranged to fit the slope and shape available, as with earlier east pediment of the Temple of Zeus at Olympus. But the figures are more violent in action, the central space taken up, not with a commanding God, but with the dynamic figure of Neoptolemos as he seizes the aged king Priam and stabs him. The remaining fragments give the impression of a whole range of human emotions, fear, horror, cruelty and lust for conquest.[46] The acroteria were sculptured by Timotheus, except for that at the centre of the east pediment which is the work of the architect. The palmate acroteria have been replaced here with small figures, the eastern pediment being surmounted by a winged Nike, poised against the wind.[46]\\r\\nHellenistic architectural sculpture (323 ÿ 31 BC) was to become more flamboyant, both in the rendering of expression and motion, which is often emphasised by flowing draperies, the Nike Samothrace which decorated a monument in the shape of a ship being a well-known example. The Pergamon Altar (c. 180ÿ160 BC) has a frieze (120 metres long by 2.3 metres high) of figures in very high relief. The frieze represents the battle for supremacy of Gods and Titans, and employs many dramatic devices: frenzy, pathos and triumph, to convey the sense of conflict.[52]\\r\\n Media related to Ancient Greek architecture at Wikimedia Commons","input":"What materials were used in ancient greek architecture?"},{"output":"Green tea exported from China was first introduced in the coffeehouses of London shortly before the Stuart Restoration (1660); in 1657, tea was offered as an item in a London coffeehouse in Exchange Alley.","context":"Since the eighteenth century, the United Kingdom has been one of the world's greatest tea consumers, with an average annual per capita tea supply of 1.9?kg (4.18 lbs).[1] The British Empire was instrumental in spreading tea from China to India; British interests controlled tea production in the subcontinent. Tea, which was an upper-class drink in mainland Europe, became the infusion of every social class in Great Britain throughout the course of the eighteenth century and has remained so. Tea is a prominent feature of British culture and society.[2]\\r\\nIn the United Kingdom, the drinking of tea is so varied that it is quite hard to generalise. While it is usually served with milk, it is not uncommon to drink it black or with lemon, with sugar being a popular addition to any of the above. Strong tea, served in a mug with milk and sugar, is a popular combination known as builder's tea.\\r\\n\\r\\n\\r\\nThe first record of tea written in English came from English merchants abroad. In 1615, Richard Wickham, who ran an East India Company office in Japan, wrote in a letter to merchants in Macao requesting that they bring him \\"a pot of the best sort of chaw\\". Peter Mundy, a traveller and merchant who came across tea in Fujian, China in 1637, wrote, \\"chaa  only water with a kind of herb boiled in it \\".[3]\\r\\nGreen tea exported from China was first introduced in the coffeehouses of London shortly before the Stuart Restoration (1660); in 1657, tea was offered as an item in a London coffeehouse in Exchange Alley.[4] The owner Thomas Garraway had to explain the new beverage in a pamphlet, and an advertisement in Mercurius Politicus for 30 September 1658 offered \\"That Excellent, and by all Physicians approved, China drink, called by the Chinese, Tcha, by other nations Tay alias Tee, ...sold at the Sultaness-head, ye Cophee-house in Sweetings-Rents, by the Royal Exchange, London\\". [5] In London \\"Coffee, chocolate and a kind of drink called tee\\" were \\"sold in almost every street in 1659\\", according to Thomas Rugge's Diurnall.[6] Tea was mainly consumed by upper and mercantile classes: Samuel Pepys, curious for every novelty, tasted the new drink in 1660 and recorded the experience in his diary: [25 September] \\"I did send for a cup of tee, (a China drink) of which I had never had drunk before\\". Some years later, in 1667, Pepys noted that his wife was taking tea on medical advice ÿ \\"a drink which Mr Pelling the Pottecary tells her is good for her colds and defluxions\\". The Royal College of Physicians debated whether any of the exotic new hot drinks would \\"agree with the Constitutions of our English bodies\\".[7]\\r\\nIn 1660, two pounds and two ounces of tea bought from Portugal were formally presented to Charles II by the British East India Company.[8] The drink, already common in Europe, was a favourite of his new Portuguese bride, Catherine of Braganza, who introduced it at court after she married Charles II in 1662. As tea was her temperance drink of choice, it gained social acceptance among the aristocracy. Catherine of Braganza's choice of tea was also instrumental in the popularization of tea in Britain ÿ because tea was introduced primarily through male-frequented coffee houses, there would have been far less social acceptability for women to drink this beverage had it not been for her example. Catherine of Braganza's use of tea as a court beverage, rather than a medicinal drink, influenced its popularity in literary circles around 1685.[9]\\r\\nThe British East India company made its first order for the importation of tea in 1667 to their agent in Bantam, and two canisters of tea weighing 143?lbs 8 oz arrived from Bantam in 1669.[10] In 1672, a servant of Baron Herbert in London sent his instructions for tea making, and warming the delicate cups, to Shropshire;\\r\\n\\"The directions for the tea are: a quart of spring water just boiled, to which put a spoonful of tea, and sweeten to the palate with candy sugar. As soon as the tea and sugar are in, the steam must be kept in as much as may be, and let it lie half or quarter of an hour in the heat of the fire but not boil. The little cups must be held over the steam before the liquid be put in.\\"[11]\\r\\nThe earliest English equipages for making tea date to the 1660s. Small porcelain tea bowls were used by the fashionable; they were occasionally shipped with the tea itself. Tea-drinking spurred the search for a European imitation of Chinese porcelain, first successfully produced in England at the Chelsea porcelain manufactory, established around 1743-45 and quickly imitated. See tea set.\\r\\nBlack tea overtook green tea in popularity in the 1720s when sugar and milk were added to tea, a practice that was not done in China. The growth in the import of tea parallels that of sugar in the 18th century.[12] Between 1720 and 1750 the imports of tea to Britain through the British East India Company more than quadrupled.[13] Fernand Braudel queried, \\"is it true to say the new drink replaced gin in England?\\"[14] By 1766, exports from Canton stood at six million pounds on British boats, compared with 4.5 on Dutch ships, 2.4 on Swedish, 2.1 on French.[15] Veritable \\"tea fleets\\" grew up. Tea was particularly interesting to the Atlantic world not only because it was easy to cultivate but also because of how easy it was to prepare and its ability to revive the spirits and cure mild colds.[16]\\r\\nThomas Twining opened the first known tea shop in 1706, which still remains at 216 Strand, London. In 1787, the company created its logo, still in use today, which is thought to be the world's oldest commercial logo that has been in continuous use since its inception.[17] Under Associated British Foods since 1964, Stephen Twining now represents the company's tenth generation. In 2006, Twinings celebrated its 300th anniversary with a special tea and associated tea caddies. Twining's is a Royal Warrant holder (appointed by HM The Queen).\\r\\nSome scholars suggest that tea played a role in British Industrial Revolution. Afternoon tea possibly became a way to increase the number of hours labourers could work in factories; the stimulants in the tea, accompanied by sugary snacks would give workers energy to finish the day's work. Further, tea helped alleviate some of the consequences of the urbanization that accompanied the industrial revolution: drinking tea required boiling the water, thereby killing water-borne diseases like dysentery, cholera, and typhoid.[18]\\r\\nThe popularity of tea occasioned the furtive export of slips, a small shoot for planting or twig for grafting to tea plants, from China to British India and its commercial cultivation there, beginning in 1840.\\r\\nBetween 1872 and 1884 the supply of tea to the British Empire increased with the expansion of the railway to the east. The demand, however, was not proportional, which caused the prices to rise. Nevertheless, from 1884 onward, due to innovation in tea preparation, the price of tea dropped and remained relatively low throughout the first half of the 20th century.\\r\\nSoon afterwards London became the centre of the international tea trade.[19] With high tea imports also came a large increase in the demand for porcelain. The demand for tea cups, pots and dishes increased to go along with this popular new drink.[16]\\r\\nRoger Fulford argues that tea rooms benefitted women in the Victorian era, in that these neutral public spaces were instrumental in the \\"spread of independence\\" for women and their struggle for the vote.[20] Paul Chrystal characterises tea rooms as \\"popular and fashionable, especially with women\\", providing them a dignified and safe place to meet and eat - and strategise on political campaigns.[21]\\r\\nEven very slightly formal events can be a cause for cups and saucers to be used instead of mugs. A typical semi-formal British tea ritual might run as follows (the host performing all actions unless noted):[22]\\r\\nWhether to put milk into the cup before or after the tea has been a matter of debate since at least the mid-20th century; in his 1946 essay \\"A Nice Cup of Tea\\", author George Orwell wrote, \\"tea is one of the mainstays of civilisation in this country and causes violent disputes over how it should be made\\".[26] Whether to put tea in the cup first and add the milk after, or the other way around, has split public opinion, with Orwell stating, \\"indeed in every family in Britain there are probably two schools of thought on the subject\\".[26]\\r\\nAnother aspect of the debate are claims that adding milk at the different times alters the flavour of the tea (for instance, see ISO 3103 and the Royal Society of Chemistry's \\"How to make a Perfect Cup of Tea\\".[27]) Some studies suggest that the heating of milk above 75 degrees Celsius (adding milk after the tea is poured, not before) does cause denaturation of the lactalbumin and lactoglobulin.[28] Other studies argue brewing time has a greater importance.[29] Regardless, when milk is added to tea, it may affect the flavour. In addition to considerations of flavour, the order of these steps is thought to have been, historically, an indication of class. Only those wealthy enough to afford good-quality porcelain would be confident of its being able to cope with being exposed to boiling water unadulterated with milk.[30]\\r\\nA further point of discussion on when to add milk is how it affects the time taken for the liquid to reach a drinkable temperature. While adding milk first will cause an initial drop in temperature which leads to a more shallow cooling curve (thus slower cooling) while also increasing volume (which would slightly increase the surface area through which the tea could lose heat), one study noted that adding milk first leads to the tea retaining heat out of all proportion with these effects. The major mechanism by which hot tea cools is not conduction or radiation but evaporative loss which is affected by the physical properties of the milk.[footnote 1] The study concluded that lipids in milk prevent water evaporating so rapidly thus retaining heat longer.[footnote 2]\\r\\nThere are opinions as to the proper manner in which to drink tea when using a cup and saucer.[31] Historically, during the 1770s and 1780s, it was fashionable to drink tea from saucers. Saucers were deeper than is the current fashion and so more similar to bowls like their Chinese antecedents.[32] If one is seated at a table, the proper manner to drink tea is to raise the teacup only, placing it back into the saucer in between sips. When standing or sitting in a chair without a table, one holds the tea saucer with the off hand and the tea cup in the dominant hand. When not in use, the tea cup is placed back in the tea saucer and held in one's lap or at waist height. In either event, the tea cup should never be held or waved in the air. Fingers should be curled inwards, no finger should extend away from the handle of the cup.[22]\\r\\nBritish workers by law, have the right to a minimum of a twenty-minute break in a shift of six hours; government guidelines describe this as \\" a tea or lunch break\\".[33] More informally, this is known as elevenses, i.e. a couple of hours before the midday meal, traditionally served at 1pm.\\r\\nBuilder's tea in a mug is typical of a quick break in the working day.\\r\\nTea is not only the name of the beverage, but of a light meal. Anna Russell, Duchess of Bedford is credited with its creation circa 1840, to ward off hunger between luncheon and dinner, as the latter was being served later and later. The tradition continues to this day in tea rooms in the UK. While these establishments have declined in popularity since World War II, there are still many to be found in the countryside. In the West Country, cream teas are a speciality: scones, clotted cream, and jam accompany the drink. Afternoon tea, in contemporary British usage, usually indicates a special occasion, perhaps in a hotel dining room, with savoury snacks (tea sandwiches) as well as small sweet pastries.\\r\\nA social event to enjoy tea together, usually in a private home, is a tea party.\\r\\n\\"Tea\\" (sometimes \\"high tea\\") can also mean the savoury, hot early evening meal. This usage is common in working class British English and in Northern England. See Tea as the evening meal.\\r\\nIn the United Kingdom a number of varieties of loose tea sold in packets from the 1940s to the 1980s contained tea cards. These were illustrated cards roughly the same size as cigarette cards and intended to be collected by children. Perhaps the best known were Typhoo tea and Brooke Bond (manufacturer of PG Tips), the latter of whom also provided albums for collectors to keep their cards in. The brand named Brooke Bond Dividend D, that is, the card was a dividend (\\"divvy\\") against the cost of the tea.\\r\\nSome renowned artists were commissioned to illustrate the cards, including Charles Tunnicliffe. Many of these card collections are now valuable collectors' items.\\r\\nA related phenomenon arose in the early 1990s when PG Tips released a series of tea-based pogs, with pictures of cups of tea and chimpanzees on them. Tetley's tea released competing pogs but never matched the popularity of the PG Tips variety.\\r\\nHistorians argue about the origins of teas popularity and many attribute it to one or two factors. Ukers argues in All About Tea: Volume I that the rise in popularity of tea in Great Britain was largely due to teas reputation among men as a medical drink that can cure a wide array of ailments and its burgeoning presence in the coffeehouses where elite men congregated.[34] As for teas popularity among women, he briefly acknowledges that Princess Catherine of Braganza made tea fashionable among aristocratic women, but largely attributes its popularity to its ubiquity in the medical discourse of seventeenth century. Ellis, Coulton, and Mauger trace teas popularity back to three distinct groups in Empire of Tea: The Asian Leaf that Conquered the World. These groups were virtuosi, merchants, and elite female aristocrats.[35] They argue that the influence of these three groups combined launched tea as a popular beverage in Great Britain. Smith, in his article Complications of the Commonplace: Tea, Sugar, and Imperialism differs from Ukers and Ellis, Coulton, and Mauger in that he argues that tea only became popular once sugar was added to the drink and tea with sugar became associated with a domestic ritual that indicated respectability.[36] Mintz, in both The Changing Roles of Food in the Story of Consumption and Sweetness and Power, agrees and disagrees with Smith. Mintz acknowledges that sugar played a monumental role in the rise of tea, but contradicts Smiths connection of tea to respectability.[37] While Smith argues that tea first became popular in the home, Mintz believes tea first became popular in the workplace, as people drank tea during the workday for its warm sweetness and stimulating properties.[38] It was later that it entered the home and became an integral part of the social fabric.[39] After reviewing the discourse, it is clear that while many historians attribute teas rise to prominence in England to only two or three varying factors, it was actually due to a combination of up to six factors that changed and progressed over time as tea became more common throughout various levels of English society.\\r\\nThe history of European interactions with tea dates back to the mid-sixteenth century. The earliest mention of tea in European literature was by Giambattista Ramusio, a Venetian explorer, as Chai Catai or Tea of China in 1559.[40] Tea was mentioned several more times in various European countries afterwards, but Jan Hugo van Linschooten, a Dutch navigator, was the first to write a printed reference of tea in 1598 in his Discours of Voyages.[41] However, it was several years later, in 1615, that the earliest known reference to tea by an Englishman took place in a letter exchanged between Mr. R. Wickham, an agent for the British East India Company stationed at Japan to a Mr. Eaton, who was stationed in Macao, China.[42] In this letter, Wickham asked Eaton to send him a pot of the best sort of chaw,[42] phonetically how one would write chh, the local (Cantonese) dialect word for tea. Another early reference to tea appears in the writings of trader Samuel Purchas in 1625.[43] Purchas describes how the Chinese consume tea as the powder of a certaine herbe called chia of which they put as much as a walnut shell may contain, into a dish of Porcelane, and drink it with hot water.[43] Though there were a number of early mentions, it was several more years before tea was actually sold in England. Thomas Garway, a tobacconist and coffee house owner, was the first person in England to sell tea as a leaf and beverage at his shop in Exchange Alley in 1657.[44] Immediately after Garway began selling it, the Sultaness Head Coffee House began selling tea as a beverage and posted the first newspaper advertisement for tea in Mercurius Politicus in 1658.[45] The announcement proclaimed That Excellent and by all Physicians approved China drink, called by the Chineans Tcha, by other Nations Tay, alias Tee, is sold at the Sultaness Head Cophee House in Sweetings Rents, by the Royal Exchange, London.[45] While tea slowly became more common in coffeehouses in the years that followed, the first tea shop in London did not open until 1717 and it was not until this time that tea became commonly used.[46] In between teas earliest mentions in England and its widespread popularity little over a century later, many factors contributed the craze for this previously unknown foreign commodity.\\r\\nThe first factor that contributed to the rise in popularity of tea was its reputation as a medical drink. Tea first became labeled as a medical drink in 1641 by Dr. Nikolas Dirx, who wrote under the pseudonym Nicolas Tulp and was a celebrated Dutch physician.[47] Tulp praised tea in his book, Observationes Medicae, claiming that nothing is comparable to this plant and that those who use it are exempt from all maladies and reach an extreme old age.[48] He goes into detail on the specific merits of tea, such as curing headaches, colds, ophthalmia, catarrh, asthma, sluggishness of the stomach, and intestinal troubles.[48] It is important to note that Tulp was also a director of the Dutch East India Company, so his praise of tea was likely a marketing tactic.[49] Thomas Garway, the first English shopkeeper to sell tea, published a broadsheet in 1660 titled An Exact Description of the Growth, Quality, and Vertues of the Leaf TEA which also praised teas medical benefits. Garway claims that the Drink is declared to be most wholesome, preserving in perfect health until extreme Old Age, as well as maketh the body active and lusty, helpeth the Headache, taketh away the difficulty of breathing, strengtheneth the Memory, and expelleth infection.[50] There were many more published works on the health benefits of tea, including those by Hartlib in 1657, Bontekoe in 1678, Povey in 1686, and Tryon in the 1690s.[51][52][53] Even John Locke, the famous English philosopher, developed a fondness for tea after spending time with Dutch medical men in the 1680s.[54] Ellis, Coulton, and Mauger refer to these men as virtuosi: scientists, philosophers, and doctors who first took an interest in tea and contributed to its early popularity as a pharmaceutical.[55] But, such as with the case of Tulp, some of these men may have been influenced by Indies companies and merchants who wished to create a market for tea. Nevertheless, there is little doubt that these writings about the so-called health benefits of tea contributed to rise in popularity of tea in England.\\r\\nThe proliferation of works on the health benefits of tea happened to come at a time when people in the upper classes of English society began to take an interest in their health, which ties into the second factor that gave rise to teas popularity. As most historians will say, Princess Catherine of Braganza, the Portuguese princess who married King Charles II in 1662, introduced tea to the aristocratic class and made it fashionable among the ladies of the court.[49][56] According to Ellis, Coulton, Maugher, tea was six to ten times more expensive than coffee in the 1660s, making it an extremely expensive and luxurious commodity.[57] Teas association with luxury was perhaps why it became so popular among the elite. Whenever it was consumed in the court, it was conspicuously on display so as to show it off.[55] Tea drinking became a central aspect of aristocratic society in England by the 1680s, particularly among women who drank it while gossiping in the home.[58] Catherine of Braganzas introduction of tea to ladies was significant because it made tea an acceptable drink for both sexes, when it easily could have been categorized as a mens drink if it had remained only available in the coffeehouses that only men frequented. Wealthy ladies desire to show off their luxurious commodities in front of other ladies also increased demand for tea and made it more popular. Another factor that made tea desirable among the elite crowd was the addition of sugar, another luxurious commodity which was already well-established among the upper classes.\\r\\nThough tea was already gaining popularity on its own, the addition of sugar is what allowed teas popularity to soar, making sugar the third factor that contributed to teas rise. According to Smith, the English began adding sugar to their tea between 1685 and the early eighteenth century.[59] At this time, sugar was already being used to enhance the flavor of other foods among the elite and had a reputation as an ostentatious luxury.[60] Because both tea and sugar had status implications it made sense to drink them together.[61] Furthermore, sugar imports into England were growing rapidly because the supply of sugar was highly elastic due to the growth of sugar plantations in the Americas.[62] But, as previously mentioned, the elite classes of England were starting to care more about their health and literature on the unhealthiness of sugar was beginning to circulate in the late seventeenth century.[63] Adding sugar to tea, however, was seen as an acceptable way to consume sugar because it suggested that one had the self-control to consume sugar in a healthy way.[63] Sugar also masks teas bitterness, so it simply made tea more desirable because it tasted better. As the supply of both tea and sugar grew during the early eighteenth century, the combination of the two commodities became more universal and increased the popularity and demand for both products.\\r\\nTea would not have become the English staple it is known as if not for the increase in its supply that made it more accessible. When tea was first introduced to England, the British East India Company was not directly trading with China and merchants relied on tea imports from Holland.[64] Because this tea was so expensive and difficult to get, there was very little demand for it, except among the elite who could afford it and made special orders. It was not until after 1700 that the British East India Company began to trade regularly with China and ordering tea, though not in large quantities.[65] Smith argues that the tea trade was actually a side effect of the silk and textile trade because these were the Chinese commodities that were most desired at the time.[65] In 1720, however, Parliament banned the importation of finished Asian textiles and traders began to focus on tea instead.[65] This new focus marked a turning point for the English tea trade and is arguably why tea became more popular than coffee. Once the British East India company focused on tea as its main import, tea attained price stability soon after. Conversely, the price of coffee remained unpredictable and high, allowing tea to grow in popularity before coffee became more accessible.[66] Furthermore, the rising demand for tea and sugar was easily met with increased supply as the tea industry grew in India, which prevented sharp price increases that would have discouraged people from buying it.[67] In fact, the price of tea actually fell as it was becoming more popular among the upper-middle and middle classes. The significant drop in teas price between 1720 and 1750 was a major turning point for tea in England. The increase in supply of tea was one of the most important factors that boosted its popularity in Britain and opened up the world of tea to new levels of society.\\r\\nThe fifth factor that led to teas dominance in Great Britain was its adoption as a domestic ritual enjoyed by a variety of groups in the middle and upper classes. Because tea began as a luxury for only the super-rich, it already had a reputation as a high-class commodity. But as prices slowly dropped in the eighteenth century, more people at the middle levels of society had access to it. According to Smith, drinking tea became associated with respectability.[68] When people drank tea, they were expected to possess certain manners and behave in a particular way.[68] Soon, drinking tea became a domestic ritual among families, colleagues, and friends who were just wealthy enough to afford it, which also increased demand.[67] The association between tea and respectability became so ingrained in British culture that it reached a point where it could not go out of fashion.[63] Tea-drinking among these groups was also soon considered patriotic. Because the British East India Company had a monopoly over the tea industry in England, tea became more popular than coffee, chocolate, and alcohol.[69] Tea was seen as inherently British and tea-drinking was encouraged by the British government because of the revenue gained from taxing tea.[70] Unlike coffee and chocolate, which came from the colonies of Britains rivals in various regions of the world, tea was produced in a single massive colony and served as a means of not only profit, but colonial power.[70][63] Mintz goes so far as to argue that the combination of ritualization and increased production in the British colonies was how tea became inherently British.[71] As the British continued to import more and more tea throughout the eighteenth century, tea slowly went from a respectable commodity consumed by the well-mannered classes in domestic rituals to an absolute necessity in the British diet, even among the poor working classes. It was at this point that tea became universal among all levels of society.\\r\\nTeas popularity finally reached the working class in the late eighteenth century and early nineteenth century and was soon considered an everyday necessity among poor laborers. According to Scottish historian David MacPherson, tea had become cheaper than beer in the early nineteenth century.[72] Furthermore, sugar had also become extremely cheap by this time and the two were almost always consumed together.[73] However, the poor consumed tea much differently than the well-mannered ritual adopted by the upper classes. For starters, according to Mintz, tea-drinking among the poor probably began in connection with work, not in the home.[74] Day laborers brewed their tea out in the open and brought their tea equipment with them to work, as opposed to the private domestic ritual that had previously surrounded tea-drinking.[39] Teas cheapness at this time definitely contributed to its adoption among the poor, but there were other factors as well. Drinking a hot, sweet beverage transformed their meals, which generally consisted of dry bread and cheese, and made them go down more easily.[39] Additionally, the warm beverage was especially appealing given Britains cold and wet climate.[39][71] The poor also got a significant calorie boost when sugar was added, which gave them an energy bump when combined with teas stimulant properties.[71] Though the price of coffee had also gone down by this point, tea was the preferred drink because, unlike coffee, it still tasted good when diluted, which is often how the poor consumed it in order to save money.[75] John Hanway, an eighteenth century social reformer, observed the widespread consumption of tea by the poor in 1767. He described a certain lane...where beggars are often seen...drinking their tea, as well as laborers mending their roads drinking their tea and tea in the cups of haymakers.[76] Just two centuries after the first appearance of tea in English society as a beverage for aristocrats, tea had become so widely popular and available that those at the absolute bottom of the social hierarchy were consuming it as their beverage of choice.\\r\\nThe rise in popularity of tea between the seventeenth and nineteenth centuries had major social, political, and economic implications for Great Britain. It defined respectability and domestic rituals, supported the rise and dominance of the British Empire, and contributed to the rise of the Industrial Revolution by supplying both the capital for factories and calories for laborers.[39] It also demonstrates the power of globalization and imperialism to transform a country and shape it into the modern society it is known as today. Tea remains a popular drink in Britain in the modern day and is still considered to be the epitome of British ritual and identity.\\r\\nIn 2003, DataMonitor reported that regular tea drinking in the United Kingdom was on the decline.[77] There was a 10.25 percent decline in the purchase of normal teabags in Britain between 1997 and 2002.[77] Sales of ground coffee also fell during the same period.[77] Britons were instead drinking health-oriented beverages like fruit or herbal teas, consumption of which increased 50 percent from 1997 to 2002. A further, unexpected, statistic is that the sales of decaffeinated tea and coffee fell even faster during this period than the sale of the more common varieties.[77] Declining tea sales were matched by an increase in espresso sales.[78]","input":"How did tea make its way to england?"},{"output":"16,000 years ago","context":"Meadowcroft Rockshelter is an archaeological site located near Avella in Jefferson Township, Washington County, Pennsylvania, United States.  The site, a rock shelter in a bluff overlooking Cross Creek (a tributary of the Ohio River), is located 27 miles west-southwest of Pittsburgh[4] in the Pittsburgh metropolitan area. In the 21st century, the site has a museum and a reconstruction of a circa 1570s Monongahela Culture Indian village. It operates as a division of the Heinz History Center of Pittsburgh.  The artifacts from the site show the area may have been continually inhabited for more than 19,000 years, since Paleo-Indian times.\\r\\n\\r\\nThe remarkably complete archaeological site shows the earliest known evidence of human presence and the longest sequence of continuous human occupation in the New World.[2]\\r\\n\\r\\nIt is recognized as a National Historic Landmark, a Pennsylvania Commonwealth Treasure, and as an official project of Save America's Treasures.\\r\\n\\r\\nThe rockshelter is a natural formation beneath an overhanging cliff of Morgantown-Connellsville sandstone, which is a thick Pennsylvanian-age sandstone, brown in color. Meadowcroft is in the Allegheny Plateau, northwest of the Appalachian Basin.[5]\\r\\n\\r\\nThe site was listed on the National Register of Historic Places in 1978.  In 1999\\r\\n, the Pennsylvania Historical and Museum Commission installed a historical marker noting the historic importance of the site.[2]  It was designated a National Historic Landmark in 2005.[3]  It is designated as a historic public landmark by the Washington County History & Landmarks Foundation.[6]\\r\\n\\r\\nNative Americans left the site during the American Revolutionary War. It was not re-discovered until many years later, when, in 1955, Albert Miller found the first artifacts in a groundhog burrow. Miller delayed reporting his findings until he contacted James M. Adovasio, who led the first excavations of the site in 1973 until 1979 by the Cultural Resource Management Program of the University of Pittsburgh. Further University of Pittsburgh field school excavations were conducted through 1989.[7][8] Since the 1990s, more recent work has also been undertaken by Adovasio through the Mercyhurst Archaeological Institute.[9] The methods of excavation used at Meadowcroft are still seen as state-of-the-art. It is viewed as one of the most carefully excavated sites in North America.[10]\\r\\n\\r\\nRadiocarbon dating of the site indicated occupancy beginning 16,000 years ago and possibly as early as 19,000 years ago.  The dates are still controversial. A recent survey carried out by the Society for American Archaeology reported support from 38% of archaeologists, with 20% rejecting the early dates.[11]  Criticism of these early radiocarbon dates has focused on the potential for contamination by ancient carbon from coal-bearing strata in the watershed.[12] The samples, tested by an independent third party geomorphologist, concluded that the samples showed no evidence of groundwater activity. Tests performed via accelerator mass spectrometry also support the earlier dates.[13] If authentic, these dates would indicate that Meadowcroft was used in the pre-Clovis era and, as such, provides evidence for very early human habitation of the Americas.[14][15] Meadowcroft Rockshelter may be the oldest known site of human habitation in North America, providing a unique glimpse into the lives of prehistoric hunters and gatherers. Paleoindian, Archaic, and  Woodland remains have all been found at the site.\\r\\n\\r\\nMeadowcroft Rockshelter has yielded the largest collection of flora and fauna materials ever recovered from a location in eastern North America.[16]  The arid environment provided the necessary and rare conditions that permitted excellent botanical preservation. In total, animal remains representing 149 species were excavated. Evidence shows that people gathered smaller game animals as well as plants, such as corn, squash, fruits, nuts and seeds.\\r\\n\\r\\nAdditionally, the site has produced Pre-Clovis remains, found as deep as 11.5 feet underground.  The site also has yielded many tools, including pottery, bifaces, bifacial fragments, lamellar blades, a lanceolate projectile point, and chipping debris. Recoveries of note also include fluted points, which are a marker of the Paleoindian period. Remains of flint from Ohio, jasper from eastern Pennsylvania and marine shells from the Atlantic coast suggest that the people inhabiting the area were mobile and involved in long-distance trade.  At least one basin-shaped hearth was reused over time.\\r\\n\\r\\nAn unusual type of arrowhead was found at the site, that has been named as the Miller Lanceolate projectile point. Similar un?uted lanceolate points have also been found at the adjacent sites.\\r\\n\\r\\nEnough lithic artifacts were recovered to define the Miller complex. This complex consists of thin bifaces, including one lanceolate point, the Miller Lanceolate; small prismatic blades; retouched flake tools and blades; and debitage related to latestage core and biface reduction and tool kit maintenance.\\r\\nThe Miller complex is further defined by surveys done in the Cross Creek watershed, where other lanceolate points, small prismatic blades, and small polyhedral blade cores have been recovered. According to Adovasio et al,[17] this complex has a Eurasiatic and Siberian appearance. These authors also note that small blades and polyhedral cores are absent from subsequent Paleoindian fluted-point assemblages in this region, reinforcing the technological distinctiveness of the Miller complex.[18]\\r\\nThe adjacent Krajacic Site is located about 10 miles southeast of Meadowcroft, and it is also important in defining the Miller complex. This site yielded a great variety of the distinctive Meadowcroft-style blade implements and several small, cylindrical polyhedral cores.\\r\\n\\r\\nAt Cactus Hill in Virginia, similar points have been found, where they are dubbed as the Early Triangular type. Some similar finds were made at the Page-Ladson prehistory site in Florida as well.\\r\\n\\r\\nBecause of the very long occupational sequence at Meadowcroft, it became a very important site, and is seen as quite valuable for comparative analysis.\\r\\n\\r\\nThe Pre-Clovis artifacts from Meadowcroft Rockshelter include a lanceolate point (named the Miller Lanceolate), bifaces, unifaces, prismatic blades, core fragments, and debitage. Remains from other Pre-Clovis sites (e.g., Cactus Hill and Saltville, Virginia, Topper, South Carolina, etc.) are usually compared to the Meadowcroft assemblage.[19] In addition, claims for Pre-Clovis inhabitants in other sections of the New World also are evaluated with Meadowcroft in mind (Lozano Ruiz 2000).[20]\\r\\nAccording to some scholars, Clovis, Folsom and other fluted point complexes may have derived from such unfluted lanceolate points.\\r\\n\\r\\nRenovations to the rock shelter in 2008 were made so that visitors can see some of the tools and campfires made by the first Americans thousands of years ago. The Rockshelter is recognized as a Pennsylvania Commonwealth Treasure and is an official project of Save America's Treasures.   The historic site also includes a recreation of a 16th-century Monongahela village as well as 18th and 19th century buildings from European and United States settlement.[21]","input":"When did the oldest human occupation of meadowcroft rockshelter occur?"},{"output":"Paul McCartney","context":"\\r\\n\\r\\n\\"Ob-La-Di, Ob-La-Da\\" is a song by the Beatles from their 1968 album The Beatles (often called \\"the White Album\\"). Although credited to LennonÿMcCartney, the song was written solely by Paul McCartney. It was released as a single that same year in many countries, but not in their native United Kingdom, nor in the United States until 1976.\\r\\n\\r\\nPaul McCartney wrote the song around the time that highlife and reggae were beginning to become popular in Britain. The starting lyric, \\"Desmond has a barrow in the market-place\\", was a reference to the first internationally renowned Jamaican ska and reggae performer Desmond Dekker who had just had a successful tour of the UK.[4] The tag line \\"ob-la-di, ob-la-da, life goes on, brah\\" was an expression used by Nigerian conga player Jimmy Scott-Emuakpor, an acquaintance of McCartney.[5] Another example of the term in popular culture is the 1945 song 'In the Land of Oo-Bla-Dee', which Mary Lou Williams composed for Dizzy Gillespie (heard on Dizzy Digs Paris).\\r\\n\\r\\nThe song is in the key of B-flat major and written in 4/4 time. The alternative version issued on Anthology 3 is in the lower key of A major.\\r\\n\\r\\nIn May 1968, following their return from studying Transcendental Meditation in Rishikesh, India, the Beatles gathered at George Harrison's Esher home, in Surrey, to record demos for their upcoming project.[6] \\"Ob-La-Di, Ob-La-Da\\" was one of the twenty-seven demos recorded there.[7] McCartney performed this demo solo, with only an acoustic guitar. He also double-tracked his vocal, which was not perfectly synchronised, creating an echoing effect.\\r\\n\\r\\nThe formal recording of \\"Ob-La-Di, Ob-La-Da\\" involved several days of work, during which the Beatles experimented with different tempos and styles. At McCartney's insistence, the band remade the song twice in an effort to capture the version he was aiming for. According to studio engineer Geoff Emerick, John Lennon \\"openly and vocally detested\\" the song, calling it Paul's \\"granny music shit\\".[8] Having left the studio during one of the sessions, Lennon then returned while under the influence of marijuana, went immediately to the piano and played the opening chords louder and faster than before. He claimed that was how the song should be played, and that is the version the Beatles ended up using.[9]\\r\\n\\r\\nWhen singing the vocals over the final verse, McCartney made a slip and said \\"Desmond stays at home and does his pretty face\\" (rather than Molly), and had Molly letting \\"the children lend a hand\\". Reportedly, this mistake was retained because the other Beatles liked it.[10] Harrison and Lennon yell \\"arm\\" and \\"leg\\" between the lines \\" Desmond lets the children lend a hand\\" and \\"Molly stays at home \\"[11]\\r\\n\\r\\nThe lyrics of Harrison's White Album track \\"Savoy Truffle\\" include the line \\"We all know Ob-la-di-bla-da, but can you show me where you are?\\"[12] According to music journalist Robert Fontenot, Harrison (like Lennon) was \\"very vocal in [his] dislike of 'Ob-La-Di, Ob-La-Da'\\", and the reference in \\"Savoy Truffle\\" was his way of conveying his opinion of McCartney's song.[13]\\r\\n\\r\\nThe intro of this song is heard on the Beatles' 1968 Christmas Record.\\r\\n\\r\\n\\"Ob-La-Di, Ob-la-Da\\" was released on The Beatles on 22 November 1968.[14] In the US, in 1976, it was released as a single with \\"Julia\\" as the B-side.[15] An alternate version, known as \\"Take 5\\", was released on Anthology 3 in which the horns are much more prominent and feature less reggae-esque style of music, focusing on acoustic guitars.\\r\\n\\r\\nThe first time the song was performed live by any of the Beatles was on 2 December 2009, when McCartney played it in Hamburg, Germany on the first night of a European tour.[16] McCartney also performed the song in Hyde Park on 27 June 2010 as part of the Hard Rock Calling event, and the song was well received by the crowd.[citation needed] He also added it as a number in the Latin American Leg of the Up and Coming Tour. In 2011, the song was performed during McCartney's on the Run Tour. It was also performed in front of Buckingham Palace for the Queen's Diamond Jubilee celebrations, then at San Francisco's Outside Lands concert on 9 August 2013. Most recently, it was performed by McCartney on his 2013-2015 Out There! tour and his 2016-2017 One on One tour.\\r\\n\\r\\n\\"Ob-La-Di, Ob-La-Da\\" went to number one in singles charts in Austria, Switzerland, Australia and Japan. In the UK and Norway (where it had not been released as a single by the Beatles), a cover version by The Marmalade also made number one.\\r\\n\\r\\nThe track is often the subject of ridicule. It was voted the worst song of all time in a 2004 online poll organised by Mars.[17] New Musical Express website editor Luke Lewis has argued that the Beatles recorded \\"a surprising amount of ropy old toss\\", singling out \\"Ob-La-Di, Ob-La-Da\\" as \\"the least convincing cod-reggae skanking this side of the QI theme tune\\".[18] Tom Rowley in The Telegraph named the track as a \\"reasonable choice\\" for derision, following the result of the Mars poll.[18] It was also included in Blender magazine's 2004 list \\"50 Worst Songs Ever!\\"[19] CNN journalist Todd Leopold reported in 2006 that Lennon \\"loathed\\" the song.[20]\\r\\n\\r\\nOn the other hand, Stephen Thomas Erlewine of AllMusic includes the song among McCartney's \\"stunning\\" compositions on The Beatles.[21] In his contemporary review for Rolling Stone, Jann Wenner wrote: \\"Part of the phenomenal talent of the Beatles is their ability to compose music that by itself carries the same message and mood as the lyrics. The lyrics and the music not only say the same thing, but are also perfectly complementary. This comes also with the realization that rock and roll is music, not literature, and that the music is the most important aspect of it. 'Obladi Oblada,' where they take one of the familiar calypso melodies and beats, is a perfect example. And it's not just a calypso, but a rock and roll calypso with electric bass and drums. Fun music for a fun song about fun. Who needs answers? Not Molly or Desmond Jones, they're married with a diamond ring and kids and a little 'Obladi Oblada.' All you need is Obladi Oblada.\\"[22]\\r\\n\\r\\nJimmy Scott-Emuakpor (McCartney's Nigerian acquaintance) later tried to claim a writer's credit for the use of his catchphrase in the song; McCartney claimed that the phrase was \\"just an expression\\". Scott argued that not only was the phrase not a general expression, but that it was in fact exclusively used in the Scott-Emuakpor family. He later dropped the case when McCartney agreed to pay his legal expenses for an unrelated issue.[10]\\r\\n\\r\\nThe Scottish pop band Marmalade released their rendition of \\"Ob-La-Di, Ob-La-Da\\" in 1968. Their version reached number one in the UK Singles Chart in January 1969, making them the first Scottish group to ever top that chart.[26][27] Their cover sold around half a million in the UK, and a million copies globally by April 1969.[28] They appeared on BBC One's music programme Top of the Pops to perform the track in kilts.\\r\\n\\r\\nBecause the song features the lyrics \\"life goes on\\", a version performed by Patti LuPone and the cast of Life Goes On was featured on the 1989ÿ1993 drama of that name on ABC.","input":"Who wrote ob la di ob la da?"},{"output":"Sudetenland","context":"The Sudetenland (/su??de?t?nl?nd/?(?listen); German: [zu?de?tn??lant]; Czech and Slovak: Sudety; Polish: Kraj Sudecki) is the historical German name for the northern, southern, and western areas of former Czechoslovakia which were inhabited primarily by Sudeten Germans. These German speakers had predominated in the border districts of Bohemia, Moravia, and Czech Silesia from the time of the Austrian Empire.\\r\\nThe word \\"Sudetenland\\" did not come into existence until the early 20th century and did not come to prominence until after the First World War, when the German-dominated Austria-Hungary was dismembered and the Sudeten Germans found themselves living in the new country of Czechoslovakia. The Sudeten crisis of 1938 was provoked by the Pan-Germanist demands of Germany that the Sudetenland be annexed to Germany, which happened after the later infamous Munich Agreement. When Czechoslovakia was reconstituted after the Second World War, the Sudeten Germans were largely expelled or killed, and the region today is inhabited almost exclusively by Czech speakers.\\r\\nSudetenland is a compound word where land means \\"country\\" and Sudeten is the German name of the Sudetes mountains, which run along the northern Czech border and Lower Silesia (now in Poland), although the Sudetenland encompassed areas well beyond those mountains.\\r\\nParts of the current Czech regions of Karlovy Vary, Liberec, Olomouc, Moravia-Silesia, and ~st nad Labem are situated within the former Sudetenland.\\r\\n\\r\\n\\r\\nThe areas later known as the Sudetenland never formed a single historical region, which makes it difficult to distinguish the history of the Sudetenland apart from that of Bohemia, until the advent of nationalism in the 19th century.\\r\\nThe Celtic and Boii tribes settled there and the region was first mentioned on the map of Ptolemaios in the 2nd century AD. The Germanic tribe of the Marcomanni dominated the entire core of the region in later centuries. Those tribes already built cities like Brno, but moved west during the Migration Period. In the 7th century AD Slavic people moved in and were united under Samo's realm. Later in the High Middle Ages Germans settled into the less populated border region.\\r\\nIn the Middle Ages the regions situated on the mountainous border of the Duchy and the Kingdom of Bohemia had since the Migration Period been settled mainly by western Slavic Czechs. Along the Bohemian Forest in the west, the Czech lands bordered on the German Slavic tribes (German Sorbs) stem duchies of Bavaria and Franconia; marches of the medieval German kingdom had also been established in the adjacent Austrian lands south of the Bohemian-Moravian Highlands and the northern Meissen region beyond the Ore Mountains. In the course of the Ostsiedlung (settlement of the east) German settlement from the 13th century onwards continued to move into the Upper Lusatia region and the duchies of Silesia north of the Sudetes mountain range.\\r\\nFrom as early as the second half of the 13th century onwards these Bohemian border regions were settled by ethnic Germans, who were invited by the P?emyslid Bohemian kings  especially by Ottokar II (1253ÿ1278) and Wenceslaus II (1278ÿ1305). After the extinction of the P?emyslid dynasty in 1306, the Bohemian nobility backed John of Luxembourg as king against his rival Duke Henry of Carinthia. In 1322 King John of Bohemia acquired (for the third time) the formerly Imperial Egerland region in the west and was able to vassalize most of the Piast Silesian duchies, acknowledged by King Casimir III of Poland by the 1335 Treaty of Trentschin. His son, Bohemian King Charles IV, was elected King of the Romans in 1346 and crowned Holy Roman Emperor in 1355. He added the Lusatias to the Lands of the Bohemian Crown, which then comprised large territories with a significant German population.\\r\\nIn the hilly border regions German settlers established major manufactures of forest glass. The situation of the German population was aggravated by the Hussite Wars (1419ÿ1434), though there were also some Germans among the Hussite insurgents.\\r\\nBy then Germans largely settled the hilly Bohemian border regions as well as the cities of the lowlands; mainly people of Bavarian descent in the South Bohemian and South Moravian Region, in Brno, Jihlava, ?esk Budjovice and the West Bohemian Plze Region; Franconian people in ?atec; Upper Saxons in adjacent North Bohemia, where the border with the Saxon Electorate was fixed by the 1459 Peace of Eger; Germanic Silesians in the adjacent Sudetes region with the County of Kladsko, in the MoravianÿSilesian Region, in Svitavy and Olomouc. The city of Prague had a German-speaking majority from the last third of the 17th century until 1860, but after 1910 the proportion of German speakers had decreased to 6.7% of the population.\\r\\nFrom the Luxembourgs, the rule over Bohemia passed through George of Podiebrad to the Jagiellon dynasty and finally to the House of Habsburg in 1526. Both Czech and German Bohemians suffered heavily in the Thirty Years War. Bohemia lost 70% of its population. From the defeat of the Bohemian Revolt that collapsed at the 1620 Battle of White Mountain, the Habsburgs gradually integrated the Kingdom of Bohemia into their monarchy. During the subsequent Counter-Reformation, less populated areas were resettled with Catholic Germans from the Austrian lands. From 1627 the Habsburgs enforced the so-called Verneuerte Landesordnung (\\"Renewed Land's Constitution\\") and one of its consequences was that German according to mother tongue gradually became the primary and official language while Czech declined to a secondary role in the Empire. Also in 1749 Austrian Empire enforced German as the official language again. Emperor Joseph II in 1780 renounced the coronation ceremony as Bohemian king and unsuccessfully tried to push German through as sole official language in all Habsburg lands (including Hungary). Nevertheless, German cultural influence grew stronger during the Age of Enlightenment and Weimar Classicism.\\r\\nOn the other hand, in the course of the Romanticism movement national tensions arose, both in the form of the Austroslavism ideology developed by Czech politicians like Franti?ek Palacky and Pan-Germanist activist raising the German question. Conflicts between Czech and German nationalists emerged in the 19th century, for instance in the Revolutions of 1848: while the German-speaking population of Bohemia and Moravia wanted to participate in the building of a German nation state, the Czech-speaking population insisted on keeping Bohemia out of such plans. The Bohemian Kingdom remained a part of the Austrian Empire and Austria-Hungary until its dismemberment after the First World War.\\r\\nIn the wake of growing nationalism, the name \\"Sudetendeutsche\\" (Sudeten Germans) emerged by the early 20th century. It originally constituted part of a larger classification of three groupings of Germans within the Austro-Hungarian Empire, which also included \\"Alpine Deutschen\\" (English: Alpine Germans) in what later became the Republic of Austria and \\"Balkandeutsche\\" (English: Balkan Germans) in Hungary and the regions east of it. Of these three terms, only the term \\"Sudetendeutsche\\" survived, because of the ethnic and cultural conflicts within Bohemia.\\r\\nDuring World War I, what would later be known as the Sudetenland experienced a rate of war deaths higher than most other German-speaking areas of Austria-Hungary and exceeded only by German South Moravia and Carinthia. Thirty-four of each 1,000 inhabitants were killed.[1]\\r\\nAustria-Hungary broke apart at the end of World War I. Late in October 1918, an independent Czechoslovak state, consisting of the lands of the Bohemian kingdom and areas belonging to the Kingdom of Hungary, was proclaimed. The German deputies of Bohemia, Moravia, and Silesia in the Imperial Council (Reichsrat) referred to the Fourteen Points of U.S. President Woodrow Wilson and the right proposed therein to self-determination, and attempted to negotiate the union of the German-speaking territories with the new Republic of German Austria, which itself aimed at joining Weimar Germany.\\r\\nThe German-speaking parts of the former Lands of the Bohemian Crown remained in a newly created Czechoslovakia, a multi-ethnic state of several nations: Czechs, Germans, Slovaks, Hungarians, Poles and Ruthenians. On 20 September 1918, the Prague government asked the United States's opinion for the Sudetenland. President Woodrow Wilson sent Ambassador Archibald Coolidge into Czechoslovakia. After Coolidge became witness of German Bohemian demonstrations,[2] Coolidge suggested the possibility of ceding certain German-speaking parts of Bohemia to Germany (Cheb) and Austria (South Moravia and South Bohemia).[citation needed] He also insisted that the German-inhabited regions of West and North Bohemia remain within Czechoslovakia. The American delegation at the Paris talks, with Allen Dulles as the American's chief diplomat in the Czechoslovak Commission who emphasized preserving the unity of the Czech lands, decided not to follow Coolidge's proposal.[3]\\r\\nFour regional governmental units were established:\\r\\nThe U.S. commission to the Paris Peace Conference issued a declaration which gave unanimous support for \\"unity of Czech lands\\".[4] In particular the declaration stated:\\r\\nThe Commission was...unanimous in its recommendation that the separation of all areas inhabited by the German-Bohemians would not only expose Czechoslovakia to great dangers but equally create great difficulties for the Germans themselves. The only practicable solution was to incorporate these Germans into Czechoslovakia.\\r\\nSeveral German minorities according to their mother tongue in Moraviaincluding German-speaking populations in Brno, Jihlava, and Olomoucalso attempted to proclaim their union with German Austria, but failed. The Czechs thus rejected the aspirations of the German Bohemians and demanded the inclusion of the lands inhabited by ethnic Germans in their state, despite the presence of more than 90% (as of 1921) ethnic Germans (which led to the presence of 23.4% of Germans in all of Czechoslovakia), on the grounds they had always been part of lands of the Bohemian Crown. The Treaty of Saint-Germain in 1919 affirmed the inclusion of the German-speaking territories within Czechoslovakia. Over the next two decades, some Germans in the Sudetenland continued to strive for a separation of the German-inhabited regions from Czechoslovakia.\\r\\nAccording to the February 1921 census, 3,123,000 native German speakers lived in Czechoslovakia23.4% of the total population. The controversies between the Czechs and the German-speaking minority lingered on throughout the 1920s, and intensified in the 1930s.\\r\\nDuring the Great Depression the mostly mountainous regions populated by the German minority, together with other peripheral regions of Czechoslovakia, were hurt by the economic depression more than the interior of the country. Unlike the less developed regions (Ruthenia, Moravian Wallachia), the Sudetenland had a high concentration of vulnerable export-dependent industries (such as glass works, textile industry, paper-making, and toy-making industry). Sixty percent of the bijouterie and glass-making industry were located in the Sudetenland, 69% of employees in this sector were Germans speaking according to mother tongue, and 95% of bijouterie and 78% of other glassware was produced for export. The glass-making sector was affected by decreased spending power and also by protective measures in other countries and many German workers lost their work.[6]\\r\\nThe high unemployment, as well as the imposition of Czech in schools and all public spaces, made people more open to populist and extremist movements such as fascism, communism, and German irredentism. In these years, the parties of German nationalists and later the Nazi Sudeten German National Socialist Party (SdP) with its radical demands gained immense popularity among Germans in Czechoslovakia.\\r\\nThe increasing aggressiveness of Hitler prompted the Czechoslovak military to build extensive border fortifications starting in 1936 to defend the troubled border region. Immediately after the Anschlu? of Austria into the Third Reich in March 1938, Hitler made himself the advocate of ethnic Germans living in Czechoslovakia, triggering the \\"Sudeten Crisis\\". The following month, Sudeten Nazis, led by Konrad Henlein, agitated for autonomy. On 24 April 1938 the SdP proclaimed the Karlsbader Programm?(de), which demanded in eight points the complete equality between the Sudeten Germans and the Czech people. The government accepted these claims on 30 June 1938.[clarification needed][7]\\r\\nIn August, British Prime Minister Neville Chamberlain sent Lord Runciman on a Mission to Czechoslovakia in order to see if he could obtain a settlement between the Czechoslovak government and the Germans in the Sudetenland. Lord Runciman's first day included meetings with President Bene? and Prime Minister Milan Hod?a as well as a direct meeting with the Sudeten Germans from Henlein's SdP. On the next day he met with Dr and Mme Bene? and later met non-Nazi Germans in his hotel.[8]\\r\\nA full account of his reportincluding summaries of the conclusions of his meetings with the various partieswhich he made in person to the Cabinet on his return to Britain is found in the Document CC 39(38).[9] Lord Runciman[10] expressed sadness that he could not bring about agreement with the various parties, but he agreed with Lord Halifax that the time gained was important. He reported on the situation of the Sudeten Germans, and he gave details of four plans which had been proposed to deal with the crisis, each of which had points which, he reported, made it unacceptable to the other parties to the negotiations.\\r\\nThe four were: Transfer of the Sudetenland to the Reich; hold a plebiscite on the transfer of the Sudetenland to the Reich, organize a Four Power Conference on the matter, create a federal Czechoslovakia. At the meeting, he said that he was very reluctant to offer his own solution; he had not seen this as his task. The most that he said was that the great centres of opposition were in Eger and Asch, in the northwestern corner of Bohemia, which contained about 800,000 Germans and very few others.\\r\\nHe did say that the transfer of these areas to Germany would almost certainly be a good thing; he added that the Czechoslovak army would certainly oppose this very strongly, and that Bene? had said that they would fight rather than accept it.[11]\\r\\nBritish Prime Minister Neville Chamberlain met with Adolf Hitler in Berchtesgaden on 15 September and agreed to the cession of the Sudetenland; three days later, French Prime Minister douard Daladier did the same. No Czechoslovak representative was invited to these discussions. Germany was now able to walk into the Sudetenland without firing a shot.\\r\\nChamberlain met Hitler in Godesberg on 22 September to confirm the agreements. Hitler, aiming to use the crisis as a pretext for war, now demanded not only the annexation of the Sudetenland but the immediate military occupation of the territories, giving the Czechoslovak army no time to adapt their defence measures to the new borders. To achieve a solution, Italian dictator Benito Mussolini suggested a conference of the major powers in Munich and on 29 September, Hitler, Daladier and Chamberlain met and agreed to Mussolini's proposal (actually prepared by Hermann G?ring) and signed the Munich Agreement, accepting the immediate occupation of the Sudetenland. The Czechoslovak government, though not party to the talks, submitted to compulsion and promised to abide by the agreement on 30 September.\\r\\nThe Sudetenland was relegated to Germany between 1 October and 10 October 1938. The Czech part of Czechoslovakia was subsequently invaded by Germany in March 1939, with a portion being annexed and the remainder turned into the Protectorate of Bohemia and Moravia. The Slovak part declared its independence from Czechoslovakia, becoming the Slovak Republic (Slovak State), a satellite state and ally of Nazi Germany. (The Ruthenian part?ÿ Subcarpathian Rus?ÿ made also an attempt to declare its sovereignty as Carpatho-Ukraine but only with ephemeral success. This area was annexed by Hungary.)\\r\\nPart of the borderland was also invaded and annexed by Poland.\\r\\nThe Catholic Requiem of fallen Czech policemen and security officials killed in a skirmish by Sudeten German Freecorps members, at Falkenau an der Eger (Czech: Sokolov) in the Egerland\\r\\nEthnic Germans in the city of Eger (Czech: Cheb) greeting Hitler with the Nazi salute after he crossed the border into the formerly Czechoslovak Sudetenland on 3 October 1938\\r\\nVolunteers of the Sudeten German Free Corps (German: Sudetendeutsches Freikorps) receiving refreshments from the local population in the city of Eger (Czech: Cheb)\\r\\nAdolf Hitler drives through the crowd in Eger, 3 October 1938\\r\\nThe Sudetenland was initially put under military administration, with General Wilhelm Keitel as military governor. On 21 October 1938, the annexed territories were divided, with the southern parts being incorporated into the neighbouring Reichsgaue Niederdonau, Oberdonau and Bayerische Ostmark.\\r\\nThe northern and western parts were reorganized as the Reichsgau Sudetenland, with the city of Reichenberg (present-day Liberec) established as its capital. Konrad Henlein (now openly a NSDAP member) administered the district first as Reichskommissar (until 1 May 1939) and then as Reichsstatthalter (1 May 1939?ÿ 4 May 1945). The Sudetenland consisted of three administrative districts (Regierungsbezirke): Eger (with Karlsbad as capital), Aussig (Aussig) and Troppau (Troppau).\\r\\nShortly after the annexation, the Jews living in the Sudetenland were widely persecuted. Only a few weeks afterwards, the Kristallnacht occurred. As elsewhere in Germany, many synagogues were set on fire and numerous leading Jews were sent to concentration camps. In later years, the Nazis transported up to 300,000 Czech and Slovak Jews to concentration camps,[12] where many of them were killed or died. Jews and Czechs were not the only afflicted peoples; German socialists, communists and pacifists were widely persecuted as well. Some of the German socialists fled the Sudetenland via Prague and London to other countries. The Gleichschaltung would permanently alter the community in the Sudetenland.\\r\\nDespite this, on 4 December 1938 there were elections in Reichsgau Sudetenland, in which 97.32% of the adult population voted for NSDAP. About a half million Sudeten Germans joined the Nazi Party which was 17.34% of the total German population in the Sudetenland (the average NSDAP membership participation in Nazi Germany was merely 7.85% in 1944). This means the Sudetenland was one of the most pro-Nazi regions of the Third Reich.[13] Because of their knowledge of the Czech language, many Sudeten Germans were employed in the administration of the ethnic Czech Protectorate of Bohemia and Moravia as well as in Nazi organizations (Gestapo, etc.). The most notable was Karl Hermann Frank: the SS and Police general and Secretary of State in the Protectorate.\\r\\nShortly after the liberation of Czechoslovakia in May 1945, the use of the term Sudety (Sudetenland) in official communications was banned and replaced by the term pohrani?n ~zem (border territory).[14]\\r\\nAfter World War II in summer 1945 the Potsdam Conference decided that Sudeten Germans would have to leave Czechoslovakia (see Expulsion of Germans after World War II). As a consequence of the immense hostility against all Germans that had grown within Czechoslovakia due to Nazi behavior, the overwhelming majority of Germans were expelled (while the relevant Czechoslovak legislation provided for the remaining Germans who were able to prove their anti-Nazi affiliation).\\r\\nThe number of expelled Germans in the early phase (springÿsummer 1945) is estimated to be around 500,000 people. Following the Bene? decrees and starting in 1946, the majority of the Germans were expelled and in 1950 only 159,938 (from 3,149,820 in 1930) still lived in the Czech Republic. The remaining Germans, proven anti-fascists and skilled laborers, were allowed to stay in Czechoslovakia, but were later forcefully dispersed within the country.[15] Some German refugees from Czechoslovakia are represented by the Sudetendeutsche Landsmannschaft.\\r\\nMany of the Germans who stayed in Czechoslovakia later emigrated to West Germany (more than 100,000). As the German population was transferred out of the country, the former Sudetenland was resettled, mostly by Czechs but also by other nationalities of Czechoslovakia: Slovaks, Greeks (arriving in the wake of the Greek Civil War 1946ÿ49), Volhynian Czechs, Gypsies, Jews and Hungarians (though the Hungarians were forced into this and later returned homesee Hungarians in Slovakia: Population exchanges).\\r\\nSome areassuch as part of Czech Silesian-Moravian borderland, southwestern Bohemia (?umava National Park), western and northern parts of Bohemiaremained depopulated for several strategic reasons (extensive mining and military interests) or are now protected national parks and landscapes. Moreover, before the establishment of the Iron Curtain in 1952ÿ55, the so-called \\"forbidden zone\\" was established (by means of engineer equipment) up to 2?km (1.2?mi) from the border in which no civilians could reside. A wider region, or \\"border zone\\" existed, up to 12?km from the border, in which no \\"disloyal\\" or \\"suspect\\" civilians could reside or work. Thus, the entire A?-Bulge fell within the border zone; this status remained until the Velvet Revolution in 1989.\\r\\nThere remained areas with noticeable German minorities in the westernmost borderland around Cheb, where skilled ethnic German miners and workers continued in mining and industry until 1955, sanctioned under the Yalta Conference protocols[citation needed]; in the Egerland, German minority organizations continue to exist. Also, the small town of Krava?e (German: Deutsch Krawarn) in the multiethnic Hlu?n Region of Czech Silesia has an ethnic German majority (2006), including an ethnic German mayor.\\r\\nIn the 2001 census, approximately 40,000 people in the Czech Republic claimed German ethnicity.\\r\\na ?SR; boundaries and government established by the 1920 constitution.\\r\\nb Annexed by Nazi Germany.\\r\\nc ?SR; included the autonomous regions of Slovakia and Carpathian Ruthenia.\\r\\nd Annexed by Hungary (1939ÿ1945).\\r\\ne ?SR; declared a \\"people's democracy\\" (without formal name change) under the Ninth-of-May Constitution following the 1948 coup.\\r\\nf ?SSR; from 1969, after the Prague Spring, consisted of the Czech Socialist Republic (?SR) and Slovak Socialist Republic (SSR).\\r\\ng Oblast of the Ukrainian SSR.\\r\\nh Oblast of Ukraine.","input":"What was the part of czechoslovakia where most german speakers lived called?"},{"output":"Scottish","context":"","input":"What is the setting of the play macbeth?"},{"output":"Igbinedion University, Okada (IUO)","context":"Igbinedion University, Okada (IUO), the first private university in Nigeria, was established in 1999. The University is located at Okada, headquarters of Ovia North-East Local Government Area, Edo state. The university was founded by Sir Gabriel Osawaru Igbinedion CFR, a billionaire, philanthropist and a prominent Benin Chief.\\r\\nBoth the graduate and undergraduate programmes of the University are accredited by the National Universities Commission and the relevant professional bodies. The university has seven Colleges namely: College of Law, College of Health Sciences, College of Natural and Applied Sciences, College of Business and Management Studies, College of Pharmacy, College of Engineering and College of Arts and Social Sciences. It also has an enrolment of over 5000 students across the seven colleges. The University is headed by the Vice Chancellor, Rev. Professor Eghosa Osaghae.\\r\\nThe University has recorded several landmark achievements including being the first Private University to produce medical doctors in Sub-Saharan Africa[1] and producing the first private university graduate in 2006 to bag a first class at the highly competitive Nigeria Law School.\\r\\nIgbinedion University, Okada is devoted to developing and strengthening the academic programmes offered in the various colleges to meet international standards and preparing them for accreditation by the National Universities Commission (NUC), the federal agency that has responsibility for quality assurance and maintenance of standards, and the relevant national regulatory professional bodies. The latter bodies include the Medical and Dental Council of Nigeria, MDCN (Medicine), Council of Legal Education (Law), Council for the Regulation of Engineering in Nigeria, COREN (Engineering), Computer Professional Council of Nigeria (Computer Science), and Institute of Chartered Accountants of Nigeria, ICAN (Accounting). The accreditation of all the programmes including medicine, law, engineering and accounting by these bodies confirms the high quality of academic programme offered by the university. Also, more than 60% of its first degree graduands yearly proceed for postgraduate studies abroad with high success rate and commendation according to its Vice Chancellor during the institution's convocation ceremony in November, 2013.\\r\\nQuite early in its life, and in line with its vision of being an internationally competitive university, IUO identified external linkages and networking with (older and mentoring-capable) universities and development partners as strategic to the realization of its goals. By March 2007, the university had established linkages with the University of Westminster (UK) in the areas of staff development, diplomatic studies and ICT and Howard University, USA (telemedicine and teleconferencing), and was finalizing an exchange programme with East Carolina University (USA) in the area of global development. The university was admitted into full membership of the Global University Network for Innovation, GUNI, based in Barcelona, Spain, the European Association for International Education, EAIE, and the Network Towards Unity for Health (Maastricht, the Netherlands) amongst other external affiliations. It was also part of the Consortium of Development Partnerships, CDP, a conglomerate of universities, research institutions, governments and development partners in North America, Europe and West Africa. IUOs Centre for Presidential Studies coordinated and continues to coordinate Module 8 of the CDPs project on Local Contexts of Conflict and Peace-building in West Africa that involves researchers from Ghana, Mali, C?te d'Ivoire, Senegal, the Netherlands and Nigeria.\\r\\n\\r\\n\\r\\nThere are seven (7) Colleges, each of which has its own College Library.[2] The Colleges are as follows:\\r\\nThe University has produced over 10,000 graduates in various undergraduate and postgraduate courses since its inception in 1999 working at reputable firms within and outside Nigeria. It has also secured funding from various individuals and bodies like the Central Bank of Nigeria, which funded the construction of an ultra modern library for the school and Air Marshall Paul Dike, former Chief of Air Staff who donated a complex.","input":"What is the first private university in nigeria?"},{"output":"patent holding companies","context":"East Texas is a distinct cultural, geographic and ecological area in the U.S. state of Texas.\\r\\nAccording to the Handbook of Texas, the East Texas area \\"may be separated from the rest of Texas roughly by a line extending from the Red River in north central Lamar County southwestward to east central Limestone County and then southeastward towards eastern Galveston Bay\\", though most sources separate the Gulf Coast area into a separate region.[1]\\r\\nAnother popular, somewhat simpler, definition defines East Texas as the region between the Trinity River, north and east of Houston, (or sometimes Interstate 45, when defining generously) as the western border, the Louisiana border as the eastern border, the Oklahoma border as the northern border, and extending as far south as Lufkin, Texas. The East Texas Regions includes Tyler, Longview, Marshall, Palestine, Jacksonville, Mount Pleasant, and Nacogdoches.\\r\\nMost of the region consists of the Piney Woods ecoregion, and East Texas can sometimes be reduced to include only the Piney Woods. [2] At the fringes, towards Central Texas, the forests expand outward toward sparser trees and eventually into open plains.\\r\\n\\r\\n\\r\\nEast Texas comprises 41 counties, 38 of which collaborate in sub-regional Ark-Tex Council of Governments, the East Texas Council of Governments, the Deep East Texas Council of Governments and the South East Texas Regional Planning Commission.\\r\\nCounties included are Anderson, Angelina, Bowie, Camp, Cass, Cherokee, Delta, Franklin, Gregg, Hardin, Harrison, Henderson, Hopkins, Houston, Jasper, Jefferson, Lamar, Marion, Morris, Nacogdoches, Newton, Orange, Panola, Polk, Rains, Red River, Rusk, Sabine, San Augustine, San Jacinto, Shelby, Smith, Titus, Trinity, Tyler, Upshur, Van Zandt, and Wood County, Texas.[2]\\r\\nThe three additional East Texas counties that join with other regional government councils are Chambers County (Anahuac), Liberty County (Liberty) and Walker County (Huntsville), all three in geographic proximity to the Houston metropolitan areas.\\r\\nOutside of the Greater Houston area the average population density is around 18ÿ45 per square mile (7ÿ12 per km2), with the population density near the Big Thicket dropping below 18 people per sq mi. East Texas's population is very large and is centered around the Golden Triangle (Texas) which is Beaumont/Port Arthur/Orange in Southeast Texas. Moving north from the coast, Lufkin and Nacogdoches anchor the population center of Deep East Texas. Continuing north from Deep East Texas, Tyler, Longview and Marshall, in Northeast Texas, along with Texarkana, on the far northeastern border with Arkansas, represent the major population centers in the northern section of East Texas. Only eight miles from the Texas border, Shreveport, Louisiana, is considered the economic and cultural center for the Ark-La-Tex, the area where Arkansas, Louisiana, and East Texas meet.\\r\\nThe 2010 U.S. Census shows these 41 East Texas counties with a population of 2,057,518 residents, which represents 8% of the total state population of Texas.\\r\\nPer the 2010 US Census records, the five most populous counties are:\\r\\nPer the 2010 US census records, the ten most populous East Texas cities are:\\r\\nAccording to US Census records from 2010, the population of East Texas counties is 65.93% White Non-Hispanic, 17.44% African-American, 14.29% Hispanic or Latino Origin and 2.34% Other (including native and Asian). East Texas' most ethnically and racially diverse county is Jefferson County, East Texas' largest county which includes the city of Beaumont, with 44.1% White Non-Hispanic, 34.1% African-American, 17.7% Hispanic or Latino Origin and 4.1% Other (including native and Asian). Unlike Texas' total state racial demographics, only two counties in East Texas have a majority minority, Jefferson County in the Golden Triangle and Titus County having a 40.6% Hispanic or Latino origin population. East Texas and Southeast Texas has a significant African-American population, ranging to nearly 20% in some counties\\r\\nClimate is the unifying factor in the region's geographyall of East Texas has the humid subtropical climate typical of the Southeast, occasionally interrupted by intrusions of cold air from the north. East Texas receives more rainfall, 35 to 60 inches (890 to 1,520?mm), than the rest of Texas.[3] In Houston the average January temperature is 50.4?F (10.2?C) and the average July temperature is 82.6?F (28.1?C), however Houston has slightly warmer winters than most of East Texas due to its proximity to the coast.\\r\\nAll of East Texas also lies within the Gulf Coastal Plain, but with less uniformity than the climate with rolling hills in the north and flat coastal plains in the south. Local vegetation also varies from north to south with the lower third consisting of the temperate grassland extending from South Texas to South Louisiana. The upper two-thirds of the region dominated by temperate forest known as the Piney Woods, which extends over 23,500 square miles (61,000?km2). The Piney Woods are part of a much larger region of pine-hardwood forest that extends into Louisiana, Arkansas, and Oklahoma. The Piney Woods thins out as it nears the Gulf of Mexico. West of the Piney Woods are the ranchlands and remnant oak forests of the East Central Texas forests ecoregion.\\r\\nThe Sabine River, Trinity River, Neches River, Angelina River and Sulphur River are the major rivers in East Texas, but the Brazos River and Red River also flow through the region. The Brazos cuts through the southwest portion of the region while the Red River forms its northern border with Oklahoma and a portion of Arkansas. In East Texas and the rest of the South, small rivers and creeks collect into swamps called \\"Bayous\\" and merge with the surrounding forest. Bald cypress and Spanish moss are the dominant plants in bayous. The most famous of these bayous are Cypress Bayou and Buffalo Bayou. Cypress Bayou surrounds the Big, Little, and Black Cypress rivers around Jefferson. They flow east into Caddo Lake and the adjoining wetlands cover the rim and islands of the lake.\\r\\nEast Texas is often considered the westernmost extension of the Deep South. The predominant cultural influence comes from customs and traditions passed down from European-American and African-American Southerners who settled the region during the mid and late 19th century. African Americans were first brought to the area as enslaved workers for the plantations. These influences are noticeable in the sub-dialect of Texan English that is spoken throughout the region. According to the most recent linguistic studies, East Texans tend to pronounce Southern English with the drawl typical of the Lower South, whereas other parts of Texas are more prone to the \\"twang\\" of the Upper South, ordepending upon demographic influences of the particular areawith some Hispanic and Midwestern traits.\\r\\nEast Texas did not have the influence of late 19th and early 20th century European immigrants from Germany and Central Europe. Similarly, the new waves of immigrants since the late 20th century, primarily from India, other Asian nations, and Latin America, and their influences, have been less prevalent in East Texas.\\r\\nEast Texans are predominantly Protestant Christians, expressing their faith as members of many denominations: Baptist (particularly Southern Baptist), Methodist, Presbyterian, Lutheran, Pentecostal, and others. Catholicism continues to have influence, particularly with an increased Hispanic population in recent decades. Other religions with smaller numbers, but with adherents in East Texas, include Mormonism and Judaism.\\r\\nSignificant numbers of people of Cajun and Creole descent have come from Louisiana, although most are assimilated partially or completely into East Texas culture (adopting the local culture and losing, to varying degrees, their original culture). This assimilation pattern has often historically included conversion from Catholicism to Protestant faiths. United States settlers from the Protestant Southeast practiced some discrimination against Cajun and Creole migrants, a cultural attitude that persisted until quite recently. Despite the tendency towards assimilation, Cajun and Creole cuisine (for example, jambalaya and catfish gumbo), are popular in the region. Many East Texans, including those without Louisiana roots, are known to be expert at preparing at least some well-known Louisiana dishes.\\r\\nWhile some East Texans associate with cowboy culture, most identify more with plantation traditions of the South than with the expansive cattle ranching of the plains regions of Texas. However, it is common for East Texans to own and trade cattle. There are several \\"sale barns\\" across East Texas with weekly and monthly trades, as is common in other parts of the lower South.\\r\\nIn the northern part of East Texas, awareness of the native and historical Caddo Mississippian culture remains significant. Cherokee County is home to the Caddo Mounds State Historic Site. Patrons can also view the \\"Caddo Indian Collection\\" at the Gregg County Historical Museum in Longview.\\r\\nMany East Texans have a mixture of European and Native American ancestry, notably country and folk singer Miranda Lambert.\\r\\nThe Museum of East Texas opened in Lufkin in 1976 under the name Lufkin Historical and Creative Arts Center.[4]\\r\\nEast Texas is home to the Texas Country Music Hall of Fame, located in Carthage. East Texans enjoy a range of music that is influenced by gospel, bluegrass, blues, rock, country, soul, rhthym and blues, Cajun, etc. Texas blues originated in East Texas, with many legends having been born in the region including Lightnin' Hopkins and T-Bone Walker. East Texans enjoy live music at many of the region's fairs and festivals, including the Texas Rose Festival in Tyler, the East Texas Yamboree in Gilmer, and Longview's Great Texas Balloon Race. East Texas also has many venues included in what is commonly referred to as the Texas country music circuit, although the majority of such venues are located in Central/South/West Texas and the metropolitan areas of the state.\\r\\nMany notable music artists have East Texas roots including: George Jones (Saratoga), Miranda Lambert (Lindale), Kacey Musgraves (Mineola), Neal McCoy (Longview and Jacksonville), Lee Ann Womack (Jacksonville), Janis Joplin (Port Arthur), Don Henley (Linden), Ray Price (Perryville), Johnny Horton (Rusk), Johnny Mathis (Gilmer), Tex Ritter (Panola County), Jim Reeves (Panola County), Mark Chesnutt (Beaumont), Tracy Byrd (Vidor), Clay Walker (Beaumont), Chris Tomlin (Grand Saline), Michelle Shocked (Gilmer) among many others.\\r\\nWorldwide-acclaimed pianist Van Cliburn, a native of nearby Shreveport, Louisiana, was raised in Kilgore. Kilgore College houses the Van Cliburn Auditorium on its home campus.\\r\\nMany high school bands in East Texas continue the tradition of military-style marching, unlike other parts of the state. These bands compete in the National Association of Military Marching Bands (NAMMB).\\r\\nAs with other parts of Texas, high school football is king in East Texas. Residents of East Texas towns and rural communities fill high school stadiums in support of their local team, cheerleaders, bands, etc. Many East Texas high school teams have won Texas state championships and have produced collegiate and professional football players.\\r\\nEarl Campbell, the \\"Tyler Rose\\", played football for John Tyler High in Tyler before playing for the Texas Longhorns and the Houston Oilers. Don Meredith, who famously played for the Dallas Cowboys, played at Mt. Vernon. Dez Bryant, a football product from Lufkin, is a current wide receiver for the Dallas Cowboys. Adrian Peterson, a star running back for the Minnesota Vikings, played high school football in Palestine. Other high school sports are popular in East Texas including basketball, baseball, volleyball, softball and track.\\r\\nA significant number of East Texas youth participate in Little League Baseball, soccer and softball. Church leagues are quite common in providing opportunities for basketball and softball for youth and adults alike. In recent years, cowboy churches have grown in number and offer rodeo events for their youth.\\r\\nEast Texans also enjoy collegiate athletic competition. Most residents support collegiate teams located in other regions of the state; the Texas Longhorns, Texas A&M Aggies, Texas Tech Red Raiders, Baylor Bears, TCU Horned Frogs, etc. Due to proximity to neighboring states, East Texas has a substantial number of fans of the LSU Tigers, Arkansas Razorbacks, Oklahoma State Cowboys and Oklahoma Sooners. The Battle of the Piney Woods is a fiercely contested sports rivalry between the Bearkats of Sam Houston State University \\"SHSU\\" in Huntsville and the Lumberjacks of Stephen F. Austin State University \\"SFA\\" in Nacogdoches. Both of these universities compete in the FCS level of NCAA athletic competition as members of the Southland Conference. The Cardinals of Lamar University in Beaumont also compete with SFA and Sam Houston State in the Southland Conference.\\r\\nOther universities and colleges that field athletic teams in East Texas include, East Texas Baptist University \\"ETBU\\" Tigers in Marshall; University of Texas at Tyler Patriots in Tyler; LeTourneau University Yellowjackets in Longview; Texas A&M University-Commerce Lions; and several junior colleges throughout the region which participate in the Southwest Junior College Conference in Region XIV of the NJCAA. East Texas is also home to the Kilgore College Rangerettes, a world-famous dance team which debuted in 1939.\\r\\nA few professional sports teams are located in East Texas. The East Texas Pump Jacks, located in Kilgore, play baseball in the Texas Collegiate League. Additionally, the East Texas Storm, a semi-professional football team located in Tyler, competes in the Lone Star Minor League.[5] Typically, northern parts of East Texas tend to support the professional teams from the Dallas/Fort Worth area (Dallas Cowboys, Dallas Mavericks, Texas Rangers, Dallas Stars), while southern parts of East Texas tend to support professional teams from the Houston area (Houston Texans, Houston Rockets, Houston Astros).\\r\\nAs with other parts of Texas and/or the South, other popular sporting activities in East Texas include rodeo (including PRCA), hunting and fishing. Prominent rodeos in East Texas are held in Beaumont, Nacogdoches, Paris, Longview, Gladewater, Huntsville, Lufkin, Athens, Palestine, Lindale, etc. East Texas contains several award-winning lakes for sport fishing including Toledo Bend Reservoir, Lake Sam Rayburn, Lake Livingston, Lake Fork, Lake Tawakoni, etc. East Texans have a long tradition in outdoors sporting and observe the opening day of deer season as a near religious holiday.\\r\\nEast Texas also contains numerous golf courses and avid golfers, as well as NASCAR fans. However, the region does not host professional events in either of those sports. The nearest NASCAR track to East Texas is Texas Motor Speedway in Fort Worth.\\r\\nEast Texans enjoy many Texas State Parks including: Caddo Lake, Atlanta, Daingerfield, Lake Bob Sandlin, Tyler, Mission Tejas in Grapeland, Cooper Lake, Lake Tawakoni, Martin Creek, Huntsville, Lake Sam Rayburn, Lake Livingston and Sea Rim among others. East Texas is also home to the Angelina National Forest, Sam Houston National Forest, Sabine National Forest, Big Thicket National Preserve, Trinity River National Wildlife Refuge, Anahuac National Wildlife Refuge and Mcfaddin National Wildlife Refuge.\\r\\nDeep East Texas is a sub-region of East Texas. According to the Deep East Texas Council of Governments the region consists of the following twelve counties: Angelina, Houston, Jasper, Nacogdoches, Newton, Polk, Sabine, San Augustine, San Jacinto, Shelby, Trinity, and Tyler.\\r\\nThe \\"Deep\\" designation comes from the similarity to East Texas (it is similar in culture and topography, being highly forested), but with a location \\"deeper\\" (i.e., farther south and towards the Gulf Coast) than the rest of East Texas.\\r\\n\\"Deep\\" also refers to the cultural and social characteristics of the area and is considered synonymous to \\"The Big Thicket\\", an allusion to the dense growth of underbrush in the \\"piney woods.\\" It was the earliest area of Texas to be settled by Anglo-Americans (and one of the last areas to submit to law enforcementby the governments of New Spain, Mexico, the Republic of Texas, state of Texas, or the United States). Renegade clans controlled local governments, especially in Shelby County, well into the first quarter of the 20th century.[citation needed]\\r\\nThe area contains two of the oldest towns in Texas; Nacogdoches, the oldest town in Texas, dating from 18th century, and San Augustine, the oldest \\"Anglo\\" settlement in Texas, dating from the 1820s. People of English, Scottish, Scots-Irish, and to a lesser extent Welsh ancestry predominate in the region, which is in contrast to South Central Texas and West Texas in which people of German and Hispanic heritage predominate, respectively. Prior to the Texas War of Independence, settlement was generally prohibited by the Spanish and later Mexican governments, but neither government was able to exert control or law enforcement in the area. As a consequence, the \\"Big Thicket\\" became a refuge for criminals fleeing the United States and hiding out in a \\"no man's land\\" in the pine tree thickets.\\r\\nThe early isolation of the region and its links to the Deep South have resulted in its well-known pine woods being described as a 'curtain' which demarcates a certain cultural enclave or bubble that distinguishes East Texas from the rest of the state. Former residents describe leaving behind the 'Pine Curtain' as a form of escape.\\r\\nThe phrase is often used to describe the area, appearing in a newspaper column in the Palestine Herald-Press, and in tourist guide by Mike Dougan.[6] [7]\\r\\nHistorically, the East Texas economy has been led by lumber, cotton, cattle and oil. Prior to the discovery of the East Texas Oil Field, cotton, lumber and cattle were the predominant source of economic gains and stability. Needs of local farmers contributed greatly to the establishment of local towns and trading posts. As with many parts of the nation, the chosen paths of railroads often determined the continuation of many towns. At the beginning of the 20th century, the oil fields were discovered and oil became accessible, which changed the future trajectory of the region.\\r\\nIn the decades leading to the new millennium, crude oil production in the East Texas Oil Field, the largest oil field in the United States, somewhat decreased. In turn, the number of high-paying jobs for uneducated workers also decreased. During the 20th century, local groceries, general stores and cafes were replaced with franchise department stores, retail chains and fast food restaurants. Due to the decline of oil production, many small towns closed cafs and gas stations, some of which were replaced with cash loan shops and pawn shops.[8]\\r\\nPaul Knight of the Houston Press in a 2009 article that \\"some say [natural gas] has surpassed crude as king in East Texas.\\"[9]\\r\\nTourism has not been a highly significant source of economic activity in East Texas, although several high-traffic corridors pass through East Texas which have aided economic development along those routes. These include: Interstate 30 (from Dallas through Texarkana), Interstate 20 (through Dallas and on through Shreveport), Interstate 10 (through Houston and Beaumont into Louisiana), Interstate 45 (through Houston up to Dallas) and U.S. Highway 59 (through Houston and up past Texarkana; in process of being upgraded along most of the route to Interstate 69).\\r\\nIn recent years, the region has become home to many patent holding companies, due to its legal system being particularly friendly to patent holders and hostile to out of state tech defendants.[10]\\r\\nThe region also contains Sam Houston State University in Huntsville and Stephen F. Austin State University in Nacogdoches, which helps contribute millions of dollars into the Deep East Texas economy. Texas A&M University-Texarkana, University of Texas at Tyler, LeTourneau University and East Texas Baptist University are a few of the smaller universities in East Texas. Texas A&M University-Commerce is right outside east Texas and is formerly known as East Texas State University, while A&M-Texarkana was a branch campus of ETSU.","input":"What type of business is common in east texas?"},{"output":"August 29, 1949","context":"The nuclear arms race was a competition for supremacy in nuclear warfare between the United States, the Soviet Union, and their respective allies during the Cold War. During this period, in addition to the American and Soviet nuclear stockpiles, other countries developed nuclear weapons, though none engaged in warhead production on nearly the same scale as the two superpowers.\\r\\n\\r\\n\\r\\nThe first nuclear weapon was created by the U.S. during the Second World War and was developed to be used against the Axis powers.[1] Scientists of the Soviet Union were aware of the potential of nuclear weapons and had also been conducting research on the field.[2]\\r\\nThe Soviet Union was not informed officially of the Manhattan Project until Stalin was briefed at the Potsdam Conference on July 24, 1945, by U.S. President Harry S. Truman,[3][4] eight days after the first successful test of a nuclear weapon. Despite their wartime military alliance, the United States and Britain had not trusted the Soviets enough to keep knowledge of the Manhattan Project safe from German spies: there were also concerns that, as an ally, the Soviet Union would request and expect to receive technical details of the new weapon.[citation needed]\\r\\nWhen President Truman informed Stalin of the weapons, he was surprised at how calmly Stalin reacted to the news and thought that Stalin had not understood what he had been told. Other members of the United States and British delegations who closely observed the exchange formed the same conclusion.[5]\\r\\nIn fact Stalin had long been aware of the program,[6] despite the Manhattan Project having a secret classification so high that, even as Vice President, Truman did not know about it or the development of the weapons (Truman was not informed until shortly after he became president).[6] A ring of spies operating within the Manhattan Project, (including Klaus Fuchs[7] and Theodore Hall) had kept Stalin well informed of American progress.[8] They provided the Soviets with detailed designs of the implosion bomb and the hydrogen bomb.[citation needed] Fuchs' arrest in 1950 led to the arrests of many other Russian spies, including Harry Gold, David Greenglass, and Ethel and Julius Rosenberg.[9]\\r\\nIn August 1945, on Truman's orders, two atomic bombs were dropped on Japanese cities. The first bomb was dropped on Hiroshima, and the second bomb was dropped on Nagasaki by the B-29 bombers named Enola Gay and Bockscar respectively.\\r\\nShortly after the end of the Second World War in 1945, the United Nations was founded. During the United Nation's first General Assembly in London in January 1946, they discussed the future of Nuclear Weapons and created the United Nations Atomic Energy Commission. The goal of this assembly was to eliminate the use of all Nuclear weapons. The United States presented their solution, which was called the Baruch Plan.[10] This plan proposed that there should be an international authority that controls all dangerous atomic activities. The Soviet Union disagreed with this proposal and rejected it. The Soviets' proposal involved universal nuclear disarmament. Both the American and Soviet proposals were refused by the UN.\\r\\nIn the years immediately after the Second World War, the United States had a monopoly on specific knowledge of and raw materials for nuclear weaponry. American leaders hoped that their exclusive ownership of nuclear weapons would be enough to draw concessions from the Soviet Union but this proved ineffective.\\r\\nJust six months after the UN General Assembly, the United States conducted its first post-war nuclear tests. This was called Operation Crossroads.[11] The purpose of this operation was to test the effectiveness of nuclear explosions on ships. These tests were performed at Bikini Atoll in the Pacific on 95 ships, including German and Japanese ships that were captured during World War II. One plutonium implosion-type bomb was detonated over the fleet, while the other one was detonated underwater.\\r\\nBehind the scenes, the Soviet government was working on building its own atomic weapons. During the war, Soviet efforts had been limited by a lack of uranium but new supplies in Eastern Europe were found and provided a steady supply while the Soviets developed a domestic source. While American experts had predicted that the Soviet Union would not have nuclear weapons until the mid-1950s, the first Soviet bomb was detonated on August 29, 1949, shocking the entire world. The bomb, named \\"First Lightning\\" by the West, was more or less a copy of \\"Fat Man\\", one of the bombs the United States had dropped on Japan in 1945.\\r\\nBoth governments spent massive amounts to increase the quality and quantity of their nuclear arsenals. Both nations quickly began the development of a hydrogen bomb and the United States detonated the first hydrogen bomb on November 1, 1952, on Enewetak, an atoll in the Pacific Ocean.[12] Code-named \\"Ivy Mike\\", the project was led by Edward Teller, a Hungarian-American nuclear physicist. It created a cloud 100 miles wide and 25 miles high, killing all life on the surrounding islands.[13] Again, the Soviets surprised the world by exploding a deployable thermonuclear device in August 1953 although it was not a true multi-stage hydrogen bomb. However, it was small enough to be dropped from an airplane, making it ready for use. The development of these two Soviet bombs was greatly aided by the Russian spies Harry Gold and Klaus Fuchs.\\r\\nOn March 1, 1954, the U.S. conducted the Castle Bravo test, which tested another hydrogen bomb on Bikini Atoll.[14] Scientists significantly underestimated the size of the bomb, thinking it would yield 5 megatons. However, it yielded 14.8 megatons, which is the largest nuclear explosion tested by the U.S. The explosion was so large the nuclear fallout exposed residents up to 300 miles away to significant amounts of radiation. They were eventually evacuated, but most of them experienced radiation poisoning and resulted in one death from a crew member of a fishing boat 90 miles from the explosion.\\r\\nThe Soviet Union detonated its first \\"true\\" hydrogen bomb on November 22, 1955, which had a yield of 1.6 megatons. On October 30, 1961, the Soviets detonated a hydrogen bomb with a yield of approximately 58 megatons.[15]\\r\\nWith both sides in the \\"cold war\\" having nuclear capability, an arms race developed, with the Soviet union attempting first to catch up and then to surpass the Americans.[16]\\r\\nStrategic bombers were the primary delivery method at the beginning of the Cold War.\\r\\nMissiles had long been regarded the ideal platform for nuclear weapons, and were potentially a more effective delivery system than bombers. Starting in the 1950s, medium-range ballistic missiles and intermediate-range ballistic missiles (\\"IRBM\\"s) were developed for delivery of tactical nuclear weapons, and the technology developed to the progressively longer ranges, eventually becoming intercontinental ballistic missiles (ICBMs). On October 4, 1957, the Soviet Union showed the world that they had missiles able to reach any part of the world when they launched the Sputnik satellite into Earth orbit. The United States launched its first satellite Explorer 1 on January 31, 1958.\\r\\nMeanwhile, submarine-launched ballistic missiles were also developed. By the 1960s, the \\"triad\\" of nuclear weapon delivery was established, with each side deploying bombers, ICBMs, and SLBMs, in order to insure that even if a defense was found against one delivery method, the other methods would still be available.\\r\\nSome in the United States during the early 1960s pointed out that although all of the individual components of nuclear missiles had been tested separately (warheads, navigation systems, rockets), it was infeasible to test them all combined. Critics charged that it was not really known how a warhead would react to the gravity forces and temperature differences encountered in the upper atmosphere and outer space, and Kennedy was unwilling to run a test of an ICBM with a live warhead. The closest thing to an actual test was 1962's Operation Frigate Bird, in which the submarine USS?Ethan Allen?(SSBN-608) launched a Polaris A2 missile over 1,000 miles to the nuclear test site at Christmas Island. It was challenged by, among others, Curtis LeMay, who put missile accuracy into doubt to encourage the development of new bombers. Other critics pointed out that it was a single test which could be an anomaly; that it was a lower-altitude SLBM and therefore was subject to different conditions than an ICBM; and that significant modifications had been made to its warhead before testing.\\r\\nBy the 1950s both the United States and Soviet Union had enough nuclear power to obliterate[clarification needed] the other side. Both sides developed a capability to launch a devastating attack even after sustaining a full assault from the other side (especially by means of submarines), called a second strike.[19] This policy became known as Mutual Assured Destruction: both sides knew that any attack upon the other would be devastating to themselves, thus in theory restraining them from attacking the other.\\r\\nBoth Soviet and American experts hoped to use nuclear weapons for extracting concessions from the other, or from other powers such as China, but the risk connected with using these weapons was so grave that they refrained from what John Foster Dulles referred to as brinkmanship. While some, like General Douglas MacArthur, argued nuclear weapons should be used during the Korean War, both Truman and Eisenhower opposed the idea.[citation needed]\\r\\nBoth sides were unaware of the details of the capacity of the enemy's arsenal of nuclear weapons. The Americans suffered from a lack of confidence, and in the 1950s they believed in a non-existing bomber gap. Aerial photography later revealed that the Soviets had been playing a sort of Potemkin village game with their bombers in their military parades, flying them in large circles, making it appear they had far more than they truly did. The 1960 American presidential election saw accusations of a wholly spurious missile gap between the Soviets and the Americans. On the other side, the Soviet government exaggerated the power of Soviet weapons to the leadership and Nikita Khrushchev.[citation needed]\\r\\nIn addition to the United States and the Soviet Union, three other nations, the United Kingdom,[20] People's Republic of China,[21] and France[22] developed nuclear weapons during the early cold war years.\\r\\nIn 1952, the United Kingdom became the third nation to possess nuclear weapons when it detonated an atomic bomb in Operation Hurricane[23] on October 3, 1952, which had a yield of 25 kilotons. Despite major contributions to the Manhattan Project by both Canadian and British governments, the U.S. Congress passed the Atomic Energy Act of 1946, which prohibited multi-national cooperation on nuclear projects. The McMahon Act fueled resentment from British scientists and Winston Churchill, as they believed that there were agreements regarding post-war sharing of nuclear technology, and led to Britain developing its own nuclear weapons. Britain did not begin planning the development of their own nuclear weapon until January 1947. Because of Britains small size, they decided to test their bomb on the Monte Bello Islands, off the coast of Australia. Following this successful test, under the leadership of Churchill, Britain decided to develop and test a hydrogen bomb. The first successful hydrogen bomb test occurred on November 8, 1957, which had a yield of 1.8 megatons.[24] An amendment to the Atomic Energy Act in 1958 allowed nuclear cooperation once again, and British-U.S. nuclear programs resumed. During the Cold War, British nuclear deterrence came from submarines and nuclear-armed aircraft. The Resolution class ballistic missile submarines armed with the American-built Polaris missile provided the sea deterrent, while aircraft such as the Avro Vulcan, SEPECAT Jaguar, Panavia Tornado and several other Royal Air Force strike aircraft carrying WE.177 gravity bomb provided the air deterrent.\\r\\nFrance became the fourth nation to possess nuclear weapons on February 13, 1960, when the atomic bomb \\"Gerboise Bleue\\" was detonated in Algeria,[25] then still a French colony [Formally a part of the Metropolitan France.] France began making plans for a nuclear-weapons program shortly after the Second World War, but the program did not actually begin until the late 1950s. Eight years later, France conducted its first thermonuclear test above Fangatuafa Atoll. It had a yield of 2.6 megatons.[26] This bomb significantly contaminated the atoll with radiation for six years, making it off-limits to humans. During the Cold War, the French nuclear deterrent was centered around the Force de frappe, a nuclear triad consisting of Dassault Mirage IV bombers carrying such nuclear weapons as the AN-22 gravity bomb and the ASMP stand-off attack missile, Pluton and Hades ballistic missiles, and the Redoutable class submarine armed with strategic nuclear missiles.\\r\\nThe People's Republic of China became the fifth nuclear power on October 16, 1964 when it detonated a 25 kiloton uranium-235 bomb in a test codenamed 596[27] at Lop Nur. In the late 1950s, China began developing nuclear weapons with substantial Soviet assistance in exchange for uranium ore. However, the Sino-Soviet ideological split in the late 1950s developed problems between China and the Soviet Union. This caused the Soviets to cease helping China develop nuclear weapons. However, China continued developing nuclear weapons without Soviet support and made remarkable progress in the 1960s.[28] Due to Soviet/Chinese tensions, the Chinese might have used nuclear weapons against either the United States or the Soviet Union in the event of a nuclear war between the United States and the Soviet Union.[citation needed] During the Cold War, the Chinese nuclear deterrent consisted of gravity bombs carried aboard H-6 bomber aircraft, missile systems such as the DF-2, DF-3, and DF-4,[29] and in the later stages of the Cold War, the Type 092 ballistic missile submarine. On June 14, 1967, China detonated its first hydrogen bomb.\\r\\nOn January 1, 1959, the Cuban government fell to communist revolutionaries, propelling Fidel Castro into power. The Soviet Union supported and praised Castro and his resistance, and the new government was recognized by the Soviet government on January 10. When the United States began boycotting Cuban sugar, the Soviet Union began purchasing large quantities to support the Cuban economy in return for fuel and eventually placing nuclear ballistic missiles on Cuban soil. These missiles would be capable of reaching the United States very quickly. On October 14, 1962, an American spy plane discovered these nuclear missile sites under construction in Cuba.[30]\\r\\nPresident Kennedy immediately called a series of meetings for a small group of senior officials to debate the crisis. The group was split between a militaristic solution and a diplomatic one. President Kennedy ordered a naval blockage around Cuba and all military forces to DEFCON 3. As tensions increased, Kennedy eventually ordered U.S. military forces to DEFCON 2. This was the closest the world has been to a nuclear war. While the U.S. military had been ordered to DEFCON 2, reaching a nuclear war was still a ways off. The theory of mutually assured destruction seems to put the entry into nuclear war an unlikely possibility. While the public perceived the Cuban Missile Crisis as a time of near mass destruction, the leaders of the United States and the Soviet Union were working behind the sight of the public eye in order to come to a peaceful conclusion. Premier Khrushchev writes to President Kennedy in a telegram on October 26, 1962 saying that, \\"Consequently, if there is no intention to tighten that knot and thereby to doom the world to the catastrophe of thermonuclear war, then let us not only relax the forces pulling on the ends of the rope, let us take measures to untie that knot.\\"[31] It is apparently clear that both men wanted to avoid nuclear war due to mutually assured destruction which leads to the question of just how close the world was from experiencing a nuclear war.\\r\\nEventually, on October 28, through much discussion between U.S and Soviet officials, Khrushchev announced that the Soviet Union would withdraw all missiles from Cuba. Shortly after, the U.S. withdrew all their nuclear missiles from Turkey in secret, which had threatened the Soviets. The U.S.'s withdrawal of their Jupiter Missiles from Turkey was kept private for decades after, causing the negotiations between the two nations to appear to the world as a major U.S. victory. This ultimately led to the downfall of Premier Khrushchev.\\r\\nBy the 1970s, with the cold war entering its 30th year with no direct conflict between the superpowers, the United States and the Soviet Union entered a period of reduced conflict, in which the two powers engaged in trade and exchanges with each other. This period known as dtente. This period included negotiation of a number of arms control agreements, building with the Nuclear Test Ban Treaty in the 1950s, but with significant new treaties negotiated in the 1970s. These treaties were only partially successful. Although both states continued to hold massive numbers of nuclear weapons and research more effective technology, the growth in number of warheads was first limited, and later, with the START I, reversed.\\r\\nIn 1958, both the U.S. and Soviet Union agreed to informally suspend nuclear testing. However, this agreement was ended when the Soviets resumed testing in 1961, followed by a series of nuclear tests conducted by the U.S. These events led to much political fallout, as well as the Cuban Missile Crisis in 1962. Something had to be done to ease the great tensions between these two countries, so on October 10, 1963, the Limited Test Ban Treaty (LTBT) was signed.[32] This was an agreement between the U.S., the Soviet Union, and the U.K., which significantly restricted nuclear testing. All atmospheric, underwater, and outer space nuclear testing were agreed to be halted, but testing was still allowed underground. An additional 113 countries have signed this treaty since 1963.\\r\\nSALT I and SALT II limited the size of the states' arsenals. Bans on nuclear testing, anti-ballistic missile systems, and weapons in space all attempted to limit the expansion of the arms race through the Partial Test Ban Treaty.\\r\\nIn November, 1969, Strategic Arms Limitation Talks (SALT) begun. This was primarily due to the economic impact that nuclear testing and production had on both U.S. and Soviet economies. The SALT I Treaty, which was signed in May, 1972, produced an agreement on two significant documents. These were the Anti-Ballistic Missile Treaty (ABM Treaty) and the Interim Agreement on the Limitation of Strategic Offensive Arms.[33] The ABM treaty limited each country to two ABM sites, while the Interim Agreement froze each country's number of intercontinental ballistic missiles (ICBMs) and submarine-launched ballistic missiles (SLBMs) at current levels for five years. This treaty significantly reduced nuclear-related costs as well as the risk of nuclear war. However, SALT I failed to address how many nuclear warheads could be placed on one missile. A new technology, known as multiple-independently targetable re-entry vehicle (MIRV), allowed single missiles to hold and launch multiple nuclear missiles at targets while in mid-air. Over the next 10 years, the Soviet Union and U.S added 12,000 nuclear warheads to their already built arsenals.\\r\\nThroughout the 1970s, both the Soviet Union and United States replaced old missiles and warheads with newer, more powerful and effective ones. This continued to worsen Soviet-U.S relations. On June 18, 1979, the SALT II treaty was signed in Vienna. This treaty limited both sides' nuclear arsenals and technology. However, this treaty as well as the era of the dtente ended with the Soviet Union's invasion of Afghanistan in January, 1980.[34] The United States once again significantly increased military and nuclear spending, while the Soviets were unable to respond and continued to pursue the dtente.\\r\\nIn 1991, the START (Strategic Arms Reduction Treaty) was negotiated between the U. S. and the Soviet Union, to reduce the number and limit the capabilities of limitation of strategic offensive arms. This was eventually succeeded by the START II, START III, and New START treaties.\\r\\nDespite dtente, both sides continued to develop and introduce more accurate weapons and weapons with more warheads (\\"MIRVs\\"). The presidency of Ronald Reagan proposed a missile defense programmed tagged the Strategic Defense Initiative, a space based anti-ballistic missile system derided as \\"Star Wars\\" by its critics; simultaneously, missile defense was also being researched in the Soviet Union. However, the SDI would require technology that had not yet been developed, or even researched. This system proposed both space- and earth-based laser battle stations. It would also need sensors on the ground, in the air, and in space with radar, optical, and infrared technology to detect incoming missiles.[35] Simultaneously, however, Reagan initiated negotiations with Mikhail Gorbachev ultimately resulting in the Strategic Arms Reduction Treaty on reducing nuclear stockpiles.\\r\\nDue to high costs and complex technology for its time, the scope of the SDI project was reduced from defense against a massive attack to a system for defending against limited attacks, transitioning into the Ballistic Missile Defense Organization.\\r\\nDuring the mid-1980s, the U.S-Soviet relations significantly improved, Mikhail Gorbachev assumed control of the Soviet Union after the deaths of several former Soviet leaders, and announced a new era of perestroika and glasnost, meaning restructuring and openness respectively. Gorbachev proposed a 50% reduction of nuclear weapons for both the U.S and Soviet Union at the meeting in Reykjavik, Iceland in October 1986. However, the proposal was refused due to disagreements over Reagan's SDI. Instead, the Intermediate Nuclear Forces (INF) Treaty was signed on December 8, 1987 in Washington, which eliminated an entire class of nuclear weapons.[36]\\r\\nDue to the dramatic economic and social changes occurring within the Soviet Union, many of its constituent republics began to declare their independence. With the wave of revolutions sweeping across Eastern-Europe, the Soviet Union was unable to impose its will on its satellite states and so its sphere of influence slowly diminished. By December 16, 1991, all of the republics had declared independence from the Union. The Soviet leader, Mikhail Gorbachev resigned as the country's President on December 25 and the Soviet Union was declared non-existent the following day.\\r\\nWith the end of the Cold War, the United States and Russia cut down on nuclear weapons spending.[citation needed] Fewer new systems were developed and both arsenals were reduced; although both countries maintain significant stocks of nuclear missiles. In the United States, stockpile stewardship programs have taken over the role of maintaining the aging arsenal.[37]\\r\\nAfter the Cold War ended, large inventories of nuclear weapons and facilities remained. Some are being recycled, dismantled, or recovered as valuable substances.[citation needed] As a result, a large amount of resources and money which was once spent on developing nuclear weapons in Soviet Union was then spent on repairing the environmental damage produced by the nuclear arms race, and almost all former production sites are now major cleanup sites.[citation needed] In the United States, the plutonium production facility at Hanford, Washington and the plutonium pit fabrication facility at Rocky Flats, Colorado are among the most polluted sites.[citation needed]\\r\\nMilitary policies and strategies have been modified to reflect the increasing intervals without major confrontation. In 1995, United States policy and strategy regarding nuclear proliferation was outlined in the document \\"Essentials of PostÿCold War Deterrence\\", produced by the Policy Subcommittee of the Strategic Advisory Group (SAG) of the United States Strategic Command.\\r\\nOn April 8, 2010, former U.S. President Barack Obama and Russian President Dmitry Medvedev signed the New START Treaty, which called for a fifty percent reduction of strategic nuclear missile launchers and a curtailment of deployed nuclear warheads.[38] The U.S. Senate ratified the treaty in December 2010 by a three-quarter majority.\\r\\nOn December 22, 2016, U.S. President Donald Trump proclaimed in a tweet that \\"the United States must greatly strengthen and expand its nuclear capability until such time as the world comes to its senses regarding nukes,\\"[39] effectively challenging the world to re-engage in a race for nuclear dominance. The next day, Trump reiterated his position to \\"Morning Joe\\" host Mika Brzezinski of MSNBC, stating: \\"Let it be an arms race. We will outmatch them at every pass and outlast them all.\\"[40]\\r\\nIn South Asia, India and Pakistan have also engaged in a technological nuclear arms race since the 1970s. The nuclear competition started in 1974 with India detonating the device, codename Smiling Buddha, at the Pokhran region of the Rajasthan state.[41] The Indian government termed this test as a \\"peaceful nuclear explosion\\", but according to independent sources, it was actually part of an accelerated covert nuclear program of India.[42]\\r\\nThis test generated great concern and doubts in Pakistan, with fear it would be at the mercy of its longÿtime arch rival. Pakistan had its own covert atomic bomb projects in 1972 which extended over many years since the first Indian weapon was detonated. After the 1974 test, Pakistan's atomic bomb program picked up a great speed and accelerated its atomic project to successfully build its own atomic weapons program. In the last few decades of the 20th century, India and Pakistan began to develop nuclear-capable rockets and nuclear military technologies. Finally, in 1998 India, under Atal Bihari Vajpayee government, test detonated 5 more nuclear weapons. While the international response to the detonation was muted,[citation needed] domestic pressure within Pakistan began to build steam and Prime Minister Nawaz Sharif ordered the test, detonated 6 nuclear war weapons (Chagai-I and Chagai-II) in a tit-for-tat fashion and to act as a deterrent.\\r\\nFrom the beginning of the Cold War, The United States, Russia, and other nations have all attempted to develop Anti-ballistic missiles. The United States developed the LIM-49 Nike Zeus in the 1950s in order to destroy incoming ICBMs.\\r\\nRussia has, too, developed ABM missiles in the form of the A-35 anti-ballistic missile system and the later A-135 anti-ballistic missile system. Chinese state media has also announced to have tested anti-ballistic missiles,[43] though specific information is not public.\\r\\nIndia has successfully developed its Ballistic Missile Shield in the programme Indian Ballistic Missile Defence Programme with the test fire of Prithvi Air Defense (PAD) and it has also developed a cruise missile defense Akash Air Defense (AAD)[44] to intercept low flying missiles making India one of the five countries with Missile Shield. [45]","input":"When did the ussr became a nuclear power?"},{"output":"The Congo River (also spelled Kongo River and known as the Zaire River; French: (le) fleuve Congo/Za?re; Portuguese: rio Congo/Zaire; Kongo: Nzadi K?ngo)","context":"The Congo River (also spelled Kongo River and known as the Zaire River; French: (le) fleuve Congo/Za?re; Portuguese: rio Congo/Zaire; Kongo: Nzadi K?ngo) is the second longest river in Africa after the Nile and the second largest river in the world by discharge volume of water (after the Amazon), and the world's deepest river with measured depths in excess of 220?m (720?ft).[2] The Congo-Chambeshi River has an overall length of 4,700?km (2,920?mi), which makes it the world's ninth-longest river. The Chambeshi is a tributary of the Lualaba River, and Lualaba is the name of the Congo River upstream of Boyoma Falls, extending for 1,800?km.\\r\\nMeasured along with the Lualaba, the Congo River has a total length of 4,370?km (2,715?mi). It is the only river to cross the equator twice.[3] The Congo Basin has a total area of about four million km2, or 13% of the entire African landmass.\\r\\n\\r\\n\\r\\nThe name Congo/Kongo river originates from the Kingdom of Kongo once located on the southern bank of the river. The kingdom in turn was named for the indigenous Bantu Kongo people, known in the 17th century as \\"Esikongo\\".[4] South of the Kingdom of Kongo proper lay the similarly named Kakongo kingdom, mentioned in 1535. Abraham Ortelius in his world map of 1564 labeled as \\"Manicongo\\" the city at the mouth of the river.[5]\\r\\nThe tribal names in kongo possibly derive from a word for a public gathering or tribal assembly. The modern name of the Kongo people or Bakongo was introduced in the early 20th century.[citation needed]\\r\\nThe name Zaire is from a Portuguese adaptation of a Kikongo word, nzere (\\"river\\"), a truncation of nzadi o nzere (\\"river swallowing rivers\\").[6] The river was known as Zaire during the 16th and 17th centuries; Congo seems to have replaced Zaire gradually in English usage during the 18th century, and Congo is the preferred English name in 19th-century literature, although references to Zahir or Zaire as the name used by the inhabitants remained common.[7]\\r\\nThe Democratic Republic of the Congo and the Republic of the Congo are named after it, as was the previous Republic of the Congo which had gained independence in 1960 from the Belgian Congo.\\r\\nThe state of Zaire during 1971ÿ1997 was also named after the river, after its name in French and Portuguese.\\r\\nThe Congo's drainage basin covers 4,014,500 square kilometres (1,550,000?sq?mi).[1] The Congo's discharge at its mouth ranges from 23,000 to 75,000 cubic metres per second (810,000 to 2,650,000?cu?ft/s), with an average of 41,000 cubic metres per second (1,400,000?cu?ft/s).[1]\\r\\nThe river and its tributaries flow through the Congo Rainforest, the second largest rain forest area in the world, second only to the Amazon Rainforest in South America. The river also has the second-largest flow in the world, behind the Amazon; the third-largest drainage basin of any river, behind the Amazon and Plate rivers; and is one of the deepest rivers in the world, at depths greater than 220?m (720?ft).[2][8] Because its drainage basin includes areas both north and south of the equator, its flow is stable, as there is always at least one part of the river experiencing a rainy season.[9]\\r\\nThe sources of the Congo are in the highlands and mountains of the East African Rift, as well as Lake Tanganyika and Lake Mweru, which feed the Lualaba River, which then becomes the Congo below Boyoma Falls. The Chambeshi River in Zambia is generally taken as the source of the Congo in line with the accepted practice worldwide of using the longest tributary, as with the Nile River.\\r\\nThe Congo flows generally toward the northwest from Kisangani just below the Boyoma falls, then gradually bends southwestwards, passing by Mbandaka, joining with the Ubangi River, and running into the Pool Malebo (Stanley Pool). Kinshasa (formerly Lopoldville) and Brazzaville are on opposite sides of the river at the Pool, where the river narrows and falls through a number of cataracts in deep canyons (collectively known as the Livingstone Falls), running by Matadi and Boma, and into the sea at the small town of Muanda.\\r\\nThe Congo River Basin is one of the distinct physiographic sections of the larger Mid-African province, which in turn is part of the larger African massive physiographic division.\\r\\nThe drainage basin of the Congo River includes most of Central-Africa.The rivers inclouded are: Sorted in order from the mouth heading upstream.\\r\\nDownstream of Kinshasa, there are no important tributaries.\\r\\nUpstream of Boyoma Falls near Kisangani, the river Congo is known as the Lualaba River.\\r\\nAlthough the Livingstone Falls prevent access from the sea, nearly the entire Congo above them is readily navigable in sections, especially between Kinshasa and Kisangani. Large river steamers worked the river until quite recently.[when?] The Congo River still is a lifeline in a land with few roads or railways.[10]\\r\\nRailways now bypass the three major falls, and much of the trade of Central Africa passes along the river, including copper, palm oil (as kernels), sugar, coffee, and cotton.[citation needed] The river is also potentially valuable for hydroelectric power, and the Inga Dams below Pool Malebo are first to exploit the Congo river.\\r\\nThe Congo River is the most powerful river in Africa. During the rainy season over 50,000 cubic metres (1,800,000?cu?ft) of water per second flow into the Atlantic Ocean. Opportunities for the Congo River and its tributaries to generate hydropower are therefore enormous. Scientists have calculated that the entire Congo Basin accounts for 13 percent of global hydropower potential. This would provide sufficient power for all of sub-Saharan Africa's electricity needs.[11]\\r\\nCurrently there are about forty hydropower plants in the Congo Basin. The largest are the Inga dams, about 200 kilometres (120?mi) southwest of Kinshasa. The project was launched in the early 1970s, when the first dam was completed.[12] The plan as originally conceived called for the construction of five dams that would have had a total generating capacity of 34,500 megawatts. To date only the Inga I and Inga II dams have been built, generating 1,776 MW.[11]\\r\\nIn February 2005, South Africa's state-owned power company, Eskom, announced a proposa to expand generation through improvements and the construction of a new hydroelectric dam. The project would bring the maximum output of the facility to 40 gigawatts (54,000,000?hp), twice that of China's Three Gorges Dam.[13]\\r\\nIt is feared that these new hydroelectric dams could lead to the extinction of many of the fish species that are native to the river.[14]\\r\\nThe current course of the Congo River formed 1.5ÿ2 million years BP, during the Pleistocene.[15]\\r\\nThe Congo's formation may have led to the allopatric speciation of the bonobo and the common chimpanzee from their most recent common ancestor.[16] The bonobo is endemic to the humid forests in the region, as are other iconic species like the Allen's swamp monkey, dryas monkey, aquatic genet, okapi, and Congo peafowl.[17][18]\\r\\nIn terms of aquatic life, the Congo River Basin has a very high species richness, and among the highest known concentrations of endemics.[19] Until now, almost 700 fish species have been recorded from the Congo River Basin, and large sections remain virtually unstudied.[20] This is by far the highest diversity of any African river system (in comparison, the next richest are the Niger, Volta and Nile with about 210, 140 and 130 fish species, respectively).[21] Due to this and the great ecological differences between the regions in the Congo basin, it is often divided into multiple ecoregions (instead of treating it as a single ecoregion). Among these ecoregions, the Lower Congo Rapids alone has more than 300 fish species, including approximately 80 endemics[14] while the southwestern part (Kasai Basin) alone has more than 200 fish species, of which about a quarter are endemic.[22] The dominant fish families ÿ at least in parts of the river ÿ are Cyprinidae (carp/cyprinids, such as Labeo simpsoni), Mormyridae (elephantfishes), Alestidae (African tetras), Mochokidae (squeaker catfishes), and Cichlidae (cichlids).[23] Among the natives in the river is the huge, highly carnivorous giant tigerfish. Three of the more unusual endemics are the whitish (non-pigmented) and blind Lamprologus lethops, which is believed to live as deep as 160 metres (520?ft) below the surface,[14] Heterochromis multidens, which appears to be more closely related to cichlids of the Americas than other African cichlids,[24] and Caecobarbus geertsii, the only known cavefish in Central Africa.[25] There are also numerous endemic frogs and snails.[23][26] Several hydroelectric dams are planned on the river, and these may lead to the extinction of many of the endemics.[14]\\r\\nSeveral species of turtles, and the slender-snouted, Nile and dwarf crocodile are native to the Congo River Basin. African manatees inhabit the lower parts of the river.[27]\\r\\nThe entire Congo basin is populated by Bantu peoples, divided into several hundred ethnic or tribal groups (see ethnic groups of the Democratic Republic of the Congo). Bantu expansion is estimated to have reached the Middle Congo by about 500 BC, and the Upper Congo by the first century AD. Remnants of the aboriginal population displaced by the Bantu migration, Pygmies/Abatwa of the Ubangian phylum, remain in the remote forest areas of the Congo basin.\\r\\nThe Kingdom of Kongo was formed around 1400 on the left banks of the lower Congo River. Its territorial control along the river remained limited to what corresponds to the modern Bas-Congo province. European exploration of the Congo begins in 1482, when Portuguese explorer Diogo C?o discovered the river estuary[28] (likely in August 1482), which he marked by a Padr?o, or stone pillar (still existing, but only in fragments) erected on Shark Point. C?o also sailed up the river for a short distance, establishing contact with the Kingdom of Congo. The full course of the river remained unknown throughout the early modern period.[29]\\r\\nThe upper Congo basin runs west of the Albertine Rift.[28] Its connection to the Congo was unknown until 1877. The extreme northeast of the Congo basin was reached by the Nilotic expansion at some point between the 15th and 18th centuries, by the ancestors of the Southern Luo speaking Alur people. Francisco de Lacerda following the Zambezi reached the uppermost part of the Congo basin (the Kazembe in the upper Luapula basin) in 1796.\\r\\nThe upper Congo River, known as the Lualaba was first reached by the Arab slave trade by the 19th century. Nyangwe was founded as a slavers' outpost around 1860. David Livingstone was the first European to reach Nyangwe in March 1871.[28] Livingstone proposed to prove that the Lualaba connected to the Nile, but on 15 July, he witnessed a massacre of about 400 Africans by Arab slavers in Nyangwe, which experience left him too horrified and shattered to continue his mission to find the sources of the Nile, so he turned back to Lake Tanganyika.[30][31]\\r\\nThe middle reaches of the Congo remained unexplored from either the east or west, until Henry Morton Stanley's expedition of 1876ÿ77. At the time one of the last open questions of the exploration of Africa (or indeed of the world) whether the Lualaba River fed the Nile (Livingstone's theory), the Congo[32] or even the Niger. Financed in 1874, Stanley's first trans-Africa exploration started in Zanzibar, and reached the Lualaba on October 17, 1876. Overland he reached Nyangwe, the centre of a lawless area containing cannibal tribes at which Tippu Tip based his trade in slaves. Stanley managed to hire a force from Tippu Tip, to guard him for the next 150 kilometres (90?mi) or so, for 90 days. The party left Nyangwe overland through the dense Matimba forest. On November 19 they reached the Lualaba again. Since the going through the forest was so heavy, Tippu Tip turned around with his party on December 28, leaving Stanley on his own, with 143 people, including 8 children and 16 women. They had 23 canoes. His first encounter with a local tribe was with the cannibal Wenya. In total Stanley would report 32 unfriendly meetings on the river, some violent, even though he attempted to negotiate a peaceful thoroughfare. But the tribes were wary as their only experience of outsiders was of slave traders.\\r\\nOn January 6, 1877, after 640 kilometres (400?mi), they reached Boyoma Falls (called Stanley Falls for some time after), consisting of seven cataracts spanning 100 kilometres (60?mi) which they had to bypass overland. It took them to February 7 to reach the end of the falls. Here Stanley learned that the river was called Ikuta Yacongo,[33] proving to him that he had reached the Congo, and that the Lualaba did not feed the Nile.\\r\\nFrom this point, the tribes were no longer cannibals, but possessed firearms, apparently as a result of Portuguese influence. Some four weeks and 1,900 kilometres (1,200?mi) later he reached Stanley Pool (now Pool Malebo), the site of the present day cities Kinshasa and Brazzaville. Further downstream were the Livingstone Falls, misnamed as Livingstone had never been on the Congo: a series of 32 falls and rapids with a fall of 270 metres (900?ft) over 350 kilometres (220?mi). On 15 March they started the descent of the falls, which took five months and cost numerous lives. From the Isangile Falls, five falls from the foot, they beached the canoes and Lady Alice and left the river, aiming for the Portuguese outpost of Boma via land. On August 3 they reached the hamlet Nsada. From there Stanley sent four men with letters forward to Boma, asking for food for his starving people. On August 7 relief came, being sent by representatives from the Liverpool trading firm Hatton & Cookson. On August 9 they reached Boma, 1,001 days since leaving Zanzibar on November 12, 1874. The party then consisted of 108 people, including three children born during the trip. Most probably (Stanley's own publications give inconsistent figures), he lost 132 people through disease, hunger, drowning, killing and desertion.[34]\\r\\nKinshasa was founded as a trading post by Stanley in 1881 and named Lopoldville in honour of Leopold II of Belgium. The Congo basin was claimed by Belgium as Congo Free State in 1885.\\r\\nThe Congo river basin is notable for the mere absence of bridges crossing the main rivers, although there are a number of ferries available for crossing the great Congo river and the major tributaries.\\r\\nThere are only two bridges on the Congo river proper and main tributary, which both are found in the DR Congo:\\r\\nThere are one bridge on the Uele River, and two on the Kibali River, which all lies in the northern province Haut-Uele of DR Congo:\\r\\nThere are two bridges on the Lulua river in the provice of Kasai of DR Congo:\\r\\nAngola - DR Congo border:\\r\\nLower Congo (Matadi - Pioka):\\r\\nDR Congo - Congo Republic border:\\r\\nUpper Congo (Irebu - Ubundu):\\r\\nOn the minor tributaries of the great Congo there are noumerous river crossings, which cannot be included here.\\r\\nCoordinates: 60445S 122700E? / ?6.07917S 12.45000E? / -6.07917; 12.45000","input":"What is the largest river in africa called?"},{"output":"filter paper","context":"A tea bag is a small, porous, sealed bag or packet containing dried plant material, which is immersed in boiling water to make a tea or an infusion. Classically these are tea leaves (Camellia sinensis), but the term is also used for herbal teas (tisanes) made of herbs or spices. Tea bags are commonly made of filter paper or food-grade plastic, or occasionally of silk. The bag contains the tea leaves while the tea is steeped, making it easier to dispose of the leaves, and performs the same function as a tea infuser. Some tea bags have an attached piece of string with a paper label at the top that assists in removing the bag while also displaying the brand or variety of tea.\\r\\n\\r\\nIn countries where the use of loose tea leaves is more prevalent, the term \\"tea bag\\" is commonly used to describe paper or foil packaging for loose leaves. They are usually square or rectangular envelopes with the brand name, flavour and decorative patterns printed on them.\\r\\n\\r\\nPacking tea in paper goes back to medieval 8th century China, during the Tang Dynasty when paper was folded and sewn into square bags to preserve tea flavoring and aromas. Then the paper tea bags were stitched from all sides to create protective casings for the tea leaves.[1][2][3]\\r\\n\\r\\nThe first modern tea bags in the Western World were hand-sewn fabric bags; tea bag patents date as early as 1903.[4] First appearing commercially around 1904, tea bags were successfully marketed about 1908 by the tea and coffee importer Thomas Sullivan from New York, who shipped his silk tea bags around the world.[5] The loose tea was intended to be removed from the bags by customers, but they found it easier to brew the tea with the tea still enclosed in the porous bags.[6] The first tea bag packing machine was invented in 1929 by Adolf Rambold for the German company Teekanne.[7]\\r\\n\\r\\nModern tea bags are usually made of paper fiber. The heat-sealed paper fiber tea bag was patented in 1930 by William Hermanson,[8] one of the founders of Technical Papers Corporation of Boston,[citation needed] who sold his patent to the Salada Tea Company.[citation needed]\\r\\n\\r\\nThe rectangular tea bag was not invented until 1944. Prior to this, tea bags resembled small sacks.[9]\\r\\n\\r\\nA broad variety of teas as well as other infusions like herbal teas, are available in tea bags. Typically, tea bags use fannings, the left-overs after larger leaf pieces are gathered for sale as loose tea, but some companies sell teabags containing whole-leaf tea.[10]\\r\\n\\r\\nTea bag paper is related to paper found in milk and coffee filters and is a blend of wood and vegetable fibers. The latter is bleached pulp abaca hemp, a plantation banana plant grown for its fiber, mostly in the Philippines and Colombia. Some bags have a heat-sealable thermoplastic such as PVC or polypropylene as a component fiber on the inner tea bag surface.[11] Paper tea bags are commonly sealed using polypropylene.[12]\\r\\n\\r\\nIn 2017, Mike Armitage, a gardener in Wrexham, UK, found that tea bags left a plastic residue after being composted. He started a petition urging Unilever to remove plastic from bag production.[13][14][15] In January 2018, Co-op Food announced that they were removing plastic from their own brand 99 tea bags in conjunction with their supplier Typhoo.[16][17]  In February 2018, PG Tips announced that their pyramid bags now use corn starch adhesive in place of polypropylene.[13][18][19]\\r\\n\\r\\nA few of the leading tea bag production machine companies are MAI from Mar del Plata, Argentina;[20] Teepack from Meerbusch, Germany;[21] and IMA, from Bologna, Italy.  A standard machine produced by the MAI company can fill 120 rectangular bags per minute[22] containing up to 3.3?grams per bag, which allows the packaging of herbal teas. Another company, the Italian Tecnomeccanica, has a faster design capable of filling 250 tetrahedral bags per minute.[23]\\r\\n\\r\\nTraditionally, tea bags have been square or rectangular in shape. More recently circular and tetrahedral bags have come on the market and are often claimed by their manufacturers to improve the quality of the brew. Environmentalists prefer silk to nylon because of health and biodegradability issues.[24] Another material for tea bags is Soilon, made from corn starch.[25] Empty tea bags are also available for consumers to fill with tea leaves themselves. These are typically open-ended pouches with long flaps. The pouch is filled with an appropriate quantity of leaf tea and the flap is closed into the pouch to retain the tea. Such tea bags combine the ease of use of a commercially produced tea bag with the wider tea choice and better quality control of loose leaf tea.\\r\\n\\r\\nThe concept of pre-measured portions to be infused in disposable bags has also been applied to coffee in the form of coffee bags, although this has not achieved such wide acceptance as tea bags.\\r\\n\\r\\nDecorative tea bag labels have become the basis for large collections and many collectors collect tea bags from around the world.\\r\\n\\r\\nTeabag folding began in the Netherlands and is often credited to Tiny van der Plas. It is a form of origami in which identical squares of patterned paper (cut from the front of tea bag wrappers) are folded, and then arranged in rosettes. These rosettes are usually used to decorate gift cards and it has become a popular craft in both the US and UK since 2000.[26]","input":"What is the tea bag made out of?"},{"output":"rabbit","context":"\\r\\n\\r\\nKing Kong is a 1933 American pre-Code monster adventure film[4] directed and produced by Merian C. Cooper and Ernest B. Schoedsack. The screenplay by James Ashmore Creelman and Ruth Rose was developed from an idea conceived by Cooper and Edgar Wallace. It stars Fay Wray, Bruce Cabot and Robert Armstrong, and opened in New York City on March 2, 1933, to rave reviews. It has been ranked by Rotten Tomatoes as the greatest horror film of all time[5] and the thirty-third greatest film of all time.[6]\\r\\n\\r\\nThe film tells of a huge, ape-like creature dubbed Kong who perishes in an attempt to possess a beautiful young woman (Wray). King Kong is especially noted for its stop-motion animation by Willis O'Brien and a groundbreaking musical score by Max Steiner. In 1991, it was deemed \\"culturally, historically and aesthetically significant\\" by the Library of Congress and selected for preservation in the National Film Registry.[7] A sequel quickly followed with Son of Kong (also released in 1933), with several more films made in the following decades.\\r\\n\\r\\nIn New York Harbor, filmmaker Carl Denham, famous for making wildlife films in remote and exotic locations, charters Captain Englehorn's ship, the Venture, for his new project. However, he is unable to secure an actress for a female role he has been reluctant to disclose. Searching in the streets of New York City, he finds Ann Darrow and promises her the adventure of a lifetime. The crew boards the Venture and sets off, during which the ship's first mate Jack Driscoll, falls in love with Ann.\\r\\n\\r\\nDenham reveals to the crew that their destination is in fact Skull Island, an uncharted territory. He alludes to a monstrous creature named Kong, rumored to dwell on the island. The crew arrives and anchor offshore. They encounter a native village, separated from the rest of the island by an ancient stone wall. They witness a group of natives preparing to sacrifice a young woman termed the \\"bride of Kong\\". The intruders are spotted and the native chief stops the ceremony. When he sees Ann, he offers to trade six of his tribal women for the \\"golden woman\\". They rebuff him and return to the Venture.\\r\\n\\r\\nThat night, natives kidnap Ann from the ship and take her to their altar, where she is offered to Kong, an enormous gorilla-like creature. Kong carries Ann into the wilderness as Denham, Driscoll and some volunteers enter the jungle in hopes of rescuing her. They are ambushed by another giant creature, a Stegosaurus, which they manage to defeat. After facing a Brontosaurus and Kong himself, Driscoll and Denham are the only survivors.\\r\\n\\r\\nA Tyrannosaurus attacks Ann and Kong, but he kills it in battle. Meanwhile, Driscoll continues to follow them, while Denham returns to the village for more men. Upon arriving in Kong's lair, Ann is menaced by a snake-like Elasmosaurus, which Kong also kills. While Kong is distracted killing a Pteranodon that tried to fly away with Ann, Driscoll reaches her and they climb down a vine dangling from a cliff ledge. When Kong notices and starts pulling them back up, the two fall unharmed. They run through the jungle and back to the village, where Denham, Englehorn, and the surviving crewmen are waiting. Kong, following, breaks open the gate and relentlessly rampages through the village. Onshore, Denham, now determined to bring Kong back alive, knocks him unconscious with a gas bomb.\\r\\n\\r\\nShackled in chains, Kong is taken to New York City and presented to a Broadway theatre audience as \\"Kong, the Eighth Wonder of the World\\". Ann and Jack are brought on stage to join him, surrounded by a group of press photographers. Kong, believing that the ensuing flash photography is an attack, breaks loose. The audience flees in horror. Ann is whisked away to a hotel room on a high floor, but Kong, scaling the building, soon finds her. His hand smashes through the hotel room window, immobilizing Jack, and abducts Ann again. Kong rampages through the city. He wrecks a crowded elevated train and then climbs the Empire State Building. At its top, he is attacked by four airplanes. Kong destroys one, but finally succumbs to their gunfire. He ensures Ann's safety before falling to his death. Ann and Jack are reunited. Denham arrives and pushes through a crowd surrounding Kong's corpse in the street. When a policeman remarks that the planes got him, Denham tells him, \\"It was Beauty  killed the Beast\\".\\r\\n\\r\\nBefore King Kong entered production, a long tradition of jungle films existed, and, whether drama or documentary, such films (for example Stark Mad) generally adhered to a narrative pattern that followed an explorer or scientist into the jungle to test a theory only to discover some monstrous aberration in the undergrowth. In these films, scientific knowledge could be subverted at any time, and it was this that provided the genre with its vitality, appeal, and endurance.[8]\\r\\n\\r\\nIn the early 20th century, few zoos had primate exhibits so there was popular demand to see them on film. At the turn of the 20th century, the Lumire Brothers sent film documentarians to places westerners had never seen, and Georges Mlis utilized trick photography in film fantasies that prefigured that in King Kong. Jungle films were launched in the United States in 1913 with Beasts in the Jungle, and the film's popularity spawned similar pictures such as Tarzan of the Apes,.[8] In 1925, The Lost World made movie history with special effects by Willis O'Brien and a crew that later would work on King Kong.[9] King Kong producer Ernest B. Schoedsack had earlier monkey experience directing Chang: A Drama of the Wilderness in 1927 (also with Merian C. Cooper) and Rango in 1931, both of which prominently featured monkeys in authentic jungle settings. Capitalizing on this trend, Congo Pictures released the hoax documentary Ingagi in 1930, advertising the film as \\"an authentic incontestable celluloid document showing the sacrifice of a living woman to mammoth gorillas.\\" Ingagi is now widely recognized as a racial exploitation film as it implicitly depicted black women having sex with gorillas, and baby offspring that looked more ape than human.[10] The film was an immediate hit, and by some estimates it was one of the highest-grossing films of the 1930s at over $4 million. Although Cooper never listed Ingagi among his influences for King Kong, it has long been held that RKO green-lit Kong because of the bottom-line example of Ingagi and the formula that \\"gorillas plus sexy women in peril equals enormous profits\\".[11]\\r\\n\\r\\nMerian C. Cooper's fascination with gorillas began with his boyhood reading of Paul Du Chaillu's Explorations and Adventures in Equatorial Africa (1861) and was furthered in 1929 by studying a tribe of baboons in Africa while filming The Four Feathers. After reading W. Douglas Burden's The Dragon Lizards of Komodo, he fashioned a scenario depicting African gorillas battling Komodo dragons intercut with artificial stand-ins for joint shots. He then narrowed the dramatis personae to one ferocious, lizard-battling gorilla (rather than a group) and included a lone woman on expedition to appease those critics who belabored him for neglecting romance in his films. A remote island would be the setting and the gorilla would be dealt a spectacular death in New York City.[12]\\r\\n\\r\\nCooper took his concept to Paramount Studios in the first years of the Great Depression but executives shied away from a project that sent film crews on costly shoots to Africa and Komodo. In 1931, David O. Selznick brought Cooper to RKO as his executive assistant and promised him he could make his own films. Cooper began immediately developing The Most Dangerous Game, and hired Ernest B. Schoedsack to direct. A huge jungle stage set was built, with Robert Armstrong and Fay Wray as the stars. Once the film was underway, Cooper turned his attention to the studio's big-budget-out-of-control fantasy, Creation, a project with stop motion animator Willis O'Brien about a group of travelers shipwrecked on an island of dinosaurs.[13]\\r\\n\\r\\nWhen Cooper screened O'Brien's stop-motion Creation footage, he was unimpressed, but realized he could economically make his gorilla picture by scrapping the Komodo dragons and costly location shoots for O'Brien's animated dinosaurs and the studio's existing jungle set. It was at this time Cooper probably cast his gorilla as a giant named Kong, and planned to have him die at the Empire State Building. The RKO board was wary about the project, but gave its approval after Cooper organized a presentation with Wray, Armstrong, and Cabot, and O'Brien's model dinosaurs. In his executive capacity, Cooper ordered the Creation production shelved, and put its crew to work on Kong.[14]\\r\\n\\r\\nCooper assigned recently hired RKO screenwriter and best-selling British mystery/adventure writer Edgar Wallace the job of writing a screenplay and a novel based on his gorilla fantasy. Cooper understood the commercial appeal of Wallace's name and planned to publicize the film as being \\"based on the novel by Edgar Wallace\\". Wallace conferred with Cooper and O'Brien (who contributed, among other things, the \\"Ann's dress\\" scene) and began work on January 1, 1932. He completed a rough draft called The Beast on January 5, 1932. Cooper thought the draft needed considerable work but Wallace died on February 10, 1932, just after beginning revisions.[8][15] Despite not using any of the draft in the final production beyond the previously agreed upon plot outline, Cooper gave a screen credit to Wallace as he had promised it as a producer.\\r\\n\\r\\nCooper called in James Ashmore Creelman (who was working on the script of The Most Dangerous Game at the time) and the two men worked together on several drafts under the title The Eighth Wonder. Some details from Wallace's rough draft were dropped, notably his boatload of escaped convicts. Wallace's Danby Denham character, a big game hunter, became film director Carl Denham. His Shirley became Ann Darrow and her lover-convict John became Jack Driscoll. The 'beauty and the beast' angle was first developed at this time. Kong's escape was switched from Madison Square Garden to Yankee Stadium and (finally) to a Broadway theater. Cute moments involving the gorilla in Wallace's draft were cut because Cooper wanted Kong hard and tough in the belief that his fall would be all the more awesome and tragic.[15]\\r\\n\\r\\nTime constraints forced Creelman to temporarily drop The Eighth Wonder and devote his time to the Game script. RKO staff writer Horace McCoy was called in to work with Cooper, and it was he who introduced the island natives, a giant wall, and the sacrificial maidens into the plot. Leon Gordon also contributed to the screenplay in a minimal capacity; both he and McCoy went uncredited in the completed film.[16] When Creelman returned to the script full-time, he hated McCoy's 'mythic elements', believing the script already had too many over-the-top concepts, but Cooper insisted on keeping them in. RKO head Selznick and his executives wanted Kong introduced earlier in the film (believing the audience would grow bored waiting for his appearance), but Cooper persuaded them that a suspenseful build-up would make Kong's entrance all the more exciting.[17]\\r\\n\\r\\nCooper felt Creelman's final draft was slow-paced, too full of flowery dialogue, weighted-down with long scenes of exposition,[17] and written on a scale that would have been prohibitively expensive to film.[18] Writer Ruth Rose (Schoedsack's wife) was brought in to for rewrites and, although she had never written a screenplay, undertook the task with a complete understanding of Cooper's style, streamlining the script and tightening the action. Rather than explaining how Kong would be transported to New York, for example, she simply cut from the island to the theater. She incorporated autobiographical elements into the script with Cooper mirrored in the Denham character, her husband Schoedsack in the tough but tender Driscoll character, and herself in struggling actress Ann Darrow. Rose also rewrote the dialogue and created the film's opening sequence, showing Denham meeting Ann on the streets of New York. Cooper was delighted with Rose's script, approving the newly re-titled Kong for production.[19] Cooper and Schoedsack decided to co-direct scenes but their styles were different (Cooper was slow and meticulous, Schoedsack brisk) and they finally agreed to work separately, with Cooper overseeing O'Brien's miniature work and directing the special effects sequences, and Schoedsack directing the dialogue scenes.[20]\\r\\n\\r\\nAfter the RKO board approved the production of a test reel, Marcel Delgado constructed Kong (or the \\"Giant Terror Gorilla\\" as he was then known) per designs and directions from Cooper and O'Brien on a one-inch-equals-one-foot scale to simulate a gorilla 18 feet tall.[citation needed] Four models were built: two jointed 18-inch aluminum, foam rubber, latex, and rabbit fur models (to be rotated during filming), one jointed 24-inch model of the same materials for the New York scenes, and a small model of lead and fur for the climactic plummeting-down-the-Empire-State-Building shot.[citation needed] At least two armatures have survived - one believed to be the original made for the test footage - and are owned by Peter Jackson and Bob Burns.[32] In 2009, one sold for S121,000 ($200,000) at Christie's in London.[33]\\r\\n\\r\\nKong's torso was streamlined to eliminate the comical appearance of the real world gorilla's prominent belly and buttocks. His lips, eyebrows, and nose were fashioned of rubber, his eyes of glass, and his facial expressions controlled by thin, bendable wires threaded through holes drilled in his aluminum skull. During filming, Kong's rubber skin dried out quickly under studio lights, making it necessary to replace it often and completely rebuild his facial features.[34]\\r\\n\\r\\nA huge bust of Kong's head, neck, and upper chest was made of wood, cloth, rubber, and bearskin by Delgado, E. B. Gibson, and Fred Reefe.[citation needed] Inside the structure, metal levers, hinges, and an air compressor were operated by three men to control the mouth and facial expressions. Its fangs were 10 inches in length and its eyeballs 12 inches in diameter. The bust was moved from set to set on a flatcar. Its scale matched none of the models and, if fully realized, Kong would have stood thirty to forty feet tall.[35]\\r\\n\\r\\nTwo versions of Kong's right hand and arm were constructed of steel, sponge rubber, rubber, and bearskin.[citation needed] The first hand was non articulated, mounted on a crane, and operated by grips for the scene in which Kong grabs at Driscoll in the cave. The other hand and arm had articulated fingers, was mounted on a lever to elevate it, and was used in the several scenes in which Kong grasps Ann. A non articulated leg was created of materials similar to the hands, mounted on a crane, and used to stomp on Kong's victims.[36]\\r\\n\\r\\nThe dinosaurs were made by Delgado in the same fashion as Kong and based on Charles R. Knight's murals in the American Museum of Natural History in New York City. All the armatures were manufactured in the RKO machine shop. Materials used were cotton, foam rubber, latex sheeting, and liquid latex. Football bladders were placed inside some models to simulate breathing.[citation needed] A scale of one-inch-equals-one-foot was employed and models ranged from 18 inches to 3 feet in length. Several of the models were originally built for Creation and sometimes two or three models were built of individual species. Prolonged exposure to studio lights wreaked havoc with the latex skin so John Cerasoli carved wooden duplicates of each model to be used as stand-ins for test shoots and lineups. He carved wooden models of Ann, Driscoll, and other human characters. Models of the Venture, railway cars, and war planes were built.[38]\\r\\n\\r\\nKing Kong is well known for its groundbreaking use of special effects, such as stop-motion animation, matte painting, rear projection and miniatures, all of which were conceived decades before the digital age.[39]\\r\\n\\r\\nThe numerous prehistoric creatures inhabiting Skull Island were brought to life through the use of stop-motion animation by Willis OBrien and his assistant animator, Buzz Gibson.[40] The stop-motion animation scenes were painstaking and difficult to achieve and complete after the special effects crew realized that they could not stop, because it would make the movements of the creatures seem inconsistent and the lighting would not have the same intensity over the many days it took to fully animate a finished sequence. A device called the surface gauge was used in order to keep track of the stop-motion animation performance. The iconic fight between Kong and the Tyrannosaurus took seven weeks to be completed. OBriens proteg, Ray Harryhausen, who would work with him on several films and become one of the most prominent stop-motion animators in Hollywood, stated that OBriens second wife noticed that there was so much of her husband in Kong.\\r\\n\\r\\nThe backdrop of Skull Island seen when the Venture crew first arrive was painted on glass by matte painters Henry Hillinck, Mario Larrinaga and Byron C. Crabb. The scene was then composted with separate bird elements and rear projected behind the ship and the actors. The background of the scenes in the jungle (a miniature set) were also painted on several layers of glass to convey the illusion of deep and dense jungle foliage.[41]\\r\\n\\r\\nThe most difficult task for the special effects artists to achieve was to make live-action footage interact with separately filmed stop-motion animation - to make the interaction between the humans and the creatures of the island seem believable. The most simple of these effects were accomplished by exposing part of the frame, then running the same piece of the film through the camera again by exposing the other part of the frame with a different image. The most complex shots, where the live-action actors interacted with the stop-motion animation, were achieved via two different techniques, the Dunning process and the Williams process, in order to produce the effect of a travelling matte.[42] The Dunning process, invented by cinematographer Carroll H. Dunning, employed the use of blue and yellow lighting, filtered and photographed into black-and-white film. Bi packing of the camera was used for these types of effects. With it, the special effects crew could combine two strips of different film at the same time, creating the final composite shot in the camera.[43] It was used in the climactic scene where one of the Curtiss Helldiver planes attacking Kong crashes from the top of the Empire State Building, and in the scene where natives are running through the foreground, while Kong is fighting other natives at the wall.\\r\\n\\r\\nOn the other hand, the Williams process, invented by cinematographer Frank D. Williams, did not require a system of colored lights and could be used for wider shots. It was used in the scene where Kong is shaking the sailors off the log, as well as the scene where Kong pushes the gates open. The Williams process did not use bipacking, but rather an optical printer, the first such device that synchronized a projector with a camera, so that several strips of film could be combined into a single composted image. Through the use of the optical printer, the special effects crew could film the foreground, the stop-motion animation, the live-action footage, and the background, and combine all of those elements into one single shot.[44] The optical printer would continue to be used for films until the late 1980s, when they were superseded by digital compositing.\\r\\n\\r\\nAnother technique that was used in combining live actors and stop-motion animation was rear-screen projection. The actor would have a translucent screen behind him where a projector would project footage onto the back of the translucent screen.[45] The translucent screen was developed by Sidney Saunders and Fred Jackman, who received a Special Achievement Oscar. It was used in the famous scene where Kong and the Tyrannosaurus fight while Ann watches from the branches of a nearby tree. The stop-motion animation was filmed first. Fay Wray then spent a twenty-two hour period sitting in a fake tree acting out her observation of the battle, which was projected onto the translucent screen while the camera filmed her witnessing the projected stop-motion battle. She was sore for days after the shoot. The same process was also used for the scene where sailors from the Venture kill a Stegosaurus.\\r\\n\\r\\nOBrien and his special effects crew also devised a way to use rear-projection in miniature sets. A tiny screen was built into the miniature onto which live-action footage would then be projected.[45] A fan pumped cool air to prevent the footage that was projected from melting or catching fire. This miniature rear projection was used in the scene where Kong is trying to grab Driscoll, who is hiding in a cave. The scene where Kong puts Ann in the top of a tree switched from a puppet in Kong's hand to a projected footage of Ann sitting.\\r\\n\\r\\nThe scene where Kong fights the snake-like reptile in his lair was likely the most significant special effects achievement of the film, due to the way in which all of the elements in the sequence work together at the same time. The scene was accomplished through the use of a miniature set, stop-motion animation for Kong, background matte paintings, real water, foreground rocks with bubbling mud, smoke and two miniature rear screen projections of Driscoll and Ann.\\r\\n\\r\\nOver the years, some media reports have alleged that in certain scenes Kong was played by an actor wearing a gorilla suit.[46][47] However, film historians have generally agreed that all scenes involving Kong were achieved with animated models.[48][49]\\r\\n\\r\\nKing Kong was filmed in several stages over an eight-month period. Some actors had so much time between their Kong periods that they were able to fully complete work on other films. Cabot completed Road House and Wray appeared in the horror films Dr. X and Mystery of the Wax Museum. She estimated she worked for ten weeks on Kong over its eight-month production.[citation needed]\\r\\n\\r\\nIn May and June 1932, Cooper directed the first live-action Kong scenes on the jungle set built for The Most Dangerous Game. Some of these scenes were incorporated into the test reel later exhibited for the RKO board. The script was still in revision when the jungle scenes were shot and much of the dialogue was improvised. The jungle set was scheduled to be struck after Game was completed, so Cooper filmed all of the other jungle scenes at this time. The last scene shot was that of Driscoll and Ann racing through the jungle to safety following their escape from Kong's lair.[citation needed]\\r\\n\\r\\nIn July 1932, the native village was readied while Schoedsack and his crew filmed establishing shots in the harbor of New York City. Curtiss F8C-5/O2C-1 Helldiver war planes taking off and in flight were filmed at a U.S. Naval airfield on Long Island. Views of New York City were filmed from the Empire State Building for backgrounds in the final scenes and architectural plans for the mooring mast were secured from the building's owners for a mock-up to be constructed on the Hollywood sound stage.[50]\\r\\n\\r\\nIn August 1932, the island landing party scene and the gas bomb scene were filmed south of Los Angeles on a beach at San Pedro, California. All of the native village scenes were then filmed on the RKO-Path lot in Culver City with the native huts recycled from Bird of Paradise (1932). The great wall in the island scenes was a hand-me-down from DeMille's The King of Kings (1927) and dressed up with massive gates, a gong, and primitive carvings. The scene of Ann being led through the gates to the sacrificial altar was filmed at night with hundreds of extras and 350 lights for illumination. A camera was mounted on a crane to follow Ann to the altar. The Culver City Fire Department was on hand due to concerns that the set might go up in flames from the many native torches used in the scene. The wall and gate were destroyed in 1939 for Gone With the Wind's burning of Atlanta sequence. Hundreds of extras were once again used for Kong's rampage through the native village, and filming was completed with individual vignettes of mayhem and native panic.\\r\\n\\r\\nMeanwhile, the scene depicting a New York woman being dropped to her apparent death from a hotel window was filmed on the sound stage using the articulated hand. At the same time, a scene depicting poker players surprised by Kong's face peering through a window was filmed using the 'big head', although the scene was eventually dropped.[51] When filming was completed, a break was scheduled to finish construction of the interior sets and to allow screenwriter Ruth Rose time to finish the script.\\r\\n\\r\\nIn SeptemberÿOctober 1932, Schoedsack returned to the sound stage after completing the native village shoots in Culver City. The decks and cabins of the Venture were constructed and all the live-action shipboard scenes were then filmed. The New York scenes were filmed, including the scene of Ann being plucked from the streets by Denham, and the diner scene. Following completion of the interior scenes, Schoedsack returned to San Pedro and spent a day on a tramp steamer to film the scene of Driscoll punching Ann, and various atmospheric harbor scenes. The Shrine Auditorium in Los Angeles was rented for one day to film the scenes where Kong is displayed in chains and the backstage theater scenes following his escape.[52] Principal photography wrapped at the end of October 1932 with the filming of the climax wherein Driscoll rescues Ann at the top of the Empire State Building. Schoedsack's work was completed and he headed to Syria to film outdoor scenes for Arabia, a project that was never completed.[53]\\r\\n\\r\\nIn December 1932 ÿ January 1933, the actors were called back to film a number of optical effects shots which were mostly rear-screen projections.[citation needed] Technical problems inherent in the process made filming difficult and time-consuming. Wray spent most of a twenty-two hour period sitting in a fake tree to witness the battle between Kong and a Tyrannosaurus. She was sore for days after. Many of the scenes featuring Wray in the articulated hand were filmed at this time.[citation needed] In December, Cooper re shot the scene of the female New Yorker falling to her death. Stunt doubles were filmed for the water scenes depicting Driscoll and Ann escaping from Kong. A portion of the jungle set was reconstructed to film Denham snagging his sleeve on a branch during the pursuit scene. Originally, Denham ducked behind a bush to escape danger, but this was later considered cowardly and the scene was re shot. The final scene was originally staged on the top of the Empire State Building, but Cooper was dissatisfied and re shot the scene with Kong lying dead in the street with the crowd gathered about him.[citation needed]\\r\\n\\r\\nMurray Spivack provided the sound effects for the film. Kong's roar was created by mixing the recorded roars of zoo lions and tigers, subsequently played backwards slowly. Spivak himself provided Kong's \\"love grunts\\" by grunting into a megaphone and playing it at a slow speed. For the huge ape's footsteps, Spivak stomped across a gravel-filled box with plungers wrapped in foam attached to his own feet, while the sounds of his chest beats were recorded by Spivak hitting his assistant (who had a microphone held to his back) on the chest with a drumstick. Spivak created the hisses and croaks of the dinosaurs with an air compressor for the former and his own vocals for the latter. The vocalizations of the Tyrannosaurus were additionally mixed in with puma screams. Bird squawks were used for the Pteranodon. Spivak also provided the numerous screams of the various sailors. Fay Wray herself provided all of her character's screams in a single recording session.[54][55]\\r\\n\\r\\nFor budget reasons, RKO decided not to have an original film score composed, instead instructing composer Max Steiner to simply reuse music from other films. Cooper thought the film deserved an original score and paid Steiner $50,000 to compose it. Steiner completed the score in six weeks and recorded it with a 46-piece orchestra. The studio later reimbursed Cooper.[56] The score was unlike any that came before and marked a significant change in the history of film music. King Kong's score was the first feature-length musical score written for an American \\"talkie\\" film, the first major Hollywood film to have a thematic score rather than background music, the first to mark the use of a 46-piece orchestra, and the first to be recorded on three separate tracks (sound effects, dialogue, and music). Steiner used a number of new film scoring techniques, such as drawing upon opera conventions for his use of leitmotifs.[57]\\r\\n\\r\\nKing Kong opened at the 6,200-seat Radio City Music Hall in New York City and the 3,700-seat RKO Roxy across the street on Thursday, March 2, 1933. The film was preceded by a stage show called Jungle Rhythms. Crowds lined up around the block on opening day, tickets were priced at $.35 to $.75, and, in its first four days, every one of its ten-shows-a-day were sold out?ÿ setting an all-time attendance record for an indoor event. Over the four-day period, the film grossed $89,931.[58][59]\\r\\n\\r\\nThe film had its official world premiere on March 23, 1933 at Grauman's Chinese Theater in Hollywood. The 'big head bust' was placed in the theater's forecourt and a seventeen-act show preceded the film with The Dance of the Sacred Ape performed by a troupe of African American dancers the highpoint. Kong cast and crew attended and Wray thought her on-screen screams distracting and excessive. The film opened nationwide on April 10, 1933, and worldwide on Easter Day in London, England.[58][60]\\r\\n\\r\\nIt was re-released in 1938, 1942, 1946, 1952 and 1956.[59]\\r\\n\\r\\nOn Rotten Tomatoes, the film holds an approval rating of 98% based on 56 reviews, with a weighted average rating of 9/10. The site's critical consensus reads, \\"King Kong explores the soul of a monster -- making audiences scream and cry throughout the film -- in large part due to Kong's breakthrough special effects.\\"[61] On Metacritic, which assigns a normalized rating to reviews, the film has a weighted average score of 90 out of 100, based on 12 critics, indicating \\"Universal acclaim\\".[62]\\r\\n\\r\\nVariety thought the film was a powerful adventure.[63] The New York Times gave readers an enthusiastic account of the plot and thought the film a fascinating adventure.[64] John Mosher of The New Yorker called it \\"ridiculous\\", but wrote that there were \\"many scenes in this picture that are certainly diverting\\".[65] The New York World-Telegram said it was \\"one of the very best of all the screen thrillers, done with all the cinema's slickest camera tricks\\".[66] The Chicago Tribune called it \\"one of the most original, thrilling and mammoth novelties to emerge from a movie studio.\\"[67]\\r\\n\\r\\nOn February 3, 2002, Roger Ebert included King Kong in his \\"Great Movies\\" list, writing that \\"In modern times the movie has aged, as critic James Berardinelli observes, and 'advances in technology and acting have dated aspects of the production.' Yes, but in the very artificiality of some of the special effects, there is a creepiness that isn't there in today's slick, flawless, computer-aided images.... Even allowing for its slow start, wooden acting and wall-to-wall screaming, there is something ageless and primeval about \\"King Kong\\" that still somehow works.\\"[68]\\r\\n\\r\\nThe film was a box office success making about $2 million in worldwide rentals on its initial release, with an opening weekend estimated at $90,000. Receipts fell by up to 50% in the second week of the film's release because of the national \\"bank holiday\\" called in President Franklin D. Roosevelt's first days in office.[69] During the film's first run it made a profit of $650,000.[3]\\r\\n\\r\\nPrior to the 1952 re-release, the film is reported to have worldwide rentals of $2,847,000 including $1,070,000 from the United States and Canada and profits of $1,310,000.[3] After the 1952 re-release, Variety estimated the film had made an additional $1.6 million in the United States and Canada taking its total to $3.9 million in cumulative domestic (United States and Canada) rentals.[70] Profits from the 1952 re-release were estimated by the studio at $2.5 million.[3]\\r\\n\\r\\nIn the 19th and early twentieth century, people of African descent were commonly visually represented as ape-like, a metaphor that fitted racist stereotypes, further bolstered by the emergence of scientific racism.[71] Early blockbuster films frequently mirrored racial tensions. While King Kong is often compared to the story of Beauty and the Beast, many film scholars have argued that the film was a racist cautionary tale about interracial romance, in which the film's \\"carrier of blackness is not a human being, but an ape\\".[72][73] Cooper and Schoedsack rejected any allegorical interpretations, insisting in interviews that the film's story contained no hidden meanings.[74]\\r\\n\\r\\nKong did not receive any Academy Awards nominations. Selznick wanted to nominate O'Brien and his crew for a special award in visual effects but the Academy declined. Such a category did not exist at the time and would not exist until 1938. Sidney Saunders and Fred Jackman received a special achievement award for the development of the translucent acetate/cellulose rear screen?ÿ the only Kong-related award.[75]\\r\\n\\r\\nThe film has since received some significant honors. In 1975, Kong was named one of the 50 best American films by the American Film Institute, and, in 1991, the film was deemed \\"culturally, historically and aesthetically significant\\" by the Library of Congress and selected for preservation in the United States National Film Registry.[76] In 1998, the AFI ranked the film #43 on its list of the 100 greatest movies of all time.[77]\\r\\n\\r\\nAmerican Film Institute Lists\\r\\n\\r\\nKing Kong was re-released in 1938, 1942, 1946, 1952 and 1956; each time to great box office success.[78] Stricter decency rules had been put into effect in Hollywood since its 1933 premiere and each time it was censored further, with several scenes being either trimmed or excised altogether.\\r\\n\\r\\nThese scenes were as follows:[79]\\r\\n\\r\\nAfter the 1956 re-release, the film was sold to television (first being broadcast March 5, 1956).[80]\\r\\n\\r\\nRKO had failed to preserve copies of film's negative or release prints with the excised footage, and the cut scenes were considered lost for years. In 1969, a 16mm print, including the censored footage, was found in Philadelphia. The cut scenes were added to the film, restoring it to its original theatrical running time of 100 minutes. This version was re-released to art houses by Janus Films in 1970.[79]\\r\\n\\r\\nOver the next two decades, Universal Studios carried out further photochemical restoration on King Kong. This was based on a 1942 release print, with missing censor cuts taken from a 1937 print, which \\"contained heavy vertical scratches from projection.\\"[81] An original release print located in the UK in the 1980s was found to contain the cut scenes in better quality.\\r\\n\\r\\nAfter a 6-year worldwide search for the best surviving materials, a further, fully digital, restoration utilizing 4K resolution scanning was completed by Warner Bros. in 2005.[82] This restoration also had a 4-minute overture added, bringing the overall running time to 104 minutes. King Kong was also, somewhat controversially, colorized in the late 1980s for television.[83]\\r\\n\\r\\nIn 1984, King Kong was one of the first films to be released on LaserDisc by the Criterion Collection, and was the very first movie to have an audio commentary track included. Criterion's audio commentary was by film historian Ron Haver; in 1985 Image Entertainment released another LaserDisc, this time with a commentary by film historian and soundtrack producer Paul Mandell. Neither of these commentaries has since resurfaced on any other format.\\r\\n\\r\\nKing Kong had numerous VHS and LaserDisc releases of varying quality prior to receiving an official studio release on DVD. Those included a Turner 60th anniversary edition in 1993 featuring a front cover which had the sound effect of Kong roaring when his chest was pressed. It also included the colorized version of the film and a 25-minute documentary, It Was Beauty Killed the Beast (1992). The documentary is also available on two different UK King Kong DVDs, while the colorized version is available on DVD in the UK and Italy.[84] Warner Home Video re-released the black and white version on VHS with the 25-minute documentary included under the Warner Bros. Classics label in 1999.\\r\\n\\r\\nIn 2005 Warner Bros released their digital restoration of King Kong in a US 2-disc Special Edition DVD, coinciding with the theatrical release of Peter Jackson's remake. It had numerous extra features, including a new, third audio commentary by visual effects artists Ray Harryhausen and Ken Ralston, with archival excerpts from actress Fay Wray and producer/director Merian C. Cooper. Warners issued identical DVDs in 2006 in Australia and New Zealand, followed by a US digibook-packaged Blu-ray in 2010.[85] In 2014 the Blu-ray was repackaged with three unrelated films in a 4 Film Favorites: Colossal Monster Collection.\\r\\n\\r\\nAt present, Universal holds worldwide rights to Kong's home video releases outside of the US, Australia and New Zealand. All Universal's releases only contain their earlier, 100 minute, pre-2005 restoration.[82] However, in the UK, Warner Home Video released the film digitally and on Blu-Ray & DVD in early 2017. The Blu-Ray contained the same contents as the  US release, but unfortunately for the DVD, that was based on the first Disc of the 2-Disc DVD release.\\r\\n\\r\\nThe 1933 King Kong film and character inspired imitations and installments. Son of Kong, a direct sequel to the 1933 film was released nine months after the first film's release. In the early 1960s, RKO had licensed the King Kong character to Japanese studio Toho and produced two King Kong films, King Kong vs. Godzilla (a crossover with the Godzilla series) and King Kong Escapes, both directed by Ishir Honda.\\r\\n\\r\\nIn 1976, Italian producer Dino De Laurentiis released his version of King Kong, a modern remake of the 1933 film, which was followed by a sequel in 1986 titled King Kong Lives. In 2005, Universal Pictures released another remake of King Kong, directed by Peter Jackson. Legendary Pictures and Warner Bros. released a Kong reboot film titled Kong: Skull Island in 2017 which was directed by Jordan Vogt-Roberts and is the second installment of a shared universe called the MonsterVerse, which started with Legendary's reboot of  Godzilla.","input":"What animals fur was used for king kong?"},{"output":"The Ordinary Fear of God","context":"\\r\\n\\r\\nRussell Ira Crowe (born 7 April 1964) is an actor, film producer and musician. Although a New Zealand citizen, he has lived most of his life in Australia.[1] He came to international attention for his role as the Roman General Maximus Decimus Meridius in the 2000 historical epic film Gladiator, directed by Ridley Scott, for which Crowe won an Academy Award for Best Actor, a Broadcast Film Critics Association Award for Best Actor, an Empire Award for Best Actor and a London Film Critics Circle Award for Best Actor and 10 further nominations for best actor.\\r\\n\\r\\nCrowe appeared as the tobacco firm whistle blower Jeffrey Wigand in the 1999 film The Insider, for which he received five awards as best actor and seven nominations in the same category. In 2001, Crowe's portrayal of mathematician and Nobel Prize winner John F. Nash in the biopic A Beautiful Mind brought him numerous awards, including a BAFTA Award for Best Actor in a Leading Role, a Golden Globe Award for Best Actor in a Motion Picture Drama and a Screen Actors Guild Award for Outstanding Performance by a Male Actor in a Leading Role.\\r\\n\\r\\nCrowe's other films include Romper Stomper (1992), L.A. Confidential (1997), Master and Commander: The Far Side of the World (2003), Cinderella Man (2005), American Gangster (2007), State of Play (2009), Robin Hood (2010), Les Misrables (2012), Man of Steel (2013) and Noah (2014). In 2015, Crowe made his directorial debut with The Water Diviner, in which he also starred. Crowe's work has earned him several accolades during his career and including a star on the Hollywood Walk of Fame, three consecutive Academy Award nominations (1999ÿ2001), one Golden Globe Award for Best Actor, one BAFTA, and an Academy Award. Crowe has also been the co-owner of the National Rugby League (NRL) team South Sydney Rabbitohs since 2006.\\r\\n\\r\\nCrowe was born on 7 April 1964 in the Wellington suburb of Strathmore Park,[2][3] the son of Jocelyn Yvonne (ne Wemyss) and John Alexander Crowe,[4] both of whom were film set caterers; his father also managed a hotel.[3] Crowe's maternal grandfather, Stan Wemyss, was a cinematographer who was named an MBE for filming footage of World War II.[5] Crowe's paternal grandfather, John Doubleday Crowe, was from Wrexham, Wales,[6][7] while one of Crowe's maternal great-great-grandmothers was Mori.[4][8] Crowe also has English, German, Irish, Italian, Norwegian, Scottish, Swedish, and Welsh ancestry.[9][10][11][12][13] He is a cousin of former New Zealand cricket captains Martin Crowe and Jeff Crowe,[14] and nephew of cricketer Dave Crowe.[15] Russell has built a cricket field named for his uncle.[citation needed]\\r\\n\\r\\nWhen Crowe was four years old, his family moved to Sydney, Australia, where his parents pursued a career in set catering.[4] The producer of the Australian TV series Spyforce was his mother's godfather, and Crowe (at age five or six) was hired for a line of dialogue in one episode, opposite series star Jack Thompson (in 1994 Thompson played the father of Crowe's character in The Sum of Us).[citation needed] Crowe also appeared briefly in the serial The Young Doctors.\\r\\n\\r\\nCrowe was educated at Vaucluse Public School but later moved to Sydney Boys High School.[4] When he was 14, his family moved back to New Zealand where, along with his brother Terry, he attended Auckland Grammar School with cousins Martin Crowe and Jeff Crowe. He then continued his secondary education at Mount Roskill Grammar School, which he left at the age 16 to pursue his ambition of becoming an actor.[citation needed]\\r\\n\\r\\nCrowe began his performing career as a musician in the early 1980s, under guidance from his good friend Tom Sharplin, when he performed under the stage name \\"Russ Le Roq\\". He released several New Zealand singles including \\"I Just Want To Be Like Marlon Brando\\", \\"Pier 13\\", \\"Shattered Glass\\", none of which charted.[16] He managed an Auckland music venue called \\"The Venue\\" in 1984.[17] When he was 18, he was featured in A Very Special Person..., a promotional video for the theology/ministry course at Avondale College, a Seventh-day Adventist tertiary education provider in New South Wales.[18]\\r\\n\\r\\nCrowe returned to Australia at age 21, intending to apply to the National Institute of Dramatic Art. \\"I was working in a theatre show, and talked to a guy who was then the head of technical support at NIDA\\", Crowe has recalled. \\"I asked him what he thought about me spending three years at NIDA. He told me it'd be a waste of time. He said, 'You already do the things you go there to learn, and you've been doing it for most of your life, so there's nothing to teach you but bad habits.'\\"[19] From 1986 to 1988, he was given his first professional role by director Daniel Abineri, in a New Zealand production of The Rocky Horror Show.[4] He played the role of Eddie/Dr Scott.[4] He repeated this performance in a further Australian production of the show, which also toured New Zealand.[20] In 1987, Crowe spent six months busking when he could not find other work.[citation needed] In the 1988 Australian production of Blood Brothers, Crowe played the role of Mickey.[citation needed] He was also cast again by Daniel Abineri in the role of Johnny, in the stage musical Bad Boy Johnny and the Prophets of Doom in 1989.[citation needed]\\r\\n\\r\\nAfter appearing in the TV series Neighbours and Living with the Law, Crowe was cast by Faith Martin in his first film, The Crossing (1990), a small-town love triangle directed by George Ogilvie. Before production started, a film-student protg of Ogilvie, Steve Wallace, hired Crowe for the film Blood Oath (1990) (aka Prisoners of the Sun), which was released a month earlier than The Crossing, although actually filmed later. In 1992, Crowe starred in the first episode of the second series of Police Rescue. Also in 1992, Crowe starred in Romper Stomper, an Australian film which followed the exploits and downfall of a racist skinhead group in blue-collar suburban Melbourne, directed by Geoffrey Wright and co-starring Jacqueline McKenzie. For the role, Crowe won an Australian Film Institute (AFI) award for Best Actor, following up from his Best Supporting Actor award for Proof in 1991.[4]\\r\\nIn 2015 it was reported that Crowe had applied for Australian citizenship in 2006 and again in 2013 but was rejected because he failed to fulfill the residency requirements.[1] However, Australia's Immigration Department said it had no record of any such application by Crowe.[21]\\r\\n\\r\\nAfter initial success in Australia, Crowe first starred in a Canadian production in 1993, For the Moment, before concentrating on American films. He co-starred with Denzel Washington in Virtuosity (the duo later appearing together in American Gangster) and with Sharon Stone in The Quick and the Dead in 1995.[4] He went on to become a three-time Oscar nominee, winning the Academy Award as Best Actor in 2000 for Gladiator.[4] Crowe was awarded the (Australian) Centenary Medal in 2001 for \\"service to Australian society and Australian film production.\\"[22]\\r\\n\\r\\nCrowe received three consecutive best actor Oscar nominations, for The Insider, Gladiator and A Beautiful Mind.[4] Crowe won the best actor award for A Beautiful Mind at the 2002 BAFTA award ceremony, as well as the Golden Globe and Screen Actors Guild Award for the same performance. Although nominated for an Academy Award, he lost to Denzel Washington.\\r\\n\\r\\nAll three films were also nominated for best picture, and both Gladiator and A Beautiful Mind won the award. Within the six-year stretch from 1997 to 2003, he also starred in two other best picture nominees, L.A. Confidential and Master and Commander: The Far Side of the World. In 2005, he re-teamed with A Beautiful Mind director Ron Howard for Cinderella Man. In 2006, he re-teamed with Gladiator director Ridley Scott for A Good Year, the first of two consecutive collaborations (the second being American Gangster co-starring again with Denzel Washington, released in late 2007). While the light romantic comedy of A Good Year was not greatly received, Crowe seemed pleased with the film, telling STV in an interview that he thought it would be enjoyed by fans of his other films.[23]\\r\\n\\r\\nIn recent years, Crowe's box office standing has declined.[24] The Hollywood stock market (HSX) share Russell Crowe (RCROW), issued in 1998, however maintains constant accretion.[25] Crowe appeared in Robin Hood, a film based on the Robin Hood legend, directed by Ridley Scott and released on 14 May 2010.[26]\\r\\nCrowe starred in the 2010 Paul Haggis film The Next Three Days, an adaptation of the 2008 French film Pour Elle.[27]\\r\\n\\r\\nAfter a year off from acting, Crowe played Jackknife in The Man with the Iron Fists, opposite RZA. He took on the role of Inspector Javert in the musical film of Les Misrables (2012),[28] and portrayed Superman's biological father, Jor-El, in the Christopher Nolan produced Superman film, Man of Steel, released in the summer of 2013. In 2014, he played a gangster in the film adaptation of Mark Helprin's 1983 novel Winter's Tale, and the title role in the Darren Aronofsky film Noah.[29] In June 2013, Crowe signed to make his directional debut with an historical drama film The Water Diviner, which he also starred in alongside Jacqueline McKenzie, Olga Kurylenko, Jai Courtney.[30] Set in the year 1919, the film was produced by Troy Lum, Andrew Mason and Keith Rodger.[31] Crowe also starred in The Mummy (2017).\\r\\n\\r\\nIn the 1980s, Crowe, under the name of \\"Russ le Roq\\", recorded a song titled \\"I Want To Be Like Marlon Brando\\".[32]\\r\\n\\r\\nIn the 1980s, Crowe and friend Billy Dean Cochran formed a band, Roman Antix, which later evolved into the Australian rock band 30 Odd Foot of Grunts (abbreviated to TOFOG). Crowe performed lead vocals and guitar for the band, which formed in 1992. The band released The Photograph Kills EP in 1995, as well as three full-length records, Gaslight (1998), Bastard Life or Clarity (2001) and Other Ways of Speaking (2003). In 2000, TOFOG performed shows in London, Los Angeles and the now famous run of shows at Stubbs in Austin, Texas which became a live DVD that was released in 2001, called Texas. In 2001, the band came to the US for major press, radio and TV appearances for the Bastard Life or Clarity release and returned to Stubbs in Austin, Texas to kick off a sold out US tour with dates in Austin, Boulder, Chicago, Portland, San Francisco, Los Angeles, Philadelphia, New York City and the last show at the famous Stone Pony in Asbury Park, New Jersey.\\r\\n\\r\\nIn early 2005, 30 Odd Foot of Grunts as a group had \\"dissolved/evolved\\" with Crowe feeling his future music would take a new direction. He began a collaboration with Alan Doyle of the Canadian band Great Big Sea, and with it a new band emerged: The Ordinary Fear of God which also involved some members of the previous TOFOG line-up. A new single, Raewyn, was released in April 2005 and an album entitled My Hand, My Heart which was released and is available for download on iTunes. The album includes a tribute song to actor Richard Harris, who became Crowe's friend during the making of Gladiator.\\r\\n\\r\\nRussell Crowe & The Ordinary Fear of God set out to break the new band in by performing a successful sold out series of dates of Australia in 2005, and then in 2006, returned to the US to promote their new release My Hand, My Heart with another sold-out US Tour and major press, radio and television appearances.\\r\\nIn March 2010, Russell Crowe & The Ordinary Fear of God's version of the John Williamson song \\"Winter Green\\" was included on a new compilation album The Absolute Best of John Williamson: 40 Years True Blue, commemorating the singer-songwriter's milestone of 40 years in the Australian music industry. As of May 2011, there are plans to release a new Russell Crowe & The Ordinary Fear of God recording (co-written with Alan Doyle) and for a US tour which would be the first live dates in the US since 2006.\\r\\n\\r\\nOn 2 August 2011, the third collaboration between Crowe and Doyle was released on iTunes as The Crowe/Doyle Songbook Vol III, featuring nine original songs followed by their acoustic demo counterparts (for a total of 18 tracks). Danielle Spencer does guest vocals on most tracks. The release coincided with a pair of live performances at the LSPU Hall in St. John's, Newfoundland.[33] The digital album was released as download versions only on Amazon.com, iTunes, spotify. The album has since charted at No. 72 on the Canadian Albums Chart.[34]\\r\\nOn 26 September 2011, Crowe appeared on-stage at Rogers Arena in Vancouver in the middle of Keith Urban's concert. He sang a cover of Folsom Prison Blues, before joining the rest of the band in a rendition of \\"The Joker\\".[35] On 18 August 2012, Crowe appeared along with Doyle at the Harpa Concert Hall in Reykjavk, Iceland as part of the city's Menningarn܇tt program. They also appeared at downtown bars, Gaukurinn and Kex.[36]\\r\\n\\r\\nDuring location filming of Cinderella Man, Crowe made a donation to a Jewish elementary school whose library had been damaged as a result of arson.[37] A note with an anti-Semitic message had been left at the scene.[38] Crowe called school officials to express his concern and wanted his message relayed to the students.[39] The school's building fund received donations from throughout Canada and the amount of Crowe's donation was not disclosed.[40]\\r\\n\\r\\nOn another occasion, Crowe donated $200,000 to a struggling primary school near his home in rural Australia. The money went towards an $800,000 project to construct a swimming pool at the school. Crowe's sympathies were sparked when a pupil drowned at the nearby Coffs Harbour beach in 2001, and he felt the pool would help students become better swimmers and improve their water safety. At the opening ceremony, he dove into the pool fully clothed as soon as it was declared open. Nana Glen principal Laurie Renshall said, \\"The many things he does up here, people just don't know about. We've been trying to get a pool for 10 years.\\"[41]\\r\\n\\r\\nCrowe began an on-again, off-again relationship with Australian singer Danielle Spencer in 1989, when they co-starred in the 1990 film The Crossing.[42] In 2000, Crowe was romantically involved with his co-star Meg Ryan while on the set of their film Proof of Life.[43] Crowe and Spencer reconciled in 2001, and married in April 2003 (on Crowe's 39th birthday) at his cattle property in Nana Glen, New South Wales.[42][44] They have two sons: Charles Spencer Crowe (born 21 December 2003)[45] and Tennyson Spencer Crowe (born 7 July 2006).[46] In October 2012, it was reported that Crowe and Spencer had separated;[47][48] they divorced in April 2018.[49]\\r\\n\\r\\nCrowe resides in Australia.[50] In 2011, he and his family moved to a house in Sydney's affluent Rose Bay.[51] Crowe also owns a house in the North Queensland city of Townsville, purchased in May 2008.[52] He is reportedly frugal with money, and is known to drive an old Jeep.[53]\\r\\n\\r\\nIn the beginning of 2009, despite not having Australian citizenship, Crowe appeared in a series of special edition postage stamps called \\"Legends of the Screen\\", featuring Australian actors. He, Geoffrey Rush, Cate Blanchett and Nicole Kidman each appear twice in the series, once as themselves and once as their Academy Award-winning character.[54]\\r\\n\\r\\nCrowe stated in November 2007 that he would like to be baptised as a Christian and felt that he had put it off for too long. \\"I do believe there are more important things than what is in the mind of a man\\", he said. \\"There is something much bigger that drives us all. I'm willing to take that leap of faith.\\"[55]\\r\\n\\r\\nIn June 2010, Crowe, who started smoking when he was 10, announced he had quit for the sake of his two sons.[56] In November 2010, Crowe told David Letterman that he had smoked more than 60 cigarettes a day for 36 years, and that he had fallen off the wagon the previous night and smoked heavily.[57]\\r\\n\\r\\nOn 9 March 2005, Crowe revealed to GQ magazine that Federal Bureau of Investigation (FBI) agents had approached him prior to the 73rd Academy Awards in March 2001, and told him that the terrorist group al-Qaeda wanted to kidnap him.[58] Crowe recalled: \\"It was something to do with some recording picked up by a French policewoman, I think, in either Libya or Algiers... It was about taking iconographic Americans out of the picture as a sort of cultural destabilisation plan.\\"[59]\\r\\n\\r\\nBetween 1999 and 2005, Crowe was involved in four altercations which gave him a reputation for having a bad temper.[60]\\r\\n\\r\\nIn 1999, Crowe was involved in a scuffle at the Plantation Hotel in Coffs Harbour, Australia, which was caught on security video.[61] Two men were acquitted of using the video in an attempt to blackmail Crowe.[62]\\r\\n\\r\\nFour years later, when part of Crowe's appearance at the 2002 BAFTA awards was cut out to fit into the BBC's tape-delayed broadcast, Crowe used strong language during an argument with producer Malcolm Gerrie. The part cut was a poem in tribute to actor Richard Harris, and it was cut for copyright reasons. Crowe later apologised, saying \\"What I said to him may have been a little bit more passionate than now, in the cold light of day, I would have liked it to have been.\\"[63]\\r\\n\\r\\nLater that year, Crowe was alleged to have been involved in a brawl with businessman and fellow New Zealander Eric Watson inside the London branch of Zuma, a fashionable Japanese restaurant chain. The fight was broken up by British actor Ross Kemp.[64][65]\\r\\n\\r\\nIn June 2005, Crowe was arrested and charged with second-degree assault by New York City police after he threw a telephone at the concierge of the Mercer Hotel, who refused to help him place a call when the system did not work from Crowe's room. He was also charged with fourth-degree criminal possession of a weapon (the telephone).[66] The concierge was treated for a facial laceration.[67] After his arrest, Crowe underwent a perp walk, a procedure customary in New York City, exposing the handcuffed suspect to the news media to take pictures. This procedure was under discussion as potentially violating Article 5 of the Universal Declaration of Human Rights. Crowe later described the incident as \\"possibly the most shameful situation that I've ever gotten myself in...\\" .[68] Crowe pleaded guilty and was conditionally discharged. Before the trial, he settled a lawsuit filed by the concierge, Nestor Estrada.[69][70] Terms of the settlement were not disclosed, but amounts in the six-figure range have been reported.[71]\\r\\n\\r\\nThe telephone incident had a generally negative impact on Crowe's public image, an example of negative public relations in the mass media, although Crowe had made a point of befriending Australian journalists in an effort to influence his image.[72] A professional public image as \\"The Gladiator\\" had to compete alongside one as \\"the telephone throwing actor\\". For example, the South Park episode, \\"The New Terrance and Phillip Movie Trailer\\" revolves around a lampooning of his aggressive tendencies. Crowe commented on the ongoing media perpetuation in November 2010, five years into the process, during an interview with American television talk show host and journalist Charlie Rose: \\"it affected me psychologically\\" (...) \\"it indelibly changed me.\\"[73]\\r\\n\\r\\nCrowe says he follows New Zealand's rugby union team, the All Blacks, and Australia in any other sport.[74] Two of his cousins, Martin Crowe and Jeff Crowe, captained the Black Caps New Zealand international cricket team.[75]\\r\\n\\r\\nCrowe has been a supporter of the rugby league football team the South Sydney Rabbitohs since childhood. Since his rise to fame as an actor, he has continued appearing at home games, and supported the financially troubled club. Following the Super League war of the 1990s Crowe made an attempt to use his Hollywood connections to convince Ted Turner, rival of Super League's Rupert Murdoch, to save the Rabbitohs before they were forced from the National Rugby League competition for two years.[76] In 1999 Crowe paid $42,000 at auction for the brass bell used to open the inaugural rugby league match in Australia in 1908 at a fund-raiser to assist Souths' legal battle for re-inclusion in the League.[77] In 2005, he made the Rabbitohs the first club team in Australia to be sponsored by a film, when he negotiated a deal to advertise his film Cinderella Man on their jerseys.[78]\\r\\nOn 19 March 2006, the voting members of the South Sydney club voted (in a 75.8% majority) to allow Crowe and businessman Peter Holmes  Court to purchase 75% of the organisation, leaving 25% ownership with the members. It cost them A$3?million, and they received four of eight seats on the board of directors. A six-part television miniseries entitled South Side Story depicting the takeover aired in Australia in 2007.[79]\\r\\nOn 5 November 2006, Crowe appeared on The Tonight Show with Jay Leno to announce that Firepower International was sponsoring the South Sydney Rabbitohs for $3?million over three years.[80] During a Tonight Show with Jay Leno appearance, Crowe showed viewers a Rabbitoh playing jersey with Firepower's name emblazoned on it.[81]\\r\\n\\r\\nCrowe helped to organise a rugby league game that took place at the University of North Florida, in Jacksonville, Florida, between the South Sydney Rabbitohs and the European Super League champions Leeds Rhinos on 26 January 2008 (Australia Day).[82] Crowe told ITV Local Yorkshire the game was not a marketing exercise.[83]\\r\\nCrowe wrote a letter of apology to a Sydney newspaper following the sacking of South Sydney's coach Jason Taylor and one of their players David Fa'alogo after a drunken altercation between the two at the end of the 2009 NRL season.[84]\\r\\nAlso in 2009 Crowe persuaded young England international forward Sam Burgess to sign with the Rabbitohs over other clubs that were competing for his signature, after inviting Burgess and his mother to the set of Robin Hood, which he was filming in Britain at the time.[85]\\r\\n\\r\\nCrowe's influence helped to persuade noted player Greg Inglis to renege on his deal to join the Brisbane Broncos and sign for the Rabbitohs for 2011.[86]\\r\\nIn 2010, the NRL was investigating Crowe's business relationships with a number of media and entertainment companies including Channel Nine, Channel Seven, ANZ Stadium, and V8 Supercars in relation to the South Sydney Rabbitohs' salary cap.[87]\\r\\n\\r\\nIn 2011, Souths also announced a corporate partnership with the bookmaking conglomerate Luxbet.[88]\\r\\nPreviously, Crowe had been prominent in trying to prevent gambling being associated with the Rabbitohs.[89]\\r\\nIn May 2011, Crowe helped arrange to have Fox broadcast the 2011 State of Origin series live for the first time in the United States, in addition to the NRL Grand Final.[90]\\r\\nIn November 2012 the South Sydney Rabbitohs confirmed that Russell Crowe was selling his 37.5 percent stake in the club.[91]\\r\\nAt the Rabbitohs Annual General Meeting on 3 March 2013, Chairman Nick Pappas claimed Crowe \\"would not be selling his shareholding in the short-to-medium term and at this stage has no intention of selling at all\\".[92]\\r\\n\\r\\nCrowe was a guest presenter at the 2013 Dally M Awards[93] and presented the prestigious Dally M Medal to winner Cooper Cronk.[94] Russell was present at the 2014 NRL Grand Final when the Rabbitohs won the NRL premiership for the first time in 43 years.[95]\\r\\n\\r\\nCrowe watches and plays cricket, and captained the 'Australian' Team containing Steve Waugh against an English side in the 'Hollywood Ashes' Cricket Match.[96] On 17 July 2009 Crowe took to the commentary box for the British sports channel, Sky Sports, as the 'third man' during the second Test of the 2009 Ashes series, between England and Australia.[97] He is friends with Lloyd Carr, the former coach of the University of Michigan Wolverines American football team, and Carr used Crowe's movie Cinderella Man to motivate his 2006 team following a 7ÿ5 season the previous year. Upon hearing of this, Crowe called Carr and invited him to Australia to address his Rugby league team, the South Sydney Rabbitohs, which Carr did the following summer. In September 2007, after Carr came under fire following the Wolverines' 0ÿ2 start, Crowe travelled to Ann Arbor, Michigan for the Wolverines' 15 September game against Notre Dame to show his support for Carr. He addressed the team before the game and watched from the sidelines as the Wolverines defeated the Irish 38ÿ0.[citation needed]\\r\\nCrowe is also a fan of the National Football League. On 22 October 2007, Crowe appeared in the booth of a Monday night game between the Indianapolis Colts and the Jacksonville Jaguars.[98]\\r\\n\\r\\nCrowe has appeared in 43 films and three television series since his career began in 1985. He won the Academy Award for Best Actor for Gladiator (2000) and was nominated twice more for The Insider (1999) and A Beautiful Mind (2001), making him the ninth actor to receive three consecutive Academy Award nominations.[4] He has also received five Golden Globe Award nominations (winning one), three BAFTA Award nominations (winning one), and three Screen Actors Guild Award nominations (winning one).","input":"What is the name of russell crowe's band?"},{"output":"12 to 14 days","context":"The house finch (Haemorhous mexicanus) is a bird in the finch family Fringillidae. It is native to western North America, and has been introduced to the eastern half of the continent and Hawaii. This species and the other \\"American rosefinches\\" are placed in the genus Haemorhous.\\r\\n\\r\\n\\r\\nThis is a moderately-sized finch. Adult birds are 12.5 to 15?cm (4.9 to 5.9?in) and span 20 to 25?cm (7.9 to 9.8?in). Body mass can vary from 16 to 27?g (0.56 to 0.95?oz), with an average weight of 21?g (0.74?oz). Among standard measurements, the wing chord is 7 to 8.4?cm (2.8 to 3.3?in), the tail is 5.7 to 6.5?cm (2.2 to 2.6?in), the culmen is 0.9 to 1.1?cm (0.35 to 0.43?in) and the tarsus is 1.6 to 1.8?cm (0.63 to 0.71?in).[2] Adults have a long, square-tipped brown tail and are a brown or dull-brown color across the back with some shading into deep gray on the wing feathers. Breast and belly feathers may be streaked; the flanks usually are. In most cases, adult males' heads, necks and shoulders are reddish.[3][4] This color sometimes extends to the belly and down the back, between the wings. Male coloration varies in intensity with the seasons[5] and is derived from the berries and fruits in its diet.[6] As a result, the colors range from pale straw-yellow through bright orange (both rare) to deep, intense red. Adult females have brown upperparts and streaked underparts.\\r\\nTheir song is a rapid, cheery warble or a variety of chirps.[citation needed]\\r\\nThis bird belongs to the genus Haemorhous, together with the purple finch and Cassin's finch. These three species are not closely related to the Old World Carpodacus rosefinches.[7][8]\\r\\nThese birds are mainly permanent residents throughout their range; some northern and eastern birds migrate south.[9] Their breeding habitat is urban and suburban areas across North America, as well as various semi-open areas in the west from southern Canada to the Mexican state of Oaxaca; the population in central Chiapas may be descended from escaped cagebirds.[4]\\r\\nOriginally only a resident of Mexico and the southwestern United States, they were introduced to eastern North America in the 1940s. The birds were sold illegally in New York City[6] as \\"Hollywood Finches\\", a marketing artifice.[5] To avoid prosecution under the Migratory Bird Treaty Act of 1918, vendors and owners released the birds. They have since become naturalized; in largely unforested land across the eastern U.S., they have displaced the native purple finch and even the non-native house sparrow.[10] In 1870, or before, they were introduced to Hawaii and are now abundant on all its major islands.[11]\\r\\nThere are estimated to be anywhere from 267 million to 1.7 billion individuals across North America.[6]\\r\\nHouse finches forage on the ground or in vegetation normally. They primarily eat grains, seeds and berries, being voracious consumers of weed seeds such as nettle and dandelion; included are incidental small insects such as aphids. They are frequent visitors to bird feeders throughout the year, particularly if stocked with sunflower or nyjer seed, and will congregate at hanging nyjer sock feeders. The house finch is known to damage orchard fruit and consume commercially grown grain but is generally not considered a significant pest but rather an annoyance.[12]\\r\\nNests are made in cavities, including openings in buildings, hanging plants, and other cup-shaped outdoor decorations. Sometimes nests abandoned by other birds are used. Nests may be re-used for subsequent broods or in following years. The nest is built by the female, sometimes in as little as two days.[13] It is well made of twigs and debris, forming a cup shape, usually 1.8 to 2.7?m (5.9 to 8.9?ft) above the ground.[13]\\r\\nDuring courtship, the male will touch bills with the female. He may then present the female with choice bits of food, and if she mimics the behavior of a hungry chick, he may actually feed her. The male also feeds the female during the breeding and incubation of both eggs and young,[14] and the male is the primary feeder of the fledgelings (who can be differentiated from the females by the pin feathers remaining on their heads). Females are typically attracted to the males with the deepest pigment of red to their head, more so than the occasional orange or yellowish-headed males that sometimes occur.[6]\\r\\nThe female lays clutches of eggs from February through August, two or more broods per year with 2 to 6 eggs per brood, most commonly 4 or 5. The egg laying usually takes place in the morning, at the rate of one egg per day.[14] The eggs are a pale bluish green with few black spots and a smooth, somewhat glossy surface. In response to mite infestation, which has a more deleterious effect on male chicks than on females, the mother finch may lay eggs containing females first, in order to reduce the length of time male chicks are exposed to mites. This strategy increases the liklihood that representative numbers of both sexes will survive.[15] The female incubates the eggs for 12 to 14 days. Shortly after hatching, she removes the empty eggshells from the nest.[16][17] The hatchlings are pink with closed eyes and tufts of fluffy down.[18] The female always feeds the young, and the male usually joins in.[14] The young are silent for the first seven or eight days, and subsequently start peeping during feedings.[13] Initially, the mother carries fecal sacs out of the nest, but when the young become older, she no longer carries them all away, allowing droppings to accumulate around the edge of the nest.[13] Before flying, the young often climb into adjacent plants, and usually fledge at about 11 to 19 days after hatching.[13] Dandelion seeds are among the preferred seeds fed to the young.[16] Most birds, even ones with herbivorous leanings as adults, tend to feed their nestlings animal matter in order to give them the protein necessary to grow. House finches are one of the few birds who feed their young only plant matter.[6]\\r\\nHouse finches are aggressive enough to drive other birds away from places such as feeders.[19]\\r\\nThe house finch may be infected by a number of parasites including Plasmodium relictum[20] and Mycoplasma gallisepticum, which caused the population of house finches in eastern North America to crash during the 1990s.[21]\\r\\nThe mite Pellonyssus reedi is often found on house finch nestlings, particularly for nests later in the season.[22]\\r\\nThe brown-headed cowbird, a brood parasite, will lay its eggs in house finch nests, although the diet house finches feed their young is inadequate for the young cowbirds, which rarely survive.[23]","input":"How long do finch eggs take to hatch?"},{"output":"Pytheas","context":"Arctic exploration is the physical exploration of the Arctic region of the Earth. It refers to the historical period during which mankind has explored the region north of the Arctic Circle. Historical records suggest that humankind have explored the northern extremes since 325 BC, when the ancient Greek sailor Pytheas reached a frozen sea while attempting to find a source of the metal tin.[1] Dangerous oceans and poor weather conditions often fetter explorers attempting to reach polar regions and journeying through these perils by sight, boat, and foot has proven difficult.[1]\\r\\n\\r\\n\\r\\nSome scholars believe that the first attempts to penetrate the Arctic Circle can be traced to ancient Greece and the sailor Pytheas, a contemporary of Aristotle and Alexander the Great, who, in c. 325 BC, attempted to find the source of the tin that would sporadically reach the Greek colony of Massilia (now Marseille) on the Mediterranean coast.[1] Sailing past the Pillars of Hercules, he reached Brittany and even Cornwall, eventually circumnavigating the British Isles. From the local population, he heard news of the mysterious land of Thule, even farther to the north. After six days of sailing, he reached land at the edge of a frozen sea (described by him as \\"curdled\\"), and described what is believed to be the aurora and the midnight sun. While some historians claim that this new land of Thule was the Norwegian coast or the Shetland Islands, based on his descriptions and the trade routes of early British sailors, it is possible that Pytheas reached as far as Iceland.\\r\\nWhile no one knows exactly how far Pytheas sailed, he may have crossed the Arctic Circle. Nevertheless, his tales were regarded as fantasy by later Greek and Roman authorities,[citation needed] such as the geographer Strabo. It was impossible, according to their perception of the world, for man to survive in these 'uninhabitable reaches'.[citation needed]\\r\\nThe first Viking to sight Iceland was Gardar Svavarsson, who went off course due to harsh conditions when sailing from Norway to the Faroe Islands. This quickly led to a wave of colonization.[citation needed] Not all the settlers were successful however in the attempts to reach the island. In the 10th century, Gunnbj?rn Ulfsson got lost in a storm and ended up within sight of the Greenland coast. His report spurred Erik the Red, an outlawed chieftain, to establish a settlement there in 985. While they flourished initially, these settlements eventually foundered due to changing climatic conditions (see Little Ice Age).[citation needed] They are believed to have survived until around 1450.\\r\\nGreenland's early settlers sailed westward, in search of better pasturage and hunting grounds. Modern scholars debate the precise location of the new lands of Vinland, Markland, and Helluland that they discovered.[citation needed]\\r\\nThe Scandinavian peoples also pushed farther north into their own peninsula by land and by sea. As early as 880, the Viking Ohthere of H?logaland rounded the Scandinavian Peninsula and sailed to the Kola Peninsula and the White Sea. The Pechenga Monastery on the north of Kola Peninsula was founded by Russian monks in 1533; from their base at Kola, the Pomors explored the Barents Region, Spitsbergen, and Novaya Zemlyaall of which are in the Arctic Circle. They also explored north by boat, discovering the Northern Sea Route, as well as penetrating to the trans-Ural areas of northern Siberia. They then founded the settlement of Mangazeya east of the Yamal Peninsula in the early 16th century.[citation needed] In 1648 the Cossack Semyon Dezhnyov opened the now famous Bering Strait between America and Asia.\\r\\nRussian settlers and traders on the coasts of the White Sea, the Pomors, had been exploring parts of the northeast passage as early as the 11th century. By the 17th century they established a continuous sea route from Arkhangelsk as far east as the mouth of Yenisey. This route, known as Mangazeya seaway, after its eastern terminus, the trade depot of Mangazeya, was an early precursor to the Northern Sea Route.\\r\\nExploration above the Arctic Circle in the Renaissance was driven by the rediscovery of Classical learning and the national quests for commercial expansion. This exploration was hampered by limits in maritime technology of the age, lack of shelf-stable food supplies, and insufficient insulation for ships' crew against extreme cold.\\r\\nA seminal event in Arctic exploration occurred in 1409, when Ptolemy's Geographia was translated into Latin, thereby introducing the concepts of latitude and longitude into Western Europe.[2] Navigators were better able to chart their positions, and the European race to China, sparked by interest in the writings of Marco Polo, commenced.[citation needed] Just two years after Columbus in 1494, the Treaty of Tordesillas divided the Atlantic Ocean between Spain and Portugal. Forced to seek other routes to the Orient, rival countries like England, began considering the northern route over the top of the globe.\\r\\nThe Inventio Fortunata, a lost book said to be a description of travels in the North Atlantic by an unknown Friar, describes, in a summary written by Jacobus Cnoyen but only found in a letter from Gerardus Mercator, voyages as far as the North Pole.[3] One widely disputed claim is that two brothers from Venice, Niccolo and Antonio Zeno, allegedly made a map of their journeys to that region, which were published by their descendants in 1558.[4]\\r\\nThe Northwest Passage is a sea route connecting the Atlantic and Pacific Oceans through the Arctic Ocean. Since the discovery of the American continent was the product of the search for a route to Asia, exploration around the northern edge of North America continued for the Northwest Passage.\\r\\nJohn Cabot's initial failure in 1497 to find a Northwest Passage across the Atlantic led the British to seek an alternative route to the east.\\r\\nInterest re-kindled in 1564 after Jacques Cartier's discovery of the mouth of the Saint Lawrence River. Martin Frobisher had formed a resolution to undertake the challenge of forging a trade route from England westward to India. In 1576 - 1578, he took three trips to what is now the Canadian Arctic in order to find the passage. Frobisher Bay, which he discovered, is named after him. In July 1583, Sir Humphrey Gilbert, who had written a treatise on the discovery of the passage and was a backer of Frobisher's, claimed the territory of Newfoundland for the English crown. On August 8, 1585, under the employ of Elizabeth I the English explorer John Davis entered Cumberland Sound, Baffin Island. Davis rounded Greenland before dividing his four ships into separate expeditions to search for a passage westward. Though he was unable to pass through the icy Arctic waters, he reported to his sponsors that the passage they sought is \\"a matter nothing doubtfull  [sic],\\"[citation needed] and secured support for two additional expeditions, reaching as far as Hudson Bay. Though England's efforts were interrupted in 1587 because of Anglo-Spanish War, Davis's favorable reports on the region and its people would inspire explorers in the coming century.[citation needed] In 1609, while in the service of the Dutch East India Company (VOC) and Dutch Republic, the English explorer Henry Hudson sailed up what is now called the Hudson River in search of the Passage; he reached present-day Albany, New York, before giving up. He later explored further north into the Arctic and Hudson Bay for the Passage.[5][6]\\r\\nThe Northeast Passage is a broad term for any route lying above the Eurasian continent and stretching between the waters north of the Norwegian Sea to the Bering Strait. The \\"Northern Sea Route\\" is defined as a specific portion of such routes. The Northern Sea Route (capitalized) including shipping lanes falling within Russia's EEZ and extending from the Kara Sea to the Bering Strait along the Russian northern coast as currently officially defined by Russian Federation law.\\r\\nThe idea to explore this region was initially economic, and was first put forward by Russian diplomat Dmitry Gerasimov in 1525. The entire route lies in Arctic waters and parts are only free of ice for about two months per year, making it a very perilous journey.[citation needed]\\r\\nIn the mid-16th century, John Cabot's son Sebastian helped organize just such an expedition, led by Sir Hugh Willoughby and Richard Chancellor. Willoughby's crew was shipwrecked off the Kola Peninsula, where they eventually died of scurvy. Chancellor and his crew made it to the mouth of the Dvina River, where they were met by a delegation from the Tsar, Ivan the Terrible. Brought back to Moscow, he launched the Muscovy Company, promoting trade between England and Russia. This diplomatic course allowed British Ambassadors such as Sir Francis Cherry the opportunity to consolidate geographic information developed by Russian merchants into maps for British exploration of the region. Some years later, Steven Borough, the master of Chancellor's ship, made it as far as the Kara Sea, when he was forced to turn back because of icy conditions.[7]\\r\\nWestern parts of the passage were simultaneously being explored by Northern European countries like England, the Netherlands, Denmark and Norway, looking for an alternative seaway to China and India. Although these expeditions failed, new coasts and islands were discovered.[citation needed] Most notable is the 1596 expedition led by Dutch navigator Willem Barentsz who discovered Spitsbergen and Bear Island.\\r\\nFearing English and Dutch penetration into Siberia, Russia closed the Mangazeya seaway in 1619. Pomor activity in Northern Asia declined and the bulk of exploration in the 17th century was carried out by Siberian Cossacks, sailing from one river mouth to another in their Arctic-worthy kochs. In 1648 the most famous of these expeditions, led by Fedot Alekseev and Semyon Dezhnev, sailed east from the mouth of Kolyma to the Pacific and doubled the Chukchi Peninsula, thus proving that there was no land connection between Asia and North America.[8] Eighty years after Dezhnev, in 1728, another Russian explorer, Danish-born Vitus Bering on Sviatoy Gavriil made a similar voyage in reverse, starting in Kamchatka and going north to the passage that now bears his name (Bering Strait). It was Bering who gave their current names to Diomede Islands, discovered and first described by Dezhnev.[9]\\r\\nIt was not until in 1878 that Finnish-Swedish explorer Adolf Erik Nordenski?ld made the first complete passage of the North East Passage from west to east, in the Vega expedition. The ship's captain on this expedition was Lieutenant Louis Palander of the Swedish Royal Navy.\\r\\nIn the first half of the 19th century, parts of the Northwest Passage were explored separately by a number of different expeditions, including those by John Ross, William Edward Parry, James Clark Ross; and overland expeditions led by John Franklin, George Back, Peter Warren Dease, Thomas Simpson, and John Rae. Sir Robert McClure was credited with the discovery of the Northwest Passage by sea in 1851[10] when he looked across M'Clure Strait from Banks Island and viewed Melville Island. However, the strait was blocked by young ice at this point in the season, and not navigable to ships.[11] The only usable route, linking the entrances of Lancaster Sound and Dolphin and Union Strait was first used by John Rae in 1851. Rae used a pragmatic approach of traveling by land on foot and dog sled, and typically employed less than ten people in his exploration parties.[12]\\r\\nThe Northwest Passage was not completely conquered by sea until 1906, when the Norwegian explorer Roald Amundsen, who had sailed just in time to escape creditors seeking to stop the expedition, completed a three-year voyage in the converted 47-ton herring boat Gj?a. At the end of this trip, he walked into the city of Eagle, Alaska, and sent a telegram announcing his success. His route was not commercially practical; in addition to the time taken, some of the waterways were extremely shallow.[13]\\r\\nKnud Rasmussen (1879 - 1933) led several Arctic expeditions. He grew up in Greenland speaking Inuktitut and Danish, and has been called the \\"father of Eskimology\\"[14] and was the first European to cross the Northwest Passage via dog sled.[15] Rasmussen and his friend Peter Freuchen participated in seven Thule Expeditions, named after Ultima Thule, and wrote numerous books on their Arctic experiences.\\r\\nOn April 6, 1909, Robert Peary claimed to be the first person in recorded history to reach the North Pole[10] (although whether he actually reached the Pole is disputed).[1][16] He traveled with the aid of dogsleds and three separate support crews who turned back at successive intervals before reaching the Pole. Many modern explorers, including Olympic skiers using modern equipment, contend that Peary could not have reached the pole on foot in the time he claimed.\\r\\nA number of previous expeditions set out with the intention of reaching the North Pole but did not succeed; that of British naval officer William Edward Parry in 1827, the tragic American Polaris expedition under Charles Francis Hall in 1871, the ill-fated Jeannette Expedition commanded by US Navy Lt Cmdr George W. DeLong in 1879, and the Norwegian Fram Expedition of Fridtjof Nansen in 1895. American Frederick Cook claimed to have reached the North Pole in 1908, but this has not been widely accepted.[17]\\r\\nOn May 9, 1926, Americans Richard E. Byrd and Floyd Bennett claimed to have flown over the North Pole in a Fokker F.VIIa/3m Tri-motor monoplane. However, their claim to have reached the Pole is disputed.[18]\\r\\nThe crew of the airship Norge (including Roald Amundsen and the American sponsor Lincoln Ellsworth) flew over the Pole on May 12, 1926. This is the first undisputed sighting of the Pole. Norge was designed and piloted by the Italian Umberto Nobile, who overflew the Pole a second time on May 24, 1928. Nobiles second trip was in the airship Italia that ran into a storm on the return trip and crashed on the ice. Survivors were eventually recovered. Amundsen disappeared, with the crew of his sea plane, during the rescue operations.\\r\\nThe first people to have without doubt walked on the North Pole were the Soviet party of 1948 under the command of Alexander Kuznetsov, who landed their aircraft nearby and walked to the pole.[19]\\r\\nOn August 3, 1958, the American submarine USS?Nautilus?(SSN-571) reached the North Pole without surfacing. It then proceeded to travel under the entire Polar ice cap. On March 17, 1959 the USS?Skate?(SSN-578) surfaced on the North Pole and dispersed the ashes of explorer Sir Hubert Wilkins. These journeys were part of military explorations stimulated by the Cold War context.\\r\\nOn April 19, 1968, Ralph Plaisted reached the North Pole via snowmobile, the first surface traveler known with certainty to have done so. His position was verified independently by a US Air Force meteorological overflight. In 1969 Wally Herbert, on foot and by dog sled, became the first man to reach the North Pole on muscle power alone, on the 60th anniversary of Robert Peary's famous but disputed expedition.\\r\\nThe first persons to reach the North Pole on foot (or skis) and return with no outside help, no dogs, air planes, or re-supplies were Richard Weber (Canada) and Misha Malakhov (Russia) in 1995. No one has completed this journey since.\\r\\nU.S. Air Force Lieutenant Colonel Joseph O. Fletcher and Lieutenant William Pershing Benedict landed a plane at the Pole on May 3, 1952, accompanied by the scientist Albert P. Crary.[20]\\r\\nOn 2 May 2007, BBC's Top Gear got to the 1996 position of the magnetic north pole (7835.7N 10411.9W? / ?78.5950N 104.1983W? / 78.5950; -104.1983? (Magnetic North Pole 1996)) in modified Toyota Hilux.\\r\\nOn 2 August 2007, during Arktika 2007 Russian manned submersibles were the first to descend to the sea-bed below the pole.\\r\\nOn April 26, 2009, Vassily Elagin, Afanassi Makovnev, Vladimir Obikhod, Sergey Larin, Alexey Ushakov, Alexey Shkrabkin and Nikolay Nikulshin after 38 days and over 2,000?km (1,200?mi) (starting from Sredniy Island, Severnaya Zemlya) drove two Russian built cars \\"Yemelya-1\\" and \\"Yemelya-2\\" to the North Pole.","input":"Who was the first greek explorer to reach the arctic?"},{"output":"King George VI","context":"","input":"Who was the last ruling king of england?"},{"output":"Indonesian","context":"","input":"What became the unifying nationalist language of indonesia?"},{"output":"third and final inversion","context":"Rock 'n' Roller Coaster Starring Aerosmith is an enclosed launched steel roller coaster at Disney's Hollywood Studios at the Walt Disney World Resort and at the Walt Disney Studios Park in Disneyland Paris (where it is called Rock 'n' Roller Coaster avec Aerosmith). As the attraction's name suggests, the coaster features Aerosmith members, Steven Tyler, Joe Perry, Tom Hamilton, Joey Kramer, and Brad Whitford.\\r\\nThe Florida attraction opened on July 29, 1999 and is located at the end of Sunset Boulevard, an area of the park which also features The Twilight Zone Tower of Terror. The Paris attraction opened on March 16, 2002 in the Backlot section of the park; it is currently the fastest roller coaster in France.[1] As of July 2008, Hanes is the attraction's presenting sponsor.[2]\\r\\nThe coaster accelerates from 0 to 57 miles per hour in 2.8 seconds (making this the second-fastest attraction at the Walt Disney World Resort, behind only Test Track). The riders experience 4.5 G as they enter the first inversion, more than an astronaut does on a space shuttle launch. Both versions of the attraction feature five trains, although only four can run at one time. The remaining train is kept in backup while being serviced (each train is rotated out periodically for safety reasons).\\r\\n\\r\\n\\r\\nCast member previews for the ride were initially held the last week of June, 1999. On 29 July 1999, the ride officially opened with a special, invitation-only party, with Aerosmith as the guests of honor. Winners rode to Disney's Hollywood Studios in stretch limousines and were treated to an all-you-can-eat buffet and bar. After a special performance by painter Denny Dent, winners got the chance to ride the roller coaster with one of the Aerosmith band members. At the exit of the ride, outside of the gift shop, there hangs a picture from the special event. The paintings Denny Dent made of the five band members hang in various employee office locations on Walt Disney World property.\\r\\nThe pre-show has changed from when the attraction first opened. Currently, band member Joe Perry would ask \\"Chris\\" to \\"grab my black Les Paul.\\" A Disney cast member in the pre-show area would then pick up and remove a black guitar signed by Joe Perry from the set. The script uses the unisex name \\"Chris\\" so either a male or female could play the part. Although not used as often as when the ride first opened, the position is still used from time to time (generally, if the attraction is overstaffed). The film also includes a roadie saying \\"Hey Joe, I'll get it for ya\\" as a backup, in the event that a cast member is not available for the part.\\r\\nIn 2007, the queue was modified to accommodate single riders in addition to FASTPASS.\\r\\nGuests begin the queue by entering through a small and narrow tent, with boxes designed like instrument cases decorating the scene. The guests then wait in an unshaded, gridded-queue area (if the queue is long), and then proceed to a ramp that takes them back and forth, to curve around the front of the building, behind the giant electric guitar, and into the \\"G-Force Records\\" recording studio. Guests then enter a circular room with a high ceiling decorated with a giant record. Guests can see posters featuring artists Disney has signed, other miscellaneous and famous bands/singers and even the guests themselves. These posters are displayed via LCD screens and are able to display a guest's name to customize the visual as they walk past.[3] Guests then continue immediately to enter a small room with doors covered in marbles and a small exhibit of recording instruments. Guests can interact with the marble doors and often do, and if they take the time to look at the exhibit, they will see various funny parts (i.e. the person who organized and presented the exhibit is named Mike Rofone). Guests are then called by a Cast Member to join other guests (this is where the Fastpass+ line and Stand-by lines merge) to enter the studio that Aerosmith is recording in. Guests wait for the recording to stop, and the automatic doors eventually open. As guests enter, the song \\"Walk This Way\\" plays, except, after the introduction is played, the drums, vocals, and guitar cuts out, leaving only the bassline (the guitar occasionally comes back in). Guests see Aerosmith recording and wait momentarily, until the band is interrupted by their manager (played by Illeana Douglas). The manager tells the band that they have a show to get to, and they can't stay with the guests any longer. Steven Tyler expresses discontent with this outcome and suggests to his manager to get the guests to their concert, along with backstage passes. The manager reluctantly accepts, after a few seconds of persuasion. After she accepts to give the ride and tickets to the show, the guests see her call her assistant \\"Sal,\\" who she tells to get a \\"stretch\\" limo. After a few seconds of thinking, she takes it back and instead asks for a \\"super stretch.\\" She then tells the guests that she has gotten a \\"really fast car\\" for them to ride to the concert because the show is all the way across town. Guests then see the limo with the band in it already peel out of the lot, leaving the manager behind.\\r\\nThe automatic doors open to the outdoor parking garage, where guests will be boarding their limos. As the doors open, the audio for \\"Walk This Way\\" plays as guests exit. Guests walk along a fence that separates them from the limos. Immediately after entering the garage, guests see the limos that are ready to be launched off from 0 to 57 MPH in 2.8 seconds. As cars launch off, guests hear echoed and intense screaming, and extra added sound effects. Guests then proceed from here through a short line to board their limo.\\r\\nWhile the guests wait for the ride to begin, a radio DJ presents the safety spiel, followed by a traffic report. The highway sign flashes humorous messages like: \\"Traffic bug you? Then STEP on it!\\" Guests wait for the car ahead of them to finish the ride, and eventually they hear an introduction (which varies, and includes messages such as \\"We're only just getting started!\\" or \\"Hold on, here we go!\\"). After this introduction, Steven Tyler alternates between each ear the countdown of \\"Five, four, three, two\\", as they hear the introduction of the song they're about to hear. As Tyler gets to 2 in the countdown, he skips 1 and guests suddenly begin to accelerate from 0 to 57 MPH in less than 2.8 seconds. During this initial second, the on-ride camera takes the photo of the guests. After a long straightway, the car proceeds to do a Roll Over (sea serpent) roll, which is a two inversion element,[4] and then some less intense maneuvers. During the ride, there are neon signs on the side of the track, designed to mimic road signs. The car continues along the track, until it reaches the third and final inversion, a corkscrew. Finally, guests perform a humpback as they enter the \\"VIP parking\\" section for the fictitious concert. Guests wait in a tunnel at a stop for a moment, then proceed to the VIP backstage area, where they're greeted by a red carpet and monitors displaying their ride photos. Guests then exit through the gift shop.\\r\\nWalt Disney Imagineering worked with Aerosmith to produce a special soundtrack for the roller coaster. Each coaster train features different Aerosmith songs.\\r\\nThere is a 6th Limo in the fleet of ride vehicles of Rock 'n' Roller Coaster. This vehicle is without a license plate, and is always \\"in refurbishment.\\" The vehicles are rotated in and out of use after a period of many thousands of laps around the track. However, the maintenance teams will switch out the plate and add the proper song to the new vehicle every time a rotation is made.\\r\\nThe ride formerly featured Uncle Joe Benson, a well-known Los Angeles rock radio DJ, as the station's DJ. Currently, Bill Hart (known as Bill St. James), the host of ABC Radio's Flashback, provides the voice for the DJ of \\"LA's Classic Rock Station.\\"\\r\\nThe height requirement on this ride is 48 inches.\\r\\nRock 'n' Roller Coaster also exists in Disneyland Paris' Walt Disney Studios Park, named \\"Rock 'n' Roller Coaster avec Aerosmith\\".\\r\\nAlthough the track layout is identical to its Orlando counterpart, the theme of the ride differsinstead of guests being taken on the Los Angeles freeways, the Paris version is based around an Aerosmith music video. Lighting rigs, projectors, strobes, and smoke effects are used in place of the road signs that exist in the U.S. version. The name of the record company is Tour de Force (instead of \\"G-Force\\") Records, and the vehicles in Paris are called \\"Soundtrackers\\" instead of limousines.\\r\\nThe story of the Paris version is that Aerosmith, working with engineers, have created a revolutionary new music experience at the Tour De Force Records studios. After watching the pre-show which features Aerosmith's Steven Tyler hyping up the ride, guests are lured into the testing area where they board one of five Soundtrackers, the prototype vehicles for the new experience.\\r\\nA unique aspect of the Walt Disney Studios version is that each Soundtracker has its own theme. There are five different lightshows and five different soundtracks, one for each Soundtracker. The themes are as follows:\\r\\nThe minimum height at Parc Walt Disney Studios is 1.2 metres (47 inches).\\r\\nIn each train, there are a total of 120 speakers. There are 7 speakers per seat including 1 subwoofer (under the seat) and 6 located in the headrest. There are 820 speakers located in the ride's show building and launch area (not including the train). This makes a total of about 900 speakers in the attraction.","input":"How many loops in rock n roller coaster?"},{"output":"June, July and August. However, according to the Irish Calendar, summer begins on 1 May and ends on 1 August.","context":"Summer is the hottest of the four temperate seasons, falling between spring and autumn. At the summer solstice, the days are longest and the nights are shortest, with day-length decreasing as the season progresses after the solstice. The date of the beginning of summer varies according to climate, tradition and culture. When it is summer in the Northern Hemisphere, it is winter in the Southern Hemisphere, and vice versa.\\r\\n\\r\\n\\r\\nFrom an astronomical view, the equinoxes and solstices would be the middle of the respective seasons,[1][2] but sometimes astronomical summer is defined as starting at the solstice, the time of maximal insolation, or on the traditional date of June 21. A variable seasonal lag means that the meteorological center of the season, which is based on average temperature patterns, occurs several weeks after the time of maximal insolation.[3] The meteorological convention is to define summer as comprising the months of June, July, and August in the northern hemisphere and the months of December, January, and February in the southern hemisphere.[4][5] Under meteorological definitions, all seasons are arbitrarily set to start at the beginning of a calendar month and end at the end of a month.[4] This meteorological definition of summer also aligns with the commonly viewed notion of summer as the season with the longest (and warmest) days of the year, in which daylight predominates. The meteorological reckoning of seasons is used in Australia, Austria, Denmark, the former Soviet Union and Japan. It is also used by many in the United Kingdom. In Ireland, the summer months according to the national meteorological service, Met ireann, are June, July and August. However, according to the Irish Calendar, summer begins on 1 May and ends on 1 August. School textbooks in Ireland follow the cultural norm of summer commencing on 1 May rather than the meteorological definition of 1 June.\\r\\nDays continue to lengthen from equinox to solstice and summer days progressively shorten after the solstice, so meteorological summer encompasses the build-up to the longest day and a diminishing thereafter, with summer having many more hours of daylight than spring. Reckoning by hours of daylight alone, summer solstice marks the midpoint, not the beginning, of the seasons. Midsummer takes place over the shortest night of the year, which is the summer solstice, or on a nearby date that varies with tradition.\\r\\nWhere a seasonal lag of half a season or more is common, reckoning based on astronomical markers is shifted half a season.[6] By this method, in North America, summer is the period from the summer solstice (usually 20 or 21 June in the Northern Hemisphere) to the autumn equinox.[7][8][9]\\r\\nReckoning by cultural festivals, the summer season in the United States is commonly regarded as beginning on Memorial Day weekend (the last weekend in May) and ending on Labor Day weekend (the first weekend in September), more closely in line with the meteorological definition for the parts of the country that have four-season weather. The similar Canadian tradition starts summer on Victoria Day one week prior (although summer conditions vary widely across Canada's expansive territory) and ends, as in the United States, on Labour Day.\\r\\nIn Chinese astronomy, summer starts on or around 5 May, with the jiq (solar term) known as lxi (٪G), i.e. \\"establishment of summer\\", and it ends on or around 6 August.\\r\\nIn southern and southeast Asia, where the monsoon occurs, summer is more generally defined as lasting from March, April, May and June, the warmest time of the year, ending with the onset of the monsoon rains.[citation needed]\\r\\nBecause the temperature lag is shorter in the oceanic temperate southern hemisphere,[10] most countries in this region use the meteorological definition with summer starting on 1 December and ending on the last day of February.[11][12]\\r\\nSummer is traditionally associated with hot or warm weather. In the Mediterranean regions, it is also associated with dry weather, while in other places (particularly in Eastern Asia because of the Monsoon) it is associated with rainy weather. The wet season is the main period of vegetation growth within the savanna climate regime.[13] Where the wet season is associated with a seasonal shift in the prevailing winds, it is known as a monsoon.[14]\\r\\nIn the northern Atlantic Ocean, a distinct tropical cyclone season occurs from 1 June to 30 November.[15] The statistical peak of the Atlantic hurricane season is 10 September. The Northeast Pacific Ocean has a broader period of activity, but in a similar time frame to the Atlantic.[16] The Northwest Pacific sees tropical cyclones year-round, with a minimum in February and March and a peak in early September. In the North Indian basin, storms are most common from April to December, with peaks in May and November.[15] In the Southern Hemisphere, the tropical cyclone season runs from 1 November until the end of April with peaks in mid-February to early March.[15][17]\\r\\nThunderstorm season in the United States and Canada runs in the spring through summer. These storms can produce hail, strong winds and tornadoes, usually during the afternoon and evening.\\r\\nSchools and universities typically have a summer break to take advantage of the warmer weather and longer days. In almost all countries, children are out of school during this time of year for summer break, although dates vary. In the United States, public schools usually end in early June while colleges get out in early May, although some schools get out on the last or second last Thursday in May. In England and Wales, school ends in mid-July and resumes again in early September; in Scotland, the summer holiday begins in late June and ends in mid- to late-August. Similarly, in Canada the summer holiday starts in late June and ends at the very start of September. In Russia the summer holiday begins at the end of May and ends on August 31. In the Southern Hemisphere, school summer holiday dates include the major holidays of Christmas and New Year's Day. School summer holidays in Australia, New Zealand and South Africa begin in early-December and end in early February, with the dates varying between states. In India, school ends in April and resumes in late June or early July. In Cameroon and Nigeria, schools usually go for summer vacation in mid-July and resume back in the later weeks of September or first week of October.\\r\\nA wide range of public holidays fall during summer, including:\\r\\nPeople take advantage of the warmer temperatures by spending more time outdoors during the summer. Activities such as traveling to the beach and picnics occur during summer months. Sports such as association football, basketball, American football, volleyball, skateboarding, baseball, softball, cricket, tennis and golf are played. Water sports also occur. These include water skiing, wake boarding, swimming, surfing, tubing and water polo. The modern Olympics have been held during the summer months every four years since 1896. The 2000 Summer Olympics, in Sydney, however, were held during the Australian spring.\\r\\nSummer is usually a low point in television viewing, and television schedules generally reflect this by not scheduling new episodes of their most popular shows between the end of May sweeps and the beginning of the television season in September, instead scheduling low-cost reality television shows and burning off commitments to already-canceled series. There is an exception to this with children's television. Many television shows made for children and are popular with children are released during the summer months, especially on children's cable channels such as the Disney Channel in the United States, as children are off school. Disney Channel, for example, ends its preschool programming earlier in the day for older school age children in the summer months while it reverts to the original scheduling as the school year begins. Conversely, the music and film industries generally experience higher returns during the summer than other times of the year and market their summer hits accordingly. The summer season is also most popular for animated movies to be released theatrically in movie theaters.[citation needed]\\r\\nWith most school-age children and college students (except those attending summer school) on summer vacation during the summer months, especially in the United States, travel and vacationing traditionally peaks during the summer, with the volume of travel in a typical summer weekend rivaled only by Thanksgiving. Teenagers and college students often take summer jobs in industries that cater to recreation. Business activity for the recreation, tourism, restaurant, and retail industries peak during the summer months as well as the holiday season.","input":"What months are summer in the southern hemisphere?"},{"output":"full-sized all-electric five-door, luxury liftback","context":"","input":"What type of car is a tesla model s?"},{"output":"the Kansas State Legislature","context":"The University of Kansas, also referred to as KU or Kansas, is a public research university in the U.S. state of Kansas. The main campus in Lawrence, one of the largest college towns in Kansas,[6] is on Mount Oread, the highest elevation in Lawrence. Two branch campuses are in the Kansas City metropolitan area: the Edwards Campus in Overland Park, Kansas, and the university's medical school and hospital in Kansas City, Kansas. There are also educational and research sites in Parsons, Kansas, Topeka, Kansas, Garden City, Kansas, Hays, Kansas, and Leavenworth, Kansas, and branches of the medical school in Wichita, Kansas and Salina, Kansas. The university is one of the 62 members of the Association of American Universities.\\r\\nFounded March 21, 1865, the university was opened in 1866, under a charter granted by the Kansas State Legislature in 1864[7] following enabling legislation passed in 1863 under the Kansas State Constitution, adopted two years after the 1861 admission of the former Kansas Territory as the 34th state into the Union following an internal civil war known as \\"Bleeding Kansas\\" during the 1850s.[8]\\r\\nEnrollment at the Lawrence and Edwards campuses was 28,401 students in 2016; an additional 3,383 students were enrolled at the KU Medical Center[9][10] for an enrollment of 28,091[11] students across the three campuses. The university overall employed 2,814 faculty members in fall 2015.[12]\\r\\n\\r\\n\\r\\nOn February 20, 1863, Kansas Governor Thomas Carney signed into law a bill creating the state university in Lawrence.[13] The law was conditioned upon a gift from Lawrence of a $15,000 endowment fund and a site for the university, in or near the town, of not less than forty acres (16 ha) of land.[14] If Lawrence failed to meet these conditions, Emporia instead of Lawrence would get the university.\\r\\nThe site selected for the university was a hill known as Mount Oread, which was owned by former Kansas Governor Charles L. Robinson. Robinson and his wife Sara bestowed the 40-acre (16?ha) site to the State of Kansas in exchange for land elsewhere.[14] The philanthropist Amos Adams Lawrence donated $10,000 of the necessary endowment fund, and the citizens of Lawrence raised the remaining cash by issuing notes backed by Governor Carney.[14] On November 2, 1863, Governor Carney announced Lawrence had met the conditions to get the state university, and the following year the university was officially organized.[7] The school's Board of Regents held its first meeting in March 1865, which is the event that KU dates its founding from.[1][15] Work on the first college building began later that year.[7] The university opened for classes on September 12, 1866, and the first class graduated in 1873.[7] According to William L. Burdick, the first degree awarded by the university was a Doctor of Divinity, bestowed upon noted abolitionist preacher Richard Cordley.[16]\\r\\nDuring World War II, Kansas was one of 131 colleges and universities nationally that took part in the V-12 Navy College Training Program which offered students a path to a Navy commission.[17]\\r\\nKU is home to the Robert J. Dole Institute of Politics, the Beach Center on Disability, Lied Center of Kansas and radio stations KJHK, 90.7 FM, and KANU, 91.5 FM. The university is host to several museums including the University of Kansas Natural History Museum and the Spencer Museum of Art. The libraries of the University include Watson Library,[18] Kenneth Spencer Research Library,[19] the Murphy Art and Architecture Library,[20] Thomas Gorton Music & Dance Library,[21] and Anschutz Library.[22]\\r\\nThe University of Kansas is a large, state-sponsored university, with five campuses. KU features the College of Liberal Arts & Sciences, which includes the School of the Arts and the School of Public Affairs & Administration; and the schools of Architecture, Design & Planning; Business; Education; Engineering; Health Professions; Journalism & Mass Communications; Law; Medicine; Music; Nursing; Pharmacy; and Social Welfare. The university offers more than 345 degree programs.\\r\\nIn its 2018 list, U.S. News & World Report ranked KU as tied for 115th place among National Universities and 53rd place among public universities.[31]\\r\\nThe city management and urban policy program was ranked first in the nation, and the special education program second, by U.S. News & World Report's 2016 rankings.[31] USN&WR also ranked several programs in the top 25 among U.S. universities.[31]\\r\\nThe University of Kansas School of Architecture, Design, and Planning (SADP), with its main building being Marvin Hall, traces its architectural roots to the creation of the architectural engineering degree program in KU's School of Engineering in 1912. The Bachelor of Architecture degree was added in 1920. In 1969, the School of Architecture and Urban Design (SAUD) was formed with three programs: architecture, architectural engineering, and urban planning. In 2001 architectural engineering merged with civil and environmental engineering. The design programs from the discontinued School of Fine Arts were merged into the school in 2009 forming the current School of Architecture, Design, and Planning.\\r\\nAccording to the journal DesignIntelligence, which annually publishes \\"America's Best Architecture and Design Schools,\\" the School of Architecture and Urban Design at the University of Kansas was named the best in the Midwest and ranked 11th among all undergraduate architecture programs in the U.S in 2012.[32]\\r\\nThe University of Kansas School of Business is a public business school on the main campus of the University of Kansas in Lawrence, Kansas. The KU School of Business was founded in 1924 and has more than 80 faculty members and approximately 1500 students.[33]\\r\\nNamed one of the best business schools in the Midwest by Princeton Review, the KU School of Business has been continually accredited by the Association to Advance Collegiate Schools of Business (AACSB) for its undergraduate and graduate programs in business and accounting.[34]\\r\\nIn 2016, The University of Kansas completed construction on a new home for the business school, named Capitol Federal Hall. It is located at 1654 Naismith Drive, near KU's Rec Center and across the street from Allen Fieldhouse. Capitol Federal Hall is a 166,500 square-foot building complete with state-of-the-art technology and several research labs. [35]\\r\\nThe University of Kansas School of Law, founded in 1878, was the top law school in the state of Kansas, and tied for 65th nationally, according to the 2016 U.S. News & World Report \\"U.S. News Best Colleges Rankings.\\"[31] Classes are held in Green Hall at W 15th St and Burdick Dr, which is named after former dean James Green.[36]\\r\\nThe KU School of Engineering is an ABET accredited, public engineering school located on the main campus. The School of Engineering was officially founded in 1891, although engineering degrees were awarded as early as 1873.[37]\\r\\nIn the U.S. News & World Report's \\"Americas Best Colleges\\" 2016 issue, KUs School of Engineering was ranked tied for 90th among national universities.[31]\\r\\nNotable alumni include: Alan Mulally (BS/MS), former President and CEO of Ford Motor Company, Lou Montulli, co-founder of Netscape and author of the Lynx web browser, Brian McClendon (BSEE 1986), VP of Engineering at Google, Charles E. Spahr (1934), former CEO of Standard Oil of Ohio.\\r\\nThe William Allen White School of Journalism and Mass Communications is recognized for its ability to prepare students to work in a variety of media. The school offers two tracts of study: 1) News and Information, and 2) Strategic Communication. This professional school teaches students reporting for print, online and broadcast, strategic campaigning for PR and advertising, photojournalism and video reporting and editing. The J-School's students maintain various publications on campus, including The University Daily Kansan, Jayplay magazine, and KUJH TV. In 2008, the Fiske Guide to Colleges praised the KU J-School for its strength. In 2010, the School of Journalism and Mass Communications placed second at the prestigious Hearst Foundation national writing competition.[38]\\r\\nThe University of Kansas Medical Center features three schools: the School of Medicine, School of Nursing, and School of Health Professions that each has its own programs of graduate study. As of the Fall 2013 semester, there were 3,349 students enrolled at KU Med.[11] The Medical Center also offers four year instruction at the Wichita campus, and features a medical school campus in Salina, Kansas devoted to rural health care.\\r\\nThe university-affiliated independent University of Kansas Hospital is co-located at the University of Kansas Medical Center.\\r\\nKU's Edwards Campus is in Overland Park, Kansas. Established in 1993, its goal is to provide adults with the opportunity to complete undergraduate, graduate and certificate programs. About 2,000 students attend the Edwards Campus, with an average age of 31.[39] Programs available at the Edwards Campus include business administration, education, engineering, social work and more.\\r\\nBeginning in the 2007ÿ2008 academic year, first-time freshman at KU pay a fixed tuition rate for 48 months according to the Four-Year Tuition Compact passed by the Kansas Board of Regents. For the 2014ÿ15 academic year, tuition was $318 per credit hour for in-state freshman and $828 for out-of-state freshmen. For transfer students, who do not take part in the compact, 2014ÿ15 per-credit-hour tuition was $295 for in-state undergraduates and $785 for out-of-state undergraduates; subject to annual increases. Students enrolled in 6 or more credit hours also paid an annual required campus fee of $888.[40] The schools of architecture, music, arts, business, education, engineering, journalism, law, pharmacy, and social welfare charge additional fees.\\r\\nAs of February 2017, the annual tuition for 30 credit hours for a freshman is estimated by the university to be $9,579, not counting room and board costs.[41]\\r\\nKU's School of Business launched interdisciplinary management science graduate studies in operations research during Fall Semester 1965. The program provided the foundation for decision science applications supporting NASA Project Apollo Command Capsule Recovery Operations.\\r\\nKU's academic computing department was an active participant in setting up the Internet and is the developer of the early Lynx text based web browser. Lynx provided hypertext browsing and navigation prior to Tim Berners Lee's invention of HTTP and HTML.[42]\\r\\nThe school's sports teams, wearing crimson and royal blue, are called the Kansas Jayhawks. They participate in the NCAA's Division I and in the Big 12 Conference. KU has won thirteen National Championships: five in men's basketball (two Helms Foundation championships and three NCAA championships), three in men's indoor track and field, three in men's outdoor track and field, one in men's cross country and one in women's outdoor track and field. The home course for KU Cross Country is Rim Rock Farm. Their most recent championship came on June 8, 2013 when the KU women's track and field team won the NCAA outdoor in Eugene, Oregon becoming the first University of Kansas women's team to win a national title.[43]\\r\\nKU football dates from 1890, and has played in the Orange Bowl three times: 1948, 1968, and 2008. They are currently coached by David Beaty, who was hired in 2014.[44] In 2008, under the leadership of Mark Mangino, the #7 Jayhawks emerged victorious in their first BCS bowl game, the FedEx Orange Bowl, with a 24ÿ21 victory over the #3 Virginia Tech Hokies. This capstone victory marked the end of the most successful season in school history, in which the Jayhawks went 12ÿ1 (.923). The team plays at David Booth Kansas Memorial Stadium, which recently underwent a $31 million renovation to add the Anderson Family Football Complex, adding a football practice facility adjacent to the stadium complete with indoor partial practice field, weight room, and new locker room.\\r\\nThe KU men's basketball team has fielded a team every year since 1898. The Jayhawks are a perennial national contender, coached by Bill Self. The team has won five national titles, including three NCAA tournament championships in 1952, 1988, and 2008. The basketball program is currently the second winningest program in college basketball history with an overall record of 2,070ÿ806 through the 2011ÿ12 season. The team plays at Allen Fieldhouse. Perhaps its best recognized player was Wilt Chamberlain, who played in the 1950s, later becoming an NBA star and Harlem Globetrotter. Other notable Jayhawk basketball players include Phog Allen (who would later become head coach of the Jayhawks), Wayne Simien, Mario Chalmers, Frank Mason III, Andrew Wiggins, Paul Pierce, Raef LaFrentz, Jo Jo White, Dean Smith, and Danny Manning, among others.\\r\\nKansas has counted among its coaches Dr. James Naismith (the inventor of basketball), Basketball Hall of Fame inductee Phog Allen (\\"the Father of basketball coaching\\" and a Kansas alumni himself), Basketball Hall of Fame inductee Roy Williams, and Basketball Hall of Fame inductee and former NBA Champion Detroit Pistons coach Larry Brown. Currently, Kansas is coached by Basketball Hall of Fame inductee Bill Self. In addition, legendary University of Kentucky coach and Basketball Hall of Fame inductee Adolph Rupp played for KU's 1922 and 1923 Helms National Championship teams, and NCAA Hall of Fame inductee and University of North Carolina Coach Dean Smith played for KU's 1952 NCAA Championship team. Both Rupp and Smith played under Phog Allen. Allen also coached Hall of Fame coaches Dutch Lonborg and Ralph Miller. Allen founded the National Association of Basketball Coaches (NABC), which started what is now the NCAA Tournament. The Tournament began in 1939 under the NABC and the next year was handed off to the newly formed NCAA.[45]\\r\\nNotable non-varsity sports include rugby, men's hockey, and men's soccer. The rugby team owns its private facility and internationally tours every two years.\\r\\nSheahon Zenger was introduced as KU's new athletic director in January 2011.[46] Under former athletic director Lew Perkins, the department's budget increased from $27.2 million in 2003 (10th in the conference) to currently over $50 million thanks in large part to money raised from a new priority seating policy at Allen Fieldhouse, a new $26.67 million eight-year contract with Adidas replacing an existing contract with Nike, and a new $40.2 million seven-year contract with ESPN Regional Television. The additional funds brought improvements to the university, including:[47]\\r\\nThe University of Kansas has had more teams (70) compete in the National Debate Tournament than any other university.[48] Kansas has won the tournament 6 times (1954, 1970, 1976, 1983, 2009 and 2018)[49] and had 15 teams make it to the final four.[48] Kansas trails only Northwestern (15) and Harvard (7) for most tournaments won, and is tied with Dartmouth (6). Kansas also won the Copeland Award in 1981-82 and 2017-18.\\r\\nNotable among a number of songs commonly played and sung at various events such as commencement and convocation, and athletic games are: \\"Im a Jayhawk\\", \\"Fighting Jayhawk\\", \\"Kansas Song\\", \\"Sunflower Song\\", \\"Crimson and the Blue\\", \\"Red and Blue\\", the \\"Rock Chalk, Jayhawk\\" chant\\", \\"Home on the Range\\" and \\"Stand Up and Cheer.\\"[50]\\r\\nThe university's newspaper is University Daily Kansan, which placed first in the Intercollegiate Writing Competition of the prestigious William Randolph Hearst Writing Foundation competition, often called \\"The Pulitzers of College Journalism\\" in 2007. In Winter 2008, a group of students created KUpedia, a wiki about all things KU. They received student funding for operations in 2008ÿ09. The KU Department of English publishes the Coal City Review, an annual literary journal of prose, poetry, reviews and illustrations. The Review typically features the work of many writers, but periodically spotlights one author, as in the case of 2006 Nelson Poetry Book Award-winner Voyeur Poems by Matthew Porubsky.[51][52]\\r\\nThe University Daily Kansan operates outside of the university's William Allen White School of Journalism[53] and reaches at least 30,000 daily readers through its print and online publications[54]\\r\\nThe university houses the following public broadcasting stations: KJHK, a student-run campus radio station, KUJH-LP, an independent station that primarily broadcasts public affairs programs, and KANU, the NPR-affiliated radio station. Kansas Public Radio station KANU was one of the nation's first public radio stations. KJHK, the campus radio has roots back to 1952 and is completely run by students.\\r\\nThe first union was built on campus in 1926 as a campus community center.[58] The unions are still the \\"living rooms\\" of campus and include three locations ÿ the Kansas Union and Burge Union at the Lawrence Campus and Jayhawk Central at the Edwards Campus. The KU Memorial Unions Corporation manages the KU Bookstore (with seven locations). The KU Bookstore is the official bookstore of KU. The Corporation also includes KU Dining Services, with more than 20 campus locations, including The Market (inside the Kansas Union) and The Underground (located in Wescoe Hall). The KU Bookstore and KU Dining Services are not-for-profit,[59] with proceeds supporting student programs, such as Student Union Activities.[60]\\r\\nKU Endowment was established in 1891 as Americas first foundation for a public university. Its mission is to partner with donors in providing philanthropic support to build a greater University of Kansas.[61]\\r\\nBob Dole, American lawyer and politician\\r\\nJoe Engle, Astronaut and Major General for the United States Air Force\\r\\nRon Evans, Astronaut who flew to the Moon\\r\\nChris Harris Jr., Professional football player\\r\\nNancy Kassebaum, former U.S. senator for Kansas\\r\\nKris Kobach, Kansas Secretary of State and Republican candidate for Governor of Kansas 2018[citation needed]\\r\\nRon Kuby, criminal defense and civil rights lawyer, radio talk show host and television commentator\\r\\nDanny Manning, former basketball player, current Wake Forest basketball coach\\r\\nPaul Pierce, former professional basketball player\\r\\nRob Riggle, actor and comedian\\r\\nPaul Rudd, actor\\r\\nJuan Manuel Santos, President of Colombia\\r\\nGale Sayers, retired professional football player, nicknamed \\"The Kansas Comet\\"\\r\\nKathleen Sebelius, former Secretary of Health and Human Services, former Governor of Kansas\\r\\nDean Smith, 36 year coach of UNC Men's Basketball\\r\\nDee Wallace, actress\\r\\nWilliam Allen White, newspaper editor and politician\\r\\nKevin Yoder, current U.S. Representative for Kansas","input":"Who was the founder of kansas state university?"},{"output":"10 January 1868","context":"Between 1788 and 1868, about 162,000 convicts were transported by the British government to various penal colonies in Australia.[1]\\r\\nThe British government began transporting convicts overseas to American colonies in the early 17th century. When transportation ended with the start of the American Revolution, an alternative site was needed to relieve further overcrowding of British prisons and hulks. Earlier in 1770, James Cook charted and claimed possession of the east coast of Australia for Britain. Seeking to pre-empt the French colonial empire from expanding into the region, Britain chose Australia as the site of a penal colony, and in 1787, the First Fleet of eleven convict ships set sail for Botany Bay, arriving on 20 January 1788 to found Sydney, New South Wales, the first European settlement on the continent. Other penal colonies were later established in Van Diemen's Land (Tasmania) in 1803 and Queensland in 1824, while Western Australia, founded in 1829 as a free colony, received convicts from 1850. Victoria and South Australia remained free colonies. Penal transportation to Australia peaked in the 1830s and dropped off significantly the following decade. The last convict ship arrived in Western Australia on 10 January 1868.\\r\\nMany convicts were transported for petty crimes, while a significant number were political prisoners. More serious crimes, such as rape and murder, were punishable by death, and therefore not transportable offences. Once emancipated, most ex-convicts stayed in Australia and joined the free settlers, with some rising to prominent positions in Australian society. However, convictism carried a social stigma, and for some later Australians, convict origins would be a source of shame. Attitudes became more accepting in the 20th century and it is now considered by many Australians to be a cause for celebration to have a convict in one's lineage. Around 20% of modern Australians are descended from transported convicts.[2] The convict era has inspired famous novels, films, and other cultural works, and the extent to which it has shaped Australia's national character has been studied by many writers and historians.[3]\\r\\n\\r\\n\\r\\nAccording to Robert Hughes in The Fatal Shore, the population of England and Wales, which had remained steady at 6 million from 1700 to 1740, began rising considerably after 1740. By the time of the American Revolution, London was overcrowded, filled with the unemployed, and flooded with cheap gin.[4] Poverty, social injustice, child labor, harsh and dirty living conditions and long working hours were prevalent in 19th-century Britain. Dickens' novels perhaps best illustrate this; even some government officials were horrified by what they saw. Only in 1833 and 1844 were the first general laws against child labour (the Factory Acts) passed in the United Kingdom.[5] Crime had become a major problem and in 1784 a French observer noted that \\"from sunset to dawn the environs of London became the patrimony of brigands for twenty miles around.\\"[6]\\r\\nEach parish had a watchman, but British cities did not have police forces in the modern sense. Jeremy Bentham avidly promoted the idea of a circular prison, but the penitentiary was seen by many government officials as a peculiar American concept. Virtually all malefactors were caught by informers or denounced to the local court by their victims.[citation needed] Pursuant to the so-called \\"Bloody Code\\", by the 1770s there were 222 crimes in Britain which carried the death penalty,[7] almost all of which were crimes against property. These included such offences as the stealing of goods worth over 5 shillings, the cutting down of a tree, the theft of an animal, even the theft of a rabbit from a rabbit warren.\\r\\nThe Industrial Revolution led to an increase in petty crime due to the economic displacement of much of the population, building pressure on the government to find an alternative to confinement in overcrowded gaols. The situation was so dire that hulks left over from the Seven Years' War were used as makeshift floating prisons.[8] Eight of every 10 prisoners were in jail for theft. The Bloody Code was gradually rescinded in the 1800s because judges and juries considered its punishments too harsh. Since lawmakers still wanted punishments to deter potential criminals, they increasingly applied transportation as a more humane alternative to execution.[9] Transportation had been employed as a punishment for both major and petty crimes since the seventeenth century. Around 60,000 convicts were transported to the British colonies in North America in the seventeenth and eighteenth centuries. Transportation to the Americas ceased following Britain's defeat in the American Revolutionary War. The number of convicts transported to North America is not verified although it has been estimated to be 50,000 by John Dunmore Lang and 120,000 by Thomas Keneally. The British American colony of Maryland received a larger felon quota than any other province.[10]\\r\\nAlternatives to the American colonies were investigated and the newly discovered and mapped East Coast of New Holland was proposed. The details provided by James Cook during his expedition to the South Pacific in 1770 made it the most suitable.\\r\\nOn 18 August 1786 the decision was made to send a colonisation party of convicts, military, and civilian personnel to Botany Bay under the command of Admiral Arthur Phillip who was to be the Governor of the new colony. There were 775 convicts on board six transport ships. They were accompanied by officials, members of the crew, marines, the families thereof and their own children who together totaled 645. In all, eleven ships were sent in what became known as the First Fleet. Other than the convict transports, there were two naval escorts and three storeships. The fleet assembled in Portsmouth and set sail on 13 May 1787.[11]\\r\\nThe fleet arrived at Botany Bay on 20 January 1788. It soon became clear that it would not be suitable for the establishment of a colony due to \\"the openness of this bay, and the dampness of the soil, by which the people would probably be rendered unhealthy\\" and Philip decided to examine Port Jackson, a bay mentioned by Captain Cook, about three leagues to the north. On 22 January a small expedition led by Phillips sailed to Port Jackson, arriving in the early afternoon:[11]\\r\\nHere all regret arising from the former disappointments was at once obliterated; and Governor Phillip had the satisfaction to find one of the finest harbours in the world, in which a thousand sail of the line might ride in perfect security. The different coves of this harbour were examined with all possible expedition, and the preference was given to one which had the finest spring of water, and in which ships can anchor so close to the shore, that at a very small expence quays may be constructed at which the largest vessels may unload. This cove is about half a mile in length, and a quarter of a mile across at the entrance. In honour of Lord Sydney, the Governor distinguished it by the name of Sydney Cove.[11]\\r\\nThere they established the first permanent European colony on the Australian continent, New South Wales, on 26 January. The area has since developed into the city of Sydney. This date is still celebrated as Australia Day.\\r\\nThere was initially a high mortality rate amongst the members of the first fleet due mainly to shortages of food. The ships carried only enough food to provide for the settlers until they could establish agriculture in the region. Unfortunately, there were an insufficient number of skilled farmers and domesticated livestock to do this, and the colony waited for the arrival of the Second Fleet. The second fleet was an unprecedented disaster that provided little in the way of help and upon its delivery in June 1790 of still more sick and dying convicts, which actually worsened the situation in Port Jackson.\\r\\nLieutenant-General Sir Richard Bourke was the ninth Governor of the Colony of New South Wales between 1831 and 1837. Appalled by the excessive punishments doled out to convicts, Bourke passed 'The Magistrates Act', which limited the sentence a magistrate could pass to fifty lashes (previously there was no such limit). Bourke's administration was controversial, and furious magistrates and employers petitioned the crown against this interference with their legal rights, fearing that a reduction in punishments would cease to provide enough deterrence to the convicts.\\r\\nBourke, however, was not dissuaded from his reforms and continued to create controversy within the colony by combating the inhumane treatment handed out to convicts, including limiting the number of convicts each employer was allowed to seventy, as well as granting rights to freed convicts, such as allowing the acquisition of property and service on juries. It has been argued that the suspension of convict transportation to New South Wales in 1840[12] can be attributed to the actions of Bourke and other men like Australian-born lawyer William Charles Wentworth. It took another 10 years, but transportation to the colony of New South Wales was finally officially abolished on 1 October 1850.[13]\\r\\nIf a convict was well behaved, the convict could be given a ticket of leave, granting some freedom. At the end of the convict's sentence, seven years in most cases, the convict was issued with a Certificate of Freedom. He was then free to become a settler or to return to England. Convicts who misbehaved, however, were often sent to a place of secondary punishment like Port Arthur, Tasmania or Norfolk Island, where they would suffer additional punishment and solitary confinement.\\r\\nWithin a month of the arrival of the First Fleet at Sydney Cove, a group of convicts and free settlers were sent to take control of Norfolk Island, a small island 1,412 kilometres (877?mi) east of the coast of New South Wales. More convicts were sent, and many of them proved to be unruly; early 1789 saw a failed attempt to overthrow Lieutenant Philip Gidley King, the island's commandant. This was followed by the wreck of the HMS Sirius on one of the island's reefs while attempting to land stores.\\r\\nIn 1803, a British expedition was sent from Sydney to Tasmania (then known as Van Diemen's Land) to establish a new penal colony there. The small party, led by Lt. John Bowen, established a settlement at Risdon Cove, on the eastern side of the Derwent River. Originally sent to Port Philip, but abandoned within weeks, another expedition led by Lieutenant-Colonel David Collins arrived soon after. Collins considered the Risdon Cove site inadequate, and in 1804 he established an alternative settlement on the western side of the river at Sullivan's Cove, Tasmania. This later became known as Hobart, and the original settlement at Risdon Cove was deserted. Collins became the first Lieutenant-Governor of Van Diemen's Land.\\r\\nWhen the convict station on Norfolk Island was abandoned in 1807-1808, the remaining convicts and free settlers were transported to Hobart and allocated land for re-settlement. However, as the existing small population was already experiencing difficulties producing enough food, the sudden doubling of the population was almost catastrophic.\\r\\nStarting in 1816, more free settlers began arriving from Great Britain. On 3 December 1825 Tasmania was declared a colony separate from New South Wales, with a separate administration.\\r\\nThe Macquarie Harbour penal colony on the West Coast of Tasmania was established in 1820 to exploit the valuable timber Huon Pine growing there for furniture making and shipbuilding. Macquarie Harbour had the added advantage of being almost impossible to escape from, most attempts ending with the convicts either drowning, dying of starvation in the bush, or (on at least two occasions) turning cannibal. Convicts sent to this settlement had usually re-offended during their sentence of transportation, and were treated very harshly, labouring in cold and wet weather, and subjected to severe corporal punishment for minor infractions.\\r\\nIn 1830, the Port Arthur penal settlement was established to replace Macquarie Harbour, as it was easier to maintain regular communications by sea. Although known in popular history as a particularly harsh prison, in reality its management was far more humane than Macquarie Harbour or the outlying stations of New South Wales. Experimentation with the so-called model prison system took place in Port Arthur. Solitary confinement was the preferred method of punishment.\\r\\nMany changes were made to the manner in which convicts were handled in the general population, largely responsive to British public opinion on the harshness of their treatment. Until the late 1830s most convicts were either retained by Government for public works or assigned to private individuals as a form of indentured labour. From the early 1840s the Probation System was employed, where convicts spent an initial period, usually two years, in public works gangs on stations outside of the main settlements, then were freed to work for wages within a set district.\\r\\nTransportation to Tasmania ended in 1853 (see section below on Cessation of Transportation).\\r\\nIn 1803 two ships arrived in Port Phillip, which Lt. John Murray in the Lady Nelson had discovered and named the previous year. The Calcutta under the command of Lieutenant-Colonel Collins transported 300 convicts, accompanied by the supply ship Ocean. Collins had previously been Judge Advocate with the First Fleet in 1788. He chose Sullivan Bay near the present-day Sorrento, Victoria for the first settlement - some 90?km south of present-day Melbourne. About two months later the settlement was abandoned due to poor soil and water shortages and Collins moved the convicts to Hobart. Several convicts had escaped into the bush and were left behind to unknown fates with the local aboriginal people. One such convict, the subsequently celebrated William Buckley, lived in the western side of Port Phillip for the next 32 years before approaching the new settlers and assisting as an interpreter for the indigenous peoples.\\r\\nA second settlement was established at Westernport Bay, on the site of present-day Corinella, in November of 1826. It comprised an initial 20 soldiers and 22 convicts, with another 12 convicts arriving subsequently. This settlement was abandoned in February 1828, and all convicts returned to Sydney.[14]\\r\\nThe Port Phillip District was officially sanctioned in 1837 following the landing of the Henty brothers in Portland Bay in 1834, and John Batman settled on the site of Melbourne.\\r\\nBetween 1844 and 1849 about 1,750 convicts arrived there from England. They were referred to either as \\"Exiles\\" or the \\"Pentonvillians\\" because most of them came from Pentonville Probationary Prison. Unlike earlier convicts who were required to work for the government or on hire from penal depots, the Exiles were free to work for pay, but could not leave the district to which they were assigned. The Port Phillip District was still part of New South Wales at this stage. Victoria separated from New South Wales and became an independent colony in 1851.\\r\\nIn 1823 John Oxley sailed north from Sydney to inspect Port Curtis and Moreton Bay as possible sites for a penal colony. At Moreton Bay he found the Brisbane River, which Cook had guessed would exist, and explored the lower part of it. In September 1824, he returned with soldiers and established a temporary settlement at Redcliffe. On 2 December 1824, the settlement was transferred to where the Central Business District (CBD) of Brisbane now stands. The settlement was at first called Edenglassie. In 1839 transportation of convicts to Moreton Bay ceased and the Brisbane penal settlement was closed. In 1842 free settlement was permitted and people began to colonize the area voluntarily. On 6 June 1859 Queensland became a colony separate from New South Wales.\\r\\nAlthough a convict-supported settlement was established in Western Australia from 1826 to 1831, direct transportation of convicts did not begin until 1850. It continued until 1868. During that period, 9,668 convicts were transported on 43 convict ships. The first convicts to arrive were transported to New South Wales, and sent by that colony to King George Sound (Albany) in 1826 to help establish a settlement there. At that time the western third of Australia was unclaimed land known as New Holland. Fears that France would lay claim to the land prompted the Governor of New South Wales, Ralph Darling, to send Major Edmund Lockyer, with troops and 23 convicts, to establish a settlement at King George Sound. Lockyer's party arrived on Christmas Day, 1826. A convict presence was maintained at the settlement for over four years. On 7 March 1831 control of the settlement was transferred to the Swan River Colony, and the troops and convicts were withdrawn.[15]\\r\\nIn April 1848, Charles Fitzgerald, Governor of Western Australia, petitioned Britain to send convicts to his state because of labor shortages. Britain rejected sending fixed term convicts, but offered to send first offenders in the final years of their terms.\\r\\nMost convicts in Western Australia spent very little time in prison. Those who were stationed at Fremantle were housed in the Convict Establishment, the colony's convict prison, and misbehaviour was punished by stints there. The majority, however, were stationed in other parts of the colony. Although there was no convict assignment in Western Australia, there was a great demand for public infrastructure throughout the colony, so that many convicts were stationed in remote areas. Initially, most offenders were set to work creating infrastructure for the convict system, including the construction of the Convict Establishment itself.\\r\\nIn 1852 a Convict Depot was built at Albany, but closed 3 years later. When shipping increased the Depot was re-opened. Most of the convicts had their Ticket-of-Leave and were hired to work by the free settlers. Convicts also manned the pilot boat, rebuilt York Street and Stirling Terrace; and the track from Albany to Perth was made into a good road. An Albany newspaper noted their commendable behaviour and wrote, \\"There were instances in which our free settlers might take an example\\".\\r\\nWestern Australia's convict era came to an end with the cessation of penal transportation by Britain. In May 1865, the colony was advised of the change in British policy, and told that Britain would send one convict ship in each of the years 1865, 1866 and 1867, after which transportation would cease. In accordance with this, the last convict ship to Western Australia, the Hougoumont, left Britain in 1867 and arrived in Western Australia on 10 January 1868.\\r\\nApproximately 20% of the transportees were women. For protection, most quickly attached themselves to male officers or convicts. Although they were routinely referred to as courtesans, relatively few had been prostitutes in England as prostitution, like murder, was not a transportable offence.[16]\\r\\nPolitical prisoners made up a small proportion of convicts. They arrived in waves corresponding to political unrest in Britain and Ireland. They included the First Scottish Martyrs in 1794; British Naval Mutineers (from the Nore Mutiny) in 1797 and 1801; Irish rebels in 1798, 1803, 1848 and 1868; Scots Rebels (1820); Yorkshire Rebels (1820 and 1822); leaders of the Merthyr Tydfil rising of 1831; the Tolpuddle Martyrs (1834); Swing Rioters and Luddites (1828ÿ1833); American and French-Canadian prisoners from the Upper Canada rebellion and Lower Canada Rebellion (1839), and Chartists (1842).[17]\\r\\nWith increasing numbers of free settlers entering New South Wales and Van Diemen's Land (Tasmania) by the mid-1830s, opposition to the transportation of felons into the colonies grew. The most influential spokesmen were newspaper proprietors who were also members of the Independent Congregation Church such as John Fairfax in Sydney and the Reverend John West in Launceston, who argued against convicts both as competition to honest free labourers and as the source of crime and vice within the colony. Bishop Bernard Ullathorne, a Catholic prelate who had been in Australia since 1832 returned for a visit to England in 1835. While there he was called upon by the government to give evidence before a Parliamentary Commission on the evils of transportation, and at their request wrote and submitted a tract on the subject. His views in conjunction with others in the end prevailed. The anti-transportation movement was seldom concerned with the inhumanity of the system, but rather the hated stain it was believed to inflict on the free (non-emancipist) middle classes.\\r\\nTransportation to New South Wales ended in 1840, by which time some 150,000 convicts had been sent to the colonies. The sending of convicts to Brisbane in its Moreton Bay district had ceased the previous year, and administration of Norfolk Island was later transferred to Van Diemen's Land.\\r\\nThe continuation of transportation to Van Diemen's Land saw the rise of a well-coordinated anti-transportation movement, especially following a severe economic depression in the early 1840s. Transportation was temporarily suspended in 1846 but soon revived with overcrowding of British gaols and clamour for the availability of transportation as a deterrent. By the late 1840s most convicts being sent to Van Diemen's Land (plus those to Victoria) were designated as \\"exiles\\" and were free to work for pay while under sentence. In 1850 the Australasian Anti-Transportation League was formed to lobby for the permanent cessation of transportation, its aims being furthered by the commencement of the Australian gold rushes the following year. The last convict ship to be sent from England, the St. Vincent, arrived in 1853, and on 10 August Jubilee festivals in Hobart and Launceston celebrated 50 years of European settlement with the official end of transportation.\\r\\nTransportation continued in small numbers to Western Australia. The last convict ship, the Hougoumont, left Britain in 1867 and arrived in Western Australia on 10 January 1868. In all, about 164,000 convicts were transported to the Australian colonies between 1788 and 1868 on board 806 ships. Convicts were made up of English and Welsh (70%), Irish (24%), Scottish (5%) and the remaining 1% from the British outposts in India and Canada, Maoris from New Zealand, Chinese from Hong Kong and slaves from the Caribbean.\\r\\nOnly South Australia and the Northern Territory had never accepted convicts directly from England but they still accepted ex-convicts from the other states. Many convicts were allowed to travel as far as New Zealand to make a new life after being given limited freedom, even if they were not allowed to return home to England. At this time the Australian population was approximately 1 million and the colonies could now sustain themselves without the need for convict labour.[18]\\r\\nIn 2010, UNESCO inscribed 11 Australian Convict Sites on its World Heritage List. The listing recognises the sites as \\"the best surviving examples of large-scale convict transportation and the colonial expansion of European powers through the presence and labour of convicts.\\"[19]\\r\\nConvict George Barrington is (perhaps apocryphally) recorded as having written the prologue for the first theatrical play performed by convicts in Australia, one year after the First Fleet's arrival. It is known as \\"Our Country's Good\\", based on the now-famous closing stanza:\\r\\nThe poems of Frank the Poet are among the few surviving literary works done by a convict while still incarcerated. His best-known work is \\"A Convict's Tour of Hell\\". A version of the convict ballad \\"Moreton Bay\\", detailing the brutal punishments meted out by commandment Patrick Logan and his death at the hands of Aborigines, is also attributed to Frank. Other convict ballads include \\"Jim Jones at Botany Bay\\". The ballad \\"Botany Bay\\", which describes the sadness felt by convicts forced to leave their loved ones in England, was written at least 40 years after the end of transportation.\\r\\nPerhaps the most famous convict in all of fiction is Abel Magwitch, a main character of Charles Dickens' 1861 novel Great Expectations. The most famous convict novel is Marcus Clarke's For the Term of His Natural Life (1874), followed by John Boyle O'Reilly's Moondyne (1879). Thomas Keneally explores the convict era in his novels Bring Larks and Heroes (1967) and The Playmaker (1987). Convicts feature heavily in Patrick White's take on the Eliza Fraser story, the 1976 novel A Fringe of Leaves. Convictism is canvassed in Bryce Courtenay's \\"Australian trilogy\\": The Potato Factory (1995), Tommo & Hawk (1997) and Solomon's Song (1999). The title character of Peter Carey's 1997 novel Jack Maggs is a reworking of Dickens' Magwitch character. Many modern works of Tasmanian Gothic focus on the state's convict past, including Gould's Book of Fish (2001) by Richard Flanagan, a fictionalised account of convict artist William Buelow Gould's imprisonment at Macquarie Harbour. Kate Grenville based the novel The Secret River (2005) on the life of her convict ancestor Solomon Wiseman.\\r\\nAlong with bushrangers and other stock characters of colonial life, convicts were a popular subject during Australia's silent film era. The first convict film was a 1908 adaptiation of Marcus Clarke's For the Term of His Natural Life, shot on location at Port Arthur with an unheard-of budget of S7000.[20] This was followed by two more films inspired by Clarke's novel: The Life of Rufus Dawes (1911), which draws on Alfred Dampier's stage production of His Natural Life, and the landmark For the Term of His Natural Life (1927), one of the most expensive silent films ever made.[20] W. J. Lincoln directed many convict melodramas including It Is Never Too Late to Mend (1911), an adaptation of Charles Reade's 1856 novel about cruelties of the convict system; Moodyne (1913), based on John Boyle O'Reilly's novel; and Transported (1913). Other early titles include Sentenced for Life, The Mark of the Lash, One Hundred Years Ago, The Lady Outlaw and The Assigned Servant, all released in 1911. Few convict films were made after 1930; even the Australian New Wave of the 1970s, with its emphasis on Australia's colonial past, largely avoided the convict era in favour of nostalgic period pieces set in the bush around the time of Federation. One exception is Journey Among Women (1977), a feminist imagining of what life was like for convict women.[20] Alexander Pearce, the infamous Tasmanian convict and cannibal, is the inspiration for The Last Confession of Alexander Pearce (2008), Dying Breed (2008) and Van Diemen's Land (2009).","input":"When did the last convicts arrive in australia?"},{"output":"Demolition","context":"WWE (formerly the WWF, WWWF, and its predecessor, Capitol Wrestling) has maintained at least one primary tag team championship since 1958 (except for a two year interim between 1967 and 1969). Whenever brand division has been implemented, separate primary tag team titles have been created or allocated for each brand.\\r\\n\\r\\n\\r\\nCapitol Wrestling set up its first tag team championship, the United States Tag Team Championship in 1958. When Capitol seceded from the National Wrestling Alliance in 1963 and became the World Wide Wrestling Federation (WWWF), the championship became the WWWF United States Tag Team Championship. In 1967, WWWF World Heavyweight Champion Bruno Sammartino teamed with Spiros Arion to win the belts. Due to Sammartino being the world champion, the team vacated the tag titles which were then abandoned.[1]\\r\\nFor two years, the WWWF had no tag team championship until The Rising Suns (Toru Tanaka and Mitsu Arakawa) arrived in the promotion in September 1969 with the WWWF International Tag Team Championship which they claimed to have won in a tournament in Tokyo in June of that year. This became the WWWF's tag team title until 1971, mostly being held by The Mongols.[2] When they left the WWWF, taking the titles with them, the promotion established their own original world tag team championship, the WWWF World Tag Team Championship. In 1979, the promotion became the World Wrestling Federation (WWF) and the tag titles were shortened to WWF Tag Team Championship until 1983 when they were renamed WWF World Tag Team Championship.\\r\\nBy 1988, wrestling magazine Pro Wrestling Illustrated was calling for the establishment of a secondary WWF Intercontinental Tag Team Championship (modelled on the WCW United States Tag Team Championship) due to the glut of tag team competition in the promotion.[3] This never took place, but in 1991, WWF-affiliated promotion UWF Japan introduced the WWF Intercontinental Tag Team Championship, claimed by the team of Perro Aguayo and Gran Hamada. This title was abandoned when the affilaition ended that same year.[4] Similarly, back in May 1985, Tatsumi Fujinami and Kengo Kimura beat Dick Murdoch and Adrian Adonis in a tournament final in Japan for a revival of the old International Tag Team Title of 1969-1971, only for the title to be abandoned again when New Japan and the WWF fell out in October\\r\\nIn 2001, the WWF bought rival company WCW, acquiring the WCW World Tag Team Championship, among other titles, which was defended on WWF programming until that year's Survivor Series, where the WCW World Tag Team Championship was unified into the WWF World Tag Team Championship.[5]\\r\\nAfter WWF's initial brand extension in the spring of 2002 and the renaming of the company as World Wrestling Entertainment (WWE), the tag titles became the WWE Tag Team Championship and champions Billy and Chuck were drafted to the SmackDown brand. That following summer, however, The Un-Americans (Christian and Lance Storm) defeated Billy and Chuck for the titles, moving the championship to the Raw brand where it was renamed World Tag Team Championship, effectively leaving the SmackDown brand without a tag team title. As a result, then-SmackDown General Manager Stephanie McMahon introduced a new WWE Tag Team Championship and commissioned it to be the tag team title for the SmackDown brand.[6]\\r\\nBoth titles were unified in 2009 and were collectively referred to as the \\"Unified WWE Tag Team Championship\\" while officially remaining independently active until the World Tag Team Championship was formally decommissioned in 2010,[5][6] leaving the newer title as WWE's only tag team championship. As a result of the 2016 draft, the championship became exclusive to Raw and was renamed the Raw Tag Team Championship, and SmackDown created the SmackDown Tag Team Championship as a counterpart title.[7] In addition, WWE's developmental brand NXT established its own Tag Team Championship in January 2013. The Raw, SmackDown, and NXT tag team titles are WWE's three currently active tag team championships.\\r\\nThe New Day, Demolition, The Fabulous Kangaroos, The Mongols, and The Ascension all retain the specific records for each of their respective titles held. At present, The Usos hold the specific record for the SmackDown Tag Team Championship at 182 days for their third reign.","input":"Who is the longest reigning wwe tag team champions?"},{"output":"21 April 1526","context":"The First Battle of Panipat, on 21 April 1526, was fought between the invading forces of Babur and the Lodi Kingdom. It took place in north India and marked the beginning of the Mughal Empire. This was one of the earliest battles involving gunpowder firearms and field artillery in the Indian subcontinent which were introduced by Mughals in this battle.[4]\\r\\n\\r\\n\\r\\nAfter losing Samarkand for the second time, Babur gave attention to conquer India as he reached the banks of the Chenab in 1519.[6] Until 1524, his aim was to only expand his rule to Punjab, mainly to fulfil his ancestor Timur's legacy, since it used to be part of his empire.[7] At the time parts of north India were under the rule of Ibrahim Lodi of the Lodi dynasty, but the empire was crumbling and there were many defectors. He received invitations from Daulat Khan Lodi, Governor of Punjab and Ala-ud-Din, uncle of Ibrahim.[8] He sent an ambassador to Ibrahim, claiming himself the rightful heir to the throne of the country, however the ambassador was detained at Lahore and released months later.[6]\\r\\nBabur started for Lahore, Punjab, in 1524 but found that Daulat Khan Lodi had been driven out by forces sent by Ibrahim Lodi.[9] When Babur arrived at Lahore, the Lodi army marched out and his army was routed.[9] In response, Babur burned Lahore for two days, then marched to Dipalpur, placing Alam Khan, another rebel uncle of Lodi's, as governor.[9] Alam Khan was quickly overthrown and fled to Kabul. In response, Babur supplied Alam Khan with troops who later joined up with Daulat Khan Lodi and together with about 30,000 troops, they besieged Ibrahim Lodi at Delhi.[10] He defeated them and drove off Alam's army and Babur realised Lodhi would not allow him to occupy the Punjab.[10]\\r\\nHearing of the size of Ibrahim's army, Babur secured his right flank against the city of Panipat, while digging a trench covered with tree branches to secure his left flank. In the center, he placed 700 carts tied together with ropes. Between every two carts there were breastworks for his matchlockmen. Babur also ensured there was enough space for his cavalry to charge between these carts.[11]\\r\\nWhen Ibrahim's army arrived, he found the approach to Babur's army too narrow to attack. While Ibrahim redeployed his forces to allow for the narrower front, Babur quickly took advantage of the situation to flank (tulghuma) the Lodi army.[1] Many of Ibrahim's troops were unable to get into action, and fled when the battle turned against Ibrahim.[12] Faced with musket fire, cannon fire and cavalry attacks from all sides, Ibrahim Lodi fought and died with 6,000 of his remaining troops.[1]\\r\\nBabur's guns proved decisive in battle, firstly because Ibrahim lacked any field artillery, but also because the sound of the cannon frightened Ibrahim's elephants, causing them to trample his own men.[2]\\r\\nNew tactics introduced by Babur were the tulghuma and the araba. Tulghuma meant dividing the whole army into various units, viz. the Left, the Right and the Centre. The Left and Right divisions were further subdivided into Forward and Rear divisions. Through this a small army could be used to surround the enemy from all sides. The Centre Forward division was then provided with carts (araba) which were placed in rows facing the enemy and tied to each other with animal hide ropes. Behind them were placed cannons protected and supported by mantlets which could be used to easily maneuver the cannons. These two tactics made Babur's artillery lethal. The cannons could be fired without any fear of being hit, as they were shielded by the bullock carts held in place by hide ropes. The heavy cannons could also be easily traversed onto new targets, as they could be maneuvered by the mantlets which were on wheels.\\r\\nIbrahim Lodi died on the field of battle along with 15,000 of his troops. The battle of Panipat was militarily a decisive victory. Politically it gained Babur little, and initiated a new phase of his establishment of the Mughal empire.[13]","input":"When did first battle of panipat taken place?"},{"output":"The Fast and the Furious: Tokyo Drift","context":"Crew members:\\r\\n\\r\\nHan Lue is a fictional character in The Fast and the Furious franchise. He first appears in The Fast and the Furious: Tokyo Drift as the mentor of Sean Boswell, dying in a collision in the film's climax. Han's status as a member of Dominic Toretto's crew was shown in the subsequent films Fast & Furious, Fast Five, Fast & Furious 6 and Furious 7, as well as the short film Los Bandoleros.\\r\\n\\r\\nThe character was said to have been inspired by another character Kang portrayed, Han Hu in Better Luck Tomorrow, directed by Justin Lin. When Lin was recruited to direct Tokyo Drift, he pitched the idea of adding an Asian character to be the \\"cool guy\\" specifically with Han Hu in mind. Kang was only supposed to appear in a one-off but was brought back in the subsequent prequel films due to positive responses from audiences.[1]\\r\\n\\r\\nLiving in Tokyo, Han uses his new-found wealth to start his own garage, as well as purchasing various expensive, modified tuner cars to store in the garage. Han also keeps himself occupied with various women, with a club attached next door to his garage. Additionally, he becomes involved with Tokyo's elite street racers and one of its most prominent drifters. At some point, he acquired a 2001 Nissan Silvia S15 Spec-S and rebuilt and restored it from the ground up, the car later being referred to by Twinkie as the Mona Lisa of the drift world.\\r\\n\\r\\nHan also affiliates himself with Takashi, the nephew of Kamata, a Yakuza member, securing profits from various business ventures. Unbeknownst to either Kamata or Takashi, Han begins stealing money from their operation and does so without either of them noticing for some time.\\r\\n\\r\\nWhen Han meets Sean Boswell, Boswell crossed Takashis unspoken boundaries by speaking to his girlfriend, Neela. Han questions why Takashi is still bothering with high school girls when Takashi decides to confront Sean. When Sean accepts Takashis challenge to drift, Han gives Sean the keys to his Nissan Silvia, curious to see what Sean is made of.\\r\\n\\r\\nWhile Sean loses the race, destroying his car in the process, Han is intrigued by what he saw in Sean for merely challenging Takashi. The following day, Han meets Sean outside of his school and demands that he get into his car. Han makes a point to tell Sean that he is in his debt and would be his personal errand boy on account of the car that he owes him. Sean is willing to agree to the terms so long as Han teaches him how to drift.\\r\\n\\r\\nWhen Sean falls out of favor with his father, Lieutenant Boswell, Sean comes to live in Hans garage.  While there, he works on the cars available to him in the garage and Han teaches him how to drift properly.  As Sean improves, Hans situation is complicated when Takashi becomes more forceful in threatening Sean to stay away from Neela.  Eventually Takashi confronts Han about the money he's been stealing from his uncle.  Han does not attempt to defend his actions to Takashi.\\r\\n\\r\\nHe merely states that the side deals he made while under the protection of Takashis word were in the nature of their business.  He goes on to say that Takashi needed him and that he wouldve amounted to nothing if it wasnt for his help.  When Takashi becomes distracted by the presence of Neela, Han takes his chance and climbs into his car and escapes.\\r\\n\\r\\nTakashi and his friend, Morimoto pursue him through the streets of Tokyo, but they are unable to catch him.  He protects Sean and Neela from Takashi, allowing them to get ahead of him. When Han finally reaches the intersection of the road, Hans car is t-boned by a Mercedes S-Class. Hans car is flipped onto its top. Han, unable to escape the car, is killed in the explosion.\\r\\n\\r\\nSome time after Hans death, Sean Boswell meets Dominic Toretto after he requests an audience with him at the parking garage. Dominic races Sean with the 1970 Plymouth Road Runner he won from Han years before.\\r\\n\\r\\nIn Los Bandoleros, Han visited Mexico, where he met Dominic \\"Dom\\" Toretto and established a relationship. Han begins running with Dominic for unspecified reasons. Dominic wins 1970 Plymouth Road Runner off of Han in a race.\\r\\n\\r\\nHan arrives in the Dominican Republic when Dominic Toretto is preparing  for a new job regarding the transportation of gas. He is picked up at the airport by the likes of Cara and Malo, Dominic's friends. He is later taken to Rico Santos' house, where Dominic lives, and they have dinner with the rest of the Santos family. He takes an immediate attraction to Cara, who shares a mutual attraction for him.\\r\\n\\r\\nLater, he follows Dominic and Santos to the prison where Tego Leo was being kept before Santos helped him escape. When Dominic takes to take them to a secluded club to meet the man responsible for the transport of their score, Dominic tells him to drive around the block or wait in the car. Han instead decides to enter the club where he mingles with Cara and Malo at the bar.\\r\\n\\r\\nWhen Cara asked how he met Dominic, Han briefly explained how they first met each other in Mexico. Malo, realizing that the two were attracted to each other, asked if they wanted a room. Cara instead gives him her drink and she and Han leave the bar.\\r\\n\\r\\nHan is seen only in the beginning of Fast & Furious. He along with Letty Ortiz, Toretto, Tego Leo, Rico Santos, and Cara, are hijacking a fuel tanker in the Dominican Republic. Han and Cara hijack the first two tankers while Leo and Santos hijack the other two tankers, not before the truck driver gives them a little problem after seeing Letty on top of the tanker and notices that the hijacking is going on. After the hijacking is done, Toretto disbands the crew after suspecting that the police are closing in on Toretto and his gang.\\r\\n\\r\\nHan is recruited for a heist in the events of Fast Five as a precision driver and a \\"chameleon\\". During the events of the film, he starts to fall in love with another member of the crew, Gisele Yashar. At the end of the film, Han and Gisele are seen driving on a highway and are in a relationship.\\r\\n\\r\\nWhen Han and Gisele arrive in London, theyre given the details of their situation with Owen Shaw and Letty Ortiz by Luke Hobbs. During their first encounter with Shaws team, Han, Brian and Gisele are attacked by the sniper Adolfson, who fires on their cars once they reach Interpol.\\r\\n\\r\\nBrian, Han and Gisele are pinned down long enough for Vegh, Jah and Klaus to escape. Brian follows after them, but Gisele runs out into the open to fire on Jan and Klauss getaway car. At the last second, Han is able to pull her out of the way and the two take cover behind a fire hydrant as Adolfson fires on them multiple times before escaping.\\r\\n\\r\\nDuring the team's attempt to stop Owen and his team from hijacking the military convoy, Han and Gisele pursue Denlinger on their motorcycles, a Harley Davidson XR1200 and Ducati Monster. Gisele is the first to reach Dillinger, hangs on the side of his Land Rover and is nearly crushed on the side of oncoming truck, but Han jumps onto the Land Rover in time to swerve the vehicle out of the way and save her life.\\r\\n\\r\\nWhen Mia Toretto is taken prisoner by Shaw, Dominic and the others are forced to let Shaw and Riley Hicks, a double agent working with both Owen and Hobbs, go to ensure her safety. However, as soon as theyre allowed, they go after the plane Shaw is planning to take off on with Mia. Gisele and Han are one of two teams designated with the task of keeping the plane on the ground using the harpoons. During their efforts, Gisele is pulled out of their car by Adolfson. Han follows after her, climbing onto the top of their car.\\r\\n\\r\\nThough Gisele is able to fend him off, she is knocked off of Adolfsons car. Han is able to save at the last moment. Gisele, realizing that Adolfson plans to kill Han, let go of Hans arms and allows herself to fall, Han unable to save her. Before she is killed from the fall, she shoots Adolfson, knocking him off balance. A devastated Han attacks Adolfson and throws him off of the car and into the turbine of the plane.\\r\\n\\r\\nAfter the plane crashes and Dominic survives the car crash in the attempt to escape the burning plane, Mia and Brian are the only ones to approach Han and attempts to comfort him when she realizes what happened to Gisele when she isn't with him.\\r\\n\\r\\nWith their records cleared by the pardons provided by Hobbs, Han and the others return to Los Angeles. While speaking with Roman Pearce and Tej Parker, Han ultimately decided to go to Tokyo.\\r\\n\\r\\nIn the post-credits scene of Fast & Furious 6, Han's death from The Fast and the Furious: Tokyo Drift is shown, and it is revealed that Deckard Shaw, Owen's brother has driven the car that crashed into his.\\r\\n\\r\\nHan's death is seen again in Furious 7 through archival footage from The Fast and the Furious: Tokyo Drift and Fast & Furious 6, occurring the same time a bomb package delivered to Dominic's house goes off. Han's death was the reason Dominic appeared in Tokyo at the end of Tokyo Drift - to retrieve his body back to Los Angeles for burial. After racing with Sean Boswell, Dominic receives several of Han's personal items, including a photo of Gisele. The crew attended Han's funeral in Los Angeles a few days later, with Dominic spying Han's killer Deckard Shaw watching from a distance, and giving chase, leading to their confrontation.\\r\\n\\r\\nHan is known for munching on snacks. As pointed out by Gisele in Fast Five, this is part of his constant need to occupy his hands, as he is a former smoker. According to director Justin Lin, this is an Easter egg reference to the other chain-smoking Han Hu character in Better Luck Tomorrow.\\r\\n\\r\\nFollowing the death of Gisele in Fast & Furious 6, Han leaves the United States to live in Tokyo, Japan, setting up his appearance in The Fast and the Furious: Tokyo Drift. Han was initially the only character from Tokyo Drift to appear in the subsequent films, before Sean Boswell's appearance in Furious 7. Both Sung Kang and Justin Lin explain the surname \\"Seoul-Oh\\" that Han uses in Fast & Furious 6 and Furious 7 is a fake ID.[2] As a result, it is largely accepted by the franchise's fanbase that Han Lue and Han Seoul-Oh are canonically the same character.[3]\\r\\n\\r\\nIn the short film Los Bandoleros and the film Fast & Furious, he was in a relationship with Cara until they broke up by the time the events of Fast Five takes place. At the end of the film and all of Fast & Furious 6 he was in a relationship with Gisele Yashar until her death in the runway battle.","input":"When was han killed in fast and furious?"},{"output":"April 21, 1649","context":"The Maryland Toleration Act, also known as the Act Concerning Religion, was a law mandating religious tolerance for Trinitarian Christians. It was passed on April 21, 1649, by the assembly of the Maryland colony, in St. Mary's City. It was the second law requiring religious tolerance in the British North American colonies and created one of the pioneer statutes passed by the legislative body of an organized colonial government to guarantee any degree of religious liberty. Specifically, the bill, now usually referred to as the Toleration Act, granted freedom of conscience to all Christians.[1] (The colony which became Rhode Island passed a series of laws, the first in 1636, which prohibited religious persecution including against non-Trinitarians; Rhode Island was also the first government to separate church and state.) Historians argue that it helped inspire later legal protections for freedom of religion in the United States. The Calvert family, who founded Maryland partly as a refuge for English Catholics, sought enactment of the law to protect Catholic settlers and those of other religions that did not conform to the dominant Anglicanism of Britain and her colonies.\\r\\nThe Act allowed freedom of worship for all Trinitarian Christians in Maryland, but sentenced to death anyone who denied the divinity of Jesus. It was revoked in 1654 by William Claiborne, a Virginian who had been appointed as a commissioner by Oliver Cromwell; he was an Anglican, a Puritan sympathizer, and strongly hostile to the Catholic Religion. When the Calverts regained control of Maryland, the Act was reinstated, before being repealed permanently in 1692 following the events of the Glorious Revolution, and the Protestant Revolution in Maryland. As the first law on religious tolerance in the British North America, it influenced related laws in other colonies and portions of it were echoed in the writing of the First Amendment to the United States Constitution, which enshrined religious freedom in American law.\\r\\n\\r\\n\\r\\nThe Maryland colony was founded by Cecil Calvert in 1634. Like his father George Calvert, who had originated the efforts that led to the colony's charter, Cecil Calvert was Catholic at a time when England was dominated by the Anglican Church.[2] The Calverts intended the colony as a haven for Catholics fleeing England and as a source of income for themselves and their descendants.[3] Many of Maryland's first settlers were Catholic, including at least two Catholic priests, one of whom became the earliest chronicler of the colony's history.[4] But whatever Calvert's intentions, Maryland was a colony of an Anglican nation. Its charter had been granted by an Anglican king and seems to have assumed that the Church of England would be its official church. Anglican and later Puritan newcomers quickly came to outnumber the early Catholic settlers. Thus, by 1649 when the law was passed, the colonial assembly was dominated by Protestants, and the law was in effect an act of Protestant tolerance for Catholics, rather than the reverse.[3]\\r\\nFrom Maryland's earliest days, Cecil Calvert had enjoined its colonists to leave religious rivalries behind. Along with giving instructions on the establishment and defense of the colony, he asked the men he appointed to lead it to ensure peace between Protestants and Catholics. He also asked the Catholics to practice their faith as privately as possible, so as not to disturb that peace.[5] The Ordinance of 1639, Maryland's earliest comprehensive law, expressed a general commitment to the rights of man, but did not specifically detail protections for religious minorities of any kind.[6] Peace prevailed until the English Civil War, which opened religious rifts and threatened Calvert's control of Maryland.[7] In 1647, after the death of Governor Leonard Calvert, Protestants seized control of the colony. Cecil Calvert, 2nd Baron Baltimore, quickly regained power, but recognized that religious tolerance not specifically enshrined in law was vulnerable.[8] This recognition was combined with the arrival of a group of Puritans whom Calvert had induced to establish Providence, now Annapolis, by guaranteeing their freedom of worship.[9] Partially to confirm the promises he made to them, Calvert wrote the Maryland Toleration Act and encouraged the colonial assembly to pass it. They did so on April 21, 1649.[8]\\r\\nThe Maryland Toleration Act was an act of tolerance, allowing specific religious groups to practice their religion without being punished, but retaining the ability to revoke that right at any time. It also only granted tolerance to Christians who believed in the Trinity.[3] The law was very explicit in limiting its effects to Christians:[10]\\r\\n...no person or persons...professing to believe in Jesus Christ, shall from henceforth be anyways troubled, Molested or discountenanced for or in respect of his or her religion nor in the free exercise thereof within this Province...\\r\\nSettlers who blasphemed by denying either the Trinity or the divinity of Jesus Christ could be punished by execution or the seizure of their lands. That meant that Jews, Unitarians, and other dissenters from Trinitarian Christianity were practicing their religions at risk to their lives.[8] Any person who insulted the Virgin Mary, the apostles, or the evangelists could be whipped, jailed, or fined. Otherwise, Trinitarian Christians' right to worship was protected. The law outlawed the use of \\"heretic\\" and other religious insults against them.[3] This attempt to limit the use of religious slurs and insults has been described as the first attempt in the world to limit the use of hate speech.[11]\\r\\nThe law was used in at least one attempt to prosecute a non-Christian. In 1658 a Jew named Jacob Lumbrozo was accused of blasphemy after saying that Jesus was not the son of God and that the miracles described in the New Testament were conjuring tricks. Lumbrozo did not deny having said such things, but argued that he had only been responding to questions asked of him.[12] He was held for trial but the case was later dismissed, and he was given full citizenship as a condition of the restoration of Calvert's rule following the English Civil War.[13]\\r\\nThe law had its detractors, even among those groups protected by it. Puritans were concerned that the act and the proprietary government in general were royalist. They were also concerned that by swearing allegiance to Calvert, who was Catholic, they were being required to submit to the Pope, whom they considered to be the antichrist. Some Anglicans also opposed the law, believing that the Church of England should be the colony's sole established church.[13]\\r\\nIn 1654, only five years after its passage, the Act was repealed.[8] Two years earlier the colony had been seized by Protestants following the execution of King Charles I of England and the outbreak of the English Civil War. In the early stages of that conflict, the colonial assembly of Maryland and its neighbors in Virginia had publicly declared their support for the King. Parliament appointed Protestant commissioners loyal to their cause to subdue the colonies, and two of them, the Virginian William Claiborne and Puritan leader Richard Bennett, took control of the colonial government in St. Mary's City in 1652. In addition to repealing the Maryland Toleration Act with the assistance of Protestant assemblymen, Claiborne and Bennett passed a new law barring Catholics from openly practicing their religion.[14] Calvert regained control after making a deal with the colony's Protestants, and in 1657 the Act was again passed by the colonial assembly. This time, it would last more than thirty years, until 1692.[8]\\r\\nFollowing the Glorious Revolution of 1688 in England, when the Catholic King James II of England was deposed and the Protestant William III ascended the throne, a rebellion of Maryland Puritan Protestants overthrew Calvert's rule. They quickly rescinded the Toleration Act and banned public practice of Catholicism, and it would never be reinstated under colonial rule. In fact, the colony established the Church of England as its official church in 1702 and explicitly barred Catholics from voting in 1718.[8] The Calvert family regained control over the colony in 1715, but only after Benedict Calvert converted to Protestantism. His political control remained tenses enough that he did not risk an attempt to reinstate protections for Catholics.[15] It took until the era of the American Revolution for religious tolerance or freedom to again become the practice in Maryland.[8]\\r\\nWhile the law did not secure religious freedom, and while it included severe limitations, it was nonetheless a significant milestone. It predates the Enlightenment, which is generally considered to be when the idea of religious freedom took root, and stands as the first legal guarantee of religious tolerance in American and British history. Later laws ensuring religious tolerance and freedom, including the British Act of Toleration of 1689, the Holy Experiment in Pennsylvania, and laws concerning religion in other colonies such as South Carolina, may have been influenced by its example.[3][12] According to historian Robert Brugger, \\"...the measure marked a notable departure from Old World oppression.\\"[9] It was not until the passage of the signed First Amendment to the Constitution over a century later that religious freedom was enshrined as a fundamental guarantee,[3] but even that document echoes the Toleration Act in its use of the phrase, \\"free exercise thereof\\". Thus, despite its lack of a full guarantee of religious freedom or broad-based tolerance, the law is, \\"a significant step forward in the struggle for religious liberty.\\"[8]","input":"When did maryland make anglicanism it's established religion?"},{"output":"Florence Green","context":"This is a list of the last World War I veterans to die by country. The last living veteran of World War I (28 July 1914 ÿ 11 November 1918) was Florence Green, a British citizen who served in the Allied armed forces, and who died 4 February 2012, aged 110.[1] The last combat veteran was Claude Choules who served in the British Royal Navy (and later the Royal Australian Navy) and died 5 May 2011, aged 110.[2] The last veteran who served in the trenches was Harry Patch (British Army) who died on 25 July 2009, aged 111. The last Central Powers veteran, Franz Knstler of Austria-Hungary, died on 27 May 2008 at the age of 107.\\r\\n\\r\\nThe total number of participating personnel is estimated by the Encyclop?dia Britannica at 65,038,810. There were approximately 9,750,103 military deaths during the conflict.\\r\\n\\r\\nVeterans, for this purpose, are defined as people who were members of the armed forces of one of the combatant nations up to and including the date of the Armistice. This policy may vary from the policy in actual use in some countries.","input":"When did the last survivor of ww1 die?"},{"output":"31 May 1985","context":"The Heysel Stadium disaster (French:?[?iz?l], Dutch:?[???iz?l]?(?listen); Dutch: Heizeldrama; French: Drame du Heysel) occurred on 29 May 1985 when escaping fans were pressed against a collapsing wall in the Heysel Stadium in Brussels, Belgium, before the start of the 1985 European Cup Final between Juventus of Italy and Liverpool of England. 39 peoplemostly Italians and Juventus fanswere killed and 600 were injured in the confrontation.[1]\\r\\nApproximately an hour before the Juventus-Liverpool final was due to kick off, Liverpool supporters charged at Juventus fans and breached a fence that was separating them from a \\"neutral area\\". This came after a period of hostility between the two sets of fans which saw missiles thrown by both teams' supporters. The instigators of violence are still unknown, with varying accounts.[2][3] Juventus fans ran back on the terraces and away from the threat into a concrete retaining wall. Fans already standing near the wall were crushed; eventually the wall collapsed. Many people climbed over to safety, but many others died or were badly injured. The game was played despite the disaster, with Juventus winning 1ÿ0.[4]\\r\\nThe tragedy resulted in all English football clubs being placed under an indefinite ban by UEFA from all European competitions (lifted in 1990ÿ91), with Liverpool being excluded for an additional three years, later reduced to one,[5] and fourteen Liverpool fans found guilty of manslaughter and each sentenced to three years' imprisonment. The disaster was later described as \\"the darkest hour in the history of the UEFA competitions\\".[6]\\r\\n\\r\\n\\r\\nIn May 1985, Liverpool were the defending European Champions' Cup winners, having won the competition after defeating Roma in the penalty shootout in the final of the previous season. Again they would face Italian opposition, Juventus, who had won, unbeaten, the 1983ÿ84 Cup Winners' Cup. Juventus had a team comprising many of Italy's 1982 FIFA World Cup winning teamÿwho played for Juventus for many yearsÿand their playmaker Michel Platini was considered the best footballer in Europe, being named Footballer of The Year by France Football magazine for the second year in a row in December 1984. Both teams were placed in the two first positions in the UEFA club ranking at the end of the last season[7] and were regarded by the specialist press as the best two sides on the continent at the time.[8] Both teams had contested the 1984 European Super Cup four months before, finishing with victory for the Italian side by 2ÿ0.\\r\\nDespite its status as Belgium's national stadium, Heysel was in a poor state of repair by the time of the 1985 European Final. The 55-year-old stadium had not been sufficiently maintained for several years, and large parts of the stadium were literally crumbling. For example, the outer wall had been made of cinder block, and fans who did not have tickets were seen kicking holes in it to get in.[9] Liverpool players and fans later said that they were shocked at Heysel's abject condition, despite reports from Arsenal fans that the ground was a \\"dump\\" when Arsenal had played there a few years earlier. They were also surprised that Heysel was chosen despite its poor condition, especially since Barcelona's Camp Nou and Bernabu in Madrid were both available. Juventus president Giampiero Boniperti and Liverpool CEO Peter Robinson urged UEFA to choose another venue, claiming that Heysel was not in any condition to host a European Final, especially a European Final involving two of the largest and most powerful clubs in Europe. However, UEFA refused to consider a move.[10][11]\\r\\nThe stadium was crammed with 58,000ÿ60,000 supporters, with more than 25,000 for each team. The two ends behind the goals comprised all-standing terraces, each end split into three zones. The Juventus end was O, N and M and the Liverpool end was X, Y and Z as deemed by the Belgian court after the disaster. However, the tickets for the Z section were reserved for neutral Belgian fans in addition to the rest of the stadium. This meant the Juventus fans had more sections than the Liverpool fans with the Z section occupied by neutrals which is thought to have heightened prematch tensions. The idea of the large neutral area was opposed by both Liverpool and Juventus,[12] as it would provide an opportunity for fans of both clubs to obtain tickets from agencies or from ticket touts outside the ground and thus create a dangerous mix of fans.\\r\\nAt the time Brussels, like the rest of Belgium, already had a large Italian community, and many expatriate Juventus fans bought the section Z tickets.[13] Added to this, many tickets were bought up and sold by travel agents, mainly to Juventus fans. A small percentage of the tickets ended up in the hands of Liverpool fans.\\r\\nAt approximately 7 p.m. local time, an hour before kick-off, the trouble started.[14] The Liverpool and Juventus supporters in sections X and Z stood merely yards apart. The boundary between the two was marked by temporary chain link fencing and a central thinly policed no-man's land.[15] Fans began to throw stones across the divide, which they were able to pick up from the crumbling terraces beneath them.\\r\\nAs kick-off approached, the throwing became more intense. Several groups of Liverpool fans broke through the boundary between section X and Z, overpowered the police, and charged at the Juventus fans. The fans began to flee toward the perimeter wall of section Z. The wall could not withstand the force of the fleeing Juventus supporters and a lower portion collapsed.\\r\\nContrary to reports at the time, and what is still assumed by many, the collapse of the wall did not cause the 39 deaths. Instead, the collapse relieved pressure and allowed fans to escape. Most died of suffocation after tripping or being crushed against the wall before the collapse. A further 600 fans were also injured. Bodies were carried out from the stadium on sections of iron fencing and laid outside, covered with giant football flags. As police and medical helicopters flew in, the down-draught blew away the modest coverings.\\r\\nIn retaliation for the events in section Z, many Juventus fans then rioted at their end of the stadium. They advanced down the stadium running track to help other Juventus supporters, but police intervention stopped the advance. A large group of Juventus fans fought the police with rocks, bottles and stones for two hours. One Juventus fan was also seen firing a starting gun at Belgian police. [16]\\r\\nDespite the scale of the disaster, UEFA officials, Belgian Prime Minister Wilfried Martens, Brussels Mayor Herv Brouhon, and the city's police force felt that abandoning the match would have risked inciting further trouble and violence, and the match eventually kicked off after the captains of both sides spoke to the crowd and appealed for calm.[17]\\r\\nJuventus won the match 1ÿ0 thanks to a penalty scored by Michel Platini, awarded by Swiss referee Daina for a foul against Zbigniew Boniek.[18]\\r\\nAt the end of the game the trophy was given in front of the stadium's Honor Stand by the confederation president Jacques Georges to Juventus captain Gaetano Scirea. Due to collective hysteria generated by the massive invasion of the pitch by journalists and fans at the end of the match,[19] and the chants of fans of both teams in the stands,[20] some Italian club players celebrated the title in the middle of the pitch among them and in front of their fans in the M section, while some Liverpool players applauded their fans between the X and Z sections, the stadium's section affected.[21]\\r\\nInitially, the blame for the incident was laid on the fans of Liverpool FC. On 30 May official UEFA observer Gunter Schneider said, \\"Only the English fans were responsible. Of that there is no doubt.\\" UEFA, the organiser of the event, the owners of Heysel Stadium and the Belgian police were investigated for culpability. After an 18-month investigation, the dossier of top Belgian judge Marina Coppieters was finally published. It concluded that blame should not rest solely with the English fans, and that some culpability lay with the police and authorities. Several top officials were incriminated by some of the dossiers findings, including police captain Johan Mahieu, who had been in charge of security on 29 May 1985 and was subsequently charged with manslaughter.\\r\\nThe British police undertook a thorough investigation to bring to justice the perpetrators. Some 17 minutes of film and many still photographs were examined. TV Eye produced an hour-long programme featuring the footage and the British press also published the photographs.\\r\\nA total of 34 people were arrested and questioned with 26 Liverpool fans being charged with manslaughter ÿ the only extraditable offence applicable to events at Heysel. An extradition hearing in London in FebruaryÿMarch 1987 ruled all 26 were to be extradited to stand trial in Belgium for the death of Juventus fan Mario Ronchi. In September 1987 they were extradited and formally charged with manslaughter applying to all 39 deaths and further charges of assault. Initially, all were held at a Belgian prison but over the subsequent months judges permitted their release as the start of the trial became ever more delayed.\\r\\nThe trial eventually got underway in October 1988, with three Belgians also standing trial for their role in the disaster: Albert Roosens, the head of the Belgian Football Association, for allowing tickets for the Liverpool section of the stadium to be sold to Juventus fans; and two police chiefs - Michel Kensier and Johann Mahieu - who were in charge of policing at the stadium that night. Two of the 26 Liverpool fans were in custody in Britain at the time and stood trial later. In April 1989, 14 fans were convicted and given three-year sentences, that were half suspended for five years, allowing them to return to the UK.[22] After Belgian prosecutors appealed the sentences as too lenient, an appeal took place in Spring 1990 that increased the sentences of 11 fans (to five or four years), with two having their sentences upheld and one being acquitted.[citation needed]\\r\\nPressure mounted to ban English clubs from European competition. On 31 May 1985, British Prime Minister Margaret Thatcher asked the FA to withdraw English clubs from European competition before they were banned,[23] but two days later, UEFA banned English clubs for \\"an indeterminate period of time\\". On 6 June, FIFA extended this ban to all worldwide matches, but this was modified a week later to allow friendly matches outside of Europe to take place. In December 1985 FIFA announced that English clubs were also free to play friendly games in Europe, though the Belgian government banned any English clubs playing in their country.\\r\\nThough the English national team was not subjected to any bans, English club sides were banned indefinitely from European club competitions, with Liverpool being provisionally subject to a further three years suspension as well. In April 1990, following years of campaigning from the English football authorities, UEFA confirmed the reintroduction of English clubs (with the exception of Liverpool) into its competitions from the 1990ÿ91 season onward; in April 1991 UEFA's Executive Committee voted to allow Liverpool back into European competition from the 1991ÿ92 season onward, a year later than their compatriots, but two years earlier than initially foreseen. In the end, all English clubs served a five-year-ban, while Liverpool were excluded for six years.\\r\\nAccording to former Liverpool striker Ian Rush, the institutional relationships between both clubs and their fans improved during his career in Italy.[10]\\r\\nThe following clubs were denied entry to European competitions during this period:\\r\\n(2nd)\\r\\nThe number of places available to English clubs in the UEFA Cup would however have been reduced had English teams been eliminated early in the competition. By the time of the readmittance of all English clubs except Liverpool in 1990ÿ91, England was only granted one UEFA Cup entrant (awarded to the league runners-up); prior to the ban, they had had four entry slots, a number not awarded to England again until the 1994ÿ95 UEFA Cup. Welsh clubs playing in the English league system, who could qualify for the Cup Winners' Cup through the Welsh Cup, were unaffected by the ban.\\r\\nIn the meantime, many other clubs missed out on a place in the UEFA Cup due to the return of English clubs to European competitions only being gradual.\\r\\nLiverpool's additional year of exclusion from Europe meant that there was no English representation in the 1990-91 European Cup, as they were defending league champions that season. Football League Cup winners Nottingham Forest also missed out on UEFA Cup places in 1990-91, along with Tottenham Hotspur, Arsenal and Chelsea.\\r\\nThe teams who missed out on the 1991ÿ92 UEFA Cup for the same reason were Sheffield Wednesday, Crystal Palace and Leeds United.\\r\\nThe excluded teams in 1992ÿ93 were Arsenal and Manchester City.\\r\\nIn 1993ÿ94, the excluded teams were Blackburn Rovers and Queens Park Rangers.\\r\\nThe final season of partial exclusion was 1994ÿ95, when Leeds United missed out.\\r\\nAfter Heysel, English clubs began to impose stricter rules intended to make it easier to prevent troublemakers from attending domestic games, with legal provision to exclude troublemakers for three months introduced in 1986, and the Football (Offences) Act introduced in 1991.\\r\\nSerious progress on legal banning orders preventing foreign travel to matches was arguably not made until the violence involving England fans (allegedly mainly involving neo-Nazi groups, such as Combat 18) at a match against Ireland on 18 February 1995 and violent scenes at the 1998 FIFA World Cup. Rioting at UEFA Euro 2000 saw introduction of new legislation and wider use of police powers ÿ by 2004, 2,000 banning orders were in place, compared to fewer than 100 before Euro 2000.[24][25]\\r\\nThe main reforms to English stadiums came after the Taylor Report into the Hillsborough disaster in which 96 people died in 1989. All-seater stadiums became a requirement for clubs in the top two divisions while pitchside fencing was removed and closed-circuit cameras have been installed. Fans who misbehave can have their tickets revoked and be legally barred from attending games at any English stadium.\\r\\nThe Heysel Stadium itself continued to be used for hosting athletics for almost a decade, but no further football matches took place in the old stadium. In 1994, the stadium was almost completely rebuilt as the King Baudouin Stadium. On 28 August 1995 the new stadium welcomed the return of football to Heysel in the form of a friendly match between Belgium and Germany. It then hosted a major European final on 8 May 1996 when Paris Saint-Germain defeated Rapid Vienna 1ÿ0 to win the Cup Winners' Cup.\\r\\nIn 1985, a memorial was presented to the victims at the Juventus headquarters in Piazza Crimea, Turin. The monument includes an epitaph written by Torinese journalist Giovanni Arpino. Since 2001 it has been situated in front of the current club's headquarters in Corso Galileo Ferraris.[26]\\r\\nIn 1986 the band Revolting Cocks, founded in part by Al Jourgensen of Ministry, released a song by the name of \\"38\\", in commemoration to the deaths of this tragic event on the album Big Sexy Land.[citation needed]\\r\\nA memorial service for those killed in the disaster was held before Liverpool's match with Arsenal at Anfield on 18 August 1985, their first fixture after the disaster. However, according to The Sydney Morning Herald, it was \\"drowned out\\" by chanting.[27]\\r\\nIn 1991, a memorial monument for the 39 victims of the disaster, the only one on Italian soil, was inaugurated in Reggio Emilia, the hometown of the victim Claudio Zavaroni, in front of Stadio Mirabello: every year the committee \\"Per non dimenticare Heysel\\" (In order not to forget Heysel) holds a ceremony on the 29th of May with relatives of the victims, representatives of Juventus, survivors and various supporters clubs from various football clubs, including Inter Milan, AC Milan, Reggiana and Torino.[28]\\r\\nDuring Euro 2000, members of the Italian team left flowers on the site, in honour of the victims.\\r\\nOn 29 May 2005, a S140,000 sculpture was unveiled at the new Heysel stadium, to commemorate the disaster. The monument is a sundial designed by French artist Patrick Rimoux and includes Italian and Belgian stone and the poem \\"Funeral Blues\\" by Englishman W.?H.?Auden to symbolise the sorrow of the three countries. Thirty-nine lights shine, one for each who died that night.[29]\\r\\nJuventus and Liverpool were drawn together in the quarter-finals of the 2005 Champions League, their first meeting since Heysel. Before the first leg at Anfield, Liverpool fans held up placards to form a banner saying \\"amicizia\\" (\\"friendship\\" in Italian). Many of the Juventus fans applauded the gesture, although a significant number chose to turn their backs on it.[30] In the return leg in Turin, Juventus fans displayed banners reading Easy to speak, difficult to pardon: murders and 15-4-89. Sheffield. God exists, the latter a reference to the Hillsborough disaster, in which 96 Liverpool fans were killed in a crush. A number of Liverpool fans were attacked in the city by Juventus ultras.[31]\\r\\nBritish composer Michael Nyman wrote a piece called \\"Memorial\\" which was originally part of a larger work of the same name written in 1985 in memory of the Juventus fans who died at Heysel Stadium.\\r\\nOn Wednesday 26 May 2010, a permanent plaque was unveiled on the Centenary Stand at Anfield to honour the Juventus fans who died 25 years earlier. This plaque is one of two permanent memorials to be found at Anfield, along with one for the 96 fans killed in the Hillsborough disaster in 1989.\\r\\nIn May 2012, a Heysel Memorial was unveiled in the J-Museum at Turin. There is also a tribute to the disaster's victims in the club's Walk of Fame in front of the Juventus Stadium. Two years later Juventus' officials announced a memorial in the Continassa headquarter.\\r\\nIn February 2014, an exhibition in Turin was dedicated both to the Heysel tragedy and Superga air disaster. The name of the exhibition was \\"Settanta angeli in un unico cielo ÿ Superga e Heysel tragedie sorelle\\" (70 angels in the one same heaven ÿ Superga and Heysel sister tragedies) and gathered material from 4 May 1949 and 29 May 1985.[32]\\r\\nIn May 2015, during a Serie A match between Juventus and Napoli at Turin, Juventus fans held up placards to form a banner saying \\"+39 Rispetto\\" (\\"respect +39\\" in Italian) including the names of the victims of the disaster.[33]\\r\\nOn 12 November 2015 Italian Football Federation (FIGC), Juventus' representatives led by Mariella Scirea and J-Museum president Paolo Garimberti and members of the Italian victims association held a ceremony in front of the Heysel monument in King Baudouin Stadium for the 30th anniversary of the event.[34] The following day, FIGC president Carlo Tavecchio announced the retirement of Squadra Azzurra's number 39 shirt prior to the friendly match between Italy and Belgium.[35]\\r\\nThe 39 people killed were 32 Italians (including two minors), four Belgians, two French fans and one from Northern Ireland.[36][37]\\r\\nCoordinates: 505342N 4202E? / ?50.89500N 4.33389E? / 50.89500; 4.33389","input":"What years were english clubs banned from europe?"},{"output":"Crispus Attucks","context":"Crispus Attucks (c.1723?ÿ March 5, 1770) was an American stevedore and whaler, widely regarded as the first person killed in the Boston massacre and thus the first American killed in the American Revolution.\\r\\nHistorians disagree on whether Crispus Attucks was a freed or escaped slave at the time of the massacre, but most agree that he was of Native American and African descent. Two major sources of eyewitness testimony about the Boston Massacre, both published in 1770, did not refer to Attucks as \\"black\\" nor as a \\"Negro\\"; it appeared that Bostonians of European descent viewed him as being of mixed ethnicity. According to a contemporary account in the Pennsylvania Gazette (Philadelphia), he was a \\"Mulattoe man, named Crispus Attucks, who was born in Framingham, but lately belonged to New-Providence, and was here in order to go for North Carolina . . .\\"[3] Attucks' mother, who was a slave, was recorded as a Natick Indian but also described as a negro, as were his siblings and extended family[4]. Because of his apparently mixed heritage, his story is significant for Native Americans and black Americans alike.[5]\\r\\nDespite the lack of clarity over whether he was a slave at the time of the massacre, Attucks became an icon of the anti-slavery movement in the mid-19th century. In the 1850s, as the abolitionist movement gained momentum in Boston, supporters lauded Attucks as having played a heroic role in the history of the United States.[6]\\r\\n\\r\\n\\r\\nAttucks was born in Framingham, Massachusetts. Town histories of Framingham written in 1847 and 1887 describe him as a slave of Deacon William Brown, though it is unclear whether Brown was his original owner. In 1750 Brown advertised for the return of a runaway slave named Crispas. In the advertisement, Brown describes Attucks and his clothing when he was last seen. He also said that a reward of 10 pounds would be given to whoever found and returned Attucks to him. Attucks's status at the time of the massacre as a free person or a runaway slave has been a matter of debate for historians. Attucks did become a sailor and whaler at some point and he spent much of his life at sea or working around the docks along the Atlantic seaboard. In an 1874 article in The American Historical Record, Jebe B. Fisher recounts a passage in the memoirs of Boston Tea Party participant George R.T. Hewees, which stated that at the time of the massacre Attucks \\"was a Nantucket Indian, belonging on board a whale ship of Mr. Folgers, then in the harbor, and he remembers a distinct war whoop which he yelled. . .the mob whistling, sreaming, and rending like an Indian yell.\\" Many historians believe Attucks went by the alias Michael Johnson in order to avoid being caught after his escape from slavery. He may only have been temporarily in Boston in early 1770, having recently returned from a voyage to the Bahamas. He was due to leave shortly afterwards on a ship for North Carolina.[7][8]\\r\\nThough he is commonly described as an African American in popular culture, two major sources of eyewitness testimony about the Massacre, both published in 1770, did not refer to Attucks as \\"black\\" nor as a \\"Negro,\\" but rather as a mulatto and an Indian. In an account from the Pennsylvania Gazette (Philadelphia), a man who may have been Attucks was referred to as a \\"Mulattoe man, named Crispas, who was born in Framingham, but lately belonged to New-Providence, and was here in order to go for North Carolina . . .\\"[9] However, during Attucks's time mulatto was often used to describe skin tone rather than ethnicity, and sometimes referred to full-blooded Native Americans[10][better?source?needed]. In Potter's American Monthly, the interchangeability of the two terms is demonstrated by court transcripts from the Attucks trial: \\"Question: Did you see a mulatto among the persons who surrounded the soldiers? Answer: I did not observe. . .Question: Did they seem to be sailors or townsmen? Answer: They were dressed some of them in the habits of sailors. Question: Did you know the Indian who was killed? Answer: No. Question: Did you see any of them press on the soldiers with a cordwood stick? Answer: No.\\"[11] Historians differ in opinion on Attucks's heritage: some assert his family had intermarried with African slaves, while others maintain he had no African heritage. It is widely acknowledged that Attucks had considerable Native American heritage.[12]\\r\\nBiographer Mitch Kachun, as well as multiple 19th century Framingham town histories, have drawn a connection between Attucks and John Attuck of Framingham, a Narragansett man who was hanged in Framingham in 1676 during King Philip's War.[13][14] The word for deer in the Narragansett language is 'Attuck.'[15][16] Kachun also noted a possible connection to a probable Natick woman and possible Attucks mother or relative named Nanny Peterattucks, who is described as a 'negro woman' in the 1747 estate inventory of Framingham slaveholder Joseph Buckminster and, along with Jacob Peterattucks, as 'probable descendant of John Attuck, the Indian' in an 1847 history of Framingham.[17][18] Other sources refer to their surname as Peter Attucks. In a 1747 history of the Hoosac Valley, a British colonial soldier named Moses Peter Attucks, living in nearby Leicester, is described as 'negro slave of John White; elsewhere he is listed as Moses Attucks[19][20] Jacob Peterattucks and Nanny Peterattucks are recorded as slaves with Joseph Buckminster in 1730, and in 1740 Jacob with Thomas Buckminster, who was appointed by Framingham in 1739 to lead a commission for preservation of deer in the area.[21] Historian William C. Nell reported an 1860 letter from a Natick resident, also printed in an 1860 edition of The Liberator newspaper that read, \\"several persons are now living in Natick who remember the Attucks family, viz., Cris, who was killed March 5th; Sam, whose name was abbreviated into Sam Attucks, or Smattox; Sal, also known as Slattox; and Peter, called Pea Tattox. . . .my mother, still living, aged 89, remembers Sal in particular, who used to be called the gourd-shell squaw, from the fact that she used to carry her rum in a gourd shell. . .the whole family are said to be the children of Jacob Peter Attucks. . .it has been conjectured that they are of Indian blood, but all who knew the descendants describe them as negroes.\\"[22][23] The letter continues, \\"his sister [Sal] used to say that if they had not killed Cris, Cris would have killed them.\\"\\r\\nPrince Yonger has been posited as the father of Attucks. However, Yonger did not arrive in Massachusetts until the mid-1720s, after Attucks was born, and did not marry Nanny Peterattucks until 1737, after which point they had children, who are noted in multiple histories but among whom Crispus is not mentioned: \\"a son, who died young, and Phebe, who never married.\\"[24] Neither Phebe nor the son are recorded with the Attucks or Peterattucks surname.\\r\\nIn the fall of 1768, British soldiers were sent to Boston in an attempt to control growing colonial unrest, which had led to a spate of attacks on local officials following the introduction of the Stamp Act and the subsequent Townshend Acts. Radical Whigs had coordinated waterfront mobs against the authorities. The presence of troops, instead of reducing tensions, served to further inflame them.\\r\\nAfter dusk on March 5, 1770, a crowd of colonists confronted a sentry who had chastised a boy for complaining that an officer did not pay a barber bill. Both townspeople and a company of British soldiers of the 29th Regiment of Foot gathered. The colonists threw snowballs and debris at the soldiers. A group of men including Attucks approached the Old State House armed with clubs. A soldier was struck with a piece of wood, an act some witnesses claimed was done by Attucks. Other witnesses stated that Attucks was \\"leaning upon a stick\\" when the soldiers opened fire.[26]\\r\\nFive colonists were killed and six were wounded. Attucks took two ricocheted bullets in the chest and was believed to be the first to die.[27] County coroners Robert Pierpoint and Thomas Crafts Jr. conducted an autopsy on Attucks.[28] Attucks' body was carried to Faneuil Hall, where it lay in state until Thursday, March 8, when he and the other victims were buried together in the same grave site in Boston's Granary Burying Ground. He had lived for approximately 47 years.\\r\\nJohn Adams successfully defended most of the accused British soldiers against a charge of murder. Two were found guilty of manslaughter. Faced with the prospect of hanging, the soldiers pleaded benefit of clergy, and were instead branded on their thumbs. In his arguments, Adams called the crowd \\"a motley rabble of saucy boys, negros and molattoes, Irish teagues and outlandish Jack Tarrs.\\"[29] In particular, he charged Attucks with having \\"undertaken to be the hero of the night,\\" and with having precipitated a conflict by his \\"mad behavior.\\"[30]\\r\\nTwo years later United States Founding Father Samuel Adams, a cousin of John Adams, named the event the \\"Boston Massacre,\\" and helped ensure it would not be forgotten.[31] Boston artist Henry Pelham (half-brother of the celebrated portrait painter John Singleton Copley) created an image of the event. Paul Revere made a copy from which prints were made and distributed. Some copies of the print show a dark-skinned man with chest wounds, presumably representing Crispus Attucks. Other copies of the print show no difference in the skin tones of the victims.[32]\\r\\nThe five who were killed were buried as heroes in the Granary Burying Ground, which also contains the graves of Samuel Adams, John Hancock, and other notable figures.[33] Custom of the period discouraged the burial of black people and white people together, with \\"black burials relegated to the rear or far side of the cemetery.[34] Such a practice was not completely unknown, however. Prince Hall, for example, was interred in Copp's Hill Burying Ground in the North End of Boston 39.[35]\\r\\nAnd to honor Crispus Attucks who was the leader and voice that day: The first to defy, and the first to die, with Maverick, Carr, and Gray. Call it riot or revolution, or mob or crowd as you may, such deaths have been seeds of nations, such lives shall be honored for aye...","input":"Who was the first person killed in the american revolution?"},{"output":"5,000","context":"The U-boat Campaign from 1914 to 1918 was the World War I naval campaign fought by German U-boats against the trade routes of the Allies. It took place largely in the seas around the British Isles and in the Mediterranean. The German Empire relied on imports for food and domestic food production (especially fertilizer) and the United Kingdom relied heavily on imports to feed its population, and both required raw materials to supply their war industry; the powers aimed, therefore, to blockade one another. The British had the Royal Navy which was superior in numbers and could operate on most of the world's oceans because of the British Empire, whereas the Imperial German Navy surface fleet was mainly restricted to the German Bight, and used commerce raiders and unrestricted submarine warfare to operate elsewhere.[citation needed]\\r\\nIn the course of events, German U-boats sank almost 5,000 ships with nearly 13 million gross register ton, losing 178 boats and about 5,000 men in combat.[4]\\r\\n\\r\\n\\r\\nIn August 1914, a flotilla of nine U-boats sailed from their base in Heligoland to attack Royal Navy warships in the North Sea in the first submarine war patrol in history.[5] Their aim was to sink capital ships of the British Grand Fleet, and so reduce the Grand Fleet's numerical superiority over the German High Seas Fleet. The first sortie was not a success. Only one attack was carried out, when U-15 fired a torpedo (which missed) at HMS?Monarch. Two of the ten U-boats were lost.\\r\\nLater in the month, the U-boats achieved success, when U-21 sank the cruiser HMS?Pathfinder. In September, SM?U-9 sank three armored cruisers (Aboukir, Hogue, and Cressy) in a single action. Other successes followed. In October U-9 sank the cruiser Hawke, and on the last day of the year SM?U-24 sank the pre-dreadnought battleship Formidable. By the end of the initial campaign, the U-boats had sunk nine warships while losing five of their own number.[6]\\r\\nThe initial phase of the U-boat campaign in the Mediterranean comprised the actions by the Austro-Hungarian Navy's U-boat force against the French, who were blockading the Straits of Otranto. At the start of hostilities, the Austro-Hungarian Navy had seven U-boats in commission; five operational, two training; all were of the coastal type, with limited range and endurance, suitable for operation in the Adriatic. Nevertheless, they had a number of successes. On 21 December 1914 U-12 torpedoed the French battleship?Jean Bart, causing her to retire, and on 27 April 1915 U-5 sank the French cruiser?Lon Gambetta, with a heavy loss of life. But the Austro-Hungarian boats were unable to offer any interference to allied traffic in the Mediterranean beyond the Straits of Otranto.\\r\\nIn 1914 the U-boat's chief advantage was to submerge; surface ships had no means to detect a submarine underwater, and no means to attack even if they could, while in the torpedo the U-boat had a weapon that could sink an armoured warship with one shot. Its disadvantages were less obvious, but became apparent during the campaign. While submerged the U-boat was virtually blind and immobile; boats of this era had limited underwater speed and endurance, so needed to be in position before an attack took place, while even on the surface their speed (around 15 knots) was less than the cruising speed of most warships and two thirds that of the most modern dreadnoughts.[7]\\r\\nThe U-boats scored a number of impressive successes, and were able to drive the Grand Fleet from its base in search of a safe anchorage, but the German Navy was unable to erode the Grand Fleet's advantage as hoped. Also, in the two main surface actions of this period the U-boat was unable to have any effect; the High Seas Fleet was unable to draw the Grand Fleet into a U-boat trap. Whilst warships were travelling at speed and on an erratic zigzag course they were relatively safe, and for the remainder of the war the U-boats were unable to mount a successful attack on a warship travelling in this manner[citation needed].\\r\\nThe first attacks on merchant ships had started in October 1914. At that time there was no plan for a concerted U-boat offensive against Allied trade. It was recognized the U-boat had several drawbacks as a commerce raider, and such a campaign risked alienating neutral opinion. In the six months to the opening of the commerce war in February 1915, U-boats had sunk 19 ships, totalling 43,000 GRT.[8]\\r\\nBy early 1915, all the combatants had lost the illusion that the war could be won quickly, and began to consider harsher measures in order to gain an advantage.\\r\\nThe British, with their overwhelming sea power, had established a naval blockade of Germany immediately on the outbreak of war in August 1914, and in early November 1914 declared it to be a war zone, with any ships entering the North Sea doing so at their own risk.[9] The blockade was unusually restrictive in that even food was considered \\"contraband of war\\". The Germans regarded this as a blatant attempt to starve the German people into submission and wanted to retaliate in kind, and in fact the severity of the British blockade did not go over well in America, either.\\r\\nGermany could not possibly deal with British naval strength on an even basis, and the only possible way Germany could impose a blockade on Britain was through the U-boat. The German Chancellor, Theobald von Bethmann Hollweg, felt that such a submarine blockade, based on \\"shoot without warning\\", would antagonise the United States and other neutrals. However, he was unable to hold back the pressures for taking such a step.\\r\\nIn response to the British declaration in November 1914 that the entire North Sea was now a war zone, on 4 February 1915 Admiral Hugo von Pohl, commander of the German High Seas Fleet, published a warning in the Deutscher Reichsanzeiger (Imperial German Gazette):\\r\\n(1) The waters around Great Britain and Ireland, including the whole of the English Channel, are hereby declared to be a War Zone. From February 18 onwards every enemy merchant vessel encountered in this zone will be destroyed, nor will it always be possible to avert the danger thereby threatened to the crew and passengers.\\r\\n(2) Neutral vessels also will run a risk in the War Zone, because in view of the hazards of sea warfare and the British authorization of January 31 of the misuse of neutral flags, it may not always be possible to prevent attacks on enemy ships from harming neutral ships.\\r\\n(3) Navigation to the north of the Shetlands, in the eastern parts of the North Sea and through a zone at least thirty nautical miles wide along the Dutch coast is not exposed to danger. [10]\\r\\nIn time, this would bring non-European nations (such as Brazil and the United States) into the war.\\r\\nThe German U-boat force was now primarily based at Ostend in Belgium, giving the submarines better access to the sea lanes around England. The Germans made use of this advantage, sending out about 20 U-boats to begin the naval blockade. In January, before the declaration of \\"unrestricted submarine warfare\\" as the submarine blockade was called, 43,550 tonnes of shipping had been sunk by U-boats. The number of sinkings then steadily increased, with 168,200 tonnes going down in August. Attacking without warning, German U-Boats sank nearly 100,000 GRT per month, an average of 1.9 ships daily.[10]\\r\\nOn 10 April 1915 the British steamer Harpalyce, a Belgian relief ship and clearly marked as such, was torpedoed without warning by SM?UB-4 near the North Hinder lightship, just outside the strip of sea declared safe by von Pohl. The ship had been en route for America to collect food for starving Belgians, and its sinking outraged American citizens already unhappy at the death of Leon C. Thrasher, drowned when SS?Falaba was sunk on 28 March 1915 by U-28 (Thrasher incident).[11]\\r\\nOn 7 May 1915, the liner RMS?Lusitania was torpedoed by U-20, 13?mi (21?km) off the Old Head of Kinsale, Ireland, and sank in just 18 minutes. Of the 1,959 people aboard, 1,198 were killed, 128 of them US citizens.\\r\\nFollowing the incident, the German government attempted to justify it with a range of arguments, which are still debated today; nevertheless there was massive outrage in Britain and America, and the British felt that the Americans had to declare war on Germany. However, US President Woodrow Wilson refused to overreact, though some believed the massive loss of life caused by the sinking of Lusitania required a firm response from the US.\\r\\nWhen Germany began its U-boat campaign against Britain, Wilson had warned that the US would hold the German government strictly accountable for any violations of American rights. Backed by State Department second-in-command Robert Lansing, Wilson made his position clear in three notes to the German government issued on 13 May, 9 June, and 21 July.\\r\\nThe first note affirmed the right of Americans to travel as passengers on merchant ships and called for the Germans to abandon submarine warfare against commercial vessels, whatever flag they sailed under.\\r\\nIn the second note Wilson rejected the German arguments that the British blockade was illegal, and was a cruel and deadly attack on innocent civilians, and their charge that Lusitania had been carrying munitions. William Jennings Bryan considered Wilson's second note too provocative and resigned in protest after failing to have it moderated.\\r\\nThe third note, of 21 July, issued an ultimatum, to the effect that the US would regard any subsequent sinkings as \\"deliberately unfriendly\\". While the American public and leadership were not ready for war, the path to an eventual declaration of war had been set as a result of the sinking of Lusitania.\\r\\nThe appearance of new minefields off the East coast of Britain in June 1915 was puzzling to the Royal Navy due to the waters being very busy, and was blamed initially on neutral fishing boats. However, on 2 July the small coaster Cottingham accidentally ran down the small coastal U-boat UC-2 off Great Yarmouth, and when she was salvaged she was found to be a submarine minelayer, fitted with twelve mines in six launching chutes.[12]\\r\\nOn 21 August UC-5 became the first submarine minelayer to penetrate into the English Channel, laying 12 mines off Boulogne, one of which sank the steamship William Dawson the same day. UC-5 laid 6 more mines off Boulogne and Folkestone on 7 September, one of which sank the cable layer Monarch. Further mines were laid off the southeast coast by UC-1, UC-3, UC-6, and UC-7.\\r\\nOn 19 August 1915 U-24 sank the White Star liner SS?Arabic, outward bound for America, 50?mi (80?km) south of Kinsale. He fired a single torpedo which struck the liner aft, and she sank within 10 minutes, with the loss of 44 passengers and crew, 3 of whom were American. Following speculation that the US would sever relations with Germany, on 28 August the Chancellor issued new orders to submarine commanders and relayed them to Washington. The new orders stated that until further notice, all passenger ships could only be sunk after warning and the saving of passengers and crews. This proved unacceptable to the Naval High Command, and on 18 September the High Seas flotillas were withdrawn from the commerce war.\\r\\nThe German Navy sent their first submarines to the Mediterranean in response to the Anglo-French Dardanelles campaign, after it became obvious that their Austro-Hungarian allies could do little against it with their small submarine force, which nevertheless was successful in defending the Adriatic. The first U-boats sent, U-21 and the two small coastal boats, UB-7 and UB-8, achieved initial success, U-21 sinking the Royal Navy predreadnought battleships HMS?Triumph and HMS?Majestic on 25 and 27 May respectively on her way to Constantinople, but ran into severe limitations in the Dardanelles, where swarms of small craft and extensive anti-submarine netting and booms restricted their movements.\\r\\nBy the end of June 1915, the Germans had assembled a further three prefabricated Type UB I submarines at Pola, two of which were to be transferred to the Austrian Navy. They were also assembling three Type UC I minelaying submarines, which were ordered converted into transports to carry small quantities of critical supplies to Turkey.\\r\\nThe Mediterranean was an attractive theater of operations to the German Admiralstab; a significant proportion of British imports passed through it, it was critical to French and Italian trade, and submarines would be able to operate effectively in it even in autumn and winter when poor weather hampered Atlantic and North Sea operations. Additionally, there were certain choke points through which shipping had to pass, such as the Suez Canal, Malta, Crete, and Gibraltar. Finally, the Mediterranean offered the advantage that fewer neutral ships would be encountered,[13] such as US or Brazilian vessels, since fewer non European citizens then travelled the waters.\\r\\nThroughout the summer, the German navy assembled a force of four U-boats at Cattaro for operations against commerce in the Mediterranean. The campaign got underway in October 1915, when U-33 and U-39, followed later by U-35, were ordered to attack the approaches to Salonika and Kavalla. That month, 18 ships were sunk, for a total of 63,848 tons. It was decided the same month that further reinforcements were called for, and a further large U-boat, U-38 sailed for Cattaro. Since Germany was not yet at war with Italy, even though Austria was, the German submarines were ordered to refrain from attacking Italian shipping in the eastern Mediterranean where the Italians might expect hostile action only from German submarines. When operating in the west, up to the line of Cape Matapan, the German U-boats flew the Austrian flag, and a sinking without warning policy was adopted, since large merchant ships could be attacked on the suspicion of being transports or auxiliary cruisers.\\r\\nThe German Admiralty also decided that the Type UB II submarine would be ideal for Mediterranean service. Since these were too large to be shipped in sections by rail to Pola like the Type UB I, the materials for their construction and German workers to assemble them were sent instead. This meant a shortage of workers to complete U-boats for service in home waters, but it seemed justified by the successes in the Mediterranean in November, when 44 ships were sunk, for a total of 155,882 tons. The total in December fell to 17 ships (73,741 tons) which was still over half the total tonnage sunk in all theaters of operation at the time.\\r\\nIn November 1915, U-38 caused a diplomatic incident when she sank the Italian steamer SS?Ancona while sailing under the Austrian flag, and the loss of nine American citizens caused the \\"sinking without warning\\" policy to be suspended in April 1916 until the resumption of unrestricted submarine warfare in 1917. A similar \\"false flag\\" incident in March 1916 was an influence on Italy's decision to declare war on Germany in August 1916.[14]\\r\\nAllied countermeasures during this period had mixed success.\\r\\nDefensive measures, such as arming merchant ships, and advising them to either run, or turn towards the U-boat in order to ram, or force it to submerge, were the most effective.[15] From arming ships for self-defence, the next step was arming ships for the purpose of engaging the U-boats in gun battles; two U-boats were sunk in 1915 whilst attacking trawlers so fitted. The following step was to arm and man ships with hidden guns to do so, the so-called Q ship. A variant on the idea was to equip small vessels with a submarine escort. In 1915, two U-boats were sunk by Q-ships, and two more by submarines accompanying trawlers.[16]\\r\\nOffensive measures were less effective; efforts were made to use nets to find submerged U-boats, and explosive sweeps to destroy them, but these were largely failures.[17] Attempts were also made to close routes like the Straits of Dover with boom nets and minefields, the so-called Dover Barrage; to lay minefields around U-boat bases, and station submarines on patrol to catch them leaving or entering port. These measures required a huge expenditure of effort and material, but met with little success. Just two U-boats were sunk by these measures in 1915.[16]\\r\\nAt the beginning of this period the British Merchant Marine had a shipping fleet totaling of 21 million GRT. In six months of unrestricted submarine warfare U-boats sank ?3?4?million tons of Allied shipping, scarcely denting the British merchant fleet; Whilst new building, and additions from ships seized, had more than made up this loss. On the other hand, serious offence had been given to neutrals such as Norway and the Netherlands, and brought the United States to the brink of war. This failure, and the various restrictions imposed on the U-boat Arm in the Atlantic area largely brought the campaign there to a halt, although it continued with little hindrance in the Mediterranean and elsewhere, where there was less likelihood of offending neutrals.\\r\\nGiven the ineffectiveness of early countermeasures, in 1917 Britain and in 1918 America adopted dazzle camouflage to attempt to reduce shipping losses to torpedoes. The results in both cases were inconclusive.[19][20]\\r\\nThe depth charge, or \\"dropping mine\\" as it was initially named, was first mooted in 1910, and developed into practicality when the British Royal Navys Commander in Chief, Admiral of the Fleet Sir George Callaghan, requested its production in 1914. Design work was carried out by Herbert Taylor at HMS Vernon Torpedo and Mine School in Portsmouth, England, and the first effective depth charge, the \\"Type D\\", became available in January 1916.\\r\\nAnti-submarine vessels initially carried only two depth charges, to be released from a chute at the stern of the ship. The first success was the sinking of U-68 off Kerry, Ireland, on 22 March 1916 by the Q-ship Farnborough. Germany became aware of the depth charge following unsuccessful attacks on U-67 on 15 April 1916, and U-69 on 20 April. UC-19 and UB-29 were the only other submarines sunk by depth charges during 1916.[21]\\r\\nIn 1916 the German Navy again tried to use the U-boats to erode the Grand Fleet's numerical superiority; they staged operations to lure the Grand Fleet into a U-boat trap. Because the U-boats were much slower than the battle fleet, these operations required U-boat patrol lines to be set up in advance; then the battle fleet maneuvered to draw the Grand Fleet onto them.[22]\\r\\nSeveral of these operations were staged, in March and April 1916, but with no success. Ironically, the major fleet action which did take place, the Battle of Jutland, in May 1916, saw no U-boat involvement at all; the fleets met and engaged largely by chance, and there were no U-boat patrols anywhere near the battle area. A further series of operations, in August and October 1916, were similarly unfruitful, and the strategy was abandoned in favor of resuming commerce warfare.\\r\\nThe British were well aware of the risk of U-boat traps to the Grand Fleet, although they had no means of knowing where these might lie. However Jellicoe had developed a tactical response to the problem (which, in the event, was never tested). Faced with a German fleet that turned away, he would assume a submarine trap, and decline to follow, but would move at high speed to the flank, before deploying or opening fire; the aim of this would be to fight the battle away from the ground chosen by his enemy, and forcing any U-boats present to surface if they intended to follow.[23]\\r\\nDuring 1916 the commerce war continued unabated in the Mediterranean. Allied countermeasures were largely ineffective; the complex arrangements for co-operation between the various navies meant a fragmented and unco-ordinated response, while the main remedy favored by the Allies for the U-boat menace, the Otranto Barrage, was of little value.\\r\\nJust two U-boats were caught in the barrage in all the time it was in operation; meanwhile merchant shipping suffered huge losses. In 1916 the Allies lost 415 ships, of 1,045,058 GRT, half of all Allied ships sunk in all theatres.\\r\\nEight of the top dozen U-boat aces served in the Pola flotilla, including the highest scoring commander of all, K/L Arnauld de la Perire.\\r\\nIn 1916 the Germans completed two submarine merchant vessels, to be used as blockade runners. The aim was to use them to carry high value goods to neutral nations such as the US, which still maintained a strict neutrality, and was prepared to trade with Germany as with any other nation. The first of these vessels, Deutschland, sailed in summer 1916 and made a favorable impact on US public opinion. She made a second equally successful voyage in autumn of that year. Her sister, Bremen, was less fortunate; she disappeared on her maiden voyage, the cause of her loss unknown.\\r\\nA less favorable impression was made by the cruise of U-53 under K/L Hans Rose. After refuelling at Newport, Rhode Island, Rose raided Allied shipping off the coast of Canada and the United States. Although this was in international waters, and Rose scrupulously followed international law, the action was seen as an affront to the US, particularly when US warships were forced to stand aside while merchant ships nearby were sunk.[24]\\r\\nIn autumn 1916, U-boats of the High Seas flotilla attacked shipping bound for Russia. Five U-boats operated in the Barents Sea between North Cape and the Kola inlet. Also, the two UE1-class minelaying boats laid minefields in the White Sea. These boats sank 34 ships (19 of them Norwegian) before winter ice closed the area for operations.\\r\\nOne of the ships sunk near the Norwegian coast was the Romanian merchant Bistri?a, sunk by U-43 on 11 November. Before sinking the ship, the captain of the U-boat allowed the ship's crew to take refuge in his submarine, then later he handed over the crew to a Russian sailing ship which took them to Vard?. From there, they were eventually repatriated.[25]\\r\\nThe Constantinople Flotilla was established in May 1915 and operated U-boats in the Black Sea.[26] Bulgaria joined the campaign in May 1916, when the German submarine UB-8 was commissioned by the Bulgarian Navy as Podvodnik.[27] In three years of operation, the Flotilla sank ships totalling 117,093 GRT.[28]\\r\\nUB-45 was lost in November 1916 and UB-46 in December, both sunk by Russian mines.[29] In addition, UB-7 was reportedly sunk by Russian aircraft in October.[30]\\r\\nThroughout September and October 1916, the main task of the submarines UB-42 and UB-14 was patrolling the Russian and Romanian coasts, from Constan?a to Sevastopol.[31] On 30 September 1916, near the port of Sulina, UB-42 launched a torpedo at the Romanian torpedo boat Smeul, but missed. The Romanian warship counterattacked, damaging the submarine's periscope and conning tower and forcing her to retreat.[32][33][34] In November, the German submarine UC-15 was sent on a minelaying mission off Sulina and never returned, being sunk by her own mines.[35][36] This was probably caused by an encounter with Smeul, whose captain surprised a German submarine near Sulina in November 1916, the latter reportedly never returning to her base at Varna. This could only be UC-15, whose systems most likely malfunctioned after being forced to submerge in the shallow waters, upon encountering the Romanian torpedo boat.[37]\\r\\nOn 22 December 1916, Admiral von Holtzendorff composed a memorandum which became the pivotal document for Germany's resumption of unrestricted U-boat warfare in 1917. Holtzendorff proposed breaking Britain's back by sinking 600,000 tons of shipping per month, based on a February 1916 study by Dr. Richard Fuss, who had postulated that if merchant shipping was sunk at such a rate, Britain would run out of shipping and be forced to sue for peace within six months, well before the Americans could act. Even if the \\"disorganized and undisciplined\\" Americans did intervene, Holtzendorff assured the Kaiser, \\"I give your Majesty my word as an officer, that not one American will land on the Continent.\\"[38]\\r\\nOn 9 January 1917, the Kaiser met with Chancellor Bethmann-Hollweg and military leaders at Schloss Pless to discuss measures to resolve Germany's increasingly grim war situation; its military campaign in France had bogged down, and with Allied divisions outnumbering German ones by 190 to 150, there was a real possibility of a successful Allied offensive. Meanwhile, the German navy was bottled up in its home port of Kiel, and the British blockade had caused a food scarcity that was in turn causing deaths due to malnutrition. The military staff urged the Kaiser to unleash the submarine fleet on shipping travelling to Britain, Hindenburg advising the Kaiser that \\"The war must be brought to an end by whatever means as soon as possible.\\" On 31 January, the Kaiser duly signed the order for unrestricted submarine warfare to resume effective 1 February; Bethmann-Hollweg, who had opposed the decision, said \\"Germany is finished\\".[39]\\r\\nOn 27 January, Admiral Beatty observed that \\"The real crux lies in whether we blockade the enemy to his knees, or whether he does the same to us.\\"[40]\\r\\nGermany had 105 submarines ready for action on 1 February: 46 in the High Seas Fleet; 23 in Flanders; 23 in the Mediterranean; 10 in the Baltic; and 3 at Constantinople. Fresh construction ensured that, despite losses, at least 120 submarines would be available for the rest of 1917. The campaign was initially a great success, nearly 500,000 tons of shipping being sunk in both February and March, and 860,000 tons in April, when Britain's supplies of wheat shrank to six weeks worth. In May losses exceeded 600,000 tons, and in June 700,000. Germany had lost only nine submarines in the first three months of the campaign.[40]\\r\\nOn 1 February, near Gironde, a U-boat surfaced near the Romanian merchant Bucure?ti, the latter being armed with two 120 mm guns. A short artillery duel ensued, between the merchant's aft gun (manned by officer Cioca? Mihail) and the submarine's deck gun. Eventually, a shell from the merchant's gun fell 50 meters away from the submarine, prompting the U-boat to submerge and retreat.[41]\\r\\nOn 3 February, in response to the new submarine campaign, President Wilson severed all diplomatic relations with Germany, and the US Congress declared war on 6 April.\\r\\nThe new policy of unrestricted submarine warfare was initially a success. In January 1917, prior to the campaign, Britain lost 49 ships; in February, after it opened, 105; and in March, 147. In March a full 25% of all Britain-bound shipping was sunk.\\r\\nAt first, the British Admiralty failed to respond effectively to the German offensive. Despite the proven success of troop convoys earlier in the war, the Channel convoys between England and France, and the Dutch, French, and Scandinavian convoys in the North Sea, they initially refused to consider widespread convoying or escorting. Convoying imposed severe delays on shipping, and was believed to be its own goal, amounting to a loss of carrying capacity greater than the loss inflicted by the U-Boats. It was disliked by both merchant and naval captains, and derided as a defensive measure. It was not until 27 April that the Admiralty endorsed the convoy system, the first convoy sailing from Gibraltar on 10 May.[40]\\r\\nIn April, US Rear Admiral William Sims arrived in London as US Naval Liaison. He was dismayed to be informed by the Admiralty that Germany would win the war if its submarines went unchecked, and cabled Washington to have USN destroyers despatched to Queenstown, Ireland, from where they were to patrol to the west.[40]\\r\\nAs merchantmen from Allied countries were sunk, Brazilian ships took over routes that had been vacated. However, this led the Brazilian vessels into waters patrolled by U-boats. When coupled with Germany's policy of unrestricted submarine warfare, the result was that Brazilian ships were soon lost, which drove the country closer to declaring war on the Central Powers.[42]\\r\\nIn May and June a regular system of transatlantic convoys were established, and after July the monthly losses never exceeded 500,000 tons, although they remained above 300,000 tons for the remainder of 1917. Convoying was an immediate success; on whichever routes it was introduced it resulted in a drop in shipping losses, with the U-boats seeking out easier prey. It also brought warships escorting the convoys in contact with attacking U-boats, leading to an increase in U-boats destroyed. German submarine losses were between 5 and 10 each month, and they soon realized the need to increase production, even at the expense of building surface warships. However, production was delayed by labour and material shortages.[40]\\r\\nAt the end of 1917 Allied shipping losses stood at over 6 million GRT for the year overall. However monthly shipping losses had dropped to around 300,000 GRT per month, and never rose to the levels suffered in spring 1917.[43] With the establishment of a comprehensive convoy system, Allied shipping losses fell to non-critical levels, while U-boat losses increased alarmingly. From 48 boats lost in the years up to February 1917, a further 61 were lost by the end of the year.[44]\\r\\nThe logical response to the convoy system, which concentrated forces for the defence, was to similarly concentrate the attacking force. The U-boat arm did not succeed in World War I in developing such a response. Just one attempt was made to operate a group, to mount a pack attack on any convoy encountered; 6 U-boats sailed in May 1918 as a group, commanded by K/L Rucker in U-103. They encountered several home-bound convoys and succeeded in sinking 3 ships, but at the loss of 2 of their number, including U-103, which was rammed by the troopship Olympic. Rucker had found it next to impossible to exercise control from his position at sea, and the loss ratio discouraged any further experiments.[45]\\r\\nLate in the war, the German high command decided to take the submarine war to the coast of the US, using the large Type U-151 and Type U-139 U-boats. The Type U-151 carried 18 torpedoes (24 torpedoes on the Type U-139) and two 150?mm deck guns, and had a range of around 25,000 nautical miles (46,300?km). Seven Type U-151 and three Type U-139 had been built, the Type U-151 originally as large merchant U-boats for shipping material to and from locations otherwise denied German surface ships, such as the United States, and 6 Type U-151 were refitted for war duty in 1917. The Type U-139 were the largest U-boats of World War I.\\r\\nU-151 departed Kiel on 14 April 1918 commanded by Korvettenkapit?n Heinrich von Nostitz und J?nckendorff, her mission to attack American shipping. She arrived in Chesapeake Bay on 21 May where she laid mines off the Delaware capes, and cut the submerged telegraph cables which connected New York with Nova Scotia. On 25 May she stopped three US schooners off Virginia, took their crews prisoner, and sank the three ships by gunfire. On 2 June 1918, known to some historians as \\"Black Sunday\\", U-151 sank six US ships and damaged two others off the coast of New Jersey in the space of a few hours. The next day the tanker Herbert L. Pratt struck a mine previously laid by U-151 in the area but was later salvaged. Only 13 people died in the seven sinkings, their deaths caused by a capsized lifeboat.[46] She returned to Kiel on 20 July 1918 after a 94-day cruise in which she had covered a distance of 10,915?mi (17,566?km), sunk 23 ships totalling 61,000 tons, and had laid mines responsible for the sinking of another 4 vessels.[47]\\r\\nEncouraged by the success of U-151, U-156, U-117, and the large Type 139, U-cruisers U-140 were despatched on similar missions, but the US Navy was now ready for them, and the hunting was not as good. U-156 was lost with all hands on the return voyage when she struck a mine off Bergen, Norway, on 25 September 1918. Another trio of long-range submarines, U-155, U-152, and U-cruiser U-139 were making their way across the Atlantic in November 1918 when the war ended.\\r\\nA few of the U-cruisers also made long voyages south to the Azores and the African coast, where they operated generally unmolested against shipping operating in the area, though one, U-154, was torpedoed by the British submarine HMS?E35 off the coast of Portugal in May 1918.\\r\\nJuly 1918 witnessed the Attack on Orleans when a U-boat sunk four barges and a tugboat off the coast of Cape Cod Massachusetts by the town of Orleans. The U-boat fired on the town ineffectually for about an hour before it was fought off by two Navy planes. It was the first attack involving a foreign power's artillery against US soil since the MexicanÿAmerican War.\\r\\nBy 1918 the Allied anti-submarine measures had continued to become more effective.\\r\\nAircraft began to play an increasingly effective role in patrolling large areas quickly. While they had little effect when attacking (only one U-boat was confirmed as sunk by air attack) the presence of aircraft forced the U-boat to dive, becoming blind and immobile, or risk the air patrol summoning hunting warships to the scene. During 1918 no convoy escorted by air patrol lost a ship, and U-boats were forced increasingly to operate at night or beyond aircraft range.[48]\\r\\nIn 1918 the USN embarked on a mammoth scheme to create a barrage across the routes exiting the North Sea. The North Sea Mine Barrage saw the laying of over 70,000 mines during the summer of 1918. From September to November 1918 6 U-boats were sunk by this measure.[49]\\r\\nThe RN also developed the R-class submarine, designed as a hunter-killer vessel, with a high underwater speed and sophisticated hydrophone system. These came too late to see action, however, and no successes were recorded by them.[50]\\r\\nBy the end of 1918, Allied shipping losses were 2? million GRT for the year overall (averaging 323,000 tons through March and declining thereafter) at a cost of 69 submarines, the U-boat Arm's worst year.[43]\\r\\nDuring the Great War United States Navy warships were deployed to both the Atlantic and Mediterranean with the primary objective of fighting German submarines and escorting convoys. American participation commenced with an event known as the \\"Return of the Mayflower\\", when the first six destroyers arrived at Queenstown, Ireland in May 1917.[51] Despite their long journey, when asked when they would be ready to go on patrol, the squadron commander replied \\"We are ready now\\". Essentially all available American destroyers and much of the submarine force were deployed in 1917-18, with bases including Queenstown, Bantry Bay, the Azores, and other locations. Many contacts and attacks were made in the Atlantic and Mediterranean, though only two U-boats were sunk or disabled by American action. An American auxiliary cruiser heavily damaged a U-boat during the Action of 4 April 1918. As a result, the Germans sailed directly for Spain where they scuttled their boat. American submarine chasers also engaged in one battle against Austro-Hungarian forces during the war. Though their participation in the conflict was intended as a counter-submarine effort, they were engaged by enemy shore batteries, charted a path through a minefield and helped sink two Austro-Hungarian destroyers at the naval base of Durazzo, Albania.\\r\\nBeginning in April 1917, Japan, an ally of the United Kingdom, sent a total of 14 destroyers to the Mediterranean with cruiser flagships which were based at Malta and played an important part in escorting convoys to guard them against enemy submarines. The Japanese ships were very effective in patrol and anti-submarine activity.[52] However, of the 9 Austro-Hungarian navy submarines lost to enemy action, 5 were sunk by Italian navy units (U-13, U-10, U-16, U-20, and U-23), 1 by Italian and French units (U-30), 1 by Royal Navy units (U-3), while none were sunk by the Japanese navy, which lost one destroyer (Japanese destroyer Sakaki, torpedoed by U-27).\\r\\nOn 21 December 1917 the British government requested that a Brazilian naval force of light cruisers be placed under Royal Navy control and a squadron comprising the cruisers Rio Grande do Sul and Bahia, the destroyers Paraba, Rio Grande do Norte, Piau, and Santa Catarina, and the support ship Belmonte and the ocean-going tug Laurindo Pitta was formed, designated the Divis?o Naval em Opera??es de Guerra (\\"Naval Division in War Operations\\"). The DNOG sailed on 31 July 1918 from Fernando de Noronha for Sierra Leone, arriving at Freetown on 9 August, and sailing onwards to its new base of operations, Dakar, on 23 August. On the night of the 25 August the division believed it had been attacked by a U-boat when the auxiliary cruiser Belmonte sighted a torpedo track. The purported submarine was depth-charged, fired on, and reportedly sunk by the Rio Grande do Norte, but the sinking was never confirmed.\\r\\nThe DNOG patrolled the Dakar-Cape Verde-Gibraltar triangle, which was suspected to be used by U-boats waiting on convoys, until 3 November 1918 when it sailed for Gibraltar to begin operations in the Mediterranean, with the exception of the Rio Grande do Sul, Rio Grande do Norte, and Belmonte. The Division arrived at Gibraltar on 10 November; while passing through the Straits of Gibraltar, they mistook three USN subchasers for U-boats but no damage was caused.[53]\\r\\nBy mid-1918, U-boat losses had reached unacceptable levels, and the morale of their crews had drastically deteriorated; by the autumn it became clear that the Central Powers could not win the war.\\r\\nThe Allies insisted that an essential precondition of any armistice was that Germany surrender all her submarines, and on 24 October 1918 all German U-boats were ordered to cease offensive operations and return to their home ports. The Allies stipulated that all seaworthy submarines were to be surrendered to them and those in shipyards be broken up. The last significant role played by U-boats in World War I was the suppression of the German naval mutiny that same month, when they stood ready to \\"fire without warning on any vessel flying the red flag\\".[54]\\r\\nGrand Total 12,850,815 gross tons\\r\\nUnrestricted submarine warfare was resumed in February 1917 and the British began full-scale convoying in September 1917. The heaviest losses were suffered in April 1917 when a record 881,027 tons were sunk by the U-boats.[55]\\r\\n150,000 tons of purely British shipping were lost in January 1917, and 300,000 tons in February; Allied and neutral losses increased in a similar proportion. In April 525,000 tons of British shipping were lost. In October 270,000 tons were lost, and in December 170,000 tons were lost. These totals are included in the above figures.[56]\\r\\nDuring World War I nearly 5,000 merchant ships had been sunk by u-boats, with the loss of 15,000 Allied sailors lives.[57]\\r\\nSir Joseph Maclay approved four standard designs of merchant ship and placed orders for over 1,000,000 tons of shipping (Britain launched 495,000 tons of shipping in the first half of 1917, but 850,000 tons were sunk in the first quarter alone; by 1918 3,000,000 tons a year were being launched).[58]\\r\\nNotes\\r\\nBibliography\\r\\nFurther reading","input":"How many ships were sunk by german u boats in ww1?"},{"output":"September 30, 2011","context":"","input":"When was the first episode of jessie made?"},{"output":"Anthony Patrick Hadley","context":"\\r\\n\\r\\nAnthony Patrick Hadley (born 2 June 1960) is an English singer-songwriter, occasional stage actor and radio presenter. He rose to fame in the 1980s as the lead singer of the new wave band Spandau Ballet before launching a solo career following the group's split in 1990. Hadley is recognisable for his suave image,[1] as well as his powerful blue-eyed soul voice, which has been described by AllMusic as a \\"dramatic warble\\".[2] He has also been described as a \\"top crooner\\" by the BBC.[3]\\r\\n\\r\\nAnthony Patrick Hadley was born the eldest of three children at the Royal Free Hospital in Hampstead, North London. He has a sister, Lee, and a brother, Steve. His father, Patrick Hadley, worked as an electrical engineer for the Daily Mail, and his mother, Josephine, worked for the local health authority.[4] Hadley attended Dame Alice Owens Grammar School in England.\\r\\n\\r\\nSpandau Ballet was formed in 1976 as The Cut, with Gary Kemp, Steve Norman, John Keeble, Michael Ellison and Tony Hadley, all of whom were students at the same grammar school. As a member of Spandau Ballet, Hadley went on to enjoy international success in the 1980s, including hits such as \\"True\\", \\"Gold\\" and \\"Through the Barricades\\", as well as appearing at Live Aid in 1985.[5] Spandau Ballet disbanded in 1989 after their final studio album, Heart Like a Sky, failed to live up to the critical and commercial success of their earlier albums, such as True and Parade. Heart Like a Sky was not released in the United States.\\r\\n\\r\\nIn April 1999, Hadley, along with fellow band members Steve Norman and John Keeble, failed in their attempt to sue Gary Kemp, the band's principal songwriter, for a share of his royalties.[6][7][8] However, in recent years Norman is again on good terms with Gary and his brother, Martin Kemp, who at one time played bass guitar in the band. In early 2009, newspaper reports claimed that Spandau Ballet was set to reform later that year.[9][10][11] On 25 March 2009, it was confirmed that the band had reformed and were embarking on a tour of the UK and Ireland in October 2009.\\r\\n\\r\\nSpandau Ballet song \\"True\\" was sampled by the American Hip Hop Music Act P.M. Dawn in their song \\"Set Adrift on Memory Bliss\\" released in their first album Of The Heart, Of The Soul and Of The Cross: The Utopian Experience released in 1991. Hadley also featured a cameo in the music video. \\"Set Adrift on Memory Bliss\\" achieved immediate commercial success. The single hit #1 the week of November 30, 1991,[citation needed] and holds the distinction of being the first #1 song on the Billboard Hot 100 chart following the introduction of Nielsen SoundScan to the chart.[citation needed] The song also reached #3 in the United Kingdom.[citation needed]\\r\\n\\r\\nAfter Spandau Ballet disbanded, Hadley pursued a solo career, signing to EMI and recording his first album, The State of Play, in 1992. After leaving EMI, Hadley formed his own record company, SlipStream Records,[12] and his first release was the single \\"Build Me Up\\", from the film When Saturday Comes. Shortly after that, in December 1996, Hadley embarked on an orchestral tour of Europe, along with Joe Cocker, Paul Michiels, Dani Klein and Guo Yue, playing to 500,000 concertgoers in six weeks.\\r\\n\\r\\nOn his return from that tour, Hadley signed a joint deal with PolyGram TV, and released his next eponymous solo album, Tony Hadley, in 1997, which included covers and songs that were chosen to match his voice. The album also featured some of his own self-penned songs, such as \\"She\\", which he wrote for daughter Toni.[13]\\r\\n\\r\\nIn 1996, Hadley performed in a BBC Radio 2 live performance of Jesus Christ Superstar, playing the title role opposite Roger Daltrey's Judas.[14]\\r\\n\\r\\nTo plug the gap between studio albums, Hadley also released Obsession (later re-released as Obsession Live), a live album recorded in just one night in 2001 at the club Ronnie Scott's in Birmingham.[15]\\r\\n\\r\\nHe also collaborated, in the past and present, with various dance acts and DJs, such as Tin Tin Out, Eddie Lock, Marc et Claude, Regi Penxten (Milk Inc.) and the Disco Bros, and played alongside people such as Alice Cooper, Paul Young, Jon Anderson, and Brian May. In 1999 Alan Parsons chose him as lead singer for the track \\"Out of the Blue\\" on the album The Time Machine.[16] Hadley's usual band line up features John Keeble (drums), Phil Taylor (keyboards), Phil Williams (bass guitar), Richie Barrett (guitar), and Dawn Joseph on backing vocals. His early band, with whom he realised his debut album, included instead, besides himself and Keeble, Spandau Ballet's regular keyboard player, Toby Chapman, Jerry Stevenson (guitar) and Kevin Miller (bass guitar).\\r\\n\\r\\nHadley was the subject of some newfound respect in the 2000s, rooted in an \\"ironic\\" appreciation for Spandau Ballet; John Darnielle of the indie folk rock group The Mountain Goats wrote about his admiration for Hadley's vocal strengths.[17]\\r\\n\\r\\nIn 2000, Hadley's solo greatest hits album was issued, entitled Debut, made up of some early solo songs.\\r\\n\\r\\nIn 2003, Hadley was the winner of the ITV reality television series Reborn in the USA, appearing alongside other singers, such as Elkie Brooks, Peter Cox from Go West and Leee John from Imagination.[18] Capitalizing on his victory of the American reality show, his Debut compilation was re-issued, and his second collection True Ballads was also released in the same year, including some of his solo tracks, most of the cover songs already contained in his second studio album, and historical hits from the Spandau Ballet period.\\r\\n\\r\\nHadley has continued with a busy performing schedule and also toured with both Cox and Martin Fry from the band ABC. He released a jazz-swing album in 2006, titled Passing Strangers,[19] and traveled on a \\"by request\\" tour from March to May 2006. This was followed by a big band tour later the same year.\\r\\n\\r\\nIn January 2007, Hadley performed in the West End musical Chicago as crooked lawyer Billy Flynn, at the Cambridge Theatre.[20] Hadley took over from ex-Emmerdale actor Ian Kelsey, and featured from 29 January to 14 April 2007. He said: \\"Three months was long enough, I didn't want to out-stay my welcome. I got a phone call offering me the part. I went to see the show, which I thought was great. While I was in it, I got great reviews. Chicago tied in with my swing album, Passing Strangers, so the whole thing worked well.\\"\\r\\n\\r\\nHadley performed a set with other 1980s acts at Retro Fest on 1 September 2007 at Culzean Castle in Ayrshire, Scotland. This appearance included a rendition of \\"Addicted to Love\\", with Fry and Cox.[21]\\r\\n\\r\\nIn February 2008, Hadley took part in the Italian Sanremo Festival, where he duetted in both English and Italian with contestant Paolo Meneguzzi on Meneguzzi's song, \\"Grande\\" (\\"Big\\"), during the third day of the contest (where all contestants re-interpreted their songs with guest artists). On 22 February 2008, he performed as an interval act at the semi-final of Dora 2008, the selection of the Croatian entry for the Eurovision Song Contest.[22]\\r\\n\\r\\nHadley has revealed that his solo career has been more financially rewarding than his period at the top of the charts with Spandau Ballet. He said that 2008 was his best-ever earning year, having performed in over 220 shows.[4]\\r\\n\\r\\nIn 2013, Hadley and his 1980s chart peers Kim Wilde, Bananarama and Go West set a new world record for Comic Relief when they performed the highest ever gig, singing on a Boeing 767 aeroplane at 43,000?ft (13,000 m).[23]\\r\\n\\r\\nIn 2014, Hadley took part in the prime-time RAI TV show La Pista as team leader of the Tacco 10 female dance troupe.[24] Over the course of the competition, Hadley performed both Spandau Ballet's \\"Gold\\", as well as \\"Rio\\", originally a hit for rival band Duran Duran. Other well known singer-contestants that took part in the weekly show included Amii Stewart and Sabrina Salerno.\\r\\n\\r\\nOn 3 July 2017, Tony Hadley announced on Twitter that due to circumstances beyond his control, he was no longer a member of Spandau Ballet.[25]\\r\\n\\r\\nHadley worked as a radio presenter with Virgin Radio, taking over the Friday Night Virgin Party Classics show from Suggs (of the band Madness) in August 2007. In January 2008, he was given the Saturday Night Virgin Party Classics show as well. He left both shows in September 2008. In 2015 he was listed as a presenter for Absolute Radio.[26]\\r\\n\\r\\nHadley appeared, sang and gave advice in Pinoy Dream Academy, a singing reality show in the Philippines. He also appeared in RocKwiz, an Australian TV programme that aired in November 2008.[27]\\r\\n\\r\\nHadley also appeared in the British short movie Shoot The DJ, in which he plays Eddie Richards. The film also featured Hadley's daughter, Toni.[28] Hadley's song \\"After All This Time\\" was used as the theme song for the popular BBC series Down to Earth, which ran from 2000 until 2005.\\r\\n\\r\\nHadley took part in the 2015 series of I'm a Celebrity...Get Me Out of Here!, beginning on 10 November 2015. He was eliminated on 4 December, finishing in sixth place.\\r\\n\\r\\nHadley is the father of five children: Thomas, Toni and Mackenzie with his first wife, Leonie Lawson,[29] then Zara (born 21 December 2006) and Genevieve (born 6 February 2012) with Alison Evers, whom he married in July 2009 at Cliveden House.[30] Hadley split from Leonie in 2003, after 20 years of marriage. Hadley lives in Buckinghamshire with wife Alison and his youngest two children, Zara and Genevieve.\\r\\n\\r\\nHadley is also an Arsenal fan and plays for the Arsenal ex-Professional and Celebrity XI team. He also runs, and enjoys skiing.\\r\\n\\r\\nHadley is a regular act in The East Festival. He is also a patron of the UK Huntington's Disease Association.[31]\\r\\n\\r\\nHadley stated on the television show Loose Women (22 February 2007) that he is 6?ft 4?in (1.93?m) and 17?1?2 stone (111 kilograms). He is proud of his work ethic, which he claims was instilled into him from a young age by his parents, and he says he has never claimed benefits.[4]\\r\\n\\r\\nIn 2006, Hadley became a co-owner of the Red Rat Craft Brewery,[4] where he issued Hadleys Golden Ale, Hadleys Crazy Dog Stout, Hadleys Gold and Hadleys SB. The business closed in 2013, but Hadley went on to issue a golden lager in association with The Great Yorkshire Brewery.[citation needed]\\r\\n\\r\\nHadley is a supporter of the Conservative Party and an admirer of former Prime Minister Margaret Thatcher.[32] Journalist Andrew Pierce, in a 2014 piece for the Daily Mail, described Hadley as \\"the Tories' biggest celebrity backer\\".[33] He has attended the party's annual conference and was once reported to be interested in standing as an MP.[34] The New Statesman has described Hadley as one of the few openly right-wing rock stars.[35]","input":"Who was the lead singer for spandau ballet?"},{"output":"17 billion dollars","context":"Tourism in Paris is a major income source for Paris and the city ranks in the world's most visited cities. In 2013, the City of Paris welcomed 15.6 million international visitors, the largest number of whom came from the United States.[1] In the Paris region, the largest numbers of foreign tourists came in order from Britain, the United States, Germany, Italy, China and Canada.\\r\\nIn 2012, 263,212 salaried workers in the city of Paris, or 18.4 percent of the total number, were engaged in tourism-related sectors; hotels, catering, transport and leisure.[2] In 2014 visitors to Paris spent 17 billion dollars (13.58 billion Euros), the third highest sum globally after London and New York.[3]\\r\\n\\r\\n\\r\\nThe Eiffel Tower is acknowledged as the universal symbol of Paris and France. It was originally designed by mile Nouguier and Maurice Koechlin. In March 1885 Gustave Eiffel, known primarily as a successful iron engineer, submitted a plan for a tower to the French Ministre du Commerce et de l'Industrie.[4] He entered a competition for students studying at the university. The winning proposal would stand as the centerpiece of the 1889 Exposition. Eiffel's was one of over 100 submissions. Eiffel's proposal was finally chosen in June 1886. Even before its construction, the Tower's uniqueness was noticed. The Eiffel Tower was finally inaugurated on March 31, 1889.[4] Currently about 6.9 million people visit the Eiffel tower each year.[5]\\r\\nCentre Georges Pompidou was officially opened on January 31, 1977 by President Valry Giscard d'Estaing.[6] The designers of Pompidou are Renzo Piano, Richard Rogers, and Peter Rice.[7] The Centre Pompidou has had over 150 million visitors since 1977.[6] Centre Georges Pompidou is a complex in the Beaubourg area of the 4th arrondissement of Paris, near Les Halles, rue Montorgueil and the Marais. In 1997 renovations had begun to drastically change the interior spaces of the Centre Pompidou. The renovations were still preserving the celebrated and original tubular design[6] The internal refurbishment was mainly done to enable the building to deal with the pressure of increasing visitor numbers. The renovation also developed the centre's capacity to host the performing arts and increased the display area of the Museum of Modern Art.[6]\\r\\nThe Arc de Triomphe de l'toile is one of the most famous monuments in Paris. It stands in the centre of the Place Charles de Gaulle (originally named Place de l'toile), at the western end of the Champs-lyses.[8] It should not be confused with a smaller arch, the Arc de Triomphe du Carrousel, which stands west of the Louvre. The Arc de Triomphe (in English: \\"Triumphal Arch\\") honours those who fought and died for France in the French Revolutionary and the Napoleonic Wars, with the names of all French victories and generals inscribed on its inner and outer surfaces. Beneath its vault lies the Tomb of the Unknown Soldier from World War I. The Arc de Triomphe is the linchpin of the historic axis (Axe historique) ÿ a sequence of monuments and grand thoroughfares on a route which goes from the courtyard of the Louvre, to the Grande Arche de la Dfense.\\r\\nThe Muse d'Orsay is a museum in Paris, France, on the left bank of the Seine. It started to be constructed in 1897 and was designed by Gae Aulenti, Victor Laloux, and mile Bernard.[9] The Muse d'Orsay is an art museum for works from 1848 to 1914 and has an emphasis on French Impressionism artwork.[10] One can walk through the museum room by room. There are sections on Symbolism, Naturalism, Impressionism, Pont Aven School, and Art Nouveau to name just a few.[4] The museum is the culmination of nearly ten years of government commitment and dedicated team-work[11] By visiting this museum it is possible to get some idea of what was happening in France in the fields of painting, drawing and sculpture, opera design, architecture, photography, metalwork, furniture, ceramics and textiles.[11]\\r\\nDisneyland Paris (formerly Euro Disneyland) is an amusement park in the Paris region. It is the most popular amusement park in Europe in terms of attendance records.\\r\\nThe Louvre Palace, originally built as a medieval fortress in the year 1190 by King Philippe Auguste, was transformed by successive governments, since the French Revolution, it hosts the Muse du Louvre one of the largest museums of the western world.[12] It houses some of the most popular and culturally ethnic form of art. The doors to The Louvre opened to the public on August 10, 1793.[12] Since the 12th Century, The Louvre has undergone several infrastructural changes due to a change of reign after every century. On March 3, 1989, I.M. Pei inaugurated the Glass Pyramid.[12] This also serves as an official entrance to the main exhibition hall, which in turn leads to the temporary exhibition halls. The Muse is divided into 3 separate wings: Sully, Richelieu and Denon, which showcase 35,000 pieces of art, dating back to the Middle Ages.[13] Some of the most renown pieces of art showcased at The Louvre are the Leonardo da Vinci's Mona Lisa, Venus of Milo, Winged Victory of Samothrace and the Dying Slave by Michelangelo.\\r\\nThe Notre-Dame de Paris, is one of the largest cathedrals in Paris. It was started to be built in 1163 by Maurice de Sully, the then appointed bishop of Paris.[14] The construction campaign was divided into 4 parts, and was done by well-known builders of that era: Jean de Chelles, Pierre de Montreuil, Pierre de Chelles, Jean Ravy, Jean le Bouteiller.[15] It took over 100 years for the Notre-Dame to be built completely. It was built in honour of Virgin Mary, making it a bishops church, a canon church and a baptistery.[15] It is one of the main symbols of Paris. It is located at ?le de la Cit, a small island in the heart of the city.[16] There have been several historical events that have taken place here, including the marriage of King Henry IV and Marguerite de Valois, in 1594.\\r\\nThe Basilique du Sacr-C?ur is a Roman Catholic Basilica, which was built in 1914 and consecrated in 1919.[17] It is located at one of the highest altitudes in Paris, at butte Montmartre. The church contains one of the world's largest mosaic of Jesus Christ with his arms wide spread. The basilica was built in the honour of the 58,000 lives lost in the Franco-Prussian war in the year 1870.[18] Paul Abadie, the winner of the competition to find the right architectural design, was the architect for the basilica.[19] The basilica offers some beautiful panoramic views of Paris. The walls of the church are naturally always white and clean, due to the travertine stone been used.[20] The stone reacts with water and creates a chemical called calcite, which acts as a natural bleacher. It is one of the most iconic monuments of Paris.[21]\\r\\nThe Muse du quai Branly is a museum in Paris, France that features indigenous art, cultures and civilizations from Africa, Asia, Oceania, and the Americas. The museum is located at 37, quai Branly - portail Debilly, 75007 Paris, France, situated close to the Eiffel Tower. The nearest mtro and RER stations are Alma ÿ Marceau and Pont de l'Alma, respectively. MQB is named after its location on the quai Branly, which in turn is named after the physicist douard Branly.\\r\\nThe Avenue des Champs-lyses is a street with cinemas, cafs, luxury specialty shops and clipped horse-chestnut trees.Around 7 million people visit the champs lyses per year and around 19,180 people per day. The Champs-lyses is arguably one of the world's most famous streets, and is one of the most expensive strips of real estate in the world.[22] Several French monuments are also on the street, including the Arc de Triomphe and the Place de la Concorde. The name is French for Elysian Fields, the place of the blessed dead in Greek mythology. According to a much used description, the Champs-lyses is la plus belle avenue du monde (\\"the most beautiful avenue in the world\\").[23]\\r\\nLes Invalides, officially known as L'H?tel national des Invalides (The National Residence of the Invalids), is a complex of buildings in the 7th arrondissement, containing museums and monuments, all relating to the military history of France, as well as a hospital and a retirement home for war veterans, the building's original purpose. The buildings house the Muse de l'Arme, the military museum of the Army of France, the Muse des Plans-Reliefs, and the Muse d'Histoire Contemporaine, as well as the burial site for some of France's war heroes, notably Napoleon.\\r\\nThe Sainte-Chapelle is a royal medieval Gothic chapel, located near the Palais de la Cit, on the ?le de la Cit in the heart of Paris, France. Begun some time after 1239 and consecrated on 26 April 1248,[24] the Sainte-Chapelle is considered among the highest achievements of the Rayonnant period of Gothic architecture. Its erection was commissioned by King Louis IX of France to house his collection of Passion Relics, including Christ's Crown of Thorns - one of the most important relics in medieval Christendom. Along with the Conciergerie, the Sainte-Chapelle is one of the earliest surviving buildings of the Capetian royal palace on the ?le de la Cit. Although damaged during the French revolution, and restored in the 19th century, it retains one of the most extensive in-situ collections of 13th-century stained glass anywhere in the world.\\r\\nThe Cit des Sciences et de l'Industrie is the biggest science museum in Europe.[25] Located in Parc de la Villette in Paris, France, it is at the heart of the Cultural Center of Science, Technology and Industry (CCSTI), a center promoting science and science culture. About five million people visit the Cit each year. Attractions include a planetarium, a submarine (the Argonaute (S636)), an IMAX theatre (La Gode) and special areas for children and teenagers. The Cit is classified as a public establishment of an industrial and commercial character, an establishment specializing in the fostering of scientific and technical culture. Created on the initiative of President Giscard d'Estaing, the goal of the Cit is to spread scientific and technical knowledge among the public, particularly for youth, and to promote public interest in science, research and industry. The most notable features of the \\"bioclimatic facade\\" facing the park are Les Serres - three greenhouse spaces each 32 metres high, 32 metres wide and 8 metres deep. The facades of Les Serres were the first structural glass walls to be constructed without framing or supporting fins. Between 30 May and 1 June 2008, the museum hosted the 3rd International Salon for Peace Initiatives.\\r\\nThe 20 top Paris museums and monuments - (2007/2006 figures from the Paris Office of Tourism)[26]","input":"How much money does paris make from tourism?"},{"output":"McIntyre, Georgia","context":"Here Comes Honey Boo Boo is an American reality television series that aired on TLC featuring the family of child beauty pageant contestant Alana \\"Honey Boo Boo\\" Thompson. The show premiered on August 8, 2012 and ended on August 14, 2014. Thompson and her family originally rose to fame on TLC's reality series Toddlers & Tiaras.[1] The show mainly revolves around Alana \\"Honey Boo Boo\\" Thompson and \\"Mama\\" June Shannon, and their family's adventures in the town of McIntyre, Georgia. The reality series has received predominantly negative reviews from television critics.\\r\\nOn October 24, 2014, TLC cancelled the series after four seasons, following reports stating that cast member June Shannon was romantically involved with a registered sex offender, which both Shannon and her older daughter Lauryn denied. A fifth season of episodes remains unaired as a result of the cancellation.\\r\\nOn April 21, 2017, TLC aired, \\"Here Comes Honey Boo Boo: The Lost Episodes\\" which were the episodes filmed for the fifth season that never aired due to the abrupt cancellation of the show in 2014. On the same night, TLC aired re-runs of the original series.\\r\\n\\r\\n\\r\\nBesides Alana, who was six years old when the first season was filmed, the show features her stay-at-home mother June \\"Mama June\\" Shannon; her father Mike \\"Sugar Bear\\" Thompson, a chalk miner; and her three sisters: Lauryn \\"Pumpkin\\" Shannon, Jessica \\"Chubbs\\" Shannon, and Anna \\"Chickadee\\" Shannon (now Anna Cardwell).[2][3][4] Anna Shannon gave birth to daughter Kaitlyn Cardwell, in the first-season finale.[5][6]\\r\\nThe first season of Here Comes Honey Boo Boo aired from August 8 to October 26, 2012, and was followed by four specials airing in early 2013.\\r\\nIn September 2012, Here Comes Honey Boo Boo was renewed for a second season.[7] The second season debuted July 17, 2013, and concluded on September 11, 2013. The second season featured preparations for the wedding/\\"commitment ceremony\\" of June Shannon and Mike Thompson. For the second season premiere, TLC distributed \\"Watch 'N' Sniff\\" cards, allowing viewers to release scents correlating with specific scenes.[8]\\r\\nOn September 20, 2013, it was announced that TLC had ordered a twelve-episode third season and three specials.[9] The third season premiered on January 16, 2014,[10] and concluded on March 6, 2014.\\r\\nThe series premiere episode attained a 1.6 rating in the 18ÿ49 demographic, attracting 2.2 million viewers.[11] The series was one of TLC's highest-rated shows in its first season.[12] The August 29 episode, airing on Wednesday night during the 2012 Republican National Convention, attracted almost 3 million viewers and scored a 1.3 rating among 18- to 49-year-olds, the highest rating in that age group for any cable program that night,[13] though about 20 million in all were watching the convention. Fox News convention coverage was second in the time period with a 1.2 rating, followed by NBC coverage with 1.1.[14]\\r\\nCritical reaction to the series has been mixed, with some characterizing the show as \\"offensive,\\" \\"outrageous,\\" and \\"exploitative,\\" while others call it \\"must-see TV.\\"[15]\\r\\nThe A.V. Club called the first episode a \\"horror story posing as a reality television program,\\"[16] with others worrying about potential child exploitation.[17] James Poniewozik mostly praised the show, but criticized the producers for \\"the way that the show seems to assume that those viewers will look at this family and the world.\\"[18]\\r\\nA reviewer for Forbes criticized TLC as trying to \\"portray Alana's family as a horde of lice-picking, lard-eating, nose-thumbing hooligans south of the MasonÿDixon line,\\" stating that \\"it falls flat, because theres no true dysfunction here, save for the beauty pageant stuff.\\"[19] The Guardian also criticized the attempt to portray the Thompsons as people to \\"point and snicker at,\\" saying, \\"none of the women or girls who participate in the show seems to hate themselves for their poverty, their weight, their less-than-urbane lifestyle, or the ways in which they diverge from the socially-acceptable beauty standard.\\"[20]\\r\\nThe Hollywood Reporter pronounced the show \\"horrifying,\\" explaining:\\r\\nYou know this show is exploitation. TLC knows it. Maybe even Mama and HBB know it, deep down in their rotund bodies. Here Comes Honey Boo Boo is a car crash, and everybody rubber-necks at a car crash, right? It's human nature. Yes, except that if you play that card, you also have to realize that human nature comes with the capacity to draw a line, to hold fast against the dehumanization and incremental tearing down of the social fabric, even if this never-ending onslaught of reality television suggests that's a losing effort. You can say no to visual exploitation. You can say no to TLC. And you can say no to Honey Boo Boo Child. Somebody has to.[21]\\r\\nTV Guide's \\"Cheers & Jeers 2012\\" issue commented, \\"Jeers to Here Comes Honey Boo Boo for existing. Alana Thompson and her family have lowered the TV bar to new depths while introducing viewers to the terms 'forklift foot' and 'neck crust.' In a word, ewww.\\"[22]\\r\\nJune Shannon herself has been criticized for her daughter's diet, which includes \\"Go Go Juice,\\" a mixture of Red Bull and Mountain Dew that contains as much caffeine as two cups of coffee. The drink is used to get her daughter ready for pageants. Shannon has responded to this criticism, saying. \\"There are far worse things...I could be giving her alcohol.\\"[1]\\r\\nOut praised the show for Alana Thompson's attitude toward her gay paternal uncle Lee \\"Poodle\\" Thompson; Thompson stated, \\"Ain't nothing wrong with bein' a little gay.\\" Out noted the show's \\"clear message of equality\\" and said that Alana's acceptance of her gay relative \\"confounded\\" the stereotype of the \\"redneck\\" working-class, Southern white female.[23]\\r\\nJune Shannon has been praised by Mother Nature Network for her \\"keen business sense\\" with which she feeds her family on $80 a week by clipping copious coupons, playing bingo, exploiting roadkill, and acquiring child-support checks from each of her four childrens fathers.[12]\\r\\nPrior to the show's second season, Hank Stuever of The Washington Post said the show \\"feels as real to me as the Great Depression images shot by the WPA photographers\\" and praised the \\"solidif unorthodoxfamily values.\\"[24]\\r\\nHere Comes Honey Boo Boo has been lampooned by the animated TV series South Park, in its season 16 episode \\"Raising the Bar\\",[25] by the animated TV series MAD, in a short called \\"Here Comes Yogi Boo Boo\\", and in an online spoof uploaded on CollegeHumor called \\"Precious Plum.\\"[26]\\r\\nChristopher Walken, Colin Farrell and Sam Rockwell took time from promoting their new film Seven Psychopaths to deliver a dramatic rendition of Here Comes Honey Boo Boo.[27]\\r\\nThe film Scary Movie 5 featured a scene parodying Sinister where Simon Rex is frightened by an Alana look-a-like that pops out of a cardboard box and says, \\"A dollar makes me holla, honey boo boo child.\\"\\r\\nOn October 24, 2014, TLC announced the cancellation of the show after reports surfaced that June Shannon was dating a man convicted of child molestation. Shannon and her older daughter Lauryn denied these reports.[28] The man in question, Mark Anthony McDaniel, Sr., was convicted of aggravated child molestation of an 8-year-old in March 2004. McDaniel is listed as a registered sex offender with the Georgia Sex Offender Registry.[28][29] Shannon's eldest daughter confirmed that she is the child who was molested by McDaniel 10 years earlier.[28][30] TLC commented on the future of the series regarding the current situation with the following statement: \\"We are currently reassessing the reports, but we do not currently have Here Comes Honey Boo Boo in production\\".[31]\\r\\nAn entire season's worth of episodes ÿ which could reportedly fill six months of schedule[32] ÿ are left unaired, following the cancellation of the show.[33]\\r\\nUpon hearing of the show's cancellation, Vivid Entertainment president Steven Hirsch sent a letter to June Shannon, offering her and her former live-in partner, Mike Thompson, US$1 million to appear in a pornographic film. Hirsch stated that the studios BBW themed productions have become a very popular genre on Vivid.com and VividTV, and he would make the couples experience enjoyable for them both, as well as give them creative input.[34]\\r\\nIn February 2015, Alana and June had appeared on an episode of The Doctors after Alana had noticeably gained more weight and had weighed 125 pounds (57?kg).[35] Upon seeing the family's refrigerator, a health intervention was staged to help Alana lose weight with healthier food. The former child star was to lose 12ÿ25 pounds (5.4ÿ11.3?kg) before the end of April.[35]\\r\\nDuring an interview with Inside Edition it was revealed that Alana, with Lauryn and Adam Barta, were set to release a song called \\"Movin' Up\\". TLC had threatened to sue the family as they were not allowed to release anything until their contract expired in late May 2015.[36]\\r\\nInside Edition had again interviewed the family in late April 2015 about Alana's sister Lauryn coming out as bisexual. It was revealed that June was also bisexual after she was outed by Lauryn in the interview.[37]\\r\\nJune \\"Mama June\\" Shannon and Mike \\"Sugar Bear\\" Thompson returned to reality television in 2015 as participants of Marriage Boot Camp: Reality Stars 4. While the couple were there to work on their marriage, Sugar Bear ultimately revealed his infidelities to June, resulting in great friction between the two. It was revealing in early 2016 after that show that the couple had officially separated.\\r\\nOn 24 February 2017, June \\"Mama June\\" Shannon returned to television for a nine-episode WE tv reality show, Mama June: From Not to Hot. The show documented her weight loss transformation from 460 to 160 pounds (209 to 73?kg).[81]","input":"Where does june from honey boo boo live?"},{"output":"Designed by John Browning in 1898 and patented in 1900","context":"The Browning Automatic 5, most often Auto-5 or simply A-5, is a recoil-operated semi-automatic shotgun designed by John Browning. It was the first successful semi-automatic shotgun design, and remained in production until 1998. The name of the shotgun designates that it is an autoloader with a capacity of five rounds, four in the magazine and one in the chamber. Remington Arms sold a variant called the Remington Model 11 that was nearly identical but lacked the magazine cutoff found on the Browning.\\r\\n\\r\\n\\r\\nThe Browning Auto-5 was the first mass-produced semi-automatic shotgun. Designed by John Browning in 1898 and patented in 1900,[4] it was produced continually for almost 100 years by several makers with production ending in 1998. It features a distinctive high rear end, earning it the nickname \\"Humpback\\". The top of the action goes straight back on a level with the barrel before cutting down sharply towards the buttstock. This distinctive feature makes it easy to identify A-5s from a distance. A-5s were produced in a variety of gauges, with 12 and 20 predominating; 16 gauge (not produced between 1976 and 1987) models were also available. The gun saw military service worldwide between World War I and the Vietnam War. A Remington Model 11 was used in the suicide of Kurt Cobain.[5]\\r\\nJohn Browning presented his design (which he called his best achievement)[4] to Winchester, where he had sold most of his previous designs. When Winchester refused his terms, Browning went to Remington. However, the president of Remington died of a heart attack as Browning waited to offer them the gun. This forced Browning to look overseas to produce the shotgun. It was manufactured by FN (a company that had already produced Browning-designed pistols) starting in 1902. Browning would later license the design to Remington, which produced it as their Model 11 (1905ÿ1947). The Remington Model 11 was the first auto-loading shotgun made in the US. Savage Arms also licensed the design from Browning and produced it as their model 720 from 1930 to 1949, and their model 745 with an alloy receiver and two-shot magazine from 1941 to 1949. Browning's long-recoil design itself served as the operating system for subsequent Remington (11-48), Savage (755, 775) and Franchi (AL-48) models.[4]\\r\\nProduction of the Auto-5 in Belgium continued until the start of World War II, when Browning moved production to Remington Arms in the United States. The Auto-5 was produced by Remington alongside the Model 11 until FN could resume making the gun after the war.[6] Unlike the Remington Model 11, the Remington-produced Browning shotguns had magazine cutoffs. Some 850,000 Remington Model 11 shotguns were produced before production ended in 1947. In 1952, production of Browning models returned to FN, where it continued until the end. However, the majority of production moved to the Japanese company Miroku in 1975. Finally, in 1998, manufacture of A-5s ceased except for a few commemorative models created at FN in 1999. As of 1983 it was well established as the second-best-selling auto-loading shotgun in U.S. history, after the Remington 1100.[4]\\r\\nIn 2014 Browning released the A5, a recoil-operated shotgun with external resemblance to the Auto 5, which is being manufactured in Belgium, assembled in Portugal.\\r\\nThe Browning Auto-5 is a long-recoil operated semi-automatic shotgun. Shells are stored in a tubular magazine under the barrel. When a chambered shell is fired, the barrel and bolt recoil together (for a distance greater than the shell length) and re-cock the hammer. As the barrel returns forward to its initial position the bolt remains behind and thus the spent shell is ejected through a port on the top of the receiver. Then the bolt returns forward and feeds another shell from the magazine into the action. This type of long recoil action was the first of its kind and patented in 1900 by John Browning.\\r\\nTo load the gun, shells are fed into the bottom of the action, where they are pushed into the tubular magazine. Most A-5s have removable plugs in the magazine which prevent more than three shells from being loaded (two in the magazine, plus one in the chamber) to comply with US federal migratory waterfowl laws, as well as some state hunting regulations. With the plug removed, the total capacity is five rounds. If the chamber is open (the operating handle is drawn back) the first shell loaded into the magazine tube will go directly into the chamber (there is a manual bolt closing button under the ejection port), the bolt then closes, and all further shells fed into the gun go into the magazine.\\r\\nThe A-5 has a system of friction piece or pieces and bevel rings which retard the barrel's rearward travel. Setting these rings correctly is vital to good shotgun performance and to ensure a long life to the weapon, by controlling excessive recoil. The friction rings are set based on the type of load to be fired through the gun. Different settings are found in the owner's manual.[7][8]","input":"When was the first semi automatic shotgun made?"},{"output":"some ~130 mya, in the Cretaceous","context":"","input":"When did flowers first appear in the fossil record?"},{"output":"original Italian sonnet form divides the poem's 14 lines into two parts","context":"The Petrarchan sonnet is a sonnet form not developed by Petrarch himself, but rather by a string of Renaissance poets.[1] Because of the structure of Italian, the rhyme scheme of the Petrarchan sonnet is more easily fulfilled in that language than in English. The original Italian sonnet form divides the poem's 14 lines into two parts, the first part being an octave and the second being a sestet.\\r\\n\\r\\n\\r\\nThe rhyme scheme for the octave is typically a b b a a b b a. The sestet is more flexible. Petrarch typically used c d e c d e or c d c d c d for the sestet. Some other possibilities for the sestet include c d d c d d, c d d e c e, or c d d c c d (as in Wordsworth's \\"Nuns Fret Not at Their Convents Narrow Room\\" poem). This form was used in the earliest English sonnets by Wyatt and others. For background on the pre-English sonnet, see Robert Canary's web page, The Continental Origins of the Sonnet.[2] In a strict Petrarchan sonnet, the sestet does not end with a couplet (since this would tend to divide the sestet into a quatrain and a couplet). However, in Italian sonnets in English, this rule is not always observed, and c d d c e e and c d c d e e are also used.\\r\\nThe octave and sestet have special functions in a Petrarchan sonnet. The octave's purpose is to introduce a problem, express a desire, reflect on reality, or otherwise present a situation that causes doubt or a conflict within the speaker's soul and inside an animal and object in the story. It usually does this by introducing the problem within its first quatrain (unified four-line section) and developing it in the second. The beginning of the sestet is known as the volta, and it introduces a pronounced change in tone in the sonnet; the change in rhyme scheme marks the turn. The sestet's purpose as a whole is to make a comment on the problem or to apply a solution to it. The pair are separate but usually used to reinforce a unified argument  they are often compared to two strands of thought organically converging into one argument, rather than a mechanical deduction. Moreover, Petrarch's own sonnets almost never had a rhyming couplet at the end as this would suggest logical deduction instead of the intended rational correlation of the form.[3]\\r\\nPoets adopting the Petrarchan sonnet form often adapt the form to their own ends to create various effects. These poets do not necessarily restrict themselves to the metrical or rhyme schemes of the traditional Petrarchan form; some use iambic hexameter, while others do not observe the octave-sestet division created by the traditional rhyme scheme. Whatever the changes made by poets exercising artistic license, no \\"proper\\" Italian sonnet has more than five different rhymes in it.\\r\\nSir Thomas Wyatt and Henry Howard, Earl of Surrey are both known for their translations of Petrarch's sonnets from Italian into English. While Howard tended to use the English sonnet form in his own work, reserving the Petrarchan form for his translations of Petrarch, Wyatt made extensive use of the Italian sonnet form in the poems of his that were not translation and adaptation work. As a result, he is often credited for integrating the Petrarchan sonnet into English vernacular tradition.[3]\\r\\nThe form also gave rise to an 'anti-Petrarchan' convention which may have revealed the mistress to be ugly and unworthy. The convention was also mocked, or adopted for alternative persuasive means by many of the Inns of Court writers during the Renaissance.\\r\\nThe sonnet is split in two groups: the \\"octave\\" (of 8 lines) and the \\"sestet\\" (of 6 lines), for a total of 14 lines.\\r\\nThe octave (the first 8 lines) typically introduces the theme or problem using a rhyme scheme of abba abba. The sestet (the last 6 lines) provides resolution for the poem and rhymes variously, but usually follows the schemes of cdecde or cdccdc.\\r\\nOctave - introduces the theme or problem\\r\\nSestet - solves the problem","input":"What is the structure of an italian sonnet?"},{"output":"parietal cells (also called oxyntic cells)","context":"Gastric acid, gastric juice or stomach acid, is a digestive fluid formed in the stomach and is composed of hydrochloric acid (HCl), potassium chloride (KCl) and sodium chloride (NaCl). The acid plays a key role in digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids. Gastric acid is produced by cells in the lining of the stomach, which are coupled in feedback systems to increase acid production when needed. Other cells in the stomach produce bicarbonate, a base, to buffer the fluid, ensuring that it does not become too acidic. These cells also produce mucus, which forms a viscous physical barrier to prevent gastric acid from damaging the stomach. The pancreas further produces large amounts of bicarbonate and secretes bicarbonate through the pancreatic duct to the duodenum to completely neutralize any gastric acid that passes further down into the digestive tract.\\r\\nThe main constituent of gastric acid is hydrochloric acid which is produced by parietal cells (also called oxyntic cells) in the gastric glands in the stomach. Its secretion is a complex and relatively energetically expensive process. Parietal cells contain an extensive secretory network (called canaliculi) from which the hydrochloric acid is secreted into the lumen of the stomach. The pH of gastric acid is 1.5 to 3.5[1] in the human stomach lumen, the acidity being maintained by the proton pump H+/K+ ATPase. The parietal cell releases bicarbonate into the bloodstream in the process, which causes a temporary rise of pH in the blood, known as an alkaline tide.\\r\\nThe highly acidic environment in the stomach lumen causes proteins from food to lose their characteristic folded structure (or denature). This exposes the protein's peptide bonds. The gastric chief cells of the stomach secrete enzymes for protein breakdown (inactive pepsinogen, and in infancy rennin). Hydrochloric acid activates pepsinogen into the enzyme pepsin, which then helps digestion by breaking the bonds linking amino acids, a process known as proteolysis. In addition, many microorganisms have their growth inhibited by such an acidic environment, which is helpful to prevent infection.\\r\\n\\r\\n\\r\\nA typical adult human stomach will secrete about 1.5 liters of gastric acid daily.[2] Gastric acid secretion happens in several steps. Chloride and hydrogen ions are secreted separately from the cytoplasm of parietal cells and mixed in the canaliculi. Gastric acid is then secreted into the lumen of the gastric gland and gradually reaches the main stomach lumen.[2] The exact manner in which the secreted acid reaches the stomach lumen is controversial, as acid must first cross the relatively pH neutral gastric mucus layer.\\r\\nChloride and sodium ions are secreted actively from the cytoplasm of the parietal cell into the lumen of the canaliculus. This creates a negative potential of -40 mV to -70 mV across the parietal cell membrane that causes potassium ions and a small number of sodium ions to diffuse from the cytoplasm into the parietal cell canaliculi.\\r\\nThe enzyme carbonic anhydrase catalyses the reaction between carbon dioxide and water to form carbonic acid. This acid immediately dissociates into hydrogen and bicarbonate ions. The hydrogen ions leave the cell through H+/K+ ATPase antiporter pumps.\\r\\nAt the same time, sodium ions are actively reabsorbed. This means that the majority of secreted K+ and Na+ ions return to the cytoplasm. In the canaliculus, secreted hydrogen and chloride ions mix and are secreted into the lumen of the oxyntic gland.\\r\\nThe highest concentration that gastric acid reaches in the stomach is 160 mM in the canaliculi. This is about 3 million times that of arterial blood, but almost exactly isotonic with other bodily fluids. The lowest pH of the secreted acid is 0.8,[3] but the acid is diluted in the stomach lumen to a pH between 1 and 3.\\r\\nThere is a small continuous basal secretion of gastric acid between meals of usually less than 10 mEq/hour.[4]\\r\\nThere are three phases in the secretion of gastric acid which increase the secretion rate in order to digest a meal:[2]\\r\\nGastric acid production is regulated by both the autonomic nervous system and several hormones. The parasympathetic nervous system, via the vagus nerve, and the hormone gastrin stimulate the parietal cell to produce gastric acid, both directly acting on parietal cells and indirectly, through the stimulation of the secretion of the hormone histamine from enterochromaffine-like cells (ECL). Vasoactive intestinal peptide, cholecystokinin, and secretin all inhibit production.\\r\\nThe production of gastric acid in the stomach is tightly regulated by positive regulators and negative feedback mechanisms. Four types of cells are involved in this process: parietal cells, G cells, D cells and enterochromaffine-like cells. Besides this, the endings of the vagus nerve (CN X) and the intramural nervous plexus in the digestive tract influence the secretion significantly.\\r\\nNerve endings in the stomach secrete two stimulatory neurotransmitters: acetylcholine and gastrin-releasing peptide. Their action is both direct on parietal cells and mediated through the secretion of gastrin from G cells and histamine from enterochromaffine-like cells. Gastrin acts on parietal cells directly and indirectly too, by stimulating the release of histamine.\\r\\nThe release of histamine is the most important positive regulation mechanism of the secretion of gastric acid in the stomach. Its release is stimulated by gastrin and acetylcholine and inhibited by somatostatin.\\r\\nIn the duodenum, gastric acid is neutralized by sodium bicarbonate. This also blocks gastric enzymes that have their optima in the acid range of pH. The secretion of sodium bicarbonate from the pancreas is stimulated by secretin. This polypeptide hormone gets activated and secreted from so-called S cells in the mucosa of the duodenum and jejunum when the pH in the duodenum falls below 4.5 to 5.0. The neutralization is described by the equation:\\r\\nThe carbonic acid rapidly equilibrates with carbon dioxide and water through catalysis by carbonic anhydrase enzymes bound to the gut epithelial lining,[6] leading to a net release of carbon dioxide gas within the lumen associated with neutralisation. In the absorptive upper intestine, such as the duodenum, both the dissolved carbon dioxide and carbonic acid will tend to equilibrate with the blood, leading to most of the gas produced on neutralisation being exhaled through the lungs.\\r\\nIn hypochlorhydria and achlorhydria, there is low or no gastric acid in the stomach, potentially leading to problems as the disinfectant properties of the gastric lumen are decreased. In such conditions, there is greater risk of infections of the digestive tract (such as infection with Vibrio or Helicobacter bacteria).\\r\\nIn ZollingerÿEllison syndrome and hypercalcemia, there are increased gastrin levels, leading to excess gastric acid production, which can cause gastric ulcers.\\r\\nIn diseases featuring excess vomiting, patients develop hypochloremic metabolic alkalosis (decreased blood acidity by H+ and chlorine depletion).\\r\\nThe proton pump enzyme is the target of proton pump inhibitors, used to increase gastric pH (and hence decrease stomach acidity) in diseases that feature excess acid. H2 antagonists indirectly decrease gastric acid production. Antacids neutralize existing acid.\\r\\nThe role of gastric acid in digestion was established in the 1820s and 1830s by William Beaumont on Alexis St. Martin, who, as a result of an accident, had a fistula (hole) in his stomach, which allowed Beaumont to observe the process of digestion and to extract gastric acid, verifying that acid played a crucial role in digestion.[7]","input":"Which cells release hydrochloric acid (hcl) into the stomach?"},{"output":"September 1931","context":"The three Round Table Conferences of 1930ÿ32 were a series of conferences organized by the British Government to discuss constitutional reforms in India. These started in November 1930 and ended in 1932 ( month is unknown). They were conducted as per the recommendation of Jinnah to Viceroy Lord Irwin and Prime Minister Ramsay MacDonald,[1][2] and by the report submitted by the Simon Commission in May 1930. Demands for swaraj, or self-rule, in India had been growing increasingly strong. By the 1930s, many British politicians believed that India needed to move towards dominion status. However, there were significant disagreements between the Indian and the British political parties that the Conferences would not resolve.\\r\\n\\r\\n\\r\\nThe Round Table Conference officially inaugurated by His Majesty George V on November 12, 1930 in Royal Gallery House of Lords at London[1] and chaired by the British Prime Minister, Ramsay MacDonald.\\r\\nThe three British political parties were represented by sixteen delegates. There were fifty-eight political leaders from British India and sixteen delegates from the princely states. In total 74 delegates from India attended the Conference. However, the Indian National Congress, along with Indian business leaders, kept away from the conference. Many of them were in jail for their participation in Civil Disobedience Movement.[3]\\r\\nThe conference started with 6 plenary meetings where delegates put forward their issues 9 sub committees were formed to deal with several different matters including federal structure, provincial constitution, province of Sindh and NWFP, defense services and minorities e.t.c.[4] These were followed by discussions on the reports of the sub-committees on Federal Structure, Provincial Constitution, Minorities, Burma, North West Frontier Province, Franchise, Defense services and Sindh. These were followed by 2 more plenary meetings and a final concluding session.[3] It was difficult for progress to be made in the absence of the Indian National Congress but some advances were made.\\r\\nThe idea of an All-India Federation was moved to the centre of discussion by Tej Bahadur Sapru.[5] All the groups attending the conference supported this concept. The princely states agreed to the proposed federation provided that their internal sovereignty was guaranteed. The Muslim League also supported the federation as it had always been opposed to a strong Centre. The British agreed that representative government should be introduced on provincial level.\\r\\nOther important discussions were the responsibility of the executive to the legislature and a separate electorate for the Untouchables as demanded by Dr. B.R. Ambedkar.\\r\\nThe Congress had boycotted the first conference was requested to come to a settlement by Sapru, M. R. Jayakar and V. S. Srinivasa Sastri. A settlement between Mahatma Gandhi and Viceroy Lord Irwin known as the GandhiÿIrwin Pact was reached and Gandhi was appointed as the sole representative of the Congress to the second Round Table Conference. By this time, there was a coalition Government in Britain with a Conservative majority. It was held in London in September 1931. The discussion led to the passing of the Government Of India act of 1935.\\r\\n[6]\\r\\nThe second session opened on September 7, 1931. There were three major differences between the first and second Round Table Conferences. By the second:\\r\\n\\r\\nDuring the Conference, Gandhi could not reach agreement with the Muslims on Muslim representation and safeguards. At the end of the conference Ramsay MacDonald undertook to produce a Communal Award for minority representation, with the provision that any free agreement between the parties could be substituted for his award[citation needed].\\r\\nGandhi took particular exception to the treatment of untouchables as a minority separate from the rest of the Hindu community. He clashed with the leader of depressed classes, Dr.B. R. Ambedkar, over this issue: the two eventually resolved the situation with the Poona Pact of 1932.\\r\\nThe third and last session assembled on November 17, 1932. Only forty-six delegates attended since most of the main political figures of India were not present. The Labour Party from Britain and the Indian National Congress refused to attend.\\r\\nFrom September 1931 until March 1933, under the supervision of the Secretary of State for India, Sir Samuel Hoare, the proposed reforms took the form reflected in the Government of India Act 1935.\\r\\n[7]","input":"When was the second round table conference held?"},{"output":"Indonesia","context":"Adherents of Islam constitute the world's second largest religious group. According to a study in 2015, Islam has 1.8 billion adherents, making up about 24% of the world population.[1] Most Muslims are either of two denominations: Sunni (80-90%, roughly 1.5 billion people)[2] or Shia (10ÿ20%, roughly 170-340 million people).[3] Islam is the dominant religion in the Central Asia, Indonesia, Middle East, South Asia, North Africa, the Sahel[4][5][6][7] and some other parts of Asia.[8]\\r\\nAround 31% of all Muslims are of South Asian origin (Pakistan, Bangladesh, Afghanistan and India combined).[9][10] The Indian subcontinent as a whole, therefore, hosts the largest population of Muslims in the world.[11] Within this region, however, Muslims are second in numbers to Hindus, as Muslims are a majority in Pakistan and Bangladesh, but not India.\\r\\nThe country with the single largest population of Muslims is Indonesia in Southeast Asia, which on its own hosts 13% of the world's Muslims.[12] Together, the Muslims in the countries of the Malay Archipelago (which includes Brunei, Singapore, Malaysia, Indonesia, the Philippines and East Timor) constitute the world's second or third largest population of Muslims. Here Muslims are majorities in each country other than Singapore, the Philippines, and East Timor.\\r\\nThe various Hamito-Semitic (including Arab, Berber), Turkic, and Iranic countries of the greater Middle East-North Africa (MENA) region,[13] where Islam is the dominant religion in all countries other than Israel,[5] hosts 23% of world Muslims.\\r\\nAbout 15% of Muslims reside in Sub-Saharan Africa,[14][6][15] and sizable Muslim communities are also found in the Americas, Caucasus, China, Europe, Horn of Africa, Mainland Southeast Asia, Philippines, Russia and Swahili coast.\\r\\nWestern Europe hosts large Muslim immigrant communities where Islam is the second largest religion after Christianity, where it represents 6% of the total population or 24 million people.[16] Converts and immigrant communities are found in almost every part of the world.\\r\\n\\r\\n\\r\\nHistorically, Islam was divided into two major religious denominations: Sunni and Shi'a. Of the total Muslim population, 87-90% are Sunni and 10-13% are Shi'a. Most Shi'as (between 68% and 80%) live in mainly four countries: Iran, Azerbaijan, Bahrain and Iraq.[17] Today, many of the Shia sects are extinct. The major surviving Imamah-Muslim Sects are Usulism (with nearly more than 10%), Nizari Ismailism (with nearly more than 1%) and Alevism (with slightly more than 0.5%[18] but less than 1%[19]). The other existing groups include Zaydi Shi'a of Yemen whose population is nearly more than 0.5% of the world's Muslim population, Mustali Ismaili (with nearly 0.1%[20] whose Taiyabi adherents reside in Sindh and Gujarat in South Asia. There are also significant diaspora populations in Europe, North America, the Far East and East Africa[21]), and Ibadis from the Kharijites whose population has diminished to a level below 0.15%. On the other hand, new Muslim sects like the Nation of Islam, Ahmadi Muslims[22] (with nearly around 1%[23]), non-denominational Muslims, Quranist Muslims and Wahhabis (with nearly around 1-2%[24] of the world's total Muslim population) were later independently developed.\\r\\nAccording to the Pew Research Center in 2010, there were 50 Muslim-majority countries.[25][26] Around 62% of the world's Muslims live in the Asia-Pacific region (from Turkey to Indonesia), with over 1?billion adherents.[27] The largest Muslim population in a country is in Indonesia, a nation home to 12.7% of the world's Muslims, followed by Pakistan (11.0%), and India (10.9%).[4][28] About 20% of Muslims live in Arab countries.[29] In the Middle East, the non-Arab countries of Iran and Turkey are the largest Muslim-majority countries; in Africa, Egypt and Nigeria have the most populous Muslim communities.[4][28] The study found more Muslims in the United Kingdom than in Lebanon and more in China than in Syria.[4]\\r\\nMost of the percentages of Muslim populations of each country, if not stated otherwise, were taken from the study by the Pew Research Center report of The Future of the Global Muslim Population, as of 27 January 2011.[4][30] Other studies show variance with Pew figures. The percentage of Muslims in Egypt is given as 93.7%. However, the figure for Christians in Egypt is usually estimated at 12-15%, but in truth nobody knows since there has been no religious census. Likewise the percentage of Christians in Jordan is usually estimated to be 6-7%.\\r\\nIslam:\\r\\nOther religions by country:\\r\\nGeneral","input":"Which country has the largest number of muslim?"},{"output":"Audie Leon Murphy","context":"Audie Leon Murphy (20 June 1925 ÿ 28 May 1971) was one of the most decorated American combat soldiers of World War II, receiving every military combat award for valor available from the U.S. Army, as well as French and Belgian awards for heroism. Murphy received the Medal of Honor for valor demonstrated at the age of 19 for single-handedly holding off an entire company of German soldiers for an hour at the Colmar Pocket in France in January 1945, then leading a successful counterattack while wounded and out of ammunition.\\r\\nMurphy was born into a large sharecropper family in Hunt County, Texas. His father abandoned them, and his mother died when he was a teenager. Murphy left school in fifth grade to pick cotton and find other work to help support his family; his skill with a hunting rifle was a necessity for putting food on the table.\\r\\nAfter the attack on Pearl Harbor, Murphy's older sister helped him to falsify documentation about his birthdate to meet the minimum-age requirement for enlisting in the military. Turned down by the Navy and the Marine Corps, he enlisted in the Army. He first saw action in the Allied invasion of Sicily and the Battle of Anzio, and in 1944 participated in the liberation of Rome and invasion of southern France. Murphy fought at Montlimar, and led his men on a successful assault at the L'Omet quarry near Cleurie in northeastern France in October.\\r\\nAfter the war, Murphy enjoyed a 21-year acting career. He played himself in the 1955 autobiographical film To Hell and Back, based on his 1949 memoirs of the same name, but most of his roles were in westerns. He made guest appearances on celebrity television shows and starred in the series Whispering Smith. Murphy was a fairly accomplished songwriter, and bred quarter horses in California and Arizona, becoming a regular participant in horse racing.\\r\\nSuffering from what would today be termed posttraumatic stress disorder (PTSD), he slept with a loaded handgun under his pillow and looked for solace in addictive sleeping pills. In his last few years, he was plagued by money problems, but refused offers to appear in alcohol and cigarette commercials because he did not want to set a bad example. Murphy died in a plane crash in Virginia in 1971 shortly before his 46th birthday, and was interred with full military honors at Arlington National Cemetery.\\r\\n\\r\\n\\r\\nMurphy was born the seventh of twelve children to Emmett Berry Murphy and his wife Josie Bell Killian in Kingston, Texas.[ALM 1] The Murphys were sharecroppers of Irish descent.[7]\\r\\nAs a child, Murphy was a loner with mood swings and an explosive temper.[8] He grew up in Texas, around Farmersville, Greenville, and Celeste, where he attended elementary school.[9] His father drifted in and out of the family's life and eventually deserted them. Murphy dropped out of school in fifth grade and got a job picking cotton for a dollar a day to help support his family; he also became skilled with a rifle, hunting small game to help feed them. After his mother died of endocarditis and pneumonia[10] in 1941, he worked at a radio repair shop and at a combination general store, garage and gas station in Greenville.[11] Hunt County authorities placed his three youngest siblings in Boles Children's Home,[12] a Christian orphanage in Quinlan. After the war, he bought a house in Farmersville for his oldest sister Corinne and her husband Poland Burns. His other siblings briefly shared the home.[13]\\r\\nThe loss of his mother stayed with Murphy throughout his life. He later stated:\\r\\nShe died when I was sixteen. She had the most beautiful hair I've ever seen. It reached almost to the floor. She rarely talked; and always seemed to be searching for something. What it was I don't know. We didn't discuss our feelings. But when she passed away, she took something of me with her. It seems I've been searching for it ever since.[14]\\r\\nMurphy had always wanted to be a soldier, and after the Japanese attack on Pearl Harbor in December 1941, he tried to enlist,[11] but the Army, Navy and Marine Corps all turned him down for being underweight and underage. After his sister provided an affidavit falsifying his birth date by a year, he was accepted by the U.S. Army on 30 June 1942.[ALM 1][ALM 2] After basic training at Camp Wolters,[19] he was sent to Fort Meade for advanced infantry training.[20] During basic training, he earned the Marksman Badge with Rifle Component Bar and Expert Badge with Bayonet Component Bar.[21]\\r\\nMurphy was shipped to Casablanca in French Morocco on 20 February 1943. He was assigned to Company B, 1st Battalion, 15th Infantry Regiment, 3rd Infantry Division,[22] which trained under the command of Major General Lucian Truscott.[23] [22][23] He participated as a platoon messenger with his division at Arzew in Algeria in rigorous training for the Allied assault landings in Sicily.[22][24] He was promoted to private first class on 7 May and corporal on 15 July.[25][26]\\r\\nWhen the 3rd Infantry landed at Licata, Sicily, on 10 July, Murphy was a division runner.[27][28] On a scouting patrol, he killed two fleeing Italian officers near Canicatt.[29] Sidelined with illness for a week when Company B arrived in Palermo on 20 July,[30] he rejoined them when they were assigned to a hillside location protecting a machine-gun emplacement, while the rest of the 3rd Infantry Division fought at San Fratello en route to the Allied capture of the transit port of Messina.[31]\\r\\nMurphy participated in the September 1943 mainland Salerno landing at Battipaglia.[32] While on a scouting party along the Volturno River, he and two other soldiers were ambushed; German machine gun fire killed one soldier. Murphy and the other survivor responded by killing five Germans with hand grenades and machine gun fire.[33] While taking part in the October Allied assault on the Volturno Line,[32][34] near Mignano Monte Lungo Hill 193, he and his company repelled an attack by seven German soldiers, killing three and taking four prisoner.[35] Murphy was promoted to sergeant on 13 December.[36]\\r\\nIn January 1944, Murphy was promoted to staff sergeant.[36] He was hospitalized in Naples with malaria on 21 January, and was unable to participate in the initial landing at the Anzio beachhead.[37] He returned on 29 January and participated in the First Battle of Cisterna,[38][39] and was made a platoon sergeant in Company B following the battle.[40] He returned with the 3rd Division to Anzio, where they remained for months.[41] Taking shelter from the weather in an abandoned farmhouse on 2 March, Murphy and his platoon killed the crew of a passing German tank.[42] He then crawled out alone close enough to destroy the tank with rifle grenades, for which he received the Bronze Star with \\"V\\" Device.[43][44] Murphy continued to make scouting patrols to take German prisoners before being hospitalized for a week on 13 March with a second bout of malaria. Sixty-one infantry officers and enlisted men of Company B, 15th Infantry, including Murphy, were awarded the Combat Infantryman Badge on 8 May.[45]\\r\\nMurphy was awarded a Bronze Oak Leaf Cluster for his Bronze Star.[46][47] American forces liberated Rome on 4 June, and Murphy remained bivouacked in Rome with his platoon throughout July.[48]\\r\\nMurphy received the Distinguished Service Cross[49][50] for action taken on 15 August 1944, during the first wave of the Allied invasion of southern France.[51] After landing on Yellow Beach near Ramatuelle,[52] Murphy's platoon was attacked by German soldiers while making their way through a vineyard. He retrieved a machine gun that had been detached from the squad and returned fire at the German soldiers, killing two and wounding one.[52] Two Germans exited a house about 100 yards (91?m) away and appeared to surrender; when Murphy's best friend responded, they shot and killed him. Murphy advanced alone on the house under direct fire. He killed six, wounded two and took 11 prisoner.[52]\\r\\nMurphy was with the 1st Battalion, 15th Infantry Regiment during the 27ÿ28 August offensive at Montlimar that secured the area from the Germans.[51][53] Along with the other soldiers who took part in the action, he received the Presidential Unit Citation.[54]\\r\\nMurphy's first Purple Heart was for a heel wound received in a mortar shell blast on 15 September 1944 in northeastern France.[55][56][57] His first Silver Star came after he killed four and wounded three at a German machine gun position on 2 October at L'Omet quarry in the Cleurie river valley.[49] Three days later, Murphy crawled alone towards the Germans at L'Omet, carrying an SCR-536 radio and directing his men for an hour while the Germans fired directly at him.\\r\\nWhen his men finally took the hill, 15 Germans had been killed and 35 wounded. Murphy's actions earned him a Bronze Oak Leaf Cluster for his Silver Star.[58] He was awarded a battlefield commission to second lieutenant on 14 October, which elevated him to platoon leader.[59] While en route to Brouvelieures on 26 October, the 3rd Platoon of Company B was attacked by a German sniper group. Murphy captured two before being shot in the hip by a sniper; he returned fire and shot the sniper between the eyes. At the 3rd General Hospital at Aix-en-Provence,[60] the removal of gangrene from the wound caused partial loss of his hip muscle and kept him out of combat until January.[49] Murphy received his first Bronze Oak Leaf Cluster for his Purple Heart for this injury.[61][62]\\r\\nThe Colmar Pocket, 850 square miles (2,200?km2) in the Vosges Mountains, had been held by German troops since November 1944.[63] On 14 January 1945, Murphy rejoined his platoon, which had been moved to the Colmar area in December.[64] He moved with the 3rd Division on 24 January to the town of Holtzwihr, where they faced a strong German counterattack.[65] He was wounded in both legs, for which he received a second Bronze Oak Leaf Cluster for his Purple Heart.[66] As the company awaited reinforcements on 26 January, he was made commander of Company B.[67]\\r\\nThe Germans scored a direct hit on an M10 tank destroyer, setting it alight, forcing the crew to abandon it.[68] Murphy ordered his men to retreat to positions in the woods, remaining alone at his post, shooting his M1 carbine and directing artillery fire via his field radio while the Germans aimed fire directly at his position.[69] Murphy mounted the abandoned, burning tank destroyer and began firing its .50 caliber machine gun at the advancing Germans, killing a squad crawling through a ditch towards him.[70] For an hour, Murphy stood on the flaming tank destroyer returning German fire from foot soldiers and advancing tanks, killing or wounding 50 Germans. He sustained a leg wound during his stand, and stopped only after he ran out of ammunition.[68] Murphy rejoined his men, disregarding his own injury, and led them back to repel the Germans. He insisted on remaining with his men while his wounds were treated.[68] For his actions that day, he was awarded the Medal of Honor.[71] The 3rd Infantry Division was awarded the Presidential Unit Citation for its actions at the Colmar Pocket, giving Murphy a Bronze Oak Leaf Cluster for the emblem.[72]\\r\\nOn 16 February, Murphy was promoted to first lieutenant[73] and was awarded the Legion of Merit for his service from 22 January 1944 to 18 February 1945.[74] He was moved from the front lines to Regimental Headquarters and made a liaison officer.[75]\\r\\nThe United States additionally honored Murphy's war contributions with the American Campaign Medal,[76] the EuropeanÿAfricanÿMiddle Eastern Campaign Medal with arrowhead device and 9 campaign stars, the World War II Victory Medal,[76] and the Army of Occupation Medal with Germany Clasp.[44][76] France recognized his service with the French Legion of Honor ÿ Grade of Chevalier,[77] the French Croix de guerre with Silver Star,[78] the French Croix de guerre with Palm,[79] the French Liberation Medal[44][76] and the French Fourragre in Colors of the Croix de guerre,[44] which was authorized for all members of the 3rd Infantry Division who fought in France during World War II. Belgium awarded Murphy the Belgian Croix de guerre with 1940 Palm.[79]\\r\\nBrigadier General Ralph B. Lovett and Lieutenant Colonel Hallet D. Edson recommended Murphy for the Medal of Honor.[80][81] Near Salzburg, Austria on 2 June 1945,[82] Lieutenant General A.M. Patch[13] presented Murphy with the Medal of Honor and Legion of Merit for his actions at Holtzwihr. When asked after the war why he had seized the machine gun and taken on an entire company of German infantry, he replied, \\"They were killing my friends.\\"[83]\\r\\nMurphy received every U.S. military combat award for valor available from the U.S. Army for his World War II service.[ALM 3]\\r\\nInquiries were made through official channels about the prospect of Murphy attending West Point upon his return to the United States, but he never enrolled.[6][86] According to author Don Graham, Murphy suggested the idea and then dropped it, possibly when he realized the extent of academic preparation needed to pass the entrance exam.[87] Murphy was one of several military personnel who received orders on 8 June 1945 to report to Fort Sam Houston in San Antonio, Texas, for temporary duty and reassignment.[6][86]\\r\\nUpon arrival on 13 June, he was one of four assigned to Fort Sam Houston Army Ground & Services Redistribution Station and sent home for 30 days of recuperation, with permission to travel anywhere within the United States during that period.[6] While on leave, Murphy was feted with parades, banquets, and speeches.[88] He received a belated Good Conduct Medal on 21 August.[89]\\r\\nHe was discharged with the rank of first lieutenant at a 50 percent disability classification on 21 September and transferred to the Officers' Reserve Corps.[ALM 4]\\r\\nMurphy had been plagued since his military service with insomnia and bouts of depression, and slept with a loaded pistol under his pillow.[91][92] A post-service medical examination on 17 June 1947 revealed symptoms of headaches, vomiting, and nightmares about war. His medical records indicated that he took sleeping pills to help prevent nightmares.[93] During the mid-1960s, he recognized his dependence on Placidyl, and locked himself alone in a hotel room for a week to break the addiction successfully.[13] Post-traumatic stress levels exacerbated his innate moodiness,[8] and surfaced in episodes that friends and professional colleagues found alarming.[94] His first wife, Wanda Hendrix, stated that he once held her at gunpoint.[95] She witnessed her husband being guilt-ridden and tearful over newsreel footage of German war orphans.[96] Murphy briefly found a creative stress outlet in writing poetry after his Army discharge. His poem \\"The Crosses Grow on Anzio\\" appeared in his book To Hell and Back,[97] but was attributed to the fictitious character Kerrigan.[98]\\r\\nIn an effort to draw attention to the problems of returning Korean War and Vietnam War veterans, Murphy spoke out candidly about his own problems with posttraumatic stress disorder.[99] It was known during Murphy's lifetime as \\"battle fatigue\\" and \\"shell shock\\", terminology that dated back to World War I. He called on the government to give increased consideration and study to the emotional impact of combat experiences, and to extend health care benefits to war veterans.[100][101] As a result of legislation introduced by U.S. Congressman Olin Teague five months after Murphy's death in 1971, the Audie L. Murphy Memorial VA Hospital[102] in San Antonio, now a part of the South Texas Veterans Health Care System, was dedicated in 1973.[103][104]\\r\\nAt the end of World War II, the 36th Infantry Division reverted to state control as part of the Texas Army National Guard,[105] and Murphy's friends Major General H. Miller Ainsworth and Brigadier General Carl L. Phinney were the 36th's commander and deputy commander respectively. After the 25 June 1950 commencement of the Korean War, Murphy began a second military career and was commissioned as a captain in the 36th Infantry Division of the Texas Army National Guard.[106][107] He drilled new recruits in the summer training camps, and granted the Guard permission to use his name and image in recruiting materials.[108] Although he wanted to join the fighting and juggled training activities with his film career, the 36th Infantry Division was never sent to Korea.[109][110]\\r\\nAt his request, he transferred to inactive status on 1 October 1951 because of his film commitments with MGM Studios, and returned to active status in 1955. Murphy was promoted to the rank of major by the Texas Army National Guard in 1956 and returned to inactive status in 1957.[111] In 1969, his official separation from the Guard transferred him to the United States Army Reserve.[112] He remained with the USAR until his transfer to the Retired Reserve in 1969.[113]\\r\\nThroughout an acting career spanning from 1948 to 1969, Murphy made more than 40 feature films and one television series.[ALM 5] When actor and producer James Cagney saw the 16 July 1945 issue of Life magazine depicting Murphy as the \\"most decorated soldier\\",[85] he brought him to Hollywood. Cagney and his brother William signed him as a contract player for their production company and gave him training in acting, voice and dance.[115] They never cast Murphy in a movie and a personal disagreement ended the association in 1947.[116] Murphy later worked with acting coach Estelle Harman, and honed his diction by reciting dialogue from William Shakespeare and William Saroyan.[117]\\r\\nMurphy moved into Terry Hunt's Athletic Club in Hollywood where he lived until 1948.[118][119] Hollywood writer David \\"Spec\\" McClure befriended Murphy, collaborating with him on Murphy's 1949 book To Hell and Back.[120] McClure used his connections to get Murphy a $500 bit part in Texas, Brooklyn and Heaven.[121] The agent of Wanda Hendrix, whom he had been dating since 1946,[122] got him a bit part in the 1948 Alan Ladd film Beyond Glory directed by John Farrow.[123] His 1949 film Bad Boy gave him his first leading role.[124] The film's financial backers refused to bankroll the project unless Murphy was given the lead;[125] thus, Allied Artists put aside their reservations about using an inexperienced actor and gave him the starring role.[126]\\r\\nUniversal Studios signed Murphy to a seven-year studio contract at $2,500 a week.[127][128] His first film for them was as Billy the Kid in The Kid from Texas in 1950. He wrapped up that year making Sierra starring Wanda Hendrix, who by that time had become his wife,[129] and Kansas Raiders as outlaw Jesse James. Universal lent him to MGM in 1951 at a salary of $25,000[130] to play the lead of The Youth[ALM 6] in The Red Badge of Courage, directed by John Huston.[132] Murphy and Huston worked together again in the 1960 film The Unforgiven.[133]\\r\\nThe only film Murphy made in 1952 was The Duel at Silver Creek with director Don Siegel. Murphy worked with Siegel one more time in 1958 for The Gun Runners. In 1953, he starred in Frederick de Cordova's Column South,[134] and played Jim Harvey in Nathan Juran's Tumbleweed, an adaptation of the Kenneth Perkins novel Three Were Renegades.[135][136] Director Nathan Juran also directed Gunsmoke and Drums Across the River.[137] George Marshall directed Murphy in the 1954 Destry, a remake of Destry Rides Again, based on a character created by author Max Brand.[138]\\r\\nAlthough Murphy was initially reluctant to appear as himself in To Hell and Back, the 1955 adaptation of his book directed by Jesse Hibbs, he eventually agreed;[139] it became the biggest hit in the history of Universal Studios at the time.[140][141] To help publicize the release of the film, he made guest appearances on television shows such as What's My Line?,[ALM 7] Toast of the Town,[142] and Colgate Comedy Hour.[ALM 8] The Hibbs-Murphy team proved so successful in To Hell and Back[143] that the two worked together on five subsequent films. The partnership resulted in the 1956 western Walk the Proud Land,[144] and the non-westerns Joe Butterfly[145] and World in My Corner. They worked together for the last time in the 1958 western Ride a Crooked Trail.[146]\\r\\nJoseph L. Mankiewicz hired Murphy to play the titular role[ALM 9] in the 1958 film The Quiet American.[148] Murphy formed a partnership with Harry Joe Brown to make three films, starting with The Guns of Fort Petticoat (1957). The partnership fell into disagreement over the remaining two projects, and Brown filed suit against Murphy.[149]\\r\\nHe featured in three westerns in 1959: he starred opposite Sandra Dee in The Wild and the Innocent,[150] collaborated as an uncredited co-producer with Walter Mirisch on the black and white Cast a Long Shadow, and performed as a hired killer in No Name on the Bullet, a film that was well received by critics.[151] Thelma Ritter was his costar in the 1960 Startime television episode \\"The Man\\".[152]\\r\\nDuring the early 1960s, Murphy donated his time and otherwise lent his name and image for three episodes of The Big Picture television series produced by the United States Army. He received the 1960 Outstanding Civilian Service Medal for his cooperation in the episode Broken Bridge, which featured his visits to military installations in Germany, Italy, Turkey and the U.S. state of New Mexico to showcase the military's latest weaponry.[153][154]\\r\\nWriter Clair Huffaker wrote the 1961 screenplays for Murphy's films Seven Ways from Sundown and Posse from Hell.[155] Willard W. Willingham and his wife Mary Willingham befriended Murphy in his early days in Hollywood and worked with him on a number of projects.[156][157][158]\\r\\nWillard was a producer on Murphy's 1961 television series Whispering Smith,[159] and co-wrote the screenplay for Battle at Bloody Beach that year.[160] He collaborated on Bullet for a Badman[161] in 1964 and Arizona Raiders in 1965.[162] The Willinghams as a team wrote the screenplay for Gunpoint[163] as well as the script for Murphy's last starring lead in the western 40 Guns to Apache Pass in 1967.[164] Murphy made Trunk to Cairo in Israel in 1966.[165]\\r\\nHe first met director Budd Boetticher when Murphy requested to be his boxing partner at Terry Hunt's Athletic Club.[166] He subsequently appeared in the 1951 title role of Boetticher's first western The Cimarron Kid.[167] Boetticher wrote the script in 1969 for Murphy's last film A Time for Dying.[168] Two other projects that Murphy and Boetticher planned to collaborate on?ÿ A Horse for Mr Barnum and When There's Sumpthin' to Do?ÿ never came to fruition.[169]\\r\\nMurphy married actress Wanda Hendrix in 1949.[170] Their divorce became final two years later in 1951.[171] Four days later, he married former airline stewardess Pamela Archer.[172] He had two sons with Archer: Terry Michael Murphy, born on 14 March 1952,[173][174] and James Shannon \\"Skipper\\" Murphy, born in 1954.[175]\\r\\nMurphy bred quarter horses at the Audie Murphy Ranch in what is now Menifee, California, and the Murphy Ranch in Pima County, Arizona.[ALM 10] His horses raced at the Del Mar Racetrack and he invested large sums of money in the hobby.[178] Murphy had a gambling habit that left his finances in a poor state. In 1968, he stated that he lost $260,000 in an Algerian oil deal and was dealing with the Internal Revenue Service over unpaid taxes.[179] In spite of his financial difficulties, Murphy refused to appear in commercials for alcohol and cigarettes, mindful of the influence he would have on the youth market.[180]\\r\\nOn 28 May 1971, Murphy was killed when the private plane in which he was a passenger crashed into Brush Mountain, near Catawba, Virginia, 20 miles (32?km) west of Roanoke in conditions of rain, clouds, fog and zero visibility.[181] The pilot and four other passengers were also killed.[182] The aircraft was a twin-engine Aero Commander 680 flown by a pilot who had a private-pilot license and a reported 8,000 hours of flying time, but who held no instrument rating. The aircraft was recovered on 31 May.[183] After her husband died, Pamela Murphy moved into a small apartment and got a clerk position at the Veterans Administration Hospital in Los Angeles, where she remained employed for 35 years.[184] In 1975, a court awarded Murphy's widow and two children $2.5 million in damages because of the accident.[185]\\r\\nOn 7 June 1971, Murphy was buried with full military honors at Arlington National Cemetery.[186] In attendance were Ambassador to the U.N. George H.W. Bush, Army Chief of Staff William Westmoreland, and many of the 3rd Infantry Division.[187] Murphy's grave site is in Section 46, headstone number 46-366-11, located across Memorial Drive from the Amphitheater. A special flagstone walkway was later constructed to accommodate the large number of people who visit to pay their respects. It is the cemetery's second most-visited grave site, after that of President John F. Kennedy.[188]\\r\\nThe headstones of Medal of Honor recipients buried at Arlington National Cemetery are normally decorated in gold leaf. Murphy previously requested that his stone remain plain and inconspicuous, like that of an ordinary soldier.[189] The headstone contains the birth year 1924, based upon purportedly falsified materials among his military records.[190] In 1974, a large granite marker was erected just off the Appalachian Trail at 372152N 801333W? / ?37.364554N 80.225748W? / 37.364554; -80.225748? (Audie Murphy monument) at 3,100 elevation, near the crash site.[191]\\r\\nCivilian honors were bestowed on Murphy during his lifetime and posthumously, including a star on the Hollywood Walk of Fame.[192] In 2013, Murphy was honored by his home state with the Texas Legislative Medal of Honor.[ALM 11]\\r\\nSwedish power metal band Sabaton wrote a song on their 2014 studio album, Heroes, also entitled \\"To Hell and Back\\", commemorating and recognizing Audie Murphy as one of the most decorated American veterans of World War II.[197]\\r\\nDavid McClure, his collaborator on the book To Hell and Back, discovered Murphy's talent for poetry during their work on the memoir when he found discarded verses in Murphy's Hollywood apartment. One of those poems, \\"The Crosses Grow on Anzio\\", appears in To Hell and Back attributed to a soldier named Kerrigan. Only two others survived, \\"Alone and Far Removed\\" and \\"Freedom Flies in Your Heart Like an Eagle\\". The latter was part of a speech Murphy had written at a 1968 dedication of the Alabama War Memorial in Montgomery, and later set to music by Scott Turner under the title \\"Dusty Old Helmet\\".[198]\\r\\nMurphy was a fan of country music, in particular Bob Wills and Chet Atkins, but was not a singer or musician himself.[199] Through his friend Guy Mitchell, Murphy was introduced to songwriter Scott Turner in 1961.[200][201] The two of them collaborated on numerous songs between 1962 and 1970, the most successful of which was \\"Shutters and Boards\\" and \\"When the Wind Blows in Chicago\\".[202]","input":"Who was the most decorated soldier of world war ii?"},{"output":"Buffalo Bills","context":"National Football League Cheerleading, or simply NFL Cheerleading, is a professional cheerleading organization in the United States. 26 of the 32 NFL teams include a cheerleading squad in their franchise. Cheerleaders are a popular attraction that can give a team more coverage/airtime, popular local support, and increased media image. In 1954, the Baltimore Colts became the first NFL team to have cheerleaders. They were part of the Baltimore Colts Marching Band.\\r\\n\\r\\nMost NFL cheerleading squads are a part-time job. Often, cheerleaders have completed or are attending a university, and continue on to other careers after cheering for one to four seasons. The members participate in practice, training camp, games, appearances, photo shoots, and charity events. Apart from their main duties of cheering during the football games, the cheerleaders have many other responsibilities. Nearly every team member is available for appearances at schools, events, conferences, etc., for a set fee.\\r\\n\\r\\nAn anticipated annual event is the release of each squad's calendar, featuring members for each month in swimsuits or uniforms.\\r\\n\\r\\nAs well as being a mainstay of American football culture, the cheerleaders are one of the biggest entertainment groups to regularly perform for the United States Armed Forces overseas with performances and tours being enlisted by the USO. Teams send their variety show, an elite group of their best members, to perform combination shows of dance, music, baton twirling, acrobatics, gymnastics, and more. In February 2007, the Buffalo Bills even sent a squad of eight along with their choreographer into the war zone of Iraq. In 1996, the San Francisco 49ers Cheerleaders and their director  helicoptered into the war inflicted country of Bosnia with the USO and the U.S. Army. The U.S. troops in Korea have been entertained during the holiday season with the USO's Bob Hope Tour. Over the years, the tour has featured NFL cheerleaders from the Dallas Cowboys and the San Francisco 49ers.\\r\\n\\r\\nIn 2018, the first male dancers were added to National Football League Cheerleading.[1][2]\\r\\n\\r\\nThe first \\"Battle of the NFL Cheerleaders\\" was held in 1979 in Hollywood, Florida. Two cheerleaders from each cheerleading team compete against other mini-teams in various athletic events. The events include kayaking, 100 yard dash, obstacle courses, and other events. The Minnesota Vikings Cheerleaders took home the title in 1979. In 1980, it was held in Atlantic City, New Jersey and the Washington Redskinettes were the champions. The winners were Shiona Baum and Jeannie Fritz, and each received a car as the grand prize. The competition was resurrected in 2006 by the NFL Network, and was called NFL Cheerleader Playoffs. The playoffs were taped between July 17 and July 21, 2006 at Six Flags New England in Agawam, Massachusetts. Two-person teams of cheerleaders from 25 of the NFL's 32 teams participated in a four-event series of competitions. The first two events tested the cheerleaders' athletic abilities in events like the 100-yard dash, kayaking, tandem cycling, and the obstacle course. The third event was a trivia challenge called \\"Know Your NFL.\\" The final competition was a one-minute dance routine, similar to what they normally perform on NFL sidelines. The San Diego Chargers team (Casie and Shantel) defeated the Atlanta Falcons and St. Louis Rams squads to win the overall championship. The 3 teams finished in a three-way tie, with 210 points. The Chargers were declared the winners based on winning the dance competition.\\r\\n\\r\\nListed by name, with corresponding NFL football team.\\r\\n\\r\\nAs of 2016, six teams do not have cheerleading squads: Buffalo Bills, Chicago Bears, Cleveland Browns, Green Bay Packers, New York Giants, and the Pittsburgh Steelers. The Packers do, however, use a collegiate squad to cheer at home games.[21] Super Bowl XLV between the Steelers and the Packers in February 2011 was the first time a Super Bowl featured no cheerleaders. The Browns and the Giants are the only NFL teams that have never had cheerleaders, while the other aforementioned teams have had cheer squads in the past. However, there are reports that the Browns did have cheerleaders in 1971, but no records exist.[22]\\r\\n\\r\\nThe Buffalo Bills endorsed the officially independent Buffalo Jills from 1966 to 2013; when several cheerleaders sued both the Bills and the Bills organizations, the Jills suspended operations.[23]\\r\\n\\r\\nTeams of \\"unofficial\\" cheerleaders began emerging in 2010 for NFL teams that don't have their own dance squad. These unofficial cheerleaders aren't sanctioned by the NFL or any franchise in the NFL and therefore are not allowed to perform at games, represent the football team at any outside functions, or use any of the team's branding or trademarked colors on their uniforms. The teams are sponsored by local businesses, and the cheerleaders perform prior to the game, at tailgate parties, and other local events. Some also attend the local NFL games in uniform, and sit together in their block of season ticket seats. Their audition process, costuming, and choreography are very similar to official NFL cheer teams. Some also produce an annual swimsuit calendar, just like the legitimate cheerleaders. All of the independent teams hope at some point to be embraced by the NFL as \\"official\\" cheerleaders of their local teams.\\r\\n\\r\\nA top honor for an NFL Cheerleader is to be selected as a Pro Bowl Cheerleader. The group is composed of an all-star cheerleader (one from each NFL cheer team) that represents her NFL team at the Pro Bowl in Hawaii. The Pro Bowl Cheerleaders were founded in 1992 and directed by Jay Howarth and Angela King-Twitero. Each year, one squad member from every NFL team is chosen to participate in the collective Pro Bowl cheerleading squad.[28]","input":"How many nfl teams do not have cheerleaders?"},{"output":"Peter Houston","context":"Rollfilm or roll film is any type of spool-wound photographic film protected from white light exposure by a paper backing, as opposed to film which is protected from exposure and wound forward in a cartridge. The term originated in contrast to sheet film. Confusingly, roll film was originally often referred to as \\"cartridge\\" film because of its resemblance to a shotgun cartridge. The opaque backing paper allows roll film to be loaded in daylight. It is typically printed with frame number markings which can be viewed through a small red window at the rear of the camera. A spool of roll film is usually loaded on one side of the camera and pulled across to an identical take up spool on the other side of the shutter as exposures are made. When the roll is fully exposed, the take up spool is removed for processing and the empty spool on which the film was originally wound is moved to the other side, becoming the take up spool for the next roll of film.\\r\\nIn 1881 a farmer in Cambria, Wisconsin, Peter Houston, invented the first roll film camera. His younger brother David, filed the patents for various components of Peter's camera.[1] David Henderson Houston (b. June 14, 1841; d. May 6, 1906 ),[2] originally from Cambria, Wisconsin, patented the first holders for flexible roll film.[2][3] Houston moved to Hunter in Dakota Territory in 1880. He was issued an 1881 patent for a roll film holder [4][5] which he licensed to George Eastman (it was used in Eastman's Kodak 1888 box camera). Houston sold the patent (and an 1886 revision[6]) outright to Eastman for $5000 in 1889.[2][7][8] Houston continued developing the camera, creating 21 patents for cameras or camera parts between 1881 and 1902.[2][9] In 1912 his estate transferred the remainder of his patents to Eastman.[2]\\r\\nThe most popular rollfilm is the type 120 film format, which is used in most medium-format cameras and roll film magazines for large-format cameras. Until the 1950s, 120 roll film was also used in what was then the most simple of snapshot cameras, and box cameras. The use of roll film in consumer cameras was largely superseded by 135 and 126 cartridges, but 120 and 220 (double length) film are still commonly used in medium-format cameras.","input":"The inventor of the popular roll-film camera was?"},{"output":"Mary Shelley","context":"\\r\\n\\r\\nGenius is an American anthology period drama television series developed by Noah Pink and  Kenneth Biller that premiered on April 25, 2017 on National Geographic.\\r\\n\\r\\nThe first season follows the life of Albert Einstein, from his early years, through his time as a patent clerk, to his later years as a physicist who developed the theory of relativity; the season is based on the 2007 book Einstein: His Life and Universe by Walter Isaacson. In April 2017, National Geographic renewed the series for a second season, which follows Pablo Picasso and aired from April 24 to June 19, 2018. In April 2018, National Geographic renewed the series for a third season set to follow the life of writer Mary Shelley.\\r\\n\\r\\nThe first season chronicles two periods in the life of Albert Einstein: the first as a patent clerk struggling to gain a teaching position and doctorate, the second as a scientist respected for his development of the theory of relativity.\\r\\n\\r\\nThe second season chronicles two periods in the life of Pablo Picasso: the first as a young man first discovering his talent, the second as a celebrated artist struggling with the rise of fascism and the price of fame.\\r\\n\\r\\n\\r\\n\\r\\nOn April 28, 2016, it was announced that National Geographic had given the production a straight-to-series order, its first ever scripted series. The series was set to be based on the biography Einstein: His Life and Universe by Walter Isaacson and adapted by Noah Pink, who was also expected to co-executive produce. Executive producers were announced to include Brian Grazer, Ron Howard, Francie Calfo, Gigi Pritzker, Rachel Shane, Sam Sokolow, and Jeff Cooney. Anna Culp was set to co-produce alongside Melissa Rucker. Ron Howard was expected to direct the first episode of the series. Production companies involved with the series were set to include Imagine TV, Fox 21 TV Studios, OddLot Entertainment and EUE/Sokolow.[19]\\r\\n\\r\\nIn August 2016, it was announced that Geoffrey Rush and Johnny Flynn would star in the series as Albert Einstein both as an old man and as a young adult, respectively.[20] Additionally, it was reported that Emily Watson would also star in the series and that Michael McElhatton, Seth Gabel, Samantha Colley, Richard Topol, and Vincent Kartheiser had joined the cast.[21] In November 2016, it was announced that Shannon Tarbet, Claire Rushbrook, and Robert Lindsay had been cast in recurring roles.[22] On February 2, 2017, it was reported that T. R. Knight had been cast in the recurring role of J. Edgar Hoover.[23]\\r\\n\\r\\nOn September 6, 2017, it was announced that Antonio Banderas would star in the second season as Pablo Picasso.[24] On November 2, 2017, it was reported that Alex Rich would co-star in the series sharing the lead role of Picasso. It was further reported that Clmence Posy, Robert Sheehan, Poppy Delevingne, Aisling Franciosi, and Sebastian Roch also joined the cast and that Samantha Colley, T. R. Knight, Seth Gabel, and Johnny Flynn were returning from season one in new roles.[25]\\r\\n\\r\\nPrincipal photography for season one took place in mid-2016 in Prague.[19] Filming for season two began in November 2017 in Mlaga and was expected to take place for over five months in various cities around the world, including Barcelona, Paris, and Budapest.[25][26]\\r\\n\\r\\nOn January 13, 2017, National Geographic released an extended trailer for the first season.[27] On January 12, 2018, a trailer for the second season was released.[28]\\r\\n\\r\\nOn April 19, 2017, National Geographic renewed the series for a second season.[29] The subject of the second season was to have been announced during the finale of the first season,[29] but was instead revealed to be Pablo Picasso the day after the finale, when the network and producers did not want to divert attention away from the season finale.[30][31] The second season premiered on April 24, 2018.[32]\\r\\n\\r\\nOn April 18, 2018, National Geographic renewed the series for a third season set to follow the life of writer Mary Shelley. Ken Biller is expected to return as showrunner, executive producer and writer. Also returning are executive producers Brian Grazer, Ron Howard, Francie Calfo, Jeff Cooney, Sam Sokolow, Gigi Pritzker, and Rachel Shane. Anna Culp will return as producer. Returning production companies include Imagine TV, MWM Studios, and EUE/Sokolow. Filming is expected to begin in late-2018.[33]\\r\\n\\r\\nThe first season received mostly positive reviews. On review aggregator website Rotten Tomatoes, the series has an approval rating of 83%, based on 29 reviews.[34] On Metacritic, the season had a score of 65 out of 100, based on 20 reviews, indicating \\"generally favorable reviews\\".[35]\\r\\n\\r\\nScience columnist Dennis Overbye of The New York Times described the series as a \\"tense binge-worthy psychological thriller full of political and romantic melodrama.\\"[36] Overbye further noted that Einstein himself, writing to his sister, wrote, \\"If everybody lived a life like mine, there would be no need for novels.\\"[36] According to Hillary Busis of Vanity Fair, the film shows, \\"... Einstein at work ... peers into the ber-genius's tumultuous love life (monogamy, he believes, is \\"not natural\\") ... his fraught emigration to the United States ...\\".[37] Busis quotes producer Ron Howard: \\"When you move past his scientific contributions, Albert's life storywhat his youth was like, who his friends were, who his enemies were, his tumultuous love lifeis a story people don't know ... I think audiences are going to be riveted as we tell this ambitious and revealing human story behind Einstein's scientific brilliance.\\"[37]\\r\\n\\r\\nThe second season received mixed reviews, but garnered praise for its star, Antonio Banderas. Rotten Tomatoes gave an approval rating of 59%, based on 17 reviews. Its critical consensus reads: \\"An impressive performance from Antonio Banderas rescues Genius: Picasso from condensed melodrama.\\"[38] On Metacritic, the season had a score of 52 out of 100, based on 10 reviews, indicating \\"mixed or average reviews\\".[39]","input":"What is the next national geographic genius series?"},{"output":"the last feudal Japanese military government","context":"Edo\\r\\n(Shgun's residence)\\r\\nThe Tokugawa shogunate, also known as the Tokugawa bakufu (?ܤ?) and the Edo bakufu (??), was the last feudal Japanese military government, which existed between 1600 and 1868.[1] The head of government was the shgun,[2] and each was a member of the Tokugawa clan.[3] The Tokugawa shogunate ruled from Edo Castle and the years of the shogunate became known as the Edo period.[4] This time is also called the Tokugawa period[1] or pre-modern (Kinsei (݆)).[5]\\r\\n\\r\\n\\r\\nFollowing the Sengoku period (\\"warring states period\\"), the central government had been largely re-established by Oda Nobunaga during the AzuchiÿMomoyama period. After the Battle of Sekigahara in 1600, central authority fell to Tokugawa Ieyasu.[1]\\r\\nSociety in the Tokugawa period, unlike in previous shogunates, was supposedly based on the strict class hierarchy originally established by Toyotomi Hideyoshi. The daimy (lords) were at the top, followed by the warrior-caste of samurai, with the farmers, artisans, and traders ranking below. In some parts of the country, particularly smaller regions, daimy and samurai were more or less identical, since daimy might be trained as samurai, and samurai might act as local rulers. Otherwise, the largely inflexible nature of this social stratification system unleashed disruptive forces over time. Taxes on the peasantry were set at fixed amounts that did not account for inflation or other changes in monetary value. As a result, the tax revenues collected by the samurai landowners were worth less and less over time. This often led to numerous confrontations between noble but impoverished samurai and well-to-do peasants, ranging from simple local disturbances to much larger rebellions. None, however, proved compelling enough to seriously challenge the established order until the arrival of foreign powers.\\r\\nA 2017 study found that peasant rebellions and collective desertion (flight) lowered tax rates and inhibited state growth in the Tokugawa shogunate.[6]\\r\\nIn the mid-19th century, an alliance of several of the more powerful daimy, along with the titular Emperor, succeeded in overthrowing the shogunate after the Boshin War, culminating in the Meiji Restoration. The Tokugawa shogunate came to an official end in 1868 with the resignation of the 15th Tokugawa shgun Tokugawa Yoshinobu, leading to the \\"restoration\\" (t?^?, sei fukko) of imperial rule. Notwithstanding its eventual overthrow in favor of the more modernized, less feudal form of governance of the Meiji Restoration, the Tokugawa shogunate oversaw the longest period of peace and stability in Japan's history, lasting well over 260 years.\\r\\nThe bakuhan taisei (O鮼) was the feudal political system in the Edo period of Japan. Baku is an abbreviation of bakufu, meaning \\"military government\\"that is, the shogunate. The han were the domains headed by daimy.\\r\\nVassals held inherited lands and provided military service and homage to their lords. The bakuhan taisei split feudal power between the shogunate in Edo and provincial domains throughout Japan. Provinces had a degree of sovereignty and were allowed an independent administration of the han in exchange for loyalty to the shgun, who was responsible for foreign relations and national security. The shgun and lords were all daimys: feudal lords with their own bureaucracies, policies, and territories. The shgun also administered the most powerful han, the hereditary fief of the House of Tokugawa. Each level of government administered its own system of taxation.\\r\\nThe emperor, nominally a religious leader, held no real power; this was invested in the shgun. The shogunate had the power to discard, annex, and transform domains. The sankin-ktai system of alternative residence required each daimy to reside in alternate years between the han and the court in Edo. During their absences from Edo, it was also required that they leave family as hostages until their return. The huge expenditure sankin-ktai imposed on each han helped centralize aristocratic alliances and ensured loyalty to the shgun as each representative doubled as a potential hostage.\\r\\nTokugawa's descendants further ensured loyalty by maintaining a dogmatic insistence on loyalty to the shgun. Fudai daimy were hereditary vassals of Ieyasu, as well as of his descendants. Tozama (\\"outsiders\\") became vassals of Ieyasu after the Battle of Sekigahara. Shinpan (\\"relatives\\") were collaterals of Tokugawa Hidetada. Early in the Edo period, the shogunate viewed the tozama as the least likely to be loyal; over time, strategic marriages and the entrenchment of the system made the tozama less likely to rebel. In the end, it was the great tozama of Satsuma, Chsh and Tosa, and to a lesser extent Hizen, that brought down the shogunate. These four states are called the Four Western Clans, or Satchotohi for short.[7]\\r\\nThe number of han (roughly 250) fluctuated throughout the Edo period. They were ranked by size, which was measured as the number of koku of rice that the domain produced each year. One koku was the amount of rice necessary to feed one adult male for one year. The minimum number for a daimy was ten thousand koku; the largest, apart from the shgun, was a million.\\r\\nRegardless of the political title of the Emperor, the shguns of the Tokugawa family controlled Japan.[8] The administration (, taisei) of Japan was a task given by the Imperial Court in Kyoto to the Tokugawa family, which returned to the court in the Meiji Restoration. While the Emperor officially had the prerogative of appointing the shgun, he had virtually no say in state affairs. The shogunate appointed a liaison, the Kyoto Shoshidai (Shogun's Representative in Kyoto), to deal with the Emperor, court and nobility.\\r\\nTowards the end of the shogunate, however, after centuries of the Emperor having very little say in state affairs and being secluded in his Kyoto palace, and in the wake of the reigning shgun, Tokugawa Iemochi, marrying the sister of Emperor Kmei (r. 1846ÿ1867), in 1862, the Imperial Court in Kyoto began to enjoy increased political influence.[9] The Emperor would occasionally be consulted on various policies and the shogun even made a visit to Kyoto to visit the Emperor.\\r\\nForeign affairs and trade were monopolized by the shogunate, yielding a huge profit. Foreign trade was also permitted to the Satsuma and the Tsushima domains. Rice was the main trading product of Japan during this time. Isolationism was the foreign policy of Japan and trade was strictly controlled. Merchants were outsiders to the social hierarchy of Japan and were thought to be greedy.\\r\\nThe visits of the Nanban ships from Portugal were at first the main vector of trade exchanges, followed by the addition of Dutch, English and sometimes Spanish ships.\\r\\nFrom 1603 onward, Japan started to participate actively in foreign trade. In 1615, an embassy and trade mission under Hasekura Tsunenaga was sent across the Pacific to Nueva Espa?a (New Spain) on the Japanese-built galleon San Juan Bautista. Until 1635, the Shogun issued numerous permits for the so-called \\"red seal ships\\" destined for the Asian trade.\\r\\nAfter 1635 and the introduction of Seclusion laws, inbound ships were only allowed from China, Korea, and the Netherlands.\\r\\nFollowers of Christianity first began appearing in Japan during the 16th century. Oda Nobunaga embraced Christianity and the Western technology that was imported with it, such as the musket. He also saw it as a tool he could use to suppress Buddhist forces.[10]\\r\\nThough Christianity was allowed to grow until the 1610s, Tokugawa Ieyasu soon began to see it as a growing threat to the stability of the shogunate. As gosho (\\"Cloistered Shgun\\"),[11] he influenced the implementation of laws that banned the practice of Christianity. His successors followed suit, compounding upon Ieyasu's laws. The ban of Christianity is often linked with the creation of the Seclusion laws, or Sakoku, in the 1630s.[12]\\r\\nThe rj (]) were the senior members of the shogunate. They supervised the metsuke, machi-bugy, ongokubugy (ja:L׻k) and other officials, oversaw relations with the Imperial Court in Kyoto, kuge (members of the nobility), daimy, Buddhist temples and Shinto shrines, and attended to matters like divisions of fiefs. Normally, four or five men held the office, and one was on duty for a month at a time on a rotating basis. They conferred on especially important matters. In the administrative reforms of 1867 (Kei Reforms), the office was eliminated in favor of a bureaucratic system with ministers for the interior, finance, foreign relations, army, and navy.\\r\\nIn principle, the requirements for appointment to the office of rj were to be a fudai daimy and to have a fief assessed at 7004500000000000000?50000 koku or more. However, there were exceptions to both criteria. Many appointees came from the offices close to the shgun, such as soba ynin (ja:??[??), Kyoto Shoshidai, and Osaka jdai.\\r\\nIrregularly, the shguns appointed a rj to the position of tair (great elder). The office was limited to members of the Ii, Sakai, Doi, and Hotta clans, but Yanagisawa Yoshiyasu was given the status of tair as well. Among the most famous was Ii Naosuke, who was assassinated in 1860 outside the Sakuradamon Gate of Edo Castle (Sakuradamon incident).\\r\\nThe wakadoshiyori were next in status below the rj. An outgrowth of the early six-man rokuninsh (?n\\\\, 1633ÿ1649), the office took its name and final form in 1662, but with four members. Their primary responsibility was management of the affairs of the hatamoto and gokenin, the direct vassals of the shgun.\\r\\nSome shguns appointed a soba ynin. This person acted as a liaison between the shgun and the rj. The soba ynin increased in importance during the time of the fifth shgun Tokugawa Tsunayoshi, when a wakadoshiyori, Inaba Masayasu, assassinated Hotta Masatoshi, the tair. Fearing for his personal safety, Tsunayoshi moved the rj to a more distant part of the castle. Some of the most famous soba ynin were Yanagisawa Yoshiyasu and Tanuma Okitsugu.\\r\\nThe metsuke and metsuke were officials who reported to the rj and wakadoshiyori. The five metsuke were in charge of monitoring the affairs of the daimys, kuge and imperial court. They were in charge of discovering any threat of rebellion. Early in the Edo period, daimys such as Yagy Munefuyu held the office. Soon, however, it fell to hatamoto with rankings of 5,000 koku or more. To give them authority in their dealings with daimys, they were often ranked at 10,000 koku and given the title of kami (an ancient title, typically signifying the governor of a province) such as Bizen-no-kami.\\r\\nAs time progressed, the function of the metsuke evolved into one of passing orders from the shogunate to the daimys, and of administering to ceremonies within Edo Castle. They also took on additional responsibilities such as supervising religious affairs and controlling firearms. The metsuke, reporting to the wakadoshiyori, oversaw the affairs of the vassals of the shgun. They were the police force for the thousands of hatamoto and gokenin who were concentrated in Edo. Individual han had their own metsuke who similarly policed their samurai.\\r\\nThe san-bugy (\\"three administrators\\") were the jisha, kanj, and machi-bugy, which oversaw temples and shrines, accounting, and the cities, respectively. The jisha-bugy had the highest status of the three. They oversaw the administration of Buddhist temples (ji) and Shinto shrines (sha), many of which held fiefs. Also, they heard lawsuits from several land holdings outside the eight Kant provinces. The appointments normally went to daimys; oka Tadasuke was an exception, though he later became a daimy.\\r\\nThe kanj-bugy were next in status. The four holders of this office reported to the rj. They were responsible for the finances of the shogunate.[13]\\r\\nThe machi-bugy were the chief city administrators of Edo and other cities. Their roles included mayor, chief of the police (and, later, also of the fire department), and judge in criminal and civil matters not involving samurai. Two (briefly, three) men, normally hatamoto, held the office, and alternated by month.\\r\\nThree Edo machi bugy have become famous through jidaigeki (period films): oka Tadasuke and Tyama Kagemoto (Kinshir) as heroes, and Torii Yz (ja:ׄи) as a villain.\\r\\nThe san-bugy together sat on a council called the hyjsho. In this capacity, they were responsible for administering the tenry, supervising the gundai (hy), the daikan (y) and the kura bugy (ٻk), as well as hearing cases involving samurai.\\r\\nThe shogun directly held lands in various parts of Japan. These were known as shihaisho (E~); since the Meiji period, the term tenry (B, \\"Emperor's land\\") has become synonymous.[14] In addition to the territory that Ieyasu held prior to the Battle of Sekigahara, this included lands he gained in that battle and lands gained as a result of the Summer and Winter Sieges of Osaka. By the end of the seventeenth century, the shogun's landholdings had reached four million koku. Such major cities as Nagasaki and Osaka, and mines, including the Sado gold mine, also fell into this category.\\r\\nThe gaikoku bugy were administrators appointed between 1858 and 1868. They were charged with overseeing trade and diplomatic relations with foreign countries, and were based in the treaty ports of Nagasaki and Kanagawa (Yokohama).\\r\\nThe late Tokugawa shogunate (Japanese: OA Bakumatsu) was the period between 1853 and 1867, during which Japan ended its isolationist foreign policy called sakoku and modernized from a feudal shogunate to the Meiji government. It is at the end of the Edo period and preceded the Meiji era. The major ideological and political factions during this period were divided into the pro-imperialist Ishin Shishi (nationalist patriots) and the shogunate forces, including the elite shinsengumi (\\"newly selected corps\\") swordsmen.\\r\\nAlthough these two groups were the most visible powers, many other factions attempted to use the chaos of the Bakumatsu era to seize personal power.[15] Furthermore, there were two other main driving forces for dissent; first, growing resentment of tozama daimys, and second, growing anti-Western sentiment following the arrival of Matthew C. Perry. The first related to those lords who had fought against Tokugawa forces at Sekigahara (in 1600) and had from that point on been exiled permanently from all powerful positions within the shogunate. The second was to be expressed in the phrase sonn ji (\\"revere the Emperor, expel the barbarians\\"). The turning points of the Bakumatsu were the Boshin War and the Battle of TobaÿFushimi, when pro-shogunate forces were defeated.[16]\\r\\nOver the course of the Edo period, influential relatives of the shogun included:\\r\\n?This article incorporates?public domain material from the Library of Congress Country Studies website http://lcweb2.loc.gov/frd/cs/.","input":"What was the significance of the tokugawa shogunate?"},{"output":"India","context":"The Jeep Grand Cherokee is a mid-size luxury SUV produced by the American manufacturer Jeep. While some other SUVs were manufactured with body-on-frame construction, the Jeep Grand Cherokee has always used a unibody chassis.[1]\\r\\n\\r\\n\\r\\nThe Grand Cherokee's origins date back to 1983 when American Motors Corporation (AMC) was designing a successor to the smaller Jeep Cherokee (XJ).[2] Three outside (non-AMC) designersLarry Shinoda, Alain Clenet, and Giorgetto Giugiarowere also under contract with AMC to create and build a clay model of the Cherokee XJ replacement, then known as the \\"XJC\\" project.[3] However, the basic design for the Cherokee's replacement was well under way by AMC's in-house designers and the 1989 Jeep Concept 1 show car foretold the basic design.[4]\\r\\nAs AMC began development of the next Jeep in 1985, management created a business process that is now known as product lifecycle management (PLM).[5] According to Fran?ois Castaing, Vice President for Product Engineering and Development, the smallest U.S. automaker was looking for a way to speed up its product development process to compete better against its larger competitors.[6] The XJC's development was aided by computer-aided design (CAD) software systems making the engineers more productive while new communication allowed potential conflicts to be resolved faster thus reducing costly engineering changes because all drawings and documents were in a central database.[6] The system was so effective that after Chrysler purchased AMC in 1987, it expanded the system throughout its enterprise, thus connecting everyone involved in designing and building products.[6]\\r\\nThe Grand Cherokee thus became the first Chrysler-badged Jeep product. Development work for the new Jeep model continued and Chrysler's employees (after the 1987 buyout of AMC) were eager for a late-1980s release date; however, CEO Lee Iacocca was pushing for redesigned Chrysler minivans, thus delaying the Grand Cherokee's release until late-1992[7] as an Explorer competitor. Unlike the Explorer, the Grand Cherokee utilized monocoque (unibody) construction, whereas the Explorer was a derivative of the Ranger pickup with a separate body-on-frame.\\r\\nThe Grand Cherokee debuted in grand fashion at the 1992 North American International Auto Show in Detroit, Michigan. The vehicle that was driven was a Poppy Red Clear Coat 1993 Grand Cherokee ZJ Laredo with a quartz cloth interior and high-back bucket seats. Then Chrysler president Robert Lutz drove Detroit mayor, Coleman Young, from the Jefferson North Assembly Plant on North Jefferson Avenue via a police escort to Cobo Hall, up the steps of Cobo Hall and through a plate glass window to show off the new vehicle.[8] Sales of the 1993 model year Grand Cherokee began in April 1992.[9]\\r\\nProduction of the Grand Cherokee started shortly afterward in the purpose-built Jefferson North Assembly in Detroit, Michigan. European Grand Cherokees are manufactured in Austria by Magna Steyr.[10] The Grand Cherokee \\"played a significant part in reviving Chrysler's fortunes by moving it into the then nascent market for high-margin sports utility vehicles.\\"[11]\\r\\nUpon its introduction, it was the first USA-manufactured automobile using HFC-134a refrigerant in place of HCFC-12 for the HVAC system.\\r\\nThe original Grand Cherokee was launched in 1992 as a 1993 model year vehicle in the luxury SUV segment. The \\"ZJ\\" models, manufactured from 1992 to 1998, originally came in three trim levels: base (also known as SE), Laredo, and Limited, subsequent trims were added, included Orvis (95ÿ98), TSI (97ÿ98). The base model included features such as full instrumentation, cloth interior, and a standard five-speed manual transmission, while gaining the moniker \\"SE\\" name for the 1994 model year. Power windows and locks were not standard equipment on the base trim. The minimal price tag differential resulted in low consumer demand, and as a result, the low-line model was eventually discontinued. Additional standard features included a driver-side air bag (starting in 96) and four-wheel anti-lock braking system (ABS). The Laredo was the mid-scale model with standard features that included power windows, power door locks, cruise control, and a leather wrapped steering wheel. Exterior features included medium-grey plastic paneling on the lower body and five-spoke alloy wheels. The Limited was the premium model, featuring body color lower body paneling, and gold exterior accents. The Limited also boasted standard features such as leather seating, heated mirrors, front power seats, a keyless entry system, wood grain interior appliqu, lace style alloy wheels, a driver information center with compass, digitized climate control, and electrochromic rearview mirror, and Jensen brand stereo with multi-band equalizer. By 1996 the option list grew to include heated seats. Standard was the 4.0, with the 5.2 V8 (and 5.9 in 1998) being optional. As with other models. Package groups with the various trim levels included: fog lamps, skid plates, as well as convenience, lighting, luxury, power, security, and trailer towing packages.\\r\\nWhen it was first introduced in April 1992 as an early 1993 model year vehicle, the Grand Cherokee only had one powertrain choice: the 4.0 L AMC-derived straight-six engine that made 190 horsepower. This became the \\"volume\\" engine for the Grand Cherokee. Transmission choices included a four-speed automatic transmission (early production ZJs used the AW4 ÿ the A500SE (later 42RE) replaced the AW4 during the latter half of the 1993 model year) or an Aisin AX15 manual transmission. Low demand for the manual transmission resulted in its discontinuation after 1994, but European-market ZJs retained it when coupled to the diesel engine (which was unavailable in North America). The drive train choices included rear-wheel drive or four-wheel-drive. In 1995, the engine dropped 5 horsepower to 185 due to new EPA regulations imposed on the 1996 model year.\\r\\nIn 1998, a variant of the top-level Grand Cherokee Limited, the \\"5.9 Limited\\" was introduced. Jeep ads claimed it to be the \\"world's fastest sport utility vehicle\\", verified by third-party testing. The primary improvements in the 5.9 Limited version included a 245-horsepower 5.9L OHV V8 engine, heavy-duty 46RE automatic transmission, functional heat-extracting hood louvers, unique wide-slot body-colored grille with mesh inserts, special rocker moldings, low-restriction exhaust with three-inch chrome tip, a low-profile roof rack, and special 16\\" Ultra-Star wheels. The 5.9 Limited also received a 150 amp alternator and a 2-speed electric cooling fan. Other features include a standard 180-watt, 10-speaker Infinity Gold sound system with rear roof-mounted sound bar, standard sunroof, and an interior swaddled with unique \\"calf's nap\\" soft leather and faux wood trim. The 5.9 Limited was awarded \\"4x4 of the Year\\" for 1998 by Petersen's 4-Wheel & Off-Road magazine. Production of this model was 14,286 units.\\r\\nExport models produced at the plant in Graz, Austria, were given the vehicle designation of \\"ZG\\".\\r\\n.\\r\\nThe redesigned WJ 1999 Grand Cherokee shared just 127?parts with its predecessor (mostly fasteners). The European model was coded WG. The spare tire was relocated from the side of the cargo compartment to under the floor. (Like the 1998 ZJ, the rear tailgate glass opened separately.) The two heavy pushrod V8 engines were replaced by Chrysler's then-new PowerTech. The new V8 engine produced less torque than the old pushrods, but was lighter, offered better fuel economy, and provided similar on road performance figures (the 23-gallon fuel tank was replaced with one of a 20.5-gallon capacity). The straight-six engine was also updated in 1999. A redesign of the intake manifold added 10 horsepower (7.5?kW). While other Jeep vehicles used the Mopar 5 x 4.5 bolt circle, this was the first Jeep following the 1987 Chrysler buyout to receive a wider bolt pattern:?ÿ 5 x 5.\\r\\nA notable feature available in this generation was the automatic four wheel drive option called Quadra-Drive, which employed the New Venture Gear NV247 transfer case. This two-speed chain-driven transfer case uses a gerotor, a clutch pack coupled to a hydraulic pump, to transfer torque between the front and rear axles. The transfer case contains three modes, 4-All Time, Neutral, and 4-Lo. In 4-All Time, 100% of torque is sent to the rear axle in normal conditions. If the rear axle starts spinning at a higher rate than the front axle, hydraulic pressure builds up in the gerotor and causes the clutch pack to progressively transfer torque to the front axle until both axles return to the same speed. Neutral mode is intended for towing the vehicle. In 4-Lo, the front and rear axles are locked together through a 2.72 reduction gear ratio. The NV247 transfer case is mated to front and rear axles containing Jeep's Vari-Lok differentials. Vari-Lok differentials also use a gerotor to transfer torque between the wheels on either side of the axle. The major advantage of Quadra-Drive was that the combined transfer case and progressive locking differentials in each axle could automatically control traction between all four wheels. However, only the center differential could be permanently locked, and only in 4Lo. The Quadra-Trac II system included the NV247 transfer case with the standard open front and rear differentials.\\r\\nThe 45RFE and 545RFE automatic transmission in the WJ was notable. It included three planetary gear sets rather than the two normally used in a four-speed automatic. This gave it six theoretical speeds, and it would have been the first six-speed transmission ever produced in volume, but it was programmed to only use five of these ratios. Four were used for upshifts, with a different second gear for downshifts. Although five of the six ratios were used, Chrysler decided to call it a \\"4-speed automatic\\". In 2001, the programming was changed to make use of all six ratios. Rather than have six forward gears, the transmission was programmed to act as a five-speed with the alternate second gear for downshifts. The rpm at 70 miles per hour (110?km/h) on a 545RFE is 2000 rpm, 200 rpm less than the 45RFE programming. 1999 and 2000 model year WJ owners can have their 45RFE transmission's programming flashed to enable the extra gear as both transmissions are physically the same. (Must purchase new PCM and ABS module and program them with a fake VIN to make this work.) The 42RE 4-speed automatic remained the transmission for the Inline 6 engine. It had slight changes from the previous model Grand Cherokee.\\r\\nThe interior was also completely redesigned in 1999. The redesign allowed for larger rear doors, and more space for rear passengers. Controls for various items like headlights, heated seats, and rear wiper were moved to more convenient locations. The electronic Vehicle Information center was moved from below the radio to above the windshield, and was standard on all 2000 and up models. Limited models included automatic dual-zone climate control. A 10 CD-Changer was also available with the Infinity Audio package.\\r\\nIn addition to Jeep's UniFrame construction, Daimler Chrysler partnered with Porsche to further strengthen the frame.[citation needed] This was done to reduce NVH. UniFrame is an unusual construction scheme, it incorporates all of the strength and durability of a body-on-frame construction into a unitized construction. By adding stiffness and rigidity to the structure, they enhanced the ride and strengthened the network of steel beams, rails and pillars (or \\"safety cage\\") that surround and protect occupants. More than 70 percent of the underbody is high-strength steel. All Jeep Grand Cherokees feature UniFrame construction.\\r\\nThe Grand Cherokee received a minor facelift for 2004 including round fog lamps, a lower front fascia and a new body-color matched inset grille design.\\r\\nExport models produced at the plant in Graz, Austria, were given the vehicle designation of \\"WG\\".\\r\\nThe all-new WK Grand Cherokee debuted in 2004 for the 2005 model year. It was first unveiled at the 2004 New York International Auto Show. Features available for the first time in a Jeep included Quadra-Drive II four-wheel drive, rear-seat DVD player and optional 5.7?L Hemi V8. The 3.7?L V6 engine replaced the 4.0?L Straight-6. A Mercedes Benz sourced 3.0 V6 Common Rail Diesel (CRD) was available outside of North America from launch.\\r\\nThe design still emphasizes power and luxury, with significant work done on improving noise, vibration, and harshness (NVH). However, for the first time, Jeep also emphasized on-road performance to a similar extent as the cornerstone of its brand, off-road capability.\\r\\nThis newfound emphasis on on-road refinement led Jeep to replace the XJ-era live-axle with leading-arms front suspension (found in the ZJ and WJ) with a new design: an independent double-wishbone setup like that which debuted in the 2002 Liberty. The new Jeep changed its philosophy due to what it perceived as increasing demand in the SUV marketplace for on-road performance and decreasing demand for off-road capability. Although classed as a truck-based SUV, the WH/WK Grand Cherokee has more luxuries than a \\"crossover\\" especially refinement, capability and NVH.\\r\\nThe 2007 Jeep Grand Cherokee made its European debut at the Euro Camp Jeep held in Ardche, France. This Jeep has gained 5 stars in the Euro Ncap crash safety tests conducted in 2005.\\r\\nThe Grand Cherokee received a minor facelift for 2008. The bottom part of the headlights became rounded and High Intensity Discharge (HID) Headlamps with auto leveling were added. The lower portion of the front bumper was still removable as it was from launch to increase the approach angle for off-road use. The 4.7?L was refined, now producing 305?hp (227?kW; 309?PS), and 334?lb{ft (453?N{m).\\r\\nThe 2009 Jeep Grand Cherokee is available with an improved 5.7?L Hemi engine rated at 357?hp (266?kW; 362?PS) and 389?lb{ft (527?N{m) of torque. The engine uses variable valve timing to increase fuel economy.[12]\\r\\nThe fourth-generation Jeep Grand Cherokee went on sale in summer 2010 as a 2011 model.[13] It was unveiled at the 2009 New York Auto Show.[14] During development of the WK2 Grand Cherokee, it was used as one of the examples of future products by Chrysler management at the time to convince United States federal regulators in 2009 of Chrysler's future viability in requesting a federal loan, which culminated in the Chrysler Chapter 11 reorganization that same year.\\r\\nThe fourth-generation Grand Cherokee retains its classic Jeep styling combined with a modern and sleek body style. The interior features leather trim and real wood accents, plus Bluetooth and uConnect electronics options. With the additional awards for the 2011 Grand Cherokee, the Jeep Grand Cherokee has won 30 awards for off-road capability, luxury, value, best-in-class, and safety, making it the most awarded SUV ever.[15] Among the awards are: Top Safety Pick for 2011 from the IIHS, listed as a Consumers Digest Best Buy for 2011, Safest SUV in America by MSN Autos, and Truck of the Year for 2011 by The Detroit News.[citation needed]\\r\\nLike the previous generations, the chassis is a steel unibody. Unlike previous models, the new WK2 features four-wheel independent suspension for better on-road handling. The Grand Cherokee (with the 2011 Durango) WK2 platform uses a Chrysler designed and engineered platform/chassis that Mercedes-Benz later used for the Mercedes-Benz's W166 series. The Chrysler-designed platform/chassis was part of the DaimerChrysler engineering projects that was to launch the new Grand Cherokee with the Mercedes-Benz ML to follow. However, due to the subsequent sale and bankruptcy of Chrysler, the Grand Cherokee launch was delayed and the Mercedes ML launched before the WK2 Grand Cherokee.\\r\\nFour wheel drive systems include Quadra-Trac I, Quadra-Trac II, and Quadra-Drive II. Using Selec-Terrain, the driver can select modes for Auto, Sport, Snow, Sand/Mud, and Rock.\\r\\nOptional Quadra-Lift height adjustable air suspension can raise the vehicle's ground clearance up to 11.1?in (282?mm).[16] Lift modes include Park, Aero, Normal Ride Height, Off-Road 1, and Off-Road 2.\\r\\nEngine choices include the all new 3.6?L Pentastar V6 and 5.7?L Hemi V8. The Hemi V8 retains the Multiple Displacement System (MDS) that shuts down four cylinders in low-power driving situations. The V8 comes with the multi-speed automatic transmission that includes Electronic Range Selection (ERS) to manually limit the high gear operating range. Trailer towing is rated 7,400?lb (3,400?kg) for Hemi models and 5,000?lb (2,300?kg) for Pentastar models.[17] A 3.0?L turbocharged diesel V6 developed and built by Fiat Powertrain Technologies and VM Motori (with Multijet II injection[18]) rated at 177?kW (241?PS; 237?hp) and 550?N{m (410?lb{ft) of torque offered in export markets from mid-2011.[19] The new 3.0?L CRD turbodiesel engine is available in European markets as 140?kW (190?PS; 188?hp) low-power version.[20]\\r\\nThe new Grand Cherokee SRT8, which started production on July 16, 2011,[21] is equipped with a 470?hp (350?kW; 480?PS) 6.4?L Hemi V8 engine. Jeep claims the new SRT8 gets 13?percent better fuel economy than its predecessor.[citation needed] To keep the gas mileage respectable,[clarification needed] Jeep has employed a new active exhaust system that lets Chrysler's cylinder-deactivating Fuel Saver Technology operate over a wider rpm band. Chrysler claims that with the larger gas tank, the SUV can now travel up to 500 miles (800?km) on a single tank, while other sources estimate range to be 450 miles (720?km).\\r\\nThe Jeep Grand Cherokee was released in India on 30 August 2016. Alongside the Wrangler, the Grand Cherokee was the first model to be sold directly by Jeep in the country.[22] Jeeps have been built under licence by Mahindra in India since the 1960s.[23]\\r\\nIn 2010, the National Highway Traffic Safety Administration (NHTSA) launched an investigation into 1993ÿ2004 model year Jeep Grand Cherokees which involves the fuel tanks of these SUVs. Because the gas tanks are mounted between the bumper and rear axle, a rear collision could cause the fuel tank to leak, causing a fire. The NHTSA claims that it has reports of 157 deaths resulting from fires caused by Grand Cherokees crashing. Also affected are 2002ÿ2007 Jeep Liberty models and 1986ÿ2001 Jeep Cherokee models, which totals about 5.1 million affected vehicles.[49]\\r\\nIn June, 2013, Chrysler Corporation responded to the recall, agreeing to recall 2.7 million Jeeps, though eliminating both the 1986ÿ2001 Jeep Cherokee XJ and 1999ÿ2004 Jeep Grand Cherokee WJ from the recall. The recall will include 2.7 million 1993ÿ1998 Jeep Grand Cherokee ZJ and 2002ÿ2007 Jeep Liberty KJ vehicles.\\r\\nTwo weeks prior to this recall, Chrysler Corporation claimed that the affected Jeep vehicles were safe, though agreed to recall the affected vehicles later.\\r\\nTo remedy the problem, Jeep dealerships will install a trailer hitch onto the rear bumpers of Jeep vehicles that will protect the fuel tank if the vehicle is involved in a rear impact. If an affected vehicle is not currently equipped with a trailer hitch, one will be installed onto it, and older Jeep and non-factory aftermarket trailer hitches will be replaced with one from Chrysler Corporation. Despite the recall, the market for these Jeep vehicles has not suffered.[50]\\r\\nIn May 2013 there was a recall of WKs with the Quadra-Drive II and Quadra-Trac II systems. This followed cases of cars rolling away due the transfer case moving into neutral of its own accord, and the owner not having applied the parking brake. The recall revised the Final Drive Control Module (FDCM) software. However, following the recall there were widespread reports on enthusiast web sites [51] of both the neutral and low ratio modes of the transfer case ceasing to function, and a survey showed that fewer than 10% of respondents had experienced no issues with the recall.[52] Attempting to resolve these issues, some dealers subsequently replaced the transfer case actuator, FDCM, and even the transfer case itself, often at customer expense and usually to no avail.\\r\\nThe cause of the roll-aways was faulty soldering in the transfer case actuator. It has been deduced that the revised software detects this by noting any deviation in resistance, and thereupon locks the transfer case in high ratio for safety; but that it is over-reacting to minor resistance variations from other causes. Originally Chrysler dealers claimed that the loss of neutral and low ratio following the recall was co-incidence; then it claimed that the revised software was revealing pre-existing faults in the system, despite it occurring even with new parts. Chrysler have also claimed that only a small fraction of cars have issues following the recall;[53] but most users never have occasion to use the low ratio and may never discover the fault. Four years after this recall its issues remain unresolved.\\r\\nIn April 2016, the National Highway Traffic Safety Administration (NHTSA) ordered a recall of 2014 and 2015 Jeep Grand Cherokees and other cars that use an electronic gear shifter because it sometimes does not go into (or does not remain in) the park position, despite the operator's best intentions. Consumers reported that they put the car in park and left the engine running, and then were surprised when the car rolled away under power.\\r\\nAn investigation by FCA US and the National Highway Traffic Safety Administration found some drivers have exited their vehicles without first selecting PARK. Such behavior may pose a safety risk if a vehicles engine is still running. The Company is aware of 41 injuries that are potentially related. The vehicles involved in these events were inspected and no evidence of equipment failure was found. The vehicles also deliver warning chimes and alert messages if their driver-side doors are opened while their engines are still running and PARK is not engaged. However, investigation suggested these measures may be insufficient to deter some drivers from exiting their vehicles without selecting PARK, so FCA US will enhance the warnings and transmission-shift strategy on these vehicles. The enhancements will combine warnings with a transmission-shift strategy to automatically prevent a vehicle from moving, under certain circumstances, even if the driver fails to select PARK.[54]\\r\\nJeep has now replaced the shifter with a conventional lever which stays in position for late 2016 models.\\r\\nIn October 2017, 2011-14 model year Grand Cherokees were recalled due to improperly installed brake shields in some vehicles.[55]","input":"Where is the 2017 jeep grand cherokee made?"},{"output":"F~tbol de Primera","context":"F~tbol de Primera is an American radio network covering soccer. It has broadcast the World Cup since 2002 along with other FIFA tournaments. FDP also broadcasts Mexico's national team games, the CONCACAF Gold Cup, and had broadcast the Copa Amrica in 2015 and 2016. It is the home of the most exclusive soccer radio rights in the country, including the upcoming 2018 and 2022 FIFA World Cup.[1]\\r\\nF~tbol de Primera produces a daily show hosted by Andrs Cantor, which has been running since 1989. Alongside Cantor, the show's personalities are Sammy Sadovnik, Jaime Gallardo, and Rosa Beatriz Snchez. The show covers a wide range of football highlighting daily events in Mexico, Latin America, and Europe providing in-depth analysis of the most important headlines of the day. They are the longest-running, nationally syndicated Spanish radio program in the country and can be heard on 115 affiliated stations in the U.S. and others throughout Central and South America.\\r\\nF~tbol de Primera is based in Miami, but has offices in New York City, San Francisco, and San Antonio. Cantor is also the co-chairman of the network along with Alejandro Gutman.\\r\\n\\r\\n\\r\\nF~tbol de Primera Radio Network was created in August 1989 by Alejandro Gutman taking its first steps in becoming an integral part of the nations soccer landscape. With vast experience in the soccer world, F~tbol de Primera realized there was a need for soccer to be listened to on a substantial market list of stations that match the quality of the games themselves. In a historic move, F~tbol de Primera Radio worked with its affiliates to broaden the landscape beyond AM and talk radio to put soccer on the FM dial music formatted stations as soccer specials. The strategy worked and powerhouse matches over the years have been heard nationally without fail. F~tbol de Primera's most renowned broadcasts include the 2002, 2006, 2010 and 2014 FIFA World Cup. Other broadcasts include the Mexico national team games, CONCACAF World Cup Qualification and a record eight consecutive CONCACAF Gold Cups.\\r\\nIn 1991, F~tbol de Primera created the F~tbol de Primera Player of the Year which for twenty years was sponsored by the American Honda Motor Company. This award recognizes the best United States men's national soccer team player as voted by the U.S. media.\\r\\nFDP also produces \\"Casos y Cosas de Collins\\" a one-hour weekly show hosted by renowned Mexican journalist and author Mara Antonieta Collins.[2]\\r\\nF~tbol de Primera has a core broadcast team that is part of the daily show.[3]\\r\\nFor World Cups, F~tbol de Primera recruits former soccer players, coaches, and savants to their show. With so many personalities, F~tbol de Primera's show can be considered one of the most knowledgeable panels in Latin American soccer. The following have been a part of F~tbol de Primera's broadcast team at World Cups.\\r\\nThe following are the 115 affiliated stations where F~tbol de Primera's broadcasts such as the daily show and matches can be heard[4]\\r\\nAlbuquerque-Santa Fe, NM\\r\\nAtlanta, GA\\r\\nAmarillo, TX\\r\\nAustin, TX\\r\\nBakersfield, CA\\r\\nBarstow, CA\\r\\nBaton Rouge, LA\\r\\nBend, OR\\r\\nBoise, ID\\r\\nChicago, IL\\r\\nColorado Springs-Pueblo, CO\\r\\nDallas-Ft. Worth, TX\\r\\nDenver-Boulder, CO\\r\\nEl Centro-Yuma, CA\\r\\nEl Paso, TX\\r\\nEugene, OR\\r\\nFayetteville, AR\\r\\nFresno-Visalia, CA\\r\\nGreensboro, NC\\r\\nGreenville, SC\\r\\nHartford-New Haven, CT\\r\\nHouston-Galveston, TX\\r\\nIndianapolis, IN\\r\\nKnoxville, TN\\r\\nLakeland, FL\\r\\nLas Vegas, NV\\r\\nLillington, NC\\r\\nLittle Rock, AR\\r\\nLos Angeles, CA\\r\\nLubbock, TX\\r\\nMcAllen-Brownsville, TX\\r\\nMemphis, TN\\r\\nMiami-Ft.Lauderdale, FL\\r\\nMinneapolis, MN\\r\\nMonett, MO\\r\\nNashville, TN\\r\\nNew Orleans, LA\\r\\nNew York, NY/Paterson, NJ\\r\\nOdessa, TX\\r\\nOklahoma City, OK\\r\\nOrlando-Daytona Beach, FL\\r\\nOxnard, CA\\r\\nPalm Springs, CA\\r\\nPhiladelphia, PA\\r\\nPhoenix, AZ\\r\\nPonce, PR\\r\\nPortland, OR\\r\\nPrattville, AL\\r\\nRaleigh-Durham, NC\\r\\nReidsville, NC\\r\\nReno, NV\\r\\nRichmond, VA\\r\\nSacto-Stockton-Modesto, CA\\r\\nSaint George, UT\\r\\nSalinas, Monterey, Santa Cruz CA\\r\\nSalt Lake City, UT\\r\\nSan Diego, CA\\r\\nSan Francisco-San Jose, CA\\r\\nSta Barbara, CA\\r\\nSanta Maria, CA\\r\\nSanta Rosa, CA\\r\\nSeattle-Tacoma, WA\\r\\nTampa-St Petersburg, FL\\r\\nTucson, AZ\\r\\nTwin Falls, ID\\r\\nVineland, NJ\\r\\nWashington, DC\\r\\nWest Palm Beach, FL\\r\\nYakima, WA","input":"What radio station is the mexico soccer game on?"},{"output":"Chicago house","context":"Electronic dance music (also known as EDM, dance music,[3] club music, or simply dance) is a broad range of percussive electronic music genres made largely for nightclubs, raves, and festivals. EDM is generally produced for playback by disc jockeys (DJs) who create seamless selections of tracks, called a mix, by segueing from one recording to another.[4] EDM producers also perform their music live in a concert or festival setting in what is sometimes called a live PA. In Europe, EDM is more commonly called 'dance music' or simply 'dance'.[5]\\r\\nIn the late 1980s and early 1990s, following the emergence of raving, pirate radio, and an upsurge of interest in club culture, EDM acquired mainstream popularity in Europe. In the United States at that time acceptance of dance culture was not universal, and although both Electro and Chicago house music were hugely influential both in Europe and the USA, mainstream media outlets, and the record industry, remained hostile to EDM. There was also a perceived association between EDM and drug culture which led governments at state and city level to enact laws and policies intended to halt the spread of rave culture.[2]\\r\\nSubsequently, in the new millennium, EDM increased its popularity and mainstream profile in Europe and across the world, this time including the United States. By the early 2010s, the term \\"electronic dance music\\" and the initialism \\"EDM\\" was being pushed by the United States music industry and music press in an effort to rebrand American rave culture.[2] Despite the industry's attempt to create a specific EDM brand, the initialism remains in use as an umbrella term for multiple genres, including house, techno, trance, drum and bass, dubstep, and their respective subgenres.[6][7][8][9]\\r\\n\\r\\n\\r\\nEarly examples of electronic dance music include Jamaican dub music in the 1960s,[10] the disco music of Giorgio Moroder in the late 1970s, and the electronic music of Kraftwerk and Yellow Magic Orchestra in the late 1970s.[11]\\r\\nAuthor Michael Veal considers dub music, a Jamaican music stemming from roots reggae and sound system culture that flourished between 1968 and 1985, to be one of the important precursors to contemporary electronic dance music.[13] Dub productions were remixed reggae tracks that emphasized rhythm, fragmented lyrical and melodic elements, and reverberant textures.[14] The music was pioneered by studio engineers, such as Sylvan Morris, King Tubby, Errol Thompson, Lee \\"Scratch\\" Perry, and Scientist.[13] Their experiments included forms of tape-based composition that Veal considers comparable to musique concrte, with its emphasis on repetitive rhythmic structures being comparable to minimalism. Dub producers made improvised deconstructions of existing multi-track reggae mixes by using the studio mixing board as a performance instrument. They also foregrounded spatial effects such as reverb and delay by using auxiliary send routings creatively.[13]\\r\\nDespite the limited electronic equipment available to dub pioneers such as King Tubby and Lee \\"Scratch\\" Perry, their experiments in remix culture were musically cutting-edge.[15] Ambient dub was pioneered by King Tubby and other Jamaican sound artists, using DJ-inspired ambient electronics, complete with drop-outs, echo, equalization and psychedelic electronic effects. It featured layering techniques and incorporated elements of world music, deep bass lines and harmonic sounds.[16] Techniques such as a long echo delay were also used.[17]\\r\\nHip hop music has played a key role in the development of electronic dance music since the 1970s.[citation needed] Inspired by Jamaican sound system culture Jamaican-American DJ Kool Herc introduced large bass heavy speaker rigs to the Bronx.[18] His parties are credited with having kick-started the New York hip-hop movement in 1973.[18] A technique developed by DJ Kool Herc that became popular in hip hop culture was playing two copies of the same record on two turntables, in alternation, and at the point where a track featured a break. This technique was further used to manually loop a purely percussive break, leading to what was later called a break beat.[19] In the 1980s and 1990s hip-hop DJs used turntables as musical instruments in their own right and virtuosic use developed into a creative practice called turntablism.[20]\\r\\nIn 1974, George McCrae's early disco hit \\"Rock Your Baby\\" was one of the first records to use a drum machine,[21] an early Roland rhythm machine.[22] Its use of a drum machine was anticipated by Sly and the Family Stone's \\"Family Affair\\" (1971), which anticipated the sound of disco, with its rhythm echoed in \\"Rock Your Baby\\".[23] The use of drum machines in \\"Family Affair\\"[23] and Timmy Thomas' \\"Why Can't We Live Together\\" (1972),[24] which used a 1972 Roland rhythm machine,[22] influenced the adoption of drum machines by later disco artists.[23][24] Disco producer Biddu used synthesizers in several disco songs from 1976 to 1977, including \\"Bionic Boogie\\" from Rain Forest (1976),[25] \\"Soul Coaxing\\" (1977),[26] and Eastern Man and Futuristic Journey[27][28] (recorded from 1976 to 1977).[29]\\r\\nEuropean acts Silver Convention, Love and Kisses, Munich Machine, and American acts Donna Summer and the Village People were acts that defined the late 1970s Euro disco sound. In 1977, Giorgio Moroder and Pete Bellotte produced \\"I Feel Love\\" for Donna Summer. It became the first well-known disco hit to have a completely synthesised backing track. Other disco producers, most famously American producer Tom Moulton, grabbed ideas and techniques from dub music (which came with the increased Jamaican migration to New York City in the seventies) to provide alternatives to the four on the floor style that dominated.[30][31] During the early 1980s, the popularity of disco music sharply declined in the United States, abandoned by major US record labels and producers. Euro disco continued evolving within the broad mainstream pop music scene.[32]\\r\\nThe early 1980s also saw the emergence of an electronic South Asian disco scene in India and Pakistan, popularized by Biddu, Nazia Hassan, R.D. Burman, and Bappi Lahiri.[33][34][35] A notable experimental record to emerge from the Indian disco scene was Charanjit Singh's Synthesizing: Ten Ragas to a Disco Beat (1982), which anticipated the sound of acid house music, years before the genre arose in the Chicago house scene of the late 1980s.[34][35][36]\\r\\nDuring the post-disco era that followed the backlash against \\"disco\\" which began in the mid to late 1979, which in the United States lead to civil unrest and a riot in Chicago known as the Disco Demolition Night,[13] an underground movement of \\"stripped-down\\" disco inspired music featuring \\"radically different sounds\\"[14] started to emerge on the East Coast.[15][Note 1] This new scene was seen primarily in the New York metropolitan area and was initially led by the urban contemporary artists that were responding to the over-commercialisation and subsequent demise of disco culture. The sound that emerged originated from P-Funk[18] the electronic side of disco, dub music, and other genres. Much of the music produced during this time was, like disco, catering to a singles-driven market.[14] At this time creative control started shifting to independent record companies, less established producers, and club DJs.[14] Other dance styles that began to become popular during the post-disco era include dance-pop,[19][20] boogie,[14] electro, Italo disco, house,[19][21][22][23] and techno.[22][24][25][26][27]\\r\\nIn the early 1980s, electro emerged as a fusion of electro-pop, funk, and boogie. Also called electro-funk or electro-boogie, but later shortened to electro, cited pioneers include Ryuichi Sakamoto, Afrika Bambaataa,[38] Zapp,[39] D.Train,[40] and Sinnamon.[40] Early hip hop and rap combined with German and Japanese electropop influences such as Kraftwerk and Yellow Magic Orchestra inspired the birth of electro.[41] As the electronic sound developed, instruments such as the bass guitar and drums were replaced by synthesizers and most notably by iconic drum machines, particularly the Roland TR-808. Early uses of the TR-808 include several Yellow Magic Orchestra tracks in 1980-1981, the 1982 track \\"Planet Rock\\" by Afrikaa Bambaataa, and the 1982 song \\"Sexual Healing\\" by Marvin Gaye.[42] In 1982, producer Arthur Baker with Afrika Bambaataa released the seminal \\"Planet Rock\\", which was influenced by Yellow Magic Orchestra, used Kraftwerk samples, and had drum beats supplied by the TR-808. Planet Rock was followed later that year by another breakthrough electro record, \\"Nunk\\" by Warp 9. In 1983, Hashim created an electro-funk sound with \\"Al-Naafyish (The Soul)\\"[38] that influenced Herbie Hancock, resulting in his hit single \\"Rockit\\" the same year. The early 1980s were electro's mainstream peak.\\r\\nIn the early 1980s, Chicago radio jocks The Hot Mix 5 and club DJs Ron Hardy and Frankie Knuckles played various styles of dance music, including older disco records (mostly Philly disco and Salsoul[43] tracks), electro funk tracks by artists such as Afrika Bambaataa,[44] newer Italo disco, B-Boy hip hop music by Man Parrish, Jellybean Benitez, Arthur Baker, and John Robie, and electronic pop music by Kraftwerk and Yellow Magic Orchestra. Some made and played their own edits of their favorite songs on reel-to-reel tape, and sometimes mixed in effects, drum machines, and other rhythmic electronic instrumentation. The hypnotic electronic dance song \\"On and On\\", produced in 1984 by Chicago DJ Jesse Saunders and co-written by Vince Lawrence, had elements that became staples of the early house sound, such as the Roland TB-303 bass synthesizer and minimal vocals as well as a Roland (specifically TR-808) drum machine and Korg (specifically Poly-61) synthesizer.\\r\\n\\"On and On\\" is sometimes cited as the 'first house record',[45][46] though other examples from around that time, such as J.M. Silk's \\"Music is the Key\\" (1985), have also been cited.[47] House music quickly spread to other American cities such as Detroit, New York City, and Newarkall of which developed their own regional scenes. In the mid-to-late 1980s, house music became popular in Europe as well as major cities in South America, and Australia.[48] Chicago House experienced some commercial success in Europe with releases such as \\"House Nation\\" by House Master Boyz and the Rude Boy of House (1987). Following this, a number House inspired c releases such as \\"Pump Up The Volume\\" by MARRS (1987), \\"Theme from S'Express\\" by S'Express (1988), and \\"Doctorin' the House\\" by Coldcut (1988) entered the pop charts.\\r\\nIn the mid 80s house music thrived on the small Balearic Island of Ibiza, Spain. The Balearic sound was the spirit of the music emerging from the island at that time; the combination of old vinyl rock, pop, reggae, and disco records paired with an anything goes attitude made Ibiza a hub of drug-induced musical experimentation.[50] The scene was mainly centered around a club called Amnesia where its resident DJ, Alfredo Fiorito, pioneered Balearic house.[51] Amnesia became known across Europe and by the mid to late 1980s it was drawing people from all over the continent.[52]\\r\\nBy 1988, house music had become the most popular form of club music in Europe, with acid house developing as a notable trend in the UK and Germany in the same year.[53] In the UK an established warehouse party subculture, centered on the British African-Caribbean sound system scene fueled underground after-parties that featured dance music exclusively. Also in 1988, the Balearic party vibe associated with Ibiza's DJ Alfredo was transported to London, when Danny Rampling and Paul Oakenfold opened the clubs Shoom and Spectrum, respectively. Both places became synonymous with acid house, and it was during this period that MDMA gained prominence as a party drug. Other important UK clubs included Back to Basics in Leeds, Sheffield's Leadmill and Music Factory, and The Ha?ienda in Manchester, where Mike Pickering and Graeme Park's spot, Nude, was an important proving ground for American underground dance music.[Note 1][54] The success of house and acid house paved the way for Detroit Techno, a style that was initially supported by a handful of house music clubs in Chicago, New York, and Northern England, with Detroit clubs catching up later.[55] The term Techno first came into use after a release of a 10 Records/Virgin Records compilation titled Techno: The Dance Sound of Detroit in 1988.[56]\\r\\nOne of the first Detroit productions to receive wider attention was Derrick May's \\"Strings of Life\\" (1987), which, together with May's previous release, \\"Nude Photo\\" (1987), helped raise techno's profile in Europe, especially the UK and Germany, during the 1987-1988 house music boom (see Second Summer of Love).[57] It became May's best known track, which, according to Frankie Knuckles, \\"just exploded. It was like something you can't imagine, the kind of power and energy people got off that record when it was first heard. Mike Dunn says he has no idea how people can accept a record that doesn't have a bassline.\\"[58] According to British DJ Mark Moore, \\"Strings of Life\\" led London club goers to accept house: \\"because most people hated house music and it was all rare groove and hip hop...I'd play 'Strings of Life' at the Mudd Club and clear the floor\\".[59][Note 2] By the late 1980s interest in house, acid house and techno escalated in the club scene and MDMA-fueled club goers, who were faced with a 2?a.m. closing time in the UK, started to seek after-hours refuge at all-night warehouse parties. Within a year, in summer 1989, up to 10,000 people at a time were attending commercially organised underground parties called raves.[3]\\r\\nBy the early 1990s, a style of music developed within the rave scene that had an identity distinct from American house and techno. This music, much like hip-hop before it, combined sampled syncopated beats or break beats, other samples from a wide range of different musical genres and, occasionally, samples of music, dialogue and effects from films and television programmes. Relative to earlier styles of dance music such as house and techno, so called 'rave music' tended to emphasise bass sounds and use faster tempos, or beats per minute (BPM). This subgenre was known as \\"hardcore\\" rave, but from as early as 1991, some musical tracks made up of these high-tempo break beats, with heavy basslines and samples of older Jamaican music, were referred to as \\"jungle techno\\", a genre influenced by Jack Smooth and Basement Records, and later just \\"jungle\\", which became recognized as a separate musical genre popular at raves and on pirate radio in Britain. It is important to note when discussing the history of drum & bass that prior to jungle, rave music was getting faster and more experimental.\\r\\nBy 1994, jungle had begun to gain mainstream popularity and fans of the music (often referred to as junglists) became a more recognisable part of youth subculture. The genre further developed, incorporating and fusing elements from a wide range of existing musical genres, including the raggamuffin sound, dancehall, MC chants, dub basslines, and increasingly complex, heavily edited breakbeat percussion. Despite the affiliation with the ecstasy-fuelled rave scene, Jungle also inherited some associations with violence and criminal activity, both from the gang culture that had affected the UK's hip-hop scene and as a consequence of jungle's often aggressive or menacing sound and themes of violence (usually reflected in the choice of samples). However, this developed in tandem with the often positive reputation of the music as part of the wider rave scene and dance hall-based Jamaican music culture prevalent in London. By 1995, whether as a reaction to, or independently of this cultural schism, some jungle producers began to move away from the ragga-influenced style and create what would become collectively labelled, for convenience, as drum and bass.[61]\\r\\nInitially, electronic dance music was associated with European rave and club culture. It achieved limited popular exposure in America but by the mid-to-late 1990s efforts were underway to market a range of dance genres using the label \\"electronica.\\"[62] At the time, a wave of electronic music bands from the UK, including The Prodigy, The Chemical Brothers, Fatboy Slim and Underworld, had been prematurely associated with an \\"American electronica revolution\\".[63][64] But rather than finding mainstream success, many established EDM acts were relegated to the margins of the US industry.[63] In 1998 Madonna's Ray of Light brought the genre to the attention of popular music listeners.[65][66] In the late 1990s, despite US media interest in dance music re-branded as electronica, American house and techno producers continued to travel abroad to establish their careers as DJs and producers.[63]\\r\\nBy the mid 2000s Dutch producer Ti?sto was bringing worldwide popular attention to EDM after providing a soundtrack to the entry of athletes during the opening ceremony of the 2004 Summer Olympics  an event which The Guardian deemed as one of the 50 most important events in dance music.[67] By 2005, the prominence of dance music in North American popular culture had markedly increased. According to Spin, Daft Punk's performance at Coachella in 2006 was the \\"tipping point\\" for EDMit introduced the duo to a new generation of \\"rock kids\\".[63] As noted by Entertainment Weekly, Justin Timberlake's \\"SexyBack\\" helped introduce EDM sounds to top 40 radio, as it brought together variations of electronic dance music with the singers R&B sounds.[68][69] In 2009, French house musician David Guetta began to gain prominence in mainstream pop music thanks to several crossover hits on Top 40 charts such as \\"When Love Takes Over\\" with Kelly Rowland,[70] as well as his collaborations with US pop and hip hop acts such as Akon (\\"Sexy Bitch\\") and The Black Eyed Peas (\\"I Gotta Feeling\\").[71] YouTube and SoundCloud helped fuel interest in EDM, as well as electro house and dubstep. Skrillex popularized a harsher sound nicknamed \\"brostep\\", or dubstep.[2][72]\\r\\nThe increased popularity of EDM was also influenced by live events and gigs. Promoters and venues realized that DJs could generate larger profits than traditional musicians; Diplo explained that \\"a band plays [for] 45 minutes; DJs can play for four hours. Rock bandsthere's a few headliner dudes that can play 3,000-4,000-capacity venues, but DJs play the same venues, they turn the crowd over two times, people buy drinks all night long at higher pricesit's a win-win.\\"[63] Electronic music festivals notably the Electric Daisy Carnival (EDC) and Ultra Music Festival also grew in size, placing an increased emphasis on visual experiences, and the DJs themselves, who began to attain a celebrity status.[2][72] Other major acts that gained prominence including Avicii and Swedish House Mafia held concert tours at arenas rather than nightclubs; in December 2011, Swedish House Mafia became the first electronic music act to sell out New York City's Madison Square Garden.[72]\\r\\nIn 2011, Spin declared a \\"new rave generation\\" led by acts like David Guetta, Deadmau5, and Skrillex.[63] In January 2013, Billboard introduced a new EDM-focused Dance/Electronic Songs chart, tracking the top 50 electronic songs based on sales, radio airplay, club play, and online streaming.[73] According to Eventbrite, EDM fans are more likely to use social media to discover and share events or gigs. They also discovered that 78% of fans say they are more likely to attend an event if their peers do, compared to 43% of fans in general. EDM has many young and social fans.[74][74] By late 2011, Music Trades was describing electronic dance music as the fastest-growing genre in the world.[75] Elements of electronic music also became increasingly prominent in pop music.[63] Radio and television also contributed to dance music's mainstream acceptance.[76]\\r\\nCorporate consolidation in the EDM industry began in 2012especially in terms of live events. In June 2012, media executive Robert F.?X. Sillermanfounder of what is now Live Nationre-launched SFX Entertainment as an EDM conglomerate, and announced his plan to invest $1 billion to acquire EDM businesses. His acquisitions included regional promoters and festivals (including ID&T, which organises Tomorrowland), two nightclub operators in Miami, and Beatport, an online music store which focuses on electronic music.[77][78] Live Nation also acquired Cream Holdings and Hard Events, and announced a \\"creative partnership\\" with EDC organizers Insomniac Events in 2013 that would allow it to access its resources whilst remaining an independent company;[79] Live Nation CEO Michael Rapino described EDM as the \\"[new] rock 'n' roll\\".[62][80][81]\\r\\nUS radio conglomerate iHeartMedia, Inc. (formerly Clear Channel Media and Entertainment) also made efforts to align itself with EDM. In January 2014 It hired noted British DJ and BBC Radio?1 personality Pete Tong to produce programming for its \\"Evolution\\" dance radio brand,[82] and announced a partnership with SFX to co-produce live concerts and EDM-oriented original programming for its top 40 radio stations. iHeartMedia president John Sykes explained that he wanted his company's properties to be the \\"best destination [for EDM]\\".[83][84]\\r\\nMajor brands have also used the EDM phenomena as a means of targeting millennials[85][86] and EDM songs and artists have increasingly been featured in television commercials and programs.[87] Avicii's manager Ash Pournouri compared these practices to the commercialization of hip-hop in the early 2000s.[87] Heineken has a marketing relationship with the Ultra Music Festival, and has incorporated Dutch producers Armin van Buuren and Ti?sto into its ad campaigns. Anheuser-Busch has a similar relationship as beer sponsor of SFX Entertainment events.[87] In 2014, 7 Up launched \\"7x7Up\\"a multi-platform campaign centered around EDM that includes digital content, advertising featuring producers, and branded stages at both Ultra and Electric Daisy Carnival.[85][88][89] Wireless carrier T-Mobile US entered into an agreement with SFX to become the official wireless sponsor of its events, and partnered with Above & Beyond to sponsor its 2015 tour.[86]\\r\\nIn August 2015, SFX began to experience declines in its value,[90] and a failed bid by CEO Sillerman to take the company private. The company began looking into strategic alternatives that could have resulted in the sale of the company.[91][92] In October 2015, Forbes declared the possibility of an EDM \\"bubble\\", in the wake of the declines at SFX Entertainment, slowing growth in revenue, the increasing costs of organizing festivals and booking talent, as well as an oversaturation of festivals in the eastern and western United States. Insomniac CEO Pasquale Rotella felt that the industry would weather the financial uncertainty of the overall market by focusing on \\"innovation\\" and entering into new markets.[93] Despite forecasts that interest in popular EDM would wane, in 2015 it was estimated to be a S5.5bn industry in the US, up by 60% compared to 2012 estimates.[94]\\r\\nSFX emerged from bankruptcy in December 2016 as LiveStyle, under the leadership of Randy Phillips, a former executive of AEG Live.[95][96]\\r\\nIn May 2015, the International Music Summit's Business Report estimated that the global electronic music industry had reached nearly $6.9 billion in value; the count included music sales, events revenue (including nightclubs and festivals), the sale of DJ equipment and software, and other sources of revenue. The report also identified several emerging markets for electronic dance music, including East Asia, India, and South Africa, credited primarily to investment by domestic, as well as American and European interests. A number of major festivals also began expanding into Latin America.[97]\\r\\nChina is a market where EDM had initially made relatively few inroads; although promoters believed that the mostly instrumental music would remove a metaphorical language barrier, the growth of EDM in China was hampered by the lack of a prominent rave culture in the country as in other regions, as well as the popularity of domestic Chinese pop over foreign artists. Former Universal Music executive Eric Zho, inspired by the US growth, made the first significant investments in electronic music in China, including the organisation of Shanghai's inaugural Storm festival in 2013, the reaching of a title sponsorship deal for the festival with Anheuser-Busch's Budweiser brand, a local talent search, and organising collaborations between EDM producers and Chinese singers, such as Avicii and Wang Leehom's \\"Lose Myself\\". In the years following, a larger number of EDM events began to appear in China, and Storm itself was also preceded by a larger number of pre-parties in 2014 than its inaugural year. A new report released during the inaugural International Music Summit China in October 2015 revealed that the Chinese EDM industry was experiencing modest gains, citing the larger number of events (including new major festival brands such as Modern Sky and YinYang), a 6% increase in the sales of electronic music in the country, and the significant size of the overall market. Zho also believed that the country's \\"hands-on\\" political climate, as well as investments by China into cultural events, helped in \\"encouraging\\" the growth of EDM in the country.[98][99]\\r\\nFollowing the popularization of EDM in America a number of producers and DJs, including Carl Cox, Steve Lawler, and Markus Schulz, raised concerns that the perceived over-commercialisation of dance music had impacted the \\"art\\" of DJing. Cox saw the \\"press-play\\" approach taken by newer EDM DJs as unrepresentative of what he called a \\"DJ ethos\\".[72] Writing in Mixmag, DJ Tim Sheridan argued that \\"push-button DJs\\" who use auto-sync and play pre-recorded sets of \\"obvious hits\\" resulted in a situation overtaken by \\"the spectacle, money and the showbiz\\".[100]\\r\\nSome house producers openly admitted that \\"commercial\\" EDM needed further differentiation and creativity. Avicii, whose 2013 album True featured songs incorporating elements of bluegrass, such as lead single \\"Wake Me Up\\", stated that most EDM lacked \\"longevity\\".[101] Deadmau5 criticized the homogenization of popular EDM, and suggested that it \\"all sounds the same.\\" During the 2014 Ultra Music Festival, Deadmau5 made critical comments about up-and-coming EDM artist Martin Garrix and later played an edited version of Garrix's \\"Animals\\" remixed to the melody of \\"Old McDonald Had a Farm\\". Afterwards, Ti?sto criticized Deadmau5 on Twitter for \\"sarcastically\\" mixing Avicii's \\"Levels\\" with his own \\"Ghosts 'n' Stuff\\".[102][103][104][105]\\r\\nIn May 2014, the NBC comedy series Saturday Night Live parodied the stereotypes of EDM culture and push-button DJs in a Digital Short entitled \\"When Will the Bass Drop?\\". It featured a DJ who goes about performing everyday activitiesplaying a computer game, frying eggs, collecting moneywho then presses a giant \\"BASS\\" button, which explodes the heads of concertgoers.[106][107][108]\\r\\nThe term \\"electronic dance music\\" (EDM) was used in the United States as early as 1985, although the term \\"dance music\\" did not catch on as a blanket term [95]. Writing in The Guardian, journalist Simon Reynolds noted that the American music industry's adoption of the term EDM in the late 2000s was an attempt to re-brand US \\"rave culture\\" and differentiate it from the 1990s rave scene. In the UK, \\"dance music\\" or \\"dance\\" are more common terms for EDM.[4]What is widely perceived to be \\"club music\\" has changed over time; it now includes different genres and may not always encompass EDM. Similarly, \\"electronic dance music\\" can mean different things to different people. Both \\"club music\\" and \\"EDM\\" seem vague, but the terms are sometimes used to refer to distinct and unrelated genres (club music is defined by what is popular, whereas EDM is distinguished by musical attributes).[96] Until the late 1990s, when the larger US music industry created music charts for \\"dance\\" (Billboard magazine has maintained a \\"dance\\" chart since 1974 and it continues to this day.).[93] In July 1995, Nervous Records and Project X Magazine hosted the first awards ceremony, calling it the \\"Electronic Dance Music Awards\\".[Note 4]\\r\\nAccording to author Steve Taylor[109] Afrika Bambaataa's 1982 electro (short for \\"electro-funk\\") album Planet Rock serves as a \\"template for all interesting dance music since\\".[109] Various EDM genres have evolved over the last 30 years, for example; electro, house, techno hardcore, trance, drum and bass etc. Stylistic variation within an established EDM genre can lead to the emergence of what is called a subgenre. Hybridization, where elements of two or more genres are combined, can lead to the emergence of an entirely new genre of EDM.[110]\\r\\nIn a 2014 interview with Tony Andrew, the owner and founder of the Funktion-One sound systemconsidered a foremost model of audio technology and installed in famous venues including Berghain, Output, and TrouwAndrew explained the critical importance of bass to dance music:\\r\\nDance music would not be so successful without bass. If you think about it, we've really only had amplified bass for around 50 years. Big bass is only a couple of generations old. Before the invention of speakers that could project true bass frequencies, humans really only came across bass in hazardous situationsfor example, when thunder struck, or an earthquake shook, or from explosions caused by dynamite or gunpowder. That is probably why it is by far the most adrenaline-inducing frequency that we have. Bass gets humans excited basically. Below 90 or 100 Hz, bass becomes more of a physical thing. It vibrates specific organs. It vibrates our bones. It causes minor molecular rearrangement, and that is what makes it so potent as a force in dance music. The molecular vibration caused by bass is what gives dance music its power. It is what makes dance music so pleasurable to hear through a proper sound system.[111]\\r\\nAndrew warned that too much bassand too much sound in generalcan be harmful, stating that a \\"good sound engineer will understand that there is a window between enough sound to give excitement and so much that it is damaging\\".[111]\\r\\nIn the 1980s, electronic dance music was often played at illegal underground rave parties held in secret locations, for example, warehouses, abandoned aircraft hangars, fields and any other large, open areas. In the 1990s and 2000s, aspects of the underground rave culture of the 1980s and early 1990s began to evolve into legitimate, organized EDM concerts and festivals. Major festivals often feature a large number of acts representing various EDM genres spread across multiple stages. Festivals have placed a larger emphasis on visual spectacles as part of their overall experiences, including elaborate stage designs with underlying thematics, complex lighting systems, laser shows, and pyrotechnics. Rave fashion also evolved among attendees, which The Guardian described as progressing from the 1990s \\"kandi raver\\" to \\"[a] slick and sexified yet also kitschy-surreal image midway between Venice Beach and Cirque du Soleil, Willy Wonka and a gay pride parade.\\"[2][72][88] These events differed from underground raves by their organized nature, often taking place at major venues, and measures to ensure the health and safety of attendees.[112] MTV's Rawley Bornstein described electronic music as \\"the new rock and roll\\",[113] as has Lollapalooza organizer Perry Ferrell.[114]\\r\\nRay Waddell of Billboard noted that festival promoters have done an excellent job at branding.[113] Larger festivals have been shown to have positive economic impacts on their host cities[112] the 2014 Ultra Music Festival brought 165,000 attendeesand over $223 millionto the Miami/South Florida region's economy.[89] The inaugural edition of TomorrowWorlda US-based version of Belgium's Tomorrowland festival, brought $85.1 million to the Atlanta areaas much revenue as its hosting of the NCAA Final Four (the national championship of US college basketball) earlier in the year.[115] The increasing mainstream prominence of electronic music has also led major US multi-genre festivals, such as Lollapalooza and Coachella, to add more electronic and dance acts to their lineups, along with dedicated, EDM-oriented stages. Even with these accommodations, some major electronic acts, such as Deadmau5 and Calvin Harris have made appearances on main stages during the final nights of Lollapalooza and Coachella, respectivelyspots traditionally reserved for prominent non-electronic genres, such as rock and alternative.[116][117]\\r\\nRussell Smith of The Globe and Mail felt that the commercial festival industry was an antithesis to the original principles of the rave subculture, citing \\"the expensive tickets, the giant corporate sponsors, the crass bro cultureshirtless muscle boys who cruise the stadiums, tiny popular girls in bikinis who ride on their shoulders ÿ not to mention the sappy music itself.\\"[118] Drug-related incidents, as well as other complaints surrounding the behaviour of their attendees, have contributed to negative perceptions and opposition to electronic music events by local authorities;[118][119] After Ultra Music Festival 2014, where a crowd of gatecrashers trampled a security guard on its first day, Miami's city commissioners considered banning the festival from being held in the city, citing the trampling incident, lewd behavior, and complaints by downtown residents of being harassed by attendees. The commissioners voted to allow Ultra to continue being held in Miami due to its positive economic effects, under the condition that its organizers address security, drug usage and lewd behavior by attendees.[120][121][122]\\r\\nDance music has a long association with recreational drug use,[123] particularly with a wide range of drugs that have been categorized under the name \\"club drugs\\". Russell Smith noted that the association of drugs and music subcultures was by no means exclusive to electronic music, citing previous examples of music genres that were associated with certain drugs, such as psychedelic rock and LSD, disco music and cocaine, and punk music and heroin.[118] Similarly, the 1980s grunge scene in Seattle was associated with heroin use.\\r\\nMethylenedioxymethamphetamine (MDMA), also known as ecstasy, \\"E\\", or \\"Molly\\", is often considered the drug of choice within the rave culture and is also used at clubs, festivals and house parties.[124] In the rave environment, the sensory effects from the music and lighting are often highly synergistic with the drug. The psychedelic amphetamine quality of MDMA offers multiple reasons for its appeals to users in the \\"rave\\" setting. Some users enjoy the feeling of mass communion from the inhibition-reducing effects of the drug, while others use it as party fuel because of the drug's stimulatory effects.[125]\\r\\nMDMA is occasionally known for being taken in conjunction with psychedelic drugs. The more common combinations include MDMA combined with LSD, MDMA with psilocybin mushrooms, and MDMA with the disassociative drug ketamine. Many users use mentholated products while taking MDMA for its cooling sensation while experiencing the drug's effects. Examples include menthol cigarettes, Vicks VapoRub, NyQuil,[126] and lozenges.\\r\\nThe incidence of nonmedical ketamine has increased in the context of raves and other parties.[127] However, its emergence as a club drug differs from other club drugs (e.g. MDMA) due to its anesthetic properties (e.g., slurred speech, immobilization) at higher doses;[128] in addition, there are reports of ketamine being sold as \\"ecstasy\\".[129] The use of ketamine as part of a \\"postclubbing experience\\" has also been documented.[130] Ketamine's rise in the dance culture was rapid in Hong Kong by the end of the 1990s.[128] Before becoming a federally controlled substance in the United States in 1999, ketamine was available as diverted pharmaceutical preparations and as a pure powder sold in bulk quantities from domestic chemical supply companies.[131] Much of the current ketamine diverted for nonmedical use originates in China and India.[131]\\r\\nA number of deaths attributed to apparent drug use have occurred at major electronic music concerts and festivals. The Los Angeles Memorial Coliseum blacklisted Insomniac Events after an underaged attendee died from \\"complications of ischemic encephalopathy due to methylenedioxymethamphetamine intoxication\\" during Electric Daisy Carnival 2010; as a result, the event was re-located to Las Vegas the following year.[132][112][133][134][135] Drug-related deaths during Electric Zoo 2013 in New York City, United States, and Future Music Festival Asia 2014 in Kuala Lumpur, Malaysia, prompted the final day of both events to be cancelled,[134][136] while Life in Color cancelled a planned event in Malaysia out of concern for the incident at Future Music Festival Asia and other drug-related deaths that occurred at the A State of Trance 650 concerts in Jakarta, Indonesia.[137][138][139]\\r\\nIn September 2016, the city of Buenos Aires, Argentina banned all electronic music events, pending future legislation, after five drug-related deaths and four injuries at a Time Warp Festival event in the city in April 2016. The ban forced electronic band Kraftwerk to cancel a planned concert in the city, despite arguing that there were dissimilarities between a festival and their concerts.[140][141]","input":"What style of electronic dance music developed in chicago?"},{"output":"from 1955 to 1975","context":"\\r\\nThe role of the United States in the Vietnam War began after World War II and escalated into full commitment during the Vietnam War from 1955 to 1975. The U.S. involvement in South Vietnam stemmed from 20 long years of political and economic action. These had the common incentive of ending the growing communist domination in Vietnam. At the time, French forces, allies of the U.S., were backed by America  President Harry S. Truman provided progressively increasing amounts of financial and military assistance to French forces fighting in Vietnam. From the spring of 1950, their involvement increased from just assisting French troops to providing direct military assistance to the associated states (Vietnam, Laos, Cambodia). Eventually, U.S. missions were carried out at a more constant rate by sending out increasing number of military assistance from the United States. Their main intent was to restrict the Communist domination that was present in the government of Vietnam as it would soon lead to a chain of neighbouring countries adopting the same. This would have resulted in a change in balance of power throughout Southeast Asia. The U.S. foreign policy establishment saw national security interests being disturbed due to the rise of this communist expansion and strived to take any measure to end it. Their actions came to be questioned by other segments of government and society, however, including the US congress.[1].  \\r\\n\\r\\nEstimates of the number of Vietnamese soldiers and civilians killed vary from 966,000[2] to 3,812,000.[3] The conflict also resulted in 58,318 US soldiers dead.[4]\\r\\n\\r\\nFeb 1965 - Operation Rolling Thunder begins\\r\\n\\r\\n\\r\\n\\r\\nIn 1961 the new administration of President John F. Kennedy remained essentially committed to the bi-partisan, anti-communist foreign policies inherited from the administrations of Presidents Truman and Eisenhower. During 1961, his first year in office, Kennedy found himself faced with a three-part crisis: The failure of the Bay of Pigs invasion in Cuba; the construction of the Berlin Wall by the Soviets; and a negotiated settlement between the pro-Western government of Laos and the Pathet Lao communist movement. Fearing that another failure on the part of the U.S. to stop communist expansion would fatally damage U.S. credibility with its allies, Kennedy realized, \\"Now we have a problem in making our power credible... and Vietnam looks like the place.\\"[15]\\r\\nThe commitment to defend South Vietnam was reaffirmed by Kennedy on May 11 in National Security Action Memorandum 52, which became known as \\"The Presidential Program for Vietnam\\". Its opening statement reads:\\r\\n\\r\\nU.S. objectives and concept of operations [are] to prevent communist domination of South Vietnam; to create in that country a viable and increasingly democratic society, and to initiate, on an accelerated basis, a series of mutually supporting actions of a military, political, economic, psychological, and covert character designed to achieve this objective.[16]\\r\\nKennedy was intrigued by the idea of utilizing United States Army Special Forces for counterinsurgency conflicts in Third World countries threatened by the new \\"wars of national liberation\\". Originally intended for use behind front lines after a conventional invasion of Europe, Kennedy believed that the guerrilla tactics employed by Special Forces would be effective in the \\"brush fire\\" war in South Vietnam. He saw British success in using such forces during the Malayan Emergency as a strategic template. Thus in May 1961 Kennedy sent detachments of Green Berets to South Vietnam.\\r\\n\\r\\nThe Di?m regime had been initially able to cope with the insurgency of the National Front for the Liberation of South Vietnam (NLF, or derogatively, Viet Cong) in South Vietnam with the aid of U.S. matriel and advisers, and, by 1962, seemed to be gaining the upper hand. Senior U.S. military leaders received positive reports from the U.S. commander, General Paul D. Harkins of the Military Assistance Command, Vietnam, or MACV. By the following year, however, cracks began to appear in the fa?ade of success. In January a possible victory that was turned into a stunning defeat for government forces at the Battle of Ap Bac caused consternation among both the military advisers in the field and among politicians in Washington, D.C. JFK also indicated to Walter Cronkite that the war may be unwinnable, and that it was ultimately a Vietnamese war, not an American war.[17]\\r\\n\\r\\nDi?m was already growing unpopular with many of his countrymen because of his administration's nepotism, corruption, and its apparent bias in favor of the Catholic minorityof which Di?m was a partat the expense of the Buddhist majority. This contributed to the impression of Di?m's rule as an extension of the French Colonial regime. Promised land reforms were not instituted, and Di?m's strategic hamlet program for village self-defense (and government control) was a disaster. The Kennedy administration grew increasingly frustrated with Di?m. In 1963, a crackdown by Di?m's forces was launched against Buddhist monks protesting discriminatory practices and demanding a political voice. Di?m's repression of the protests sparked the so-called Buddhist Revolt, during which several monks committed self-immolation, which was covered in the world press. The communists took full advantage of the situation and fueled anti-Di?m sentiment to create further instability.\\r\\n\\r\\nOn July 27, 1964, 5,000 additional U.S. military advisers were ordered to the Republic of Vietnam (RVN or South Vietnam), bringing the total American troop level to 21,000. Shortly thereafter an incident occurred off the coast of the Democratic Republic of Vietnam (North Vietnam) that was destined to escalate the conflict to new levels and lead to the full scale Americanization of the war.\\r\\n\\r\\nOn the evening of August 2, 1964, the destroyer USS?Maddox was conducting an electronic intelligence collection mission in international waters (even as claimed by North Vietnam) in the Gulf of Tonkin when it was attacked by three P-4 torpedo boats of the North Vietnamese Navy.[18] Reports later reached the Johnson administration saying that the Maddox was under attack. Two nights later, after being joined by the destroyer C. Turner Joy, the Maddox again reported that both vessels were under attack.[citation needed] Regardless, President Johnson addressed Congress asking for more political power to utilize American military forces in South Vietnam, using the attack on the Maddox as cause to get what he wanted.\\r\\n\\r\\nThere was rampant confusion in Washington, but the incident was seen by the administration as the perfect opportunity to present Congress with \\"a pre-dated declaration of war\\" in order to strengthen weakening morale in South Vietnam through reprisal attacks by the U.S. on the North.[19] Even before confirmation of the phantom attack had been received in Washington, President Johnson had decided that an attack could not go unanswered.\\r\\n\\r\\nJust before midnight he appeared on television and announced that retaliatory air strikes were underway against North Vietnamese naval and port facilities. Neither Congress nor the American people learned the whole story about the events in the Gulf of Tonkin until the publication of the Pentagon Papers in 1969. It was on the basis of the administration's assertions that the attacks were \\"unprovoked aggression\\" on the part of North Vietnam, that the United States Congress approved the Southeast Asia Resolution (also known as the Gulf of Tonkin Resolution) on August 7. The law gave the President broad powers to conduct military operations without an actual declaration of war. The resolution passed unanimously in the House of Representatives and was opposed in the Senate by only two members.\\r\\n\\r\\nNational Security Council members, including United States Secretary of Defense Robert McNamara, Secretary of State Dean Rusk, and General Maxwell Taylor, agreed on November 28 to recommend that Johnson adopt a plan for a two-stage escalation of the bombing of North Vietnam.\\r\\n\\r\\nIn February 1965, a U.S. air base at Pleiku, in the Central Highlands of South Vietnam, was attacked twice by the NLF, resulting in the deaths of over a dozen U.S. personnel. These guerrilla attacks prompted the administration to order retaliatory air strikes against North Vietnam.\\r\\n\\r\\nOperation Rolling Thunder was the code name given to a sustained strategic bombing campaign targeted against the North by aircraft of the U.S. Air Force and Navy that was inaugurated on March 2, 1965. Its original purpose was to bolster the morale of the South Vietnamese and to serve as a signaling device to Hanoi. U.S. airpower would act as a method of \\"strategic persuasion\\", deterring the North Vietnamese politically by the fear of continued or increased bombardment. Rolling Thunder gradually escalated in intensity, with aircraft striking only carefully selected targets. When that did not work, its goals were altered to destroying North Vietnam's will to fight by destroying the nation's industrial base, transportation network, and its (continually increasing) air defenses. After more than a million sorties were flown and three-quarters of a million tons of bombs were dropped, Rolling Thunder was ended on November 11, 1968.[20]\\r\\n\\r\\nOther aerial campaigns (Operation Barrel Roll, Operation Steel Tiger, Operation Tiger Hound, and Operation Commando Hunt) were directed to counter the flow of men and material down the PAVN logistical system that flowed from North Vietnam through southeastern Laos, and into South Vietnam known as the Ho Chi Minh Trail.\\r\\n\\r\\nPresident Johnson had already appointed General William C. Westmoreland to succeed General Harkins as Commander of MACV in June 1964. Under Westmoreland, the expansion of American troop strength in South Vietnam took place. American forces rose from 16,000 during 1964 to more than 553,000 by 1969. With the U.S. decision to escalate its involvement it had created the Many Flags program to legitimise intervention and ANZUS Pact allies Australia and New Zealand agreed to contribute troops and matriel to the conflict. They were joined by the Republic of Korea, Thailand, and [[the Philippines|the Philippines[citation needed]]]. The U.S. paid for (through aid dollars) and logistically supplied all of the allied forces.\\r\\n\\r\\nMeanwhile, political affairs in Saigon were finally settling down  at least as far as the Americans were concerned. On February 14 the most recent military junta, the National Leadership Committee, installed Air Vice-Marshal Nguy?n Cao K? as prime minister. In 1966, the junta selected General Nguy?n V?n Thi?u to run for president with Ky on the ballot as the vice-presidential candidate in the 1967 election. Thieu and Ky were elected and remained in office for the duration of the war. In the presidential election of 1971, Thieu ran for the presidency unopposed. With the installation of the Thieu and Ky government (the Second Republic), the U.S. had a pliable, stable, and semi-legitimate government in Saigon with which to deal[citation needed].\\r\\n\\r\\nWith the advent of Rolling Thunder, American airbases and facilities needed to be constructed and manned for the aerial effort[citation needed]. On March 8, 1965, 3,500 United States Marines came ashore at Da Nang as the first wave of U.S. combat troops into South Vietnam, adding to the 25,000 U.S. military advisers already in place. The US Government deployment of ground forces to Da Nang had not been consulted with the South Vietnamese government.[21] Instead the initial deployment and gradual build-up was a unilateral decision by the US government[22]. On May 5 the U.S. 173rd Airborne Brigade became the first U.S. Army ground unit committed to the conflict in South Vietnam. On August 18, Operation Starlite began as the first major U.S. ground operation, destroying an NLF stronghold in [[Qu?ng Ng?i Province|Qu?ng Ng?i Province[citation needed]]]. \\r\\n\\r\\nThe North Vietnamese had already sent units of their regular army into southern Vietnam beginning in late 1964. Some officials in Hanoi had favored an immediate invasion of the South, and a plan was developed to use PAVN units to split southern Vietnam in half through the Central Highlands[citation needed]. The two imported adversaries first faced one another during Operation Silver Bayonet, better known as the Battle of the Ia Drang. During the savage fighting that took place, both sides learned important lessons. The North Vietnamese,  began to adapt to the overwhelming American superiority in air mobility, supporting arms, and close air support by moving in as close as possible during confrontations, thereby negating the effects of the above[citation needed]. \\r\\n\\r\\nOn November 27, 1965, the Pentagon declared that if the major operations needed to neutralize North Vietnamese and NLF forces were to succeed, U.S. troop levels in South Vietnam would have to be increased from 120,000 to 400,000. In a series of meetings between Westmoreland and the President held in Honolulu in February 1966, Westmoreland claimed that the U.S. presence had succeeded in preventing the immediate defeat of the South Vietnamese government but that more troops would be necessary if systematic offensive operations were to be conducted[citation needed]. The issue then became in what manner American forces would be used[citation needed].\\r\\n\\r\\nThe nature of the American military's strategic and tactical decisions made during this period coloured the conflict for the duration of the American commitment. The logistical system in Laos and Cambodia should be cut by ground forces, isolating the southern battlefield[citation needed]. However, political considerations limited U.S. military actions, mainly because of the memory of Chinese reactions during the [[Korean War|Korean War[citation needed]]]. Ever present in the minds of diplomats, military officers, and politicians was the possibility of a spiraling escalation of the conflict into a superpower confrontation and the possibility of a nuclear exchange. Therefore, there would be no invasion of North Vietnam, the \\"neutrality\\" of Laos and Cambodia would be respected, and Rolling Thunder would not resemble the bombing of Germany and Japan during the Second World War.\\r\\n\\r\\nThese limitations were not foisted upon the military as an afterthought. Before the first U.S. soldiers came ashore at Da Nang, the Pentagon was cognizant of all of the parameters that would be imposed by their civilian leaders, yet they still agreed that the mission could be accomplished within them. Westmoreland believed that he had found a strategy that would either defeat North Vietnam or force it into serious negotiations. Attrition was to be the key. The general held that larger offensive operations would grind down the communists and eventually lead to a \\"crossover point\\" in PAVN/NLF casualties after which a decisive (or at least political) victory would be possible.\\r\\n\\r\\nIt is widely held that the average U.S. serviceman was nineteen years old, as evidenced by the casual reference in a pop song (\\"19\\" by Paul Hardcastle); the figure is cited by Lt. Col. Dave Grossman ret. of the Killology Research Group in his 1995 book On Killing: The Psychological Cost of Learning to Kill in War and Society (p.?265). However, it is disputed by the[23] Vietnam Helicopter Flight Crew Network Website, which claims the average age of MOS 11B personnel was 22. This compares with 26 years of age for those who participated in World War II. Soldiers served a one-year tour of duty. The average age of the U.S. military men who died in Vietnam was 22.8 years old.[24]\\r\\n\\r\\nThe one-year tour of duty deprived units of experienced leadership. As one observer put it, \\"we were not in Vietnam for 10 years, but for one year 10 times.\\"[25] As a result, training programs were shortened. Some NCOs were referred to as \\"Shake 'N' Bake\\" to highlight their accelerated training. Unlike soldiers in World War II and Korea, there were no secure rear areas in which to get rest and relaxation.[citation needed] One unidentified soldier said to United Press International that there was nothing to do in Vietnam and therefore many of the men smoked marijuana. He said, \\"One of the biggest reasons that a lot of GIs do get high over here is there is nothing to do. This place is really a drag; it's a bore over here. Like right now sitting around here, we are getting loaded. Whereas, it doesn't really get you messed up; that's I guess the main reason why we smoke it.\\"[26]\\r\\n\\r\\nAmerican forces would conduct operations against PAVN forces, pushing them further back into the countryside away from the heavily populated coastal lowlands. In the backcountry the U.S. could fully utilize its superiority in firepower and mobility to bleed the enemy in set-piece battles. The cleaning-out of the NLF and the pacification of the villages would be the responsibility of the South Vietnamese military. The adoption of this strategy, however, brought Westmoreland into direct conflict with his Marine Corps commander, General Lewis W. Walt, who had already recognized the security of the villages as the key to success. Walt had immediately commenced pacification efforts in his area of responsibility, but Westmoreland was unhappy, believing that the Marines were being underutilized and fighting the wrong enemy. In the end, MACV won out and Westmoreland's search and destroy concept, predicated on the attrition of enemy forces, won the day.\\r\\n\\r\\nBoth sides chose similar strategies. PAVN, which had been operating a more conventional, large-unit war, switched back to small-unit operations in the face of U.S. military capabilities. The struggle moved to the villages, where the \\"hearts and minds\\" of the South Vietnamese peasants, whose cooperation was absolutely necessary to military success, would be won or lost. The U.S. had given responsibility for this struggle to the Army of the Republic of Vietnam (ARVN), whose troops and commanders were notoriously unfit for the task.\\r\\n\\r\\nFor the American soldier, whose doctrine was one of absolute commitment to total victory, this strategy led to a frustrating small-unit war. Most of the combat was conducted by units smaller than battalion-size (the majority at the platoon level). Since the goal of the operations was to kill the enemy, terrain was not taken and held as in previous wars. Savage fighting and the retreat of the communists was immediately followed by the abandonment of the terrain just seized. Combined with this was the anger and frustration engendered among American troops by the effective tactics of the NLF, who conducted a war of sniping, booby traps, mines, and terror against the Americans.\\r\\n\\r\\nAs a result of the conference held in Honolulu, President Johnson authorized an increase in troop strength to 429,000 by August 1966. The large increase in troops enabled MACV to carry out numerous operations that grew in size and complexity during the next two years. For U.S. troops participating in these operations (Operation Masher/White Wing, Operation Attleboro, Operation Cedar Falls, Operation Junction City and dozens of others) the war boiled down to hard marching through some of the most difficult terrain on the planet and weather conditions that were alternately hot and dry, or cold and wet. It was the PAVN/NLF that actually controlled the pace of the war, fighting only when their commanders believed that they had the upper hand and then disappearing when the Americans and/or ARVN brought their superiority in numbers and firepower to bear. North Vietnam, utilizing the Ho Chi Minh and Sihanouk Trails, matched the U.S. at every point of the escalation, funneling manpower and supplies to the southern battlefields.\\r\\n\\r\\nDuring the Vietnam War, the use of the helicopter, known as \\"Air Mobile\\", was an essential tool for conducting the war. In fact, the whole conduct and strategy of the war depended on it. Vietnam was the first time the helicopter was used on a major scale, and in such important roles. Search and destroy missions, for example, would have been nearly impossible without it. Helicopters allowed American commanders to move large numbers of troops to virtually anywhere, regardless of the terrain or roads. Troops could also be easily resupplied in remote areas. The helicopter also provided another new and vital capability: medical evacuation. It could fly wounded soldiers to aid stations very quickly, usually within the critical first hour. This gave wounded soldiers a higher chance of survival in Vietnam than in any previous war. The helicopter was also adapted for many other roles in Vietnam, including ground attack, reconnaissance, and electronic warfare. Without the helicopter, the war would have been fought very differently.[27]\\r\\n\\r\\nBy mid-1967, Westmoreland said that it was conceivable that U.S. forces could be phased out of the war within two years, turning over progressively more of the fighting to the ARVN.[28] That fall, however, savage fighting broke out in the northern provinces. Beginning below the DMZ at Con Tien and then spreading west to the Laotian border near Dak To, large PAVN forces began to stand their ground and fight. This willingness of the communists to remain fixed in place inspired MACV to send reinforcements from other sectors of South Vietnam. The Border Battles had begun.\\r\\n\\r\\nMost of the PAVN/NLF operational capability was possible only because of the unhindered movement of men along the Ho Chi Minh Trail. To threaten this flow of supplies, the Marine Corps established a combat base on the South Vietnamese side of the Laotian frontier, near the village of Khe Sanh. The U.S. used the base as a border surveillance position overlooking Route 9, the only east-west road that crossed the border in the province. Westmoreland also hoped to use the base as a jump-off point for any future incursion against the Trail system in Laos. During the spring of 1967, a series of small-unit actions near Khe Sanh prompted MACV to increase its forces. These small unit actions and increasing intelligence information indicated that the PAVN was building up significant forces just across the border.\\r\\n\\r\\nIndeed, PAVN was doing just that. Two regular divisions (and later elements of a third) were moving toward Khe Sanh, eventually surrounding the base and cutting off its only road access. Westmoreland, contrary to the advice of his Marine commanders, reinforced the outpost. As far as he was concerned, if the communists were willing to mass their forces for destruction by American air power, so much the better. He described the ideal outcome as a \\"Dien Bien Phu in reverse\\". MACV then launched the largest concentrated aerial bombardment effort of the conflict (Operation Niagara) to defend Khe Sanh. Another massive aerial effort was undertaken to keep the beleaguered Marines supplied. There were many comparisons (by the media, Americans military and political officials, and the North Vietnamese) to the possibility of PAVN staging a repeat of its victory at Dien Bien Phu, but the differences outweighed the similarities in any comparison.\\r\\n\\r\\nMACV used this opportunity to field its latest technology against the North Vietnamese. A sensor-driven, anti-infiltration system known as Operation Igloo White was in the process of being field tested in Laos as the siege of Khe Sanh began. Westmoreland ordered that it be employed to detect PAVN troop movements near the Marine base and the system worked well. By March, the long-awaited ground assault against the base had failed to materialize and communist forces began to melt back toward Laos. MACV (and future historians) were left with only questions. What was the goal of the PAVN? Was the siege a real attempt to stage another Dien Bien Phu? Or had the battles near the border (which eventually drew in half of MACV's maneuver battalions) been a diversion, meant to pull forces away from the cities, where another PAVN offensive would soon commence?\\r\\n\\r\\nGeneral Westmoreland's public reassurances that \\"the light at the end of the tunnel\\" was near were countered when, on January 30, 1968, PAVN and NLF forces broke the truce that accompanied the T?t holiday and mounted their largest offensive thus far, in hopes of sparking a general uprising among the South Vietnamese. These forces, ranging in size from small groups to entire regiments, attacked nearly every city and major military installation in South Vietnam. The Americans and South Vietnamese, initially surprised by the scope and scale of the offensive, quickly responded and inflicted severe casualties on their enemies. The NLF was essentially eliminated as a fighting force and the places of the dead within its ranks were increasingly filled by North Vietnamese.\\r\\n\\r\\nThe PAVN/NLF attacks were speedily and bloodily repulsed in virtually all areas except Saigon, where the fighting lasted for three days, and in the old imperial capital of Hu?, where it continued for a month. During the occupation of the historic city, 2,800 South Vietnamese were murdered by the NLF in the single worst massacre of the conflict. The hoped-for uprising never took place; indeed, the offensive drove some previously apathetic South Vietnamese to fight for the government. Another surprise for the communists was that the ARVN did not collapse under the onslaught, instead turning in a performance that pleased even its American patrons.\\r\\n\\r\\nAfter the Tet Offensive, influential news magazines and newspapers, including the Wall Street Journal, Time and The New York Times, increasingly began to characterize the war as a stalemate. What shocked and dismayed the American public was the realization that either it had been lied to or that the American military command had been dangerously overoptimistic in its appraisal of the situation in Vietnam. The public could not understand how such an attack was possible after being told for several years that victory was just around the corner. The Tet Offensive came to embody the growing credibility gap at the heart of U.S. government statements. These realizations and changing attitudes forced the American public (and politicians) to face hard realities and to reexamine their position in Southeast Asia. Moreover, the U.S. media coverage made it even more clear that an overall victory in Vietnam was not imminent. It also massively weakened the domestic support for the Johnson administration at the time[29]. The days of an open-ended commitment to the conflict were over.\\r\\n\\r\\nThe psychological impact of the Tet Offensive effectively ended the political career of Lyndon Johnson. On March 11, Senator Eugene McCarthy won 42 percent of the vote in the Democratic New Hampshire primary. Although Johnson was not on the ballot, commentators viewed this as a defeat for the President. Shortly thereafter, Senator Robert Kennedy announced his intention to seek the Democratic nomination for the 1968 presidential election. On March 31, in a speech that took America and the world by surprise, Johnson announced that \\"I shall not seek, and I will not accept the nomination of my party for another term as your President\\" and pledged himself to devoting the rest of his term in office to the search for peace in Vietnam.[30] Johnson announced that he was limiting bombing of North Vietnam to just north of the Demilitarized Zone and that U.S. representatives were prepared to meet with North Vietnamese counterparts in any suitable place \\"to discuss the means to bring this ugly war to an end\\". A few days later, much to Johnson's surprise, North Vietnam agreed to contacts between the two sides. On May 13, what became known as the Paris peace talks began.[31]\\r\\n\\r\\nOn March 16, 1968, three companies of Task Force Barker, part of the Americal Division, took part in a search and destroy operation near the village of My Lai, in Qu?ng Nam Province. Although not all of the members of the company participated, a significant number of them, led by Calley, did. He personally ordered the executions of hundreds of villagers in large groups. The killings ended only when an American helicopter crew, headed by Warrant Officer Hugh Thompson, Jr., discovered Calley's unit in the act and threatened to attack them with his aircraft's weapons unless they stopped. One of the soldiers on the scene was Ron Haeberle, a photographer for the newspaper Stars and Stripes, who took unobtrusive official black-and-white photos of the operation through the lens of his military-issued camera and color shots of the massacre with his personal camera. Although the operation appeared suspicious to Calley's superiors, it was forgotten.\\r\\n\\r\\nIn 1969, investigative journalist Seymour Hersh exposed the My Lai massacre in print, and the Haeberle photos were released to the world media. The Pentagon launched an investigation headed by General William R. Peers to look into the allegations. After a flurry of activity, the Peers Commission issued its report. It declared that \\"an atmosphere of atrocity\\" surrounded the event, concluding that a massacre had taken place and the crime had been covered up by the commander of the Americal Division and his executive officer. Perhaps 400 Vietnamese civilians, mostly old men, women, and children had been killed by Charlie company. Several men were charged in the killings, but only Calley was convicted. He was given a life sentence by a court-martial in 1970, but after numerous appeals he was finally set free; he had served just over three years of house arrest.\\r\\n\\r\\nAlthough My Lai generated a lot of civilian recriminations and bad publicity for the military, it was not the only massacre. The Vietnam War Crimes Working Group Files made public in 1994 by the \\"Freedom of Information Act\\" reveal seven, albeit much smaller, massacres previously unacknowledged by the Pentagon, in which at least 137 civilians had died.[1]\\r\\nCover-ups may have occurred in other cases, as detailed in the Pulitzer Prize-winning series of articles concerning the Tiger Force of the 101st Airborne Division by the Toledo Blade in 2003.\\r\\n\\r\\nRichard Nixon had campaigned in the 1968 presidential election under the slogan that he would end the war in Vietnam and bring \\"peace with honor\\". However, there was no plan to do this, and the American commitment continued for another five years. The goal of the American military effort was to buy time, gradually building up the strength of the South Vietnamese armed forces, and re-equipping it with modern weapons so that they could defend their nation on their own. This policy became the cornerstone of the so-called Nixon Doctrine. As applied to Vietnam, it was labeled Vietnamization.\\r\\n\\r\\nNixon's papers show that in 1968, as a presidential candidate, he ordered Anna Chennault, his liaison to the South Vietnam government, to persuade them to refuse a cease-fire being brokered by President Lyndon Johnson. This action violated the Logan Act, banning private citizens from intruding into official government negotiations with a foreign nation, and has been said to constitute treason.[32]\\r\\n\\r\\nSoon after Tet, General Westmoreland was promoted to Army Chief of Staff and he was replaced by his deputy, General Creighton W. Abrams. Because of the change in American strategy posed by Vietnamization, Abrams pursued a very different approach. The U.S. was gradually withdrawing from the conflict, and Abrams favored smaller-scale operations aimed at PAVN/NLF logistics, more openness with the media, less indiscriminate use of American firepower, elimination of the body count as the key indicator of battlefield success, and more meaningful cooperation with South Vietnamese forces.\\r\\n\\r\\nVietnamization of the war, however, created a dilemma for U.S. forces: the strategy required that U.S. troops fight long enough for the ARVN to improve enough to hold its own against Communist forces. Morale in the U.S. ranks rapidly declined during 1969ÿ1972, as evidenced by declining discipline, worsening drug use among soldiers, and increased \\"fraggings\\" of U.S. officers by disgruntled troops.\\r\\n\\r\\nOne of Nixon's main foreign policy goals had been the achievement of a breakthrough in U.S. relations with the People's Republic of China and the Soviet Union. An avowed anti-communist since early in his political career, Nixon could make diplomatic overtures to the communists without being accused of being \\"soft on communism\\". The result of his overtures was an era of dtente that led to nuclear arms reductions by the U.S. and Soviet Union and the beginning of a dialogue with China. In this context, Nixon viewed Vietnam as simply another limited conflict forming part of the larger tapestry of superpower relations; however, he was still determined to preserve South Vietnam until such time as he could not be blamed for what he saw as its inevitable collapse (or a \\"decent interval\\", as it was known). To this end he and National Security Advisor Henry Kissinger employed Chinese and Soviet foreign policy gambits to successfully defuse some of the anti-war opposition at home and secured movement at the negotiations that had begun in Paris.\\r\\n\\r\\nChina and the Soviet Union had been the principal backers of North Vietnam's effort through large-scale military and financial aid. The two communist superpowers had competed with one another to prove their \\"fraternal socialist links\\" with the regime in Hanoi. The North Vietnamese had become adept at playing the two nations off against one another. Even with Nixon's rapprochement, their support of North Vietnam increased significantly in the years leading up to the U.S. departure in 1973, enabling the North Vietnamese to mount full-scale conventional offensives against the South, complete with tanks, heavy artillery, and the most modern surface-to-air missiles.\\r\\n\\r\\nThe credibility of the U.S. government again suffered in 1971 when The New York Times, The Washington Post and other newspapers serially published The Pentagon Papers (actually U.S.-Vietnam Relations, 1945ÿ1967). This top-secret historical study of the American commitment in Vietnam, from the Franklin Roosevelt administration until 1967, had been contracted to the RAND Corporation by Secretary of Defense McNamara. The documents were leaked to the press by Daniel Ellsberg, a former State Department official who had worked on the study.\\r\\n\\r\\nThe Pentagon Papers laid out the missteps taken by four administrations in their Vietnam policies. For example, they revealed the Johnson administration's obfuscations to Congress concerning the Gulf of Tonkin incidents that had led to direct U.S. intervention; they exposed the clandestine bombing of Laos that had begun in 1964; and they detailed the American government's complicity in the death of Ng? ?nh Di?m. The study presented a continuously pessimistic view of the likelihood of victory and generated fierce criticism of U.S. policies.\\r\\n\\r\\nThe importance of the actual content of the papers to U.S. policy-making was disputed, but the window that they provided into the flawed decision-making process at the highest levels of the U.S. government opened the issue for other questions. Their publication was a news event and the government's legal (Nixon lost to the Supreme Court) and extra-legal efforts (the \\"Plumbers\\" break-in at the office of Ellsberg's psychiatrist committed to gain material to discredit him, was one of the first steps on the road to Watergate) carried out to prevent their publicationmainly on national security groundsthen went on to generate yet more criticism and suspicion of the government by the American public.\\r\\n\\r\\nBy 1969 the policy of non-alignment and neutrality had worn thin for Prince Sihanouk, ruler of Cambodia. Pressures from the right in Cambodia caused the prince to begin a shift away from the pro-left position he had assumed in 1965ÿ1966. He began to make overtures for normalized relations with the U.S. and created a Government of National Salvation with the assistance of the pro-American General Lon Nol. Seeing a shift in the prince's position, President Nixon ordered the launching of a top-secret bombing campaign, targeted at the PAVN/NLF Base Areas and sanctuaries along Cambodia's eastern border.\\r\\n\\r\\nOn March 18, 1970, Sihanouk, who was out of the country on a state visit, was deposed by a vote of the National Assembly and replaced by General Lon Nol. Cambodia's ports were immediately closed to North Vietnamese military supplies, and the government demanded that PAVN/NLF forces be removed from the border areas within 72 hours. On March 29, 1970, the Vietnamese had taken matters into their own hands and launched an offensive against the Cambodian army. A force of North Vietnamese quickly overran large parts of eastern Cambodia reaching to within 15 miles (24?km) of Phnom Penh allowing their allies, the Chinese-supported Khmer Rouge to extend their power. Nixon ordered a military incursion into Cambodia by U.S. and ARVN troops in order to both destroy PAVN/NLF sanctuaries bordering South Vietnam and to buy time for the U.S. withdrawal. During the Cambodian Campaign, U.S. and ARVN forces discovered and removed or destroyed a huge logistical and intelligence haul in Cambodia.\\r\\n\\r\\nThe incursion also sparked large-scale demonstrations on and closures of American college campuses. The expansion of the conflict into Cambodia was seen as an expansion of the conflict into yet another country, nullifying Nixon's promises of de-escalating the war. During the ensuing protests, four students were killed and a score were wounded by Ohio National Guardsmen during a demonstration at Kent State University. Two other students were killed at Jackson State University in Mississippi. In an effort to lessen opposition to the U.S. commitment, Nixon announced on October 12 that the U.S. would withdraw 40,000 more troops from Vietnam before Christmas.\\r\\n\\r\\nFollowing the coup, Sihanouk arrived in Beijing, where he established and headed a government in exile, throwing his substantial personal support behind the Khmer Rouge, the North Vietnamese, and the Laotian Pathet Lao.\\r\\n\\r\\nIn 1971 the U.S. authorized the ARVN to carry out an offensive operation aimed at cutting the Ho Chi Minh Trail in southeastern Laos. Besides attacking the PAVN logistical system (which would buy time for the U.S. withdrawal) the incursion would be a significant test of Vietnamization. Backed by U.S. air and artillery support (American troops were forbidden to enter Laos), the ARVN moved across the border along Route 9, utilizing the abandoned Marine outpost of Khe Sanh as a jumping-off point. At first, the incursion went well, but unlike the Cambodian operation of 1970, the PAVN decided to stand and fight, finally mustering around 60,000 men on the battlefield.\\r\\n\\r\\nThe North Vietnamese first struck the flanks of the ARVN column, smashed its outposts, and then moved in on the main ARVN force. Unlike previous encounters during the conflict, the PAVN fielded armored formations, heavy artillery, and large amounts of the latest anti-aircraft artillery. After two months of savage fighting, the ARVN retreated back across the border, closely pursued by the North Vietnamese. One half of the invasion force was killed or captured during the operation, and Vietnamization was seen as a failure.\\r\\n\\r\\nOn August 18, Australia and New Zealand decided to withdraw their troops from the conflict. The total number of U.S. forces in South Vietnam dropped to 196,700 on October 29, 1971, the lowest level since January 1966. On November 12, 1971, Nixon set a February 1, 1972 deadline for the removal of another 45,000 troops.\\r\\n\\r\\nVietnamization received another severe test in the spring of 1972 when the North Vietnamese launched a massive conventional offensive across the Demilitarized Zone. Beginning on March 30, the Easter Offensive (known as the Nguy?n Hu? Offensive to the North Vietnamese) quickly overran the three northernmost provinces of South Vietnam, including the provincial capital of Qu?ng Tr? City. PAVN forces then drove south toward Hu?.\\r\\n\\r\\nEarly in April, PAVN opened two additional operations. The first, a three-division thrust supported by tanks and heavy artillery, advanced out of Cambodia on April 5. The North Vietnamese seized the town of Loc Ninh and advanced toward the provincial capital of An L?c in Bnh Long Province. The second new offensive, launched from the tri-border region into the Central Highlands, seized a complex of ARVN outposts near Dak To and then advanced toward Kon Tum, threatening to split South Vietnam in two.\\r\\n\\r\\nThe U.S. countered with a buildup of American airpower to support ARVN defensive operations and to conduct Operation Linebacker, the first offensive bombing of North Vietnam since Rolling Thunder had been terminated in 1968. The PAVN attacks against Hu?, An L?c, and Kon Tum were contained and the ARVN launched a counteroffensive in May to retake the lost northern provinces. On September 10, the South Vietnamese flag once again flew over the ruins of the Citadel of Qu?ng Tr? City, but the ARVN offensive then ran out of steam, conceding the rest of the occupied territory to the North Vietnamese. South Vietnam had countered the heaviest attack since Tet, but it was very evident that it was totally dependent on U.S. airpower for its survival. Meanwhile, the withdrawal of American troops, who numbered less than 100,000 at the beginning of the year, was continued as scheduled. By June only six infantry battalions remained. On August 12, the last American ground combat division left the country. However, the U.S. continued to operate the base At Long Binh. Combat patrols continued there until November 11 when the U.S. handed over the base to the South Vietnamese. After this, only 24,000 American troops remained in Vietnam and President Nixon announced that they would stay there until all U.S. POW's were freed.\\r\\n\\r\\nAt the beginning of the North Vietnamese invasion, the media, including conservative commentator William F. Buckley, predicted the downfall of the Republic of Vietnam; Buckley even called for the firing of General Creighton Abrams as an incompetent military leader. But the ARVN succeeded in defeating General Giap and his huge invading army. His forces were shattered at the Battle of An L?c, where he threw several divisions at the entrenched South Vietnamese forces, ultimately losing over half of his army as casualties. General Giap's loss and subsequent retreat was viewed as so great a failure by the North Vietnamese Communist Party that Giap was relieved of his command. Although ARVN troops withstood and repelled the massive PAVN attack at An L?c, American air power seems to have been a key to the ARVN success, just as it had been a key factor in supporting U.S. ground forces when they operated in South Vietnam prior to 1972. Thus, the 1973 withdrawal of U.S. military support and passage of Congressional resolutions cutting off U.S. funding for combat activities in Indochina (H.R. 9055 and H.J.Res. 636) opened the way for the 1975 defeat of the Republic of Vietnam.\\r\\n\\r\\nDuring the run-up to the 1972 presidential election, the war was once again a major issue. An antiwar Democrat, George McGovern, ran against President Nixon. The president ended Operation Linebacker on October 22 after the negotiating deadlock was broken and a tentative agreement had been hammered out by U.S. and North Vietnamese representatives at the peace negotiations in Paris. The head of the U.S. negotiating team, Henry Kissinger, declared that \\"peace is at hand\\" shortly before election day, dealing a death blow to McGovern's already doomed campaign. Kissinger had not, however, counted on the intransigence of South Vietnamese President Thieu, who refused to accept the agreement and demanded some 90 changes in its text. These the North Vietnamese refused to accept, and Nixon was not inclined to put too much pressure on Thieu just before the election, even though his victory was all but assured. The mood between the U.S. and North further turned sour when Hanoi went public with the details of the agreement. The Nixon Administration claimed that North Vietnamese negotiators had used the pronouncement as an opportunity to embarrass the President and to weaken the United States. White House Press Secretary Ron Ziegler told the press on November 30 that there would be no more public announcements concerning U.S. troop withdrawals from Vietnam since force levels were down to 27,000.\\r\\n\\r\\nBecause of Thieu's unhappiness with the agreement, primarily the stipulation that North Vietnamese troops could remain \\"in place\\" on South Vietnamese soil, the negotiations in Paris stalled as Hanoi refused to accept Thieu's changes and retaliated with amendments of its own. To reassure Thieu of American resolve, Nixon ordered a massive bombing campaign against North Vietnam utilizing B-52s and tactical aircraft in Operation Linebacker II, which began on December 18 with large raids against both Hanoi and the port of Haiphong. Nixon justified his actions by blaming the impasse in negotiations on the North Vietnamese, causing one commentator to describe his actions as \\"War by tantrum\\". Although this heavy bombing campaign caused protests, both domestically and internationally, and despite significant aircraft losses over North Vietnam, Nixon continued the operation until December 29. He also exerted pressure on Thieu to accept the terms of the agreement reached in October.\\r\\n\\r\\nOn January 15, 1973, citing progress in peace negotiations, Nixon announced the suspension of all offensive actions against North Vietnam, to be followed by a unilateral withdrawal of all U.S. troops. The Paris Peace Accords on \\"Ending the War and Restoring Peace in Vietnam\\" were signed on January 27, officially ending direct U.S. involvement in the Vietnam War.\\r\\n\\r\\nThe agreement called for the withdrawal of all U.S. personnel and an exchange of prisoners of war. Within South Vietnam, a cease-fire was declared (to be overseen by a multi-national, 1,160-man International Control Commission force) and both ARVN and PAVN/NLF forces would remain in control of the areas they then occupied, effectively partitioning South Vietnam. Both sides pledged to work toward a compromise political solution, possibly resulting in a coalition government. To maximize the area under their control, both sides in South Vietnam almost immediately engaged in land-grabbing military operations, which turned into flashpoints. The signing of the Accords was the main motivation for the awarding of the 1973 Nobel Peace Prize to Henry Kissinger and to leading North Vietnamese negotiator Le Duc Tho. A separate cease-fire had been installed in Laos in February. Five days before the signing of the agreement in Paris, President Lyndon Johnson, whose presidency had been tainted with the Vietnam issue, died.\\r\\n\\r\\nThe first U.S. prisoners of war were released by North Vietnam on February 11, and all U.S. military personnel were ordered to leave South Vietnam by March 29. As an inducement for Thieu's government to sign the agreement, Nixon had promised that the U.S. would provide financial and limited military support (in the form of air strikes) so that the South would not be overrun. But Nixon was fighting for his political life in the growing Watergate scandal and facing an increasingly hostile Congress that withheld funding. The President was able to exert little influence on a hostile public long sick of the Vietnam War.\\r\\n\\r\\nThus, Nixon (or his successor Gerald Ford) was unable to fulfill his promises to Thieu. At the same time, aid to North Vietnam from the Soviet Union increased. With the U.S. no longer heavily involved, both the U.S. and the Soviet Union no longer saw the war as significant to their relations. The balance of power shifted decisively in North Vietnam's favor, and the North subsequently launched a major military offensive, the Ho Chi Minh Campaign, against the South that culminated in the surrender of the Republic of Vietnam to PAVN forces on April 30, 1975.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThe Office of the Secretary of Defense & Joint Staff, FOIA Requester Service Center\\r\\n\\r\\nForeign Relations Series\\r\\n\\r\\nUnder Eisenhower\\r\\n\\r\\nUnder Kennedy\\r\\n\\r\\nUnder Johnson\\r\\n\\r\\n\\r\\n\\r\\nUnder Nixon\\r\\n\\r\\nUnder Ford","input":"When did the us engage in the vietnam war?"},{"output":"Wilbur Ross","context":"The United States Secretary of Commerce (SecCom) is the head of the United States Department of Commerce. The Secretary is appointed by the President of the United States with the advice and consent of the United States Senate and serves in the President's Cabinet. The Secretary is concerned with promoting American businesses and industries; the Department states its mission to be \\"to foster, promote, and develop the foreign and domestic commerce\\".[2]\\r\\nUntil 1913 there was one Secretary of Commerce and Labor, uniting this department with the Department of Labor, which is now headed by a separate Secretary of Labor.[3]\\r\\nThe current Commerce Secretary is Wilbur Ross, who was nominated by President Donald Trump and approved by the Senate on February 28, 2017.\\r\\n\\r\\n\\r\\n??No party (1) ??Democratic (20) ??Republican (18)\\r\\nSource: Department of Commerce: Secretaries\\r\\nAs of December 2017, there are eleven living former Secretaries of Commerce, the oldest being Frederick B. Dent (served 1973-1975, born 1922). The most recent Secretary of Commerce to die was Juanita M. Kreps (served 1977-1979, born 1921), on July 5, 2010. The most recently serving Secretary to die was Ron Brown (1993-1996, born 1941), who died in office on April 3, 1996.\\r\\nThe line of succession for the Secretary of Commerce is as follows:[4]","input":"Who is the head of department of commerce?"},{"output":"31 August 1991","context":"","input":"When did uzbekistan gain independence from the soviet union?"},{"output":"Justin Timberlake","context":"Halftime shows are a tradition during American football games at all levels of competition. Entertainment during the Super Bowl, the annual championship game of the National Football League (NFL), represents a fundamental link to pop culture, which helps broaden the television audience and nationwide interest. As the Super Bowl itself is typically the most-watched event on television in the United States annually, the halftime show has been equally-viewed in recent years: the halftime show of Super Bowl XLIX featuring Katy Perry was viewed by 118.5 million, as part of an overall telecast that peaked at 120.3 million at its conclusionthe most-watched television broadcast in U.S. history.[1][2][3] The NFL claims that the Super Bowl LI halftime show, with Lady Gaga was the \\"most-watched musical event of all-time,\\" citing a figure of 150 million viewers based on the television audience, as well as unique viewership of video postings of the halftime show on the league's platforms, and social media interactions (a metric that was never calculated prior to 2017).[4][5] However, the show was seen by 117.5 million television viewers, making it the second-highest-rated halftime show.[6]\\r\\nPrior to the early 1990s, the halftime show was based around a theme, and featured university marching bands (the Grambling State University Marching Band has performed at the most Super Bowl halftime shows, featuring in six shows including at least one per decade from the 1960s to the 1990s), drill teams, and other performance ensembles such as Up with People. Beginning in 1991, the halftime show began to feature pop music acts such as New Kids on the Block and Gloria Estefan. In an effort to boost the prominence of the halftime show to increase viewer interest, Super Bowl XXVII featured a headlining performance by Michael Jackson. After Super Bowl XXXVIII, whose halftime show featured an incident where Justin Timberlake exposed one of Janet Jackson's breasts, the halftime show began to feature classic rock acts until the return of headlining pop musicians in 2011.\\r\\n\\r\\n\\r\\nDuring most of the Super Bowl's first decade, the halftime show featured a college marching band. The show's second decade featured a more varied show, often featuring drill teams and other performance ensembles; the group Up with People produced and starred in four of the performances. The middle of the third decade, in an effort to counter other networks' efforts to counterprogram the game,[7] saw the introduction of popular music acts such as New Kids on the Block, Gloria Estefan, Michael Jackson, Clint Black, Patti LaBelle, and Tony Bennett. Starting with Super Bowl XXXII, commercial sponsors presented the halftime show; within five years, the tradition of having a themebegun with Super Bowl IIIended, replaced by major music productions by arena rock bands and other high-profile acts. In the six years immediately following an incident at Super Bowl XXXVIII where Justin Timberlake exposed one of Janet Jackson's breasts in an alleged \\"wardrobe malfunction\\", all of the halftime shows consisted of a performance by one artist or group, with the musicians in that era primarily being rock artists from the 1960s, 1970s and 1980s. These shows were considered \\"family friendly\\" and the time in which they took place has been described as \\"the age of reactionary halftime shows.[8] Since Super Bowl XLV, the halftime show has returned to featuring popular contemporary musicians, with the typical format featuring a single headline artist collaborating with a small number of guest acts.\\r\\nThe NFL does not pay the halftime show performers an appearance fee, though it covers all expenses for the performers and their entourage of band members management, technical crew, security personnel, family, and friends.[9] Super Bowl XXVII halftime show with Michael Jackson provided an exception, as the NFL and Frito-Lay agreed to make a donation and provide commercial time for Jackson's Heal the World Foundation.[10][11][12][11] According to Nielsen SoundScan data, the halftime performers regularly experience significant spikes in weekly album sales and paid digital downloads due to the exposure.[13] For Super Bowl XLIX, it was reported by the Wall Street Journal that league officials asked representatives of potential acts if they would be willing to provide financial compensation to the NFL in exchange for their appearance, in the form of either an up-front fee, or a cut of revenue from concert performances made after the Super Bowl. While these reports were denied by an NFL spokeswoman, the request had, according to the Journal, received a \\"chilly\\" response from those involved.[14][15]\\r\\nThe following is a list of the performers, producers, themes, and sponsors for each Super Bowl game's show.\\r\\nU2 performed 3 songs: \\"Beautiful Day,\\" \\"MLK,\\" and \\"Where the Streets Have No Name.\\" During the beginning of \\"MLK\\" and continuing until the end of \\"Where The Streets Have No Name,\\" a large banner behind the band displayed the names of all the people who lost their lives on the September 11 attacks. Bono ended the song by opening up his jacket, the inside of which displayed the American flag.\\r\\nFor The Rolling Stones, the stage was in the form of the group's iconic tongue logo (John Pasche's \\"Cunning Linguist\\" first used in 1971 on their Sticky Fingers album). It was the largest stage ever assembled for a Super Bowl halftime show, with 28 separate pieces assembled in five minutes by a 600-member volunteer stage crew. The group performed three songs: \\"Start Me Up,\\" \\"Rough Justice,\\" and \\"(I Can't Get No) Satisfaction.\\" The show was viewed by 89.9 million people, more than the audiences for the Oscars, Grammys and Emmy Awards combined.[54] In the wake of the Super Bowl XXXVIII halftime show controversy with Janet Jackson and Justin Timberlake, ABC and the NFL imposed a five-second delay and censored lyrics considered too sexually explicit in the first two songs by briefly turning off Mick Jagger's microphonecensoring to which the group had previously agreed.[55] However, the choice of The Rolling Stones sparked controversy in the Detroit community because the band did not represent the traditional Detroit \\"Motown Sound,\\" and no artists from the area were included.[56]","input":"Who did the last super bowl halftime show?"},{"output":"Marvel's Jessica Jones","context":"The Marvel Cinematic Universe (MCU) television series are American superhero television shows based on characters that appear in publications by Marvel Comics. The shows have been in production since 2013, and in that time Marvel Television and ABC Studios, along with its production division ABC Signature Studios, have premiered 10 series, with at least four more in various stages of development, across broadcast, streaming, and cable television on ABC, Netflix and Hulu, and Freeform, respectively. The ABC series have averaged around 4ÿ8 million viewers a season, with many of the MCU series receiving strong critical responses.\\r\\nThe first series in the universe, Marvel's Agents of S.H.I.E.L.D., began airing on ABC during the 2013ÿ14 television season, and was joined by Marvel's Agent Carter in the 2014ÿ15 television season. Marvel formed a unique partnership with IMAX Corporation to premiere Marvel's Inhumans in IMAX theaters in September 2017 before airing on ABC during the 2017ÿ18 television season; a put pilot for another ABC series, Marvel's Damage Control, has also been ordered. Netflix's Marvel series began in 2015 with Marvel's Daredevil and Marvel's Jessica Jones, followed by Marvel's Luke Cage in 2016. Marvel's Iron Fist, the crossover miniseries Marvel's The Defenders, and Marvel's The Punisher released in 2017. Additionally, the MCU expanded to Hulu with Marvel's Runaways in 2017, and will also expand to Freeform with Marvel's Cloak & Dagger in 2018. Marvel's New Warriors is also scheduled to air in 2018, despite not having a broadcaster.\\r\\nStarring in the series are Clark Gregg as Phil Coulson, in Agents of S.H.I.E.L.D., and Hayley Atwell as Peggy Carter, in Agent Carter, both reprising their roles from MCU films, while Anson Mount headlines Inhumans as Black Bolt. Daredevil introduces Charlie Cox in the title role of Matt Murdock / Daredevil as well as Jon Bernthal as the Punisher in its second season, who reprises his role as the star of The Punisher. Jessica Jones introduces Krysten Ritter as Jessica Jones and Mike Colter as Luke Cage, with the latter also headlining Luke Cage. Finn Jones stars as Danny Rand / Iron Fist in Iron Fist, and joins Cox, Ritter, and Colter for The Defenders. The Runaways cast consists of the titular group, including Rhenzy Feliz as Alex Wilder, and their parents, including Ryan Sands as Geoffrey Wilder. Olivia Holt and Aubrey Joseph star in Cloak & Dagger as Tandy Bowen / Dagger and Tyrone Johnson / Cloak, respectively, while Milana Vayntrub and Derek Theler lead New Warriors as Doreen Green / Squirrel Girl and Craig Hollis / Mister Immortal, respectively.\\r\\nAgent Phil Coulson assembles a small team of S.H.I.E.L.D. (Strategic Homeland Intervention, Enforcement and Logistics Division) agents to handle strange new cases.[7] After discovering that Project Centipede and their leader, \\"The Clairvoyant\\", were affiliated with Hydra, a terrorist organization, Coulson and his team must deal with Hydra members still at large following Hydra's infiltration of, and the destruction of, S.H.I.E.L.D., while also looking to restore trust from the government and public.[8] In the wake of S.H.I.E.L.D.'s wars with Hydra and the Inhumans, a race of superhumans, Coulson begins a secret mission to protect the world from new threats.[9] After the defeat of the Inhuman Hive and with Hydra destroyed, S.H.I.E.L.D. is made a legitimate organization once again, with Coulson returning to being a field agent, and is tasked with tracking down more enhanced peopleÿincluding Robbie Reyes / Ghost Riderÿwhile Agent Leo Fitz and Dr. Holden Radcliffe complete their work on Life Model Decoys.[10] Coulson and members of his team are eventually abducted to deep space, where they must try and save humanity while figuring out how to get home.[11]\\r\\nIn August 2012, ABC ordered a pilot for a show called S.H.I.E.L.D., to be written by Joss Whedon, Jed Whedon, and Maurissa Tancharoen, and directed by Joss Whedon.[12] On April 6, 2013, ABC announced that the show would be titled Marvel's Agents of S.H.I.E.L.D.,[13] and it was officially ordered to series on May 10, 2013.[14] Jed Whedon, Tancharoen and Jeffrey Bell act as the series' showrunners,[1] while Clark Gregg reprises his role from the films as Phil Coulson.[15] The series was renewed for a second season on May 8, 2014,[16] a third on May 7, 2015,[17] a fourth on March 3, 2016,[18] and a fifth on May 11, 2017.[19]\\r\\nThe first season, which premiered on September 24, 2013,[20] aired episodes that directly relate to events in the films Thor: The Dark World and Captain America: The Winter Soldier.[21][22] The revelation in Captain America: The Winter Soldier that S.H.I.E.L.D. had been infiltrated by Hydra had a huge impact on the series. Regarding the synergy the show had with addressing events from the film, Loeb said, \\"It's an extremely unique experience that doesn't exist anywhere else out there in the entertainment business.\\"[23] The second season, which premiered on September 23, 2014,[24] introduces Inhumans to the MCU,[25] ahead of their own television series.[26] Additionally, a recurring plot point in the first two seasons involved the body of a member of the Kree race, who play a significant role in Guardians of the Galaxy.[27] The third season, which premiered on September 29, 2015,[28] introduces the concept of the Secret Warriors, with new Inhuman characters inspired by the comic of the same name,[29][30] as well as Life Model Decoys.[31] The fourth season, which premiered on September 20, 2016,[32] sees Robbie Reyes / Ghost Rider introduced to the MCU,[33] and ties to the second season of Agent Carter and Doctor Strange.[34][35] The fifth season premiered on December 1, 2017.[11]\\r\\nIn the first season, Samuel L. Jackson,[36] Cobie Smulders,[37] Maximiliano Hernndez,[38] Titus Welliver[39] and Jaimie Alexander[40] all reprise their roles as Nick Fury, Maria Hill, Jasper Sitwell, Felix Blake, and Sif, respectively, from previous MCU films and One-Shots. In the second season, Alexander and Smulders return,[41][42] while Hayley Atwell,[43] Neal McDonough, Kenneth Choi,[44] and Henry Goodman[45][46] also reprise their roles as Peggy Carter, Timothy \\"Dum Dum\\" Dugan, Jim Morita, and List, respectively, from previous MCU films. In the third season, William Sadler reprises his role as Matthew Ellis from the MCU films,[47] and Powers Boothe recurs as his previously unnamed The Avengers character, Gideon Malick.[48]\\r\\nIn 1946, Peggy Carter must balance the routine office work she does for the Strategic Scientific Reserve while secretly assisting Howard Stark, who finds himself framed for supplying deadly weapons to enemies of the United States. Carter is assisted by Stark's butler, Edwin Jarvis, to find those responsible and dispose of the weapons.[49][50] Carter eventually moves from New York City to Los Angeles to deal with the threats of the new atomic age in the wake of World War II, gaining new friends, a new home and potential new love.[51]\\r\\nBy September 2013, Marvel was developing a series inspired by the Agent Carter One-Shot, featuring Peggy Carter,[52] and in January 2014, the series was confirmed to be in development, with the script for a potential pilot to be written by Captain America: The First Avenger and Captain America: The Winter Soldier writers Christopher Markus & Stephen McFeely.[53] On May 8, 2014, ABC officially ordered Marvel's Agent Carter to series.[16] Tara Butters, Michele Fazekas and Chris Dingess act as showrunners on the series,[4][53] while Hayley Atwell reprises her role from the films as Peggy Carter.[53] The series was renewed for a second season on May 7, 2015,[17] and was officially canceled by ABC on May 12, 2016.[54]\\r\\nThe first season, which premiered on January 6, 2015,[55] introduces the origins of the Black Widow and Winter Soldier programs, which both appear in several MCU films.[56][57][58] The second season, which premiered on January 19, 2016,[59] features the Darkforce, which ties to the character Marcus Daniels in Agents of S.H.I.E.L.D. and Doctor Strange.[60]\\r\\nIn the first season, Dominic Cooper reprise his role of Howard Stark from Captain America: The First Avenger.[61] James D'Arcy portrays Edwin Jarvis,[62] Stark's butler in the series who eventually serves as inspiration for Tony Stark's artificial intelligence J.A.R.V.I.S.[63] Costa Ronin portrays a young Anton Vanko, the co-creator of the arc reactor with Stark.[64] Chris Evans appears as Steve Rogers / Captain America via archive footage from The First Avenger.[65] McDonough and Toby Jones reprise their roles as Dugan and Arnim Zola, respectively.[66][67] In the second season, Cooper returns to reprise his role.[68]\\r\\nAfter a military coup, the Inhuman Royal Family, led by Black Bolt, escape to Hawaii where they must save themselves and the world.[69]\\r\\nIn November 2016, Marvel Television and IMAX Corporation announced Marvel's Inhumans, to be produced in conjunction with ABC Studios.[26][70] The series' first two episodes were filmed entirely on IMAX digital cameras,[71] and premiered on IMAX screens on September 1, 2017, for two weeks.[5] ABC will then broadcast the series weekly starting with the first two episodes on September 29, 2017,[5] with the network airing of the first two episodes featuring exclusive content, outside of the versions screened on IMAX.[26] Select action sequences in the rest of the series were also shot on IMAX.[71] The series was neither intended to be a reworking of the planned film from Marvel Studios, nor a spin-off from Agents of S.H.I.E.L.D.[72] Ben Sherwood, president of DisneyÿABC Television Group, added that \\"Weve worked very carefully with our friends at Marvel Studiosand this is a critical pointto make sure that calendar-wise and content-wise we are only enhancing\\" the MCU; the theatrical debut of the series was timed to not interfere with the release of any Marvel Studios films.[73] In December 2016, Scott Buck was announced as showrunner and executive producer for the series.[6] In February 2017, Anson Mount was cast as Black Bolt.[70] Filming began in March 2017 in Hawaii,[74] and concluded in June.[75]\\r\\nBy October 2013, Marvel was preparing four drama series and a miniseries to present to video on demand services and cable providers, with Netflix, Amazon, and WGN America expressing interest.[91] That November, it was announced that Disney would provide Netflix with live-action series based on Daredevil, Jessica Jones, Iron Fist, and Luke Cage, leading up to a miniseries based on the Defenders.[92]\\r\\nLawyer-by-day Matt Murdock uses his heightened senses from being blinded as a young boy to fight crime at night on the streets of Hells Kitchen as Daredevil, juxtaposed with the rise of crime lord Wilson Fisk.[93] Murdock eventually crosses paths with Frank Castle / Punisher, a vigilante with far deadlier methods, and sees the return of his old girlfriend, Elektra Natchios.[94][95]\\r\\nIn December 2013, Marvel confirmed that Drew Goddard would be the executive producer and showrunner for Daredevil, and would write and direct the first episode,[96] though at the end of May 2014, it was announced that Goddard would no longer be the showrunner for the series, being replaced by Steven S. DeKnight. Goddard, who wrote the first two episodes, remained with the show as an executive producer. It was also revealed that the series would be titled Marvel's Daredevil.[76] A few days later, Charlie Cox was cast as Daredevil.[97] A second season was ordered on April 21, 2015, with Doug Petrie and Marco Ramirez taking over as showrunners from DeKnight, who could not return to the series due to a prior commitment.[77] A third season was ordered in July 2016,[98] with Erik Oleson announced as the new showrunner of the series in October 2017.[78]\\r\\nThe first season, which debuted in its entirety on April 10, 2015,[99] features references to The Avengers and the Battle of New York,[100] as well as mentioning Carl \\"Crusher\\" Creel, who appears on Agents of S.H.I.E.L.D.[101] The insignia for the Iron Fist antagonist Steel Serpent is also seen in the season.[102] The second season, which premiered on March 18, 2016,[103] features the motorcycle gang Dogs of Hell, who appeared on Agents of S.H.I.E.L.D.,[104] along with numerous references to the events of the first season of Jessica Jones.[105][106][107] The third season is slated to be released in 2018.[78]\\r\\nIn the second season, Jon Bernthal was cast in a leading role as Frank Castle / Punisher,[108] before headlining his own series,[89] while Michelle Hurd and Carrie-Anne Moss reprise their roles of Samantha Reyes and Jeri Hogarth from Jessica Jones.[106][107]\\r\\nFormer superhero Jessica Jones suffers from post-traumatic stress disorder, so she opens her own detective agency to help people.[109] She begins to put her life back together after her encounter with Kilgrave, taking on a new case that makes her reluctantly confront her past.[110]\\r\\nIn November 2013, Melissa Rosenberg was announced as the writer and executive producer of the series,[79] and the following March, Loeb stated that filming would begin after Daredevil.[111] In December 2014, Krysten Ritter was cast as Jessica Jones in the series,[112] officially titled Marvel's Jessica Jones.[113] A second season was ordered on January 17, 2016,[114] and a third on April 12, 2018.[80]\\r\\nThe first season, which debuted in its entirety on November 20, 2015,[115] features references to the events and characters of The Avengers.[116] In the first season, Mike Colter was cast as Luke Cage,[117] a recurring role in the series before headlining his own series.[109] Rosario Dawson reprises her Daredevil role of Claire Temple,[118] as does Royce Johnson in his role of Brett Mahoney.[119] The second season, which was released on March 8, 2018,[120] sees Elden Henson reprise his role of Franklin \\"Foggy\\" Nelson,[121] as well as Rob Morgan as Turk Barrett[122] and Tijuana Ricks as Thembi Wallace.\\r\\nWhen a sabotaged experiment gives him super strength and unbreakable skin, Luke Cage becomes a fugitive attempting to rebuild his life in Harlem, and must soon confront his past and fight a battle for the heart of his city.[123] After clearing his name, Cage becomes a hero and celebrity in Harlem, only to encounter a new threat that makes him confront the line between hero and villain.[83]\\r\\nColter reprises his role as Carl Lucas / Luke Cage in his own series,[109][117][124] titled Marvel's Luke Cage.[81] In March 2014, Loeb stated that the series would begin filming after Iron Fist, being the fourth of the individual series.[111] By March 2015, it was instead slated to be the third of the individual series, beginning production after Jessica Jones.[77][125] The series was switched with Iron Fist after the positive reception Luke Cage received on Jessica Jones, becoming that series' breakout star and Marvel wanting to \\"follow the momentum\\".[126] Also in March, Cheo Hodari Coker was announced as showrunner and executive producer of the series.[81] A second season was ordered on December 3, 2016.[127]\\r\\nThe first season, which premiered on September 30, 2016,[128] features references to The Avengers, the second season of Daredevil, the first season of Jessica Jones, and a flier for Colleen Wing's martial arts class, and mentions Justin Hammer, Wilson Fisk and Frank Castle.[129] Dawson,[130] Morgan, Rachel Taylor, Stephen Rider,[129] Parisa Fitz-Henley,[131] and Danny Johnson[132] reprise their roles as Claire Temple, Turk Barrett, Trish Walker, Blake Tower, Reva Connors and Ben Donovan in the series, respectively.\\r\\nThe second season is scheduled to be released on June 22, 2018.[83] Finn Jones will reprise his role as Danny Rand in the season.[133]\\r\\nDanny Rand returns to New York City, after being missing for fifteen years, to reclaim his family company. However, when a threat emerges, Rand must choose between his family's legacy and his duties as the Iron Fist.[134]\\r\\nIn March 2014, Loeb initially stated that the series would begin filming after Jessica Jones as the third of the individual series.[111] By March 2015, it was expected to be the fourth of the individual series, entering production following Luke Cage.[77][125] The series was switched with Luke Cage after the positive reception Luke Cage received on Jessica Jones, becoming that series' breakout star and Marvel wanting to \\"follow the momentum\\".[126] In April 2015, the title of the series was revealed to be Marvel's Iron Fist.[77] In December 2015, Marvel announced that Scott Buck would serve as showrunner and executive producer of the series.[84] In February 2016, Finn Jones was cast as Rand.[135][136] A second season was revealed to be in development in July 2017,[85] with Raven Metzner announced as the new showrunner for the season, replacing Buck.[87]\\r\\nThe first season, which premiered on March 17, 2017,[134] makes references to the events of The Avengers, the Hulk, Stark Industries, Jessica Jones, Daredevil, Luke Cage, and Seagate Prison,[137] and mentions the Dogs of Hell biker gang, New York Bulletin editor-in-chief Mitchell Ellison and reporter Karen Page,[138] Roxxon Oil and Midland Circle.[139][140] Events from the second season of Daredevil are also noted throughout.[137][140] Moss,[141] Dawson,[142] Wai Ching Ho,[143] Marquis Rodriguez,[144] Tijuana Ricks, and Suzanne H. Smart reprise their roles as Jeri Hogarth, Claire Temple, Gao, Darryl, Thembi Wallace, and Shirley Benson, respectively, in the series.\\r\\nThe second season will see Simone Missick reprise her role as Misty Knight.[85]\\r\\nThe superheroes Daredevil, Jessica Jones, Luke Cage, and Iron Fist team-up in New York City.[84]\\r\\nThe Defenders sees Cox, Ritter, Colter, and Jones reprise their roles as Matt Murdock / Daredevil, Jessica Jones, Luke Cage, and Danny Rand / Iron Fist, respectively, from the previous television series.[145] In March 2014, Loeb stated that the miniseries, officially titled Marvel's The Defenders, would begin filming after Iron Fist.[146][111][125] In April 2016, Marvel announced that Douglas Petrie and Marco Ramirez would act as showrunners for The Defenders.[146] However, by the start of filming in New York City in October 2016,[147][148] Petrie had left the series as co-showrunner.[88] Filming concluded in March 2017.[149] The eight-episode event premiered on August 18, 2017.[150][151]\\r\\nThe miniseries also sees many supporting characters from the individual series reprise their roles, including, Deborah Ann Woll,[152] Henson,[153] Scott Glenn,[154] lodie Yung,[155] Eka Darville,[156] Moss,[153] Taylor,[154] Simone Missick,[157] Jessica Henwick,[158] Dawson,[154] Ho,[159] Ram܇n Rodrguez,[160] Peter McRobbie,[161] Morgan,[162] Amy Rutberg, Susan Varon, and Nichole Yannetty as Karen Page, Foggy Nelson, Stick, Elektra Natchios, Malcolm Ducasse, Jeri Hogarth, Trish Walker, Misty Knight, Colleen Wing, Claire Temple, Gao, Bakuto, Lantom, Turk Barrett, Marci Stahl, Josie and Nicole, respectively. Midland Circle, which was referenced in previous Netflix series,[163][164] is revealed to be an operation of the Hand, who bought the building to search for the life substance hidden beneath the property.[164] The miniseries also references the events of The Avengers.[162]\\r\\nFrank Castle is haunted and hunted after the murder of his family and becomes a vigilante known in the criminal underworld as \\"the Punisher\\", who aims to fight crime by any means necessary.[89][165]\\r\\nBy January 2016, ahead of the debut of Bernthal as armed vigilante Frank Castle / Punisher in the second season of Daredevil, Netflix was in \\"very early development\\" on a spin-off series titled The Punisher, and was looking for a showrunner. The series would be centered on Bernthal as Castle, and was described as a stand-alone series, outside of the series leading up to The Defenders.[166][167][168] Loeb implied that Marvel Television had not instigated the development of the spin-off and were focusing on making \\"the best 13 episodes of Daredevil season two\\" at the time, but did say, \\"Im never going to discourage a network from looking at one of our characters and encouraging us to do more....If we are lucky enough that through the writing, through the direction, through the actor that people want to see more of that person, terrific.\\"[169] In April 2016, Marvel and Netflix ordered The Punisher, along with confirming Bernthal's involvement and naming Steve Lightfoot as showrunner.[89] Filming began in Brooklyn, New York in October 2016,[170] and concluded in April 2017.[171] A second season was ordered on December 12, 2017.[90]\\r\\nIn the first season, which was released on November 17, 2017,[172] Woll and Morgan reprise their roles as Karen Page and Turk Barrett, respectively.[173][174]\\r\\nWhen six teenagers discover their parents are villains, they reluctantly unite to go against them.[175]\\r\\nIn August 2016, Marvel announced Marvel's Runaways had received a pilot order, along with additional scripts, from the streaming service Hulu, based on the team of the same name. The pilot is written by Josh Schwartz and Stephanie Savage, who also serve as executive producers and showrunners of the series.[175] In February 2017, Marvel announced the cast of the Runaways, with Rhenzy Feliz as Alex Wilder, Lyrica Okano as Nico Minoru, Virginia Gardner as Karolina Dean, Ariela Barer as Gert Yorkes, Gregg Sulkin as Chase Stein, and Allegra Acosta as Molly Hernandez.[177] Shortly after, they announced the cast of the Pride, the parents of the Runaways, with Ryan Sands as Geoffrey Wilder, Angel Parker as Catherine Wilder, Brittany Ishibashi as Tina Minoru, James Yaegashi as Robert Minoru, Kevin Weisman as Dale Yorkes, Brigid Brannagh as Stacey Yorkes, Annie Wersching as Leslie Dean, Kip Pardue as Frank Dean, James Marsters as Victor Stein, and Ever Carradine as Janet Stein.[178] Hulu ordered the series in May 2017.[179] Filming began in Los Angeles in February 2017,[180][181] and concluded in October 2017.[182] The first season, consisting of 10 episodes, premiered on November 21, 2017.[183] Hulu renewed the series for a second season on January 8, 2018.[176]\\r\\nTina Minoru previously appeared in Doctor Strange, in a minor role as a Master of the Mystic Arts portrayed by Linda Louise Duan.[184][185][186]\\r\\nTandy Bowen and Tyrone Johnson, two teenagers from different backgrounds, acquire superpowers while forming a romantic relationship. They soon realize that their powers work better when they are together, \\"but their feelings for each other make their already complicated world even more challenging.\\"[190]\\r\\nIn April 2016, the ABC-owned network Freeform announced a straight-to-series order for Marvel's Cloak & Dagger, based on the characters of the same name,[190] calling it their \\"first venture into the Marvel Cinematic Universe\\", and describing the show as a \\"superhero love story\\".[191] In January 2017, Olivia Holt and Aubrey Joseph were cast as Tandy Bowen / Dagger and Tyrone Johnson / Cloak, respectively.[192] Joe Pokaski serves as showrunner for the series.[189] Filming began in New Orleans in February 2017,[193] and concluded in November 2017.[194] The first season, consisting of 10 episodes,[187] is set premiere on June 7, 2018.[188]\\r\\nRoxxon Oil is seen in the series,[195] as is the Darkforce, which fuels Cloak's powers and was previously established in Agents of S.H.I.E.L.D. and Agent Carter.[196]\\r\\nDoreen Green / Squirrel Girl, Craig Hollis / Mister Immortal, Dwayne Taylor / Night Thrasher, Robbie Baldwin / Speedball, Zach Smith / Microbe, and Deborah Fields / Debrii,[198] are superpowered young people with abilities very different from the Avengers, who want to make a positive impact in the world even if they are not quite ready to be heroes.[197]\\r\\nBy the end of August 2016, Marvel Television and ABC Studios were developing a half-hour comedy series based on the New Warriors featuring Squirrel Girl, with the series being offered to cable networks and streaming outlets.[199] In April 2017, Freeform announced a straight-to-series order for Marvel's New Warriors, with Kevin Biegel serving as the series' showrunner and writing the first script.[197][200] In July 2017, the cast was revealed with Milana Vayntrub starring as Doreen Green / Squirrel Girl and Derek Theler as Craig Hollis / Mister Immortal.[201] In November 2017, it was announced that the series would no longer air on Freeform and was being shopped to other networks, with Marvel intent on airing the series in 2018.[202] The first season, consisting of 10 episodes, is set to air in 2018, with Biegel serving as showrunner for the series.[197][200][201]\\r\\nList indicator(s)\\r\\nList indicator(s)\\r\\nWith the release of the second season of Daredevil, Brian Lowery of Variety felt the Netflix series \\"have already leapfrogged ABCs forays into the Marvel universe in terms of their appeal, in part by tapping into the avid fan base that supports pay models and doesnt need to be spoon-fed plot points. In the process, they have demonstrated that its possible to deliver a credible superhero show without a lot of pyrotechnics\\".[286]\\r\\nAfter the release of the first season of Luke Cage, The Atlantic's David Sims wrote on the pacing issue of Marvel's Netflix series, a common complaint to that point, stating, \\"After two seasons of Daredevil, one of Jessica Jones, and now one of Luke Cage, the Netflix model feels fundamentally flawed, encouraging the kind of molasses-slow plotting comic books are designed to eschew. The problem isnt that these shows are bad, necessarily... But they all take far too long to get going, by which point many viewers will have already tuned out.\\" He felt one of the problems was the fact that Netflix does not rely on viewers tuning into a particular series as broadcast series do each week, but rather subscribers who, if they lose interest, \\"can take as long as they want to catch up... as long as they keep paying their subscription fee every month.\\" The Netflix series are also afforded the opportunity to explore elements in more detail, with Sims noting \\"A lot of this detail [is] good, but it could have been considerably compressednone of the Marvel Netflix series, so far, would have lost much by being squeezed into 10 episodes, or even 8. If Netflix shaved the 60-minute running time down quite a bit, it would likely inspire more economicaland betterstorytelling from its shows.\\" Sims concluded by saying, \\"Whats most frustrating of all is that Netflix isnt getting rid of this approach anytime soon. Daredevil season three, Jessica Jones season two, Iron Fist, and The Punisher are all on their way, and each will follow the same 13-episode structure... The only respite may come in the form of The Defenders, a planned crossover series... over the course of just eight episodes. Who knows? The show might even surprise viewers and explain its villains motivations within the first hour. Until then, fans will be stuck needlessly giving over entire days to these series, while others are deterred from watching at all.\\"[287] In her review for the first season of Iron Fist, Allison Keene of Collider spoke more on the pacing of Marvel's Netflix series, stating, \\"By focusing so intently on making these series... much more grounded in a gritty real world than what we typically expect from a superhero show (like DC's candy-colored [Arrowverse] on The CW), the problem is that they miss out on the key element: this should be fantastical entertainment.\\"[288] With The Defenders, Jeff Jansen of Entertainment Weekly felt many improvements were made to the general complaints the previous seasons received. He said, \\"The Defenders is far from perfect. But its an enjoyable superhero adventure distinguished by improvements and innovations that I hope Marvel will carry forward. Shorter seasons. More team-ups. Fewer shows. Start the consolidation by letting go of Iron Fist. If Danny Rand must persist, add him to the other shows and let the stronger players carry him.\\"[289]\\r\\nThe show follows the overworked, underpaid, clean up crew of the Marvel Cinematic Universe, who specialize in dealing with the aftermath of superhero conflicts, rescheduling events because of the conflicts, and retrieving lost items.[290]\\r\\nIn October 2015, ABC ordered a put pilot for a half-hour live-action comedy series Marvel's Damage Control, based on the comics construction company of the same name. The series is being developed by Ben Karlin for ABC Studios and Marvel Television, with Karlin also writing the script for the project and serving as executive producer.[290][291] In January 2016, ABC Entertainment president Paul Lee said Damage Control was \\"going to be coming out this season,\\" seemingly implying it would air in the 2016ÿ17 television season.[292]\\r\\nMarvel has been working with screenwriter John Ridley since mid-April 2015 to craft a new television series, \\"reinventing\\" an existing Marvel character or property.[293] In January 2016, Ridley confirmed that the project was \\"still in development\\". He stated that he was looking to \\"bring some of the socially conscious nature\\" of Jessica Jones and his series American Crime to the show, while also creating something that is \\"straight entertainment\\".[294] A year later, Channing Dungey revealed that Ridley's project was still progressing, with Ridley working on a rewrite of his script.[295] Ridley added that the rewrite was not because \\"anything didn't work the first time around\\", but rather trying to make sure the series does something viewers have not necessarily seen before in a superhero television series, hoping it would occupy \\"a space that is not currently being filled\\" by Marvel. He also stated that he hoped to create the series \\"in the near term.\\"[296] By August 2017, Dungey was \\"not sure\\" if Ridley was still working on the project.[297]\\r\\nIn January 2016, Lee announced that ABC Studios was developing a second comedy series with Marvel in hope it would air on ABC,[292] while Netflix CCO Ted Sarandos stated that \\"all the characters in the universe could also spin out\\" into their own series at some point.[168] That May, Dungey said that there were \\"a handful of projects in development\\", after passing on Most Wanted and canceling Agent Carter, and that Marvel and ABC were looking \\"at series that would be beneficial to both brands.\\"[298] By November 2017, Disney was developing a Marvel series specifically for release on its new streaming service, which it planned to launch before the end of 2019.[299] In January 2018, Dungey noted Marvel and ABC \\"tried a few things that havent worked out as well as we wouldve liked. We developed a couple things this season that we dont think are going to end up going forward, so were going to look really carefully about what we do next, because the idea for us is to come up with something that works very well for both Marvel and ABC, so were going to continue to try there.\\"[300]\\r\\nBy April 2015, Marvel was developing a spinoff series of Agents of S.H.I.E.L.D. The series, which was being developed by Agents of S.H.I.E.L.D. executive producer Jeffrey Bell and writer Paul Zbyszewski, would be based on storylines occurring at the end of the second season of Agents of S.H.I.E.L.D., and would receive its own pilot rather than a backdoor pilot.[301] Adrianne Palicki and Nick Blood entered into discussions to headline the potential new series as their characters Bobbi Morse and Lance Hunter, respectively.[302] By May 7, 2015, when ABC announced their series renewals and cancellations, and new series pickups, the Agents of S.H.I.E.L.D. spinoff was passed on.[303]\\r\\nIn August 2015, the Agents of S.H.I.E.L.D. spinoff series received new life as a reworked series, titled Marvel's Most Wanted, with a pilot order.[304] Bell and Zbyszewski once again developed the series, while also serving as co-writers of the pilot, executive producers, and showrunners, with Jeph Loeb also attached as executive producer.[305] The series would still focus on Morse and Hunter, with Palicki and Blood both attached, and was described as \\"a new take focusing on the same duo and their continuing adventures.\\"[304] In May 2016, the series was passed on by ABC once again.[306]","input":"What came first luke cage or jessica jones?"},{"output":"eastern gorilla","context":"\\r\\n\\r\\nThe mountain gorilla (Gorilla beringei beringei) is one of the two subspecies of the eastern gorilla. The subspecies is listed as critically endangered by the IUCN, with only two surviving populations. One is found in the Virunga Mountains of Central Africa in three bordering national parks: Mgahinga Gorilla National Park in Uganda, Volcanoes National Park in Rwanda, and Virunga National Park in the Democratic Republic of Congo (DRC). The other population is found in Uganda's Bwindi Impenetrable National Park. A count in 2018 put the mountain gorilla population at just over 1,000.[3]\\r\\n\\r\\nMountain gorillas are descendants of ancestral monkeys and apes found in Africa and Arabia during the start of the Oligocene epoch (34-24 million years ago). The fossil record provides evidence of the hominoid primates (apes) found in east Africa about 22ÿ32 million years ago. The fossil record of the area where mountain gorillas live is particularly poor and so its evolutionary history is not clear.[4]\\r\\nIt was about 9 million years ago that the group of primates that were to evolve into gorillas split from their common ancestor with humans and chimps; this is when the genus Gorilla emerged. It is not certain what this early relative of the gorilla was, but it is traced back to the early ape Proconsul africanus.[5] Mountain gorillas have been isolated from eastern lowland gorillas for about 400,000 years and these two taxa separated from their western counterparts approximately 2 million years ago.[6] There has been considerable and as yet unresolved debate over the classification of mountain gorillas. The genus was first referenced as Troglodytes in 1847, but renamed to Gorilla in 1852. It was not until 1967 that the taxonomist Colin Groves proposed that all gorillas be regarded as one species (Gorilla gorilla) with three sub-species Gorilla gorilla gorilla (western lowland gorilla), Gorilla gorilla graueri (eastern lowland gorilla) and Gorilla gorilla beringei (mountain gorilla). Following a review in 2003, they were divided into two species (Gorilla gorilla and Gorilla beringei) by The World Conservation Union (IUCN).[4]\\r\\n\\r\\nSome primatologists[who?] speculate the Bwindi population in Uganda is a separate subspecies,[citation needed] though no description has been finalized.\\r\\n\\r\\nThe fur of the mountain gorilla, often thicker and longer than that of other gorilla species, enables them to live in colder temperatures.[7] Gorillas can be identified by nose prints unique to each individual.[8] \\r\\nMales, at a mean weight of 195?kg (430?lb) upright standing height of 168?cm (66?in) usually weigh twice as much as the females, at a mean of 100?kg (220?lb) and a height of 140?cm (55?in).[9] This subspecies is smaller than the eastern lowland gorilla, the other subspecies of eastern gorilla. Adult males have more pronounced bony crests on the very top and back of their skulls, giving their heads a more conical shape. These crests anchor the powerful temporalis muscles, which attach to the lower jaw (mandible). Adult females also have these crests, but they are less pronounced.[8] Like all gorillas they feature dark brown eyes framed by a black ring around the iris.\\r\\nAdult males are called silverbacks because a saddle of gray or silver-colored hair develops on their backs with age. The hair on their backs is shorter than on most other body parts, and their arm hair is especially long.The tallest silverback recorded was a 1.95?m (6?ft 5?in) with an arm span of 2.7?m (8?ft 10?in), a chest of 1.98?m (6?ft 6?in), and a weight of 219?kg (483?lb), shot in Alimbongo, northern Kivu in May 1938. There is an unconfirmed record of another individual, shot in 1932, that was 2.06?m (6?ft 9?in) and weighed 218.6?kg (482?lb). The heaviest silverback recorded was a 1.83?m (6?ft 0?in) shot in Ambam, Cameroon, which weighed 267?kg (589?lb).[10]\\r\\n\\r\\nThe mountain gorilla is primarily terrestrial and quadrupedal. However, it will climb into fruiting trees if the branches can carry its weight, and it is capable of running bipedally up to 6?m (20?ft).[citation needed] Like all great apes other than humans, its arms are longer than its legs. It moves by knuckle-walking (like the common chimpanzee, but unlike the bonobo and both orangutan species), supporting its weight on the backs of its curved fingers rather than its palms.[citation needed]\\r\\n\\r\\nThe mountain gorilla is diurnal, most active between 6:00?a.m. and 6:00?p.m.[citation needed] Many of these hours are spent eating, as large quantities of food are needed to sustain its massive bulk. It forages in early morning, rests during the late morning and around midday, and in the afternoon it forages again before resting at night. Each gorilla builds a nest from surrounding vegetation to sleep in, constructing a new one every evening. Only infants sleep in the same nest as their mothers. They leave their sleeping sites when the sun rises at around 6 am, except when it is cold and overcast; then they often stay longer in their nests.[11]\\r\\n\\r\\nThe mountain gorilla inhabits the Albertine Rift montane cloud forests and of the Virunga Volcanoes, ranging in altitude from 2,200ÿ4,300 metres (7,200ÿ14,100?ft).  Most are found on the slopes of three of the dormant volcanoes: Karisimbi, Mikeno, and Visoke.[12] The vegetation is very dense at the bottom of the mountains, becoming more sparse at higher elevations, and the forests where the mountain gorilla lives are often cloudy, misty and cold.[13]\\r\\n\\r\\nThe mountain gorilla is primarily a herbivore; the majority of its diet is composed of the leaves, shoots and stems (85.8%) of 142 plant species. It also feeds on bark (6.9%), roots (3.3%), flowers (2.3%), and fruit (1.7%), as well as small invertebrates. (0.1%).[14] Adult males can eat up to 34 kilograms (75?lb) of vegetation a day, while a female can eat as much as 18 kilograms (40?lb).[citation needed]\\r\\n\\r\\nThe home range size (the area used by one group of gorillas during one year) is influenced by availability of food sources and usually includes several vegetation zones. George Schaller identified ten distinct zones, including: the bamboo forests at 2,200ÿ2,800 metres (7,200ÿ9,200?ft); the Hagenia forests at 2,800ÿ3,400 metres (9,200ÿ11,200?ft); and the giant senecio zone at 3,400ÿ4,300 metres (11,200ÿ14,100?ft).[11] The mountain gorilla spends most of its time in the Hagenia forests, where galium vines are found year-round. All parts of this vine are consumed: leaves, stems, flowers, and berries. It travels to the bamboo forests during the few months of the year fresh shoots are available, and it climbs into subalpine regions to eat the soft centers of giant senecio trees.[12]\\r\\n\\r\\nThe mountain gorilla is highly social, and lives in relatively stable, cohesive groups held together by long-term bonds between adult males and females. Relationships among females are relatively weak.[15] These groups are nonterritorial; the silverback generally defends his group rather than his territory. In the Virunga mountain gorillas, the average length of tenure for a dominant silverback is 4.7 years.[16]\\r\\n\\r\\nSilverback with female\\r\\n\\r\\nTwo-year-olds, Mubare Group, Uganda\\r\\n\\r\\n10-month-old babyTitus Group, Rwanda\\r\\n\\r\\n10-month-old babyTitus Group, Rwanda\\r\\n\\r\\n61% of groups are composed of one adult male and a number of females and 36% contain more than one adult male. The remaining gorillas are either lone males or exclusively male groups, usually made up of one mature male and a few younger males.[17] Group sizes vary from five to thirty, with an average of ten individuals. A typical group contains: one dominant silverback, who is the group's undisputed leader; another subordinate silverback (usually a younger brother, half-brother, or even an adult son of the dominant silverback); one or two blackbacks, who act as sentries; three to four sexually mature females, who are ordinarily bonded to the dominant silverback for life; and from three to six juveniles and infants.[18]\\r\\n\\r\\nMost males, and about 60% of females, leave their natal group. Males leave when they are about 11 years old, and often the separation process is slow: they spend more and more time on the edge of the group until they leave altogether.[19] They may travel alone or with an all-male group for 2ÿ5 years before they can attract females to join them and form a new group. Females typically emigrate when they are about 8 years old, either transferring directly to an established group or beginning a new one with a lone male. Females often transfer to a new group several times before they settle down with a certain silverback male.[20]\\r\\n\\r\\nThe dominant silverback generally determines the movements of the group, leading it to appropriate feeding sites throughout the year. He also mediates conflicts within the group and protects it from external threats.[13] When the group is attacked by humans, leopards, or other gorillas, the silverback will protect them even at the cost of his own life.[21] He is the center of attention during rest sessions, and young gorillas frequently stay close to him and include him in their games. If a mother dies or leaves the group, the silverback is usually the one who looks after her abandoned offspring, even allowing them to sleep in his nest.[22] Experienced silverbacks are capable of removing poachers' snares from the hands or feet of their group members.[23]\\r\\n\\r\\nWhen the silverback dies or is killed by disease, accident, or poachers, the family group may be disrupted.[12] Unless there is an accepted male descendant capable of taking over his position, the group will either split up or adopt an unrelated male. When a new silverback joins the family group, he may kill all of the infants of the dead silverback.[24] Infanticide has not been observed in stable groups.\\r\\n\\r\\nAnalysis of mountain gorilla genomes by whole genome sequencing indicates that a recent decline in their population size has led to extensive inbreeding.[25]  As an apparent result, individuals are typically homozygous for 34% of their genome sequence.  Furthermore, homozygosity and the expression of deleterious recessive mutations as consequences of inbreeding have likely resulted in the purging of severely deleterious mutations from the population.\\r\\n\\r\\nAlthough strong and powerful, the mountain gorillas are generally gentle and very shy.[21] Severe aggression is rare in stable groups, but when two mountain gorilla groups meet, the two silverbacks can sometimes engage in a fight to the death, using their canines to cause deep, gaping injuries.[18] For this reason, conflicts are most often resolved by displays and other threat behaviors that are intended to intimidate without becoming physical. The ritualized charge display is unique to gorillas. The entire sequence has nine steps: (1) progressively quickening hooting, (2) symbolic feeding, (3) rising bipedally, (4) throwing vegetation, (5) chest-beating with cupped hands, (6) one leg kick, (7) sideways running four-legged, (8) slapping and tearing vegetation, and (9) thumping the ground with palms .[26] Jill Donisthorpe stated that a male charged at her twice. In both cases the gorilla turned away, when she stood her ground.[27]\\r\\n\\r\\nThe midday rest period is an important time for establishing and reinforcing relationships within the group. Mutual grooming reinforces social bonds, and helps keep hair free from dirt and parasites. It is not as common among gorillas as in other primates, although females groom their offspring regularly. Young gorillas play often and are more arboreal than the large adults. Playing helps them learn how to communicate and behave within the group. Activities include wrestling, chasing, and somersaults. The silverback and his females tolerate and even participate if encouraged.[citation needed]\\r\\n\\r\\nTwenty-five distinct vocalizations are recognized, many of which are used primarily for group communication within dense vegetation. Sounds classified as grunts and barks are heard most frequently while traveling, and indicate the whereabouts of individual group members.[28] They may also be used during social interactions when discipline is required. Screams and roars signal alarm or warning, and are produced most often by silverbacks. Deep, rumbling belches suggest contentment and are heard frequently during feeding and resting periods. They are the most common form of intragroup communication.[18]\\r\\n\\r\\nFor reasons unknown, mountain gorillas that have been studied appear to be naturally afraid of certain reptiles and insects. Infants, whose natural behavior is to chase anything that moves, will go out of their way to avoid chameleons and caterpillars. They are also afraid of water and will cross streams only if they can do so without getting wet, such as by crossing over fallen logs. The mountain gorilla's dislike of rain has been observed and noted, as well.[29]\\r\\n\\r\\nIn October 1902, Captain Robert von Beringe (1865ÿ1940) shot two large apes during an expedition to establish the boundaries of German East Africa.[11] One of the apes was recovered and sent to the Berlin Zoological Museum, where Professor Paul Matschie (1861ÿ1926) classified the animal as a new form of gorilla and named it Gorilla beringei after the man who discovered it.[23] In 1925 Carl Akeley, a hunter from the American Museum of Natural History who wished to study the gorillas, convinced Albert I of Belgium to establish the Albert National Park to protect the animals of the Virunga mountains.[30]\\r\\n\\r\\nGeorge Schaller began his 20-month observation of the mountain gorillas in 1959, subsequently publishing two books: The Mountain Gorilla and The Year of the Gorilla. Little was known about the life of the mountain gorilla before his research, which described its social organization, life history, and ecology.[30] Following Schaller, Dian Fossey began what would become an 18-year study in 1967. Fossey made new observations, completed the first accurate census, and established active conservation practices, such as anti-poaching patrols.[18] The Digit Fund, which Fossey started, continued her work and was later renamed the Dian Fossey Gorilla Fund International. The Fund's Karisoke Research Center monitors and protects the mountain gorillas of the Virungas. Close monitoring and research of the Bwindi mountain gorillas began in the 1990s.[31]\\r\\n\\r\\nConservation efforts have led to an increase in overall population of the mountain gorilla (Gorilla beringei beringei) in the Virungas and at Bwindi. The overall population is now believed to be at least 880 individuals.[32] Three more ÿ infants who suffered a traumatic poaching experience, injuries from snares, and/or losing their mothers in brutal killings ÿ are currently in care of the Senkwekwe Centre orphanage in the DR of Congo.[33]\\r\\n\\r\\nIn December 2010 the official website of Virunga National Park announced that \\"the number of mountain gorillas living in the tri-national forested area of which Virunga forms a part, has increased by 26.3% over the last seven years - an average growth rate of 3.7% per annum.\\"[34] The 2010 census estimated that 480 mountain gorillas inhabited the region.  The 2003 census had estimated the Virunga gorilla population to be 380 individuals; which represented a 17% increase in the total population since 1989 when there were 320 individuals.[35] The population has almost doubled since its lowest point in 1981, when a census estimated that only 254 gorillas remained.[36]\\r\\n\\r\\nThe 2006 census at Bwindi indicated a population of 340 gorillas, representing a 6% increase in total population size since 2002 and a 12% increase from 320 individuals in 1997.[37] All of those estimates were based on traditional census methods using dung samples collected at night nests.  Conversely, genetic analyses of the entire population during the 2006 census indicated there were only approximately 300 individuals in Bwindi.[2]  The discrepancy highlights the difficulty in using imprecise census data to estimate population growth.\\r\\n\\r\\nIn both Bwindi and the Virungas, groups of gorillas that were habituated for research and ecotourism have higher growth rates than unhabituated gorillas, according to computer modeling of their population dynamics.[31][38]  Habituation means that through repeated, neutral contact with humans, gorillas exhibit normal behavior when people are in proximity.  Habituated gorillas are more closely guarded by field staff and they receive veterinary treatment for snares, respiratory disease, and other life-threatening conditions.[38]  Nonetheless, researchers recommended that some gorillas remain unhabituated as a bet-hedging strategy against the risk of human pathogens being transmitted throughout the population.[38]\\r\\n\\r\\nDespite their recent population growth, the mountain gorilla remains threatened. As of 2008, mountain gorillas were listed as Critically Endangered on the IUCN Red List and are dependent on conservation efforts to survive.[2]\\r\\n\\r\\nKarisoke Research centre has:\\r\\n\\r\\nPoaching:  Mountain gorillas are not usually hunted for bushmeat, but they are frequently maimed or killed by traps and snares intended for other animals.  They have been killed for their heads, hands, and feet, which are sold to collectors. Infants are sold to zoos, researchers, and people who want them as pets.  The abduction of infants generally involves the loss of at least one adult, as members of a group will fight to the death to protect their young. The Virunga gorillas are particularly susceptible to animal trafficking for the illegal pet trade. With young gorillas worth from $1000 to $5000 on the black market, poachers seeking infant and juvenile specimens will kill and wound other members of the group in the process.[39] Those of the group that survive often disband. One well documented case was that known as the Taiping 4. In this situation, a Malaysian Zoo received four wild-born infant gorillas from Nigeria at a cost of US$1.6 million using falsified export documents.[40][41]\\r\\nPoaching for meat is also particularly threatening in regions of political unrest.  Most of the African great apes survive in areas of chronic insecurity, where there is a breakdown of law and order. The killing of mountain gorillas at Bikenge in Virunga National Park in January 2007 was a well documented case.\\r\\n\\r\\nHabitat loss:  This is one of the most severe threats to gorilla populations. The forests where mountain gorillas live are surrounded by rapidly increasing human settlement. Through shifting (slash-and-burn) agriculture, pastoral expansion and logging, villages in forest zones cause fragmentation and degradation of habitat.[42] The late 1960s saw the Virunga Conservation Area (VCA) of Rwandas national park reduced by more than half of its original size to support the cultivation of Pyrethrum. This led to a massive reduction in mountain gorilla population numbers by the mid-1970s.[43] The resulting deforestation confines the gorillas to isolated deserts. Some groups may raid crops for food, creating further animosity and retaliation. \\r\\nThe impact of habitat loss extends beyond the reduction of suitable living space for gorillas. As gorilla groups are increasingly geographically isolated from one another due to human settlements, the genetic diversity of each group is reduced.[44] Some signs of inbreeding are already appearing in younger gorillas, including webbed hands and feet.[45]\\r\\n\\r\\nDisease: Despite the protection garnered from being located in national parks, the mountain gorilla is also at risk from people of a more well-meaning nature. Groups subjected to regular visits from tourists and locals are at a continued risk of disease cross-transmission (Lilly et al., 2002) ÿ this is in spite of attempts to enforce a rule that humans and gorillas be separated by a distance of 7 metres at all times to prevent this.[38]\\r\\nWith a similar genetic makeup to humans and an immune system that has not evolved to cope with human disease, this poses a serious conservation threat.[46] Indeed, according to some researchers, infectious diseases (predominantly respiratory) are responsible for about 20% of sudden deaths in mountain gorilla populations.[47]\\r\\nWith the implementation of a successful ecotourism program in which human-gorilla interaction was minimised, during the period of 1989ÿ2000 four sub-populations in Rwanda experienced an increase of 76%.  By contrast, seven of the commonly visited sub-populations in the Democratic Republic of Congo (DRC) saw a decline of almost 20% over only four years (1996ÿ2000).[48] From this, we[who?] can conclude that the negative impacts of ecotourism on gorilla health can be minimised if proper management is undertaken.\\r\\n\\r\\nThe risk of disease transmission is not limited to those of a human origin; pathogens from domestic animals and livestock through contaminated water are also a concern.[49] Studies have found that water borne, gastrointestinal parasites such as Cryptosporidium sp., Microsporidia sp.,and Giardia sp. are genetically identical when found in livestock, humans, and gorillas; particularly along theborder of the Bwindi Impenetrable Forest, Uganda.[50][51] Another example of human induced disease is Tuberculosis; Kabagambe et al.[39] found that as high as 11% of cattle in Rwanda suffered from this affliction.\\r\\n\\r\\nWar and civil unrest: Rwanda, Uganda and the Democratic Republic of Congo have been politically unstable and beleaguered by war and civil unrest over the last decades. Simulation modeling, Byers et al. (2003) has suggested that times of war and unrest have negative impacts on the habitat and populations of mountain gorillas.[52] For example, events such as 1994s Rwanda genocide would take place approximately every 30 years, with each event lasting for 10 years. Due to the increase in human encounters, aggressive and passive alike, this would result in a rise in mortality rates and a decrease in reproductive success.[42] \\r\\nMore direct impacts from conflict can also be seen.  Kanyamibwa notes that there were reports that mines were placed along trails in the Volcanos National Park, and that many gorillas were killed as a result.[53] Pressure from habitat destruction in the form of logging also increased as refugees fled the cities and cut down trees for wood.[53] During the Rwandan genocide, some poaching activity was also linked to the general breakdown of law and order and lack of any ramifications.[54]\\r\\n\\r\\nThe main International Non-Government Organization involved in conservation of mountain gorillas is the International Gorilla Conservation Programme, which was established in 1991 as a joint effort of the African Wildlife Foundation, Fauna & Flora International and the World Wide Fund for Nature.[55] Conservation requires work at many levels, from local to international, and involves protection and law enforcement as well as research and education.  Dian Fossey broke down conservation efforts into the following three categories:\\r\\n\\r\\nActive conservation includes frequent patrols in wildlife areas to destroy poacher equipment and weapons, firm and prompt law enforcement, census counts in regions of breeding and ranging concentration, and strong safeguards for the limited habitat the animals occupy.\\"\\r\\n\\r\\nTheoretical conservation seeks to encourage growth in tourism by improving existing roads that circle the mountains, by renovating the park headquarters and tourists' lodging, and by the habituation of gorillas near the park boundaries for tourists to visit and photograph.\\"\\r\\n\\r\\nCommunity-based conservation management involves biodiversity protection by, for, and with the local community[56] in practise this is applied in varying degrees. The process seeks equity between meeting the needs of the local population and preserving the protected areas and involves local people in decision making processes.\\r\\n\\r\\nA collaborative management process has had some success in the Bwindi National Park. The forest was gazetted to National Park in 1991; this occurred with little community consultation and the new status prohibited local people from accessing resources within the park as well as reduced economic opportunities. Subsequently, a number of forest fires were deliberately lit and threats were made to the gorillas.[57]  To counteract this, three schemes to provide benefits from existence of the forest communities and involve the local community in park management were developed. They included agreements allowing the controlled harvesting of resources in the park, receipt of some revenue from tourism and establishment of a trust fund partly for community development. Tension between people and park have been reduced[57] and now there is more willingness to take part in gorilla protection.[58] Surveys of community attitudes conducted by CARE show a steadily increasing proportion of the people in favour of the park. More than that there have been no cases of deliberate burning and the problem of snares in these areas has been reduced.[58]\\r\\nThe introduction of ceremonies such as Kwita Izina (in 2005) has also had some impact in drawing attention to gorilla preservation and its importance to local communities.\\r\\n\\r\\nWhile community-based conservation bears out individual analysis, there are significant overlaps between active and theoretical conservation and a discussion of the two as halves of a whole seems more constructive.  For example, in 2002 Rwanda's national parks went through a restructuring process. The director of the IGCP, Eugene Rutagarama stated that \\"They got more rangers on better salaries, more radios, more patrol cars and better training in wildlife conservation. They also built more shelters in the park, from which rangers could protect the gorillas\\".[59]  The funding for these types of improvements usually comes from tourism - in 2008, approximately 20 000 tourists visited gorilla populations in Rwanda, generating around $8 million in revenue for the parks.[38]  In Uganda too, tourism is seen as a \\"high value activity that generates enough revenue to cover park management costs and contribute to the national budget of the Uganda Wildlife Authority.\\"[60]  Furthermore, tourist visits which are conducted by park rangers also allow censuses of gorilla sub-populations to be undertaken concurrently.[31]\\r\\n\\r\\nIn addition to tourism, other measures for conservation of the sub-population can be taken such as ensuring connecting corridors between isolated areas to make movement between them easier and safer.[61]\\r\\n\\r\\n[1] Meeting the Mountain Gorillas at the Volcanoes National Park in Rwanda","input":"What type of animal is a mountain gorilla?"},{"output":"a revolution in firepower was not matched by similar advances in mobility","context":"","input":"What caused trench warfare in world war 1?"},{"output":"a total of 2,430 games, plus the postseason","context":"The Major League Baseball (MLB) season schedule consists of 162 games for each of the 30 teams in the American League (AL) and National League (NL), played over approximately six monthsa total of 2,430 games, plus the postseason. The regular season runs from late March/early April to late September/early October, followed by the postseason which can run to early November. The season begins with the official Opening Day, and, as of 2018, runs 26? weeks through the last Sunday of September or first Sunday of October. One or more International Opener games may be scheduled outside the United States before the official Opening Day.[1] It is possible for a given team to play a maximum of 20 games in the postseason in a given year, provided the team is a wild card and advances to each of the Division Series, Championship Series, and World Series with each series going the distance (5 games in the Division Series, 7 games in the League Championship Series/World Series).\\r\\nThe regular season is constructed from series. Due to travel concerns and the sheer number of games, pairs of teams are never scheduled to play single games against each other (except in the instance of making up a postponed game); instead they play games on several consecutive days in the same ballpark. Most often the series are of three or four games, but two-game series are also scheduled. Teams play one mid-week series and one weekend series per week. Depending on the length of the series, mid-week series games are usually scheduled between Monday and Thursday, while weekend games are scheduled between Thursday and Monday. Beginning in 2018, teams start and end their season on a weekend for a total of 26? weeks. Due to the mid-week all-star break in July, teams are scheduled to play 27 weekend series and 25 mid-week series for a total of 52 series (24 divisional series, 20 inter-divisional series, 8 inter-league series). A team's road games are usually grouped into a multi-series road trip; home series are grouped into homestands.\\r\\nNote that rainouts and other cancellations are often rescheduled ad hoc during the season, sometimes as doubleheaders. However, if two teams are scheduled to meet for the final time in the last two weeks of the season, and the game is cancelled, it may not be rescheduled if there's no impact on the divisional or wild card races. For example, in 2016, the September 29 game between the Cleveland Indians and Detroit Tigers was cancelled due to rain because the teams were unable to reschedule a make-up date before the end of the season on October 2, and it didn't affect the divisional race. In contrast, a 2008 AL Central division game between Detroit and the Chicago White Sox needed to be made up following the last day of the regular season because it affected a division race involving the White Sox and the Minnesota Twins.\\r\\n\\r\\n\\r\\nThis account gives the length of the major league \\"championship season\\" schedule by league and year. It does not cover the curtailment of play by war (1918) or by strikes and lockouts (1972, 1981, 1994). The schedules for 1995 were revised and shortened from 162 to 144 games, after late resolution of the strike that had begun in 1994 required a delay in the season to accommodate limited spring training.\\r\\nThe listed years are those in which the league revised its schedule. For example, the National League (NL) scheduled 84 games during 1879, 1880, 1881, and 1882 ÿ that is, four seasons from 1879, ending before 1883, the next listing. 1876 is listed here for convenience although the NL did not schedule games (see 1871 to 1876, below).\\r\\n1882 ÿ 1891\\r\\nThus the AA expanded its schedule to 140 games two years before the National League did so. After 1891 four AA clubs joined the NL and four were bought out, nominally creating one big league, the \\"National League and American Association\\" of 12 clubs.\\r\\n1884\\r\\n1890\\r\\n1914: 1915\\r\\nThe National Association of Professional Base Ball Players (1871ÿ1875) did not schedule games, nor did it control the number of teams, a major reason for its demise after the 1875 season. Clubs paid a $10 entry fee, later $20, to enter the Association for one season, and thereby declare for that year's national championship. Without continuing membership or heavy investment, there was little to deter a team from breaking a commitment, and though it happened, it was mainly due to clubs going out of business.\\r\\nThe National League organized for 1876 on a different basis, granting exclusive memberships to eight clubs that would continue from year to year  it was generally expected, if only because membership would be profitable. But the new league followed its predecessor in merely agreeing that each club would play a certain number of matches to a decision (excluding ties) by a certain date. Boston played 70 games with its quota of ten decisions against every rival. The others achieved 56 to 68 decisions, 64 to 66 for the four western teams as the teams from New York and Philadelphia (eastern) abandoned their schedule-concluding road trips.\\r\\nFor all six early seasons, prior to the first league schedule in 1877, member clubs scheduled their own matches by mutual arrangement, including championship games necessarily with member clubs, other games with members, and games with non-member clubs. Some may have practically dictated their arrangements with some others, but there was no central control or coordination.\\r\\nThis listing gives the greatest number of games played by any club for each season. Naturally, the leader by games played was always a strong club fielding one of the better gate attractions.\\r\\nThe leading numbers of games played to a decision were 33, 54, 59, 71, 82, and 70 decisions; by the listed teams except the Mutuals in 1872.\\r\\nSince 1998, there have been 30 major league teams with a single advance schedule for every season that comprises 2430 games. Each team plays 162 games, 81 as the \\"home\\" team, 81 as the \\"visitor\\". (This is true even on the rare occasion when a game is played at a ballpark not home to either team.) Occasionally, the advance schedule is subsequently altered due to a game postponement or a one-game tie-breaker to determine which team will play in the postseason.\\r\\nBefore 2013 the schedule included 252 \\"interleague games\\" that matched one team from the American League and one from the National League; the other 2178 games matched a pair from within one league. About half of the latter matched teams from within one division and about half matched teams from different divisions in one league. In the Central Division of the National League, which alone had six teams, every pair of division rivals played 15 or 16 games. Within the other, smaller divisions every pair of teams played 18 or 19 games.\\r\\nDivision games (1091). There are 61 pairs of teams from within one division.\\r\\nOther intraleague games (1087). There are 150 pairs of teams from two different divisions within one league.\\r\\nThe schedule for interleague play comprised 84 three-game series in each season from 1998 to 2012, divided as six series (18 games) for each of fourteen AL teams and as many as six for each of sixteen NL teams.\\r\\nAmong the 224 interleague pairs of teams, 11 played six games every year, which were scheduled in two three-game series \\"home and home\\", or one at each home ballpark. Five of these 11 special arrangements matched two teams in the same city or in neighboring cities, where they wholly or partly share territorial rights. Six were regional matches at greater distance, four of which were in the same state.\\r\\nThese special local and regional series accounted for 66 interleague games annually from 1998-2012, and the other 186 games were determined by rotation.\\r\\nThe 2001 season was suspended for one week due to the September 11 terrorist attacks and resulting disruptions in travel, resulting in games scheduled for September 11ÿ16 being rescheduled to the first week of October and the playoffs and World Series being rescheduled one week later than their originally planned dates, which resulted in the World Series continuing into early November.\\r\\nSchedule changes for 2013, precipitated by realignment that created two equal-sized leagues of 15 teams each, gave every team 20 interleague games.[2] Sixteen of which were determined by a match of divisions, one from each league; all teams in a given division play all teams in a given division from the other league. (Each plays a three-game series against four teams from the designated division and two two-game series against the remaining team.)\\r\\nThe matched divisions rotate annually:\\r\\nEach team played its four other interleague games against a designated \\"natural rival\\", with two games in each club's city. Thus all 30 teams, rather than 22 of 30 as previously, were deemed to have a natural rival in the other league. In 2013 the natural rivalry games were all scheduled for May 27 to May 30 (Memorial Day weekend) but in 2014 their scheduled dates range from May to August.\\r\\nTen of the natural rivalries from 2012 and earlier continued, while the HoustonÿTexas \\"Lone Star\\" rivalry had been transformed into an intra-division one with 19 games played. Five of the special arrangements were new in 2013 , including one each for Houston and Texas.\\r\\nFor 2014, four (4) of the five (5) new rivalries have been revised (?), all except Detroit and Pittsburgh.\\r\\nEvery team now plays 19 games against each of 4 opponents within its division (76 games), and 6 or 7 games against each of 10 opponents from other divisions within its own league (66 games).\\r\\nWhen corresponding divisions (i.e. NL East vs. AL East) play each other, a slight adjustment was made to the interleague games. Teams now play 6 games against their rival and 4 games (home and home) against two opponents plus one home and one away 3 game series (14 total) against the other four teams in the opposing division. This was done in 2015, and will next occur in 2018.\\r\\nUnder the new collective bargaining agreement reached in December 2016, several changes were done to the scheduling pattern for the 2018 season. The overall length of the season has been extended to 187 days with the addition of four off-days for all teams. All teams will play on Opening Day, which for 2018 will be held on March 29. Sunday Night Baseball will no longer be played on the final Sunday before the All-Star Game, in order to ease travel time for those who are participating in the Home Run Derby. A single, nationally-televised afternoon game will be played the following Thursday, with all other teams returning to play on Friday.[3][4]\\r\\nStart of Major League Baseball games depends on days of the week, game number in series, holidays, and other factors. Most games start at 7pm in the local time zone, so there are more night games than day games even though baseball is traditionally played during the day. The reason why there are more night baseball games is to attract more fans to ballparks as well as viewers from home because most fans would be at work or school during the day. On Mondays (excluding Opening Day and holidays), Tuesdays, and Fridays, games are almost exclusively played at night except for Cubs home games. Getaway days, days on which teams play their last game of the series before departing for another series in another city the next day, are usually day games, mainly Sundays, Wednesdays, and Thursdays. On Sundays, usually all but one are day games, with the final game reserved for ESPN's Sunday Night Baseball.\\r\\nAbout half of Saturday games are day games (1, 2 or 4pm ET). In some markets, Saturday night start an hour earlier than usual night start times, but other cities start Saturday night games at the same time as weeknight games. In conclusion, weekday games are only played at night except for getaway days while many weekend games are played during the day.\\r\\nThe initial pitch typically occurs 5 or 10 minutes after the hour, in order to allow time for pre-game ceremonies.","input":"How many games are in major league baseball season?"},{"output":"Louisa \\"Ouiser\\" Boudreaux","context":"Steel Magnolias is a 1989 American comedy-drama film directed by Herbert Ross. It is a film adaptation of Robert Harling's 1987 play of the same name. The play and film are about the bond a group of women share in a small-town Southern community, and how they cope with the death of one of their own.\\r\\nThe story is based on Robert Harling's real life experience of the death of his sister, Susan Harling Robinson, in 1985 due to complications from Type 1 diabetes. He changed his sister's name in the story from Susan to Shelby Eatenton-Latcherie.\\r\\nThe title suggests the main female characters can be both as delicate as the magnolia flower, and as tough as steel.[3]\\r\\n\\r\\n\\r\\nAnnelle Dupuy, a reserved beauty school graduate, is hired by Truvy Jones to work in her home-based beauty salon in northwestern Louisiana. At the same time, in another part of the neighborhood, M'Lynn Eatenton, and her daughter, Shelby, are preparing for Shelby's wedding, which is taking place later that day. They arrive, along with Clairee Belcher, the cheerful widow of the former mayor, to have their hair done. Suddenly, Shelby, who has type 1 diabetes, falls into a hypoglycemic state, but recovers quickly with the help of her mother's quick thinking. Later that afternoon, short-tempered, grouchy, and sarcastic Louisa \\"Ouiser\\" Boudreaux arrives in the salon and questions Annelle about where she has moved from, forcing Annelle to reveal that her husband has recently left her while fleeing the police, taking all their money and their car. Moved by Annelle's emotional confession, Shelby invites her to the wedding, where Annelle meets Sammy, who is tending bar.\\r\\nSeveral months pass and Shelby returns to town to celebrate Christmas. During the festivities, she announces that she and her husband, Jackson Latcherie, are expecting their first child. Shelby's father Drum is thrilled, but M'Lynn is too worried to share in the joy. Truvy, Annelle, and Clairee had originally thought that Shelby couldn't have children, but on the night of the big announcement, M'Lynn clarifies for them that the doctors said Shelby shouldn't have children because of her health. It becomes clear that Shelby could actually die due to pregnancy complications related to her diabetes. Unable to give her any words of wisdom, Truvy suggests they focus on the joy of the situation: Jackson and Shelby's first child, as well as Drum and M'Lynn's first grandchild, as well as their sons, Jonathan and Tommy's, first niece or nephew. M'Lynn agrees, saying that nothing pleases Shelby more than proving her wrong.\\r\\nShelby successfully delivers a baby boy, Jackson Jr., but begins showing signs of kidney failure and starts dialysis around the time Jackson Jr. turns one. M'Lynn successfully donates a kidney and Shelby seemingly resumes a normal life. Clairee and Ouiser offer to make sure that M'Lynn's husband, Drum, Jonathan, and Tommy have enough food to last until M'Lynn returns home after the transplant. Later, on Halloween, Ouiser, Clairee, Truvy, and M'Lynn throw Annelle a surprise wedding shower, as she is now engaged to Sammy. Shelby is unavailable to attend due to a conflicting schedule with her nursing job, and is later found by Jackson unconscious on the porch of her house. Shelby is rushed to the hospital, where it is determined that her body rejected the new kidney, and she is now in a coma. The doctors inform the family that Shelby is likely to remain comatose indefinitely, and they all jointly decide to take her off life support. At the funeral, after the other mourners have left, M'Lynn breaks down in hysterics in front of Ouiser, Clairee, Truvy, and Annelle, but is comforted by them.\\r\\nLater, at the wake, M'Lynn begins to accept her daughter's death and focuses her energy on helping Jackson raise Jackson Jr. Annelle, now married and pregnant, asks M'Lynn if she could name her own baby after Shelby, since Shelby was the reason Annelle and Sammy met. M'Lynn gives her blessings and assures Annelle that Shelby would've loved it. Months later, on Easter morning, Annelle goes into labor during an Easter egg hunt, is rushed to the hospital by Truvy and her husband Spud, and another life begins.\\r\\nThe original play dramatized experiences of the family and friends of the play's author following the 1985 death of his sister from diabetic complications after the birth of his namesake nephew and the failure of a family member's donated kidney. A writer friend continuously encouraged him to write it down in order to come to terms with the experience. He did but originally as a short story for his nephew then later to get an understanding of the deceased mother. It evolved in ten days into the play.[4][5]\\r\\nReleased by TriStar Pictures in the United States on November 15, 1989 and grossed more than $83.7?million at the box office. Harling's first produced screenplay, he adapted the original film script which was then heavily rewritten beyond the on-stage one-set scenario (which had taken place entirely in Truvy's beauty salon) of the stage production: the scenes increased and the sequence was more tightly linked with major holidays than the play; the increased characters beyond the original, all-female play cast caused dialogue changes between on-screen characters (among them, Harling playing the preacher and Truvy has one son instead of two). Natchitoches, Louisiana served as both the 1989 film location and scenario location[6] with historian Robert DeBlieux, a former Natchitoches mayor, as the local advisor.[7]\\r\\nIt received generally positive reviews from critics and has a score of 69% on Rotten Tomatoes.[8] An example of a less enthusiastic critic was Hal Hinson of The Washington Post, who said that it felt, \\"more Hollywood than the South.\\"[9] More enthusiastic was Roger Ebert, who said that the film was, \\"willing to sacrifice its over-all impact for individual moments of humor, and while that leaves us without much to take home, you've got to hand it to them: The moments work.\\"[10][11]\\r\\nThe movie received a limited release on November 15, 1989: entered the U.S. box office at No. 4 with an opening weekend gross of $5,425,440; by the time of wider release two days later it grossed $15,643,935; stayed in the top 10 for 16 weeks, gross $83,759,091 domestically with a further $12,145,000 with foreign markets giving a worldwide gross of $95,904,091.[12]\\r\\nThe film was released on VHS on June 19, 1990 and on DVD July 25, 2000, allowing the film to gross a further $40?million.[13][14] The movie's overall gross was $135,904,091. The film was released on Blu-ray through the boutique label Twilight Time, on September 11, 2012ÿit has since gone out of print.\\r\\nCBS broadcast on August 17, 1990, a half-hour television pilot sitcom sans Shelby's character as the story line was post death. The cast included Cindy Williams as M'Lynn, Sally Kirkland as Truvy, Elaine Stritch as Ouiser, Polly Bergen as Clairee and Sheila McCarthy as Annelle.\\r\\nLifetime Television Network announced (October 10, 2011) a planned remake under the direction of Kenny Leon, director of the ABC movie A Raisin in the Sun (2008), set in Louisiana[15] featuring lead role black actors: Queen Latifah (M'Lynn), Jill Scott (Truvy), Alfre Woodard (Ouiser), Phylicia Rashd (Clairee), Adepero Oduye (Annelle) and Condola Rashd (Shelby).[16][17] The New York Times had mixed reactions: applauded it on some points and on others as either schmaltz or less attentive than the 1989 film.[18]","input":"Who did shirley maclaine play in steel magnolias?"},{"output":"igneous rock","context":"\\r\\n\\r\\nDevils Tower (also known as Bear Lodge Butte[6]) is a laccolithic butte composed of igneous rock in the Bear Lodge Mountains (part of the Black Hills) near Hulett and Sundance in Crook County, northeastern Wyoming, above the Belle Fourche River. It rises 1,267 feet (386 m) above the Belle Fourche River, standing 867 feet (265 m) from summit to base. The summit is 5,112 feet (1,559 m) above sea level.\\r\\n\\r\\nDevils Tower was the first United States National Monument, established on September 24, 1906, by President Theodore Roosevelt.[7] The monument's boundary encloses an area of 1,347 acres (545?ha).\\r\\n\\r\\nIn recent years, about 1% of the monument's 400,000 annual visitors climbed Devils Tower, mostly using traditional climbing techniques.[8]\\r\\n\\r\\nThe name Devil's Tower originated in 1875 during an expedition led by Colonel Richard Irving Dodge, when his interpreter reportedly misinterpreted a native name to mean \\"Bad God's Tower\\".[9] All information signs in that area use the name \\"Devils Tower\\", following a geographic naming standard whereby the apostrophe is omitted.[10]\\r\\n\\r\\nNative American names for the monolith include:\\r\\n\\"Bear's House\\" or \\"Bear's Lodge\\" (or \\"Bear's Tipi\\", \\"Home of the Bear\\", \\"Bear's Lair\\"; Cheyenne, Lakota Mat?܇ Thpila, Crow Daxpitcheeaasao \\"Home of Bears\\"[11]), \\"Aloft on a Rock\\" (Kiowa), \\"Tree Rock\\", \\"Great Gray Horn\\",[9] and \\"Brown Buffalo Horn\\" (Lakota Pteh ?).[citation needed]\\r\\n\\r\\nIn 2005, a proposal to recognize several Native American ties through the additional designation of the monolith as Bear Lodge National Historic Landmark met with opposition from United States Representative Barbara Cubin, arguing that a \\"name change will harm the tourist trade and bring economic hardship to area communities\\".[12] In November 2014, one Arvol Looking Horse again proposed renaming the geographical feature \\"Bear Lodge\\", and submitted the request to the United States Board on Geographic Names. A second proposal was submitted to request that the U.S. acknowledge what it described as the \\"offensive\\" mistake in keeping the current name and to rename the monument and sacred site Bear Lodge National Historic Landmark. The formal public comment period ended in fall 2015. Local state senator Ogden Driskill opposed the change.[13][14] The name was not changed.[15][not in citation given]\\r\\n\\r\\nThe landscape surrounding Devils Tower is composed mostly of sedimentary rocks. The oldest rocks visible in Devils Tower National Monument were laid down in a shallow sea during the mid- to late-Triassic period, 225 to 195 million years ago. This dark red sandstone and maroon siltstone, interbedded with shale, can be seen along the Belle Fourche River. Oxidation of iron minerals causes the redness of the rocks. This rock layer is known as the Spearfish Formation.\\r\\n\\r\\nAbove the Spearfish Formation is a thin band of white gypsum, called the Gypsum Springs Formation. This layer of gypsum was deposited during the Jurassic period, 195 to 136 million years ago.\\r\\n\\r\\nCreated as sea levels and climates repeatedly changed, gray-green shales (deposited in low-oxygen environments such as marshes) were interbedded with fine-grained sandstones, limestones, and sometimes thin beds of red mudstone. This composition, called the Stockade Beaver member, is part of the Sundance Formation. The Hulett Sandstone member, also part of the Sundance Formation, is composed of yellow fine-grained sandstone. Resistant to weathering, it forms the nearly vertical cliffs that encircle the Tower.\\r\\n\\r\\nDuring the Paleocene Epoch, 56 to 66 million years ago, the Rocky Mountains and the Black Hills were uplifted. Magma rose through the crust, intruding into the existing sedimentary rock layers.[16]\\r\\n\\r\\nGeologists Carpenter and Russell studied Devils Tower in the late 19th century and came to the conclusion that it was formed by an igneous intrusion. Modern geologists agree that it was formed by the intrusion of igneous material, but not on exactly how that process took place. Several believe the molten rock composing the Tower might not have surfaced; others are convinced the tower is all that remains of what once was a large explosive volcano.\\r\\n\\r\\nIn 1907, scientists Darton and O'Hara[who?] decided that Devils Tower must be an eroded remnant of a laccolith.[citation needed] A laccolith is a large mass of igneous rock which is intruded through sedimentary rock beds without reaching the surface, but makes a rounded bulge in the sedimentary layers above. This theory was quite popular in the early 20th century, since numerous studies had earlier been done on laccoliths in the Southwest.\\r\\n\\r\\nOther theories have suggested that Devils Tower is a volcanic plug or that it is the neck of an extinct volcano. Some pyroclastic material of the same age as Devils Tower has been identified elsewhere in Wyoming.[citation needed]\\r\\n\\r\\nThe igneous material that forms the Tower is a phonolite porphyry intruded about 40.5 million years ago,[17] a light to dark-gray or greenish-gray igneous rock with conspicuous crystals of white feldspar.[18] As the magma cooled, hexagonal (and sometimes 4-, 5-, and 7-sided) columns formed, each about six feet in diameter. As the rock continued to cool, the vertical columns shrank in width and cracks began to occur at 120-degree angles, generally forming compact 6-sided columns. The nearby Missouri Buttes, 3.5 miles (5.6?km) to the northwest of Devils Tower, are also composed of columnar phonolite of the same age. Devils Postpile National Monument in California and Giant's Causeway in Northern Ireland, are also columnar basalt, which are superficially similar, but with columns typically 2 feet (0.61?m) in diameter.\\r\\n\\r\\nDevils Tower did not visibly protrude out of the landscape until the overlying sedimentary rocks eroded away. As the elements wore down the softer sandstones and shales, the more resistant igneous rock making up the tower survived the erosional forces. As a result, the gray columns of Devils Tower began to appear as an isolated mass above the landscape.\\r\\n\\r\\nAs rain and snow continue to erode the sedimentary rocks surrounding the Tower's base, more of Devils Tower will be exposed. Nonetheless, the exposed portions of the Tower still experience certain amounts of erosion. Cracks along the columns are subject to water and ice erosion. Erosion due to the expansion of ice along cracks and fractures within rock formations is common in colder climates, a prime example being the columnar hoodoo formations at Bryce Canyon National Park. Portions, or even entire columns, of rock at Devils Tower are continually breaking off and falling. Piles of broken columns, boulders, small rocks, and stones, called scree, lie at the base of the tower, indicating that it was once wider than it is today.[16]\\r\\n\\r\\nAccording to the Native American tribes of the Kiowa and Lakota, a group of girls went out to play and were spotted by several giant bears, who began to chase them. In an effort to escape the bears, the girls climbed atop a rock, fell to their knees, and prayed to the Great Spirit to save them. Hearing their prayers, the Great Spirit made the rock rise from the ground towards the heavens so that the bears could not reach the girls. The bears, in an effort to climb the rock, left deep claw marks in the sides, which had become too steep to climb. Those are the marks which appear today on the sides of Devils Tower. When the girls reached the sky, they were turned into the stars of the Pleiades.\\r\\n\\r\\nAnother version tells that two Sioux boys wandered far from their village when Mato the bear, a huge creature that had claws the size of tipi poles, spotted them, and wanted to eat them for breakfast. He was almost upon them when the boys prayed to Wakan Tanka the Creator to help them. They rose up on a huge rock, while Mato tried to get up from every side, leaving huge scratch marks as he did. Finally, he sauntered off, disappointed and discouraged. The bear came to rest east of the Black Hills at what is now Bear Butte. Wanblee, the eagle, helped the boys off the rock and back to their village. A painting depicting this legend by artist Herbert A. Collins hangs over the fireplace in the visitor's center at Devils Tower.\\r\\n\\r\\nIn a Cheyenne version of the story, the giant bear pursues the girls and kills most of them. Two sisters escape back to their home with the bear still tracking them. They tell two boys that the bear can only be killed with an arrow shot through the underside of its foot. The boys have the sisters lead the bear to Devils Tower and trick it into thinking they have climbed the rock. The boys attempt to shoot the bear through the foot while it repeatedly attempts to climb up and slides back down leaving more claw marks each time. The bear was finally scared off when an arrow came very close to its left foot. This last arrow continued to go up and never came down.[19]\\r\\n\\r\\nWooden Leg, a Northern Cheyenne, related another legend told to him by an old man as they were traveling together past the Devils Tower around 1866ÿ1868. An Indian man decided to sleep at the base of Bear Lodge next to a buffalo head. In the morning he found that both he and the buffalo head had been transported to the top of the rock by the Great Medicine with no way down. He spent another day and night on the rock with no food or water. After he had prayed all day and then gone to sleep, he awoke to find that the Great Medicine had brought him back down to the ground, but left the buffalo head at the top near the edge. Wooden Leg maintained that the buffalo head was clearly visible through the old man's spyglass. At the time, the tower had never been climbed and a buffalo head at the top was otherwise inexplicable.[20]\\r\\n\\r\\nThe buffalo head gives this story special significance for the Northern Cheyenne. All the Cheyenne maintained in their camps a sacred teepee to the Great Medicine containing the tribal sacred objects. In the case of the Northern Cheyenne, the sacred object was a buffalo head.[21]\\r\\n\\r\\nFur trappers may have visited Devils Tower, but they left no written evidence of having done so. The first documented Caucasian visitors were several members of Captain William F. Raynolds' 1859 expedition to Yellowstone. Sixteen years later, Colonel Richard I. Dodge escorted an Office of Indian Affairs scientific survey party to the massive rock formation and coined the name Devils Tower.[22] Recognizing its unique characteristics, the United States Congress designated the area a U.S. forest reserve in 1892 and in 1906 Devils Tower became the nation's first National Monument.[23]\\r\\n\\r\\nThe 1977 movie Close Encounters of the Third Kind used the formation as a plot element and as the location of its climactic scenes.[24][25] Its release was the cause of a large increase in visitors and climbers to the monument.[26]\\r\\n\\r\\nIn recent years, climbing Devils Tower has increased in popularity. The first known ascent of Devils Tower by any method occurred on July 4, 1893, and is accredited to William Rogers and Willard Ripley, local ranchers in the area. They completed this first ascent after constructing a ladder of wooden pegs driven into cracks in the rock face. A few of these wooden pegs are still intact and are visible on the tower when hiking along the 1.3-mile (2.1?km) Tower Trail at Devils Tower National Monument. Over the following thirty years many climbs were made using this method before the ladder fell into disrepair.\\r\\n\\r\\nThe first ascent using modern climbing techniques was made by Fritz Wiessner with William P. House and Lawrence Coveney in 1937. Wiessner led almost the entire climb free, placing only a single piece of fixed gear, a piton, which he later regretted, deeming it unnecessary.\\r\\n\\r\\nIn 1941 George Hopkins parachuted onto Devils Tower, without permission, as a publicity stunt resulting from a bet. He had intended to descend by a 1,000?ft (300?m) rope dropped to him after successfully landing on the butte, but the package containing the rope, a sledge hammer and a car axle to be driven into the rock as an anchor point slid over the edge. As the weather deteriorated, a second attempt was made to drop equipment, but Hopkins deemed it unusable after the rope became snarled and frozen due to the rain and wind. Hopkins was stranded for six days, exposed to cold, rain and 50?mph (80?km/h) winds before a mountain rescue team led by Jack Durrance, who had successfully climbed Devils Tower in 1938, finally reached him and brought him down.[27][28] His entrapment and subsequent rescue was widely covered by the media of the time.[29]\\r\\n\\r\\nToday, hundreds of climbers scale the sheer rock walls of Devils Tower each summer. The most common route is the Durrance Route, which was the second free route established in 1938. There are many established and documented climbing routes covering every side of the tower, ascending the various vertical cracks and columns of the rock. The difficulty of these routes range from relatively easy to some of the most challenging in the world. All climbers are required to register with a park ranger before and after attempting a climb. No overnight camping at the summit is allowed; climbers return to base on the same day they ascend.[30]\\r\\n\\r\\nThe Tower is sacred to several Plains tribes, including the Lakota, Cheyenne and Kiowa. Because of this, many Indian leaders objected to climbers ascending the monument, considering this to be a desecration. The climbers argued that they had a right to climb the Tower, since it is on federal land. A compromise was eventually reached with a voluntary climbing ban during the month of June when the tribes are conducting ceremonies around the monument. Climbers are asked, but not required, to stay off the Tower in June. According to the PBS documentary In the Light of Reverence, approximately 85% of climbers honor the ban and voluntarily choose not to climb the Tower during the month of June. However, several climbers along with the Mountain States Legal Foundation sued the Park Service, claiming an inappropriate government entanglement with religion.[31]\\r\\n\\r\\nDevils Tower National Monument protects many species of wildlife, such as white-tailed deer, prairie dogs, and bald eagles.[32][33]\\r\\n\\r\\nFour areas of Devils Tower National Monument are on the National Register of Historic Places:","input":"What is the devils tower made out of?"},{"output":"2,430 games, plus the postseason","context":"The Major League Baseball (MLB) season schedule consists of 162 games for each of the 30 teams in the American League (AL) and National League (NL), played over approximately six monthsa total of 2,430 games, plus the postseason. The regular season runs from late March/early April to late September/early October, followed by the postseason which can run to early November.  The season begins with the official Opening Day, and, as of 2018, runs 26? weeks through the last Sunday of September or first Sunday of October. One or more International Opener games may be scheduled outside the United States before the official Opening Day.[1][2] It is possible for a given team to play a maximum of 20 games in the postseason in a given year, provided the team is a wild card and advances to each of the Division Series, Championship Series, and World Series with each series going the distance (5 games in the Division Series, 7 games each in the League Championship Series/World Series).\\r\\n\\r\\nThe regular season is constructed from series.  Due to travel concerns and the sheer number of games, pairs of teams are never scheduled to play single games against each other (except in the instance of making up a postponed game); instead they play games on several consecutive days in the same ballpark.  Most often the series are of three or four games, but two-game series are also scheduled.  Teams play one mid-week series and one weekend series per week. Depending on the length of the series, mid-week series games are usually scheduled between Monday and Thursday, while weekend games are scheduled between Thursday and Monday.  Beginning in 2018, teams start and end their season on a weekend for a total of 26? weeks. Due to the mid-week all-star break in July, teams are scheduled to play 27 weekend series and 25 mid-week series for a total of 52 series (24 divisional series, 20 inter-divisional series, 8 inter-league series).  A team's road games are usually grouped into a multi-series road trip; home series are grouped into homestands.\\r\\n\\r\\nNote that rainouts and other cancellations are often rescheduled ad hoc during the season, sometimes as doubleheaders.  However, if two teams are scheduled to meet for the final time in the last two weeks of the season, and the game is cancelled, it may not be rescheduled if there is no impact on the divisional or wild card races.  For example, in 2016, the September 29 game between the Cleveland Indians and Detroit Tigers was cancelled due to rain because the teams were unable to reschedule a make-up date before the end of the season on October 2, and it did not affect the divisional race.  In contrast, a 2008 AL Central division game between Detroit and the Chicago White Sox needed to be made up following the last day of the regular season because it affected a division race involving the White Sox and the Minnesota Twins.\\r\\n\\r\\nThis account gives the length of the major league \\"championship season\\" schedule by league and year. It does not cover the curtailment of play by war (1918) or by strikes and lockouts (1972, 1981, 1994). The schedules for 1995 were revised and shortened from 162 to 144 games, after late resolution of the strike that had begun in 1994 required a delay in the season to accommodate limited spring training.\\r\\n\\r\\nThe listed years are those in which the league revised its schedule. For example, the National League (NL) scheduled 84 games during 1879, 1880, 1881, and 1882 ÿ that is, four seasons from 1879, ending before 1883, the next listing. 1876 is listed here for convenience although the NL did not schedule games (see 1871 to 1876, below).\\r\\n\\r\\n1882 ÿ 1891\\r\\n\\r\\nThus the AA expanded its schedule to 140 games two years before the National League did so. After 1891 four AA clubs joined the NL and four were bought out, nominally creating one big league, the \\"National League and American Association\\" of 12 clubs.\\r\\n\\r\\n1884\\r\\n\\r\\n1890\\r\\n\\r\\n1914: 1915\\r\\n\\r\\nThe National Association of Professional Base Ball Players (1871ÿ1875) did not schedule games, nor did it control the number of teams, a major reason for its demise after the 1875 season. Clubs paid a $10 entry fee, later $20, to enter the Association for one season, and thereby declare for that year's national championship. Without continuing membership or heavy investment, there was little to deter a team from breaking a commitment, and though it happened, it was mainly due to clubs going out of business.\\r\\n\\r\\nThe National League organized for 1876 on a different basis, granting exclusive memberships to eight clubs that would continue from year to year  it was generally expected, if only because membership would be profitable. But the new league followed its predecessor in merely agreeing that each club would play a certain number of matches to a decision (excluding ties) by a certain date.  Boston played 70 games with its quota of ten decisions against every rival. The others achieved 56 to 68 decisions, 64 to 66 for the four western teams as the teams from New York and Philadelphia (eastern) abandoned their schedule-concluding road trips.\\r\\n\\r\\nFor all six early seasons, prior to the first league schedule in 1877, member clubs scheduled their own matches by mutual arrangement, including championship games necessarily with member clubs, other games with members, and games with non-member clubs. Some may have practically dictated their arrangements with some others, but there was no central control or coordination.\\r\\n\\r\\nThis listing gives the greatest number of games played by any club for each season. Naturally, the leader by games played was always a strong club fielding one of the better gate attractions.\\r\\n\\r\\nThe leading numbers of games played to a decision were 33, 54, 59, 71, 82, and 70 decisions; by the listed teams except the Mutuals in 1872.\\r\\n\\r\\nSince 1998, there have been 30 major league teams with a single advance schedule for every season that comprises 2430 games.  Each team plays 162 games, 81 as the \\"home\\" team, 81 as the \\"visitor\\". (This is true even on the rare occasion when a game is played at a ballpark not home to either team.)  Occasionally, the advance schedule is subsequently altered due to a game postponement or a one-game tie-breaker to determine which team will play in the postseason.\\r\\n\\r\\nBefore 2013 the schedule included 252 \\"interleague games\\" that matched one team from the American League and one from the National League; the other 2178 games matched a pair from within one league. About half of the latter matched teams from within one division and about half matched teams from different divisions in one league. In the Central Division of the National League, which alone had six teams, every pair of division rivals played 15 or 16 games. Within the other, smaller divisions every pair of teams played 18 or 19 games.\\r\\n\\r\\nDivision games (1091). There are 61 pairs of teams from within one division.\\r\\n\\r\\nOther intraleague games (1087). There are 150 pairs of teams from two different divisions within one league.\\r\\n\\r\\nThe schedule for interleague play comprised 84 three-game series in each season from 1998 to 2012, divided as six series (18 games) for each of fourteen AL teams and as many as six for each of sixteen NL teams.\\r\\n\\r\\nAmong the 224 interleague pairs of teams, 11 played six games every year, which were scheduled in two three-game series \\"home and home\\", or one at each home ballpark. Five of these 11 special arrangements matched two teams in the same city or in neighboring cities, where they wholly or partly share territorial rights. Six were regional matches at greater distance, four of which were in the same state.\\r\\n\\r\\nThese special local and regional series accounted for 66 interleague games annually from 1998-2012, and the other 186 games were determined by rotation.\\r\\n\\r\\nThe 2001 season was suspended for one week due to the September 11 terrorist attacks and resulting disruptions in travel, resulting in games scheduled for September 11ÿ16 being rescheduled to the first week of October and the playoffs and World Series being rescheduled one week later than their originally planned dates, which resulted in the World Series continuing into early November.\\r\\n\\r\\nSchedule changes for 2013, precipitated by realignment that created two equal-sized leagues of 15 teams each, gave every team 20 interleague games.[3] Sixteen of which were determined by a match of divisions, one from each league; all teams in a given division play all teams in a given division from the other league. (Each plays a three-game series against four teams from the designated division and two two-game series against the remaining team.)\\r\\n\\r\\nThe matched divisions rotate annually:\\r\\n\\r\\nEach team played its four other interleague games against a designated \\"natural rival\\", with two games in each club's city. Thus all 30 teams, rather than 22 of 30 as previously, were deemed to have a natural rival in the other league.  In 2013 the natural rivalry games were all scheduled for May 27 to May 30 (Memorial Day weekend) but in 2014 their scheduled dates range from May to August.\\r\\n\\r\\nTen of the natural rivalries from 2012 and earlier continued, while the HoustonÿTexas \\"Lone Star\\" rivalry had been transformed into an intra-division one with 19 games played. Five of the special arrangements were new in 2013 , including one each for Houston and Texas.\\r\\n\\r\\nFor 2014, four (4) of the five (5) new rivalries have been revised (?), all except Detroit and Pittsburgh.\\r\\n\\r\\nEvery team now plays 19 games against each of 4 opponents within its division (76 games), and 6 or 7 games against each of 10 opponents from other divisions within its own league (66 games).\\r\\n\\r\\nWhen corresponding divisions (i.e. NL East vs. AL East) play each other, a slight adjustment was made to the interleague games. Teams now play 6 games against their rival and 4 games (home and home) against two opponents plus one home and one away 3 game series (14 total) against the other four teams in the opposing division.  This was done in 2015, and will next occur in 2018.\\r\\n\\r\\nUnder the new collective bargaining agreement reached in December 2016, several changes were done to the scheduling pattern for the 2018 season. The overall length of the season has been extended to 187 days with the addition of four off-days for all teams. All teams will play on Opening Day, which for 2018 will be held on March 29. Sunday Night Baseball will no longer be played on the final Sunday before the All-Star Game, in order to ease travel time for those who are participating in the Home Run Derby. A single, nationally televised afternoon game will be played the following Thursday, with all other teams returning to play on Friday.[4][5]\\r\\n\\r\\nStart of Major League Baseball games depends on days of the week, game number in series, holidays, and other factors. Most games start at 7pm in the local time zone, so there are more night games than day games even though baseball is traditionally played during the day. The reason why there are more night baseball games is to attract more fans to ballparks as well as viewers from home because most fans would be at work or school during the day. On Mondays (excluding Opening Day and holidays), Tuesdays, and Fridays, games are almost exclusively played at night except for Cubs home games. Getaway days, days on which teams play their last game of the series before departing for another series in another city the next day, are usually day games, mainly Sundays, Wednesdays, and Thursdays. On Sundays, usually all but one are day games, with the final game reserved for ESPN's Sunday Night Baseball.\\r\\n\\r\\nAbout half of Saturday games are day games (1, 2 or 4pm ET).  In some markets, Saturday night start an hour earlier than usual night start times, but other cities start Saturday night games at the same time as weeknight games. In conclusion, weekday games are only played at night except for getaway days while many weekend games are played during the day.\\r\\n\\r\\nThe initial pitch typically occurs 5 or 10 minutes after the hour, in order to allow time for pre-game ceremonies.","input":"How many games are in a mlb series?"},{"output":"Rodrigo Duterte","context":"The President of the Philippines (Filipino: Pangulo ng Pilipinas, informally referred to as Presidente ng Pilipinas) or in (Spanish: Presidente de Filipinas) is the head of state and head of government of the Philippines. The President leads the executive branch of the Philippine government and is the commander-in-chief of the Armed Forces of the Philippines. The President is directly elected by the people, and is one of only two nationally elected executive officials, the other being the Vice President of the Philippines. However, four vice presidents have assumed the presidency without having been elected to the office, by virtue of a president's intra-term death or resignation.[note 1]\\r\\nFilipinos refer to their President as Pangulo or Presidente. The President serves a single, fixed, six-year term without possibility of re-election. On June 30, 2016, Rodrigo Duterte was sworn in as the 16th and current president.\\r\\n\\r\\n\\r\\nIn Filipino, one of the two official languages of the Philippines, the President is referred to as Pangulo. In the other major languages of the Philippines such as the Visayan languages, Presidente is more common when Filipinos are not actually code-switching with the English word.\\r\\n\\r\\n\\r\\n\\r\\nDepending on the definition chosen for these terms, a number of persons could alternatively be considered the inaugural holder of the office. Andrs Bonifacio could be considered the first President of a united Philippines since he was the third Supreme President (Spanish: Presidente Supremo; Filipino: Kataas-taasang Pangulo) of the Katipunan, a secret revolutionary society. Its Supreme Council, led by the Supreme President, coordinated provincial and district councils. When the Katipunan started an open revolt against the Spanish colonial government in August 1896, Bonifacio transformed the society into a revolutionary government with him as its head. While the term Katipunan remained, Bonifacio's government was also known as the Tagalog Republic (Spanish: Rep~blica Tagala; Filipino: Republikang Tagalog). Although the word Tagalog refers to the Tagalog people, a specific ethno-linguistic group, Bonifacio used it to denote all non-Spanish peoples of the Philippines in place of Filipinos, which had colonial origins.[3][4][5][6][7] Bonifacio's revolutionary government never controlled much territory for any significant period. Some historians contend that including Bonifacio as a past president would imply that Macario Sacay and Miguel Malvar should also be included.[8]\\r\\nIn March 1897, during the Philippine Revolution against Spain Emilio Aguinaldo was elected president of the revolutionary government at the Tejeros Convention.[9] The new government was meant to replace the Katipunan, though the latter was not formally abolished until 1899. Aguinaldo was again elected President at Biak-na-Bato in November, leading the Republic of Biak-na-Bato. Aguinaldo therefore signed the Pact of Biak-na-Bato and went into exile in Hong Kong at the end of 1897.\\r\\nIn April 1898, the SpanishÿAmerican War broke out, and the Asiatic Squadron of the United States Navy sailed for the Philippines. At the Battle of Manila Bay on May 1, 1898 the American Navy decisively defeated the Spanish Navy effectively ending Spanish rule in the Philippines.[10] Aquinaldo subsequently returned to the Philippines aboard a U.S. Navy vessel and renewed the revolution. He formed a dictatorial government on May 24, 1898 and issued the Philippine Declaration of Independence on June 12, 1898. On June 23, 1898, Aguinaldo transformed his dictatorial government into a revolutionary government. On January 23, 1899, he was then elected President of the First Philippine Republic, a government constituted by the Malolos Congress under the Malolos Constitution. Consequently, this government is also called the Malolos Republic.\\r\\nThe First Philippine Republic was short-lived and never internationally recognized. The Philippines was transferred from Spanish to American control by the Treaty of Paris of 1898, signed in December of that year.[11] The PhilippineÿAmerican War broke out between the United States and Aguinaldo's government. His government effectively ceased to exist on April 1, 1901, after he pledged allegiance to the United States following his capture by U.S. forces in March.\\r\\nThe current government of the Republic of the Philippines, considers Emilio Aguinaldo to be the first President of the Philippines.[12]\\r\\nMiguel Malvar continued Aguinaldo's leadership of the Philippine Republic after the latter's capture until his own capture in 1902, while Macario Sakay founded a Tagalog Republic in 1902 as a continuing state of Bonifacio's Katipunan. They are both considered by some scholars as \\"unofficial presidents\\", and along with Bonifacio, are not recognized as Presidents by the government.[13][14]\\r\\nBetween 1901 and 1935, executive power in the Philippines was exercised by a succession of four American military Governors-General and eleven civil Governors-General.\\r\\nIn October 1935, Manuel L. Quezon was elected the first President of the Commonwealth of the Philippines, which had been established, still under United States sovereignty, under a constitution ratified on 14 May of that year. During its first five years, the President could serve for an unrenewable six-year term. It was later amended in 1940 to limit a President to serving no more than two four-year terms. When President Quezon exiled himself to the United States after the Philippines fell to the Empire of Japan in World War II, he appointed Chief Justice Jos Abad Santos as Acting President and as Acting Commander-in Chief of the Armed Forces. Abad Santos was subsequently executed by the Imperial Japanese Army on May 2, 1942.\\r\\nOn October 14, 1943, Jos P. Laurel became President under a constitution imposed by the Japanese occupation. Laurel, an Associate Justice of the Supreme Court of the Philippines, had been instructed to remain in the City of Manila by President Quezon, who withdrew to Corregidor and then to the United States to establish a government in exile in the United States. The General Headquarters and Military Camp Base of the Philippine Commonwealth Army was a military station are moved in the province.\\r\\nAfter the combined American and Filipino forces liberated the islands in 1945, Laurel officially dissolved the republic on August 17, 1945.\\r\\nThe 1935 Constitution was restored after the Japanese surrender ended World War II, with Vice President Sergio Osme?a becoming President due to Quezon's death on August 1, 1944. It remained in effect after the United States recognized the sovereignty of the Republic of the Philippines as a separate self-governing nation on July 4, 1946.\\r\\nA new Constitution ratified on January 17, 1973 under the rule of Ferdinand E. Marcos introduced a parliamentary-style government. Marcos instituted himself as Prime Minister while serving as President in 1978. He later appointed Csar Virata as Prime Minister in 1981.\\r\\nThis Constitution was in effect until the People Power Revolution of 1986 toppled Marcos's 21-year authoritarian regime and replaced him with Corazon C. Aquino.\\r\\nRuling by decree during the early part of her tenure and as a president installed by revolutionary means, President Corazon Aquino issued Proclamation No. 3 on March 25, 1986 which abrogated many of the provisions of the then 1973 Constitution, including the provisions associated with the Marcos regime which gave the President legislative powers, as well as the unicameral legislature called the Batasang Pambansa (literally National Legislature in Filipino). Often called the \\"Freedom Constitution,\\" the proclamation retained only parts of the 1973 Constitution that were essential for a return to democratic rule, such as the bill of rights. This constitution was superseded on February 2, 1987 by the present constitution.\\r\\nBoth Bonifacio and Aguinaldo might be considered to have been an inaugural president of an insurgent government. Quezon was the inaugural president of a predecessor state to the current one, while Aquino, mre, was the inaugural president of the currently-constituted government.\\r\\nThe government considers Aguinaldo to have been the first President of the Philippines, followed by Quezon and his successors.[12][15] Despite the differences in constitutions and government, the line of presidents is considered to be continuous. For instance, the current president, Rodrigo R. Duterte, is considered to be the 16th president.\\r\\nWhile the government may consider Aguinaldo as the first president, the First Republic fell under the United States' jurisdiction due to the 1898 Treaty of Paris which ended the SpanishÿAmerican War; the United States thus does not consider his tenure to have been legitimate.[12][16] Manuel L. Quezon is considered to be the first president by the United States. He is also the first to win a popular election and a nationwide election.\\r\\nAs with many other Axis-occupied countries in the Second World War, the Philippines had at one point two presidents heading two governments. One was Quezon and the Commonwealth government-in-exile in Washington, D.C., and the other was Manila-based Laurel heading the Japanese-sponsored Second Republic. Notably, Laurel was himself instructed to remain in Manila by President Quezon.[citation needed] Laurel was not formally recognized as a President until the rule of Diosdado Macapagal.[citation needed] His inclusion in the official list coincided with the transfer of the official date of Independence Day from July 4 (the anniversary of the Philippines' independence from the United States) to June 12 (the anniversary of the 1898 Declaration of Independence).\\r\\nThe inclusion of Laurel thus causes some problems in determining the order of presidents. It is inaccurate to call Laurel the successor of Osme?a or vice versa, since Laurel's Second Republic was formally repudiated after World War II, its actions not considered legal or binding. Quezon, Osme?a, and Roxas were seen as being in a contiguous line according to the 1935 Constitution, while Laurel was the only president of the Second Republic, which had a separate charter. Thus, Laurel had neither predecessor nor successor, while Osme?a succeeded Quezon after the latter's death, and was in turn succeeded by Roxas as President of the Third Republic.\\r\\nThe President of the Philippines, being the chief executive, serves as both the head of state and head of government of the Philippines. The Constitution vests the executive power upon the President who thus heads the government's executive branch, which includes the Cabinet and all executive departments.[17]\\r\\nThe President also has the power to grant pardons[18] to enter into foreign loans with the prior concurrence of the Monetary Board.[19]\\r\\nThe President also exercises general supervision over local government units.[20]\\r\\nThe President also serves as the Commander-in-Chief of the Armed Forces of the Philippines.[21] This includes the power to suspend the writ of habeas corpus and to declare martial law.[21]\\r\\nWith the consent of the Commission on Appointments, the President also appoints the heads of the executive departments, board of members and its leaders from any national government-related institutions, ambassadors, other public ministers and consuls, high-ranking officers of the armed forces, and other officials.[22] The members of the Supreme Court and lower courts are also appointed by the President, but only from the list of nominees prepared by the Judicial and Bar Council. Such appointments do not need the approval of the Commission on Appointments.[23]\\r\\nSome government agencies report to no specific department but are instead under the Office of the President. These include important agencies such as the National Security Council, Office of The Presidential Adviser on the Peace Process, Commission on Human Rights, Commission on Higher Education, Climate Change Commission, Commission on Population, Housing and Land Use Regulatory Board, Metropolitan Manila Development Authority, Movie and Television Review and Classification Board, Authority of the Freeport Area of Bataan, Subic Bay Metropolitan Authority, and many more.[24] The Presidential Security Group, which is composed mostly of members from the Armed Forces of the Philippines and the Philippine National Police, is directly under the Office of the President.\\r\\nArticle 7, Section 2 of the Constitution reads: \\"No person may be elected President unless he or she is a natural-born citizen of the Philippines, a registered voter, able to read and write, at least forty years of age on the day of the election, and a resident of the Philippines for at least ten years immediately preceding such election.\\" [25] The Constitution also provides term limits where the President is ineligible for reelection and a person who has succeeded as President and has served as such for more than four years will be ineligible to be elected for a second term. However, with the case of Joseph Ejercito Estrada who was elected president in 1998, served until 2001, and again ran for the presidency in 2010, the Constitution's wording where \\"[the] President shall not be eligible for any re-election\\"[26] remains unclear as his case was never brought to the Supreme Court. It remains unclear whether the term limit of no re-election applies only to the incumbent President or for any person who has been elected as President.\\r\\nThe President is elected by direct vote every six years, usually on the second Monday of May.[26]\\r\\nThe returns of every election for President and Vice President, duly certified by the board of canvassers of each province or city, shall be transmitted to Congress, directed to the President of the Senate. Upon receipt of the certificates of canvass, the President of the Senate shall open all the certificates in the presence of a joint public session of Congress not later than 30 days after election day. Congress then canvasses the votes upon determining that the polls are authentic and were done in the manner provided by law.\\r\\nThe person with the highest number of votes is declared the winner, but in case two or more have the highest number of votes, the President is elected by a majority of all members of both Houses, voting separately on each.\\r\\nThe President of the Philippines usually takes the Oath of Office at noon of June 30 following the Presidential election\\r\\nTraditionally, the Vice President takes the Oath first, a little before noon. This is for two reasons: first, according to protocol, no one follows the President (who is last due to his supremacy), and second, to establish a constitutionally valid successor before the President-elect accedes. During the Quezon inauguration, however, the Vice President and the Legislature were sworn in after the President, to symbolise a new start.\\r\\nAs soon as the President takes the Oath of Office, a 21-gun salute is fired to salute the new head of state, and the Presidential Anthem Mabuhay is played. The President delivers his inaugural address, and then proceeds to Malaca?ang Palace to climb the Grand Staircase, a ritual which symbolises the formal possession of the Palace. The President then inducts the newly formed cabinet into office in one of the state rooms.\\r\\nCustom has enshrined three places as the traditional venue for the inauguration ceremony: Barasoain Church in Malolos City, Bulacan; in front of the old Legislative Building (now part of the National Museum) in Manila; or at Quirino Grandstand, where most have been held. In 2004, Gloria Macapagal Arroyo delivered her pre-inaugural address at Quirino Grandstand, took the Oath of Office in Cebu City before Chief Justice Hilario Davide Jr., and the next day held the first cabinet meeting in Butuan City. She broke with precedent, reasoning that she wanted to celebrate her inauguration in each of the three main island groups of the Philippines: Luzon, Visayas, and Mindanao. Her first inauguration also broke precedent as she was sworn in at the EDSA Shrine on January 20, 2001, during the EDSA Revolution of 2001 that removed Joseph Estrada from office.\\r\\nIn the past, elections were held in November and the President's inauguration was held on December 30 (Rizal Day). This ensured that when the inauguration was usually held at Quirino Grandstand, the new President could see the Rizal Monument on the anniversary of his death. Ferdinand Marcos transferred the dates of both the elections and the inauguration to May and June, respectively, and it remains so to this day.\\r\\nThe dress code at the modern inaugural ceremony is traditional, formal Filipino clothing, which is otherwise loosely termed Filipiniana. Ladies must wear terno, baro't saya (the formal wear of other indigenous groups is permissible), while men don the Barong Tagalog. Non-Filipinos at the ceremony may wear their respective versions of formal dress, but foreign diplomats have often been seen donning Filipiniana as a mark of cultural respect.\\r\\nThe Constitution provides the following oath or affirmation for the President and Vice President-elect which must be taken before they enter into office:[27]\\r\\nI, (name), do solemnly swear [or affirm], that I will faithfully and conscientiously fulfill my duties as President [or Vice-President or Acting President] of the Philippines. Preserve and defend its Constitution, execute its laws, do justice to every man, and consecrate myself to the service of the Nation. So help me God. [In case of affirmation, last sentence will be omitted.]\\r\\nThe Filipino text of the oath used for the inaugurations of Fidel V. Ramos, Joseph Ejercito Estrada, and Benigno S. Aquino III reads:[28]\\r\\n\\"Ako si (pangalan), ay taimtim kong pinanunumpaan (o pinatototohanan) na tutuparin ko nang buong katapatan at sigasig ang aking mga tungkulin bilang Pangulo (o Pangalawang Pangulo o Nanunungkulang Pangulo) ng Pilipinas, pangangalagaan at ipagtatanggol ang kanyang Konstitusyon, ipatutupad ang mga batas nito, magiging makatarungan sa bawat tao, at itatalaga ang aking sarili sa paglilingkod sa Bansa. Kasihan nawa ako ng Diyos. (Kapag pagpapatotoo, ang huling pangungusap ay kakaltasin.)\\r\\nImpeachment in the Philippines follows procedures similar to the United States. The House of Representatives, one of the houses of the bicameral Congress, has the exclusive power to initiate all cases of impeachment against the President, Vice President, members of the Supreme Court, members of the Constitutional Commissions and the Ombudsman.[29] When a third of its membership has endorsed the impeachment articles, it is then transmitted to the Senate of the Philippines which tries and decide, as impeachment tribunal, the impeachment case.[30] A main difference from US proceedings however is that only a third of House members are required to approve the motion to impeach the President (as opposed to the majority required in the United States). In the Senate, selected members of the House of Representatives act as the prosecutors and the Senators act as judges with the Senate President and Chief Justice of the Supreme Court jointly presiding over the proceedings. Like the United States, to convict the official in question requires that a minimum of two-thirds (i.e., 16 of 24 members) of the senate vote in favour of conviction. If an impeachment attempt is unsuccessful or the official is acquitted, no new cases can be filed against that impeachable official for at least one full year.\\r\\nThe Constitution enumerates the culpable violation of the Constitution, treason, bribery, graft and corruption, other high crimes, and betrayal of public trust as grounds for the impeachment of the President.[31] The same also applies for the Vice President, the Members of the Supreme Court, the Members of the Constitutional Commissions, and the Ombudsman.\\r\\nJoseph Ejercito Estrada was the first President to undergo impeachment when the House of Representatives voted to raise the impeachment proceedings to the Senate in 2000. However, the trial ended prematurely where anti-Estrada senators walked out of the impeachment sessions when Estrada's allies in the Senate voted narrowly to block the opening of an envelope which allegedly contained critical evidence on Estrada's wealth. Estrada was later ousted from office when the 2001 EDSA Revolution forced him out of the presidential palace and when the Supreme Court confirmed that his leaving the palace was his de facto resignation from office.\\r\\nSeveral impeachment complaints were filed against Gloria Macapagal-Arroyo but none reached the required endorsement of a third of the House of Representatives.\\r\\nThe official title of the Philippine head of state and government is \\"President of the Philippines.\\"[32] The title in Filipino is Pangulo (cognate of Malay penghulu \\"leader\\", \\"chieftain\\"). The honorific for the President is \\"Your Excellency\\" or \\"His/Her Excellency\\", adopted from the title of the Governor-General of the Philippines during Spanish and American occupation.[citation needed]\\r\\nThe term \\"President of the Republic of the Philippines\\" used under Japanese occupation of the Philippines distinguished the government of then-President Jos P. Laurel from the Commonwealth government-in-exile under President Manuel L. Quezon.[33] The restoration of the Commonwealth in 1945 and the subsequent independence of the Philippines restored the title of \\"President of the Philippines\\" enacted in the 1935 constitution.[34] The 1973 constitution, though generally referring to the president as \\"President of the Philippines\\" did, in Article XVII, Section 12, once use the term, \\"President of the Republic.\\"[35] In the text of Proclamation No. 1081 that announced martial law in September 1972, President Ferdinand E. Marcos consistently referred to himself as \\"President of the Philippines.\\"[36]\\r\\nThe State of the Nation Address (abbreviated SONA) is an annual event in the Philippines, in which the President of the Philippines reports on the status of the nation, normally to the resumption of a joint session of the Congress (the House of Representatives and the Senate). This is a duty of the President as stated in Article VII, Section 23 of the 1987 Constitution:[32]\\r\\nThe 1935 Constitution originally set the president's term at six years, without re-election.[37] In 1940, however, the 1935 Constitution was amended and the term of the President (and Vice President) was shortened to four years, with a two-term limit. Since the amendment was done, only Presidents Manuel L. Quezon (1941) and Ferdinand E. Marcos (1969) were re-elected. Presidents Sergio Osme?a (1946), Elpidio Quirino (1953), Carlos P. Garcia (1961) and Diosdado Macapagal (1965) all failed in seeking a new term.\\r\\nHowever, in 1973, a new Constitution was promulgated and allowed then-incumbent President Marcos to seek a new term. In 1981, Marcos was again elected as President against Alejo Santos ÿ making him the only President to be elected to a third term.[38]\\r\\nThe 1987 Constitution restored the 1935 Constitution's original ban on presidential reelection. Under Article 7, Section 4 of the current constitution, the term of the President shall begin at noon on the thirtieth day of June next following the day of the election and shall end at noon of the same date, six years thereafter. The incumbent President shall not be eligible for any re-election. No person who has been President and has served as such for more than four years shall be qualified for election to the presidency at any time.[39]\\r\\nUnder Article 7, Section 7 of the Constitution of the Philippines, In case the president-elect fails to qualify, the Vice President-elect shall act as President until the President-elect shall have qualified.[32]\\r\\nIf at the beginning of the term of the President, the President-elect shall have died or shall have become permanently disabled, the Vice President-elect shall become President.[32]\\r\\nWhere no President and Vice President shall have been chosen or shall have qualified, or where both shall have died or become permanently disabled, the President of the Senate or, in case of his inability, the Speaker of the House of Representatives, shall act as President until a President or a Vice President shall have been chosen and qualified.[32]\\r\\nArticle 7, Sections 8 and 11 of the Constitution of the Philippines provide rules of succession to the presidency. In case of death, permanent disability, removal from office, or resignation of the President, the Vice President will become the President to serve the unexpired term. In case of death, permanent disability, removal from office, or resignation of both the President and Vice President; the President of the Senate or, in case of his inability, the Speaker of the House of Representatives, shall then act as President until the President or Vice President shall have been elected and qualified.\\r\\nThe Congress shall, by law, provide who shall serve as President in case of death, permanent disability, or resignation of the Acting President. He shall serve until the President or the Vice President shall have been elected and qualified, and be subject to the same restrictions of powers and disqualifications as the Acting President.\\r\\nThe line of presidential succession as specified by Article VII, Section 8 of the Constitution of the Philippines are the Vice President, Senate President and the Speaker of the House of Representatives.\\r\\nThe current Presidential line of succession is:\\r\\nNotes:\\r\\nBefore the Malaca?ang Palace was designated as the official residence of the President, various establishments served as residence of the chief executive. The Spanish Governor-General, the highest-ranking official in the Philippines during the Spanish Era, resided in the Palacio del Gobernador inside the walled city of Intramuros. However, after an earthquake in 1863, the Palacio del Gobernador was destroyed, and the residence and office of the Governor-General transferred to Malaca?ang Palace. During the Philippine Revolution, President Aguinaldo resided in his own home in Kawit, Cavite. After his defeat in the PhilippineÿAmerican War, Aguinaldo transferred the Capital of the Philippines to different areas while he struggled in the pursuit of American Forces. When the Americans occupied the Philippines, they also used the Palace as an official residence. During the Japanese Occupation of the Philippines, the governmental offices and the presidential residence transferred to Baguio, and the Mansion House was used as the official residence. Meanwhile, President Quezon of the Philippine Commonwealth resided in the Omni Shoreham Hotel in Washington D.C. After the restoration of independence, plans were made for the construction of a new capital city. However, the plans did not push through and Manila remained as the capital city, and Malaca?ang Palace as the President's official residence.[40][41]\\r\\nThe Filipino name is derived from the Tagalog phrase \\"may lakn diyn\\", (\\"there is a nobleman there\\"), and this was eventually shortened to Malakanyng. There are two variant of the name in official use: \\"Malaca?an Palace\\" refers to the structure of the Palace, while \\"Malaca?ang\\" identifies the office of the President. The latter, along with the term \\"the Palace\\" (\\"ang Palasyo\\") are interchangeable, metonyms for the President and his household in colloquial speech and in the media.[citation needed]\\r\\nMalaca?an Palace serves as the official residence of the President of the Philippines, a privilege entitled to him/her under Article VII, Section 6 of the Constitution.[32] The Palace is located along the north bank of the Pasig River, along J.P. Laurel Street in the district of San Miguel, Manila.\\r\\nMalaca?ang Palace is depicted on the reverse side of the 20-peso bill in the Pilipino, Ang Bagong Lipunan, New Design, and the present New Generation series.\\r\\nThe actual residence of incumbent President Rodrigo Duterte is Bahay Pangarap (English: House of Dreams),[42] a smaller structure located across the Pasig River from Malaca?ang Palace in Malaca?ang Park,[43] which is itself part of the Presidential Security Group Complex.[42][44] Former President Aquino was the first President to live in Bahay Pangarap his official residence.[45][46]\\r\\nMalaca?ang Park was originally built by former President Manuel L. Quezon as a rest house and venue for informal activities and social functions for the First Family.[42][46] The house was built and designed by architect Juan Arellano in the 1930s,[42][46] and underwent a number of renovations.[42] In 2008, the house was demolished and rebuilt in contemporary style by architect Conrad Onglao,[42][46] and a new swimming pool was built, replacing the Commonwealth Era one.[45][46] The house originally had one bedroom,[42] however, it was renovated for Aquino to have four bedrooms,[45] a guest room, a room for his household staff, and a room for his close-in security.[43] Malaca?ang Park was refurbished through the efforts of First Lady Eva Macapagal, the second wife of President Diosdado Macapagal, in the early 1960s.[46] Mrs. Macapagal renamed the rest house as Bahay Pangarap.[46]\\r\\nUnder Fidel V. Ramos, Bahay Pangarap was transformed into a clubhouse for the Malaca?ang Golf Club.[42] The house was subsequently used by President Gloria Macapagal-Arroyo to welcome special guests.[42] Aquino made it clear before he assumed office that he refused to live in the main Palace, or in the nearby Arlegui Mansion (where he once lived during his mother's rule and where Ramos later stayed), stating that both were too big.[42] He lived in the Aquino family residence along Times Street, Quezon City in the first few days of his rule, although he transferred to Bahay Pangarap because it was deemed a security concern for his neighbours if he stayed in their small, 1970s home.[44]\\r\\nThe President also has other complexes nationwide for official use:\\r\\nThe 250th (Presidential) Airlift Wing of the Philippine Air Force has the mandate of providing safe and efficient air transport for the President of the Philippines and the First Family. On occasion, the wing has also been tasked to provide transportation for other members of government, visiting heads of state, and other state guests.\\r\\nThe fleet includes: 1 Fokker F28, which is primarily used for the President's domestic trips and it is also called \\"Kalayaan One\\" when the President is on board, 4 Bell 412 helicopters, 3 Sikorsky S-76 helicopters, 1 Sikorsky S-70-5 Black Hawk, a number of Bell UH-1N Twin Hueys, as well as Fokker F-27 Friendships. For trips outside of the Philippines, the Air Force employs a Bombardier Global Express or charters appropriate aircraft from the country's flag carrier, Philippine Airlines. In 1962, the Air Force chartered aircraft from Pan American World Airways as the international services of Philippine Airlines were suspended. Pan Am later went defunct in 1991. For short-haul flights, PAL used the Boeing 737 until they were replaced by Airbus A320 and Airbus A321 aircraft. For medium to long-haul flights, the airline's Boeing 747-400's were used until their retirement in September 2014. The Airbus A340-300, Airbus A330-300 and Boeing 777-300ER have since fulfilled these roles. Any PAL aircraft with the flight number PR/PAL 001 and callsign PHILIPPINE 001 is a special plane operated by Philippine Airlines to transport the President of the Philippines. The President sometimes charter private jets for domestic trips within the Philippines due to some airports in the Philippines having small runways.\\r\\nA Presidential Helicopter Bell 412 crashed on April 7, 2009, in the mountainous Ifugao Province north of Manila. On board were eight people, including two Cabinet undersecretaries and several servicemen. The flight was en route to Ifugao from Baguio City as an advance party of President Macapagal-Arroyo, when the control tower at the now-defunct Loakan Airport lost communication with the craft several minutes after takeoff.\\r\\nThe Arroyo administration planned to buy another aircraft worth of about 1.2?billion pesos before her term ended in June 2010,[47] but cancelled the purchase due to other issues.[48]\\r\\nBRP Ang Pangulo (BRP stands for Bark܇ ng Rep~blika ng Pilipinas, \\"Ship of the Republic of the Philippines\\"; \\"Ang Pangulo\\" is Filipino for \\"The President\\") was commissioned by the Philippine Navy on March 7, 1959. It was built in and by Japan during the administration of President Garca as part of Japanese reparations to the Philippines for World War II.[49] It is primarily used in entertaining guests of the incumbent President.\\r\\nThe President of the Philippines uses two black and heavily armored Mercedes-Benz W221 S600 Guard, whereas one is a decoy vehicle. In convoys, the President is escorted by the Presidential Security Group using primarily Nissan Patrol SUVs with the combination of the following vehicles: Audi A6, BMW 7 Series, Chevrolet Suburban, Hyundai Equus, Hyundai Starex, Toyota Camry, Toyota Fortuner, Toyota Land Cruiser, Philippine National Police 400cc motorcycles, Philippine National Police Toyota Altis (Police car variant), other government-owned vehicles, and ambulances at the tail of the convoy; the number depends on the destination. The presidential cars are designated and registered a plate number of 1 or the word PANGULO (President). The limousine bears the Flag of the Philippines and, occasionally, the Presidential Standard.[50]\\r\\nFor regional trips, the President boards a Toyota Coaster or Mitsubishi Fuso Rosa or other vehicles owned by government-owned and controlled corporations or government agencies. In this case, the PSG escorts the President using local police cars with an ambulance at the tail of the convoy.\\r\\nFormer President Benigno Aquino III, preferred to use his personal vehicle, a Toyota Land Cruiser 200 or his relative's Lexus LX 570 over the black Presidential limousines after their electronic mechanisms were damaged by floodwater. The Palace has announced its interest to acquire a new Presidential limousine.[51]\\r\\nThe current President, Rodrigo Duterte, prefers to utilize a white, bullet-proof armored Toyota Landcruiser as his official presidential vehicle instead of the \\"luxurious\\" Mercedes-Benz W221 S600 Guard, in his commitment to being the \\"People's President\\".\\r\\nThe Office of the President has also owned various cars over the decades, including a 1937 Chrysler Airflow that served as the country's very first Presidential limousine for Manuel L. Quezon.\\r\\nThe Presidential Security Group (abbreviated PSG), is the lead agency tasked with providing security for the President, Vice President, and their immediate families. They also provide protective service for visiting heads of state and diplomats.\\r\\nUnlike similar groups around the world who protect other political figures, the PSG is not required to handle presidential candidates. However, former Presidents and their immediate families are entitled to a small security detail from the PSG. Currently, the PSG uses Nissan Patrol SUVs as its primary security vehicles.\\r\\nAfter leaving office, a number of presidents held various public positions and made an effort to remain in the limelight. Among other honors, former Presidents and their immediate families are entitled to three soldiers as security detail.[52]\\r\\nAs of April 2018[update], there are four living former Presidents:","input":"Who is the current leader of the philippines?"},{"output":"Notre Dame","context":"The 1973 NCAA Division I football season was the first for the NCAA's current three-division structure. Effective with the 1973ÿ74 academic year, schools formerly in the NCAA \\"University Division\\" were classified as Division I (later subdivided for football only in 1978 (I-A and I-AA) and renamed in 2006 into today's Division I FBS and FCS). Schools in the former \\"College Division\\" were classified into Division II, which allowed fewer athletic scholarships than Division I, and Division III, in which athletic scholarships were prohibited.\\r\\nIn its inaugural season, Division I had two NCAA-recognized national champions, and they faced each other at year's end in the Sugar Bowl on New Year's Eve. The New Orleans game matched two unbeaten teams, the Alabama Crimson Tide (11-0), ranked #1 by AP and UPI, and the Notre Dame Fighting Irish (10ÿ0), ranked #3 by AP and #4 by UPI.\\r\\nWhile both wire services ranked Alabama #1 at the end of the regular season, the final AP poll was after the bowl games. By agreement with the American Football Coaches' Association, however, UPI bestowed its championship before the postseason bowl games, and Alabama was crowned champion by UPI on December 4.[2][3] UPI ranked Notre Dame #4. One coach had given the Irish a first place vote, compared to 21 for Alabama. (In the next season, the final coaches' poll was after the bowls.)[4]\\r\\nIn a game where the lead changed six times, Notre Dame won by a single point, 24ÿ23, to claim the AP national championship. During the 20th century, the NCAA had no playoff for major college football teams that would become Division I-A in 1978. The NCAA Football Guide, however, did note an \\"unofficial national champion\\" based on the top ranked teams in the \\"wire service\\" (AP and UPI) polls. The \\"writers' poll\\" by Associated Press (AP) was the most popular, followed by the \\"coaches' poll\\" by United Press International) (UPI). In 1973, the UPI issued its final poll before the bowls, but the AP Trophy was withheld until the postseason was completed. The AP poll in 1973 consisted of the votes of as many as 63 sportswriters and broadcasters, though not all of them voted in every poll. UPI's voting was made by 34 coaches. Those who cast votes would give their opinion of the ten best teams. Under a point system of 20 points for first place, 19 for second, etc., the \\"overall\\" ranking was determined.\\r\\n\\r\\n\\r\\nElsewhere, Tulane defeated LSU 14-0 to end a 25-year winless drought in the Battle for the Rag in the final meeting at Tulane Stadium. Also, the 4-7 Navy Midshipmen trounced the Army Cadets 51-0. As for the Cadets, they completed one of their worst season in their football program history, when they completed a season with an imperfect 0-10 record.\\r\\nIn the final regular season poll, the top six schools were unbeaten. 1.Alabama (11-0) 2. 2.Notre Dame (10-0) 3.Oklahoma (10-0-1) 4.Ohio State (9-0-1) 5.Michigan (10-0-1) and 6.Penn State (11-0). The other major college unbeaten, Miami (Ohio) (10-0-0), was #15. Oklahoma, however, was on probation for having used an ineligible player (Kerry Jackson) in three 1972 games, and was ineligible to play in a bowl game. #1 Alabama and #2 Notre Dame accepted invitations to play in the Sugar Bowl.\\r\\nMonday, December 31, 1973\\r\\nTuesday, January 1, 1974\\r\\nAlabama and Notre Dame had never met in a college football game before their encounter in the Sugar Bowl, which was played on New Year's Eve at Tulane Stadium, with kickoff at 7:15 pm CST.[6] Two legendary coaches, Bear Bryant and Ara Parseghian brought their teams to New Orleans, and the game was a thriller. The Irish scored first, but missed the extra point. After Alabama took a 7ÿ6 lead, freshman Al Hunter returned the ensuing kickoff 93 yards for a touchdown, and a two-point conversion put Notre Dame up 14ÿ7. Alabama went ahead 17ÿ14 in the third, but a fumble on their own 12-yard line gave the Irish a chance to make it 21ÿ17. In the fourth quarter, Bama got back the lead on a trick play, as quarterback Richard Todd handed off to running back, Mike Stock, who then fired a touchdown pass back to Todd; but Bill Davis, who had made 51 of 53 extra point attempts in his career, was wide right, and the score stayed 23ÿ21. In the final minutes, Notre Dame's Bob Thomas (who had missed the earlier point after try) kicked a 19-yard field goal that gave the team the 24ÿ23 win.[7][8] Asked whether Notre Dame would be voted #1, Coach Parseghian replied, \\"Certainly. What was the final score?\\"[9]\\r\\nThe final AP writers' poll was split. Notre Dame received a majority of the first place votes, 33 out of 60, followed by #2 Ohio State (11 votes) and #3 Oklahoma (16 votes, but fewer points overall). The fourth spot (held by Notre Dame in the final UPI poll) went to Alabama. UPI, who crowned Alabama as national champion at the end of the regular season,[2] would begin holding the coaches' poll after the bowl games beginning with the 1974 season.[4]\\r\\nRunning back John Cappelletti had the third best year in Penn State history when he gained 1,117 yards rushing in 1972. As a senior in 1973, he had the second best year in school history rushing for 1,522 yards. In his two-year running career, he gained 100 yards in the thirteen games and had a career total of 2,639 yards and twenty-nine touchdowns for an average of 120 yards per game and 5.1 yards per carry. Cappelletti's acceptance speech on December 13 at the Heisman Dinner (with Vice President Gerald Ford next to him on the dais) was considered the most moving ever given at these ceremonies, as he honored his 11-year-old brother Joey, a victim of leukemia.[10]\\r\\nSource:[11][12][13]","input":"Who won the 1973 college football national championship?"},{"output":"Wilhelm Maximilian Wundt","context":"","input":"Who is the founding father of modern psychology?"},{"output":"There have been six manned U.S. landings (between 1969 and 1972) and numerous unmanned landings","context":"??Luna programme (USSR)\\r\\n??Chang'e 3 (China)\\r\\n??Surveyor program (USA)\\r\\n??Apollo program (USA)\\r\\nA Moon landing is the arrival of a spacecraft on the surface of the Moon. This includes both manned and unmanned (robotic) missions. The first human-made object to reach the surface of the Moon was the Soviet Union's Luna 2 mission, on 13 September 1959.[3]\\r\\nThe United States' Apollo 11 was the first manned mission to land on the Moon, on 20 July 1969.[4] There have been six manned U.S. landings (between 1969 and 1972) and numerous unmanned landings, with no soft landings happening from 22 August 1976 until 14 December 2013.\\r\\nTo date, the United States is the only country to have successfully conducted manned missions to the Moon, with the last departing the lunar surface in December 1972.\\r\\n\\r\\n\\r\\nAfter the unsuccessful attempt by the Luna 1 to land on the moon in 1959, the Soviet Union performed the first hard (unpowered) moon landing later that same year with the Luna 2 spacecraft, a feat the U.S. duplicated in 1962 with Ranger 4. Since then, twelve Soviet and U.S. spacecraft have used braking rockets to make soft landings and perform scientific operations on the lunar surface, between 1966 and 1976. In 1966 the USSR accomplished the first soft landings and took the first pictures from the lunar surface during the Luna 9 and Luna 13 missions. The U.S. followed with five unmanned Surveyor soft landings.\\r\\nThe Soviet Union achieved the first unmanned lunar soil sample return with the Luna 16 probe on 24 September 1970. This was followed by Luna 20 and Luna 24 in 1972 and 1976, respectively. Following the failure at launch in 1969 of the first Lunokhod, Luna E-8 No.201, the Luna 17 and Luna 21 were successful unmanned lunar rover missions in 1970 and 1973.\\r\\nMany missions were failures at launch. In addition, several unmanned landing missions achieved the Lunar surface but were unsuccessful, including: Luna 15, Luna 18, and Luna 23 all crashed on landing; and the U.S. Surveyor 4 lost all radio contact only moments before its landing.\\r\\nMore recently, other nations have crashed spacecraft on the surface of the Moon at speeds of around 8,000 kilometres per hour (5,000?mph), often at precise, planned locations. These have generally been end-of-life lunar orbiters that, because of system degradations, could no longer overcome perturbations from lunar mass concentrations (\\"masscons\\") to maintain their orbit. Japan's lunar orbiter Hiten impacted the Moon's surface on 10 April 1993. The European Space Agency performed a controlled crash impact with their orbiter SMART-1 on 3 September 2006.\\r\\nIndian Space Research Organisation (ISRO) performed a controlled crash impact with its Moon Impact Probe (MIP) on 14 November 2008. The MIP was an ejected probe from the Indian Chandrayaan-1 lunar orbiter and performed remote sensing experiments during its descent to the lunar surface.\\r\\nThe Chinese lunar orbiter Chang'e 1 executed a controlled crash onto the surface of the Moon on 1 March 2009. The rover mission Chang'e 3 was launched on 1 December 2013 and soft-landed on 14 December.\\r\\nA total of twelve men have landed on the Moon. This was accomplished with two US pilot-astronauts flying a Lunar Module on each of six NASA missions across a 41-month period starting on 20 July 1969 UTC, with Neil Armstrong and Buzz Aldrin on Apollo 11, and ending on 14 December 1972 UTC with Gene Cernan and Jack Schmitt on Apollo 17. Cernan was the last to step off the lunar surface.\\r\\nAll Apollo lunar missions had a third crew member who remained on board the Command Module. The last three missions had a rover for increased mobility.\\r\\nIn order to go to the Moon, a spacecraft must first leave the gravity well of the Earth. The only practical way of accomplishing this currently is with a rocket. Unlike other airborne vehicles such as balloons or jets, a rocket is the only known form of propulsion which can continue to increase its speed at high altitudes in the vacuum outside the Earth's atmosphere.\\r\\nUpon approach of the target moon, a spacecraft will be drawn ever closer to its surface at increasing speeds due to gravity. In order to land intact it must decelerate to less than about 160 kilometres per hour (99?mph) and be ruggedized to withstand a \\"hard landing\\" impact, or it must decelerate to negligible speed at contact for a \\"soft landing\\" (which is the only viable option with human occupants). The first three attempts by the U.S. to perform a successful hard moon landing with a ruggedized seismometer package in 1962 all failed.[5] The Soviets first achieved the milestone of a hard lunar landing with a ruggedized camera in 1966, followed only months later by the first unmanned soft lunar landing by the U.S.\\r\\nThe speed of a crash landing on its surface is typically between 70 and 100% of the escape velocity of the target moon, and thus this is the total velocity which must be shed from the target moon's gravitational attraction for a soft landing to occur. For Earth's Moon, the escape velocity is 2.38 kilometres per second (1.48?mi/s).[6] The change in velocity (referred to as a delta-v) is usually provided by a landing rocket, which must be carried into space by the original launch vehicle as part of the overall spacecraft. An exception is the soft moon landing on Titan carried out by the Huygens probe in 2005. As the moon with the thickest atmosphere, landings on Titan may be accomplished by using atmospheric entry techniques that are generally lighter in weight than a rocket with equivalent capability.\\r\\nThe Soviets succeeded in making the first crash landing on the Moon in 1959.[7] Crash landings[8] may occur because of malfunctions in a spacecraft, or they can be deliberately arranged for vehicles which do not have an onboard landing rocket. There have been many such moon crashes, often with their flight path controlled to impact at precise locations on the lunar surface. For example, during the Apollo program the S-IVB third stage of the Saturn V moon rocket as well as the spent ascent stage of the lunar module were deliberately crashed on the Moon several times to provide impacts registering as a moonquake on seismometers that had been left on the lunar surface. Such crashes were instrumental in mapping the internal structure of the Moon.\\r\\nTo return to Earth, the escape velocity of the Moon must be overcome for the spacecraft to escape the gravity well of the Moon. Rockets must be used to leave the Moon and return to space. Upon reaching Earth, atmospheric entry techniques are used to absorb the kinetic energy of a returning spacecraft and reduce its speed for safe landing.[citation needed] These functions greatly complicate a moon landing mission and lead to many additional operational considerations. Any moon departure rocket must first be carried to the Moon's surface by a moon landing rocket, increasing the latter's required size. The Moon departure rocket, larger moon landing rocket and any Earth atmosphere entry equipment such as heat shields and parachutes must in turn be lifted by the original launch vehicle, greatly increasing its size by a significant and almost prohibitive degree.\\r\\nThe intense efforts devoted in the 1960s to achieving first an unmanned and then ultimately a manned moon landing become easier to understand in the political context of its historical era. World War II had introduced many new and deadly innovations including blitzkrieg-style surprise attacks used in the invasion of Poland and in the attack on Pearl Harbor; the V-2 rocket, a ballistic missile which killed thousands in attacks on London and Antwerp; and the atom bomb, which killed hundreds of thousands in the atomic bombings of Hiroshima and Nagasaki. In the 1950s, tensions mounted between the two ideologically opposed superpowers of the United States and the Soviet Union that had emerged as victors in the conflict, particularly after the development by both countries of the hydrogen bomb.\\r\\nWilly Ley wrote in 1957 that a rocket to the Moon \\"could be built later this year if somebody can be found to sign some papers\\".[9] On 4 October 1957, the Soviet Union launched Sputnik 1 as the first artificial satellite to orbit the Earth and so initiated the Space Race. This unexpected event was a source of pride to the Soviets and shock to the U.S., who could now potentially be surprise attacked by nuclear-tipped Soviet rockets in under 30 minutes.[citation needed] Also, the steady beeping of the radio beacon aboard Sputnik 1 as it passed overhead every 96 minutes was widely viewed on both sides[citation needed] as effective propaganda to Third World countries demonstrating the technological superiority of the Soviet political system compared to that of the U.S. This perception was reinforced by a string of subsequent rapid-fire Soviet space achievements. In 1959, the R-7 rocket was used to launch the first escape from Earth's gravity into a solar orbit, the first crash impact onto the surface of the Moon and the first photography of the never-before-seen far side of the Moon. These were the Luna 1, Luna 2 and Luna 3 spacecraft.\\r\\nThe U.S. response to these Soviet achievements was to greatly accelerate previously existing military space and missile projects and to create a civilian space agency, NASA. Military efforts were initiated to develop and produce mass quantities of intercontinental ballistic missiles (ICBMs) that would bridge the so-called missile gap and enable a policy of deterrence to nuclear war with the Soviets known as mutual assured destruction or MAD. These newly developed missiles were made available to civilians of NASA for various projects (which would have the added benefit of demonstrating the payload, guidance accuracy and reliabilities of U.S. ICBMs to the Soviets).\\r\\nWhile NASA stressed peaceful and scientific uses for these rockets, their use in various lunar exploration efforts also had secondary goal of realistic, goal-oriented testing of the missiles themselves and development of associated infrastructure,[citation needed] just as the Soviets were doing with their R-7.\\r\\nAfter the fall of the Soviet Union in 1991, historical records were released to allow the true accounting of Soviet lunar efforts. Unlike the U.S. tradition of assigning a particular mission name in advance of a launch, the Soviets assigned a public \\"Luna\\" mission number only if a launch resulted in a spacecraft going beyond Earth orbit. The policy had the effect of hiding Soviet Moon mission failures from public view. If the attempt failed in Earth orbit before departing for the Moon, it was frequently (but not always) given a \\"Sputnik\\" or \\"Cosmos\\" Earth-orbit mission number to hide its purpose. Launch explosions were not acknowledged at all.\\r\\nIn contrast to Soviet lunar exploration triumphs in 1959, success eluded initial U.S. efforts to reach the Moon with the Pioneer and Ranger programs. Fifteen consecutive U.S. unmanned lunar missions over a six-year period from 1958 to 1964 all failed their primary photographic missions;[10][11] however, Rangers 4 and 6 successfully repeated the Soviet lunar impacts as part of their secondary missions.[12][13]\\r\\nFailures included three U.S. attempts[5][12][14] in 1962 to hard land small seismometer packages released by the main Ranger spacecraft. These surface packages were to use retrorockets to survive landing, unlike the parent vehicle, which was designed to deliberately crash onto the surface. The final three Ranger probes performed successful high altitude lunar reconnaissance photography missions during intentional crash impacts between 2.62 and 2.68 kilometres per second (9,400 and 9,600?km/h).[15][16][17]\\r\\nThree different designs of Pioneer lunar probes were flown on three different modified ICBMs. Those flown on the Thor booster modified with an Able upper stage carried an infrared image scanning television system with a resolution of 1 milliradian to study the Moon's surface, an ionization chamber to measure radiation in space, a diaphragm/microphone assembly to detect micrometeorites, a magnetometer, and temperature-variable resistors to monitor spacecraft internal thermal conditions. The first, a mission managed by the United States Air Force, exploded during launch; all subsequent Pioneer lunar flights had NASA as the lead management organization. The next two returned to Earth and burned up upon reentry into the atmosphere after achieved maximum altitudes of around 110,000 kilometres (68,000?mi) and 1,450 kilometres (900?mi), far short of the roughly 400,000 kilometres (250,000?mi) required to reach the vicinity of the Moon.\\r\\nNASA then collaborated with the United States Army's Ballistic Missile Agency to fly two extremely small cone-shaped probes on the Juno ICBM, carrying only photocells which would be triggered by the light of the Moon and a lunar radiation environment experiment using a Geiger-Mller tube detector. The first of these reached an altitude of only around 100,000 kilometres (62,000?mi), serendipitously gathering data that established the presence of the Van Allen radiation belts before reentering Earth's atmosphere. The second passed by the Moon at a distance of more than 60,000 kilometres (37,000?mi), twice as far as planned and too far away to trigger either of the on-board scientific instruments, yet still becoming the first U.S. spacecraft to reach a solar orbit.\\r\\nThe final Pioneer lunar probe design consisted of four \\"paddlewheel\\" solar panels extending from a one-meter diameter spherical spin-stabilized spacecraft body that was equipped to take images of the lunar surface with a television-like system, estimate the Moon's mass and topography of the poles, record the distribution and velocity of micrometeorites, study radiation, measure magnetic fields, detect low frequency electromagnetic waves in space and use a sophisticated integrated propulsion system for maneuvering and orbit insertion as well. None of the four spacecraft built in this series of probes survived launch on its Atlas ICBM outfitted with an Able upper stage.\\r\\nFollowing the unsuccessful Atlas-Able Pioneer probes, NASA's Jet Propulsion Laboratory embarked upon an unmanned spacecraft development program whose modular design could be used to support both lunar and interplanetary exploration missions. The interplanetary versions were known as Mariners; lunar versions were Rangers. JPL envisioned three versions of the Ranger lunar probes: Block I prototypes, which would carry various radiation detectors in test flights to a very high Earth orbit that came nowhere near the Moon; Block II, which would try to accomplish the first Moon landing by hard landing a seismometer package; and Block III, which would crash onto the lunar surface without any braking rockets while taking very high resolution wide-area photographs of the Moon during their descent.\\r\\nThe Ranger 1 and 2 Block I missions were virtually identical.[18][19] Spacecraft experiments included a Lyman-alpha telescope, a rubidium-vapor magnetometer, electrostatic analyzers, medium-energy-range particle detectors, two triple coincidence telescopes, a cosmic-ray integrating ionization chamber, cosmic dust detectors, and scintillation counters. The goal was to place these Block I spacecraft in a very high Earth orbit with an apogee of 110,000 kilometres (68,000?mi) and a perigee of 60,000 kilometres (37,000?mi).[18]\\r\\nFrom that vantage point, scientists could make direct measurements of the magnetosphere over a period of many months while engineers perfected new methods to routinely track and communicate with spacecraft over such large distances. Such practice was deemed vital to be assured of capturing high-bandwidth television transmissions from the Moon during a one-shot fifteen-minute time window in subsequent Block II and Block III lunar descents. Both Block I missions suffered failures of the new Agena upper stage and never left low Earth parking orbit after launch; both burned up upon reentry after only a few days.\\r\\nThe first attempts to perform a Moon landing took place in 1962 during the Rangers 3, 4 and 5 missions flown by the United States.[5][12][14] All three Block II missions basic vehicles were 3.1?m high and consisted of a lunar capsule covered with a balsa wood impact-limiter, 650?mm in diameter, a mono-propellant mid-course motor, a retrorocket with a thrust of 5,050 pounds-force (22.5?kN),[12] and a gold- and chrome-plated hexagonal base 1.5?m in diameter. This lander (code-named Tonto) was designed to provide impact cushioning using an exterior blanket of crushable balsa wood and an interior filled with incompressible liquid freon. A 42?kg (56 pounds) 30-centimetre-diameter (0.98?ft) metal payload sphere floated and was free to rotate in a liquid freon reservoir contained in the landing sphere[citation needed].\\r\\nThis payload sphere contained six silver-cadmium batteries to power a fifty-milliwatt radio transmitter, a temperature sensitive voltage controlled oscillator to measure lunar surface temperatures, and a seismometer that was designed with sensitivity high enough to detect the impact of a 5?lb (2.3?kg) meteorite on the opposite side of the Moon. Weight was distributed in the payload sphere so it would rotate in its liquid blanket to place the seismometer into an upright and operational position no matter what the final resting orientation of the external landing sphere. After landing, plugs were to be opened allowing the freon to evaporate and the payload sphere to settle into upright contact with the landing sphere. The batteries were sized to allow up to three months of operation for the payload sphere. Various mission constraints limited the landing site to Oceanus Procellarum on the lunar equator, which the lander ideally would reach 66 hours after launch.\\r\\nNo cameras were carried by the Ranger landers, and no pictures were to be captured from the lunar surface during the mission. Instead, the 3.1 metres (10?ft) Ranger Block II mother ship carried a 200-scan-line television camera which was to capture images during the free-fall descent to the lunar surface. The camera was designed to transmit a picture every 10 seconds.[12] Seconds before impact, at 5 and 0.6 kilometres (3.11 and 0.37?mi) above the lunar surface, the Ranger mother ships took picture (which may be viewed here).\\r\\nOther instruments gathering data before the mother ship crashed onto the Moon were a gamma ray spectrometer to measure overall lunar chemical composition and a radar altimeter. The radar altimeter was to give a signal ejecting the landing capsule and its solid-fueled braking rocket overboard from the Block II mother ship. The braking rocket was to slow and the landing sphere to a dead stop at 330 metres (1,080?ft) above the surface and separate, allowing the landing sphere to free fall once more and hit the surface[citation needed].\\r\\nOn Ranger 3, failure of the Atlas guidance system and a software error aboard the Agena upper stage combined to put the spacecraft on a course that would miss the Moon. Attempts to salvage lunar photography during a flyby of the Moon were thwarted by in-flight failure of the onboard flight computer. This was probably because of prior heat sterilization of the spacecraft by keeping it above the boiling point of water for 24 hours on the ground, to protect the Moon from being contaminated by Earth organisms. Heat sterilization was also blamed for subsequent in-flight failures of the spacecraft computer on Ranger 4 and the power subsystem on Ranger 5. Only Ranger 4 reached the Moon in an uncontrolled crash impact on the far side of the Moon.[citation needed]\\r\\nHeat sterilization was discontinued for the final four Block III Ranger probes.[citation needed] These replaced the Block II landing capsule and its retrorocket with a heavier, more capable television system to support landing site selection for upcoming Apollo manned Moon landing missions. Six cameras were designed to take thousands of high-altitude photographs in the final twenty-minute period before crashing on the lunar surface. Camera resolution was 1,132 scan lines, far higher than the 525 lines found in a typical U.S. 1964 home television. While Ranger 6 suffered a failure of this camera system and returned no photographs despite an otherwise successful flight, the subsequent Ranger 7 mission to Mare Cognitum was a complete success.\\r\\nBreaking the six-year string of failures in U.S. attempts to photograph the Moon at close range, the Ranger 7 mission was viewed as a national turning point and instrumental in allowing the key 1965 NASA budget appropriation to pass through the United States Congress intact without a reduction in funds for the Apollo manned Moon landing program. Subsequent successes with Ranger 8 and Ranger 9 further buoyed U.S. hopes.\\r\\nThe Luna 9 spacecraft, launched by the Soviet Union, performed the first successful soft Moon landing on 3 February, 1966. Airbags protected its 99 kilograms (218?lb) ejectable capsule which survived an impact speed of over 15 metres per second (54?km/h).[20] Luna 13 duplicated this feat with a similar Moon landing on 24 December 1966. Both returned panoramic photographs that were the first views from the lunar surface.[21]\\r\\nLuna 16 was the first robotic probe to land on the Moon and safely return a sample of lunar soil back to Earth.[22] It represented the first lunar sample return mission by the Soviet Union, and was the third lunar sample return mission overall, following the Apollo 11 and Apollo 12 missions. This mission was later successfully repeated by Luna 20 (1972) and Luna 24 (1976).\\r\\nIn 1970 and 1973 two Lunokhod (\\"Moonwalker\\") robotic lunar rovers were delivered to the Moon, where they successfully operated for 10 and 4 months respectively, covering 10.5?km (Lunokhod 1) and 37?km (Lunokhod 2). These rover missions were in operation concurrently with the Zond and Luna series of Moon flyby, orbiter and landing missions.\\r\\nThe U.S. robotic Surveyor program was part of an effort to locate a safe site on the Moon for a human landing and test under lunar conditions the radar and landing systems required to make a true controlled touchdown. Five of Surveyor's seven missions made successful unmanned Moon landings. Surveyor 3 was visited two years after its Moon landing by the crew of Apollo 12. They removed parts of it for examination back on Earth to determine the effects of long-term exposure to the lunar environment.\\r\\nWithin four months of each other in early 1966 the Soviet Union and the United States had accomplished successful Moon landings with unmanned spacecraft. To the general public both countries had demonstrated roughly equal technical capabilities by returning photographic images from the surface of the Moon. These pictures provided a key affirmative answer to the crucial question of whether or not lunar soil would support upcoming manned landers with their much greater weight.\\r\\nHowever, the Luna 9 hard landing of a ruggedized sphere using airbags at a 50 kilometres (31?mi)-per-hour ballistic impact speed had much more in common with the failed 1962 Ranger landing attempts and their planned 160 kilometres (99?mi)-per-hour impacts than with the Surveyor 1 soft landing on three footpads using its radar-controlled, adjustable-thrust retrorocket. While Luna 9 and Surveyor 1 were both major national accomplishments, only Surveyor 1 had reached its landing site employing key technologies that would be needed for a manned flight. Thus as of mid-1966, the United States had begun to pull ahead of the Soviet Union in the so-called Space Race to land a man on the Moon.\\r\\nAdvances in other areas were necessary before manned spacecraft could follow unmanned ones to the surface of the Moon. Of particular importance was developing the expertise to perform flight operations in lunar orbit. Ranger, Surveyor and initial Luna Moon landing attempts all utilized flight paths from Earth that traveled directly to the lunar surface without first placing the spacecraft in a lunar orbit. Such direct ascents use a minimum amount of fuel for unmanned spacecraft on a one-way trip.\\r\\nIn contrast, manned vehicles need additional fuel after a lunar landing to enable a return trip back to Earth for the crew. Leaving this massive amount of required Earth-return fuel in lunar orbit until it is used later in the mission is far more efficient than taking such fuel down to the lunar surface in a Moon landing and then hauling it all back into space yet again, working against lunar gravity both ways. Such considerations lead logically to a lunar orbit rendezvous mission profile for a manned Moon landing.\\r\\nAccordingly, beginning in mid-1966 both the U.S. and U.S.S.R. naturally progressed into missions which featured lunar orbit operations as a necessary prerequisite to a manned Moon landing. The primary goals of these initial unmanned orbiters were extensive photographic mapping of the entire lunar surface for the selection of manned landing sites and, for the Soviets, the checkout of radio communications gear that would be used in future soft landings.\\r\\nAn unexpected major discovery from initial lunar orbiters were vast volumes of dense materials beneath the surface of the Moon's maria. Such mass concentrations (\\"mascons\\") can send a manned mission dangerously off course in the final minutes of a Moon landing when aiming for a relatively small landing zone that is smooth and safe. Mascons were also found over a longer period of time to greatly disturb the orbits of low-altitude satellites around the Moon, making their orbits unstable and forcing an inevitable crash on the lunar surface in the relatively short period of months to a few years.\\r\\nControlling the location of impact for spent lunar orbiters can have scientific value. For example, in 1999 the NASA Lunar Prospector orbiter was deliberately targeted to impact a permanently shadowed area of Shoemaker Crater near the lunar south pole. It was hoped that energy from the impact would vaporize suspected shadowed ice deposits in the crater and liberate a water vapor plume that would be detectable from Earth. No such plume was observed. However, a small vial of ashes from the body of pioneer lunar scientist Eugene Shoemaker was delivered by the Lunar Prospector to the crater named in his honor ÿ currently the only human remains on the Moon.\\r\\nLuna 10 became the first spacecraft to orbit the Moon on 3 April 1966.\\r\\nIt is possible to aim a spacecraft from Earth so that it will loop around the Moon and return to Earth without entering lunar orbit, following the so-called free return trajectory. Such circumlunar loop missions are simpler than lunar orbit missions because rockets for lunar orbit braking and Earth return are not required. However, a manned circumlunar loop trip poses significant challenges above and beyond those found in a manned low-Earth-orbit mission, offering valuable lessons in preparation for a manned Moon landing. Foremost among these are mastering the demands of re-entering the Earth's atmosphere upon returning from the Moon.\\r\\nManned Earth-orbiting vehicles such as the Space Shuttle return to Earth from speeds of around 17,000 miles per hour (27,000?km/h; 7,600?m/s). Due to the effects of gravity, a vehicle returning from the Moon hits Earth's atmosphere at a much higher speed of around 25,000 miles per hour (40,000?km/h; 11,000?m/s). The g-loading on astronauts during the resulting deceleration can be at the limits of human endurance even during a nominal reentry. Slight variations in the vehicle flight path and reentry angle during a return from the Moon can easily result in fatal levels of deceleration force.\\r\\nAchieving a manned circumlunar loop flight prior to a manned lunar landing became a primary goal of the Soviets with their Zond spacecraft program. The first three Zonds were unmanned planetary probes; after that, the Zond name was transferred to a completely separate manned program. The initial focus of these later Zonds was extensive testing of required high-speed reentry techniques. This focus was not shared by the U.S., who chose instead to bypass the stepping stone of a manned circumlunar loop mission and never developed a separate spacecraft for this purpose.\\r\\nInitial manned spaceflights in the early 1960s placed a single person in low Earth orbit during the Soviet Vostok and U.S. Mercury programs. A two-flight extension of the Vostok program known as Voskhod effectively used Vostok capsules with their ejection seats removed to achieve Soviet space firsts of multiple person crews in 1964 and spacewalks in early 1965. These capabilities were later demonstrated by the U.S. in ten Gemini low Earth orbit missions throughout 1965 and 1966, using a totally new second-generation spacecraft design that had little in common with the earlier Mercury. These Gemini missions went on to prove critical techniques for orbital rendezvous and docking that were crucial to a manned lunar landing mission profile.\\r\\nAfter the end of the Gemini program, the Soviets Union began flying their second-generation Zond manned spacecraft in 1967 with the ultimate goal of looping a cosmonaut around the Moon and returning him immediately to Earth. The Zond spacecraft was launched with the simpler and already operational Proton launch rocket, unlike the parallel Soviet manned Moon landing effort also underway at the time based on third-generation Soyuz spacecraft requiring development of the advanced N-1 booster. The Soviets thus believed they could achieve a manned Zond circumlunar flight years before a U.S. manned lunar landing and so score a propaganda victory. However, significant development problems delayed the Zond program and the success of the U.S. Apollo lunar landing program led to the eventual termination of the Zond effort.\\r\\nLike Zond, Apollo Moon flights were generally launched on a free return trajectory that would return them to Earth via a circumlunar loop in the event that a Service Module malfunction failed to place them in lunar orbit as planned. This option was implemented after an explosion aboard the Apollo 13 mission in 1970, which is the only manned circumlunar loop mission flown to date.\\r\\nZond 5 was the first spacecraft to carry life from Earth to the vicinity of the Moon and return, initiating the final lap of the Space Race with its payload of turtles, insects, plants and bacteria. Despite the failure suffered in its final moments, the Zond 6 mission was reported by Soviet media as being a success as well. Although hailed worldwide as remarkable achievements, both of these Zond missions flew off-nominal reentry trajectories resulting in deceleration forces that would have been fatal to human crewmembers had they been aboard.\\r\\nAs a result, the Soviets secretly planned to continue unmanned Zond tests until their reliability to support manned flight had been demonstrated. However, due to NASA's continuing problems with the lunar module, and because of CIA reports of a potential Soviet manned circumlunar flight in late 1968, NASA fatefully changed the flight plan of Apollo 8 from an Earth-orbit lunar module test to a lunar orbit mission scheduled for late December 1968.\\r\\nIn early December 1968 the launch window to the Moon opened for the Soviet launch site in Baikonur, giving the USSR their final chance to beat the US to the Moon. Cosmonauts went on alert and asked to fly the Zond spacecraft then in final countdown at Baikonur on the first manned trip to the Moon. Ultimately, however, the Soviet Politburo decided the risk of crew death was unacceptable given the combined poor performance to that point of Zond/Proton and so scrubbed the launch of a manned Soviet lunar mission. Their decision proved to be a wise one, since this unnumbered Zond mission was destroyed in another unmanned test when it was finally launched several weeks later.\\r\\nBy this time flights of the third generation U.S. Apollo spacecraft had begun. Far more capable than the Zond, the Apollo spacecraft had the necessary rocket power to slip into and out of lunar orbit and to make course adjustments required for a safe reentry during the return to Earth. The Apollo 8 mission carried out the first manned trip to the Moon on 24 December 1968, certifying the Saturn V booster for manned use and flying not a circumlunar loop but instead a full ten orbits around the Moon before returning safely to Earth. Apollo 10 then performed a full dress rehearsal of a manned Moon landing in May 1969. This mission orbited within 47,400 feet (14.4?km) altitude above the lunar surface, performing necessary low-altitude mapping of trajectory-altering mascons using a factory prototype lunar module that was too overweight to allow a successful landing. With the failure of the unmanned Soviet sample return Moon landing attempt Luna 15 in July 1969, the stage was set for Apollo 11.\\r\\nPlans for manned Moon exploration originated during the Eisenhower administration. In a series of mid-1950s articles in Collier's magazine, Wernher von Braun had popularized the idea of a manned expedition to the Moon to establish a lunar base. A manned Moon landing posed several daunting technical challenges to the US and USSR. Besides guidance and weight management, atmospheric re-entry without ablative overheating was a major hurdle. After the Soviet Union's launch of Sputnik, von Braun promoted a plan for the United States Army to establish a military lunar outpost by 1965.\\r\\nAfter the early Soviet successes, especially Yuri Gagarin's flight, US President John F. Kennedy looked for a US project that would capture the public imagination. He asked Vice President Lyndon Johnson to make recommendations on a scientific endeavor that would prove US world leadership. The proposals included non-space options such as massive irrigation projects to benefit the Third World. The Soviets, at the time, had more powerful rockets than the United States, which gave them an advantage in some kinds of space mission.\\r\\nAdvances in US nuclear weapon technology had led to smaller, lighter warheads, and consequently, rockets with smaller payload capacities. By comparison, Soviet nuclear weapons were much heavier, and the powerful R-7 rocket was developed to carry them. More modest potential missions such as flying around the Moon without landing or establishing a space lab in orbit (both were proposed by Kennedy to von Braun) were determined to offer too much advantage to the Soviets, since the US would have to develop a heavy rocket to match the Soviets. A Moon landing, however, would capture world imagination while functioning as propaganda.\\r\\nJohnson had championed the US manned space program ever since the Sputnik scare, sponsoring the legislation which created NASA when he was in the Senate in 1958. When Kennedy asked him in 1961 to research the best manned space achievement to counter the Soviets' lead, Johnson responded that the US had an even chance of beating the USSR to a manned lunar landing, but not for anything less. Kennedy seized on Apollo as the ideal focus for efforts in space. He ensured continuing funding, shielding space spending from the 1963 tax cut, but diverting money from other NASA scientific projects. This last dismayed NASA's leader, James E. Webb, who perceived the need for NASA's support from the scientific community.\\r\\nThe Moon landing required development of the large Saturn V launch vehicle, which achieved a perfect record of zero catastrophic failures or launch vehicle-caused mission failures, in thirteen launches.\\r\\nFor the program to succeed, its proponents would have to defeat criticism from politicians on the left, who wanted more money spent on social programs, and on those on the right, who favored a more military project. By emphasizing the scientific payoff and playing on fears of Soviet space dominance, Kennedy and Johnson managed to swing public opinion: by 1965, 58 percent of Americans favored Apollo, up from 33 percent two years earlier. After Johnson became President in 1963, his continuing defense of the program allowed it to succeed in 1969, as Kennedy planned.\\r\\nSoviet leader Nikita Khrushchev said in October 1963 that the USSR was \\"not at present planning flight by cosmonauts to the Moon,\\" while insisting that the Soviets had not dropped out of the race. Only after another year would the USSR fully commit itself to a Moon-landing attempt, which ultimately failed.\\r\\nAt the same time, Kennedy had suggested various joint programs, including a possible Moon landing by Soviet and U.S. astronauts and the development of better weather-monitoring satellites. Khrushchev, sensing an attempt by Kennedy to steal Russian space technology, rejected the idea: if the USSR went to the Moon, it would go alone. Sergey Korolev, the Soviet space program's chief designer, had started promoting his Soyuz craft and the N1 launcher rocket that would have the capability of carrying out a manned Moon landing.\\r\\nKhrushchev directed Korolev's design bureau to arrange further space firsts by modifying the existing Vostok technology, while a second team started building a completely new launcher and craft, the Proton booster and the Zond, for a manned cislunar flight in 1966. In 1964 the new Soviet leadership gave Korolev the backing for a Moon landing effort and brought all manned projects under his direction.\\r\\nWith Korolev's death and the failure of the first Soyuz flight in 1967, the co-ordination of the Soviet Moon landing program quickly unraveled. The Soviets built a landing craft and selected cosmonauts for the mission that would have placed Aleksei Leonov on the Moon's surface, but with the successive launch failures of the N1 booster in 1969, plans for a manned landing suffered first delay and then cancellation.\\r\\nIn total, twenty-four U.S. astronauts have traveled to the Moon. Three have made the trip twice, and twelve have walked on its surface. Apollo 8 was a lunar-orbit-only mission, Apollo 10 included undocking and Descent Orbit Insertion (DOI), followed by LM staging to CSM redocking, while Apollo 13, originally scheduled as a landing, ended up as a lunar fly-by, by means of free return trajectory; thus, none of these missions made landings. Apollo 7 and Apollo 9 were Earth-orbit-only missions. Apart from the inherent dangers of manned Moon expeditions as seen with Apollo 13, one reason for their cessation according to astronaut Alan Bean is the cost it imposes in government subsidies.[23]\\r\\nUnlike other international rivalries, the Space Race has remained unaffected in a direct way regarding the desire for territorial expansion. After the successful landings on the Moon, the U.S. explicitly disclaimed the right to ownership of any part of the Moon.\\r\\nPresident Richard Nixon had speechwriter William Safire prepare a condolence speech for delivery in the event that Armstrong and Aldrin became marooned on the Moon's surface and could not be rescued.[24]\\r\\nIn 1951, science fiction writer Arthur C. Clarke forecast that man would reach the Moon by 1978.[25]\\r\\nOn 16 August 2006, the Associated Press reported that NASA is missing the original Slow-scan television tapes (which were made before the scan conversion for conventional TV) of the Apollo 11 Moon walk. Some news outlets have mistakenly reported that the SSTV tapes were found in Western Australia, but those tapes were only recordings of data from the Apollo 11 Early Apollo Surface Experiments Package.[26]\\r\\nScientists believe the six American flags planted by astronauts have been bleached white because of more than 40 years of exposure to solar radiation.[27] Using LROC images, five of the six American flags are still standing and casting shadows at all of the sites, except Apollo 11.[28] Astronaut Buzz Aldrin reported that the flag was blown over by the exhaust from the ascent engine during liftoff of Apollo 11.[28]\\r\\nLaunched on 24 January 1990, 11:46 UTC. At the end of its mission, the Japanese lunar orbiter Hiten was commanded to crash into the lunar surface and did so on 10 April 1993 at 18:03:25.7 UT (11 April 03:03:25.7 JST).[29]\\r\\nLunar Prospector was launched on 7 January 1998. The mission ended on 31 July 1999, when the orbiter was deliberately crashed into a crater near the lunar south pole after the presence of water ice was successfully detected.[30]\\r\\nLaunched 27 September 2003, 23:14 UTC from the Guiana Space Centre in Kourou, French Guiana. At the end of its mission, the ESA lunar orbiter SMART-1 performed a controlled crash into the Moon, at about 2?km/s. The time of the crash was 3 September 2006, at 5:42 UTC.[31]\\r\\nSELENE or Kaguya was launched on 14 September 2007. After successfully orbiting the Moon for a year and eight months, the main orbiter was instructed to impact on the lunar surface near the crater Gill at 18:25 UTC on 10 June 2009.[32]\\r\\nThe Chinese lunar orbiter Chang'e 1, launched 24 October 2007, 10:05 UTC, executed a controlled crash onto the surface of the Moon on 1 March 2009, 20:44 GMT, after a 16-month mission.[33]\\r\\nChandrayaan-1 was launched on 22 October 2008, 00:52 UTC. The impactor, the Moon Impact Probe, impacted near Shackleton Crater at the south pole of the lunar surface at 14 November 2008, 20:31 IST.[34] Chandrayaan-2 is scheduled for launch in 2018.\\r\\nThe LCROSS data collecting shepherding spacecraft was launched together with the Lunar Reconnaissance Orbiter (LRO) on 18 June 2009 on board an Atlas V rocket with a Centaur upper stage. On 9 October 2009, at 11:31 UTC, the Centaur upper stage impacted the lunar surface, releasing the kinetic energy equivalent of detonating approximately 2 tons of TNT (8.86 GJ).[35] Six minutes later at 11:37 UTC, the LCROSS shepherding spacecraft also impacted the surface.[36]\\r\\nThe GRAIL mission consisted of two small spacecraft: GRAIL A (Ebb), and GRAIL B (Flow). They were launched on 10 September 2011 on board a Delta II rocket. GRAIL A separated from the rocket about nine minutes after launch, and GRAIL B followed about eight minutes later.[37][38] The first probe entered orbit on 31 December 2011 and the second followed on 1 January 2012.[39] The two spacecraft impacted the Lunar surface on 17 December 2012.[40]\\r\\nLADEE was launched on 7 September 2013.[41] The mission ended on 18 April 2014, when the spacecraft's controllers intentionally crashed LADEE into the far side of the Moon,[42][43] which, later, was determined to be near the eastern rim of Sundman V crater.[44][45]\\r\\nOn 14 December 2013 at 13:12 UTC[46] Chang'e 3 soft-landed a rover on the Moon. This was the first lunar soft landing since Luna 24 on 22 August 1976.[47]\\r\\nProgress in space exploration has recently broadened the phrase moon landing to include other moons in the Solar System as well. The Huygens probe of the CassiniÿHuygens mission to Saturn performed a successful unmanned moon landing on Titan in 2005. Similarly, the Soviet probe Phobos 2 came within 120?mi (190?km) of performing an unmanned moon landing on Mars' moon Phobos in 1989 before radio contact with that lander was suddenly lost. A similar Russian sample return mission called Fobos-Grunt (\\"grunt\\" means \\"soil\\" in Russian) launched in November 2011, but stalled in low Earth orbit. There is widespread interest in performing a future moon landing on Jupiter's Europa moon to drill down and explore the possible liquid water ocean beneath its icy surface.\\r\\nChina is planning to land another rover and collect samples in the Chang'e 4 mission and return lunar soil samples by 2018 in the Chang'e 5 mission.[48]\\r\\nISRO, the Indian National Space agency, is planning a second version of Chandrayaan named Chandrayaan 2. According to former ISRO Chairman G. Madhavan Nair, \\"The Indian Space Research Organisation (ISRO) hopes to land two rovers ÿ one Indian and another Russian ÿ on the Moon in 2018, as a part of its second Chandrayaan mission. The rover will be designed to move on wheels on the lunar surface, pick up samples of soil or rocks, do on-site chemical analysis and send the data to the mother-spacecraft Chandrayaan II, which will be orbiting above. Chandrayaan II will transmit the data to Earth.\\" The payloads have already been finalized.[49][50] ISRO has mentioned that due to weight restrictions it will not be carrying any overseas payloads on this mission. The lander weight is projected to be 1,250?kg, and the spacecraft will be launched by the Geosynchronous Satellite Launch Vehicle.\\r\\nRussia's Luna-Glob 1 is expected to be launched in 2018.[51] In 2007 the head of the Russian Space Agency announced plans to send cosmonauts to the Moon by 2025 and establish a permanent robotically operated base there in 2027ÿ2032.[52] In 2015, Roscosmos stated that Russia plans to place a cosmonaut on the Moon by 2030, leaving Mars to NASA. The purpose is to work jointly with NASA and avoid another Space Race.[53]\\r\\nThe Lunar Precursor Robotic Program (LPRP) is a program of robotic spacecraft missions which NASA will use to prepare for future Moon landings.[54] Three orbiters have been launched in the program, the Lunar Reconnaissance Orbiter (LRO), the Lunar Crater Observation and Sensing Satellite (LCROSS), and the Lunar Atmosphere and Dust Environment Explorer (LADEE), launched in 2013, but no Moon landings are scheduled yet.\\r\\nThe Google Lunar X Prize competition offers a $20?million award for the first privately funded team to land a robotic probe on the Moon. Like the Ansari X Prize before it, the competition aims to advance the state of the art in private space exploration.[55] Of the several competing teams, Puli Space Technologies at one time (2012) planned to launch in 2014[56][needs update] and Astrobotic Technology plans to launch in the second half of 2016 with their own rover plus another team's lunar rovers from Hakuto.[57][58]\\r\\nMany conspiracy theorists hold that the Apollo Moon landings were a hoax;[59] however, empirical evidence is readily available to show that manned moon landings did indeed occur. Anyone on Earth with an appropriate laser and telescope system can bounce laser beams off three retroreflector arrays left on the Moon by Apollo 11,[60] 14 and 15, verifying deployment of the Lunar Laser Ranging Experiment at historically documented Apollo Moon landing sites and so proving equipment constructed on Earth was successfully transported to the surface of the Moon. In addition, in August 2009 NASA's Lunar Reconnaissance Orbiter began to send back high resolution photos of the Apollo landing sites. These photos show not only the large Descent Stages of the lunar landers left behind but also tracks of the astronauts' walking paths in the lunar dust.[61]","input":"How many times have we been to the moon nasa?"},{"output":"The Calico log ride","context":"Knotts Berry Farm is a 160-acre (65?ha) theme park located in Buena Park, California, and owned by Cedar Fair. In 2017, it was the tenth-most-visited theme park in North America. Knott's Berry Farm is also the most-visited theme park in the Cedar Fair chain.[3] The park features 35 rides including roller coasters, family rides, and water rides, and it employs approximately 10,000 employees.[4]\\r\\n\\r\\nThe origin of the theme park dates back to 1920, when Walter Knott and his family began selling berry products at a roadside stand along State Route 39 in California. By the 1940s, a restaurant, several shops, and other attractions had been constructed on the property to entertain a growing number of visitors, including a replica ghost town. The site continued its transformation into a modern amusement park over the next two decades, and an admission charge was added in 1968. The park was sold to Cedar Fair in the late 1990s, and the family's food business was eventually acquired by The J. M. Smucker Company.\\r\\n\\r\\nThe theme park sits on the site of a former berry farm established by Walter Knott and his family. Beginning around 1920, the Knott family sold berries, berry preserves, and pies from a roadside stand along State Route 39. In 1934, the Knotts began selling fried chicken dinners in a tea room on the property, later called \\"Mrs. Knott's Chicken Dinner Restaurant\\". The dinners soon became a major tourist draw, and the Knotts built several shops and other attractions to entertain visitors while waiting for a seat in the restaurant. In 1940, Walter Knott began constructing a replica Ghost Town on the property, the beginning of the present-day theme park. The idea of an amusement park really picked up in the 1950s when Walter Knott opened a \\"summer-long county fair\\".\\r\\n\\r\\nIn 1968, for the first time, an admission price was required to get into the park, originally set at 25 cents. The Calico log ride was added in 1969. The park became a popular destination for conservative college students in the 1960s, especially as conservative organizations like the California Free Enterprise Association, the Libres Foundation, and the Americanism Educational League were based there.[5] According to Assistant Professor Caroline Rolland-Diamond of the Paris West University Nanterre La Dfense:\\r\\n\\r\\nit also appealed to conservative Americans, young and old, because the idealized representation of a past devoid of social and racial tensions that it offered stood in sharp contrast with the political and social upheavals affecting California since the Free Speech Movement erupted at the University of California at Berkeley in 1964.\\r\\nOn April 12, 1974, Cordelia Knott died. Walter turned his attention toward political causes,[7][8] Roaring Twenties[9] re-themed Gypsy Camp in the 1970s with the addition of a nostalgic traditional amusement area, Wheeler Dealer Bumper Cars, Knott's Bear-y Tales. Then with the northward expansion of a 1920s-era Knott's Airfield themed area featuring the Cloud 9 Dance Hall, Sky Cabin/Parachute Sky Jump and Motorcycle Chase steeplechase roller coaster above the electric guided rail Gasoline Alley car ride.[10]\\r\\n\\r\\nSky Tower with the illuminated \\"K\\" in logo script at the top was built to support two attractions, the Parachute Sky Jump (now closed) and the Sky Cabin. Parachute Sky Jump boarded one or two standing riders anticipating the thrill of the drop into baskets beneath a faux parachute canopy. From the top, eight arms supported the vertical cable tracks of wire rope which lifted the baskets. The Sky Cabin ringed the support pole with a single floor of seats that are enclosed behind windows. The Sky Cabin ring revolves slowly as it rises to the top and back offering a pleasantly changing vista. Sky Cabin is very sensitive to weather and passenger motion, such as walking, which is prohibited during the trip. During winds 25+?mph or rain it is closed. When built, Sky Tower was the tallest structure in Orange County (a distinction briefly held by WindSeeker before its relocation to Worlds of Fun in 2012.)\\r\\n\\r\\nMotorcycle Chase, modernized steeplechase rollercoaster built in 1976 by Arrow Development, featured single motorbike themed vehicles racing side-by-side, each on one of four parallel tracks, launched together.[10] One or two riders straddled each \\"Indian motorcycle\\" attraction vehicle. The tubular steel monorail track closely followed dips and bumps in \\"the road\\" and tilted to lean riders about the curves. Gasoline Alley, an electric steel-guiderail car ride below, was built together and intimately intertwined, which enhanced ride-to-ride interaction thrill value.[11] Rider safety concerns of the high center of gravity coupled with the method of rider restraints caused it to be re-themed Wacky Soap Box Racers with vehicles themed to look like soap box racers, each seating two riders, strapped in low (nearly straddling the track), surrounded by the close fitting car sides, and the dips and bumps of the track were straightened flat in 1980.\\r\\nMotorcycle Chase/Wacky Soap Box Racers was removed 1996 for a dueling loop coaster Windjammer Surf Racers and now Xcelerator, a vertical launch coaster, takes its place.\\r\\n\\r\\nOn December 3, 1981, Walter Knott died, survived by his children who would continue to operate Knott's as a family business for another fourteen years.\\r\\n\\r\\nIn the 1980s, Knott's built the Barn Dance featured Bobbi & Clyde as the house band. It was during the height of the \\"Urban Cowboy\\" era. The \\"Barn Dance\\" was featured in Knott's TV Commercials.\\r\\n\\r\\nDuring the 1980s, Knott's met the competition in Southern California theme parks by theming a new land and building two massive attractions:\\r\\n\\r\\nThe Boomerang roller coaster replaced the Corkscrew[9] in 1990 with a lift shuttle train passing to and fro through a cobra roll and a vertical loop for six inversions each trip.\\r\\n\\r\\nMystery Lodge (1994),[12] inspired by General Motors \\"Spirit Lodge\\" pavilion, was a live show augmented with Pepper's ghost and other special effects, which was among the most popular exhibits at Expo 86 in Vancouver, British Columbia, Canada, which was produced by Bob Rogers of BRC Imagination Arts[13] and created with the assistance of the Kwagulth Native reserve in the village of Alert Bay, British Columbia.[14] Mystery Lodge recreates a quiet summer night in Alert Bay, then guests \\"move inside\\" the longhouse and listen to the storyteller weave a tale of the importance of family from the smoke of the bonfire.\\r\\n\\r\\nThe Jaguar! was opened June 17, 1995, to add another roller coaster to the mix of Fiesta Village alongside Montezooma's Revenge.\\r\\n\\r\\nIn the 1990s, after Walter and Cordelia died, their children decided to sell off their businesses:\\r\\n\\r\\nIn the late 1990s Cedar Fair acquired the Buena Park Hotel at the corner of Grand Ave. and Crescent. It was then brought up to Radisson standards and branded Radisson Resort Hotel as a franchise. In 2004, the park renamed the Radisson Resort Hotel the Knott's Berry Farm Resort Hotel.\\r\\n\\r\\nIn 1995, the Knott family sold the food specialty business to ConAgra Foods, which later re-sold the brand to The J.M. Smucker Company in 2008.\\r\\n\\r\\nIn 1997, the Knott family sold the amusement park operations to Cedar Fair Entertainment Company. Initially, the Knotts were given an opportunity to sell the park to The Walt Disney Company. The park would have been amalgamated into the Disneyland Resort and converted into Disney's America, which had previously failed to be built near Washington, D.C. The Knotts refused to sell the park to Disney out of fear most of what Walter Knott had built would be eliminated.\\r\\n\\r\\nSince being acquired by Cedar Fair, the park has seen an aggressive shift towards thrill rides, with the construction of a number of large roller coasters and the addition of a high-performance Shoot-the-Chutes ride Perilous Plunge. Perilous Plunge had the record of being the tallest and steepest water ride in the world until September 2012 when it was closed and removed.[15] Also, in 2013, Knott's Berry Farm announced that the most popular ride at the park, the Timber Mountain Log Ride, would be closed for a major five-month refurbishment, led by Garner Holt Productions, Inc.[16]\\r\\n\\r\\nOn May 25, 2013, Knott's Berry Farm added three new family rides on the site of former Perilous Plunge. They include: Coast Rider (wild mouse roller coaster), Pacific Scrambler (Scrambler ride) and Surfside Gliders. All three of the rides added to the Boardwalk theme. The old bridge which connected the exit of Perlious Plunge and the boardwalk is now used as the entrance to Surfside Gliders and Pacific Scrambler. The Boomerang roller coaster was also repainted a lime-green color as part of the Boardwalk expansion.\\r\\n\\r\\nOn September 2, 2013, Knott's Berry Farm announced that Windseeker would be removed from the park.  The ride was removed and sent to Worlds of Fun for the 2014 season.\\r\\n\\r\\nOn November 22, 2013, Knott's Berry Farm made a major announcement for the 2014 operating season; the famous and historical Calico Mine Ride would be closed for a major six-month refurbishment beginning in January 2014.[17]\\r\\n\\r\\nThe park's annual Knott's Scary Farm has drawn crowds since 1973. The idea for this event was presented at one of the regularly scheduled round table meetings for managers by Patricia Pawson. The actual event was created by Bill Hollingshead, Gary Salisbury, Martha Boyd and Gene Witham, along with other members of the Knott's Berry Farm Entertainment Department as documented in the DVD Season of Screams. Initially fake corpses and other static figures were rented from Hollywood prop house, but Bud Hurlbut, the creator/concessionaire of the Mine Ride, Log Ride and other rides at Knott's, decided that this wasn't enough.[26] He dressed up in a gorilla suit, and started scaring guests on the Mine Ride. Halloween Haunt was an instant hit, and by the next year, the event sold out nightly.[27] During this special ticketed event, the entire park (or major portions of it) re-themes itself into a \\"haunted house\\" style attraction in the form of mazes and \\"scare zones\\" in the evening. Over a thousand specially employed monsters are also scatteredoften hidden out of viewthroughout the park at this time. Some of the characters have become well-known, such as the green witch, which has been portrayed by Charlene Parker since 1983, the longest of any performer.[28][29][30][31][32][33][34] Several attractions are decorated for the event including the Timber Mountain Log Ride and Calico Mine Train and there are 13 mazes of various themes. Elvira (actress Cassandra Peterson) was introduced into the Halloween Event in 1982 and was prominently featured in many Halloween Haunt events until 2001. According to postings on her My Space page, Cassandra was released from her contract by the park's new owners due to their wanting a more family friendly appeal,[35] although she returned for one night in 2012 for the 40th anniversary of the event and has returned as a regular performer throughout the run of the event for the last several years.[36] During the month of October, Knott's Scary Farm generates half the revenue for Knott's Berry Farm's fiscal year.[citation needed]\\r\\n\\r\\nSeason of Screams is a DVD produced by an independent company which traces the beginnings of Halloween Haunt and the story behind how it all got started back in 1973. Season of Screams also highlights recent Halloween Haunts.\\r\\n\\r\\nWinter Coaster Solace is an event that takes place in the first or second weekend of March every year when roller coaster enthusiasts can come before the park opens and stay after the park closes to ride the rides and eat at the Chicken Dinner Restaurant. It is intended to provide \\"solace\\" to visitors from other parts of the country where theme parks and roller coasters are seasonal, not year-round operations like the Southern California parks. Knott's Berry Farm also used to give attendees behind the scenes tours of the rides.\\r\\n\\r\\nEvery year since 1991, Knott's has offered free admission to veterans and their families during the month of November. Though this was originally started as a tribute to returning Gulf War veterans, they subsequently expanded it to include all veterans and have run it every year since.\\r\\n\\r\\nA Christmas event known as \\"Knott's Merry Farm\\" also happens annually. Previous Merry Farm events have included manufactured snow, handcrafts exhibits, and a visit with Santa Claus. This event was originally created by Gary Salisbury in the Fall of 1985.\\r\\n\\r\\nPraise (festival) has been a Christian themed celebration presented many years as a mix-in special event of music and comedy on New Year's Eve.\\r\\n\\r\\nThe park consists of four themed areas:\\r\\n\\r\\nCraftsmen in Ghost Town demonstrate the arts of the blacksmith, woodcarver, glass-blower, sign cutter, and spinner. Demonstrations of narrow gauge railroading and farm equipment hobbyists accompany additional merchant stalls of cottage-craft fairs seasonally at discounted admission which is restricted to Ghost Town only.\\r\\n\\r\\nWestern Trails Museum, relocated between the candy store and the General Store to accommodate Bigfoot Rapids, still features historical western artifacts large and small, from a hand powered horse-drawn fire engine to miniature replica of a borax hauling \\"Twenty Mule Team\\" and utensils necessary to survive the prairie and wilderness.\\r\\n\\r\\nThe Ghost Town area has a few other notable attractions. The Bird Cage Theatre only hosts two seasonal entertainmentsduring \\"Knott's Merry Farm,\\" two small productions of \\"The Gift of the Magi\\" and \\"A Christmas Carol,\\" and a Halloween Haunt thrill show. The Calico Stage, a large open-air stage in Calico Square, hosts a variety of shows and acts, big and small, from those of elementary school students, Gallagher, a local band, and the summer-spectacular All Wheels Extreme stunt show featuring youthful performers demonstrating aerial tricks with acrobatics, trampolines, and riding ramps with skates, scooters, skateboards, and freestyle bikes to popular music. Calico Saloon recreates the revelry of music, singing and dancing, with Cameo Kate hosting a variety of acts. Jersey Lily, Judge Roy Bean's combination courthouse/saloon, offers certified comical \\"genuine illegal hitchin'\\" alongside pickles, candy, and sports/soft drinks.\\r\\n\\r\\nMany parts of Ghost Town are forever lost to progress. The conversion of the Silver Dollar Saloon to a shooting gallery, Hunters Paradise shooting gallery to Panda Express and the original Berry Stand, moved several times with its last location now occupied by the Silver Bullet station.\\r\\n\\r\\nWhat is left of Ghost Town today was based on Calico ghost town and other real ghost towns in the Western United States such as Prescott, Arizona. Walter Knott inherited his uncle's silver mill and land, then bought more of the actual Calico ghost town in 1951 and developed it. In 1966, he donated that property to the corporate-municipal County of San Bernardino which then made the town of Calico, California into a public historic park, for which it charged an entrance/parking fee. See 'History?ÿ Ghost Town?ÿ Calico' section above.\\r\\n\\r\\nWild Water Wilderness is a section of Ghost Town that features two major rides: the Bigfoot Rapids river rafting adventure, and Pony Express, a horse themed family roller coaster installed in 2008. Nearby Bigfoot Rapids is Rapids Trader, a small merchandise stand. It is also home to Mystery Lodge, a multimedia show based on an Expo 86 pavilion featuring a Native American storyteller.\\r\\n\\r\\nIndian Trails is a section of Ghost Town that showcases native american art, crafts and dance.\\r\\n\\r\\nFiesta Village was built in 1969 with a pop-culture Mexican theme. It was the second area constructed after the completion of Ghost Town. Stores like Casa California, restaurants like Pancho's Tacos, La Papa Loca, and La Victoria Cantina, games like Shoot If Yucan, and the themed rides like La Revoluci܇n, Jaguar!, and Montezooma's Revenge, along with the former attraction Tampico Tumbler, all contribute to the Mexican and Aztec theme of the area. In 2013 colorful string lights were added for the summer season.\\r\\n\\r\\nBoardwalk Games include physical challenges such as a rock wall, soccer, basketball and a rope ladder crawl. A variety of traditional pitch three balls and win a prize type games, such as squirt gun into clowns mouth, knock off milk bottles, pitch a quarter onto a plate are pitched by hawkers along the Boardwalk Games midway. In September 2012, Perilous Plunge closed for an expansion of the Boardwalk. Perilous Plunge was noticeably known as one of Knott's major thrill rides. The boardwalk reopened after a year transformation with two flat rides and a new family roller coaster taking the spot of Perilous Plunge. The Boomerang roller coaster also got repainted with a new vibrant green and yellow color scheme.\\r\\nThe world's largest Johnny Rockets restaurant franchise is located at Knott's Boardwalk, featuring over 5,900 square feet (550?m2) of indoor dining space for more than 260 guests.\\r\\n\\r\\nCamp Snoopy is home to the park's family and children's rides, with many of the rides and attractions being built specifically for children and guests who cannot ride the park's more aggressive attractions. Its theme is Charles M. Schulz' \\"Peanuts\\" comic strip characters. Snoopy has been the mascot of Knott's Berry Farm since 1983, and the characters can now be seen at all of Cedar Fair's parks, except Gilroy Gardens, which is managed by Cedar Fair and owned by the city of Gilroy. The 14 rides include a mini roller coaster called the Timberline Twister, a Zamperla Rockin' Tug called Rapid River Run, and a steel spinning roller coaster called Sierra Sidewinder. For guests who cannot ride the park's more aggressive and thrilled rides, Camp Snoopy contains a good number of rides for guests of all ages including infants, children, and seniors. With the exception of Sierra Sidewinder and Timberline Twister, the rides are relativity tame and not aggressive.\\r\\n\\r\\nKnott's Berry Farm also built the Mall of America's indoor theme park, which itself was originally called Camp Snoopy. (In fact, Charles M. Schulz hailed from St. Paul.) However, today the park is no longer affiliated with Knott's or Cedar Fair, and is now called Nickelodeon Universe.\\r\\n\\r\\nOn November 22, 2013, Knott's Berry Farm announced major improvements in the area of Camp Snoopy. Camp Snoopy will receive a makeover as the section is approaching its 30th anniversary. In summer 2014, Knott's Berry Farm will open up new rides in Camp Snoopy.[17]\\r\\n\\r\\nThe 2?ft (610?mm) narrow gauge[43] Grand Sierra Railroad takes guest on a four-minute train ride through the reflection lake. The ride was made shorter with the construction of Silver Bullet.\\r\\n\\r\\nLocated next to the Bottle House in Ghost Town, Indian Trails is a small area sandwiched between Camp Snoopy, Ghost Town, and Fiesta Village, showcasing Native American art, crafts, and dance. One ride is located in this area. It is called Butterfield Stagecoach which is a family ride where an actual stagecoach take guest on a circular ride through Fiesta Village and Camp Snoopy. It is one of the original rides at the park. The ride was developed directly by the park and it opened in 1949.\\r\\n\\r\\nMany of the original attractions are outside the gates of the current-day theme park along Grand Ave. at the California Marketplace, mostly things which would no longer be considered interesting to today's audience, or things which were merely there for decoration. Near the restrooms behind Berry Place are the waterfall overshooting the water wheel and historic gristmill grindstone, a replica of George Washington's Mount Vernon estate fireplace hearth, and what remains of the visible beehive. Some attractions still exist, but have been incorporated into backstage areas, such as the Rock Garden, now an employee smoking area. Other attractions have been removed, such as the historic volcano, and the cross-section of giant sequoia with age rings denoting historic events such as Christopher Columbus visiting America.\\r\\n\\r\\nThe east side of the property, divided by Beach Blvd., features the main parking lot, Knott's Soak City a seasonal water park that requires separate admission, the picnic grounds rental areas, complementary admission to Independence Hall and gift shop, and the Church of Reflections which was moved outside the theme park in 2004 and held non-denominational Sunday services until 2010, but is still used for wedding ceremonies. A tunnel and pedestrian underpass beneath Beach Blvd. connects the main parking lot to the shops, restaurants and theme park.\\r\\n\\r\\nFor Halloween Haunt in 2016, Knott's Berry Farm introduced FearVR: 5150, a virtual reality attraction that was met with controversy from the mental health community regarding the negative portrayal of mental illness.[46] The ten-minute-long attraction immersed guests inside of a chaotic mental hospital haunted by a supernatural central character named Katie and zombie-like patients.[47] The initial controversy came from the attraction's name, with 5150 referring to the California law that allows a law enforcement officer or clinician to involuntarily commit a person suspected of having a mental illness and determined \\"a danger to themselves or others\\". The backlash was focused on Cedar Fair's use of painful experiences suffered by those dealing with mental illness and to have it \\"transmogrified into spooky entertainment\\".[46] In response, Cedar Fair removed \\"5150\\" from the name, and after continued opposition, permanently closed the attraction on September 28, 2016, only six days after its debut.[48][49] A petition was signed by more than 2,000 people hoping Cedar Fair would bring it back, with the petition's organizer stating that Cedar Fair shouldn't be \\"forced to shut down an attraction based on the words of people who had not even experienced the attraction\\".[50]\\r\\n\\r\\nKnott's Soak City is Knott's Berry Farm's water park. It opened in 1999 as Soak City U.S.A. It requires separate admission from Knott's Berry Farm.\\r\\n\\r\\nFast Lane is Knott's Berry Farm's virtual queue system. For an extra fee, visitors get a wrist band that enables them to get to the front of the line on some of the most popular attractions without queuing.\\r\\n\\r\\nThe J.M. Smucker Company continues to sell the jam and preserves made famous by the Knott family; however, other products such as the syrups have been discontinued due to low demand.[51]\\r\\n\\r\\nIn November 2013, Knott's Berry Farm began selling their \\"Berry Market\\" brand of preserves at the park. The Berry Market brand is all-natural and uses the Knott family's original recipe. They are unable to use \\"Knott's\\" on the label, since Smucker's owns the rights to the name.\\r\\n\\r\\nKnott's Berry Farm can easily be accessed by public transportation. Service is available by both Los Angeles Metro and the Orange County Transportation Authority.[52] Bus routes serving the park include Metro Express Line 460 which provides direct express service between Downtown Los Angeles and Disneyland and OCTA bus routes 29 and 38.[53]","input":"What was the first ride at knotts berry farm?"},{"output":"City of London","context":"This is a list of official cities in the United Kingdom as of 2015.[1] It lists those places that have been granted city status by letters patent or royal charter. There are currently a total of 69 such cities in the United Kingdom: 51 in England, seven in Scotland, six in Wales, and five in Northern Ireland.[1] Of these, 23 in England, two in Wales, and one in Northern Ireland possess Lord Mayors and four in Scotland have Lord Provosts. In some cases, the area holding city status does not coincide with the built up area or conurbation of which it forms part. In Greater London, for example, the City of London and that of Westminster each hold city status separately but no other neighbourhood has been granted city status, nor has Greater London as a whole. In other cases, such as the Cities of Canterbury and Lancaster, the status extends over a number of towns and rural areas outside the main settlement proper.[2]\\r\\n\\r\\n\\r\\nThe initial cities (Latin: civitas) of Britain were the fortified settlements organized by the Romans as the capitals of the Celtic tribes under Roman rule. The British clerics of the early Middle Ages later preserved a traditional list of the \\"28 Cities\\" (Old Welsh: cair) which was mentioned by Gildas[4] and listed by Nennius.[5]\\r\\nThe title of city was initially informal and, into the 20th century, royal charters were considered to recognize city status rather than to grant it.[7] The usual criterion in early modern Britain was the presence of a cathedral, particularly after King Henry VIII granted letters patent establishing six new cities when he established a series of new dioceses in the 1540s as part of the English Reformation.[8] No new cities were created between the 16th and 19th centuries, but following the Industrial Revolution and the accompanying population boom and growth in urbanisation, new sees were established at Ripon (1836) and Manchester (1847); their councils began to style them cities immediately. Inverness in Scotland was even refused a charter at the time of the Jubilee honours of 1897, in part because it would have drawn more attention to the other traditional \\"cities\\" still not formally chartered as such.[2]\\r\\nBeginning in the mid-19th century, however, the process became more formal. A visit by Queen Victoria in 1851 prompted Manchester to petition Parliament for recognition of its status. Ripon followed in the 1860s, and a series of hitherto informal \\"cities\\" were formally recognized in the 1880s and 1890s. On the basis of its size, importance, and regular government, Belfast was elevated in spite of its lack of a cathedral in 1888; other large municipalities followed, while smaller applicants began to be rejected. King Edward VII and the Home Office established three criteria for future applicants in 1907a minimum population of 300?000, a good record of local government, and a \\"local metropolitan character\\"[2]but these criteria were not made public, and following Leicester's successful elevation in 1919 a series of exceptions were made. The 1972 Local Government Act effectively eliminated all authorities holding city status outside London on 1 April 1974; most of their replacements were confirmed in their predecessor's statuseven in cases such as the City of Carlisle, where much of the local authority area is undeveloped countrysidebut the Borough of Medway was not permitted to continue Rochester's title. In recent times there have been competitions for new grants of city status. Towns or councils that claim city status or add \\"city\\" to their name have been known to be rebuked by the Advertising Standards Authority.[9]\\r\\nThe cities of Scotland and Ireland were treated separately. Scottish towns irregularly applied the description to themselves, but were formally organized as royal burghs; the special rights of these were preserved by Article XXI of the Treaty of Union which established the single state of Great Britain in 1707.[10] Edinburgh and Glasgow were confirmed as cities \\"by ancient usage\\" in the 18th century,[11] as was Aberdeen, and this was later reconfirmed in the Act enlarging the burgh in 1891. Dundee was granted letters patent in 1889 and Elgin and Perth were recognized as cities by the Home Office in 1972, before the privilege was removed by the Scottish Local Government Act of 1973.[12]\\r\\nIn Ireland, only the seat of the primate at Armagh was accorded city status by ancient usage, and this status was abolished by the Irish Municipal Corporations Act of 1840. All other cities have been those explicitly recognized as such.\\r\\nThere are a number of cities in the British Overseas Territories, such as the City of James Town on Saint Helena.[37] These are however not part of the United Kingdom.","input":"What are the 5 most populated cities in the uk?"},{"output":"in the epididymis","context":"\\r\\n\\r\\nSperm is the male reproductive cell and is derived from the Greek word (?ϫ) sperma (meaning \\"seed\\"). In the types of sexual reproduction known as anisogamy and its subtype oogamy, there is a marked difference in the size of the gametes with the smaller one being termed the \\"male\\" or sperm cell. A uniflagellar sperm cell that is motile is referred to as a spermatozoon, whereas a non-motile sperm cell is referred to as a spermatium. Sperm cells cannot divide and have a limited life span, but after fusion with egg cells during fertilization, a new organism begins developing, starting as a totipotent zygote. The human sperm cell is haploid, so that its 23 chromosomes can join the 23 chromosomes of the female egg to form a diploid cell. In mammals, sperm develops in the testicles, is stored in the epididymis, and released from the penis.\\r\\n\\r\\nThe main sperm function is to reach the ovum and fuse with it to deliver two sub-cellular structures: (i) the male pronucleus that contains the genetic material and (ii) the centrioles that are structures that help organize the microtubule cytoskeleton.\\r\\n\\r\\nThe mammalian sperm cell can be divided in 4 parts:\\r\\n\\r\\nDuring fertilization, the sperm provides three essential parts to the oocyte: (1) a signalling or activating factor, which causes the metabolically dormant oocyte to activate; (2) the haploid paternal genome; (3) the centriole, which is responsible for forming the centrosome and  microtubule system.[5]\\r\\n\\r\\nThe spermatozoa of animals are produced through spermatogenesis inside the male gonads (testicles) via meiotic division. The initial spermatozoon process takes around 70 days to complete. The spermatid stage is where the sperm develops the familiar tail. The next stage where it becomes fully mature takes around 60 days when it is called a spermatozoan.[6]\\r\\nSperm cells are carried out of the male body in a fluid known as semen. Human sperm cells can survive within the female reproductive tract for more than 5 days post coitus.[7] Semen is produced in the seminal vesicles, prostate gland and urethral glands.\\r\\n\\r\\nIn 2016 scientists at Nanjing Medical University claimed they had produced cells resembling mouse spermatids artificially from stem cells.  They injected these spermatids into mouse eggs and produced pups.[8]\\r\\n\\r\\nSperm quantity and quality are the main parameters in semen quality, which is a measure of the ability of semen to accomplish fertilization. Thus, in humans, it is a measure of fertility in a man. The genetic quality of sperm, as well as its volume and motility, all typically decrease with age.[9] (See paternal age effect.)\\r\\n\\r\\nDNA damages present in sperm cells in the period after meiosis but before fertilization may be repaired in the fertilized egg, but if not repaired, can have serious deleterious effects on fertility and the developing embryo. Human sperm cells are particularly vulnerable to free radical attack and the generation of oxidative DNA damage.[10] (see e.g. 8-Oxo-2'-deoxyguanosine)\\r\\n\\r\\nThe postmeiotic phase of mouse spermatogenesis is very sensitive to environmental genotoxic agents, because as male germ cells form mature sperm they progressively lose the ability to repair DNA damage.[11] Irradiation of male mice during late spermatogenesis can induce damage that persists for at least 7 days in the fertilizing sperm cells, and disruption of maternal DNA double-strand break repair pathways increases sperm cell-derived chromosomal aberrations.[12] Treatment of male mice with melphalan, a bifunctional alkylating agent frequently employed in chemotherapy, induces DNA lesions during meiosis that may persist in an unrepaired state as germ cells progress though DNA repair-competent phases of spermatogenic development.[13] Such unrepaired DNA damages in sperm cells, after fertilization, can lead to offspring with various abnormalities.\\r\\n\\r\\nRelated to sperm quality is sperm size, at least in some animals. For instance, the sperm of some species of fruit fly (Drosophila) are up to 5.8?cm long  about 20 times as long as the fly itself. Longer sperm cells are better than their shorter counterparts at displacing competitors from the females seminal receptacle. The benefit to females is that only healthy males carry good genes that can produce long sperm in sufficient quantities to outcompete their competitors.[14][15]\\r\\n\\r\\nSome sperm banks hold up to 170 litres (37?imp?gal; 45?US?gal) of sperm.[16]\\r\\n\\r\\nIn addition to ejaculation, it is possible to extract sperm through TESE.\\r\\n\\r\\nOn the global market, Denmark has a well-developed system of human sperm export. This success mainly comes from the reputation of Danish sperm donors for being of high quality[17] and, in contrast with the law in the other Nordic countries, gives donors the choice of being either anonymous or non-anonymous to the receiving couple.[17] Furthermore, Nordic sperm donors tend to be tall and highly educated[18] and have altruistic motives for their donations,[18] partly due to the relatively low monetary compensation in Nordic countries. More than 50 countries worldwide are importers of Danish sperm, including Paraguay, Canada, Kenya, and Hong Kong.[17] However, the Food and Drug Administration (FDA) of the US has banned import of any sperm, motivated by a risk of transmission of CreutzfeldtÿJakob disease, although such a risk is insignificant, since artificial insemination is very different from the route of transmission of CreutzfeldtÿJakob disease.[19] The prevalence of CreutzfeldtÿJakob disease for donors is at most one in a million, and if the donor was a carrier, the infectious proteins would still have to cross the blood-testis barrier to make transmission possible.[19]\\r\\n\\r\\nSperm were first observed in 1677 by Antonie van Leeuwenhoek[20] using a microscope, he described them as being animalcules (little animals), probably due to his belief in preformationism, which thought that each sperm contained a fully formed but small human.[citation needed]\\r\\n\\r\\nEjaculated fluids are detected by ultraviolet light, irrespective of the structure or colour of the surface.[21] Sperm heads, e.g. from vaginal swabs, are still detected by microscopy using the \\"Christmas Tree Stain\\" method, i.e., Kernechtrot-Picroindigocarmine (KPIC) staining.[22][23]\\r\\n\\r\\nSperm cells in algal and many plant gametophytes are produced in male gametangia (antheridia) via mitotic division. In flowering plants, sperm nuclei are produced inside pollen.[citation needed]\\r\\n\\r\\nMotile sperm cells typically move via flagella and require a water medium in order to swim toward the egg for fertilization. In animals most of the energy for sperm motility is derived from the metabolism of fructose carried in the seminal fluid. This takes place in the mitochondria located in the sperm's midpiece (at the base of the sperm head). These cells cannot swim backwards due to the nature of their propulsion. The uniflagellated sperm cells (with one flagellum) of animals are referred to as spermatozoa, and are known to vary in size.[citation needed]\\r\\n\\r\\nMotile sperm are also produced by many protists and the gametophytes of bryophytes, ferns and some gymnosperms such as cycads and ginkgo. The sperm cells are the only flagellated cells in the life cycle of these plants. In many ferns and lycophytes, they are multi-flagellated (carrying more than one flagellum).[24]\\r\\n\\r\\nIn nematodes, the sperm cells are amoeboid and crawl, rather than swim, towards the egg cell.[25]\\r\\n\\r\\nNon-motile sperm cells called spermatia lack flagella and therefore cannot swim. Spermatia are produced in a spermatangium.[24]\\r\\n\\r\\nBecause spermatia cannot swim, they depend on their environment to carry them to the egg cell. Some red algae, such as Polysiphonia, produce non-motile spermatia that are spread by water currents after their release.[24] The spermatia of rust fungi are covered with a sticky substance. They are produced in flask-shaped structures containing nectar, which attract flies that transfer the spermatia to nearby hyphae for fertilization in a mechanism similar to insect pollination in flowering plants.[26]\\r\\n\\r\\nFungal spermatia (also called pycniospores, especially in the Uredinales) may be confused with conidia. Conidia are spores that germinate independently of fertilization, whereas spermatia are gametes that are required for fertilization. In some fungi, such as Neurospora crassa, spermatia are identical to microconidia as they can perform both functions of fertilization as well as giving rise to new organisms without fertilization.[27]\\r\\n\\r\\nIn almost all embryophytes, including most gymnosperms and all angiosperms, the male gametophytes (pollen grains) are the primary mode of dispersal, for example via wind or insect pollination, eliminating the need for water to bridge the gap between male and female. Each pollen grain contains a spermatogenous (generative) cell. Once the pollen lands on the stigma of a receptive flower, it germinates and starts growing a pollen tube through the carpel. Before the tube reaches the ovule, the nucleus of the generative cell in the pollen grain divides and gives rise to two sperm nuclei, which are then discharged through the tube into the ovule for fertilization.[24]\\r\\n\\r\\nIn some protists, fertilization also involves sperm nuclei, rather than cells, migrating toward the egg cell through a fertilization tube. Oomycetes form sperm nuclei in a syncytical antheridium surrounding the egg cells. The sperm nuclei reach the eggs through fertilization tubes, similar to the pollen tube mechanism in plants.[24]\\r\\n\\r\\nMost sperm cells have centrioles in the sperm neck.[28] Sperm of many animals has 2 typical centrioles known as the proximal centriole and distal centriole. Some animals like human and bovine have a single typical centriole, known as the proximal centriole, and a second centriole with atypical structure.[2] Mice and rat have no recognizable sperm centrioles. The fruit fly Drosophila melanogaster has a single centriole and an atypical centriole named the Proximal Centriole-Like (PCL).[29]\\r\\n\\r\\nThe sperm tail is a specialized type of cilium (aka flagella). In many animals the sperm tail is formed in a unique way, which is named Cytosolic ciliogenesis, since all or part of  axoneme of the sperm tail is formed in the cytoplasm or get exposed to the cytoplasm.[30]","input":"Where is sperm stored in the human body?"},{"output":"over 670","context":"","input":"How many goals did christiano ronaldo score in his career?"},{"output":"1,500","context":"Lasallian educational institutions[1] are educational institutions affiliated with the De La Salle Brothers, a Roman Catholic religious teaching order founded by French Priest Saint Jean-Baptiste de La Salle, who was canonized in 1900 and proclaimed by the Vatican in 1950 as patron saint of all teachers. In regard to their educational activities the Brothers have since 1680 also called themselves \\"Brothers of the Christian Schools\\", associated with the Institute of the Brothers of the Christian Schools;[2] they are often referred to by themselves and others by the shorter term \\"Christian Brothers\\",[3][4] a name also applied to the unrelated Congregation of Christian Brothers or Irish Christian Brothers,[5][6] also providers of education, which commonly causes confusion.[7]\\r\\nThe De La Salle Brothers, say that, with the assistance of more than 73,000 lay colleagues, they teach over 900,000 students as they provide Christian value education worldwide to 1,500 Lasallian educational institutions and is globally established in 82 countries.[8]\\r\\nAll Lasallian educational institutions come to prayer with the call:\\r\\nLet us remember that we are in the holy presence of God.\\r\\nI will continue O my God to do all my actions for love of you.\\r\\nSaint John Baptist de La Salle\\r\\nPray for us.\\r\\nLive Jesus In Our Hearts, Forever!\\r\\nThe US-based La Salle International Foundation, which supports global educational and other networks of the De La Salle Brothers, say on their Web site that they sponsor educational projects and support schools in 82 countries; and that they give special attention to youth at risk, including those \\"educationally excluded, street children, orphans, victims of child abuse, drug addicts, disabled youth, individuals with mental illness, migrant and refugee youth, HIV+ and AIDS children, child victims of war, juvenile offenders, child laborers, victims of child trafficking, ethnic minorities, disadvantaged girls, and impoverished children\\".[9]\\r\\nSince the 1980s increasing numbers of cases of sexual and physical abuse of children, covered up by authorities, in institutions of the Catholic Church[10] and others[11] have been reported. Cases of physical and sexual abuse of children in Lasallian educational institutions, and failure to investigate, report, and subsequently protect children have been investigated and admitted.[12][11]\\r\\nEscola Joao XXIII, Beira, Sofala\\r\\nL.E.P. Issa Bri in Niamey\\r\\nAcadmie De La Salle in Byumba cole dArt in Gisenyi\\r\\nCollge Saint Charles Lwanga, Ziguinchor\\r\\nThe international community regards East Jerusalem, including the Old City, as part of the occupied Palestinian territories, but no part of Jerusalem is considered to be part of either Israel or the State of Palestine.\\r\\n(Note: The Lasallian Education Mission in Malaysia cites 44 schools in total)[16]\\r\\nFormer Lasallian schools; no longer affiliated\\r\\nWien\\r\\nIn France, the Brothers of the Christian schools run 68 primary schools, 92 middle schools, 53 general high schools and 47 vocational high schools, including:\\r\\nSee also; Instituciones educacionales lasalianas.\\r\\nCountries listed from north to south.\\r\\nThere have been a number of cases of institutional sexual and physical abuse of children, many over a period of several decades, in Lasallian educational institutions in several countries. Several are described, with references, in a section of the article on De La Salle Brothers. Branches of the De La Salle Brothers admitted to these cases, and issued apologies publicly and to victims. The Northern Ireland Historical Institutional Abuse Inquiry in its report on physical and sexual abuse at the De La Salle Boys' Home at Rubane House considered \\"the extent and frequency of the abuse was such that it was systemic\\" and that \\"the [La Salle] Order's failings to properly investigate allegations of sexual abuse and to properly report them to relevant authorities and its failure to take proper steps to protect children from further sexual abuse\\" amounted to \\"a systemic failure to take appropriate steps to ensure the investigation and prosecution of criminal offences involving abuse\\".[11]","input":"How many la salle schools in the world?"},{"output":"24 January 1950","context":"\\r\\n\\r\\n\\"Jana Gana Mana\\" (Hindi:?[??n? g??? m?n?]) is the national anthem of India. It was originally composed as Bharoto Bhagyo Bidhata in Bengali by poet Rabindranath Tagore.[1][2] The first stanza of the song Bharoto Bhagyo Bidhata in its Hindi version was adopted by the Constituent Assembly of India as the National Anthem on 24 January 1950.[3][4] A formal rendition of the national anthem takes approximately fifty-two seconds. A shortened version consisting of the first and last lines (and taking about 20?seconds to play) is also staged occasionally.[5]  It was first publicly sung on 27 December 1911 at the Calcutta (now, Kolkata) Session of the Indian National Congress.[6]\\r\\n\\r\\nA separate poem, Vande Mataram, was created \\"national song\\" of India during both the colonial period and after independence in 1950.\\r\\n\\r\\nThe poem was first sung on the second day of the annual session of the Indian National Congress in Calcutta on December 27, 1911, and again in January 1912 at the annual event of the Adi Brahmo Samaj.[7][8] Though the Bengali song had been written in 1911,[7] it was largely unknown except to the readers of the Adi Brahmo Samaj journal, Tattwabodhini Patrika, of which Tagore was the editor.\\r\\n\\r\\nSong was performed by Sarala Devi Chowdhurani, Tagores niece, along with a group of school students, in front of prominent Congress Members like Bishan Narayan Dhar, Indian National Congress President and Ambika Charan Majumdar. \\r\\n\\r\\nIn 1912, the song was published under the title Bharat Bhagya Bidhata in the Tatwabodhini Patrika, which was the official publication of the Brahmo Samaj and of which Tagore was the Editor.  \\r\\n\\r\\nOutside of Calcutta, the song was first sung by the bard himself at a session in Besant Theosophical College in Madanapalle, Andhra Pradesh on February 28, 1919 when Tagore visited the college and sung the song. The song enthralled the college students while Margaret Cousins, then vice-principal of the college (also an expert in European music and wife of Irish poet James Cousins), both requested Tagore to create an English translation of the song and set down the musical notation to the national anthem, which is followed only when the song is sung in the original slow rendition style. Tagore translated the work into English while at the college on February 28, 1919, titled  ?The Morning Song of India. Wikisource.?. The college adopted Tagore's translation of the song as their prayer song which is sung till today.\\r\\n\\r\\nBefore it was the national anthem of India, \\"Jana Gana Mana\\" was heard in the film Hamrahi (1945).[9]\\r\\n\\r\\nOn the occasion of India attaining freedom, the Indian Constituent Assembly assembled for the first time as a sovereign body on August 14, 1947, midnight and the session closed with a unanimous performance of Jana Gana Mana.  \\r\\n\\r\\nThe members of the Indian Delegation to the General Assembly of the United Nations held at New York in 1947 gave a recording of Jana Gana Mana as the countrys national anthem. The song was played by the house orchestra in front of a gathering consisting of representatives from all over the world.\\r\\n\\r\\nThe National Anthem of India is played or sung on various occasions. Instructions have been issued from time to time about the correct versions of the Anthem, the occasions on which these are to be played or sung, and about the need for paying respect to the anthem by observance of proper decorum on such occasions. The substance of these instructions has been embodied in the information sheet issued by the government of India for general information and guidance. The approximate duration of the Full Version of National Anthem of India is 52 seconds and 20 seconds for shorter version.[5]\\r\\n\\r\\nThe poem was composed in a literary register of the Bengali language called sadhu bhasa. The song has been written almost entirely using nouns that also can function as verbs and has commonality with all major languages in India due to Sanskrit being their common source of formal vocabulary. Therefore, the original song is quite clearly understandable, and in fact, remains almost unchanged in several widely different Indian languages (if variations in inherent vowel and pronunciation of approximants and some sibilants are ignored).\\r\\n\\r\\n??-??-?? ??????? ?? ??\\r\\n???? ????? ?????? ?\\r\\n?????-??????-??????-?????,\\r\\n????????-?????-??? \\r\\n??????[a] ?????? ????? ????,\\r\\n????? ???? ????\\r\\n??[b] ??? ???? ????, ??[c] ??? ???? ?????\\r\\n???? ??[d] ?? ???? ?\\r\\n??-??-???????? ?? ??, ???? ????? ?????? ?\\r\\n?? ??, ?? ??, ?? ??, ?? ?? ?? ?? ?? ?\\r\\n\\r\\nJana-gana-mana-adhinayaka jaya he\\r\\nBharata-bhagya-vidhata\\r\\nPanjaba-Sindhu-Gujarata-Maratha\\r\\nDravida-Utkala-Banga\\r\\nVindhya-Himachala-Yamuna-Ganga\\r\\nuchchala-jaladhi-taranga\\r\\nTava Subha name jage, tave subha asisa mage,\\r\\ngahe tava jaya-gatha.\\r\\nJana-gana-mangala-dayaka jaya he\\r\\nBharata-bhagya-vidhata.\\r\\nJaya he, Jaya he, Jaya he,\\r\\njaya jaya jaya jaya he.\\r\\n\\r\\nJana-gana-mana adhinyaka jaya h\\r\\nBhrata-bhgya-vidht.\\r\\nPa?jba-Sindhu-Gujarta-Mar?h,\\r\\nDrvi?a-Utkala Ba?ga\\r\\nVi?dhya[e] Himcala Yamun Ga?g,\\r\\nucchala jaladhi tara?ga\\r\\nTaba[f] ?ubha nm jg, taba[g] ?ubha ?i?a m?g\\r\\ngh taba[h] jaya gth.\\r\\nJana gana ma?gala-dyaka jaya h, Bhrata bhgya vidht.\\r\\nJaya h, Jaya h, Jaya h, jaya jaya jaya jaya h.\\r\\n\\r\\n\\r\\n\\r\\n??????-???????? ??? ?? ???????????????!\\r\\n?????? ?????? ?????? ????? ???????? ???? ????\\r\\n??????? ?????? ????? ????? ??????????????\\r\\n?? ??? ???? ????, ?? ??? ????[i] ????,\\r\\n???? ?? ????????\\r\\n?????????????? ??? ?? ???????????????!\\r\\n??? ??, ??? ??, ??? ??, ??? ??? ??? ??? ???\\r\\n\\r\\nJana-gana-mana-adhin?aka ja?a h Bhrata-bhgya-bidht[j]!\\r\\nPa?jba[k] Sindhu Gujar?a Mar?h Drbi?a[l] Utkala Ba?ga[m]\\r\\nBindhya[n] Himcala Yamun Ga?g ucchala-jaladhi-tara?ga\\r\\nTaba[o] ?ubha nm jg, taba[p] ?ubha ?isa[q] mg,\\r\\ngh taba[r] ja?a-gth.\\r\\nJana-gana-ma?gala-d?aka ja?a h Bhrata-bhgya-bidht[s]!\\r\\nJa?a h, Ja?a h, Ja?a h, ja?a ja?a ja?a ja?a h.\\r\\n\\r\\nA short version consisting of the first and last lines of the National Anthem is also played on certain occasions. It reads as follows[12]\\r\\n\\r\\n\\r\\n\\r\\n??-??-?? ??????? ?? ??\\r\\n???? ????? ?????? ?\\r\\n?? ??, ?? ??, ?? ??, ?? ?? ?? ?? ???!?\\r\\n\\r\\nJana-gana-mana-adhinayaka jaya he\\r\\nBharata-bhagya vidhata.\\r\\nJaya he, Jaya he, Jaya he,\\r\\nJaya jaya jaya jaya he.\\r\\n\\r\\nJana-gana-mana adhinyaka jaya h\\r\\nBhrata bhgya vidht.\\r\\nJaya h, Jaya h, Jaya h, jaya jaya jaya jaya h?!.\\r\\n\\r\\nTranslation by Tagore, dated February 28, 1919 at the Besant Theosophical College. Refer to  ?The Morning Song of India. Wikisource.? for the translation of the full poem. Primary sources available in the \\"Gallery\\" section.\\r\\n\\r\\nThou art, the ruler of our minds, of all people\\r\\nThe dispenser of India's destiny!\\r\\nThy name rouses the heart of Punjab, Sindh, Gujarat\\r\\nand Maratha, of the Dravida and Odisha\\r\\nand Bengal; It echoes in the hills of Vindhya and the \\r\\nHimalayas, and mingles in the music of Ganga and Yamuna\\r\\nand is chanted by the waves of the Indian sea.\\r\\nThey pray for thy blessings and sing thy praise.\\r\\nThe saving of all people waits in thy hands,\\r\\nThou dispenser of India's destiny.\\r\\nVictory, Victory, Victory to thee.[15]\\r\\n\\r\\nTagore's translation of Jana Gana Mana on February 28, 1919 at the Besant Theosophical College\\r\\n\\r\\nPage 1 of Tagore's translation of Jana Gana Mana on February 28, 1919 at the Besant Theosophical College\\r\\n\\r\\nPage 2 of Tagore's translation of Jana Gana Mana on February 28, 1919 at the Besant Theosophical College\\r\\n\\r\\nEarly or original score of Jana Gana Mana\\r\\n\\r\\nIn Kerala, students belonging to the Jehovah's Witnesses religious denomination were expelled by school authorities for their refusal to sing the national anthem on religious grounds, although they stood up respectfully when the anthem was sung.[16] The Kerala High Court concluded that there was nothing in it which could offend anyone's religious susceptibilities, and upheld their expulsion. On 11 August 1986,[17] the Supreme Court reversed the High Court and ruled that the High Court had misdirected itself because the question is not whether a particular religious belief or practice appeals to our reason or sentiment but whether the belief is genuinely and conscientiously held as part of the profession or practice of a religion. \\"Our personal views and reactions are irrelevant\\" The Supreme Court affirmed the principle that it is not for a secular judge to sit in judgment on the correctness of a religious belief.[18]\\r\\n\\r\\nSupreme Court observed in its ruling[19]\\r\\n\\r\\n\\"There is no provision of law which obliges anyone to sing the National Anthem nor is it disrespectful to the National Anthem if a person who stands up respectfully when the National Anthem is sung does not join the singing. Proper respect is shown to the National Anthem by standing up when the National Anthem is sung. It will not be right to say that disrespect is shown by not joining in the singing. Standing up respectfully when the National Anthem is sung but not singing oneself clearly does not either prevent the singing of the National Anthem or cause disturbance to an assembly engaged in such singing so as to constitute the offence mentioned in s. 3 of the Prevention of Insults to National Honour Act\\".\\r\\n\\r\\nOn 30 November 2016, Supreme Court of India ordered the National Anthem must be played before movies in theaters, in order to instill \\"committed patriotism and nationalism\\".[20] On February 10, 2017, 2 Kashmiris were booked for not standing during anthem in Jammu Cinema, under provisions of the Prevention of Insults to National Honour Act, 1971. This was the first arrest of its kind made by a state government in India.[21][22] In January 2018, the government reversed its stance and requested that the Supreme Court rescind the order until a government panel could consider the issue in more depth; the court agreed, and so around 9 January 2018 the National Anthem ceased being compulsory in movie theaters.[23]\\r\\n\\r\\n\\r\\nThe composition was first sung during a convention of the Indian National Congress in Calcutta on 27 December 1911.[24] It was sung on the second day of the convention, and the agenda of that day devoted itself to a loyal welcome of George V on his visit to India. The event was reported thus in the British Indian press:\\r\\n\\"The Bengali poet Rabindranath Tagore sang a song composed by him specially to welcome the Emperor.\\" (Statesman, Dec. 28, 1911)\\r\\n\\r\\n\\"The proceedings began with the singing by Rabindranath Tagore of a song specially composed by him in honour of the Emperor.\\" (Englishman, Dec. 28, 1911)\\"When the proceedings of the Indian National Congress began on Wednesday 27th December 1911, a Bengali song in welcome of the Emperor was sung. A resolution welcoming the Emperor and Empress was also adopted unanimously.\\" (Indian, Dec. 29, 1911)\\r\\nMany historians aver that the newspaper reports cited above were misguided. The confusion arose in British Indian press since a different song, \\"Badshah Humara\\" written in Hindi by Rambhuj Chaudhary,[25] was sung on the same occasion in praise of the monarch. The nationalist Indian press stated this difference of events clearly:\\r\\n\\r\\n\\"The proceedings of the Congress party session started with a prayer in Bengali to praise God (song of benediction). This was followed by a resolution expressing loyalty to King George V. Then another song was sung welcoming King George V.\\" (Amrita Bazar Patrika, Dec.28,1911)\\r\\n\\r\\n\\r\\n \\"The annual session of Congress began by singing a song composed by the great Bengali poet Ravindranath Tagore. Then a resolution expressing loyalty to King George V was passed. A song paying a heartfelt homage to King George V was then sung by a group of boys and girls.\\" (The Bengalee, Dec. 28, 1911)\\r\\nEven the report of the annual session of the Indian National Congress of December 1911 stated this difference:\\r\\n\\r\\n\\"On the first day of 28th annual session of the Congress, proceedings started after singing Vande Mataram. On the second day the work began after singing a patriotic song by Babu Ravindranath Tagore. Messages from well wishers were then read and a resolution was passed expressing loyalty to King George V. Afterwards the song composed for welcoming King George V and Queen Mary was sung.\\"\\r\\n\\r\\nOn 10 November 1937 Tagore wrote a letter to Mr Pulin Bihari Sen about the controversy. That letter in Bengali can be found in Tagore's biography Ravindrajivani, volume II page 339 by Prabhatkumar Mukherjee.\\r\\n\\r\\n \\"A certain high official in His Majesty's service, who was also my friend, had requested that I write a song of felicitation towards the Emperor. The request simply amazed me. It caused a great stir in my heart. In response to that great mental turmoil, I pronounced the victory in Jana Gana Mana of that Bhagya Bidhata [ed. God of Destiny] of India who has from age after age held steadfast the reins of India's chariot through rise and fall, through the straight path and the curved. That Lord of Destiny, that Reader of the Collective Mind of India, that Perennial Guide, could never be George V, George VI, or any other George. Even my official friend understood this about the song. After all, even if his admiration for the crown was excessive, he was not lacking in simple common sense.\\"[26] \\r\\nAgain in his letter of 19 March 1939 Tagore writes:[27]\\r\\n\\r\\n\\"I should only insult myself if I cared to answer those who consider me capable of such unbounded stupidity as to sing in praise of George the Fourth or George the Fifth as the Eternal Charioteer leading the pilgrims on their journey through countless ages of the timeless history of mankind.\\"\\r\\n(Purvasa, Phalgun, 1354, p. 738.)\\r\\n\\r\\nMoreover, Tagore was hailed as a patriot who wrote other songs too apart from \\"Jana Gana Mana\\" lionising the Indian independence movement. He renounced his knighthood in protest against the 1919 Jallianwala Bagh Massacre. The Knighthood (i.e. the title of 'Sir') was conferred on him by the same King George V after receiving the Nobel Prize in Literature for \\"Gitanjali\\" from the government of Sweden. Two of Tagore's more politically charged compositions, \\"Chitto Jetha Bhayshunyo\\" (\\"Where the Mind is Without Fear\\", Gitanjali Poem #35) and \\"Ekla Chalo Re\\" (\\"If They Answer Not to Thy Call, Walk Alone\\"), gained mass appeal, with the latter favoured by Gandhi and Netaji.[citation needed]\\r\\n\\r\\nAnother controversy is that only those provinces that were under British rule, i.e. Punjab, Sindh, Gujarat, Maratha, Dravid (South India), Odisha/Utkal and Bengal, were mentioned. None of the princely states ÿ Kashmir, Rajasthan, Hyderabad, Mysore or Kerala ÿ or the states in Northeast India, which are now integral parts of India were mentioned. But opponents of this proposition claim that Tagore mentioned only the border states of India to include complete India. Whether the princely states would form a part of a liberated Indian republic was a matter of debate even till Indian Independence. 'Dravida' includes the people from the south (though Dravida specifically means Tamil and even then, the same consideration is not given for the south since there are many distinct people whereas in the north each of the distinct people are named) and 'Jolodhi' (Stanza 1) is Sanskrit for \\"seas and oceans\\". Even North-East which was under British rule or holy rivers apart from Ganges and Yamuna are not mentioned to keep the song in its rhythm. India has 29 states, 7 union territories.\\r\\n\\r\\nIn 2005, there were calls to delete the word \\"Sindh\\" and substitute it with the word Kashmir. The argument was that Sindh was no longer a part of India, having become part of Pakistan as a result of the Partition of 1947. Opponents of this proposal hold that the word \\"Sindh\\" refers to the Indus and to Sindhi culture, and that Sindhi people are an integral part of India's cultural fabric. The Supreme Court of India declined to change the national anthem and the wording remains unchanged.\\r\\n\\r\\nOn 17 December 2013, MLA of Assam, Phani Bhushan Choudhury cited article of 'The Times of India' published on 26 January 1950, stating that originally the word 'Kamarup' was included in the song, but was later changed to 'Sindhu' and claimed that Kamarup should be re-included.[28] To this, the then minister Rockybul Hussain replied that the state government would initiate steps in this regard after response from the newspaper.[28] The debate was further joined by the then minister Ardhendu Dey, mentioning 'Sanchayita' (edited by Tagore himself) etc. where he said Kamrup was not mentioned.[28]","input":"When was jana gana mana accepted as national anthem?"},{"output":"Bandi Rajan Babu","context":"Bandi Rajan Babu (9 February 1938 ÿ 25 August 2011) was an Indian photographer,[1] known for his black and white pictures of tribal people. He also owned the Rajan School of Photography.[2]\\r\\n\\r\\nBandi Rajan Babu was born at Korutla, in the Karimnagar district of Telangana.  Starting his career as a lecturer at JNTU Fine Arts College, he went on to establish his own school and master the craft of pictorial photography'. He was a Fellow of the Royal Photographic Society of Great Britain, an Associate of the Federation of International Photographic Art, France, and an Honorary Fellow of the AP State Akademi of Photography.\\r\\n\\r\\nRajan took to serious photography in 1960 after joining the Jawaharlal Nehru Technological University, and became a pictorial, fashion and glamour, industrial and advertising photographer.  He drew inspiration from Raja Triambak Raj Bahadur, the first one from  erstwhile Andhra Pradesh to be honoured with the status of Associate of Britain's Royal Photographic Society.  Rajan, who was on the faculty of JNTU, got his first international honour from Belgium, received the APRS honour in 1983, and followed it up with the Fellowship of the Royal Photographic Society in 1987.\\r\\n\\r\\nRajan Babu wanted to become a painter and he was all set to become one until given a Kodak. One of my cousins presented me with a camera when I was in my seventh class and I casually clicked some photos that were appreciated by all and that was the seeding of a photographer in me. Later, when I joined the five-year diploma course in commercial art, I came across Raja Triambak Raj Bahadur, a pioneer in pictorial photography.  It was he who inspired me to wield the camera. And here I am today from a painter to a photographer.\\"\\r\\n\\r\\nStarting his career as a lecturer in photography in Jawaharlal Nehru Technological University, Hyderabad, he later worked as a scientific photographer in International Crop Research Institute for Semi-Arid Tropics. He opened his studio in 1978 and has, thereafter, been one among the leading photographers in India.\\r\\nApart from winning a number of national and international awards he is the only Fellow of Royal Photographic Society from AP.\\r\\n\\r\\nHe also married and had three kids. He has 5 grand children.","input":"Who is the well known photographer of telangana?"},{"output":"Wilhelm Maximilian Wundt","context":"","input":"Who was known as the father of psychology?"},{"output":"23 hours, 56 minutes, and 4 seconds","context":"Earth's rotation is the rotation of Planet Earth around its own axis. Earth rotates eastward, in prograde motion. As viewed from the north pole star Polaris, Earth turns counter clockwise.\\r\\nThe North Pole, also known as the Geographic North Pole or Terrestrial North Pole, is the point in the Northern Hemisphere where Earth's axis of rotation meets its surface. This point is distinct from Earth's North Magnetic Pole. The South Pole is the other point where Earth's axis of rotation intersects its surface, in Antarctica.\\r\\nEarth rotates once in about 24 hours with respect to the Sun, but once every 23 hours, 56 minutes, and 4 seconds with respect to the stars (see below). Earth's rotation is slowing slightly with time; thus, a day was shorter in the past. This is due to the tidal effects the Moon has on Earth's rotation. Atomic clocks show that a modern day is longer by about 1.7 milliseconds than a century ago,[1] slowly increasing the rate at which UTC is adjusted by leap seconds. Analysis of historical astronomical records shows a slowing trend of about 2.3 milliseconds per century since the 8th century BCE.[2]\\r\\n\\r\\n\\r\\nAmong the ancient Greeks, several of the Pythagorean school believed in the rotation of the earth rather than the apparent diurnal rotation of the heavens. Perhaps the first was Philolaus (470ÿ385 BCE), though his system was complicated, including a counter-earth rotating daily about a central fire.[3]\\r\\nA more conventional picture was that supported by Hicetas, Heraclides and Ecphantus in the fourth century BCE who assumed that the earth rotated but did not suggest that the earth revolved about the sun. In the third century BCE, Aristarchus of Samos suggested the sun's central place.\\r\\nHowever, Aristotle in the fourth century BCE criticized the ideas of Philolaus as being based on theory rather than observation. He established the idea of a sphere of fixed stars that rotated about the earth.[4] This was accepted by most of those who came after, in particular Claudius Ptolemy (2nd century CE), who thought the earth would be devastated by gales if it rotated.[5]\\r\\nIn 499 CE, the Indian astronomer Aryabhata wrote that the spherical earth rotates about its axis daily, and that the apparent movement of the stars is a relative motion caused by the rotation of the Earth. He provided the following analogy: \\"Just as a man in a boat going in one direction sees the stationary things on the bank as moving in the opposite direction, in the same way to a man at Lanka the fixed stars appear to be going westward.\\"[6][7]\\r\\nIn the 10th century, some Muslim astronomers accepted that the Earth rotates around its axis.[8] According to al-Biruni, Abu Sa'id al-Sijzi (d. circa 1020) invented an astrolabe called al-zraqؐ based on the idea believed by some of his contemporaries \\"that the motion we see is due to the Earth's movement and not to that of the sky.\\"[9][10] The prevalence of this view is further confirmed by a reference from the 13th century which states: \\"According to the geometers [or engineers] (muhandisؐn), the earth is in constant circular motion, and what appears to be the motion of the heavens is actually due to the motion of the earth and not the stars.\\"[9] Treatises were written to discuss its possibility, either as refutations or expressing doubts about Ptolemy's arguments against it.[11] At the Maragha and Samarkand observatories, the Earth's rotation was discussed by Tusi (b. 1201) and Qushji (b. 1403); the arguments and evidence they used resemble those used by Copernicus.[12]\\r\\nIn medieval Europe, Thomas Aquinas accepted Aristotle's view[13] and so, reluctantly, did John Buridan[14] and Nicole Oresme[15] in the fourteenth century. Not until Nicolaus Copernicus in 1543 adopted a heliocentric world system did the contemporary understanding of earth's rotation begin to be established. Copernicus pointed out that if the movement of the earth is violent, then the movement of the stars must be very much more so. He acknowledged the contribution of the Pythagoreans and pointed to examples of relative motion. For Copernicus this was the first step in establishing the simpler pattern of planets circling a central sun.[16]\\r\\nTycho Brahe, who produced accurate observations on which Kepler based his laws, used Copernicus's work as the basis of a system assuming a stationary earth. In 1600, William Gilbert strongly supported the earth's rotation in his treatise on the earth's magnetism[17] and thereby influenced many of his contemporaries.[18] Those like Gilbert who did not openly support or reject the motion of the earth about the sun are often called \\"semi-Copernicans\\".[19] A century after Copernicus, Riccioli disputed the model of a rotating earth due to the lack of then-observable eastward deflections in falling bodies;[20] such deflections would later be called the Coriolis effect. However, the contributions of Kepler, Galileo and Newton gathered support for the theory of the rotation of the Earth.\\r\\nThe earth's rotation implies that the equator bulges and the poles are flattened. In his Principia, Newton predicted this flattening would occur in the ratio of 1:230, and pointed to the 1673 pendulum measurements by Richer as corroboration of the change in gravity,[21] but initial measurements of meridian lengths by Picard and Cassini at the end of the 17th century suggested the opposite. However measurements by Maupertuis and the French Geodesic Mission in the 1730s established the flattening, thus confirming both Newton and the Copernican position.[22]\\r\\nIn the Earth's rotating frame of reference, a freely moving body follows an apparent path that deviates from the one it would follow in a fixed frame of reference. Because of the Coriolis effect, falling bodies veer slightly eastward from the vertical plumb line below their point of release, and projectiles veer right in the northern hemisphere (and left in the southern) from the direction in which they are shot. The Coriolis effect is mainly observable at a meteorological scale, where it is responsible for the differing rotation direction of cyclones in the northern and southern hemispheres.\\r\\nHooke, following a 1679 suggestion from Newton, tried unsuccessfully to verify the predicted eastward deviation of a body dropped from a height of 8.2 meters, but definitive results were only obtained later, in the late 18th and early 19th century, by Giovanni Battista Guglielmini in Bologna, Johann Friedrich Benzenberg in Hamburg and Ferdinand Reich in Freiberg, using taller towers and carefully released weights.[n 1] A ball dropped from a height of 158.5?m (520?ft) departed by 27.4?mm (1.08?in) from the vertical compared with a calculated value of 28.1?mm (1.11?in).\\r\\nThe most celebrated test of Earth's rotation is the Foucault pendulum first built by physicist Lon Foucault in 1851, which consisted of a lead-filled brass sphere suspended 67 m from the top of the Panthon in Paris. Because of the Earth's rotation under the swinging pendulum, the pendulum's plane of oscillation appears to rotate at a rate depending on latitude. At the latitude of Paris the predicted and observed shift was about 11 degrees clockwise per hour. Foucault pendulums now swing in museums around the world.\\r\\nEarth's rotation period relative to the Sun (solar noon to solar noon) is its true solar day or apparent solar day. It depends on the Earth's orbital motion and is thus affected by changes in the eccentricity and inclination of Earth's orbit. Both vary over thousands of years, so the annual variation of the true solar day also varies. Generally, it is longer than the mean solar day during two periods of the year and shorter during another two.[n 2] The true solar day tends to be longer near perihelion when the Sun apparently moves along the ecliptic through a greater angle than usual, taking about 10 seconds longer to do so. Conversely, it is about 10 seconds shorter near aphelion. It is about 20 seconds longer near a solstice when the projection of the Sun's apparent motion along the ecliptic onto the celestial equator causes the Sun to move through a greater angle than usual. Conversely, near an equinox the projection onto the equator is shorter by about 20 seconds. Currently, the perihelion and solstice effects combine to lengthen the true solar day near 22 December by 30 mean solar seconds, but the solstice effect is partially cancelled by the aphelion effect near 19 June when it is only 13 seconds longer. The effects of the equinoxes shorten it near 26 March and 16 September by 18 seconds and 21 seconds, respectively.[24][25][26]\\r\\nThe average of the true solar day during the course of an entire year is the mean solar day, which contains 86,400 mean solar seconds. Currently, each of these seconds is slightly longer than an SI second because Earth's mean solar day is now slightly longer than it was during the 19th century due to tidal friction. The average length of the mean solar day since the introduction of the leap second in 1972 has been about 0 to 2 ms longer than 86,400 SI seconds.[27][28][29] Random fluctuations due to core-mantle coupling have an amplitude of about 5 ms.[30][31] The mean solar second between 1750 and 1892 was chosen in 1895 by Simon Newcomb as the independent unit of time in his Tables of the Sun. These tables were used to calculate the world's ephemerides between 1900 and 1983, so this second became known as the ephemeris second. In 1967 the SI second was made equal to the ephemeris second.[32]\\r\\nThe apparent solar time is a measure of the Earth's rotation and the difference between it and the mean solar time is known as the equation of time.\\r\\nEarth's rotation period relative to the fixed stars, called its stellar day by the International Earth Rotation and Reference Systems Service (IERS), is 86,164.098 903 691 seconds of mean solar time (UT1) (23h 56m 4.098 903 691s, 0.997 269 663 237 16 mean solar days).[33][n 3] Earth's rotation period relative to the precessing or moving mean vernal equinox, named sidereal day, is 86,164.090 530 832 88 seconds of mean solar time (UT1) (23h 56m 4.090 530 832 88s, 0.997 269 566 329 08 mean solar days).[33] Thus the sidereal day is shorter than the stellar day by about 8.4 ms.[35]\\r\\nBoth the stellar day and the sidereal day are shorter than the mean solar day by about 3 minutes 56 seconds. The mean solar day in SI seconds is available from the IERS for the periods 1623ÿ2005[36] and 1962ÿ2005.[37]\\r\\nRecently (1999ÿ2010) the average annual length of the mean solar day in excess of 86,400 SI seconds has varied between 0.25 ms and 1 ms, which must be added to both the stellar and sidereal days given in mean solar time above to obtain their lengths in SI seconds (see Fluctuations in the length of day).\\r\\nThe angular speed of Earth's rotation in inertial space is (7.2921150 I 0.0000001) G10?5 radians per SI second (mean solar second).[33] Multiplying by (180/ radians)G(86,400 seconds/mean solar day) yields 360.9856/mean solar day, indicating that Earth rotates more than 360 relative to the fixed stars in one solar day. Earth's movement along its nearly circular orbit while it is rotating once around its axis requires that Earth rotate slightly more than once relative to the fixed stars before the mean Sun can pass overhead again, even though it rotates only once (360) relative to the mean Sun.[n 4] Multiplying the value in rad/s by Earth's equatorial radius of 6,378,137 m (WGS84 ellipsoid) (factors of 2 radians needed by both cancel) yields an equatorial speed of 465.1?m/s (1,526?ft/s), or 1,674.4?km/h (1,040.4?mph).[38] Some sources state that Earth's equatorial speed is slightly less, or 1,669.8 km/h.[39] This is obtained by dividing Earth's equatorial circumference by 24 hours. However, the use of only one circumference unwittingly implies only one rotation in inertial space, so the corresponding time unit must be a sidereal hour. This is confirmed by multiplying by the number of sidereal days in one mean solar day, 1.002 737 909 350 795,[33] which yields the equatorial speed in mean solar hours given above of 1,674.4 km/h.\\r\\nThe tangential speed of Earth's rotation at a point on Earth can be approximated by multiplying the speed at the equator by the cosine of the latitude.[40] For example, the Kennedy Space Center is located at latitude 28.59 N, which yields a speed of: cos 28.59 G 1,674.4?km/h (1,040.4?mph; 465.1?m/s) = 1,470.23?km/h (913.56?mph; 408.40?m/s)\\r\\nThe Earth's rotation axis moves with respect to the fixed stars (inertial space); the components of this motion are precession and nutation. It also moves with respect to the Earth's crust; this is called polar motion.\\r\\nPrecession is a rotation of the Earth's rotation axis, caused primarily by external torques from the gravity of the Sun, Moon and other bodies. The polar motion is primarily due to free core nutation and the Chandler wobble.\\r\\nOver millions of years, the Earth's rotation slowed significantly by tidal acceleration through gravitational interactions with the Moon. In this process, angular momentum is slowly transferred to the Moon at a rate proportional to \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n?\\r\\n6\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle r^{-6}}\\r\\n\\r\\n, where \\r\\n\\r\\n\\r\\n\\r\\nr\\r\\n\\r\\n\\r\\n{\\\\displaystyle r}\\r\\n\\r\\n is the orbital radius of the Moon. This process gradually increased the length of day to its current value and resulted in the Moon being tidally locked with the Earth.\\r\\nThis gradual rotational deceleration is empirically documented with estimates of day lengths obtained from observations of tidal rhythmites and stromatolites; a compilation of these measurements[41] found the length of day to increase steadily from about 21 hours at 600Myr ago[42] to the current 24 hour value. By counting the microscopic lamina that form at higher tides, tidal frequencies (and thus day lengths) can be estimated, much like counting tree rings, though these estimates can be increasingly unreliable at older ages.[43]\\r\\nThe current rate of tidal deceleration is anomalously high, implying the Earth's rotational velocity must have decreased more slowly in the past. Empirical data[41] tentatively shows a sharp increase in rotational deceleration about 600Myr ago. Some models suggest that the Earth maintained a constant day length of 21 hours throughout much of the Precambrian.[42] This day length corresponds to the semidiurnal resonant period of the thermally-driven atmospheric tide; at this day length, the decelerative lunar torque could have been canceled by an accelerative torque from the atmospheric tide, resulting in no net torque and a constant rotational period. This stabilizing effect could have been broken by a sudden change in global temperature. Recent computational simulations support this hypothesis and suggest the Marinoan or Sturtian glaciations broke this stable configuration about 600Myr ago, citing the resemblance of simulated results and existing paleorotational data.[44]\\r\\nAdditionally, some large-scale events, such as the 2004 Indian Ocean earthquake, have caused the length of a day to shorten by 3 microseconds by affecting the Earth's moment of inertia.[45] Post-glacial rebound, ongoing since the last Ice age, is also changing the distribution of the Earth's mass thus affecting the moment of inertia of the Earth and, by the conservation of angular momentum, the Earth's rotation period.[46]\\r\\nThe primary monitoring of the Earth's rotation is performed with very-long-baseline interferometry coordinated with the Global Positioning System, satellite laser ranging, and other satellite techniques. This provides an absolute reference for the determination of universal time, precession, and nutation.[47]\\r\\nThere are recorded observations of solar and lunar eclipses by Babylonian and Chinese astronomers beginning in the 8th century BCE, as well as from the medieval Islamic world and elsewhere. These observations can be used to determine changes in the Earth's rotation over the last 27 centuries, since the length of the day is a critical parameter in the calculation of the place and time of eclipses. A change in day length of milliseconds per century shows up as a change of hours and thousands of kilometers in eclipse observations. The ancient data is consistent with a shorter day, meaning the Earth was turning faster throughout the past.[48][49]\\r\\nThe Earth's original rotation was a vestige of the original angular momentum of the cloud of dust, rocks, and gas that coalesced to form the Solar System. This primordial cloud was composed of hydrogen and helium produced in the Big Bang, as well as heavier elements ejected by supernovas. As this interstellar dust is heterogeneous, any asymmetry during gravitational accretion resulted in the angular momentum of the eventual planet.[50]\\r\\nHowever, if the giant-impact hypothesis for the origin of the Moon is correct, this primordial rotation rate would have been reset by the Theia impact 4.5 billion years ago. Regardless of the speed and tilt of the Earth's rotation before the impact, it would have experienced a day some five hours long after the impact.[51] Tidal effects would then have slowed this rate to its modern value.","input":"How many hours does it take for the earth to spin on its axis?"},{"output":"22 public universities","context":"This is a list of universities and colleges in Kenya. Kenya has a number of universities and other institutions of higher learning. There are 22 public universities, 14 chartered private universities and 13 universities with Letter of Interim Authority (LIA).\\r\\nThese universities are established through institutional Acts of Parliament under the Universities Act, 2012 which provides for the development of university education, the establishment, accreditation and governance of universities. According to a 2004 report on reforming higher education in Kenya, the rapid expansion of university education in the country was a spontaneous response to the increasing demand for higher education necessitated by the increasing flow of students from schools.\\r\\nFrom July 2014, all government and private institutions offering technical and vocational education and training were put under TVETA.[1][2] This act normalized this sector as it had become tainted by unaccredited institutions offering substandard education as revealed by The Standard[3] and The Star.[4] As of October 10, 2016 there were 540 institutions accredited by the Authority.[5]\\r\\n\\r\\n\\r\\nRiara University","input":"How many universities do we have in kenya?"},{"output":"Columbia","context":"\\r\\n\\r\\nSerena Celia van der Woodsen is a main character in the Gossip Girl novel series and the lead in its TV adaptation, in which she is portrayed by Blake Lively. Serena is featured on the blog of the series' mysterious narrator, \\"Gossip Girl\\". Serena is Blair Waldorf's best friend and is a character that appears to easily get whatever she wants because of her good looks, energy, and charisma. She is also known as the \\"It Girl\\" in the series.\\r\\n\\r\\nSerena is a tall, blonde, slim, and attractive teenage girl from the Upper East Side of Manhattan in New York City. Many of the girls at the Constance Billard school accuse her of using her good looks as a means to secure everything she wants. She is not particularly academically skilled, but she is often told that she is not meeting her full potential. Her father runs the same Dutch shipping firm his great-great-grandfather founded in the 18th century, and her mother, Lillian van der Woodsen, is a socialite, art collector, and philanthropist. Her parents are on the boards of all major charities and art organizations in the city. The van der Woodsens reside at 994 Fifth Avenue, a ritzy, white-gloved doorman building directly across the street from The Met and Central Park. Serena and her family own half the top floor in a 14-room penthouse.\\r\\n\\r\\nSerena has a nail-biting habit and also cuts her split ends off, mainly during her classes at Constance Billard. Though exposed and aware of the on-goings in the fashion world, she, unlike Blair, is not as meticulous about her fashion choices and wardrobe. She is described to have an effortless way about her. Serena is charismatic, charming, talented, funny, kind, care-free, and laid-back. These attributes help her to thrive and often, whether wittingly or unwittingly, attract older men.\\r\\n\\r\\nDespite all of her attributes, Janet Malcolm of The New Yorker considers her \\"incandescently beautiful, exceptionally kind, and, in the end, it has to be said, somewhat boring.\\"[1]\\r\\n\\r\\nPeople compares her character with Josh Schwartz's original it-girl creation, Marissa Cooper, stating that Serena \\"seems to have it all, but in addition to a party girl reputation, dark family secrets and a disregard for high society, Serena one-ups the sulky Coop with a history of BFF betrayal.\\"[2] Jason Gay of Rolling Stone describes Serena as \\"the bad girl gone good(ish) who serves as Gossip Girl's wobbly moral compass.\\" He added praise while describing her early strained relationship with Blair, stating, \\"Lively's Serena is a former queen bee who mysteriously disappeared from campus, only to return and find her spiteful ex-best friend, Blair (Meester), in charge.\\"[3] With regards to her character's direction in the show, actress Blake Lively commented on her character's adventurous storylines during an interview with Nylon saying, \\"I feel ridiculous at times with her, because I'm, you know, killing someone or marrying someone, but I look like me. I'm like, 'Oh, this is absurd.'\\"[4][5] Vogue magazine considers Lively's upbringing to be advantageous to her character background and finds her \\"dazzling and worldly and optimistic\\". Her mother, a former model from Georgia would dress her differently and her differing fashion choices drew the attention of her classmates from the L.A. private school she enrolled in. \\"It was the only school where people were just downright mean to me,\\" Lively stated. \\"They would make fun of my clothes because I dressed differently than the other kids.\\"[6]\\r\\n\\r\\nIn November 2012 concept music artist Marty McKay released a single called \\"Serena\\" featuring former Dr. Dre / Aftermath producer Focus.... The song is based on Serena's character in Gossip Girl. Due to a lack of promotion, the song did not garner much attention.[7]\\r\\n\\r\\nThe first season introduces Serena as the beautiful, wealthy daughter of divorced parents who returns from boarding school. Her return sparks her old rivalry with her best friend, Blair. Serena's return is due to her younger brother, Eric van der Woodsen, who attempted suicide. She is considered unwelcome, most so by her old best friend Blair, who has always seen Serena as a threat to her reign as Queen Bee of Constance. After Serena successfully reconciles with her, Chuck Bass reveals to Serena that he knows the cause of her sudden departure prior to the first season - taking Nate Archibald's (Blair's boyfriend) virginity during a wedding,[8] and he attempts to kiss her. Serena manages to escape and runs into Dan, a St. Jude's student from Brooklyn, who often expresses cynicism about the lifestyle his wealthier classmates lead. Serena also finds a friend in Jenny Humphrey, Dan's younger sister. Nate eventually reveals his tryst with Serena to Blair, and Serena is ostracized in the first few episodes of the show.[9] Blair and Serena consistently fight and reconcile throughout the show's subsequent episodes, often dealing with Serena's tendency to overshadow Blair.[10] Serena and Blair reconcile after a heartfelt confrontation that prompted Serena to admit her mistake with Nate and leaving Blair in her time of need.[11]\\r\\n\\r\\nSerena encounters a myriad of problems as her mother becomes engaged to Bart Bass,[12] who forces her family to adjust to living with Chuck, then she discovers her mother's relationship with Dan's father, Rufus Humphrey, and the complications of embarking on a relationship with Dan that is met with disapproval of her mother and her peers. Her relationship with Dan further reaches complications with the arrival of Georgina Sparks, a longtime friend who slowly reveals to viewers the real reason why Serena left Manhattan. Georgina drives her to commit the same mistakes she did before leaving Manhattan, ranging from partying excessively to drinking heavily, causing Serena to miss the SATs.[13] Serena confronts Georgina, only to draw her anger, prompting Georgina to destroy her relationship with Dan and blackmail her with knowledge of a particular event in the past: she accidentally killed a man.[14][15] Serena's constant lying in order to keep Dan from discovering her past eventually takes its toll on their relationship and Dan breaks up with her.\\r\\n\\r\\nBlair eventually retaliates against Georgina with the help of Chuck and Nate and the intervention of Vanessa, successfully driving Georgina out of Manhattan.[14][16] Serena finally tells Dan the truth, only to discover during Lily's wedding, that he wants to end their relationship. A disappointed Serena attempts to move on throughout the summer.\\r\\n\\r\\nThe second season shows Serena spending the summer with her family and Blair in the Hamptons, attempting to move on from her failed relationship with Dan. During a dramatic party, she and Dan briefly reconcile their relationship and return to New York.[17] Their relationship becomes public again but ends sooner than expected during a blackout as both are unable to move past the problems that previously ruined their relationship.[18] After a disastrous double date with Dan and a new transfer, Amanda, that ends with two of Blair's mean girls throwing Nair at Amanda and Dan accusing Serena of being behind it, Serena takes matters into her own hands and easily re-establishes herself as Queen, thus reigniting her rivalry with Blair. She has Dan publicly ostracized throughout the school.[19] Exposing herself to New York's high society, she meets Poppy Lifton, a socialite, and further strains her relationship with Blair during Eleanor Waldorf's fashion show when she and Poppy participate in it.[20] Serena and Blair eventually reconcile during a trip to Yale, where she didn't originally want to apply to but then took the opportunity to do so after Blair told her she couldn't possibly get in.[21]\\r\\n\\r\\nAn exhibit in Rufus' gallery has Serena finding new love with a childhood friend and artist, Aaron Rose.[22] She eventually reconciles with Dan but their friendship soon threatens her new love with Aaron, prompting him to escort her to a ball where Serena receives news from her mother of Bart's death.[23] During Bart's funeral, Aaron notices her continually drawn towards Dan and invites her to come with him to Argentina, which she accepts.[24] Upon their return, Serena breaks up with Aaron, and she is free to pursue a relationship with Dan. The two reunite, only to face the awkward discovery that they share a sibling.[25] Dan and Serena's relationship further suffers when she realizes their diverging college choices,[26] her continuous mistrust in him, and Dan's affair with a teacher that drives her to prematurely end their relationship.[27]\\r\\n\\r\\nAfter throwing a disastrous Sweet Sixteen party for Jenny, Serena retreats to Spain with Poppy and Poppy's boyfriend, Gabriel Edwards. She returns to New York pursued by Gabriel after he broke up with Poppy and finds herself in a new relationship. During a party held by her mother, Serena discovers that Gabriel and Poppy have conned her mother's guests and calls on Blair's aid to obtain their stolen money, breaking up with Gabriel as she pursues Poppy. Blair reluctantly teams up with Chuck and a reformed Georgina, ignoring Lily's wishes that they let her handle it herself, ending with the plan completely back-firing: Serena is arrested, Poppy escapes and Georgina, becoming the scapegoat, eases back into her old ways.\\r\\n\\r\\nA stubborn Serena chooses to stay in prison, until Dan bails her out and the two go to prom together. Her arrest soon adds to her fame as she becomes a local celebrity. On the day of graduation, Gossip Girl sends a blast that further ruins Serena and her friends' reputations. Declaring war on Gossip Girl, Serena finds herself the center of blame when a ticked-off Gossip Girl decides to drop every unreleased piece of gossip she had in store, creating further divide within the group. Sending a text to Gossip Girl, Serena calls a bluff that she knows Gossip Girl's identity, only for Gossip Girl to escape and warning everyone that she'll be pursuing them in college. She spends the summer leaving New York with Carter in pursuit of her father.\\r\\n\\r\\nSerena returns from her European adventure and a complicated relationship with Carter that indicates a possible romance. The Los Angeles Times noted her character's penchant for secrecy but stated \\"It initially seems as though Bad Serena is back, but we all know her highway of crazy behavior is always paved with good intentions.\\"[28] Serena's relationship with Carter earns the disapproval of her peers but discovers redeeming qualities in him. Lily first assumes that she's preparing to go to Brown but defers from entering, preferring to stay in the city and find herself. During Lily's wedding, she discovers Carter's previous transgressions and she loses him when he chooses to make amends for his mistakes, breaking her heart in the process.\\r\\n\\r\\nSerena eventually makes her time in New York useful by taking a job as a publicist, one that is short-lived as her relationships with both her friends and her family begin to erode. Her friendship with Blair and Nate crumble due to her job but finds even more trouble when she falls for Nate's married congressman cousin, Trippp van der Bilt (Aaron Tveit). Her relationship with him is tumultuous as both Nate and Blair fail in persuading her from continuing the affair. The affair ends when an offer to become a mistress from Trippp's wife makes her come to her senses. As Serena and Trippp return to New York, their car crashes, leaving her hospitalized. She survives and Nate proves his love for her and the two begin a relationship.\\r\\n\\r\\nWhen Chuck's mother returns, Serena's resolve to find her father is reignited. Her decision slowly damages her relationship with Nate as she reconnects with Carter who is back to his old habits. Knowing that he has information regarding her father, the two work together to find him but is no longer interested in a relationship with Carter. Jenny's growing feelings for Nate also threaten her relationship with him when she makes every effort to steal Nate from her.One of the incidents where Jenny happens to ruin her relationship between her and Serena, also her and Nate is during Nate's \\"assassin\\" birthday bash. During his birthday party, Nate and Jenny happened to be the last two players. They got stuck in a supply closet. Jenny happened to be blocking the entrance. So, in order to win, she kissed Nate, which came unexpectedly for him. He happened to be head over heels in love with Serena, her stepsister. This threatened this relationship on many counts. Another instance is when they had just spent the drinking with Chuck and Nate. Nate and Jenny go back to the hotel room. Just as soon as Serena gets off the elevator, you see Jenny trying to kiss Nate. Then, Nate kicks Jenny out of the apartment to talk to his girlfriend in private. \\r\\n\\r\\nDuring Dorota's wedding, Serena leaves with Carter and gives Jenny a message telling Nate that she has found her father. Serena soon finds out that Carter has been delaying her in an attempt to get close to her and leaves him, flies alone. Upon arriving, she is shocked to find her mother answering the hotel door, assuming that she had been in Canyon Ranch the entire time.\\r\\n\\r\\nWilliam van der Woodsen (William Baldwin) returns, making Serena happy but is unknowingly dragged into her father's plot to win back his ex-wife. The plot nearly works until Jenny, Blair, Nate and Chuck scheme against William, who had been trying to frame Rufus for adultery and intentionally misdiagnosing Lily, and William leaves. Her father's departure leads to Dan comforting her and reignites her feelings for him. Serena sleeps over at Dan's and wake up to find themselves in a compromising position, one that Jenny photographs and sends to Gossip Girl. As the photo spreads, Nate and Serena temporarily end their relationship and she joins Blair for a summer in Paris.\\r\\n\\r\\nSerena is seen spending her summer in Paris with Blair, reluctant to tell Blair that she has enrolled in Columbia, something that Blair fears will have them return to their high school pettiness, when she receives news that Chuck might be dead. After an unfortunate double date involving a handsome royal, Blair eventually forgives her. Chuck's arrival and a visit to a Parisian morgue confirms that he is alive but Serena pursues him in hopes of convincing him to return to New York when he tries to run away to London. She returns to New York having made her decision between Dan and Nate but her decision becomes irrelevant when she sees them with their new respective significant others, Vanessa and Juliet Sharp (Katie Cassidy), a girl with a personal vendetta against Serena.\\r\\n\\r\\nSerena's enrollment in Columbia has her face Juliet's many attempts at getting rid of her, ranging from excluding her from an exclusive society along with driving Blair against her, exposing her relationship with her professor, Colin Forrester (Sam Page), who happens to be Juliet's cousin to get her kicked out, and spreading various rumors about Serena, who manages to evade these attempts. Juliet then recruits Jenny and Vanessa and succeed in gaslighting her into toying with Dan and Nate's feelings, attempting to take a foundation position from Blair, and returning to her old partying habits. Serena is rehabilitated while Dan and Blair subsequently discover Juliet's reasons for ruining Serena. Serena was supposedly in an illicit, but not ever consummated, relationship with Juliet's half-brother and Serena's boarding school English teacher, Ben Donovan (David Call) and was arrested when Lily forged an affidavit that falsely accused Ben of statutory rape, out of concern for Serena.\\r\\n\\r\\nThe holidays has Serena trying to figure out how to release Ben from prison and her relationship with Lily is yet again strained. Serena and Dan put a possible return to their relationship on hold, knowing that they might not have the same chance of loving and trusting each other. Meanwhile, Ben's release from prison reignites Serena's feelings for him and they pursue a loving, yet troubled relationship. Serena's relationship with Ben slowly erodes when she receives news from Vanessa that he is responsible for hurting Nate's father in prison and when Ben's mother, Cynthia, raises Ben's personal troubles while at the same time seeking to exonerate him. Serena becomes proud of her mother when Lily decides to face the consequences of sending an innocent Ben to prison. Serena and Ben's relationship eventually ends due to family complications.\\r\\n\\r\\nSerena's cousin, Charlie Rhodes, comes to stay with Serena's family for a while. Charlie helps Serena find out that Dan and Blair have had a secret romance, causing a fight between Serena and Blair. Serena continues to use Charlie as a spy until noticing that Charlie is starting to act exactly as Serena and steals Serena's dress. In the season finale, Serena gets Charlie help with a medical condition, though it is later revealed that Charlie is really Ivy, and Ivy is just acting. Later, while walking the streets of Los Angeles, Serena gets offered a job in Hollywood where she decides to move to.\\r\\n\\r\\nIn Season 5, Serena is working as a film producer's assistant in Los Angeles and spending her free time with Nate and Chuck. Although Serenas boss, Marshall, is difficult to please, his boss, Jane, promotes Serena after she succeeds at a task that Marshall failed. Later, she runs into Charlie and convinces her to move with her back to New York.\\r\\n\\r\\nWhen Dan tells Serena, Nate, Blair, Chuck, Rufus and Lily that he wrote a book about his life and their roles in it, Serena is offended when he portrays her as a self-centered, promiscuous party-girl and is even more upset when Blair tells her that's exactly who she's been. After this revelation, she stops speaking to Dan. This cannot last, however, when her boss, Jane, requires Serena to get the movie rights to Dan's book. He agrees eventually saying that he trusts her and she gives him her word to protect him and his work. However when Serena's boss tries to smear Dan's character and his real life image in the movie, she kills the deal to protect him, but when Dan finds out, he accuses her of killing the movie because of the negative way she is portrayed. Heartbroken over his accusation, she reveals that her real reason for killing his movie was to protect him, not herself, then walks away. \\r\\n\\r\\nAfter being fired by Jane, Serena is hired by Nate's boss, Diana Payne, to start a blog based on her life in order to take down Gossip Girl. Later, Nate and Serena discover a list of sources for Gossip Girl, which would be the silver bullet in Diana's campaign against Gossip Girl. They struggle over whether or not to use it and ultimately decide it would be too damaging to release. The list is leaked anyway and the two accuse each other before Blair discovers that it was Louis who leaked Gossip Girl's list of sources. Charlie encourages Serena to start dating in order to motivate her for her blog and she begins dating a guy named Max that she met on the street, not knowing that Max is actually Charlie's ex-boyfriend. Diana arranges for Max to meet Serena at the opening of Chuck's premiere of Sleep No More in order to make it look like Max has stood her up. Serena forgives Max for standing her up, and the two begin dating.\\r\\n\\r\\nCharlie finds out the two are dating and convinces her to slow down the relationship. Serena's aunt Carol returns and Serena overhears an argument between the two about Carol forcing Charlie to live under the name 'Ivy Dickens'. Serena makes the connection between Max and Charlie when she remembers that Max's ex-girlfriend's name was Ivy. She demands the truth from Charlie and Max. Ivy as Charlie and Carol manage to convince Serena and the family that Max is lying and Serena tells Max to leave before she calls the police.\\r\\n\\r\\nAs Serena and Lily prepare Charlie for her debut into New York society, Dan tells Serena that he is going to tell Blair how he feels about her. In order to make Dan see that Blair's happy ending will be with Louis, she sends Louis to the Humphrey loft. When she finds Dan with Blair and Chuck later, she realizes that he gave up his desire for Blair for Blair's own happiness with Chuck and realizes that Blair is still in love with Chuck. Later that night, after Charlie's debutante party, Serena receives a call from Nate that Blair and Chuck have been in an accident. This causes Serena to declare war on Gossip Girl, using Nate's power at the Spectator, and Dan.\\r\\n\\r\\nWith Gossip Girl gone, Serena finds that Gossip Girl's tipsters have begun sending their blasts to her via her blog. Nate encourages her to use the blasts productively, but Serena is reluctant to become the next Gossip Girl. Meanwhile, Serena is concerned for Blair's well-being and confronts her at Nate's New Year's Eve party where Blair tells her that the accident was God's way of telling her that she and Chuck are not meant to be together and that she made a promise with God that if Chuck lived, she would marry Louis and that Dan has been going to church with her since. In order to cover Blair, Serena pretends that she has rekindled her romance with Dan. This \\"romance\\" becomes the focus of her soon-to-be-launched blog which causes problems for Dan, as while Dan thinks that their romance is fake, Serena is shown to have genuine feelings for Dan again.\\r\\n\\r\\nSerena is humiliated at the press premiere of her new blog, being photographed holding a tablet that shows \\"Site not found.\\" Upset, she is told the time wasn't right for her blog, but she ultimately discovers that Nate had it shut down as a favour to Gossip Girl. In return, Gossip Girl would help him find out the truth about Blair and Chuck's car accident. Serena doesn't agree with Nate's suspicions that Trippp was responsible, and confronts the latter over at the Waldorf residence. This is revealed to be a set-up brought about by Nate, Serena and Nate's grandfather as a way for Tripp to admit that he was behind the accident thinking that Nate was going to be in the car instead.\\r\\n\\r\\nFollowing this, Serena finds out that Blair was arrested at her own bachelorette party, and rushes to her aide. Blair tells her that she's alright, and that since she's going to go through with her wedding, Serena doesn't have to pretend to be together with Dan anymore. Serena, however, decides to keep this truth from Dan a little while longer.\\r\\n\\r\\nOn Blair's wedding day, Serena tries to convince Blair not to marry Louis. Blair goes through with her wedding anyway, even after Gossip Girl launches a video of Blair professing her true feelings to Chuck. After the vows are said, Serena, Dan and Nate confront Georgina and she blames each of them in a vague manner before leaving. When Blair goes missing after her wedding, Serena and Chuck search for her, and find her in a motel in Queens with Dan, which upsets Serena as she still has feelings for him. When Georgina arrives, Serena is revealed to have Georgina's video camera that was used to record Blair's confession and she takes the fall for the video.\\r\\n\\r\\nFollowing this, Blair and Serena are in yet another rut, but forgive each other and Serena is unknowingly set up on a blind date with Dan, after she told him her feelings and he rejected her. At a party later, she and Georgina find Dan and Blair kissing, which causes another rift between her and Blair. After her grandmother's death and shocking news of her will, Serena starts a vendetta against Ivy (who received the major part of CeCe's estate), trying to win back her family fortunes. In a surprising turn of events, she gets a package from former Gossip Girl, Georgina Sparks, containing a computer and the means necessary to become the next Gossip Girl. Serena accepts.\\r\\n\\r\\nAfter losing the reins to Gossip Girl and her unintentional role in exposing Blair's diary to the Upper East side, Serena attempts to deceive Blair by having sex with Dan. The plan almost works only for Dan to realize what has happened. Serena once again tells Dan that she loves him but Dan tells her that he does not feel anything for her. A depressed Serena is last seen leaving the city with one of Damien Dalgaard's drug dealers, a flashback to her days before she returned to the Upper East Side in season one.\\r\\n\\r\\nIn season 6, Serena is seen together with a new boyfriend, Steven Spence (who is significantly older than her). She is seen leading a happy, peaceful life away from the UES. Confronted by Blair, she simply says that she doesn't see how they could ever be friends again. Serena ultimately moves back to the UES with Steven, and his jealous daughter Sage. Sage uses every chance she gets to sabotage her father's relationship with Serena, and proves herself to be on par, scheming-wise, with Georgina and Blair. After some shocking revelations, including the fact that Steven has slept with Lily when her last name was Mller, they decide to end things.\\r\\n\\r\\nSerena is re-united with Dan again in a last attempt to make things work. Dan, on his hand, has been writing a scathingly honest sequel to \\"Inside\\" with the help of Georgina. One of his last and most poignant chapters is The Serena Chapter, which is released during the Thanksgiving party. Serena is, in the chapter, described as a \\"Golden girl\\" who lives for attention and love, and dramatically ends things with Dan. She decides to move away from New York, but is intercepted by Dan, who tries to convince her that he has always loved her and always will. Hurt and upset, she doesn't believe him, and leaves. Before she leaves, Dan slides a file into her bag, which she opens on the plane before take-off. It is revealed that Dan wrote two chapters on Serena, and that the second one was the \\"Good Serena Chapter\\". She gets off the plane and goes to talk things through thoroughly with Dan.\\r\\n\\r\\nIn the finale, Dan reveals to her how they first met at a party at Blair's, and how he fell in love at first sight. He had then realised that he could never pull her out of her world and into his, so he found a way to enter her world by creating a UES blog. This blog, launching Serena's rise to legend, became known as Gossip Girl. Serena realises that Gossip Girl was only ever a manifestation of Dan's love for her, and that he practically wrote them all a seven-year-long love letter.\\r\\n\\r\\nA scene set in the future shows everyone reunited at the Bass-Waldorf residence, witnessing the marriage of Dan and Serena.\\r\\n\\r\\nSerena's style has earned noteworthy praise from periodicals such as InStyle[29] and NYLON.[30] EW's Meeta Agrawal places Blake Lively's Serena van der Woodsen amongst the wearers of the 20 Knockout Dresses of the '00s. Her Tory Burch designed dress in the pilot earning the 2nd spot on the list.[31] People magazine references an issue of NYLON, reporting that even the actress herself admits to liking her character's style and wardrobe and InStyle's Joyann King praises \\"Serenas vixen-like style and Livelys smoldering off-screen choices\\".[29][32] In an interview for Vanity Fair, costume designers Eric Daman and Meredith Markworth-Pollack considered fashion model Kate Moss and New York socialites Tinsley Mortimer and Arden Wohl as a muse when dressing Lively and when asked if they were influenced by New York socialites, respectively.[33] TV Guide named her the fifth most fashionable TV character.[34] Glamour listed her as one of the 12 Most Stylish TV Characters.[35]\\r\\n\\r\\nBlair and Serena's friendship was praised as \\"it offered a relationship whose depth and complexity approached Rory and Paris' [from Gilmore Girls].\\"[36] Vanity Fair considered Serena's murder storyline to be \\"unrealistic\\" and \\"an obvious ratings ploy,\\" going on to compare it to a dramatic scene in The O.C., in which Marissa shot Ryan Atwood's brother, stating that the show may have possibly jumped the shark.[37]\\r\\n\\r\\nFor her portrayal of Serena van der Woodsen, Blake Lively won the 2008 Teen Choice Award for Choice TV Actress Drama and was nominated for the same award in 2009 and 2010, losing to her co-star, Leighton Meester, who portrays Blair Waldorf.[38] She, however, won the award again in 2011. Lively also earned a People's Choice Award nomination for Favorite TV Drama Actress in 2011 and 2012.","input":"Where did serena van der woodsen go to college?"},{"output":"104.80%","context":"In economics, the debt-to-GDP ratio is the ratio between a country's government debt (a cumulative amount) and its gross domestic product (GDP) (measured in years). A low debt-to-GDP ratio indicates an economy that produces and sells goods and services sufficient to pay back debts without incurring further debt. Geopolitical and economic considerations - including interest rates, war, recessions, and other variables - influence the borrowing practices of a nation and the choice to incur further debt.[1]\\r\\n\\r\\n\\r\\nIn 2016, United States public debt-to-GDP ratio was at 104.8%.[2] The level of public debt in Japan 2013 was 243.2% of GDP, in China 22.4% and in India 66.7%, according to the IMF,[3] while the public debt-to-GDP ratio at the end of the 2nd quarter of 2016 was at 70.1% of GDP in Germany, 89.1% in the United Kingdom, 98.2% in France and 135.5% in Italy, according to Eurostat.[4]\\r\\nTwo thirds of US public debt is owned by US citizens, banks, corporations, and the Federal Reserve Bank;[5] approximately one third of US public debt is held by foreign countries - particularly China and Japan. Conversely, less than 5% of Japanese public debt is held by foreign countries.\\r\\nParticularly in macroeconomics, various debt-to-GDP ratios can be calculated. The most commonly used ratio is the Government debt divided by the gross domestic product (GDP), which reflects the government's finances, while another common ratio is the total debt to GDP, which reflects the finances of the nation as a whole.\\r\\nThe debt-to-GDP ratio is generally expressed as a percentage, but properly has units of years, as below.\\r\\nBy dimensional analysis these quantities are the ratio of a stock (with dimensions of currency) by a flow (with dimensions of currency/time), so[note 1] they have dimensions of time. With currency units of US dollars (or any other currency) and time units of years (GDP per annum), this yields the ratio as having units of years, which can be interpreted as \\"the number of years to pay off debt, if all of GDP is devoted to debt repayment\\". Thus, 90% refers to a debt which would take 90% of a year's GDP to pay off.\\r\\nThis interpretation must be tempered by the understanding that GDP cannot be entirely devoted to debt repayment  some must be spent on survival, at the minimum, and in general only 5ÿ10% will be devoted to debt repayment, even during episodes such as the Great Depression, which have been interpreted as debt-deflation  and thus actual \\"years to repay\\" is debt-to-GDP divided by \\"fraction of GDP devoted to repayment\\", which will generally be 10 times as long or more than simple debt-to-GDP.\\r\\nThe change in debt-to-GDP is approximately \\"net increase in debt as percentage of GDP\\"; for government debt, this is deficit or (surplus) as percentage of GDP.\\r\\nThis is only approximate as GDP changes from year to year, but generally year-on-year GDP changes are small (say, 3%), and thus this is approximately correct.\\r\\nHowever, in the presence of significant inflation, or particularly hyperinflation, GDP may increase rapidly in nominal terms; if debt is nominal, then its ratio to GDP will decrease rapidly. A period of deflation would have the opposite effect.\\r\\nA government's debt-to-GDP ratio can be analysed by looking at how it changes or, in other words, how the debt is evolving over time:\\r\\n\\r\\n\\r\\nThe left hand side of the equation demonstrates the dynamics of the government's debt. \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nB\\r\\n\\r\\nt\\r\\n\\r\\n\\r\\n\\r\\nY\\r\\n\\r\\nt\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\textstyle {\\\\frac {B_{t}}{Y_{t}}}}\\r\\n\\r\\n is the debt-to-GDP at the end of the period t, and \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nB\\r\\n\\r\\nt\\r\\n?\\r\\n1\\r\\n\\r\\n\\r\\n\\r\\nY\\r\\n\\r\\nt\\r\\n?\\r\\n1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\textstyle {\\\\frac {B_{t-1}}{Y_{t-1}}}}\\r\\n\\r\\n is the debt-to-GDP ratio at the end of the previous period (t-1). Hence, the left side of the equation shows the change in the debt-to-GDP ratio. The right hand side of the equation shows the causes of the government's debt. \\r\\n\\r\\n\\r\\n\\r\\n(\\r\\nr\\r\\n?\\r\\ng\\r\\n)\\r\\n(\\r\\n\\r\\n\\r\\n\\r\\nB\\r\\n\\r\\nt\\r\\n?\\r\\n1\\r\\n\\r\\n\\r\\n\\r\\nY\\r\\n\\r\\nt\\r\\n?\\r\\n1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n)\\r\\n\\r\\n\\r\\n{\\\\textstyle (r-g)({\\\\frac {B_{t-1}}{Y_{t-1}}})}\\r\\n\\r\\n is the interest payments on the stock of debt as a ratio of GDP so far, and \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nG\\r\\n\\r\\nt\\r\\n\\r\\n\\r\\n?\\r\\n\\r\\nT\\r\\n\\r\\nt\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nY\\r\\n\\r\\nt\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\textstyle {\\\\frac {G_{t}-T_{t}}{Y_{t}}}}\\r\\n\\r\\n shows the primary deficit-to-GDP ratio.\\r\\nIf the government has the ability to print money, and therefore monetize the outstanding debt, the budget constraint becomes:\\r\\n\\r\\n\\r\\nThe term \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nM\\r\\n\\r\\nt\\r\\n\\r\\n\\r\\n\\r\\nY\\r\\n\\r\\nt\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n?\\r\\n\\r\\n\\r\\n\\r\\nM\\r\\n\\r\\nt\\r\\n?\\r\\n1\\r\\n\\r\\n\\r\\n\\r\\nY\\r\\n\\r\\nt\\r\\n?\\r\\n1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\textstyle {\\\\frac {M_{t}}{Y_{t}}}-{\\\\frac {M_{t-1}}{Y_{t-1}}}}\\r\\n\\r\\n is the change in money balances (i.e. money growth). By printing money the government is able to increase nominal money balances to pay off the debt (consequently acting in the debt way that debt financing does, in order to balance the government's expenditures). However, the effect that an increase in nominal money balances has on seignorage is ambiguous, as while it increases the amount of money within the economy, the real value of each unit of money decreases due to inflationary effects. This inflationary effect from money printing is called an inflation tax.\\r\\nDebt-to-GDP measures the financial leverage of an economy.\\r\\nOne of the Euro convergence criteria was that government debt-to-GDP be below 60%.\\r\\nThe World Bank and the IMF hold that a country can be said to achieve external debt sustainability if it can meet its current and future external debt service obligations in full, without recourse to debt rescheduling or the accumulation of arrears and without compromising growth. According to these two institutions, external debt sustainability can be obtained by a country by bringing the net present value (NPV) of external public debt down to about 150 percent of a countrys exports or 250 percent of a countrys revenues. [1] High external debt is believed to have harmful effects on an economy.[6]\\r\\nIn 2013 Herndon, Ash, and Pollin reviewed an influential, widely cited research paper entitled, \\"Growth in a time of debt\\",[7] by two Harvard economists Carmen Reinhart and Kenneth Rogoff. Herndon, Ash and Pollin argued that \\"coding errors, selective exclusion of available data, and unconventional weighting of summary statistics lead to serious errors that inaccurately represent the relationship between public debt and GDP growth among 20 advanced economies in the post-war period.\\"[8][9] Their research had significant basic computation errors that, when corrected, undermined the central claim of the book that too much debt causes recession.[10][11] Rogoff and Reinhardt claimed that their fundamental conclusions were accurate, despite the errors.[12][13] Recently, the Growth in a Time of Debt controversy was argued to instantiate the emerging contrary result phenomenon.[14] The following arguments support this thesis: (1) the viewpoint according to which weighted averaging scheme is superior to the unweighted one is not justified by the cliometric methodology, (2) excluding post-war statistics was grounded in the lack of believable estimates and (3) the infamous spreadsheet error influenced the summary statistics in a minor way. Therefore, none of the two contrary results obtained by Reinhart and Rogoff and Herndon, Ash and Pollin is superior and the question whether there is a threshold in the relation between public debt and economic growth stays open.\\r\\nThere is a difference between external debt denominated in domestic currency, and external debt denominated in foreign currency. A nation can service external debt denominated in domestic currency by tax revenues, but to service foreign currency debt it has to convert tax revenues in foreign exchange market to foreign currency, which puts downward pressure on the value of its currency. So all of the money used to service foreign currency debt has to come from a country's balance of payments transfers.[dubious ÿ discuss]","input":"What is the u.s. debt to gdp ratio?"},{"output":"31 May 1961","context":"","input":"When was the republic of south africa established?"},{"output":"Las Vegas Sands","context":"Marina Bay Sands is an integrated resort fronting Marina Bay in Singapore. At its opening in 2010, it was billed as the world's most expensive standalone casino property at S$8 billion, including the land cost.[2][3]\\r\\nThe resort includes a 2,561-room hotel, a 120,000-square-metre (1,300,000?sq?ft) convention-exhibition centre, the 74,000?m2 (800,000?sq?ft) The Shoppes at Marina Bay Sands mall, a museum, two large theatres, \\"celebrity chef\\" restaurants, two floating Crystal Pavilions, a skating rink, and the world's largest atrium casino with 500 tables and 1,600 slot machines.\\r\\nThe complex is topped by a 340-metre-long (1,120?ft) SkyPark with a capacity of 3,900 people and a 150?m (490?ft) infinity swimming pool, set on top of the world's largest public cantilevered platform, which overhangs the north tower by 67?m (220?ft).[4][5] The 20-hectare resort was designed by Moshe Safdie architects.[6][7][8] The architect was Aedas,[9] and they were responsible for employing all consultants and for developing, co-ordinating and implementing the design. Engineering was provided by Arup and Parsons Brinkerhoff (MEP). The main contractor was Ssangyong Engineering and Construction.[10][11]\\r\\nOriginally set to open in 2009, Las Vegas Sands faced delays caused by escalating costs of material and labour shortages from the outset. The global financial crisis also pressured the company to delay its projects elsewhere to complete the integrated resort.[12] Although Marina Bay Sands has been compared in scale and development costs to MGM's CityCenter, the latter is a mixed-use development, with condominium properties (comprising three of the seven main structures) being sold off.[13][14]\\r\\nThe resort and SkyPark were officially opened on 23 and 24 June 2010 as part of a two-day celebration, following the casino's opening on 27 April that year.[15] The SkyPark opened the following day. The theatres were completed in time for the first performance of Riverdance on 30 November. The indoor skating rink, which uses artificial ice, opened to a performance by Michelle Kwan on 18 December. The ArtScience Museum opened to the public and the debut of a 13-minute light, laser and water show called Wonder Full on 19 February 2011 marked the full completion of the integrated resort.\\r\\nThe grand opening of Marina Bay Sands was held on 17 February 2011. It also marked the opening of the seven celebrity chef restaurants. The musical The Lion King debuted on 3 March 2011.[16] The last portion of the Marina Bay Sands, the floating pavilions, were finally opened to the public when the two tenants, Louis Vuitton and Pangaea Club, opened on 18 and 22 September 2011 respectively.[17]\\r\\n\\r\\n\\r\\nMarina Bay Sands is one of two winning proposals for Singapore's first integrated resorts, the other being the Resorts World Sentosa, which incorporates a family-friendly Universal Studios Theme Park (Universal Studios Singapore). The two large-scale resorts were conceived to meet Singapore's economic and tourism objectives for the next decade and will have 30-year casino licenses, exclusive for the first ten years. Bidders were assessed based on four criteria: tourism appeal and contribution, architectural concept and design, development investment, and strength of the consortium and partners\\r\\nOn 27 May 2006, Las Vegas Sands (LVS) was declared the winner with its business-oriented resort.[18] LVS submitted its winning bid on its own. Its original partner City Developments Limited (CDL), with a proposed 15% equity stake, pulled out of the partnership in the second phase of the tender process. CDL's CEO, Kwek Leng Beng said his company's pullout was a combination of factors ÿ such as difficulties in getting numerous companies he owns to comply in time, as well as reluctance of some parties to disclose certain private information in probity checks required by the Singapore government.[19] However, Kwek was retained as an advisor for Sands' bid.\\r\\nLas Vegas Sands initially committed to invest S$3.85 billion in the project, not including the fixed S$1.2 billion cost of the 6,000,000 square feet (560,000?m2) site itself.[20] With the escalating costs of materials, such as sand and steel, and labour shortages owing to other major infrastructure and property development in the country, Sheldon Adelson placed the total cost of the development at S$8.0 billion as of July 2009.[2][21]\\r\\nLas Vegas Sands declared the undertaking as \\"one of the world's most challenging construction projects and certainly the most expensive stand-alone integrated resort property ever built\\".[22] It expects the casino to generate at least $1 billion in annual profit.[13] Two months after the initial phased opening, the casino attracts around 25,000 visitors daily, about a third being Singaporeans and permanent residents who pay a $100 daily entry levy or $2,000 for annual unlimited access.[23] Half a million gamblers passed through the casino in June 2010.[24] In the third quarter of 2012, the revenues of the Marina Bay Sands fell almost 28 per cent from a year earlier.[25]\\r\\nFor the economy, Marina Bay Sands is projected to stimulate an addition of $2.7 billion or 0.8% to Singapore's Gross Domestic Product by 2015, employing 10,000 people directly and 20,000 jobs being created in other industries.[19]\\r\\nThe resort is designed by Moshe Safdie,[6][7][8] who says it was initially inspired by card decks. In addition to the casino, other key components of the plan are three hotel towers with 2,500 rooms and suites, a 19,000?m2 (200,000?sq?ft) ArtScience Museum and a convention centre with 110,000?m2 (1,200,000?sq?ft) of space, capable of accommodating up to 45,000 people. A continuous lobby at the base linked the three towers. The resort's architecture and major design changes along the way were also approved by its feng shui consultants, the late Chong Swan Lek and Louisa Ong-Lee.[26][27]\\r\\nA distinctive feature of the hotel is the SkyPark, a three-acre park on top of the building with swimming pools, gardens, and jogging paths. The structure bridges all three towers with a segment cantilevered off the north tower. The hull of the SkyPark was pre-fabricated off-site in 14 separate steel sections and then assembled on top of the towers.[28] There are four movement joints beneath the main pools, designed to help them withstand the natural motion of the towers, and each joint has a unique range of motion. The total range of motion is 500 millimetres (19.68?inches). In addition to wind, the hotel towers are also subject to settlement in the earth over time, so engineers built and installed custom jack legs to allow for future adjustment at more than 500 points beneath the pool system. This jacking system is important primarily to ensure the infinity edge of the pool continues to function properly.[29]\\r\\nThe three towers are broader at the base and narrow as they rise. Each tower has two asymmetric legs, with a curved eastern leg leaning against the other, creating a significant technical challenge in its construction. Substantial temporary structures were necessary to support the legs of the tower while they were under construction, and required real-time monitoring for continual assessment and analyses in the course of their erection. The structural engineering for the project was handled by Arup, with Parsons Brinckerhoff as the MEP engineers.[30]\\r\\nMarina Bay Sands was originally planned to be completed in a single phase in 2009,[21] but rising construction costs and the financial crisis forced the company to open it in phases. The first phase's preview opening was further delayed until 27 April 2010, and the official opening was pushed back to 23 June 2010. The rest of the complex remained under construction and was opened after a grand opening on 17 February 2011.\\r\\nOn 27 April 2010, Marina Bay Sands had the first of a planned 3 to 4 phase openings. The casino, parts of the conference hall, a segment of the Shoppes, 963 hotel rooms and the event plaza were opened at the auspicious time of 3:18 p.m as part of the \\"preview opening\\".[31]\\r\\nThe Inter-Pacific Bar Association (IPBA) held the first conference at Marina Bay Sands Convention Centre on 2ÿ5 May 2010, but the event was marred by uncompleted facilities and power failure during a speech. IPBA withheld payment of S$300,000 and was consequently sued by Marina Bay Sands.[32] In June, IPBA counter-sued, describing the venue as a \\"complete disaster\\" and that its earlier payments had been imposed by \\"duress, fear and force\\".[32] An \\"amicable settlement\\" with undisclosed terms was announced in August.\\r\\nOn 23 June 2010, the resort had its official opening with a \\"2-day celebration\\"; this includes the Sands SkyPark, the Event Plaza along Marina Bay, more shops, additional dining options and nightlife offerings, and the rest of the hotel rooms. First day events included ÿ a \\"World Championship Climb\\" on the glass facade of the building to the SkyPark, with 7 teams of 21 top rock climbers from around the world competing, and an evening concert for 4,000 invited guests and customers, featuring Jacintha Abisheganaden, Sylvia Ratonel, Tabitha Nauser and Toni Braxton among others. The SkyPark was opened on the second day at 2?pm,[22] with about 2,000 adult tickets costing S$20 each sold.[33]\\r\\nThe two Sands theatres were completed in time for the first performance by Riverdance on 30 November 2010. The ArtScience Museum opened its doors to the public at 10?am on 19 February 2011. The highly anticipated musical The Lion King made its debut on 3 March 2011. The floating pavilions were opened when the tenants Louis Vuitton and Pangaea Club finished their refurbishment and opened on 18 September 2011 and 22 September 2011 respectively. The Lion King musical ran till its last show on 30 October 2011.[34]\\r\\nMarina Bay Sands has three 55-story hotel towers which were topped out in July 2009. The three towers are connected by a 1 hectare roof terrace, Sands SkyPark.[35] The observation deck provides panoramic views across the bay.[36]\\r\\nIn front of the three towers include a Theatre Block, a Convention and Exhibition Facilities Block, as well as the Casino Block, which have up to 1,000 gaming tables and 1,400 slot machines. The ArtScience Museum is constructed next to the three blocks and has the shape of a lotus. Its roof is retractable, providing a waterfall through the roof of collected rainwater when closed in the day and laser shows when opened at night. In front of the Event Plaza is Wonder Full, a light and water show that is the largest in Southeast Asia and was produced by Laservision.[37] The ArtScience Museum and Wonder Full show opened on 17 February 2011.\\r\\nThe SkyPark has the world's longest elevated swimming pool,[38][29] with a 146-metre (478?ft) vanishing edge (a concept called as infinity pool) located 191 metres above ground. The pools are made up of 422,000 pounds of stainless steel and can hold 376,500 gallons (1424 cubic metres) of water. The SkyPark also has rooftop celebrity chef restaurants such as Sky on 57 (by Justin Quek), Spago (by Wolfgang Puck), nightclubs such as Ce La Vie, gardens, hundreds of trees and plants, and a public observatory deck on the cantilever with 360-degree views of the Singapore skyline. The SkyPark is accessible only to the hotel guests for security reasons.\\r\\nThe Shoppes at Marina Bay Sands have close to 93,000?m2 (1,000,000?sq?ft) of retail space with over 300 stores and F&B outlets, featuring boutiques such as Ralph Lauren, Chanel, Cartier, Prada, Gucci, Herms, Emporio Armani, Chopard, REDValentino, Dior, Dunhill, Vertu, Miu Miu, Saint Laurent Paris, Salvatore Ferragamo, Montblanc, Blancpain, Vera Wang Bride, a Herms watch boutique, and Herve Leger.\\r\\nA canal runs through the length of the Shoppes, in the same style as the Venetian in Las Vegas. Sampan rides on the canal are available for guests and shoppers at the shopping mall, similar to the gondola rides available in the Venetian. Also housed within the Shoppes are six of the ten Celebrity Chef restaurants ÿ Bread Street Kitchen (by Gordon Ramsay), Cut (by Wolfgang Puck), Waku Ghin (by Tetsuya Wakuda), Pizzeria and Osteria Mozza (by Mario Batali), Long Chim (by David Thompson), DB Bistro & Oyster Bar (by Daniel Boulud).\\r\\nThere are two Crystal Pavilions. Despite a brief legal dispute in June 2011, it was decided that one of the Pavilions will house two nightclubs ÿ Avalon and Pangaea. In addition, the second Pavilion houses the world's largest Louis Vuitton boutique, in addition to being on a floating island, at 1,900?m2 (20,000?sq?ft), which is connected to the portion of the boutique in the Shoppes via an underwater tunnel. Both Pavilions opened in 2011 just before the 2011 Formula One season came to the Marina Bay Street Circuit.\\r\\nThe Sands Theatre and Grand Theatre seat 1,680 people and 2,155 people respectively, with The Lion King showing, and international acts, such as Cirque loize and A. R. Rahman's Jai Ho, located in the latter during their world tours. The musical, Wicked, is set to run for a limited season which started 7 December 2011. Next to the theatres is a skating rink (synthetic ice) measuring 600?m2 (6,500?sq?ft).\\r\\nDragonfire boxing is another regular event, which started on 5 May 2012 with the boxers Chris John with Daud Yordan\\r\\nMoshe Safdie designed an Art Path within the resort, incorporating installations by five artists including Zheng Chongbin, Antony Gormley, and Sol LeWitt. The pieces are meant to play on environmental influences including light, water and wind, integrating art with architecture.[6][7][8][39]\\r\\nBy Mass Rapid Transit (MRT):\\r\\nBy public bus:\\r\\nBy water taxi:\\r\\nThe trailer of the 2016 movie Independence Day: Resurgence has a scene depicting the destruction of the property by a hovering alien spacecraft.[40]\\r\\nConstruction area taken from The Float at Marina Bay on 18 August 2007\\r\\nPart of the parcel of land for Marina Bay Sands in the foreground prior to development. The parcel overlooks Singapore's financial district in the background.\\r\\nMarina Bay Sands with Singapore Merlion\\r\\nView of Marina Bay Sands in the background with Custom House located at the foreground\\r\\nCoordinates: 11657.54N 1035130.30E? / ?1.2826500N 103.8584167E? / 1.2826500; 103.8584167","input":"Who is the owner of marina bay sands?"},{"output":"Mitosis","context":"The cell cycle or cell-division cycle is the series of events that take place in a cell leading to its division and duplication of its DNA (DNA replication) to produce two daughter cells. In bacteria, which lack a cell nucleus, the cell cycle is divided into the B, C, and D periods. The B period extends from the end of cell division to the beginning of DNA replication. DNA replication occurs during the C period. The D period refers to the stage between the end of DNA replication and the splitting of the bacterial cell into two daughter cells.[1] In cells with a nucleus, as in eukaryotes, the cell cycle is also divided into three periods: interphase, the mitotic (M) phase, and cytokinesis. During interphase, the cell grows, accumulating nutrients needed for mitosis, preparing it for cell division and duplicating its DNA. During the mitotic phase, the chromosomes separate. During the final stage, cytokinesis, the chromosomes and cytoplasm separate into two new daughter cells. To ensure the proper division of the cell, there are control mechanisms known as cell cycle checkpoints.\\r\\nThe cell-division cycle is a vital process by which a single-celled fertilized egg develops into a mature organism, as well as the process by which hair, skin, blood cells, and some internal organs are renewed. After cell division, each of the daughter cells begin the interphase of a new cycle. Although the various stages of interphase are not usually morphologically distinguishable, each phase of the cell cycle has a distinct set of specialized biochemical processes that prepare the cell for initiation of cell divisions.\\r\\n\\r\\n\\r\\nThe cell cycle consists of four distinct phases: G1 phase, S phase (synthesis), G2 phase (collectively known as interphase) and M phase (mitosis). M phase is itself composed of two tightly coupled processes: karyokinesis, in which the cell's chromosomes are divided, and cytokinesis, in which the cell's cytoplasm divides forming two daughter cells. Activation of each phase is dependent on the proper progression and completion of the previous one. Cells that have temporarily or reversibly stopped dividing are said to have entered a state of quiescence called G0 phase.\\r\\nAfter cell division, each of the daughter cells begin the interphase of a new cycle. Although the various stages of interphase are not usually morphologically distinguishable, each phase of the cell cycle has a distinct set of specialized biochemical processes that prepare the cell for initiation of cell division.\\r\\nG0 is a resting phase where the cell has left the cycle and has stopped dividing. The cell cycle starts with this phase. The word \\"post-mitotic\\" is sometimes used to refer to both quiescent and senescent cells. Non-proliferative (non-dividing) cells in multicellular eukaryotes generally enter the quiescent G0 state from G1 and may remain quiescent for long periods of time, possibly indefinitely (as is often the case for neurons). This is very common for cells that are fully differentiated. Cellular senescence occurs in response to DNA damage and external stress and usually constitutes an arrest in G1. Some cells enter the G0 phase semi-permanently and are considered post-mitotic, e.g., some liver, kidney, and stomach cells. Many cells do not enter G0 and continue to divide throughout an organism's life, e.g., epithelial cells.\\r\\nCellular senescence is also a state that occurs in response to DNA damage or degradation that would make a cell's progeny nonviable; it is often a biochemical alternative to the self-destruction of such a damaged cell by apoptosis.\\r\\nBefore a cell can enter cell division, it needs to take in nutrients. All of the preparations are done during interphase. Interphase is a series of changes that takes place in a newly formed cell and its nucleus, before it becomes capable of division again. It is also called preparatory phase or intermitosis. Previously it was called resting stage because there is no apparent activity related to cell division.Typically interphase lasts for at least 91% of the total time required for the cell cycle.\\r\\nInterphase proceeds in three stages, G1, S, and G2, followed by the cycle of mitosis and cytokinesis. The cell's nuclear DNA contents are duplicated during S phase but may continue till G2 in case of heterochromatin.\\r\\nThe first phase within interphase, from the end of the previous M phase until the beginning of DNA synthesis, is called G1 (G indicating gap). It is also called the growth phase. During this phase, the biosynthetic activities of the cell, which are considerably slowed down during M phase, resume at a high rate. The duration of G1 is highly variable, even among different cells of the same species.[3] In this phase, the cell increases its supply of proteins, increases the number of organelles (such as mitochondria, ribosomes), and grows in size. In G1 phase, a cell has three options. (1) To continue cell cycle and enter S phase (2) Stop cell cycle and enter G0 phase for undergoing differentiation. (3) Get arrested in G1 phase hence it may enter G0 phase or re-enter cell cycle. The deciding factor is availability of nitrogens and storage of energy rich compounds at the deciding point called check point. This check point is called the restriction point or START and is regulated by G1/S cyclins, which cause transition from G1 to S phase. Passage through the G1 check point commits the cell to division.\\r\\nThe ensuing S phase starts when DNA synthesis commences; when it is complete, all of the chromosomes have been replicated, i.e., each chromosome has two (sister) chromatids. Thus, during this phase, the amount of DNA in the cell has effectively doubled, though the ploidy of the cell remains the same. Rates of RNA transcription and protein synthesis are very low during this phase. An exception to this is histone production, most of which occurs during the S phase.[4][5][6]\\r\\nG2 phase occurs after DNA replication and is a period of protein synthesis and rapid cell growth to prepare the cell for mitosis. During this phase microtubules begin to reorganize to form a spindle.\\r\\nThe relatively brief M phase consists of nuclear division (karyokinesis). It is a relatively short period of the cell cycle. M phase is complex and highly regulated. The sequence of events is divided into phases, corresponding to the completion of one set of activities and the start of the next. These phases are sequentially known as:\\r\\nMitosis is the process by which a eukaryotic cell separates the chromosomes in its cell nucleus into two identical sets in two nuclei.[7] During the process of mitosis the pairs of chromosomes condense and attach to fibers that pull the sister chromatids to opposite sides of the cell.[8]\\r\\nMitosis occurs exclusively in eukaryotic cells, but occurs in different ways in different species. For example, animals undergo an \\"open\\" mitosis, where the nuclear envelope breaks down before the chromosomes separate, while fungi such as Aspergillus nidulans and Saccharomyces cerevisiae (yeast) undergo a \\"closed\\" mitosis, where chromosomes divide within an intact cell nucleus.[9] Prokaryotic cells, which lack a nucleus, divide by a process called binary fission.\\r\\nMitosis is immediately followed by cytokinesis, which divides the nuclei, cytoplasm, organelles and cell membrane into two cells containing roughly equal shares of these cellular components. Mitosis and cytokinesis together define the division of the mother cell into two daughter cells, genetically identical to each other and to their parent cell. This accounts for approximately 10% of the cell cycle.\\r\\nBecause cytokinesis usually occurs in conjunction with mitosis, \\"mitosis\\" is often used interchangeably with \\"M phase\\". However, there are many cells where mitosis and cytokinesis occur separately, forming single cells with multiple nuclei in a process called endoreplication. This occurs most notably among the fungi and slime moulds, but is found in various groups. Even in animals, cytokinesis and mitosis may occur independently, for instance during certain stages of fruit fly embryonic development.[10] Errors in mitosis can either kill a cell through apoptosis or cause mutations that may lead to cancer.\\r\\nThe process of mitosis is complex and highly regulated. The sequence of events is divided into phases, corresponding to the completion of one set of activities and the start of the next. These stages are prophase, prometaphase, metaphase, anaphase and telophase. During the process of mitosis the pairs of chromosomes condense and attach to fibers that pull the sister chromatids to opposite sides of the cell. The cell then divides in cytokinesis, to produce two identical daughter cells.[8]\\r\\nRegulation of the cell cycle involves processes crucial to the survival of a cell, including the detection and repair of genetic damage as well as the prevention of uncontrolled cell division. The molecular events that control the cell cycle are ordered and directional; that is, each process occurs in a sequential fashion and it is impossible to \\"reverse\\" the cycle.\\r\\nTwo key classes of regulatory molecules, cyclins and cyclin-dependent kinases (CDKs), determine a cell's progress through the cell cycle.[11] Leland H. Hartwell, R. Timothy Hunt, and Paul M. Nurse won the 2001 Nobel Prize in Physiology or Medicine for their discovery of these central molecules.[12] Many of the genes encoding cyclins and CDKs are conserved among all eukaryotes, but in general more complex organisms have more elaborate cell cycle control systems that incorporate more individual components. Many of the relevant genes were first identified by studying yeast, especially Saccharomyces cerevisiae;[13] genetic nomenclature in yeast dubs many of these genes cdc (for \\"cell division cycle\\") followed by an identifying number, e.g. cdc25 or cdc20.\\r\\nCyclins form the regulatory subunits and CDKs the catalytic subunits of an activated heterodimer; cyclins have no catalytic activity and CDKs are inactive in the absence of a partner cyclin. When activated by a bound cyclin, CDKs perform a common biochemical reaction called phosphorylation that activates or inactivates target proteins to orchestrate coordinated entry into the next phase of the cell cycle. Different cyclin-CDK combinations determine the downstream proteins targeted. CDKs are constitutively expressed in cells whereas cyclins are synthesised at specific stages of the cell cycle, in response to various molecular signals.[14]\\r\\nUpon receiving a pro-mitotic extracellular signal, G1 cyclin-CDK complexes become active to prepare the cell for S phase, promoting the expression of transcription factors that in turn promote the expression of S cyclins and of enzymes required for DNA replication. The G1 cyclin-CDK complexes also promote the degradation of molecules that function as S phase inhibitors by targeting them for ubiquitination. Once a protein has been ubiquitinated, it is targeted for proteolytic degradation by the proteasome. However, results from a recent study of E2F transcriptional dynamics at the single-cell level argue that the role of G1 cyclin-CDK activities, in particular cyclin D-CDK4/6, is to tune the timing rather than the commitment of cell cycle entry.[15]\\r\\nActive S cyclin-CDK complexes phosphorylate proteins that make up the pre-replication complexes assembled during G1 phase on DNA replication origins. The phosphorylation serves two purposes: to activate each already-assembled pre-replication complex, and to prevent new complexes from forming. This ensures that every portion of the cell's genome will be replicated once and only once. The reason for prevention of gaps in replication is fairly clear, because daughter cells that are missing all or part of crucial genes will die. However, for reasons related to gene copy number effects, possession of extra copies of certain genes is also deleterious to the daughter cells.\\r\\nMitotic cyclin-CDK complexes, which are synthesized but inactivated during S and G2 phases, promote the initiation of mitosis by stimulating downstream proteins involved in chromosome condensation and mitotic spindle assembly. A critical complex activated during this process is a ubiquitin ligase known as the anaphase-promoting complex (APC), which promotes degradation of structural proteins associated with the chromosomal kinetochore. APC also targets the mitotic cyclins for degradation, ensuring that telophase and cytokinesis can proceed.[16]\\r\\nCyclin D is the first cyclin produced in the cell cycle, in response to extracellular signals (e.g. growth factors). Cyclin D binds to existing CDK4, forming the active cyclin D-CDK4 complex. Cyclin D-CDK4 complex in turn phosphorylates the retinoblastoma susceptibility protein (Rb). The hyperphosphorylated Rb dissociates from the E2F/DP1/Rb complex (which was bound to the E2F responsive genes, effectively \\"blocking\\" them from transcription), activating E2F. Activation of E2F results in transcription of various genes like cyclin E, cyclin A, DNA polymerase, thymidine kinase, etc. Cyclin E thus produced binds to CDK2, forming the cyclin E-CDK2 complex, which pushes the cell from G1 to S phase (G1/S, which initiates the G2/M transition).[17] Cyclin B-cdk1 complex activation causes breakdown of nuclear envelope and initiation of prophase, and subsequently, its deactivation causes the cell to exit mitosis.[14] A quantitative study of E2F transcriptional dynamics at the single-cell level by using engineered fluorescent reporter cells provided a quantitative framework for understanding the control logic of cell cycle entry, challenging the canonical textbook model. Genes that regulate the amplitude of E2F accumulation, such as Myc, determine the commitment in cell cycle and S phase entry. G1 cyclin-CDK activities are not the driver of cell cycle entry. Instead, they primarily tune the timing of E2F increase, thereby modulating the pace of cell cycle progression.[15]\\r\\nTwo families of genes, the cip/kip (CDK interacting protein/Kinase inhibitory protein) family and the INK4a/ARF (Inhibitor of Kinase 4/Alternative Reading Frame) family, prevent the progression of the cell cycle. Because these genes are instrumental in prevention of tumor formation, they are known as tumor suppressors.\\r\\nThe cip/kip family includes the genes p21, p27 and p57. They halt cell cycle in G1 phase, by binding to, and inactivating, cyclin-CDK complexes. p21 is activated by p53 (which, in turn, is triggered by DNA damage e.g. due to radiation). p27 is activated by Transforming Growth Factor of  (TGF ), a growth inhibitor.\\r\\nThe INK4a/ARF family includes p16INK4a, which binds to CDK4 and arrests the cell cycle in G1 phase, and p14ARF which prevents p53 degradation.\\r\\nSynthetic inhibitors of Cdc25 could also be useful for the arrest of cell cycle and therefore be useful as antineoplastic and anticancer agents.[18]\\r\\nCurrent evidence suggests that a semi-autonomous transcriptional network acts in concert with the CDK-cyclin machinery to regulate the cell cycle. Several gene expression studies in Saccharomyces cerevisiae have identified 800ÿ1200 genes that change expression over the course of the cell cycle.[13][19][20] They are transcribed at high levels at specific points in the cell cycle, and remain at lower levels throughout the rest of the cycle. While the set of identified genes differs between studies due to the computational methods and criteria used to identify them, each study indicates that a large portion of yeast genes are temporally regulated.[21]\\r\\nMany periodically expressed genes are driven by transcription factors that are also periodically expressed. One screen of single-gene knockouts identified 48 transcription factors (about 20% of all non-essential transcription factors) that show cell cycle progression defects.[22] Genome-wide studies using high throughput technologies have identified the transcription factors that bind to the promoters of yeast genes, and correlating these findings with temporal expression patterns have allowed the identification of transcription factors that drive phase-specific gene expression.[19][23] The expression profiles of these transcription factors are driven by the transcription factors that peak in the prior phase, and computational models have shown that a CDK-autonomous network of these transcription factors is sufficient to produce steady-state oscillations in gene expression).[20][24]\\r\\nExperimental evidence also suggests that gene expression can oscillate with the period seen in dividing wild-type cells independently of the CDK machinery. Orlando et al. used microarrays to measure the expression of a set of 1,271 genes that they identified as periodic in both wild type cells and cells lacking all S-phase and mitotic cyclins (clb1,2,3,4,5,6). Of the 1,271 genes assayed, 882 continued to be expressed in the cyclin-deficient cells at the same time as in the wild type cells, despite the fact that the cyclin-deficient cells arrest at the border between G1 and S phase. However, 833 of the genes assayed changed behavior between the wild type and mutant cells, indicating that these genes are likely directly or indirectly regulated by the CDK-cyclin machinery. Some genes that continued to be expressed on time in the mutant cells were also expressed at different levels in the mutant and wild type cells. These findings suggest that while the transcriptional network may oscillate independently of the CDK-cyclin oscillator, they are coupled in a manner that requires both to ensure the proper timing of cell cycle events.[20] Other work indicates that phosphorylation, a post-translational modification, of cell cycle transcription factors by Cdk1 may alter the localization or activity of the transcription factors in order to tightly control timing of target genes.[22][25][26]\\r\\nWhile oscillatory transcription plays a key role in the progression of the yeast cell cycle, the CDK-cyclin machinery operates independently in the early embryonic cell cycle. Before the midblastula transition, zygotic transcription does not occur and all needed proteins, such as the B-type cyclins, are translated from maternally loaded mRNA.[27]\\r\\nAnalyses of synchronized cultures of Saccharomyces cerevisiae under conditions that prevent DNA replication initiation without delaying cell cycle progression showed that origin licensing decreases the expression of genes with origins near their 3' ends, revealing that downstream origins can regulate the expression of upstream genes.[28] This confirms previous predictions from mathematical modeling of a global causal coordination between DNA replication origin activity and mRNA expression,[29][30][31] and shows that mathematical modeling of DNA microarray data can be used to correctly predict previously unknown biological modes of regulation.\\r\\nCell cycle checkpoints are used by the cell to monitor and regulate the progress of the cell cycle.[32] Checkpoints prevent cell cycle progression at specific points, allowing verification of necessary phase processes and repair of DNA damage. The cell cannot proceed to the next phase until checkpoint requirements have been met. Checkpoints typically consist of a network of regulatory proteins that monitor and dictate the progression of the cell through the different stages of the cell cycle.\\r\\nThere are several checkpoints to ensure that damaged or incomplete DNA is not passed on to daughter cells. Three main checkpoints exist: the G1/S checkpoint, the G2/M checkpoint and the metaphase (mitotic) checkpoint.\\r\\nG1/S transition is a rate-limiting step in the cell cycle and is also known as restriction point.[14] This is where the cell checks whether it has enough raw materials to fully replicate its DNA (nucleotide bases, DNA synthase, chromatin, etc.). An unhealthy or malnourished cell will get stuck at this checkpoint.\\r\\nThe G2/M checkpoint is where the cell ensures that it has enough cytoplasm and phospholipids for two daughter cells. But sometimes more importantly, it checks to see if it is the right time to replicate. There are some situations where many cells need to all replicate simultaneously (for example, a growing embryo should have a symmetric cell distribution until it reaches the mid-blastula transition). This is done by controlling the G2/M checkpoint.\\r\\nThe metaphase checkpoint is a fairly minor checkpoint, in that once a cell is in metaphase, it has committed to undergoing mitosis. However that's not to say it isn't important. In this checkpoint, the cell checks to ensure that the spindle has formed and that all of the chromosomes are aligned at the spindle equator before anaphase begins.[33]\\r\\nWhile these are the three \\"main\\" checkpoints, not all cells have to pass through each of these checkpoints in this order to replicate. Many types of cancer are caused by mutations that allow the cells to speed through the various checkpoints or even skip them altogether. Going from S to M to S phase almost consecutively. Because these cells have lost their checkpoints, any DNA mutations that may have occurred are disregarded and passed on to the daughter cells. This is one reason why cancer cells have a tendency to exponentially accrue mutations. Aside from cancer cells, many fully differentiated cell types no longer replicate so they leave the cell cycle and stay in G0 until their death. Thus removing the need for cellular checkpoints. An alternative model of the cell cycle response to DNA damage has also been proposed, known as the postreplication checkpoint.\\r\\nCheckpoint regulation plays an important role in an organism's development. In sexual reproduction, when egg fertilization occurs, when the sperm binds to the egg, it releases signalling factors that notify the egg that it has been fertilized. Among other things, this induces the now fertilized oocyte to return from its previously dormant, G0, state back into the cell cycle and on to mitotic replication and division.\\r\\np53 plays an important role in triggering the control mechanisms at both G1/S and G2/M checkpoints. In addition to p53, checkpoint regulators are being heavily researched for their roles in cancer growth and proliferation.\\r\\nPioneering work by Atsushi Miyawaki and coworkers developed the fluorescent ubiquitination-based cell cycle indicator (FUCCI), which enables fluorescence imaging of the cell cycle. Originally, a green fluorescent protein, mAG, was fused to hGem(1/110) and an orange fluorescent protein (mKO2) was fused to hCdt1(30/120). Note, these fusions are fragments that contain a nuclear localization signal and ubiquitination sites for degradation, but are not functional proteins. The green fluorescent protein is made during the S, G2, or M phase and degraded during the G0 or G1 phase, while the orange fluorescent protein is made during the G0 or G1 phase and destroyed during the S, G2, or M phase.[34] A far-red and near-infrared FUCCI was developed using a cyanobacteria-derived fluorescent protein (smURFP) and a bacteriophytochrome-derived fluorescent protein (movie found at this link).[35]\\r\\nA disregulation of the cell cycle components may lead to tumor formation.[36] As mentioned above, when some genes like the cell cycle inhibitors, RB, p53 etc. mutate, they may cause the cell to multiply uncontrollably, forming a tumor. Although the duration of cell cycle in tumor cells is equal to or longer than that of normal cell cycle, the proportion of cells that are in active cell division (versus quiescent cells in G0 phase) in tumors is much higher than that in normal tissue.[citation needed] Thus there is a net increase in cell number as the number of cells that die by apoptosis or senescence remains the same.\\r\\nThe cells which are actively undergoing cell cycle are targeted in cancer therapy as the DNA is relatively exposed during cell division and hence susceptible to damage by drugs or radiation. This fact is made use of in cancer treatment; by a process known as debulking, a significant mass of the tumor is removed which pushes a significant number of the remaining tumor cells from G0 to G1 phase (due to increased availability of nutrients, oxygen, growth factors etc.). Radiation or chemotherapy following the debulking procedure kills these cells which have newly entered the cell cycle.[14]\\r\\nThe fastest cycling mammalian cells in culture, crypt cells in the intestinal epithelium, have a cycle time as short as 9 to 10 hours. Stem cells in resting mouse skin may have a cycle time of more than 200 hours. Most of this difference is due to the varying length of G1, the most variable phase of the cycle. M and S do not vary much.\\r\\nIn general, cells are most radiosensitive in late M and G2 phases and most resistant in late S phase.\\r\\nFor cells with a longer cell cycle time and a significantly long G1 phase, there is a second peak of resistance late in G1.\\r\\nThe pattern of resistance and sensitivity correlates with the level of sulfhydryl compounds in the cell. Sulfhydryls are natural substances that protect cells from radiation damage and tend to be at their highest levels in S and at their lowest near mitosis.","input":"When does chromosome replication occur in eukaryotic cell?"},{"output":"Manchester Piccadilly","context":"Manchester Piccadilly is the principal railway station in Manchester, England. Opened as Store Street in 1842, it was renamed Manchester London Road in 1847 and Manchester Piccadilly in 1960. Located to the south-eastern side of Manchester city centre, it hosts intercity and cross-country services to national destinations including London Euston, Birmingham, Bristol, Southampton, Wales and Scotland, and local and regional services to destinations in Northern England including Liverpool, Leeds, Sheffield, Newcastle and York. It is one of 19 major stations managed by Network Rail.\\r\\nThe station has twelve terminal platforms in the train shed and two through platforms to the south of it. Piccadilly is also a major interchange with the Metrolink light rail system with two tram platforms in its undercroft.\\r\\nPiccadilly is the busiest station in the Manchester station group with more than 25 million passenger entries and exits between April 2015 and March 2016, (the other major stations in Manchester are Oxford Road and Victoria). It is the fourth busiest station in the United Kingdom outside London.[2] The station hosts services from six train operating companies. It is the second busiest interchange station outside London, with almost 3.8?million passengers changing trains there annually.[3]\\r\\nRefurbishment took five years and cost S100m in 2002, it was the most expensive improvement on the UK rail network at the time.[4] According to an independent poll carried out in 2007, Manchester Piccadilly had the highest customer satisfaction level of any UK station, with 92% of passengers satisfied compared with the national average of 60%.[5]\\r\\nA Transport and Works Act application to build two extra platforms was made in October 2016 and construction is expected to commence after the completion of the Ordsall Chord in January 2018.[6] High Speed 2 proposals would require five more platforms and reconfiguration of the Metrolink station.\\r\\n\\r\\n\\r\\nIn June 1840 the Manchester and Birmingham Railway (M&BR) opened a temporary terminus on its line to Stockport on Travis Street. Its permanent station, Store Street, adjacent to London Road opened on 8 May 1842. It had two platforms, offices and passenger amenities and by then the line extended to Crewe. A large site, 1,700?ft (518?m) long by 500?ft (152?m) wide containing terraced houses and industrial premises had been cleared to make way for the station, which was built on top of a viaduct, 30?ft (9?m) above ground level.[7][8]\\r\\nThe station was shared from the beginning with the Sheffield, Ashton-under-Lyne and Manchester Railway (SA&MR) after an agreement in 1837 by the promoters.[7] The M&BR amalgamated with other railways to create the London and North Western Railway (LNWR) in 1846, and the SA&MR changed its name to the Manchester, Sheffield and Lincolnshire Railway (MS&LR) three years later.[9]\\r\\nThe station's name was changed to London Road in 1847. In 1849 the Manchester, South Junction and Altrincham Railway (MSJA&R) began using the station when it opened its line from Manchester Oxford Road station from the west. Its single platform, opened on 1 August 1849 to the south of, and adjacent to, the main part of the station was the predecessor of the through platforms 13 and 14. The MSJA&R's line connected to the main line just south of the station, forming a through route to the LNWR's line to Liverpool.[8][10]\\r\\nLondon Road was overcrowded by the 1850s and the relationship between the LNWR and MS&LR was poor. In 1862 the companies agreed to rebuild and expand the station so it could be divided, with the MS&LR occupying the north-eastern side and the LNWR occupying the south-western side. The rebuilt station had a new entrance and concourse and a 656?ft (200?m) long iron and glass trainshed consisting of two 95?ft (29?m) wide arched spans covering the terminal platforms, one for each company's platforms. While under construction on 20 January 1866, part of the roof collapsed killing two workmen and injuring 30 more. An enquiry found the collapse was due to strong winds and heavy snowfall. At the same time, both companies built warehouses to the northern side of the station and the viaduct south of the station to Ardwick was widened to four tracks.[11]\\r\\nWithin ten years, the station was again overcrowded as traffic continued to increase and further expansion was required. Between 1880 and 1883 the LNWR widened its side of the station and added more platforms which were covered by two extra 69?ft (21?m) wide arched spans to the trainshed. At the same time the MSJ&AR platform was taken out and rebuilt as an island platform on a girder bridge over Fairfield Street. It was linked to the main station by a footbridge. The improvements were opened in May 1882.[8][12]\\r\\nThe MS&LR changed its name to the Great Central Railway (GCR) in 1897 and opened its own direct route to London in 1899.[12]\\r\\nThe adjacent Mayfield station opened in 1910, providing four platforms which alleviated overcrowding at London Road. The two stations were linked by a footbridge.[12] It closed to passengers in 1960 and closed permanently in 1986. The derelict station building still exists, and various redevelopment schemes have been proposed.[13]\\r\\nFollowing the 1923 railway grouping, the LNWR amalgamated with other railways to create the London, Midland and Scottish Railway (LMS) and the GCR amalgamated with other railways to create the London and North Eastern Railway (LNER).[14] After nationalisation in 1948, the division of the station continued: on one side was the London Midland Region of British Railways, on the other was the Eastern Region. They continued to operate London Road as two separate stations.[8]\\r\\nBetween 1958 and 1966 London Road station underwent a major reconstruction as part of British Railways West Coast Main Line modernisation programme and was renamed Manchester Piccadilly on 12 September 1960.[8]\\r\\nThe London Midland Region rebuilt the station at a cost of S1.75 million (equivalent to S37,500,000 in 2018 prices[15]) in preparation for the introduction of electric train services to London. Most of the station was rebuilt except for the Victorian trainsheds which remained mostly unaltered, although the two 1880s spans were shortened at the concourse end. Reconstruction took place in two phases, 1958ÿ60 and 1963ÿ66, because funding ran out due to a national credit squeeze.[16]\\r\\nThe former MSJA&R through platforms and bridges over Fairfield Street were rebuilt on a pre-stressed concrete slab bridge with cantilevered sides for the tracks. The layout in the trainshed was reconfigured and more and longer platforms added. A new concourse and entrance replaced the 1860s buildings and a ten-storey office block was built alongside to house British Rail. The work was completed on 11 May 1966 in time for the introduction of electric expresses to London.[16][17]\\r\\nThe approach to the station was also redeveloped. The LNWR goods warehouse alongside the station approach closed in 1965 and a curved office block, Gateway House was built in its place, opening in 1969.[16]\\r\\nPiccadilly remained open throughout the reconstruction but much disruption was caused to train services and extensive use was made of Manchester Mayfield and Manchester Central stations by diverted trains. When the work was completed, both stations were closed as surplus to requirements when services into Manchester from the south were concentrated at Piccadilly.[16]\\r\\nIn the early 1970s, the Picc-Vic tunnel project proposed building an underground station, Piccadilly Low Level, under the station.[18] The scheme proposed creating a direct rail link between Piccadilly and Manchester Victoria by building a tunnel and several underground stations under the city centre. The project was cancelled because of the high cost causing transport planners to turn to light rail as a lower-cost option; the stations were eventually linked by the Manchester Metrolink system that opened in the early 1990s. The street-level tramway across the city centre linked the stations and two converted rail lines to Altrincham and Bury. The tram stop in the station's undercroft opened in 1992.[8][13]\\r\\nPiccadilly's through platforms 13 and 14 were further lengthened in 1988/89,[19][20] in connection with the opening of the Windsor Link chord in Salford which allowed trains from destinations to the north of Manchester, such as Bolton, Preston, Blackpool and Scotland to run directly into Piccadilly via the through platforms and continue south to destinations such as Manchester Airport, Stockport and Buxton. It allowed many services from the north to be diverted from Manchester Victoria, which was reduced in size, and enhanced Piccadilly's status as Manchester's main station. The link opened in 1988 and was fully operational in 1989.[21][22]\\r\\nBetween 1998 and 2002, in preparation for the 2002 Commonwealth Games, the station underwent a S100 million redevelopment. The glass roof of the trainshed, which is Grade II listed[1] was re-glazed and re-painted. A new main entrance and enlarged concourse with a mezzanine level, designed by BDP, replaced the 1960s structure which had become insufficient for the number of passengers. A moving walkway was installed to take passengers from the concourse to platforms 13 and 14 at the far south end of the station which involves a long walk. Another entrance was also created on Fairfield Street to access a new taxi rank and drop-off point for cars.[13][8][4][23]\\r\\nThe station has seen several different types of electrification: The first electrified line into London Road was the MSJA&R line to Altrincham, a busy commuter route. It was electrified with overhead lines at 1,500 V DC in 1931. London Road was the terminus of this electrification scheme which extended to the through platforms.[14]\\r\\nThe second line to be electrified was the LNER's Woodhead Route from Manchester to Sheffield at 1,500 V DC. Work on the scheme started in the late 1930s, but was stopped due to World War II, before restarting in the early 1950s. Electrification was completed in September 1954.[24] The two electric 1,500 V DC lines ran into different parts of the station and so did not join with each other.\\r\\n25 kV AC overhead electrification, which was adopted as the national standard by British Railways was brought to London Road/Piccadilly as part of the West Coast Main Line electrification scheme starting in the late-1950s. Electrification reached from Manchester to Crewe by 1960, and to London by 1966. At the same time, the 1,500 V electrification on the Altrincham line was cut back to Oxford Road, as the newer system was extended there from the south.[25] The Altrincham line was converted to 25 kV in 1971.[26]\\r\\nThe two systems co-existed for a number of years. The Woodhead Route was closed as a through line in 1981 but local services to Glossop and Hadfield continued to be operated by 1,500 V trains until the line was converted to 25 kV in 1984.[27]\\r\\nThe Northern Hub scheme saw electrification extended from Manchester to Liverpool in 2015, with work underway to electrify the routes from Manchester to Preston and to Blackpool.[28]\\r\\nThe listed train shed roof which is 105 metres wide between platforms 1 and 12, has four spans, two spans 185 metres in length over the eastern part of the station date from the 1860s while the other two at the western side measuring 150 metres long were built in the early 1880s. The roof is supported by masonry walls with round-headed windows alongside platforms 1 and 12 and rows of cast iron columns. The roof spans have wrought iron trusses with cast iron struts on girders between the columns.[1] The original roof was covered with slates with some glazing. The slates were subsequently replaced with boarded felt. Between 1997 and 1999 the roof was refurbished and 10,000 panes of toughened glass 'float' above the wrought iron trusses.[29]\\r\\nBelow the train shed is an area once used as a goods station. Its cast iron columns and brick arches support the non-through platforms above. The area is now used by the Metrolink station, its tracks and sidings, as well as car parking. The columns were encased in concrete for protection against collision.\\r\\nGeorge W. Buck designed the original skew arch bridge over Fairfield Street with ten cast iron arch ribs as part of a long brick arch viaduct topped with open stonework parapets. The bridge was widened by adding wrought iron plate girders and transverse girders, supporting longitudinal joists with iron arch plates. As part of reconstruction in the 1960s the cast iron arches and spandrels were encased in concrete.[30] Platforms 13 and 14 are situated on the bridge.\\r\\nThe main entrance leads to a concourse with ground floor and mezzanine levels. The Fairfield Street entrance leads to the Metrolink station in the undercroft and is linked to the rail platforms by escalators. Redevelopment between 1997 and 2002 revised the station layout. A glass partition wall separates the concourse from the platforms.[31] The station's approach, constructed in 1969 along with the \\"wavy\\" fronted Gateway House by Richard Seifert, was modernised in 2003.[29]\\r\\nThe Fairfield Street entrance, at basement level, serves the car park, the taxi rank, and the Metrolink station. Above it at track level is a concourse into which the main entrance feeds, housing ticket offices, information points, seating, timetables, toilets, shops, and food and drink outlets. Above the concourse is a second level of food outlets and bars, and the Virgin Trains First Class Lounge. On the main concourse, glass doors within a large glass partition lead to platforms 1 to 12. A travelator leads to the upper concourse linked by a footbridge, steps and lift to platforms 13 and 14. The island lounge contains retail outlets, toilets and a departure lounge. There are vending machines, waiting areas and snack bars on platforms 13 and 14.\\r\\nManchester Piccadilly is accessible for disabled people and has escalators and lifts to all levels, wide-access doors and gates, braille signs, hearing loops and disabled toilet facilities.\\r\\nCycle racks are available on Fairfield Street and the long-stay car park and next to the tower block at the station front. In March 2010, Manchester City Council and Network Rail unveiled plans for a 'Cycle Centre' to provide secure facilities, with maintenance and hire services.\\r\\nThe station has a taxi rank, drop-off/pick-up point, and short- and long-stay car parks[32] accessible from Fairfield Street.[32] The long-stay multi-storey car park is at the rear of the station.\\r\\nTicket barriers were installed in Autumn 2016 between platforms 3 and 7, following an application by Virgin Trains.[33] Ticket barriers are to be introduced on platforms 1-3 and platforms 8-12 in 2018.[citation needed]\\r\\nPlatform 1 is at the north end of the station and the through platforms 13 and 14 are at the south end. Of the terminus platforms, 1-9 are full length platforms, 10-12 are shorter than the others and can only accommodate local trains, platform 12 is the shortest and can only accommodate three coaches.[34] The main entrance and concourse are to the front of the terminal platforms and the taxi and car drop-off entrance is on the southern side on Fairfield Street. The Metrolink tram line passes under the station through the undercroft. Its platforms are under the concourse and railway platforms. To the south of Piccadilly on the opposite side of Fairfield Street is the derelict Manchester Mayfield station which closed for railway use in 1986.\\r\\nIn 2009 the Greater Manchester Integrated Transport Authority advocated reopening the neighbouring derelict Mayfield station to alleviate capacity problems at Piccadilly. The proposal was not advanced and plans focused on increasing track capacity on the cross-city route between Piccadilly and Oxford Road stations.[35]\\r\\nNetwork Rail's Northern Hub plans, costing more than S560?million, aim to improve the heavily congested rail network on the approach into Manchester.[36] Two through platforms would be constructed at Piccadilly and the station linked to Manchester Victoria via the Ordsall Chord, cutting journey times on Trans-Pennine routes.[37][38] The Ordsall Chord will make it possible for trains from the airport to travel via Piccadilly's platforms 13 and 14 and Oxford Road to Manchester Victoria and Leeds and via the Calder Valley Line to Bradford Interchange. Construction started in 2015.[39]\\r\\nPhase 2 aims to alleviate congestion at platforms 13 and 14 by constructing a parallel elevated island platform (platforms 15 and 16) to end crowding and allow the minimum time between trains to be decreased from four to three minutes, improving reliability. It will allow four more trains an hour to be timetabled to Oxford Road including a second freight to Trafford Park.[40][41] Approval for the platforms, at an estimated cost of S200?million, was announced in July 2012.[42]\\r\\nThe proposals aim to simplify train operations at Manchester Piccadilly, creating close associations between pairs of lines leading out of the station and particular platforms, with few crossing moves. Platforms 1 to 4 would be for services on the 'east' lines, to and from Marple, Glossop and Huddersfield; platforms 5 to 12 would be for services on the 'fast' lines, to and from Crewe and Stoke; through platforms 13 to 16 would be dedicated to services on the present 'slow' lines, to and from Manchester Airport and Hazel Grove.[43]\\r\\nIn July 2013 Network Rail opened consultation on three options for the additional platforms at Piccadily, all three of which would impact on local roads and the Grade II listed Star and Garter public house.[44]\\r\\nIn early 2017, doubts arose over government funding and Network Rail's commitment to the project.[45]\\r\\nTo accommodate High Speed 2 (HS2), an extension would require four platforms and a 7.5 miles (12.1?km) tunnel under south Manchester to join the West Coast Main Line at Ardwick. Journey times to Manchester Airport would be reduced to 9 minutes from 18, Birmingham 41 minutes from 86 minutes and London 68 minutes from 128. Station upgrades could include enhanced Metrolink services, improved road access and car parking. The line is planned to be completed by 2032.[46]\\r\\nA major redevelopment of the station and surrounding area has been proposed to complement the HS2 proposals involving the construction of a canopy over the HS2 platforms, the creation of a new entrance, and office, retail and residential development. Designs indicate that the derelict Mayfield Station and the Gateway House office block will be demolished.[47][48] The plans were approved by the Government in November 2016.[49][50]\\r\\nHigh Speed 3 proposals include new platforms under the station and the proposed HS2 platforms. The 2016 \\"Manchester Piccadilly Options Assessment\\" by the National Infrastructure Commission stated: \\"Addition of Northern Powerhouse Rail and Station to the Manchester Piccadilly system will be the last step of the process of transforming the station in to [sic] a transport super hub. The NPR station and its construction will need to be considered throughout the design and implementation of the other station improvements which form the station concept but which are delivered earlier. The NPR station is proposed to stay underground on its way east as it passes through Manchester city. This provides opportunities and offers location and orientation alternatives. Staying under the existing Piccadilly station or positioning NPR under the HS2 station box will maximise interchange efficiencies and travel distances. The orientation will also dictate the number of vertical connection cores also referred to as drums and their locations. The drums will have the function to connect all levels of transport to one and other [sic] at critical junction points.[51]\\r\\nIn October 2017, proposals emerged for an underground station as the preferred option for HS3 services with up to eight trains per hour and connections to HS2.[52]\\r\\nThe station has 12 terminus platforms for services terminating from locations to the south of Manchester, and two through platforms, 13 and 14. The platforms are split into A and B sections to allow more than one train to stand. The through platforms 13 and 14 are used by through services via Manchester Oxford Road to North Wales, Liverpool, North West England, Glasgow and Edinburgh, and through services from Manchester Airport.\\r\\nManchester Piccadilly is currently served by six train operating companies:\\r\\nNorthern\\r\\nThese are operated by a variety of trains of Class 142 Pacers, Class 150 or Class 156 DMUs or Class 323 and Class 319 electric units.\\r\\nArriva Trains Wales\\r\\nAll services (except for the 10:30 departure) are booked for a Class 175 Coradia unit. Class 158 Express Sprinter and occasionally Class 150 Sprinter units when 175s are not available. Two services are operated by Mark 3 carriages hauled by a Class 67.[53]\\r\\nCrossCountry\\r\\nAll CrossCountry services are operated by Class 220 Voyager and Class 221 Super Voyager units.\\r\\nEast Midlands Trains\\r\\nTransPennine Express operate services on three routes.\\r\\nClass 185 Desiro units operate most TransPennine Express services, with the exception of the Scottish services which are operated by Class 350 Desiro units. The Class 185s were supplemented on the Hull and Cleethorpes services by Class 170 Turbostar units until February 2016 (these have now been transferred to Chiltern Railways).[54] A number of services on these routes to/from Manchester Airport start or end here.\\r\\nVirgin Trains\\r\\n City Centre\\r\\nThe Piccadilly Metrolink tram stop, is located at ground level in the undercroft underneath the main line station; an area of the station which was historically used for warehousing,[8] it is one of nine stops serving Manchester city centre, within the system's City Zone. Trams enter the stop from the streets in each direction via short tunnels. There are two platforms, one for trams towards Etihad Campus and Ashton-under-Lyne , and one for trams towards Bury, Eccles and Altrincham. There are steps, lifts and escalators from platform level to a mezzanine level, and further steps, lifts and escalators to the main line station concourse. There are also entrances at ground level from the surrounding streets.[55]\\r\\nThe stop was first opened on 20 July 1992, and was originally known as Piccadilly Undercroft. As the stop was built underneath the main line station platforms, British Rail required that it be built inside a protective concrete box, in order to protect the cast iron supports for the main line platforms from the possibility of collision or fire damage.[55][56]\\r\\nAs Piccadilly was originally a terminus of the system, one platform was originally used for arrivals from Altrincham, Bury, and later Eccles, and the other platform was used for departures. Empty trams ran from the arrival platform into a reversing siding in a tunnel, where they would reverse and then enter the departure platform. The stop was built with extension in mind, and since the opening of the extension towards Ashton in 2013, the former arrivals platform is also used for departures towards Ashton as well as terminating trams, while the former departures platform now also handles arrivals from Ashton. Terminating trams use a reversing siding on the Ashton line between Piccadilly and New Islington tram stops.[55][56]\\r\\nThe tram station was refurbished in 2008, and became the first to display the new Metrolink corporate identity.[57] Station signage bears the yellow and silver livery as applied to the new generation of trams since 2009.[58]\\r\\nThe stop is one of the most used on the Metrolink network.[59]\\r\\nAs of 2018, Manchester Piccadilly stop is the terminus for Metrolink services to Bury and Altrincham, and a major stop on the through services between MediaCityUK and Etihad Campus, and Eccles and Ashton-under-Lyne.[60] Services mostly run every 12 minutes on all routes.[61]\\r\\n\\r\\nItalics denote building under construction","input":"What is the main train station in manchester called?"},{"output":"putative fossilized microorganisms","context":"The earliest known life forms on Earth are putative fossilized microorganisms found in hydrothermal vent precipitates.[1] The earliest time that life forms first appeared on Earth is unknown. They may have lived earlier than 3.77 billion years ago, possibly as early as 4.28 billion years ago,[1] not long after the oceans formed 4.41 billion years ago, and not long after the formation of the Earth 4.54 billion years ago.[1][2][3][4]\\r\\n\\r\\n\\r\\nA life form, or lifeform, is an entity or being that is living.[5][6] Earth remains the only place in the universe known to harbor life forms.[7][8]\\r\\nMore than 99% of all species of life forms, amounting to over five billion species,[9] that ever lived on Earth are estimated to be extinct.[10][11]\\r\\nSome estimates on the number of Earth's current species of life forms range from 10 million to 14 million,[12] of which about 1.2 million have been documented and over 86 percent have not yet been described.[13] However, a May 2016 scientific report estimates that 1 trillion species are currently on Earth, with only one-thousandth of one percent described.[14] The total number of DNA base pairs on Earth is estimated at 5.0 x 1037 with a weight of 50 billion tonnes.[15] In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon).[16] In July 2016, scientists reported identifying a set of 355 genes from the Last Universal Common Ancestor (LUCA) of all organisms living on Earth.[17]\\r\\nThe Earth's biosphere includes soil, hot springs, rock up to 19?km (12?mi) or deeper underground, the deepest parts of the ocean, and at least 64?km (40?mi) high into the atmosphere.[18][19][20] Under certain test conditions, life forms have been observed to thrive in the near-weightlessness of space[21][22] and to survive in the vacuum of outer space.[23][24] Life forms appear to thrive in the Mariana Trench, the deepest spot in the Earth's oceans.[25][26] Other researchers reported related studies that life forms thrive inside rocks up to 580?m (1,900?ft; 0.36?mi) below the sea floor under 2,590?m (8,500?ft; 1.61?mi) of ocean off the coast of the northwestern United States,[25][27] as well as 2,400?m (7,900?ft; 1.5?mi) beneath the seabed off Japan.[28] In August 2014, scientists confirmed the existence of life forms living 800?m (2,600?ft; 0.50?mi) below the ice of Antarctica.[29][30] According to one researcher, \\"You can find microbes everywhere  they're extremely adaptable to conditions, and survive wherever they are.\\"[25]\\r\\nFossil evidence informs most studies of the origin of life. The age of the Earth is about 4.54 billion years;[31][32][33] the earliest undisputed evidence of life on Earth dates from at least 3.5 billion years ago.[34][35][36]\\r\\nThere is evidence that life began much earlier.\\r\\nIn 2017, fossilized microorganisms, or microfossils, were announced to have been discovered in hydrothermal vent precipitates in the Nuvvuagittuq Belt of Quebec, Canada that may be as old as 4.28 billion years old, the oldest record of life on Earth, suggesting \\"an almost instantaneous emergence of life\\" after ocean formation 4.41 billion years ago, and not long after the formation of the Earth 4.54 billion years ago.[1][2][3][4]\\r\\n\\"Remains of life\\" have been found in 4.1 billion-year-old rocks in Western Australia.[39]\\r\\nEvidence of biogenic graphite,[40] and possibly stromatolites,[41] was discovered in 3.7 billion-year-old metasedimentary rocks in southwestern Greenland.\\r\\nIn May 2017, evidence of life on land may have been found in 3.48 billion-year-old geyserite which is often found around hot springs and geysers, and other related mineral deposits, uncovered in the Pilbara Craton of Western Australia.[37][38] This complements the November 2013 publication that microbial mat fossils had been found in 3.48 billion-year-old sandstone in Western Australia.[42][43][44]\\r\\nAccording to biologist Stephen Blair Hedges, \\"If life arose relatively quickly on Earth  then it could be common in the universe.\\"[39][45]\\r\\nStromatolites are made by microbes moving upward to avoid being smothered by sediment.\\r\\nStromatolites left behind by cyanobacteria are one of the oldest fossils of life on Earth.\\r\\nThe cyanobacterial-algal mat, salty lake on the White Sea seaside.\\r\\nWrinkled Kinneyia-type sedimentary structures formed beneath cohesive microbial mats in peritidal zones.[46]\\r\\nKinneyia-like structure in the Grimsby Formation (Silurian) exposed in Niagara Gorge, NY.","input":"The first life forms to appear on earth were?"},{"output":"Technical Sergeant","context":"The chart below represents the current enlisted rank insignia of the United States Air Force.\\r\\nWhile all Air Force military personnel are referred to as Airmen, it can specifically refer to the pay grades of E-1 through E-4 which are below the level of non-commissioned officers (NCOs).[1] Above the pay grade of E-4 (E-5 through E-9) all ranks fall into the category of NCO and are further subdivided into NCOs (E-5 & E-6) and Senior NCOs (E-7 through E-9); the term Junior NCO is sometimes used to refer to staff sergeants and technical sergeants (E-5 & E-6).[1]\\r\\nThe Air Force is the only one of the five branches of the United States military where NCO status is now only achieved at the grade of E-5. Formerly, the grade of Sergeant was obtained after a time as a Senior Airman and successful completion of the Air Force NCO School. In all other branches, NCO status can be achieved at the grade of E-4 (a Corporal in the Army and Marine Corps, Petty Officer Third Class in the Navy and Coast Guard). However, E-4s in the Army with the rank of Specialist are not NCOs. The Air Force mirrored the Army from 1976 to 2 May 1991 with an E-4 being either a Senior Airman wearing three stripes without a star or a Sergeant (informally referred to as \\"Buck Sergeant\\") which was noted by the presence of the central star and considered an NCO.[2] Despite not being an NCO, a Senior Airman who has completed Airman Leadership School can be a supervisor.[1]\\r\\nAlthough the Air Force became an independent service with the National Security Act of 1947, it retained the Army Air Force rank structure and corresponding insignia of years past. This rank structure provided for seven enlisted ranks: Private, Private First Class, Corporal/Technician Fifth Grade, Sergeant/Technician Fourth Grade, Staff Sergeant/Technician Third Grade, Technical Sergeant and Master Sergeant/First Sergeant. Additionally, Air Force personnel were still referred to as soldiers.[2] During the Second World War, many USAAF NCOs wore the Army Air Corps branch insignia of the winged propeller underneath their chevrons.[3]\\r\\nChanges to the rank structure were proposed almost immediately but did not start occurring until the next year. Sometime during late 1947 and early 1948, new chevron designs were tested at Bolling Air Force Base. The style preferred was the one used today, the inverted chevron. Air Force Chief of Staff General Hoyt Vandenberg approved the new chevron on 9 March 1948.[2] A new Air Force \\"Uxbridge Blue\\" uniform and black leather replaced the US Army Air Corps Olive Drab uniform and russet leather in 1949. Air Force personnel were allowed to wear their old Army World War Two pattern uniforms and rank insignia until July, 1952. Recolored \\"hash marks\\" and Overseas Service Bars were worn on the uniform until 1957.\\r\\nAlthough the new chevrons were approved, the titles did not change. Two years would pass (February 1950) before General Vandenberg ordered all enlisted personnel in the Air Force be referred to as \\"airman\\" (singular) and \\"airmen\\" (plural) rather than \\"soldier.\\". A further two years would go by while the enlisted rank structure was studied and changes proposed. The end results finally became effective on 24 April 1952 with the release of a revised Air Force Regulation (AFR) 39-36. This revision changed the names of the enlisted ranks to Basic Airman, Airman Third Class, Airman Second Class, Airman First Class (with resultant loss of NCO status that was not restored until 1967), Staff Sergeant, Technical Sergeant and Master Sergeant.[2]\\r\\nWith the new titles came a proposal for new rank insignia for Airman Third Class through Airman First Class. The proposed insignia would have horizontal stripes for Airman Third Class through Airman First Class while NCOs keep their inverted chevrons. The purpose of the two different types of insignia was to more readily differentiate the airman and NCO tiers while increasing the prestige of the latter. These were not approved at the time of the release of the revised regulation. When they were finally approved by General Vandenberg in December 1952, procurement of these stripes was deferred until approximately June 1955. This change would eventually be reversed, on 12 March 1956, by General Vandenberg's successor, General Twining.[2]\\r\\nDuring his tenure, General Twining also approved the diamond insignia for First Sergeants. This became available on 21 September 1955.[2] With this approval, the foundations of the first seven ranks and insignia the Air Force uses today were in place.\\r\\nThe next major change came with the Military Pay Act of 1958. This established the pay grades of E-8 and E-9 but without corresponding rank titles. The titles of Senior Master Sergeant and Chief Master Sergeant were chosen between July and December 1958 after comments were solicited from the major Air Force commands of the day. After much discussion, the insignia for these two ranks were designed by simply adding one and two chevrons to the top of the Master Sergeant insignia (for E-8 and E-9 respectively), each stripe pointing up.[2]\\r\\nThe rank of Basic Airman was renamed Airman Basic on 5 February 1959, still with no insignia attached.[2]\\r\\nThe next series of changes to Air Force enlisted ranks did not occur for almost eight years. In January 1967 the position of Chief Master Sergeant of the Air Force was created. This position gained its own special insignia, the Chief Master Sergeant chevrons with a wreath encircling the center star. On 1 August 1967 the lower enlisted rank names changed (revised AFR 39-36 on 19 October 1967) renamed Airman Third Class, Airman Second Class and Airman First Class to Airman, Airman First Class and Sergeant (known unofficially as \\"Buck Sergeant\\" by the NCO ranks at the time) respectively. This returned Sergeant to the rank structure as the first step in the NCO tier as a retention move but required achievement of a 5-skill Air Force Specialty Code (AFSC) level. No changes to the respective insignias were made.[2] Footnote: On 1 July 1969 the Air Force Serial Number was changed to the member's Social Security Number (SSAN). This change was for all grades and the three major US military forces including guard and reserve components. The commandant of the USMC did not adopt the serial number change to his forces.\\r\\nIn a 30 December 1975 directive the grade of Sergeant was split into two separate ranks while retaining the grade of E-4. Senior Airman would be the last junior enlisted tier rank while Sergeant would remain the first rank in the NCO tier. The impetus behind this was to laterally promote senior E-4 airmen who were ready for NCO responsibilities but not prepared to take on the role of a Staff Sergeant. This permitted airmen who had not yet reached the AFSC 5-skill level to achieve the pay grade of E-4, while according those who had NCO status. To differentiate the two ranks, the directive changed the silver star in the center of Airman, Airman First Class and Senior Airman changed to blue while the star on Sergeant chevrons remained silver. Having two ranks within one grade mirrored the Army's Specialist/Corporal division of E-4. This dual role would last until March 1991 when then Chief of Staff General McPeak terminated the rank of Sergeant effective 2 May 1991. This termination was due in part to the manning reductions that occurred in the postÿCold War drawdowns of the early 1990s. The last of the \\"Buck Sergeants\\" would have either been promoted or discharged under High Year Tenure by December 1998.[2]\\r\\nThe year 1991 also saw the last major change to the enlisted rank insignia. In October 1991 General McPeak and Chief Master Sergeant of the Air Force Pfingston announced that the senior NCO tier would have new chevron layouts and that all chevrons would have a white star in the center. The change in senior NCO chevrons was the first since chevrons came into being in 1948. Until that time, Master Sergeant had been composed of six inverted chevrons (six down) with none pointing up, Senior Master Sergeant six down with one up and Chief Master Sergeant six down with two up. The new layout changed the insignia to the current layout (see chart above). The second change, changing the star color to white, was actually two changes in one. It added a star to the Airman through Senior Airman rank insignias where there had been none since 1975 (the blue star carried by these chevrons was the same color as the blue in the stripes giving the impression that the star was not there) and changing the silver star on the NCO and senior NCO chevrons to white.[2]\\r\\nIn November 1998, the duty position of Senior Enlisted Advisor was changed to Command Chief Master Sergeant. Along with the change, the addition of a star in the empty blue area between the chevrons was added to denote those holding this position.\\r\\nIn November 2004, the Chief Master Sergeant of the Air Force insignia was updated to include the Great Seal of the United States with a white star on either side. These additions were placed in the empty blue area between the chevrons.","input":"What's an e6 in the air force?"},{"output":"near Babylon","context":"The petroleum industry is not of recent origin, but petroleum's current status as the key component of politics, society, and technology has its roots in the early 20th century. The invention of the internal combustion engine was the major influence in the rise in the importance of petroleum.\\r\\n\\r\\n\\r\\nFour thousand years ago, according to Herodotus and confirmed by Diodorus Siculus, asphalt was used in the construction of the walls and towers of Babylon; there were oil pits near Ardericca (near Babylon), and a pitch spring on Zacynthus (Ionian islands, Greece).[1] Great quantities of it were found on the banks of the river Issus[citation needed], one of the tributaries of the Euphrates. Ancient Persian tablets indicate the medicinal and lighting uses of petroleum in the upper levels of their society[citation needed].\\r\\nOil was exploited in the Roman province of Dacia, now in Romania, where it was called picula.[citation needed]\\r\\nThe use of petroleum dates back to ancient China more than 2000 years ago. In I Ching, one of the earliest Chinese writings cites the use of oil in its raw state without refining was first discovered, extracted, and used in China in the first century BCE. In addition, the Chinese were the first to use petroleum as fuel as the early as the fourth century BCE.[2][3][4][5]\\r\\nThe earliest known oil wells were drilled in China in 347 AD or earlier. They had depths of up to about 800 feet (240?m) and were drilled using bits attached to bamboo poles.[6][7][8][9][unreliable source?] The oil was burned to evaporate brine and produce salt. By the 10th century, extensive bamboo pipelines connected oil wells with salt springs. The ancient records of China and Japan are said to contain many allusions to the use of natural gas for lighting and heating. Petroleum was known as burning water in Japan in the 7th century.[1] In his book Dream Pool Essays written in 1088, the polymathic scientist and statesman Shen Kuo of the Song Dynasty coined the word fS (Shy܇u, literally \\"rock oil\\") for petroleum, which remains the term used in contemporary Chinese and Japanese (Sekiy).\\r\\nThe first streets of Baghdad were paved with tar, derived from petroleum that became accessible from natural fields in the region. In the 9th century, oil fields were exploited in the area around modern Baku, Azerbaijan. These fields were described by the Arab geographer Abu al-Hasan 'Alؐ al-Mas'dؐ in the 10th century, and by Marco Polo in the 13th century, who described the output of those wells as hundreds of shiploads. Distillation of Petroleum was described by the Persian alchemist, Muhammad ibn Zakarؐya Rzi (Rhazes).[10][unreliable source] There was production of chemicals such as kerosene in the alembic (al-ambiq),[11] which was mainly used for kerosene lamps.[12] Arab and Persian chemists also distilled crude oil in order to produce flammable products for military purposes. Through Islamic Spain, distillation became available in Western Europe by the 12th century.[13] It has also been present in Romania since the 13th century, being recorded as p?cur?.[14]\\r\\nThe earliest mention of petroleum in the Americas occurs in Sir Walter Raleigh's account of the Trinidad Pitch Lake in 1595; while thirty-seven years later, the account of a visit of a Franciscan, Joseph de la Roche d'Allion, to the oil springs of New York was published in Gabriel Sagard's Histoire du Canada. A Finnish born Swede, scientist and student of Carl Linnaeus, Peter Kalm, in his work Travels into North America published first in 1753 showed on a map the oil springs of Pennsylvania.[1]\\r\\nIn 1710 or 1711 (sources vary) the Russian-born Swiss physician and Greek teacher Eirini d'Eyrinys (also spelled as Eirini d'Eirinis) discovered asphaltum at Val-de-Travers, (Neuchatel). He established a bitumen mine de la Presta there in 1719 that operated until 1986.[15][16][17][18]\\r\\nIn 1745 under the Empress Elizabeth of Russia the first oil well and refinery were built in Ukhta by Fiodor Priadunov. Through the process of distillation of the \\"rock oil\\" (petroleum) he received a kerosene-like substance, which was used in oil lamps by Russian churches and monasteries (though households still relied on candles).[19]\\r\\nOil sands were mined from 1745 in Merkwiller-Pechelbronn, Alsace under the direction of Louis Pierre Ancillon de la Sablonnire, by special appointment of Louis XV.[20][21] The Pechelbronn oil field was active until 1970, and was the birthplace of companies like Antar and Schlumberger. The first modern refinery was built there in 1857.[20]\\r\\nThe modern history of petroleum began in the 19th century with the refining of paraffin from crude oil. The Scottish chemist James Young in 1847 noticed a natural petroleum seepage in the Riddings colliery at Alfreton, Derbyshire from which he distilled a light thin oil suitable for use as lamp oil, at the same time obtaining a thicker oil suitable for lubricating machinery. In 1846, Baku (settlement Bibi-Heybat) the first ever well drilled with percussion tools to a depth of 21 meters for oil exploration. In 1848, Young set up a small business refining the crude oil. The new oils were successful, but the supply of oil from the coal mine soon began to fail (eventually being exhausted in 1851). Young, noticing that the oil was dripping from the sandstone roof of the coal mine, theorized that it somehow originated from the action of heat on the coal seam and from this thought that it might be produced artificially.\\r\\nFollowing up this idea, he tried many experiments and eventually succeeded, by distilling cannel coal at a low heat, a fluid resembling petroleum, which when treated in the same way as the seep oil gave similar products. Young found that by slow distillation he could obtain a number of useful liquids from it, one of which he named \\"paraffine oil\\" because at low temperatures it congealed into a substance resembling paraffin wax.[22]\\r\\nThe production of these oils and solid paraffin wax from coal formed the subject of his patent dated 17 October 1850. In 1850 Young & Meldrum and Edward William Binney entered into partnership under the title of E.W. Binney & Co. at Bathgate in West Lothian and E. Meldrum & Co. at Glasgow; their works at Bathgate were completed in 1851 and became the first truly commercial oil-works and oil refinery in the world, using oil extracted from locally mined torbanite, shale, and bituminous coal to manufacture naphtha and lubricating oils; paraffin for fuel use and solid paraffin were not sold till 1856.\\r\\nAbraham Pineo Gesner, a Canadian geologist developed a process to refine a liquid fuel from coal, bitumen and oil shale. His new discovery, which he named kerosene, burned more cleanly and was less expensive than competing products, such as whale oil. In 1850, Gesner created the Kerosene Gaslight Company and began installing lighting in the streets in Halifax and other cities. By 1854, he had expanded to the United States where he created the North American Kerosene Gas Light Company at Long Island, New York. Demand grew to where his companys capacity to produce became a problem, but the discovery of petroleum, from which kerosene could be more easily produced, solved the supply problem.\\r\\nIn 1848 the first modern oil well was drilled in Asia, on the Aspheron Peninsula north-east of Baku, by Russian engineer F.N. Semyenov.[23]\\r\\nIgnacy ?ukasiewicz improved Gesner's method to develop a means of refining kerosene from the more readily available \\"rock oil\\" (\\"petr-oleum\\") seeps, in 1852, and the first rock oil mine was built in B܇brka, near Krosno in central European Galicia (Poland) in 1854. These discoveries rapidly spread around the world, and Meerzoeff built the first modern Russian refinery in the mature oil fields at Baku in 1861. At that time Baku produced about 90% of the world's oil.\\r\\nThe question of what constituted the first commercial oil well is a difficult one to answer. Edwin Drake's 1859 well near Titusville, Pennsylvania, discussed more fully below, is popularly considered the first modern well.[24] Drake's well is probably singled out because it was drilled, not dug; because it used a steam engine; because there was a company associated with it; and because it touched off a major boom. However, the first well ever drilled anywhere in the world, which produced oil, was drilled in 1857 to a depth of 280 feet by the American Merrimac Company in La Brea (Spanish for Pitch) in southeast Trinidad in the Caribbean.[25] Additionally, there was considerable activity before Drake in various parts of the world in the mid-19th century. A group directed by Major Alexeyev of the Bakinskii Corps of Mining Engineers hand-drilled a well in the Baku region in 1848.[26] There were engine-drilled wells in West Virginia in the same year as Drake's well.[27] An early commercial well was hand dug in Poland in 1853, and another in nearby Romania in 1857. At around the same time the world's first, but small, oil refineries were opened at Jas?o, in Poland, with a larger one being opened at Ploie?ti, in Romania, shortly after. Romania is the first country in the world to have its crude oil output officially recorded in international statistics, namely 275 tonnes.[28][29] In 1875, crude oil was discovered by David Beaty at his home in Warren, Pennsylvania. This led to the opening of the Bradford oil field, which, by the 1880s, produced 77 percent of the global oil supply. However, by the end of the 19th century, the Russian Empire, particularly the Branobel company in Azerbaijan, had taken the lead in production.[30]\\r\\nSamuel Kier established America's first oil refinery in Pittsburgh on Seventh avenue near Grant Street, in 1853. In addition to the activity in West Virginia and Pennsylvania, an important early oil well in North America was in Oil Springs, Ontario, Canada in 1858, dug by James Miller Williams.[31] The discovery at Oil Springs touched off an oil boom which brought hundreds of speculators and workers to the area. New oil fields were discovered nearby throughout the late 19th century and the area developed into a large petrochemical refining centre and exchange.[32] The modern US petroleum industry is considered to have begun with Edwin Drake's drilling of a 69-foot (21?m) oil well in 1859,[33] on Oil Creek near Titusville, Pennsylvania, for the Seneca Oil Company (originally yielding 25 barrels per day (4.0?m3/d), by the end of the year output was at the rate of 15 barrels per day (2.4?m3/d)). The industry grew through the 1800s, driven by the demand for kerosene and oil lamps. It became a major national concern in the early part of the 20th century; the introduction of the internal combustion engine provided a demand that has largely sustained the industry to this day. Early \\"local\\" finds like those in Pennsylvania and Ontario were quickly outpaced by demand, leading to \\"oil booms\\" in Ohio, Texas, Oklahoma, and California.\\r\\nBy 1910, significant oil fields had been discovered in the Dutch East Indies (1885, in Sumatra), Persia (1908, in Masjed Soleiman), Peru (1863, in Zorritos District), Venezuela (1914, in Maracaibo Basin), and Mexico, and were being developed at an industrial level. Significant oil fields were exploited in Alberta (Canada) from 1947. First offshore oil drilling at Oil Rocks (Neft Dashlari) in the Caspian Sea off Azerbaijan eventually resulted in a city built on pylons in 1949. Availability of oil and access to it, became of \\"cardinal importance\\" in military power before[34] and after World War I, particularly for navies as they changed from coal, but also with the introduction of motor transport, tanks and airplanes.[35] Such thinking would continue in later conflicts of the twentieth century, including World War II, during which oil facilities were a major strategic asset and were extensively bombed.[36] In 1938, vast reserves of oil were discovered in the Al-Ahsa region along the coast of the Persian Gulf.\\r\\nUntil the mid-1950s coal was still the world's foremost fuel, but after this time oil quickly took over. Later, following the 1973 and 1979 energy crises, there was significant media coverage on the subject of oil supply levels. This brought to light the concern that oil is a limited resource that will eventually run out, at least as an economically viable energy source. Although at the time the most common and popular predictions were quite dire, a period of increased production and reduced demand in the following years caused an oil glut in the 1980s. This was not to last, however, and by the first decade of the 21st century discussions about peak oil had returned to the news.\\r\\nToday, about 90% of vehicular fuel needs are met by oil. Petroleum also makes up 40% of total energy consumption in the United States, but is responsible for only 2% of electricity generation. Petroleum's worth as a portable, dense energy source powering the vast majority of vehicles and as the base of many industrial chemicals makes it one of the world's most important commodities.\\r\\nThe top three oil producing countries are Saudi Arabia, Russia, and the United States.[37] About 80% of the world's readily accessible reserves are located in the Middle East, with 62.5% coming from the Arab 5: Saudi Arabia (12.5%), UAE, Iraq, Qatar and Kuwait. However, with high oil prices (above $100/barrel), Venezuela has larger reserves than Saudi Arabia due to its crude reserves derived from bitumen.\\r\\n29. ^ www.geohelp.net/world.html\\r\\n30. ^ www.azer.com/.../102_oil_chronology.html\\r\\n31. ^ archives.datapages.com/data/phi/v12_2011/yusif.pdf\\r\\n32. ^ www.energy-101.org/non-renewable-energy/petroleum-facts/petroleum-history","input":"Where was oil first discovered in the world?"},{"output":"about 1290","context":"Glasses, also known as eyeglasses or spectacles, are devices consisting of glass or hard plastic lenses mounted in a frame that holds them in front of a person's eyes, typically using a bridge over the nose and arms which rest over the ears.\\r\\nGlasses are typically used for vision correction, such as with reading glasses and glasses used for nearsightedness. Safety glasses provide eye protection against flying debris for construction workers or lab technicians; these glasses may have protection for the sides of the eyes as well as in the lenses. Some types of safety glasses are used to protect against visible and near-visible light or radiation. Glasses are worn for eye protection in some sports, such as squash. Glasses wearers may use a strap to prevent the glasses from falling off during movement or sports. Wearers of glasses that are used only part of the time may have the glasses attached to a cord that goes around their neck, to prevent the loss of the glasses.\\r\\nSunglasses allow better vision in bright daylight, and may protect one's eyes against damage from high levels of ultraviolet light. Typical sunglasses are darkened for protection against bright light or glare; some specialized glasses are clear in dark or indoor conditions, but turn into sunglasses when in bright light. Most sunglasses do not have corrective power in the lenses; however, special prescription sunglasses can be ordered.\\r\\nSpecialized glasses may be used for viewing specific visual information, for example 3D glasses for 3D films (stereoscopy). Sometimes glasses are worn purely for fashion or aesthetic purposes. Even with glasses used for vision correction, a wide range of fashions are available, using plastic, wire, and other materials.\\r\\nPeople are more likely to need glasses the older they get with 93% of people between the age of 65-75 wearing corrective lenses.[1][2]\\r\\nGlasses can be marked or found by their primary function, but also appear in combinations such as prescription sunglasses or safety glasses with enhanced magnification.\\r\\nCorrective lenses are used to correct refractive errors by bending the light entering the eye in order to alleviate the effects of conditions such as nearsightedness (myopia), farsightedness (hypermetropia) or astigmatism. The ability of one's eyes to accommodate their focus to near and distant focus alters over time. A common condition in people over forty years old is presbyopia, which is caused by the eye's crystalline lens losing elasticity, progressively reducing the ability of the lens to accommodate (i.e. to focus on objects close to the eye). Few people have a pair of eyes that show exactly equal refractive characteristics; one eye may need a \\"stronger\\" (i.e. more refracting) lens than the other.\\r\\nCorrective lenses bring the image back into focus on the retina. They are made to conform to the prescription of an ophthalmologist or optometrist. A lensmeter can be used to verify the specifications of an existing pair of glasses. Corrective eyeglasses can significantly improve the life quality of the wearer. Not only do they enhance the wearer's visual experience, but can also reduce problems that result from eye strain, such as headaches or squinting.\\r\\nThe most common type of corrective lens is \\"single vision\\", which has a uniform refractive index. For people with presbyopia and hyperopia, bifocal and trifocal glasses provide two or three different refractive indices, respectively, and progressive lenses have a continuous gradient.\\r\\nReading glasses provide a separate set of glasses for focusing on close-by objects. Reading glasses are available without prescription from drugstores, and offer a cheap, practical solution, though these have a pair of simple lenses of equal power, so will not correct refraction problems like astigmatism or refractive or prismatic variations between the left and right eye. For total correction of the individual's sight, glasses complying to a recent ophthalmic prescription are required.\\r\\nAdjustable-focus eyeglasses might be used to replace bifocals or trifocals, or might be used to produce cheaper single-vision glasses (since they don't have to be custom-manufactured for every person).\\r\\nPinhole glasses are a type of corrective glasses that do not use a lens. Pinhole glasses do not actually refract the light or change focal length. Instead, they create a diffraction limited system, which has an increased depth of field, similar to using a small aperture in photography. This form of correction has many limitations that prevent it from gaining popularity in everyday use. Pinhole glasses can be made in a DIY fashion by making small holes in a piece of card which is then held in front of the eyes with a strap or cardboard arms.\\r\\nSafety glasses are worn to protect the eyes in different situations. They are made with break-proof plastic lenses to protect the eye from flying debris or other matter. Construction workers, factory workers, machinists and lab technicians are often required to wear safety glasses to shield the eyes from flying debris or hazardous splatters such as blood or chemicals. As of 2017, dentists and surgeons in Canada and other countries are required to wear safety glasses to protect against infection from patients' blood or other body fluids. There are also safety glasses for welding, which are styled like wraparound sunglasses, but with much darker lenses, for use in welding where a full sized welding helmet is inconvenient or uncomfortable. These are often called \\"flash goggles\\", because they provide protection from welding flash. Nylon frames are usually used for protection eyewear for sports because of their lightweight and flexible properties. Unlike most regular glasses, safety glasses often include protection beside the eyes as well as in front of the eyes.\\r\\nSunglasses provide improved comfort and protection against bright light and often against ultraviolet (UV) light. To properly protect the eyes from the dangers of UV light, sunglasses should have UV-400 blocker to provide good coverage against the entire light spectrum that poses a danger. [3] Photochromic lenses, which are photosensitive, darken when struck by UV light. The dark tint of the lenses in a pair of sunglasses blocks the transmission of light through the lens.\\r\\nLight polarization is an added feature that can be applied to sunglass lenses. Polarization filters are positioned to remove horizontally polarized rays of light, which eliminates glare from horizontal surfaces (allowing wearers to see into water when reflected light would otherwise overwhelm the scene). Polarized sunglasses may present some difficulties for pilots since reflections from water and other structures often used to gauge altitude may be removed. Liquid-crystal displays often emit polarized light making them sometimes difficult to view with polarized sunglasses. Sunglasses may be worn just for aesthetic purposes, or simply to hide the eyes. Examples of sunglasses that were popular for these reasons include teashades and mirrorshades. Many blind people wear nearly opaque glasses to hide their eyes for cosmetic reasons.\\r\\nSunglasses may also have corrective lenses, which requires a prescription. Clip-on sunglasses or sunglass clips can be attached to another pair of glasses. Some wrap-around sunglasses are large enough to be worn over top of another pair of glasses. Otherwise, many people opt to wear contact lenses to correct their vision so that standard sunglasses can be used.\\r\\nThe illusion of three dimensions on a two dimensional surface can be created by providing each eye with different visual information. 3D glasses create the illusion of three dimensions by filtering a signal containing information for both eyes. The signal, often light reflected off a movie screen or emitted from an electronic display, is filtered so that each eye receives a slightly different image. The filters only work for the type of signal they were designed for.\\r\\nAnaglyph 3D glasses have a different colored filter for each eye, typically red and blue or red and green. A polarized 3D system on the other hand uses polarized filters. Polarized 3D glasses allow for color 3D, while the red-blue lenses produce an image with distorted coloration. An active shutter 3D system uses electronic shutters. Head-mounted displays can filter the signal electronically and then transmit light directly into the viewers eyes.\\r\\nAnaglyph and polarized glasses are distributed to audiences at 3D movies. Polarized and active shutter glasses are used with many home theaters. Head-mounted displays are used by a single person, but the input signal can be shared between multiple units.\\r\\nGlasses can also provide magnification that is useful for people with vision impairments or specific occupational demands. An example would be bioptics or bioptic telescopes which have small telescopes mounted on, in, or behind their regular lenses. Newer designs use smaller lightweight telescopes, which can be embedded into the corrective glass and improve aesthetic appearance (mini telescopic spectacles). They may take the form of self-contained glasses that resemble goggles or binoculars, or may be attached to existing glasses.\\r\\nYellow tinted glasses are a type of glasses with a minor yellow tint. They perform minor color correction, on top of reducing headaches due to lack of blinking. They may also be considered minor corrective unprescribed glasses.[4] Depending on the company, these computer or gaming glasses can also filter out high energy blue and ultra-violet light from LCD screens, fluorescent lighting, and other sources of light. This allows for reduced eye-strain.[5] These glasses can be ordered as standard or prescription lenses that fit into standard optical frames.[6] Due to the ultra-violet light blocking nature of these lenses, they also help users sleep at night along with reducing age-related macular degeneration.[7][8]\\r\\nAnti-glare protection glasses, or anti-reflective glasses, can reduce the reflection of light that enters our eyes. The lenses are given an anti-glare coating to prevent reflections of light under different lighting conditions. By reducing the amount of glare on your eyes, vision can be improved.[9] The anti-glare also applies to the outer glass, thus allowing for better eye contact.[9]\\r\\nThe ophthalmic frame is the part of a pair of glasses which is designed to hold the lenses in proper position. Ophthalmic frames come in a variety of styles, sizes, materials, shapes, and colors.[10]\\r\\nCorrective lenses can be produced in many different shapes from a circular lens called a lens blank. Lens blanks are cut to fit the shape of the frame that will hold them. Frame styles vary and fashion trends change over time, resulting in a multitude of lens shapes. For lower power lenses, there are few restrictions which allows for many trendy and fashionable shapes. Higher power lenses can cause distortion of peripheral vision and may become thick and heavy if a large lens shape is used. However, if the lens becomes too small, the field of view can be drastically reduced.\\r\\nBifocal, trifocal, and progressive lenses generally require a taller lens shape to leave room for the different segments while preserving an adequate field of view through each segment. Frames with rounded edges are the most efficient for correcting myopic prescriptions, with perfectly round frames being the most efficient. Before the advent of eyeglasses as a fashion item, when frames were constructed with only functionality in mind, virtually all eyeglasses were either round, oval, or curved octagons. It was not until glasses began to be seen as an accessory that different shapes were introduced to be more aesthetically pleasing than functional.\\r\\nScattered evidence exists for use of vision aid devices in Greek and Roman times, most prominently the use of an emerald by emperor Nero as mentioned by Pliny the Elder.[15]\\r\\nThe use of a convex lens to form an enlarged/magnified image was most likely described in Ptolemy's Optics (which however only survives in a poor Arabic translation). Ptolemy's description of lenses was commented upon and improved by Ibn Sahl (10th century) and most notably by Alhazen (Book of Optics, ca. 1021). Latin translations of Ptolemy's Optics and of Alhazen became available in Europe in the 12th century, coinciding with the development of \\"reading stones\\".\\r\\nRobert Grosseteste's treatise De iride (\\"On the Rainbow\\"), written between 1220 and 1235, mentions using optics to \\"read the smallest letters at incredible distances\\". A few years later in 1262, Roger Bacon is also known to have written on the magnifying properties of lenses.[16] The development of the first eyeglasses took place in Northern Italy in the second half of the 13th century.[17]\\r\\nIndependently of the development of optical lenses, some cultures developed \\"sunglasses\\" for eye protection, without any corrective properties.[18] Thus, flat panes of smoky quartz, were used in 12th-century China.[a] Similarly, the Inuit have used snow goggles for eye protection.\\r\\nThe first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290: In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa (ca. 1255ÿ1311) wrote \\"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision... And it is so short a time that this new art, never before extant, was discovered.?... I saw the one who first discovered and practiced it, and I talked to him.\\"[20]\\r\\nGiordano's colleague Friar Alessandro della Spina of Pisa (d. 1313) was soon making eyeglasses. The Ancient Chronicle of the Dominican Monastery of St. Catherine in Pisa records: \\"Eyeglasses, having first been made by someone else, who was unwilling to share them, he [Spina] made them and shared them with everyone with a cheerful and willing heart.\\"[21] By 1301, there were guild regulations in Venice governing the sale of eyeglasses.[22]\\r\\nThe earliest pictorial evidence for the use of eyeglasses is Tommaso da Modena's 1352 portrait of the cardinal Hugh de Provence reading in a scriptorium. Another early example would be a depiction of eyeglasses found north of the Alps in an altarpiece of the church of Bad Wildungen, Germany, in 1403. These early glasses had convex lenses that could correct both hyperopia (farsightedness), and the presbyopia that commonly develops as a symptom of aging. It was not until 1604 that Johannes Kepler published the first correct explanation as to why convex and concave lenses could correct presbyopia and myopia.[b]\\r\\nEarly frames for glasses consisted of two magnifying glasses riveted together by the handles so that they could grip the nose. These are referred to as \\"rivet spectacles\\". The earliest surviving examples were found under the floorboards at Kloster Wienhausen, a convent near Celle in Germany; they have been dated to circa 1400.[25]\\r\\nClaims that Salvino degli Armati of Florence invented eyeglasses have been exposed as hoaxes.[26][27]\\r\\nMarco Polo is sometimes claimed to have encountered eyeglasses during his travels in China in the 13th century, however, no such statement appears in his accounts.[28][29] Indeed, the earliest mentions of eyeglasses in China occur in the 15th century and those Chinese sources state that eyeglasses were imported.[30]\\r\\nIt is also sometimes claimed that glasses were first invented in India. In 1907 Professor Berthold Laufer stated in his history of glasses that \\"the opinion that spectacles originated in India is of the greatest probability and that spectacles must have been known in India earlier than in Europe\\".[31] However, Joseph Needham showed that the mention of glasses in the manuscript Laufer used to justify the prior invention of them in Asia did not exist in older versions of that manuscript, and the reference to them in later versions was added during the Ming dynasty.[32] In a 1971 article in the British Journal of Ophthalmology it was argued that it: \\"...is therefore most likely that the use of lenses reached Europe via the Arabs, as did Hindu mathematics and the ophthalmological works of the ancient Hindu surgeon Susruta\\",[33] but all dates given are well after the existence of eyeglasses in Italy was established, and there had been significant shipments of eye glasses from Italy to the Middle East, with one shipment as large as 24,000 glasses.[34]\\r\\nThe American scientist Benjamin Franklin, who suffered from both myopia and presbyopia, invented bifocals. Serious historians have from time to time produced evidence to suggest that others may have preceded him in the invention; however, a correspondence between George Whatley and John Fenno, editor of The Gazette of the United States, suggested that Franklin had indeed invented bifocals, and perhaps 50 years earlier than had been originally thought.[35] The first lenses for correcting astigmatism were designed by the British astronomer George Airy in 1825.[36]\\r\\nOver time, the construction of frames for glasses also evolved. Early eyepieces were designed to be either held in place by hand or by exerting pressure on the nose (pince-nez). Girolamo Savonarola suggested that eyepieces could be held in place by a ribbon passed over the wearer's head, this in turn secured by the weight of a hat. The modern style of glasses, held by temples passing over the ears, was developed some time before 1727, possibly by the British optician Edward Scarlett. These designs were not immediately successful, however, and various styles with attached handles such as \\"scissors-glasses\\" and lorgnettes were also fashionable from the second half of the 18th century and into the early 19th century.\\r\\nIn the early 20th century, Moritz von Rohr and Zeiss (with the assistance of H. Boegehold and A. Sonnefeld[37]), developed the Zeiss Punktal spherical point-focus lenses that dominated the eyeglass lens field for many years. In 2008, Joshua Silver designed eyewear with adjustable corrective glasses. They work by silicone liquid, a syringe, and a pressure mechanism.[38]\\r\\nDespite the increasing popularity of contact lenses and laser corrective eye surgery, glasses remain very common, as their technology has improved. For instance, it is now possible to purchase frames made of special memory metal alloys that return to their correct shape after being bent. Other frames have spring-loaded hinges. Either of these designs offers dramatically better ability to withstand the stresses of daily wear and the occasional accident. Modern frames are also often made from strong, light-weight materials such as titanium alloys, which were not available in earlier times.\\r\\nIn the 1930s, \\"spectacles\\" were described as \\"medical appliances.\\"[39] Wearing spectacles was sometimes considered socially humiliating. In the 1970s, fashionable glasses started to become available through manufacturers, and the government also recognized the demand for stylized eyewear.[39]\\r\\nGraham Pullin describes how devices for disability, like glasses, have traditionally been designed to camouflage against the skin and restore ability without being visible.[39] In the past, design for disability has \\"been less about projecting a positive image as about trying not to project an image at all.\\"[39] Pullin uses the example of spectacles, traditionally categorized as a medical device for \\"patients\\", and outlines how they are now described as eyewear: a fashionable accessory.[39] Much like other fashion designs and accessories, eyewear is created by designers, has reputable labels, and comes in collections, by season and designer.[39] It is becoming more common for consumers purchase eyewear with clear, non-prescription lenses, illustrating that glasses are no longer a social stigma, but a fashionable accessory that \\"frames your face.\\"[39]\\r\\nSome organizations like Lions Clubs International,[40] Unite For Sight,[41] ReSpectacle,[42] and New Eyes for the Needy provide a way to donate glasses and sunglasses. Unite For Sight has redistributed more than 200,000 pairs.[43]\\r\\nMany people require glasses for the reasons listed above. There are many shapes, colors, and materials that can be used when designing frames and lenses that can be utilized in various combinations. Oftentimes, the selection of a frame is made based on how it will affect the appearance of the wearer. Some people with good natural eyesight like to wear eyeglasses as a style accessory.\\r\\nFor most of their history, eyeglasses were seen as unfashionable, and carried several potentially negative connotations: wearing glasses caused individuals to be stigmatized and stereotyped as pious clergymen (as those in religious vocation were the most likely to be literate and therefore the most likely to need reading glasses), elderly, or physically weak and passive.[44][45] The stigma began to fall away in the early 1900s when the popular Theodore Roosevelt was regularly photographed wearing eyeglasses, and in the 1910s when popular comedian Harold Lloyd began wearing a pair of horn-rimmed glasses as the \\"Glasses\\" character in his films.[44][45]\\r\\nSince, eyeglasses have become an acceptable fashion item and often act as a key component in individuals' personal image. Musicians Buddy Holly and John Lennon became synonymous with the styles of eye-glasses they wore to the point that thick, black horn-rimmed glasses are often called \\"Buddy Holly glasses\\" and perfectly round metal eyeglass frames called \\"John Lennon (or Harry Potter) Glasses.\\" British comedic actor Eric Sykes was known in the United Kingdom for wearing thick, square, horn-rimmed glasses, which were in fact a sophisticated hearing aid that alleviated his deafness by allowing him to \\"hear\\" vibrations.[46] Some celebrities have become so associated with their eyeglasses that they continued to wear them even after taking alternate measures against vision problems: United States Senator Barry Goldwater and comedian Drew Carey continued to wear non-prescription glasses after being fitted for contacts and getting laser eye surgery, respectively.\\r\\nOther celebrities have used glasses to differentiate themselves from the characters they play, such as Anne Kirkbride, who wore oversized, 1980s-style round horn-rimmed glasses as Deirdre Barlow in the soap opera Coronation Street, and Masaharu Morimoto, who wears glasses to separate his professional persona as a chef from his stage persona as Iron Chef Japanese. In 2012 some NBA players wear lensless glasses with thick plastic frames like horn-rimmed glasses during post-game interviews, geek chic that draws comparisons to Steve Urkel.[47][48]\\r\\nIn superhero fiction, eyeglasses have become a standard component of various heroes' disguises (as masks), allowing them to adopt a nondescript demeanor when they are not in their superhero persona: Superman is well known for wearing 1950s style horn-rimmed glasses as Clark Kent, while Wonder Woman wears either round, Harold Lloyd style glasses or 1970s style bug-eye glasses as Diana Prince. An example of the halo effect is seen in the stereotype that those who wear glasses are intelligent.\\r\\nIn the 20th century, eyeglasses came to be considered a component of fashion; as such, various different styles have come in and out of popularity. Most are still in regular use, albeit with varying degrees of frequency.\\r\\nThe market for spectacles has been characterized as having highly inelastic demand, and advertising restrictions in the USA have correlated with higher prices, suggesting that ads make the spectacles market more price-competitive.[49] It may also be monopolistically competitive.[citation needed]\\r\\nThere are claims that insufficiently free market competition inflates the prices of frames, which cost an average of $25-$50 US to make, to an average retail price of $300 in the United States. This claim is disputed by some in the industry.[50][51][52][53] See also Luxottica#Criticism.","input":"When was the first pair of glasses invented?"},{"output":"Kylie Jenner's daughter Stormi Webster","context":"This list contains the top 20 pictures with the most likes on the social photo-sharing platform Instagram. As of August 2018, the most liked picture is of Kylie Jenner's daughter Stormi Webster  with 18 million likes.[1] Cristiano Ronaldo has the most pictures in the top 20, with seven.\\r\\n\\r\\nThe following table lists the last seven pictures that were once the most-liked picture on Instagram.","input":"What is the most liked photo on insta?"},{"output":"fluorescent","context":"Fluorescence is the emission of light by a substance that has absorbed light or other electromagnetic radiation. It is a form of luminescence. In most cases, the emitted light has a longer wavelength, and therefore lower energy, than the absorbed radiation. The most striking example of fluorescence occurs when the absorbed radiation is in the ultraviolet region of the spectrum, and thus invisible to the human eye, while the emitted light is in the visible region, which gives the fluorescent substance a distinct color that can only be seen when exposed to UV light. Fluorescent materials cease to glow nearly immediately when the radiation source stops, unlike phosphorescence, where they continue to emit light for some time after.\\r\\nFluorescence has many practical applications, including mineralogy, gemology, medicine, chemical sensors (fluorescence spectroscopy), fluorescent labelling, dyes, biological detectors, cosmic-ray detection, and, most commonly, fluorescent lamps. Fluorescence also occurs frequently in nature in some minerals and in various biological states in many branches of the animal kingdom.\\r\\n\\r\\n\\r\\nAn early observation of fluorescence was described in 1560 by Bernardino de Sahag~n and in 1565 by Nicols Monardes in the infusion known as lignum nephriticum (Latin for \\"kidney wood\\"). It was derived from the wood of two tree species, Pterocarpus indicus and Eysenhardtia polystachya.[1][2][3][4] The chemical compound responsible for this fluorescence is matlaline, which is the oxidation product of one of the flavonoids found in this wood.[1]\\r\\nIn 1819, Edward D. Clarke[5] and in 1822 Ren Just Hay[6] described fluorescence in fluorites, Sir David Brewster described the phenomenon for chlorophyll in 1833[7] and Sir John Herschel did the same for quinine in 1845.[8][9]\\r\\nIn his 1852 paper on the \\"Refrangibility\\" (wavelength change) of light, George Gabriel Stokes described the ability of fluorspar and uranium glass to change invisible light beyond the violet end of the visible spectrum into blue light. He named this phenomenon fluorescence?: \\"I am almost inclined to coin a word, and call the appearance fluorescence, from fluor-spar [i.e., fluorite], as the analogous term opalescence is derived from the name of a mineral.\\"[10] The name was derived from the mineral fluorite (calcium difluoride), some examples of which contain traces of divalent europium, which serves as the fluorescent activator to emit blue light. In a key experiment he used a prism to isolate ultraviolet radiation from sunlight and observed blue light emitted by an ethanol solution of quinine exposed by it.[11]\\r\\nFluorescence occurs when an orbital electron of a molecule, atom, or nanostructure, relaxes to its ground state by emitting a photon from an excited singlet state:[12]\\r\\nExcitation: \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nS\\r\\n\\r\\n0\\r\\n\\r\\n\\r\\n+\\r\\nh\\r\\n\\r\\n\\r\\n\\r\\ne\\r\\nx\\r\\n\\r\\n\\r\\nL\\r\\n\\r\\nS\\r\\n\\r\\n1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle S_{0}+h\\\\nu _{ex}\\\\to S_{1}}\\r\\n\\r\\n\\r\\nFluorescence (emission): \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nS\\r\\n\\r\\n1\\r\\n\\r\\n\\r\\nL\\r\\n\\r\\nS\\r\\n\\r\\n0\\r\\n\\r\\n\\r\\n+\\r\\nh\\r\\n\\r\\n\\r\\n\\r\\ne\\r\\nm\\r\\n\\r\\n\\r\\n+\\r\\nh\\r\\ne\\r\\na\\r\\nt\\r\\n\\r\\n\\r\\n{\\\\displaystyle S_{1}\\\\to S_{0}+h\\\\nu _{em}+heat}\\r\\n\\r\\n\\r\\nHere \\r\\n\\r\\n\\r\\n\\r\\nh\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle h\\\\nu }\\r\\n\\r\\n is a generic term for photon energy with h = Planck's constant and \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\nu }\\r\\n\\r\\n = frequency of light. The specific frequencies of exciting and emitted light are dependent on the particular system.\\r\\nS0 is called the ground state of the fluorophore (fluorescent molecule), and S1 is its first (electronically) excited singlet state.\\r\\nA molecule in S1 can relax by various competing pathways. It can undergo non-radiative relaxation in which the excitation energy is dissipated as heat (vibrations) to the solvent. Excited organic molecules can also relax via conversion to a triplet state, which may subsequently relax via phosphorescence, or by a secondary non-radiative relaxation step.\\r\\nRelaxation from S1 can also occur through interaction with a second molecule through fluorescence quenching. Molecular oxygen (O2) is an extremely efficient quencher of fluorescence just because of its unusual triplet ground state.\\r\\nIn most cases, the emitted light has a longer wavelength, and therefore lower energy, than the absorbed radiation; this phenomenon is known as the Stokes shift. However, when the absorbed electromagnetic radiation is intense, it is possible for one electron to absorb two photons; this two-photon absorption can lead to emission of radiation having a shorter wavelength than the absorbed radiation. The emitted radiation may also be of the same wavelength as the absorbed radiation, termed \\"resonance fluorescence\\".[13]\\r\\nMolecules that are excited through light absorption or via a different process (e.g. as the product of a reaction) can transfer energy to a second 'sensitized' molecule, which is converted to its excited state and can then fluoresce.\\r\\nThe fluorescence quantum yield gives the efficiency of the fluorescence process. It is defined as the ratio of the number of photons emitted to the number of photons absorbed.[14][15]\\r\\nThe maximum possible fluorescence quantum yield is 1.0 (100%); each photon absorbed results in a photon emitted. Compounds with quantum yields of 0.10 are still considered quite fluorescent. Another way to define the quantum yield of fluorescence is by the rate of excited state decay:\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nk\\r\\n\\r\\n\\r\\nf\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle {k}_{f}}\\r\\n\\r\\n is the rate constant of spontaneous emission of radiation and\\r\\nis the sum of all rates of excited state decay. Other rates of excited state decay are caused by mechanisms other than photon emission and are, therefore, often called \\"non-radiative rates\\", which can include: dynamic collisional quenching, near-field dipole-dipole interaction (or resonance energy transfer), internal conversion, and intersystem crossing. Thus, if the rate of any pathway changes, both the excited state lifetime and the fluorescence quantum yield will be affected.\\r\\nFluorescence quantum yields are measured by comparison to a standard. The quinine salt quinine sulfate in a sulfuric acid solution is a common fluorescence standard.\\r\\nThe fluorescence lifetime refers to the average time the molecule stays in its excited state before emitting a photon. Fluorescence typically follows first-order kinetics:\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n[\\r\\n\\r\\nS\\r\\n\\r\\n1\\r\\n\\r\\n\\r\\n]\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\left[S_{1}\\\\right]}\\r\\n\\r\\n is the concentration of excited state molecules at time \\r\\n\\r\\n\\r\\n\\r\\nt\\r\\n\\r\\n\\r\\n{\\\\displaystyle t}\\r\\n\\r\\n, \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n[\\r\\n\\r\\nS\\r\\n\\r\\n1\\r\\n\\r\\n\\r\\n]\\r\\n\\r\\n\\r\\n0\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\left[S_{1}\\\\right]_{0}}\\r\\n\\r\\n is the initial concentration and \\r\\n\\r\\n\\r\\n\\r\\næ\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\Gamma }\\r\\n\\r\\n is the decay rate or the inverse of the fluorescence lifetime. This is an instance of exponential decay. Various radiative and non-radiative processes can de-populate the excited state. In such case the total decay rate is the sum over all rates:\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\n\\r\\næ\\r\\n\\r\\nt\\r\\no\\r\\nt\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\Gamma _{tot}}\\r\\n\\r\\n is the total decay rate, \\r\\n\\r\\n\\r\\n\\r\\n\\r\\næ\\r\\n\\r\\nr\\r\\na\\r\\nd\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\Gamma _{rad}}\\r\\n\\r\\n the radiative decay rate and \\r\\n\\r\\n\\r\\n\\r\\n\\r\\næ\\r\\n\\r\\nn\\r\\nr\\r\\na\\r\\nd\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\Gamma _{nrad}}\\r\\n\\r\\n the non-radiative decay rate. It is similar to a first-order chemical reaction in which the first-order rate constant is the sum of all of the rates (a parallel kinetic model). If the rate of spontaneous emission, or any of the other rates are fast, the lifetime is short. For commonly used fluorescent compounds, typical excited state decay times for photon emissions with energies from the UV to near infrared are within the range of 0.5 to 20 nanoseconds. The fluorescence lifetime is an important parameter for practical applications of fluorescence such as fluorescence resonance energy transfer and fluorescence-lifetime imaging microscopy.\\r\\nThe Jablonski diagram describes most of the relaxation mechanisms for excited state molecules. The diagram alongside shows how fluorescence occurs due to the relaxation of certain excited electrons of a molecule.[16]\\r\\nFluorophores are more likely to be excited by photons if the transition moment of the fluorophore is parallel to the electric vector of the photon.[17] The polarization of the emitted light will also depend on the transition moment. The transition moment is dependent on the physical orientation of the fluorophore molecule. For fluorophores in solution this means that the intensity and polarization of the emitted light is dependent on rotational diffusion. Therefore, anisotropy measurements can be used to investigate how freely a fluorescent molecule moves in a particular environment.\\r\\nFluorescence anisotropy can be defined quantitatively as\\r\\nwhere \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nI\\r\\n\\r\\n~\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle I_{\\\\parallel }}\\r\\n\\r\\n is the emitted intensity parallel to polarization of the excitation light and \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nI\\r\\n\\r\\n}\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle I_{\\\\perp }}\\r\\n\\r\\n is the emitted intensity perpendicular to the polarization of the excitation light.[18]\\r\\nStrongly fluorescent pigments often have an unusual appearance which is often described colloquially as a \\"neon color.\\" This phenomenon was termed \\"Farbenglut\\" by Hermann von Helmholtz and \\"fluorence\\" by Ralph M. Evans. It is generally thought to be related to the high brightness of the color relative to what it would be as a component of white. Fluorescence shifts energy in the incident illumination from shorter wavelengths to longer (such as blue to yellow) and thus can make the fluorescent color appear brighter (more saturated) than it could possibly be by reflection alone.[19]\\r\\nThere are several general rules that deal with fluorescence. Each of the following rules has exceptions but they are useful guidelines for understanding fluorescence (these rules do not necessarily apply to two-photon absorption).\\r\\nKasha's rule dictates that the quantum yield of luminescence is independent of the wavelength of exciting radiation.[20] This occurs because excited molecules usually decay to the lowest vibrational level of the excited state before fluorescence emission takes place. The KashaÿVavilov rule does not always apply and is violated severely in many simple molecules. A somewhat more reliable statement, although still with exceptions, would be that the fluorescence spectrum shows very little dependence on the wavelength of exciting radiation.[citation needed]\\r\\nFor many fluorophores the absorption spectrum is a mirror image of the emission spectrum.[21] This is known as the mirror image rule and is related to the FranckÿCondon principle which states that electronic transitions are vertical, that is energy changes without distance changing as can be represented with a vertical line in Jablonski diagram. This means the nucleus does not move and the vibration levels of the excited state resemble the vibration levels of the ground state.\\r\\nIn general, emitted fluorescence light has a longer wavelength and lower energy than the absorbed light.[22] This phenomenon, known as Stokes shift, is due to energy loss between the time a photon is absorbed and when a new one is emitted. The causes and magnitude of Stokes shift can be complex and are dependent on the fluorophore and its environment. However, there are some common causes. It is frequently due to non-radiative decay to the lowest vibrational energy level of the excited state. Another factor is that the emission of fluorescence frequently leaves a fluorophore in a higher vibrational level of the ground state.\\r\\nThere are many natural compounds that exhibit fluorescence, and they have a number of applications. Some deep-sea animals, such as the greeneye, use fluorescence.\\r\\nBiofluorescence is the absorption of electromagnetic wavelengths from the visible light spectrum by fluorescent proteins in a living organism, and the emission of light at a lower energy level. This causes the light that is emitted to be a different color than the light that is absorbed. Stimulating light excites an electron, raising energy to an unstable level. This instability is unfavorable, so the energized electron is returned to a stable state almost as immediately as it becomes unstable. This return to stability corresponds with the release of excess energy in the form of fluorescence light. This emission of light is only observable when the stimulant light is still providing light to the organism/object and is typically yellow, pink, orange, red, green, or purple. Biofluorescence is often confused with the following forms of biotic light, bioluminescence and biophosphorescence.[23]\\r\\nBioluminescence differs from biofluorescence in that it is the natural production of light by chemical reactions within an organism, whereas biofluorescence is the absorption and reemission of light from the environment.[23]\\r\\nBiophosphorescence is similar to biofluorescence in its requirement of light wavelengths as a provider of excitation energy. The difference here lies in the relative stability of the energized electron. Unlike with biofluorescence, here the electron retains stability, emitting light that continues to glow-in-the-dark even long after the stimulating light source has been removed.[23]\\r\\nPigment cells that exhibit fluorescence are called fluorescent chromatophores, and function somatically similar to regular chromatophores. These cells are dendritic, and contain pigments called fluorosomes. These pigments contain fluorescent proteins which are activated by K+ (potassium) ions, and it is their movement, aggregation, and dispersion within the fluorescent chromatophore that cause directed fluorescence patterning.[24][25] Fluorescent cells are innervated the same as other chromatphores, like melanophores, pigment cells that contain melanin. Short term fluorescent patterning and signaling is controlled by the nervous system.[24] Fluorescent chromatophores can be found in the skin (e.g. in fish) just below the epidermis, amongst other chromatophores.\\r\\nEpidermal fluorescent cells in fish also respond to hormonal stimuli by the ϫÿMSH and MCH hormones much the same as melanophores. This suggests that fluorescent cells may have color changes throughout the day that coincide with their circadian rhythm.[26] Fish may also be sensitive to cortisol induced stress responses to environmental stimuli, such as interaction with a predator or engaging in a mating ritual.[24]\\r\\nIt is suspected by some scientists that GFPs and GFP like proteins began as electron donors activated by light. These electrons were then used for reactions requiring light energy. Functions of fluorescent proteins, such as protection from the sun, conversion of light into different wavelengths, or for signaling are thought to have evolved secondarily.[27]\\r\\nThe incidence of fluorescence across the tree of life is widespread, and has been studied most extensively in a phylogenetic sense in fish. The phenomenon appears to have evolved multiple times in multiple taxa such as in the anguilliformes (eels), gobioidei (gobies and cardinalfishes), and tetradontiformes (triggerfishes), along with the other taxa discussed later in the article. Fluorescence is highly genotypically and phenotypically variable even within ecosystems, in regards to the wavelengths emitted, the patterns displayed, and the intensity of the fluorescence. Generally, the species relying upon camouflage exhibit the greatest diversity in fluorescence, likely because camouflage is one of the most common uses of fluorescence.[28]\\r\\nCurrently, relatively little is known about the functional significance of fluorescence and fluorescent proteins.[27] However, it is suspected that biofluorescence may serve important functions in signaling and communication, mating, lures, camouflage, UV protection and antioxidation, photoacclimation, dinoflagellate regulation, and in coral health.[citation needed]\\r\\nWater absorbs light of long wavelengths, so less light from these wavelengths reflects back to reach the eye. Therefore, warm colors from the visual light spectrum appear less vibrant at increasing depths. Water scatters light of shorter wavelengths, meaning cooler colors dominate the visual field in the photic zone. Light intensity decreases 10 fold with every 75 m of depth, so at depths of 75 m, light is 10% as intense as it is on the surface, and is only 1% as intense at 150 m as it is on the surface. Because the water filters out the wavelengths and intensity of water reaching certain depths, different proteins, because of the wavelengths and intensities of light they are capable of absorbing, are better suited to different depths. Theoretically, some fish eyes can detect light as deep as 1000 m. At these depths of the aphotic zone, the only sources of light are organisms themselves, giving off light through chemical reactions in a process called bioluminescence.\\r\\nFluorescence is simply defined as the absorption of electromagnetic radiation at one wavelength and its reemission at another, lower energy wavelength.[28] Thus any type of fluorescence depends on the presence of external sources of light. Biologically functional fluorescence is found in the photic zone, where there is not only enough light to cause biofluorescence, but enough light for other organisms to detect it. The visual field in the photic zone is naturally blue, so colors of fluorescence can be detected as bright reds, oranges, yellows, and greens. Green is the most commonly found color in the biofluorescent spectrum, yellow the second most, orange the third, and red is the rarest. Fluorescence can occur in organisms in the aphotic zone as a byproduct of that same organisms bioluminescence. Some biofluorescence in the aphotic zone is merely a byproduct of the organisms tissue biochemistry and does not have a functional purpose. However, some cases of functional and adaptive significance of biofluorescence in the aphotic zone of the deep ocean is an active area of research.[29]\\r\\nBony fishes living in shallow water, due to living in a colorful environment, generally have good color vision. Thus, in shallow-water fishes, red, orange, and green fluorescence most likely serves as a means of communication with conspecifics, especially given the great phenotypic variance of the phenomenon.[28]\\r\\nMany fish that exhibit biofluorescence, such as sharks, lizardfish, scorpionfish, wrasses, and flatfishes, also possess yellow intraocular filters.[30] Yellow intraocular filters in the lenses and cornea of certain fishes function as long-pass filters, thus enabling the species that possess them to visualize and potentially exploit fluorescence to enhance visual contrast and patterns that are unseen to other fishes and predators that lack this visual specialization.[28] Fishes that possess the necessary yellow intraocular filters for visualizing biofluorescence potentially exploit a light signal from members of it or a similar functional role. Biofluorescent patterning was especially prominent in cryptically patterned fishes possessing complex camouflage, and that many of these lineages also possess yellow long-pass intraocular filters that could enable visualization of such patterns.[30]\\r\\nAnother adaptive use of fluorescence is to generate red light from the ambient blue light of the photic zone to aid vision. Red light can only be seen across short distances due to attenuation of red light wavelengths by water.[31] Many fish species that fluoresce are small, group-living, or benthic/aphotic, and have conspicuous patterning. This patterning is caused by fluorescent tissue and is visible to other members of the species, however the patterning is invisible at other visual spectra. These intraspecific fluorescent patterns also coincide with intra-species signaling. The patterns present in ocular rings to indicate directionality of an individuals gaze, and along fins to indicate directionality of an individuals movement.[31] Current research suspects that this red fluorescence is used for private communication between members of the same species.[24][28][31] Due to the prominence of blue light at ocean depths, red light and light of longer wavelengths are muddled, and many predatory reef fish have little to no sensitivity for light at these wavelengths. Fish such as the fairy wrasse that have developed visual sensitivity to longer wavelengths are able to display red fluorescent signals that give a high contrast to the blue environment and are conspicuous to conspecifics in short ranges, yet are relatively invisible to other common fish that have reduced sensitivities to long wavelengths. Thus, fluorescence can be used as adaptive signaling and intra-species communication in reef fish.[31][32]\\r\\nAdditionally, it is suggested that fluorescent tissues that surround an organisms eyes are used to convert blue light from the photic zone or green bioluminescence in the aphotic zone into red light to aid vision.[31]\\r\\nFluorescence serves a wide variety of functions in coral. Fluorescent proteins in corals may contribute to photosynthesis by converting otherwise unusable wavelengths of light into ones for which the corals symbiotic algae are able to conduct photosynthesis.[33] Also, the proteins may fluctuate in number as more or less light becomes available as a means of photoacclimation.[34] Similarly, these fluorescent proteins may possess antioxidant capacities to eliminate oxygen radicals produced by photosynthesis.[35] Finally, through modulating photosynthesis, the fluorescent proteins may also serve as a means of regulating the activity of the corals photosynthetic algal symbionts.[36]\\r\\nAlloteuthis subulata and Loligo vulgaris, two types of nearly transparent squid, have fluorescent spots above their eyes. These spots reflect incident light, which may serve as a means of camouflage, but also for signaling to other squids for schooling purposes.[37]\\r\\nAnother, well-studied example of biofluorescence in the ocean is the hydrozoan Aequorea victoria. This jellyfish lives in the photic zone off the west coast of North America and was identified as a carrier of green fluorescent protein (GFP) by Osamu Shimomura. The gene for these green fluorescent proteins has been isolated and is scientifically significant because it is widely used in genetic studies to indicate the expression of other genes.[38]\\r\\nSeveral species of mantis shrimp, which are stomatopod crustaceans, including Lysiosquillina glabriuscula, have yellow fluorescent markings along their antennal scales and carapace (shell) that males present during threat displays to predators and other males. The display involves raising the head and thorax, spreading the striking appendages and other maxillipeds, and extending the prominent, oval antennal scales laterally, which makes the animal appear larger and accentuates its yellow fluorescent markings. Furthermore, as depth increases, mantis shrimp fluorescence accounts for a greater part of the visible light available. During mating rituals, mantis shrimp actively fluoresce, and the wavelength of this fluorescence matches the wavelengths detected by their eye pigments.[39]\\r\\nSiphonophorae is an order of marine animals from the phylum Hydrozoa that consist of a specialized medusoid and polyp zooid. Some siphonophores, including the genus Erenna that live in the aphotic zone between depths of 1600 m and 2300 m, exhibit yellow to red fluorescence in the photophores of their tentacle-like tentilla. This fluorescence occurs as a by-product of bioluminescence from these same photophores. The siphonophores exhibit the fluorescence in a flicking pattern that is used as a lure to attract prey.[40]\\r\\nThe predatory deep-sea dragonfish Malacosteus niger, the closely related Aristostomias genus and the species Pachystomias microdon are capable of harnessing the blue light emitted from their own bioluminescence to generate red biofluorescence from suborbital photophores. This red fluorescence is invisible to other animals, which allows these dragonfish extra light at dark ocean depths without attracting or signaling predators.[41]\\r\\nThe Polka-dot tree frog, widely found in the Amazon was discovered to be the first fluorescent amphibian in 2017. The frog is pale green with dots in white, yellow or light red. The fluorescence of the frog was discovered unintentionally in Buenos Aires, Argentina. The fluorescence was traced to a new compound found in the lymph and skin glads.[42] The main fluorescent compound is Hyloin-L1 and it gives a blue-green glow when exposed to violet or ultra violet light. Scientists behind the discovery say that the fluorescence can be used for communication. They also think that about 100 or 200 species of frogs are likely to be fluorescent.[43]\\r\\nSwallowtail (Papilio) butterflies have complex systems for emitting fluorescent light. Their wings contain pigment-infused crystals that provide directed fluorescent light. These crystals function to produce fluorescent light best when they absorb radiance from sky-blue light (wavelength about 420?nm). The wavelengths of light that the butterflies see the best correspond to the absorbance of the crystals in the butterfly's wings. This likely functions to enhance the capacity for signaling.[44]\\r\\nParrots have fluorescent plumage that may be used in mate signaling. A study using mate-choice experiments on budgerigars (Melopsittacus undulates) found compelling support for fluorescent sexual signaling, with both males and females significantly preferring birds with the fluorescent experimental stimulus. This study suggests that the fluorescent plumage of parrots is not simply a by-product of pigmentation, but instead an adapted sexual signal. Considering the intricacies of the pathways that produce fluorescent pigments, there may be significant costs involved. Therefore, individuals exhibiting strong fluorescence may be honest indicators of high individual quality, since they can deal with the associated costs.[45]\\r\\nSpiders fluoresce under UV light and possess a huge diversity of fluorophores. Remarkably, spiders are the only known group in which fluorescence is taxonomically widespread, variably expressed, evolutionarily labile, and probably under selection and potentially of ecological importance for intraspecific and interspecific signaling. A study by Andrews et al. (2007) reveals that fluorescence has evolved multiple times across spider taxa, with novel fluorophores evolving during spider diversification. In some spiders, ultraviolet cues are important for predator-prey interactions, intraspecific communication, and camouflaging with matching fluorescent flowers. Differing ecological contexts could favor inhibition or enhancement of fluorescence expression, depending upon whether fluorescence helps spiders be cryptic or makes them more conspicuous to predators. Therefore, natural selection could be acting on expression of fluorescence across spider species.[46]\\r\\nScorpions also fluoresce.[47]\\r\\nThe Mirabilis jalapa flower contains violet, fluorescent betacyanins and yellow, fluorescent betaxanthins. Under white light, parts of the flower containing only betaxanthins appear yellow, but in areas where both betaxanthins and betacyanins are present, the visible fluorescence of the flower is faded due to internal light-filtering mechanisms. Fluorescence was previously suggested to play a role in pollinator attraction, however, it was later found that the visual signal by fluorescence is negligible compared to the visual signal of light reflected by the flower.[48]\\r\\nChlorophyll fluoresces a weak red under ultraviolet light.[49]\\r\\nGemstones, minerals, may have a distinctive fluorescence or may fluoresce differently under short-wave ultraviolet, long-wave ultraviolet, visible light, or X-rays.\\r\\nMany types of calcite and amber will fluoresce under shortwave UV, longwave UV and visible light. Rubies, emeralds, and diamonds exhibit red fluorescence under long-wave UV, blue and sometimes green light; diamonds also emit light under X-ray radiation.\\r\\nFluorescence in minerals is caused by a wide range of activators. In some cases, the concentration of the activator must be restricted to below a certain level, to prevent quenching of the fluorescent emission. Furthermore, the mineral must be free of impurities such as iron or copper, to prevent quenching of possible fluorescence. Divalent manganese, in concentrations of up to several percent, is responsible for the red or orange fluorescence of calcite, the green fluorescence of willemite, the yellow fluorescence of esperite, and the orange fluorescence of wollastonite and clinohedrite. Hexavalent uranium, in the form of the uranyl cation, fluoresces at all concentrations in a yellow green, and is the cause of fluorescence of minerals such as autunite or andersonite, and, at low concentration, is the cause of the fluorescence of such materials as some samples of hyalite opal. Trivalent chromium at low concentration is the source of the red fluorescence of ruby. Divalent europium is the source of the blue fluorescence, when seen in the mineral fluorite. Trivalent lanthanides such as terbium and dysprosium are the principal activators of the creamy yellow fluorescence exhibited by the yttrofluorite variety of the mineral fluorite, and contribute to the orange fluorescence of zircon. Powellite (calcium molybdate) and scheelite (calcium tungstate) fluoresce intrinsically in yellow and blue, respectively. When present together in solid solution, energy is transferred from the higher-energy tungsten to the lower-energy molybdenum, such that fairly low levels of molybdenum are sufficient to cause a yellow emission for scheelite, instead of blue. Low-iron sphalerite (zinc sulfide), fluoresces and phosphoresces in a range of colors, influenced by the presence of various trace impurities.\\r\\nCrude oil (petroleum) fluoresces in a range of colors, from dull-brown for heavy oils and tars through to bright-yellowish and bluish-white for very light oils and condensates. This phenomenon is used in oil exploration drilling to identify very small amounts of oil in drill cuttings and core samples.\\r\\nOrganic solutions such anthracene or stilbene, dissolved in benzene or toluene, fluoresce with ultraviolet or gamma ray irradiation. The decay times of this fluorescence are on the order of nanoseconds, since the duration of the light depends on the lifetime of the excited states of the fluorescent material, in this case anthracene or stilbene.[citation needed]\\r\\nScintillation is defined a flash of light produced in a transparent material by the passage of a particle (an electron, an alpha particle, an ion, or a high-energy photon). Stilbene and derivatives are used in scintillation counters to detect such particles. Stilbene is also one of the gain mediums used in dye lasers.\\r\\nFluorescence is observed in the atmosphere when the air is under energetic electron bombardment. In cases such as the natural aurora, high-altitude nuclear explosions, and rocket-borne electron gun experiments, the molecules and ions formed have a fluorescent response to light.[50]\\r\\nThe common fluorescent lamp relies on fluorescence. Inside the glass tube is a partial vacuum and a small amount of mercury. An electric discharge in the tube causes the mercury atoms to emit mostly ultraviolet light. The tube is lined with a coating of a fluorescent material, called the phosphor, which absorbs the ultraviolet and re-emits visible light. Fluorescent lighting is more energy-efficient than incandescent lighting elements. However, the uneven spectrum of traditional fluorescent lamps may cause certain colors to appear different than when illuminated by incandescent light or daylight. The mercury vapor emission spectrum is dominated by a short-wave UV line at 254?nm (which provides most of the energy to the phosphors), accompanied by visible light emission at 436?nm (blue), 546?nm (green) and 579?nm (yellow-orange). These three lines can be observed superimposed on the white continuum using a hand spectroscope, for light emitted by the usual white fluorescent tubes. These same visible lines, accompanied by the emission lines of trivalent europium and trivalent terbium, and further accompanied by the emission continuum of divalent europium in the blue region, comprise the more discontinuous light emission of the modern trichromatic phosphor systems used in many compact fluorescent lamp and traditional lamps where better color rendition is a goal.[51]\\r\\nFluorescent lights were first available to the public at the 1939 New York World's Fair. Improvements since then have largely been better phosphors, longer life, and more consistent internal discharge, and easier-to-use shapes (such as compact fluorescent lamps). Some high-intensity discharge (HID) lamps couple their even-greater electrical efficiency with phosphor enhancement for better color rendition.[citation needed]\\r\\nWhite light-emitting diodes (LEDs) became available in the mid-1990s as LED lamps, in which blue light emitted from the semiconductor strikes phosphors deposited on the tiny chip. The combination of the blue light that continues through the phosphor and the green to red fluorescence from the phosphors produces a net emission of white light.[citation needed]\\r\\nGlow sticks sometimes utilize fluorescent materials to absorb light from the chemiluminescent reaction and emit light of a different color.[51]\\r\\nMany analytical procedures involve the use of a fluorometer, usually with a single exciting wavelength and single detection wavelength. Because of the sensitivity that the method affords, fluorescent molecule concentrations as low as 1 part per trillion can be measured.[52]\\r\\nFluorescence in several wavelengths can be detected by an array detector, to detect compounds from HPLC flow. Also, TLC plates can be visualized if the compounds or a coloring reagent is fluorescent. Fluorescence is most effective when there is a larger ratio of atoms at lower energy levels in a Boltzmann distribution. There is, then, a higher probability of excitement and release of photons by lower-energy atoms, making analysis more efficient.\\r\\nUsually the setup of a fluorescence assay involves a light source, which may emit many different wavelengths of light. In general, a single wavelength is required for proper analysis, so, in order to selectively filter the light, it is passed through an excitation monochromator, and then that chosen wavelength is passed through the sample cell. After absorption and re-emission of the energy, many wavelengths may emerge due to Stokes shift and various electron transitions. To separate and analyze them, the fluorescent radiation is passed through an emission monochromator, and observed selectively by a detector.[53]\\r\\nFluorescence in the life sciences is used generally as a non-destructive way of tracking or analysis of biological molecules by means of the fluorescent emission at a specific frequency where there is no background from the excitation light, as relatively few cellular components are naturally fluorescent (called intrinsic or autofluorescence). In fact, a protein or other component can be \\"labelled\\" with an extrinsic fluorophore, a fluorescent dye that can be a small molecule, protein, or quantum dot, finding a large use in many biological applications.[54]\\r\\nThe quantification of a dye is done with a spectrofluorometer and finds additional applications in:\\r\\nFingerprints can be visualized with fluorescent compounds such as ninhydrin or DFO (1,8-Diazafluoren-9-one). Blood and other substances are sometimes detected by fluorescent reagents, like fluorescein. Fibers, and other materials that may be encountered in forensics or with a relationship to various collectibles, are sometimes fluorescent.\\r\\nFluorescent penetrant inspection is used to find cracks and other defects on the surface of a part. Dye tracing, using fluorescent dyes, is used to find leaks in liquid and gas plumbing systems.\\r\\nFluorescent colors are frequently used in signage, particularly road signs. Fluorescent colors are generally recognizable at longer ranges than their non-fluorescent counterparts, with fluorescent orange being particularly noticeable.[60] This property has led to its frequent use in safety signs and labels.\\r\\nFluorescent compounds are often used to enhance the appearance of fabric and paper, causing a \\"whitening\\" effect. A white surface treated with an optical brightener can emit more visible light than that which shines on it, making it appear brighter. The blue light emitted by the brightener compensates for the diminishing blue of the treated material and changes the hue away from yellow or brown and toward white. Optical brighteners are used in laundry detergents, high brightness paper, cosmetics, high-visibility clothing and more.","input":"What is something that gives out light called?"},{"output":"parliamentary representative democracy","context":"Politics of Bosnia and Herzegovina takes place in a framework of a parliamentary representative democracy, whereby executive power is exercised by the Council of Ministers of Bosnia and Herzegovina. Legislative power is vested in both the Council of Ministers and the Parliamentary Assembly of Bosnia and Herzegovina. Members of the Parliamentary Assembly are chosen according to a proportional representation system.\\r\\nThe judiciary is independent of the executive and the legislature. The system of government established by the Dayton Accord is an example of consociationalism, as representation is by elites who represent the country's three major ethnic groups termed constituent peoples, with each having a guaranteed share of power.\\r\\nBosnia and Herzegovina is divided into two Entities ÿ the Federation of Bosnia and Herzegovina and the Republika Srpska, which are politically autonomous to an extent, as well as the district of Br?ko, which is jointly administered by both. The Entities have their own constitutions. The?Economist Intelligence Unit?has rated Bosnia and Herzegovina as \\"hybrid regime\\" in 2016.[1]\\r\\n\\r\\n\\r\\nDue to the Dayton Agreement, signed on 14 December 1995, Bosnia and Herzegovina forms an undeclared protectorate with elements of hegemony by neighboring Croatia and Serbia as co-signatories to the Agreement, where highest power is given to the High Representative for Bosnia and Herzegovina. The intention of the Agreement was to retain Bosnia's exterior border, while creating a joint multi-ethnic and democratic government based on proportional representation similar to the former socialist rgime, and charged with conducting foreign, economic, and fiscal policy.\\r\\nThe Dayton Agreement established the Office of the High Representative (OHR) to oversee the implementation of the civilian aspects of the agreement. About 250 international and 450 local staff members are employed by the OHR.\\r\\nThe highest political authority in the country is the High Representative in Bosnia and Herzegovina, the chief executive officer for the international civilian presence in the country. Since 1995, the High Representative has been able to bypass the elected Parliamentary Assembly or to remove officials from office without due process. The methods selected by the High Representative are often seen as dictatorship. Even the symbols of Bosnian statehood (flag, coat of arms) have been chosen by the High Representative rather than by the Bosnian people. The source of the authority of the High Representative is in international law while his role is essentially contractual. His mandate derives from the Dayton Agreement, as confirmed by the Peace Implementation Council, a body with a Steering Board composed of representatives of Canada, France, Germany, Italy, Japan, Russia, the United Kingdom, the United States, the presidency of the European Union, the European Commission, and the Organisation of Islamic Cooperation.\\r\\nThe Chair of the Presidency of Bosnia and Herzegovina rotates amongst three members (a Bosniak, a Serb, and a Croat) every 8 months within their 4-year term. The three members of the Presidency are elected directly by the people, with Federation voters electing both the Bosniak and the Croat member, and Republika Srpska voters electing the Serb member. The Presidency serves as a collective head of state. The Presidency is mainly responsible for the foreign policy and proposing the budget.[citation needed][2]\\r\\nThe Prime Minister, formally titled Chairman of the Council of Ministers of Bosnia and Herzegovina, is nominated by the Presidency and approved by the House of Representatives. He appoints the Minister of Foreign Affairs, the Minister of Foreign Trade and other ministers as may be appropriate (no more than two thirds of the ministers may be appointed from the territory of the Federation of Bosnia and Herzegovina), who assume the office upon the approval by the House of Representatives; also, the Chair appoints deputy ministers (who may not be from the same constituent people as their ministers), who assume the office upon the approval by the House of Representatives.\\r\\nThe Council is responsible for carrying out policies and decisions in the fields of diplomacy, economy, inter-entity relations and other matters as agreed by the entities.\\r\\nThe two Entities have Governments that deal with internal matters not dealt with by the Council of Ministers.\\r\\nPast international high representatives: Carl Bildt, Carlos Westendorp, Wolfgang Petritsch, Paddy Ashdown, Christian Schwarz-Schilling, Miroslav Laj?k.\\r\\nMembers of the Presidency who stepped down under pressure from the Office of the High Representative: Mirko ?arovi?, Ante Jelavi?, Dragan ?ovi?. Alija Izetbegovi? also withdrew from the Presidency.\\r\\nIn February 2000, the Supreme Court ruled that the structure of the Council of Ministers was unconstitutional; a new structure is being negotiated.\\r\\nFederation president and vice-president in 1999: Ejup Gani? and Ivo Andri?-Lu?anski.\\r\\nPast RS presidents: Radovan Karad?i?, Biljana Plav?i?, Nikola Popla?en, Mirko ?arovi?, Dragan ?avi?, Milan Jeli?.\\r\\nRS president Nikola Popla?en was removed by the OHR on 5 March 1999.\\r\\nThe Parliamentary Assembly or Parliamentarna skup?tina is the main legislative body in Bosnia and Herzegovina. It consists of two chambers:\\r\\nThe Parliamentary Assembly is responsible for:\\r\\nBosnia and Herzegovina did not have a permanent election law until 2001, during which time a draft law specified four-year terms for the state and first-order administrative division entity legislatures. The final election law was passed and publicized on 9 September 2001.\\r\\nThe House of Peoples includes 15 delegates who serve two-year terms. Two-thirds of delegates come from the Federation (5 Croats and 5 Bosniaks) and one-third from the Republika Srpska (5 Serbs). Nine constitutes a quorum in the House of Peoples, provided that at least three delegates from each group are present. Federation representatives are selected by the House of Peoples of the Federation, which has 58 seats (17 Bosniak, 17 Croat, 17 Serb, 7 others), and whose members are delegated by cantonal assemblies to serve four-year terms. Republika Srpska representatives are selected by the 28-member Republika Srpska Council of Peoples, which was established in the People's Assembly of Republika Srpska; each constituent people has eight delegates, while four delegates are representatives of \\"others\\".\\r\\nThe House of Representatives of Bosnia and Herzegovina comprises 42 members elected under a system of proportional representation (PR) for a four-year term. Two thirds of the members are elected from the Federation (14 Croats; 14 Bosniaks) and one third from the Republika Srpska (14 Serbs).\\r\\nFor the 2010 elections, Voters in the Federation of Bosnia and Herzegovina elected twenty-one members in five multi-member constituencies by PR, while the remaining seven seats were allocated by compensatory PR. Voters in the Republika Srpska elected nine members in three multi-member constituencies by PR, while the five other seats were allocated by compensatory PR.[3]\\r\\nNational House of Representatives:\\r\\nHouse of Peoples:\\r\\nFederation House of Representatives:\\r\\nFederation House of Peoples:\\r\\nRepublika Srpska National Assembly:\\r\\nThe Constitutional Court of Bosnia and Herzegovina is supposedly the supreme, final arbiter of legal matters, however its decisions are largely ignored.[4] The court is composed of nine members: four selected by the House of Representatives of the Federation, two by the People's Assembly of Republika Srpska, and three are foreign citizens appointed by the President of the European Court of Human Rights after courtesy-consultation with the Presidency.\\r\\nThe initial term of appointee is 5 years, unless they resign or are removed by consensus of other judges. Appointed judges are not eligible for reappointment. Judges subsequently appointed will serve until the age of 70, unless they resign sooner or are removed. Appointments made 5 years into the initial appointments may be governed by a different regulation for selection, to be determined by the Parliamentary Assembly.\\r\\nProceedings of the Court are public, and decisions are published. Court rules are adopted by a majority in the Court. Court decisions are final and supposedly binding though this is not always the case, as noted.[4]\\r\\nThe Constitutional Court has jurisdiction over deciding in constitutional disputes that arise between the Entities or amongst Bosnia and Herzegovina and an Entity or Entities. Such disputes may be referred only by a member of the Presidency, the Chair of the Council of Ministers, the Chair or Deputy Chair of either of the chambers of the Parliamentary Assembly, or by one-fourth of the legislature of either Entity.\\r\\nThe Court also has appellate jurisdiction within the territory of Bosnia and Herzegovina.\\r\\nThe State Court of Bosnia and Herzegovina consists of three divisions ÿ Administrative, Appellate and Criminal ÿ having jurisdiction over cases related to the state-level law and executive, as well as appellate jurisdiction over cases initiated in the entities.\\r\\nA War Crimes Chamber was introduced in January 2005, and has adopted two cases transferred from the ICTY, as well as dozens of war crimes cases originally initiated in cantonal courts.\\r\\nThe State Court also deals with organized crime, and economic crime including corruption cases. For example, the former and 2014 member-elect of the Presidency Dragan ?ovi? is currently on trial for alleged involvement in organized crime.\\r\\nThe Human Rights Chamber for Bosnia and Herzegovina (Dom za ljudska prava za Bosnu i Hercegovinu) existed between March 1996 and 31 December 2003. It was a judicial body established under the Annex 6 to the General Framework Agreement for Peace in Bosnia and Herzegovina (Dayton Peace Agreement).\\r\\nThe two Entities have Supreme Courts. Each entity also has a number of lower courts. There are 10 cantonal courts in the Federation, along with a number of municipal courts. The Republika Srpska has five municipal courts.","input":"What type of government does bosnia and herzegovina have?"},{"output":"Before the 1988 season","context":"National Football League (1920ÿpresent)\\r\\n\\r\\nLeague championships (2)\\r\\n\\r\\nConference championships (1)\\r\\n\\r\\nDivision championships (7)\\r\\n\\r\\nThe Arizona Cardinals are a professional American football franchise based in the Phoenix metropolitan area. The Cardinals compete in the National Football League (NFL) as a member of the league's National Football Conference (NFC) West division. The Cardinals were founded as the Morgan Athletic Club in 1898, and are the oldest continuously run professional football team in the United States.[4] The Cardinals play their home games at State Farm Stadium, which opened in 2006 and is located in the northwestern suburb of Glendale.\\r\\n\\r\\nThe team was established in Chicago in 1898 as an amateur football team and joined the NFL as a charter member on September 17, 1920.[3] Along with the Chicago Bears, the club is one of two NFL charter member franchises still in  operation since the league's founding. (The Green Bay Packers were an independent team until they joined the NFL a year after its creation in 1921.) The club then moved to St. Louis in 1960 and played in that city through 1987 (sometimes referred to as the \\"Football Cardinals\\" or the \\"Big Red\\" to avoid confusion with the St. Louis Cardinals of Major League Baseball). Before the 1988 season, the team moved west to Tempe, Arizona, a college suburb east of Phoenix, and played their home games for the next 18 seasons at Sun Devil Stadium on the campus of Arizona State University. In 2006, the club moved to their current home field in Glendale, although the team's executive offices and training facility remain in Tempe.\\r\\n\\r\\nThe franchise has won two NFL championships, both while it was based in Chicago. The first occurred in 1925, but is the subject of controversy, with supporters of the Pottsville Maroons believing that Pottsville should have won the title. Their second title, and the first to be won in a championship game, came in 1947, nearly two decades before the first Super Bowl. They returned to the title game to defend in 1948, but lost the rematch 7ÿ0 in a snowstorm in Philadelphia.\\r\\n\\r\\nSince winning the championship in 1947, the team suffered many losing seasons, and currently holds the longest active championship drought of North American sports at 70 consecutive seasons after Major League Baseball's Chicago Cubs ended their 108 year drought in 2016. In 2012 the Cardinals became the first NFL franchise to lose 700 games since its inception. The franchise's all-time win-loss record (including regular season and playoff games) at the conclusion of the 2017 season is 557ÿ749ÿ40 (550ÿ740ÿ40 in the regular season, 7ÿ9 in the playoffs).[5] They have been to the playoffs ten times and have won seven playoff games, three of which were victories during their run in the 2008ÿ09 NFL playoffs. During that season, they won their only NFC Championship Game since the 1970 AFLÿNFL merger, and reached Super Bowl XLIII (losing 27ÿ23 to the Pittsburgh Steelers). The team has also won five division titles (1974, 1975, 2008, 2009 and 2015) since their 1947ÿ48 NFL championship game appearances. The Cardinals are the only NFL team who have never lost a playoff game at home, with a 5ÿ0 record: the 1947 NFL Championship Game, two postseason victories during the aforementioned 2008ÿ09 NFL playoffs, one during the 2009ÿ10 playoffs, and one during the 2015ÿ16 playoffs.\\r\\n\\r\\nFrom 1988 through 2012 (except 2005, when they trained in Prescott), the Cardinals conducted their annual summer training camp at Northern Arizona University in Flagstaff. The Cardinals moved their training camp to University of Phoenix Stadium in 2013. The stadium was the site of the 2015 Pro Bowl, unlike in past years, where it was held at Aloha Stadium in Honolulu, Hawaii. The stadium also played host to Super Bowls XLII and XLIX, and will host Super Bowl LVII in 2023.\\r\\n\\r\\nThe franchise's inception dates back to 1898, when a neighborhood group gathered to play in the Chicago South Side, calling themselves Morgan Athletic Club. Chicago painting and building contractor Chris O'Brien acquired the team, which he relocated to Normal Field on Racine Avenue. The team was known as Racine Normals until 1901, when O'Brien bought used jerseys from the University of Chicago. He described the faded maroon clothing as \\"Cardinal red\\" and the team became the Racine Street Cardinals. The team eventually became in 1920 a charter member of the American Professional Football Association (APFA), which two years later was rechristened to National Football League (NFL). The team entered the league as the Racine Cardinals, however the name was changed in 1922 to Chicago Cardinals to avoid confusion with the Horlick-Racine Legion, who entered the league the same year.[6] Except for 1925, when they were awarded the championship after the Pottsville Maroons were suspended, the Cardinals experienced only minimal success on the playing field during their first 26 seasons in the league. During the post-World War II years, the team reached two straight NFL finals against the Philadelphia Eagles, winning in 1947 ÿ eight months after Charles Bidwill's death ÿ and losing the following year. After years of bad seasons and losing fans to the cross-town rivals Chicago Bears, by the late 1950s the Cardinals were almost bankrupt, and owner Violet Bidwill Wolfner became interested in a relocation.\\r\\n\\r\\nDue to the formation of the rival American Football League, the NFL allowed Bidwill to relocate the team to St. Louis, Missouri, where they became the St. Louis Cardinals (locally, they were called the \\"Big Red\\" or the \\"Football Cardinals\\" in order to avoid confusion with the baseball team).[7] During the Cardinals' 28-year stay in St. Louis, they advanced to the playoffs just three times (1974, 1975 & 1982), never hosting or winning in any appearance. The overall mediocrity of the Cardinals, combined with a then-21-year-old stadium, caused game attendance to dwindle, and owner Bill Bidwill decided to move the team to Arizona.\\r\\n\\r\\nNot long after the 1987 NFL season, Bidwill agreed to move to Arizona on a handshake deal with state and local officials, and the team became the Phoenix Cardinals.[8] The franchise changed its geographic name from Phoenix to Arizona on March 17, 1994.[9] (The franchise has never played in the city of Phoenix proper.) The 1998 NFL season saw the Cardinals break two long droughts, qualifying for the playoffs for the first time in 16 years. The team got their first postseason win since 1947 by winning the Wild Card Playoffs. In 2008, the Cardinals won the NFC Championship Game to advance to the Super Bowl for the first time in franchise history. They lost Super Bowl XLIII 27ÿ23 to the Pittsburgh Steelers in the final seconds.[10]\\r\\n\\r\\nAfter their historic 2008 season, the Cardinals posted a 10ÿ6 record in 2009, their first season with 10 wins in Arizona. The Cardinals clinched their second consecutive NFC West title, and were defeated by eventual Super Bowl champion New Orleans Saints 45ÿ14 in the divisional playoffs. The next time they would make the playoffs would be in 2014, when they ended up as a wild card. They set the best regular-season record in the team's history in Arizona at 11ÿ5, but were defeated by the 7ÿ8ÿ1 NFC South champions Carolina Panthers.\\r\\n\\r\\nThe next year, the Cardinals set a franchise-best 13ÿ3 record, and clinched their first-ever first-round playoff bye as the NFC's second seed. They defeated the Green Bay Packers 26ÿ20 in overtime, giving quarterback Carson Palmer his first playoff victory. The Cardinals then advanced to their second NFC Championship Game in their history, but were blown out by the top-seeded 15ÿ1 Panthers 49ÿ15, committing seven turnovers.[11]\\r\\n\\r\\nStarting in 1947, the team had a logo of a cardinal bird perched on the stitches of a football.\\r\\n\\r\\nThe Cardinals moved to Arizona in 1988, and the flag of Arizona was added to the sleeves the following year. In 1990, the team began wearing red pants with their white jerseys, as new coach Joe Bugel wanted to emulate his former employer, the Washington Redskins, who at the time wore burgundy pants with their white jerseys (the Redskins later returned to their 1970s gold pants with all their jerseys).\\r\\n\\r\\nIn 1994, the Cardinals participated in the NFL's 75th anniversary throwback uniform program. The jerseys were similar to those of the 1920s Chicago Cardinals, with an interlocking \\"CC\\" logo and three stripes on each sleeve. The uniform numbers were relocated to the right chest. The pants were khaki to simulate the color and material used in that era. The Cardinals also stripped the logos from their helmets for two games: at Cleveland and home vs. Pittsburgh.\\r\\n\\r\\nThe Cardinal head on the helmet was repeated on the white jersey from 1982 to 1995. In 1996, the state flag of Arizona was moved higher on the sleeve after the Cardinal head was eliminated, and black was removed as an accent color, instead replaced with a blue to match the predominant color of the state flag. In 2002, the Cardinals began to wear all-red and all-white combinations, and continued to do so through 2004, prior to the team's makeover.\\r\\n\\r\\nIn 2005, the team unveiled its first major changes in a century. The cardinal-head logo was updated to look sleeker and meaner than its predecessor. Numerous fans had derisively called the previous version a \\"parakeet\\".[12] Black again became an accent color after an eight-year absence, while trim lines were added to the outside shoulders, sleeves, and sides of the jerseys and pants. Both the red and white jerseys have the option of red or white pants.[13]\\r\\n\\r\\nHoping to break a six-game losing streak, the Cardinals wore the red pants for the first time on October 29, 2006, in a game at Lambeau Field against the Green Bay Packers. The Packers won 31ÿ14, and the Cards headed into their bye week with a 1ÿ7 mark. Following the bye week, the Cardinals came out in an all-red combination at home against the Dallas Cowboys and lost, 27ÿ10. Arizona did not wear the red pants for the remainder of the season and won four of their last seven games. However, the following season, in 2007, the Cardinals again wore their red pants for their final 3 home games. They wore red pants with white jerseys in games on the road at the Cincinnati Bengals and Seattle Seahawks. They paired red pants with red jerseys, the all-red combination, for home games against the Detroit Lions, San Francisco 49ers, Cleveland Browns, and St. Louis Rams. The red pants were not worn at all in 2008, but they were used in home games vs. Seattle, Minnesota, and St. Louis in 2009. The red pants were paired with the white road jersey for the first time in three years during a 2010 game at Carolina, but the white jersey/red pants combination has not been used since.\\r\\n\\r\\nThe Cardinals' first home game in Arizona, in 1988, saw them play in red jerseys. Thereafter, for the next 18 years in Arizona, the Cardinals, like a few other NFL teams in warm climates, wore their white jerseys at home during the first half of the seasonforcing opponents to suffer in their darker jerseys during Arizona autumns that frequently see temperatures over 100?F (38?C). However, this tradition did not continue when the Cardinals moved from Sun Devil Stadium to University of Phoenix Stadium in 2006, as early-season games (and some home games late in the season) were played with the roof closed. With the temperature inside at a comfortable 70?F (21?C), the team opted to wear red jerseys at home full-time. The Cardinals wore white jerseys at home for the first time in University of Phoenix Stadium on August 29, 2008, in a preseason game against the Denver Broncos.\\r\\n\\r\\nThe Cardinals wore white at home for the first time in a regular season game at University of Phoenix Stadium against the Houston Texans on October 11, 2009. In October 2009, the NFL recognized Breast Cancer Awareness Month, and players wore pink-accented items, including gloves, wristbands, and shoes. The team thought the pink accents looked better with white uniforms than with red.[14]\\r\\n\\r\\nFrom 1970 through 1983, and again in many seasons between 1989 and 2002, the Cardinals would wear white when hosting the Dallas Cowboys in order to force the Cowboys to don their \\"jinxed\\"[clarification needed] blue jerseys. They have not done this since moving into University of Phoenix Stadium, however.[citation needed]\\r\\n\\r\\nThe 2010 season saw the Cardinals debut a new, alternate black jersey.[15] Prior to its introduction, the Cardinals were the only NFL team without an alternate jersey or throwback kit, save for the NFL's 75th anniversary program in 1994.[16]\\r\\n\\r\\nPoints Scored: 489 (2015)\\r\\n\\r\\nPassing\\r\\n\\r\\nRushing\\r\\n\\r\\nReceiving\\r\\n\\r\\nReturns\\r\\n\\r\\nKicking\\r\\n\\r\\nRunning backs\\r\\n\\r\\nWide receivers\\r\\n\\r\\nTight ends\\r\\n\\r\\nDefensive linemen\\r\\n\\r\\nDefensive backs\\r\\n\\r\\nSpecial teams\\r\\n\\r\\nPractice squad\\r\\n\\r\\nRoster updated October 27, 2018\\r\\nDepth chart ? Transactions\\r\\n53 Active, 5 Inactive, 10 Practice squad\\r\\n\\r\\nNotes:\\r\\n\\r\\nitalics = played a portion of career with the Cardinals and enshrined representing another team\\r\\nDierdorf, Smith, Wehrli and Wilson were members of the St. Louis Football Ring of Fame in The Dome at America's Center when the Rams played there from 1995 to 2015.\\r\\n\\r\\nThe Cardinals' Ring of Honor was started in 2006 to mark the opening of University of Phoenix Stadium. It honors former Cardinal greats from all eras of the franchise's history. Following is a list of inductees and the dates that they were inducted.\\r\\n\\r\\nL Coaching staff\\r\\nL Management\\r\\nL More NFL staffs\\r\\n\\r\\nThe Cardinals' flagship radio station is KMVP-FM; Dave Pasch, Ron Wolfley, and Paul Calvisi handle the radio broadcast. Spanish-language radio broadcasts are heard on the combo of KQMR/KHOV-FM \\"Latino Mix\\" under a contract with Univisi܇n, signed in 2015.[23] Prior to 2015, they were heard on KDVA/KVVA-FM \\"Jos FM\\", as well as co-owned KBMB AM 710. The Cardinals were the first NFL team to offer all 20 preseason and regular season games on Spanish-language radio, doing so in 2000. Gabriel Trujillo and Rolando Cant~ are the Spanish broadcast team. The Cardinals have the most extensive Mexican affiliate network in the NFL, with contracts with Grupo Larsa (in the state of Sonora) and Grupo Radiorama (outside Sonora) and stations in 20 cities, including Hermosillo, Guadalajara and Mexico City.\\r\\n\\r\\nAs of the 2017 season, NBC affiliate KPNX broadcasts the team's preseason games on television (which, that year, included the Hall of Fame Game broadcast by NBC), called by Pasch and Wolfley, with station anchor Paul Gerke as sideline reporter. The broadcasts are syndicated regionally to KTTU and KMSB-TV in Tucson, and KVVU-TV in Las Vegas.[24][25]\\r\\n\\r\\n?= Never played in the league","input":"When did the arizona cardinals move to arizona?"},{"output":"165,521","context":"Fort Lauderdale (/?f??rt ?l??d?rde?l/; frequently abbreviated as Ft. Lauderdale) is a city in the U.S. state of Florida, 28 miles (45?km) north of Miami. It is the county seat of Broward County. As of the 2010 census, the city had a population of 165,521 in 2010.[10]\\r\\nIt is a principal city of the Miami metropolitan area, which was home to an estimated 6,012,331 people in the 2015 census.\\r\\nThe city is a popular tourist destination, with an average year-round temperature of 75.5?F (24.2?C) and 3,000 hours of sunshine per year.\\r\\nGreater Fort Lauderdale, encompassing all of Broward County, hosted 12 million visitors in 2012, including 2.8 million international visitors. In 2012, the county collected $43.9 million from the 5% hotel tax it charges, after hotels in the area recorded an occupancy rate for the year of 72.7 percent and an average daily rate of $114.48. The district has 561 hotels and motels comprising nearly 35,000 rooms. Forty-six cruise ships sailed from Port Everglades in 2012. Greater Fort Lauderdale has over 4,000 restaurants, 63 golf courses, 12 shopping malls, 16 museums, 132 nightclubs, 278 parkland campsites, and 100 marinas housing 45,000 resident yachts.[11]\\r\\nFort Lauderdale is named after a series of forts built by the United States during the Second Seminole War. The forts took their name from Major William Lauderdale (1782ÿ1838), younger brother of Lieutenant Colonel James Lauderdale. William Lauderdale was the commander of the detachment of soldiers who built the first fort.[12] However, development of the city did not begin until 50 years after the forts were abandoned at the end of the conflict.\\r\\nThree forts named \\"Fort Lauderdale\\" were constructed: the first was at the fork of the New River, the second was at Tarpon Bend on the New River between the present-day Colee Hammock and Rio Vista neighborhoods, and the third was near the site of the Bahia Mar Marina.[12]\\r\\n\\r\\n\\r\\nThe area in which the city of Fort Lauderdale would later be founded was inhabited for more than two thousand years by the Tequesta Indians.[13] Contact with Spanish explorers in the 16th century proved disastrous for the Tequesta, as the Europeans unwittingly brought with them diseases, such as smallpox, to which the native populations possessed no resistance. For the Tequesta, disease, coupled with continuing conflict with their Calusa neighbors, contributed greatly to their decline over the next two centuries.[14] By 1763, there were only a few Tequesta left in Florida, and most of them were evacuated to Cuba when the Spanish ceded Florida to the British in 1763, under the terms of the Treaty of Paris (1763), which ended the Seven Years' War.[13] Although control of the area changed between Spain, United Kingdom, the United States, and the Confederate States of America, it remained largely undeveloped until the 20th century.\\r\\nThe Fort Lauderdale area was known as the \\"New River Settlement\\" before the 20th century. In the 1830s there were approximately 70 settlers living along the New River. William Cooley, the local Justice of the Peace, was a farmer and wrecker, who traded with the Seminole Indians. On January 6, 1836, while Cooley was leading an attempt to salvage a wrecked ship, a band of Seminoles attacked his farm, killing his wife and children, and the children's tutor. The other farms in the settlement were not attacked, but all the white residents in the area abandoned the settlement, fleeing first to the Cape Florida Lighthouse on Key Biscayne, and then to Key West.[15]\\r\\nThe first United States stockade named Fort Lauderdale was built in 1838,[16] and subsequently was a site of fighting during the Second Seminole War. The fort was abandoned in 1842, after the end of the war, and the area remained virtually unpopulated until the 1890s. It was not until Frank Stranahan arrived in the area in 1893 to operate a ferry across the New River, and the Florida East Coast Railroad's completion of a route through the area in 1896, that any organized development began. The city was incorporated in 1911, and in 1915 was designated the county seat of newly formed Broward County.[17]\\r\\nFort Lauderdale's first major development began in the 1920s, during the Florida land boom of the 1920s.[18] The 1926 Miami Hurricane[19] and the Great Depression of the 1930s caused a great deal of economic dislocation. In July 1935, an African-American man named Rubin Stacy was accused of robbing a white woman at knife point. He was arrested and being transported to a Miami jail when police were run off the road by a mob. A group of 100 white men proceeded to hang Stacy from a tree near the scene of his alleged robbery. His body was riddled with some twenty bullets.[20] The murder was subsequently used by the press in Nazi Germany to discredit US critiques of its own persecution of Jews, Communists, and Catholics.[21]\\r\\nWhen World War II began, Fort Lauderdale became a major US base, with a Naval Air Station to train pilots, radar operators, and fire control operators. A Coast Guard base at Port Everglades was also established.[22]\\r\\nOn July 4, 1961 African Americans started a series of protests, wade-ins, at beaches that were off-limits to them, to protest \\"the failure of the county to build a road to the Negro beach\\".[23][24] On July 11, 1962 a verdict by Ted Cabot went against the city's policy of racial segregation of public beaches.\\r\\nToday, Fort Lauderdale is a major yachting center,[25] one of the nation's largest tourist destinations,[25] and the center of a metropolitan division with 1.8 million people.[26]\\r\\nAfter the war ended, service members returned to the area, spurring an enormous population explosion which dwarfed the 1920s boom.[14] The 1960 Census counted 83,648 people in the city, about 230% of the 1950 figure.[27] A 1967 report estimated that the city was approximately 85% developed,[28] and the 1970 population figure was 139,590.[29]\\r\\nAfter 1970, as Fort Lauderdale became essentially built out, growth in the area shifted to suburbs to the west. As cities such as Coral Springs, Miramar, and Pembroke Pines experienced explosive growth, Fort Lauderdale's population stagnated, and the city actually shrank by almost 4,000 people between 1980, when the city had 153,279 people,[30] and 1990, when the population was 149,377. A slight rebound brought the population back up to 152,397 at the 2000 census. Since 2000, Fort Lauderdale has gained slightly over 18,000 residents through annexation of seven neighborhoods in unincorporated Broward County.[31]\\r\\nAccording to the United States Census Bureau, the city has a total area of 38.6 square miles (99.9?km2), 34.7 square miles (90.0?km2) of which is land and 3.8 square miles (9.9?km2) of which is water (9.87%).[10] Fort Lauderdale is known for its extensive network of canals; there are 165 miles (266?km) of waterways within the city limits.[32]\\r\\nThe city of Fort Lauderdale is adjacent to the Atlantic Ocean, includes 7 miles (11?km) of beaches,[33] and borders the following municipalities:\\r\\nThe northwestern section of Fort Lauderdale is separate from the remainder of the city, connected only by the Cypress Creek Canal as it flows under I-95. This section of Fort Lauderdale borders the cities of Tamarac and Oakland Park on its south side. Oakland Park also borders Fort Lauderdale on the west side of its northeastern portion. The greater portion of Fort Lauderdale in the south is bordered, along its north side by Wilton Manors.\\r\\nOff the coast of Fort Lauderdale is the Osborne Reef, an artificial reef made of discarded tires that has proven to be an ecological disaster.[34] The dumping began in the 1960s, with the intent to provide habitat for fish while disposing of trash from the land. However, in the rugged and corrosive environment of the ocean, nylon straps used to secure the tires wore out, cables rusted, and tires broke free. The tires posed a particular threat after breaking free from their restraints. The tires then migrated shoreward and ran into a living reef tract, washed up on its slope and killed many things in their path. In recent years, thousands of tires have also washed up on nearby beaches, especially during hurricanes. Local authorities are now working to remove the 700,000 tires, in cooperation with the U.S. Army, Navy and Coast Guard.[35]\\r\\nFort Lauderdale has an official program for designating and recognizing neighborhoods. Under the Neighborhood Organization Recognition Program,[36] more than 60 distinct neighborhoods have received official recognition from the city. An additional 25ÿ30 neighborhoods exist without official recognition, although the city's neighborhood map displays them as well.[37]\\r\\nFort Lauderdale features a tropical rainforest climate (K?ppen Af)[38] with little seasonal variation in temperature. Average monthly temperatures are always above 65?F (18.3?C) and average monthly precipitation is above 2.39 inches (60.71?mm).[citation needed] This qualifies the city's climate as a tropical climate, and the city does not have a true dry season. While some rain does fall in winter, the majority of precipitation is received during the summer months (see climate chart below).\\r\\nSummers from May through October are hot, humid, and wet with average high temperatures of 86ÿ90?F (30ÿ32?C) and lows of 71ÿ76?F (22ÿ24?C). During this period, more than half of summer days may bring afternoon or evening thunderstorms.[39] The record high temperature of 100?F (38?C) was recorded on June 22, 2009.[40]\\r\\nWinters from November through April are warm and mostly dry with average high temperatures of 75ÿ82?F (24ÿ28?C) and lows of 59ÿ67?F (15ÿ19?C). However, the city experiences occasional cold fronts during this period, bringing high temperatures in the 60s F (16-21?C) and lows in the 40s F (4-10?C), lasting only for a day or so.[39] Rare frosts occur every few decades. Only once in reported history have snow flurries been reported in the air or trace amounts on the ground?ÿ on January 19, 1977.[41][42] During the dry season (winter), brush fires can be a concern in many years.\\r\\nAnnual average precipitation is 64.2 inches (1,630?mm), with most of it occurring during the wet season from May through October. However, rainfall occurs in all months, even during the drier months from November through April, mainly as short-lived heavy afternoon thunderstorms. Fort Lauderdale has an average of 143 rain days and 250 sunshine days annually. The hurricane season is between June 1 and November 30 with major hurricanes most likely to affect the city or state in September and October.[43] The most recent storms to directly affect the city were Hurricane Katrina and Hurricane Wilma, both of which struck the city in 2005. Other direct hits were Hurricane Cleo in 1964, Hurricane King in 1950, and the 1947 Fort Lauderdale Hurricane.\\r\\nAs of 2010, those of Hispanic or Latino ancestry accounted for 13.7% of Fort Lauderdale's population. Out of the 13.7%, 2.5% were Cuban, 2.3% Puerto Rican, 1.7% Mexican, 1.1% Colombian, 0.9% Guatemalan, 0.8% Salvadoran, 0.6% Honduran, and 0.6% were Peruvian.[47]\\r\\nAs of 2010, those of African ancestry accounted for 31.0% of Fort Lauderdale's population, which includes African Americans. Out of the 31.0%, 10.0% were West Indian or Afro-Caribbean American (6.4% Haitian, 2.5% Jamaican, 0.4% Bahamian, 0.2% Other or Unspecified West Indian, 0.2% British West Indian, 0.1% Trinidadian and Tobagonian, 0.1% Barbadian), 0.6% were Black Hispanics, and 0.5% were Subsaharan African.[47][48][49]\\r\\nAs of 2010, those of (non-Hispanic white) European ancestry accounted for 52.5% of Fort Lauderdale's population. Out of the 52.5%, 10.3% were Irish, 10.1% German, 8.1% Italian, 7.1% English, 3.0% Polish, 2.1% French, 1.9% Russian, 1.7% Scottish, 1.2% Scotch-Irish, 1.0% Dutch, 1.0% Swedish, 0.6% Greek, 0.6% Hungarian, 0.5% Norwegian, and 0.5% were French Canadian.[48][49]\\r\\nAs of 2010, those of Asian ancestry accounted for 1.5% of Fort Lauderdale's population. Out of the 1.5%, 0.4% were Indian, 0.3% Filipino, 0.3% Other Asian, 0.2% Chinese, 0.1% Vietnamese, 0.1% Japanese, and 0.1% were Korean.[48]\\r\\nIn 2010, 7.1% of the population considered themselves to be of only American ancestry (regardless of race or ethnicity.)[48][49] 0.6% were of Arab ancestry, as of 2010.[48]\\r\\nAs of 2010, there were 74,786 occupied households, while 19.7% were vacant. 17.7% had children under the age of 18 living with them, 30.4% were married couples living together, 12.3% have a female head of household with no husband present, and 52.4% were non-families. 39.4% of all households were made up of individuals and 11.1% had someone living alone who was 65 years of age or older (4.8% male and 6.3% female.) The average household size was 2.17 and the average family size was 3.00.[48][50]\\r\\nIn 2010, the city population was spread out with 17.6% under the age of 18, 8.1% from 18 to 24, 28.4% from 25 to 44, 30.6% from 45 to 64, and 15.3% who were 65 years of age or older. The median age was 42.2 years. For every 100 females there were 111.8 males. For every 100 females age 18 and over, there were 113.1 males.[48][50]\\r\\nAs of 2010, the median income for a household in the city was $49,818, and the median income for a family was $59,238. Males had a median income of $46,706 versus $37,324 for females. The per capita income for the city was $35,828. About 13.1% of families and 18.2% of the population were below the poverty line, including 30.3% of those under age 18 and 12.5% of those aged 65 or over.[51]\\r\\nIn 2010, 21.3% of the city's population was foreign-born. Of foreign-born residents, 69.6% were born in Latin America and 15.3% were born in Europe, with smaller percentages from North America, Africa, Asia, and Oceania.[49]\\r\\nIn 2000, Fort Lauderdale had the twenty-sixth highest percentage of Haitian residents in the US, at 6.9% of the city's population,[52] and the 127th highest percentage of Cuban residents, at 1.7% of the city's residents.[53]\\r\\nLike South Florida in general, Fort Lauderdale has many residents who can speak languages other than English, although its proportion is lower than the county average.[54] As of 2000, 75.63% of the population spoke only English at home, while 24.37% spoke other first languages. Speakers of Spanish were 9.43%, French Creole (mostly Haitian Creole) 7.52%, French 2.04%, Portuguese 1.02%, Italian 0.82%, and German at 0.80%.[55]\\r\\nThe city, along with adjacent small cities Oakland Park and Wilton Manors, is known for its large LGBT community and has one of the highest ratios of gay men and lesbians, with gay men being more largely present,[56] in the United States.[57] The city is also known as a popular vacation spot for gays and lesbians,[58] with many LGBT or LGBT-friendly hotels and guesthouses.[59] Fort Lauderdale hosts the Stonewall Library & Archives, and in neighboring Wilton Manors there is a large LGBT community center, the Pride Center, and the World AIDS Museum and Educational Center.\\r\\nFort Lauderdale's economy has diversified over time. From the 1940s through the 1980s, the city was known as a spring break destination for college students. However, the college crowd has since dwindled, with the city now attracting wealthier tourists.[60] Cruise ships and nautical recreation provide the basis for much of the revenue raised by tourism. There is a convention center located west of the beach and southeast of downtown, with 600,000 square feet (55,742?m2) of space, including a 200,000-square-foot (18,581?m2) main exhibit hall.[61] Approximately 30% of the city's 10 million annual visitors attend conventions at the center.[62]\\r\\nThe downtown area, especially around Las Olas Boulevard, first underwent redevelopment starting in 2002[63] and now hosts many new hotels and high-rise condominium developments.[64] The downtown area is the largest in Broward County, although there are other cities in the county with commercial centers. Office buildings and highrises include Las Olas River House, Las Olas Grand, 110 Tower (formerly AutoNation Tower), Bank of America Plaza, One Financial Plaza, Broward Financial Center, One East Broward Boulevard, Barnett Bank Plaza, PNC Center, New River Center, One Corporate Center, SunTrust Centre, 101 Tower, and SouthTrust Tower.[65]\\r\\nThe Fort Lauderdale metropolitan area foreclosures increased 127.4% from 2006 to 2007, or one filing per 48 households in the quarter. Fort Lauderdale ranks fourth in the list of top 10 metropolitan areas ranked by foreclosure filings per household for the third quarter of 2007.[66]\\r\\nFort Lauderdale is a major manufacturing and maintenance center for yachts. The boating industry is responsible for over 109,000 jobs in the county.[67] With its many canals, and proximity to the Bahamas and Caribbean, it is also a popular yachting vacation stop, and home port for 42,000 boats, and approximately 100 marinas and boatyards.[25] Additionally, the annual Fort Lauderdale International Boat Show, the world's largest[68] boat show, brings over 125,000 people to the city each year.[69][70]\\r\\nCompanies based in the Fort Lauderdale area include AutoNation, Citrix Systems, DHL Express, Spirit Airlines, and National Beverage Corporation. The largest employers in the county are Tenet Healthcare, which employs 5,000 people; American Express, which employs 4,200; The Continental Group, which employs 3,900; Motorola, which employs 3,000, and Maxim Integrated Products, which employs 2,000.[71]\\r\\nGulfstream International Airlines, a commuter airline, is headquartered in nearby Dania Beach.[72][73][74] An Online Trading Academy center is also located in the city.\\r\\nFort Lauderdale was recently listed as 2017's third best city out of 150 U.S. cities by WalletHub for summer jobs, and the 24th best city to start a career in.[75]\\r\\nFort Lauderdale has a Commission-Manager form of government. City policy is set by a city commission of five elected members: the mayor and four district commission members. In 1998, the municipal code was amended to limit the mayoral term. The mayor of Fort Lauderdale now serves a three-year term and cannot serve more than three consecutive terms.[76] The current mayor is John P. \\"Jack\\" Seiler. He succeeds the longest serving mayor, Jim Naugle, 1991-2009.[77] Administrative functions are performed by a city manager, who is appointed by the city commission. Fort Lauderdale Fire-Rescue Department provides Fire and Emergency Medical Services.\\r\\nThe United States Postal Service operates post offices in Fort Lauderdale. The Fort Lauderdale Main Post Office is located at 1900 West Oakland Park Boulevard in the city of Oakland Park.[78] Post offices within the city limits include Alridge,[79] Colee,[80] Coral Ridge,[81] Gateway Station,[82] Melrose Vista,[83] and Southside Station.[84]\\r\\nAccording to 2000 census data, 79.0% of the city's population aged 25 or older were high school graduates, slightly below the national figure of 80.4%. 27.9% held at least a baccalaureate, slightly higher than the national figure of 24.4%. Broward County Public Schools operates 23 public schools in Fort Lauderdale. 2007 Florida Comprehensive Assessment Test (FCAT) results for Fort Lauderdale's public schools were mixed; while ten (of sixteen) elementary schools and one (of four) middle schools received \\"A\\" or \\"B\\" grades, Sunland Park Elementary School[85] and Arthur Ashe Middle School[86] received failing grades. Boyd Anderson High School, which is located in Lauderdale Lakes but whose attendance zone includes part of Fort Lauderdale, also received a failing grade.[87] None of the three failing schools have failed twice in a four-year period, thus triggering the \\"Opportunity Scholarship Program\\" school choice provisions of the Florida's education plan.[88]\\r\\nNine institutions of higher learning have main or satellite campuses in the city:\\r\\nAdditionally, the Davenport, Iowa-based Kaplan University's Corporate headquarters and an academic support center are located in the city.[89]\\r\\nLocal bus transportation is provided by Broward County Transit (BCT), the county bus system. BCT provides for connections with the bus systems in other parts of the metropolitan area: Metrobus in Dade County and Palm Tran in Palm Beach County. Tri-Rail, a commuter rail system, connects the major cities and airports of South Florida. In November 2006, Broward County voters rejected[90] a one-cent-per-hundred sales tax increase intended to fund transportation projects such as light rail and expansion of the bus system.[91]\\r\\nFour railroads serve Fort Lauderdale. Florida East Coast Railroad (FEC) and CSX Transportation are freight lines, Amtrak provides passenger service to other cities on the Atlantic coast via the Fort Lauderdale station, and Tri-Rail provides commuter service between Palm Beach County, Broward County (including two stations in Fort Lauderdale), and Miami-Dade County. All Aboard Florida is constructing a new station in downtown Fort Lauderdale for its Brightline rail service connecting Miami and Orlando, Florida.\\r\\nThe Wave (streetcar), a new 2.7-mile (4.3?km) electric streetcar system costing $125 million, is being planned for the downtown. Most of the construction funding will come from federal ($62.5 million), state ($37 million) and city taxpayers ($10.5 million), with approximately $15 million from assessments on properties located within the Downtown Development Authority. Broward County (BCT) has committed to operating the system for the first 10 years at an expected annual cost of $2 million, and has guaranteed funding to cover any shortfall in ridership revenues.[92] The construction cost of $50 million per mile is considerably higher than other recently built streetcar projects, in part due to the challenges of building an electric transit system over the 3rd Avenue drawbridge.\\r\\nFort Lauderdale-Hollywood International Airport, near Dania Beach, Florida, is the city's main airport and is the fastest-growing major airport in the country.[93] This is, in part, attributable to service by low-cost carriers such as Spirit Airlines, JetBlue Airways, Southwest Airlines and Virgin America, resulting in lower airfares than nearby Miami International Airport.[94] Fort Lauderdale-Hollywood is an emerging international gateway for the Caribbean and Latin America. Miami International Airport and Palm Beach International Airport also serve the city.\\r\\nFort Lauderdale is home to Port Everglades, the nation's third busiest cruise port.[95] It is Florida's deepest port, and is an integral petroleum receiving point.[96] Fort Lauderdale is served by a regular international passenger ferry service to Freeport, Grand Bahama Island, Bahamas operated by Baleria Bahamas Express. Broward County is served by three major Interstate Highways (I-75, I-95, I-595) and U.S. Highways such as U.S. 1, US 27 and US 441. The interchange between I-95 and I-595/SR 862 is known as the Rainbow Interchange. It is also served by Florida's Turnpike and State Highway 869, also known as the Sawgrass Expressway.\\r\\nFort Lauderdale is served by Broward General Medical Center and Imperial Point Medical Center, which are operated by Broward Health, the third largest hospital consortium in the United States. Broward General is a 716-bed[97] acute care facility which is designated as a Level I trauma center.[98] It is also home to Chris Evert Children's Hospital and a Heart Center of Excellence. The hospital serves as a major training site for medical students from Nova Southeastern University's College of Osteopathic Medicine, as well as nursing and paramedic programs from throughout the area. Imperial Point Medical Center is a 204-bed facility[97] with a hyperbaric medicine program.[99] Holy Cross Hospital, a 571-bed[100] hospital operated by the Sisters of Mercy, was named by HealthGrades as one of the 50 best hospitals in the country for 2007.[101]\\r\\nFort Lauderdale is served by English-language newspapers South Florida-Sun Sentinel and The Miami Herald, Spanish-language newspapers El Sentinel, El Nuevo Herald and an alternative newspaper New Times Broward-Palm Beach.\\r\\nAs is true of many parts of Florida, the city's population has a strong seasonal variation, as snowbirds from the northern United States, Canada, and Europe spend the winter and early spring in Florida.[102] The city is also sometimes referred to as \\"Fort Liquordale\\" because of its beaches, bars, nightclubs, and history as a spring break location, back in the 1960s and 1970s, for tens of thousands of college students.[103] However, the city has actively discouraged college students from visiting the area since the mid-1980s, passing strict laws aimed at preventing the mayhem that regularly occurred each year in the 1970s and 1980s. The city had an estimated 350,000 college visitors for spring break 1985;[104] by 2006, that number had declined to about 10,000. Since the 1990s, Fort Lauderdale has increasingly become a location that caters to those seeking the resort lifestyle seasonally or year-round and is often a host city to many professional venues, concerts, and art shows.\\r\\nFort Lauderdale's arts and entertainment district, otherwise known as the Riverwalk Arts & Entertainment District, runs east-west along Las Olas Boulevard, from the beach to the heart of downtown. The district is anchored in the West by the Broward Center for the Performing Arts, and runs through the city to the intersection of Las Olas and A1A. This intersection is the \\"ground zero\\" of Fort Lauderdale Beach, and is the site of the Elbo Room bar featured in the 1960 film Where the Boys Are, which led in large measure to the city's former reputation as a spring break mecca. The city and its suburbs host over 4,100 restaurants and over 120 nightclubs, many of them in the arts and entertainment district.[25] The city is also the setting for the 1986 movie Flight of the Navigator, and host of Langerado, an annual music festival. In 2013, the county welcomed about 1.3 million LGBT travelers who spent about $1.5 billion in area restaurants, hotels, attractions and shops, according to the Greater Fort Lauderdale Convention & Visitors Bureau.\\r\\nLockhart Stadium in Fort Lauderdale, is the current home of the Fort Lauderdale Strikers which play in the current incarnation of the North American Soccer League. It was previously the home of the original Fort Lauderdale Strikers, which played in the previous version of the North American Soccer League. The Miami Fusion of Major League Soccer played home games at this stadium from 1998 to 2001. The Florida Atlantic University Owls football team played its home games at Lockhart Stadium from 2003 through 2010.[105][106]\\r\\nAlthough Fort Lauderdale does not host any top division professional sports teams, the Florida Panthers of the National Hockey League play at BB&T Center in suburban Sunrise.[107] Major League Baseball's Miami Marlins,[108] the National Football League's Miami Dolphins[109] and the Miami Heat of the National Basketball Association all play in neighboring Dade County.\\r\\nThe New York Yankees, Baltimore Orioles, and Kansas City Royals used to conduct spring training in the city at Fort Lauderdale Stadium,[110] and NCAA Division I college sports teams of Florida International University and University of Miami play in Dade County. Florida Atlantic University's athletic programs are located in neighboring Palm Beach County.\\r\\nFort Lauderdale is also home to the Fort Lauderdale Aquatic Complex, which is located at the International Swimming Hall of Fame. It contains two 25-yard (23?m) by 50-meter competition pools, as well as one 20 by 25-yard (23?m) diving well. The complex is open to Fort Lauderdale residents, and has also been used in many different national and international competitions since its opening in 1965. 10 world records have been set there, from Catie Ball's 100?m breaststroke in 1966[111] to Michael Phelps' 400?m individual medley in 2002.[112]\\r\\ncompLexity Gaming's Dota 2 squad is currently based in Fort Lauderdale.[113]\\r\\nThe International Swimming Hall of Fame is located on Fort Lauderdale beach, and houses a large aquatic complex as well as a museum, theater, and research library.[114]\\r\\nHugh Taylor Birch State Park is a 180-acre (0.73?km2) park along the beach, with nature trails, camping and picnicking areas, canoeing, and features the Terramar Visitor Center, with exhibits about the ecosystem of the park.[115] Hugh Taylor Birch came to Florida in 1893. He purchased ocean-front property for about a dollar per acre, he eventually owned a 3.5-mile stretch of beachfront.[116] The Bonnet House is a historic home in Fort Lauderdale, Florida, United States. Bonnet House's modern history began when Birch gave the Bonnet House property as a wedding gift to his daughter Helen and her husband, Chicago artist Frederic Clay Bartlett in 1919. The site was listed on the National Register of Historic places in 1984 and declared a historic landmark by the City of Fort Lauderdale in 2002.[117]\\r\\nHenry E. Kinney Tunnel on U.S. Route 1 is the only tunnel on a state road in the state of Florida.[118] It was constructed in 1960, and its 864-foot (263?m) length travels underneath the New River and Las Olas Boulevard.\\r\\nThe Florida Everglades is one of the most popular sites of interest among visitors to Fort Lauderdale. There are numerous services available to bring visitors from Fort Lauderdale Beach to the Everglades.[119] Just minutes from the beach is the Riverwalk Arts and Entertainment District in downtown Fort Lauderdale, home to cultural attractions, shops, parks and restaurants. Along Riverwalk, the brick-lined meandering promenade, discover the Broward Center for the Performing Arts, Museum of Discovery and Science with its AutoNation 3D IMAX Theater, Florida Grand Opera, Fort Lauderdale Historical Center, Stranahan House and the Museum of Art.[120]\\r\\nLas Olas Boulevard is a popular thoroughfare in downtown Fort Lauderdale that runs from Andrews Avenue in the Central Business District to A1A and Fort Lauderdale Beach. The boulevard is a popular attraction for locals and visitors, being ideally situated close to Fort Lauderdale beach, Fort Lauderdale-Hollywood International Airport and Port Everglades. It is considered to be South Florida's most architecturally unique, authentic, and eclectic shopping and dining district.[121]\\r\\nIn addition to its museums, beaches, and nightlife, Fort Lauderdale is home to the Fort Lauderdale Swap Shop, a large indoor/outdoor flea market and the site of the world's largest drive-in movie theater, with 13 screens.[122]\\r\\nThe following are images of some of the remaining historical structures in Fort Lauderdale. Some are listed in the National Register of Historic Places:[123][124][125]","input":"What's the population of fort lauderdale florida?"},{"output":"at least 21","context":"The Arizona Lottery is a state agency in Arizona. It is a member of the Multi-State Lottery Association (MUSL). Draw games include Mega Millions, Powerball, The Pick, Fantasy 5, Pick 3, 5 Card Cash, and All or Nothing. A variety of instant scratch tickets, or Scratchers, are also offered.\\r\\n\\r\\nThe Arizona Lottery's mission statement is to support Arizona programs for the public benefit by maximizing revenue in a responsible manner. Arizona became the first state west of the Mississippi to approve a lottery when the statewide public initiative passed in November 1980. In 2002, a vote to extend the lottery for another 10 years was passed, with 73% in favor. In 2010, the Lottery was extended into 2035.\\r\\n\\r\\nThe first sale from the Arizona Lottery was on July 1, 1981. The product was an instant scratch ticket called Scratch It Rich. \\r\\n\\r\\nProceeds from sales of Arizona Lottery tickets, nearly $4 million weekly, fund a variety of state programs. In fiscal year 2016, the Arizona Lottery transferred over $205 million to these programs. The Lottery transfers money to 12 funds that serve 18 beneficiaries. There are six core Arizona Lottery pillars that these 18 beneficiaries align with: arts and education; community enrichment; economic development; environmental conservation; health and human services; and public safety.\\r\\n\\r\\nArizona requires lottery players to be at least 21; the minimum age was 18 until June 1, 2003.\\r\\n\\r\\nThe Pick is an in-state jackpot game; its first drawing was October 13, 1984. Its largest jackpot was $13.5 million in 2007. The Pick is drawn Wednesdays and Saturdays at 8:00 PM MST. Plays are $1. Jackpots begin at $1 million. Its players can add EXTRA!. The Pick draws 6 of 44 numbers.\\r\\n\\r\\nArizona participated in its first Powerball drawing on April 3, 1994, when the lottery became a member of MUSL. To date, 12 jackpot winners have won in Arizona. Powerball is drawn Wednesdays and Saturdays. Each play is $2 ($3 with Power Play) Starting jackpot is $40 million (annuitized with cash option.)\\r\\n\\r\\nFirst Mega Millions Drawing for Arizona: April 8, 2010\\r\\n\\r\\nThe Arizona Lottery began selling Mega Millions tickets in April 2010. The state is waiting for its first Mega Millions jackpot winner. However, 6 lucky players have won second place prizes of $1 million or more during the past six years.\\r\\n\\r\\nIn October 13, 2009, the Mega Millions consortium and MUSL reached an agreement in principle to cross-sell Mega Millions and Powerball in US lottery jurisdictions. Most lotteries with either game began selling tickets for both on January 31, 2010. Arizona joined Mega Millions on April 18, 2010. For an extra $1 the winnings may be multiplied by up to 5 with the Megaplier option.\\r\\n\\r\\nOn November 1, 2017, Mega Millions became a two dollar play. \\r\\n\\r\\nOn November 1, 2017 the Trio became $5. The Trio consists of one Pick, one Power Ball and one Mega Millions which is two $2 dollar plays and one $1 dollar play for a total of $5 dollars using 3 different numbering systems with 3 different number formats offering a 3 times better chance to win for a five dollar bill.\\r\\n\\r\\nFantasy 5 is also drawn six nights a week. It draws 5 of 41 numbers. Its minimum jackpot is $50,000, increasing until there is a 5-of-5 winner. Games are $1. Fantasy 5 has an add-on game, EXTRA!.\\r\\n\\r\\nPick 3 is drawn Mondays through Saturdays. The prize for an exact match (Straight) is $250 on a 50-cent wager, or $500 on a $1 wager.\\r\\n\\r\\nFirst Scratchers Ticket: Scratch it Rich\\r\\n\\r\\nThe first Arizona Lottery ticket was a Scratchers ticket called Scratch it Rich. The game launched on July 1, 1981. Since then, the Arizona Lottery has sold nearly 1,000 different versions of its Scratchers tickets.\\r\\n\\r\\nThe states longest running, most popular Scratchers tickets include:\\r\\n\\r\\nUnusual Scratchers Ticket Prizes\\r\\n\\r\\nArizona Lottery winners have received more than just cash prizes in the past 35 years. Some of the most unusual Scratchers prizes have included hot air balloon rides, a Caribbean cruise, a Las Vegas game show experience, a Phoenix Suns travel package, a trip to Caesars Palace?, a seat in the 2011 World Series of Poker Main Event and a contestant spot on an episode of Wheel of Fortune featuring lottery winners exclusively.\\r\\n\\r\\nScratchers? is a registered service mark of the California Lottery.","input":"How old do you have to be to buy scratchers in arizona?"},{"output":"Finland","context":"","input":"Which country was the first country to impose carbon tax?"},{"output":"major tectonic plate","context":"The Australian Plate is a major tectonic plate in the eastern and, largely, in the southern hemispheres. Originally a part of the ancient continent of Gondwana, Australia remained connected to India and Antarctica until approximately 100?million years ago when India broke away and began moving north. Australia and Antarctica began rifting 85?million years ago and completely separated roughly 45?million years ago[2] The Australian plate later fused with the adjacent Indian Plate beneath the Indian Ocean to form a single Indo-Australian Plate. However, recent studies suggest that the two plates have once again split apart and have been separate plates for at least 3 million years and likely longer.[3] The Australian plate includes the continent of Australia, including Tasmania, as well portions of New Guinea, New Zealand, and the Indian Ocean basin.\\r\\n\\r\\n\\r\\nThe northeasterly side is a complex but generally convergent boundary with the Pacific Plate. The Pacific Plate is subducting under the Australian Plate, which forms the Tonga and Kermadec Trenches, and the parallel Tonga and Kermadec island arcs. It has also uplifted the eastern parts of New Zealand's North Island.\\r\\nThe continent of Zealandia, which separated from Australia 85 million years ago and stretches from New Caledonia in the north to New Zealands subantarctic islands in the south, is now being torn apart along the transform boundary marked by the Alpine Fault.\\r\\nSouth of New Zealand the boundary becomes a transitional transform-convergent boundary, the Macquarie Fault Zone, where the Australian Plate is beginning to subduct under the Pacific Plate along the Puysegur Trench. Extending southwest of this trench is the Macquarie Ridge.\\r\\nThe southerly side is a divergent boundary with the Antarctic Plate called the Southeast Indian Ridge (SEIR).\\r\\nThe subducting boundary through Indonesia is not parallel to the biogeographical Wallace line that separates the indigenous fauna of Asia from that of Australasia. The eastern islands of Indonesia lie mainly on the Eurasian Plate, but have Australasian-related fauna and flora. Southeasterly lies the Sunda Shelf.\\r\\nDepositional age of the Mount Barren Group on the southern margin of the Yilgarn Craton and zircon provenance analysis support the hypothesis that collisions between the PilbaraÿYilgarn and YilgarnÿGawler Cratons assembled a proto-Australian continent approximately 1,696?million years ago (Dawson et al. 2002).[4]","input":"What kind of plate boundary separates australia from antarctica?"},{"output":"Clint Murchison, Jr. (45%), John D. Murchison (45%), along with minority shareholders","context":"","input":"Who was the first owner of the dallas cowboys?"},{"output":"University Park","context":"\\r\\n\\r\\nThe Pennsylvania State University (commonly referred to as Penn State or PSU) is a state-related, land-grant, doctoral university with campuses and facilities throughout Pennsylvania. Founded in 1855, the university has a stated threefold mission of teaching, research, and public service. Its instructional mission[12] includes undergraduate, graduate, professional and continuing education offered through resident instruction and online delivery. Its University Park campus, the flagship campus, lies within the Borough of State College and College Township. It has two law schools: Penn State Law, on the school's University Park campus, and Dickinson Law, located in Carlisle, 90 miles south of State College. The College of Medicine is located in Hershey. Penn State has another 19 commonwealth campuses and 5 special mission campuses located across the state.[13] Penn State has been labeled one of the \\"Public Ivies,\\" a publicly funded university considered as providing a quality of education comparable to those of the Ivy League.[14][15][16]\\r\\n\\r\\nAnnual enrollment at the University Park campus totals more than 46,800 graduate and undergraduate students, making it one of the largest universities in the United States.[7] It has the world's largest dues-paying alumni association.[17] The university's total enrollment in 2015ÿ16 was approximately 97,500 across its 24 campuses[18] and online through its World Campus.[19]\\r\\n\\r\\nThe university offers more than 160 majors among all its campuses[20] and administers $3.62 billion (as of June 30, 2016) in endowment and similar funds.[21] The university's research expenditures totaled $836 million during the 2016 fiscal year.[22]\\r\\n\\r\\nAnnually, the university hosts the Penn State IFC/Panhellenic Dance Marathon (THON), which is the world's largest student-run philanthropy.[23] This event is held at the Bryce Jordan Center on the University Park campus. In 2014, THON raised a program record of $13.3 million.[24] The university's athletics teams compete in Division I of the NCAA and are collectively known as the Penn State Nittany Lions. They compete in the Big Ten Conference for most sports.\\r\\n\\r\\nThe school was founded as a degree-granting institution on February 22, 1855, by act P.L. 46, No. 50 of the General Assembly of the Commonwealth of Pennsylvania as the Farmers' High School of Pennsylvania. Centre County, Pennsylvania, became the home of the new school when James Irvin of Bellefonte, Pennsylvania, donated 200 acres (0.8?km2) of land?ÿ the first of 10,101 acres (41?km2) the school would eventually acquire. In 1862, the school's name was changed to the Agricultural College of Pennsylvania, and with the passage of the Morrill Land-Grant Acts, Pennsylvania selected the school in 1863 to be the state's sole land-grant college. The school's name changed to the Pennsylvania State College in 1874; enrollment fell to 64 undergraduates the following year as the school tried to balance purely agricultural studies with a more classic education.[25]\\r\\n\\r\\nGeorge W. Atherton became president of the school in 1882, and broadened the curriculum. Shortly after he introduced engineering studies, Penn State became one of the ten largest engineering schools in the nation.[26] Atherton also expanded the liberal arts and agriculture programs, for which the school began receiving regular appropriations from the state in 1887.[27] A major road in State College has been named in Atherton's honor. Additionally, Penn State's Atherton Hall, a well-furnished and centrally located residence hall, is named not after George Atherton himself, but after his wife, Frances Washburn Atherton.[28] His grave is in front of Schwab Auditorium near Old Main, marked by an engraved marble block in front of his statue.\\r\\n\\r\\nIn the years that followed, Penn State grew significantly, becoming the state's largest grantor of baccalaureate degrees and reaching an enrollment of 5,000 in 1936.[25] Around that time, a system of commonwealth campuses was started by President Ralph Dorn Hetzel to provide an alternative for Depression-era students who were economically unable to leave home to attend college.[25]\\r\\n\\r\\nIn 1953, President Milton S. Eisenhower, brother of then-U.S. President Dwight D. Eisenhower, sought and won permission to elevate the school to university status as The Pennsylvania State University.[29]  Under his successor Eric A. Walker (1956ÿ1970), the university acquired hundreds of acres of surrounding land, and enrollment nearly tripled.[25] In addition, in 1967, the Penn State Milton S. Hershey Medical Center, a college of medicine and hospital, was established in Hershey with a $50?million gift from the Hershey Trust Company.[25]\\r\\n\\r\\nIn the 1970s, the university became a state-related institution. As such, it now belongs to the Commonwealth System of Higher Education. In 1975, the lyrics in Penn State's alma mater song were revised to be gender-neutral in honor of International Women's Year; the revised lyrics were taken from the posthumously-published autobiography of the writer of the original lyrics, Fred Lewis Pattee, and Professor Patricia Farrell acted as a spokesperson for those who wanted the change.[30]\\r\\n\\r\\nIn 1989, the Pennsylvania College of Technology in Williamsport joined ranks with the university, and in 2000, so did the Dickinson School of Law.[31] The university is now the largest in Pennsylvania, and in 2003, it was credited with having the second-largest impact on the state economy of any organization, generating an economic effect of over $17 billion on a budget of $2.5?billion.[32] To offset the lack of funding due to the limited growth in state appropriations to Penn State, the university has concentrated its efforts on philanthropy (2003 marked the end of the Grand Destiny campaigna seven-year effort that raised over $1.3?billion).[33]\\r\\n\\r\\nIn 2011, the university and its football team garnered major international media attention and criticism due to a sex abuse scandal in which university officials were alleged to have covered up incidents of child sexual abuse by former football team defensive coordinator Jerry Sandusky. Athletic director Timothy Curley and Gary Schultz, Senior Vice President for Finance and Business, were indicted for perjury. In the wake of the scandal, coach Joe Paterno was fired[34] and school president Graham B. Spanier was forced to resign[35] by the Board of Trustees. Sandusky, who maintained his innocence,[36] was indicted and subsequently convicted in June 2012 on 45 counts for the abuse.\\r\\n\\r\\nA subcommittee of the Board of Trustees engaged former FBI director Louis Freeh to head an independent investigation on the university's handling of the incidents. Freeh released his findings in July 2012, announcing that Paterno, along with Spanier, Curley and Schultz \\"conceal[ed] Sandusky's activities from the Board of Trustees, the University community and authorities\\" and \\"failed to protect against a child sexual predator harming children for over a decade\\".[37][38] On July 23, 2012, the National Collegiate Athletic Association announced a series of sanctions against Penn State and the Nittany Lions football team for the role of their leadership in the Penn State sex abuse scandal. The NCAA penalized Penn State football with a $60 million fine, a ban from bowl games and post-season play for 4 years, a reduction in scholarships from 25 to 15 per year for four years, the vacating of all wins from 1998 to 2011 and a 5-year probationary period.[39]\\r\\n\\r\\nThe validity of the sanctions later came into question, and emails surfaced that indicated highly ranked officials within the NCAA did not believe the organization had the jurisdiction to pass down the original sanctions.[40] Subsequent emails, brought forward under subpoena, quoted Mark Emmert, the NCAA President, as agreeing the original sanctions were possible due to a bluff by the NCAA.[41]  On September 8, 2014, the sanctions, following a report by former U.S. Senator and athletics integrity monitor George J. Mitchell citing progress by Penn State in implementing reforms,[42] were officially repealed by the NCAA and all previous records were restored.[43]\\r\\n\\r\\nAn investigation led by former U.S. Attorney General Richard Thornburgh, who was retained by the Paterno family to review the Freeh report,[44] concluded that the report that placed so much blame on Penn State and Paterno was a \\"rush to injustice\\" that could not be relied upon.[45] He found that not only did the evidence \\"fall far short\\" of showing Paterno attempted to conceal the Sandusky scandal, but rather that \\"the contrary is true\\".[44] In November 2014, state Sen. Jake Corman released emails showing \\"regular and substantive\\" contact between NCAA officials and Freeh's investigators, suggesting that the Freeh conclusions were orchestrated.[46]\\r\\n\\r\\nPaterno was posthumously honored by Penn State during the September 17, 2016 football game that marked the 50th anniversary of his first game as head coach.[47][48] The controversial tribute was met with both a standing ovation by fans and protests inside and outside of the stadium.[49][50]\\r\\n\\r\\nThe largest of the university's 24 campuses, University Park is almost entirely within the boundaries of State College borough, a site chosen because it is near the geographic center of the state. With an undergraduate acceptance rate of 23 percent,[51] it is the most selective campus in the Penn State system, due primarily to the fact that students select University Park as their first-choice campus at a far greater rate than the university's other undergraduate campuses.[52] During the fall 2016 semester, 41,359 undergraduate students and 8,955 graduate students were enrolled at University Park.[53] Of those, 46.3 percent were female[54] and 40.5 percent were not Pennsylvania residents.[55]\\r\\n\\r\\nTransportation access:\\r\\n\\r\\nThe University Park campus is centrally located at the junction of Interstate 99 and U.S. Route 322, and is due south of Interstate 80. Before the arrival of the Interstates, University Park was a short distance from the Lock Haven ÿ Altoona branch line of the Pennsylvania Railroad. The last run of long distance trains from Buffalo or Harrisburg through Lock Haven was in 1971.[56] Today, the nearest passenger rail access is in Lewistown, 31 miles to the southeast. The University Park Airport, serving four regional airlines, is near University Park.\\r\\n\\r\\nIn addition to the University Park campus, 19 campus locations throughout the state offer enrollment for undergraduate students. Over 60 percent of Penn State first-year students begin their education at a location other than University Park.[57] Each of these commonwealth campuses offer a unique set of degree programs based on the student demographics. Any student in good academic standing is guaranteed a spot at University Park to finish his or her degree if required or desired, known as \\"change of campus\\" or more accurately \\"the 2+2 program\\"; where a Penn State student may start at any Penn State campus, including University Park, for 2 years and finish at any Penn State the final 2 years.[58]\\r\\n\\r\\nIn 1998, the university launched Penn State World Campus, or Penn State Online, which offers more than 60 online education programs, degrees, and certificates. Distance education has a long history at Penn State, one of the first universities in the country to offer a correspondence course for remote farmers in 1892. Examples of online programs include an MBA, master of professional studies in homeland security, a bachelor of science in nursing, and post-baccalaureate certificates in geographic information systems and applied behavior analysis. Penn State's World Campus offers 18 graduate degrees, 21 graduate certificates, 17 undergraduate degrees, and 11 undergraduate certificates. World Campus students come from all 50 U.S. states, more than 40 countries, and six continents.\\r\\n\\r\\nPenn State is a \\"state-related\\" university, part of Pennsylvania's Commonwealth System of Higher Education. As such, although it receives funding from the Commonwealth and is connected to the state through its board of trustees, it is otherwise independent and not subject to the state's direct control. For the 2006ÿ2007 fiscal year, the university received 9.7 percent of its budget from state appropriations, the lowest of the four state-related institutions in Pennsylvania.[63] Initial reports concerning the 2007ÿ2008 fiscal year indicated that Pennsylvania Governor Ed Rendell is recommending a 1.6 percent increase in state appropriations.[64] Penn State's appropriation request, submitted to the Pennsylvania Department of Education in September, requested a 6.8 percent increase in funding.[65][needs update]\\r\\n\\r\\nPenn State has eighteen colleges, including three at special-mission campuses. The University Park campus is organized into fourteen distinct colleges, plus the Graduate School and the Division of Undergraduate Studies:[66]\\r\\n\\r\\nIn addition, the university's Board of Trustees voted in January 2007 to create a School of International Affairs, with the first classes admitted in the fall 2008 semester.[67] The school is part of Penn State Law.[68]\\r\\n\\r\\nFormerly the School of Nursing, on September 25, 2013, the Board of Trustees granted the nursing program college status.[69]\\r\\n\\r\\nThe university is governed by the 32-member board of trustees. Its members include the university's president, the Governor of the Commonwealth, and the state Secretaries of Agriculture, Conservation and Natural Resources, and Education. The other members include six trustees appointed by the Governor, nine elected by alumni, and six elected by Pennsylvania agricultural societies. Six additional trustees are elected by a board representing business and industry enterprises.[70] Undergraduate students do not elect any trustees; the court case Benner v. Oswald ruled that the Equal Protection Clause of the Fourteenth Amendment did not require the undergraduate students be allowed to participate in the selection of trustees.\\r\\n\\r\\nAs of 2013, the chair of the board of trustees is Keith E. Masser, a graduate of Penn State and the Chairman & Chief Executive Officer of Sterman Masser, Inc.[71]\\r\\n\\r\\nThe main responsibilities of the board are to select the president of Penn State, to determine the goals and strategic direction of the University, and to approve the annual budget.[72] Regular meetings of the board are held bi-monthly and take place primarily on the University Park campus, although on occasion meetings are held at other locations within the Commonwealth.[73]\\r\\n\\r\\nThe president of the University is selected by the board and is given the authority for actual control of the university, including day-to-day management. In practice, part of this responsibility is delegated by the president to other departments of the administration, to the faculty, and to the student body.[72] Eric J. Barron became the university's 18th and current president on May 12, 2014, upon the departure of Rodney Erickson.[4][74]\\r\\n\\r\\nThe executive vice president and provost is the chief academic officer of the University. The current provost, Nicholas P. Jones, assumed office on July 1, 2013.[75] The current Associate Vice President and Senior Associate Dean For Undergraduate Education is Robert N. Pangborn[76]\\r\\n\\r\\nPenn State has a long history of student governance. Elected student leaders remain directly involved in the decision-making of the University administration, as provided for in the Board of Trustee's Standing Orders.[77] Currently, there are three Student Governments recognized by the University administration: the University Park Undergraduate Association (UPUA), the Graduate and Professional Student Association (GPSA), and the Council of Commonwealth Student Governments (CCSG).\\r\\n\\r\\nThe University Park Undergraduate Association (UPUA) is the representative student government of the 39,102[78] undergraduate students at Penn State's University Park campus,[79] which was established in 2006 after the former student government, Undergraduate Student Government (USG), lost its recognition by way of a student referendum.[80]\\r\\n\\r\\nThe UPUA is composed of an Assembly of Student Representatives, an Executive Board, and a Judicial Board. The Executive Board is the bureaucratic branch of the UPUA and is led by Student Body President Katie Jordan. The Assembly, which is led by Chair Brent Rice, is the legislative body of UPUA and is composed of elected representatives whose constituencies include the academic units of Penn State, Greek Life, Freshmen Representatives, and At-Large Representatives.[81] The UPUA meets every Wednesday at 8:00?pm in 233A HUB. These meetings are open to the public.[82] Additionally, students are able to reach out to the UPUA regarding issues at the University through its \\"What to Fix PSU (WTFPSU)\\" social media campaign.\\r\\n\\r\\nThe graduate and professional students of the University are governed by the Graduate and Professional Student Association (GPSA), which is the oldest continuously existing student governance organization at Penn State.[83] GPSA \\"work[s] on the behalf of the students to make sure that the graduate voice is heard by all levels of the administration and faculty at Penn State and to put on events geared towards graduate and professional students.\\"[83]\\r\\n\\r\\nThe 19 commonwealth campuses of the university are governed by the Council of Commonwealth Student Governments (CCSG), formerly known as the Council of Branch Campus Student Governments (CBCSG).[84]\\r\\n\\r\\nPenn State is regionally accredited by the Middle States Association of Colleges and Schools.\\r\\n\\r\\nAs of September 2009, only 24 Pennsylvania colleges and universities held Association to Advance Collegiate Schools of Business accreditation in business and only four in accounting. The Smeal College of Business, The Sam and Irene Black School of Business, Penn State Harrisburg, and Penn State Great Valley were among the institutions accredited.[85]\\r\\n\\r\\nThe university offers an accelerated Premedical-Medical Program in cooperation with Sidney Kimmel Medical College.[86] Students in the program spend two or three years at the university before attending medical school at Jefferson.\\r\\n\\r\\nRecently, a joint venture between the Eberly College of Science and the Smeal College of Business created an integrated undergraduate/graduate program to give highly motivated students the opportunity to receive a bachelor's degree in Science and an MBA two to five years sooner than those pursuing a traditional path. The BS/MBA Program prepares individuals to be future leaders of the world's scientific organizations and is led by Mr. Peter Tombros and Dr. James Gardner.\\r\\n\\r\\nAs of fall 2010, the racial makeup of the Penn State system including all campuses and special-mission colleges, was 75.4 percent white, 5.5 percent black, 4.3 percent Asian, 4.4 percent Hispanic, 0.2 percent Native American, 0.1 percent Native Hawaiian/Pac Island, 1.7 percent two or more races, 5.8 percent international students and 3.1 percent of an unknown race. Over the period 2000ÿ2010, minority enrollment as a percentage of total enrollments has risen 5.3 percentage points,[87] while minorities as a percentage of total teaching positions rose 2.0 percentage points from 1997 to 2002.[88]\\r\\n\\r\\nPenn State has been the subject of controversy for several issues of discrimination. Following some violent attacks on African-Americans in downtown State College in 1988 and complaints that Penn State was not adequately recruiting African-American faculty and students to representative population levels, student activists occupied Old Main and demanded that Penn State do more to recruit minority students and address intolerance toward minority students on campus, as well as in the local community.  After President Bryce Jordan canceled a promised meeting with students and organizations in the Paul Robeson Cultural Center on April 8, 1988, 250 students and activists nonviolently occupied Penn State's Telecommunications building on campus. The following morning, 50 state troopers and 45 local and campus police, equipped with helmets, batons, and rubber gloves, entered the building as the crowd outside sang \\"We Shall Overcome\\", arresting 89 individuals for trespassing.[89] All charges were later dismissed.\\r\\n\\r\\nIn 1990 a vice provost for educational equity was appointed to lead a five-year strategic plan to \\"create an environment characterized by equal access and respected participation for all groups and individuals irrespective of cultural differences.\\"[90][91] Since then, discrimination issues include the handling of death threats in 1992 and 2001,[92][93][94][95] controversy around LGBT issues,[96] and the investigation of a 2006 sexual discrimination lawsuit filed by former Lady Lions basketball player Jennifer Harris, alleging that head coach Rene Portland dismissed her from the team in part due to her perceived sexual orientation.[97][98]\\r\\n\\r\\nSix-year graduation rates for the 2004 cohort at University Park was 85.3 percent. Graduation rates by race among this group are 86.6 percent white, 75.0 percent black, 81.9 percent Asian, 77.4 percent Hispanic, 57.1 percent Native American and 76.1 percent international students.[87] According to a 2006 survey by USA Today, the university's flagship campus, University Park, has the highest in-state tuition rates among comparable institutions nationwide.[99] While a task force formed in 2001 to study options for tuition projections determined that the university's operating efficiency is among the highest in postsecondary education,[100] it found that tuition increases at Penn State still consistently outpaced increases at other Big Ten Conference institutions.[101] Student leaders of The Council of Commonwealth Student Governments (CCSG) have led annual rallies to support lower rate hikes at each of the nineteen commonwealth campuses and at the Pennsylvania state capitol in Harrisburg.[102][103] In 2005, the board of trustees proposed a tuition freeze at the commonwealth campus locations as part of its state appropriation request.[104]\\r\\n\\r\\nThe 2016 Academic Ranking of World Universities ranks the university 77th among universities worldwide and 41st nationally. U.S. News & World Report ranks the university's undergraduate program 50th in its 2017 American's Best College[129] and 14th among Top Public Schools in the United States.[130] In 2015, the university was also ranked 101st in the QS World University Rankings.[131] A more updated 2013ÿ2014 World University Ranking by Times Higher Education ranks Penn State as the 49th best university in the world.[132] Similarly, the 2013 report by the Center for World University Rankings ranks the university as Top 50 in the world.[133]\\r\\n\\r\\nAccording to a Wall Street Journal survey released in September 2010, the university was ranked number 1 by 479 corporate recruiting executives who were asked to identify \\"whose bachelor degree graduates were the best-trained and educated, and best able to succeed once hired.\\"[134][135]\\r\\n\\r\\nAccording to the Carnegie Classification of Institutions of Higher Education, the university is a research university with very high research activity.[136] Over 10,000 students are enrolled in the university's graduate school (including the law and medical schools), and over 70,000 degrees have been awarded since the school was founded in 1922.[137]\\r\\n\\r\\nPenn State's research and development expenditure has been on the rise in recent years. For fiscal year 2013, according to institutional rankings of total research expenditures for science and engineering released by the National Science Foundation, Penn State stands second in the nation, behind only Johns Hopkins and tied with the Massachusetts Institute of Technology, in the number of fields in which it is ranked in the top ten. Overall, Penn State ranked 17th nationally in total research expenditures across the board. In 12 individual fields, however, the University achieved rankings in the top ten nationally. The fields and sub-fields in which Penn State ranked in the top ten are materials (1st), psychology (2nd), mechanical engineering (3rd), sociology (3rd), electrical engineering (4th), total engineering (5th), aerospace engineering (8th), computer science (8th), agricultural sciences (8th), civil engineering (9th), atmospheric sciences (9th), and earth sciences (9th). In eleven of these fields, moreover, the University has repeated top-ten status every year since at least 2008.[138] For fiscal year 2011, the National Science Foundation reported that Penn State had spent $794,846,000 on R&D and ranked 15th among U.S. universities and colleges in R&D spending.[139]\\r\\nFor the 2008ÿ2009 fiscal year, Penn State was ranked ninth among U.S. universities by the National Science Foundation, with $753 million in research and development spending for science and engineering.[140] During the 2015ÿ2016 fiscal year, Penn State received $836 million in research expenditures.[141]\\r\\n\\r\\nThe Applied Research Lab (ARL), located near the University Park campus, has been a research partner with the United States Department of Defense since 1945 and conducts research primarily in support of the United States Navy. It is the largest component of Penn State's research efforts statewide, with over 1,000 researchers and other staff members.[142][143]\\r\\n\\r\\nThe Materials Research Institute was created to coordinate the highly diverse and growing materials activities across Penn State's University Park campus. With more than 200 faculty in 15 departments, 4 colleges, and 2 Department of Defense research laboratories, MRI was designed to break down the academic walls that traditionally divide disciplines and thereby enable faculty to collaborate across departmental and even college boundaries. MRI has become a model for this interdisciplinary approach to research, both within and outside the university. Dr Richard E. Tressler, was an international leader in the development of high temperature materials. He pioneered high temperature fiber testing and use, advanced instrumentation and test methodologies for thermostructural materials, and design and performance verification of ceramics and composites in high temperature aerospace, industrial and energy applications. He was founding director of the Center for Advanced Materials (CAM) which supported many faculty and students from the College of Earth and Mineral Science, the Eberly College of Science, the College of Engineering, the Materials Research Laboratory and the Applied Research Laboratories at Penn State on high temperature materials. His vision for Interdisciplinary research played a key role in the creation of the Materials Research Institute, and the establishment of Penn State as an acknowledged leader among major universities in materials education and research.[144][145][146]\\r\\n\\r\\nThe university was one of the founding members of the Worldwide Universities Network (WUN), a partnership that includes 17 research-led universities in the United States, Asia, and Europe. The network provides funding, facilitates collaboration between universities, and coordinates exchanges of faculty members and graduate students among institutions. Former Penn State president Graham Spanier is a former vice-chair of the WUN.[147][148]\\r\\n\\r\\nThe Pennsylvania State University Libraries were ranked 14th among research libraries in North America in the 2003ÿ2004 survey released by The Chronicle of Higher Education.[149] The university's library system began with a 1,500-book library in Old Main.[citation needed] In 2009, its holdings had grown to 5.2?million volumes, in addition to 500,000 maps, five million microforms, and 180,000 films and videos.[150]\\r\\n\\r\\nThe university's College of Information Sciences and Technology is the home of CiteSeerX, an open-access repository and search engine for scholarly publications. The university is also the host to the Radiation Science & Engineering Center, which houses the oldest operating university research reactor. Additionally, University Park houses the Graduate Program in Acoustics,[151] the only freestanding acoustics program in the United States. The university also houses the Center for Medieval Studies, a program that was founded to research and study the European Middle Ages,[152] and the Center for the Study of Higher Education (CSHE), one of the first centers established to research postsecondary education.\\r\\n\\r\\nPenn State is a participant in the Big Ten Academic Alliance. The Big Ten Academic Alliance (BTAA) is the academic consortium of the universities in the Big Ten Conference. Engaging in $10 billion in research in 2014ÿ2015, BTAA universities provide powerful insight into important issues in medicine, technology, agriculture, and communities. Students at participating schools are also allowed \\"in-house\\" borrowing privileges at other schools' libraries.[153] The BTAA uses collective purchasing and licensing, and has saved member institutions $19 million to date.[154] Course sharing,[155] professional development programs,[156] study abroad and international collaborations,[157] and other initiatives are also part of the BTAA.\\r\\n\\r\\nThere are seven housing complexes located on campus for students attending the University Park campus: East Halls, North Halls, Pollock Halls, South Halls, West Halls, Eastview Terrace, and Nittany Apartments. Each complex consists of a few separate buildings that are dormitories and a commons building, which has: lounges, the help desk for the complex, mailboxes for each dormitory room, a convenience store, a food court, and all-you-care-to-eat buffet. Different floors within a building may be designated as a Special Living Option (SLO). SLOs are offered to members of certain student groups (such as sororities), students studying particular majors, students who wish to engage in a particular life style (such as the alcohol-free LIFE House), or other groups who wish to pursue similar goals.\\r\\n\\r\\nAs of September 2014, 864 student organizations were recognized at the University Park campus.[158] In addition, the university has one of the largest Greek systems in the country, with approximately 12 percent of the University Park population affiliated. Additional organizations on campus include Thespians, Blue Band, Chabad, Glee Club, Aish HaTorah,[159] Student Programming Association (SPA), Lion's Pantry, Boulevard, Apollo, 3D Printer Club, and the Anime Organization, which hosts a Centre County anime convention, Setsucon.[160]\\r\\n\\r\\nEvery February, thousands of students participate in the Penn State IFC/Panhellenic Dance Marathon (THON), which has been \\"dubbed by supporters as the world's largest student-run philanthropy.\\"[23] In previous years, participants stood for 48 hours nonstop and performed a line dance at least once every hour to stay alert. In 2007, THON was moved to the Jordan Center and now lasts 46 hours. THON raises millions of dollars annually for pediatric cancer care and research, generally through the Four Diamonds Fund. In 2014, THON raised a program record of $13.3 million.\\r\\n\\r\\nThe Lion's Pantry is an undergraduate student run on-campus food pantry (and a registered student organization).  The Lion's Pantry serves undergraduate, graduate, and professional students.  With an increase awareness of hunger on college campuses, the Lion's Pantry is one of the most successful startup food pantries in the nation.  They partner with groups ranging from Boulevard, UPUA, Greek Life, and more to receive over 8,000 food donations a year.  The club was also awarded the Class Gift of 2017 in the form of an endowment.[161]\\r\\n\\r\\nStudent media on campus includes La Vie, the university's annual student yearbook; the student-run radio station The LION 90.7 FM (WKPS-FM); Com Radio, independently programmed and operated by university undergraduates; The Daily Collegian, a student-run newspaper; Onward State, a student-run independent news website covering the Penn State community; and Phroth, a student-run humor magazine. For additional information on media related to Penn State ÿ including Penn State Live, the official news source of the University ÿ see the Media section below.\\r\\n\\r\\nPenn State Live is the official news source of the university published by its public relations team. The student-run newspaper is The Daily Collegian, which is published every weekday while classes are in session. Since the summer of 1996, the traditional paper publication has been supplemented by an online edition, known as The Digital Collegian. Onward State, was founded in November 2008 by Davis Shaver, Evan Kalikow, and Eli Glazier.  In addition, Penn State's newspaper readership program provides free copies of USA Today, The New York Times, as well as local and regional newspapers depending on the campus location (for example, the Centre Daily Times in University Park). This program, initiated by then-President Graham Spanier in 1997,[162] has since been instituted on several other universities across the country.[163]\\r\\n\\r\\nLa Vie (the Life), the university's annual student yearbook, has been in production documenting student life continuously since 1890.[164] La Vie 1987, edited by David Beagin, won a College Gold Crown for Yearbooks award from the Columbia Scholastic Press Association.[165]\\r\\n\\r\\nThe student-run radio station is The LION 90.7 fm (WKPS-FM). Founded in 1995 as a replacement for Penn State's original student radio station WDFM, The LION broadcasts from the ground floor of the HUBÿRobeson Center, serving the Penn State and State College communities with alternative music and talk programming, including live coverage of home Penn State football games. In the early 1990s, students who belonged to a sports radio journalism club covered sporting events and produced and anchored weekly sports segments for WPSU, which eventually became solely an NPR affiliate.\\r\\n\\r\\nIn addition, the Penn State College of Communications operates ComRadio. It was founded in the spring of 2003 as an internet-based audio laboratory and co-curricular training environment for aspiring student broadcasters. ComRadio is most well known for its coverage of most major Penn State sporting events. ComRadio also airs student-produced Penn State news. Other programming includes student talk shows, political coverage, AP syndicated news and soft rock music. In recent years, ComRadio broadcasters have won numerous state awards for their on-air work. The station's sports department prides itself on the broadcasts of every home and away football game, including bowl games, and its coverage of the NFL Draft live from New York City.\\r\\n\\r\\nOnward State is a student-run blog geared towards members of the university's community. The blog provides news, features, and event-listings. Founded in November 2008, U.S. News & World Report named the blog the \\"Best Alternative Media Outlet\\" in February 2009.  Alison Go, a blogger of U.S. News & World Report organized the contest \\"Best Alternative Media Outlet\\" at the beginning of 2009.  Onward State, still a fledgling organization, was surprisingly nominated.  Pitted against Onward State were seasoned blogs from UC Berkeley, Vassar, Wesleyan, Columbia, Georgetown, Middlebury, Yale, and an Ivy League conglomerate. Snatching 24.76 percent of the vote, Onward State finished in first place, pleasantly surprising the Penn State bloggers.[166][167] The Daily Collegian first acknowledged Onward State at the time of the blog's victory.  The two Collegian articles brought greater awareness of the blog to the university's community. In an interview with The Collegian about next year's contest, Davis Shaver explained \\"We have big ambitions... I think that we're just going to be more established, more of a name within the Penn State community by then. There is a strong possibility of being Alternative Media repeat champions.\\"[168]\\r\\n\\r\\nThe student-run humor magazine is Phroth, which publishes two to four issues each year. Its roots date back to 1909 when it was called Froth. Several Froth writers and editors have gone on to win fame: Julius J. Epstein wrote the screenplay for the film Casablanca (1942) and won three Academy Awards; Jimmy Dugan wrote for the Saturday Evening Post, National Geographic, and The New York Times; and Ronald Bonn was a producer with NBC Nightly News and CBS Evening News.[169]\\r\\n\\r\\nKalliope is an undergraduate literary magazine produced by students and sponsored by the university's English Department. Kalliope includes works of fiction, nonfiction, poetry, and visual art.[170] The student-run life and style magazine is Valley.[171]\\r\\n\\r\\nThe Underground, a multicultural student-run media site was founded in 2015 and serves as another alternative media news site.\\r\\n\\r\\nThe Underground is a multicultural student-run media site devoted to telling the untold stories within the Penn State community. The publication seeks to foster the multicultural student voice through creating an open forum of discussion and promoting diversity and community involvement.\\r\\n\\r\\nThe idea of The Underground was discussed on Wednesday, February 11, 2015, after an inspiring presentation from Soledad O'Brien on the Penn State University Park campus. The project began as a simple idea by two freshmen in Ritner Hall. After discussion with other students, a website was created. We hope to grow as a site, engage with more members of the community, and continue to promote the sharing of diverse stories.\\r\\n\\r\\nThe Underground is produced by students at Penn State and was put into play by Candice Crutchfield and Adriana Lacy. The first contributors included a great group of friends: Candice Crutchfield, Adriana Lacy, Matthew Lamas, and Adam Tidball.\\r\\n\\r\\nPenn State's mascot is the Nittany Lion, a representation of a type of mountain lion that once roamed what is now University Park. The school's official colors, now blue and white, were originally black and dark pink.  Penn State participates in the NCAA Division I FBS and in the Big Ten Conference for most sports.[172]\\r\\n\\r\\nTwo sports participate in different conferences: men's volleyball in the Eastern Intercollegiate Volleyball Association (EIVA)[173] and women's hockey in College Hockey America (CHA).[174] The fencing teams operate as independents.\\r\\n\\r\\nAthletic teams at Penn State have won 77 national collegiate team championships (49 NCAA, 2 consensus Division I football titles, 6 AIAW, 3 USWLA, 1 WIBC, and 4 national titles in boxing, 11 in men's soccer and one in wrestling in years prior to NCAA sponsorship).[175] The 49 NCAA Championships ranks fifth all time in NCAA Division I, and is the most of any Big Ten school.[176]\\r\\n\\r\\nSince joining the Big Ten in 1991, Penn State teams have won 103 conference regular season and tournament titles.[177]\\r\\n\\r\\nPenn State has one of the most successful overall athletic programs in the country, as evidenced by its rankings in the NACDA Director's Cup, a list compiled by the National Association of Collegiate Directors of Athletics that charts institutions' overall success in college sports. From the Cup's inception in the 1993ÿ1994 season, the Nittany Lions have finished in the top 25 every year.[178]\\r\\n\\r\\nDespite widespread success in the overall athletic program, however, the school is best known for its football team, which draws a very large following. Penn State's Beaver Stadium has the second largest seating capacity of any stadium in the nation,[179] with an official capacity of 106,572 slightly behind Michigan Stadium with an official capacity of 107,601. For decades, the football team was led by coach Joe Paterno. Paterno was in a close competition with Bobby Bowden, the head coach for Florida State, for the most wins ever in Division I-A (now the FBS) history. This competition effectively ended with Paterno still leading following Bowden's retirement after the 2010 Gator Bowl. In 2007, he was inducted into the College Football Hall of Fame.[180] Paterno amassed 409 victories over his career, the most in NCAA Division 1 history.[181] Paterno died on January 22, 2012, at the age of 85.\\r\\n\\r\\nThe school's wrestling team has also become noticed. Under Cael Sanderson, the Nittany Lions won six national titles in a seven-year span, from 2011 to 2017.\\r\\n\\r\\nThe university opened a new Penn State All-Sports Museum in February 2002. This two-level 10,000-square-foot (1,000?m2) museum is located inside Beaver Stadium.[182]\\r\\nIn addition to the school funded athletics, club sports also play a major role in the University, with over 68 club sport organizations meeting regularly to date. Many club teams compete nationally in their respective sports. The Penn State Ski Team, which competes as part of the United States Collegiate Ski and Snowboard Association (USCSA) in the Allegheny Conference, as well as the Penn State Swim Club, which competes in the American Swimming Association ÿ University League (ASAU), are just a few examples. Some other clubs include baseball, squash, karate, crew, and sailing.\\r\\n\\r\\nPenn State's most well known athletic cheer is \\"We are...Penn State.\\" Typically, the students and cheerleaders shout, \\"We are,\\" followed by a response of \\"Penn State\\" from the rest of the fans. By tradition, this is done three times, and followed by \\"Thank you...\\" \\"... You're welcome!\\"\\r\\n\\r\\nThe list of eminent past and present individuals associated with Penn Stateas alumni, faculty, and athletic staffcan be found in the list of Pennsylvania State University people.\\r\\n\\r\\nEstablished in 1870, nine years after the university's first commencement exercises, the Penn State Alumni Association has the stated mission \\"to connect alumni to the University and to each other, provide valuable benefits to members and support the University's mission of teaching, research and service.\\"[183] The Alumni Association supports a number of educational and extracurricular missions of Penn State through financial support and is the network that connects alumni through over 280 \\"alumni groups\\", many of which are designated based on geographical, academic, or professional affiliation.[184]\\r\\n\\r\\nAs of July 1, 2010, the Alumni Association counts 496,969 members within the United States, with an additional 16,180 in countries around the globe.[185][186] About half the United States alumni reside in Pennsylvania, primarily in the urban areas of Philadelphia (and the surrounding counties), the Pittsburgh Area and in the Centre County region surrounding State College, although alumni can be found in every region of the country and abroad. About 34 percent of United States alumni and 21 percent of international alumni are members of the Alumni Association.[187][188] With membership totaling 176,426 as of FY2016, the Penn State Alumni Association is the largest dues-paying alumni association in the world, a distinction it has held since 1995.[189]\\r\\n\\r\\nSince 2001, the university, along with all schools in the Big Ten, has participated in the \\"Big Ten Challenge\\" website, which is a \\"competitive\\" clearinghouse of alumni donation statistics for member schools. Results are tracked to determine a percentage of each school's alumni from the previous decade who gave to their alma mater each calendar year (during the 2005ÿ2006 year, alumni donations from 1996 to 2005 were tallied). With the exception of 2005ÿ2006, when Penn State fell to second behind Northwestern University,[190] Penn State has won the challenge each year since its inception.[191][192][193][194]","input":"What is the main campus at penn state?"},{"output":"seven splendors","context":"In Ancient Mesopotamian religion, Humbaba (???????? Assyrian spelling), also spelled Huwawa (?????? Sumerian spelling) and surnamed the Terrible, was a monstrous giant of immemorial age raised by Utu, the Sun.[1] Humbaba was the guardian of the Cedar Forest, where the gods lived, by the will of the god Enlil, who \\"assigned [Humbaba] as a terror to human beings. Gilgamesh defeated this great enemy.\\"\\r\\n\\r\\n\\r\\nHis face is that of a lion. \\"When he looks at someone, it is the look of death.\\"[2] \\"Humbaba's roar is a flood, his mouth is death and his breath is fire! He can hear a hundred leagues away any [rustling?] in his forest! Who would go down into his forest!\\"[3] In various examples, his face is scribed in a single coiling line like that of the coiled entrails of men and beasts, from which omens might be read.[4]\\r\\nAnother description from Georg Burckhardt translation of Gilgamesh says, \\"he had the paws of a lion and a body covered in thorny scales; his feet had the claws of a vulture, and on his head were the horns of a wild bull; his tail and phallus each ended in a snake's head.\\"[5]\\r\\nYet another description in a newly discovered tablet in Sulaymaniyah is somewhat positive about Humbaba:\\r\\n\\"Where Humbaba came and went there was a track, the paths were in good order and the way was well trodden ... Through all the forest a bird began to sing: A wood pigeon was moaning, a turtle dove calling in answer. Monkey mothers sing aloud, a youngster monkey shrieks: like a band of musicians and drummers daily they bash out a rhythm in the presence of Humbaba.\\"\\r\\nIn this version of the story, Humbaba is beloved of the gods and a kind of king in the palace of the forest. Monkeys are his heralds, birds his courtiers, and his entire throne room breathes with the heady aroma of cedar resin.[6]\\r\\nThe tablet goes on to portray Gilgamesh as an aggressor who destroys a forest unnecessarily, and his death is lamented by Enkidu.\\r\\nHumbaba is first mentioned in Tablet II of the Epic of Gilgamesh: after Gilgamesh and Enkidu become friends following their initial fight, they set out on an adventure to the Cedar Forest beyond the seventh mountain range, to slay Humbaba (Huwawa): \\"Enkidu,\\" Gilgamesh vows, \\"since a man cannot pass beyond the final end of life, I want to set off into the mountains, to establish my renown there.\\"[2] Gilgamesh tricks the monster into giving away his seven \\"radiances\\" by offering his sisters as wife and concubine. When Humbaba's guard is down, Gilgamesh punches him and captures the monster. Defeated, Humbaba appeals to a receptive Gilgamesh for mercy, but Enkidu convinces Gilgamesh to slay Humbaba. In a last effort, Humbaba tries to escape but is decapitated by Enkidu, or in some versions by both heroes together; his head is put in a leather sack, which is brought to Enlil, the god who set Humbaba as the forest's guardian. Enlil becomes enraged upon learning this and redistributes Humbaba's seven splendors (or in some tablets \\"auras\\"). \\"He gave Humbaba's first aura to the fields. He gave his second aura to the rivers. He gave his third aura to the reed-beds. He gave his fourth aura to the lions. He gave his fifth aura to the palace (one text has debt slaves). He gave his sixth aura to the forests (one text has the hills). He gave his seventh aura to Nungal.\\"[7] No vengeance was laid upon the heroes, though Enlil says, \\"He should have eaten the bread that you eat, and should have drunk the water that you drink! He should have been honored.\\"\\r\\nAs each gift was given by Gilgamesh, he received a \\"terror\\" (= \\"radiance\\") in exchange, from Humbaba. The seven gifts successively given by Gilgamesh were:[8]\\r\\nWhile Gilgamesh thus distracts and tricks this spirit of the cedar forest, the fifty unmarried young men he has brought on the adventure are felling cedar timber, stripping it of its branches and laying it \\"in many piles on the hillside,\\" ready to be taken away. Thus the adventure reveals itself in the context of a timber raid, bringing cedar wood to timberless Mesopotamia.\\r\\nAs his death approaches, and Gilgamesh is oppressed with his own mortality, the gods remind him of his great feats: \\"having fetched cedar, the unique tree, from its mountains, having killed Humbaba in the forest\\"[9]\\r\\nThe iconography of the apotropaic severed head of Humbaba, with staring eyes, flowing beard and wild hair, is well documented from the First Babylonian Dynasty, continuing into Neo-Assyrian art and dying away during the Achaemenid rule. The severed head of the monstrous Humbaba found a Greek parallel in the myth of Perseus[10] and the similarly employed head of Medusa, which Perseus placed in his leather sack.[11] Archaic Greek depictions of the gorgoneion render it bearded, an anomaly in the female Gorgon. Judith McKenzie detected Humbaba heads in a Nabatean tomb frieze at Petra.[12]","input":"How many splendors or ornaments does humbaba have?"},{"output":"The Choice","context":"Nicholas Charles Sparks (born December 31, 1965) is an American romance novelist and screenwriter. He has published nineteen novels and two non-fiction books. Several of his novels have become international bestsellers, and eleven of his romantic-drama novels have been adapted to film all with multimillion-dollar box office grosses.[1]\\r\\nSparks was born in Omaha, Nebraska and wrote his first novel, The Passing, in 1985, while a student at the University of Notre Dame. His first published work came in 1990, when he co-wrote with Billy Mills Wokini: A Lakota Journey to Happiness and Self-Understanding, which sold approximated 50,000 copies in its first year. In 1993, Sparks wrote his breakthrough novel The Notebook in his spare time while selling pharmaceuticals in Washington, D.C.. Two years later, his novel was discovered by literary agent Theresa Park who offered to represent him. The novel was published in October 1996 and made the New York Times best-seller list in its first week of release.\\r\\n\\r\\n\\r\\nNicholas Sparks was born on December 31, 1965 in Omaha, Nebraska to Patrick Michael Sparks, a future professor of business, and Jill Emma Marie Sparks (ne Thoene), a homemaker and an optometrist's assistant. Nicholas was the second of three children, with an older brother, Michael Earl \\"Micah\\" Sparks (born 1964), and a younger sister, Danielle \\"Dana\\" Sparks (1966ÿ2000), who died at the age of 33 from a brain tumor. Sparks has said that she was the inspiration for the main character in his novel A Walk to Remember.\\r\\nSparks was raised in the Roman Catholic faith,[2] and is of German, Czech, English, and Irish ancestry. He and his ex-wife are Catholics and are raising their children in the Catholic faith.[3]\\r\\nHis father pursued graduate studies at University of Minnesota and University of Southern California, one reason for his family's frequent moves. By the time Sparks was eight, he had lived in Watertown, Minnesota; Inglewood, California; Playa Del Rey, California and his mother's hometown of Grand Island, Nebraska for a year, during which his parents were separated. By 1974 his father became a professor of business at California State University, Sacramento, and the family settled in Fair Oaks, California.\\r\\nThe family remained there through Sparks' high school days, and in 1984, he graduated as the valedictorian of Bella Vista High School. After being offered a full sports scholarship for track and field, at the University of Notre Dame, Sparks accepted and enrolled, majoring in business finance. In 1988, while on spring break, he met his future wife, Cathy Cote of New Hampshire, and then concluded his early academic work by graduating from Notre Dame with honors. Sparks and Cote would be married on July 22, 1989, and they moved to New Bern, North Carolina. Prior to those milestones, however, Sparks had begun writing in his early college years.\\r\\nSparks decided to start writing based on a simple remark from his mother when he was 19 years old that introduced him to the possibility:\\r\\n'\\"Your problem is that you're bored. You need to find something to do...\\" Then she looked at me and said the words that would eventually change my life: \\"Write a book.\\" Until that moment, I had never considered writing. Granted, I read all the time, but actually sitting down and coming up with a story on my own? ...I was nineteen years old and had become an accidental author.[4]\\r\\nIn 1985, while at home for the summer between his freshman and sophomore years at Notre Dame, Sparks penned his first ÿ though never published ÿ novel entitled The Passing. He wrote another novel in 1989, also unpublished called The Royal Murders.\\r\\nAfter college, Sparks sought both work with publishers, and applied to law school, but was rejected in both attempts. He then spent the next three years trying other careers, including real estate appraisal, waiting tables, selling dental products by phone and starting his own manufacturing business.\\r\\nIn 1990, Sparks co-wrote a book with Billy Mills entitled Wokini: A Lakota Journey to Happiness and Self-Understanding,[5] a nonfiction book about a three-week trip Sparks and his brother took around the around the world, as well as their personal growth experiences during that time, and the influence of Lakota spiritual beliefs and practices. The book was published by Feather Publishing, Random House, and Hay House, and sales for this first book approximated 50,000 copies in its first year after release.[6]\\r\\nIn 1992, Sparks began selling pharmaceuticals, and in 1993 was transferred to Washington, D.C.. It was there that he wrote another novel in his spare time, The Notebook.[7] Two years later, he was discovered by literary agent Theresa Park, who picked The Notebook out of her agency's slush pile, liked it, and offered to represent him. In October 1995, Park secured a $1 million advance for The Notebook from Time Warner Book Group. The novel was published in October 1996 and made the New York Times best-seller list in its first week of release.\\r\\nWith the success of his first novel, he moved to New Bern, North Carolina. He subsequently wrote several international bestsellers, and several of his novels have been adapted as films: Message in a Bottle (1999), A Walk to Remember (2002), The Notebook (2004), Nights in Rodanthe (2008), Dear John (2010), The Last Song (2010), The Lucky One (2012), Safe Haven (2013), The Best of Me (2014), The Longest Ride (2015), and The Choice (2016). He has also sold the screenplay adaptations of True Believer and At First Sight. His 2016 novel, Two by Two, sold about 98,000 copies during the first week after release.[8][9] 11 of Nicholas Sparks' novels have been #1 New York Times Best Sellers.\\r\\nSparks and his then-wife Cathy lived together in New Bern, North Carolina with their three sons and twin daughters until 2014. On January 6, 2015, Sparks announced that he and Cathy had amicably separated. They subsequently divorced.[10]\\r\\nSparks donated $9,000,000 for a new, all-weather tartan track to New Bern High School along with his time to help coach the New Bern High School track team and a local club track team as a volunteer head coach.[11]\\r\\nSparks contributes to other local and national charities, as well, including the Creative Writing Program (MFA) at the University of Notre Dame by funding scholarships, internships and annual fellowships. In 2008, Entertainment Weekly reported that Sparks and his then-wife had donated \\"close to $10 million\\" to start a Christian, international, college-prep private school, The Epiphany School of Global Studies, which emphasizes travel and lifelong learning.[12][13] He was later sued by the headmaster of this school who accused Sparks of homophobia, racism and anti-semitism.[14] In his spare time, Sparks volunteers at his local retirement home.","input":"What is the most recent nicholas sparks movie?"},{"output":"Gateway Arch","context":"The tallest buildings in St. Louis, Missouri, include the 630-foot (190?m) Gateway Arch,[1] which is also the tallest accessible structure in Missouri and the tallest monument in a national park, rising 75 feet (23?m) higher than the Washington Monument.[1][Note 1][Note 2]\\r\\nThe tallest habitable building in the city is the 42-story One Metropolitan Square, completed in 1989. At 593 feet (181?m), it is the third-tallest building in Missouri and the second-tallest habitable building.[Note 1] Its tenants include architecture firm Hellmuth, Obata & Kassabaum (HOK), which designed the building.[2][3] The only other habitable buildings in St. Louis over 500 feet (150?m) are the One AT&T Center[4] and the Thomas F. Eagleton United States Courthouse.[5]\\r\\nNone of the city's buildings are among the 100 tallest in the United States.\\r\\n\\r\\n\\r\\nThe history of skyscrapers in St. Louis began with the 1850s construction of Barnum's City Hotel, a six-story building designed by architect George I. Barnett.[6] Until the 1890s, no building in St. Louis rose over eight stories, but construction in the city rose during that decade, due to the development of elevators and the use of steel frames.[7] The first building to use a steel frame in St. Louis was the Wainwright Building, a 10-story office building and one of the first modern skyscrapers. The building, which was designed by Louis Sullivan and Dankmar Adler, illustrates Sullivan's principle of \\"form follows function\\".[8] From 1864ÿ1894, the tallest building in St. Louis was the Old Courthouse, at a height of 192 feet (59?m).[9][10] Throughout the 1890s and into the 1900s, St. Louis saw construction move westward, especially that of office buildings. In 1914, the Railway Exchange Building was completed, which became the city's tallest building for many years.[7] The city then underwent a moderate building boom in the 1920s, leading to the planning of the Jefferson National Expansion Memorial in 1935.[7]\\r\\nRecent development of new St. Louis high-rises has not seen much progress. The planned McGowan Walsh Tower (MW Tower) was put on hold in 2007 as a result of the economic situation at the time.[11] If completed, the building would be the tallest building in both St. Louis and Missouri, at a height of over 1,000 feet (300?m) and 90 stories.[12] The Renaissance on Euclid, a planned 30-floor, $115 million condominium project[13] was later canceled.[14] The 26-story Lindell Condominiums were also canceled[15] as a result of a court ruling that the construction of high-rise buildings would not be permitted in the Central West End Historic District, where the complex was planned. The condos had already been approved when two residents filed suit to stop the plan.[16] In addition, the proposed Bottle District Residential Towers project were canceled as well. Architect Daniel Libeskind designed the three towers of the $290 million proposal, which would have boasted St. Louis's tallest building if it had been completed.[Note 3][17][18] Construction for the $70 million, 25-story, 300 feet (91?m) Roberts Tower began in 2009. As a result of economic issues, work on the tower stalled in January 2010, although it soon restarted.[19][20]\\r\\nSt. Louis is beginning to look upward again as a slew of proposals have come in with buildings that will be over 300 feet tall including the BPV 2 Tower and One Hundred.\\r\\nThis list ranks St. Louis skyscrapers that stand at least 250 feet (76?m) tall, based on standard height measurement. This includes spires and architectural details but does not include antenna masts. An equal sign (=) following a rank indicates the same height between two or more buildings. The \\"Year\\" column indicates the year in which a building was completed. The \\"Floors\\" column indicates floors above ground only.\\r\\nThis list ranks St. Louis skyscrapers based on their pinnacle height, which includes radio masts and antennas. As architectural features and spires can be regarded as subjective, some skyscraper enthusiasts prefer this method of measurement. Standard architectural height measurement, which excludes antennas in building height, is included for comparative purposes.\\r\\nThis lists buildings that are under construction, approved, or proposed in St. Louis and are planned to rise over 300 feet (91?m). A floor count of 20 stories is used in place of the 300-foot (91?m) limit if the building's proposed height has not yet been determined.\\r\\nThis lists buildings that once held the title of tallest building in St. Louis, based on standard height measurement.","input":"What's the tallest building in st louis?"},{"output":"in Simla","context":"\\r\\n\\r\\nShimla, Barnes court (Raj bhavan)[1]\\r\\n\\r\\nThe Simla Agreement (or Shimla Agreement) was signed between India and Pakistan on 2 July 1972 in Simla, the capital city of Indian state of Himachal Pradesh.[2] It followed from the Bangladesh Liberation war in 1971 that led to the independence of Bangladesh, which was earlier known as East Pakistan and was part of the territory of Pakistan. India entered the war as an ally of Bangladesh which transformed the war into an Indo-Pakistani War of 1971. The agreement was ratified by the Parliaments of both the nations in same year.[citation needed]\\r\\n\\r\\nThe agreement was the result of resolve of both the countries to \\"put an end to the conflict and confrontation that have hitherto marred their relations\\". It conceived the steps to be taken for further normalisation of mutual relations and it also laid down the principles that should govern their future relations.[3] However, this was not respected and aggression continued on both sides.[4]\\r\\n\\r\\nThe treaty was signed in Simla, India, by Zulfiqar Ali Bhutto, the President of Pakistan, and Indira Gandhi, the Prime Minister of India. The agreement also paved the way for diplomatic recognition of Bangladesh by Pakistan. Technically the document was signed on 0040 hours in the night of 3 July, despite this official documents are dated 2 July 1972.[3][5] Few major outcomes of the Simla Agreement are:\\r\\n\\r\\nThe agreement has not prevented the relationship between the two countries from deteriorating to the point of armed conflict, most recently in the Kargil War of 1999. In Operation Meghdoot of 1984 India seized all of the inhospitable Siachen Glacier region where the frontier had been clearly not defined in the agreement (possibly as the area was thought too barren to be controversial), this was considered as a violation of the Simla Agreement by Pakistan. Most of the subsequent deaths in the Siachen Conflict have been from natural disasters, e.g. avalanches in 2010, 2012 and 2016.\\r\\n\\r\\nSimla Agreement on Bilateral Relations between India and Pakistan signed by Prime Minister Indira Gandhi, and President of Pakistan, Z. A. Bhutto, in Simla on 2 July 1972.\\r\\n\\r\\nThe Government of India and the Government of Pakistan are resolved that the two countries put an end to the conflict and confrontation that have hitherto marred their relations and work for the promotion of a friendly and harmonious relationship and the establishment of durable peace in the subcontinent so that both countries may henceforth devote their resources and energies to the pressing task of advancing the welfare of their people.  \\r\\n\\r\\n\\r\\nIn order to achieve this objective, the Government of India and the Government of Pakistan have agreed as follows:  \\r\\n\\r\\n\\r\\n(i) That the principles and purposes of the Charter of the United Nations shall govern the relations between the two countries.  \\r\\n\\r\\n\\r\\n(ii) That the two countries are resolved to settle their differences by peaceful means through bilateral negotiations or by any other peaceful means mutually agreed upon between them. Pending the final settlement of any of the problems between the two countries, neither side shall unilaterally alter the situation and both shall prevent the organization, assistance or encouragement of any acts detrimental to the maintenance of peace and harmonious relations.  \\r\\n\\r\\n\\r\\n(iii) That the prerequisite for reconciliation, good neighborliness and durable peace between them is a commitment by both the countries to peaceful coexistence respect for each others territorial integrity and sovereignty and noninterference in each others internal affairs, on the basis of equality and mutual benefit. That the basic issues and causes of conflict which have bedeviled the relations between the two countries for the last 25 years shall be resolved by peaceful means.  \\r\\n\\r\\n\\r\\n(v) That they shall always respect each others national unity, territorial integrity, political independence and sovereign equality.  \\r\\n\\r\\n\\r\\n(vi) That in accordance with the Charter of the United Nations, they will refrain from the threat or use of force against the territorial integrity or political independence of each other. \\r\\n\\r\\n\\r\\nBoth governments will take all steps within their power to prevent hostile propaganda directed against each other. Both countries will encourage the dissemination of such information as would promote the development of friendly relations between them.  \\r\\n\\r\\n\\r\\nIn order progressively to restore and normalize relations between the two countries step by step, it was agreed that:  \\r\\n\\r\\n\\r\\n(i) Steps shall be taken to resume communications, postal, telegraphic, sea, land, including border posts, and air links, including over flights.  \\r\\n\\r\\n\\r\\n(ii) Appropriate steps shall be taken to promote travel facilities for the nationals of the other country.  \\r\\n\\r\\n\\r\\n(iii) Trade and cooperation in economic and other agreed fields will be resumed as far as possible.  \\r\\n\\r\\n\\r\\n(iv) Exchange in the fields of science and culture will be promoted. \\r\\n\\r\\n\\r\\nIn this connection delegations from the two countries will meet from time to time to work out the necessary details.  \\r\\n\\r\\n\\r\\nIn order to initiate the process of the establishment of durable peace, both the governments agree that:  \\r\\n\\r\\n\\r\\n(i) Indian and Pakistani forces shall be withdrawn to their side of the international border.  \\r\\n\\r\\n\\r\\n(ii) In Jammu and Kashmir, the line of control resulting from the ceasefire of December 17, 1971, shall be respected by both sides without prejudice to the recognized position of either side. Neither side shall seek to alter it unilaterally, irrespective of mutual differences and legal interpretations. Both sides further undertake to refrain from the threat or the use of force in violation of this line.  \\r\\n\\r\\n\\r\\n(iii) The withdrawals shall commence upon entry into force of this agreement and shall be completed within a period of 30 days thereof. \\r\\n\\r\\n\\r\\nThis agreement will be subject to ratification by both countries in accordance with their respective constitutional procedures, and will come into force with effect from the date on which the instruments of ratification are exchanged.  \\r\\n\\r\\n\\r\\nBoth governments agree that their respective heads will meet again at a mutually convenient time in the future and that in the meanwhile the representatives of the two sides will meet to discuss further the modalities and arrangements for the establishment of durable peace and normalization of relations, including the questions of repatriation of prisoners of war and civilian internees, a final settlement of Jammu and Kashmir and the resumption of diplomatic relations.\\r\\n\\r\\n\\r\\nZulfiqar Ali Bhutto\\r\\nPresident\\r\\nIslamic Republic of Pakistan\\r\\n\\r\\n\\r\\nIndira Gandhi\\r\\nPrime Minister\\r\\nIndia\\r\\n\\r\\n\\r\\nSimla, the 2 July 1972.\\r\\nThe Delhi Agreement on the Repatriation of War and Civilian Internees is a tripartite agreement among the aforementioned states, signed on 28 August 1973. The agreement was signed by Kamal Hossain, the Foreign Minister of the Government of Bangladesh, Sardar Swaran Singh, Minister of External Affairs of India and Aziz Ahmed, the Minister of State for Defense and Foreign Affairs of the Government of Pakistan.[8][9][10]","input":"Where was indo pak simla agreement 1972 conducted?"},{"output":"Yoshihiro Togashi","context":"Yoshihiro Togashi (??? đ, Togashi Yoshihiro, born April 27, 1966 in Shinj, Yamagata[1][2]) is a Japanese manga artist. He began drawing manga at an early age; while he attended college, the publishing company Shueisha recognized his talent. Togashi has authored numerous manga series in different genres during the past three decades. He is perhaps best known for writing and illustrating the YuYu Hakusho and Hunter G Hunter series, both of which have been published in the popular Weekly Shnen Jump magazine. Togashi is married to Naoko Takeuchi, the author of Sailor Moon.\\r\\n\\r\\n\\r\\nBorn in Shinj, Yamagata, Togashi began drawing manga casually in his first to second year of elementary school.[1][2][3] In high school, Togashi joined the fine-arts club; he later enrolled at Yamagata University where he studied education in the hope of becoming a teacher.[1] During college he submitted some of his manga work to Weekly Young Jump, published by Shueisha.[1][2] In 1986, at age 20, he authored a manga titled Buttobi Straight (ل̫, Buttobi Sutorto) for which he received the Tezuka Award, the most prestigious award for new comic artists in Japan.[3][4][5] Another manga by Togashi titled Jura no Mizuki (⁃¼͡ƽ) was an honorable mention in Shueisha's first annual Hop Step Award Selection magazine, published in 1988.[6] After having given up his goal of becoming a teacher, Togashi was contacted by an editor of Weekly Shnen Jump during his senior year of college, who asked him to move to Tokyo.[2]\\r\\nTogashi's earliest published works for Shueisha included kami Nante Kowakunai!! (ئϻئ!!, lit. I'm Not Afraid of the Wolf!!), a collection of comedy manga short-stories. Weekly Shnen Jump published some of the stories prior to a tankbon release in 1989. Between 1989 and 1990, Togashi authored Ten de Shwaru Cupid (ƥm??ƽ, lit. An Ill-tempered Cupid in Heaven), a four-volume romance manga involving the relationship between a normal, human boy and a beautiful, devil girl.\\r\\nIn 1990, Togashi made a name for himself with his next series YuYu Hakusho (L߽߆??, lit. Poltergeist Report). Based on his interests in the occult and in horror films, the plot features the character Yusuke Urameshi, who is killed and brought back to life as a \\"Underworld Detective\\". The manga, which lasted 175 chapters over 19 tankbon from 1990 to 1994, went on to sell over 50 million copies worldwide, earned Togashi a Shogakukan Manga Award in 1994, and received a hit anime adaptation.[7][8] In 1995, he created Level E (ìE), a science fiction-comedy manga. Comprising three volumes, it was first published in Weekly Shnen Jump in 1995 and ran until 1997.[9][10][11] Level E was adapted into an anime television series in 2011.[12]\\r\\nTogashi's next major series Hunter G Hunter (˦ΨG˦), an action-adventure manga, began serialization in 1998. The story revolves around the protagonist Gon Freecss, a young boy in search of his father, who is a legendary, elite member of society called a \\"Hunter\\". This manga also performed very well commercially, with the first 20 volumes selling nearly 55 million copies in Japan as of August 2011.[13] In 2008, Togashi tied with One Piece author Eiichiro Oda as the fifth favorite manga artist from a poll posted by the marketing research firm Oricon.[14]\\r\\nTogashi is married to Naoko Takeuchi, the manga artist of Sailor Moon.[1][2][4] The two were introduced at a party hosted by Kazushi Hagiwara in August 1997. The following year, Takeuchi assisted Togashi for short time by adding screentone to his manga Hunter G Hunter.[15] Togashi and Takeuchi were married on January 6, 1999. In attendance for the ceremony were several fellow manga artists and voice actors from both the Sailor Moon and YuYu Hakusho anime series.[16] The couple have two children and have collaborated on a children's book titled Oobo Nu Tochiibo Nu (إζвإζ), which Takeuchi wrote and Togashi illustrated.[3][17][18] Togashi is also one of the favorite artists of Masashi Kishimoto, the author of Naruto.[19]\\r\\nTogashi enjoys board-game-style video games and bowling with his family.[3] He also likes watching horror movies,[20] and considers Don't Look Up and Dawn of the Dead his favorites.[3] Togashi cites visual effects designer H. R. Giger as a major influence.[3] Togashi suffered from an immense amount of stress while working on YuYu Hakusho, which caused him inconsistent sleep patterns and chest pain.[21] Togashi has taken numerous breaks in recent years while writing Hunter G Hunter, the first of which was due to illness.[22][23][24][25][26][27] On March 29, 2011, Togashi and his fellow manga artist posted messages on the official Shnen Jump website in support of the victims of the 2011 Thoku earthquake and tsunami.[28] He has a younger brother named Hideaki Togashi, who is also a manga artist.","input":"Who is the writer of hunter x hunter?"},{"output":"plants","context":"The Columbian Exchange was the widespread transfer of plants, animals, culture, human populations, technology, and ideas between the Americas and the Old World in the 15th and 16th centuries, related to European colonization and trade after Christopher Columbus's 1492 voyage.[1] Invasive species, including communicable diseases, were a byproduct of the Exchange. The changes in agriculture significantly altered and changed global populations. However, the most significant immediate impact of the Columbian Exchange was the cultural exchanges and the transfer of people between continents.\\r\\nThe new contact between the global population circulated a wide variety of crops and livestock, which supported increases in population in both hemispheres, although diseases initially caused precipitous declines in the numbers of indigenous peoples of the Americas. Traders returned to Europe with maize, potatoes, and tomatoes, which became very important crops in Europe by the 18th century.\\r\\nThe term was first used in 1972 by American historian Alfred W. Crosby in his environmental history book The Columbian Exchange.[2] It was rapidly adopted by other historians and journalists and has become widely known.\\r\\n\\r\\n\\r\\nIn 1972 Alfred W. Crosby, an American historian at the University of Texas at Austin, published The Columbian Exchange.[2] This book covers the environmental impact of Columbus' landing in the new world.[3]\\r\\nThe term has become popular among historians and journalists, such as Charles C. Mann, whose book 1493 expands and updates Crosby's original research.[4]\\r\\nFour plants native to the Americas have spread around the world: Potato, maize, tomato, and tobacco.[5] Before 1500, potatoes were not grown outside of South America. By the 1840s, Ireland was so dependent on the potato that the proximate cause of the Great Famine was a potato disease.[6] Potatoes eventually became an important staple of the diet in much of Europe. Many European rulers, including Frederick the Great of Prussia and Catherine the Great of Russia, encouraged the cultivation of the potato.[7]\\r\\nMaize and cassava, introduced to the Portuguese from South America in the 16th century,[8] have replaced sorghum and millet as Africa's most important food crops.[9] 16th-century Spanish colonizers introduced new staple crops to Asia from the Americas, including maize and sweet potatoes, and thereby contributed to population growth in Asia.[10]\\r\\nTomatoes, which came to Europe from the New World via Spain, were initially prized in Italy mainly for their ornamental value (see below). From the 19th century tomato sauces became typical of Neapolitan cuisine and, ultimately, Italian cuisine in general.[11] Coffee (introduced in the Americas circa 1720) from Africa and the Middle East and sugarcane (introduced from South Asia) from the Spanish West Indies became the main export commodity crops of extensive Latin American plantations. Introduced to India by the Portuguese, chili and potatoes from South America have become an integral part of Indian cuisine.[12]\\r\\nBefore the Columbian Exchange, there were no oranges in Florida, no bananas in Ecuador, no paprika in Hungary, no potatoes in Ireland, no coffee in Colombia, no pineapples in Hawaii, no rubber trees in Africa, no chili peppers in Thailand, no tomatoes in Italy, and no chocolate in Switzerland.\\r\\nIt took three centuries after their introduction in Europe for tomatoes to become widely accepted. Of all the New World plants introduced to Italy, only the potato took as long as the tomato to gain acceptance. In large part this was due to 16th-century physicians believing that this native Mexican fruit was poisonous and the generator of \\"melancholic humours.\\" In 1544, Pietro Andrea Mattioli, a Tuscan physician and botanist, suggested that tomatoes might be edible, but no record exists of anyone consuming them at this time. On October 31, 1548 the tomato was given its first name anywhere in Europe when a house steward of Cosimo I de' Medici, Duke of Florence, wrote to the De' Medici's private secretary that the basket of pomi d'oro \\"had arrived safely.\\" At this time, the label pomi d'oro was also used to refer to figs, melons, and citrus fruits in treatises by scientists.[13]\\r\\nIn the early years, tomatoes were mainly grown as ornamentals in Italy. For example, the Florentine aristocrat Giovan Vettorio Soderini wrote how they \\"were to be sought only for their beauty\\" and were grown only in gardens or flower beds. Tomatoes were grown in elite town and country gardens in the fifty years or so following their arrival in Europe and were only occasionally depicted in works of art. However, in 1592 the head gardener at the botanical garden of Aranjuez near Madrid, under the patronage of Philip II of Spain wrote, \\"it is said [tomatoes] are good for sauces.\\" Besides this account, tomatoes remained exotic plants grown for ornamental purposes, but rarely for culinary use. The combination of pasta with tomato sauce was developed only in the late nineteenth century. Today around 32,000 acres (12,950?ha) of tomatoes are cultivated in Italy, although there are still areas where relatively few tomatoes are grown and consumed.[13]\\r\\nInitially, at least, the Columbian exchange of animals largely went through one route, from Europe to the New World, as the Eurasian regions had domesticated many more animals. Horses, donkeys, mules, pigs, cattle, sheep, goats, chickens, large dogs, cats and bees were rapidly adopted by native peoples for transport, food, and other uses.[14] One of the first European exports to the Americas, the horse, changed the lives of many Native American tribes in the mountains. They shifted to a nomadic lifestyle, as opposed to agriculture, based on hunting bison on horseback and moved down to the Great Plains. The existing Plains tribes expanded their territories with horses, and the animals were considered so valuable that horse herds became a measure of wealth.[15]\\r\\nStill, the effects of the introduction of European livestock on the environments and peoples of the New World were not always positive. In the Caribbean, the proliferation of European animals had large effects on native fauna and undergrowth and damaged conucos, plots managed by indigenous peoples for subsistence.[16]\\r\\nEuropean exploration of tropical areas was aided by the New World discovery of quinine, the first effective treatment for malaria. Europeans suffered from this disease, but some indigenous populations had developed at least partial resistance to it. In Africa, resistance to malaria has been associated with other genetic changes among sub-Saharan Africans and their descendants, which can cause sickle-cell disease.[1]:164\\r\\nBefore regular communication had been established between the two hemispheres, the varieties of domesticated animals and infectious diseases that jumped to humans, such as smallpox, were substantially more numerous in the Old World than in the New due to more extensive long-distance trade networks. Many had migrated west across Eurasia with animals or people, or were brought by traders from Asia, so diseases of two continents were suffered by all occupants. While Europeans and Asians were affected by the Eurasian diseases, their endemic status in those continents over centuries resulted in many people gaining acquired immunity.\\r\\nBy contrast, \\"Old World\\" diseases had a devastating effect when introduced to Native American populations via European carriers, as the people in the Americas had no natural immunity to the new diseases. Measles caused many deaths. The smallpox epidemics are believed to have caused the largest death tolls among Native Americans, surpassing any wars[17] and far exceeding the comparative loss of life in Europe due to the Black Death.[1]:164 It is estimated that upwards of 80ÿ95 percent of the Native American population died in these epidemics within the first 100ÿ150 years following 1492. Many regions in the Americas lost 100%.[1]:165 The beginning of demographic collapse on the North American continent has typically been attributed to the spread of a well-documented smallpox epidemic from Hispaniola in December 1518.[16] At that point in time, approximately only 10,000 indigenous people were still alive in Hispaniola.[16]\\r\\nSimilarly, yellow fever is thought to have been brought to the Americas from Africa via the Atlantic slave trade. Because it was endemic in Africa, many people there had acquired immunity. Europeans suffered higher rates of death than did African-descended persons when exposed to yellow fever in Africa and the Americas, where numerous epidemics swept the colonies beginning in the 17th century and continuing into the late 19th century. The disease caused widespread fatalities in the Caribbean during the heyday of slave-based sugar plantation.[16] The replacement of native forests by sugar plantations and factories facilitated its spread in the tropical area by reducing the number of potential natural predators.[16] Yet, the means of the transmission was unknown until 1881, when Carlos Finlay suggested that the disease was transmitted through mosquitoes, now known to be female mosquitoes of the species Aedes aegypti.[16]\\r\\nThe history of syphilis has been well-studied, but the exact origin of the disease is unknown and remains a subject of debate.[18] There are two primary hypotheses: one proposes that syphilis was carried to Europe from the Americas by the crew of Christopher Columbus in the early 1490s, while the other proposes that syphilis previously existed in Europe but went unrecognized.[19] These are referred to as the \\"Columbian\\" and \\"pre-Columbian\\" hypotheses.[19] The first written descriptions of the disease in the Old World came in 1493.[20] The first large outbreak of syphilis in Europe occurred in 1494/1495 in Naples, Italy, among the army of Charles VIII, during their invasion of Naples.[19][21][22][23]\\r\\nOne of the influences related to the migration of people were cultural exchanges. For example, in the article \\"The Myth of Early Globalization: The Atlantic Economy, 1500ÿ1800\\" Pieter Remmer makes the point that \\"from 1500 onward, a 'clash of cultures' had begun in the Atlantic\\".[24] This clash of culture transferred European values to indigenous cultures. For example, the emergence of private property in regions where there were little to no rights to lands, the concepts of monogamy and the nuclear family, the role of women and children in the family system, and the \\"superiority of free labor\\".[25] An example of this type of cultural exchange occurred during the 1500s in North America. When these early European colonizers first entered North America, they encountered fence-less lands which indicated to them that this land was unimproved. For these Europeans, they were seeking economic opportunities, therefore, land and resources were important for the success of the mission. When these colonizers entered North America they encountered a fully established culture of people called the Powhatan. The Powhatan farmers in Virginia scattered their farm plots within larger cleared areas. These larger cleared areas were a communal place for naturally growing and useful plants. As the Europeans viewed fences as \\"hallmarks of civilization\\" they set about transforming \\"the land into something more suitable for themselves\\".[26] In implementing their practices, the Europeans enslaved, murdered, and exploited indigenous populations. Furthermore, in cases of enslaved peoples (and in particular, enslaved Africans) the Europeans simultaneously implemented their value system while at the same time justifying enslaving people through a philosophy which reduced the enslaved people to property. Thus, the slave traders and some of the plantation owners used the concept of family to exploit and control the enslaved people. In other subtle ways, which had a large impact the cultural exchanges involved sharing practices and traditions. An example of this can be found in the tobacco industry.\\r\\nTobacco was one of the luxury goods which was spread as a direct result of the Columbian Exchange. As is discussed in regard to the trans-Atlantic slave trade, the tobacco trade increased demand for free labor and spread tobacco worldwide. In discussing the widespread uses of tobacco, the Spanish physician Nicolas Monardes (1493ÿ1588) noted that \\"The black people that have gone from these parts to the Indies, have taken up the same manner and use of tobacco that the Indians have\\".[27] As the European colonizers and enslaved Africans traveled the globe and came into contact with indigenous peoples, they took with them the cultural practices related to tobacco, and spread them to additional regions. Therefore, demand for tobacco grew in the course of the cultural exchanges and increased contacts among peoples.\\r\\nPlants that arrived by land, sea, or air in the times before 1492 are called archaeophytes, and plants introduced to Europe after those times are called neophytes. Invasive species of plants and pathogens also were introduced by chance, including such weeds as tumbleweeds (Salsola spp.) and wild oats (Avena fatua). Some plants introduced intentionally, such as the kudzu vine introduced in 1894 from Japan to the United States to help control soil erosion, have since been found to be invasive pests in the new environment.\\r\\nFungi have also been transported, such as the one responsible for Dutch elm disease, killing American elms in North American forests and cities, where many had been planted as street trees. Some of the invasive species have become serious ecosystem and economic problems after establishing in the New World environments.[28][29] A beneficial, although probably unintentional, introduction is Saccharomyces eubayanus, the yeast responsible for lager beer now thought to have originated in Patagonia.[30]\\r\\nIn addition to these, many animals were introduced to new habitats on the other side of the world either accidentally or incidentally. These include such animals as brown rats, earthworms (apparently absent from parts of the pre-Columbian New World), and zebra mussels, which arrived on ships.[31] Escaped and feral populations of non-indigenous animals have thrived in both the Old and New Worlds, often negatively impacting or displacing native species. In the New World, populations of feral European cats, pigs, horses and cattle are common, and Burmese pythons are considered problematic. In the Old World, Eastern gray squirrel have been particularly successful in colonising Great Britain and populations of raccoons can now be found in some regions of Germany, the Caucasus and Japan. Fur farm escapees such as coypu and American mink have extensive populations. Canada geese are also common.","input":"What type of goods were traded on the columbian exchange?"},{"output":"April 10, 1959","context":"Capital punishment for juveniles in the United States existed until March 1, 2005, when the U.S. Supreme Court banned it in Roper v. Simmons.\\r\\n\\r\\nSince 1642, in the Thirteen Colonies, the United States under the Articles of Confederation, and the United States under the Constitution, an estimated 364 juvenile offenders have been put to death by the individual states (colonies, before 1776) and the federal government. \\r\\n\\r\\nThe youngest person to be executed in the 20th century was George Stinney, electrocuted in South Carolina at the age of 14 on June 16, 1944. The second youngest person to be executed in the 20th century was Fortune Ferguson in 1927 for rape in Florida. The youngest person ever to be sentenced to death in the United States was James Arcene, a Native American, for his role in a robbery and murder committed when he was ten years old. He was, however, 23 years old when he was actually executed on June 18, 1885.[1]  The last execution of a juvenile was convicted murderer Leonard Shockley, who died in the Maryland gas chamber on April 10, 1959, at the age of 17. No one has been under the age of 19 at the time of execution since at least 1964.[2][3]\\r\\n\\r\\nSince the reinstatement of the death penalty in 1976[4] when the Supreme Court ruled that the death penalty did not violate the Eighth Amendment's prohibition against cruel and unusual punishment, 22 people have been executed for crimes committed while they were under the age of 18.  All of the 22 executed individuals were males.  Twenty-one of them were age 17 when the crime occurred; one, Sean Sellers (executed on February 4, 1999, in Oklahoma), was 16 years old when he murdered his mother, stepfather, and a store clerk.\\r\\n\\r\\nDue to the slow process of appeals since 1976, none was actually under the age of 18 at the time of execution.\\r\\n\\r\\nIn Thompson v. Oklahoma (1988), the U.S. Supreme Court first held unconstitutional imposition of the death penalty for crime committed aged 15 or younger. \\r\\n\\r\\nBut in the 1989 case Stanford v. Kentucky, it upheld capital punishment for crimes committed aged 16 or 17. Justice Scalia's plurality part of his opinion famously criticized Justice Brennans dissent by accusing it to \\"replace judges of the law with a committee of philosopher-kings\\".[5]\\r\\n\\r\\nJustice OConnor was the key vote in both cases, being the lone justice to concur in the two.\\r\\n\\r\\nSixteen years later, Roper v. Simmons overruled Stanford. Justice Kennedy, who concurred to Scalias opinion in Stanford, instead wrote the opinion of the court in Roper and became the key vote. Justice OConnor dissented.\\r\\n\\r\\nBefore 2005, of the 38 U.S. states that allow capital punishment:\\r\\n\\r\\nAt the time of the Roper v. Simmons decision, there were 71 juvenile offenders awaiting execution on death row: 13 in Alabama; four in Arizona; three in Florida; two in Georgia; four in Louisiana; five in Mississippi; one in Nevada; four in North Carolina; two in Pennsylvania; three in South Carolina; 29 in Texas; and one in Virginia.  Detailed summaries of each of these offenders can be found here.\\r\\n\\r\\n[6]In some ways the debate over the death penalty for juveniles is a curious one. Many have pointed out that historically, few juveniles have ever been executed for their crimes. Even when there have been juveniles sentenced to death, few if any executions have actually been carried out. The United States for example, youths under the age of 18 were executed at a rate of 20 to 27 per decade, or about 1.6 to 2.3 percent of all executions from 1880s to the 1920s. This has dropped significantly when only 3 juveniles were executed between January 1977 and November 1986.","input":"When was the last juvenile executed in the us?"},{"output":"Aeromarine Airways","context":"In-flight entertainment (IFE) refers to the entertainment available to aircraft passengers during a flight. In 1936, the airship Hindenburg offered passengers a piano, lounge, dining room, smoking room, and bar during the 2 1/2 day flight between Europe and America.[1] After the Second World War, IFE was delivered in the form of food and drink services, along with an occasional projector movie during lengthy flights. In 1985 the first personal audio player was offered to passengers, along with noise cancelling headphones in 1989.[2] During the 1990s the demand for better IFE was a major factor in the design of aircraft cabins. Before then, the most a passenger could expect was a movie projected on a screen at the front of a cabin, which could be heard via a headphone socket at his or her seat. Now, in most aircraft, private IFE TV screens are offered on most airlines.\\r\\nThe current European trend is to implement bring your own device systems that provide intranet connectivity, allowing the user to stream a predefined range of multimedia content. Following this trend, companies such as Immfly are advancing at a fast pace to deliver on-board entertainment on short-haul commercial flights.\\r\\nDesign issues for IFE include system safety, cost efficiency, software reliability, hardware maintenance, and user compatibility.\\r\\nThe in-flight entertainment onboard airlines is frequently managed by content service providers.\\r\\n\\r\\n\\r\\nThe first in-flight movie was in 1921 on Aeromarine Airways showing a film called Howdy Chicago to its passengers as the amphibious airplane flew around Chicago.[3] The film The Lost World was shown to passengers of an Imperial Airways flight in April 1925 between London (Croydon Airport) and Paris.[4]\\r\\nEleven years later in 1932, the first in-flight television called 'media event' was shown on a Western Air Express Fokker F.10 aircraft.[3]\\r\\nThe post-WWII British Bristol Brabazon airliner was initially specified with a 37-seat cinema within its huge fuselage; this was later reduced to a 23-seat cinema sharing the rear of the aircraft with a lounge and cocktail bar. The aircraft never entered service.[5]\\r\\nHowever, it was not until the 1960s that in-flight entertainment (other than reading, sitting in a lounge and talking, or looking out the window) was becoming mainstream and popular. In 1961, David Flexer of Inflight Motion Pictures developed the 16mm film system using a 25-inch reel for a wide variety of commercial aircraft. Capable of holding the entire film, and mounted horizontally to maximize space, this replaced the previous 30-inch-diameter film reels. In 1961, TWA committed to Flexer's technology and was first to debut a feature film in flight.[3] Interviewed by the New Yorker in 1962, Mr Flexner said, \\"an awful lot of ingenuity has gone into this thing, which started from my simply thinking one day, in flight, that air travel is both the most advanced form of transportation and the most boring.[6] Amerlon Productions, a subsidiary of Inflight, produced at least one film, Deadlier Than the Male, specifically for use on airplanes.\\r\\nIn 1963, AVID Airline Products developed and manufactured the first pneumatic headset used on board the airlines and provided these early headsets to TWA. These early systems consisted of in-seat audio that could be heard with hollow tube headphones.[3] In 1979 pneumatic headsets were replaced by electronic headsets. The electronic headsets were initially available only on selected flights and premium cabins whereas economy class still had to make do with the old pneumatic headsets.[citation needed] In the United States, the last airline to offer pneumatic headphones was Delta Air Lines, which switched to electronic headphones in 2003, despite the fact that all Delta aircraft equipped with in-flight entertainment since the Boeing 767-200 have included jacks for electronic headphones.\\r\\nThroughout the early to mid-1960s, some in-flight movies were played back from videotape, using early compact transistorized videotape recorders made by Sony (such as the SV-201 and PV-201) and Ampex (such as the VR-660 and VR-1500), and played back on CRT monitors mounted on the upper sides in the cabin above the passenger seats with several monitors placed a few seats apart from each other. The audio was played back through the headsets.\\r\\nIn 1971, TRANSCOM developed the 8mm film cassette. Flight attendants could now change movies in-flight and add short subject programming.\\r\\nIn the late 1970s and early 1980s, CRT-based projectors began to appear on newer widebody aircraft, such as the Boeing 767. These used LaserDiscs or video cassettes for playback. Some airlines upgraded the old film IFE systems to the CRT-based systems in the late 1980s and early 1990s on some of their older widebodies. In 1985, Avicom introduced the first audio player system, based on the Philips Tape Cassette technology. In 1988, the Airvision company introduced the first in-seat audio/video on-demand systems using 2.7 inches (69?mm) LCD technology for Northwest Airlines.[citation needed] The trials, which were run by Northwest Airlines on its Boeing 747 fleet, received overwhelmingly positive passenger reaction. As a result, this completely replaced the CRT technology.[citation needed]\\r\\nToday, in-flight entertainment is offered as an option on almost all wide body aircraft, while some narrow body aircraft are not equipped with any form of In-flight entertainment at all. This is mainly due to the aircraft storage and weight limits. The Boeing 757 was the first narrow body aircraft to widely feature both audio and video In-flight entertainment and today it is rare to find a Boeing 757 without an In-flight entertainment system. Most Boeing 757s feature ceiling-mounted CRT screens, although some newer 757s may feature drop-down LCDs or audio-video on demand systems in the back of each seat. Many Airbus A320 series and Boeing 737 Next Generation aircraft are also equipped with drop-down LCD screens. Some airlines, such as WestJet, United Airlines, and Delta Air Lines, have equipped some narrow body aircraft with personal video screens at every seat. Others, such as Air Canada and JetBlue, have even equipped some regional jets with AVOD.\\r\\nFor the introduction of personal TVs onboard jetBlue, company management tracked that lavatory queuing went far down. They originally had two planes, one with functioning IFE and one with none, the functioning one later was called \\"the happy plane\\".[7]\\r\\nOne major obstacle in creating an in-flight entertainment system is system safety. With the sometimes miles of wiring involved, voltage leaks and arcing become a problem. This is of more than theoretical concern. The IFE system was implicated in the crash of Swissair Flight 111 in 1998. To contain any possible issues, the in-flight entertainment system is typically isolated from the main systems of the aircraft. In the United States, for a product to be considered safe and reliable, it must be certified by the FAA and pass all of the applicable requirements found in the Federal Aviation Regulations. The concerning section, or title, dealing with the aviation industry and the electronic systems embedded in the aircraft, is CFR title 14 part 25. Contained inside Part 25 are rules relating to the aircraft's electronic system.[8]\\r\\nThere are two major sections of the FAA\\"s airworthiness regulations that regulate flight entertainment systems and their safety in transport category aircraft: 14 CFR 25.1301 which approves the electronic equipment for installation and use, by assuring that the system in question is properly labeled, and that its design is appropriate to its intended function.[9] 14 CFR 25.1309 states that the electrical equipment must not alter the safety or functionality of the aircraft upon the result of a failure.[10] One way for the intended IFE system to meet this regulatory requirement is for it to be independent from the aircraft's main power source and processor. By separating the power supplies and data links from that of the aircraft's performance processor, in the event of a failure the system is self-sustained, and can not alter the functionality of the aircraft. Upon a showing of compliance to all of the applicable U.S. regulations the in-flight entertainment system is capable of being approved in the United States. Certain U.S. design approvals for IFE may be directly accepted in other countries, or may be capable of being validated, under existing bilateral airworthiness safety agreements.\\r\\nThe companies involved are in a constant battle to cut costs of production, without cutting the system's quality and compatibility. Cutting production costs may be achieved by anything from altering the housing for personal televisions, to reducing the amount of embedded software in the in-flight entertainment processor. Difficulties with cost are also present with the customers, or airlines, looking to purchase in-flight entertainment systems. Most in-flight entertainment systems are purchased by existing airlines as an upgrade package to an existing fleet of aircraft. This cost can be anywhere from $2 million to $5 million for a plane to be equipped with a set of seat back LCD monitors and an embedded IFE system.[11] Some of the IFE systems are being purchased already installed in a new aircraft, such as the Airbus A320,[12] which eliminates the possibility of having upgrade difficulties. Some airlines are passing the cost directly into the customers ticket price, while some are charging a user fee based on an individual customers use. Some are also attempting to get a majority of the cost paid for by advertisements on, around, and in their IFE.\\r\\nThe largest international airlines sometimes pay more than $90,000 for a licence to show one movie over a period of two or three months. These airlines usually feature up to 100 movies at once, whereas 20 years ago they would have only 10 or 12. In the United States, airlines pay a flat fee every time the movie is watched by a passenger. Some airlines spend up to $20 million per year on content.[13]\\r\\nSoftware for In-flight entertainment systems should be aesthetically pleasing, reliable, compatible, and also must be user friendly. These restrictions account for expensive engineering of individually specific software. In-flight entertainment equipment is often touch screen sensitive, allowing interaction between each seat in the aircraft and the flight attendants, which is wireless in some systems.[citation needed] Along with a complete aircraft intranet to deal with, the software of the in-flight entertainment system must be reliable when communicating to and from the main In-flight entertainment processor. These additional requirements not only place an additional strain on the software engineers, but also on the price. Programming errors can slip through the testing phases of the software and cause problems.[14]\\r\\nA moving-map system is a real-time flight information video channel broadcast through to cabin project/video screens and personal televisions (PTVs). In addition to displaying a map that illustrates the position and direction of the plane, the system gives the altitude, airspeed, outside air temperature, distance to the destination, distance from the origination point, and local time. The moving-map system information is derived in real time from the aircraft's flight computer systems.[15]\\r\\nThe first moving-map system designed for passengers was named Airshow and introduced in 1982.[16] It was invented by Airshow Inc (ASINC), a small southern California corporation, which later became part of Rockwell Collins. KLM and Swissair were the first airlines to offer the moving map systems to their passengers.\\r\\nThe latest versions of moving-maps offered by IFE manufacturers include AdonisOne IFE, ICARUS Moving Map Systems, Airshow 4200 by Rockwell Collins, iXplor2 by Panasonic Avionics and JetMap HD by Honeywell Aerospace. In 2013, Betria Interactive unveiled FlightPath3D, a fully interactive moving-map that enables passengers to zoom and pan around a 3D world map using touch gestures, similar to Google Earth.[17] FlightPath3D was chosen by Norwegian as the moving-map on their new fleet of Boeing 787 Dreamliners, running on Panasonic's Android based touch-screen IFE system.[18]\\r\\nAfter the attempted Christmas Day bombing of 2009, the United States Transportation Security Administration (TSA) briefly ordered the live-map shut-off on international flights landing in the United States. Some airlines complained that doing so may compel the entire IFE system to remain shut. After complaints from airlines and passengers alike, these restrictions were eased.\\r\\nAudio entertainment covers music, as well as news, information, and comedy. Most music channels are pre-recorded and feature their own DJs to provide chatter, song introductions, and interviews with artists. In addition, there is sometimes a channel devoted to the plane's radio communications, allowing passengers to listen in on the pilot's in-flight conversations with other planes and ground stations.\\r\\nIn audio-video on demand (AVOD) systems, software such as MusicMatch is used to select music off the music server. Phillips Music Server is one of the most widely used servers running under Windows Media Center used to control AVOD systems.\\r\\nThis form of in-flight entertainment is experienced through headphones that are distributed to the passengers. The headphone plugs are usually only compatible with the audio socket on the passenger's armrest (and vice versa), and some airlines may charge a small fee to obtain a pair. The headphones provided can also be used for the viewing of personal televisions.\\r\\nIn-flight entertainment systems have been made compatible with XM Satellite Radio and with iPods, allowing passengers to access their accounts or bring their own music, along with offering libraries of full audio CDs from an assortment of artists.[19]\\r\\nVideo entertainment is provided via a large video screen at the front of a cabin section, as well as smaller monitors situated every few rows above the aisles. Sound is supplied via the same headphones as those distributed for audio entertainment.\\r\\nHowever, personal televisions (PTVs) for every passenger provide passengers with channels broadcasting new and classic films, as well as comedies, news, sports programming, documentaries, children's shows, and drama series. Some airlines also present news and current affairs programming, which are often pre-recorded and delivered in the early morning before flights commence.\\r\\nPTVs are operated via an In flight Management System which stores pre-recorded channels on a central server and streams them to PTV equipped seats during flight. AVOD systems store individual programs separately, allowing a passenger to have a specific program streamed to them privately, and be able to control the playback.\\r\\nSome airlines also provide video games as part of the video entertainment system. For example, Singapore Airlines passengers on some flights have access to a number of Super Nintendo games as part of its KrisWorld entertainment system. Also Virgin America's and V Australia's new RED Entertainment System offers passengers internet gaming over a Linux-based operating system.[20]\\r\\nSome airlines have now installed personal televisions (otherwise known as PTVs) for every passenger on most long-haul routes. These televisions are usually located in the seat-backs or tucked away in the armrests for front row seats and first class. Some show direct broadcast satellite television which enables passengers to view live TV broadcasts. Some airlines also offer video games using PTV equipment. Fewer still provide closed captioning for deaf and hard-of-hearing passengers.\\r\\nAudio-video on demand (AVOD) entertainment has also been introduced. This enables passengers to pause, rewind, fast-forward, or stop a program that they have been watching. This is in contrast to older entertainment systems where no interactivity is provided for. AVOD also allows the passengers to choose among movies stored in the aircraft computer system.\\r\\nIn addition to the personal televisions that are installed in the seatbacks, a new portable media player (PMP) revolution is under way.[when?] There are two types available: commercial off the shelf (COTS) based players and proprietary players. PMPs can be handed out and collected by the cabin crew, or can be \\"semi-embedded\\" into the seatback or seat arm. In both of these scenarios, the PMP can pop in and out of an enclosure built into the seat, or an arm enclosure. An advantage of PMPs is that, unlike seatback PTVs, equipment boxes for the inflight entertainment system do not need to be installed under the seats, since those boxes increase the weight of the aircraft and impede legroom.\\r\\nPersonal on-demand videos are stored in an aircraft's main in-flight entertainment system, from whence they can be viewed on demand by a passenger over the aircraft's built in media server and wireless broadcast system. Along with the on-demand concept comes the ability for the user to pause, rewind, fast forward, or jump to any point in the movie. There are also movies that are shown throughout the aircraft at one time, often on shared overhead screens or a screen in the front of the cabin. More modern aircraft are now allowing Personal Electronic Devices (PED's) to be used to connect to the on board in-flight entertainment systems.[citation needed]\\r\\nRegularly scheduled in flight movies began to premiere in 1961 on flights from New York to Los Angeles.[21]\\r\\nClosed captioning technology for deaf and hard-of-hearing passengers started in 2008 with Emirates Airlines. The captions are text streamed along with video and spoken audio and enables passengers to either enable or disable the subtitle/caption language. Closed captioning is capable of streaming various text languages, including Arabic, Chinese, English, French, German, Hindi, Spanish, and Russian. The technology is currently based on Scenarist file multiplexing so far; however, portable media players tend to use alternative technologies. A WAEA technical committee is trying to standardize the closed caption specification. In 2009, the US Department of Transportation ruled a compulsory use of captions of all videos, DVDs, and other audio-visual displays played for safety and/or informational purposes in aircraft should be high-contrast captioned (e.g., white letters on a consistent black background [14 CFR Part 382/ RIN 2105ÿAD41 /OST Docket No. 2006ÿ23999]). As of 2013, several airlines, including\\r\\nhave closed-captioning provided on their AVOD systems.\\r\\nVideo games are another emerging facet of in-flight entertainment. Some game systems are networked to allow interactive playing by multiple passengers. Later generations of IFE games began to shift focus from pure entertainment to learning. The best examples of this changing trend are the popular trivia game series and the Berlitz Word Traveler that allows passengers to learn a new language in their own language. Appearing as a mixture of lessons and mini games, passengers can learn the basics of a new language while being entertained. Many more learning applications continue to appear in the IFE market.\\r\\nIn several airlines from the Muslim world the AVOD systems provide Qibla directions to allow Muslims to pray toward Mecca (e.g. Emirates, Etihad, Malaysia Airlines, Qatar Airways, Royal Jordanian and Saudia); Malaysia Airlines has built-in Qur'an e-books and Garuda Indonesia has a unique Qur'an channel.\\r\\nSeveral Islamic airlines may also switch to a pre-flight Qur'an prayer prior to taking off, like Egypt Air, Etihad, Jazeera Airways, Kuwait Airways, Pakistan International Airlines, Royal Brunei, and Saudia.\\r\\nIn recent years, IFE has been expanded to include in-flight connectivityservices such as Internet browsing, text messaging, cell phone usage (where permitted), and emailing. In fact, some in the airline industry have begun referring to the entire in-flight-entertainment category as \\"IFEC\\" (In-Flight Entertainment and Connectivity or In-Flight Entertainment and Communication).\\r\\nThe airline manufacturer Boeing entered into the in-flight-connectivity industry in 2000 and 2001 with an offshoot called Connexion by Boeing. The service was designed to provide in-flight broadband service to commercial airlines; Boeing built partnerships with United Airlines, Delta, and American. By 2006, however, the company announced it was closing down its Connexion operation. Industry analysts cited technology, weight, and cost issues as making the service unfeasible at the time. The Connexion hardware that needed to be installed on an aircraft, for example, weighed nearly 1,000 pounds (450?kg), which added more \\"drag\\" (a force working against the forward movement of the plane) and weight than was tolerable for the airlines.\\r\\nSince the shuttering of Connexion by Boeing, several new providers have emerged to deliver in-flight broadband to airlinesnotably Row 44, OnAir and AeroMobile (who offer satellite-based solutions), and Aircell (which offers air-to-ground connectivity via a cellular signal).\\r\\nIn the past few years, many US commercial airlines have begun testing and deploying in-flight connectivity for their passengers, such as Alaska Airlines, American, Delta, and United. Industry expectations were that by the end of 2011, thousands of planes flying in the US will offer some form of in-flight broadband to passengers. Airlines around the world are also beginning to test in-flight-broadband offerings as well.\\r\\nSome airlines provide satellite telephones integrated into their system. These are either found at strategic locations in the aircraft or integrated into the passenger remote control used for the individual in-flight entertainment. Passengers can use their credit card to make phone calls anywhere on the ground. A rate close to US$10.00/minute is usually charged regardless of where the recipient is located and a connection fee may be applied even if the recipient does not answer. These systems are usually not capable of receiving incoming calls. There are also some aircraft that allow faxes to be sent and the rate is usually the same as the call rate, but at a per page rate. Some systems also allow the transmission of SMS.\\r\\nMore modern systems allow passengers to call fellow passengers located in another seat by simply keying in the recipient's seat number.\\r\\nIFE producers have begun to introduce Intranet type systems. Virgin America's and V Australia's RED Entertainment System allows for passengers to chat amongst one another, compete against each other in the provided games, talk to the flight attendants and request, and pay for in advance, food or drinks, and have full access to the internet and email.\\r\\nSeveral airlines are testing in-cabin wi-fi systems.[26] In-flight internet service is provided either through a satellite network or an air-to-ground network.[27] In the Airbus A380 aircraft, data communication via satellite system allows passengers to connect to live Internet from the individual IFE units or their laptops via the in-flight Wi-Fi access.[28]\\r\\nBoeing's cancellation of the Connexion by Boeing system in 2006 caused concerns that inflight internet would not be available on next-generation aircraft such as Qantas' fleet of Airbus A380s and Boeing Dreamliner 787s. However, Qantas announced in July 2007 that all service classes in its fleet of A380s would have wireless internet access as well as seat-back access to email and cached web browsing when the Airbuses started operations in October 2008. Certain elements were also retrofitted into existing Boeing 747-400s.[29]\\r\\nSixteen major U.S. airlines now offer Wi-Fi connectivity service on their aircraft. The majority of these airlines use the service provided by Gogo Wi-Fi service. The service allows for Wi-Fi enabled devices to connect to the Internet. Delta currently has the most Wi-Fi equipped fleet with 500 aircraft that now offer in-flight Wi-Fi.[30]\\r\\nAs a general rule, mobile phone use while airborne is usually not just prohibited by the carrier but also by regulatory agencies in the relevant jurisdiction (e.g. FAA and FCC in the US). However, with added technology, some carriers nonetheless allow the use of mobile phones on selected routes.\\r\\nEmirates became the first airline to allow mobile phones to be used during flight. Using the systems supplied by telecom company AeroMobile, Emirates launched the service commercially on 20 March 2008.[31] Installed first on an Airbus A340-300, AeroMobile is presently operating on Emirates A340, A330, and B777 aircraft.[32] Emirates planned to roll out the system over their entire fleet by 2010.\\r\\nRyanair had previously aimed to become the first airline to enable mobile phone usage in the air, but instead ended up launching its system commercially in February 2009.[33] The system is set up on 22 737-800 jets based at Dublin Airport and was fitted on Ryanair's 200+ fleet off 737-800 jets by 2010.\\r\\nOnAir offers inflight mobile connectivity to a range of airlines through its GSM network. The GSM network connects to the ground infrastructure via an Inmarsat SwiftBroadband satellite which provides consistent global coverage.\\r\\nMost airlines have their own brand for its in-flight entertainment system to differentiate themselves. Amongst them are:","input":"What airline was the first to offer in-flight movies to their 1st class passengers?"},{"output":"1890s","context":"The automotive industry in the United States began in the 1890s and, as a result of the size of the domestic market and the use of mass-production, rapidly evolved into the largest in the world. However, the United States was overtaken as the largest automobile producer by Japan in the 1980s, and subsequently by China in 2008. The U.S. is currently second among the largest manufacturer in the world by volume, with approximately 8-10 million manufactured annually. Notable exceptions were 5.7 million automobiles manufactured in 2009 (due to crisis), and peak production levels of 13-15 million units during the 1970s and early 2000s.[1][2][3]\\r\\nThe motor vehicle industry began with hundreds of manufacturers, but by the end of the 1920s it was dominated by three large companies: General Motors, Ford, and Chrysler, all based in Metro Detroit. After the Great Depression and World War II, these companies continued to prosper, and the U.S. produced nearly three quarters of all automobiles in the world by 1950 (8,005,859 of 10,577,426).[2][3] Beginning in the 1970s, a combination of high oil prices and increased competition from foreign auto manufacturers severely affected the companies. In the ensuing years, the companies periodically bounced back, but by 2008 the industry was in turmoil due to the aforementioned crisis. As a result, General Motors and Chrysler filed for bankruptcy reorganization and were bailed out with loans and investments from the federal government. But according to Autodata Corp, June 2014 seasonally adjusted annualized sales is the biggest in history with 16.98 million vehicles and toppled previous record in July 2006.[4]\\r\\nPrior to the 1980s, most manufacturing facilities were owned by the Big Three (GM, Ford, Chrysler) and AMC. Their U.S. market share has dropped steadily as numerous foreign-owned car companies have built factories in the U.S.\\r\\nToyota had 31,000 direct employees in the U.S. in 2012, meaning a total payroll of about $2.1 billion, compared to Ford's 80,000 U.S. employees supplying their 3,300 dealerships and Chrysler's 71,100 U.S. employees supplying their 2,328 dealerships.[5]\\r\\n\\r\\n\\r\\nThe development of self-powered vehicles was accompanied by numerous technologies and components giving rise to numerous supplier firms and associated industries. Various types of energy sources were employed by early automobiles including steam, electric, and gasoline. Thousands of entrepreneurs were involved in developing, assembling, and marketing of early automobiles on a small and local scale. Increasing sales facilitated production on a larger scale in factories with broader market distribution. Ransom E. Olds and Thomas B. Jeffery began mass production of their automobiles. Henry Ford focused on producing an automobile that many middle class Americans could afford.\\r\\nOriginally purchased by wealthy individuals, by 1916 cars began selling at $875. Soon, the market widened with the mechanical betterment of the cars, the reduction in prices, as well as the introduction of installment sales and payment plans. During the period from 1917 to 1926, the annual rate of increase in sales was considerably less than from 1903 to 1916. In the years 1918, 1919, 1921, and 1924 there were absolute declines in automotive production. The automotive industry caused a massive shift in the industrial revolution because it accelerated growth by a rate never before seen in the U.S. economy. The combined efforts of innovation and industrialization allowed the automotive industry to take off during this period and it proved to be the backbone of United States manufacturing during the 20th century.[6]\\r\\nThe practicality of the automobile was initially limited because of the lack of suitable roads. Travel between cities was mostly done by railroad, waterways, or carriages. Roads were mostly dirt and hard to travel, particularly in bad weather. The League of American Wheelman maintained and improved roads as it was viewed as a local responsibility with limited government assistance. During this time, there was an increase in production of automobiles coupled with a swell of auto dealerships, marking their growth in popularity.\\r\\nState governments began to use the corvee system to maintain roads, an implementation of required physical labor on a public project on the local citizens. Part of their motivation was the needs of farmers in rural areas attempting to transport their goods across rough, barely functioning roads (article).\\r\\nThe other reason was the weight of the wartime vehicles. The materials involved altered during World War I to accommodate the heavier trucks on the road and were responsible for widespread shift to macadam highways and roadways. However, rural roads were still a problem for military vehicles, so four wheel drive was developed by automobile manufacturers to assist in powering through. As the prevalence of automobiles grew, it became clear funding would need to improve as well and the addition of government financing reflected that change.\\r\\nThe Federal Aid Road Act of 1916 allocated $75 million for building roads. It was also responsible for approving a refocusing of military vehicles to road maintenance equipment. It was followed by the Federal Aid Highway Act of 1921 provided additional funding for road construction. By 1924, there were 31,000 miles of paved road in the U.S.[8]\\r\\nAbout 3,000 automobile companies have existed in the United States.[9] In the early 1900s, the U.S. saw the rise of the Big Three automakers; Ford, GM, and Chrysler. In the late 19th century Thorstein Veblen introduced his Theory of the Leisure Class which introduced conspicuous consumption and demonstrated that wealth was the basis for social status. Ford and General Motors each played a role in their target market and what social status each consumer belonged to.\\r\\nHenry Ford began building cars in 1896 and started his own company in 1903. The Ford Motor Company improved mass-production with the first conveyor belt-based assembly line in 1913, producing the Model T (which had been introduced in 1908). These assembly lines significantly reduced costs. The first models were priced at $850, but by 1924 had dropped to $290. The Model T sold extremely well and Ford became the largest automobile company in the U.S. By the time it was retired in 1927, more than 15 million Model Ts had been sold. Ford introduced the Model A in 1927 (after a six-month production stoppage to convert from the Model T), and produced it through 1931. However, while the Model A was successful, Ford lost ground to GM and eventually Chrysler, as auto buyers looked to more upscale cars and newer styling. Ford was also a pioneer in establishing foreign manufacturing facilities, with production facilities created in England in 1911, and Germany and Australia in 1925. Ford purchased the luxury Lincoln automaker in 1922 and established the Mercury division in 1938.\\r\\nGeneral Motors Corporation (GM), the company that would soon become the world's largest automaker, was founded in 1908 by William Durant. Durant had previously been a carriage maker, and had taken control of Buick in 1904. The company initially acquired Buick, Oldsmobile and Oakland (later to become Pontiac) in 1908. The next year GM acquired Cadillac, along with a number of other car companies and parts suppliers. Durant also was interested in acquiring Ford, but after initial merger talks, Henry Ford decided to keep his company independent. In 1910, Durant lost control of GM after over-extending the company with its acquisitions. A group of banks took over control of GM and ousted Durant. Durant and Louis Chevrolet founded Chevrolet in 1913 and it quickly became very successful. Durant began acquiring stock in GM and by 1915 had majority control. Chevrolet was acquired by GM in 1917 and Durant was back in charge of GM. In 1921, Durant was again forced out of the company. During the late 1920s, General Motors overtook Ford to become the largest automaker. Under the leadership of Alfred P. Sloan, General Motors instituted decentralized management and separate divisions for each price class. They also introduced annual model changes. GM also became an innovator in technology under the leadership of Charles F. Kettering. GM followed Ford by expanding overseas, including purchasing England's Vauxhall Motors in 1925, Germany's Opel in 1929, and Australia's Holden in 1931. GM also established GMAC (now Ally Financial) in 1919 to provide credit for buyers of its cars.\\r\\nWalter Chrysler was formerly president of Buick and an executive of GM. After leaving GM in 1920, he took control of the Maxwell Motor Company, revitalized the company and, in 1925, reorganized it into Chrysler Corporation. He then acquired Dodge Brothers in 1927. The acquisition of Dodge gave Chrysler the manufacturing facilities and dealer network that it needed to significantly expand production and sales. In 1928, Chrysler introduced the Plymouth and DeSoto brands. Chrysler also overtook Ford to become the second largest auto maker by the 1930s, following similar strategies as General Motors.\\r\\nGeneral Motors wanted automobiles to be status symbols and illustrate a defined social class structure. Thorstein Veblen refers to conspicuous consumption as spending money on luxury goods and services to display power or social status. Through offering different makes and models they offered different levels in social status meeting the demands of consumers needing to display wealth.\\r\\nFord and General Motors each had their own impact on social status and the type of market they were targeting. Henry Ford focused on delivery one product for the masses. Fords focus was one car, one color, all for one price. He not only manufactured a product for the masses, but he provided a $5 a day wage so that there was a market to buy this product. In doing these things he eliminated the social status that went along with owning a car. The contrast of that is General Motors offered a product that catered to those looking to gain status by having that sense of individualism and offering different make, models, and quality.[10]\\r\\nThe 1930s saw the demise of many auto makers due to the economic effects of the Great Depression, stiff competition from the Big Three, and/or mismanagement. Luxury car makers were particularly affected by the economy, with companies like Stutz Motor Company, Pierce-Arrow Motor Car Company, Peerless Motor Company, Cunningham, and the Marmon Motor Car Company going out of business. The decade also saw several companies with innovative engineering, such as the Doble Steam Motors Corporation (advanced steam engines) and Franklin Automobile Company (air-cooled aluminium engines) going out of business. Errett Lobban Cord, who controlled the Auburn Automobile Company (which also sold the Cord) and the Duesenberg Motor Company, was under investigation by the Securities and Exchange Commission and the Internal Revenue Service. His auto empire collapsed in 1937 and production ceased.\\r\\nMajor technological innovations were introduced or were widely adopted during the 1930s, such as synchromesh manual transmissions, semi-automatic transmissions, automatic transmissions, hydraulic brakes, independent front suspension, and overhead-valve engines. The Cord 810 used front-wheel drive, had hidden headlights, and was offered with a supercharger. Exterior styling designs were more flowing, as shown most noticeably on the Auburn Speedster and the Cord 810/812. Radical air-streamed design was introduced on the Chrysler Airflow, a sales flop, and the Lincoln-Zephyr (both of which used unit-body construction). Packard introduced their \\"Air Cool-ditioned\\" car in 1940.\\r\\nWhen the U.S. entered World War II, all domestic passenger automobile production ceased by February 1942. The industry received $10 billion in war-related orders by that month, compared to $4 billion before the attack on Pearl Harbor. All factories were enlarged and converted, many new ones such as Ford's Willow Run and Chrysler's Detroit Arsenal Tank Plant were built, and hundreds of thousands more workers were hired to produce war material such as armaments, aircraft, and military vehicles. Experts anticipated that Detroit would learn advanced engineering methods from the aviation industry that would result in great improvements for postwar civilian automobiles.[11] These factories produced an astonishing amount of material, including 5.9 million weapons, 2.8 million tanks and trucks, and 27,000 aircraft. This production was a major factor in the victory of the allies.\\r\\nDue to the difficult working conditions in the auto production plants, auto workers began to seek representation to help improve conditions and ensure fair pay. The United Automobile Workers union won recognition from GM and Chrysler in 1937, and Ford in 1941. In 1950, the automakers granted workers a company-paid pension to those 65 years old and with 30 years seniority. In the mid-1950s, the automakers agreed to set up a trust fund for unemployed auto workers. In 1973, the automakers agreed to offer pensions to any worker with 30 years seniority, regardless of age. By then the automakers had also agreed to cover the entire health insurance bill for its employees, survivors, and retirees.\\r\\nThe only major auto companies to survive the Great Depression were General Motors Corporation, Ford Motor Company, Chrysler Corporation, Hudson Motor Car Company, Nash-Kelvinator Corporation, Packard Motor Car Company, Studebaker Corporation, and Crosley Motors. The former three companies, known as the Big Three, enjoyed significant advantages over the smaller independent auto companies due to their financial strength, which gave them a big edge in marketing, production, and technological innovation. Most of the Big Three's competitors ended production by the 1960s, and their last major domestic competitor was acquired in the 1980s.\\r\\nCrosley Motors ceased auto production in 1952. Packard and Studebaker merged in 1954, but ended production of Packard-branded cars in 1958 and ceased all auto production in 1966.\\r\\nKaiser-Frazer Corporation was started in 1945 and acquired Willys-Overland Motors (maker of the Jeep) in 1953. Production of passenger cars was discontinued in 1955. In 1970, the company was sold to American Motors.\\r\\nIn 1954, Nash-Kelvinator and Hudson merged to form American Motors (AMC). The company introduced numerous product and marketing innovations, but its small size made it difficult to compete with the Big Three and struggled financially. The French auto maker Renault took control of AMC in the early 1980s, but financial difficulties continued and AMC was purchased by Chrysler Corporation in 1987.\\r\\nPeriodically, other entrepreneurs would found automobile companies, but most would soon fail and none achieved major sales success. Some of the best known included Preston Tucker's 1948 sedan, Earl Muntz's Muntz Car Company, Malcolm Bricklin's Bricklin SV-1, the modern Stutz Blackhawk, Clnet Coachworks, Zimmer, Excalibur, and John DeLorean's DMC-12.\\r\\nInitial auto production after the WWII was slowed by the retooling process, shortages of materials, and labor unrest. However, the American auto industry reflected the post-war prosperity of the late-1940s and the 1950s. Cars grew in overall size, as well as engine size during the 1950s. The Overhead valve V-8 engine developed by GM in the late-1940s proved to be very successful and helped ignite the horsepower race, the second salvo of which was Chrysler's 1951 Hemi engine. Longer, lower, and wider tended to be the general trend. Exterior styling was influenced by jets and rockets as the space-age dawned. Rear fins were popular and continued to grow larger, and front bumpers and taillights were sometimes designed in the shape of rockets. Chrome plating was very popular, as was two-tone paint. The most extreme version of these styling trends were found in the 1959 Cadillac Eldorado and Chrysler Corporation's 1957 Imperial. The Chevrolet Corvette and the Ford Thunderbird, introduced in 1953 and 1955 respectively, were designed to capture the sports car market. However, the Thunderbird grew in size in 1958 and evolved into a personal luxury car. The 1950s were also noted for perhaps one of the biggest miscues in auto marketing with the Ford Edsel, which was the result of unpopular styling and being introduced during an economic recession.\\r\\nThe introduction of the Interstate Highway System[12] and the suburbanization of America made automobiles more necessary[13] and helped change the landscape and culture in the United States. Individuals began to see the automobile as an extension of themselves.[14]\\r\\nBig changes were taking place in automobile development in the 1960s, with the Big Three dominating the industry. Meanwhile, with the passage of the $33 billion Federal Aid Highway Act of 1956, a network of regional and interstate roads continued to enhance transportation. As urban areas became more congested, more families migrated to the suburbs. Between 1960 and 1970, 70 percent of the population's growth occurred in the suburbs.[15]\\r\\nImported vehicles grew during the 1950s and 1960s - from a very low base. In 1966, the Big Three (GM, Ford, Chrysler) had market share of 89.6% (44.5% in 2014).[16] From 1966 to 1969, net imports increased at an average annual rate of 84%.[17] The Volkswagen Beetle was the biggest seller.\\r\\nThe compact Nash Rambler had been around since 1950, and American Motors Corporation (AMC) expanded into a range of smaller cars than were offered by the Big Three. By 1960, Rambler was the third most popular brand of automobile in the United States, behind Ford and Chevrolet.[18] In response to this the domestic auto makers developed compact-sized cars, such as the Ford Falcon, Chevrolet Corvair, Studebaker Lark, and Plymouth Valiant.\\r\\nThe four-seat 1958 Ford Thunderbird (second generation) was arguably the first personal luxury car, which became a large market segment.[19]\\r\\nPony cars were introduced with the Ford Mustang in 1964. This car combined sporty looks with a long hood, small rear deck, and a small rear seat. The car proved highly successful and imitators soon arose, including the Chevrolet Camaro, Pontiac Firebird, Plymouth Barracuda (actually introduced two weeks prior to the Mustang), AMC Javelin, and the two-seat AMX, as well as the \\"luxury\\" version of the Mustang, the Mercury Cougar. Muscle cars were also introduced in 1964 with the Pontiac GTO. These combined an intermediate-sized body with a large high-output engine. Competitors were also quickly introduced, including the Chevrolet Chevelle SS, Dodge R/T (Coronet and Charger), Plymouth Road Runner/GTX, Ford Torino, and AMC's compact SC/Rambler. Muscle cars reached their peak in the late-1960s, but soon fell out of favor due to high insurance premiums along with the combination of emission controls and high gas prices in the early 1970s.\\r\\nWhile the personal luxury, pony, and muscle cars got most of the attention, the full sized cars formed the bulk of auto sales in the 1960s, helped by low oil prices. The styling excesses and technological gimmicks (such as the retractable hardtop and the pushbutton automatic transmission) of the 1950s were de-emphasized. The rear fins were downsized and largely gone by the mid-1960s, as was the excessive chrome.\\r\\nSafety and environmental issues during the 1960s led to stricter government regulation of the auto industry, spurred in part by Ralph Nader and his book: Unsafe at Any Speed: The Designed-in Dangers of the American Automobile. This resulted in higher costs and eventually to weaker performance for cars in the 1970s. Seat lap belts were mandated by many states effective in 1962. Under the National Traffic and Motor Vehicle Safety Act of 1966, Federal Motor Vehicle Safety Standards required shoulder belts for front passengers, front head restraints, energy-absorbing steering columns, ignition-key warning systems, anti-theft steering column/transmission locks, side marker lights and padded interiors starting in 1968.\\r\\nBeginning in 1972, bumpers were required to be reinforced to meet 5-mph impact standards, a decision that was revised in 1982.\\r\\nWith the Clean Air Act (United States) of 1963 and the Vehicle Air Pollution and Control Act of 1965, emission controls began being instituted in 1968. The use of leaded gasoline began being curtailed in the early 1970s, which resulted in lower-compression engines being used, and thus reducing horsepower and performance. Catalytic converters began being widely used by the mid-1970s.\\r\\nDuring his first term as EPA Administrator, William Ruckelshaus spent 60% of his time on the automobile industry, whose emissions were to be reduced 90% under the 1970 Clean Air Act after senators became frustrated at the industrys failure to cut emissions under previous, weaker air laws.[20]\\r\\nBy 1969, imports had increased their share of the U.S. auto market, with Volkswagen selling 548,904 vehicles, followed by Toyota with 127,018 vehicles. In response to this, the domestic auto makers introduced new compact and sub-compact cars, such as the Ford Pinto and Maverick, the Chevrolet Vega, and the AMC Gremlin, Hornet and Pacer. (Chrysler had to make do with importing cars from Mitsubishi Motors and their affiliated Rootes Group.) However, design and manufacturing problems infected a number of these cars and led to unfavorable perceptions of the cars.\\r\\nThe auto industry was severely affected by the 1973 oil crisis Arab embargo. Small fuel-efficient cars from foreign automakers took a sharply higher share of the U.S. auto sales market. Under the Energy Policy and Conservation Act[21] the federal government initiated fuel efficiency standards (known as Corporate Average Fuel Economy, or CAFE) in 1975, effective as of 1978 for passenger cars, and as of 1979 for light trucks. For passenger cars, the initial standard was 18 miles per gallon (mpg), and increased to 27.5 mpg by 1985.\\r\\nGeneral Motors began responding first to the high gas prices by downsizing most of their models by 1977. In 1979, the second oil price spike occurred, precipitated by political events in Iran, resulting in the 1979 energy crisis. By 1980, the economy slid into turmoil, with high inflation, high unemployment, and high interest rates. The automakers suffered large operating losses. Chrysler was hurt most severely and in 1979 received a bailout from the federal government in the form of $1.5 billion in loan guarantees. One quick fix was a Detroit-built version of their then-new French (Simca) economy car, the Horizon.[22] As a result of its financial difficulties, Chrysler sold its British and French subsidiaries, Rootes Group and Simca.\\r\\nAs bold and confident as the Big Three automakers were in the 1950s and 1960s, the American auto makers in the 1970s and 1980s stumbled badly, going from one engineering, manufacturing, or marketing disaster to another. Ford struggled when it was revealed that the Ford Pinto's gas tank was vulnerable to exploding when hit from behind. Ford knew about this vulnerability but did not design any safeguards in order to save a few dollars per vehicle. They rationalized that the cost of lawsuits would be less than the cost of redesigning the car.[23] GM had a string of miscues starting with the Chevrolet Vega, which developed a reputation for rapidly rusting and having major problems with the aluminium engine.[24] Cadillac damaged their reputation when the four-cylinder Cadillac Cimarron was introduced in 1981 (a gussied-up Chevrolet Cavalier at twice the price) and the \\"V8-6-4\\" engine didn't work as advertised.[25] GM's reputation was also damaged when it revealed in 1977 that they were installing Chevrolet engines in Oldsmobiles, and lawsuits from aggrieved Oldsmobile owners followed.[26] Likewise litigation ensued when a trio of diesel engines, designed from gasoline engines and used in GM cars from 1978 to 1985 suffered major problems. Class action lawsuits and efforts from the Federal Trade Commission resulted in buybacks of the cars from GM.[27] Chrysler also suffered damage to its reputation when its compact cars, the Plymouth Volar and Dodge Aspen, were developed quickly and suffered from massive recalls and poor quality.[28]\\r\\nIn 1981, Japanese automakers entered into a so-called \\"Voluntary restraint agreement\\" limiting the number of autos that they could import to the U.S. to 1.68 million per year.[29] One side effect of this quota was that the Japanese car companies began developing luxury cars that had higher profit margins, such as Toyota's Lexus, Honda's Acura, and Nissan Motor Company's Infiniti divisions. Another consequence was that the Japanese car makers began opening auto production plants in the U.S., with the three largest Japanese auto manufacturers all opening production facilities by 1985. These facilities were opened primarily in the southern U.S., in states which disadvantaged unions through right-to-work laws. The UAW failed in its substantial union-organizing efforts at these plants. The Big Three also began investing in and/or developing joint manufacturing facilities with several of the Japanese automakers. Ford invested in Mazda as well as setting up a joint facility with them called AutoAlliance International. Chrysler bought stock in Mitsubishi Motors and established a joint facility with them called Diamond-Star Motors. GM invested in Suzuki and Isuzu Motors, and set up a joint manufacturing facility with Toyota, called NUMMI (New United Motor Manufacturing, Inc.).\\r\\nOn the evening of June 19, 1982, while celebrating his Bachelor party at the Fancy Pants strip club, Vincent Chin, a 27-year old Chinese American from Detroit, Michigan, was approached by two Chrysler employees, Ronald Ebens and his stepson Michael Nitz, both of whom mistook him for a Japanese person and blamed the global presence of Japanese automobiles for the loss of jobs in the American automotive industry (particularly blaming Chrysler's increased sales of Mitsubishi models as captive imports). One of the club's dancers heard Ebens proclaim, \\"It's because of you little motherfuckers that we're out of work.\\" The fight between Ebens, Nitz and Chin continued into Detroit's outskirts after they were kicked out of the club. It took Ebens and Nitz 20 to 30 minutes to find Chin before they finally spotted him at a nearby McDonald's restaurant. Ebens beat Chin with a baseball bat four times, cracking his skull. Chin was rushed to Henry Ford Hospital, where he died in a coma on June 23. His 500 wedding guests attended his funeral instead. Ebens and Nitz both received a three-year probation for their deadly crime, but neither served jail time.[30]\\r\\nDespite the financial and marketing upheavals during the 1970s and 1980s, the decades led to technological innovations and/or widespread use of such improvements as disc brakes, fuel injection, electronic engine control units, and electronic ignition. Front-wheel drive became the standard drive system by the late 1980s.\\r\\nBy the mid-1980s, oil prices had fallen sharply, helping lead to the revitalization of the American auto industry. Under the leadership of Lee Iacocca, Chrysler Corporation mounted a comeback after its flirtation with bankruptcy in 1979. The Minivan was introduced in the 1984 model year by Chrysler with the Plymouth Voyager and Dodge Caravan, and proved very popular. These vehicles were built on a passenger-car chassis and seated up to seven people as well as being able to hold bulky loads. Chrysler also introduced their \\"K-cars\\" in the 1980s, which came with front-wheel drive and fuel-efficient OHC engines. In 1987, Chrysler bought American Motors, which produced the Jeep. This proved to be excellent timing to take advantage of the Sport utility vehicle boom. Ford also began a comeback after losses of $3.3 billion in the early 1980s. In 1985, the company introduced the very successful, aerodynamic Taurus. General Motors, under the leadership of Roger Smith, was not as successful as its competitors in turning itself around, and its market share fell significantly. While Ford and Chrysler were cutting production costs, GM was investing heavily in new technology. The company's attempts at overhauling its management structure and using increased technology for manufacturing production were not successful. Several large acquisitions (Electronic Data Systems and Hughes Aircraft Company) also diverted management attention away from their main industry. (Ford and Chrysler also joined in the acquisition and diversification trend, with Ford buying Jaguar Cars, Aston Martin, The Associates (a finance company), and First Nationwide Financial Corp. (a savings and loan). Chrysler purchased Lamborghini, an interest in Maserati, and Gulfstream Aerospace jets.) GM started the Saturn brand in the late 1980s as a way to retake sales from imported cars. While Saturn initially succeeded, GM later neglected to provide it much support. Around this time GM also began development on the General Motors EV1 electric car, which debuted in 1996.\\r\\nThe 1990s began the decade in a recession, which resulted in weak auto sales and operating losses. In addition, the Invasion of Kuwait by Iraq caused a temporary jump in oil prices. However, the automakers recovered fairly quickly. In the mid-1990s, light truck sales (which included Sport utility vehicles, Pickup trucks and Minivans) began to rise sharply.[31] Due to the Corporate Average Fuel Economy standards differentiating between passenger cars and light trucks, the automakers were able to sell large and heavy vehicles without fear of the CAFE fines. Low oil prices also gave incentives for consumers to buy these gas-guzzling vehicles. The American automakers sold combined, and even separately, millions of pickup trucks and body-on-frame SUVs during this period. Imports such as the Toyota 4Runner, Land Cruiser, Tacoma, and Nissan Pathfinder and Frontier were also popular during this time period.\\r\\nThe automakers also continued their trend of purchasing or investing in foreign automakers. GM purchased a controlling interest in Saab in 1990 and Daewoo Motors in 2001, and invested in Subaru in 1999 and Fiat in 2000. They also purchased the Hummer name from AM General in 1998. Ford purchased Volvo in 1999 and Land Rover in 2000. GM and Ford also established joint ventures with Chinese auto companies during this period. GM's joint ventures are with Shanghai GM, SAIC-GM-Wuling Automobile, and FAW-GM Light Duty Commercial Vehicle Co Ltd. Ford's joint ventures are with Chang'an Ford and Jiangling Ford.\\r\\nWhile the American automakers were investing in or buying foreign competitors, the foreign automakers continued to establish more production facilities in the United States. In the 1990s, BMW and Daimler-Benz opened SUV factories in Spartanburg County, South Carolina and Tuscaloosa County, Alabama, respectively. In the 2000s, assembly plants were opened by Honda in Lincoln, Alabama, Nissan in Canton, Mississippi, Hyundai in Montgomery, Alabama and Kia in West Point, Georgia. Toyota opened an engine plant in Huntsville, Alabama in 2003 (along with a truck assembly plant in San Antonio, Texas) and is building an assembly plant in Blue Springs, Mississippi. Volkswagen has announced a new plant for Chattanooga, Tennessee. Also, several of the Japanese auto manufacturers expanded or opened additional plants during this period. For example, while new, the Alabama Daimler-Benz and Honda plants have expanded several times since their original construction. The opening of Daimler-Benz plant in the 1990s had a cascade effect. It created a hub of new sub-assembly suppliers in the Alabama area. This hub of sub-assemblies suppliers helped in attracting several new assembly plants into Alabama plus new plants in nearby Mississippi, Georgia and Tennessee.\\r\\nIn 1998, Chrysler and the German automaker Daimler-Benz entered into a \\"merger of equals\\" although in reality it turned out be an acquisition by Daimler-Benz. Thus the Big Three American-owned automakers turned into the Big Two automakers. However, a culture clash emerged between the two divisions, and there was an exodus of engineering and manufacturing management from the Chrysler division. The Chrysler division struggled financially, with only a brief recovery when the Chrysler 300 was introduced. In 2007, Daimler-Benz sold the company to a private equity firm, Cerberus Capital Management, thus again making it American-owned.\\r\\nThe 2000s began with a recession in early 2001 and the effects of the September 11 attacks, significantly affecting auto industry sales and profitability. The stock market decline affected the pension fund levels of the automakers, requiring significant contributions to the funds by the automakers (with GM financing these contributions by raising debt). In 2001, Chrysler discontinued their Plymouth brand, and in 2004 GM ended their Oldsmobile division.\\r\\nIn 2005, oil prices began rising and peaked in 2008. With the American automakers heavily dependent upon the gas-guzzling light truck sales for their profits, their sales fell sharply. Additionally, the finance subsidiaries of the Big Three became of increasing importance to their overall profitability (and their eventual downfall). GMAC (now Ally Financial), began making home mortgage loans, especially subprime loans. With the subsequent collapse of the sub-prime mortgage industry, GM suffered heavy losses.\\r\\nThe Automotive industry crisis of 2008ÿ10 happened when the Big Three were in weak financial condition and the beginning of an economic recession, and the financial crisis resulted in the automakers looking to the federal government for help. Ford was in the best position, as under new CEO Alan Mulally they had fortuitously raised $23 billion in cash in 2006 by mortgaging most of their assets. Chrysler, purchased in 2007 by a private equity firm, had weak financial backing, was the most heavily dependent on light truck sales, and had few new products in their pipeline. General Motors was highly leveraged, also heavily dependent on light truck sales, and burdened by high health care costs.[32]\\r\\nThe CEOs of the Big Three requested government aid in November 2008, but sentiment in Congress was against the automakers, especially after it was revealed that they had flown to Washington D.C. on their private corporate jets. In December 2008, President Bush gave $17.4 billion to GM and Chrysler from the Troubled Asset Relief Program as temporary relief for their cash flow problems. Several months later, President Obama formed the Presidential Task Force on the Auto Industry to decide how to handle GM and Chrysler. Chrysler received a total of $12.5 billion in TARP funds and entered Chapter 11 bankruptcy in April 2009.\\r\\nAutomaker Fiat was given management control and a 20% ownership stake (adjusted to 35% under certain conditions), the U.S. and Canadian governments were given a 10% holding, and the remaining ownership was given to a Voluntary Employee Beneficiary Association (VEBA), which was a trust fund established to administer employee health care benefits.\\r\\nThe Automotive Task Force requested that GM CEO Rick Wagoner resign (although he was replaced by another long-time GM executive, Frederick Henderson). GM received a total of $49.5 billion in TARP finds and entered Chapter 11 bankruptcy in June 2009. The U.S. and Canadian governments received a 72.5% ownership stake, a VEBA received 17.5%, and the unsecured creditors received 10%. As part of the bailout GM and Chrysler closed numerous production plants, and eliminated hundreds of dealerships and thousands of jobs. They also required a number of major labor union concessions. GM also sold off the Saab division and eliminated the Pontiac, Hummer, and Saturn Corporation brands. In addition to the $62 billion that the automakers received from TARP, their financing arms, Ally Financial and TD Auto Finance received an additional $17.8 billion.[33] In addition to the funding from the United States government, the Canadian government provided $10.8 billion to GM and $2.9 billion to Chrysler as incentives to maintain production facilities in Canada.[34]\\r\\nFord did not request any government assistance, but as part of their downsizing sold Volvo in 2010 and phased out their Mercury division in 2011. (They had previously sold Aston Martin in 2007, and Land Rover and Jaguar Cars in 2008). Under the Advanced Technology Vehicles Manufacturing Loan Program Ford borrowed $5.9 billion to help their vehicles meet higher mileage requirements.\\r\\nFord went through 2012 having recovered to the point of having 80,000 total U.S. employees, supplying their 3,300 dealerships. In comparison, Chrysler had 71,100 U.S. employees supplying their 2,328 dealerships during that year.[5]\\r\\nData for the beginning of 2014 put the four companies of GM, Ford, Toyota, and Chrysler, in that order, at the top as having the most U.S. car sales. In terms of specific types of vehicles, the new decade has meant Chrysler having an emphasis on its Ram trucks and the Jeep Cherokee SUV, both of which had \\"hefty sales\\" for 2014 according to a news report.[35]\\r\\nIn 2017, it is reported that auto makers spent more on incentives, US$3,830 per vehicle sold, than labour, which is estimated to be less than US$2,500 per vehicle.[36]","input":"When was the first car made in united states?"},{"output":"Jeff Sessions","context":"The United States Attorney General (A.G.) is the head of the United States Department of Justice per 28 U.S.C.??503, concerned with all legal affairs, and is the chief lawyer of the United States government. In cases of the federal death penalty, the power to seek the death penalty rests with the Attorney General.\\r\\nUnder Article II Sec. 2 of the Constitution the Attorney General is nominated by the President and appointed with the advice and consent of Congress. The Constitution is clear that the Attorney General may be impeached by Congress. As to whether the Attorney General may be summarily removed by the President, no provision of the Constitution grants this power. The decisional law suggests that the President has the power to remove an official engaged in purely executive functions or an official whose duties immediately affect the President's ability to fulfill his constitutional responsibilities, (Bowsher v. Synar, 1986), but provides little or no guidance as to whether the office of Attorney General falls within these general guidelines.\\r\\n\\r\\n\\r\\nCongress passed the Judiciary Act of 1789 which, besides other things, established the Office of the Attorney General. The original duties of this officer were \\"to prosecute and conduct all suits in the Supreme Court in which the United States shall be concerned, and to give his or her advice and opinion upon questions of law when required by the President of the United States, or when requested by the heads of any of the departments.\\"[3]\\r\\nThe Department of Justice was established in 1870 to support the Attorney General in the discharge of their responsibilities.\\r\\nThe Attorney General, the Secretary of State, the Secretary of the Treasury, and the Secretary of Defense are generally regarded as the four most important cabinet officials in the United States because of the importance and age of their respective departments.[4]\\r\\nIt is the practice for the Attorney General, along with many other public officials, to give resignation with effect on the Inauguration Day (January 20) of a new President. The Deputy Attorney General, who is also required to tender their resignation, is commonly requested to stay on and act as Attorney General pending the confirmation by the Senate of the new Attorney General.\\r\\nFor example, on the inauguration of President Donald Trump on January, 20, 2017, the tenure of the then Attorney General Loretta Lynch was brought to an end, and the Deputy Attorney General Sally Yates, who had also tendered her resignation, was asked to stay on and be Acting Attorney General until the confirmation of the new Attorney General Jeff Sessions, who had been nominated for the office in November 2016 by then-President-elect Donald Trump. However, Yates was dismissed by Trump on January 30, 2017[5][6] before Sessions had been confirmed. Dana Boente automatically succeeded Yates as Acting Attorney General as the next available successor in the line of succession. Boente, who was the United States Attorney for the Eastern District of Virginia,[7] was the most senior Justice Department official whose resignation had not been accepted by Trump.[8][9] When Sessions was confirmed and sworn in as Attorney General on February 9, 2017, Boente became Acting Deputy Attorney General.[10][11] On March 10, 2017, Sessions oversaw the firing of 46 United States Attorneys, leaving only his acting Deputy Dana Boente and nominated Deputy Rod Rosenstein in place.[12] Rosenstein's appointment was subject to Senate confirmation. Rosenstein was confirmed on April 25, 2017 and became Deputy Attorney General on April 26, 2017, and Boente reverted to his permanent position.\\r\\n??No party (1) ??Federalist (3) ??Democratic-Republican (5) ??Democratic (34) ??Whig (4) ??Republican (38)\\r\\nAs of May 2018, there are eleven, living former US Attorneys General, the oldest being Ramsey Clark (served 1967ÿ1969, born 1927). The most recent Attorney General to die was Janet Reno (served 1993ÿ2001, born 1938) on November 7, 2016.\\r\\nOn February 9, 2017, President Donald Trump signed an Executive Order which modified the line of succession for the Attorney General.[13] Under Executive Order 13762 signed by President Obama on January 13, 2017, before leaving office, the line of succession was:[14]","input":"Who is the us attorney general right now?"},{"output":"Detroit","context":"A winless season is a regular season in which a sports team fails to win any of their games. The antithesis of a perfect season, this ignominy has been suffered eleven times in professional American football, six times in arena football, three times in professional Canadian football, once each in American professional lacrosse and box lacrosse, more than twenty-five times in major Australian football leagues, thirteen times in top-level rugby league, at least twice in top-level rugby union, and twice in English county cricket.\\r\\n\\r\\n\\r\\nBecause of the relatively small number of games played in college and professional football seasons, there is a possibility that a very bad team will not manage to win any games. Before overtime was used consistently, teams might tie a game without winning one; these are generally counted in lists of winless seasons. This is because, during eras before overtime was introduced to American football, leagues generally ignored tied games when calculating winning percentage. In 2001, the Columbus Wardogs of AF2, the minor league of the Arena Football League, made history becoming the first American football team to go 0ÿ16.\\r\\nThe Rochester Jeffersons went a combined 0ÿ21ÿ2 from 1922ÿ25, but played only partial NFL schedules in those years (0ÿ4ÿ1, 0ÿ4, 0ÿ7 and 0ÿ6ÿ1, respectively). They also had another winless season in 1911 going 0ÿ1ÿ3 in the New York Pro Football League.\\r\\nSource: Worst NFL Teams of all time (ESPN)[1]\\r\\nThe previously shorter length of seasons in arena football made imperfect seasons quite possible. The following teams went through an Arena Football League season without winning a game:\\r\\nThe United Football League had one winless season. In their inaugural season, the 2009 New York Sentinels lost all six of their games. The team, which was a traveling team that played games in Hartford, Long Island and New Jersey (and had intended to play a game in New York City but backed out), fired its head coach and settled permanently in Hartford to become the Hartford Colonials. Under the UFL's double round robin format, only one team could finish any particular season entirely with losses, since every team played each other at least twice.\\r\\nThe 1991 inaugural season of the World League of American Football saw the Raleigh-Durham Skyhawks fold after losing all ten of their regular-season games. The following year, the WLAF replaced that franchise with the Ohio Glory who almost met the same fate but managed one win in their lone season.\\r\\nSince non-professional, semi-professional and minor league teams are inherently unstable in their membership, it is far easier for seasons in which a team wins no games to occur. In the case of non-professional teams, neither mechanisms to force a team to shut down against its will, nor effective drafts or revenue sharing mechanisms to distribute talent evenly among teams typically exist, leading to poor teams accumulating multiple winless seasons. Four teams in football history have both lost all their games and failed to score a single point in an entire season; all played eight games or less. The 1938 Clintonville Four Wheel Drive Truckers failed to score a point in a nine-game season, but managed two 0ÿ0 ties.[2] There are at least twelve teams who have accumulated losing streaks of 20 games or more; there are also four teams who have accumulated seasons of all losses with at least 13 games.[3] In the case of minor professional football, particularly in indoor football leagues, winless seasons often result from an owner's abandonment or other financial hardship. The American Indoor Football Association had at least one winless team in five out of six seasons. The National Indoor Football League went its first three seasons without a winless season, but beginning in 2004, at least one team went winless every year until the league's collapse in 2007. Though the Spring Football League had two teams with winless seasons (the Los Angeles Dragons and the Miami Tropics), and the Stars Football League had one such team (the traveling 2011 Michigan Coyotes), they are almost never mentioned in discussions of perfect and perfectly bad seasons, since those teams only played two games each before the seasons were cut short.\\r\\nAF2 was the minor league of the Arena Football League. In 2001, the Columbus Wardogs made history becoming the first American football team to finish a season 0ÿ16.\\r\\nThe Legends Football League (originally Lingerie Football League), whose seasons are only three to four games long for each team, has had eight teams with perfectly bad seasons in three years of play. One such team, the Toronto Triumph, did not win a game in either of their competing seasons in 2011 and 2012.\\r\\nThe Princeton Tigers sprint football squad, a team consisting of players under 172 pounds, sustained 16 consecutive winless seasons before Princeton University shut the team down in 2015, citing safety concerns in allowing players to play on a team so heavily outmatched.[4]\\r\\nThe Canadian Football League currently has a regular season of eighteen games; from 1952 to 1985 it was generally sixteen games as with the current NFL season, though those teams in the Eastern Division played only fourteen as late as 1973.[5] Also, the CFL did not adopt interdivisional regular season play until the early 1960s. Consequently, especially given the much smaller number of teams playing, there have been fewer imperfect seasons than in the National Football League, with the exception of the first decade or so when fewer games were played.\\r\\nThe National Pro Grid League has a short season of 3 to 4 games per team plus a 4 to 8 team playoff. The Los Angeles Reign did not win one game during the first three seasons of the league.\\r\\nSeasons in the National Lacrosse League and its predecessors Major Indoor Lacrosse League and Eagle Pro Box Lacrosse League have varied from eight games in the first years of competition to sixteen games today, with the extension having been gradual. The Charlotte Cobras, who played only one season before folding, are the only team in the history of the NLL to have not won a game in a season. In their sole 1996 season they played twelve games and lost them all, before folding.\\r\\nIn Major League Lacrosse, the season has consisted of either twelve or fourteen games since the league was formed in 2001. The only winless season in Major League Lacrosse has been by the 2006 Chicago Machine, who went 0ÿ12 and lost an MLL record thirteen consecutive games.\\r\\nIn the other major professional sports leagues of North America it is virtually impossible that a team could lose all its games, for the simple reason that there are many more games in the regular season than in football or lacrosse.\\r\\nThe Major League Soccer schedule has consisted of between twenty-six and thirty-four games. No team in Major League Soccer has ever come close to losing all its games: the most losses in a MLS season is 24 from 32 games by the Kansas City Wizards in 1999, the year when the league used shootouts to decide all tied games. Shootouts were abandoned the following season. In 2013, D.C. United set new MLS records in futility. They won a league low three games, and lost a record 24 games, tying the aforementioned Wizards.\\r\\nSince the 1967ÿ68 season, the National Basketball Association's regular season schedule has been 82 games long (except 1998ÿ99, 50 games and 2011ÿ12, 66 games due to lockouts). It has been as few as 48 games long, but eventually expanded to an 82-game schedule.\\r\\nThe 2011ÿ12 Charlotte Bobcats hold the record for the lowest winning percentage of any team in an NBA season, winning only 7 out of 66 games in a lockout-shortened season, for a winning percentage of .106. This broke the record held by the 1972ÿ73 Philadelphia 76ers, who had a winning percentage of .110 in a full 82-game season. The 1947ÿ48 Providence Steamrollers won an all-time NBA low of six games out of 48 (.125 winning percentage).\\r\\nThe 1953ÿ54 Baltimore Bullets went 0ÿ20 on the road. More recently, the 1990ÿ91 Sacramento Kings managed a near-imperfect road season, winning only one of 41 away games.[6] Overall, the Kings lost 43 consecutive road games before beating the Orlando Magic 95ÿ93 on November 23, 1991.\\r\\nSince its formation in 1997, the WNBA regular season has been gradually increased from 30 to the current 34-game schedule.\\r\\nNo team has gone through a WNBA season without winning a game; the fewest wins in a WNBA season has been three by the 1998 Washington Mystics in their first season, and the 2011 Tulsa Shock. Two other expansion WNBA teams, the 2008 Atlanta Dream at 4ÿ30 and the 2006 Chicago Sky at 5ÿ29 have come closest to this record.\\r\\nThe Atlantic City Seagulls of the (now defunct) summertime, minor league USBL finished the 2001 season with an 0ÿ28 record. It was quite a turnaround for the franchise, as they were dominant in the USBL just a few years earlier; the Seagulls were USBL runners-up in 1996, then swept to three straight titles in 1997ÿ99. In 2000, the Seagulls slipped to 12ÿ18, fourth place, and were beaten in the first round of the playoffs; after their winless 2001 campaign, the Seagulls folded.\\r\\nIn 2013, Mersey Tigers became the first top-flight British basketball team to go a whole season winless.\\r\\nThis record of 0ÿ33 in the regular season of the 2012ÿ13 BBL Championship, was completed with a 90ÿ57 loss away to Glasgow Rocks, but can also be extended to include their complete season of 0ÿ35 (defeats in the first round of the BBL Cup and BBL Trophy).\\r\\nThe defeat in the BBL Trophy was also significant because they fell at this stage to EBL Division One side, Worthing Thunder, and in doing so, it was the first time a BBL side had been knocked out from a competition by an EBL team.\\r\\nThey also currently hold the longest losing streak of 34 consecutive defeats in the BBL Championship.\\r\\nThe National Hockey League's schedule, like that of the NBA, consists of 82 games. Since the 2004ÿ05 lockout, teams receive two points for a win, one point for a loss in overtime or a shootout, and zero points for a loss in regulation time. From 1997 until 2004, teams received two points for a win, one point for a tie or overtime loss, and zero points for a regulation loss. Prior to 1997, teams received two points for a win, one point for a tie, and no points for a loss. From 1997 to 2004, NHL standings tables had four columns: WÿLÿTÿOTL. From 2005 to 2010, it was reduced to three, WÿLÿOTL; in 2011, a \\"regulation/overtime win\\" column (ROW) was added, which excludes shootout wins; it does not change the point totals, but does serve as the second tiebreaker (after games played; since all teams play 82 games by the season's end barring any unreschedulable cancellations, it becomes the first tiebreaker at season's end).\\r\\nNo team has ever come close to losing every game in an NHL season; the worst record is by the 1974ÿ75 Washington Capitals who went 8ÿ67ÿ5 (8 wins, 67 losses, 5 ties). The 1974ÿ75 Capitals and 1992ÿ93 Ottawa Senators hold the record for fewest wins on the road with one. The NHL played an 80-game season in 1974ÿ75, whereas in 1992ÿ93 the schedule consisted of 84 games, thus giving the Senators the percentage record for worst road record. The Senators also set a record by losing their first 38 consecutive road games (the Senators' road statistics include a neutral site game played in Hamilton, Ontario, in which the Senators were considered the road team).\\r\\nSince the early 1960s, the schedule of both leagues of Major League Baseball has been 162 games long, and before that it was 154 games long. With such a schedule, it is practically impossible for a team to finish with a winless season. The sabermetric baseball statistic Wins Above Replacement is calculated on the premise that even a team consisting entirely of replacement-level players is expected to win a baseline minimum number of games (typically 40-50 depending primarily on the caliber of the team's division) per 162 game season.\\r\\nThe closest to a perfectly imperfect season in the National League was the infamous 1899 Cleveland Spiders season, who finished with a record of 20-134 after its roster was looted by the owners of the team, who then stacked the best players onto the St. Louis Perfectos.\\r\\nWith a win percentage of .130, the Spiders are (as of 2016) the last of three major league teams to have finished a season below the Mendoza line (.200) in win percentage; the others were the 1889 Louisville Colonels (.196), and the 1890 Pittsburgh Alleghenys (.169), whose best players had jumped to the Pittsburgh Burghers of the newly formed Player's League.\\r\\nSince the establishment of the American League in 1901, the teams to have come closest to imperfection are the 1916 Philadelphia Athletics (36ÿ117), the 1935 Boston Braves (38ÿ115), the 1962 New York Mets (40ÿ120) and the 2003 Detroit Tigers (43ÿ119).\\r\\nIn the Australian Football League (until 1990 called the Victorian Football League), seasons have ranged from twelve games per team (in 1916, when only four teams competed due to World War I) to 22 games (since 1970, except for 1993 when 20 games were played), with most seasons being of 18 or 22 games duration.\\r\\nIn the South Australian National Football League, season length has varied from twelve games to 22. Since 2015, teams have played 18 games per season.\\r\\nThe West Australian Football League has existed within Western Australia under various monikers since 1885, and until the 1980s was of equivalent standard to the VFL and SANFL. Its season was originally around six to nine games in length, later increasing to 21 games, and from 2018 is 18 .[a][20]\\r\\nFrom the time of the formation of the Victorian Football League in 1896 until it was dissolved in 1995, the VFA was the second-tier club competition in Victoria. Its home-and-away season varied erratically from 12 to 22 games in length.\\r\\nAfter 1995, the VFA was replaced by the current Victorian Football League (VFL), which serves as a state league and feeder to the AFL.\\r\\nIn the Rugby Football League Championship, teams initially played a variable number of games, with the maximum ranging over time from 26 to 38, and some teams playing as few as fourteen. In more modern times the fixture list has been standardised at 26 games per team.\\r\\nAs a result of this fairly lengthy schedule, it has been almost impossible for British rugby league teams to lose all their games, with the only exception being during World War II's so-called \\"Wartime emergency League\\" when teams were often able to arrange no more than ten games and some as few as five. The only two winless seasons since normal competition resumed after the war have been in the second and third divisions of the Championship.\\r\\nIn Australian rugby league seasons were initially between eight (in the event of Kangaroo tours) and sixteen games long, so that a very bad team could go through a season with only losses. As a result of the expansion of the NSWRL from 1947 onwards, the season has been lengthened gradually with a few intermissions. The following NSWRL teams up to 1966 did not win a single game:\\r\\nSince 1967, NSWRL and later NRL seasons have been between 22 and 26 games long; thus it is much less likely a very bad team could lose every single one of its games.\\r\\nSuper Rugby, the Southern Hemisphere's principal club competition, has seen two teams go through an entire season with no wins or draws. Both seasons were in the competition's past incarnations of Super 12 and Super 14, each name reflecting the number of competing teams.\\r\\nUnder both Super 12 (1996ÿ2005) and Super 14 (2006ÿ2010) formats, each team played all other teams once, resulting in seasons of 11 and then 13 games. The competition became Super Rugby with the addition of a 15th team in 2011. The season format was also heavily revamped; the regular season now consists of 16 matches.\\r\\nThe Super 12 and Super 14 eras each saw one team finish a season with only losses; both teams with this dubious distinction are from South Africa. In 2002, the Bulls, based in Pretoria, finished with 11 losses from 11 matches. The other imperfect season was that of the Johannesburg-based Lions in the final season of the Super 14 format in 2010, who lost all 13 of their matches, while ending up with a final points difference of negative 300.\\r\\nIn English first-class county cricket, which has a history dating back to the early nineteenth century and was until the middle twentieth century up to the highest standard of the game, seasons have varied in length. Before the 1880s, they were generally less than ten matches in length and some \\"first-class\\" counties played only against one or two different opponents, so that a team losing all its games was not uncommon. Between 1887 and 1929, seasons were gradually increased in length to a standard twenty-eight matches for all counties. However, because of the development and popularity of one-day cricket, seasons have been reduced to twenty-four games in 1969 and twenty in 1972, though this was increased by two in 1977 and 1983. With an increase to four days for all games, sixteen or seventeen games have been played since 1993.\\r\\nAlso, because of improvements to pitches via the heavy roller and covering to protect from rain, the proportion of games \\"drawn\\" (not finished) has steadily risen since the 1870s.\\r\\nOnly two county teams have ever finished a season with only losses in a program of eight or more games:\\r\\nTeams losing or drawing every game in a first-class county season have been rather less exceptional, though by no means frequent:[21]\\r\\nThere were no completely winless seasons in the Sunday League limited-overs competition during its history from 1969 to 2009.\\r\\nWith the exception of the Sheffield Shield since the 1970s, most first-class cricket competitions outside England have either been knock-outs or of such short length that it becomes an everyday occurrence for a team to lose all its games. Some, such as the Ranji Trophy and most seasons of the Quaid-e-Azam Trophy, have indeed been knockout competitions, which typically use first innings lead to decide if a match is unfinished.\\r\\nThere have still be some notable winless sequences in non-English first-class cricket:\\r\\nIn the 2012ÿ13 season of the Australian Big Bash League, the Sydney Thunder completed an imperfect season where they lost all their eight games despite possessing the likes of Chris Gayle.\\r\\nIn the ANZ Championship, which formed out of the old Commonwealth Bank Trophy in 2008, seasons have been thirteen games. There has so far been one winless season, by the Central Pulse from Wellington (formed as a combination of the Wellington Shakers and Western Flyers)[29] in the opening 2008 season. They did earn one point when a game was abandoned due to a leaking roof. The Pulse were to win only one game each in 2009[30] and 2010, thus having a record of 2ÿ36 after three seasons.\\r\\nOnly two teams are known to have completed a season with no victories or draws. Antigua Barracuda lost all 26 matches of the 2013 USL Pro, while in the 2015-16 season, English non-league team Longford AFC, played a 30-game season in the Gloucestershire Northern Senior League Division Two (14th tier on the English pyramid), losing all their matches after the majority of their players and manager left. In the 2010ÿ11 Ukrainian Second League (3rd tier on the Ukrainian pyramid), FC Veres Rivne lost all 14 out of 22 scheduled games before being expelled from the league due to failure of payment of league dues; in addition, they also did not score a single goal at home.\\r\\nIn top-level domestic league football however, few teams have completed their respective seasons without winning a game. In the 2010ÿ11 Serbian SuperLiga, FK ?ukari?ki Stankom played an entire season winless, drawing five matches and losing 25 in a 30-game season, giving them only 5 points and finishing bottom in a field of 16. The team also only scored ten goals whilst conceding 65.\\r\\nIn the Bulgarian A Professional Football Group, which is the top tier of association football in the European country, three teams have all played a season without winning, with those being Torpedo Ruse (four draws out of 22 matches during 1951), Rakovski Ruse (one draw out of 30 matches during 1996/97) and Chernomorets Burgas Sofia (also one draw out of 30 matches during 2006/07). Chernomorets were however the worse performing out of these, conceding 131 goals with only eight in reply (the same number scored as Rakovski Ruse in their winless season), they still however completed the season with a minus 2 points total, because they violated a rule concerning not being able to field enough youth players.\\r\\nIn the 1946-47 Allsvenskan, the Swedish Football League season of 1946-47 with 22 games played, Billingsfors IK tied 3 games and lost 19, the only team in Swedish football history never to win even one single Allsvenskan game.\\r\\nIn the 1999ÿ2000 Vyshcha Liha, the highest division of Ukrainian football championship, FC Zirka Kirovohrad tied 9 matches and lost 21 out of 30.\\r\\nThe open high frequency of draws in association football, coupled with the relatively long length of seasons and promotion and relegation system used in a majority of jurisdictions to automatically remove the lowest performing teams from any given league, makes winless seasons less likely to occur.\\r\\nWinless seasons occurred frequently in the Ukrainian Hockey Championship, the top-level ice hockey league in Ukraine. The longest series belongs to HK Dniprovski Vovky who lost all 30 games in the regulation time in the 2007ÿ08 season. SDYuShOR Sokil, the academy team of HC Sokil Kyiv, had three winless seasons (1999ÿ2000, 2004ÿ05, and 2006ÿ07). Four more teams completed a season without winning a single game: Ivars Kyiv lost all 12 games in 1996ÿ97, Kryzynka II, the second team of HK Kryzynka Kiev (playing in the same league as the main team), tied 1 and lost 13 games out of 14 in 1998-99, HC Khimik Sieverodonetsk lost all 16 games in 2003ÿ04, and VIM-Berkut lost all 10 games in 2009ÿ10.\\r\\na In the 1944 under-19 wartime competition that replaced the senior competition between 1942 and that season due to the player drain of World War II, South Fremantle lost all nineteen of their games.","input":"What is the worst nfl record in history?"},{"output":"20 different themed series","context":"\\r\\n\\r\\n\\r\\n\\r\\nPower Rangers is an American entertainment and merchandising franchise built around a live action superhero television series. Produced first by Saban Entertainment, later by BVS Entertainment, and today by SCG Power Rangers the television series takes much of its footage from the Japanese tokusatsu Super Sentai, produced by Toei Company.[1] The first Power Rangers entry, Mighty Morphin Power Rangers, debuted on August 28, 1993, and helped launch the Fox Kids programming block of the 1990s, during which it catapulted into popular culture along with a line of action figures and other toys by Bandai.[2] As of  2001[update], the media franchise has generated over $6 billion in retail sales worldwide.[3]\\r\\n\\r\\nDespite initial criticism that its action violence targeted child audiences, the franchise has continued, and as of  2017[update] the show consists of 24 television seasons of 20 different themed series and three theatrical films released in 1995, 1997 and 2017. In 2010, Haim Saban, creator of the series, regained ownership of the franchise after seven years under The Walt Disney Company.\\r\\n\\r\\nIn 2018, shortly after naming Hasbro the new master toy licensee, Saban Brands and Hasbro announced that Hasbro would acquire the franchise in a $522 million deal, with the first products from Hasbro becoming available in Spring 2019.[4][5]\\r\\n\\r\\nSince Power Rangers derives most of its footage from the Super Sentai series, it features many hallmarks that distinguish it from other superhero series.  Each series revolves around a team of youths recruited and trained by a mentor to morph into the eponymous Power Rangers, able to utilize special powers and pilot immense assault machines, called Zords, to overcome the periodic antagonists. In the original series Mighty Morphin, the wizard Zordon recruits \\"teenagers with attitude\\" against Rita Repulsa.[6]\\r\\n\\r\\nWhen \\"morphed,\\" the rangers become powerful superheroes wearing color-coded skin-tight spandex suits and helmets with opaque visors; identical except in individual rangers' color and helmet design. Morphed Rangers generally possess enhanced strength, durability, agility and combat prowess. Some possess superhuman or psychic abilities such as super-speed, element manipulation, extra-sensory perception or invisibility.[7] In addition, each individual ranger has a unique weapon, as well as common weaponry used for ground fighting.[note 1] When enemies grow to incredible size (as nearly all do), Rangers utilize individual Zords that combine into a larger Megazord.\\r\\n\\r\\nRangers teams operate in teams of five or three, with more Rangers joining the team later. Each team of Rangers, with a few exceptions, obeys a general set of conventions, outlined at the beginning of Mighty Morphin and implied by mentors throughout many of the other series: Power Rangers may not use their Ranger powers for personal gain or for escalating a fight (unless the enemy does so), nor may the Power Rangers disclose their identities to the general public.[note 2] The penalty for disobeying these rules is the loss of their power.\\r\\n\\r\\nAs in Super Sentai, the color palette of each Power Rangers team changes every series.[note 3] Only Red and Blue appear in every Ranger team, while a Yellow Ranger has been present in every season except Power Rangers Dino Charge.  Other colors and designations also appear throughout the series.[note 4] A Rangers' color designation also influences their wardrobe throughout the series: civilian clothing often matches Ranger color.[note 5]\\r\\n\\r\\nBefore creating Power Rangers, the idea of adapting Sentai series to the American public emerged in the late 1970s after the agreement between Toei Company and Marvel Comics to exchange concepts to adapt them to their respective audiences. Toei, together with Marvel, created the Spider Man series, based on the comics of the same name, and produced three Super Sentai series, which had great success in Japan. While Stan Lee and Marvel tried to sell the Sun Vulcan series to various television stations, including HBO, but unlike what happened in Japan, this did not succeed and after three years, the agreement ended.[8][9]\\r\\n\\r\\nSeveral years later, another idea to adapt Super Sentai began in the 80s when Haim Saban made a business trip to Japan, in which, during his stay at the hotel, the only thing that was being transmitted on his television was the Japanese series \\"Super Sentai\\". At that time, Saban was fascinated by the concept of 5 people masked in spandex suits fighting monsters, so in 1985, he produced the pilot episode of Bio-Man, an American adaptation of Choudenshi Bioman, which was rejected by several of the largest American television stations.[10][11]\\r\\n\\r\\nProduction of Power Rangers episodes involves extensive localization of and revision of original Super Sentai source material in order to incorporate American culture and conform to American television standards. Rather than making an English dub or translation of the Japanese footage, Power Rangers programs consist of scenes featuring English-speaking actors spliced with scenes featuring either Japanese actors dubbed into English or the action scenes from the Super Sentai Series featuring the Rangers fighting monsters or the giant robot (Zord and Megazord) battles with English dubbing. In some series, original fight scenes are filmed to incorporate characters or items unique to the Power Rangers production.[12] Like many of Saban Entertainment previous ventures in localizing Japanese television for a Western audience, the plot, character names, and other names usually differ greatly from the source footage, though a few seasons have stayed close to the story of the original Super Sentai season.\\r\\n\\r\\nAlong with adapting the villains from the Super Sentai counterparts, most Power Rangers series also feature villains with no Sentai counterpart. Generally, the primary antagonist of a Power Rangers series (for example, Lord Zedd, Divatox, etc.) are not adapted from the Sentai. Exceptions to this includes Mighty Morphin, Zeo, Lightspeed Rescue and a few others which only use villains adapted from the Japanese shows.\\r\\n\\r\\nThe series that began the franchise, Mighty Morphin Power Rangers (an American adaptation of the 1992 Japanese Super Sentai Series, Kyry Sentai Zyuranger), began broadcasting as part of the Fox Kids block of programing that aired on the FOX network. It lasted for three seasons (from 1993 to 1996).[13]\\r\\n\\r\\nSaban Entertainment distributed the Power Rangers series from 1993 until the end of 2001, and Fox broadcast it until the fall of 2002. The Walt Disney Company purchased the franchise as part of a buyout that took place in 2001.[13][14][15][16] This resulted in Fox Family Worldwide becoming ABC Family Worldwide Inc.[16] This buyout also saw Saban Entertainment becoming BVS Entertainment in 2002, from News Corporation, Fox's parent company, and Haim Saban.[16] The show continued to air on Fox until the company replaced its Fox Kids package with \\"FoxBox\\" in the United States. Since September 2002, all Power Rangers shows had aired on various Disney-owned networks (ABC Kids, Toon Disney and Jetix channels worldwide).[13] When Wild Force ended, Disney moved production of the franchise from Los Angeles to New Zealand. This resulted in the closure of MMPR Productions and the dismissal of many members of the production. From Ninja Storm to date, Power Rangers is produced in New Zealand. ABC Family, another Disney-owned network, also used to air Power Rangers until it did away with its Jetix timeslot after August 31, 2006. On February 12, 2009, Toon Disney ended in the wake of Disney XD, ending cable airings of Power Rangers in certain areas of the United States. Several ABC affiliate broadcasting groups declined to air most of the Power Rangers series since 2006 due to the lack of FCC-compliant educational and informational content in the programs.[17]\\r\\n\\r\\nThe Saban era seasons, starting with In Space, have gone under the \\"Saban's Power Rangers\\" moniker, up until Time Force. Since the re-acquisition of Power Rangers by Saban in 2010, this practice has continued once again starting with Samurai.\\r\\n\\r\\nStarting in 2005, up until 2007, during its run on Jetix, Power Rangers reruns were aired under the moniker Power Rangers Generations, showcasing select episodes from Mighty Morphin through Dino Thunder.\\r\\n\\r\\nAn article in The New Zealand Herald published on March 7, 2009, identified Power Rangers RPM as the last season of the Power Rangers run. Production manager Sally Campbell stated in an interview, \\"...at this stage we will not be shooting another season.\\"[18][19] A September 1, 2009, revision to Disney A to Z: The Official Encyclopedia by Disney's head archivist Dave Smith states that \\"production of new episodes [of Power Rangers] ceased in 2009\\".[20] Production of Power Rangers ceased and the last[update] series by BVS Entertainment, RPM, ended on December 26, 2009.[18]\\r\\n\\r\\nOn October 1, 2009, Bandai released a press release that Disney would re-broadcast Mighty Morphin Power Rangers starting in January 2010 on ABC Kids in lieu of a new series utilizing footage from the 2009 Super Sentai television series. A new toy line accompanied the series and appeared in stores in the later part of 2009.[13][21][22] ABC's over-the air telecasts ended on August 28, 2010, and turned the hour back to affiliates.\\r\\n\\r\\nOn May 12, 2010, Haim Saban bought back the Power Rangers franchise from Disney for $43 million and announced plans to produce a new season of the television series.[23][24][25] The eighteenth season, Samurai, began airing on Nickelodeon on February 7, 2011,[24][26] with the previous episodes beginning rebroadcast on Nicktoons later that year.[26][27][28] It was also announced that Saban plans to make a new Power Rangers movie.[29]\\r\\n\\r\\nOn July 2, 2012, it was announced that Saban Brands would launch a Saturday morning cartoon block on The CW, called Vortexx, on August 25, 2012, that would air Power Rangers Lost Galaxy.[30][31][32][33][34] The series was removed before the season even finished, ending up doing so on the Vortexx website. The block itsel ended in fall 2014.\\r\\n\\r\\nTo commemorate the series' 20th anniversary, Nickelodeon began airing Power Rangers Megaforce on February 2, 2013, featuring all of the past rangers from the series' 20-year history in the last episode of the season. On October 1, 2013, Saban Brands announced that it had extended agreements with Nickelodeon and Bandai America Incorporated through 2016 for its globally recognized Power Rangers franchise.[35] The 90s Are All That aired Mighty Morphin Power Rangers as part of Mighty Morphin Weekend in 2013. \\r\\n\\r\\nIn May 2014, Saban Brands and Lionsgate Films announced that they are planning to produce a new Power Rangers feature film, and would hopefully launch a Power Rangers film franchise.[36] The movie, titled simply Power Rangers, was released on March 24, 2017, with mixed reviews and a failure at the box office, as a result, the future of a cinematographic universe for the franchise is uncertain.\\r\\n\\r\\nIn January 2016, Saban and Nickelodeon extended their broadcast partnership through 2018.[37] In February 2018, the companies announced that Power Rangers would continue airing on Nickelodeon through 2021.[38]\\r\\n\\r\\nThe first six seasons, starting with Mighty Morphin Power Rangers and ending with In Space, were direct continuations of the preceding season with evolving storylines and character development. The second season began the annual tradition of the Power Rangers acquiring new Zords to battle enemies when they grow to an incredible size while the core suites from first season were used except for the White Ranger. The fourth season began the annual tradition of the Power Rangers receiving new powers and Zords similar to the Super Sentai series. Beginning with Lost Galaxy, although it had ties with the previous story arc, each Power Rangers series had its own self-contained storylines, independent of previous series. Crossover episodes between different series featuring rangers, villains, and other characters from past seasons also began with Lost Galaxy, with a few exceptions.\\r\\n\\r\\nThe Power Rangers franchise has also generated three theatrical motion pictures. The first two are distributed by 20th Century Fox, and the third film released in 2017 by Lionsgate.\\r\\n\\r\\nPower Rangers has long had success in international markets and continues to air in many countries, with the exception of New Zealand, where the series filming takes place as of  2009[update]. As of 2006, Power Rangers aired at least 65 times a week in more than 40 worldwide markets.[43] Many markets carry or have carried the series on their respective Fox or later Jetix/Disney XD channels or have syndicated the program on regional children's channels or blocks, either dubbed into the local language or broadcast in the original English. Since the 2010 acquisition by Saban Brands, international television distribution rights for Power Rangers have been managed by MarVista Entertainment.[44][45][46]\\r\\n\\r\\nBroadcast in East Asian territories has been treated differently from in other international markets due to the prevalence and familiarity of 'the Super Sentai brand originating in Japan. Power Rangers was briefly banned in Malaysia for supposedly encouraging the use of drugs because it contained the word \\"Morphin'\\" in its title, which could be associated with morphine. The show eventually aired without the offending word.[47] In Japan, many Power Rangers television seasons and movies were dubbed into Japanese for television and video with the voice actors often pulled from past Super Sentai casts, leading to the English-dubbed action sequences being \\"re-dubbed\\" or \\"restored\\" back to Japanese as well. Power Rangers Mystic Force is the latest season to be broadcast in Japan on Toei Channel in January 2014, with the Magiranger cast voicing their counterparts. After broadcast of Power Rangers ended in South Korea with Wild Force, Bandai of Korea started airing dubbed Super Sentai series under the ????? (Power Ranger) brand on JEI TV. Some seasons of Super Sentai broadcast in South Korea have similarly named titles as their American counterparts, such as Power Ranger Dino Thunder[48] for Abaranger in 2007 and Power Ranger S.P.D.[49] in place of Dekaranger.\\r\\n\\r\\nAs of  October?2009[update], 33 Power Rangers DVD collections have been released in the United States:\\r\\n\\r\\nInternationally, additional DVD releases have occurred (such as Lightspeed Rescue, Time Force and Wild Force in Germany) and as free DVDs attached to the Jetix magazine, published in the UK. Mighty Morphin Power Rangers Season 1, Season 2, and Season 3, Power Rangers Zeo, Power Rangers Turbo, and Power Rangers In Space have been released in Germany as well in both English and German, with Power Rangers Lost Galaxy only in German.[56][57][58][59][60][61][62] Additionally, Ninja Storm, Dino Thunder, S.P.D., Mystic Force, and Operation Overdrive saw complete boxset releases in the UK.[63][64][65][66][67] In France, Mighty Morphin Season 1 and Season 2 have been released in their entirety in 5 episode DVD volumes, and the first 25 episodes of Season 3 were released in May 2008.[68] In Italy, Mighty Morphin, Zeo, Dino Thunder and S.P.D. have appeared in their entirety. Zeo and S.P.D. were made available as commercial DVDs, while Mighty Morphin and Dino Thunder were issued as bi-weekly volumes at newsstands.\\r\\n\\r\\nThe iTunes Store previously made Power Rangers episodes available: part of Mighty Morphin Power Rangers, all of Power Rangers S.P.D., and the first 26 episodes of Power Rangers Mystic Force. Subsequent seasons and episodes of the program also made their appearances in the iTunes Store, but as of  July?2009[update], Turbo: A Power Rangers Movie is the only Power Rangers film available. In 2012, Mighty Morphin Power Rangers Season 1 volumes 1 & 2 were released on iTunes to coincide with the DVD releases. As of February 2013, all 3 seasons of MMPR were released on iTunes.\\r\\n\\r\\nOn June 15, 2011, all episodes of Power Rangers from Mighty Morphin Power Rangers Season 1 to Mighty Morphin Power Rangers re-version were made available for instant streaming on Netflix.[69] As of 2018, all seasons through Ninja Steel have been made available on Netflix.\\r\\n\\r\\nOn March 12, 2012, Shout! Factory announced a home video distribution deal with Saban, which includes the first 17 series of Power Rangers. Shout! Factory released the first seven seasons on DVD in August 2012,[70] seasons 8-12 on November 2013,[71] a 20-year collection on December 2013,[72] and seasons 13-17 on April 2014.[73]\\r\\n\\r\\nOn March 22, 2012 Lionsgate Home Entertainment reached a home media distribution deal with Saban to release Power Rangers Samurai to DVD and Blu-ray.[74]\\r\\n\\r\\nAs of  April?2015[update], all series through Super Megaforce are available on the iTunes Store.\\r\\n\\r\\nAs of  2016[update], Dino Charge became available on iTunes.\\r\\n\\r\\nOn February 15, 2018, Saban Brands announced that their 25-year partnership with Bandai will end in 2019.[75] The next day, it was confirmed that Hasbro will be the new \\"global master toy licensee\\" for the franchise starting in April 2019, with a future option for Hasbro to buy the entire franchise.[76]\\r\\n\\r\\nPower Rangers has had several series of comics over the years.\\r\\n\\r\\nIn 2015, Boom Studios won the Power Rangers comics license, which brought a lot of award-winning publications.","input":"How many variations of power rangers are there?"},{"output":"After a very long exposure in the camera (traditionally said to be eight hours, but now believed to be several days)","context":"The history of photography has roots in remote antiquity with the discovery of two critical principles, that of the camera obscura (darkened or obscured room or chamber) and the fact that some substances are visibly altered by exposure to light, as discovered by observation. As far as is known, nobody thought of bringing these two phenomena together to capture camera images in permanent form until around 1800, when Thomas Wedgwood made the first reliably documented, although unsuccessful attempt. In the mid-1820s, Nicphore Nipce succeeded, but several days of exposure in the camera were required and the earliest results were very crude.\\r\\nNipce's associate Louis Daguerre went on to develop the daguerreotype process, the first publicly announced and commercially viable photographic process. The daguerreotype required only minutes of exposure in the camera, and produced clear, finely detailed results. It was commercially introduced in 1839, a date generally accepted as the birth year of practical photography.[1][2] The metal-based daguerreotype process soon had some competition from the paper-based calotype negative and salt print processes invented by William Henry Fox Talbot. Subsequent innovations made photography easier and more versatile. New materials reduced the required camera exposure time from minutes to seconds, and eventually to a small fraction of a second; new photographic media were more economical, sensitive or convenient, including roll films for casual use by amateurs. In the mid-20th century, developments made it possible for amateurs to take pictures in natural color as well as in black-and-white.\\r\\nThe commercial introduction of computer-based electronic digital cameras in the 1990s soon revolutionized photography. During the first decade of the 21st century, traditional film-based photochemical methods were increasingly marginalized as the practical advantages of the new technology became widely appreciated and the image quality of moderately priced digital cameras was continually improved.\\r\\n\\r\\n\\r\\nThe coining of the word \\"photography\\" is usually attributed to Sir John Herschel in 1839. It is based on the Greek ?? (phs), (genitive: pht܇s) meaning \\"light\\", and ϫ? (graph), meaning \\"drawing, writing\\", together meaning \\"drawing with light\\".[3]\\r\\nA natural phenomenon, known as camera obscura or pinhole image, can project an image through a small opening onto an opposite surface. This principle may have been known and used in prehistoric times. The earliest known written record of the camera obscura is to be found in Chinese writings called Mozi, dated to the 4th century BCE. Since circa 1550 the use of a lens in the opening of a wall or closed window shutter of a darkened room has been practiced. Around the same time the camera obscura was described as a drawing aid by Giambattista della Porta. Portable camerae obscurae were commonly used as drawing aids since the 17th century - first as a tent, later as boxes. The box type camera obscura was the basis for the earliest photographic cameras when photography was developed in the early 19th century.\\r\\nDaniel Barbaro described a diaphragm in 1568.[citation needed]\\r\\nThe Shroud of Turin contains an image that resembles a sepia photographic negative, that is much clearer when it is converted to a positive image. It has been suggested that this could mean that some type of photographic technology was applied before 1357, when the shroud first appeared in historical records and supported by radiocarbon dating tests placing it between 1260 and 1390.[4] The actual method that resulted in this image has not yet been conclusively identified. No other examples of detailed negative images from before 1800 are known.[citation needed]\\r\\nAlbertus Magnus (1193/1206ÿ80) discovered silver nitrate, and Georges Fabricius (1516ÿ71) discovered silver chloride. Wilhelm Homberg described how light darkened some chemicals (photochemical effect) in 1694. Johann Kaspar Lavater invented an apparatus to capture silhouettes by the end of the eighteenth century.[5]\\r\\nThe early science fiction novel Giphantie[6] (1760) by the French Tiphaigne de la Roche described something quite similar to photography:\\"They coat a piece of canvas with this material, and place it in front of the object to capture. The first effect of this cloth is similar to that of a mirror, but by means of its viscous nature the prepared canvas, as is not the case with the mirror, retains a facsimile of the image. The mirror represents images faithfully, but retains none; our canvas reflects them no less faithfully, but retains them all. This impression of the image is instantaneous. The canvas is then removed and deposited in a dark place. An hour later the impression is dry, and you have a picture the more precious in that no art can imitate its truthfulness.\\"[7]\\r\\nIn 1614, Angelo Sala demonstrated that \\"powdered silver nitrate is blackened by the sun\\",[9] as was paper that was wrapped around it. This discovery of the sun's effect on powdered silver nitrate was not supported and was subsequently disregarded by then-respected scientists who said that his discovery \\"had no practical application.\\"\\r\\nAround 1717,[n 1] Johann Heinrich Schulze, a German professor of anatomy and physics, set down a bottle containing silver nitrate and chalk by the window and unintentionally in the path of incoming light from the sun. The mixture, unsurprisingly, turned dark. But what he noticed and found to be strange was that part of it remained white and formed a line across the bottle. He then observed a cord hanging down and going across in front of the window, which he found out to be the cause. On further examination, he found that the entire mixture inevitably reverted to its original white color. Experimenting further, Schulze succeeded in transferring words he pasted on the bottle printed into the substance.[10]\\r\\nDescribing his achievement, Schulze wrote that [t]he suns rays, where they hit the glass through the cut-out parts of the paper, wrote each word or sentence on the chalk precipitate so exactly and distinctly that many who were curious about the experiment but ignorant of its nature took occasion to attribute the thing to some sort of trick.[11] He put the silver nitrate in an oven, which had no effect on its color. This proved to him, definitively, that heat had not facilitated the transformation, as popularly suspected. Rather, it was the light.[11]\\r\\nIn 1777, the chemist Carl Wilhelm Scheele was studying the more intrinsically light-sensitive silver chloride and determined that light darkened it by disintegrating it into microscopic dark particles of metallic silver. Of greater potential usefulness, Scheele found that ammonia dissolved the silver chloride but not the dark particles. This discovery, which could have been used to stabilize or \\"fix\\" a camera image captured with silver chloride, was little-noticed at the time and unknown to the earliest photography experimenters.\\r\\nIt was not until around the year 1800 that Thomas Wedgwood made the first known attempt to capture the image in a camera obscura by means of a light-sensitive substance. He used paper or white leather treated with silver nitrate. Although he succeeded in capturing the shadows of objects placed on the surface in direct sunlight, and even made shadow-copies of paintings on glass, it was reported in 1802 that \\"[t]he images formed by means of a camera obscura have been found too faint to produce, in any moderate time, an effect upon the nitrate of silver.\\" The shadow images eventually darkened all over because \\"[n]o attempts that have been made to prevent the uncoloured part of the copy or profile from being acted upon by light have as yet been successful.\\"[12] Wedgwood may have prematurely abandoned his experiments due to frail and failing health; he died aged 34 in 1805.\\r\\nIn 1816 Nicphore Nipce, using paper coated with silver chloride, succeeded in photographing the images formed in a small camera, but the photographs were negatives, darkest where the camera image was lightest and vice versa, and they were not permanent in the sense of being reasonably light-fast; like earlier experimenters, Nipce could find no way to prevent the coating from darkening all over when it was exposed to light for viewing. Disenchanted with silver salts, he turned his attention to light-sensitive organic substances.[13]\\r\\nThe oldest surviving photograph of the image formed in a camera was created by Nipce in 1826 or 1827.[1] It was made on a polished sheet of pewter and the light-sensitive substance was a thin coating of bitumen, a naturally occurring petroleum tar, which was dissolved in lavender oil, applied to the surface of the pewter and allowed to dry before use.[15] After a very long exposure in the camera (traditionally said to be eight hours, but now believed to be several days),[16] the bitumen was sufficiently hardened in proportion to its exposure to light that the unhardened part could be removed with a solvent, leaving a positive image with the light areas represented by hardened bitumen and the dark areas by bare pewter.[15] To see the image plainly, the plate had to be lit and viewed in such a way that the bare metal appeared dark and the bitumen relatively light.[13]\\r\\nIn partnership, Nipce in Chalon-sur-Sa?ne and Louis Daguerre in Paris refined the bitumen process,[17] substituting a more sensitive resin and a very different post-exposure treatment that yielded higher-quality and more easily viewed images. Exposure times in the camera, although substantially reduced, were still measured in hours.[13]\\r\\nNipce died suddenly in 1833, leaving his notes to Daguerre. More interested in silver-based processes than Nipce had been, Daguerre experimented with photographing camera images directly onto a mirror-like silver-surfaced plate that had been fumed with iodine vapor, which reacted with the silver to form a coating of silver iodide. As with the bitumen process, the result appeared as a positive when it was suitably lit and viewed. Exposure times were still impractically long until Daguerre made the pivotal discovery that an invisibly slight or \\"latent\\" image produced on such a plate by a much shorter exposure could be \\"developed\\" to full visibility by mercury fumes. This brought the required exposure time down to a few minutes under optimum conditions. A strong hot solution of common salt served to stabilize or fix the image by removing the remaining silver iodide. On 7 January 1839, this first complete practical photographic process was announced at a meeting of the French Academy of Sciences,[18] and the news quickly spread.[19] At first, all details of the process were withheld and specimens were shown only at Daguerre's studio, under his close supervision, to Academy members and other distinguished guests.[20] Arrangements were made for the French government to buy the rights in exchange for pensions for Nipce's son and Daguerre and present the invention to the world (with the exception of Great Britain, where an agent for Daguerre patented it) as a free gift.[21] Complete instructions were made public on 19 August 1839.[22] Known as the Daguerreotype process, it was the most common commercial process until the late 1850s. It was superseded by the collodion process.\\r\\nAfter reading early reports of Daguerre's invention, Henry Fox Talbot, who had succeeded in creating stabilized photographic negatives on paper in 1835, worked on perfecting his own process. In early 1839, he acquired a key improvement, an effective fixer, from his friend John Herschel, a polymath scientist who had previously shown that hyposulfite of soda (commonly called \\"hypo\\" and now known formally as sodium thiosulfate) would dissolve silver salts.[23] News of this solvent also benefited Daguerre, who soon adopted it as a more efficient alternative to his original hot salt water method.[24]\\r\\nTalbot's early silver chloride \\"sensitive paper\\" experiments required camera exposures of an hour or more. In 1840, Talbot invented the calotype process, which, like Daguerre's process, used the principle of chemical development of a faint or invisible \\"latent\\" image to reduce the exposure time to a few minutes. Paper with a coating of silver iodide was exposed in the camera and developed into a translucent negative image. Unlike a daguerreotype, which could only be copied by rephotographing it with a camera, a calotype negative could be used to make a large number of positive prints by simple contact printing. The calotype had yet another distinction compared to other early photographic processes, in that the finished product lacked fine clarity due to its translucent paper negative. This was seen as a positive attribute for portraits because it softened the appearance of the human face[citation needed]. Talbot patented this process,[25] which greatly limited its adoption, and spent many years pressing lawsuits against alleged infringers. He attempted to enforce a very broad interpretation of his patent, earning himself the ill will of photographers who were using the related glass-based processes later introduced by other inventors, but he was eventually defeated. Nonetheless, Talbot's developed-out silver halide negative process is the basic technology used by chemical film cameras today. Hippolyte Bayard had also developed a method of photography but delayed announcing it, and so was not recognized as its inventor.\\r\\nIn 1839, John Herschel made the first glass negative, but his process was difficult to reproduce. Slovene Janez Puhar invented a process for making photographs on glass in 1841; it was recognized on June 17, 1852 in Paris by the Acadmie Nationale Agricole, Manufacturire et Commerciale.[26] In 1847, Nicephore Nipce's cousin, the chemist Nipce St. Victor, published his invention of a process for making glass plates with an albumen emulsion; the Langenheim brothers of Philadelphia and John Whipple and William Breed Jones of Boston also invented workable negative-on-glass processes in the mid-1840s.[27]\\r\\nIn 1851 Frederick Scott Archer invented the collodion process.[28] Photographer and children's author Lewis Carroll used this process. (Carroll refers to the process as \\"Tablotype\\" [sic] in the story \\"A Photographer's Day Out\\")[29]\\r\\nHerbert Bowyer Berkeley experimented with his own version of collodion emulsions after Samman[disambiguation needed] introduced the idea of adding dithionite to the pyrogallol developer.[citation needed] Berkeley discovered that with his own addition of sulfite, to absorb the sulfur dioxide given off by the chemical dithionite in the developer, that dithionite was not required in the developing process. In 1881 he published his discovery. Berkeley's formula contained pyrogallol, sulfite and citric acid. Ammonia was added just before use to make the formula alkaline. The new formula was sold by the Platinotype Company in London as Sulpho-Pyrogallol Developer.[30]\\r\\nNineteenth-century experimentation with photographic processes frequently became proprietary.The German-born, New Orleans photographer Theodore Lilienthal successfully sought legal redress in an 1881 infringement case involving his \\"Lambert Process\\" in the Eastern District of Louisiana.\\r\\nThe daguerreotype proved popular in response to the demand for portraiture that emerged from the middle classes during the Industrial Revolution.[citation needed] This demand, which could not be met in volume and in cost by oil painting, added to the push for the development of photography.\\r\\nRoger Fenton and Philip Henry Delamotte helped popularize the new way of recording events, the first by his Crimean war pictures, the second by his record of the disassembly and reconstruction of The Crystal Palace in London. Other mid-nineteenth-century photographers established the medium as a more precise means than engraving or lithography of making a record of landscapes and architecture: for example, Robert Macpherson's broad range of photographs of Rome, the interior of the Vatican, and the surrounding countryside became a sophisticated tourist's visual record of his own travels.\\r\\nIn America, by 1851 a broadside by daguerreotypist Augustus Washington was advertising prices ranging from 50 cents to $10.[31] However, daguerreotypes were fragile and difficult to copy. Photographers encouraged chemists to refine the process of making many copies cheaply, which eventually led them back to Talbot's process.\\r\\nUltimately, the photographic process came about from a series of refinements and improvements in the first 20 years. In 1884 George Eastman, of Rochester, New York, developed dry gel on paper, or film, to replace the photographic plate so that a photographer no longer needed to carry boxes of plates and toxic chemicals around. In July 1888 Eastman's Kodak camera went on the market with the slogan \\"You press the button, we do the rest\\". Now anyone could take a photograph and leave the complex parts of the process to others, and photography became available for the mass-market in 1901 with the introduction of the Kodak Brownie.\\r\\nA practical means of color photography was sought from the very beginning. Results were demonstrated by Edmond Becquerel as early as 1848, but exposures lasting for hours or days were required and the captured colors were so light-sensitive they would only bear very brief inspection in dim light.\\r\\nThe first durable color photograph was a set of three black-and-white photographs taken through red, green, and blue color filters and shown superimposed by using three projectors with similar filters. It was taken by Thomas Sutton in 1861 for use in a lecture by the Scottish physicist James Clerk Maxwell, who had proposed the method in 1855.[32] The photographic emulsions then in use were insensitive to most of the spectrum, so the result was very imperfect and the demonstration was soon forgotten. Maxwell's method is now most widely known through the early 20th century work of Sergei Prokudin-Gorskii. It was made practical by Hermann Wilhelm Vogel's 1873 discovery of a way to make emulsions sensitive to the rest of the spectrum, gradually introduced into commercial use beginning in the mid-1880s.\\r\\nTwo French inventors, Louis Ducos du Hauron and Charles Cros, working unknown to each other during the 1860s, famously unveiled their nearly identical ideas on the same day in 1869. Included were methods for viewing a set of three color-filtered black-and-white photographs in color without having to project them, and for using them to make full-color prints on paper.[33]\\r\\nThe first widely used method of color photography was the Autochrome plate, a process inventors and brothers Auguste and Louis Lumire began working on in the 1890s and commercially introduced in 1907.[34] It was based on one of Louis Ducos du Hauron's ideas: instead of taking three separate photographs through color filters, take one through a mosaic of tiny color filters overlaid on the emulsion and view the results through an identical mosaic. If the individual filter elements were small enough, the three primary colors of red, blue, and green would blend together in the eye and produce the same additive color synthesis as the filtered projection of three separate photographs.\\r\\nAutochrome plates had an integral mosaic filter layer with roughly five million previously dyed potato grains per square inch added to the surface. Then through the use of a rolling press, five tons of pressure were used to flatten the grains, enabling every one of them to capture and absorb color and their microscopic size allowing the illusion that the colors are merged together. The final step was adding a coat of the light capturing substance silver bromide after which a color image could be imprinted and developed. In order to see it, reversal processing was used to develop each plate into a transparent positive that could be viewed directly or projected with an ordinary projector. One of the drawbacks of the technology is an exposure time of at least a second was required during the day in bright light and the worse the light is, the time required quickly goes up. An indoor portrait required a few minutes with the subject not being able to move or else the picture would come out blurry. This was because the grains absorbed the color fairly slowly and that a filter of a yellowish-orange color was added to the plate to keep the photograph from coming out excessively blue. Although necessary, the filter had the effect of reducing the amount of light that was absorbed. Another drawback was that the film could only be enlarged so much until the many dots that make up the image become apparent.[34][35]\\r\\nCompeting screen plate products soon appeared and film-based versions were eventually made. All were expensive and until the 1930s none was \\"fast\\" enough for hand-held snapshot-taking, so they mostly served a niche market of affluent advanced amateurs.\\r\\nA new era in color photography began with the introduction of Kodachrome film, available for 16?mm home movies in 1935 and 35?mm slides in 1936. It captured the red, green, and blue color components in three layers of emulsion. A complex processing operation produced complementary cyan, magenta, and yellow dye images in those layers, resulting in a subtractive color image. Maxwell's method of taking three separate filtered black-and-white photographs continued to serve special purposes into the 1950s and beyond, and Polachrome, an \\"instant\\" slide film that used the Autochrome's additive principle, was available until 2003, but the few color print and slide films still being made in 2015 all use the multilayer emulsion approach pioneered by Kodachrome.\\r\\nIn 1957, a team led by Russell A. Kirsch at the National Institute of Standards and Technology developed a binary digital version of an existing technology, the wirephoto drum scanner, so that alphanumeric characters, diagrams, photographs and other graphics could be transferred into digital computer memory. One of the first photographs scanned was a picture of Kirsch's infant son Walden. The resolution was 176x176 pixels with only one bit per pixel, i.e., stark black and white with no intermediate gray tones, but by combining multiple scans of the photograph done with different black-white threshold settings, grayscale information could also be acquired.[36]\\r\\nThe charge-coupled device (CCD) is the image-capturing optoelectronic component in first-generation digital cameras. It was invented in 1969 by Willard Boyle and George E. Smith at AT&T Bell Labs as a memory device. The lab was working on the Picturephone and on the development of semiconductor bubble memory. Merging these two initiatives, Boyle and Smith conceived of the design of what they termed \\"Charge 'Bubble' Devices\\". The essence of the design was the ability to transfer charge along the surface of a semiconductor. It was Dr. Michael Tompsett from Bell Labs however, who discovered that the CCD could be used as an imaging sensor. The CCD has increasingly been replaced by the active pixel sensor (APS), commonly used in cell phone cameras. These mobile phone cameras are used by billions of people worldwide, dramatically increasing photographic activity and material and also fueling citizen journalism.\\r\\nThe web has been a popular medium for storing and sharing photos ever since the first photograph was published on the web by Tim Berners-Lee in 1992 (an image of the CERN house band Les Horribles Cernettes). Today sites and apps such as Flickr, Picasa, Instagram, Imgur and PhotoBucket are used by many millions of people to share their pictures.","input":"How long did it take to take a photo in the 1800s?"},{"output":"Iowa City","context":"","input":"What was the capital of iowa before des moines?"},{"output":"December 27, 1971","context":"The Arizona Coyotes are a professional ice hockey team based in the Phoenix suburb of Glendale, Arizona. They are members of the Pacific Division of the Western Conference of the National Hockey League (NHL). The team's primary owner is Andrew Barroway. The Coyotes first played at America West Arena in downtown Phoenix, before moving to Glendale's Gila River Arena in 2003.\\r\\nThe Coyotes were founded on December 27, 1971, as the Winnipeg Jets of the World Hockey Association (WHA). After the WHA had ceased operations, they were one of four franchises absorbed into the National Hockey League and then granted membership on June 22, 1979. The Jets moved to Phoenix on July 1, 1996, and were renamed the Phoenix Coyotes. The NHL took ownership of the Phoenix Coyotes franchise in 2009 after owner Jerry Moyes turned it over to the league after declaring bankruptcy. Spending several years finding prospective owners who would not move the franchise out of Metro Phoenix, the NHL completed the sale of the Coyotes to IceArizona Acquisition Co., LLC. on August 5, 2013.[3]\\r\\nOn June 27, 2014, the team changed its geographic name from \\"Phoenix\\" to \\"Arizona\\", and modified its secondary logo.[4] On June 26, 2015, the team introduced updated jerseys for the 2015ÿ16 NHL season.\\r\\n\\r\\n\\r\\nThe team began play as the Winnipeg Jets, one of the founding franchises in the World Hockey Association (WHA). The Jets were the most successful team in the short-lived WHA, winning the Avco World Trophy, the league's championship trophy, three times and making the finals five out of the WHA's seven seasons. It then became one of the four teams admitted to the NHL as part of a merger when the financially struggling WHA folded in 1979.\\r\\nHowever, the club was never able to translate its WHA success into the NHL after the merger. The merger's terms allowed the established NHL teams to reclaim most of the players that had jumped to the upstart league, and the Jets lost most of their best players in the ensuing reclamation draft. As a result, they finished last in the NHL during their first two seasons, including a nine-win season in 1980ÿ81 that is still the worst in franchise history. They recovered fairly quickly, however, making the playoffs 11 times in the next 15 seasons. However, the Jets only won two playoff series, largely due to being in the same division as the powerful Edmonton Oilers and Calgary Flames. Because of the way the playoffs were structured for much of their Winnipeg run, the team was all but assured of having to defeat either the Oilers or the Flames (or both) to reach the Conference Finals. In 1984ÿ85, for instance, they finished with the fifth-best record in the league, only to be bounced by the Oilers in the division finals. Two years later, they dispatched the Flames in the first round, only to be eliminated again by the Oilers in the division finals. The franchise would not win another playoff series for 25 years.\\r\\nThe Jets ran into financial trouble when player salaries began spiraling up in the 1990s; this hit the Canadian teams particularly hard. Winnipeg was the second-smallest market in the NHL for most of the Jets' existence, and after the Quebec Nordiques moved to Denver in 1995 to become the Colorado Avalanche, it became the smallest market. In addition, the club's home arena, Winnipeg Arena, was one of the smallest in the league. Despite strong fan support, several attempts to keep the team in Winnipeg fell through. In December 1995, Jerry Colangelo, owner of the National Basketball Association's Phoenix Suns, Phoenix businessmen Steven Gluckstern and Richard Burke, and a local investor group, bought the team with plans to move it to Phoenix for the 1996ÿ97 season. After the franchise considered \\"Mustangs,\\" \\"Outlaws,\\" \\"Wranglers\\" and \\"Freeze,\\" a name-the-team contest yielded the nickname \\"Coyotes\\", which finished ahead of the second-place \\"Scorpions\\".[5]\\r\\nIn the summer that the move took place, Jets star Alexei Zhamnov left the team, while the team added established superstar Jeremy Roenick from the Chicago Blackhawks. Roenick teamed up with power wingers Keith Tkachuk and Rick Tocchet to form a dynamic 1ÿ2ÿ3 offensive punch that led the Coyotes through their first years in Arizona. Also impressive were young players like Shane Doan (he would also be the last remaining player from the team's days in Winnipeg), Oleg Tverdovsky and goaltender Nikolai Khabibulin, whom the fans nicknamed the \\"Bulin Wall.\\"\\r\\nAnother key addition to the squad was veteran forward Mike Gartner, who had come over from the Toronto Maple Leafs. Despite his experience and scoring his 700th career goal on December 15, 1997, Gartner battled injuries in the latter half of the 1997ÿ98 season. The Coyotes did not renew his contract, and he retired at the end of the season. After arriving in Phoenix, the team posted six consecutive .500 or better seasons, making the playoffs in every year but one. The one time they didn't make the playoffs, in 2000ÿ01, they became the first team to earn 90 points and miss the playoffs.\\r\\nThe Coyotes' original home, America West Arena, was suboptimal for hockey. Although considered a state-of-the-art arena when built for the Phoenix Suns, unlike most modern arenas, it was not designed with a hockey rink in mind. The floor was just barely large enough to fit a standard NHL rink, forcing the Coyotes to hastily re-engineer it to accommodate the 200-foot rink. The configuration left a portion of one end of the upper deck hanging over the boards and ice, obscuring almost a third of the rink and one goal from several sections. As a result, listed capacity had to be cut down from over 18,000 seats to just over 16,000 ÿ the second-smallest in the league at the time ÿ after the first season.\\r\\nRichard Burke bought out Steven Gluckstern in 1998, but was unable to attract more investors to alleviate the team's financial woes (see below). In 2001, Burke sold the team to Phoenix-area developer Steve Ellman, with Wayne Gretzky as a part-owner and head of hockey operations.\\r\\nThe closest that they came to advancing past the first round during their first decade in Arizona was during the 1999 playoffs. After building a 3ÿ1 series lead, The Coyotes would fall in overtime of Game 7 on a goal by Pierre Turgeon of the St. Louis Blues. In 2002, the Coyotes posted 95 points, one point behind their best total as an NHL team while in Winnipeg, but went down rather meekly to the San Jose Sharks in five games.\\r\\nFrom then until the 2007ÿ08 season, the Coyotes were barely competitive and managed to break the 80-point barrier only once during that time. Attendance levels dropped considerably, worrying many league executives. In addition, an unfavorable arena lease at city-owned America West Arena had the team suffering massive losses[6] (as much as $40?million a year at one point[7]); the Coyotes have yet to really recover from the resulting financial problems.\\r\\nThe team moved into Glendale Arena (now known as Gila River Arena) about 2? months into the 2003ÿ04 NHL season. Ellman put forward numerous proposals to improve the hockey sight lines in America West Arena in hopes of boosting capacity back over the 17,000 mark. However, none of these got beyond the planning stages, leading Ellman to commit to building a new arena. Simultaneously, the team changed its logo and uniforms, moving from the multi-colored kit to a more streamlined look. In 2005, Ellman sold the Coyotes, the National Lacrosse League's Arizona Sting and the lease to Gila River Arena to trucking magnate Jerry Moyes, who is also a part-owner of Major League Baseball's Arizona Diamondbacks.\\r\\nOn August 6, 2005, Brett Hull, son of former Jet Bobby Hull, was signed and promptly assigned the elder Hull's retired No. 9. Two days later, Gretzky named himself head coach, replacing Rick Bowness, despite the fact that he had never coached at any level of hockey. The Coyotes \\"Ring of Honor\\" was unveiled on October 8, inducting Gretzky (who had never played for the organization) and Bobby Hull. Only a week later, Brett Hull announced his retirement. On January 21, 2006, Jets great Thomas Steen was the third inductee to the \\"Ring of Honor.\\"\\r\\nAnother moment in a series of bad luck: the Coyotes were planning to host the 2006 NHL All-Star Game, but the event was canceled because of the 2006 Winter Olympics. The team returned to Winnipeg on September 17, 2006, to play a pre-season game against the Edmonton Oilers, but were shut-out 5ÿ0 before a sellout crowd of 15,015.\\r\\nOn April 11, 2007, CEO Jeff Shumway announced that General Manager Michael Barnett (Gretzky's agent for over 20 years), senior executive vice president of hockey operations Cliff Fletcher and San Antonio Rampage's general manager and Coyotes' assistant general manager Laurence Gilman \\"have been relieved of their duties.\\" The Coyotes finished the 2006ÿ2007 season 31ÿ46ÿ5, their worst record since relocating to Phoenix.[8]\\r\\nOn May 29, 2007, Jeff Shumway announced that Don Maloney had agreed to a multi-year contract to become general manager of the Coyotes. As per club policy, terms of the contract were not disclosed.[9] However, as has been the case with all general managers since 2001, Maloney serves in an advisory role to Gretzky.\\r\\nThe 2007ÿ08 season was something of a resurgence for the Coyotes. After their disastrous 2006ÿ07 campaign, the Coyotes looked to rebuild the team by relying on their drafted talent such as Peter Mueller and Martin Hanzal to make the team successful as opposed to using free agency. The Coyotes also acquired Radim Vrbata from the Chicago Blackhawks for Kevyn Adams in an effort to provide the team with more offense. The team signed both Alex Auld and David Aebischer to compete for the starting goaltender position with Mikael Tellqvist acting as the backup goaltender. Neither Auld or Aebischer were able to hold on to the starting position, leaving the Coyotes to turn to the waiver wire for assistance. On November 17, 2007, the Coyotes were able to claim Ilya Bryzgalov off waivers from the Anaheim Ducks. Bryzgalov responded by not only starting in goal the day he was acquired, but posting a shutout in his Coyotes debut against the Los Angeles Kings. Bryzgalov was soon given a three-year contract extension because of his high level of play. Despite predictions of another disastrous season, the Coyotes played competitive hockey for most of the season. However, they finished eight points short of the last playoff spot, with 83 points.\\r\\nOn September 24, 2009, Dave Tippett took over coaching duties of the Phoenix Coyotes after Wayne Gretzky stepped down hours before. In just 61 games, Tippett led the Coyotes to more wins in their 2009ÿ10 regular season (37) than their previous season (36), en route to the first 50-win season in the franchise's NHL history.\\r\\nOn March 27, 2010, the Coyotes clinched a playoff spot, their first playoff spot since the 2001ÿ02 season, and in the process, reached the 100-point mark for the first time ever as an NHL team, and the first time overall since the 1977ÿ78 (WHA) Jets scored 102 points.[10] They finished with 107 points, the highest point total in the franchise's 38-year history. This was good enough for fourth overall in the league, tying the 1984ÿ85 Jets for the franchise's highest finish as an NHL team. They also qualified for the fourth seed in the Western Conference, giving them home-ice advantage in the first round for the first time since 1985.\\r\\nTheir first round opponent in the 2010 Stanley Cup playoffs was the Detroit Red Wings. Game 1 of the series was the first NHL playoff game to be played in Gila River Arena. However, an injury to Shane Doan sidelined him for most of the series, and the veteran Red Wings defeated the Coyotes in seven games.\\r\\nIn the following year, the Coyotes played the Detroit Red Wings for the second straight postseason, in the first round of the 2011 Stanley Cup playoffs. The Coyotes were swept in four games.\\r\\nOn April 7, 2012, the Coyotes defeated the Minnesota Wild with a score of 4ÿ1 to win the Pacific Division titletheir first division title as an NHL team (in Winnipeg or Phoenix).[11] This gave them the third seed in the West, and with it home ice advantage in a playoff series for only the third time in franchise history. In the first round, they defeated the Chicago Blackhawks in six games, the franchise's first playoff series win since 1987. The first five games went to overtime, tying a record when the Montreal Canadiens and Toronto Maple Leafs did it in the 1951 Stanley Cup Final. They faced the Nashville Predators in the second round, winning the first two games and the series 4ÿ1. However, the Coyotes fell to the Los Angeles Kings in game five of a 4ÿ1 series.\\r\\nIn December 2008, the media became aware that the Coyotes were suffering massive losses, and the NHL was paying the team's bills. The media reports were minimized by NHL commissioner Gary Bettman and vice-president Bill Daly. However, Moyes had secretly given operational control of the team to the league. In May 2009, Moyes put the team into bankruptcy hours before Bettman was to present him an offer to sell the team to Chicago Bulls and Chicago White Sox owner Jerry Reinsdorf. Moyes intended to sell the team to Canadian billionaire Jim Balsillie who intended to purchase the team out of bankruptcy and move it to Hamilton, Ontario. The NHL responded by stripping Moyes of his remaining ownership authority.\\r\\nFrom May until September 2009, hearings were held in Phoenix bankruptcy court to determine the fate of the Coyotes and the holding company. Two potential bidders for the team surfaced, Reinsdorf and Ice Edge Holdings. but they did not submit a bid for the team at the bankruptcy hearing. Instead, the NHL put in the only rival bid to Balsillie for the team, while it contended the Moyes-Balsillie deal violated NHL rules. The bankruptcy court voided the planned sale to Balsillie, accepting the league's argument that bankruptcy could not be used to circumvent league rules. The NHL's bid was also declared insufficient, but the judge left the window open to an improved bid. Moyes and the NHL settled, with the NHL buying the team and assuming all debts. The NHL negotiated a temporary lease with the city of Glendale, which owns Gila River Arena.\\r\\nThe NHL then negotiated with the Reinsdorf and Ice Edge to work out a deal with Glendale. Ice Edge signed a letter of intent to buy the team from the NHL, while Reinsdorf had won the approval of the City of Glendale. On Friday, May 7, 2010, ESPN.com reported that Reinsdorf bid had fallen apart, and the City of Glendale was working with Ice Edge to buy the team in a last-ditch effort to keep them in Arizona. The National Post criticized both bids, as they were conditional on municipal taxpayers covering any losses that the Coyotes might incur, and suggested that keeping the team in Phoenix was never economically viable.[12]\\r\\nIn July 2010, the Ice Edge bid collapsed, as it did not satisfy Glendale's financial conditions. Ice Edge decided to concentrate on an effort to buy a minor league team. The City of Glendale had to step in and guarantee the team's losses for 2010ÿ11 as a precondition of the NHL not transferring the franchise. A consortium of investors led by Chicago investor Matt Hulsizer then reached a deal to purchase the Coyotes from the NHL along with a lease agreement with Glendale. However, the Hulsizer deal collapsed in late June 2011 at least in part due to a threatened suit by the Goldwater Institute over the legality of payments Glendale would make to Hulsizer prior to the consortium buying the team. The threat of the suit may have prevented the sale of bonds to finance the payments. The team only stayed in the Phoenix area for the 2011ÿ12 season after another $25?million payment by the city of Glendale.\\r\\nThe 2012ÿ13 NHL lockout provided another opportunity for the Coyotes to find a potential owner and avoid relocation while the league suspended team operations during the labor dispute. A deal to former San Jose Sharks owner Greg Jamison had been drafted just as the lockout ended, but failed to be finalized and fulfilled by January 31, 2013. The deal would have kept the Coyotes in Phoenix for the next 20 years relying on a tax payer subsidy, according to the agreement. It would also have had \\"Phoenix\\" dropped from the name and instead use the more inclusive term \\"Arizona.\\"[13]\\r\\nCalifornia investment executive Darin Pastor also submitted a bid to buy the Coyotes. His bid proposed to keep the team in the Glendale area while engaging young hockey players in the region through school partnerships and scholarship efforts.[14] The NHL rejected Pastor's bid on May 13, 2013, citing the bid was \\"inconsistent with what we had previously indicated were the minimum prerequisites\\" of a bid.[15]\\r\\nDue to the team's bankruptcy status since 2009 and the annual revenue lost each year, the NHL planned to move the Coyotes should a deal with the city for a new lease and new ownership not be decided by July 2, 2013. The plan was to move the franchise to a new city, likely Seattle.[16] On July 2, 2013, by a vote of 4ÿ3, the Glendale City Council approved a 15-year lease agreement with Renaissance Sports and Entertainment (RSE), who would purchase the team from the NHL for US$225?million by August 5, 2013.[17] The members of the Canadian group are Executive Chairman & Governor George Gosbee, President, CEO & Alternate Governor Anthony LeBlanc, Alternate Governor Craig Stewart, and Directors Gary J. Drummond, W. David Duckett, William \\"Bill\\" Dutton, Robert Gwin, Scott Saxberg and Richard Walter. RSE partnered with Global Spectrum (owners of the Philadelphia Flyers) for help in managing Gila River Arena. The agreement has the city of Glendale giving RSE US$15?million per year for management fees. There is an agreement that RSE can move the team after five years, if it accrues $50?million US in losses.[17]\\r\\nOn January 29, 2014, the new ownership group announced that the team would change its name to the \\"Arizona Coyotes\\" for the 2014ÿ15 season. According to Coyotes President Anthony LeBlanc, the change is being made to reflect that the team is no longer located within Phoenix city limits and to include all hockey fans in the state of Arizona. Aside from a new shoulder patch, the team's uniform design will not change.[18] The Coyotes played their final game under the Phoenix moniker with a 2ÿ1 victory over the Dallas Stars on April 13, 2014. In front of 15,146 fans, David Moss scored the final goal in Phoenix Coyotes history with 2:31 left in the regulation time.[19]\\r\\nFollowing the conclusion of the 2013ÿ14 season, it was reported that due to lackluster revenue from parking and non-hockey events, the City of Glendale would recoup just $4.4?million, which was significantly less than the $6.8?million the city expected to receive back from source including parking receipts, ticket sales and naming rights for the arena.[20]\\r\\nOn June 4, 2014, it was reported that a Scottsdale, Arizona, public-relations firm had sued IceArizona, the owner of the Phoenix Coyotes, alleging that the NHL club had reneged on a sponsorship deal worth nearly $250,000. A Coyotes' spokesman responded to this issue by calling it a \\"quarter-million-dollar scheme.\\"[21] By October, IceArizona entered a deal to sell 51% of the Coyotes to Philadelphia-based hedge fund manager Andrew Barroway who had recently failed in his attempt to purchase the New York Islanders.[22] The deal was approved by the NHL Board of Governors on December 31, 2014.[23]\\r\\nDuring the 2014ÿ15 season, the team finished last in the Pacific Division with the second-worst record in the NHL. On June 10, 2015 the Glendale, Arizona city council voted to terminate its 15-year, $225?million agreement with the Coyotes. \\"The city claimed it was entitled to terminate the agreement because two former city employees, Craig Tindall and Julie Frisoni, were involved in securing the deal and later worked for the Coyotes.\\"[24] On July 23, 2015, it was announced that the Coyotes and Glendale City Council had agreed on a resolution.[25][26] On July 24, 2015, the Coyotes announced that Glendale City Council had enacted a two-year deal.[27]\\r\\nAt the conclusion of the 2015ÿ16 season, General Manager Don Maloney was relieved of his duties after eight seasons and one GM of the Year award.[28] The Coyotes replaced Maloney as general manager with John Chayka, who became the NHL's youngest GM, being promoted from his position as assistant general manager/analytics within the Coyotes staff.[29] In August 2016, Dawn Braid was hired as the Arizona Coyotes' skating coach, making her the first female full-time coach in the NHL.[30]\\r\\nOn November 14, 2016, the Coyotes announced plans to build a new arena in Tempe, Arizona, which was scheduled to be completed for the 2019ÿ20 NHL season. The project would have included an adjoining 4,000-seat arena that would be used for Coyotes practices and as the home for the Arizona State University men's hockey team.[31][32] However, the arena project was withdrawn when ASU pulled out of the deal in February 2017.[33]\\r\\nAt the end of the 2016ÿ17 season, Barroway bought out the rest of the IceArizona ownership group and became the sole owner of the franchise. Following the transfer, former IceArizona CEO Anthony LeBlanc and the director of hockey operations Gary Drummond both left the organization.[34] On June 19, 2017, the Coyotes opted not to re-sign long time captain Shane Doan, who had been with the franchise since they were the Winnipeg Jets. The Coyotes left Doan[35] a standing offer to remain with the team in a non-playing role. On June 22, 2017, head coach Dave Tippett would also leave his positions within the Coyotes after eight seasons,[36] and would be succeeded by Rick Tocchet on July 11, 2017.[37]\\r\\nWith the relocation program, a (public) team naming voting process was being held, with \\"Coyotes\\" defeating \\"Scorpions\\" amongst the finalists. Both coyotes and scorpions are inhabitants of the Sonoran Desert, and the owners/supporters of the club wanted the team name to be an animal that was representative of the region.[38] On June 27, 2014, the team changed its geographic name from \\"Phoenix\\" to \\"Arizona\\".[4]\\r\\nUpon their arrival in Phoenix in 1996, the team adopted a look with a strong Southwestern flavor. The primary logo was a stylized hockey stick-wielding coyote in a kachina-inspired style. The jerseys featured pointed green shoulders with brick red trim over a white (home) or black (road) body, and non-traditional striping patterns. These uniforms remained in place until 2003. A third jersey, primarily green with a nighttime desert landscape wrapped around the bottom and the cuffs of the sleeves, was introduced in 1998, and retired in 2003 when the team redesigned the uniforms.\\r\\nAs the NHL switched home and road jerseys beginning in the 2003ÿ04 season, and coinciding with the team's move from America West Arena to the newly completed Glendale Arena, the Coyotes redesigned their look completely, adopting the current howling coyote head logo, while dropping several colors from the team's palette. Sedona red and white became the primary colors, with desert sand and black remaining as logo trim colors. A variation of these colors was later used for the Major League Baseball team Arizona Diamondbacks. The uniform's simplified two-color scheme with three stripes on each sleeve and the tail bears some resemblance to later versions of the Montreal Maroons jerseys. The team also changed its shoulder patch, taking the form of the outline of the state of Arizona, with an homage to the state flag and the abbreviation \\"PHX\\". This logo was worn only on the right shoulder leaving the left shoulder bare.\\r\\nThe Coyotes updated their jerseys for the 2007ÿ08 season, along with all NHL teams, as part of the switchover to Rbk Edge jerseys. The changes made were adding an NHL crest just below the neck opening, removing the stripes that were previously just above the lower hem, and moving the \\"PHX\\" patch from the right to the left shoulder. The white jersey also gained red shoulder coloring and laces at the collar. The three-stripe pattern is applied to the side of the pants.\\r\\nThe Coyotes also added a third jersey for the 2008ÿ09 season. It is primarily black and features a new alternate coyote logo on the front, with the primary logo (coyote head) patch on the right shoulder, and the \\"Official Seal\\" on the left.[39] Since white does not appear on the alternate, solid red pant shells are worn with this jersey.\\r\\nBefore the 2014ÿ15 season, it was announced that the Coyotes' third jersey would no longer be used. The patch on the home and away jerseys that used to read \\"PHX\\" would also be changed to read \\"AZ\\" to comply with the team's rebranded name.[4]\\r\\nOn June 26, 2015, the Coyotes introduced updated jerseys. As described by an official press release, \\"The body of the Coyotes home and away jerseys remains unchanged but the new jerseys feature an original sleeve stripe designed to connect with Arizona's distinctive striated landscape. These bold sleeves, along with a striking black pant, will be worn both at home in Glendale and on the road. The new red jersey shoulder patch features a coyote's paw \\"A\\" mark, an icon built for Arizona's hockey fans; while the white jersey shoulder will carry an updated \\"AZ\\" mark, connecting back to the new word mark. Finally, a uniquely Southwestern pattern in the jersey's neckline connects the Coyotes to the legacy of Arizona. This updated uniform features Reebok's latest technological innovations and represents an industry leading commitment to the best for the athlete.\\"[40]\\r\\nHowler is the coyote-suited mascot of the Arizona Coyotes. He was introduced on October 15, 2005. The Coyotes' official kids club is called Howler's Kids Club.[41] Howler wears number 96 on his jersey, representing the year the Winnipeg Jets moved to Arizona, and wears a \\"M\\" Designation for Mascot. He is known to beat on a bucket to encourage the fans to cheer, and has many different outfits in games.\\r\\nThis is a partial list of the last five seasons completed by the Coyotes. For the full season-by-season history, see List of Arizona Coyotes seasons.\\r\\nNote: GP = Games played, W = Wins, L = Losses, OTL = Overtime Losses, Pts = Points, GF = Goals for, GA = Goals against\\r\\nRecords as of April 11, 2016.\\r\\nUpdated March 20, 2018.[42][43]\\r\\n\\r\\nThe Coyotes owner Andrew Barroway stated that the Arizona Coyotes want to retire Shane Doans number at a time that is right for him [44]\\r\\nNote: This list does not include selections of the Winnipeg Jets.\\r\\nNote: This list includes scoring of the original Winnipeg Jets, including WHA seasons.\\r\\nThese are the top-ten point-scorers in team history. Figures are updated after each completed NHL regular season.\\r\\nNote: Pos = Position; GP = Games Played; G = Goals; A = Assists; Pts = Points; P/G = Points per game\\r\\nJack Adams Award\\r\\nKing Clancy Memorial Trophy\\r\\nMark Messier Leadership Award\\r\\nNote: This list does not include seasons of the 1972ÿ1996 Winnipeg Jets.\\r\\nIn the NHL, each team may select a captain. Along with the two alternate captains, they have the \\"privilege of discussing with the referee any questions relating to interpretation of rules which may arise during the progress of a game\\".[49][50] Captains are required to wear the letter \\"C\\" on their uniform for identification, which is 3 inches (7.6?cm) high.[49]\\r\\nNote: This list does not include captains from the Winnipeg Jets (NHL & WHA).\\r\\n[51]\\r\\nOnly includes staff part of the Hockey Operations side. This list does not include staff on the business side.","input":"When did the arizona coyotes become a team?"},{"output":"Danny Thomas","context":"St. Jude Children's Research Hospital, founded in 1962, is a pediatric treatment and research facility focused on children's catastrophic diseases, particularly leukemia and other cancers. The hospital costs about $2.4 million a day to run, and there is no cost to the patient to be treated.[1] It is located in Memphis, Tennessee, and is a nonprofit medical corporation designated as a 501(c)(3) tax-exempt organization by the Internal Revenue Service.[2]\\r\\n\\r\\nSt. Jude was founded by entertainer Danny Thomas in 1962, with help from Lemuel Diggs and close friend, Miami, Florida, automobile dealer Anthony Abraham, on the premise that \\"no child should die in the dawn of life\\".[3] This idea resulted from a promise that Thomas, a Maronite Catholic, had made to a saint years before the hospital was founded. Thomas was a comedian who was struggling to get a break in his career and living paycheck to paycheck. When his first child was about to be born, he attended Mass in Detroit and put his last $7.00 in the offering bin. He prayed to St. Jude Thaddeus for a means to provide for his family, and about a week later, he obtained a gig that paid 10 times what he had put in the offering bin. After that time, Thomas believed in the power of prayer.  He promised St. Jude Thaddeus that if he made him successful, he would one day build him a shrine. Years later, Thomas became an extremely successful comedian and built St. Jude Childrens Research Hospital as a shrine to St. Jude Thaddeus to honor his promise.[4]\\r\\n\\r\\nIn 1957, Thomas founded the American Lebanese Syrian Associated Charities (ALSAC), which helped him realize his dream. ALSAC is also the fundraising organization of St. Jude. Since St. Jude opened its doors in 1962, ALSAC has had the responsibility of raising the necessary funds to keep the hospital open.  Memphis was chosen at the suggestion of Roman Catholic Cardinal Samuel Stritch, a Tennessee native who had been a spiritual advisor to Thomas since he presided at Thomas's confirmation in Thomas's boyhood home of Toledo, Ohio.[5][6]\\r\\n\\r\\nAlthough it was named after Thomas's patron saint, St. Jude is not a Catholic hospital and is not affiliated with any religious organization.[7]\\r\\n\\r\\nIn late 2007, the Chili's Care Center opened on the St. Jude campus. Chili's restaurant chain has pledged to provide $50 million to fund the construction of the center. The seven-story Chili's Care Center will house 340,000 square feet (32,000?m2) and will add 24 labs and 16 beds to the campus. It will house the department of radiological services, The Pediatric Brain Tumor Consortium, two floors of outpatient clinics, one floor of inpatient clinics and rooms, two floors of laboratory space, an office floor and an unfinished level for future expansion.\\r\\n\\r\\nIn June 2008, Sterling Jewelers and St. Jude officially opened the new Kay Kafe (named after one of Sterling's jewelery chains), featuring a spacious lounge area, a significantly larger dining area and a variety of new dining options. More than ever, the cafeteria is the focal point of the campus where families and staff can escape and relax away from the treatment areas. The grand opening ceremony featured Marlo Thomas, national outreach director for St. Jude; Tony Thomas, member of the ALSAC/St. Jude Boards of Directors and Governors; Terry Burman, chairman of Sterling; Mark Light, CEO and president of Sterling; John P. Moses, CEO of ALSAC, the fundraising organization for St. Jude; Dr. William E. Evans, CEO of St. Jude; Joyce Aboussie, chair of the ALSAC Board of Directors, and Robert Breit, chair of the St. Jude Board of Governors.[8]\\r\\n\\r\\nIn 2014, the Marlo Thomas Center for Global Education and Collaboration was opened as part of the hospital.[9]\\r\\n\\r\\nDiscoveries at St. Jude have profoundly changed how doctors treat children with cancer and other catastrophic illnesses.[10][11] Since St. Jude was established, the survival rate for acute lymphoblastic leukemia, the most common type of childhood cancer, has increased from 4 percent in 1962 to 94 percent today.[11] During this time, the overall survival rate for childhood cancers has risen from 20 percent to 80 percent.[12] St. Jude has treated children from across the United States and from more than 70 countries. Doctors across the world consult with St. Jude on their toughest cases.[13] Also, St. Jude has an International Outreach Program to improve the survival rates of children with catastrophic illnesses worldwide through the transfer of knowledge, technology and organizational skills.[14]\\r\\n\\r\\nDonald Pinkel was the first director of St. Jude and served from 1962 until 1973. His successor, Alvin Mauer, was director from 1973 to 1983. Joseph Simone was the hospital's third director from 1983 to 1992. Arthur W. Nienhuis was CEO and director of St. Jude from 1993 until 2004. William E. Evans, the hospital's fifth director, served from 2004 to 2014. He was succeeded by current CEO and director James R. Downing on July 15, 2014.\\r\\n\\r\\nAs of  2018[update], St. Jude's scientific director was James I. Morgan, Ph.D.[15]\\r\\n\\r\\nSt. Jude's board of directors is chaired by Camille F. Sarrouf Jr. and includes Joyce Aboussie, Ruth Gaviria and Tony Thomas (producer).\\r\\n\\r\\nSt. Jude and over 46 of its staff members have been the recipients of numerous exemplary awards and achievements. For example, in 2010 St. Jude Children's Research Hospital was named the number one children's cancer hospital in the U.S by U.S. News & World Report.[16] It has also been named one of the top 10 companies to work for in academia by The Scientist for 7 successive years.[17] Most notably, Peter C. Doherty, Ph.D., of St. Jude Children's Research Hospital was co-recipient of the 1996 Nobel Prize in Physiology or Medicine for work related to how the immune system kills virus-infected cells.\\r\\n\\r\\nSt. Jude is associated with several affiliated hospitals in the United States to further its efforts beyond its own physical walls. The hospital uses its Domestic Affiliates Program to form this partnership with the other pediatric programs. This program is a network of hematology clinics, hospitals, and universities that are united under the mission of St. Jude.\\r\\n\\r\\nThese sites are used as a means of referring eligible patients to St. Jude as well as a location to administer some care. Through the Domestic Affiliates Program staff at St. Jude work together and collaborate with those at the other institutions. Affiliated sites are expected to comply with standards set by St. Jude and are audited to ensure proper and quality care.[18]\\r\\n\\r\\nCurrently the Domestic Affiliate Clinic sites include:\\r\\n\\r\\nSt. Jude also works closely with Le Bonheur Children's Medical Center, also located in downtown Memphis.  St. Jude patients needing certain procedures, such as brain surgery, may undergo procedures at LeBonheur Hospital.  Both St. Jude and Le Bonheur are teaching hospitals affiliated with the University of Tennessee Health Science Center. University of Tennessee physicians training in pediatrics, surgery, radiology, and other specialties undergo service rotations at St. Jude Hospital.\\r\\n\\r\\nThe Children's Cancer Center of Lebanon was established in Beirut on April 12, 2002. The center is an affiliate of St. Jude Children's Research Hospital and works in association with the American University of Beirut Medical Center (AUBMC).[20]\\r\\n\\r\\nA commitment has been made to establish a US$412 million research facility in Memphis, Tennessee, one purpose of which will be to serve as a collaborative hub.[15]\\r\\n\\r\\nFunding for St. Jude comes from many sources, including government grants and insurance recoveries, but the principal source of funding (64% average over the past seven years) is from the American Lebanese Syrian Associated Charities (ALSAC) - a semi-independent entity that raises funds using the name of St. Jude.[21] Of a dollar donated to the American Lebanese Syrian Associated Charities, about $0.52  makes its way through to St. Jude Children's Research Hospital (averaged over seven years).[21]\\r\\n\\r\\nAll medically eligible patients who are accepted for treatment at St. Jude are treated without regard to the family's ability to pay. St. Jude is one of a few pediatric research organizations in the United States where families never pay for treatments that are not covered by insurance, and families without insurance are never asked to pay. In addition to providing medical services to eligible patients, St. Jude also assists families with transportation, lodging, and meals. Three separate specially-designed patient housing facilities Tri Delta Place for short-term (up to one week), Ronald McDonald House for medium-term (one week to 3 months), and Target House for long-term (3 months or more)provide housing for patients and up to three family members, with no cost to the patient. These policies, along with research expenses and other costs, cause the hospital to incur more than $2.4 million in operating costs each day.[22]\\r\\n\\r\\nFrom 2000 to 2005, 83.7% of every dollar received by St. Jude went to the current or future needs of St. Jude. In 2002 to 2004, 47% of program expenses went to patient care and 41% to research.[23] As of 2012, 81 cents of every dollar donated to St. Jude goes directly to its research and treatment.[12]\\r\\n\\r\\nTo cover operating costs, ALSAC conducts many fund-raising events and activities. The FedEx St. Jude Classic, a PGA Tour event, is one of the most visible fund-raising events for the hospital. Other fund-raising programs include the St. Jude Math-A-Thon, Up 'til Dawn, direct mailings, radiothons and television marketing.\\r\\n\\r\\nSt. Jude also has a merchandise catalog called the Hope Catalog. The catalog contains everything from shirts to office items, and from patient art to \\"Give Thanks\\" wristbands.\\r\\n\\r\\nIn November 2004, St. Jude launched its inaugural Thanks and Giving campaign which encourages consumers to help raise funds at participating retailers by adding a donation at checkout or by purchasing specialty items to benefit St. Jude. The campaign is supported by network television spots, advertisements in major publications, interactive marketing on Yahoo! and a movie trailer that runs on 20,000 screens nationwide, runs from Thanksgiving until the New Year. The campaign was created by St. Jude National Outreach Director Marlo Thomas and her siblings Terre Thomas and Tony Thomas, children of hospital founder Danny Thomas. Customers nationwide are asked to help raise funds at participating retailers by adding a donation at check out or by purchasing specialty items to benefit St. Jude.\\r\\n\\r\\nCorporations such as Target, Best Buy, Domino's Pizza, the Williams-Sonoma family of brands, CVS/pharmacy, Kmart, Kay Jewelers, New York & Company, 7-Eleven, Inc., American Airlines, American Kiosk Management, AutoZone, Brooks Brothers, Busch Gardens, Catherines, Diane von Frstenberg, Dollar General, DXL Group, Easy Spirit, General Nutrition Centers, Gymboree, HSN, J. P. Morgan Chase, Marshall's, Alor, The Melting Pot, Memphis Grizzlies (NBA), Nine West, Rochester, Sag Harbor, Saks Fifth Avenue, SeaWorld, St. Louis Rams (NFL), West Elm, Westfield Shoppingtowns, and Yahoo! give customers a host of opportunities to support St. Jude.[24] The ultimate goal is to increase awareness with the hope that people will come to identify Thanksgiving with St. Jude, said Joyce Aboussie, vice chairwoman of the nonprofits board.[25] The official kick-off event for the Thanks and Giving campaign is the Give Thanks Walk. This event is a noncompetitive 5K that is now held in 75 cities across the country. Those participating in the race are encouraged to form teams, invite family and friends, and raise money for St. Jude. These walks have raised over $11 million to date.[26]\\r\\n\\r\\nOne of the hospital's most recent and successful fund-raising efforts has been the Dream Home Giveaway.\\"About St. Jude Dream Home Giveaway\\". St. Jude Children's Research Hospital. Retrieved January 29, 2008.? The giveaway allows contest entrants to reserve tickets for $100 each to qualify to win homes valued between $300,000 and $600,000. The Dream Home Giveaway, one of the largest national fund-raising programs, is conducted in cities across the United States.\\r\\n\\r\\nMany high schools around the country are creating student-led and student-run organizations called Team Up for St. Jude. These programs consist of high school students putting on events that raise funds and awareness for St. Jude while showing their school spirit. One of the main events is a letter writing campaign in which the students are sent pre-written letters that include stories of a patient and ask for donations. The high school students often have a \\"letter writing party\\" to address and send the letters to their family and friends asking them to support St. Jude.[27] \\r\\nHoover High School (Hoover, AL) has a program that has brought in many fundraising ideas including \\"Team Up Week\\" which consists of prize wheels, inflatables, karaoke, cake walk, etc. to raise funds and awareness for the hospital.[28] Though this program is done on a much a smaller scale than the college program Up 'til Dawn, it has the potential to grow and increase awareness.\\r\\n\\r\\nAt various college campuses, some student organizations, fraternities and sororities raise funds in a program called Up 'til Dawn[29]\\r\\nPhi Mu Delta National Fraternity is partnered with St. Jude Children's Research Hospital. The fraternity's second core belief, \\"I Believe in Service... service to the college; service to every group organized for the common good; service to the individual. I believe in service defined in the terms of voluntary sacrifice for the welfare of those with whom I come in contact.\\" has helped shape many young men of admirable quality and exceptional character towards a dedication to St. Jude and other equally important causes.[30]\\r\\nTau Kappa Epsilon (TKE) Fraternity partnered with St. Jude in the 1970s and 1980s to help raise money to fight childhood cancer. The fraternity renewed its link to St. Jude as its philanthropy of emphasis in 2008.[31][32]\\r\\n\\r\\nSt. Jude is an International Philanthropic Project of Epsilon Sigma Alpha International, a co-ed service sorority. As of April 2013, ESA has raised more than $160 million in cash and pledges for St. Jude.[33][34]\\r\\n\\r\\nIn 1999, the Delta Delta Delta collegiate sorority formed a philanthropic partnership with St. Jude.[35] Tri Delta supports St. Jude nationally and supports cancer charities at a local level.[36]  At the hospital in Memphis, the sorority donated the Teen Room for teenage patients to relax and spend time with each other. In July 2010, Tri Delta completed its \\"10 by 10\\" goal, raising over $10 million in less than four years, six years short of the original goal. Those funds were used to sponsor the Tri Delta Patient Care Floor in the Chilis Care Center. Upon completion of the \\"10 by 10\\" campaign, the sorority announced a new fundraising goal of $15 million in 5 years to name the Specialty Clinic located in the Patient Care Center.[37] Three and a half years later, Delta Delta Delta had raised $15 million and completed its goal ahead of schedule.[38] In July 2014, the on-campus residence center was renamed Tri Delta Place as a result of Tri Delta's pledge of $60 Million in 10 years.[39]\\r\\n\\r\\nIn July 2005, Kappa Alpha Psi (ʽ) fraternity announced St. Jude Childrens Research Hospital as its national philanthropic partner. Since that time, members across the country have joined in the fight against pediatric cancer, sickle cell disease, and other catastrophic illnesses. Kappa Alpha Psi has answered the call to service by raising more than $400,000representing the largest contribution that Kappa Alpha Psi has donated to any charity. Members of Kappa Alpha Psi have committed to raise $500,000 in support of the hospitals sickle cell program. St. Jude has one of the largest pediatric sickle cell research and treatment programs in the world. St. Jude is the first known hospital in the world to cure sickle cell disease through bone marrow transplantation. Today, bone marrow transplantation still offers the only cure for sickle cell disease. Members of Kappa Alpha Psi reach out to churches in their local communities to host a Sunday of Hope each January in support of St. Jude. January was selected because this is the month of Kappas founding. During the Sunday of Hope, churches will take up a special offering in honor of the patients and families of St. Jude. At the 2008 ALSAC/St. Jude Board and Awards Dinner, Kappa Alpha Psi received the Volunteer Group of the Year Award for their efforts in the inaugural year of the Sunday of Hope program which secured more than 130 churches to participate and raised more than $280,000.[40]\\r\\n\\r\\nLambda Theta Alpha sorority serves thousands of hours each year to a variety of philanthropic causes and needs. In the effort to create a more united and bigger impact nationally, Lambda Theta Alpha selected a national philanthropy. In January 2010, LTA became an official collegiate partner to St. Jude Children's Research Hospital, becoming the first individual Latino Greek organization to commit fully to the hospital's efforts. With this partnership, LTA provides our resources of community service and activism and more importantly, another direct link to the Hispanic community for St. Jude. LTA has pledged to raise awareness about childhood cancer and St. Jude in the Latin community, as well as fundraise for the hospital through a variety of events and programs.[41][42]\\r\\n\\r\\nPast events have included: sporting tournaments, charity galas, informational meetings, and much more.[42]\\r\\n\\r\\nAnother successful event is the Country Cares for St. Jude Kids radio-thon. During these events, country radio stations around the country allow those touched by St. Jude to share stories with listeners, highlighting patient stories, and having exciting promotions. Listeners are encouraged to call in and become a Partner In Hope by making either a one-time or monthly donation to the hospital. The 200 stations involved have helped raise over $400 million since 1989. Country artists have also supported St. Jude through concerts, hospital visits, call-ins, and other forms of support.[43]\\r\\n\\r\\nEagles for St. Jude is a program created during Stanford Financial Groups inaugural sponsorship year of the Stanford St. Jude Championship out of the desire to provide a season-long fundraising component to the Memphis PGA tournament.\\r\\n\\r\\nIn 1995, St. Jude received an anonymous letter postmarked in Dallas, Texas, containing a $1 million winning McDonald's Monopoly game piece.  McDonald's officials came to the hospital, accompanied by a representative from the accounting firm Arthur Andersen,  and verified it as a winner.[44] Although game rules prohibited the transfer of prizes, McDonald's waived the rule and has made the annual $50,000 annuity payments, even after learning that the piece was sent by an individual involved in an embezzlement scheme intended to defraud McDonald's.[45]\\r\\n\\r\\nSt. Jude Childrens Research celebrity visitors are individuals that are in the entertainment industry who visit the children in the hospital. Over the years, many celebrities such as musicians, political figures, actors and others have become involved with this foundation. Hollywood actors visit the hospital to meet some of the kids and try to get involved. Other celebrities have filmed commercials to encourage individuals to donate to St. Jude. Some of the most recognized celebrities that have visited St. Jude to see the effort going on daily in order to combat catastrophic illnesses are:[46]","input":"Who started st jude's children's hospital?"},{"output":"20.95% oxygen","context":"The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. The atmosphere of Earth protects life on Earth by creating pressure allowing for liquid water to exist on the Earth's surface, absorbing ultraviolet solar radiation, warming the surface through heat retention (greenhouse effect), and reducing temperature extremes between day and night (the diurnal temperature variation).\\r\\nBy volume, dry air contains 78.09% nitrogen, 20.95% oxygen,[2] 0.93% argon, 0.04% carbon dioxide, and small amounts of other gases. Air also contains a variable amount of water vapor, on average around 1% at sea level, and 0.4% over the entire atmosphere. Air content and atmospheric pressure vary at different layers, and air suitable for use in photosynthesis by terrestrial plants and breathing of terrestrial animals is found only in Earth's troposphere and in artificial atmospheres.\\r\\nThe atmosphere has a mass of about 5.15G1018?kg,[3] three quarters of which is within about 11?km (6.8?mi; 36,000?ft) of the surface. The atmosphere becomes thinner and thinner with increasing altitude, with no definite boundary between the atmosphere and outer space. The Krmn line, at 100?km (62?mi), or 1.57% of Earth's radius, is often used as the border between the atmosphere and outer space. Atmospheric effects become noticeable during atmospheric reentry of spacecraft at an altitude of around 120?km (75?mi). Several layers can be distinguished in the atmosphere, based on characteristics such as temperature and composition.\\r\\nThe study of Earth's atmosphere and its processes is called atmospheric science (aerology). Early pioneers in the field include Lon Teisserenc de Bort and Richard Assmann.[4]\\r\\n\\r\\n\\r\\nThe three major constituents of Earth's atmosphere, are nitrogen, oxygen, and argon. Water vapor accounts for roughly 0.25% of the atmosphere by mass. The concentration of water vapor (a greenhouse gas) varies significantly from around 10 ppm by volume in the coldest portions of the atmosphere to as much as 5% by volume in hot, humid air masses, and concentrations of other atmospheric gases are typically quoted in terms of dry air (without water vapor).[5] The remaining gases are often referred to as trace gases,[6] among which are the greenhouse gases, principally carbon dioxide, methane, nitrous oxide, and ozone. Filtered air includes trace amounts of many other chemical compounds. Many substances of natural origin may be present in locally and seasonally variable small amounts as aerosols in an unfiltered air sample, including dust of mineral and organic composition, pollen and spores, sea spray, and volcanic ash. Various industrial pollutants also may be present as gases or aerosols, such as chlorine (elemental or in compounds), fluorine compounds and elemental mercury vapor. Sulfur compounds such as hydrogen sulfide and sulfur dioxide (SO2) may be derived from natural sources or from industrial air pollution.\\r\\n(A) volume fraction is equal to mole fraction for ideal gas only,\\r\\n????also see volume (thermodynamics)\\r\\n(B) ppmv: parts per million by volume\\r\\n(C) Water vapor is about 0.25% by mass over full atmosphere\\r\\n(D) Water vapor strongly varies locally[5]\\r\\nThe relative concentration of gasses remains constant until about 10,000?m (33,000?ft).[9]\\r\\nIn general, air pressure and density decrease with altitude in the atmosphere. However, temperature has a more complicated profile with altitude, and may remain relatively constant or even increase with altitude in some regions (see the temperature section, below). Because the general pattern of the temperature/altitude profile is constant and measurable by means of instrumented balloon soundings, the temperature behavior provides a useful metric to distinguish atmospheric layers. In this way, Earth's atmosphere can be divided (called atmospheric stratification) into five main layers. Excluding the exosphere, the atmosphere has four primary layers, which are the troposphere, stratosphere, mesosphere, and thermosphere.[10] From highest to lowest, the five main layers are:\\r\\nThe exosphere is the outermost layer of Earth's atmosphere (i.e. the upper limit of the atmosphere). It extends from the exobase, which is located at the top of the thermosphere at an altitude of about 700?km above sea level, to about 10,000?km (6,200?mi; 33,000,000?ft) where it merges into the solar wind.\\r\\nThis layer is mainly composed of extremely low densities of hydrogen, helium and several heavier molecules including nitrogen, oxygen and carbon dioxide closer to the exobase. The atoms and molecules are so far apart that they can travel hundreds of kilometers without colliding with one another. Thus, the exosphere no longer behaves like a gas, and the particles constantly escape into space. These free-moving particles follow ballistic trajectories and may migrate in and out of the magnetosphere or the solar wind.\\r\\nThe exosphere is located too far above Earth for any meteorological phenomena to be possible. However, the aurora borealis and aurora australis sometimes occur in the lower part of the exosphere, where they overlap into the thermosphere. The exosphere contains most of the satellites orbiting Earth.\\r\\nThe thermosphere is the second-highest layer of Earth's atmosphere. It extends from the mesopause (which separates it from the mesosphere) at an altitude of about 80?km (50?mi; 260,000?ft) up to the thermopause at an altitude range of 500ÿ1000?km (310ÿ620?mi; 1,600,000ÿ3,300,000?ft). The height of the thermopause varies considerably due to changes in solar activity.[11] Because the thermopause lies at the lower boundary of the exosphere, it is also referred to as the exobase. The lower part of the thermosphere, from 80 to 550 kilometres (50 to 342?mi) above Earth's surface, contains the ionosphere.\\r\\nThe temperature of the thermosphere gradually increases with height. Unlike the stratosphere beneath it, wherein a temperature inversion is due to the absorption of radiation by ozone, the inversion in the thermosphere occurs due to the extremely low density of its molecules. The temperature of this layer can rise as high as 1500?C (2700?F), though the gas molecules are so far apart that its temperature in the usual sense is not very meaningful. The air is so rarefied that an individual molecule (of oxygen, for example) travels an average of 1 kilometre (0.62?mi; 3300?ft) between collisions with other molecules.[13] Although the thermosphere has a high proportion of molecules with high energy, it would not feel hot to a human in direct contact, because its density is too low to conduct a significant amount of energy to or from the skin.\\r\\nThis layer is completely cloudless and free of water vapor. However, non-hydrometeorological phenomena such as the aurora borealis and aurora australis are occasionally seen in the thermosphere. The International Space Station orbits in this layer, between 350 and 420?km (220 and 260?mi).\\r\\nThe mesosphere is the third highest layer of Earth's atmosphere, occupying the region above the stratosphere and below the thermosphere. It extends from the stratopause at an altitude of about 50?km (31?mi; 160,000?ft) to the mesopause at 80ÿ85?km (50ÿ53?mi; 260,000ÿ280,000?ft) above sea level.\\r\\nTemperatures drop with increasing altitude to the mesopause that marks the top of this middle layer of the atmosphere. It is the coldest place on Earth and has an average temperature around ?85?C (?120?F; 190?K).[14][15]\\r\\nJust below the mesopause, the air is so cold that even the very scarce water vapor at this altitude can be sublimated into polar-mesospheric noctilucent clouds. These are the highest clouds in the atmosphere and may be visible to the naked eye if sunlight reflects off them about an hour or two after sunset or a similar length of time before sunrise. They are most readily visible when the Sun is around 4 to 16 degrees below the horizon. Lightning-induced discharges known as transient luminous events (TLEs) occasionally form in the mesosphere above tropospheric thunderclouds. The mesosphere is also the layer where most meteors burn up upon atmospheric entrance. It is too high above Earth to be accessible to jet-powered aircraft and balloons, and too low to permit orbital spacecraft. The mesosphere is mainly accessed by sounding rockets and rocket-powered aircraft.\\r\\nThe stratosphere is the second-lowest layer of Earth's atmosphere. It lies above the troposphere and is separated from it by the tropopause. This layer extends from the top of the troposphere at roughly 12?km (7.5?mi; 39,000?ft) above Earth's surface to the stratopause at an altitude of about 50 to 55?km (31 to 34?mi; 164,000 to 180,000?ft).\\r\\nThe atmospheric pressure at the top of the stratosphere is roughly 1/1000 the pressure at sea level. It contains the ozone layer, which is the part of Earth's atmosphere that contains relatively high concentrations of that gas. The stratosphere defines a layer in which temperatures rise with increasing altitude. This rise in temperature is caused by the absorption of ultraviolet radiation (UV) radiation from the Sun by the ozone layer, which restricts turbulence and mixing. Although the temperature may be ?60?C (?76?F; 210?K) at the tropopause, the top of the stratosphere is much warmer, and may be near 0?C.[16]\\r\\nThe stratospheric temperature profile creates very stable atmospheric conditions, so the stratosphere lacks the weather-producing air turbulence that is so prevalent in the troposphere. Consequently, the stratosphere is almost completely free of clouds and other forms of weather. However, polar stratospheric or nacreous clouds are occasionally seen in the lower part of this layer of the atmosphere where the air is coldest. The stratosphere is the highest layer that can be accessed by jet-powered aircraft.\\r\\nThe troposphere is the lowest layer of Earth's atmosphere. It extends from Earth's surface to an average height of about 12?km, although this altitude varies from about 9?km (30,000?ft) at the poles to 17?km (56,000?ft) at the equator,[12] with some variation due to weather. The troposphere is bounded above by the tropopause, a boundary marked in most places by a temperature inversion (i.e. a layer of relatively warm air above a colder one), and in others by a zone which is isothermal with height.[17][18]\\r\\nAlthough variations do occur, the temperature usually declines with increasing altitude in the troposphere because the troposphere is mostly heated through energy transfer from the surface. Thus, the lowest part of the troposphere (i.e. Earth's surface) is typically the warmest section of the troposphere. This promotes vertical mixing (hence the origin of its name in the Greek word ??, tropos, meaning \\"turn\\"). The troposphere contains roughly 80% of the mass of Earth's atmosphere.[19] The troposphere is denser than all its overlying atmospheric layers because a larger atmospheric weight sits on top of the troposphere and causes it to be most severely compressed. Fifty percent of the total mass of the atmosphere is located in the lower 5.6?km (18,000?ft) of the troposphere.\\r\\nNearly all atmospheric water vapor or moisture is found in the troposphere, so it is the layer where most of Earth's weather takes place. It has basically all the weather-associated cloud genus types generated by active wind circulation, although very tall cumulonimbus thunder clouds can penetrate the tropopause from below and rise into the lower part of the stratosphere. Most conventional aviation activity takes place in the troposphere, and it is the only layer that can be accessed by propeller-driven aircraft.\\r\\nWithin the five principal layers that are largely determined by temperature, several secondary layers may be distinguished by other properties:\\r\\nThe average temperature of the atmosphere at Earth's surface is 14?C (57?F; 287?K)[22] or 15?C (59?F; 288?K),[23] depending on the reference.[24][25][26]\\r\\nThe average atmospheric pressure at sea level is defined by the International Standard Atmosphere as 101325 pascals (760.00?Torr; 14.6959?psi; 760.00?mmHg). This is sometimes referred to as a unit of standard atmospheres (atm). Total atmospheric mass is 5.1480G1018 kg (1.135G1019 lb),[28] about 2.5% less than would be inferred from the average sea level pressure and Earth's area of 51007.2 megahectares, this portion being displaced by Earth's mountainous terrain. Atmospheric pressure is the total weight of the air above unit area at the point where the pressure is measured. Thus air pressure varies with location and weather.\\r\\nIf the entire mass of the atmosphere had a uniform density from sea level, it would terminate abruptly at an altitude of 8.50?km (27,900?ft). It actually decreases exponentially with altitude, dropping by half every 5.6?km (18,000?ft) or by a factor of 1/e every 7.64?km (25,100?ft), the average scale height of the atmosphere below 70?km (43?mi; 230,000?ft). However, the atmosphere is more accurately modeled with a customized equation for each layer that takes gradients of temperature, molecular composition, solar radiation and gravity into account.\\r\\nIn summary, the mass of Earth's atmosphere is distributed approximately as follows:[29]\\r\\nBy comparison, the summit of Mt. Everest is at 8,848?m (29,029?ft); commercial airliners typically cruise between 10?km (33,000?ft) and 13?km (43,000?ft) where the thinner air improves fuel economy; weather balloons reach 30.4?km (100,000?ft) and above; and the highest X-15 flight in 1963 reached 108.0?km (354,300?ft).\\r\\nEven above the Krmn line, significant atmospheric effects such as auroras still occur. Meteors begin to glow in this region, though the larger ones may not burn up until they penetrate more deeply. The various layers of Earth's ionosphere, important to HF radio propagation, begin below 100?km and extend beyond 500?km. By comparison, the International Space Station and Space Shuttle typically orbit at 350ÿ400?km, within the F-layer of the ionosphere where they encounter enough atmospheric drag to require reboosts every few months. Depending on solar activity, satellites can experience noticeable atmospheric drag at altitudes as high as 700ÿ800?km.\\r\\nThe division of the atmosphere into layers mostly by reference to temperature is discussed above. Temperature decreases with altitude starting at sea level, but variations in this trend begin above 11?km, where the temperature stabilizes through a large vertical distance through the rest of the troposphere. In the stratosphere, starting above about 20?km, the temperature increases with height, due to heating within the ozone layer caused by capture of significant ultraviolet radiation from the Sun by the dioxygen and ozone gas in this region. Still another region of increasing temperature with altitude occurs at very high altitudes, in the aptly-named thermosphere above 90?km.\\r\\nBecause in an ideal gas of constant composition the speed of sound depends only on temperature and not on the gas pressure or density, the speed of sound in the atmosphere with altitude takes on the form of the complicated temperature profile (see illustration to the right), and does not mirror altitudinal changes in density or pressure.\\r\\nThe density of air at sea level is about 1.2?kg/m3 (1.2?g/L, 0.0012 g/cm3). Density is not measured directly but is calculated from measurements of temperature, pressure and humidity using the equation of state for air (a form of the ideal gas law). Atmospheric density decreases as the altitude increases. This variation can be approximately modeled using the barometric formula. More sophisticated models are used to predict orbital decay of satellites.\\r\\nThe average mass of the atmosphere is about 5 quadrillion (5G1015) tonnes or 1/1,200,000 the mass of Earth. According to the American National Center for Atmospheric Research, \\"The total mean mass of the atmosphere is 5.1480G1018?kg with an annual range due to water vapor of 1.2 or 1.5G1015?kg, depending on whether surface pressure or water vapor data are used; somewhat smaller than the previous estimate. The mean mass of water vapor is estimated as 1.27G1016?kg and the dry air mass as 5.1352 I0.0003G1018?kg.\\"\\r\\nSolar radiation (or sunlight) is the energy Earth receives from the Sun. Earth also emits radiation back into space, but at longer wavelengths that we cannot see. Part of the incoming and emitted radiation is absorbed or reflected by the atmosphere. In May 2017, glints of light, seen as twinkling from an orbiting satellite a million miles away, were found to be reflected light from ice crystals in the atmosphere.[31][32]\\r\\nWhen light passes through Earth's atmosphere, photons interact with it through scattering. If the light does not interact with the atmosphere, it is called direct radiation and is what you see if you were to look directly at the Sun. Indirect radiation is light that has been scattered in the atmosphere. For example, on an overcast day when you cannot see your shadow there is no direct radiation reaching you, it has all been scattered. As another example, due to a phenomenon called Rayleigh scattering, shorter (blue) wavelengths scatter more easily than longer (red) wavelengths. This is why the sky looks blue; you are seeing scattered blue light. This is also why sunsets are red. Because the Sun is close to the horizon, the Sun's rays pass through more atmosphere than normal to reach your eye. Much of the blue light has been scattered out, leaving the red light in a sunset.\\r\\nDifferent molecules absorb different wavelengths of radiation. For example, O2 and O3 absorb almost all wavelengths shorter than 300 nanometers. Water (H2O) absorbs many wavelengths above 700?nm. When a molecule absorbs a photon, it increases the energy of the molecule. This heats the atmosphere, but the atmosphere also cools by emitting radiation, as discussed below.\\r\\nThe combined absorption spectra of the gases in the atmosphere leave \\"windows\\" of low opacity, allowing the transmission of only certain bands of light. The optical window runs from around 300?nm (ultraviolet-C) up into the range humans can see, the visible spectrum (commonly called light), at roughly 400ÿ700?nm and continues to the infrared to around 1100?nm. There are also infrared and radio windows that transmit some infrared and radio waves at longer wavelengths. For example, the radio window runs from about one centimeter to about eleven-meter waves.\\r\\nEmission is the opposite of absorption, it is when an object emits radiation. Objects tend to emit amounts and wavelengths of radiation depending on their \\"black body\\" emission curves, therefore hotter objects tend to emit more radiation, with shorter wavelengths. Colder objects emit less radiation, with longer wavelengths. For example, the Sun is approximately 6,000?K (5,730?C; 10,340?F), its radiation peaks near 500?nm, and is visible to the human eye. Earth is approximately 290?K (17?C; 62?F), so its radiation peaks near 10,000?nm, and is much too long to be visible to humans.\\r\\nBecause of its temperature, the atmosphere emits infrared radiation. For example, on clear nights Earth's surface cools down faster than on cloudy nights. This is because clouds (H2O) are strong absorbers and emitters of infrared radiation. This is also why it becomes colder at night at higher elevations.\\r\\nThe greenhouse effect is directly related to this absorption and emission effect. Some gases in the atmosphere absorb and emit infrared radiation, but do not interact with sunlight in the visible spectrum. Common examples of these are CO2 and H2O.\\r\\nThe refractive index of air is close to, but just greater than 1. Systematic variations in refractive index can lead to the bending of light rays over long optical paths. One example is that, under some circumstances, observers onboard ships can see other vessels just over the horizon because light is refracted in the same direction as the curvature of Earth's surface.\\r\\nThe refractive index of air depends on temperature,[33] giving rise to refraction effects when the temperature gradient is large. An example of such effects is the mirage.\\r\\nAtmospheric circulation is the large-scale movement of air through the troposphere, and the means (with ocean circulation) by which heat is distributed around Earth. The large-scale structure of the atmospheric circulation varies from year to year, but the basic structure remains fairly constant because it is determined by Earth's rotation rate and the difference in solar radiation between the equator and poles.\\r\\nThe first atmosphere consisted of gases in the solar nebula, primarily hydrogen. There were probably simple hydrides such as those now found in the gas giants (Jupiter and Saturn), notably water vapor, methane and ammonia.[34]\\r\\nOutgassing from volcanism, supplemented by gases produced during the late heavy bombardment of Earth by huge asteroids, produced the next atmosphere, consisting largely of nitrogen plus carbon dioxide and inert gases.[34] A major part of carbon-dioxide emissions dissolved in water and reacted with metals such as calcium and magnesium during weathering of crustal rocks to form carbonates that were deposited as sediments. Water-related sediments have been found that date from as early as 3.8 billion years ago.[35]\\r\\nAbout 3.4 billion years ago, nitrogen formed the major part of the then stable \\"second atmosphere\\". The influence of life has to be taken into account rather soon in the history of the atmosphere, because hints of early life-forms appear as early as 3.5 billion years ago.[36] How Earth at that time maintained a climate warm enough for liquid water and life, if the early Sun put out 30% lower solar radiance than today, is a puzzle known as the \\"faint young Sun paradox\\".\\r\\nThe geological record however shows a continuous relatively warm surface during the complete early temperature record of Earth ÿ with the exception of one cold glacial phase about 2.4 billion years ago. In the late Archean Eon an oxygen-containing atmosphere began to develop, apparently produced by photosynthesizing cyanobacteria (see Great Oxygenation Event), which have been found as stromatolite fossils from 2.7 billion years ago. The early basic carbon isotopy (isotope ratio proportions) strongly suggests conditions similar to the current, and that the fundamental features of the carbon cycle became established as early as 4 billion years ago.\\r\\nAncient sediments in the Gabon dating from between about 2,150 and 2,080 million years ago provide a record of Earth's dynamic oxygenation evolution. These fluctuations in oxygenation were likely driven by the Lomagundi carbon isotope excursion.[37]\\r\\nThe constant re-arrangement of continents by plate tectonics influences the long-term evolution of the atmosphere by transferring carbon dioxide to and from large continental carbonate stores. Free oxygen did not exist in the atmosphere until about 2.4 billion years ago during the Great Oxygenation Event and its appearance is indicated by the end of the banded iron formations.\\r\\nBefore this time, any oxygen produced by photosynthesis was consumed by oxidation of reduced materials, notably iron. Molecules of free oxygen did not start to accumulate in the atmosphere until the rate of production of oxygen began to exceed the availability of reducing materials that removed oxygen. This point signifies a shift from a reducing atmosphere to an oxidizing atmosphere. O2 showed major variations until reaching a steady state of more than 15% by the end of the Precambrian.[40] The following time span from 541 million years ago to the present day is the Phanerozoic Eon, during the earliest period of which, the Cambrian, oxygen-requiring metazoan life forms began to appear.\\r\\nThe amount of oxygen in the atmosphere has fluctuated over the last 600 million years, reaching a peak of about 30% around 280 million years ago, significantly higher than today's 21%. Two main processes govern changes in the atmosphere: Plants use carbon dioxide from the atmosphere, releasing oxygen. Breakdown of pyrite and volcanic eruptions release sulfur into the atmosphere, which oxidizes and hence reduces the amount of oxygen in the atmosphere. However, volcanic eruptions also release carbon dioxide, which plants can convert to oxygen. The exact cause of the variation of the amount of oxygen in the atmosphere is not known. Periods with much oxygen in the atmosphere are associated with rapid development of animals. Today's atmosphere contains 21% oxygen, which is great enough for this rapid development of animals.[41]\\r\\nAir pollution is the introduction into the atmosphere of chemicals, particulate matter or biological materials that cause harm or discomfort to organisms.[42] Stratospheric ozone depletion is caused by air pollution, chiefly from chlorofluorocarbons and other ozone-depleting substances.\\r\\nThe scientific consensus is that the anthropogenic greenhouse gases currently accumulating in the atmosphere are the main cause of global warming.[43]\\r\\nOn October 19, 2015 NASA started a website containing daily images of the full sunlit side of Earth on http://epic.gsfc.nasa.gov/. The images are taken from the Deep Space Climate Observatory (DSCOVR) and show Earth as it rotates during a day.[44]","input":"How much percentage of oxygen is in the air?"},{"output":"3 May 1921","context":"","input":"When did northern ireland and southern ireland separate?"},{"output":"Donald Trump","context":"","input":"Who was the 45th president of the us?"},{"output":"George Town","context":"\\r\\nCoordinates: 1930N 8030W? / ?19.500N 80.500W? / 19.500; -80.500\\r\\n\\r\\nThe Cayman Islands (/?ke?m?n/ or /ke??m?n/) is an autonomous British Overseas Territory in the western Caribbean Sea. The 264-square-kilometre (102-square-mile) territory comprises the three islands of Grand Cayman, Cayman Brac and Little Cayman, which are located to the south of Cuba and northeast of Honduras, between Jamaica and the Yucatn Peninsula. The total population of the three islands is approximately 60,765.[7] The capital city is George Town, situated on Grand Cayman.\\r\\n\\r\\nThe Cayman Islands is considered to be part of the geographic Western Caribbean Zone as well as the Greater Antilles. The territory is often considered a major world offshore financial haven for international businesses and many wealthy individuals.[8]\\r\\n\\r\\nThe Cayman Islands remained largely uninhabited until the 17th century. While there is no archaeological evidence for an indigenous people on the islands, a variety of settlers from various backgrounds made their home on the islands, including pirates, shipwrecked sailors, and deserters from Oliver Cromwell's army in Jamaica.[9] Folklore suggests that the emergence of the name Cayman is a result of a captives successful flee from Cromwells army. His name was Cayman Cushing, and he supposedly initiated the escape. It is believed that several other captives escaped to the islands alongside Cushing. As a result of his bravery, the runaway prisoners settled on what they called the Cayman Islands.[10]\\r\\n\\r\\nThe first recorded permanent inhabitant of the Cayman Islands, Isaac Bodden, was born on Grand Cayman around 1661. He was the grandson of the original settler named Bodden who was probably one of Oliver Cromwell's soldiers at the taking of Jamaica in 1655.[11]\\r\\n\\r\\nEngland took formal control of the Cayman Islands, along with Jamaica, as a result of the Treaty of Madrid of 1670. Following several unsuccessful attempts at settlement, a permanent English-speaking population in the islands dates from the 1730s. With settlement, after the first royal land grant by the Governor of Jamaica in 1734, came the perceived need for slaves.[12] Many were brought to the islands from Africa; this is evident today with the majority of native Caymanians being of African and English descent. The results of the first census taken in the islands in 1802 showed the population on Grand Cayman to be 933 with 545 of those inhabitants being enslaved. Slavery was abolished in the Cayman Islands in 1833. At the time of abolition, there were over 950 Blacks of African ancestry enslaved by 116 white families of English ancestry.[13]\\r\\n\\r\\nThe islands continued to be governed as part of the Colony of Jamaica until 1962, when they became a separate Crown colony while Jamaica became an independent Commonwealth realm.[14]\\r\\n\\r\\nOn 8 February 1794, the Caymanians rescued the crews of a group of ten merchant ships, including HMS Convert, an incident that has since become known as the Wreck of the Ten Sail. The ships had struck a reef and run aground during rough seas.[15] Legend has it that King George III rewarded the island with a promise never to introduce taxes as compensation for their generosity, as one of the ships carried a member of the King's own family. While this remains a popular legend, the story is not true.[16]\\r\\n\\r\\nThe Cayman Islands historically has been a tax-exempt destination. The government of the Cayman Islands has always relied on indirect and not direct taxes. The territory has never levied income tax, capital gains tax, or any wealth tax, making them a popular tax haven.[17]\\r\\n\\r\\nOn 11 September 2004 the island of Grand Cayman, which lies largely unprotected at sea level, was hit by Hurricane Ivan, creating an 8-ft (2.4?m) storm surge which flooded many areas of Grand Cayman. An estimated 83% of the dwellings on the island were damaged including 4% requiring complete reconstruction. A reported 70% of all dwellings suffered severe damage from flooding or wind. Another 26% sustained minor damage from partial roof removal, low levels of flooding, or impact with floating or wind driven hurricane debris.[18] Power, water and communications were disrupted for months in some areas as Ivan was the worst hurricane to hit the islands in 86 years.[19] Grand Cayman began a major rebuilding process and within two years its infrastructure was nearly returned to pre-hurricane status. Due to the tropical location of the islands, more hurricanes or tropical systems have affected the Cayman Islands than any other region in the Atlantic basin; it has been brushed or directly hit, on average, every 2.23 years.[20]\\r\\n\\r\\nThe islands are in the western Caribbean Sea and are the peaks of a massive underwater ridge, known as the Cayman Ridge (or Cayman Rise). This ridge flanks the Cayman Trough, 6,000?m (20,000?ft) deep[21] which lies 6?km (3.7?mi) to the south.[22] The islands lie in the northwest of the Caribbean Sea, east of Quintana Roo, Mexico and Yucatn State, Mexico, northeast of Costa Rica, north of Panama, south of Cuba and west of Jamaica. They are situated about 700?km (430?mi) south of Miami,[23] 750?km (470?mi) east of Mexico,[24] 366?km (227?mi) south of Cuba,[25] and about 500?km (310?mi) northwest of Jamaica.[26] Grand Cayman is by far the largest, with an area of 197?km2 (76?sq?mi).[27] Grand Cayman's two \\"sister islands\\", Cayman Brac and Little Cayman, are about 120?km (75?mi) east north-east of Grand Cayman and have areas of 38 and 28.5?km2 (14.7 and 11.0?sq?mi)[28] respectively.\\r\\n\\r\\nAll three islands were formed by large coral heads covering submerged ice age peaks of western extensions of the Cuban Sierra Maestra range and are mostly flat. One notable exception to this is The Bluff on Cayman Brac's eastern part, which rises to 43?m (141?ft) above sea level, the highest point on the islands.[29]\\r\\n\\r\\nTerrain is mostly a low-lying limestone base surrounded by coral reefs.\\r\\n\\r\\nThe mammalian species in the Cayman Islands include the introduced Central American agouti[30] and eight species of bats. At least three now extinct native rodent species were present up until the discovery of the islands by Europeans. Marine life around the island of the Grand Cayman includes tarpon, silversides (Atheriniformes), French angelfish (Pomacanthus paru), and giant barrel sponges. A number of cetaceans are found in offshore waters. These species include the goose-beaked whale (Ziphius cavirostris), Blainville's beaked whale (Mesoplodon densirostris) and sperm whale (Physeter macrocephalus).\\r\\n\\r\\nCayman avian fauna includes two endemic subspecies of Amazona parrots: Amazona leucocephala hesterna or Cuban amazon, presently restricted to the island of Cayman Brac, but formerly also on Little Cayman, and Amazona leucocephala caymanensis or Grand Cayman parrot, which is native to the Cayman Islands, forested areas of Cuba, and the Isla de la Juventud. Little Cayman and Cayman Brac are also home to red-footed and brown boobies.[31][32] Although the barn owl (Tyto alba)  occurs in all three of the islands but they are not commonplace. The Cayman Islands also possess five endemic subspecies of butterflies on the islands.[33] These butterfly breeds can be viewed at the Queen Elizabeth II Botanic Park on the Grand Cayman.\\r\\n\\r\\nAmong other notable fauna at the Queen Elizabeth II Botanic Park is the critically threatened blue iguana which is also known as the Grand Cayman iguana (Cyclura lewisi). The blue iguana is endemic to the Grand Cayman[34] particularly because of rocky, sunlit, open areas near the island's shores that are advantageous for the laying of eggs. Nevertheless, habitat destruction and invasive mammalian predators remain primary reasons that blue iguana hatchlings do not survive naturally.[35]\\r\\n\\r\\nThe Cuban crocodile (Crocodylus rhombifer) once inhabited the islands;[36] and the American crocodile (C. acutus) is thought to be repopulating Grand Cayman. The name \\"Cayman\\" is derived from a Carib word for various crocodilians.[37]\\r\\n\\r\\nThe Cayman Islands has a tropical wet and dry climate, with a wet season from May to October, and a dry season that runs from November to April. Seasonally, there is little temperature change.[38]\\r\\n\\r\\nA major natural hazard is the tropical cyclones that form during the Atlantic hurricane season from June to November.\\r\\n\\r\\nOn 11 and 12 September 2004, Hurricane Ivan struck the Cayman Islands. The storm resulted in two deaths and caused great damage to the infrastructure on the islands. The total economic impact of the storms was estimated to be $3.4 billion.[39]\\r\\n\\r\\nThe Cayman Islands have more registered businesses than people.[40] In 2016 the Cayman Islands had an estimated population of about 60,765,[7] representing a mix of more than 100 nationalities. Out of that number, about half are of Caymanian descent. About 60% of the population is of mixed race (mostly mixed African-Caucasian). The islands are almost exclusively Christian, with large numbers of Baptists, Presbyterians and Catholics, but also hosts Jewish,[41] Muslim and Hindu communities. The vast majority of the population resides on Grand Cayman, followed by Cayman Brac and Little Cayman, respectively.[4] The capital of the Cayman Islands is George Town, on the southwest coast of Grand Cayman.\\r\\n\\r\\nAccording to the Cayman Islands 2016 Compendium of Statistics released by the Economics and Statistics Office (ESO) the estimated resident population is above 61,000 people,[42] broken down as follows:\\r\\n\\r\\nSir Vassel Johnson, who became the only Caymanian ever knighted, was a pioneer of Caymans financial services industry. Cayman Islands Past Governor Stuart Jack said As one of the architects of modern Cayman, especially the financial industry, Sir Vassel guided the steady growth of these Islands as the first financial secretary. His remarkable vision set the foundation for the prosperity and economic stability of these islands. Without his input, Cayman might well have remained the islands that time forgot.[43]\\r\\n\\r\\nWith an average income of around KYD$47,000, Caymanians have the highest standard of living in the Caribbean. According to the CIA World Factbook, the Cayman Islands GDP per capita is the 38th highest in the world, but the CIA's data for Cayman dates to 2004 and is likely to be lower than present-day values.[44] The territory prints its own currency, the Cayman Islands dollar (KYD), which is pegged to the US dollar 1.227 USD to 1 KYD. However, in many retail stores throughout the islands, the KYD is typically traded at 1.25 USD.[45]   The government has established a Needs Assessment Unit to relieve poverty in the islands.[46]\\r\\n\\r\\nThe government's primary source of income is indirect taxation: there is no income tax, capital gains tax, or corporation tax.[17] An import duty of 5% to 22% (automobiles 29.5% to 100%) is levied against goods imported into the islands. Few goods are exempt; notable exemptions include books, cameras, gold, and perfume.[47]\\r\\n\\r\\nOn 15 July 2012 one of the Cayman Islands' former Premiers McKeeva Bush announced the intended introduction of a \\"community enhancement fee\\" in the form of a payroll tax to be paid solely by expatriate workers. Caymanians themselves were to remain exempt from this tax. This would have been the first direct tax on income in the Cayman Islands' history.[48] Bush also announced a five percent fee on \\"certain categories of employment\\" to be payable by businesses. However, the payroll tax was scrapped before it had been implemented.[49]\\r\\n\\r\\nOne of Grand Cayman's main attractions is Seven Mile Beach, site of a number of the island's hotels and resorts. Named one of the Ultimate Beaches by Caribbean Travel and Life, Seven Mile Beach is on the western shore of Grand Cayman Island. It is a public property and possible to walk the full length of the beach, past all the hotels, resorts, and public beach bars.[50] Historical sites in Grand Cayman, such as Pedro St. James Castle in Savannah, also attract visitors.[51] Tourists also visit the \\"sister islands\\", Little Cayman[52] and Cayman Brac.[53]\\r\\n\\r\\nAll three islands offer scuba diving, and the Cayman Islands is home to several snorkelling locations where tourists can swim with stingrays. The most popular area to do this is Stingray City, Grand Cayman. Stingray City is a top attraction in Grand Cayman and originally started in the 1980s, when divers started feeding squid to stingrays. The stingrays started to associate the sound of the boat motors with food, and thus visit this area year round.[54]\\r\\n\\r\\nThere are two shipwrecks off the shores of Cayman Brac, including the MV Captain Keith Tibbetts;[55] Grand Cayman also has several shipwrecks off its shores, including one deliberate one. On 30 September 1994 the USS?Kittiwake was decommissioned and struck from the Naval Vessel Register. In November 2008 her ownership was transferred for an undisclosed amount to the government of the Cayman Islands, which had decided to sink the Kittiwake in June 2009 to form a new artificial reef off Seven Mile Beach, Grand Cayman. Following several delays, the ship was finally scuttled according to plan on 5 January 2011. The Kittiwake has become a dynamic environment for marine life. While visitors are not allowed to take anything, there are endless sights. Each of the five decks of the ship offers squirrelfish, rare sponges, Goliath groupers, urchins, and more. Experienced and beginner divers are invited to swim around the Kittiwake.[56]  Pirates Week, an annual 11-day November festival, was started in 1977 by Jim Bodden, then Minister of Tourism, to boost tourism during the country's tourism slow season.[57]\\r\\n\\r\\nOther Grand Cayman tourist attractions include: the ironshore landscape of Hell; the 23-acre (93,000?m2) marine theme park \\"Cayman Turtle Centre: Island Wildlife Encounter\\", previously known as \\"Boatswain's Beach\\"; the production of gourmet sea salt; and the Mastic Trail, a hiking trail through the forests in the centre of the island. The National Trust for the Cayman Islands provides guided tours weekly on the Mastic Trail and other locations.[58]\\r\\n\\r\\nAnother attraction to visit on Grand Cayman is the Observation Tower, located in Camana Bay. The Observation Tower is 75 feet tall and provides 360-degree views across Seven Mile Beach, George Town, the North Sound, and beyond. It is free to the public and climbing the tower has become a popular thing to do in the Cayman Islands.[59]\\r\\n\\r\\nPoints of interest include the East End Light (sometimes called Gorling Bluff Light), a lighthouse at the east end of Grand Cayman island. The lighthouse is the centrepiece of East End Lighthouse Park, managed by the National Trust for the Cayman Islands; the first navigational aid on the site was the first lighthouse in the Cayman Islands.\\r\\n\\r\\nThe merchant marine total is 123 ships (1,000 GRT or over) totalling 2,402,058 GRT/3,792,094 metric tons deadweight (DWT). The fleet includes 22 bulk carriers, 5 cargo ships, 31 chemical tankers, 2 container ships, 1 liquefied gas transport, 21 petroleum tankers, 35 refrigerated cargo ships, 5 roll-on/roll-off vessels and 1 specialised tanker. (Note: some foreign ships register in the Cayman Islands as a flag of convenience. In 2002 ships from eleven countries took advantage of this option, including 15 from Greece, 5 from the United States, 5 from the United Kingdom, 2 from Cyprus, 2 from Denmark and 3 from Norway.)\\r\\n\\r\\nThe Cayman Islands has a small population of 60,765 (as of 2016) and therefore a limited workforce. Work permits may, therefore, be granted to foreigners. On average, there have been more than 21,000 foreigners holding valid work permits.[60]\\r\\n\\r\\nTo work in the Cayman Islands as a non-citizen, a work permit is required. This involves passing a police background check and a health check. A prospective immigrant worker will not be granted a permit unless certain medical conditions are present which include testing negative for syphilis and HIV. A permit may be granted to individuals on special work.\\r\\n\\r\\nA foreigner must first have a job to move to the Cayman Islands. The employer applies and pays for the work permit.[61] Work permits are not granted to foreigners who are in the Cayman Islands (unless it is a renewal). The Cayman Islands Immigration Department requires foreigners to remain out of the country until their work permit has been approved.[62]\\r\\n\\r\\nThe Cayman Islands presently imposes a controversial \\"rollover\\" in relation to expatriate workers who require a work permit. Non-Caymanians are only permitted to reside and work within the territory for a maximum of nine years unless they satisfy the criteria of key employees. Non-Caymanians who are \\"rolled over\\" may return to work additional nine-year periods, subject to a one-year gap between their periods of work. The policy has been the subject of some controversy within the press. Law firms have been particularly upset by the recruitment difficulties that it has caused.[63] Other less well-remunerated employment sectors have been affected as well. Concerns about safety have been expressed by diving instructors, and realtors have also expressed concerns. Others support the rollover as necessary to protect Caymanian identity in the face of immigration of large numbers of expatriate workers.[64]\\r\\n\\r\\nConcerns have been expressed that in the long term, the policy may damage the preeminence of the Cayman Islands as an offshore financial centre by making it difficult to recruit and retain experienced staff from onshore financial centres. Government employees are no longer exempt from this \\"rollover\\" policy, according to this report in a local newspaper.[65] The governor has used his constitutional powers, which give him absolute control over the disposition of civil service employees, to determine which expatriate civil servants are dismissed after seven years service and which are not.[citation needed]\\r\\n\\r\\nThis policy is incorporated in the Immigration Law (2003 revision), written by the United Democratic Party government, and subsequently enforced by the People's Progressive Movement Party government. Both governments agree to the term limits on foreign workers, and the majority of Caymanians also agree it is necessary to protect local culture and heritage from being eroded by a large number of foreigners gaining residency and citizenship.[66]\\r\\n\\r\\nIn recognition of the CARICOM (Free Movement) Skilled Persons Act which came into effect in July 1997 in some of the CARICOM countries such as Jamaica and which has been adopted in other CARICOM countries, such as Trinidad and Tobago[67]  it is possible that CARICOM nationals who hold the \\"A Certificate of Recognition of Caribbean Community Skilled Person\\" may be allowed to work in the Cayman Islands[68] under normal working conditions.\\r\\n\\r\\nThe Cayman Islands is a British overseas territory, listed by the UN Special Committee of 24 as one of the 16 non-self-governing territories. The current Constitution, incorporating a Bill of Rights, was ordained by a statutory instrument of the United Kingdom in 2009.[69] A 19-seat (not including two non-voting members appointed by the Governor which brings the total to 21 members) Legislative Assembly is elected by the people every four years to handle domestic affairs.[70] Of the elected Members of the Legislative Assembly (MLAs), seven are chosen to serve as government Ministers in a Cabinet headed by the Governor. The Premier is appointed by the Governor.[71]\\r\\n\\r\\nA Governor is appointed by the Queen of the United Kingdom on the advice of the British Government to represent the monarch.[72] Governors can exercise complete legislative and executive authority if they wish through blanket powers reserved to them in the constitution.[73] Bills which have passed the Legislative Assembly require royal assent before becoming effective. The Constitution empowers the Governor to withhold royal assent in cases where the legislation appears to him or her to be repugnant to or inconsistent with the Constitution or affects the rights and privileges of the Legislative Assembly or the Royal Prerogative, or matters reserved to the Governor by article 55.[74] The executive authority of the Cayman Islands is vested in the Queen and is exercised by the Government, consisting of the Governor and the Cabinet.[75] There is an office of the Deputy Governor, who must be a Caymanian and have served in a senior public office. The Deputy Governor is the acting Governor when the office of Governor is vacant, or the Governor is not able to discharge his or her duties or is absent from the Cayman Islands.[76] The current Governor of the Cayman Islands is Martyn Roper.[77]\\r\\n\\r\\nThe Cabinet is composed of two official members and seven elected members, called Ministers; one of whom is designated Premier. The Premier can serve for two consecutive terms after which he is barred from attaining the office again. Although an MLA can only be Premier twice any person who meets the qualifications and requirements for a seat in the Legislative Assembly can be elected to the Legislative Assembly indefinitely.[78]\\r\\n\\r\\nThere are two official members of the Legislative Assembly, the Deputy Governor and the Attorney General. They are appointed by the Governor in accordance with Her Majesty's instructions, and although they have seats in the Legislative Assembly, under the 2009 Constitution, they do not vote. They serve in a professional and advisory role to the MLAs, the Deputy Governor represents the Governor who is a representative of the Queen and the British Government. While the Attorney General serves to advise on legal matters and has special responsibilities in the LA, he is generally responsible for changes to the Penal code among other things.\\r\\n\\r\\nThe seven Ministers are voted into office by the 19 elected members of the Legislative Assembly of the Cayman Islands. One of the Ministers, the leader of the majority political party, is appointed Premier by the Governor.\\r\\n\\r\\nAfter consulting the Premier, the Governor allocates a portfolio of responsibilities to each Cabinet Minister. Under the principle of collective responsibility, all Ministers are obliged to support in the Assembly any measures approved by Cabinet.\\r\\n\\r\\nAlmost 80 departments, sections and units carry out the business of government, joined by a number of statutory boards and authorities set up for specific purposes, such as the Port Authority, the Civil Aviation Authority, the Immigration Board, the Water Authority, the University College Board of Governors, the National Pensions Board and the Health Insurance Commission.\\r\\n\\r\\nSince 2000, there have been two official major political parties: The Cayman Democratic Party (CDP) and the People's Progressive Movement (PPM). While there has been a shift to political parties, many contending for office still run as independents. The two parties are notably similar, though they consider each other rivals in most cases, their differences are generally in personality and implementation rather than actual policy. The Cayman Islands currently lacks any real liberal or progressive representation in the Legislative Assembly or in the form of organized political parties.[79] As of the May 2017 General Election, members of the PPM and CDP have joined together with 3 independent members to form a government coalition despite many years of enmity.[80]\\r\\n\\r\\nThe defence of the Cayman Islands is the responsibility of the United Kingdom. Law enforcement in the country is provided chiefly by the Royal Cayman Islands Police Service and the Cayman Islands Customs Department. These two agencies co-operate in aspects of law enforcement, including their joint marine unit. The Cayman Islands Cadet Corps was formed in March 2001 and carries out military-type training with teenage citizens of the country. As of 2017 the PPM led Coalition government have pledged to form a Coast Guard to protect the interests of the Islands, especially in terms of illegal immigration and illegal drug importation.\\r\\n\\r\\nNo direct taxation is imposed on residents and Cayman Islands companies. The government receives the majority of its income from indirect taxation. Duty is levied against most imported goods, which is typically in the range of 22% to 25%. Some items are exempted, such as baby formula, books, cameras and certain items are taxed at 5%. Duty on automobiles depends on their value. The duty can amount to 29.5% up to $20,000.00 KYD CIF (cost, insurance and freight) and up to 42% over $30,000.00 KYD CIF for expensive models. The government charges flat licensing fees on financial institutions that operate in the islands and there are work permit fees on foreign labour. A 13% government tax is placed on all tourist accommodations in addition to US$37.50 airport departure tax which is built into the cost of an airline ticket. There are no taxes on corporate profits, capital gains, or personal income. There are no estate or death inheritance taxes payable on Cayman Islands real estate or other assets held in the Cayman Islands.[81]\\r\\n\\r\\nForeign policy is controlled by the United Kingdom, as the islands remain an overseas territory of the United Kingdom. Although in its early days, the Cayman Islands' most important relationships were with Britain and Jamaica, in recent years, as a result of economic dependence, a relationship with the United States has developed.\\r\\n\\r\\nThough the Cayman Islands is involved in no major international disputes, they have come under some criticism due to the use of their territory for narcotics trafficking and money laundering. In an attempt to address this, the government entered into the Narcotics Agreement of 1984 and the Mutual Legal Assistance Treaty of 1986 with the United States, to reduce the use of their facilities associated with these activities. In more recent years, they have stepped up the fight against money laundering, by limiting banking secrecy, introducing requirements for customer identification and record keeping, and requiring banks to co-operate with foreign investigators.\\r\\n\\r\\nDue to their status as an overseas territory of the UK, the Cayman Islands has no representation either in the United Nations or in most other international organisations. However, the Cayman Islands still participates in some international organisations, being an associate member of Caricom and UNESCO, and a member of a sub-bureau of Interpol.[82]\\r\\n\\r\\nGeorge Town is the port capital of Grand Cayman. There are no berthing facilities for cruise ships, but up to 4 cruise ships can anchor in designated anchorages. There are three cruise terminals in George Town, the North, South, and Royal Watler Terminals. The ride from the ship to the terminal is about 5 minutes.[83]\\r\\n\\r\\nThe Cayman Islands Education Department operates state schools. Caymanian children are entitled to free primary and secondary education. There are two public high schools on Grand Cayman, John Gray High School and Clifton Hunter High School, and one on Cayman Brac, Layman E. Scott High School. Various churches and private foundations operate several private schools.\\r\\n\\r\\nThe University College of the Cayman Islands has campuses on Grand Cayman and Cayman Brac and is the only government-run university on the Cayman Islands.[84] A hall at the University College of the Cayman Islands is named after Sir Vassel Johnson, who The Cayman Islands Financial Services Association credited as one of the founding fathers of the financial services sector in the Cayman Islands. Sir Vassel is also the only person to ever be knighted in any British Dependent Territory. http://www.gov.ky/portal/page/portal/cighome/pressroom/archive/200811/governorstributetosirvassel\\r\\n\\r\\nThe International College of the Cayman Islands is a private college in Grand Cayman. The college was established in 1970 and offers associate's, bachelor's and master's degree programmes.[85] Grand Cayman is also home to St. Matthew's University, which includes a medical school and a school of veterinary medicine.[86] The Cayman Islands Law School, a branch of the University of Liverpool, is based on Grand Cayman.[87]\\r\\n\\r\\nThe Cayman Islands Civil Service College, a unit of Cayman Islands government organised under the Portfolio of the Civil Service, is in Grand Cayman. Co-situated with University College of the Cayman Islands, it offers both degree programs and continuing education units of various sorts. The college opened in 2007 and is also used as a government research centre.\\r\\n\\r\\nThere is a University of the West Indies Open campus in the territory.[88]\\r\\n\\r\\nSee Health in the Cayman Islands\\r\\n\\r\\nThe Royal Cayman Islands Police Service (RCIPS) provides law enforcement for the three islands. Regular off-shore marine and air patrols are conducted by the RCIP using a small fleet of vessels and a helicopter. Grand Cayman is a port of call for Britain's Royal Navy and the United States Coast Guard who often assist with sea rescues when their resources are in the Cayman Islands area. The Cayman Islands Fire Service provides fire prevention, fire fighting and rescue.[89] Its headquarters are in George Town and has substations in Frank Sound, West Bay, Cayman Brac and Little Cayman.[90]\\r\\n\\r\\nAccess to Emergency Services is available using 9-1-1, the Emergency telephone number, the same number as is used in Canada and the United States.[91] The Cayman Islands Department of Public Safety's Communications Centre processes 9-1-1 and non-emergency law enforcement, EMS, fire, and Search and Rescue calls for all three islands. The Communications Centre dispatches RCIP and EMS units directly, however, the Cayman Islands Fire Service maintains their own dispatch room at the airport fire station.[92]\\r\\n\\r\\nTruman Bodden Sports Complex is a multi-use complex in George Town. The complex is separated into an outdoor, six-lane 25-metre (82?ft) swimming pool, full purpose track and field and basketball/netball courts. The field surrounded by the track is used for association football matches as well as other field sports. The track stadium holds 3,000 people.\\r\\n\\r\\nAssociation football is the national and most popular sport, with the Cayman Islands national football team representing the Cayman Islands in FIFA.[citation needed]\\r\\n\\r\\nThe Cayman Islands Basketball Federation joined the international basketball governing body FIBA in 1976.[93] The country's national team attended the official 2011 Caribbean Basketball Championship for the first time.\\r\\n\\r\\nRugby union is a developing sport, and has its own national men's team, women's team, and Sevens team. The Cayman Men's Rugby 7s team is second in the region after the 2011 NACRA 7s Championship.\\r\\n\\r\\nThe Cayman Islands is a member of FIFA, the International Olympic Committee and the Pan American Sports Organisation, and also competes in the biennial Island Games.[94]\\r\\n\\r\\nThe Cayman Islands is a member of the International Cricket Council which they joined in 1997 as an Affiliate, before coming an Associate member in 2002. The Cayman Islands national cricket team represents the islands in international cricket. The team has previously played the sport at first-class, List A and Twenty20 level. It competes in Division Five of the World Cricket League.[95]\\r\\n\\r\\nSquash is popular in the Cayman Islands with a vibrant community of mostly ex-pats playing out of the 7 court South Sound Squash Club. In addition, the women's professional squash association hosts one of their major events each year in an all glass court being set up in Camana Bay. In December 2012, the former Cayman Open will be replaced by the Women's World Championships, the largest tournament in the world. The top Cayman men's player, Cameron Stafford is No. 2 in the Caribbean and ranked top 200 on the men's professional circuit.\\r\\n\\r\\nFlag football (CIFFA) has men's, women's and co-ed leagues.\\r\\n\\r\\nOther organised sports leagues include softball, beach volleyball, Gaelic football and ultimate frisbee.\\r\\n\\r\\nThe Cayman Islands Olympic Committee was founded in 1973 and was recognised by the IOC (International Olympic Committee) in 1976.\\r\\n\\r\\nIn the 21st century, skateboarding has become popular among the youth.[citation needed]\\r\\n\\r\\nIn February 2010, the first purpose built track for kart racing in the Cayman Islands was opened.[96] Corporate karting Leagues at the track have involved widespread participation with 20 local companies and 227 drivers taking part in the 2010 Summer Corporate Karting League.[97]\\r\\n\\r\\nThe Cayman National Cultural Foundation manages the F.J. Harquail Cultural Centre and the US$4?million Harquail Theatre. The Cayman National Cultural Foundation, established in 1984, helps to preserve and promote Cayman folk music, including the organisation of festivals such as Cayman Islands International Storytelling Festival, the Cayman JazzFest, Seafarers Festival and Cayfest.[98] The jazz, calypso and reggae genres of music styles feature prominently in Cayman music as celebrated cultural influences.[99] Many of Cayman-inspired pop songs belong to these forms of music styles.\\r\\n\\r\\nThere is one print newspaper currently in circulation throughout the islands: the Cayman Compass. There are numerous online news services including Cayman News Service and the Cayman Compass online edition. A local television station, CITN ÿ Cayman 27, shows Cayman Islands news.[100] Local radio stations are broadcast throughout the islands.\\r\\n\\r\\nFeature films that have been filmed in the Cayman Islands include: The Firm, Haven, Cayman Went[101] and Zombie Driftwood.[102]\\r\\n\\r\\nLat. and Long. 1920N 8124W? / ?19.333N 81.400W? / 19.333; -81.400 (George Town)\\r\\n\\r\\nClick on a coloured area to see an article about English in that country or region","input":"What is the capital of the cayman islands?"},{"output":"Twelve","context":"The Babysitter is a 2017 American teen horror-comedy film directed by McG and written by Brian Duffield. The film stars Samara Weaving, Judah Lewis, Hana Mae Lee, Robbie Amell and Bella Thorne. It was released by Netflix on October 13, 2017 and received positive reviews from critics.\\r\\n\\r\\n\\r\\nTwelve-year-old Cole Johnson is bullied by his neighbor Jeremy, but his babysitter Bee stands up for him and scares Jeremy off. The following day, when his parents go out for an overnight stay at a hotel, Bee and Cole spend quality time together until he has to go to bed. Cole is encouraged by a text from his neighbor and best friend Melanie to go see what Bee gets up to after he goes to sleep. To his surprise, he sees what looks like Bee and several of her high school friends: Max, John, Allison, Sonya, and Samuel. They are playing a game of truth or dare formatted as a game of spin the bottle. However, as Bee kisses Samuel on a dare, she pulls two daggers from behind her back and stabs him in the skull. The others collect Samuel's blood, revealing themselves to be members of a demonic cult. Cole hurries to his room where he calls 911, puts on his shoes, and finds a pocket knife. He pretends to be asleep as Bee and the cult members enter his room to draw a blood sample. After they leave, he tries to escape out the window but Bee stays in the room, and Cole passes out from the exhaustion.\\r\\nBee and her cult question Cole, while fending off his questions by saying it was a science project. When the cops arrive, Max kills one with a poker, but the cop accidentally shoots Allison in her breast, whereas Bee and Max kill the other cop. Bee forces Cole to give them the police code to call off the other cops. While Allison complains about being shot, Cole rushes up the stairs; John pursues him, but is pushed over the banister, landing on a trophy that impales his neck.\\r\\nCole escapes out his bedroom window and hides in the crawlspace under his house. Although Sonya finds him, he traps her in the basement and then ignites a firework rocket and bug spray to blow her up. After showing appreciation for Cole's ingenuity, Max chases Cole up the old tree house; he is killed when he falls and is hanged by the rope swing. Cole escapes to Melanie's house, but Bee follows him. While hiding in a room, Cole apologizes to Melanie for dragging her into this situation and assures her that he is going to take care of things. He asks Melanie to call the police, then she kisses Cole before he leaves.\\r\\nCole returns to his house to find Allison, who tries to kill Cole with a kitchen knife; she is instead shot in the head with a shotgun by Bee. Bee explains to Cole that when she was young, she made a deal with The Devil to get whatever she wanted by sacrificing innocent people and spilling their blood on the ancient book while reciting its verses. Although she wants him to join her cause, Cole refuses and burns the spell book. He rushes to Melanie's house to take her dad's car, and drives it straight towards his house while Bee fixes the book in the living room. After crashing into her, they have one last emotional farewell before Cole climbs out of the wreckage. As the police and emergency crew arrive, Cole tells his parents that he no longer needs a babysitter. Later, a firefighter going through Cole's house is attacked by Bee.\\r\\nOn November 24, 2014, it was announced that Brian Duffield's horror comedy script The Babysitter had been bought by McG's Wonderland Sound and Vision, with McG and Mary Viola producing the film. The project was brought in by executive producer Steven Bello.[8] In December 2014, the script appeared on the 2014 Black List of the best unproduced scripts in Hollywood.[9]\\r\\nOn September 10, 2015, McG was attached to direct the film for New Line Cinema, while Wonderland co-financed the film, along with the Boies/Schiller Film Group.[6][10] Principal photography began on October 27, 2015, in Los Angeles.[6][11]\\r\\nIn December 2016, Netflix acquired distribution rights to the film, from New Line Cinema.[12] It premiered on the service on October 13, 2017.[13]\\r\\nThe Babysitter holds a 75% approval rating on review aggregator website Rotten Tomatoes, based on 16 reviews, with a weighted average of 5.5/10.[14]","input":"How old is the kid in the babysitter?"},{"output":"May 8 2018","context":"The six season of El Se?or de los Cielos,[1][2] an American television series created by Luis Zelkowicz, that premiered on Telemundo on May 8 2018.[3][4]\\r\\nThe season was ordered in May 2017.[5] Rafael Amaya stars as Aurelio Casillas, with principal cast members Carmen Aub,and Robinson Daz also returning from previous seasons, Guy Ecker, Alberto Guerra, Francisco Gattorno as the new main cast, and the promotion to the main cast of Alejandro L܇pez, Jes~s Mor, and Lisa Owen.\\r\\n\\r\\n\\r\\nAurelio Casillas recovered all the lost fortune and finally feels the need to retire. But it is time for retribution, the hatred that he sowed since he sold his soul to the drug trafficking demon is now knocking on his door with the face and blood of the many innocent people he destroyed. Aurelio will understand that his riches are an illusion, and that after being the great hunter he was, he will now become the prey. The women he mistreated, the men he betrayed, the political puppets he put in power, and even his own children will turn against him.[6]\\r\\nOn March 30, 2018 People en Espa?ol magazine confirmed the first confirmed actors for the season, which are Rafael Amaya, Carmen Aub, Ivn Arana, Lisa Owen, Alejandro L܇pez, and Jes~s Mor.[13] This season features the return of Robinson Daz as El Cabo,[14] and new cast members including Mara Conchita Alonso, Juana Arias, Carlos Bardem, Isabella Castillo, Ninel Conde, Guy Ecker, Alberto Guerra, Thali Garca, Dayana Garroz, Francisco Gattorno, and Fernando Noriega, among others.[14]\\r\\nAfter Mauricio Ochmann announced that he would no longer playing El Chema,[15] actor Alberto Guerra joins the series with the same character as Ochmann.[16]\\r\\nThe premiere of the sixth season was watched by 2.14 million viewers,[17] which made Telemundo position itself as the Spanish-language network most watched at 10pm/9c,[17] thus outperforming its Por amar sin ley competition, that it only obtained a total of 1.44 million viewers.[17] After the good reception obtained by the first two episodes of the season,[18] Telemundo renewed the series for a seventh season during the Upfront for the 2018ÿ19 television season.[18]","input":"When does el se?or de los cielos start?"},{"output":"the establishment of the state of Israel in 1948","context":"","input":"What is the origin of israeli palestinian conflict?"},{"output":"over 50","context":"As one of the most iconic and recognisable structures in the world, the Eiffel Tower has been the inspiration for the creation of over 50 similar towers around the world. Most are not exact replicas, though there are many like it.\\r\\n\\r\\nThe Eiffel Tower was an inspiration for the Blackpool Tower in Blackpool, England, which proved that a tower could be a profitable tourist attraction. The Blackpool Tower was originally the idea of the Standard Contract and Debenture Corporation, based in the Isle of Man, who proposed the erection of two towers, one in Blackpool and one in the Isle of Man and sold shares to potential investors, including many prominent Blackpool families. When the corporation got into financial difficultly John Bickerstaffe stopped the scheme from collapsing and ensured the scheme was a success. The Blackpool Tower, though one of the oldest, is not a true replica of the Eiffel Tower and differs from the Paris tower in a number of ways: it is approximately half the height of the Eiffel Tower (158 m compared to 324 m), it is not freestanding and the base contains buildings which house entertainments including the Tower Circus and Ballroom, making it in itself one of the most unique replica-like Towers in the world. It was also designed by the British architects Maxwell and Tuke who designed a number of towers including New Brighton. \\r\\n\\r\\nOther Eiffel-inspired towers are listed in the table in descending order of scale and height:\\r\\n\\r\\nThese replicas are of unknown height.\\r\\n\\r\\nSee also:  Media related to Replicas of the Eiffel Tower at Wikimedia Commons\\r\\n@media all and (max-width:720px){.mw-parser-output .mw-module-gallery{display:block!important;float:none!important}.mw-parser-output .mw-module-gallery div{display:inherit!important;float:none!important;width:auto!important}}","input":"How many eiffel towers are there in the world?"},{"output":"Jesus","context":"\\r\\nBaptism has been part of Christianity from the start, as shown by the many mentions in the Acts of the Apostles and the Pauline epistles.\\r\\n\\r\\nAlthough the term \\"baptism\\" is not today used to describe the Jewish rituals (in contrast to New Testament times, when the Greek word baptismos did indicate Jewish ablutions or rites of purification),[1][2] the purification rites (or mikvahritual immersion) in Jewish law and tradition have some similarity to baptism, and the two have been linked.[3][4] In the Hebrew Bible and other Jewish texts, immersion in water for ritual purification was established for restoration to a condition of \\"ritual purity\\" in specific circumstances. For example, Jews who (according to the Law of Moses) became ritually defiled by contact with a corpse had to use the mikvah before being allowed to participate in the Temple in Jerusalem. Immersion was not required for converts to Judaism as part of their conversion, although many mistakenly believe otherwise.[5] Immersion in the mikvah represents a change in status in regards to purification, restoration, and qualification for full religious participation in the life of the community, ensuring that the cleansed person will not impose uncleanness on property or its owners.[6][7]\\r\\n\\r\\nThe New Testament includes several references to baptism as an important practice among early Christians and, while giving no actual account of its institution by Jesus, portrays him as giving instructions, after his resurrection, for his followers to perform the rite (see Great Commission).[8] It also gives interpretations by the Apostle Paul and in the First Epistle of Peter of the significance of baptism.\\r\\n\\r\\n Truly, truly, I say to you, unless one is born of water and the Spirit, he cannot enter the kingdom of God \\r\\n Christ loved the church and gave himself up for her, that he might sanctify her by the washing of water with the word, that he might present the church to himself in splendor, without spot or wrinkle or any such thing, that she might be holy and without blemish. \\r\\n God's patience waited in the days of Noah, during the building of the ark, in which a few, that is, eight persons, were saved through water. Baptism, which corresponds to this, now saves you \\r\\nThe baptism of Jesus is described in the gospels of Matthew, Mark and Luke. John's gospel does not directly describe Jesus' baptism.\\r\\n\\r\\nJohn the Baptist was a 1st-century mission preacher on the banks of the River Jordan.[9][page?needed] He baptized Jews for repentance in the River Jordan.[10]\\r\\n\\r\\nAt the start of his ministry, Jesus was baptized by John the Baptist. Critical scholars broadly agree that the baptism of Jesus is one of the most authentic, or historically likely, events in the life of the historical Jesus.[citation needed] Christian baptism has its origin in the baptism of Jesus, in both a direct and historical sense.[11] Many of the earliest followers of Jesus were people who, like him, were baptized in the Jordan by John the Baptist.[12]\\r\\n\\r\\nThe Gospel of John[Jn 3:22-30] [4:1-4] states that Jesus at an early stage led a mission of baptism that drew crowds. John 4:2, considered by many scholars to be a later editorial insertion,[13] denies that Jesus himself baptized and states that he did so only through his disciples.\\r\\n\\r\\nSome prominent scholars conclude that Jesus did not baptize. Gerd Theissen and Annette Merz assert that Jesus did not baptize, detached the notion of repentance from baptism, recognized John's baptism, and put forward a purity ethic in tension with baptism.[14] The Oxford Dictionary of World Religions also states that Jesus did not baptize as part of his ministry.[15][page?needed]\\r\\n\\r\\nE. P. Sanders omits John's account of Jesus' baptizing mission from his portrait of Jesus as a historical figure.[16]\\r\\n\\r\\nRobert W. Funk considers the account of Jesus' baptism ministry in John to have internal difficulties: that, for instance, it reports Jesus coming to Judea even though he is already in Jerusalem and thus in Judea.[17][page?needed] John 3:22 actually speaks of Jesus and his disciples coming, not \\"?? ? ?Ѵϫ?ϫ\\" (into Judea), but \\"?? ? ?Ѵϫ?ϫ ?\\" (into the Judean countryside),[18] which some interpret as contrasted with Jerusalem, the scene of the encounter with Nicodemus described immediately before.[19]  According to the Jesus Seminar, the passage about Jesus \\"coming to Judea\\" (as they interpret \\"?? ? ?Ѵϫ?ϫ ?\\") to lead a mission of baptism probably preserves no historical information (a \\"black\\" rating).[20][page?needed]\\r\\n\\r\\nOn the other hand, the Cambridge Companion to Jesus[21] takes a different view. According to this source, Jesus accepted and made his own John the Baptist's message of repentance, forgiveness and baptism;[22] taking over from John, when the latter was imprisoned, he called for repentance and for baptism as a first step in accepting the imminent Kingdom of God;[23] and the central place of baptism in his message is confirmed by the passage in John about Jesus baptizing.[24]  After John's execution, Jesus ceased baptizing, through he may have occasionally returned to the practice; accordingly, while baptism played an important part in Jesus' ministry before John's death and again among his followers after his resurrection, it had no such prominence in between.[25]\\r\\n\\r\\nNew Testament scholar Raymond E. Brown, a specialist in the Johannine writings, considers that the parenthetic editorial remark of John 4:2 that Jesus baptized only through his disciples was intended to clarify or correct the twice repeated statement in the preceding verses that Jesus did baptize, and that the reason for its insertion may have been that the author considered the baptism that the disciples administered to be a continuation of the Baptist's work, not baptism in the Holy Spirit.[26]\\r\\n\\r\\nOther New Testament scholars also accept the historical value of this passage in John. This is the view expressed by Joel B. Green, Scot McKnight, I. Howard Marshall.[27] Another states that there is \\"no a priori reason to reject the report of Jesus and his disciples' conducting a ministry of baptism for a time\\", and mentions that report as one of the items in John's account[3:22ÿ26] \\"that are likely to be historical and ought to be given due weight\\".[28]\\r\\n\\r\\nIn his book on the relationship between John the Baptist and Jesus of Nazareth, Daniel S. Dapaah says that John's account \\"may be a snippet of historical tradition\\", and comments that the silence of the Synoptic Gospels does not mean that the information in John was invented, and that Mark's account also suggests that Jesus worked with John at first, before moving to Galilee.[29] Frederick J. Cwiekowski agrees that the account in John \\"gives the impression\\" that Jesus baptized.[30]\\r\\n\\r\\nThe Joseph Smith Translation of the Bible says that \\"though he [Christ] himself baptized not so many as his disciples; 'For he suffered them for an example, preferring one another.'[31]\\r\\n\\r\\nThe Gospel of John remarks, in John 3:32, that, though Jesus drew many people to his baptism, they still did not accept his testimony,[32] and the Jesus Seminar concludes, on the basis of Josephus's accounts, that John the Baptist likely had a larger presence in the public mind than Jesus.[10]\\r\\n\\r\\nIn the Pauline epistles baptism effects and represents the believer's union with Christ, a union by which the believer shares in Christ's death and resurrection;[Rom 6:3ÿ4] cleanses of sin;[1 Cor 6:11] incorporates into the Body of Christ and makes one \\"drink of the Spirit.\\"[1 Cor 12:13][33]\\r\\n\\r\\nThe conception of a sacramental principle, widespread not only in the Greco-Roman world, but even in pre-Columbian America and in preliterate societies, took on a unique significance, and to Paul's influence is attributed an interpretation given to the Christian rite in terms of the Greco-Roman mysteries[34] but little weight can be attached to the counterparts of baptism in mystery religions as an explanation of the Christian practice.[33]\\r\\n\\r\\nMatthew[a] begins with the \\"generation\\" of Jesus as Son of David, followed by the visit of the gentile Magi, and the flight into Egypt to escape Herod, after whose death the holy family returns into the land of Israel, then moves to Nazareth, and then includes a detailed version of the preaching of John the Baptist, followed by the baptism of Jesus.[Mt 3:11ÿ15]  John protests to Jesus that he needs to be baptized by Jesus, but Jesus tells him to let it be so now, saying that it is fitting for the two of them (\\"for us\\") to thus \\"fulfill all righteousness.\\" When Jesus is baptized, he goes up immediately out of the water, the heavens open and John sees the Spirit of God descend upon him like a dove, alighting on him, and he hears a voice from heaven say, \\"This is my beloved Son, with whom I am well pleased.\\"\\r\\n\\r\\nLater, at the request of the mother of James and John, who prompted her to present their request to him to declare that they are to sit one at his right hand and the other at his left, Jesus speaks of the \\"cup\\" he is to drink[20:20ÿ23], and he tells them that they too will drink of his cup, but in Matthew's gospel Jesus does not explicitly state that the baptism with which he must be baptized is also the \\"cup\\" that he must drink.\\r\\n\\r\\nThe Gospel of Matthew also includes the most famous version of the Great Commission.[28:18ÿ20] Here, the resurrected Jesus appears to the apostles and commissions them to make disciples of all nations, to baptize, and teach.[35][page?needed] This commission reflects the program adopted by the infant Christian movement.[35][page?needed]\\r\\n\\r\\nThis gospel, today generally believed by scholars to be the first[b] and to have been used as a basis for Matthew and Luke, begins with Jesus' baptism by John, who preached a baptism of repentance for forgiveness of sins.  John says of Jesus that he will baptize not with water but with the Holy Spirit. At Jesus' baptism, he hears God's voice proclaiming him to be his Son, and he sees the spirit like a dove descend on him.\\r\\n\\r\\nDuring Jesus' ministry, when James and John ask Jesus for seats of honor in the coming kingdom[10:35ÿ39], Jesus likens his fate to the cup that he will drink and to the baptism with which he must be baptized, the very cup and baptism in store for John and James (that is, martyrdom).[42]\\r\\n\\r\\nThe traditional ending of Mark is thought to have been compiled early in the 2nd century, and initially appended to the gospel by the middle of that century.[43] It says that those who believe and are baptized will be saved, \\"but he who does not believe will be condemned.\\"[Mk 16:9ÿ20] Mark's gospel does not explicitly state that baptized persons who believe will be saved from the \\"wrath to come,\\" the wrath to which John the Baptist refers in Matthew's gospel[3:7ÿ10], but readers can infer that being \\"condemned\\" includes the \\"wrath to come\\".\\r\\n\\r\\nThis gospel begins with a statement that it contains reliable information obtained directly from the original eyewitnesses and servants of the word[1:1ÿ4]. It introduces the conception of John the Baptist, the annunciation of Gabriel to Mary the virgin, the birth of the Baptist who will be called the prophet of the Most High, and then the birth of Jesus, in the days of Herod, king of Judea, and of Caesar Augustus, emperor of the Roman Empire. There follows the account of Jesus in the Temple among the teachers; and then the calling and preaching of the prophet John the Baptist in the days of Tiberius Caesar, emperor, of Herod and Philip, tetrarchs, of Annas and Caiaphas, high priests; and then by far the briefest account in the canonical Gospels of the baptism of Jesus[3:1ÿ22].\\r\\n\\r\\nThe baptism of John is different from the baptism of the one who is to come after him[3:3][3:16]. Jesus declares later that he has another baptism to be baptized with, and that he is under constraint (he is straitened[44]) until it is accomplished[12:50]. (The petition of the mother of James and John, the personal request of James and John, and Jesus' declaration to them that they will be baptized as he will be baptized, and will drink the cup that he will drink, is not in Luke's gospel.)\\r\\n\\r\\nIn the Gospel of Luke, the risen Jesus appears to the disciples and the eleven apostles gathered together with them in Jerusalem and gives them the Great Commission[24:45ÿ47] without explicitly speaking of baptism, but readers can infer that \\"the forgiveness of sins\\" here includes \\"baptism\\" according to the preaching of the apostles at the time of Luke's gospel.\\r\\n\\r\\nThe Gospel of John mentions John the Baptist's baptizing activity,[1:24-28][3:22ÿ23] [10:40ÿ41] in particular his baptism of Jesus,[1:15], and his statement that Jesus would baptize with the Holy Spirit.[1:29-34] It also mentions baptizing activity by Jesus,[3:25ÿ30] specifying that the baptizing was not done by Jesus himself but by his disciples.[4:1ÿ3]\\r\\n\\r\\nSome references to water in John's Gospel have been interpreted as referring to baptism, in particular, the phrase \\"born of water and the Spirit\\"[3:2ÿ9] and the account of blood and water coming out of the side of Jesus when pierced after crucifixion[19:31ÿ37][45]\\r\\n\\r\\nActs of the Apostles, written c.?85ÿ90,[46] states that about 3,000 people in Jerusalem were baptized in one day on Pentecost.[2:41]  It further relates baptisms of men and women in Samaria,[8:12ÿ13] of an Ethiopian eunuch,[8:36ÿ40] of Saul of Tarsus,[9:18] [22:16] of the household of Cornelius,[10:47ÿ48] of Lydia's household,[16:15] of the Philippi jailer's household,[16:33] of many Corinthians[18:8] and of certain Corinthians baptized by Paul personally.[1:14ÿ16]\\r\\n\\r\\nIn Acts, the prerequisites of baptism are faith and repentance, but in certain cases (like Cornelius' household) the reception of the Spirit also precedes baptism.[33]\\r\\n\\r\\nAlso in Acts, some twelve men who had undergone John's baptism, a \\"baptism of repentance\\" that John administered, \\"telling the people to believe in the one who was to come after him, that is, Jesus\\", were baptized \\"in the name of the Lord Jesus\\", whereupon they received the Holy Spirit.[19:1ÿ7]\\r\\n\\r\\nActs 2:38, Acts 10:48 and Acts 19:5 speak of baptism \\"in the name of Jesus\\" or \\"in the name of the Lord Jesus Christ\\", but whether this was a formula that was used has been questioned.[33]\\r\\n\\r\\nThere is a scholarly consensus that the earliest Christian baptism was by immersion.[47] Thomas Schreiner likewise states that \\"Most scholars agree that immersion was practiced in the NT\\",[48] identifying submersion as the form of immersion practiced.[49]  Heyler says most New Testament scholars generally agree that Christian baptism in the New Testament era was by immersion.[50] Everett Ferguson similarly speaks of \\"general scholarly agreement\\" that the baptism commanded by Jesus was immersion in water by dipping, in the form of a \\"full bath\\".[51]  He describes medieval depictions of Jesus standing in water while John poured water over him as a \\"strange fantasy\\" deriving from later church practice.[52]  Di Berardino describes the baptism of the New Testament era as generally requiring total immersion,[53] Tischler says that total immersion seems to have been most commonly used,[54] and Lang says \\"Baptism in the Bible was by immersion, that is, the person went fully under the waters\\".[55] Sookey says it is \\"almost certain\\" that immersion was used.[56] The Global Dictionary of Theology says that it is probable that immersion was the early church's normal mode of baptism, but that it was not seen as an important issue.[57]\\r\\n\\r\\nThe Didache or Teaching of the Twelve Apostles, an anonymous book of 16 short chapters, is probably the earliest known written instructions, outside of the Bible, for administering baptism.  The first version of it was written c.?60ÿ80?AD.[58]  The second, with insertions and additions, was written c.?100ÿ50?AD.[58] This work, rediscovered in the 19th century, provides a unique look at Christianity in the Apostolic Age and is the first explicit reference to baptism by pouring, although the New Testament does not exclude the possibility of this practice.\\"[59]  Its instructions on baptism are as follows:\\r\\n\\r\\nNow about baptism: this is how to baptize. Give public instruction on all these points, and then baptize in running water, in the name of the Father and of the Son and of the Holy Spirit...  If you do not have running water, baptize in some other. If you cannot in cold, then in warm.  If you have neither, then pour water on the head three times in the name of the Father, Son, and Holy Spirit. Before the baptism, moreover, the one who baptizes and the one being baptized must fast, and any others who can. And you must tell the one being baptized to fast for one or two days beforehand.[60][c]\\r\\n\\r\\nCommentaries typically understand that the Didache indicates a preference for baptizing by immersion.[62][63][64][65][66][67][68][69][70] in \\"living water\\" (i.e., running water, seen as symbolic of life).[71] Furthermore, in cases of insufficient water it permits pouring (affusion),[72][73][74][75][76] which it differentiates from immersion, using the Greek word ekche,[77] (\\"pour\\", in the English translation) and not baptiz (\\"baptize\\", in the English translation), while at the same time considering the action done by pouring to be a baptism,[78][79] giving no hint that this form made the baptism any less valid,[80] and showing that immersion was not the only baptismal practice then acceptable.[81] Barclay observes the Didache shows that baptism in the early church was by total immersion, if possible,[82] Barton describes the immersion of the Didache as \\"ideally by total immersion\\",[83] and Welch says it was by \\"complete immersion\\".[84]\\r\\n\\r\\nJames V. Brownson notes that the Didache does not specify either immersion or pouring when using running water,[85] and Sinclair B. Ferguson argues that really the only mode that the Didache mentions is affusion.[86] Martin and Davids say the Didache envisages \\"some form of immersion\\",[87] and the Oxford Dictionary of the Christian Church refers its readers to its entry on immersion, which it distinguishes from submersion and affusion.[88]\\r\\n\\r\\nThe theology of baptism attained precision in the 3rd and 4th centuries.[15] While instruction was at first given after baptism, believers were given increasingly specific instructions before being baptized, especially in the face of heresies in the 4th century.[89] By the 4th and 5th centuries, a series of rites spread over several weeks led up to the actual baptism at Easter: catechumens attended several meetings of intensive catechetical instruction, often by the bishop himself, and often accompanied by special prayers, exorcisms, and other rites.[90]  Catechumens recited the Creed on Holy Saturday to show that they had completed their catechetical instruction.[91]  At dawn following the Paschal Vigil starting the night of Holy Saturday, they were taken to the baptistry where the bishop consecrated the water with a long prayer recounting the types of baptisms. The catechumens disrobed, were anointed with oil, renounced the devil and his works, confessed their faith in the Trinity, and were immersed in the font. They were then anointed with chrism, received the laying on of hands, clothed in white, and led to join the congregation in the Easter celebration.[90]  By then, postponement of baptism had become general, and a large proportion of believers were merely catechumens (Constantine was not baptized until he was dying); but as baptisms of the children of Christians, using an adaptation of the rite intended for adults, became more common than baptisms of adult converts, the number of catechumens decreased.[89]\\r\\n\\r\\nAs baptism was believed to forgive sins, the issue of sins committed after baptism arose. Some insisted that apostasy, even under threat of death, and other grievous sins cut one off forever from the Church.  As indicated in the writings of Saint Cyprian, others favoured readmitting the \\"lapsi\\" easily. The rule that prevailed was that they were readmitted only after undergoing a period of penance that demonstrated sincere repentance.\\r\\n\\r\\nWhat is now generally called the Nicene Creed, longer than the text adopted by the First Council of Nicaea of 325, and known also as the Niceno-Constantinopolitan Creed because of its adoption in that form by the First Council of Constantinople in 381, was probably the baptismal creed then in use in Constantinople, the venue of the 381 Council.[92][page?needed]\\r\\n\\r\\nScholars \\"generally agree that the early church baptized by immersion\\",[93] but sometimes used other forms.[15][94] Howard Marshall says that immersion was the general rule, but affusion and even sprinkling were also practised,[95]  His presentation of this view has been described by Porter and Cross as \\"a compelling argument\\".[96] Laurie Guy says immersion was probably the norm, but that at various times and places full immersion, partial immersion and affusion were probably in use.[97]\\r\\n\\r\\nIt is disputed where immersion was necessarily total. Tischler and the Encyclopedia of Catholicism say that the immersion was total.[98][99] The same encyclopedia of Roman Catholicism notes that the preference of the Early Church was total immersion in a stream or the sea or, if these were not available, in a fountain or bath-sized tank,[100] and Eerdman's Handbook to the History of Christianity says that baptism was normally by immersion, without specifying whether total or partial.[101] The Dictionary of the Bible (2004)[102] says \\"Archaeological evidence from the early centuries shows that baptism was sometimes administered by submersion or immersion... but also by affusion from a vessel when water was poured on the candidate's head...\\".  In one form of early Christian baptism, the candidate stood in water and water was poured over the upper body.[15] Baptism of the sick or dying usually used means other than even partial immersion and was still considered valid.[103] Internet-available illustrations of ancient Christian representations of baptism from as early as the 2nd century include those in CF Rogers, Baptism and Christian Archeology,[104] the chapter \\"The Didache and the Catacombs\\" of Philip Schaff's The Oldest Church Manual Called the Teaching of the Twelve Apostles,[105] and Wolfrid Cote's The Archaeology of Baptism.[106]\\r\\n\\r\\nIn The Archaeology of Baptism (1876) Wolfrid Cote, quoting Prudentius, who in his Psychomachia spoke of the \\"bathed chests\\" of the baptized, and the views of two earlier Italian archaeologists, stated that \\"the primitive mode appears to have been this: The administrator and candidate both standing in the water the former placed his right hand on the head of the candidate, and, pronouncing the baptismal words, gently bowed him forward, till he was completely immersed in the water\\".[107] He included in his book a woodcut of a fresco in the Catacomb of San Callisto (a photographic reproduction appears in this article), and reported that one archaeologist interpreted it as a youth being baptized by affusion, while for another the youth standing in the water was \\"immersed in a cloud of water\\". Cote described this painting as of great antiquity, probably of the 4th or 5th century, while remarking that it is impossible to ascertain the precise age of the pictures in the catacombs of Rome.[108]  The other paintings that Cote described are of much later periods, while the mosaic in the Baptistery of San Giovanni in Fonte, in Ravenna (erected in the 4th century), which shows John baptizing Jesus by pouring water on his head from a cup, Cote explained as the product of later restoring.[109] The font in this baptistery Cote described as ten feet in diameter and three and a half feet deep. Cote listed 67 still existing Italian baptisteries dating from the 4th to the 14th centuries, all of which he understood to have been used for total immersion.[110] He made no mention of any pre-Constantine evidence.\\r\\n\\r\\nIn 1903 Clement F Rogers published \\"Baptism and Christian Archaeology\\".  This was a study of the archaeological evidence, both the positive evidence that paintings and carvings on sarcophagi etc. provide about how baptism actually was conferred, and the negative evidence given by the structure of baptismal fonts on how it could not have been conferred. He used literary sources plentifully but merely for illustration. For the first three centuries (i.e. before the time of Constantine) direct archaeological evidence is limited to pictures of baptism in the catacombs of Rome. Rogers concluded that \\"the direct evidence from archaeology alone may not be conclusive to show that in pre-Constantinian times baptism by affusion only was practiced generally or indeed in any one single case; but it does show that there was nothing repugnant in it to the general mind, that no stress was laid on total immersion, that the most important moments were held to be those when water was poured over the catchumen, and when the minister laid his hand on his head. This, taken in connexion with the known customs of later ages, make it more than probable that the usual method of administration was by affusion only.\\"[111]  Taking into account the positive archaeological evidence of post-Constantinian times, Roger concludes: \\"All the evidence of archaeology goes to prove that the essential part of baptism was considered in the early Church to be the pouring of water over the candidate's head by the bishop, or the guiding his head under a descending stream, followed by the laying on of hands\\"; he adds: \\"There remains the question, whether this was preceded by a self-immersion\\".[112] To answer this question, he examines the negative evidence of ancient baptismal fonts, especially those found in archaeological sites, providing on pp.?347ÿ49 a Synoptic Table of Fonts, with date, shape, diameter and depth, showing that some of them could not have been intended for full immersion.\\r\\n\\r\\nIn his \\"Churches Separated from Rome\\" (1907), Louis Duchesne responded to accusations by Eastern Orthodox that the Roman Catholic was corrupted because of \\"the Filioque, baptism by affusion, unleavened bread, &c.\\",[113] by pointing to the absence of any ancient representation of baptism that showed the neophyte actually being immersed totally.[114]\\r\\n\\r\\nAlois Stenzel's 1958 study of baptism with a focus on liturgy[115] argued that both immersion and affusion were practised by the early Church, since some baptismal pools which have been uncovered were too shallow for baptism and pictorial evidence favoured affusion.[116]\\r\\n\\r\\n\\"Baptism in the Early Church\\" by George Rice (1981), in \\"Bible and Spade\\", cited Cote with favour and claimed that archaeology \\"overwhelmingly testifies to immersion as the normal mode of baptism in the Christian church during the first ten to fourteen centuries\\".[117]  Rice cites in particular imagery in the Catacomb of San Ponziano[118] and a crypt in the catacomb of Santa Lucina,[119] as well as a 9th- or 10th-century fresco in the basilica of San Clemente[120] he also states that \\"pictures of Jesus standing in water while John pours water over His head are of a much later date than those depicting immersion and they demonstrate the change in the mode of baptism that came into the church\\". He mentions a 4th-century baptistery sufficiently large for immersion,[121]  Rice says that archaeological evidence demonstrates some early baptismal fonts large enough for adult immersion were later made smaller or replaced, to accommodate affusion baptism of infants,[122] leading to mistakes in the dating of art works by 20th-century studies.[123]\\r\\n\\r\\nIn his contribution to the 1986 11th International Archaeology Congress on \\"What do the texts teach us on the equipment and furnishings needed for baptism in southern Gaul and northern Italy?\\" Jean-Charles Picard concluded that the texts speak only of immersion and that the area has no archaeological images of baptism by pouring water on the head.[124]\\r\\n\\r\\nIn 1987, on the basis of archaeology and parallels with Jewish practice, Sanford La Sor considered it likely that total immersion was also Christian practice.[125]\\r\\n\\r\\nIn the same year, Lothar Heiser, in his study of baptism in the Orthodox Church, concluded on the basis of the literary and pictorial evidence in that field that \\"the water customarily reached the hips of the baptizand; after calling on the triune God, the priest bent the baptizand under so as to dip him in water over the head; in the cases of pouring in the Didache and in sickbed baptism the baptized did not stand in the font\\"; but acknowledges that in present Greek practice the priest places the infant being baptized as far down in the water as possible and scoops water over the head so as to cover the child fully with water.[126]\\r\\n\\r\\nIn 1995, Renate Pillinger concluded from the evidence provided by images and buildings and by some literary sources that it was usual for the baptizand to stand in water no more than hip-deep and for the baptizer to pour water over him.[127]\\r\\n\\r\\nWith regard to the shallow baptismal fonts that archaeologists had discovered, Malka Ben Pechat expressed in 1999 the view that full immersion was possible even in small fonts with a mere 60 centimetres (2 feet) of water, while the fonts that were even shallower were intended for the baptism of infants.[128]\\r\\n\\r\\nIn the close of his comprehensive 2009 study, Baptism in the Early Church,[129] Everett Ferguson devoted four pages (457ÿ60) to summarizing his position on the mode of baptism, expressed also in his The Church of Christ of 1996,[130] that the normal early-Christian mode of baptism was by full immersion.[131]\\r\\n\\r\\nHe observed that \\"those who approach the study of baptism from the standpoint of archaeology tend to find greater probability that affusion, or perfusion was a normal practice; those who come from the literary evidence see a greater likelihood of immersion, or submersion, being the normal practice\\"; but he intended his own comprehensive survey to give coherence to the evidence (p.?857). Ferguson dismissed Rogers' 1903 study as dated with regard to both the depictions of baptism and his survey of the baptismal fonts.[132]\\r\\n\\r\\nLike Rice, whom he did not mention, Ferguson said that the size of the baptismal fonts was progressively reduced in connection with the prevalence of infant baptism,[133] although there are a few cases where larger fonts are later than the smaller ones.[134] Ferguson also stated: \\"The predominant number of baptismal fonts permitted immersion, and many were so large as to defy any reason for their existence other than immersion\\".[135]\\r\\n\\r\\nRobin Jensen writes: \\"Historians have sometimes assumed that baptism was usually accomplished by full immersion ÿ or submersion ÿ of the body (dunking). However, the archaeological and iconographic evidence is ambiguous on this point. Many ÿ if not most ÿ surviving baptismal fonts are too shallow to have allowed submersion. In addition, a significant number of depictions show baptismal water being poured over the candidate's head (affusion), either from a waterfall, an orb or some kind of liturgical vessel.\\"[136] Eerdman's Dictionary of the Bible also casts doubt on \\"the usual assumption that all NT baptisms were by immersion\\", stating that some early baptisteries were deep enough to stand in but not broad enough to lie down in, and mentioning that ancient representation of Christ at his baptism show him standing in waist-deep water.[137] The immersion used by early Christians in baptizing \\"need not have meant full submersion in the water\\"[138][139] and, while it may have been normal practice, it was not seen as a necessary mode of baptism,[57] so that other modes also may have been used.[140] Submersion, as opposed to partial immersion, may even have been a minority practice in early Christianity.[141]","input":"Who was the first person baptized in the bible?"},{"output":"television personality","context":"Whitney Eve Port (born March 4, 1985) is an American television personality, fashion designer, and author. Born and raised in Los Angeles, California, she attended Crossroads School in Santa Monica as a teenager. In 2006, Port came to prominence after being cast in the reality television series The Hills, which chronicled the personal and professional lives of Port and friends Lauren Conrad, Heidi Montag, and Audrina Patridge. During its production, she held positions with Teen Vogue and Kelly Cutrone's People's Revolution.\\r\\n\\r\\nAfter moving to New York City to begin employment with Diane von Frstenberg in 2008, Port was commissioned to star in her own spin-off series The City, which originally documented the lives of Port and companions Jay Lyon, Olivia Palermo, and Adam Senn. After undergoing several casting adjustments and receiving underwhelming ratings, the series was canceled in 2010, after airing two seasons. Port launched her fashion line \\"Whitney Eve\\" in 2009. In 2012, she served as a judge on the eighth cycle of Britain & Ireland's Next Top Model.\\r\\n\\r\\nWhitney Eve Port was born in Los Angeles, California, to parents Jeffrey and Vicki (ne Woskoff).[1][2] Her father owned the fashion company Swarm, and died in March 2013 from kidney cancer.[3] Port has one brother Ryan and three sisters Ashley, Paige, and Jade, and was raised in a Jewish household.[4][5]\\r\\n\\r\\nPort attended Warner Avenue Elementary School and Crossroads School. In 2007, she graduated from the University of Southern California, having majored in gender studies and was a member of Kappa Alpha Theta.[6] Afterwards, Port held internships with the magazines Women's Wear Daily and W.[7][8]\\r\\n\\r\\nIn 2006, MTV developed the reality television series The Hills as the spin-off of Laguna Beach: The Real Orange County. It originally chronicled the lives of Lauren Conrad, who appeared on its predecessor, her housemate Heidi Montag, and friends Audrina Patridge and Port.[9] During production of the first season, Port and Conrad held internships with Teen Vogue under the direction of West Coast Vogue editor Lisa Love, who stated the girls had to interview successfully for the positions, \\"regardless of what the cameras wanted\\".[10] In 2007, Port notably tripped down the stairs during a live segment for Good Morning America.[2] During the third season of The Hills, Port was promoted as the West Coast fashion contributor for Teen Vogue, and left the position in 2008.[11] Later that year, Port and Conrad began employment with Kelly Cutrone's PR firm, People's Revolution.[12] Port rejected an opportunity to become housemates with Conrad and Patridge, saying she \\"[prefers] to keep some things private\\".[13]\\r\\n\\r\\nIn March 2008, Port debuted her first fashion line \\"Whitney Eve\\".[14] Upon the conclusion of the fourth season of The Hills that December, Port moved to New York City to accept a position with Diane von Frstenberg. That month, she was commissioned to star in the spin-off series The City, which additionally placed emphasis on her boyfriend Jay Lyon, their friends Erin Lucas and Adam Senn, and her co-worker Olivia Palermo.[15] During the first half of the inaugural season, Port severed ties with Lyon, clashed with Palermo at the workplace, and ultimately returned to People's Revolution. After underwhelming ratings, Lyon, Lucas, and Senn were replaced by Port's friend Roxy Olin and Palermo's new co-worker Erin Kaplan in the second half of the first season. The series' second season saw the development of \\"Whitney Eve\\", and aired its final episode in July 2010 before being officially cancelled that October.[16][17]\\r\\n\\r\\nIn late 2010, Port made an appearance on the online series Hollywood Is Like High School with Money, for which she served as the executive producer.[18] The program additionally served as a promotional platform for her \\"Whitney Eve\\" collection.[19] In January 2011, Port was featured in a magazine spread in Maxim.[20] In February, Port released her first book True Whit: Designing a Life of Style, Beauty, and Fun.[21] Later that year, she hosted the Hulu-exclusive game show Genuine Ken.[22]\\r\\n\\r\\nIn 2012, Port was confirmed to join the judging panel of the eighth cycle of Britain and Ireland's Next Top Model, alongside fellow new hire Tyson Beckford and returning judges Elle Macpherson and Julien MacDonald. She left the program upon the conclusion of the season.[23] Port had a cameo role in the film What To Expect When You're Expecting, starring Jennifer Lopez.\\r\\n\\r\\nIn March 2013, Whitney's father, Jeffrey Port, died from a year-long battle with kidney cancer. In November 2013, she announced her engagement to her former The City producer, Tim Rosenman, whom she began dating in 2012. They were married on November 7, 2015.[24] In February 2017, Port and Rosenman announced they were expecting their first child.[25] They welcomed a son, Sonny Sanford, on July 27, 2017.[26]","input":"What does whitney port do for a living?"},{"output":"Casino Night","context":"\\"Casino Night\\" is the second season finale of the American comedy television series The Office, and the twenty-eighth episode overall. Written by Steve Carell, who also acts in the show as Michael Scott, and directed by Ken Kwapis, the episode originally aired in the United States on May 11, 2006 on NBC. The episode guest stars Nancy Carell as Carol Stills and Melora Hardin as Jan Levinson.\\r\\n\\r\\nThe series depicts the everyday lives of office employees in the Scranton, Pennsylvania branch of the fictional Dunder Mifflin Paper Company. In this episode, the office hosts a casino night, to which Michael Scott (Carell) inadvertently invites two dates. Meanwhile, Jim Halpert (John Krasinski) decides to transfer to Dunder Mifflin's Stamford branch and reveals to Pam Beesly (Jenna Fischer) his feelings for her.\\r\\n\\r\\nThe episode was the first of the series to run as a \\"supersized\\" episode, featuring twenty-eight minutes and twenty seconds of content rather than the standard twenty minutes and thirty seconds. In addition, the episode was the first of the series to be written by Carell; he had suggested the idea for the episode to executive producer Greg Daniels, who thoroughly enjoyed the idea and green lit the script. \\"Casino Night\\" also introduces the musical exploits of Kevin Malone, played by Brian Baumgartner. The episode received wide acclaim from television critics and earned a Nielsen rating of 3.9 in the 18ÿ49 demographic, being seen by 7.7 million viewers. It is generally considered by both critics and audiences to be one of the show's greatest episodes.\\r\\n\\r\\nMichael Scott (Steve Carell) organizes a casino charity event in the warehouse, and unwittingly winds up with two dates for the evening, his boss Jan Levinson (Melora Hardin) and his real-estate agent Carol Stills (Nancy Carell).  Jim Halpert (John Krasinski) and Pam Beesly (Jenna Fischer) go through audition tapes for her wedding band and discover that colleague Kevin Malone (Brian Baumgartner) has his own band.  Jim, upset about Pam's impending marriage to Roy Anderson (David Denman), tells the documentary crew that he met with Jan about transferring to the Stamford, Connecticut branch of Dunder Mifflin because he has \\"no future here.\\"\\r\\n\\r\\nDuring Casino Night, Dwight Schrute (Rainn Wilson) wins a game of craps and kisses Angela Martin (Angela Kinsey) on the cheek, disregarding their attempts to keep their intimate relationship a secret. She slaps him and walks away, the two quietly enjoying the experience. Jan and Carol share an awkward conversation when they realize Michael has invited them both. Jim tells Jan that he's made a decision about the transfer. After Roy leaves, Jim tells Pam that he is in love with her. After a stunned pause, she states she cannot be with him. He tells her he wants to be more than friends, but she is sorry he \\"misinterpreted things.\\" Heartbroken, Jim apologizes for misinterpreting their friendship and discreetly wipes a tear from his cheek as he walks away. Jan leaves Michael and Carol, noticeably upset at the night's events, and it is revealed she packed an overnight bag in her car, implying she had planned to spend the night with Michael. Pam returns to the office and talks to her mother over the phone about Jim's statement. Jim enters the room and approaches her as she hastily hangs up. She begins to say something but Jim kisses her, and after hesitating, she returns the kiss, with the two staring at each other in silence.\\r\\n\\r\\n\\"Casino Night\\" was the first episode of the series written by Steve Carell.[2][3] Initially, Carell suggested to executive producer Greg Daniels that an episode should revolve around a casino night. When it came time to plan the finale for the show, Daniels chose the idea and picked Carell to write the script. Parts of the script were fleshed out during the flights to and from New York City when the show was filming the earlier episode \\"Valentine's Day\\". Later, Carell had only one weekend to write the bulk script. Daniels was very happy with the rough script and noted that Carell \\"came in with a great draft\\".[4] Jenna Fischer admitted that filming the episode was a relief because she had \\"been carrying around the secret cliff-hangers for two months\\".[3] Toby Flenderson, who is portrayed by writer Paul Lieberstein, stated during the episode \\"I'm gonna chase that feeling\\" after winning at a game of poker. The line was originally intended to lead to a subplot wherein Toby develops a gambling addiction, but the storyline was later abandoned.[5]\\r\\n\\r\\nThe episode was the fifth episode of the season and the seventh of the entire series directed by Ken Kwapis.[3][6] During the editing of the episode, executive producer Greg Daniels publicly addressed NBC in an interview, stating, \\"I'd like to get a supersized episode, because its a really long script with a lot of good stuff.\\"[7] In response, fans of the show set up an online petition to \\"supersize\\" the season finale. The website generated over 2,800 signatures. On April 20, NBC announced it would be extending the season finale by ten minutes.[2] Although other NBC shows Will & Grace and My Name Is Earl that aired on the same night had extended episodes, cast members David Denman and John Krasinski credited in interviews the petition for the extended time. Denman and Krasinski both believed that the petition was partially responsible for the other two shows getting extended times as well.[8]\\r\\n\\r\\nThe filming of the episode's ending caused a \\"huge divide among the writing staff and the director and the cast\\".[9] Carell, Kwapis, and the actors wanted the moment when Pam and Jim kiss to \\"follow the characters and the emotion of the moment\\" by having the action captured in full by the show's cameramen. The writing staff, on the other hand, wanted Pam and Jim's moment to be private and only heard via the mics; Daniels explained, \\"The writing staff was itching to do something kind of weird [with the scene] and have it be a private moment that the doc crew didn't know was going to happen and so only heard on their mics and came running around the corner to film.\\"[9] Eventually, both versions were filmed, but the former was broadcast. The alternate version has never been released.[9]\\r\\n\\r\\nThe episode features Kevin Malone playing the drums in a band, which had been an idea circulated since the first season, when allusions to him being in a Steve Miller tribute band were written; the scenes had to be removed from the series due to issues negotiating with the singer. The crew later decided to have Kevin be in a Police tribute band called Scrantonicity because he \\"talks so low, and has very little expression, and there is no band that sings higher and with more expression than the Police.\\"[10] While Kevin was always intended to be the band's lead singer, executive producer Greg Daniels approached Baumgartner about possibly playing an instrument, but the actor replied he could not play anything. Daniels and Baumgartner then discussed instruments that would be \\"funny\\" to play and brought up harmonicas, saxophones, and drums. They ultimately decided on the latter because they deemed a \\"drumming lead singer [to] be the funniest choice,\\" regardless of the fact that the actor had \\"absolutely no drumming experience, and it's a difficult instrument.\\"[10]\\r\\n\\r\\nThe Season Two DVD contains a number of deleted scenes from this episode. Notable cut scenes include Michael creating Dunder Mifflin Mad Libs, Dwight and Jim choosing their charities, Dwight considering Jim's telekinetic powers, an extension of Michael's scene with Darryl, Pam finding planning a wedding stressful, Meredith and the casino dealer sharing a past.[11]\\r\\n\\r\\nOn the phone with Jan, Michael compares the performance of the Scranton branch of Dunder Mifflin to the biblical story of David and Goliath. He later tells her that she's the \\"Eva Peron to his Cesar Chavez\\".[12] He later answers a phone from her by saying \\"Jan Levinson, I presume\\", a reference to the quote \\"Dr. Livingstone, I Presume\\", supposedly said by Henry Morton Stanley to David Livingstone after the former met the latter on the shores of Lake Tanganyika in 1871.[12] Michael reasons that the money from the casino night should benefit the Boy Scouts of America because \\"They don't have cookies like the Girl Scouts!\\"[12] He later states that he will donate all of his charity winnings to Comic Relief, a British charity. Kelly reasons that she would donate her winnings to Kobe Bryant's foundation, only because he bought his wife a large ring.[12]\\r\\n\\r\\nWhen Michael mentions donating money to \\"Afghanistanis with AIDS\\", the conversation gets confused, and the various office workers being talking about Afghanis, Afghans, and the nonsensical \\"Afghanistanannis\\".[12] In a talking head, Michael notes that AIDS is not a humorous disease, and is one of the many things that is off-topic in comedy, including the assassination of John F. Kennedy and The Holocaust. However, he notes that the assassination of Abraham Lincoln recently became funny. While looking through the various cover bands, Jim and Pam stumble upon a Kiss tribute and Jim tells Pam that her wedding should have three stages like Lollapalooza. Kevin's band is playing a cover of \\"Don't Stand So Close to Me\\" by The Police.[12]\\r\\n\\r\\n\\"Casino Night\\" originally aired on NBC in the United States on May 11, 2006.[13] The episode received a 3.9 rating/10 percent share among adults between the ages of 18 and 49.[14] This means that it was seen by 3.9 percent of all 18- to 49-year-olds, and 10 percent of all 18- to 49-year-olds watching television at the time of the broadcast.[14] The episode was viewed by 7.7 million viewers, and retained 93 percent of its lead-in \\"My Name is Earl\\" audience.[14] For his work on this episode, Steve Carell was nominated for and won the Writers Guild of America Award for Television: Episodic Comedy.[15]\\r\\n\\r\\n\\"Casino Night\\" received widespread critical acclaim from television critics. Michael Sciannamea of TV Squad stated that \\"This episode, the season finale, was, in a word, brilliant. You could not ask for a better way to tie up story lines that occurred over the course of a season while opening up new ones at the same time.\\"[16] Sciannamea went on to praise Carell's writing, as well as the progression of the relationship arcs in the show.[16] Brian Zoromski of IGN said that \\"'Casino Night,' was full of great character development, awkward situations and laugh-out-loud moments.\\"[17] Zoromski enjoyed the unfolding of the Jim-Pam relationship during the latter half of season two, and the climax of it in the season finale.  He also enjoyed and praised the development of two minor characters, Kevin Malone and Creed Bratton, the latter played by the actor of the same name. He ultimately awarded the episode a ten out of ten, denoting a \\"Masterpiece\\".[17] Jacob Cliffton of Television Without Pity awarded the episode an \\"A\\".[12] Gillian Flynn of Entertainment Weekly noted that, unlike other shows that featured resolved sexual tension, The Office was in no worry of being cancelled. She based this deduction on the fact that the show \\"isn't based entirely on the endearing flirtation between\\" Jim and Pam.[18] In a 2011 poll conducted by fansite OfficeTally, fans voted \\"Casino Night\\" as their favorite of all Office episodes that had been aired at that time.[19]","input":"What episode did pam and jim first kiss?"},{"output":"Canadian Shield","context":"The Canadian Shield, also called the Laurentian Plateau, or Bouclier canadien (French), is a large area of exposed Precambrian igneous and high-grade metamorphic rocks (geological shield) that forms the ancient geological core of the North American continent (the North American Craton or Laurentia). Composed of igneous rock resulting from its long volcanic history, the area is covered by a thin layer of soil.[3] With a deep, common, joined bedrock region in eastern and central Canada, it stretches north from the Great Lakes to the Arctic Ocean, covering over half of Canada; it also extends south into the northern reaches of the United States. Human population is sparse, and industrial development is minimal,[4] while mining is prevalent.\\r\\n\\r\\n\\r\\nThe Canadian Shield is a physiographic division, consisting of five smaller, physiographic provinces: the Laurentian Upland, Kazan Region, Davis, Hudson and James.[1] The shield extends into the United States as the Adirondack Mountains (connected by the Frontenac Axis) and the Superior Upland. The Canadian Shield is U-shaped and is a subsection of the Laurentia craton signifying the area of greatest glacial impact (scraping down to bare rock) creating the thin soils. The Canadian Shield is more than 3.96 billion years old. The Canadian Shield once had jagged peaks, higher than any of today's mountains, but millions of years of erosion have changed these mountains to rolling hills.[citation needed]\\r\\nThe Canadian Shield is a collage of Archean plates and accreted juvenile arc terranes and sedimentary basins of the Proterozoic Eon that were progressively amalgamated during the interval 2.45 to 1.24 Ga, with the most substantial growth period occurring during the Trans-Hudson orogeny, between ca. 1.90 to 1.80 Ga.[5] The Canadian Shield was the first part of North America to be permanently elevated above sea level and has remained almost wholly untouched by successive encroachments of the sea upon the continent. It is the Earth's greatest area of exposed Archean rock. The metamorphic base rocks are mostly from the Precambrian Supereon (between 4.5 billion and 540 million years ago), and have been repeatedly uplifted and eroded. Today it consists largely of an area of low relief 300 to 610?m (980 to 2,000?ft) above sea level with a few monadnocks and low mountain ranges (including the Torngat and Laurentian Mountains) probably eroded from the plateau during the Cenozoic Era. During the Pleistocene Epoch, continental ice sheets depressed the land surface (see Hudson Bay), scooped out thousands of lake basins, and carried away much of the region's soil.\\r\\nWhen the Greenland section is included, the Shield is approximately circular, bounded on the northeast by the northeast edge of Greenland, with Hudson Bay in the middle. It covers much of Greenland, Labrador, most of Quebec north of the St. Lawrence River, much of Ontario including northern sections of the southern peninsula between the Great Lakes, the Adirondack Mountains[6] of New York, the northernmost part of Lower Michigan and all of Upper Michigan, northern Wisconsin, northeastern Minnesota, the central/northern portions of Manitoba away from Hudson Bay, northern Saskatchewan, a small portion of northeastern Alberta,[7] and the mainland northern Canadian territories to the east of a line extended north from the Saskatchewan/Alberta border (Northwest Territories and Nunavut).[2] In total, the exposed area of the Shield covers approximately 8,000,000?km2 (3,088,817?sq?mi). The true extent of the Shield is greater still and stretches from the Western Cordillera in the west to the Appalachians in the east and as far south as Texas, but these regions are overlaid with much younger rocks and sediment. The underlying rock structure also includes Hudson Bay.\\r\\nThe Canadian Shield is among the oldest on earth, with regions dating from 2.5 to 4.2 billion years.[8] The multitude of rivers and lakes in the entire region is caused by the watersheds of the area being so young and in a state of sorting themselves out with the added effect of post-glacial rebound. The Shield was originally an area of very large, very tall mountains (about 12,000 metres or 39,000 feet)[9] with much volcanic activity, but over hundreds of millions of years, the area has been eroded to its current topographic appearance of relatively low relief.[citation needed] It has some of the oldest (extinct) volcanoes on the planet.[citation needed] It has over 150 volcanic belts (now deformed and eroded down to nearly flat plains) whose bedrock ranges from 600 to 1200 million years old.[citation needed]\\r\\nEach belt probably grew by the coalescence of accumulations erupted from numerous vents, making the tally of volcanoes reach the hundreds. Many of Canada's major ore deposits are associated with Precambrian volcanoes.\\r\\nThe Sturgeon Lake Caldera in Kenora District, Ontario, is one of the world's best preserved mineralized Neoarchean caldera complexes, which is 2.7 billion years old.[10] The Canadian Shield also contains the Mackenzie dike swarm, which is the largest dike swarm known on Earth.[11]\\r\\nMountains have deep roots and float on the denser mantle much like an iceberg at sea. As mountains erode, their roots rise and are eroded in turn. The rocks that now form the surface of the Shield were once far below the Earth's surface.\\r\\nThe high pressures and temperatures at those depths provided ideal conditions for mineralization. Although these mountains are now heavily eroded, many large mountains still exist in Canada's far north called the Arctic Cordillera. This is a vast deeply dissected mountain range, stretching from northernmost Ellesmere Island to the northernmost tip of Labrador. The range's highest peak is Nunavut's Barbeau Peak at 2,616 metres (8,583?ft) above sea level.[12] Precambrian rock is the major component of the bedrock.\\r\\nThe North American craton is the bedrock forming the heart of the North American continent and the Canadian Shield is the largest exposed part of the craton's bedrock.\\r\\nThe Canadian Shield is part of an ancient continent called Arctica, which was formed about 2.5 billion years ago during the Neoarchean era. It was split into Greenland, Laurentia, Scotland and Siberia and is now roughly situated in the Arctic around the current North Pole.\\r\\nThe current surface expression of the Shield is one of very thin soil lying on top of the bedrock, with many bare outcrops. This arrangement was caused by severe glaciation during the ice age, which covered the Shield and scraped the rock clean.\\r\\nThe lowlands of the Canadian Shield have a very dense soil that is not suitable for forestation; it also contains many marshes and bogs (muskegs). The rest of the region has coarse soil that does not retain moisture well and is frozen with permafrost throughout the year. Forests are not as dense in the north.\\r\\nThe Shield is covered in parts by vast boreal forests in the south that support natural ecosystems as well as a major logging industry. This boreal forest area includes ecoregions such as the Eastern Canadian Shield taiga that covers northern Quebec and most of Labrador, and the Midwestern Canadian Shield forests that run westwards from Northwestern Ontario. Hydrographical drainage is generally poor, the soil compacting effects of glaciation being one of the many causes. Tundra typically prevails in the northern regions. Many mammals such as caribou, white-tailed deer, moose, wolves, wolverines, weasels, mink, otters, grizzly bear, polar bears and black bears are present.[13] In the case of polar bears (Ursus maritimus) the Shield area contains many of the denning locations such as the Wapusk National Park.[14]\\r\\nThe Canadian Shield is one of the world's richest areas in terms of mineral ores. It is filled with substantial deposits of nickel, gold, silver, and copper. Throughout the Shield there are many mining towns extracting these minerals. The largest, and one of the best known, is Sudbury, Ontario. Sudbury is an exception to the normal process of forming minerals in the Shield since the Sudbury Basin is an ancient meteorite impact crater. Ejecta from the meteorite impact was found in the Rove Formation in May 2007. The nearby, but less known Temagami Magnetic Anomaly, has striking similarities to the Sudbury Basin. This suggests it could be a second metal-rich impact crater.[15]\\r\\nIn northeastern Quebec, the giant Manicouagan Reservoir is the site of an extensive hydroelectric project (Manic-cinq, or Manic-5). This is one of the largest-known meteorite impact craters on Earth.\\r\\nThe Flin Flon greenstone belt in central Manitoba and east-central Saskatchewan is one of the largest Paleoproterozoic volcanic-hosted massive sulfide (VMS) districts in the world, containing 27 copper-zinc-(gold) deposits from which more than 183 million tons[clarification needed] of sulfide have been mined.[16]\\r\\nThe Shield, particularly the portion in the Northwest Territories, has recently been the site of several major diamond discoveries. The kimberlite pipes in which the diamonds are found are closely associated with cratons, which provide the deep lithospheric mantle required to stabilize diamond as a mineral. The kimberlite eruptions then bring the diamonds from over 150 kilometres (93?mi) depth to the surface. Currently the Ekati and Diavik mines are actively mining kimberlite diamonds.\\r\\nCoordinates: 5200N 7100W? / ?52.000N 71.000W? / 52.000; -71.000","input":"What landform region is the geological foundation of canada?"},{"output":"Tommy Vext","context":"Bad Wolves is an American heavy metal supergroup[5] formed in 2017.\\r\\n\\r\\n\\r\\nThe band consists of vocalist Tommy Vext (ex-Divine Heresy, ex-Snot), drummer John Boecklin (ex-DevilDriver), lead guitarist Doc Coyle (ex-God Forbid), rhythm guitarist Chris Cain (ex-Bury Your Dead, ex-For the Fallen Dreams) and bassist Kyle Konkiel (ex-In This Moment, Vimic).[4] and is managed by Zoltan Bathory of Five Finger Death Punch.\\r\\nThe band announced that they will release their debut studio album, Disobey on May 11, 2018.[6] In May 2017, Bad Wolves released their debut single, \\"Learn to Live\\".[7] In November 2017, Bad Wolves released their second single, \\"Toast to the Ghost\\".[4] On January 18, 2018, they released a third single, which was a cover of \\"Zombie\\" (originally by The Cranberries), which charted on multiple Billboard charts.[8][9] The Cranberries singer, Dolores O'Riordan, was supposed to have performed the song with the band, but died prior to recording it.[8] A music video was released on February 22. The song topped the US Billboard Mainstream Rock chart.\\r\\nThe band is touring with Five Finger Death Punch, Shinedown, Breaking Benjamin, and Starset in the first half of 2018.[10]","input":"Who is the lead singer of bad wolves?"},{"output":"Hue Jackson","context":"The Cleveland Browns are a professional American football franchise based in Cleveland, Ohio. They are a member of the North Division of the American Football Conference (AFC) in the National Football League (NFL). The team began playing in 1946 as a charter member of the All-America Football Conference (AAFC), and joined the NFL as part of the AAFCÿNFL merger in 1950.[1] The team played their home games at Cleveland Stadium from 1946 to 1995 before moving to FirstEnergy Stadium, where they have played since 1999.[2] The Browns did not play from 1996 to 1998 when the team's owner, Art Modell, moved the team to Baltimore, Maryland and formed the Baltimore Ravens. The team was re-activated under new ownership in Cleveland in 1999.[3] The team is currently owned by Jimmy Haslam III, and Joe Banner is their Chief Executive Officer.[4] Tom Heckert was their general manager until the end of the 2012 season, when he was fired along with the team's incumbent head coach Pat Shurmur.[5]\\r\\n\\r\\nThere have been 15 non-interim head coaches for the Browns franchise. Their first head coach was Paul Brown, who coached for 17 complete seasons.[6] Brown is also the franchise's all-time leader for the most regular season games coached (214), the most regular season game wins (158), the most playoffs games coached (14), and the most playoff game wins (9). Brown is the only Browns head coach to win an AAFC championship with four, the NFL championship with three, the Sporting News NFL Coach of the Year three times, the United Press International (UPI) NFL Coach of the Year once,[7] and to have been elected into the Pro Football Hall of Fame as a coach.[8] Blanton Collier, Dick Modzelewski, Sam Rutigliano, Bud Carson, Jim Shofner, Chris Palmer, Butch Davis, Pat Shurmur, and Rob Chudzinski have spent their entire NFL head coaching careers with the Browns. Eric Mangini had been the head coach of the Browns since the firing of Romeo Crennel,[9] but was himself fired on January 3, 2011. Shurmur replaced Mangini as head coach, but was fired after posting a 9ÿ23 record over two seasons in charge.[5] On January 11, 2013, the Cleveland Browns officially named Rob Chudzinski as the replacement for Pat Shurmur. Chudzinski compiled a 4ÿ12 record during the 2013 season, but he was fired on December 29.[10] On January 23, 2014, the Browns hired Mike Pettine as their head coach. Pettine was fired on January 3, 2016, hours after the Browns lost their 2015 season finale. On January 13, 2016, Hue Jackson was named the Browns' new head coach.\\r\\n\\r\\nNote: Statistics are updated through the 2017 NFL season.\\r\\n\\r\\n1949, 1951, and 1953 Sporting News NFL Coach of the Year[13]1957 UPI NFL Coach of the Year[7]\\r\\n\\r\\n# denotes interim head coach","input":"Who is the head coach of the cleveland browns?"},{"output":"a coalition of Arab states led by Egypt and Syria against Israel","context":"","input":"Who was involved in the yom kippur war?"},{"output":"neurons, or nerve cells","context":"Nervous tissue or nerve tissue is the main tissue component of the two parts of the nervous system; the brain and spinal cord of the central nervous system (CNS), and the branching peripheral nerves of the peripheral nervous system (PNS), which regulates and controls bodily functions and activity. It is composed of neurons, or nerve cells, which receive and transmit impulses, and neuroglia, also known as glial cells or more commonly as just glia (from the Greek, meaning glue), which assist the propagation of the nerve impulse as well as providing nutrients to the neuron.\\r\\nNervous tissue is made up of different types of nerve cells, all of which have an axon, the long stem-like part of the cell that sends action potential signals to the next cell. Bundles of axons make up the nerves.\\r\\nFunctions of the nervous system are sensory input, integration, control of muscles and glands, homeostasis, and mental activity.\\r\\n\\r\\n\\r\\nNervous tissue is composed of neurons, also called nerve cells, and neuroglial cells. Typically, nervous tissue is categorized into four types of tissue. In the central nervous system (CNS), the tissue types found are grey matter and white matter. In the peripheral nervous system (PNS), the tissue types are nerves and ganglia. The tissue is categorized by its neuronal and neuroglial components.[1]\\r\\nNeurons are cells with specialized features that allow them to receive and facilitate nerve impulses, or action potentials, across their membrane to the next neuron.[2] They possess a large cell body (soma), with cell projections called dendrites and an axon. Dendrites are thin, branching projections that receive electrochemical signaling (neurotransmitters) to create a change in voltage in the cell. Axons are long projections that carry the action potential away from the cell body toward the next neuron. The bulb-like end of the axon, called the axon terminal, is separated from the dendrite of the following neuron by a small gap called a synaptic cleft. When the action potential travels to the axon terminal, neurotransmitters are released across the synapse and bind to the post-synaptic receptors, continuing the nerve impulse.[3]\\r\\nNeurons are classified both functionally and structurally.\\r\\nFunctional classification:[4]\\r\\nStructural classification:[4]\\r\\nNeuroglia encompasses the non-neural cells in nervous tissue that provide various crucial supportive functions for neurons. They are smaller than neurons, and vary in structure according to their function.[3]\\r\\nNeuroglial cells are classified as follows:[5]\\r\\nIn the central nervous system:[10]\\r\\nIn the Peripheral Nervous System:[11]\\r\\nThe three layers of connective tissue surrounding each nerve are:[10]\\r\\nThe function of nervous tissue is to form the communication network of the nervous system by conducting electric signals across tissue.[12] In the CNS, grey matter, which contains the synapses, is important for information processing. White matter, containing myelinated axons, connects and facilitates nerve impulse between grey matter areas in the CNS.[13] In the PNS, the ganglion tissue, containing the cell bodies and dendrites, contain relay points for nerve tissue impulses. The nerve tissue, containing myelinated axons bundles, carry action potential/nerve impulses.[10]\\r\\nNeoplasms (tumours) in nervous tissue include:","input":"What is the most abundant type of cell in the nervous system?"},{"output":"a nonsteroidal anti-inflammatory drug (NSAID)","context":"Aspirin, also known as acetylsalicylic acid (ASA), is a medication used to treat pain, fever, or inflammation.[3] Specific inflammatory conditions in which aspirin is used include Kawasaki disease, pericarditis, and rheumatic fever.[3] Aspirin given shortly after a heart attack decreases the risk of death.[3] Aspirin is also used long-term to help prevent heart attacks, ischaemic strokes, and blood clots, in people at high risk.[3] Aspirin may also decrease the risk of certain types of cancer, particularly colorectal cancer.[4] For pain or fever, effects typically begin within 30 minutes.[3] Aspirin is a nonsteroidal anti-inflammatory drug (NSAID) and works similar to other NSAIDs but also suppresses the normal functioning of platelets.[3]\\r\\nCommon side effects include an upset stomach.[3] More significant side effects include stomach ulcers, stomach bleeding, and worsening asthma.[3] Bleeding risk is greater among those who are older, drink alcohol, take other NSAIDs, or are on blood thinners.[3] Aspirin is not recommended in the last part of pregnancy.[3] It is not generally recommended in children with infections because of the risk of Reye's syndrome.[3] High doses may result in ringing in the ears.[3]\\r\\nAspirin, in the form of leaves from the willow tree, has been used for its health effects for at least 2,400 years.[5] In 1853, chemist Charles Frdric Gerhardt treated sodium salicylate with acetyl chloride to produce acetylsalicylic acid for the first time.[6] In the second half of the nineteenth century, other chemists established the chemical structure and came up with more efficient methods to make it.[6]:69ÿ75 In 1897, scientists at Bayer began studying acetylsalicylic acid as a less-irritating replacement for common salicylate medicines.[6]:69ÿ75 By 1899, Bayer had named the drug Aspirin and was selling it around the world.[7] The word Aspirin was Bayer's brand name; however, their rights to the trademark were lost or sold in many countries.[8] Aspirin's popularity grew over the first half of the twentieth century leading to competition between many brands and formulations.[8]\\r\\nAspirin is one of the most widely used medications globally with an estimated 40,000 tonnes (50 to 120 billion pills) being consumed each year.[5][9] It is on the World Health Organization's List of Essential Medicines, the most effective and safe medicines needed in a health system.[10] Aspirin is available as a generic medication. The wholesale cost in the developing world as of 2014 is 0.002 to 0.025 USD per dose.[11] As of 2015 the cost for a typical month of medication in the United States is less than US$25.[12]\\r\\nAspirin is used in the treatment of a number of conditions, including fever, pain, rheumatic fever, and inflammatory diseases, such as rheumatoid arthritis, pericarditis, and Kawasaki disease.[13] Lower doses of aspirin have also been shown to reduce the risk of death from a heart attack, or the risk of stroke in some circumstances.[14][15][16] There is some evidence that aspirin is effective at preventing colorectal cancer, though the mechanisms of this effect are unclear.[17] In the United States low dose aspirin is deemed reasonable in those between 50 and 70 years old who have a more than 10% risk of cardiovascular disease and are not at an increased risk of bleeding who are otherwise healthy.[18]\\r\\nAspirin is an effective analgesic for acute pain, but is generally considered inferior to ibuprofen for the alleviation of pain because aspirin is more likely to cause gastrointestinal bleeding.[19] Aspirin is generally ineffective for those pains caused by muscle cramps, bloating, gastric distension, or acute skin irritation.[20] As with other NSAIDs, combinations of aspirin and caffeine provide slightly greater pain relief than aspirin alone.[21] Effervescent formulations of aspirin, such as Alka-Seltzer or Blowfish,[22] relieve pain faster than aspirin in tablets,[23] which makes them useful for the treatment of migraines.[24] Topical aspirin may be effective for treating some types of neuropathic pain.[25]\\r\\nAspirin, either by itself or in a combined formulation, effectively treats certain types of a headache, but its efficacy may be questionable for others. Secondary headaches, meaning those caused by another disorder or trauma, should be promptly treated by a medical provider.\\r\\nAmong primary headaches, the International Classification of Headache Disorders distinguishes between tension headache (the most common), migraine, and cluster headache. Aspirin or other over-the-counter analgesics are widely recognized as effective for the treatment of tension headache.[26]\\r\\nAspirin, especially as a component of an aspirin/paracetamol/caffeine combination, is considered a first-line therapy in the treatment of migraine, and comparable to lower doses of sumatriptan. It is most effective at stopping migraines when they are first beginning.[27]\\r\\nLike its ability to control pain, aspirin's ability to control fever is due to its action on the prostaglandin system through its irreversible inhibition of COX.[28] Although aspirin's use as an antipyretic in adults is well-established, many medical societies and regulatory agencies (including the American Academy of Family Physicians, the American Academy of Pediatrics, and the U.S. Food and Drug Administration (FDA)) strongly advise against using aspirin for treatment of fever in children because of the risk of Reye's syndrome, a rare but often fatal illness associated with the use of aspirin or other salicylates in children during episodes of viral or bacterial infection.[29][30][31] Because of the risk of Reye's syndrome in children, in 1986, the FDA required labeling on all aspirin-containing medications advising against its use in children and teenagers.[32]\\r\\nAspirin is used as an anti-inflammatory agent for both acute and long-term inflammation,[33] as well as for treatment of inflammatory diseases, such as rheumatoid arthritis.[13]\\r\\nAspirin is an important part of the treatment of those who have had a myocardial infarction (heart attack).[34] One trial found that among those likely having an ST-segment elevation MI, aspirin saves the life of 1 in 42 by reducing the 30-day death rate from 11.8% to 9.4%.[35] There was no difference in major bleeding, but there was a small increase in minor bleeding amounting to roughly 1 in every 167 people given aspirin.[35]\\r\\nFor people who have already had a heart attack or stroke, taking aspirin daily for two years prevented 1 in 50 from having a cardiovascular problem (heart attack, stroke, or death), but also caused non-fatal bleeding problems to occur in 1 of 400 people.[36][37][38]\\r\\nStudies have not found an overall benefit in the general population of healthy people, although it is possible that there are small benefits for those at especially high risk, despite never having had a heart attack or stroke in the past.[39] One study found that among those who have never had a heart attack or stroke, taking aspirin daily for 1 year prevents 1 in 1,667 from having a non-fatal heart attack or stroke, but caused 1 in 3,333 to have a non-fatal bleeding event. However, the study population were at relatively higher risk than those who had never had a heart attack or stroke.[40]\\r\\nAspirin appears to offer little benefit to those at lower risk of heart attack or strokefor instance, those without a history of these events or with pre-existing disease. Some studies recommend aspirin on a case-by-case basis,[41][42] while others have suggested the risks of other events, such as gastrointestinal bleeding, were enough to outweigh any potential benefit, and recommended against using aspirin for primary prevention entirely.[43] Aspirin has also been suggested as a component of a polypill for prevention of cardiovascular disease.[44][45]\\r\\nComplicating the use of aspirin for prevention is the phenomenon of aspirin resistance.[46][47] For people who are resistant, aspirin's efficacy is reduced.[48] Some authors have suggested testing regimens to identify people who are resistant to aspirin.[49]\\r\\nAfter percutaneous coronary interventions (PCIs), such as the placement of a coronary artery stent, a U.S. Agency for Healthcare Research and Quality guideline recommends that aspirin be taken indefinitely.[50] Frequently, aspirin is combined with an ADP receptor inhibitor, such as clopidogrel, prasugrel, or ticagrelor to prevent blood clots. This is called dual antiplatelet therapy (DAPT). United States and European Union guidelines disagree somewhat about how long, and for what indications this combined therapy should be continued after surgery. U.S. guidelines recommend DAPT for at least 12 months, while EU guidelines recommend DAPT for 6ÿ12 months after a drug-eluting stent placement.[51] However, they agree that aspirin be continued indefinitely after DAPT is complete.\\r\\nAspirin is thought to reduce the overall risk of both getting cancer and dying from cancer.[52] This effect is particularly beneficial for colorectal cancer (CRC).[17][53][54][55] It may also slightly reduce the risk of endometrial cancer,[56] breast cancer, and prostate cancer.[57]\\r\\nSome conclude the benefits are greater than the risks due to bleeding in those at average risk.[52] Others are unclear if the benefits are greater than the risk.[58][59] Given this uncertainty, the 2007 United States Preventive Services Task Force guidelines on this topic recommended against the use of aspirin for prevention of CRC in people with average risk.[60]\\r\\nAspirin is a first-line treatment for the fever and joint-pain symptoms of acute rheumatic fever. The therapy often lasts for one to two weeks, and is rarely indicated for longer periods. After fever and pain have subsided, the aspirin is no longer necessary, since it does not decrease the incidence of heart complications and residual rheumatic heart disease.[61][62] Naproxen has been shown to be as effective as aspirin and less toxic, but due to the limited clinical experience, naproxen is recommended only as a second-line treatment.[61][63]\\r\\nAlong with rheumatic fever, Kawasaki disease remains one of the few indications for aspirin use in children[64] in spite of a lack of high quality evidence for its effectiveness.[65]\\r\\nLow-dose aspirin supplementation has moderate benefits when used for prevention of pre-eclampsia.[66][67] This benefit is greater when started in early pregnancy.[68]\\r\\nFor some people, aspirin does not have as strong an effect on platelets as for others, an effect known as aspirin-resistance or insensitivity. One study has suggested women are more likely to be resistant than men,[69] and a different, aggregate study of 2,930 people found 28% were resistant.[70] A study in 100 Italian people, though, found, of the apparent 31% aspirin-resistant subjects, only 5% were truly resistant, and the others were noncompliant.[71] Another study of 400 healthy volunteers found no subjects who were truly resistant, but some had \\"pseudoresistance, reflecting delayed and reduced drug absorption\\".[72][verification needed]\\r\\nAdult aspirin tablets are produced in standardised sizes, which vary slightly from country to country, for example 300?mg in Britain and 325?mg (or 5 grains) in the United States. Smaller doses are based on these standards, e.g., 75?mg and 81?mg tablets. The 81?mg (1?1?4-grain) tablets are commonly called \\"baby aspirin\\" or \\"baby-strength\\", because they were originallybut no longerintended to be administered to infants and children.[73] No medical significance occurs due to the slight difference in dosage between the 75?mg and the 81?mg tablets.\\r\\nIn general, for adults, doses are taken four times a day for fever or arthritis,[74] with doses near the maximal daily dose used historically for the treatment of rheumatic fever.[75] For the prevention of myocardial infarction (MI) in someone with documented or suspected coronary artery disease, much lower doses are taken once daily.[74]\\r\\nMarch 2009 recommendations from the USPSTF on the use of aspirin for the primary prevention of coronary heart disease encourage men aged 45ÿ79 and women aged 55ÿ79 to use aspirin when the potential benefit of a reduction in MI for men or stroke for women outweighs the potential harm of an increase in gastrointestinal hemorrhage.[76] The WHI study said regular low dose (75 or 81?mg) aspirin female users had a 25% lower risk of death from cardiovascular disease and a 14% lower risk of death from any cause.[76] Low-dose aspirin use was also associated with a trend toward lower risk of cardiovascular events, and lower aspirin doses (75 or 81?mg/day) may optimize efficacy and safety for people requiring aspirin for long-term prevention.[76]\\r\\nIn children with Kawasaki disease, aspirin is taken at dosages based on body weight, initially four times a day for up to two weeks and then at a lower dose once daily for a further six to eight weeks.[77]\\r\\nAspirin should not be taken by people who are allergic to ibuprofen or naproxen,[78][79] or who have salicylate intolerance[80][81] or a more generalized drug intolerance to NSAIDs, and caution should be exercised in those with asthma or NSAID-precipitated bronchospasm. Owing to its effect on the stomach lining, manufacturers recommend people with peptic ulcers, mild diabetes, or gastritis seek medical advice before using aspirin.[78][82] Even if none of these conditions is present, the risk of stomach bleeding is still increased when aspirin is taken with alcohol or warfarin.[78][79] People with hemophilia or other bleeding tendencies should not take aspirin or other salicylates.[78][82] Aspirin is known to cause hemolytic anemia in people who have the genetic disease glucose-6-phosphate dehydrogenase deficiency, particularly in large doses and depending on the severity of the disease.[83] Use of aspirin during dengue fever is not recommended owing to increased bleeding tendency.[84] People with kidney disease, hyperuricemia, or gout should not take aspirin because it inhibits the kidneys' ability to excrete uric acid, thus may exacerbate these conditions. Aspirin should not be given to children or adolescents to control cold or influenza symptoms, as this has been linked with Reye's syndrome.[85]\\r\\nAspirin use has been shown to increase the risk of gastrointestinal bleeding.[86] Although some enteric-coated formulations of aspirin are advertised as being \\"gentle to the stomach\\", in one study, enteric coating did not seem to reduce this risk.[86] Combining aspirin with other NSAIDs has also been shown to further increase this risk.[86] Using aspirin in combination with clopidogrel or warfarin also increases the risk of upper gastrointestinal bleeding.[87]\\r\\nBlockade of COX-1 by aspirin apparently results in the upregulation of COX-2 as part of a gastric defense[88] and that taking COX-2 inhibitors concurrently with aspirin increases the gastric mucosal erosion.[89] Therefore, caution should be exercised if combining aspirin with any \\"natural\\" supplements with COX-2-inhibiting properties, such as garlic extracts, curcumin, bilberry, pine bark, ginkgo, fish oil, resveratrol, genistein, quercetin, resorcinol, and others.\\r\\nIn addition to enteric coating, \\"buffering\\" is the other main method companies have used to try to mitigate the problem of gastrointestinal bleeding. Buffering agents are intended to work by preventing the aspirin from concentrating in the walls of the stomach, although the benefits of buffered aspirin are disputed. Almost any buffering agent used in antacids can be used; Bufferin, for example, uses magnesium oxide. Other preparations use calcium carbonate.[90]\\r\\nTaking it with vitamin C is a more recently investigated method of protecting the stomach lining. Taking equal doses of vitamin C and aspirin may decrease the amount of stomach damage that occurs compared to taking aspirin alone.[91][92]\\r\\nLarge doses of salicylate, a metabolite of aspirin, cause temporary tinnitus (ringing in the ears) based on experiments in rats, via the action on arachidonic acid and NMDA receptors cascade.[93]\\r\\nReye's syndrome, a rare but severe illness characterized by acute encephalopathy and fatty liver, can occur when children or adolescents are given aspirin for a fever or other illness or infection. From 1981 through 1997, 1207 cases of Reye's syndrome in people younger than 18 were reported to the U.S. Centers for Disease Control and Prevention. Of these, 93% reported being ill in the three weeks preceding the onset of Reye's syndrome, most commonly with a respiratory infection, chickenpox, or diarrhea. Salicylates were detectable in 81.9% of children for whom test results were reported.[94] After the association between Reye's syndrome and aspirin was reported, and safety measures to prevent it (including a Surgeon General's warning, and changes to the labeling of aspirin-containing drugs) were implemented, aspirin taken by children declined considerably in the United States, as did the number of reported cases of Reye's syndrome; a similar decline was found in the United Kingdom after warnings against pediatric aspirin use were issued.[94] The U.S. Food and Drug Administration now recommends aspirin (or aspirin-containing products) should not be given to anyone under the age of 12 who has a fever,[85] and the British Medicines and Healthcare products Regulatory Agency recommends children who are under 16 years of age should not take aspirin, unless it is on the advice of a doctor.[95]\\r\\nFor a small number of people, taking aspirin can result in symptoms resembling an allergic reaction, including hives, swelling, and headache. The reaction is caused by salicylate intolerance and is not a true allergy, but rather an inability to metabolize even small amounts of aspirin, resulting in an overdose.\\r\\nAspirin and other NSAIDs, such as ibuprofen, may delay the healing of skin wounds.[96] Aspirin may however help heal venous leg ulcers that have not healed following usual treatment.[97]\\r\\nAspirin can induce swelling of skin tissues in some people. In one study, angioedema appeared one to six hours after ingesting aspirin in some of the people. However, when the aspirin was taken alone, it did not cause angioedema in these people; the aspirin had been taken in combination with another NSAID-induced drug when angioedema appeared.[98]\\r\\nAspirin causes an increased risk of cerebral microbleeds having the appearance on MRI scans of 5 to 10?mm or smaller, hypointense (dark holes) patches.[99][100] Such cerebral microbleeds are important, since they often occur prior to ischemic stroke or intracerebral hemorrhage, Binswanger disease, and Alzheimer's disease.[original research?]\\r\\nA study of a group with a mean dosage of aspirin of 270?mg per day estimated an average absolute risk increase in intracerebral hemorrhage (ICH) of 12 events per 10,000 persons.[101] In comparison, the estimated absolute risk reduction in myocardial infarction was 137 events per 10,000 persons, and a reduction of 39 events per 10,000 persons in ischemic stroke.[101] In cases where ICH already has occurred, aspirin use results in higher mortality, with a dose of about 250?mg per day resulting in a relative risk of death within three months after the ICH around 2.5 (95% confidence interval 1.3 to 4.6).[102]\\r\\nAspirin and other NSAIDs can cause abnormally high blood levels of potassium by inducing a hyporeninemic hypoaldosteronic state via inhibition of prostaglandin synthesis; however, these agents do not typically cause hyperkalemia by themselves in the setting of normal renal function and euvolemic state.[103]\\r\\nAspirin can cause prolonged bleeding after operations for up to 10 days. In one study, 30 of 6499 people having elective surgery required reoperations to control bleeding. Twenty had diffuse bleeding and 10 had bleeding from a site. Diffuse, but not discrete, bleeding was associated with the preoperative use of aspirin alone or in combination with other NSAIDS in 19 of the 20 diffuse bleeding people.[104]\\r\\nOn 9 July 2015, the FDA toughened warnings of increased heart attack and stroke risk associated with nonsteroidal anti-inflammatory drugs (NSAID). Aspirin is an NSAID but is not affected by the new warnings.[105]\\r\\nAspirin overdose can be acute or chronic. In acute poisoning, a single large dose is taken; in chronic poisoning, higher than normal doses are taken over a period of time. Acute overdose has a mortality rate of 2%. Chronic overdose is more commonly lethal, with a mortality rate of 25%;[106] chronic overdose may be especially severe in children.[107] Toxicity is managed with a number of potential treatments, including activated charcoal, intravenous dextrose and normal saline, sodium bicarbonate, and dialysis.[108] The diagnosis of poisoning usually involves measurement of plasma salicylate, the active metabolite of aspirin, by automated spectrophotometric methods. Plasma salicylate levels in general range from 30ÿ100?mg/l after usual therapeutic doses, 50ÿ300?mg/l in people taking high doses and 700ÿ1400?mg/l following acute overdose. Salicylate is also produced as a result of exposure to bismuth subsalicylate, methyl salicylate, and sodium salicylate.[109][110]\\r\\nAspirin is known to interact with other drugs. For example, acetazolamide and ammonium chloride are known to enhance the intoxicating effect of salicylates, and alcohol also increases the gastrointestinal bleeding associated with these types of drugs.[78][79] Aspirin is known to displace a number of drugs from protein-binding sites in the blood, including the antidiabetic drugs tolbutamide and chlorpropamide, warfarin, methotrexate, phenytoin, probenecid, valproic acid (as well as interfering with beta oxidation, an important part of valproate metabolism), and other NSAIDs. Corticosteroids may also reduce the concentration of aspirin. Ibuprofen can negate the antiplatelet effect of aspirin used for cardioprotection and stroke prevention.[111] The pharmacological activity of spironolactone may be reduced by taking aspirin, and it is known to compete with penicillin G for renal tubular secretion.[112] Aspirin may also inhibit the absorption of vitamin C.[113][114][unreliable medical source?][115]\\r\\nAspirin decomposes rapidly in solutions of ammonium acetate or the acetates, carbonates, citrates, or hydroxides of the alkali metals. It is stable in dry air, but gradually hydrolyses in contact with moisture to acetic and salicylic acids. In solution with alkalis, the hydrolysis proceeds rapidly and the clear solutions formed may consist entirely of acetate and salicylate.[116]\\r\\nLike flour mills, factories that make aspirin tablets must pay attention to how much of the powder gets into the air inside the building, because the powder-air mixture can be explosive. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit in the United States of 5?mg/m3 (time-weighted average).[117] In 1989, the Occupational Safety and Health Administration (OSHA) set a legal permissible exposure limit for aspirin of 5?mg/m3, but this was vacated by the AFL-CIO v. OSHA decision in 1993.[118]\\r\\nThe synthesis of aspirin is classified as an esterification reaction. Salicylic acid is treated with acetic anhydride, an acid derivative, causing a chemical reaction that turns salicylic acid's hydroxyl group into an ester group (R-OH L R-OCOCH3). This process yields aspirin and acetic acid, which is considered a byproduct of this reaction. Small amounts of sulfuric acid (and occasionally phosphoric acid) are almost always used as a catalyst. This method is commonly employed in undergraduate teaching labs.[119]\\r\\nFormulations containing high concentrations of aspirin often smell like vinegar[120] because aspirin can decompose through hydrolysis in moist conditions, yielding salicylic and acetic acids.[121]\\r\\nAspirin, an acetyl derivative of salicylic acid, is a white, crystalline, weakly acidic substance, with a melting point of 136?C (277?F), and a boiling point of 140?C (284?F).[122] Its acid dissociation constant (pKa) is 3.5 at 25?C (77?F).[123]\\r\\nPolymorphism, or the ability of a substance to form more than one crystal structure, is important in the development of pharmaceutical ingredients. Many drugs are receiving regulatory approval for only a single crystal form or polymorph. For a long time, only one crystal structure for aspirin was known. That aspirin might have a second crystalline form was suspected since the 1960s. The elusive second polymorph was first discovered by Vishweshwar and coworkers in 2005,[124] and fine structural details were given by Bond et al.[125] A new crystal type was found after attempted cocrystallization of aspirin and levetiracetam from hot acetonitrile. The form II is only stable at 100?K and reverts to form I at ambient temperature. In the (unambiguous) form I, two salicylic molecules form centrosymmetric dimers through the acetyl groups with the (acidic) methyl proton to carbonyl hydrogen bonds, and in the newly claimed form II, each salicylic molecule forms the same hydrogen bonds with two neighboring molecules instead of one. With respect to the hydrogen bonds formed by the carboxylic acid groups, both polymorphs form identical dimer structures.[citation needed]\\r\\nIn 1971, British pharmacologist John Robert Vane, then employed by the Royal College of Surgeons in London, showed aspirin suppressed the production of prostaglandins and thromboxanes.[126][127] For this discovery he was awarded the 1982 Nobel Prize in Physiology or Medicine, jointly with Sune Bergstr?m and Bengt Ingemar Samuelsson.[128]\\r\\nAspirin's ability to suppress the production of prostaglandins and thromboxanes is due to its irreversible inactivation of the cyclooxygenase (COX; officially known as prostaglandin-endoperoxide synthase, PTGS) enzyme required for prostaglandin and thromboxane synthesis. Aspirin acts as an acetylating agent where an acetyl group is covalently attached to a serine residue in the active site of the PTGS enzyme (Suicide inhibition). This makes aspirin different from other NSAIDs (such as diclofenac and ibuprofen), which are reversible inhibitors .\\r\\nLow-dose aspirin use irreversibly blocks the formation of thromboxane A2 in platelets, producing an inhibitory effect on platelet aggregation during the lifetime of the affected platelet (8ÿ9 days). This antithrombotic property makes aspirin useful for reducing the incidence of heart attacks in people who have had a heart attack, unstable angina, ischemic stroke or transient ischemic attack.[129] 40?mg of aspirin a day is able to inhibit a large proportion of maximum thromboxane A2 release provoked acutely, with the prostaglandin I2 synthesis being little affected; however, higher doses of aspirin are required to attain further inhibition.[130]\\r\\nProstaglandins, local hormones produced in the body, have diverse effects, including the transmission of pain information to the brain, modulation of the hypothalamic thermostat, and inflammation. Thromboxanes are responsible for the aggregation of platelets that form blood clots. Heart attacks are caused primarily by blood clots, and low doses of aspirin are seen as an effective medical intervention for acute myocardial infarction.\\r\\nAt least two different types of cyclooxygenases, COX-1 and COX-2, are acted on by aspirin. Aspirin irreversibly inhibits COX-1 and modifies the enzymatic activity of COX-2. COX-2 normally produces prostanoids, most of which are proinflammatory. Aspirin-modified PTGS2 produces lipoxins, most of which are anti-inflammatory.[131][verification needed] Newer NSAID drugs, COX-2 inhibitors (coxibs), have been developed to inhibit only PTGS2, with the intent to reduce the incidence of gastrointestinal side effects.[9]\\r\\nHowever, several of the new COX-2 inhibitors, such as rofecoxib (Vioxx), have been withdrawn in the last decade, after evidence emerged that PTGS2 inhibitors increase the risk of heart attack and stroke.[132][133] Endothelial cells lining the microvasculature in the body are proposed to express PTGS2, and, by selectively inhibiting PTGS2, prostaglandin production (specifically, PGI2; prostacyclin) is downregulated with respect to thromboxane levels, as PTGS1 in platelets is unaffected. Thus, the protective anticoagulative effect of PGI2 is removed, increasing the risk of thrombus and associated heart attacks and other circulatory problems. Since platelets have no DNA, they are unable to synthesize new PTGS once aspirin has irreversibly inhibited the enzyme, an important difference with reversible inhibitors.\\r\\nFurthermore, aspirin, while inhibiting the ability of COX-2 to form pro-inflammatory products such as the prostaglandins, converts this enzyme's activity from a prostaglandin-forming cyclooxygenase to a lipoxygenase-like enzyme: aspirin-treated COX-2 metabolizes a variety of polyunsaturated fatty acids to hydroperoxy products which are then further metabolized to specialized proresolving mediators such as the aspirin-triggered lipoxins, aspirin-triggered resolvins, and aspirin-triggered maresins. These mediators possess potent anti-inflammatory activity. It is proposed that this aspirin-triggered transition of COX-2 from cyclooxygenase to lipoxygenase activity and the consequential formation of specialized proresolving mediators contributes to the anti-inflammatory effects of aspirin.[134][135][136]\\r\\nAspirin has been shown to have at least three additional modes of action. It uncouples oxidative phosphorylation in cartilaginous (and hepatic) mitochondria, by diffusing from the inner membrane space as a proton carrier back into the mitochondrial matrix, where it ionizes once again to release protons.[137] Aspirin buffers and transports the protons. When high doses are given, it may actually cause fever, owing to the heat released from the electron transport chain, as opposed to the antipyretic action of aspirin seen with lower doses. In addition, aspirin induces the formation of NO-radicals in the body, which have been shown in mice to have an independent mechanism of reducing inflammation. This reduced leukocyte adhesion is an important step in the immune response to infection; however, evidence is insufficient to show aspirin helps to fight infection.[138] More recent data also suggest salicylic acid and its derivatives modulate signaling through NF-B.[139] NF-B, a transcription factor complex, plays a central role in many biological processes, including inflammation.\\r\\nAspirin is readily broken down in the body to salicylic acid, which itself has anti-inflammatory, antipyretic, and analgesic effects. In 2012, salicylic acid was found to activate AMP-activated protein kinase, which has been suggested as a possible explanation for some of the effects of both salicylic acid and aspirin.[140][141] The acetyl portion of the aspirin molecule has its own targets. Acetylation of cellular proteins is a well-established phenomenon in the regulation of protein function at the post-translational level. Aspirin is able to acetylate several other targets in addition to COX isoenzymes.[142][143] These acetylation reactions may explain many hitherto unexplained effects of aspirin.\\r\\nAcetylsalicylic acid is a weak acid, and very little of it is ionized in the stomach after oral administration. Acetylsalicylic acid is quickly absorbed through the cell membrane in the acidic conditions of the stomach. The increased pH and larger surface area of the small intestine causes aspirin to be absorbed more slowly there, as more of it is ionised. Owing to the formation of concretions, aspirin is absorbed much more slowly during overdose, and plasma concentrations can continue to rise for up to 24 hours after ingestion.[144][145][146]\\r\\nAbout 50ÿ80% of salicylate in the blood is bound to albumin protein, while the rest remains in the active, ionized state; protein binding is concentration-dependent. Saturation of binding sites leads to more free salicylate and increased toxicity. The volume of distribution is 0.1ÿ0.2 L/kg. Acidosis increases the volume of distribution because of enhancement of tissue penetration of salicylates.[146]\\r\\nAs much as 80% of therapeutic doses of salicylic acid is metabolized in the liver. Conjugation with glycine forms salicyluric acid, and with glucuronic acid to form two different glucuronide esters. The conjugate with the acetyl group intact is referred to as the acyl glucuronide; the deacetylated conjugate is the phenolic glucuronide. These metabolic pathways have only a limited capacity. Small amounts of salicylic acid are also hydroxylated to gentisic acid. With large salicylate doses, the kinetics switch from first-order to zero-order, as metabolic pathways become saturated and renal excretion becomes increasingly important.[146]\\r\\nSalicylates are excreted mainly by the kidneys as salicyluric acid (75%), free salicylic acid (10%), salicylic phenol (10%), and acyl glucuronides (5%), gentisic acid (< 1%), and 2,3-dihydroxybenzoic acid.[147] When small doses (less than 250?mg in an adult) are ingested, all pathways proceed by first-order kinetics, with an elimination half-life of about 2.0 h to 4.5 h.[148][149] When higher doses of salicylate are ingested (more than 4 g), the half-life becomes much longer (15 h to 30 h),[150] because the biotransformation pathways concerned with the formation of salicyluric acid and salicyl phenolic glucuronide become saturated.[151] Renal excretion of salicylic acid becomes increasingly important as the metabolic pathways become saturated, because it is extremely sensitive to changes in urinary pH. A 10- to 20-fold increase in renal clearance occurs when urine pH is increased from 5 to 8. The use of urinary alkalinization exploits this particular aspect of salicylate elimination.[152]\\r\\nMedicines made from willow and other salicylate-rich plants appear in clay tablets from ancient Sumer as well as the Ebers Papyrus from ancient Egypt.[6]:8ÿ13[8] Hippocrates referred to their use of salicylic tea to reduce fevers around 400 BC, and were part of the pharmacopoeia of Western medicine in classical antiquity and the Middle Ages.[8] Willow bark extract became recognized for its specific effects on fever, pain and inflammation in the mid-eighteenth century.[153] By the nineteenth century pharmacists were experimenting with and prescribing a variety of chemicals related to salicylic acid, the active component of willow extract.[6]:46ÿ55\\r\\nIn 1853, chemist Charles Frdric Gerhardt treated acetyl chloride with sodium salicylate to produce acetylsalicylic acid for the first time;[6]:46ÿ48 in the second half of the nineteenth century, other academic chemists established the compound's chemical structure and devised more efficient methods of synthesis. In 1897, scientists at the drug and dye firm Bayer began investigating acetylsalicylic acid as a less-irritating replacement for standard common salicylate medicines, and identified a new way to synthesize it.[6]:69ÿ75 By 1899, Bayer had dubbed this drug Aspirin and was selling it around the world.[7]:27 The word Aspirin was Bayer's brand name, rather than the generic name of the drug; however, Bayer's rights to the trademark were lost or sold in many countries. Aspirin's popularity grew over the first half of the twentieth century leading to fierce competition with the proliferation of aspirin brands and products.[8]\\r\\nAspirin's popularity declined after the development of acetaminophen/paracetamol in 1956 and ibuprofen in 1962. In the 1960s and 1970s, John Vane and others discovered the basic mechanism of aspirin's effects,[6]:226ÿ231 while clinical trials and other studies from the 1960s to the 1980s established aspirin's efficacy as an anti-clotting agent that reduces the risk of clotting diseases.[6]:247ÿ257 The initial large studies on the use of low-dose aspirin to prevent heart attacks that were published in the 1970s and 1980s helped spur reform in clinical research ethics and guidelines for human subject research and US federal law, and are often cited as examples of clinical trials that included only men, but from which people drew general conclusions that did not hold true for women.[154][155][156]\\r\\nAspirin sales revived considerably in the last decades of the twentieth century, and remain strong in the twenty-first with widespread use as a preventive treatment for heart attacks and strokes.[6]:267ÿ269\\r\\nDue to allowing the use of \\"Aspirin\\" for years by other manufacturing chemists, despite the trademark-infringing nature of the use, and its own failure to use the name for its own product when it began selling direct, Bayer lost its trademark in the United States in 1918, affirmed by court appeal in 1921.[157] Today, aspirin is a generic word in Australia, France, India, Ireland, New Zealand, Pakistan, Jamaica, Colombia, the Philippines, South Africa, Ghana, the United Kingdom and the United States.[158] Aspirin, with a capital \\"A\\", remains a registered trademark of Bayer in Germany, Canada, Mexico, and in over 80 other countries, where the trademark is owned by Bayer, using acetylsalicylic acid in all markets, but using different packaging and physical aspects for each.[159][160]\\r\\nAspirin is sometimes used for pain relief or as an anticoagulant in veterinary medicine, primarily in dogs and sometimes horses, although newer medications with fewer side effects are generally used instead.\\r\\nBoth dogs and horses are susceptible to the gastrointestinal side effects associated with salicylates, but it is a convenient treatment for arthritis in older dogs, and has shown some promise in cases of laminitis in horses.[citation needed][163] It is no longer commonly used for cases of laminitis, as it could be counterproductive for treatment. Aspirin should be used in animals only under the direct supervision of a veterinarian; in particular, cats lack the glucuronide conjugates that aid in the excretion of aspirin, making it potentially toxic.[164] No clinical signs of toxicosis occurred when cats were given 25?mg/kg of aspirin every 48 hours for 4 weeks.[165] The dose recommended in cats for relief of pain and fever is 10?mg/kg every 48 hours.[166]\\r\\nNotes","input":"Aspirin is a widely used drug. what kind of medicine is it?"},{"output":"Typhoon","context":"Approximately twenty tropical cyclones enter the Philippine Area of Responsibility yearly, an area which incorporates parts of the Pacific Ocean, South China Sea and the Philippine Archipelago (with the exception of Tawi-Tawi province). Among these cyclones, ten will be typhoons, with five having the potential to be destructive ones.[1]  The Philippines is \\"the most exposed country in the world to tropical storms\\" according to a Time Magazine article in 2013.[2] In the Philippine languages, typhoons are called bagyo.[3]\\r\\n\\r\\nTyphoons can hit the Philippines any time of year, with the months of June to September being most active, with August being the most active individual month and May the least active.  Typhoons move east to west across the country, heading north as they go.  Storms most frequently make landfall on the islands of Eastern Visayas, Bicol region, and northern Luzon[2] whereas the southern island and region of Mindanao is largely free of typhoons.\\r\\n\\r\\nThe deadliest overall tropical cyclone to impact the Philippines is believed to have been the Haiphong typhoon which is estimated to have killed up to 20,000 people as it passed over the country in September 1881. In modern meteorological records, the deadliest storm was Typhoon Yolanda (international name Haiyan), which became the strongest landfalling tropical cyclone ever recorded as it crossed the Visayas in central Philippines on November 7ÿ8, 2013. The wettest known tropical cyclone to impact the archipelago was the July 14ÿ18, 1911 cyclone which dropped over 2,210 millimetres (87?in) of rainfall within a 3-day, 15-hour period in Baguio City.[4] Tropical cyclones usually account for at least 30?percent of the annual rainfall in the northern Philippines while being responsible for less than 10?percent of the annual rainfall in the southern islands.  PAGASA Senior Weather Specialist Anthony Lucero told the newsite Rappler that the number of destructive typhoons have increased recently but it is too early to call it a trend.[1]\\r\\n\\r\\nTropical cyclones entering the Philippine Area of Responsibility are given a local name by the Philippine Atmospheric, Geophysical and Astronomical Services Administration (PAGASA), which also raises public storm signal warnings as deemed necessary.[5][6]\\r\\n\\r\\nPreparation and response to typhoons is coordinated by the National Disaster Risk Reduction and Management Council (NDRRMC). Each Philippine province and local government in the Philippines has a corresponding Disaster Risk Reduction and Management Office (DRRMO).  Each provincial and local government is required to set aside 5% of its yearly budget for disaster  risk reduction, preparations, and response.[1]\\r\\n\\r\\nThe frequency of typhoons in the Philippines have made the typhoons a significant part of everyday ancient and modern Filipino culture.[2]\\r\\n\\r\\nBagyo (sometimes spelled bagyu) is the word for \\"typhoon\\" or \\"storm\\" in most Philippine languages, including Tagalog, Visayan, Ilocano, Bicolano, Hanun܇'o, Aklanon, and Pangasinan. It is derived from Proto-Austronesian *baRiuS, meaning \\"typhoon\\". Cognates in other Austronesian languages include Sama baliw (\\"wind\\"), Amis faliyos or farios (\\"typhoon\\"); Saisiyat balosh (\\"typhoon\\"), Babuza bayus (\\"storm\\"), Puyuma variw, Bintulu bauy (\\"wind\\"), Kelabit bariw (\\"storm wind\\"), and Chamorro pakyo (\\"typhoon\\").[7]\\r\\n\\r\\nThe Joint Typhoon Warning Center in Honolulu started monitoring and naming storms in the Western Pacific region in 1945, originally using female names in English alphabetical order. That list was revised in 1979 by introducing male names to be used in alternation with the female names.[8] The Philippine Weather Bureau started naming storms within their area of responsibility in 1963, using female Filipino names ending in ng in native alphabetical order. The Bureau continued to monitor typhoons until the agency's abolition in 1972, after which its duties were transferred to the newly-established PAGASA. This often resulted in a Western Pacific cyclone carrying two names: an international name and a local name generally used within the Philippines. This two-name scheme is still followed today.\\r\\n\\r\\nBeginning in 2000, cyclone monitoring duties in the Western Pacific were transferred from the JTWC to the Japan Meteorological Agency, the RSMC of the World Meteorological Organization. The international naming scheme of the typhoons was replaced with a sequential list of names contributed by 14 nations in the region, including the Philippines. The new scheme largely uses terms for local features of the contributing nation, such as animals, plants, foods and adjectives in the native language. The rotation of names is based on the alphabetical order of the contributing nations. The Philippines, however, would maintain its own naming scheme for its local forecasts. In 2001, PAGASA revised its naming scheme to contain longer annual lists with a more mixed set of names.\\r\\n\\r\\nCurrently, the JMA and PAGASA each assign names to typhoons that form within or enter the Philippine Area of Responsibility. The JMA naming scheme for international use contains 140 names described above. The list is not restricted by year; the first name to be used in a typhoon season is the name after the last-named cyclone of the preceding season. The PAGASA naming scheme for Philippine use contains four lists, each containing twenty-five names arranged in alphabetical order. Every typhoon season begins with the first name in the assigned list, and the rolls of names are each reused every four years. An auxiliary list of ten names is used when the main list in a year had been exhausted. Not all Western Pacific cyclones are given names by both weather agencies, as JMA does not name tropical depressions, and PAGASA does not name cyclones outside the Philippine Area of Responsibility.\\r\\n\\r\\nIn the case of both weather agencies, names are retired when a typhoon carrying it caused severe or costly damage and loss of life. Retirement is decided by the agencies' committees, although in PAGASA's case, names are routinely retired when the cyclone caused at least 300 deaths or ?1 billion in damage in the Philippines. Retired names are replaced with another name for the next rotation, for JMA by the nation that submitted the retired name, and for PAGASA with a name sharing the same first letter as the retired name.\\r\\n\\r\\nOn an annual time scale, activity reaches a minimum in May, before increasing steadily to June, and spiking from July to September, with August being the most active month for tropical cyclones in the Philippines. Activity reduces significantly in October.[9] The most active season, since 1945, for tropical cyclone strikes on the island archipelago was 1993 when nineteen tropical cyclones moved through the country (though there were 36 storms that were named by PAGASA).[10] There was only one tropical cyclone which moved through the Philippines in 1958.[11] The most frequently impacted areas of the Philippines by tropical cyclones are northern Luzon and eastern Visayas.[12] A ten-year average of satellite determined precipitation showed that at least 30?percent of the annual rainfall in the northern Philippines could be traced to tropical cyclones, while the southern islands receive less than 10?percent of their annual rainfall from tropical cyclones.[13]\\r\\n\\r\\nThe Philippine Atmospheric, Geophysical and Astronomical Services Administration (PAGASA) releases tropical cyclone warnings in the form of Tropical Cyclone Warning Signals.[6] An area having a storm signal may be under:\\r\\n\\r\\nThese Tropical Cyclone Warning Signals are usually raised when an area (in the Philippines only) is about to be hit by a tropical cyclone.  As a tropical cyclone gains strength and/or gets nearer to an area having a storm signal, the warning may be upgraded to a higher one in that particular area (e.g. a signal No. 1 warning for an area may be increased to signal #3).  Conversely, as a tropical cyclone weakens and/or gets farther to an area, it may be downgraded to a lower signal or may be lifted (that is, an area will have no storm signal).\\r\\n\\r\\nClasses for Preschool are canceled when Signal No. 1 is in effect. Elementary and High School classes and below are cancelled under Signal No. 2 and classes for Colleges and Universities and below are cancelled under Signal Nos. 3, 4 and 5.\\r\\n\\r\\nSources\\r\\n\\r\\nFor other storms impacting the Philippines in deadly seasons, see:","input":"What is the second strongest typhoon in the philippines?"},{"output":"National Academy of Recording Arts and Sciences","context":"The Recording Academy (formerly the National Academy of Recording Arts and Sciences or NARAS) is a U.S. organization of musicians, producers, recording engineers, and other recording professionals. It is headquartered in Santa Monica, California. Neil Portnow is its current president.\\r\\nThe Recording Academy, which began in 1957, is known for its Grammy Awards (popularly referred to as \\"The Grammys\\"). In 1997, the Recording Academy under Michael Greene launched The Latin Recording Academy, which produces the Latin Grammy Awards.\\r\\n\\r\\n\\r\\nThe origin of the academy dates back to the beginning of the 1950s Hollywood Walk of Fame project. The Hollywood Chamber of Commerce asked the help of major recording industry executives in compiling a list of people in the music business who should be honored by Walk of Fame stars.[1][2] The music committee, made up of these executives, compiled a list, but as they worked, they realized there were many more talented industry people who would not qualify to be recognized with a Hollywood Boulevard bronze star. The founding committee members included Jesse Kaye, MGM Records; Lloyd Dunn and Richard Jones, Capitol Records; Sonny Burke and Milt Gabler, Decca Records; Dennis Farnon, RCA Records; and Axel Stordahl, Paul Weston, and Doris Day from Columbia Records.[3] This was the start of the academy and also of the Grammy Awards.[4][5][6]\\r\\nThe Producers and Engineers Wing (P&E Wing) is a part of the academy made up of producers, engineers, mixers, and other technically involved professionals. It is composed of almost 6,000 members. The producers and engineers wing addresses various aspects of issues facing the recording profession. They also support music and recording arts education. The P&E Wing also advocates for the use of professional usage of recording technology as well as the preservation of recordings.\\r\\nThe members of this division make up a large portion of those who vote on the Grammy Awards each year.\\r\\nThe Grammy University Network (Grammy U) is an organization for college students who are pursuing a career in the music industry. It offers forms of networking, interactive educational experiences and programs, advice from music professionals and internship opportunities.\\r\\nThe Recording Academy supports the MusiCares Foundation,[7] a philanthropic organization which provides money and services to musicians in an emergency or crisis.[citation needed]\\r\\nThe academy has twelve chapters in various locations throughout the United States. The twelve chapters are in Atlanta, Chicago, Florida, Los Angeles, Memphis, Nashville, New York City, the Pacific Northwest, Philadelphia, San Francisco, Texas, and Washington D.C.","input":"What is the recording academy's full name?"},{"output":"Morgans","context":"The Pony Express was a mail service delivering messages, newspapers, and mail.\\r\\nOfficially operating as the Leavenworth and Pike's Peak Express Company of 1859, in 1860 it became the Central Overland California and Pikes Peak Express Company; this firm was founded by William H. Russell, Alexander Majors, and William B. Waddell, all of whom were notable in the freighting business.[1]\\r\\nDuring its 19 months of operation, it reduced the time for messages to travel between the Atlantic and Pacific coasts to about 10 days.[2] From April 3, 1860 to October 1861, it became the West's most direct means of eastÿwest communication before the telegraph was established and was vital for tying the new state of California with the rest of the United States.\\r\\n\\r\\n\\r\\nThe idea of a fast mail route to the Pacific coast was prompted largely by California's newfound prominence and its rapidly growing population. After gold was discovered there in 1848, thousands of prospectors, investors and businessmen made their way to California, at that time a new territory of the U.S. By 1850, California entered the Union as a free state. By 1860, the population had grown to 380,000.[3] The demand for a faster way to get mail and other communications to and from this westernmost state became even greater as the American Civil War approached.\\r\\nIn the late 1850s, William Russell, Alexander Majors, and William Waddell were the three founders of the Pony Express. They were already in the freighting and drayage business. At the peak of the operations, they employed 6,000 men, owned 75,000 oxen, thousands of wagons, and warehouses plus a sawmill, a meatpacking plant, a bank and an insurance company.[4]\\r\\nRussell was a prominent businessman, well respected among his peers and the community.[citation needed] Waddell was co-owner of the firm Morehead, Waddell & Co. After Morehead was bought out and retired, Waddell merged his company with Russell's, changing the name to Waddell & Russell. In 1855 they took on a new partner, Alexander Majors, and founded the company of Russell, Majors & Waddell.[5] They held government contracts for delivering army supplies to the western frontier, and Russell had a similar idea for contracts with the U.S. Government for fast mail delivery.[6]\\r\\nBy utilizing a short route and using mounted riders rather than traditional stagecoaches, they proposed to establish a fast mail service between St. Joseph, Missouri, and Sacramento, California, with letters delivered in 10 days, a duration many said was impossible. The initial price was set at $5 per 1?2 ounce (14?g), then $2.50, and by July 1861 to $1. The founders of the Pony Express hoped to win an exclusive government mail contract, but that did not come about.\\r\\nRussell, Majors, and Waddell organized and put together the Pony Express in two months in the winter of 1860. The undertaking assembled 120 riders, 184 stations, 400 horses, and several hundred personnel during January and February 1861.[7]\\r\\nAlexander Majors was a religious man and resolved \\"by the help of God\\" to overcome all difficulties. He presented each rider with a special edition Bible and required this oath,[8][9] which they were also required to sign.[10]\\r\\n\\"I, ..., do hereby swear, before the Great and Living God, that during my engagement, and while I am an employee of Russell, Majors, and Waddell, I will, under no circumstances, use profane language, that I will drink no intoxicating liquors, that I will not quarrel or fight with any other employee of the firm, and that in every respect I will conduct myself honestly, be faithful to my duties, and so direct all my acts as to win the confidence of my employers, so help me God.\\"\\r\\nThe Pony Express demonstrated that a unified transcontinental system of communications could be established and operated year-round. When replaced by the telegraph, the Pony Express quickly became romanticized and became part of the lore of the American West. Its reliance on the ability and endurance of individual young, hardy riders and fast horses was seen as evidence of rugged American individualism of the Frontier times.\\r\\nFrom 1866 until 1889, the Pony Express logo was used by stagecoach and freight company Wells Fargo, which provided secure mail service. The United States Postal Service (USPS) used \\"Pony Express\\" as a trademark for postal services in the US.[13] Freight Link international courier services, based in Russia, adopted the Pony Express trademark and a logo similar to that of the USPS.[14]\\r\\nIn 1860, there were about 157 Pony Express stations that were about 10 miles (16?km) apart along the Pony Express route.[7] At each station stop the express rider would change to a fresh horse, taking only the mail pouch called a mochila (from the Spanish for pouch or backpack) with him.\\r\\nThe employers stressed the importance of the pouch. They often said that, if it came to be, the horse and rider should perish before the mochila did. The mochila was thrown over the saddle and held in place by the weight of the rider sitting on it. Each corner had a cantina, or pocket. Bundles of mail were placed in these cantinas, which were padlocked for safety. The mochila could hold 20 pounds (9?kg) of mail along with the 20 pounds (9?kg) of material carried on the horse.[16] Eventually, everything except one revolver and a water sack was removed, allowing for a total of 165 pounds (75?kg) on the horse's back. Riders, who could not weigh over 125 pounds (57?kg), changed about every 75ÿ100 miles (120ÿ160?km), and rode day and night. In emergencies, a given rider might ride two stages back to back, over 20 hours on a quickly moving horse.\\r\\nIt is unknown if riders tried crossing the Sierra Nevada in winter, but they certainly crossed central Nevada. By 1860 there was a telegraph station in Carson City, Nevada. The riders received $100 a month as pay. A comparable wage for unskilled labor at the time was about $0.43ÿ$1 per day.\\r\\nAlexander Majors, one of the founders of the Pony Express, had acquired more than 400 horses for the project. He selected horses from around the west, paying an average of $200.[17] These averaged about 14.2?hands (58?inches, 147?cm) high and averaged 900 pounds (410?kg)[18] each; thus, the name pony was appropriate, even if not strictly correct in all cases.\\r\\nThe approximately 1,900-mile-long (3,100?km) route[19] roughly followed the Oregon and California Trails to Fort Bridger in Wyoming, and then the Mormon Trail (known as the Hastings Cutoff) to Salt Lake City, Utah. From there it followed the Central Nevada Route to Carson City, Nevada before passing over the Sierra into Sacramento, California.[20]\\r\\nThe route started at St. Joseph, Missouri on the Missouri River, it then followed what is modern-day U.S. Highway 36 (US?36 the Pony Express Highway) to Marysville, Kansas, where it turned northwest following Little Blue River to Fort Kearny in Nebraska. Through Nebraska it followed the Great Platte River Road, cutting through Gothenburg, Nebraska, clipping the edge of Colorado at Julesburg, Colorado, and passing Courthouse Rock, Chimney Rock, and Scotts Bluff, before arriving at Fort Laramie in Wyoming. From there it followed the Sweetwater River, passing Independence Rock, Devil's Gate, and Split Rock, to Fort Caspar, through South Pass to Fort Bridger and then down to Salt Lake City. From Salt Lake City it generally followed the Central Nevada Route blazed by Captain James H. Simpson of the Corps of Topographical Engineers in 1859. This route roughly follows today's US?50 across Nevada and Utah. It crossed the Great Basin, the Utah-Nevada Desert, and the Sierra Nevada near Lake Tahoe before arriving in Sacramento. Mail was then sent via steamer down the Sacramento River to San Francisco. On a few instances when the steamer was missed, riders took the mail via horseback to Oakland, California.\\r\\nThere were 184 stations along the long and arduous route used by the Pony Express. The stations and station keepers were essential to the successful, timely and smooth operation of the Pony Express mail system. The stations were often fashioned out of existing structures, several of them located in military forts, while others were built anew in remote areas where living conditions were very basic.[21] The route was divided up into five divisions.[22] To maintain the rigid schedule, 157 relay stations were located from 5 to 25 miles (8 to 40?km) apart as the terrain would allow for. At each swing station, riders would exchange their tired mounts for fresh ones, while \\"home stations\\" provided room and board for the riders between runs. This technique allowed the mail to be whisked across the continent in record time. Each rider rode about 75 miles (120?km) per day.[23]\\r\\nDivision One: Stations between St. Joseph and Fort Kearney\\r\\nMissouri:\\r\\n1. St. Joseph Station\\r\\nKansas:\\r\\n2. Troy Station\\r\\n3. Lewis Station\\r\\n4. Kennekuk (Kinnekuk) Station\\r\\n5. Kickapoo, Goteschall Station\\r\\n6. Log Chain Station\\r\\n7. Seneca Station\\r\\n8. Ash Point, Laramie Creek Station\\r\\n9. Guittard Station (aka Gantard's, Guttard)\\r\\n10. Marysville Station\\r\\n11. Cottonwood, Hollenberg Station\\r\\n12. Atchison Station\\r\\n13. Lancaster Station\\r\\nNebraska:\\r\\n14. Rock House Station\\r\\n15. Rock Creek Station\\r\\n16. Virginia City\\r\\n17. Big Sandy Station\\r\\n18. Millersville, Thompson's Station\\r\\n19. Kiowa Station\\r\\n20. Little Blue, Oak Grove Station\\r\\n21. Liberty Farm Station\\r\\n22. Spring Ranch, Lone Tree Station\\r\\n23. Thirty-two Mile Creek Station\\r\\n24. Sand Hill, Summit Station\\r\\n25. Hook's, Kearney, Valley Station\\r\\n26. Fort Kearney\\r\\n\\r\\nDivision Two: Stations between Fort Kearney and Horseshoe Creek\\r\\nNebraska (continued):\\r\\n27. Seventeen Mile, Platte Station\\r\\n28. Garden Station\\r\\n29. Plum Creek Station\\r\\n30. Willow Island, Willow Bend Station\\r\\n31. Cold Water, Midway Ranch Station\\r\\n32. Gilman's Station\\r\\n33. Machette's Station (Gothenburg)\\r\\n34. Cottonwood Springs Station\\r\\n35. Cold Springs Station\\r\\n36. Fremont Springs Station\\r\\n37. O'Fallon's Bluff, Dansey's/Elkhorn Station\\r\\n38. Alkali Lake Station\\r\\n39. Gill's, Sand Hill Station\\r\\n40. Diamond Springs Station\\r\\n41. Beauvais Ranch Station\\r\\nColorado:\\r\\n42. Frontz's/South Platte Station\\r\\n43. Julesburg Station\\r\\nNebraska (continued):\\r\\n44. Nine Mile Station\\r\\n45. Pole Creek No. 2 Station\\r\\n46. Pole Creek No. 3 Station\\r\\n47. Midway Station\\r\\n48. Mud Springs Station\\r\\n49. Court House (Rock) Station\\r\\n50. Chimney Rock Station\\r\\n51. Ficklin's Springs Station\\r\\n52. Scott's Bluff(s) Station\\r\\n53. Horse Creek Station\\r\\nWyoming:\\r\\n54. Cold Springs, Spring Ranch/Torrington Station\\r\\n55. Verdling's, Bordeaux, Bedeau's Ranch/Fort Benard Station\\r\\n56. Fort Laramie Station\\r\\n57. Nine Mile, Sand Point, Ward's, Central Star Station\\r\\n58. Cottonwood Station\\r\\n59. Horseshoe Creek, Horseshoe Station\\r\\n\\r\\nDivision Three: Stations between Horseshoe Creek and Salt Lake City\\r\\nWyoming (continued)?:\\r\\n60. Elk Horn Station\\r\\n61. La Bonte Station\\r\\n62. Bed Tick Station\\r\\n63. Lapierelle/La Prele Station\\r\\n64. Box Elder (Creek) Station\\r\\n65. Deer Creek Station\\r\\n66. Little Muddy Station\\r\\n67. Bridger Station\\r\\n68. Platte Bridge/North Platte Station\\r\\n69. Red Butte (s) Station\\r\\n70. Willow Springs Station\\r\\n71. Horse, Greesewood Creek Station\\r\\n72. Sweetwater Station\\r\\n73. Devil's Gate Station\\r\\n74. Plant's, Plante Station\\r\\n75. Split Rock Station\\r\\n76. Three Crossings Station\\r\\n77. Ice Slough, Ice Springs Station\\r\\n78. Warm Springs Station\\r\\n79. Rocky Ridge, St. Mary's Station\\r\\n80. Rock Creek Station\\r\\n81. Upper Sweetwater, South Pass Station\\r\\n82. Pacific Springs Station\\r\\n83. Dry Sandy Station\\r\\n84. Little Sandy Creek Station\\r\\n85. Big Sandy Station\\r\\n86. Big Timber Station\\r\\n87. Green River Station (crossing Station)\\r\\n88. Michael Martin's Station\\r\\n89. Ham's Fork Station\\r\\n90. Church Buttes Station\\r\\n91. Millersville Station\\r\\n92. Fort Bridger\\r\\n93. Muddy Creek Station\\r\\n94. Quaking Asp, Aspen, Springs Station\\r\\n95. Bear River Station\\r\\nUtah:\\r\\n96. The Needles, Needle Rock(s) Station\\r\\n97. (Head of) Echo Canyon Station\\r\\n98. Halfway Station\\r\\n99. Weber Station\\r\\n100. Brimville Emergency Station\\r\\n101. Carson House Station\\r\\n102. East Canyon Station\\r\\n103. Wheaton Springs Station\\r\\n104. Mountain Dell/Dale Station\\r\\n105. Salt Lake City Station\\r\\n\\r\\nDivision Four: Stations between Salt Lake City and Robert's Creek\\r\\nUtah (continued):\\r\\n106. Trader's Rest, Traveler's Rest Station\\r\\n107. Rockwell's Station\\r\\n108. Dugout, Joe's Dugout Station\\r\\n109. Camp Floyd, Fairfield Station\\r\\n110. Pass, East Rush Valley Station\\r\\n111. Rush Valley, Faust's Station\\r\\n112. Point Lookout, Lookout Pass Station\\r\\n113. Government Creek Station\\r\\n114. Simpson's Springs, Egan's Springs Station\\r\\n115. River Bed Station\\r\\n116. Dugway Station\\r\\n117. Black Rock Station\\r\\n118. Fish Springs Station\\r\\n119. Boyd's Station\\r\\n120. Willow Springs Station\\r\\n121. Willow Creek Station\\r\\n122. Canyon, Burnt Station\\r\\n123. Deep Creek Station\\r\\nNevada:\\r\\n124. Prairie Gate, Eight Mile Station\\r\\n125. Antelope Springs Station\\r\\n126. Spring Valley Station\\r\\n127. Schell Creek Station\\r\\n128. Egan's Canyon, Egan's Station\\r\\n129. Bates', Butte Station\\r\\n130. Mountain Spring(s) Station\\r\\n131. Ruby Valley Station\\r\\n132. Jacob's Well Station\\r\\n133. Diamond Springs Station\\r\\n134. Sulphur Springs Station\\r\\n135. Robert's Creek Station\\r\\n\\r\\nDivision Five: Stations between Roberts Creek and Sacramento\\r\\nNevada (continued): 136. Camp Station, Grub(b)s Well Station\\r\\n137. Dry Creek Station\\r\\n138. Simpson Park Station\\r\\n139. Reese River, Jacob's Spring Station\\r\\n140. Dry Wells Station\\r\\n141. Smith's Creek Station\\r\\n142. Castle Rock Station\\r\\n143. Edward's Creek Station\\r\\n144. Cold Springs, East Gate Station\\r\\n145. Middle Gate Station\\r\\n146. West Gate Station\\r\\n147. Sand Springs Station\\r\\n148. Sand Hill Station\\r\\n149. Carson Sink Station\\r\\n150. Williams Station\\r\\n151. Desert, Hooten Wells Station\\r\\n152. Buckland's Station\\r\\n153. Fort Churchill Station\\r\\n154. Fairview Station\\r\\n155. Mountain Well Station\\r\\n156. Stillwater Station\\r\\n157. Old River Station\\r\\n158. Bisby's Station\\r\\n159. Nevada Station\\r\\n160. Ragtown Station\\r\\n161. Desert Wells Station\\r\\n162. Miller's, Reed's Station\\r\\n163. Dayton Station\\r\\n164. Carson City Station\\r\\n165. Genoa Station\\r\\n166. Friday's, Lakeside Station\\r\\nCalifornia:\\r\\n167. Woodford's Station\\r\\n168. Fountain Place Station\\r\\n169. Yank's Station\\r\\n170. Strawberry Station\\r\\n171. Webster's, Sugar Loaf House Station\\r\\n172. Moss/Moore, Riverton Station\\r\\n173. Sportsman's Hall Station\\r\\n174. Placerville Station\\r\\n175. El Dorado, Nevada House/Mud Springs Station\\r\\n176. Mormon Tavern, Sunrise House Station\\r\\n177. Fifteen Mile House Station\\r\\n178. Five Mile House Station\\r\\n179. Pleasant Grove House Station\\r\\n180. Duroc Station\\r\\n181. Folsom Station\\r\\n182. Sacramento Station\\r\\n183. Benicia, Martinez, and Oakland Stations\\r\\n184. San Francisco Station\\r\\nThe first Westbound Pony Express trip left St. Joseph on April 3, 1860 and arrived ten days later in San Francisco, California, on April 14. These letters were sent under cover from the East to St. Joseph, and never directly entered the U.S. mail system. Today there is only a single letter known to exist from the inaugural westbound trip from St. Joseph, Missouri to San Francisco, California.[24] The mailing depicted below is on a pre-stamped (embossed) envelope, first issued by the U.S. Post Office in 1855, used five years later here.[25]\\r\\nThe messenger delivering the mochila from New York and Washington, DC, missed a connection in Detroit and arrived in Hannibal, Missouri, two hours late. The railroad cleared the track and dispatched a special locomotive called Missouri with a one-car train to make the 206-mile (332?km) trek across the state in a record 4 hours 51 minutes, an average of 40 miles per hour (64?km/h).[26] It arrived at Olive and 8th Street, a few blocks from the company's new headquarters in a hotel at Patee House at 12th and Penn Street and the company's nearby stables on Penn Street. The first pouch contained 49 letters, five private telegrams, and some papers for San Francisco and intermediate points.[27]\\r\\nSt. Joseph Mayor M. Jeff Thompson, William H. Russell, and Alexander Majors gave speeches before the mochila was handed off. The ride began at about 7:15?p.m. The St. Joseph Gazette was the only newspaper included in the bag.\\r\\nThe identity of the first rider has long been in dispute. The St. Joseph Weekly West (April 4, 1860) reported Johnson William Richardson was the first rider.[28] Johnny Fry is credited in some sources as the rider. Nonetheless, the first westbound rider carried the pouch across the Missouri River ferry to Elwood, Kansas. The first horse-ridden leg of the Express was only about 1?2 mile (800?m) from the Express stables/railroad area to the Missouri River ferry at the foot of Jules Street. Reports indicated that horse and rider crossed the river. In later rides, the courier crossed the river without a horse and picked up his mount at a stable on the other side.\\r\\nThe first westbound mochila reached its destination, San Francisco, on April 14, at 1:00?a.m.[29]\\r\\nThe first eastbound Pony Express trip left San Francisco, California, on April 3, 1860 and arrived at its destination ten days later in St. Joseph, Missouri. From St. Joseph, letters were placed in the U.S. mails for delivery to eastern destinations. There are only two letters known to exist from the inaugural eastbound trip from San Francisco to St. Joseph.[30]\\r\\nAs the Pony Express Mail service existed only briefly in 1860 and 1861, there are consequently very few surviving examples of Pony Express mail. Also, contributing to the scarcity of surviving Pony Express mail is that the cost to send a 1?2-ounce (14?g) letter was $5.00[31] at the beginning, (about $130.00 to today's standards). By the end period of the Pony Express, the price had dropped to $1.00 per ?1?2 ounce but even that was considered expensive (equivalent to $27 in 2016[32]) just to mail one letter. As this mail service was also a frontier enterprise, removed from the general population in the east, along with the largely unaffordable rates, there are consequently few pieces of surviving Pony Express mail in the hands of collectors and museums. There are only 250 known examples of Pony Express mail.[24]\\r\\nVarious postmarks were added to mail to be carried by the Pony Express at the point of departure.\\r\\nWilliam Russell, senior partner of 'Russell, Majors, and Waddell' and one of the biggest investors in the Pony Express, used the 1860 presidential election as a way to promote the Pony Express and how fast it could deliver the U.S. Mail. Prior to the election, Russell hired extra riders to ensure that fresh riders and relay horses were available along the route. On November 7, 1860, a Pony Express rider departed Fort Kearny, Nebraska Territory (the end of the eastern telegraph line) with the election results. Riders sped along the route, over snow-covered trails and into Fort Churchill, Nevada Territory (the end of the western telegraph line). California's newspapers received word of Lincoln's election only seven days and 17 hours after the East Coast papers, an unrivaled feat at the time.[34]\\r\\nThe Paiute War was a minor series of raids and ambushes initiated by the Paiute Indian tribe in Nevada, which resulted in the disruption of mail services of the Pony Express. It took place from May through June 1860, though sporadic violence continued for a period afterward. In the brief history that the Pony Express operated only once did the mail not go through. After completing eight weekly trips from both Sacramento and Saint Joseph, the Pony Express was forced to suspend mail services because of the outbreak of the Paiute Indian War in May 1860.\\r\\nApproximately 6,000 Paiutes in Nevada had suffered during a winter of fierce blizzards that year. By spring, the whole tribe was ready to embark on a war, except for the Paiute chief named Numaga. For three days Numaga fasted and argued for peace.[36] Meanwhile, a raiding party attacked Williams Station, a Pony Express station located on the Carson River near present-day Lake Lahontan. One account says the raid was a deliberate attempt to provoke war. Another says the raiders had heard that men at the station had kidnapped two Paiute women, and fighting broke out when they went to investigate and free the women. Either way, the war party killed five men and the station was burned.[37]\\r\\nDuring the following weeks, other isolated incidents occurred when whites in Paiute country were ambushed and killed. The Pony Express was a special target. Seven other express stations were also attacked; some 16 employees were killed and approximately 150 express horses were either stolen or driven off. The Paiute war cost the Pony Express company about $75,000 in livestock and station equipment, not to mention the loss of life. In June of that year, the Paiute uprising had been ended through the intervention of U.S. government troops, after which four delayed mail shipments from the East were finally brought to San Francisco on June 25, 1860.[38]\\r\\nDuring this brief war, one Pony Express mailing, which left San Francisco on July 21, 1860, did not immediately reach its destination. That mail pouch (mochila) did not reach St. Joseph and subsequently New York until almost two years later.\\r\\nIn 1860, riding for the Pony Express was difficult work? riders had to be tough and lightweight. A famous advertisement allegedly read:\\r\\nThe Pony Express had an estimated 80 riders who were traveling east or west along various points of the route at any given time. In addition, there were also about 400 other employees, including station keepers, stock tenders and route superintendents. Many young men applied for jobs with the Pony Express, ready to face the dangers and the challenges that sometimes lay along the delivery route. Waddell and Majors could have easily hired them at a much lesser rate, but instead paid them a handsome sum for that time of one hundred dollars a month.[40] Famous American author Mark Twain, who saw the Pony Express in action first hand, described the riders in his travel memoir Roughing It as: \\"...?usually a little bit of a man\\". Though the riders were small, lightweight, generally teenage boys, their untarnished record proved them to be heroes of the American West for the much needed and dangerous service they provided for the nation.[23] Establishing a complete list of riders is virtually impossible. There was no official list of riders kept by the express company and the scarcity of newspapers along the route contributed to the absence of this information. When the American Civil War broke out in 1861, the Pony Express was forgotten about almost entirely, and consequently there was not much interest in pursuing and searching out this information for many years following, by which time much of it had simply vanished in the course of everyday affairs.[41] A partial list of riders has been compiled in Raymond and Nancy Settle's 1972 book Saddles & Spurs.[42]\\r\\nThe identity of the first westbound rider to depart St. Joseph has been disputed, but currently most historians have narrowed it down to either Johnny Fry or Billy Richardson.[28][43][44][7] Both Expressmen were hired at St. Joseph for A. E. Lewis' Division which ran from St. Joseph to Seneca, Kansas, a distance of 80 miles (130?km). They covered at an average speed of 12?1?2 miles per hour (20?km/h), including all stops.[45] Before the mail pouch was delivered to the first rider on April 3, 1860, time was taken out for ceremonies and several speeches. First, Mayor M. Jeff Thompson gave a brief speech on the significance of the event for St. Joseph. Then William H. Russell and Alexander Majors addressed the gala crowd about how the Pony Express was just a \\"precursor\\" to the construction of a transcontinental railroad. At the conclusion of all the speeches, approximately 7:15?p.m., Russell turned the mail pouch over to the first rider. A cannon fired, the large assembled crowd cheered, and the rider dashed to the landing at the foot of Jules Street where the ferry boat Denver, under a full head of steam, alerted by the signal cannon, waited to carry the horse and rider across the Missouri River to Elwood, Kansas Territory.[46][47] On April 9 at 6:45?p.m., the first rider from the east reached Salt Lake City, Utah. Then, on April 12, the mail pouch reached Carson City, Nevada at 2:30?p.m. The riders raced over the Sierra Nevada Mountains, through Placerville, California and on to Sacramento. Around midnight on April 14, 1860, the first mail pouch was delivered via the Pony Express to San Francisco. Bringing with it was a letter of congratulations from President Buchanan to California Governor Downey along with other official government communications, newspapers from New York, Chicago, and St. Louis, along with other important mail to banks and commercial houses in San Francisco. In all, 85 pieces of mail were delivered on this first trip.[48]\\r\\nJames Randall is credited as the first eastbound rider from the San Francisco Alta telegraph office since he was on the steamship Antelope to go to Sacramento.[49] Mail for the Pony Express left San Francisco at 4:00 pm, carried by horse and rider to the waterfront, and then on by steamboat to Sacramento where it was picked up by the Pony Express rider. At 2:45?a.m., William (Sam) Hamilton was the first Pony Express rider to begin the journey from Sacramento. He rode all the way to Sportsman Hall Station where he gave his mochila filled with mail to Warren Upson.[50] A California Registered Historical Landmark plaque at the site reads:\\r\\nThis was the site of Sportsman's Hall, also known as the Twelve-Mile House. The hotel operated in the late 1850's and 1860's by John and James Blair. A stopping place for stages and teams of the Comstock, it became a relay station of the central overland Pony Express. Here, at 7:40 a.m., April 4, 1860, Pony rider William (Sam) Hamilton, riding in from Placerville, handed the Express mail to Warren Upson who, two minutes later, sped on his way eastward.\\r\\nProbably more than any other rider in the Pony Express, William Cody (better known as Buffalo Bill) epitomizes the legend and the folklore, be it fact or fiction, of the Pony Express.[51][52] Numerous stories have been told of young Cody's adventures as a Pony Express rider. At the age of 15 Cody was on his way west to California when he met Pony Express agents along the way and signed on with the company. Cody helped in the construction of several way-stations. Thereafter, he was employed as a rider and was given a short 45-mile (72?km) delivery run from the township of Julesburg which lay to the west. After some months he was transferred to Slade's Division in Wyoming where he made the longest non-stop ride from Red Buttes Station to Rocky Ridge Station and back when he found that his relief rider had been killed. The distance of 322 miles (518?km) over one of the most dangerous sections of the entire trail was completed in 21 hours and 40 minutes, and 21 horses were required to complete this section.[23] On one occasion when carrying mail he unintentionally ran into an Indian war party but managed to escape. Cody was present for many significant chapters in early western history, including the gold rush, the building of the railroads and cattle herding on the Great Plains. A career as a scout for the Army under General Phillip Sheridan following the Civil War earned him his nickname and established his notoriety as a frontiersman.[53][54][55]\\r\\nRobert Haslam (Pony Bob) was among the most brave, resourceful, and best-known riders of the Pony Express. He was born January 1840 in London, England, and came to the United States as a teenager. Haslam was hired by Bolivar Roberts, helped build the stations, and was given the mail run from Friday's Station at Lake Tahoe to Buckland's Station near Fort Churchill, 75 miles (121?km) to the east.\\r\\nHis greatest ride, 120 miles (190?km) in 8 hours and 20 minutes while wounded, was an important contribution to the fastest trip ever made by the Pony Express. The mail carried Lincoln's inaugural address. Indian problems in 1860 led to Pony Bob Haslam's record-breaking ride. He had received the eastbound mail (probably the May 10 mail from San Francisco) at Friday's Station. When he reached Buckland's Station his relief rider was so badly frightened over the Indian threat that he refused to take the mail. Haslam agreed to take the mail all the way to Smith's Creek for a total distance of 190 miles (310?km) without a rest. After a rest of nine hours, he retraced his route with the westbound mail where, at Cold Springs, he found that Indians had raided the place, killing the station keeper and running off all of the stock. On the ride he was shot through the jaw with an Indian arrow, losing three teeth.[56] Finally, he reached Buckland's Station, making the 380-mile (610?km) round trip the longest on record.[23]\\r\\nPony Bob continued to work as a rider for Wells Fargo and Company after the Civil War, scouted for the U.S. Army well into his fifties, and later accompanied his good friend Buffalo Bill Cody on a diplomatic mission to negotiate the surrender of Chief Sitting Bull in December 1890. He drifted in and out of public mention but eventually died in Chicago during the winter of 1912 (age 72) in deep poverty after suffering a stroke. Buffalo Bill paid for his friend's headstone at Mount Greenwood Cemetery (111 Street and Sacramento) on Chicago's far south side.[57]\\r\\nJack Keetley was hired by A. E. Lewis for his Division at the age of nineteen, and put on the run from Marysville to Big Sandy. He was one of those who rode for the Pony Express during the entire nineteen months of its existence.\\r\\nJack Keetley's longest ride, upon which he doubled back for another rider, ended at Seneca where he was taken from the saddle sound asleep. He had ridden 340 miles (550?km) in thirty-one hours without stopping to rest or eat.[58][59] After the Pony Express was disbanded, Keetley went to Salt Lake City where he engaged in mining. He died there on October 12, 1912 where he was also buried.[60]\\r\\nIn 1907, Keetley wrote the following letter (excerpt):\\r\\nAlex Carlyle was the first man to ride the Pony Express out of St. Joe. He was a nephew of the superintendent of the stage line to Denver, called the \\"Pike's Peak Express.\\" The superintendent's name was Ben Ficklin. Carlyle was a consumptive, and could not stand the hardships, and retired after about two months trial, and died within about six months after retiring. John Frye was the second rider, and I was the third, and Gus Cliff was the fourth.\\r\\n\\r\\nBilly Tate was a 14-year-old Pony Express rider who rode the express trail in Nevada near Ruby Valley. During the Paiute uprising of 1860 he was chased by a band of Paiute Indians on horseback and was forced to retreat into the hills behind some big rocks where he killed seven of his assailants in a shoot-out before being killed himself. His body was found riddled with arrows but was not scalped, a sign that the Paiutes honored their enemy.[61]\\r\\nAn estimated 400 horses in total were used by the Pony Express to deliver the mail. Horses were selected for swiftness and endurance. On the east end of Pony Express route the horses were usually selected from U.S. Cavalry units. At the west end of the Pony Express route in California, W.W. Finney purchased 100 head of short coupled stock called \\"California Horses\\"' while A.B. Miller purchased another 200 native ponies in and around the Great Salt Lake Valley. The horses were ridden quickly between stations, an average distance of 15 miles (24?km), and then were relieved and a fresh horse would be exchanged for the one that just arrived from its strenuous run.\\r\\nDuring his route of 80 to 100 miles (130 to 160?km), a Pony Express rider would change horses 8 to 10 times. The horses were ridden at a fast trot, canter or gallop, around 10 to 15 miles per hour (16 to 24?km/h) and at times they were driven to full gallop at speeds up to 25 miles per hour (40?km/h). Horses of the Pony Express were purchased in Missouri, Iowa, California, and some western U.S. territories.\\r\\nThe various types of horse ridden by riders of the Pony Express included Morgans and thoroughbreds which were often used on the eastern end of the trail. Mustangs were often used on the western (more rugged) end of the mail route. [62]\\r\\nIn 1844, years before the Pony Express came to St. Joseph, Israel Landis opened a small saddle and harness shop there. His business expanded as the town grew, and when the Pony Express came to town Landis was the ideal candidate to produce saddles for the newly founded Pony Express. Because Pony Express riders rode their horses at a quick pace over a distance of 10 miles (16?km) or more between stations, every consideration was made to reduce the overall weight the horse had to carry. To help reduce this load, special lightweight saddles were designed and crafted. Using less leather and fewer metallic and wood components they fashioned a saddle that was similar in design to the regular stock saddle generally in use in the West at that time.[63]\\r\\nThe mail pouch was a separate component to the saddle that made the Pony Express unique. Standard mail pouches for horses were never employed because of their size and shape, as it was time consuming detaching and attaching it from one saddle to the other, causing undue delay in changing mounts. With many stops to make, the delayed time at each station would accumulate to appreciable proportions. To get around this difficulty, a mochila, or covering of leather, was thrown over the saddle. The saddle horn and cantle projected through holes which were specially cut to size in the mochila. Attached to the broad leather skirt of the mochila were four cantinas, or box-shaped hard leather compartments, where letters were carried on the journey.[63]\\r\\nDuring its brief time in operation, the Pony Express delivered approximately 35,000 letters between St. Joseph, Missouri, and Sacramento, California.[64] Although the Pony Express proved that the central/northern mail route was viable, Russell, Majors and Waddell did not get the contract to deliver mail over the route. The contract was instead awarded to Jeremy Dehut in March 1861, who had taken over the southern Congressionally favored Butterfield Overland Mail Stage Line. The so-called 'Stagecoach King', Ben Holladay, acquired the Russell, Majors and Waddell stations for his stagecoaches.\\r\\nShortly after the contract was awarded, the start of the American Civil War caused the stage line to cease operation. From March 1861, the Pony Express ran mail only between Salt Lake City and Sacramento. The Pony Express announced its closure on October 26, 1861, two days after the transcontinental telegraph reached Salt Lake City and connected Omaha, Nebraska, and Sacramento, California. Other telegraph lines connected points along the line and other cities on the east and west coasts.[65]\\r\\nDespite the subsidy, the Pony Express was a financial failure. It grossed $90,000 and lost $200,000.[66]\\r\\nIn 1866, after the Civil War was over, Holladay sold the Pony Express assets along with the remnants of the Butterfield Stage to Wells Fargo for $1.5 million.\\r\\nIn 1869, the United States Post Office issued the first U.S. Postage stamp to depict an actual historic event, and the subject that was chosen was the Pony Express. Until then only the faces of George Washington, Benjamin Franklin, Thomas Jefferson and Andrew Jackson were found on the face of U.S. Postage.[67] Sometimes mistaken for an actual stamp used by the Pony Express, the 'Pony Express Stamp' issue was released in 1869 (8 years after the Pony Express service had ended) to honor the men who rode the long and sometimes dangerous journeys and to commemorate the service they provided for the nation. In 1940 and 1960 commemorative stamps were issued for the 80th and 100th anniversaries of the Pony Express respectively.\\r\\nNational Pony Express Association (NPEA) is a non-profit, volunteer-led historical organization. Its purpose is to preserve the original Pony Express trail and to continue the memory and importance of Pony Express in American history in partnership with the National Park Service, Pony Express Trail Association, and the Oregon-California Trails Association.\\r\\nApril 3, 2010 was the Pony Express' 150th anniversary. Located in St. Joseph, Missouri, the Patee House Museum, which was the Pony Express' headquarters, hosted events celebrating the anniversary.[68]\\r\\nThe foundation of accountable Pony Express history rests in the few tangible areas where records, papers, letters and mailings have yielded the most historical evidence. Until the 1950s most of what was known about the short-lived Pony Express was the product of a few accounts, hearsay and folklore, generally true in their overall aspects, but lacking in verification in many areas for those who wanted to explore the history surrounding the founders, the various riders and station keepers or who were interested in stations or Forts along the Pony Express route.\\r\\nThe most complete books on the Pony Express are The Story of the Pony Express and Saddles and Spurs by Raymond & Mary Settle and Roy Bloss. Settle's account is unique as he was the first writer and historical researcher to make use of Pony Express founder William B. Waddell's papers, now in a collection at the Huntington Library in San Marino, California. Mr. Settle wrote in the mid-1950s. Mr. Bloss was a writer for the Pony Express Centennial. While Settle's work was published generally without his annotations and notes, the writer's background here is unique and Settle does have an excellent bibliography. When Settle prepared to publish his well-researched account he had a good volume of footnotes, citations prepared, but the editors chose not to use most of them. Instead, they opted for a less expensive approach to print and publish and released an accurate, but simplified account. Settle was not pleased with this new and sudden development, as he put much time and effort into the annotations. Yet, the account Settle wrote was and is a definitive one and is considered the best account on the history of the Pony Express amongst many historians.[69]\\r\\nWells Fargo used the Pony Express logo for its guard and armored car service. The logo continued to be used when other companies took over the security business into the 1990s. Since 2001, the Pony Express logo is no longer used for security businesses since the business has been sold.[70]\\r\\nThe United States Postal Service has trademarked \\"Pony Express\\" along with \\"Air Mail.\\"[71]\\r\\nThe Pony Express route has been designated the Pony Express National Historic Trail. Approximately 120 historic sites along the trail may eventually be open to the public, including 50 stations or station ruins.[72]\\r\\nThe continued remembrance and popularity of the Pony Express can be linked to Buffalo Bill Cody, his autobiographies, and his Wild West Show. The first book dedicated solely to the Pony Express was not published until 1900.[73] However, in his first autobiography, published in 1879, Cody claims to have been an Express rider.[74][75] While this claim has recently come under dispute,[73] his show became the \\"primary keeper of the pony legend\\" when it premiered as a scene in the Wild West Show.[73]","input":"What kind of horses were used in the pony express?"},{"output":"February 27, 1844","context":"\\r\\n\\r\\n\\r\\n\\r\\nDominican victory\\r\\n\\r\\nThe Dominican Independence War gave the Dominican Republic autonomy from Haiti on February 27, 1844. Before the war, the island of Hispaniola had been united under the Haitian government for a period of 22 years when the newly independent nation, previously known as the Captaincy General of Santo Domingo, was unified with Haiti in 1822. The criollo class within the country overthrew the Spanish crown in 1821 before unifying with Haiti a year later.\\r\\n\\r\\nIn 1844, the members of La Trinitaria chose El Conde, the prominent Gate of the Count in the old city walls, as the rallying point for their insurrection against the Haitian government. On the morning of 24 February 1844, El Conde rang with the shots of the plotters, who had emerged from their secret meetings to openly challenge the Haitians. Their efforts were successful, and for the next ten years, Dominican military strongmen fought to preserve their country's independence from their Haitian neighbors.[2]\\r\\n\\r\\nUnder the command Faustin Soulouque Haitian soldiers tried to gain back control of lost territory, but this effort was to no avail as the Dominicans would go on to decisively win every battle henceforth. In March 1844, a 30,000-strong two-pronged attack by Haitians was successfully repelled by an under-equipped Dominican army under the command of the wealthy rancher Gen. Pedro Santana.[2] Four years later, it took a Dominican flotilla harassing Haitian coastal villages, and land reinforcements in the south to force the determined Haitian emperor into a one-year truce.[2] In the most thorough and intense encounter of all, Dominican irregulars armed with swords sent Haitian troops into flight on all three fronts in 1855.[2]\\r\\n\\r\\nAt the beginning of the 1800s, the colony of Santo Domingo, which had once been the headquarters of Spanish power in the New World, was in its worst decline. Spain during this time was embroiled in the Peninsular War in Europe, and other various wars to maintain control of the Americas. With Spain's resources spread among its global interest, Santo Domingo and other Caribbean territories became neglected. This period is referred to as the Espa?a Boba era.\\r\\n\\r\\nThe population of the Spanish colony stood at approximately 80,000 with the vast majority being European descendants and free people of color. For most of its history, Santo Domingo had an economy based on mining and cattle ranching. The Spanish colony's plantation economy never truly flourished, because of this black slave population had been significantly lower than that of the neighboring Saint-Domingue, which was nearing a million slaves before the Haitian Revolution.\\r\\n\\r\\nAt the time Haiti had been more economically and militarily powerful and had a population 8 to 10 times larger than the former Spanish colony, having been the richest colony in the western hemisphere before the Haitian Revolution. Dominican military officers agreed to merge the newly independent nation with Haiti, as they sought for political stability under the Haitian president Jean-Pierre Boyer, who belonged to Haiti's elite mulatto class and was seen as an ally at the time. However, due to the Haitian government's mismanagement, heavy military disputes, and an economic crisis the Haitian government became increasingly unpopular. A conspiracy of Dominicans in Santo Domingo called La Trinitaria hastened the end of the Haitian occupation.\\r\\n\\r\\nLate in 1821 the leader Jos N~?ez de Cceres proclaimed Santo Domingo's adhesion to the new Republic of Gran Colombia, created by Sim܇n Bolvar, but the determination of the island elite to perpetuate their privileged status by maintaining intact all colonial-era institutions such as social hierarchy, land titles, and slavery doomed this limited experiment in liberty to failure two months later.[3]\\r\\n\\r\\nA group of Dominican politicians and military officers[who?] had expressed interest in uniting the entire island, while they sought for political stability and support under Haiti, which at the time was still seen as having a great deal of wealth and power.[citation needed] Haiti had been by far the richest colony in the western hemisphere and was known as the Pearl of the Antilles.\\r\\n\\r\\nHaiti's president, Jean-Pierre Boyer, conducted the third military campaign of Santo Domingo, this one was met with resistance, partly due to the previous invasion experiences, and because of Haiti's overpowering military strength at the time. The population of Haiti had a ratio of 8:1 compared to the Dominican population of 1822.\\r\\n\\r\\nOn February 9, 1822, Boyer formally entered the capital city, Santo Domingo, where he was met and received by N~?ez who handed to him the keys of the Palace. Boyer then proclaimed: \\"I have not come into this city as a conqueror but by the will of its inhabitants\\". The island was thus united from \\"Cape Tiburon to Cape Samana in possession of one government.\\"\\r\\n\\r\\nEventually, the Haitian government became extremely unpopular throughout the country. The Dominican population grew increasingly impatient with Haiti's poor management and perceived incompetence, and the heavy taxation that was imposed on their side. The country was hit with a severe economic crisis after having been forced to pay a huge indemnity to France. A debt was accrued by Haiti in order to pay for their own independence from the European nation; this would give rise to many anti-Haitian plots.\\r\\n\\r\\nIn 1838 Juan Pablo Duarte, an educated nationalist, founded a resistance movement called La Trinitaria (\\"The Trinity\\") along with Ram܇n Matas Mella and Francisco del Rosario Snchez. It was so named because its original nine members had organized themselves into cells of three. The cells went on to recruit as separate organizations, maintaining strict secrecy, with little or no direct contact among themselves, in order to minimize the possibility of detection by the Haitian authorities. Many recruits quickly came to the group, but it was discovered and forced to change its name to La Filantr܇pica (\\"The Philanthropic\\"). The Trinitarios won the loyalty of two Dominican-manned Haitian regiments.[4]\\r\\n\\r\\nIn 1843 the revolution made a breakthrough: they worked with a liberal Haitian party that overthrew President Jean-Pierre Boyer. However, the Trinitarios'[5] work in the overthrow gained the attention of Boyer's replacement, Charles Rivire-Hrard. Rivire-Hrard imprisoned some Trinitarios and forced Duarte to leave the island. While gone, Duarte searched for support in Colombia and Venezuela, but was unsuccessful. Upon returning to Haiti, Hrard, a mulatto, faced a rebellion by blacks in Port-au-Prince. The two regiments of Dominicans were among those used by Hrard to suppress the uprising.[4]\\r\\n\\r\\nIn December 1843 the rebels told Duarte to return since they had to act quickly because they were afraid the Haitians had learned of their insurrection plans. When Duarte had not returned by February, because of illness, the rebels decided to take action anyway with the leadership of Francisco del Rosario Snchez, Ram܇n Matas Mella, and Pedro Santana, a wealthy cattle-rancher from El Seibo who commanded a private army of peons who worked on his estates.\\r\\n\\r\\nOn February 27, 1844, some 100 Dominicans seized the fortress of Puerta del Conde in the city of Santo Domingo, and the following day the Haitian garrison surrendered.[4] As these Haitian troops withdrew to the west side of the island, they pillaged and burned.[4] Mella headed the provisional governing junta of the new Dominican Republic. On March 14, Duarte finally returned after recovering from his illness and was greeted in celebration. Haitian Commander, Charles Rivire-Hrard, sent three columns totaling 30,000 men to crush the Dominican uprising.[6] In the south, Hrard was checked by Dominican forces led by Pedro Santana at Azua on March 19. In the north, General Jean-Louis Pierrot and 15,000 Haitians were repelled in an attack on Santiago by the garrison commanded by Jos Mara Imbert.[6] As the Haitians retreated, they laid waste to land.[4]\\r\\n\\r\\nMeanwhile, at sea, the Dominican schooners Maria Chica (3 guns), commanded by Juan Bautista Maggiolo, and the Separaci܇n Dominicana (5 guns), commanded by Juan Bautista Cambiaso, defeated a Haitian brigantine Pandora (unk guns) plus schooners Le signifie (unk guns) and La Mouche (unk guns) off Tortuguero on April 15.[4]\\r\\n\\r\\nOn June 17, 1845, the Dominicans, only a little over a year after winning independence from Haiti, invaded their former master in retaliation for Haitian border raids.[6] The invaders captured two towns on the Plateau du Centre and established a bastion at Cachimn.[6] Haitian President Jean-Louis Pierrot quickly mobilized his army and counterattacked on July 22, driving the invaders from Cachimn and back across the frontier.[1] In the first significant naval action between the Hispaniolan rivals, a Dominican squadron captured 3 small Haitian warships and 149 seamen off Puerto Plata on December 21.[1]\\r\\n\\r\\nOn March 9, 1849, President Faustin Soulouque of Haiti led 10,000 troops in an invasion of the Dominican Republic. Dominican General (and presidential contender) Santana raised 6,000 soldiers and, with the help of several gunboats, routed the Haitian invaders at El N~mero on April 17 and at Las Carreras[7] on April 21ÿ22.[8] In November 1849, a small naval campaign was undertaken in which Dominican government schooners captured Anse--Pitres and one or two other villages on the southern coast of Haiti, which were sacked and burned by the Dominicans.[9] The Dominicans also captured Dame-Marie, which they plundered and set on fire.[10]\\r\\n\\r\\nBy late 1854 the Hispaniolan nations were at war again. In November, 2 Dominican ships captured a Haitian warship and bombarded two Haitian ports.[1] In November 1855, Soulouque, having proclaimed himself Emperor Faustin I of a Haitian empire which he hoped to expand to include the Dominican Republic, invaded his neighbor again, this time with a ravaging and looting army of 30,000 men marching in three columns.[1] But again the Dominicans proved to be superior soldiers, defeating Soulouque's army, which vastly outnumbered them.[11]","input":"When did dominican republic gain independence from haiti?"},{"output":"June 7, 1996","context":"Julio Csar Chvez vs. Oscar De La Hoya, billed as \\"Ultimate Glory\\", was a professional boxing match contested on June 7, 1996 for the WBC and lineal super lightweight championship.\\r\\nAfter both Julio Csar Chvez and Oscar De La Hoya defeated their opponents (Scott Walker and Darryl Tyson respectively) in tune-up bouts on February 9, 1996, the two fighters agreed to face one another in a \\"dream match\\" set for June of that year. The undefeated De La Hoya had already won world titles in two divisions and was looking to capture a third world title in a third weight class at only 23ÿyears old. The 33ÿyear old Chavez, meanwhile, was entering his 100th fight and still possessed one of the most impressive records in boxing history, having gone 97ÿ1ÿ1 and capturing four world titles in three divisions in his 16ÿyear career.[1] The bout was highly anticipated, with some even calling the biggest fight in Latino boxing history and both fighters taking home a thenÿcareer high $9 million purse.[2] Despite his vast experience advantage over De La Hoya (who had only partaken in 21 pro fights up to that point) and his status as champion, the aging Chavez was initially installed as a 3ÿ1 underdog before odds were dropped to 2ÿ1 by the time of the fight. Though both fighters were of Mexican heritage, most Mexican and MexicanÿAmerican fans favored Chavez as De La Hoya had been born in the United States. In promotional stops for their fight, De La Hoya was largely booed by the largely Hispanic populations of Phoenix, San Diego and even his native Los Angeles.[3]\\r\\nA controversial decision was made prior to the fight as De La Hoya's promoter Bob Arum refused to let the fight be carried on Pay-per-view and instead opted for it to be shown almost exclusively on closed-circuit television, severely limiting the highly anticipated bouts audience. Arum claimed that he made the decision to combat the use of illegal \\"black boxes\\", which steal pay-per-view signals and allow its users to watch the program for free. Though Arum claimed that the fight would net somewhere between $60 to $90 million even without pay-per-view, the fight drew a somewhat disappointing crowd of 750,000, down from the 1.7 million fans Arum had expected, and fell well short of his expected earnings, with the fight grossing around $14 million.[4][5]\\r\\nThe fight would last less than four rounds. Only one minute into round one, De La Hoya would connect with a straight right hand that opened up a huge gash around Chavez' eye. The fight was temporally halted not even a minute later as the cut had become severe enough for the referee Joe Cortez to stop the action and allow Chavez to find a towel. Though Chavez was able to continue, he was unable to get any momentum and was dominated by De La Hoya for the remainder of the fight. In round four, as Chavez was finally mounting some offense, De La Hoya took control of the latter stages of the round and brutalized Chavez with a series of hard combinations and broke Chavez' nose with a left hook. As the cut around his eye had deteriorated even further, Cortez halted the fight once again and sent him to ringside physician Flip Homansky. Homansky then informed Cortez that Chavez could not continue due to the multiple lacerations to his face and De La Hoya was awarded with the TKO victory at 2:37 of the fourth round[6]","input":"When did oscar de la hoya fight chavez?"},{"output":"more than 20","context":"Mall of America (commonly, locally known as \\"MOA\\") is a shopping mall located in Bloomington, Minnesota, United States (a suburb of the Twin Cities). Southeast of the junction of Interstate 494 and Minnesota State Highway 77, north of the Minnesota River and across the Interstate from the MinneapolisÿSt. Paul International Airport. Opened in 1992, it is the second largest mall in the United States in terms of number of stores and total floor area.\\r\\nThe mall is managed by the Triple Five Group (which in turn is owned by Canada's Ghermezian family, along with the West Edmonton Mall). Eighty percent of visitors to the Mall of America are from Minnesota, Wisconsin, Iowa, the Dakotas, Illinois, Ohio, and Canada.[2]\\r\\n\\r\\n\\r\\nThe mall's concept was designed by the Triple Five Group, owned by the Ghermezian brothers, who also own the largest shopping mall in North America, the West Edmonton Mall. Mall of America is located on the site of the former Metropolitan Stadium, where the Minnesota Vikings and Minnesota Twins played until the Hubert H. Humphrey Metrodome opened in 1982. A plaque in the amusement park commemorates the former location of home plate, and one seat from Met Stadium was placed in Mall of America at the exact location it occupied in the stadium, commemorating a 520-foot (160?m) home run hit by hall-of-famer Harmon Killebrew on June 3, 1967.\\r\\nIn 1986, the Bloomington Port Authority signed an agreement with the Ghermezian organization. Groundbreaking for the mall took place on June 14, 1989. Organizations involved include Melvin Simon and Associates, Teachers Insurance and Annuity (a.k.a. TIAA), the Triple Five Group, and the office of architect Jon Jerde.\\r\\nMall of America opened its doors to the public on August 11, 1992. Even before opening, the mall had earned several nicknames, including \\"The Megamall\\", \\"Sprawl of America\\", \\"Hugedale\\"in reference to the four major \\"dale\\" shopping malls within the Twin Cities: Rosedale, Southdale, Ridgedale, and (defunct as of 2010[update]) Brookdaleand simply, \\"The Mall\\".\\r\\nMall of America became the largest shopping mall in total area and largest in total store vendors in the United States when it opened. The Mall of America's 42 million annual visitors equal roughly eight times the population of the state of Minnesota. The mall employs over 11,000 workers year-round and 13,000 during peak seasons.[3]\\r\\nIn 1996, Mall of America appeared in the Christmas movie Jingle All the Way.\\r\\nDuring its run as an all-encompassing entertainment and retail venue, certain aspects, particularly its bars, have come under scrutiny. In early-2000 a Mardi Gras-themed bar, Fat Tuesday, shut its doors due to indecent exposure and alcohol-related offenses.[4]\\r\\nIn 2003, after a protracted six-year legal battle between Simon Property Group, the managing general partner of the property, and the Ghermezian brothers/Triple Five Group, over majority ownership of the site, a federal appeals court ruled in favor of the Ghermezians, effectively transferring control and planning authority of the mall back to the creator of the concept.[5] The dispute stemmed from a 1999 purchase of Teacher's Insurance's 27.5% equity stake by Simon Properties, giving them majority ownership. The Ghermezians claimed they were never told of the deal and sued Simon, citing fiduciary responsibility.\\r\\nOn November 3, 2006, the Ghermezians gained full control of Mall of America by spending US$1 billion.[6]\\r\\nOn May 18, 2008, the Minnesota State Legislature passed a bill granting the City of Bloomington the right to use $34 million in tax-increment-financing to pay for public infrastructure to support the MoA expansion. In early 2011, construction began on an expansion of the south side of the mall near Killebrew Drive, where the 506-room Radisson Blu hotel opened in March 2013. The addition of this hotel was for the purposes of increasing accessibility to the park and making the Mall of America a destination location for anyone. The addition of the lightrail between the airport and the Mall of America also enabled people with layovers in Minneapolis to spend a convenient afternoon at the Mall of America.\\r\\nOn November 29, 2011, Google announced indoor maps for Mall of America along with several other places like airports, parks and public spaces.[7]\\r\\nOn March 24, 2012, the Triple Five Group announced the start of a $200 million expansion that would build into the north parking lot of the mall. Rather than the long planned Phase II expansion, this would be a step in building this expansion. The plans call for an additional hotel and an additional 200,000 square feet (19,000?m2) of retail space.[8] In March 2014, ground was broken on the mall's north side for the $104 million, 14-story JW Marriott hotel, owned and financed by the Shakopee Mdewakanton Sioux Community.[9]\\r\\nIn winter 2012ÿ2013, Mall of America hosted a 40 feet (12?m) tall ice castle made of icicles formed from 4 million gallons of water and then fused together. The castle joined 50 large ice towers together to create a series of shimmering archways, tunnels, walls and caverns.[10]\\r\\nIn 2015, King of Prussia Mall in King of Prussia, PA finished building a 140,000+ square ft. expansion with all new shops and restaurants connecting its two buildings; the plaza, and the court. This expansion meant that Mall of America lost its spot of being the largest.\\r\\nThe Mall of America has a gross area of 4,870,000?sq?ft (452,000?m2) or 96.4 acres (390,000?m2), enough to fit seven Yankee Stadiums inside,[11] with 2,500,000?sq?ft (230,000?m2) available as retail space.[3] The mall is nearly symmetric, with a roughly rectangular floor plan. More than 530 stores are arranged along three levels of pedestrian walkways on the sides of the rectangle, with a fourth level on the east side. Four anchor department stores are located at the corners. The mall is organized into four different zones, each of those zones had its own decorative style until a series of renovations from 2010 to 2015 led to a unified and more luxurious style, as well as to coincide with the mall's first major expansion.[12]\\r\\nDespite Minnesota's cold winters, only the mall's entrances and some below ground areas are heated. Heat is allowed in through skylights above the central amusement park area. The majority of the heat is produced by lighting fixtures, other electric devices, and people in the mall.[13] In fact, even during the winter, air conditioning systems may still be in use during peak hours to ensure a comfortable shopping environment.[14] Although the common areas are unheated, the individual stores do have heating systems.[15]\\r\\nTwo nearly identical seven-story parking ramps on the east and west sides of the mall provide 12,287 parking spaces. Overflow parking north of the building provides an additional 1,200ÿ1,500 spaces, and 1,407 spaces are provided by IKEA that is part of the Phase II expansion of the mall which is under construction.\\r\\nLevel One is the location of Nickelodeon Universe amusement park (formerly Camp Snoopy), and first level of general retail which includes Sea Life Minnesota, Hard Rock Cafe, Lego Store, American Girl Place, Apple Store, Barnes & Noble, Fabletics, Sears, Macy's, and Microsoft Store, [16] Level Two features restaurants, shopping, MOA? Moments, and the first Verizon Wireless Destination Store. Level Three has two food courts with more than 20 fast food and full service restaurants, mini-golf, shopping, and Crayola Experience. Level Four is the entertainment level with Hooters, Cantina # 1, Rick Bronson's House of Comedy, Gameworks, Dick's Last Resort, Sky Deck Sports Grille and Lane, and the first U.S. location of SMAAASH, a virtual reality sports entertainment center.\\r\\nThe Theatres at Mall of America (Initially run by General Cinemas, then AMC Theatres, and eventually operated by mall management) occupied the south side of the fourth floor through December 2016, when it closed permanently. It will be replaced by Cinemex subsidiary CMX Cinemas in fall 2017.[17]\\r\\nNickelodeon Universe is an indoor theme park in the center of the mall. The park features roller coasters, among numerous other rides and attractions, and is the largest indoor theme park in the United States. Unlike many indoor amusement parks, Nickelodeon Universe has a great deal of natural foliage in and about the park, and its floor has a wide variance in height ÿ the highest ground level in the park is 15 feet (4.6?m) above the lowest. The rides include the roller coasters SpongeBob SquarePants Rock Bottom Plunge and Avatar Airbender, and a thrill ride called BrainSurge. The latter attraction bills itself as a \\"rather peculiar\\" ride. It also has a miniature golfing section called Moose Mountain. This miniature golf course features eighteen holes and a relatively fast astroturf surface.[citation needed]\\r\\nAt the Sea Life Minnesota Aquarium, guests travel through a 300-foot-long (91?m) curved tunnel through 14 feet (4.3?m) of water to view over 4,500 sea creatures including sharks, turtles, stingrays, and many more.[18] Sea Life Minnesota Aquarium offers special events such as sleepovers, scuba diving, snorkeling, and birthday parties.[19][third-party source needed]\\r\\nThe Mall recently added Crayola Experience and FlyOver America to the list of family attractions.\\r\\nIn the lower level of the eastern parking ramp is the Mall of America Transit Station, the busiest transit hub in Minnesota with services to and from many destinations in the Minneapolis ÿ St. Paul metropolitan area.\\r\\nThe Transit Station contains two stops on the Metro transit network: the southern terminus of the METRO Blue Line (light rail) to Downtown Minneapolis via MSP Airport and Hiawatha Avenue (operated by Metro Transit), and the northern terminus of the METRO Red Line (BRT) to Lakeville (operated by the Minnesota Valley Transit Authority). Both agencies also operate many local bus services to the Transit Station, and many area hotels along with the Mystic Lake Casino offer free shuttles to their establishments.\\r\\nThe mall is not a park and ride facility, and overnight parking is banned to prevent passengers taking the train to the airport. Commuters are required to use the nearby 28th Avenue Station's parking ramp.\\r\\nThe Mall of America Transit Station is undergoing a study to increase efficiency and capacities, and to provide a better experience for its users.[22] Estimates for the upgrade are approximately $20 million.\\r\\nThe Mall of America's security program is unique and in many ways the first of its kind. Michael Rozin, who used to be employed as the mall's Special Operations Security Captain, developed and implemented a behavior detection unit specifically focused on mitigating the threat of terrorism and enhancing counter-terrorism capabilities.[23] Behavior Detection Officers (BDOs) are trained extensively in Israel, each one going through at least 240 hours of training that includes communication techniques, first aid, defensive tactics, crisis intervention, terrorism awareness, and rapid response.[24] As Doug Reynolds, the Security Director at the mall, noted in a congressional testimony in 2008, BDOs are taught to \\"look for intent, rather than means. The objective is to focus on suspicious indicators in three categories: People, vehicles and unattended items like backpacks, shopping bags, suitcases.\\"[25] This methodology has prepared the mall for a variety of threats, both from terrorists and everyday criminals.\\r\\nThe mall's private security personnel were featured in 2010 TLC series Mall Cops: Mall of America.[26]\\r\\nIn 2011, NPR's All Things Considered and Morning Edition and PBS's Newshour both aired programs documenting security abuses by the mall's security personnel.[27][28]\\r\\nIn February 2015, the Al-Shabaab militant group also released a propaganda video calling for attacks on the Mall of America and other Western shopping centers.[29] Although the group had never launched attacks in North America,[30] security at the mall was tightened in response and Homeland Security issued a one-day alert to shoppers to remain vigilant.[29]\\r\\nDuring the first decade of MOA's existence, demonstrators protested animal cruelty and sweatshop conditions.[31] In 1994, protesters confronted actor Charlton Heston at a mall restaurant over his campaigning efforts on behalf of a Republican U.S. Senate candidate. In 1996, two people were arrested after they locked themselves to Macys doors in the spirit of the annual Fur-Free Friday demonstration. The Minnesota Supreme Court decided in 1999 that because the mall is private property, constitutional free speech protections do not apply.[31]\\r\\nPeople inside the mall have been questioned or detained for operating video cameras, using notebooks, or other perceived suspicious behaviors. As of 2010[update], Michael Rozin, the former Special Operations Security Captain and founder of the mall's behavior detection unit instructed its members that \\"suspicious behavior\\" constitutes \\"photographing such things as air-conditioning ducts or signs that a shopper might have something to hide.\\"[32] Commander Jim Ryan of the Bloomington Police Department commented that the mall's security methods may \\"infringe on some freedoms, unfortunately.\\"[33]\\r\\nOn December 31, 2013, members from the First Nations protest movement Idle No More attempted to repeat a successful Native-American round dance held at the mall in 2012,[34] but failed after being stopped by mall security, who refused to allow Idle No More to hold their dance. Organizers of the dance, Patricia Shepard and Reyna Crow from Duluth were arrested on site for trespassing.[35]\\r\\nOn December 21, 2014, thousands of protesters attended an unauthorized demonstration organized by Black Lives Matter in the mall's rotunda. The demonstration was in response to the Michael Brown fatal shooting in Ferguson, Missouri, and the then recent jury decision not to prosecute the white officer in that case, as well as the death of Eric Garner of New York. In response to the demonstration, the Mall of America closed the areas of the mall around the rotunda.[36] Police arrested 25 demonstrators.[37] The Bloomington City Attorney, Sandra Johnson, is pursuing charges against the organizers, ranging \\"from disorderly conduct and trespassing to inciting a riot\\".[31] The city is seeking thousands of dollars in compensatory damages from some of the organizers for out-of-pocket costs the city incurred while paying overtime for additional security. In response to these charges, demonstrators have called for a boycott of the mall.[38]\\r\\nPlans for another Black Lives Matter demonstration at the Mall of America on December 23, 2015 prompted Mall officials to file a restraining order against the movement's activists.[39] Eight individual activists were sued in Hennepin County District Court.[40] The mall's lawsuit would prohibit the defendants from demonstrating and require them to delete all of their posts to social media pertaining to the demonstration. The lawsuit additionally asked that the court jail Black Lives Matter activists unless they publicly announce that the demonstration is cancelled on their social media accounts. The American Civil Liberties Union of Minnesota called the mall's lawsuit an \\"improper prior restraint on speech\\" and an unconstitutional overreach.[41] Leaders of the demonstration indicated that the demonstration would go ahead as scheduled.[42]\\r\\nWord of Mall of America's expansion has been stirring since the mid 1990s, however the first confirmation of an expansion occurred in 2005 when Triple 5 announces Mall of America Phase 2, a project that would expand the Mall of America to the north, crossing Lindau Lane and occupying the former site of Met Center.[43]\\r\\nHowever, this expansion was delayed due to the tightening of the credit market. Eventually this was broken into four major projects: 1b, 1c, 2b, 2c.[44]\\r\\nStatus of Phase 2 completion:\\r\\nComplete:\\r\\n1B: Radisson Blu\\r\\nSouth expansion complete 2013\\r\\n1C: retail, restaurant, office and J.W. Marriott\\r\\nNorth expansion complete 2016\\r\\nPlanned:\\r\\n2B: 2-3 story retail expansion including connection over Lindau Lane, luxury hotel, addition parking ramp.\\r\\nNorth Expansion on site of Met Center, Plan submitted to Bloomington Fall 2016, Construction 2017, Open 2018-2019\\r\\nConcepts:\\r\\n2C: 3 story retail plus additional hotel, entertainment venue located north of 2B with connections to Ikea and American Blvd\\r\\nShown on approved PDP from 2015 submission for 2B, but schedule dependent on 2B completion.\\r\\nThe amusement park, during its \\"Camp Snoopy\\" days.\\r\\nThe Metropolitan Stadium home plate marker.\\r\\nThe Harmon Killebrew chair.\\r\\nThe carousel at the amusement park.\\r\\nThe band organ, formerly at the carousel entrance.\\r\\nThe Bubba Gump Shrimp Co. restaurant.\\r\\nAnother shot of the amusement park during the Camp Snoopy era.\\r\\nAnother shot of Camp Snoopy from a different angle. The Kite-Eating Tree ride is shown in this picture.\\r\\nWhen Camp Snoopy became Nickelodeon Universe in 2008, the Kite-Eating Tree was restyled and renamed Swing-Along.\\r\\nThe three-story American flag, which was used on July 4, 2008.\\r\\nThe mall's information sign, which shows the use of \\"MOA\\".\\r\\nThe MPR store, emphasizing A Prairie Home Companion.\\r\\nAl's Farm Toys, a farm-themed toy store which closed in 2016.\\r\\nA few of the unique sports-themed stores throughout the mall. Team Choice and Lids Locker Room (formerly Locker Room) closed, but Goldy's and Rybicki Cheese remain and Goldy's has since become Goldy's Locker Room.\\r\\nThe legendary mural imitating Seurat; formerly near the food court.\\r\\nThe Lego \\"Imagination Center\\", the longest-standing Mall attraction.\\r\\nThe Lego Store after 2009 remodeling.","input":"How many restaurants are in mall of america?"},{"output":"132,656","context":"","input":"How many schools do we have in the usa?"},{"output":"Drawing on the unpublished diary of Antonina ?abiski's, it recounts the true story of how Antonina and her husband, Jan ?abiski, director of the Warsaw Zoo, saved the lives of 300 Jews who had been imprisoned in the Warsaw Ghetto following the German invasion of Poland on September 1, 1939.","context":"The Zookeeper's Wife is a non-fiction book written by the poet and naturalist Diane Ackerman. Drawing on the unpublished diary of Antonina ?abiski's, it recounts the true story of how Antonina and her husband, Jan ?abiski, director of the Warsaw Zoo, saved the lives of 300 Jews who had been imprisoned in the Warsaw Ghetto following the German invasion of Poland on September 1, 1939.[1][2] The book was first published in 2007 by W. W. Norton.\\r\\n\\r\\n\\r\\nIn the 1930s, Jan ?abiski was the director of the thriving zoo in Warsaw, Poland; his wife Antonina had a remarkable sympathy for animals, and their villa in the zoo was a nursery and residence for numerous animals as well as their son. This life came to an abrupt end with the German invasion of Poland on September 1, 1939, which started World War II (1939ÿ1945). Most of the zoo's animals and structures were destroyed in the bombings and siege of the city. The zoo was closed under German occupation, but the ?abiskis continued to occupy the villa, and the zoo itself was used first as a pig farm and subsequently as a fur farm.\\r\\nJan and Antonina ?abiski became active with the Polish underground resistance. At the villa and in the zoo's structures, they secretly sheltered Jews, most escaping from the doomed Warsaw ghetto. As many as 300 such \\"guests\\" passed through the zoo, and many did survive the war with the assistance of the ?abiskis and other members of the underground. Although the German occupiers executed those they discovered helping Jews, Antonina ?abiska maintained a semblance of prewar life at the villa, harboring a menagerie of animals ÿ such as otters, a badger, hyena pups, lynxes, and a rabbit ÿ as well as the secret guests.\\r\\nAlthough Jan ?abiski was wounded in the armed August 1944 Warsaw uprising against the German occupiers and was, for a time, interred in a POW camp, the ?abiskis survived the war. The zoo reopened in 1949, with Jan as its new director. On September 21, 1965, Yad Vashem (Israel's official memorial to the Jewish victims of the Holocaust) recognized Jan and Antonina ?abiski as Righteous Among the Nations.[3]\\r\\nDonna Seaman wrote enthusiastically in her Los Angeles Times review, \\"It is no stretch to say that this is the book Ackerman was meant to write. Ever since A Natural History of the Senses, she has been building a galaxy of incandescent works that celebrate the unity and wonder of the living world. But every rapturous hour she has spent communing with plants and animals, every insight gleaned into human nature, every moment under the spell of language is a steppingstone that led her to Poland, the home of her maternal grandparents, and to the incomparable heroes Jan and Antonina Zabinski. The result of her tenacious research, keen interpretation and her own \\"transmigration of sensibility\\" is a shining book beyond category.\\"[1] D. T. Max wrote in The New York Times, \\"This is an absorbing book, diminished sometimes by the choppy way Ackerman balances Antoninas account with the larger story of the Warsaw Holocaust. For me, the more interesting story is Antoninas. She was not, as her husband once called her, a housewife, but the alpha female in a unique menagerie.\\"[4]\\r\\nFor Orion Magazine Suzanne Antonetta wrote: \\"Ackerman, with her profound understanding of nature, tells Antoninas story in a way that makes it clear her roles as the zookeepers wife and heroine of the Resistance are inextricably connected, both in what the natural world has taught her, and taught her to accept.\\"[5]\\r\\nOn February 10, 2008, the book was number 13 on The New York Times non-fiction best seller list.[6]\\r\\nIn 2008, The Zookeeper's Wife won the annual Orion Book Award from Orion Magazine; the selection committee noted, \\"The Zookeepers Wife is a groundbreaking work of nonfiction in which the human relationship to nature is explored in an absolutely original way through looking at the Holocaust.\\"[7]\\r\\nIn 2013, plans were announced for a an eponymous feature film adaptation. The film is based on a screenplay by Angela Workman and directed by New Zealand director Niki Caro. American actress Jessica Chastain stars as Antonina ?abiska,[8][9] along with Johan Heldenbergh, Michael McElhatton, and Daniel Brhl. The film was released on March 31, 2017.[10]","input":"What's the story behind the zookeeper's wife?"},{"output":"tasked with gathering, processing, and analyzing national security information from around the world, primarily through the use of human intelligence (HUMINT)","context":"","input":"What is the central intelligence agency's job?"},{"output":"Calvary Baptist Academy, a private Christian high school in Shreveport, Louisiana","context":"As player\\r\\nAs coach\\r\\nDouglas Irving Pederson (born January 31, 1968) is an American football coach who is currently the head coach of the Philadelphia Eagles of the National Football League (NFL). He served as the offensive coordinator of the Kansas City Chiefs from 2013ÿ2015. He spent most of his playing career as a member of the Green Bay Packers, serving as a backup quarterback to Brett Favre and holder on placekicks, and winning Super Bowl XXXI with the team over the New England Patriots. He was also a backup to Dan Marino as a member of the Miami Dolphins, and a starting quarterback for the Eagles and Cleveland Browns.\\r\\nIn his second season as the Eagles' head coach, Pederson won Super Bowl LII (also against the Patriots), marking the first Super Bowl title in franchise history. He also became just the fourth person, after Mike Ditka, Tom Flores, and Tony Dungy to win a Super Bowl as both a player and head coach.[1]\\r\\n\\r\\n\\r\\nPederson was born in Bellingham, Washington, in 1968. He attended Ferndale High School in nearby Ferndale, Washington, and was an All-State selection in football, basketball, and baseball. After high school he graduated from Northeast Louisiana University, where he was quarterback from 1987 through 1990.[2] He still holds multiple passing records at the school.[3]\\r\\nPederson originally signed as a rookie free agent by the Miami Dolphins on May 1, 1991,[4] out of Northeast Louisiana University (now University of Louisiana at Monroe) in Monroe, Louisiana.[5] He was waived on August 17, 1991, before the start of the regular season.[6] After spending the 1991 season as a free agent, the New York/New Jersey Knights of the World League of American Football (WLAF) drafted him in the fifth round for the first pool of draft-eligible players on February 4, 1992. The second pool, which was drafted from on February 20, consisted of players allocated by NFL teams to the league.[7] He was the backup quarterback to Reggie Slack with the Knights from March to May 1992.[8]\\r\\nAfter the WLAF season finished, he was re-signed by the Dolphins on June 2, 1992.[9] Pederson spent 1992 training camp with the Dolphins, before being released during final roster cuts again. He was subsequently re-signed to the team's practice squad, where he practiced on the scout team until he was waived on October 8, 1992.[10] He was re-signed by the Dolphins after the season on March 3, 1993.[11] After his third training camp with the Dolphins, he was waived again on August 31, 1993.[12] For the second consecutive season, Pederson was re-signed to the team's practice squad, on September 1, 1993.[13] Dan Marino, the Dolphins' starting quarterback since 1983, ruptured his Achilles' tendon in a week 6 game against the Cleveland Browns on October 10, 1993, forcing backup Scott Mitchell to replace him. Pederson replaced Marino on the active roster, and served as Mitchell's backup for the next four games. Pederson made his NFL debut on October 24, 1993, in a week 8 game against the Indianapolis Colts.[14] He helped head coach Don Shula win his NFL-record 325th victory as a coach when Mitchell suffered a separated shoulder in a week 11 game against the Philadelphia Eagles on November 14, 1993.[15] In that record breaking game for Coach Shula, Pederson entered in the 3rd quarter of the game and went 3 for 6 for 34 yards, and completed several crucial 3rd downs.[16][17] Pederson was able to steer the Dolphins to the win. Pederson also served as the backup to recently acquired Steve DeBerg for the three games Mitchell missed with injury. He briefly entered a week 14 game against the New York Giants while DeBerg was receiving stitches on his face.[18] Mitchell returned as the Dolphins' starter after week 15, and Pederson was released in favor of backup DeBerg and third-string quarterback Hugh Millen on December 16, 1993.[19] Pederson re-signed with the Dolphins on April 16, 1994, after the season ended.[20] He spent the entire 1994 season on the Dolphins' active roster as the third-string quarterback behind Marino and Bernie Kosar. On February 15, 1995, Pederson was selected by the Carolina Panthers in the twenty-second round of the NFL Expansion Draft,[21] after being placed on the Dolphins' available players list on January 19,[22] but was released on May 24, 1995.[23] He returned to the World League after his release, playing with Rhein Fire. Pederson re-signed with the Dolphins again in June 1995.[24] After competing with Dan McGwire throughout training camp, Pederson was waived on August 22, 1995.[25] Marino suffered a knee injury during a week 6 game,[26] so Pederson was re-signed on October 10 to serve as the third quarterback behind Kosar and McGwire for the next two games.[27] He was released again after Marino returned for week 9 on October 24.[28]\\r\\nPederson worked out for the Green Bay Packers following week 10 in 1995, due to a season-ending injury suffered by backup Ty Detmer and a minor injury sustained by starter Brett Favre. Third-string quarterback T. J. Rubley was forced to play in week 10 and threw a game-ending interception after calling an audible, going against head coach Mike Holmgren's playcall. The Packers signed Bob Gagliano to serve as the third-stringer quarterback for weeks 11 and 12.[29] Pederson replaced Gagliano as the third-string quarterback when he signed with the Packers on November 22, 1995.[30] The Packers claimed Jim McMahon off waivers from the Browns to serve as Favre's backup ahead of Pederson and Rubley on November 29, 1995.[31] Rubley was waived on December 13, leaving McMahon and Pederson as Favre's backups.[32] Favre did not miss any games, so Pederson did not see any game action for the Packers in 1995. Pederson served as the third quarterback behind Favre and McMahon in 1996, playing in one game but recorded no statistics. He received a Super Bowl ring following the Packers' win over the Patriots in Super Bowl XXXI. He re-signed with the Packers with a two-year contract on February 20, 1997.[33] Pederson was again the third quarterback throughout 1997, backing up Favre and Steve Bono. Pederson beat out Rick Mirer for the backup job to Favre, as well as the primary placekick holder job, in 1998. In a week 5 loss to the Minnesota Vikings, Pederson replaced Favre in the last five minutes of a blowout game, and threw two touchdowns in his place. However, Pederson suffered a broken jaw that knocked him out for the team's next four games.[34][35]\\r\\nPederson signed a three-year, $4.5 million contract with the Philadelphia Eagles on February 18, 1999, to become the team's starting quarterback under new head coach Andy Reid, who was Pederson's quarterbacks coach in Green Bay from 1997ÿ1998.[36] The Eagles drafted Donovan McNabb with the second overall pick in the 1999 NFL Draft in April 1999, and Reid said Pederson would remain the starter until McNabb was ready to play.[37] In his nine starts for the Eagles, Pederson had a 2ÿ7 record, a 51.6% completion rate, 1,168 passing yards, six touchdowns, and nine interceptions. In his first career start, a week 1 game against the Arizona Cardinals, Pederson threw two touchdowns in the first quarter to help give the Eagles a 21ÿ0 lead. The Cardinals came back, however, and won the game on a field goal as time expired, 25ÿ24. Pederson went 12-for-25 for 91?yards and two touchdowns in the game.[38] McNabb replaced Pederson, who suffered a bruised throwing shoulder, after one half in a week 2 loss to the Tampa Bay Buccaneers, in which Pederson went 12-of-19 for 100?yards and an interception.[39] Pederson started a week 3 shutout loss (26ÿ0) to the Buffalo Bills, going 14-of-26 for 137?yards and two lost fumbles, before being replaced by McNabb again in the fourth quarter.[40] In a week 4 loss to the New York Giants, Pederson went 6-for-15 for 75?yards and two interceptions before being replaced by McNabb after halftime.[41] Pederson's first NFL win came in week 5 in a game against the Dallas Cowboys. He played the entire game, going 11-of-29 for 145?yards, one touchdown, and one interception.[42] Pederson played the entirety of the next three games, posting a 1ÿ2 record while throwing three touchdowns and three interceptions. In his final start as an Eagle, Pederson was benched at halftime of a week 9 game against the Carolina Panthers after going 3-of-9 for 28?yards and being down 23ÿ0. He did not see game action at quarterback again until a week 14 game against the Cowboys in which McNabb suffered an injury in the fourth quarter. Pederson went 8-for-12 for 108?yards and a touchdown in the loss, and Koy Detmer received the start ahead of him in week 15 with McNabb still injured. After spending the next season's training camp with the team, the Eagles released Pederson on August 28, 2000.[43]\\r\\nPederson considered retirement after being released by the Eagles, but instead signed a two-year contract with the Cleveland Browns on September 2, 2000.[44] The Browns' backup, Ty Detmer, suffered a season-ending injury, and the Browns needed a backup quarterback to starter Tim Couch. This was the second time in Pederson's career that he was signed to replace an injured Ty Detmer. Pederson started as the third quarterback behind Couch and Spergon Wynn, until Couch suffered a season-ending injury in week 7. Pederson started the next six games, posting a 1ÿ5 record. In a week 13 game against the Baltimore Ravens, he was knocked out of the game with bruised ribs and replaced with Wynn. Wynn started the next week against the Jacksonville Jaguars, but he suffered a season-ending injury and Pederson replaced him.[45] Pederson returned for the final two games of the season, losing both, including a 35ÿ24 loss to his former team, the Eagles, and a 24ÿ0 shutout loss to the Tennessee Titans. Pederson was released after the season on February 22, 2001.[28]\\r\\nThe Packers re-signed Pederson to a one-year contract on March 13, 2001, to replace backup Matt Hasselbeck, who was traded to the Seattle Seahawks.[46] Pederson was the primary backup to Favre for the entire 2001 season, and was the primary placekick holder in every game. He was re-signed to a one-year, $650,000 contract with the Packers on April 2, 2002. Pederson again was the backup quarterback and primary holder in all 16 games in 2002. In a week 7 game against the Washington Redskins, Favre suffered a sprained knee and Pederson took most of the snaps in the second half, going 9-for-15 for 78?yards to help win the game 30ÿ9. Pederson also played in games against the Miami Dolphins, Detroit Lions, and New York Jets. He re-signed with the Packers to a one-year, $750,000 contract on April 29, 2003.[47] For the third consecutive season, Pederson backed up Favre in all 16 games and held placekicks. He completed both of his passes during the regular season for a total of 16?yards. The Packers re-signed Pederson to a one-year contract on April 28, 2004.[48] Tim Couch was signed to compete for the backup quarterback job, but lost out to Pederson and was released on September 5, 2004.[49] In a week 3 game against the Indianapolis Colts, Pederson replaced Favre in a blowout loss and went 4-of-6 for 34?yards and an interception. The next week, a week 4 game against the New York Giants, Favre sustained a concussion in the third quarter, and Pederson replaced him at quarterback. Pederson went 7-of-17 for 86?yards and an interception in the loss before he suffered a hit to his side in the third quarter that resulted in a cracked bone in his back, a torn muscle in his side, and a broken rib.[50] He stayed in the game up until the last snap, when he was replaced by third-string quarterback Craig Nall. Pederson was placed on injured reserve on October 7, ending his season.[51] He retired in March 2005 to become a head coach at Calvary Baptist Academy.[52]\\r\\nAfter his retirement, Pederson was hired as head football coach of Calvary Baptist Academy, a private Christian high school in Shreveport, Louisiana.[52] Calvary was going into its second year as a program when Pederson signed on in March 2005.\\r\\nPederson was the head coach at Calvary for four years, and held a 33ÿ7 record in the regular season and an 8ÿ3 record in the post-season. The Cavaliers were in the state playoffs all four years with Pederson as head coach. In his first season in 2005, the Cavaliers went 5ÿ6 and lost in the first round of the state playoffs.[53] In 2007, he led the Cavaliers to the semi-finals and to their first district title.\\r\\nOn January 29, 2009, Pederson was hired as the offensive quality control coach for the Philadelphia Eagles, reuniting him with his former head coach, Andy Reid.[54] He was promoted to quarterbacks coach on February 8, 2011, replacing James Urban, who was promoted to assistant offensive coordinator.[55]\\r\\nOn January 11, 2013, Pederson followed Andy Reid to the Kansas City Chiefs to serve as offensive coordinator.[56]\\r\\nOn January 18, 2016, Pederson was hired as head coach of the Eagles replacing Chip Kelly.[57] Despite having Sam Bradford on the roster as the starting quarterback, the Eagles drafted Carson Wentz with the second overall pick in 2016. Right before the 2016 season began, Bradford was traded to the Minnesota Vikings and Wentz was named the starting quarterback as a rookie. Pederson and Wentz won their first three NFL games together, but finished the season 7ÿ9, missing the playoffs.\\r\\nPederson's second season was much more successful as he led the Eagles to a 13-3 record, winning them the NFC East division championship and allotting them home-field advantage throughout the playoffs. Wentz, who was having a career year and was considered a front runner for league MVP, tore his ACL in Week 14, leaving backup Nick Foles with the starting job for the remainder of the year. Despite becoming major playoff underdogs due to the loss of Wentz, Foles filled in admirably as the starter, allowing Philadelphia to make it to Super Bowl LII, their first Super Bowl appearance since the 2004 season. Eventual Super Bowl MVP Foles led the team in a 41-33 win over the New England Patriots, giving them their first Lombardi Trophy in franchise history and their first league championship since 1960.\\r\\nNFL head coaches under whom Pederson has served:\\r\\nAssistant coaches under Pederson who have become NFL head coaches:\\r\\nPederson was born to Teri (ne Boykin) and Gordon \\"Gordy\\" Pederson (1939ÿ2016)[59] on January 31, 1968, in Bellingham, Washington. A devout Christian [60], Pederson and his wife Jeannie have three sons.[61] Pederson has been a resident of Moorestown, New Jersey.[62]\\r\\nPound (#) sign denotes interim head coach.","input":"Where did doug pederson coach high school football?"},{"output":"La mam del 10","context":"La jefa del campe܇n is a Mexican telenovela produced by Roberto G܇mez Fernndez that premiered on 11 June 2018 on Las Estrellas.[3][4] It stars frica Zavala and Carlos Ferro.[5] In the United States it premired on UniMs on 10 July 2018.[6]\\r\\n\\r\\nYou never said it would be easy, but you were stronger than any lie, you are bigger than any challenge. Fulfilling our dreams made you invincible. Nobody notices your pain, nobody sees your tears. Your heart beats in silence and somebody finally somebody heard it. You believed in me and taught me not to give up, to fight for what I want, to fall. And to always get back up with more strength. Who else can give their life for a promise??, Thanks, mom.\\r\\nTita Menchaca (frica Zavala) is a woman of limited resources, determined and very committed to moving forward with her children; Rey and her step-daughter, Fabiola. When she was abandoned by her husband Waldo (Alberto Agnesi), she moved to the capital to reorganize her life as a single mother. With the passage of time and hope, her son Rey dreams of being one of the best footballers in the country, which drives Tita to do everything possible to help him achieve his dream, no matter how difficult it will be.\\r\\n\\r\\nOn 23 April 2018, Mexican television company Televisa stated filming began of the Mexican version of the Colombian telenovela La mam del 10.[8][9] Roberto G܇mez Fernndez executive producer of the telenovela, created the telenovela in order to support the 2018 FIFA World Cup.[10] The adaptation for Mexico is made by Ximena Surez and Julin Aguilar, while the direction is in charge of Walter Doehner and Vctor Herrera.[11]","input":"Who is la jefa del campeon based on?"},{"output":"1 April 1957","context":"Decimalisation is the process of converting a currency from its previous non-decimal denominations to a decimal system (i.e., a system based on one basic unit of currency and one or more sub-units, such that the number of sub-units in one basic unit is a power of 10, most commonly 100).\\r\\nThe only[citation needed] current non-decimal currencies are the Malagasy ariary (equal to five iraimbilanja) and the Mauritanian ouguiya (equal to five khoums), though in practice both just have one currency unit and no sub-unit because khoums and iraimbilanja are no longer minted.[citation needed]\\r\\n\\r\\n\\r\\nDecimal currencies have sub-units based on a factor of 10. There are most commonly 100 sub-units to the base currency unit, but currencies based on 1000 sub-units also exist, especially in Arab countries.\\r\\nFor example:\\r\\nHistorically, non-decimal currencies were much more common: such as the British pound sterling before decimalisation in 1971. Until 1971, the pound sterling had sub-units of account of shillings (20 to a pound) and pence (12 to a shilling). Like other currencies, it also had coins with other names (ha'pence, guineas, and crowns); and in addition, until 1960 the penny was divided into 4 farthings. There were nineteen different fractions of a pound of a whole number of pence. For example, a third, quarter, fifth and sixth of a pound were respectively 80, 60, 48, and 40 pence, normally written as shillings and pence: 6/8, 5/-, 4/-, and 3/4. There were eight additional fractions which were a whole number of farthings (for example, one sixty-fourth of a pound was three pence three farthings, written ?3?3?4d).\\r\\nRussia converted to a decimal currency under Tsar Peter the Great in 1704, with the ruble being equal to 100 kopeks, thus making the Russian ruble the world's first decimal currency.[1]\\r\\nFrance introduced the franc in 1795 to replace the livre tournois,[2] abolished during the French Revolution. France introduced decimalisation in a number of countries that it occupied during the Napoleonic period.\\r\\nDutch guilder decimalised in 1817 ( became equal to 100 centen instead of 20 stuivers=160 duits=320 penningen ), with last pre-decimal coins withdrawn from circulation in 1848.\\r\\nSweden introduced decimal currency in 1855. The currency riksdaler was divided into 100 ?re. The riksdaler was renamed krona in 1873.\\r\\nThe Austro-Hungarian Empire decimalised the Austro-Hungarian gulden in 1857, concurrent with its transition from the Conventionsthaler to the Vereinsthaler standard.\\r\\nSpain introduced its decimal currency unit, the peseta, in 1868, replacing all previous currencies.\\r\\nCyprus decimalised the Cypriot pound in 1955, which comprised 1,000 mils, later replaced by 100 cents.\\r\\nOn Decimal Day, 15 February 1971, the United Kingdom decimalised the pound sterling and the Republic of Ireland decimalised the Irish pound.\\r\\nMalta decimalised the lira in 1972.\\r\\nThe euro, which comprises 100 cents, was introduced in the eurozone, and as of 2015, it replaced 19 national currencies in Europe.\\r\\n\\r\\nIn places where Ssd was used, the decimalisation process either defined one new penny = ?1?100 pound, where the main unit (the pound) was unchanged, or introduced a new main unit (such as the dollar), equivalent to half a pound, with one cent = ?1?100 dollar.\\r\\nThe following table shows the conversion of common denominations of coins of the Ssd system.\\r\\nThe farthing, at ?1?4 penny, was never converted, as it ceased to be legal tender a decade prior to decimalisation. In 1971, a new penny would have been worth 9.6 farthings (making a farthing slightly more than 0.104 new pence).\\r\\nIn 1784, Thomas Jefferson proposed a decimal currency system based on the Spanish dollar, with coins for 10 dollars, 1 dollar, 1/10 dollar, and 1/100 dollar; possibly supplemented by a half-dollar, \\"double tenth\\", and \\"five copper piece\\". One argument he advanced in favour of this system was that the 1/100-dollar coin would be similar in value to existing copper coins:[3]\\r\\nThe initial currency of the United States was of decimal denomination from the outset of home minted currency in 1792 with the dollar being equal to 100 cents, but other currencies were also accepted for some time afterwards. For example, the Spanish dollar, a non-decimalized currency, was accepted as official currency in the United States alongside the U.S. dollar until 1857.[4]\\r\\nDecimalisation in Canada was complicated by the different jurisdictions before Confederation in 1867. In 1841, the united Province of Canada's Governor General, Lord Sydenham, argued for establishment of a bank that would issue dollar currency (the Canadian dollar). Francis Hincks, who would become the Province of Canada's Prime Minister in 1851, favoured the plan. Ultimately the provincial assembly rejected the proposal.[5] In June 1851, the Canadian legislature passed a law requiring provincial accounts to be kept decimalised as dollars and cents. The establishment of a central bank was not touched upon in the 1851 legislation. The British government delayed the implementation of the currency change on a technicality, wishing to distinguish the Canadian currency from the United States' currency by referencing the units as \\"Royals\\" rather than \\"Dollars\\".[6] The British delay was overcome by the Currency Act of 1 August 1854. In 1858, coins denominated in cents and imprinted with \\"Canada\\" were issued for the first time.\\r\\nDecimalisation occurred in:[7]\\r\\nThe colonial elite, the main advocates of decimalisation, based their case on two main arguments:[8] The first was for facilitation of trade and economic ties with the United States, the colonies' largest trading partner; the second was to simplify calculations and reduce accounting errors.[9]\\r\\nThe Mexican peso was formally decimalised in the 1860s with the introduction of coins denominated in centavos; however, the currency did not fully decimalise in practice immediately and pre-decimal reales were issued until 1897.\\r\\nBermuda decimalised in 1970, by introducing the Bermudian dollar equal to 8 shillings 4 pence (100 pence, effectively equal to the US dollar under the Bretton Woods system).\\r\\nThe rand was introduced on 14 February 1961. A Decimal Coinage Commission had been set up in 1956 to consider a move away from the denominations of pounds, shillings and pence, submitting its recommendation on 8 August 1958.[10] It replaced the South African pound as legal tender, at the rate of 2 rand = 1 pound or 10 shillings to the rand. Australia, New Zealand and Rhodesia also chose ten shillings as the base unit of their new currency.\\r\\nAustralia decimalised on 14 February 1966, with the new Australian dollar equivalent to ten shillings or half an Australian pound in the previous currency. Since a shilling became equal to ten cents, the Australian cent was equal to 1.2 Australian pence, although they were usually exchanged on a 1:1 basis during the brief period when both were circulating.[citation needed] The television campaign containing a memorable jingle, sung to the tune of Click Go the Shears, was used to help the public to understand the changes.[11]\\r\\nNew Zealand decimalised on 10 July 1967, with the New Zealand dollar replacing the New Zealand pound. The conversion rates were the same as Australia's10c to one shilling, one dollar to 10 shillings, and two dollars to one pound. Confusion was expected with twelve pence becoming ten cents, such as people expecting four cents' change from paying ten cents/one shilling for an item costing eight cents. To help avoid this, the Decimal Currency Board recommended on inter-currency transactions (e.g., paying 4c with Ssd coins, or paying 4d with decimal coins) to pay to the next highest five cents or sixpence to get the correct change.\\r\\nSri Lanka (known as Ceylon at the time) decimalised in 1869.\\r\\nIndia changed from the rupee, anna, pie system to decimal currency on 1 April 1957.\\r\\nYemen Arab Republic introduced coinage system of 1 North Yemeni rial=100 fils in 1974, to replace former system of 1 rial = 40 buqsha = 80 halala = 160 zalat. The country was one of the last to convert its coinage.\\r\\nJapan historically had two decimalisations of the yen, the sen (1/100) and the rin (1/1,000). However, they were taken out of circulation as of December 31, 1953, and all transactions are now conducted in round amounts of 1 yen or greater.[12]\\r\\nIn India, Pakistan, and other places where a system of 1 rupee = 16 annas = 64 paise = 192 pies was used, the decimalisation process defines 1 new paisa = ?1?100 rupee. The following table shows the conversion of common denominations of coins issued in modern India and Pakistan. Bold denotes the actual denomination written on the coins\\r\\nIn the special context of quoting the prices of stocks, traded almost always in blocks of 100 or more shares and usually in blocks of many thousands, stock exchanges in the United States used eighths or sixteenths of dollars, until converting to decimals between September 2000 and April 2001.[13]\\r\\nSimilarly, in the UK, the prices of government securities continued to be quoted in multiples of ?1?32 of a pound (?7?1?2?d or ?3?1?8?p) long after the currency was decimalised.\\r\\nMauritania and Madagascar theoretically retain currencies with units whose values are in the ratio five to one: the Mauritanian ouguiya (MRO) is equivalent to five khoums, and the Malagasy ariary (MGA) to five iraimbilanja.\\r\\nIn practice, however, the value of each of these two larger units is very small: as of 2010, the MRO is traded against the euro at about 370 to one, and the MGA at about 2,900 to one. In each of these countries, the smaller denomination is no longer used, and coins denominated in khoums and iraimbilanja are no longer minted. Therefore, in practice, they are neither decimal nor non-decimal currencies as there is no sub-unit.\\r\\nBefore introducing physical euro notes and coins on 1 January 2002, previous decimalisation efforts, particularly that of the UK in 1971, were studied by the European Central Bank.[14] Questions included how to most effectively educate the public (particularly the elderly), the duration of the transition, the likely speed of uptake, the likely effects on inflation for currencies where one euro cent, the smallest circulating denomination, was greater in value than the smallest coin in circulation before the transition, and the likely criminal activities which might be attempted during the transition period.","input":"When was the decimal currency system introduced in india?"},{"output":"the senior-most commissioned officer rank below that of flag officer (i.e., admirals)","context":"In the United States Navy, United States Coast Guard, United States Public Health Service Commissioned Corps (USPHS), and National Oceanic and Atmospheric Administration Commissioned Officer Corps (NOAA Corps), captain is the senior-most commissioned officer rank below that of flag officer (i.e., admirals). The equivalent rank is colonel in the United States Army, Air Force, and Marine Corps. The predecessors of the NOAA Corpsthe United States Coast and Geodetic Survey Corps (1917ÿ1965) and the Environmental Science Services Administration Corps (ESSA Corps) (1965ÿ1970)also used the rank.\\r\\nReflecting its nautical heritage, the term \\"captain\\" also sometimes is used as a military title by more junior officers who are serving as the commanding officer (CO) of a commissioned vessel of the Navy, Coast Guard, or National Oceanic and Atmospheric Administration ship of patrol boat size or greater, while officers below O-6 commanding aviation squadrons (typically O-5 commanders) will usually use the less formal title of \\"skipper.\\" (see rank vs. title)\\r\\n\\r\\n\\r\\nUSN, USCG, USPHSCC, and NOAACOC collar, cover (hat), or shoulder rank insignia (on select uniforms)\\r\\nThe eagle, shoulder boards, and dress blue sleeve stripes of a U.S. Coast Guard captain\\r\\nThe eagle, shoulder boards, and sleeve stripes (dress blues + female dress whites) of a USPHS captain\\r\\nThe eagle, shoulder boards, and sleeve stripes (dress blues + female dress whites) of a NOAA captain\\r\\nIn the United States Navy, captain (abbreviated CAPT) is a senior officer rank, with the pay grade of O-6. It ranks above commander and below rear admiral (lower half). It is equivalent to the rank of colonel in the other uniformed services. Promotion to captain is governed by Department of Defense policies derived from the Defense Officer Personnel Management Act (DOPMA) of 1980 or its companion Reserve Officer Personnel Management Act (ROPMA). DOPMA/ROPMA guidelines suggest that no more than 50% of eligible commanders should be promoted to captain after serving a minimum of three years at their present rank and after attaining 21ÿ23 years of cumulative commissioned service, although this percentage may be appreciably less contingent on force structure and the needs of the service. With very few exceptions, such as Naval Aviator Astronaut and Naval Flight Officer Astronaut, unrestricted line officer captains in the Navy will have successfully completed at least one commanding officer assignment at the commander (O-5) level, typically a destroyer or frigate for surface warfare officers, a nuclear-powered attack submarine or ballistic missile submarine for submarine warfare officers, a SEAL team for special warfare officers, or an aviation squadron for Naval Aviators and Naval Flight Officers, before being selected for promotion to captain.\\r\\nNavy captains with sea commands in the surface warfare officer community generally command ships of cruiser size or larger. The more senior the officer, the larger the ship. Others may hold command as commodores of destroyer squadrons (DESRON) consisting of multiple destroyers and frigates. Surface Warfare Officers may also command large deck amphibious warfare ships or combat support ships and also serve as commodores of amphibious squadrons (PHIBRON) or other type of surface ship squadrons.\\r\\nIn the submarine community, a captain typically commanded a nuclear-powered ballistic missile submarine (SSBN) until the early 21st century when the requisite rank for the position was downgraded to that of a commander. Today, like their surface warfare counterparts, captains in the submarine community may serve as commodores of submarine squadrons (SUBRON), commanding a group of SSBNs or attack submarines (SSN).\\r\\nIn Naval Aviation, captains with sea commands are Naval Aviators or Naval Flight Officers who are commanding officers of aircraft carriers, commanding officers of large-deck air-capable amphibious assault ships, commanders of carrier air wings (CAG), or commodores of functional or \\"type\\" air wings or air groups. A smaller cohort outside of sea and shore commands may also serve as astronauts on loan to the National Aeronautics and Space Administration (NASA).\\r\\nIn the Naval Special Warfare \\"Sea Air Land\\" (SEAL) community, captains with sea commands are typically commodores in command of Naval Special Warfare Groups (NAVSPECWARGRU).\\r\\nIn contrast, commanders of aircraft carrier strike groups (CSG) and expeditionary strike groups (ESG) are normally rear admirals, while subordinate destroyer squadron commodores, amphibious squadron commodores, carrier air wing commanders and the individual ship commanding officers within the strike group are of captain rank or lower. In addition, in the expeditionary strike group, the Marine Expeditionary Unit (MEU) commanding officer will always be a Marine Corps colonel. Adding to the confusion, all commanding officers of commissioned U.S. Navy warships and submarines (e.g., USS or \\"United States Ship\\") are called \\"captain\\" regardless of actual rank.\\r\\nNavy captains who are line officers may also fill important senior command and staff positions ashore as Chiefs of Staff/Executive Assistants or senior operations officers to flag officers, or they may hold shore command assignments such as commanding officers of naval bases, naval stations, naval air stations, naval air facilities, naval support activities, logistics groups, specialized centers or schools, or commanders of test wings or training air wings. They may also occupy senior leadership positions on fleet staffs, naval component commands staffs, the staffs of the joint Unified Combatant Commands, the staff of the Chief of Naval Operations (OPNAV), or the Joint Staff.\\r\\nAs opposed to unrestricted line captains, restricted line and staff corps captains will command facilities and organizations appropriate to their designators, such as intelligence centers commanded by intelligence officers; naval aviation depots/fleet readiness centers commanded by aeronautical engineering duty officers; naval hospitals commanded by Medical Corps (MC), Dental Corps (DC), Medical Service Corps (MSC), or Nurse Corps (NC) officers; supply centers by Supply Corps (SC) officers; Construction Battalions or civil engineering centers by Civil Engineer Corps (CEC) officers; or region legal service offices or defense service offices commanded by Judge Advocate General's Corps (JAGC) officers.\\r\\nThe United States Coast Guard also uses the same naval rank system for its commissioned officers as the U.S. Navy, with a Coast Guard captain ranking above a commander and below rear admiral (lower half). The sleeve and shoulder board insignia are similar to the Navy insignia, with a lighter shade of blue with a gold USCG shield above the stripes. Coast Guard captains follow career paths very similar to their Navy counterparts, with marine safety, security, and boat forces officers serving as Captain of the Port in command of Coast Guard Sectors, seagoing officers typically commanding large maritime security cutters or high endurance cutters and aviators commanding coast guard air stations. Coast Guard captains will also command all types of major Coast Guard shore installations and activities, as well as serve as chiefs of staff / executive assistants, senior operations officers, and other senior staff officers for Coast Guard flag officers. The Coast Guard has no staff corps officers.\\r\\nLike the U.S. Navy, all commanding officers of commissioned cutters (e.g., USCGC or \\"United States Coast Guard Cutter\\") are addressed as \\"captain\\" regardless of their actual rank.\\r\\nIn the United States Public Health Service (USPHS), and in the National Oceanic and Atmospheric Administration Commissioned Officer Corps, captains are senior non-combatant officers that serve as directors or ranking supervisors in their respective uniformed service corps. Seagoing NOAA captains command certain National Oceanic and Atmospheric Administration (NOAA) ships, while NOAA aviators command NOAA flight operations activities. USPHS rapid deployment force teams, containing 105 USPHS physicians, nurses, and other medical professionals, are commanded exclusively by captains.\\r\\nAlthough it exists largely as a maritime training organization, the United States Maritime Service also uses the rank of captain. Even though the Maritime Service is an auxiliary service, the grade is appointed by the President via the Secretary of Transportation, making it a federally recognized rank with corresponding paygrade of O-6.","input":"How high is a captain in the navy?"},{"output":"Woodrow Wilson","context":"The Revenue Act of 1913, also known as the Tariff Act, the Underwood Tariff, the Underwood Act, the Underwood Tariff Act, or the Underwood-Simmons Act (ch. 16, 38?Stat.?114, October 3, 1913), re-imposed the federal income tax after the ratification of the Sixteenth Amendment and lowered basic tariff rates from 40% to 25%, well below the Payne-Aldrich Tariff Act of 1909. It was signed into law by President Woodrow Wilson on October 3, 1913 and was sponsored by Alabama Representative Oscar Underwood.\\r\\n\\r\\n\\r\\nWilson summoned a special session of the Congress in April 1913. His immediate objective was to confront the perennial tariff question, and he brought special attention to the matter by deciding to appear in person before Congress to make his appeal. He was the first president since John Adams to do so.[1]\\r\\nThe joint session was a spectacular event. A huge crowd gathered, and every seat in the House chamber was taken. Newspaper coverage was intense. Wilson spoke only briefly but made it clear that tariff reform was needed and that he would not be a party to a repeat of the embarrassment of the thwarted reform of 1894. The burden was clearly on the shoulders of the Democrats, as they controlled both houses of Congress for the first time in 18 years.[citation needed]\\r\\nUnderwood guided a reform measure through the House of Representatives, but his counterpart in the Senate, Furnifold McLendel Simmons of North Carolina, reverted to form and allowed numerous increases in the tariffs to be added. Wilson, unlike many of his predecessors, took the offensive. He went to the Capitol and twisted the arms of backsliding Democrats. He also warned the public of the invasion of Washington, DC, then underway by scores of lobbyists.\\r\\nWilson was successful with generating a public reaction. Angry constituents wrote to their representatives and demanded tariff reform.[citation needed]\\r\\nThe Act passed the House 281-139 on May 8, 1913. Wilson used his patronage powers to guide it to passage by the Senate, which occurred 44-37 on September 9, 1913. Politically, the Act was considered a major triumph for the new president.\\r\\nThe Act established the lowest rates since the Walker Tariff of 1857. Most schedules were ad valorem basis, a percentage of the value of the item.\\r\\nThe duty on woolens went from 56% to 18.5%. Steel rails, raw wool, iron ore, and agricultural implements now had zero rates. The reciprocity program wanted by the Republicans was eliminated. Congress rejected proposals for a tariff board to fix rates scientifically, but it set up a study commission.\\r\\nThe Underwood-Simmons measure vastly increased the free list, adding woolens, iron, steel, farm machinery, and many raw materials and foodstuffs. The average rate was approximately 26%.\\r\\nThe Act also provided for the reinstitution of a federal income tax[2] to compensate for the anticipated loss of revenue from the reduction of tariff duties. The most recent effort to tax incomes, the Wilson-Gorman Tariff of 1894, had been declared unconstitutional by the Supreme Court because the tax on dividends, interest, and rents had been deemed to be a direct tax not apportioned by representation. That obstacle, however, was removed by ratification of the Sixteenth Amendment on February 3, 1913. The Act, which was declared to be constitutional later that year by the Supreme Court in Brushaber v. Union Pacific Railroad, provided:\\r\\nThe incomes of couples exceeding $4,000, as well as those of single persons earning $3,000 or more, were subject to a 1% tax.[4] Also, the measure provided a progressive tax structure; those with high incomes were taxed at higher rates.\\r\\nIn only a few years, the income tax became the federal government's chief source of income and greatly exceeded tariff revenues.\\r\\nLess than 1% of the population then paid federal income tax.[citation needed]\\r\\nThe Act was applicable to incomes for 1913, 1914, and 1915. [5]\\r\\nA normal income tax and an additional tax were levied against the net income of individuals, as shown in the following table:\\r\\n38?Stat.?166 [6]\\r\\nThere was an exemption of $3,000 for single filers and $4,000 for married couples. Therefore, the 1% bottom marginal rate applied only to the first $17,000 ($374,400 in 2010 dollars) of income for single filers or the first $16,000 ($352,300 in 2010 dollars) of income for married filers (see also below the adjustments for inflation between 1913 and 2010 in the BLS table).\\r\\nThe ratio of top marginal rate to bottom marginal rate in 1913 was 7:1 (7%:1%). The last time a similar ratio was applicable was in 1980, when the ratio of the top rate to the bottom rate was 6.36:1 (70%:11%). In 1981, the top rate was reduced to 50%, and in 1986, it was reduced to 28% (the bottom rate rose from 11% to 15%). The 1986 change dramatically altered the ratio, from 6.36:1 to 1.87:1 (28%:15%). Today, the ratio is 3.96:1 (39.6%:10%).\\r\\nHere are the rates adjusted for inflation by the average Consumer Price Index:\\r\\nAll figures are rounded.\\r\\nIn 2010 dollars, the 2010 personal exemption ($3,650) and the standard deduction ($5,700) for single filers were together $9,350, only 14.1% of the 1913 exemption of $66,100 in 2010 dollars ($9,350/$66,100).\\r\\nIn 2010 dollars, the 2010 personal exemptions ($7,300) and the standard deduction ($11,400) for married couples filing jointly were together $18,700, only 21.2% of the 1913 exemption of $88,100 in 2010 dollars ($18,700/$88,100).\\r\\nIt is impossible to offer a meaningful judgment on the impact of the Act because the entire international economic picture was soon upset by the outbreak of World War I. American products were in great demand throughout the world, making the question of protectionism moot. The next reordering of national tariff policy would not occur until after the war ended, and the Fordney-McCumber Tariff of 1922 raised the rates.\\r\\nThere was nevertheless an impact for the Cuban Tabaco Industry concerning their import to the States. Theodor Garbade, President of the Union of Manufacturers of Cigars of Cuba laid this out to Cuban s President Mario G. Menocal.[7]\\r\\nHowever, the top marginal income tax rate of 7% was mentioned in Ronald Reagan's remarks on the South Lawn of the White House on October 22, 1986, when he said that the top rate was for \\"the equivalent of multimillionaires today.\\"[8]\\r\\nThe Act also created a new group of tax-exempt organizations dedicated to social welfare. The provision was a precursor to what is now Internal Revenue Code Section 501(c)(4).[9]","input":"Which u.s. president enacted the federal income tax system?"},{"output":"October 1, 1949","context":"The history of the People's Republic of China details the history of mainland China since October 1, 1949, when, after a near complete victory by the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People's Republic of China (PRC) from atop Tiananmen. The PRC has for several decades been synonymous with China, but it is only the most recent political entity to govern mainland China, preceded by the Republic of China (ROC) and thousands of years of imperial dynasties.\\r\\n\\r\\n\\r\\nFollowing the Chinese Civil War and the victory of Mao Zedong's Communist forces over the Kuomintang forces of Generalissimo Chiang Kai-shek, who fled to Taiwan, Mao declared the founding of the People's Republic of China on October 1, 1949. Mao's first goal was a total overhaul of the land ownership system, and extensive land reforms. China's old system of landlord ownership of farmland and tenant peasants was replaced with a distribution system in favor of poor/landless peasants which significantly reduced economic inequality. Over a million landlords were executed.[1] In Zhangzhuangcun, in the more thoroughly reformed north of the country, most \\"landlords\\" and \\"rich peasants\\" had lost all their land and often their lives or had fled. All formerly landless workers had received land, which eliminated this category altogether. As a result, \\"middling peasants,\\" who now accounted for 90 percent of the village population, owned 90.8 percent of the land, as close to perfect equality as one could possibly hope for.[2] Mao laid heavy theoretical emphasis on class struggle, and in 1953 began various campaigns to persecute former landlords and merchants, including the execution of more powerful landlords. Drug trafficking in the country as well as foreign investment were largely wiped out.\\r\\nMao believed that socialism would eventually triumph over all other ideologies, and following the First Five-Year Plan based on a Soviet-style centrally controlled economy, Mao took on the ambitious project of the Great Leap Forward in 1958, beginning an unprecedented process of collectivization in rural areas. Mao urged the use of communally organized iron smelters to increase steel production, pulling workers off of agricultural labor to the point that large amounts of crops rotted unharvested. Mao decided to continue to advocate these smelters despite a visit to a factory steel mill which proved to him that high quality steel could only be produced in a factory. He thought that ending the program would dampen peasant enthusiasm for his political mobilization, the Great Leap Forward.\\r\\nThe implementation of Maoist thought in China may have been responsible for over 40-70 million deaths including famine during peacetime[3], with the Great Leap Forward, Anti-Rightist Campaign of 1957-58,[4] and the Cultural Revolution. Millions died from both executions and forced labour. Because of Mao's land reforms during the Great Leap Forward, which resulted in massive famines, thirty million perished between 1958 and 1961. By the end of 1961 the birth rate was nearly cut in half because of malnutrition.[5] Active campaigns, including party purges and \\"reeducation\\" resulted in the imprisonment or execution of those deemed to hold views contrary to Maoist ideals.[6] Mao's failure with the Leap reduced his power in government, whose administrative duties fell to Liu Shaoqi and Deng Xiaoping.\\r\\nTo impose socialist orthodoxy and rid China of \\"old elements\\", and at the same time serving certain political goals, Mao began the Cultural Revolution in May 1966. The campaign was far reaching into all aspects of Chinese life. Red Guards terrorized the streets as many ordinary citizens were deemed counter-revolutionaries. Education and public transportation came to a nearly complete halt. Daily life involved shouting slogans and reciting Mao quotations. Many prominent political leaders, including Liu and Deng, were purged and deemed \\"capitalist-roaders\\". The campaign would not come to a complete end until the death of Mao in 1976.\\r\\nSupporters of the Maoist Era claim that under Mao, China's unity and sovereignty was assured for the first time in a century, and there was development of infrastructure, industry, healthcare, education (only 20% of the population could read in 1949, compared to 65.5% thirty years later)[7], which raised standard of living for the average Chinese. They also claimed that campaigns such as the Great Leap Forward and the Cultural Revolution were essential in jumpstarting China's development and \\"purifying\\" its culture. Others[who?] claim that though the consequences of both these campaigns were economically and humanly disastrous, they left behind a \\"clean slate\\" on which later economic progress could be built. Supporters often also doubt statistics or accounts given for death tolls or other damages incurred by Mao's campaigns, attributing the high death toll to natural disasters, famine, or other consequences of political chaos during the rule of Chiang Kai-shek.\\r\\nMao Zedong's death was followed by a power struggle between the Gang of Four, Hua Guofeng, and eventually Deng Xiaoping. Deng would maneuver himself to the top of China's leadership by 1980. At the Third Plenum of the Eleventh National Party Congress Central Committee, Deng embarked China on the road to Economic Reforms and Openness (T˜ Gaige Kaifang), policies that began with the de-collectivization of the countryside, followed with industrial reforms aimed at decentralizing government controls in the industrial sector. A major document presented at the September 1979 Fourth Plenum, gave a \\"preliminary assessment\\" of the entire 30-year period of Communist rule. At the plenum, party Vice Chairman Ye Jianying declared the Cultural Revolution \\"an appalling catastrophe\\" and \\"the most severe setback to [the] socialist cause since [1949].\\"[8] The Chinese government's condemnation of the Cultural Revolution culminated in the Resolution on Certain Questions in the History of Our Party Since the Founding of the People's Republic of China, adopted by the Sixth Plenary Session of the Eleventh Central Committee of the Communist Party of China. This stated that \\"Comrade Mao Zedong was a great Marxist and a great proletarian revolutionary, strategist and theorist. It is true that he made gross mistakes during the \\"cultural revolution\\", but, if we judge his activities as a whole, his contributions to the Chinese revolution far outweigh his mistakes. His merits are primary and his errors secondary.\\"[9]\\r\\nOn the subject of Mao's legacy Deng coined the famous phrase \\"7 parts good, 3 parts bad\\" and avoided denouncing Mao altogether. Deng championed the idea of Special Economic Zones (SEZs), areas where foreign investment would be allowed to pour in without strict government restraint and regulations, running on a basically capitalist system. Deng laid emphasis on light industry as a stepping stone to the development of heavy industries.\\r\\nSupporters of the economic reforms point to the rapid development of the consumer and export sectors of the economy, the creation of an urban middle class that now constitutes 15% of the population, higher living standards (which is shown via dramatic increases in GDP per capita, consumer spending, life expectancy, literacy rate, and total grain output) and a much wider range of personal rights and freedoms for average Chinese as evidence of the success of the reforms.\\r\\nAlthough standards of living improved significantly in the 1980s, Deng's reforms were not without criticism. Hard-liners asserted that Deng opened China once again to various social evils, and an overall increase in materialistic thinking, while liberals attacked Deng's unrelenting stance on political reform. Liberal forces began gathering in different forms to protest against the Party's authoritarian leadership. In 1989, the death of Hu Yaobang, a liberal figure, triggered weeks of spontaneous protests in the Tiananmen Square. The government imposed martial law and sent in tanks and soldiers to suppress the demonstrations. Western countries and multilateral organizations briefly suspended their formal ties with China's government under Premier Li Peng's leadership, which was directly responsible for the military curfew and bloody crackdown.\\r\\nCritics of the economic reforms, both in China and abroad, claim that the reforms have caused wealth disparity, environmental pollution, rampant corruption, widespread unemployment associated with layoffs at inefficient state-owned enterprises, and has introduced often unwelcome cultural influences. Consequently, they believe that China's culture has been corrupted, the poor have been reduced to a hopeless abject underclass, and that the social stability is threatened. They are also of the opinion that various political reforms, such as moves towards popular elections, have been unfairly nipped in the bud. Regardless of either view, today, the public perception of Mao has improved at least superficially; images of Mao and Mao related objects have become fashionable, commonly used on novelty items and even as talismans. However, the path of modernization and market-oriented economic reforms that China started since the early 1980s appears to be fundamentally unchallenged. Even critics of China's market reforms do not wish to see a backtrack of these two decades of reforms, but rather propose corrective measures to offset some of the social issues caused by existing reforms.\\r\\nIn 1979, the Chinese government instituted a one child policy to try to control its rapidly increasing population. The controversial policy resulted in a dramatic decrease in child poverty. The law currently applies to about a third of mainland Chinese, with plans in place to ease it to a two-child limit.[10][11]\\r\\nThe achievements of Lee Kuan Yew to create an economic superpower in Singapore had a profound effect on the Communist leadership in China. They made a major effort, especially under Deng Xiaoping, to emulate his policies of economic growth, entrepreneurship, and subtle suppression of dissent. Over 22,000 Chinese officials were sent to Singapore to study its methods.[12]\\r\\nAfter the events at Tiananmen, Deng Xiaoping retired from public view. While keeping ultimate control, power was passed onto the third generation of leadership led by Jiang Zemin, who was hailed as its \\"core\\". Economic growth, despite foreign trade embargoes, returned to a fast pace by the mid-1990s. Jiang's macroeconomic reforms furthered Deng's vision for \\"Socialism with Chinese Characteristics\\". At the same time, Jiang's period saw a continued rise in social corruption in all areas of life. Unemployment skyrocketed as unprofitable SOE's were closed to make way for more competitive ventures, internally and abroad. The ill-equipped social welfare system was put on a serious test. Jiang also laid heavy emphasis on scientific and technological advancement in areas such as space exploration. To sustain vast human consumption, the Three Gorges Dam was built, attracting supporters and widespread criticism. Environmental pollution became a very serious problem as Beijing was frequently hit by sandstorms as a result of desertification.\\r\\nThe 1990s saw two foreign colonies returned to China, Hong Kong from Britain in 1997, and Macau from Portugal in 1999. Hong Kong and Macau mostly continued their own governance, retaining independence in their economic, social, and judicial systems.\\r\\nJiang and President Clinton exchanged state visits, but Sino-American relations took very sour turns at the end of the decade. On May 7, 1999, during the Kosovo War, US aircraft bombed the Chinese embassy in Belgrade. The U.S. government claimed the strike was due to bad intelligence and false target identification.\\r\\nInside the US, the Cox Report stated that China had been stealing various top US military secrets.\\r\\nIn 2001, a US surveillance plane collided with a Chinese fighter jet over international waters near Hainan, inciting further outrage with the Chinese public, already dissatisfied with the US.\\r\\nOn the political agenda, China was once again put on the spotlight for the banning of public Falun Gong activity in 1999. Silent protesters from the spiritual movement sat outside of Zhongnanhai, asking for dialogue with China's leaders. Jiang saw it as threatening to the political situation and outlawed the group altogether, while using the mass media to denounce it as an evil cult.\\r\\nConversely, Premier Zhu Rongji's economic policies held China's economy strong during the Asian Financial Crisis. Economic growth averaged at 8% annually, pushed back by the 1998 Yangtze River Floods. After a decade of talks, China was finally admitted into the World Trade Organization. Standards of living improved significantly, although a wide urban-rural wealth gap was opened, as China saw the reappearance of the middle class. Wealth disparity between East and the Western hinterlands continued to widen by the day, prompting government programs to \\"develop the West\\", taking on such ambitious projects such as the Qinghai-Tibet Railway. The burden of education was greater than ever. Rampant corruption continued despite Premier Zhu's anti-corruption campaign that executed many officials.\\r\\nThe first major crisis faced by China in the 21st century as a new generation of leaders led by Hu Jintao after assuming power was the public health crisis involving SARS, an illness that seemed to have originated out of Guangdong province. China's position in the war on terror drew the country closer diplomatically to the United States. The economy continues to grow in double-digit numbers as the development of rural areas became the major focus of government policy. In gradual steps to consolidate his power, Hu Jintao removed Shanghai Party Chief Chen Liangyu and other potential political opponents amidst the fight against corruption, and the ongoing struggle against once powerful Shanghai clique. The assertion of the Scientific Perspective to create a Socialist Harmonious Society is the focus of the Hu-Wen administration, as some Jiang-era excesses are slowly reversed. In the years after Hu's rise to power, respect of basic human rights in China continue to be a source of concern.\\r\\nThe political status and future of Taiwan remain uncertain, but steps have been taken to improving relations between the Communist Party and several of Taiwan's parties that hold a less antagonistic view towards China, notably former rival Kuomintang.\\r\\nThe continued economic growth of the country as well as its sporting power status gained China the right to host the 2008 Summer Olympics. However, this also put Hu's administration under intense spotlight. While the 2008 Olympic was commonly understood to be a come-out party for People's Republic of China, in light of the March 2008 Tibet protests, the government received heavy scrutiny. The Olympic torch was met with protest en route. Within the country these reactions were met with a fervent wave of nationalism with accusations of Western bias against China.\\r\\nIn May 2008, a massive earthquake registering 8.0 on the Richter scale hit Sichuan province of China, exacting a death toll officially estimated at approximately 70,000. The government responded more quickly than it did with previous events, and has allowed foreign media access to the regions that were hit the hardest. The adequacy of the government response was generally praised, and the relief efforts extended to every corner of Chinese life. In May and June 2008, heavy rains in southern China caused severe flooding in the provinces of Anhui, Hunan, Jiangxi, Fujian and Guangdong, with dozens of fatalities and over a million people forced to evacuate. As of 2009 China has increased its internet monitoring capabilities by adding hundreds of new monitoring stations.","input":"When was the people's republic of china established?"},{"output":"15 minutes","context":"","input":"How long is a quarter in a nfl football game?"},{"output":"a Winchester Model 1892 (or modern derivative) with a shortened barrel and stock","context":"The Mare's Leg (aka Mare's Laig; both sometimes spelled without the apostrophe) is the name given to a customized shortened rifle used by Steve McQueen's character on the television series Wanted: Dead or Alive (1958ÿ1961).  McQueen's character was named Josh Randall, and the gun has also been referred to as a Winchester Randall, or a Randall Special. \\"Mare's leg\\" is now a generic term for a Winchester Model 1892 (or modern derivative) with a shortened barrel and stock.[2]\\r\\n\\r\\nThe term \\"mare's leg\\" was introduced in 1957 in the TV series Trackdown, where Steve McQueen first appeared as a bounty hunter.[3] Steve McQueen and his \\"mare's leg\\" went on to star in the CBS TV series Wanted Dead or Alive.[4]\\r\\n\\r\\nDesigned by Kenny \\"Von Dutch\\" Howard, an experienced artist and gunsmith,[5] the original mare's leg was made by cutting down a .44-40 caliber Winchester Model 1892 rifle to a size that could be worn in a large leg holster and used with one hand.  The barrel was cut to a length of nine inches,[1] and much of the butt-stock was removed. The original mare's leg did not have sights. McQueen was involved in the final design, suggesting the duck-bill hammer and enlarged lever loop, and initiating a redesign of the custom holster.[1] The Bureau of Alcohol, Tobacco, and Firearms was not consulted before the program aired and producers had to pay taxes totalling $1100.[1]\\r\\n\\r\\nDuring filming three guns were made, each with an enlarged loop on the cocking lever. After filming started, the size of the levers was made smaller on all 3 guns. The second and third guns bore octagonal barrels instead of a round one. In a continuity oversight, a gun sometimes changed partway through a given scene. While the guns were chambered for the .44-40 round, McQueen wore more impressive looking .45-70 rounds in the loops of his gun belt. In season one a doctor, after removing a bullet fired from the Mare's Leg from the back of a criminal, identified the removed bullet as a 30-30 round.[6]\\r\\n\\r\\nAs of the 1980s, one of the original guns was on display at the Fort Spaghetti Restaurant and Museum (999 Ball Road, Anaheim, California).[7] Another is in the Autry National Center of the American West.[8] There have been a number of toys based on the Mare's Leg, from small cap guns to larger detailed toys complete with a holster.\\r\\n\\r\\nIn the 1987 film Wanted: Dead or Alive, a sequel to the series starring Rutger Hauer as Nick Randall, the grandson of Josh Randall, Nick keeps his grandfather's Mare's Leg in a display case in his office.\\r\\n\\r\\nSimilar shortened rifles have appeared in:\\r\\n\\r\\nA number of companies have marketed functional reproductions of the Mare's Leg, making them the same way as the original, by cutting down Winchester rifles.  These reproductions also have the same legal restrictions as the original: a rifle may not have a barrel length less than 16 inches (41?cm) without obtaining a tax stamp from the ATF, in accordance with the National Firearms Act.[11]\\r\\n\\r\\nOther companies have marketed reproductions originally made and sold as handguns. Because of the legal restrictions, non-functional prop-quality replicas have been produced by some of the same companies that make functional copies.\\r\\n\\r\\nSince before 2000, Eagle Squadron Productions has produced and sold an authentic 1892 Winchester Mare's Leg carbine.  It uses a Winchester 1892 carbine in the correct caliber of .44-40, and is based on one of the original prop guns. They also produce replica gun belt and a non-firing replica carbine.[12]\\r\\n\\r\\nIn 2005, J.B. Custom began marketing a \\"1892 Mares Leg Lever Action Pistol\\". This pistol is a fully functional copy of Randall's weapon, available in a number of calibers.  Since they are newly manufactured as pistols and sold subject to handgun regulations, rather than cut down rifles, they avoid legal difficulties.  Like the original weapon, the J.B. Custom version has a 12-inch (30?cm) barrel, and an overall length of 24 inches (61?cm).[13]\\r\\n\\r\\nThe pistol was available in .45 Colt, .44-40 Winchester, and .38-40 Winchester. Early promotional material specified a limited production run of 50 units based on the number of available 1892 actions that could be used legally. Later versions of the weapons use a slightly different action that while not exactly like the 1892 model, cycles more reliably, and is commercially available.  This version is available in .44 Magnum, and .357 Magnum.[13]\\r\\n\\r\\nIn 2008, Legacy Sports International introduced their version of the Mare's Leg, made by Chiappa in Italy, imported for Legacy, and sold under the brand name \\"Puma\\". This Puma 92 pistol is named the Bounty Hunter. It is available in several calibers including; .44 Magnum, .45 Colt, and .44-40. With a 12-inch (30?cm) barrel, no shoulder stock, and a receiver that has never been built into a rifle, it is considered a pistol by the ATF.[13]\\r\\n\\r\\nIn 2010 Rossi Firearms began offering a Mare's Leg under the name \\"Ranch Hand\\". The Rossi version is chambered in .45 Colt, .44 Magnum/.44 Special, and .357 Magnum/.38 Special.[14] The Rossi Ranch Hand is manufactured by Taurus in Brazil.[15]\\r\\n\\r\\nHenry Repeating Arms manufactures two versions of the Mare's Leg. The rimfire model has a blued receiver and barrel and chambers .22 Long Rifle, .22 Long, and .22 Short. The centerfire model has a brass receiver and blued barrel and is available in .357 Mag, .44 Mag, and .45 Colt.[16]\\r\\n\\r\\n The Italian firms, such as Chiappa Firearms, manufacture modern reproductions of the Winchester Model 1887 series shotguns. The shotguns appeared on the Australian and the European firearms markets in late 2008. Chiappas replicas are offered with barrels ranging from 28 to 18.5 inches.  They also offer a model with a rifled barrel and two models with pistol grips.[17]\\r\\n\\r\\nThe Model 1887 Mare's Leg was prominently used by the title character in the film Terminator 2: Judgment Day, portrayed by Arnold Schwarzenegger. One of the guns used in the film was modified with a pistol grip and an oversized loop on the trigger guard, allowing the character to fire and cycle the action with a one hand reverse spin.[17] This in turn has popularised the gun's portrayal in various pop culture, mostly in shooter video games, where they mimic the cycling and reloding actions from the movie.\\r\\n\\r\\nIn the United States under the National Firearms Act, to make a short barreled rifle from a firearm originally made and sold as a rifle requires  payment of  $200 for a tax stamp, approval from the BATFE and federal registration.[18]  However, a \\"lever action pistol\\" made and sold subject to BATFE regulations is treated as a pistol by federal law. While most states allow the purchase of Mare's Leg lever action pistols, New York State has banned this gun from being sold there. They are also not approved for sale in Massachusetts. It is hard to get in California since most stores believe it is not legal to sell there (including Henry USA)[citation needed].","input":"What kind of gun did josh randall carry?"},{"output":"August","context":"The Flowers Festival (Spanish: Feria de las Flores) is a festival that takes place in Medelln, Colombia. The festival is the most important social event for the city and includes a pageant, automobiles, a Paso Fino horse parade and many musical concerts.[1]\\r\\n\\r\\n\\r\\nThe first Flowers Festival took place on May 1, 1957 and was organized by Arturo Uribe, a member of the Board of the Office of Development and Tourism in Medellin, Colombia. The festival lasted for five days with an exposition of flowers displayed in the Metropolitan Cathedral, which was organized by the Gardening Club of Medelln and monsignor Tulio Botero to celebrate Virgin Mary day. This flower parade represents the end of slavery when slaves carried men and women on their backs up steep hills instead of flowers. The first silleteros parade also took place with some 40 men from the corregimiento of Santa Elena carrying on their backs flower arrangements to the exposition site.[1][2]\\r\\nThe festival initially took place during the month of May but was changed to August in 1958 to celebrate the independence of Antioquia. Since then, other events have been added like the International Pageant of the Flowers, the cavalcade, Guinness Records in 1996 and 1999, classic automobiles parade, Orchids exposition, among others.[1]\\r\\nIn 1999 during its first edition, the festival reached 482 silleteros participants.[3] The 2006 edition also featured a new category of silleteros as spokeswomen for the Convention Center Bureau of Madrid Maria Isabel Lopez mentioned \\"these are the Pioneers, who will show all their Silletas making experience, but will not participate in the contest\\".[4] Some 50 peasants will carry the silletas, 260 featuring traditional arrangements, 50 with commercial propaganda and 28 from the new Pioneer category. As in previous years, the Mayor of Medelln sponsored the awards of the Silleteros contest. In 2006, there were a total of 260 awards, selected and given by three juries.[4]","input":"When is la feria de las flores celebrated?"},{"output":"for bulk storage of grain","context":"A silo (from the Greek ?? ÿ siros, \\"pit for holding grain\\") is a structure for storing bulk materials.  Silos are used in agriculture to store grain (see grain elevators) or fermented feed known as silage.  Silos are more commonly used for bulk storage of grain, coal, cement, carbon black, woodchips, food products and sawdust. Three types of silos are in widespread use today: tower silos, bunker silos, and bag silos.\\r\\n\\r\\nThere are different types of cement silos such as the low-level mobile silo and the static upright cement silo, which are used to hold and discharge cement and other powder materials such as PFA (Pulverised Fuel Ash). The low-level silos are fully mobile with capacities from 100 to 750 tons. They are simple to transport and are easy to set up on site. These mobile silos generally come equipped with an electronic weighing system with digital display and printer. This allows any quantity of cement or powder discharged from the silo to be controlled and also provides an accurate indication of what remains inside the silo. The static upright silos have capacities from 200 to 800 tons. These are considered a low-maintenance option for the storage of cement or other powders. Cement silos can be used in conjunction with bin-fed batching plants.\\r\\n\\r\\nCement can be stored in different types of Silos like Horizontal Mobile Silos, Concrete Silos, Steel Panel Silos etc. depending upon the requirement of the end user. While Mobile Silos come in a relatively small storage capacity of approximately 90MT of Cement, Concrete Silos can store practically thousands of MT of Cement. A majority of Silos that store more than 5000 MT of Cement are constructed from Concrete. A good compromise between cost, construction time and ease of operation is Steel Panel Silos. These silos can be manufactured in a factory, and then erected at site using small panels that are bolted together to form a Silo that is watertight because of a sandwiched layer of special rubber seals.\\r\\n\\r\\nStorage silos are cylindrical structures, typically 10 to 90?ft (3 to 27?m) in diameter and 30 to 275?ft (10 to 90?m) in height with the slipform and Jumpform concrete silos being the larger diameter and taller silos.  They can be made of many materials.  Wood staves, concrete staves, cast concrete, and steel panels have all been used, and have varying cost, durability, and airtightness tradeoffs. Silos storing grain, cement and woodchips are typically unloaded with air slides or augers. Silos can be unloaded into rail cars, trucks or conveyors.\\r\\n\\r\\nTower silos containing silage are usually unloaded from the top of the pile, originally by hand using a silage fork, which has many more tines than the common pitchfork, 12 vs 4, in modern times using mechanical unloaders.  Bottom silo unloaders are utilized at times but have problems with difficulty of repair.\\r\\n\\r\\nAn advantage of tower silos is that the silage tends to pack well due to its own weight, except in the top few feet. However, this may be a disadvantage for items like chopped wood. The tower silo was invented by Franklin Hiram King.\\r\\n\\r\\nIn Canada, Australia and the United States, many country towns or the larger farmers in grain-growing areas have groups of wooden or concrete tower silos, known as grain elevators, to collect grain from the surrounding towns and store and protect the grain for transport by train, truck or barge to a processor or to an export port.  In bumper crop times, the excess grain is stored in piles without silos or bins, causing considerable losses.\\r\\n\\r\\nConcrete stave silos are constructed from small precast concrete blocks with ridged grooves along each edge that lock them together into a high strength shell. Concrete is much stronger in compression than tension, so the silo is reinforced with steel hoops encircling the tower and compressing the staves into a tight ring. The vertical stacks are held together by intermeshing of the ends of the staves by a short distance around the perimeter of each layer, and hoops which are tightened directly across the stave edges.\\r\\n\\r\\nThe static pressure of the material inside the silo pressing outward on the staves increases towards the bottom of the silo, so the hoops can be spaced wide apart near the top but become progressively more closely spaced towards the bottom to prevent seams from opening and the contents leaking out.\\r\\n\\r\\nConcrete stave silos are built from common components designed for high strength and long life. They have the flexibility to have their height increased according to the needs of the farm and purchasing power of the farmer, or to be completely disassembled and reinstalled somewhere else if no longer needed.\\r\\n\\r\\nLow-oxygen silos are designed to keep the contents in a low-oxygen atmosphere at all times, to keep the fermented contents in a high quality state, and to prevent mold and decay, as may occur in the top layers of a stave silo or bunker. Low-oxygen silos are only opened directly to the atmosphere during the initial forage loading, and even the unloader chute is sealed against air infiltration.\\r\\n\\r\\nIt would be expensive to design such a large structure that is immune to atmospheric pressure changes over time. Instead, the silo structure is open to the atmosphere but outside air is separated from internal air by large impermeable bags sealed to the silo breather openings. In the warmth of the day when the silo is heated by the sun, the gas trapped inside the silo expands and the bags \\"breathe out\\" and collapse. At night the silo cools, the air inside contracts and the bags \\"breathe in\\" and expand again.\\r\\n\\r\\nWhile the iconic blue Harvestore low-oxygen silos were once very common, the speed of its unloader mechanism was not able to match the output rates of modern bunker silos, and this type of silo went into decline. Unloader repair expenses also severely hurt the Harvestore reputation, because the unloader feed mechanism is located in the bottom of the silo under tons of silage. In the event of cutter chain breakage, it can cost up to US$10,000 to perform repairs. The silo may need to be partially or completely emptied by alternate means, to unbury the broken unloader and retrieve broken components lost in the silage at the bottom of the structure.\\r\\n\\r\\nIn 2005 the Harvestore company recognized these issues and worked to develop new unloaders with double the flow rate of previous models to stay competitive with bunkers, and with far greater unloader chain strength. They are now also using load sensing soft-start variable frequency drive motor controllers to reduce the likelihood of mechanism breakage, and to control the feeder sweep arm movement.\\r\\n\\r\\nBunker silos are trenches, usually with concrete walls, that are filled and packed with tractors and loaders.  The filled trench is covered with a plastic tarp to make it airtight.  These silos are usually unloaded with a tractor and loader.  They are inexpensive and especially well suited to very large operations.\\r\\n\\r\\nBag silos are heavy plastic tubes, usually around 8 to 12?ft (2.4 to 3.6?m) in diameter, and of variable length as required for the amount of material to be stored.  They are packed using a machine made for the purpose, and sealed on both ends.  They are unloaded using a tractor and loader or skid-steer loader.  The bag is discarded in sections as it is torn off.  Bag silos require little capital investment.  They can be used as a temporary measure when growth or harvest conditions require more space, though some farms use them every year.\\r\\n\\r\\nA bin [1] is typically much shorter than a silo, and is typically used for holding dry matter such as cement or grain. Grain is often dried in a grain dryer [2] before being stored in the bin. Bins may be round or square, but round bins tend to empty more easily due to a lack of corners for the stored material to become wedged and encrusted.\\r\\n\\r\\nThe stored material may be powdered, as seed kernels, or as cob corn. Due to the dry nature of the stored material, it tends to be lighter than silage and can be more easily handled by under-floor grain unloaders. To facilitate drying after harvesting, some grain bins contain a hollow perforated or screened central shaft to permit easier air infiltration into the stored grain.\\r\\n\\r\\nSand and salt for winter road maintenance are stored in conical dome-shaped silos. These are more common in North America, namely in Canada and the United States.\\r\\n\\r\\nFabric silos are constructed of a fabric bag suspended within a rigid, structural frame.  Polyester based fabrics are often used for fabrication of the bag material, with specific attention given to fabric pore size. Upper areas of silo fabric are often manufactured with slightly larger pore size, with the design intent of acting as a vent filter during silo filling. Some designs include metal thread within the fabric, providing a static conductive path from the surface of the fabric to ground. The frame of a fabric silo is typically constructed of steel.  Fabric silos are an attractive option because of their relative low cost compared to conventional silos.  However, when fabric silos are used to store granular or particulate combustible materials, conventional practices prescribed by established industry consensus standards [3] addressing combustible dust hazards can not be applied without a considerable engineering analysis of the system.\\r\\n\\r\\nArchaeological ruins and ancient texts show that silos were used in ancient Greece as far back as the late 8th century BC, as well as the 5th Millennium B.C site of Tell Tsaf, Israel. The term silo is derived from the Greek ?? (siros), \\"pit for holding grain\\".[4][5][6]\\r\\n\\r\\nThe silo pit, as it has been termed, has been a favorite way of storing grain from time immemorial in all oriental lands[clarification needed]Asia. In Turkey and Persia, usurers used to buy up wheat or barley when comparatively cheap, and store it in hidden pits against seasons of dearth. In Malta a relatively large stock of wheat was preserved in some hundreds of pits (silos) cut in the rock. A single silo stored from 60 to 80 tons of wheat, which, with proper precautions, kept in good condition for four years or more.[7]\\r\\n\\r\\nThe first modern silo, a wooden and upright one filled with grain, was invented and built in 1873 by Fred Hatch of McHenry County, Illinois, USA.[8][9]\\r\\n\\r\\nForage silo filling is performed using a forage harvester which may either be self-propelled with an engine and driver's cab, or towed behind a tractor that supplies power through a PTO.\\r\\n\\r\\nThe harvester contains a drum-shaped series of cutting knives which shear the fibrous plant material into small pieces no more than an inch long, to facilitate mechanized blowing and transport via augers. The finely chopped plant material is then blown by the harvester into a forage wagon which contains an automatic unloading system.\\r\\n\\r\\nTower forage filling is typically performed with a silo blower which is a very large fan with paddle-shaped blades. Material is fed into a vibrating hopper and is pushed into the blower using a spinning spiral auger.\\r\\n\\r\\nThere is commonly a water connection on the blower to add moisture to the plant matter being blown into the silo. The blower may be driven by an electric motor but it is more common to use a spare tractor instead.\\r\\n\\r\\nA large slow-moving conveyor chain underneath the silage in the forage wagon moves the pile towards the front, where rows of rotating teeth break up the pile and drop it onto a high-speed transverse conveyor that pours the silage out the side of the wagon into the blower hopper.\\r\\n\\r\\nSilo bags are filled using a traveling sled driven from the PTO of a tractor left in neutral and which is gradually pushed forward as the bag is filled. The steering of the tractor controls the direction of bag placement as it fills, but bags are normally laid in a straight line.\\r\\n\\r\\nThe bag is loaded using the same forage harvesting methods as the tower, but the forage wagon must be moved progressively forward with the bag loader. The loader uses an array of rotating cam-shaped spiraled teeth associated with a large comb-shaped tines to push forage into the bag. The forage is pushed in through a large opening, and as the teeth rotate back out, they pass between the comb tines. The cam-shaped auger teeth essentially wipe the forage off using the steel tines, keeping the forage in the bag.\\r\\n\\r\\nBefore filling begins, the entire bag is placed onto the loader as a bunched-up tube folded back on itself in many layers to form a thick pile of plastic. Because the plastic is minimally elastic, the loader mechanism filling chute is slightly smaller than the final size of the bag, to accommodate this stack of plastic around the mouth of the loader. The plastic slowly unfurls itself around the edges of the loader as the tube is filled.\\r\\n\\r\\nThe contents of the silo bag are under pressure as it is filled, with the pressure controlled by a large brake shoe pressure regulator, holding back two large winch drums on either side of the loader. Cables from the drum extend to the rear of the bag where a large mesh basket holds the rear end of the bag shut.\\r\\n\\r\\nTo prevent molding and to assure an airtight seal during fermentation, the ends of the silo bag tube are gathered, folded, and tied shut to prevent oxygen from entering the bag. Removal of the bag loader can be hazardous to bystanders since the pressure must be released and the rear end allowed to collapse onto the ground.\\r\\n\\r\\nA silo unloader specifically refers to a special cylindrical rotating forage pickup device used inside a single tower silo.\\r\\n\\r\\nThe main operating component of the silo unloader is suspended in the silo from a steel cable on a pulley that is mounted in the top-center of the roof of the silo. The vertical positioning of the unloader is controlled by an electric winch on the exterior of the silo.\\r\\n\\r\\nFor the summer filling of a tower silo, the unloader is winched as high as possible to the top of the silo and put into a parking position. The silo is filled with a silo blower, which is literally a very large fan that blows a large volume of pressurized air up a 10-inch tube on the side of the silo. A small amount of water is introduced into the air stream during filling to help lubricate the filling tube. A small adjustable nozzle at the top, controlled by a handle at the base of the silo directs the silage to fall into the silo on the near, middle, or far side, to facilitate evenly layered loading. Once completely filled, the top of the exposed silage pile is covered with a large heavy sheet of silo plastic which seals out oxygen and permits the entire pile to begin to ferment in the autumn.\\r\\n\\r\\nIn the winter when animals must be kept indoors, the silo plastic is removed, the unloader is lowered down onto the top of the silage pile, and a hinged door is opened on the side of the silo to permit the silage to be blown out. There is an array of these access doors arranged vertically up the side of the silo, with an unloading tube next to the doors that has a series of removable covers down the side of the tube. The unloader tube and access doors are normally covered with a large U-shaped shield mounted on the silo, to protect the farmer from wind, snow, and rain while working on the silo.\\r\\n\\r\\nThe silo unloader mechanism consists of a pair of counter-rotating toothed augers which rip up the surface of the silage and pull it towards the center of the unloader. The toothed augers rotate in a circle around the center hub, evenly chewing the silage off the surface of the pile. In the center, a large blower assembly picks up the silage and blows it out the silo door, where the silage falls by gravity down the unloader tube to the bottom of the silo, typically into an automated conveyor system.\\r\\n\\r\\nThe unloader is typically lowered only a half-inch or so at a time by the operator, and the unloader picks up only a small amount of material until the winch cable has become taut and the unloader is not picking up any more material. The operator then lowers the unloader another half-inch or so and the process repeats. If lowered too far, the unloader can pull up much more material than it can handle, which can overflow and plug up the blower, outlet spout, and the unloader tube, resulting in a time-wasting process of having to climb up the silo to clear the blockages.\\r\\n\\r\\nOnce silage has entered the conveyor system, it can be handled by either manual or automatic distribution systems. The simplest manual distribution system uses a sliding metal platform under the pickup channel. When slid open, the forage drops through the open hole and down a chute into a wagon, wheelbarrow, or open pile. When closed, the forage continues past the opening and onward to other parts of the conveyor. Computer automation and a conveyor running the length of a feeding stall can permit the silage to be automatically dropped from above by each animal, with the amount dispensed customized for each location.\\r\\n\\r\\nSilos are hazardous, and people are killed or injured every year in the process of filling and maintaining them.[10]  The machinery used is dangerous and with tower silos workers can fall from the silo's ladder or work platform. Several fires have occurred over the years.\\r\\n\\r\\nFilling a silo requires parking two tractors very close to each other, both running at full power and with live PTO shafts, one powering the silo blower and the other powering a forage wagon unloading fresh-cut forage into the blower. The farmer must continually move around in this highly hazardous environment of spinning shafts and high-speed conveyors to check material flows and adjust speeds, and to start and stop all the equipment between loads.\\r\\n\\r\\nPreparation for filling a silo requires winching the unloader to the top, and any remaining forage at the base that the unloader could not pick up must be removed from the floor of the silo. This job requires that the farmer work directly underneath a machine weighing several tons suspended fifty feet or more overhead from a small steel cable.  Should the unloader fall, the farmer will likely be killed instantly.\\r\\n\\r\\nUnloading also poses its own special hazards, due to the requirement that the farmer regularly climb the silo to close an upper door and open a lower door, moving the unloader chute from door to door in the process. The fermentation of the silage produces methane gas which over time will outgas and displace the oxygen in the top of the silo. A farmer directly entering a silo without any other precautions can be asphyxiated by the methane, knocked unconscious, and silently suffocate to death before anyone else knows what has happened. It is either necessary to leave the silo blower attached to the silo at all times to use it when necessary to ventilate the silo with fresh air, or to have a dedicated electric fan system to blow fresh air into the silo, before anyone attempts to enter it.\\r\\n\\r\\nIn the event that the unloader mechanism becomes plugged, the farmer must climb the silo and directly stand on the unloader, reaching into the blower spout to dig out the soft silage. After clearing a plug, the forage needs to be forked out into an even layer around the unloader so that the unloader does not immediately dig into the pile and plug itself again. All during this process the farmer is standing on or near a machine that could easily kill them in seconds if it were to accidentally start up. This could happen if someone in the barn were to unknowingly switch on the unloading mechanism while someone is in the silo working on the unloader.\\r\\n\\r\\nOften, when unloading grain from an auger or other opening at the bottom of the silo, another worker will be atop the grain \\"walking it down\\", to ensure an even flow of grain out of the silo. Sometimes unstable pockets in the grain will collapse beneath the worker doing the walking; this is called grain entrapment as the worker can be completely sunk into the grain within seconds. Entrapment can also occur in moving grain, or when workers clear large clumps of grain that have become stuck on the side of the silo. This often results in death by suffocation.\\r\\n\\r\\nThere have also been many cases of silos and the associated ducts and buildings exploding. If the air inside becomes laden with finely granulated particles, such as grain dust, a spark can trigger an explosion powerful enough to blow a concrete silo and adjacent buildings apart, usually setting the adjacent grain and building on fire.  Sparks are often caused by (metal) rubbing against metal ducts; or due to static electricity produced by dust moving along the ducts when extra dry.\\r\\n\\r\\nThe two main problems which will necessitate silo cleaning in dry-matter silos and bins are bridging and rat-holing. Bridging occurs when the material interlaces over the unloading mechanism at the base of the silo and blocks the flow of stored material by gravity into the unloading system.  Rat-holing occurs when the material starts to adhere to the side of the silo. This will reduce the operating capacity of a silo as well as leading to cross-contamination of newer material with older material. There are a number of ways to clean a silo and many of these carry their own risks. However, since the early 1990s acoustic cleaners have become available. These are non-invasive, have minimum risk, and can offer a very cost-effective way to keep a small particle silo clean.[citation needed]","input":"What is the purpose of a grain silo?"},{"output":"Wolfe","context":"The Siege of Louisbourg was a pivotal operation of the Seven Years' War (known in the United States as the French and Indian War) in 1758 that ended the French colonial era in Atlantic Canada and led directly to the loss of Quebec in 1759 and the remainder of French North America the following year.[4]\\r\\n\\r\\n\\r\\nThe British government realized that with the Fortress of Louisbourg under French control, the Royal Navy could not sail up the St. Lawrence River unmolested for an attack on Quebec. After an expedition against Louisbourg in 1757 led by Lord Loudon was turned back due to a strong French naval deployment, the British under the leadership of William Pitt resolved to try again with new commanders.\\r\\nPitt assigned the task of capturing the fortress to Major General Jeffrey Amherst. Amherst's brigadiers were Charles Lawrence, James Wolfe and Edward Whitmore, and command of naval operations was assigned to Admiral Edward Boscawen. The chief engineer was John Henry Bastide who had been present at the first siege of Louisbourg in 1745 and was chief engineer at Fort St Philip, Minorca, in 1756 when the British had surrendered the fort and island to the French after a long siege.\\r\\nAs they had in 1757, the French planned to defend Louisbourg by means of a large naval build-up. However, the British blockaded the French fleet sailing from Toulon when it arrived in Cartagena, and defeated a French relief force at the Battle of Cartagena. The French consequently abandoned their attempt to reinforce Louisbourg from the Mediterranean, and only 11 ships were available to oppose the British off Louisbourg. Most of the cannons and men were moved inside the fort and five ships (Appolon, Fidle, Chvre, Biche, Diane) were sunk to block the entrance to the harbour.[5] On 9 July, Echo tried to slip out of the harbour under the cover of a dense fog, but was intercepted and seized by HMS Scarborough and HMS Junon. This left the French with only five half-empty ships in the harbour?: Clbre (64), Entreprenant (74), Capricieux (64), Prudent (74) and Bienfaisant (64).\\r\\n Nova Scotia portal\\r\\n History of Canada portal\\r\\nBritish forces assembled at Halifax, Nova Scotia where army and navy units spent most of May training together as the massive invasion fleet came together. After a large gathering at the Great Pontack, on 29 May the Royal Navy fleet departed from Halifax for Louisbourg. The fleet consisted of 150 transport ships and 40 men-of-war. Housed in these ships were almost 14,000 soldiers, almost all of whom were regulars (with the exception of four companies of American rangers). The force was divided into three divisions: Red, commanded by James Wolfe, Blue, commanded by Charles Lawrence and White commanded by Edward Whitmore. On 2 June the British force anchored in Gabarus Bay, 3 miles (4.8?km) from Louisbourg.\\r\\nThe French commander (and governor of ?le-Royale (New France), the Chevalier de Drucour, had at his disposal some 3,500 regulars as well as approximately 3,500 marines and sailors from the French warships in the harbour. However, unlike the previous year, the French navy was unable to assemble in significant numbers, leaving the French squadron at Louisbourg outnumbered five to one by the British fleet. Drucour ordered trenches to be prepared and manned by some 2,000 French troops, along with other defences, such as an artillery battery, at Kennington Cove.\\r\\nWeather conditions in the first week of June made any landing impossible and the British were only able to mount a bombardment of the improvised shore defenses of Gabarus Bay from a frigate. However, conditions improved, and at daybreak on 8 June Amherst launched his assault using a flotilla of large boats, organized in seven divisions, each commanded by one of his brigadiers. French defenses were initially successful and after heavy losses, Wolfe ordered a retreat. However, at the last minute, a boatload of light infantry in Wolfe's division (i.e., members of Rogers Rangers) found a rocky inlet protected from French fire and secured a beachhead. Wolfe redirected the rest of his division to follow. Outflanked, the French retreated rapidly back to their fortress.\\r\\nContinuing heavy seas and the difficulty inherent to moving siege equipment over boggy terrain delayed the commencement of the formal siege. In the meantime, Wolfe was sent with 1,220 picked men around the harbour to seize Lighthouse Point, which dominated the harbour entrance. This he did on 12 June. After eleven days, on 19 June, the British artillery batteries were in position and the orders were given to open fire on the French. The British battery consisted of seventy cannons and mortars of all sizes. Within hours, the guns had destroyed walls and damaged several buildings.\\r\\nOn 21 July a mortar round from a British gun on Lighthouse Point struck a 64-gun French ship of the line, Le Clbre , and set it ablaze. A stiff breeze fanned the fire, and shortly after Le Clbre caught fire, two other French ships, L'Entreprenant and Le Capricieux, had also caught fire. L'Entreprenant sank later in the day, depriving the French of the largest ship in the Louisbourg fleet.\\r\\nThe next major blow to French morale came on the evening of 23 July, at 10:00. A British \\"hot shot\\" set the King's Bastion on fire. The King's Bastion was the fortress headquarters and the largest building in North America in 1758. Its destruction eroded confidence and reduced morale in the French troops and their hopes to lift the British siege.\\r\\nMost historians regard the British actions of 25 July as the \\"straw that broke the camel's back\\". Using a thick fog as cover, Admiral Boscawen sent a cutting-out party to destroy the last two French ships in the harbour. The British raiders eliminated these two French ships of the line, capturing Bienfaisant and burning Prudent, thus clearing the way for the Royal Navy to enter the harbour. James Cook, who later became famous as an explorer, took part in this operation and recorded it in his ship's log book.[6]\\r\\nOn 26 July the French surrendered. Having fought a spirited defence, the French expected to be accorded the honours of war, as they had given to the surrendering British at the Battle of Minorca. However, Amherst refused, tales of the atrocities supposedly committed by France's native allies at the surrender of Fort Oswego and Fort William Henry probably fresh in his mind[citation needed]. The defenders of Louisbourg were ordered to surrender all of their arms, equipment and flags. These actions outraged Drucour, but because the safety of the non-combatant inhabitants of Louisbourg depended upon him he reluctantly accepted the terms of surrender. The Cambis regiment refused to honour the terms of surrender, breaking its muskets and burning its regimental flags rather than hand them over to the British victors.[7] Brigadier-General Whitmore was appointed the new Governor of Louisbourg, and remained there with four regiments.[8]\\r\\nLouisbourg had held out long enough to prevent an attack on Quebec in 1758. However the fall of the fortress led to the loss of French territory across Atlantic Canada. From Louisbourg, British forces spent the remainder of the year routing French forces and occupying French settlements in what is today New Brunswick, Prince Edward Island and Newfoundland. The second wave of the Acadian expulsion began. The British engaged in the St. John River Campaign, the Cape Sable Campaign, the Petitcodiac River Campaign, the Ile Saint-Jean Campaign, and the removal of Acadians in the Gulf of St. Lawrence Campaign (1758).\\r\\nThe loss of Louisbourg deprived New France of naval protection, opening the Saint Lawrence to attack. Louisbourg was used in 1759 as the staging point for General Wolfe's famous Siege of Quebec ending French rule in North America. Following the surrender of Quebec, British forces and engineers set about methodically destroying the fortress with explosives, ensuring that it could not return to French possession a second time in any eventual peace treaty. By 1760, the entire fortress was reduced to mounds of rubble. In 1763 the Treaty of Paris saw France formally cede Canada, including Cape Breton Island, to the British. In 1768 the last of the British garrison departed along with most of the remaining civilian inhabitants.[9]\\r\\n[10]\\r\\nEnglish propaganda against Louisbourg and French Canada in 1755\\r\\nEdward Boscawen Medal\\r\\nThe fortress today, as seen from the harbour\\r\\nCannon from Le Prudent, currently at the Battlefields Park, Quebec City\\r\\nFrench mortar used during the siege, displayed at the Canadian War Museum, Ottawa.\\r\\nLouisbourg Canons, Toronto\\r\\nMap of Louisbourg (1758)\\r\\nPrimary sources\\r\\nEndnotes","input":"Who was the british brigadier general that captured lighthouse?"},{"output":"Elon Reeve Musk","context":"","input":"Telsa was cofounded by what south african born inventor?"},{"output":"around July 4","context":"The perihelion (/?p?r??hi?li?n/) of any orbit of a celestial body about the Sun is the point where the body comes nearest to the Sun. It is the opposite of aphelion (/?p?hi?li?n/), which is the point in the orbit where the celestial body is farthest from the Sun.[1] Apogee means it is the moon far from earth Perigee means that the moon is near earth\\r\\n\\r\\n\\r\\nThe words perihelion and aphelion were coined by Johannes Kepler[2] to describe the orbital motion of the planets. The words are formed from the prefixes peri- (Greek: ?, near) and apo- (Greek: ??, away from) affixed to the Greek word for the sun, ??.[3]\\r\\nPerihelion and aphelion are sometimes incorrectly used for the orbits of objects about bodies other than the Sun. The correct terms are:\\r\\nAccording to Kepler's first law of planetary motion, all planets, comets, and asteroids in the Solar System have approximately elliptical orbits around the Sun.[4] It is only approximate because of perturbations due to the gravity of other bodies. Every ellipse has two focus points, and the Sun is at one of these focus points for the elliptical orbits of its satellites. Hence, an orbiting body has a closest and a farthest point from its parent object, that is, a perihelion and an aphelion. Each extreme is known as an apsis.\\r\\nOrbital eccentricity measures the flatness (departure from a perfect circle) of the orbit.\\r\\nEarth is about 147.1 million kilometers (91.4 million miles) from the Sun at perihelion around January 3, in contrast to about 152.1 million kilometers (94.5 million miles) at aphelion around July 4  a difference of about 5.0 million kilometers (3.1 million miles). (These dates change over time due to precession and other orbital factors, which follow cyclical patterns known as Milankovitch cycles. For a table of these dates for various years, see Apsis.)\\r\\nBecause of the increased distance at aphelion, only 93.55% of the solar radiation from the Sun falls on a given area of land as does at perihelion. However, this fluctuation does not account for the seasons,[5] as it is summer in the northern hemisphere when it is winter in the southern hemisphere and vice versa. Instead, seasons result from the tilt of Earth's axis, which is 23.4 degrees away from perpendicular to the plane of Earth's orbit around the sun. Winter falls on the hemisphere where sunlight strikes least directly, and summer falls where sunlight strikes most directly, regardless of the Earth's distance from the Sun.\\r\\nIn the northern hemisphere, summer occurs at the same time as aphelion. Despite this, there are larger land masses in the northern hemisphere, which are easier to heat than the seas. Consequently, summers are 2.3?C (4?F) warmer in the northern hemisphere than in the southern hemisphere under similar conditions.[6]","input":"When is the earth largest distance from sun?"},{"output":"1,814","context":"Gaylord Texan Resort & Convention Center is a hotel and convention center, opened in Grapevine, Texas minutes from Dallas - Fort Worth, on April 4, 2004. It has 486,000?sq?ft (45,200?m2) of meeting space and 1,814 guest rooms.\\r\\nGaylord Texan is owned by Ryman Hospitality Properties (formerly known as Gaylord Entertainment Company), and operated by Marriott International. It is a sister hotel to the Gaylord Opryland Resort & Convention Center, Gaylord National Resort & Convention Center, and Gaylord Palms Resort & Convention Center.\\r\\nIn 2004, 2005, 2009 and 2017 it was the location of QuakeCon, a major gaming convention based in Texas.[3]\\r\\nThe resort hosted the National Conference of the Technology Student Association from June 28, 2015 through July 2, 2015.[4]\\r\\nThe resort is the official hotel of the Dallas Cowboys NFL team.[5]\\r\\nThe hotel was expanded with a new vineyard tower in 2018. The tower has 303 luxury guest rooms, an outdoor terrace offering spectacular views of Lake Grapevine and 86,000 square feet of carpeted meeting space including a 30,000-square-foot ballroom, 30,000 square feet of breakout space and 26,000 square feet of pre-function space.\\r\\nThe resort features an annual event with different themes each year. The event is called ICE! and Lone Star Christmas and is sponsored by different corporations every year. Each annual exhibit is a different holiday theme such as Charlie Brown, Nutcracker, Shrek, and Frosty the Snowman.","input":"How many rooms are in the gaylord texan?"},{"output":"26 June 1997","context":"","input":"When was the first harry potter book released?"},{"output":"Yogi Adityanath","context":"The Chief Minister of Uttar Pradesh (UP), a North Indian state, is the head of the Government of Uttar Pradesh. As per the Constitution of India, the governor is the state's de jure head, but de facto executive authority rests with the chief minister. Following elections to the Uttar Pradesh Legislative Assembly, the governor usually invites the party (or coalition) with a majority of seats to form the government. The governor appoints the chief minister, whose council of ministers are collectively responsible to the assembly. Given that he has the confidence of the assembly, the chief minister's term is for five years and is subject to no term limits.[1]\\r\\nOn 26 January 1950 Govind Ballabh Pant, Premier of United Provinces, became the first Chief Minister of the newly renamed Uttar Pradesh. Including him, 11 out of UP's 21 chief ministers belonged to the Indian National Congress. Among these is V. P. Singh, a future Prime Minister of India, as was Charan Singh of the Rashtriya Lok Dal. UP has also had two women chief ministersSucheta Kriplani and Mayawati. Akhilesh Yadav of the Samajwadi Party served as the Chief Minister of Uttar Pradesh from 2012 to 2017, having assumed office at the age of 38, he is the youngest person to have held the office. On ten occasions, most recently in 2002, the state has come under President's rule, leaving the office of chief minister vacant.\\r\\nYogi Adityanath of the Bharatiya Janata Party has served as the incumbent chief minister since 19 March 2017.\\r\\n\\r\\n\\r\\nThe United Provinces, headquartered in Allahabad was a province of British India that comprised present day Uttar Pradesh and Uttarakhand. Under the Government of India Act, 1935, a bicameral legislature was set up with a legislative assembly and a legislative council.","input":"Who is the chief minister of uttara pradesh?"},{"output":"West Africa near the present-day southwestern border of Nigeria and Cameroon","context":"Bantu peoples is used as a general label for the 300ÿ600 ethnic groups in Africa who speak Bantu languages.[1] They inhabit a geographical area stretching east and southward from Central Africa across the African Great Lakes region down to Southern Africa.[1] Bantu is a major branch of the NigerÿCongo language family spoken by most populations in Africa. There are about 650 Bantu languages by the criterion of mutual intelligibility,[2] though the distinction between language and dialect is often unclear, and Ethnologue counts 535 languages.[3]\\r\\nAround 3,000 years ago, speakers of the Proto-Bantu language group began a millennia-long series of migrations eastward from their homeland between West Africa and Central Africa, at the border of eastern Nigeria and Cameroon.[4] This Bantu expansion first introduced Bantu peoples to central, southern and southeastern Africa, regions they had previously been absent from. The proto-Bantu migrants in the process assimilated and/or displaced a number of earlier inhabitants that they came across, such as Pygmy and Khoisan populations in the centre and south, respectively. They also encountered some Afro-Asiatic outlier groups in the southeast who had been there for centuries, having migrated from Northeast Africa.[5][6]\\r\\nIndividual Bantu groups today often comprise millions of people. Among these are the Ndebele and Shona of Zimbabwe with 14.2 million people; the Luba of the Democratic Republic of the Congo, with over 13.5 million people; the Zulu of South Africa, with over 10 million people; the Sukuma of Tanzania, with around eight million people; and the Kikuyu of Kenya, with over six million people. Although only around five million individuals speak the Arabic-influenced Swahili language as their mother tongue,[7] it is used as a lingua franca by over 100 million people throughout Southeast Africa.[8] Swahili also serves as one of the official languages of the African Union.\\r\\n\\r\\n\\r\\nThe word Bantu, and its variations, means \\"people\\" or \\"humans\\". The root in Proto-Bantu is reconstructed as *-ntu. Versions of the word Bantu (that is, the root plus the class 2 noun class prefix *ba-) occur in all Bantu languages: for example, as watu in Swahili; bantu in Kikongo; anthu in Chichewa; batu in Lingala; bato in Kiluba; bato in Duala; abanto in Gusii; and? in Kamba and Kikuyu; abantu in Kirundi, Kinyarwanda, Zulu, Xhosa, Runyakitara,[9] and Ganda; wandru in Shingazidja; abantru in Mpondo and Ndebele; b?tfu in Phuthi; bantfu in Swati; banu in Lala; vanhu in Shona and Tsonga; batho in Sesotho, Tswana and Northern Sotho; antu in Meru; andu in Embu; vandu in some Luhya dialects; vhathu in Venda; and bhandu in Nyakyusa.\\r\\nCurrent scholarly understanding places the ancestral proto-Bantu homeland in West Africa near the present-day southwestern border of Nigeria and Cameroon c.?4,000 years ago (2000?B.C.), and regards the Bantu languages as a branch of the NigerÿCongo language family.[13] This view represents a resolution of debates in the 1960s over competing theories advanced by Joseph Greenberg and Malcolm Guthrie, in favor of refinements of Greenberg's theory. Based on wide comparisons including non-Bantu languages, Greenberg argued that Proto-Bantu, the hypothetical ancestor of the Bantu languages, had strong ancestral affinities with a group of languages spoken in Southeastern Nigeria. He proposed that Bantu languages had spread east and south from there, to secondary centers of further dispersion, over hundreds of years.\\r\\nUsing a different comparative method focused more exclusively on relationships among Bantu languages, Guthrie argued for a single Central African dispersal point spreading at a roughly equal rate in all directions. Subsequent research on loanwords for adaptations in agriculture and animal husbandry and on the wider NigerÿCongo language family rendered that thesis untenable. In the 1990s, Jan Vansina proposed a modification of Greenberg's ideas, in which dispersions from secondary and tertiary centers resembled Guthrie's central node idea, but from a number of regional centers rather than just one, creating linguistic clusters.[14]\\r\\nIt is unclear exactly when the spread of Bantu-speakers began from their core area as hypothesized c. 4,000 years ago (2000 B.C.). By 3,500 years ago (1500?B.C.) in the west, Bantu-speaking communities had reached the great Central African rain forest, and by 2,500 years ago (500?B.C.) pioneering groups had emerged into the savannahs to the south, in what are now the Democratic Republic of the Congo, Angola, and Zambia. Another stream of migration, moving east, by 3,000 years ago (1000?B.C.) was creating a major new population center near the Great Lakes of East Africa, where a rich environment supported a dense population. Movements by small groups to the southeast from the Great Lakes region were more rapid, with initial settlements widely dispersed near the coast and near rivers, due to comparatively harsh farming conditions in areas farther from water. Pioneering groups had reached modern KwaZulu-Natal in South Africa by 300 A.D. along the coast, and the modern Northern Province (encompassed within the former province of the Transvaal) by 500 A.D.[15]\\r\\nBefore the expansion of farming and herding peoples, including those speaking Bantu languages, Africa south of the equator was populated by neolithic hunting and foraging peoples. Some of them were ancestral to proto-Khoisan-speaking peoples, whose modern hunter-forager and linguistic descendants, the Khoekhoe and San, occupy the arid regions around the Kalahari desert. The Hadza and Sandawe populations in Tanzania comprise the other modern hunter-forager remnant in Africa of these proto-Khoisan-speaking peoples.\\r\\nOver a period of many centuries, most hunting-foraging peoples were displaced and absorbed by incoming Bantu-speaking communities, as well as by Ubangian, Nilotic, and Sudanic language-speakers in North Central and Eastern Africa. The Bantu expansion was a long series of physical migrations, a diffusion of language and knowledge out into and in from neighboring populations, and a creation of new societal groups involving inter-marriage among communities and small groups moving to communities and small groups moving to new areas.\\r\\nAfter their movements from their original homeland in West Africa, Bantus also encountered in East Africa peoples of Afro-Asiatic (mainly Cushitic) and Nilo-Saharan (mainly Nilotic and Sudanic) ancestral origin. As cattle terminology in use amongst the few modern Bantu pastoralist groups suggests, the Bantu migrants would acquire cattle from their new Cushitic neighbors. Linguistic evidence also indicates that Bantus likely borrowed the custom of milking cattle directly from Cushitic peoples in the area.[16] Later interactions between Bantu and Cushitic peoples resulted in Bantu groups with significant Cushitic ethnic admixture, such as the Tutsi of the African Great Lakes region; and culturo-linguistic influences, such as the Herero herdsmen of southern Africa.[17][18]\\r\\nOn the coastal section of East Africa, another mixed Bantu community developed through contact with Muslim Arab and Persian traders. The Swahili culture that emerged from these exchanges evinces many Arab and Islamic influences not seen in traditional Bantu culture, as do the many Afro-Arab members of the Bantu Swahili people. With its original speech community centered on the coastal parts of Zanzibar, Kenya, and Tanzania ÿ a seaboard referred to as the Swahili Coast ÿ the Bantu Swahili language contains many Arabic loan-words as a result of these interactions.[19]\\r\\nBetween the 14th and 15th centuries, Bantu-speaking states began to emerge in the Great Lakes region in the savannah south of the Central African rain forest. On the Zambezi river, the Monomatapa kings built the famous Great Zimbabwe complex, a civilisation of what are today referred to as the Shona people. From the 16th century onward, the processes of state formation amongst Bantu peoples increased in frequency. This was probably due to denser population (which led to more specialized divisions of labor, including military power, while making emigration more difficult); to increased interaction amongst Bantu-speaking communities with Chinese, European, Indonesian, and Arab traders on the coasts; to technological developments in economic activity; and to new techniques in the political-spiritual ritualization of royalty as the source of national strength and health.[20]\\r\\nKongo youth and adults in Kinshasa, Democratic Republic of the Congo\\r\\nA Kikuyu woman in Kenya\\r\\nA Makua mother and child in Mozambique\\r\\nBubi girls in Equatorial Guinea\\r\\nBetween the 14th and 15th centuries, Bantu states began to emerge in the Great Lakes region in the savanna south of the Central African rain-forest. In Southern Africa on the Zambezi river, the Monomatapa kings built the famous Great Zimbabwe complex, the largest of over 200 such sites in Southern Africa, such as Bumbusi in Zimbabwe and Manyikeni in Mozambique. From the 16th century onward, the processes of state formation among Bantu peoples increased in frequency. Some examples of such Bantu states include: in Central Africa, the Kingdom of Kongo,[21] Lunda Empire,[22] and Luba Empire[23] of Angola, the Republic of Congo, and the Democratic Republic of Congo; in the Great Lakes Region, the Buganda[24] and Karagwe[24] Kingdoms of Uganda and Tanzania; and in Southern Africa, the Mutapa Empire,[25] Rozwi Empire,[26] and the Danamombe, Khami, and Naletale Kingdoms of Zimbabwe and Mozambique.[25]\\r\\nToward the 18th and 19th centuries, the flow of Zanj (Bantu) slaves from Southeast Africa increased with the rise of the Omani Sultanate of Zanzibar, based in Zanzibar, Tanzania. With the arrival of European colonialists, the Zanzibar Sultanate came into direct trade conflict and competition with Portuguese and other Europeans along the Swahili Coast, leading eventually to the fall of the Sultanate and the end of slave trading on the Swahili Coast in the mid-20th century.","input":"In what area of africa did the early bantu originate?"},{"output":"potato","context":"Dum Aloo (also spelled as Dam Aloo) or Alu Dum (Hindi: ?? ???) is a potato based dish, it is a part of the traditional Kashmiri Pandit cuisine,[1][2] from the Kashmir Valley, in the Indian state of Jammu and Kashmir. The potatoes, usually smaller ones, are first deep fried, then cooked slowly at low flame in a gravy with spices.[3] Dum Aloo is a popular recipe cooked throughout India. In Bengal, it is a specialty dish eaten mostly with Luchi and is known as \\"Aloor dum\\".\\r\\nPeel, wash and prick baby potatoes all over with the help of a fork. In some recipes the potatoes are kept unpeeled. In this case they should be washed properly. Keep the potatoes in salted water for fifteen minutes. Heat sufficient oil in a kadai and deep-fry the potatoes on medium heat till golden brown. Drain and place on an absorbent paper and keep aside. Heat mustard oil in a pan to smoking point. Cool and heat again. Add cumin seeds and asafoetida and cook on medium heat till the cumin seeds change colour. Add onion and saut for three to four minutes or till the onion turns light golden. Add ginger-garlic paste and saut for a minute. Add a little water and stir. Add tomatoes and saut for a minute. Add a little water and cook till tomatoes turn pulpy. Add red chili powder, cumin powder, coriander powder, turmeric powder and a little water and stir. Add fried potatoes and stir to mix well and cook for two minutes. Add a little water and salt. Mix well and simmer for five minutes or till the potatoes absorb the gravy. Add garam masala powder and stir. Remove from heat and serve hot garnished with coriander leaves and ginger strips. It can be served with jeera rice, fried rice, or rotis. [4]","input":"What is the main ingredient of dum aloo?"},{"output":"March 10, 1997","context":"","input":"When did buffy the vampire slayer first air?"},{"output":"September 10, 1990","context":"Quincy Jones\\r\\nAndy Borowitz\\r\\nSusan Borowitz\\r\\nKevin Wendle (Season 1)\\r\\nWinifred Hervey (Seasons 2ÿ3)\\r\\nGary H. Miller (Season 4ÿ5)\\r\\nCheryl Gard (Mid-Late Season 5)\\r\\nJeff Pollack\\r\\nWill Smith (Season 6)\\r\\nThe Fresh Prince of Bel-Air is an American sitcom that originally aired on NBC from September 10, 1990, to May 20, 1996. The show stars Will Smith as a fictionalized version of himself, a street-smart teenager from West Philadelphia who is sent to move in with his wealthy aunt and uncle in their Bel Air mansion after getting into a fight on a local basketball court. In the series, his lifestyle often clashes with the lifestyle of his relatives in Bel Air. The series ran for six seasons and aired 148 episodes.[1][2]\\r\\n\\r\\n\\r\\nIn December 1989, NBC approached Will Smith, a popular rapper during the late 1980s.[3] The pilot episode began taping on May 1, 1990.[4] Season 1 first aired in September 1990, and ended in May 1991. The series finale was taped on Thursday, March 21, 1996.[5][6]\\r\\nThe theme song \\"Yo Home to Bel Air\\" was written and performed by Smith under his stage name, The Fresh Prince. The music was composed by Quincy Jones, who is credited with Smith at the end of each episode. The music often used to bridge scenes together during the show is based on a similar chord structure.\\r\\nThe theme song and opening sequence set the premise of the show. Will Smith is a street smart teenager, born and raised in West Philadelphia. While playing basketball, Will misses a shot and the ball hits a group of people, causing a confrontation that frightens his mother, who sends him to live with his aunt and uncle in the opulent neighborhood of Bel Air, Los Angeles.\\r\\nWill's working-class background ends up clashing in various humorous ways with the upper class world of the Banks family ÿ Will's uncle Phil and aunt Vivian and their children, Will's cousins: Hilary, Carlton, and Ashley.\\r\\nDuring the fall 1991ÿ1992 season, NBC gained two hit television shows to anchor their Monday night lineup (Blossom aired immediately after The Fresh Prince of Bel-Air). To gain popularity between the two shows, Will Smith appeared in the Blossom episode \\"I'm with the Band\\" as himself under his rap stage name, The Fresh Prince. That same season, Karyn Parsons appeared in the Blossom episode \\"Wake Up Little Suzy\\" as Hilary Banks. Parsons also appeared in the Patti LaBelle sitcom Out All Night as Hilary.\\r\\nIn the House and Fresh Prince were both executive produced by Winifred Hervey, David Salzman and Quincy Jones. During the second season's first episode, Alfonso Ribeiro and Tatyana Ali appeared as their Fresh Prince characters (Carlton and Ashley Banks) in the crossover episode \\"Dog Catchers\\". Later that season, James Avery (Phillip Banks) appeared as a mediator in the episode \\"Love on a One-Way Street\\".\\r\\nIn the Season 4 episode \\"My Pest Friend's Wedding\\", James Avery and Daphne Maxwell Reid (Vivian Banks) guest starred as Dr. Maxwell Stanton's parents (Stanton was played by Ribeiro). Both Avery and Reid portrayed the parents of Ribeiro's Fresh Prince character. Joseph Marcell, who played the wisecracking Geoffrey Butler on Fresh Prince, also appeared as an officiating minister in the same episode.\\r\\nThe series was produced by NBC Productions in association with The Stuffed Dog Company and Quincy Jones Entertainment (later Quincy Jones-David Salzman Entertainment in 1993). After the show was released to syndication in 1994, the series has been distributed by Warner Bros. Television, which continues to distribute the show worldwide (although NBCUniversal does own the series' copyright). WGN America was the first cable channel to acquire the series in 1997, TBS acquired the series a year later in 1998; both channels carried the series until the fall of 2003, though TBS reacquired the series in 2007.\\r\\nThe theme song was shown in the original TBS run, but after TBS re-acquired Fresh Prince in 2007, the opening credits were truncated and the theme song removed and replaced with the instrumental version used as the show's closing theme; these versions also re added portions of scenes cut from the original syndicated prints for some episodes, particularly those from Seasons 3 to 6. TBS continues to air the series today, early in the morning. Reruns also aired on WPIX-TV back to back weeknights at 6 pm & 6:30 pm EST from 1994 until 2000, and as a weekday basis at 5 pm from 2000 to 2005, sometimes on weekends until 2007. But, the series was still rerunning on The WB's affiliation WPIX-TV until 2006. While moving The WB to Nick at Nite, it was airing to 2006-2009 and moved to Disney XD.\\r\\nIn July 2009, Disney XD acquired the rights to the series, though it was quickly moved from prime time to late night airings, and only episodes from Seasons 1 to 3 are aired, mainly because those episodes are more appropriate for young viewers and does not contain as many mature themes, sexual content and strong language as later episodes. But in August 2010, Disney XD stopped airing the show. ABC Family (now called Freeform) acquired the series in September 2008, though airing all 148 episodes; originally airing exclusively on Saturday nights, the series was added to ABC Family's weekday line up in late 2009. On September 29, 2014, Disney/ABC rights to the show expired. Viacom Media Networks got the series back.\\r\\nIn October 2014, Viacom Media Networks also gave the series to BET, it also will air on Centric. It was previously aired on MTV's retro block. Also, the series reruns on VH1. On November 2, 2015, the series started airing on the Family Channel in Canada. On January 1, 2017, the series was added to Netflix in the United Kingdom and Ireland. In 2014, Fresh Prince Of Bel Air started airing again in Nickelodeon\`s block night channel, Nick at Nite. In 2017, the series began from the beginning on the 5* channel in the UK. MeTV will start airing the show in September 2018.\\r\\nWarner Home Video has released the complete series, seasons 1 to 6 on DVD in Region 1.[8] Seasons 1 to 4 have been released in Regions 2 and 4. Seasons 5 to 6 have been released in Region 2 in Germany, and in the complete series boxset in the United Kingdom. The episodes and DVD menus are in English; only the DVD packaging is in German.\\r\\nOn August 13, 2015, it was reported that a reboot of the show was in development by Overbrook Entertainment, with Will Smith serving as a producer.[23][24] In August 2016, during a promotional interview with the E! television network, for his then upcoming film Suicide Squad, Smith had denied that a reboot was in development, saying that it would happen \\"...pretty close to when Hell freezes over.\\"[25]","input":"When did fresh prince of bel air start?"},{"output":"December 29, 1970","context":"The Occupational Safety and Health Act of 1970 is a US labor law governing the federal law of occupational health and safety in the private sector and federal government in the United States. It was enacted by Congress in 1970 and was signed by President Richard Nixon on December 29, 1970.[1] Its main goal is to ensure that employers provide employees with an environment free from recognized hazards, such as exposure to toxic chemicals, excessive noise levels, mechanical dangers, heat or cold stress, or unsanitary conditions. The Act created the Occupational Safety and Health Administration (OSHA) and the National Institute for Occupational Safety and Health (NIOSH).\\r\\nThe Act can be found in the United States Code at title 29, chapter 15.\\r\\n\\r\\n\\r\\nEfforts by the federal government to ensure workplace health and safety were minimal until the passage of OSHA. The American system of mass production encouraged the use of machinery, while the statutory regime did nothing to protect workplace safety. For most employers, it was cheaper to replace a dead or injured worker than it was to introduce safety measures.[2][3][4] Tort law provided little recourse for relief for the survivors of dead workers or for injured employees.[5] After the Civil War, some improvements were made through the establishment of state railroad and factory commissions, the adoption of new technology (such as the railway air brake), and more widespread availability of life insurance. But the overall impact of these improvements was minimal.[4]\\r\\nThe first federal safety legislation was enacted in the Progressive period. In 1893, Congress passed the Safety Appliance Act, the first federal statute to require safety equipment in the workplace (the law applied only to railroad equipment, however).[4] In 1910, in response to a series of highly publicized and deadly mine explosions and collapses, Congress established the United States Bureau of Mines to conduct research into mine safety (although the Bureau had no authority to regulate mine safety).[6] Backed by trade unions, many states also enacted workers' compensation laws which discouraged employers from permitting unsafe workplaces.[5] These laws, as well as the growing power of labor unions and public anger toward poor workplace safety, led to significant reductions in worker accidents for a time.[4]\\r\\nIndustrial production increased significantly in the United States during World War II, and industrial accidents soared. Winning the war took precedence over safety, and most labor unions were more concerned with maintaining wages in the face of severe inflation than with workplace health and safety.[7] After the war ended, however, workplace accident rates remained high and began to rise. In the two years preceding OSHA's enactment, 14,000 workers died each year from workplace hazards, and another 2 million were disabled or harmed.[8] Additionally, the \\"chemical revolution\\" introduced a vast array of new chemical compounds to the manufacturing environment. The health effects of these chemicals were poorly understood, and workers received few protections against prolonged or high levels of exposure.[9][10] While a few states, such as California and New York, had enacted workplace safety as well as workplace health legislation, most states had not changed their workplace protection laws since the turn of the century.[11]\\r\\nIn the mid-1960s, growing awareness of the environmental impact of many chemicals had led to a politically powerful environmental movement. Some labor leaders seized on the public's growing unease over chemicals in the environment, arguing that the effect of these compounds on worker health was even worse than the low-level exposure plants and animals received in the wild.[12][13] On January 23, 1968, President Lyndon B. Johnson submitted a comprehensive occupational health and safety bill to Congress.[9] Led by the United States Chamber of Commerce and the National Association of Manufacturers, the legislation was widely opposed by business.[14] Many labor leaders, including the leadership of the AFL-CIO, supported the legislation, including testifying in support at congressional hearings.[15] The legislation died in committee.[7]\\r\\nOn April 14, 1969, President Richard Nixon introduced two bills into Congress which would have also protected worker health and safety.[7] The Nixon legislation was much less prescriptive than the Johnson bill, and workplace health and safety regulation would be advisory rather than mandatory.[9] However, Representative James G. O'Hara and Senator Harrison A. Williams introduced a much stricter bill similar to the Johnson legislation of the year before.[7]\\r\\nCompanion legislation introduced in the House also imposed an all-purpose \\"general duty\\" clause on the enforcing agency as well.[7] With the stricter approach of the Democratic bill apparently favored by a majority of both chambers,[7] and unions now strongly supporting a bill,[12][13] Republicans introduced a new, competing bill.[7] The compromise bill established the independent research and standard-setting board favored by Nixon, while creating a new enforcement agency. The compromise bill also gave the Department of Labor the power to litigate on the enforcement agency's behalf (as in the Democratic bill).[7] In November 1970, both chambers acted: The House passed the Republican compromise bill, while the Senate passed the stricter Democratic bill (which now included the general duty clause).[7]\\r\\nA conference committee considered the final bill in early December 1970. Union leaders pressured members of the conference committee to place the standard-setting function in the Department of Labor rather than an independent board. In return, unions agreed to let an independent review commission have veto power over enforcement actions.[14] Unions also agreed to removal of a provision in the legislation which would have let the Secretary of Labor shut down plants or stop manufacturing procedures which put workers in \\"imminent danger\\" of harm.[14] In exchange for a Republican proposal to establish an independent occupational health and safety research agency, Democrats won inclusion of the \\"general duty\\" clause and the right for union representatives to accompany a federal inspector during inspections.[14] The conference committee bill passed both chambers on December 17, 1970, and President Nixon signed the bill on December 29, 1970.[7] According to the New York Times, labor and environment activist Tony Mazzocchi was a \\"principal force behind the legislation\\".[16]\\r\\nThe Act went into effect on April 28, 1971 (now celebrated as Workers' Memorial Day by American labor unions).[17][18]\\r\\nIn passing the Act, Congress declared its intent \\"to assure so far as possible every working man and woman in the Nation safe and healthful working conditions and to preserve our human resources.\\"[19]\\r\\nThe Act created the Occupational Safety and Health Administration (OSHA), an agency of the Department of Labor. OSHA was given the authority both to set and enforce workplace health and safety standards.[9] The Act also created the independent Occupational Safety and Health Review Commission to review enforcement priorities, actions and cases.[9]\\r\\nThe Act also established the National Institute for Occupational Safety and Health (NIOSH), an independent research institute in the then Department of Health, Education & Welfare now under-Centers for Disease Control and Prevention.[9]\\r\\nThe Act defines an employer to be any \\"person engaged in a business affecting commerce who has employees, but does not include the United States or any state or political subdivision of a State.\\" The Act applies to employers as diverse as manufacturers, construction companies, law firms, hospitals, charities, labor unions and private schools.\\r\\nChurches and other religious organizations are covered if they employ workers for secular purposes. The Act excludes the self-employed, family farms, workplaces covered by other federal laws (such as mining, nuclear weapons manufacture, railroads and airlines) and state and local governments (unless state law permits otherwise). The Act covers federal agencies and the United States Postal Service.[20]\\r\\nSection 5 of the Act contains the \\"general duty clause.\\" The \\"general duty clause\\" requires employers to 1) Maintain conditions or adopt practices reasonably necessary and appropriate to protect workers on the job; 2) Be familiar with and comply with standards applicable to their establishments; and 3) Ensure that employees have and use personal protective equipment when required for safety and health.[20] OSHA has established regulations for when it may act under the \\"general duty clause.\\" The four criteria are 1) There must be a hazard; 2) The hazard must be a recognized hazard (e.g., the employer knew or should have known about the hazard, the hazard is obvious, or the hazard is a recognized one within the industry); 3) The hazard could cause or is likely to cause serious harm or death; and 4) The hazard must be correctable (OSHA recognizes not all hazards are correctable).\\r\\nAlthough theoretically a powerful tool against workplace hazards, it is difficult to meet all four criteria. Therefore, OSHA has engaged in extensive regulatory rule-making to meet its obligations under the law.[21][22]\\r\\nDue to the difficulty of the rule-making process (which is governed by the Administrative Procedures Act), OSHA has focused on basic mechanical and chemical hazards rather than procedures. Major areas which its standards currently cover are: Toxic substances, harmful physical agents, electrical hazards, fall hazards, hazards associated with trenches and digging, hazardous waste, infectious disease, fire and explosion dangers, dangerous atmospheres, machine hazards, and confined spaces.[20]\\r\\nSection 8 of the Act covers reporting requirements. All employers must report to OSHA within eight hours if an employee dies from a work-related incident, or three or more employees are hospitalized as a result of a work-related incident. Additionally, all fatal on-the-job heart attacks must also be reported. Section 8 permits OSHA inspectors to enter, inspect and investigate, during regular working hours, any workplace covered by the Act.[20] Employers must also communicate with employees about hazards in the workplace. By regulation, OSHA requires that employers keep a record of every non-consumer chemical product used in the workplace. Detailed technical bulletins called material safety data sheets (MSDSs) must be posted and available for employees to read and use to avoid chemical hazards.[23] OSHA also requires employers to report on every injury or job-related illness requiring medical treatment (other than first aid) on OSHA Form 300, \\"Log of Work-Related Injuries and Illnesses\\" (known as an \\"OSHA Log\\" or \\"Form 300\\"). An annual summary is also required and must be posted for three months, and records must be kept for at least five years.[24]\\r\\nSection 11(c) of the Act prohibits any employer from discharging, retaliating or discriminating against any employee because the worker has exercised rights under the Act. These rights include complaining to OSHA and seeking an OSHA inspection, participating in an OSHA inspection, and participating or testifying in any proceeding related to an OSHA inspection.[20]\\r\\nSection 18 of the Act permits and encourages states to adopt their own occupational safety and health plans, so long as the state standards and enforcement \\"are or will be at least as effective in providing safe and healthful employment\\" as the federal OSH Act. States that have such plans are known as \\"OSHA States.\\" As of 2007, 22 states and territories operated complete plans and four others had plans that covered only the public sector.[20]","input":"When was the occupational health and safety act established?"},{"output":"education was open to all and seen as one of the methods to achieve Moksha in those days, or enlightenment.","context":"The history of education in the South Asia began with teaching of traditional elements such as Indian religions, Indian mathematics, Indian logic at early Hindu and Buddhist centres of learning such as ancient Taxila (in modern-day Pakistan) and Nalanda (in India) before the common era. Islamic education became ingrained with the establishment of the Islamic empires in the Indian subcontinent in the Middle Ages while the coming of the Europeans later brought western education to colonial India. A series of measures continuing throughout the early half of the 20th century ultimately laid the foundation of education in the Republic of India, education in Pakistan and much of South Asia.\\r\\n\\r\\n\\r\\nEarly education in India commenced under the supervision of a guru/prabhu.[1] Initially, education was open to all and seen as one of the methods to achieve Moksha in those days, or enlightenment. As time progressed, due to superiority complexes, the education was imparted on the basis of caste and the related duties that one had to perform as a member of a specific caste.[1] The Brahmans learned about scriptures and religion while the Kshatriya were educated in the various aspects of warfare.[1] The Vaishya caste learned commerce and other specific vocational courses while education was largely denied to the Shudras, the lowest caste.[1] The earliest venues of education in India were often secluded from the main population.[1] Students were expected to follow strict monastic guidelines prescribed by the guru and stay away from cities in ashrams.[2] However, as population increased under the Gupta empire centres of urban learning became increasingly common and Cities such as Varanasi and the Buddhist centre at Nalanda became increasingly visible.[2]\\r\\nEducation in India is a piece of education traditional form was closely related to religion.[3] Among the Heterodox schools of belief were the Jain and Buddhist schools.[4] Heterodox Buddhist education was more inclusive and aside of the monastic orders the Buddhist education centres were urban institutes of learning such as Taxila and Nalanda where grammar, medicine, philosophy, logic, metaphysics, arts and crafts etc. were also taught.[1][2] Early secular Buddhist institutions of higher learning like Taxila and Nalanda continued to function well into the common era and were attended by students from China and Central Asia.[3]\\r\\nOn the subject of education for the nobility Joseph Prabhu writes: \\"Outside the religious framework, kings and princes were educated in the arts and sciences related to government: politics (danda-n?ti), economics (vartta), philosophy (anv?ksiki), and historical traditions (itihasa). Here the authoritative source was Kautilyas Arthashastra, often compared to Niccol Machiavellis The Prince for its worldly outlook and political scheming.\\"[1] The Rgveda mentions female poets called brahmavadinis, specifically Lopamudra and Ghosha.[5] By 800 BCE women such as Gargi and Maitreyi were mentioned as scholars in the religious Upnishads.[5] Maya, mother of the historic Buddha, was an educated queen while other women in India contributed to writing of the Pali canon.[5] Out of the composers of the Sangam literature 154 were women.[6] However, the education and society of the era continued to be dominated by educated male population.[7] .\\r\\nChinese scholars such as Xuanzang and Yi Jing arrived in Indian institutions of learning to survey Buddhist texts.[8] Yi Jing additionally noted the arrival of 56 scholars from India, Japan, and Korea.[9] However, the Buddhist institutions of learning were slowly giving way to a resurgent tradition of Brahmanism during that era.[9] Scholars from India also journeyed to China to translate Buddhist texts.[10] During the 10th century a monk named Dharmadeva from Nalanda journeyed to China and translated a number of texts.[10] Another centre at Vikramshila maintained close relations with Tibet.[10] The Buddhist teacher Atisa was the head monk in Vikramshila before his journey to Tibet.[10]\\r\\nExamples of royal patronage include construction of buildings under the Rastrakuta dynasty in 945 CE.[11] The institutions arranged for multiple residences for educators as well as state sponsored education and arrangements for students and scholars.[11] Similar arrangements were made by the Chola dynasty in 1024 CE, which provided state support to selected students in educational establishments.[12] Temple schools from 12ÿ13th centuries included the school at the Nataraja temple situated at Chidambaram which employed 20 librarians, out of whom 8 were copiers of manuscripts and 2 were employed for verification of the copied manuscripts.[13] The remaining staff conducted other duties, including preservation and maintained of reference material.[13]\\r\\nAnother establishment during this period is the Uddandapura institute established during the 8th century under the patronage of the Pala dynasty.[14] The institution developed ties with Tibet and became a centre of Tantric Buddhism.[14] During the 10ÿ11th centuries the number of monks reached a thousand, equaling the strength of monks at the sacred Mahabodhi complex.[14] By the time of the arrival of the Islamic scholar Al Biruni India already had an established system of science and technology in place.[15] Also by the 12th century, invasions from India's northern borders disrupted traditional education systems as foreign armies raided educational institutes, among other establishments.[14]\\r\\nWith the advent of Islam in India the traditional methods of education increasingly came under Islamic influence.[16] Pre-Mughal rulers such as Qutb-ud-din Aybak and other Muslim rulers initiated institutions which imparted religious knowledge.[16] Scholars such as Nizamuddin Auliya and Moinuddin Chishti became prominent educators and established Islamic monasteries.[16] Students from Bukhara and Afghanistan visited India to study humanities and science.[16]\\r\\nIslamic institution of education in India included traditional madrassas and maktabs which taught grammar, philosophy, mathematics, and law influenced by the Greek traditions inherited by Persia and the Middle East before Islam spread from these regions into India.[17] A feature of this traditional Islamic education was its emphasis on the connection between science and humanities.[17] Among the centres of education in India was 18th century Delhi was the Madrasa Rahimiya under the supervision of Shah Waliullah, an educator who favored an approach balancing the Islamic scriptures and science.[18] The course at the Madrasa Rahimiya prescribed 2 books on grammar, 1 book on philosophy, 2 books on logic, 2 books on astronomy and mathematics, and 5 books on mysticism.[18] Another centre of prominence arose in Lucknow under Mulla Nizamuddin Sahlawi, who educated at the Firangi Mahal and prescribed a course called the Dars-i-Nizami which combined traditional studies with modern and laid emphasis on logic.[18]\\r\\nThe education system under the rule of Akbar adopted an inclusive approach with the monarch favoring additional courses: medicine, agriculture, geography, and texts from other languages and religions, such as Patanjali's work in Sanskrit.[19] The traditional science in this period was influenced by the ideas of Aristotle, Bhskara II, Charaka and Ibn Sina.[20] This inclusive approach was not uncommon in Mughal India.[18] The more conservative monarch Aurangzeb also favored teaching of subjects which could be applied to administration.[18] The Mughals, in fact, adopted a liberal approach to sciences and as contact with Persia increased the more intolerant Ottoman school of manqul education came to be gradually substituted by the more relaxed maqul school.[21]\\r\\nThe Middle Ages also saw the rise of private tuition in India as state failed to invest in public education system.[20] A tutor, or Riyazi, was an educated professional who could earn a suitable living by performing tasks such as creating calendars or generating revenue estimates for nobility.[20] Another trend in this era is the mobility among professions, exemplified by Qaim Khan, a prince famous for his mastery in crafting leather shoes and forging cannons.[20]\\r\\n[22]\\r\\nBefore the introduction of British education, Indigenous Education was given higher importance from early time to colonial era.\\r\\nIn every Indian village which has retained anything of its form.the rudiments of knowledge are sought to be imparted, there is not a child, except those of the outcasts (who form no part of the community), who is not able to read, to write, to cipher; in the last branch of learning, they are confessedly most proficient.\\r\\n[23] According to a survey done in the region of Madras, There were 11,758 schools and 740 centers for higher education in Madras Presidency. The number of students was 1,88,650.[24].Around 1830 there exist 1,00,000 village schools in Bengal and Bihar region alone.[25][26]. After the introduction of British education, the numbers of these indigenous education institutes decreased drastically.[27][28].according to Minute of dissent, British government restricted indigenous education.\\r\\nEfforts were then made by the Government to confine higher education and secondary education leading to higher education to boys in affluent, circumstances This again was done not in the interests of sound education but for political reasons. Rules were made calculated to restrict the diffusion of education generally and among the poorer boys in particular. Conditions for recognition for  grants stiff and various-were laid down and enforced, and the non-fulfilment of any one of these conditions was liable to be followed by serious consequences. Fees were raised to a degree which considering the circumstances of the classes that resort to schools, were abnormal. When it was objected that the minimum fee would be a great hardship to poor students the answer was-such students had no business to receive that kind of education.Managers of private schools who remitted fees in whole or in part were penalized by reduced grants-in-aid. These rules had undoubtedly the effect of checking the great expansion of education that would have taken place. This is the real explanation of the very unsatisfactory character of the nature and progress of secondary education and it will never be remedied till we are prepared either to give education to the boys ourselves or to make sufficient grants to the private schools to enable them to be staffed with competent teachers. We are at present not prepared to do either.English education, according to this policy, is to be confined to the well-to-do classes.They, it was believed, would give no trouble to Government.For this purpose, the old system of education under which a pupil could prosecute his studies from the lowest to the highest class was altered.\\r\\n[29]\\r\\nThe Jesuits introduced India to both the European college system and the printing of books, through founding Saint Paul's College, Goa in 1542. The French traveler Fran?ois Pyrard de Laval, who visited Goa c.1608, described the College of St Paul, praising the variety of the subjects taught there free of charge. Like many other European travelers who visited the College, he recorded that at this time it had 3000 students, from all the missions of Asia.[5] Its Library was one of the biggest in Asia, and the first Printing Press was mounted there.\\r\\nThe British made education, in Englisha high priority hoping it would speed modernization and reduce the administrative charges.[30] The colonial authorities had a sharp debate over policy. This was divided into two schools - the orientalists, who believed that education should happen in Indian languages (of which they favoured classical or court languages like Sanskrit or Persian) or utilitarians (also called anglicists) like Thomas Babington Macaulay, who strongly believed that traditional India had nothing to teach regarding modern skills; the best education for them would happen in English. Macaulay introduced English education in India, especially through his famous minute of February 1835. He called for an educational system that would create a class of anglicised Indians who would serve as cultural intermediaries between the British and the Indians.[31] Macaulay succeeded in implementing ideas previously put forward by Lord William Bentinck, the governor general since 1829. Bentinck favoured the replacement of Persian by English as the official language, the use of English as the medium of instruction, and the training of English-speaking Indians as teachers. He was inspired by utilitarian ideas and called for \\"useful learning.\\" However, Bentinck's ideas were rejected by the Court of Directors of the East India Company and he retired as governor general.[32][33]\\r\\nFrykenberg examines the 1784 to 1854 period to argue that education helped integrate the diverse elements Indian society, thereby creating a new common bond from among conflicting loyalties. The native elite demanded modern education. The University of Madras, founded in 1857, became the single most important recruiting ground for generations of ever more highly trained officials. This exclusive and select leadership was almost entirely \\"clean-caste\\" and mainly Brahman. It held sway in both the imperial administration and within princely governments to the south. The position of this mandarin class was never seriously challenged until well into the twentieth century.[34]\\r\\nEllis argues that historians of Indian education have generally confined their arguments to very narrow themes linked to colonial dominance and education as a means of control, resistance, and dialogue. Ellis emphasizes the need to evaluate the education actually experienced by most Indian children, which was outside the classroom.[35] Public education expenditures varied dramatically across regions with the western and southern provinces spending three to four times as much as the eastern provinces. The reason involved historical differences in land taxes. However the rates of attendance and literacy were not nearly as skewed.[36]\\r\\nPrior to the British era, education in India commenced under the supervision of a guru in traditional schools called gurukuls. The gurukuls were supported by public donation and were one of the earliest forms of public school offices. However these Gurukuls catered only to the Upper castes of the Indian society and the overwhelming masses were denied any formal education. In the colonial era, the gurukul system began to decline as the system promoted by the British began to gradually take over. Between 1881ÿ82 and 1946ÿ47, the number of English primary schools grew from 82,916 to 134,866 and the number of students in English Schools grew from 2,061,541 to 10,525,943. Literacy rates in accordance to British in India rose from 3.2 per cent in 1881 to 7.2 per cent in 1931 and 12.2 per cent in 1947.\\r\\nJha argues that local schools for pre-adolescent children were in a flourishing state in thousands of villages of Bihar and Bengal until the early decades of the nineteenth century. They were village institutions, maintained by village elders with local funds, where their children (from all caste clusters and communities) could, if the father wished, receive useful skills. However, the British policies in respect of education and land control adversely affected both the village structure and the village institutions of secular education. The British legal system and the rise of caste consciousness since the second half of the nineteenth century made it worse. Gradually, village as the base of secular identity and solidarity became too weak to create and maintain its own institution by the end of the nineteenth century and the traditional system decayed.[37]\\r\\nBritish education became solidified into India as missionary schools were established during the 1820s.[38] New policies in 1835 gave rise to the use of English as the language of instruction for advanced topics.[38]\\r\\nIndia established a dense educational network (very largely for males) with a Western curriculum based on instruction in English. To further advance their careers many ambitious upper class men with money, including Gandhi, Nehru and Muhammad Ali Jinnah went to England, especially to obtain a legal education at the Inns of Court. By 1890 some 60,000 Indians had matriculated, chiefly in the liberal arts or law. About a third entered public administration, and another third became lawyers. The result was a very well educated professional state bureaucracy. By 1887 of 21,000 mid-level civil service appointments, 45% were held by Hindus, 7% by Muslims, 19% by Eurasians (European father and Indian mother), and 29% by Europeans. Of the 1000 top -level positions, almost all were held by Britons, typically with an Oxbridge degree.[39]\\r\\nThe Raj, often working with local philanthropists, opened 186 colleges and universities. Starting with 600 students scattered across 4 universities and 67 colleges in 1882, the system expanded rapidly. More exactly, there never was a \\"system\\" under the Raj, as each state acted independently and funded schools for Indians from mostly private sources. By 1901 there were 5 universities and 145 colleges, with 18,000 students (almost all male). The curriculum was Western. By 1922 most schools were under the control of elected provincial authorities, with little role for the national government. In 1922 there were 14 universities and 167 colleges, with 46,000 students.In 1947 21 universities and 496 colleges were in operation. Universities at first did no teaching or research; they only conducted examinations and gave out degrees.[40][41]\\r\\nThe Madras Medical College opened in 1835, and admitted women so that they could treat the female population who traditionally shied away from medical treatments under qualified male professionals.[42] The concept of educated women among medical professionals gained popularity during the late 19th century and by 1894, the Women's Christian Medical College, an exclusive medical school for women, was established in Ludhiana in Punjab.[42]\\r\\nThe British established the Government College University in Lahore, of present-day Pakistan in 1864. The institution was initially affiliated with the University of Calcutta for examination. The prestigious University of the Punjab, also in Lahore, was the fourth university established by the colonials in South Asia, in the year 1882.\\r\\nMuhammadan Anglo-Oriental College, founded in 1875, was the first modern institution of higher education for Muslims in India. By 1920 it became The Aligarh Muslim University and was the leading intellectual center of Muslim political activity.[43] The original goals were to train Muslims for British service and prepare an elite that would attend universities in Britain. After 1920 it became a centre of political activism. Before 1939, the faculty and students supported an all-India nationalist movement. However, when the Second World War began political sentiment shifted toward demands for a Muslim separatist movement. The intellectual support it provided proved significant in the success of Jinnah and the Muslim League.[44]\\r\\nThe East India Company in 1806 set up Haileybury College in England to train administrators. In India, there were four colleges of civil engineering; the first was Thomason College(Now IIT Roorkee), founded in 1847. The second was Bengal Engineering College (now Indian Institute of Engineering, Science and Technology, IIEST). Their role was to provide civil engineers for the Indian Public Works Department. Both in Britain and in India, the administration and management of science, technical and engineering education was undertaken by officers from the Royal Engineers and the Indian Army equivalent, (commonly referred to as sapper officers). This trend in civil/military relationships continued with the establishment of the Royal Indian Engineering College (also known as Cooper's Hill College) in 1870, specifically to train civil engineers in England for duties with the Indian Public Works Department. he Indian Public Works Department, although technically a civilian organisation, relied on military engineers until 1947 and after.[45]\\r\\nGrowing awareness for the need of technical education in India gave rise to establishment of institutions such as the Indian Institute of Science, established by philanthropist Jamshetji Tata in 1909.[46] By the 1930s India had 10 institutions offering engineering courses.[47] However, with the advent of the Second World War in 1939 the \\"War Technicians Training Scheme\\" under Ernest Bevin was initiated, thereby laying the foundation of modern technical education in India.[47] Later, planned development of scientific education under Ardeshir Dalal was initiated in 1944.[47]\\r\\nDuring the 19th and 20th centuries most of the Indian princely states fell under the British Raj.[48] The British rule during the 19th century did not take adequate measures to help develop science and technology in India and instead focused more on arts and humanities.[49] Till 1899 only the University of Bombay offered a separate degree in sciences.[50] In 1899 B.Sc and M.Sc. courses were also supported by the University of Calcutta.[51] By the late 19th century India had lagged behind in science and technology and related education.[49] However, the nobility and aristocracy in India largely continued to encourage the development of sciences and technical education, both traditional and western.[48]\\r\\nWhile some science related subjects were not allowed in the government curriculum in the 1850s the private institutions could also not follow science courses due to lack of funds required to establish laboratories etc.[51] The fees for scientific education under the British rule were also high.[51] The salary that one would get in the colonial administration was meager and made the prospect of attaining higher education bleak since the native population was not employed for high positions in the colonial setup.[51] Even the natives who did manage to attain higher education faced issues of discrimination in terms of wages and privileges.[52]\\r\\nOne argument for the British detachment towards the study of science in India is that England itself was gradually outpaced in science and technology by European rival Germany and a fast-growing United States so the prospects of the British Raj adopting a world class science policy towards its colonies increasingly decreased.[53] However, Deepak Kumar notes the British turn to professional education during the 1860s and the French initiatives at raising awareness on science and technology in French colonies.[53]","input":"When was the first school started in india?"},{"output":"Pinehurst, North Carolina","context":"Miniature golf, also known as minigolf, or putt-putt, is an offshoot of the sport of golf focusing solely on the putting aspect of its parent game. It is played on courses consisting of a series of holes (usually a multiple of 9) similar to its parent, but characterized by their short length (usually within 10 yards from tee to cup), the use of artificial putting surfaces such as carpet, astroturf and/or concrete, a geometric layout often requiring non-traditional putting lines such as bank shots, and artificial obstacles such as tunnels/tubes, ramps, concrete/metal/fiberglass forms, and moving obstacles such as windmills. When miniature golf retains many of these characteristics but without the use of any props or obstacles, it is purely a mini version of its parent game.\\r\\n\\r\\n\\r\\nWhile the international sports organization World Minigolf Sport Federation (WMF)[1] prefers to use the name \\"minigolf\\", the general public in different countries has also many other names for the game: miniature golf, mini-golf, midget golf, goofy golf, shorties, extreme golf, crazy golf, adventure golf, mini-putt, putter golf and so on. The name Putt-Putt is the trademark of an American company[2] that builds and franchises miniature golf courses in addition to other family-oriented entertainment, and the term \\"putt-putt\\" is sometimes used colloquially to refer to the game itself. The term \\"Minigolf\\" was formerly a registered trademark of a Swedish company that built its own patented type of minigolf courses. Resort towns such as Myrtle Beach, SC, Branson, MO, Pigeon Forge, TN and Wisconsin Dells, WI are known for their numerous minigolf courses.[3]\\r\\nGeometrically-shaped minigolf courses made of artificial materials (carpet) began to emerge during the early 20th century. The earliest documented mention of such a course is in the 8 June 1912 edition of The Illustrated London News, which introduces a minigolf course called Gofstacle.[4]\\r\\nThe first standardized minigolf courses to enter commercial mass-production were the Thistle Dhu (\\"This'll Do\\") course 1916 in Pinehurst, North Carolina, and the 1927 Tom Thumb patent of Garnet Carter from Lookout Mountain, Tennessee. Thomas McCulloch Fairbairn (inventor), a golf fanatic, revolutionized the game in 1922 with his formulation of a suitable artificial greena mixture of cottonseed hulls, sand, oil, and dye. With this discovery, miniature golf became accessible everywhere; by the late 1920s there were over 150 rooftop courses in New York City alone, and tens of thousands across the United States.[5] This American minigolf boom of early 20th century came to an end during the economic depression in the late 1930s. Nearly all minigolf courses in the United States were closed and demolished before the end of the 1930s.[6] A rare surviving example from this period is the Parkside Whispering Pines Miniature Golf Course located near Rochester, New York, and listed on the National Register of Historic Places in 2002.[7]\\r\\nThe first miniature golf course in Canada was at the Maples Inn in Pointe-Claire, Quebec. The \\"Mapes\\" was constructed as a summer home in the 1890s but was renovated into a club in 1902, opened to the public in 1914, and had a miniature golf course in 1930. The popular nightspot burned in 1985. (See: West Island Chronicle, June 29, 2008.)\\r\\nOne of the first documented minigolf courses in mainland Europe was built in 1926 by Fr. Schr?der in Hamburg, Germany. Mr. Schr?der had been inspired by his visit to the United States, where he had seen minigolf courses spreading across the country.[8]\\r\\nIn 1930 Edwin O. Norrman and Eskil Norman returned to Sweden from the United States, where they had stayed for several years and witnessed the golden days of the American minigolf boom. In 1931 they founded a company \\"Norman och Norrmans Miniatyrgolf\\", and began manufacturing standardized minigolf courses for the Swedish market. During the following years they spread this new leisure activity across Sweden, by installing minigolf courses in public parks and other suitable locations.[8]\\r\\nSwedish minigolf courses typically had a rectangular wooden frame surrounding the playing area made of tennis field sand[9] (while the American manufacturers used newly developed and patented felt as the surface of their minigolf courses). Felt did not become popular as a surface material in Sweden until in the mid-1960sbut since then it has become practically the only surface material used in Scandinavia and Britain, due to its favorable playing qualities in wet weather. (Minigolf courses with a felt surface can be played in rainy weather, because water soaks through the felt into the ground. The other commonly used surface materials, beton and eternite, cannot be used in rainy weather, because the rainwater pools on them, stopping the ball from rolling.)\\r\\nThe Swedish Minigolf Federation (Svenska Bangolff?rbundet)[10] was founded in 1937, being the oldest minigolf sport organization in the world. National Swedish championships in minigolf have been played yearly since 1939.[11] In other countries minigolf sport federations were not founded until the late 1950s, due to the post-war economical depression.\\r\\nIn 1954, the minigolf course in Ascona (Switzerland) opened, the oldest course worldwide following the norms of Paul Bongni.\\r\\nThe earliest documented minigolf competitions were played in the United States. The first National Tom Thumb Open minigolf tournament was arranged in 1930, with a total cash purse $10,000 (the top prize being $2,000). Qualification play-offs were played in all of the 48 states, and the final competition on Lookout Mountain, Chattanooga, Tennessee attracted over 200 players representing thirty states.[12] After the Depression ten years later, minigolf died out as a competition sport in America, and has begun to recover only during the most recent decades. The American minigolf sport boom of the 1930s inspired many European countries, and the sport of minigolf lived on in Europe even after the American game fell into Depression.\\r\\nIn 1938 Joseph and Robert Taylor from Binghamton, New York started building and operating their own miniature golf courses. These courses differed from the ones in the late 20s and early 30s; they were no longer just rolls, banks, and curves, with an occasional pipe thrown in. Their courses not only had landscaping, but also obstacles, including windmills, castles, and wishing wells.\\r\\nImpressed by the quality of the courses, many customers asked if the Taylors would build a course for them. By the early 1940s, Joe and Bob formed Taylor Brothers, and were in the business of building miniature golf courses and supplying obstacles to the industry. During both the Korean and Vietnam Wars, many a G.I. played on a Taylor Brothers prefabricated course that the U.S. Military had contracted to be built and shipped overseas.\\r\\nBy the late 50s almost all supply catalogs carried Taylor Brothers' obstacles. In 1961 Bob Taylor, Don Clayton of Putt-Putt, and Frank Abramoff of Arnold Palmer Miniature Golf organized the first miniature golf association known as NAPCOMS (or the \\"National Association of Putting Course Operators, Manufacturers, and Suppliers\\"). Their first meeting was held in New York City. Though this organization only lasted a few years it was the first attempt to bring miniature golf operators together to promote miniature golf.\\r\\nIn 1955, Lomma Golf, Inc., founded by Al Lomma and his brother Ralph Lomma, led the revival of wacky, animated trick hazards. These hazards required both accurately aimed shots and split-second timing to avoid spinning windmill blades, revolving statuary, and other careening obstacles.\\r\\nThe book Tilting At Windmills (How I Learned To Stop Worrying And Love Sport) by Andy Miller tells the story of the formerly sports-hating author attempting to change by competing in miniature golf, including events in Denmark and Latvia.\\r\\nIn the United States, National Miniature Golf Day is held yearly on the second Saturday of May. The event had its inaugural celebration on May 12, 2007, and was officially recognized and published in 2008's edition of Chase's Calendar of Events.\\r\\nMinigolf has so far not reached wide popularity outside Europe and North America.[citation needed] The reason is probably economic, at least to some extent: the less wealthy countries invest their limited sports funds into such sports that enjoy widest public attention and media coverage, leaving the less popular sports with little or no funding at all. (Minigolf is one of the most popular outdoor games in Europe and America, though, but only as an occasional leisure activity, not as a competitive sport.)\\r\\nBy the 1950s the American Putt-Putt company was exporting their minigolf courses to South Africa, Australia, Japan, Korea, India, Iran, Italy, Pakistan, Argentina, Brazil, and the Eastern Bloc.[13] Minigolf courses are found in all parts of the world, but their popularity is by far highest in the USA, the UK, New Zealand, Scandinavia, and central Europe.[citation needed]\\r\\nThe sport of miniature golf is governed internationally by the World Minigolf Sport Federation (WMF), headquartered in G?teborg, Sweden. The WMF is a member of SportAccord. It organises World Championships for youth and elite players, and Continental Championships in Europe, Asia and the USA, held in alternate years.\\r\\nAll competitions approved by World Minigolfsport Federation are played on standardized courses, whose design has been checked to be suitable for competitive play. The WMF currently approves four different course types:\\r\\nThe world record on one round of minigolf is 18 strokes on 18 holes. More than a thousand players have officially achieved this score on eternite. On other playing systems a perfect round of 18 holes-in-one is extremely rare, and has never been scored in an official national or international tournament. Unofficial 18-rounds on concrete and felt courses have been reported in Sweden.[18]\\r\\nIn addition to classical outdoor miniature golf, indoor \\"glow in the dark\\" miniature golf has achieved some popularity, especially in colder climates like Canada[19] and Finland.[20] It can be played throughout the year, and climate control allows building elaborate obstacles that would not withstand inclement weather. There are also a variety of portable miniature golf fairways or 'tracks'[21] that can be set up as temporary courses indoors or outdoors. The fairways are usually constructed of wooden or glass fibre frames. Portable fairways are often used for summer festivals and fairs, corporate events, team-building events, and product launches.\\r\\nThe 18th and final holes of many miniature golf courses are designed to literally capture the ball, effectively preventing the player from playing additional rounds without purchasing another game. This may be accomplished with a \\"drain\\" or trap-door hole setup that channels the ball to a lockbox. One popular method of theming the 18th hole in the United States is to use a gated, ramped target area depicting the face of a clown; if the ball lands \\"in\\" the clown's nose, a bell might sound and the player would win a discount ticket for another game.\\r\\nNearly all European countries have an official national federation for promoting minigolf as a competition sport. The bi-annual European Championships attract competitors from more than twenty European countries. As of 2012, Chris Beattie has been the holder of the European Championship title.[22] Outside Europe only a small number of countries have participated in international minigolf competitions. These countries include USA, Japan, China, India and Taiwan. A national minigolf federation exists also in Moldova, Mexico, Australia and New Zealand, but none of these countries has ever participated in international competitions, and probably are not arranging many domestic competitions either.[23]\\r\\nWorld Minigolfsport Federation represents some 40,000 registered competition players from 37 countries.[24] The national minigolf federation of Germany has 11,000 members with a competing license,[25] and the Swedish federation has 8,000 registered competition players.[18] Other strong minigolf countries include Austria and Switzerland, each having a few thousand licensed competition players. Also Italy, Czech Republic and Netherlands have traditionally been able to send a strong team to international championships, even if they cannot count their licensed players in thousands.\\r\\nThe sceptre of competitive minigolf rests quite firmly in mainland Europe: no player from other countries (such as UK, USA, Japan et cetera) has ever reached even the top 50 in World Championships (in men's category).[22] Nearly all national federations outside Europe were founded only quite recently (within the last 10 years), and it will take time before the players of these countries learn all secrets of the game. USA has a longer history of minigolf competitions, but the standardized European competition courses are practically unknown in USA, and therefore the American players have been unable to learn the secrets of European minigolf. On the traditional American courses the best American players are able to challenge the European top players into a tough and exciting competition.[26]\\r\\nThe British Minigolf Association (BMGA) has an additional ÿ and quite surprising ÿ problem on their way to greater success in competitive minigolf. While the minigolf federations in mainland Europe receive annual funding from the government, in England the national sports organisation Sport England has refused to accept BMGA as its member ÿ which means that BMGA is left without the public funding that other forms of sports enjoy. The rules of Sport England declare that only one variant of each sport can be accepted as member ÿ and minigolf is interpreted as a variant of golf.[24]\\r\\nNo person is known to be earning his living by competing in minigolf. Many course owners and employees naturally earn their living by working at minigolf courses, and some of the best minigolf players earn their living from minigolf-related work, such as giving putting lessons to golf players.[27]\\r\\nThe highest money prizes are paid in the United States, where the winner of a major competition may earn up to 5,000 US dollars. In mainland Europe the money prizes are generally quite low, and in many cases honor is the only thing at stake in the competition. International championships usually award no money prizes at all.\\r\\nIn the US there are two organizations offering national tournaments: the Professional Putters Association and the US Pro Mini-Golf Association (USPMGA). The USPMGA represents the United States in the World Minigolfsport Federation, having been an active member since 1995. USPMGA President Robert Detwiler is also the WMF representative for North and South America.\\r\\nNew Israeli Minigolf Association was established in February 2010 in Israel. Setting up, for the first time, league playing according to the rules of WMF and USPMGA. Now, a series of lush and inviting minigolf parks in prime locations are building around Israel and will be offering this need of adventure to the public at very attractive surrounding.\\r\\nWorld Minigolfsport Federation (WMF), a member of AGFIS, organises World Championships biennially (on odd-numbered years), while the continental championships in Europe and Asia are organized on even-numbered years. Many of these competitions are arranged for three age groups: juniors (under 20 years), adults (no age limit), and seniors (over 45 years).[28] Men and women compete separately in their own categories, except in some team competitions and pair competitions. The difference in the playing skills of men and women is very small on top level, however: it is not unheard-of that the best player in a major international tournament is female. Typically the winner in women's category would be very close to medals also in men's category.[29]\\r\\nWorld and European Championships have so far never been arranged on MOS courses (which are popular in USA and UK, and were approved by WMF for competition use only a few years ago). International competitions are typically arranged on two courses of 18 holes, of which one course is eternite, and the other course is usually concrete, less commonly felt. In the future, the WMF is expected to use also MOS courses in international championships ÿ which will give American and British players a chance to show their skills on their own traditional course types.\\r\\nThe most prestigious MOS minigolf competitions in the world are the US Masters, US Open, British Open, Kent Open, World Crazy Golf Championships and the World Adventuregolf Masters.","input":"Where was the first miniature golf course built?"},{"output":"the establishment of the Roman Empire","context":"","input":"What was the end of the roman republic?"},{"output":"in the 980s","context":"The Norse exploration of North America began in the late 10th century AD when Norsemen explored and settled areas of the North Atlantic including the northeastern fringes of North America.[1] Remains of Norse buildings were found at LAnse aux Meadows near the northern tip of Newfoundland in 1960. This discovery aided the reignition of archaeological exploration for the Norse in the North Atlantic.[2]\\r\\n\\r\\nThe Norse settlements in Greenland lasted for almost 500 years. The only confirmed Continental North American settlement, LAnse aux Meadows, was small and did not last as long. While voyages, for example to collect timber, are likely to have occurred for some time, there is no evidence of any lasting Norse settlements on mainland North America.[3]\\r\\n\\r\\nAccording to the Sagas of Icelanders, Norsemen from Iceland first settled Greenland in the 980s. There is no special reason to doubt the authority of the information that the sagas supply regarding the very beginning of the settlement, but they cannot be treated as primary evidence for the history of Norse Greenland because they embody the literary preoccupations of writers and audiences in medieval Iceland that are not always reliable.[4]\\r\\n\\r\\nErik the Red (Old Norse: Eirkr rauei), having been banished from Iceland for manslaughter, explored the uninhabited southwestern coast of Greenland during the three years of his banishment.[5][6]  He made plans to entice settlers to the area, naming it Greenland on the assumption that \\"people would be more eager to go there because the land had a good name\\".[7] The inner reaches of one long fjord, named Eiriksfjord after him, was where he eventually established his estate Brattahlid.  He issued tracts of land to his followers.[8]\\r\\n\\r\\nAt its peak the colony consisted of two settlements. The Eastern was at the southwestern tip of Greenland, while the Western Settlement was about 500?km up the west coast, inland from present-day Nuuk. A smaller settlement near the Eastern Settlement is sometimes considered the Middle Settlement. The combined population was around 2,000ÿ3,000.[9] At least 400 farms have been identified by archaeologists.[8] Norse Greenland had a bishopric (at Garear) and exported walrus ivory, furs, rope, sheep, whale or seal blubber, live animals such as polar bears, supposed \\"unicorn horns\\" (in reality narwhal tusks), and cattle hides. In 1126, the population requested a Bishop (headquartered at Garear), and in 1261, they accepted the overlordship of the Norwegian King. They continued to have their own law and became almost completely independent after 1349, the time of the Black Death. In 1380, the Norwegian Kingdom entered into a personal union with the Kingdom of Denmark.[10]\\r\\n\\r\\nThere is evidence of Norse trade with the natives (called Skraelings by the Norse). The Norse would have encountered both Native Americans (the Beothuk, related to the Algonquin) and the Thule, the ancestors of the Inuit. The Dorset had withdrawn from Greenland before the Norse settlement of the island. Items such as comb fragments, pieces of iron cooking utensils and chisels, chess pieces, ship rivets, carpenter's planes, and oaken ship fragments used in Inuit boats have been found far beyond the traditional range of Norse colonization. A small ivory statue that appears to represent a European has also been found among the ruins of an Inuit community house.[10]\\r\\n\\r\\nThe colony began to decline in the 14th century. The Western Settlement was abandoned around 1350, and the last bishop at Garear died in 1377.[10] After a marriage was recorded in 1408, no written records mention the settlers. It is probable that the Eastern Settlement was defunct by the late 15th century. The most recent radiocarbon date found in Norse settlements as of 2002 was 1430 (I15 years). Several theories have been advanced to explain the decline.\\r\\n\\r\\nThe Little Ice Age of this period would have made travel between Greenland and Europe, as well as farming, more difficult; although fishing and seal hunting provided a healthy diet, there was more prestige in cattle farming, and there was increased availability of farms in Scandinavian countries depopulated by famine and plague epidemics. In addition, Greenlandic ivory may have been supplanted in European markets by cheaper ivory from Africa.[11] Despite the loss of contact with the Greenlanders, the Norwegian-Danish crown continued to consider Greenland a possession.\\r\\n\\r\\nNot knowing whether the old Norse civilization remained in Greenland or notand worried that if it did, it would still be Catholic 200 years after the Scandinavian homelands had experienced the Reformationa joint merchant-clerical expedition led by the Dano-Norwegian missionary Hans Egede was sent to Greenland in 1721. Though this expedition found no surviving Europeans, it marked the beginning of Denmark's re-assertion of sovereignty over the island.\\r\\n\\r\\nNorse Greenlanders were limited to scattered fjords on the island that provided a spot for their animals (such as cattle, sheep, goats, dogs, and cats) to be kept and farms to be established.[12][13] In these fjords, the farms depended upon byres to host their livestock in the winter, and routinely culled their herds in order to survive the season.[12][13][14] The coming warmer seasons meant that livestocks were taken from their byres to pasture, the most fertile being controlled by the most powerful farms and the church.[13][14][15] What was produced by livestock and farming was supplemented with subsistence hunting of mainly seal and caribou as well as walrus for trade.[12][13][14] The Norse mainly relied on the Nordrsetur hunt, a communal hunt of migratory harp seals that would take place during spring.[12][15] Trade was highly important to the Greenland Norse and they relied on imports of lumber due to the barrenness of Greenland. In turn they exported goods such as walrus ivory and hide, live polar bears, and narwhal tusks.[14][15] Ultimately these setups were vulnerable as they relied on migratory patterns created by climate as well as the well-being of the few fjords on the island.[13][15]\\r\\n\\r\\nA portion of the time the Greenland settlements existed was during The Little Ice Age and the climate was, overall, becoming cooler and more humid.[12][13][14] As climate began to cool and humidity began to increase, this brought longer winters and shorter springs, more storms and affected the migratory patterns of the harp seal.[12][13][14][15] Pasture space began to dwindle and fodder yields for the winter became much smaller. This combined with regular herd culling made it hard to maintain livestock, especially for the poorest of the Greenland Norse.[12] In spring, the voyages to where migratory harp seals could be found became more dangerous due to more frequent storms, and the lower population of harp seals meant that Nordrsetur hunts became less successful, making subsistence hunting extremely difficult.[12][13] The strain on resources made trade difficult, and as time went on, Greenland exports lost value in the European market due to competing countries and the lack of interest in what was being traded.[15]\\r\\n\\r\\nIn addition, it seemed that the Norse were unwilling to integrate with the indigenous Thule of Greenland, either through marriage or culture. There is evidence of contact as seen through the Thule archaeological record including ivory depictions of the Norse as well as bronze and steel artifacts. However, there is essentially no material evidence of the Thule among Norse artifacts.[12][13] In older research it was posited that it was not climate change alone that lead to Norse decline, but also their unwillingness to adapt.[12] For example, if the Norse had decided to focus their subsistence hunting on the ringed seal (which could be hunted year round, though individually), and decided to reduce or do away with their communal hunts, food would have been much less scarce during the winter season.[13][14][15][16] Also, had Norse individuals used skin instead of wool to produce their clothing, they would have been able to fare better nearer to the coast, and wouldn't have been as confined to the fjords.[13][14][15] However, more recent research has shown that the Norse did try to adapt in their own ways.[17] Some of these attempts included increased subsistence hunting. A significant number of bones of marine animals can be found at the settlements, suggesting increased hunting with the absence of farmed food.[17] In addition, pollen records show that the Norse didn't devastate the small forests and foliage as previously thought. Instead the Norse ensured that overgrazed or overused sections were given time to regrow and moved to other areas.[17] Norse farmers also attempted to adapt. With the increased need for winter fodder and smaller pastures, they would self-fertilize their lands in an attempt to keep up with the new demands caused by the changing climate.[17] However, even with these attempts, climate change was not the only thing putting pressure on the Greenland Norse. The economy was changing, and the exports they relied on were losing value.[15] Current research suggests that the Norse were unable to maintain their colonies because of economic and climatic change happening at the same time.[17][18]\\r\\n\\r\\nAccording to the Icelandic sagasEirik the Red's Saga,[19] Saga of the Greenlanders, plus chapters of the Hauksb܇k and the Flatey Bookthe Norse started to explore lands to the west of Greenland only a few years after the Greenland settlements were established.  In 985, while sailing from Iceland to Greenland with a migration fleet consisting of 400ÿ700 settlers[8][20] and 25 other ships (14 of which completed the journey), a merchant named Bjarni Herj܇lfsson was blown off course, and after three days' sailing he sighted land west of the fleet. Bjarni was only interested in finding his father's farm, but he described his discovery to Leif Erikson who explored the area in more detail and planted a small settlement fifteen years later.[8]\\r\\n\\r\\nThe sagas describe three separate areas discovered during this exploration: Helluland, which means \\"land of the flat stones\\"; Markland, \\"the land of forests\\", definitely of interest to settlers in Greenland where there were few trees; and Vinland, \\"the land of wine\\", found somewhere south of Markland. It was in Vinland that the settlement described in the sagas was founded.\\r\\n\\r\\nThree of Erik the Red's children visited the North American continent: his sons Leif and Thorvald, and their sister (or half-sister) Freydis. Thorvald died there.\\r\\n\\r\\nUsing the routes, landmarks, currents, rocks, and winds that Bjarni had described to him, Leif sailed from Greenland westward across the Labrador Sea, with a crew of 35sailing the same knarr Bjarni had used to make the voyage. He described Helluland as \\"level and wooded, with broad white beaches wherever they went and a gently sloping shoreline.\\"[8] Leif and others had wanted his father, Erik the Red, to lead this expedition and talked him into it.  However, as Erik attempted to join his son Leif on the voyage towards these new lands, he fell off his horse as it slipped on the wet rocks near the shore; thus he was injured and stayed behind.[8]\\r\\n\\r\\nLeif wintered in 1001, probably near Cape Bauld on the northern tip of Newfoundland, where one day his foster father Tyrker was found drunk, on what the saga describes as \\"wine-berries.\\" Squashberries, gooseberries, and cranberries all grew wild in the area. There are varying explanations for Leif apparently describing fermented berries as \\"wine.\\"\\r\\n\\r\\nLeif spent another winter at \\"Leifsb~eir\\" without conflict, and sailed back to Brattahle in Greenland to assume filial duties to his father.\\r\\n\\r\\nIn 1004, Leif's brother Thorvald Eiriksson sailed with a crew of 30 men to Vinland and spent the following winter at Leif's camp. In the spring, Thorvald attacked nine of the local people who were sleeping under three skin-covered canoes. The ninth victim escaped and soon came back to the Norse camp with a force. Thorvald was killed by an arrow that succeeded in passing through the barricade. Although brief hostilities ensued, the Norse explorers stayed another winter and left the following spring. Subsequently, another of Leif's brothers, Thorstein, sailed to the New World to retrieve his dead brother's body, but he died before leaving Greenland.[8]\\r\\n\\r\\nIn 1009, Thorfinn Karlsefni, also known as \\"Thorfinn the Valiant\\", supplied three ships with livestock and 160 men and women[20] (although another source sets the number of settlers at 250). After a cruel winter, he headed south and landed at Straumfjord.  He later moved to Straums?y, possibly because the current was stronger there.  A sign of peaceful relations between the  indigenous peoples and the Norsemen is noted here. The two sides bartered with furs and gray squirrel skins for milk and red cloth, which the natives tied around their heads as a sort of headdress.\\r\\n\\r\\nThere are conflicting stories but one account states that a bull belonging to Karlsefni came storming out of the wood, so frightening the natives that they ran to their skin-boats and rowed away.  They returned three days later, in force.  The natives used catapults, hoisting \\"a large sphere on a pole; it was dark blue in color\\" and about the size of a sheep's belly,[21] which flew over the heads of the men and made an ugly din.[21]\\r\\n\\r\\nThe Norsemen retreated.  Leif Erikson's half-sister Freyds Eirksd܇ttir was pregnant and unable to keep up with the retreating Norsemen. She called out to them to stop fleeing from \\"such pitiful wretches\\", adding that if she had weapons, she could do better than that. Freyds seized the sword belonging to a man who had been killed by the natives. She pulled one of her breasts out of her bodice and struck it with the sword, frightening the natives, who fled.[21]\\r\\n\\r\\nPurported runestones have been found in North America, most famously the Kensington Runestone. These are generally considered to be hoaxes or misinterpretations of Native American petroglyphs.[22]\\r\\n\\r\\nThere are many claims of Norse colonization in New England, none well-founded.\\r\\n\\r\\nMonuments claimed to be Norse include:[23]\\r\\n\\r\\nThe nineteenth-century Harvard chemist Eben Norton Horsford connected the Charles River Basin to places described in the Norse sagas and elsewhere, notably Norumbega.[24] He published several books on the topic and had plaques, monuments, and statues erected in honor of the Norse.[25] His work received little support from mainstream historians and archeologists at the time, and even less today.[26][27][28]\\r\\n\\r\\nSettlements in continental North America aimed to exploit natural resources such as furs and in particular lumber, which was in short supply in Greenland.[29]  It is unclear why the short-term settlements did not become permanent, though it was likely in part because of hostile relations with the indigenous peoples, referred to as Skr?lings by the Norse.[30] Nevertheless, it appears that sporadic voyages to Markland for forages, timber, and trade with the locals could have lasted as long as 400 years.[31][32]\\r\\n\\r\\nEvidence of continuing trips includes the Maine Penny, a Norwegian coin from King Olaf Kyrre's reign (1067ÿ1093) allegedly found in a Native American archaeological site in the U.S. state of Maine, suggesting an exchange between the Norse and the Native Americans late in or after the 11th century; and an entry in the Icelandic Annals from 1347 which refers to a small Greenlandic vessel with a crew of eighteen that arrived in Iceland while attempting to return to Greenland from Markland with a load of timber.[33]\\r\\n\\r\\nFor centuries it remained unclear whether the Icelandic stories represented real voyages by the Norse to North America. The sagas first gained serious historic respectability when, in 1837, the Danish antiquarian Carl Christian Rafn pointed out the possibility for a Norse settlement in, or voyages to, North America. North America, by the name Winland, first appeared in written sources in a work by Adam of Bremen from approximately 1075. The most important works about North America and the early Norse activities there, namely the Sagas of Icelanders, first reached written form only in the 13th and 14th centuries.[citation needed]\\r\\n\\r\\nEvidence of Norse west of Greenland came in the 1960s when archaeologist Anne Stine Ingstad and her husband, outdoorsman and author Helge Ingstad, excavated a Norse settlement at L'Anse aux Meadows in Newfoundland.  The location of the various lands described in the sagas remains unclear, however. Many historians identify Helluland with Baffin Island and Markland with Labrador. The location of Vinland poses a thornier question. Most believe that the L'Anse aux Meadows settlement represents the Vinland settlement described in the sagas; others argue that the sagas depict Vinland as warmer than Newfoundland and therefore lying farther south.[citation needed]\\r\\n\\r\\nIn 2012 Canadian researchers identified possible signs of Norse outposts in Nanook at Tanfield Valley on Baffin Island, as well as on Nunguvik, Willows Island and Avayalik.[34][35][36] Unusual fabric cordage found on Baffin Island in the 1980s and stored at the Canadian Museum of Civilization was identified in 1999 as possibly of Norse manufacture; that discovery led to more in-depth exploration of the Tanfield Valley archaeological site.[citation needed]\\r\\n\\r\\nArcheological findings in 2015 at Point Rosee,[37][38] on the southwest coast of Newfoundland, were originally thought to reveal evidence of a turf wall and the roasting of bog iron ore, and therefore a possible second 10th century Norse settlement in Canada.[39] Findings from the 2016 excavation suggest the turf wall and the roasted bog iron ore discovered in 2015 were the result of natural processes.[40] The possible settlement was initially discovered through satellite imagery in 2014,[41] and archaeologists excavated the area in 2015 and 2016.[41][39] Birgitta Linderoth Wallace, one of the leading experts of Norse archaeology in North America and an expert on the Norse settlement at L'Anse aux Meadows, is unsure of the identification of Point Rosee as a Norse site.[42] Archaeologist Karen Milek was a member of the 2016 Point Rosee excavation and is a Norse expert. She also expressed doubt that Point Rosee was a Norse site as there are no good landing sites for their boats and there are steep cliffs between the shoreline and the excavation site.[43] In their November 8, 2017, report[44] Sarah Parcak and Gregory Mumford, co-directors of the excavation, wrote that they \\"found no evidence whatsoever for either a Norse presence or human activity at Point Rosee prior to the historic period\\"[38] and that \\"None of the team members, including the Norse specialists, deemed this area as having any traces of human activity.\\"[37]\\r\\n\\r\\nThe Sklholt Map, made by an Icelandic teacher in 1570, depicts part of north-eastern North America mentioning Helluland, Markland and Vinland.[45]","input":"When did the vikings arrive in north america?"},{"output":"cumulus (\\"heap\\")","context":"Cumulonimbus, from the Latin cumulus (\\"heap\\") and nimbus (\\"rainstorm\\", \\"storm cloud\\"), is a dense towering vertical cloud[1] associated with thunderstorms and atmospheric instability, forming from water vapor carried by powerful upward air currents. If observed during a storm, these clouds may be referred to as thunderheads. Cumulonimbus can form alone, in clusters, or along cold front squall lines. These clouds are capable of producing lightning and other dangerous severe weather, such as tornadoes. Cumulonimbus progress from overdeveloped cumulus congestus clouds and may further develop as part of a supercell. Cumulonimbus is abbreviated Cb.\\r\\n\\r\\n\\r\\nTowering cumulonimbus clouds are typically accompanied by smaller cumulus clouds. The cumulonimbus base may extend several miles across and occupy low to middle altitudes- formed at altitude from approximately 200 to 4,000?m (700 to 10,000?ft). Peaks typically reach to as much as 40,000?ft (12,000?m), with extreme instances as high as 70,000?ft (21,000?m) or more.[2] Well-developed cumulonimbus clouds are characterized by a flat, anvil-like top (anvil dome), caused by wind shear or inversion near the tropopause. The shelf of the anvil may precede the main cloud's vertical component for many miles, and be accompanied by lightning. Occasionally, rising air parcels surpass the equilibrium level (due to momentum) and form an overshooting top culminating at the maximum parcel level. When vertically developed, this largest of all clouds usually extends through all three cloud regions. Even the smallest cumulonimbus cloud dwarfs its neighbors in comparison.\\r\\nCumulonimbus calvus\\r\\nA clearly developed cumulonimbus fibrous-edged top capillatus\\r\\nAnvil-topped incus\\r\\nArcus cloud (shelf cloud) leading a thunderstorm\\r\\nMammatocumulus with drooping pouches\\r\\nA cap (pileus) atop a calvus\\r\\nA funnel cloud (tuba) over the Netherlands\\r\\nIncus with a velum edge\\r\\nCumulonimbus calvus against sunlight with rain falling beneath it as a rain shaft (praecipatio)\\r\\nRain evaporating before reaching the ground (virga)\\r\\nPicture of a Cumulonimbus Cloud over Zambales Mountains, Photographed from my SM-G7102 Cellphone, Visible from SubicÿClarkÿTarlac Expressway\\r\\nPicture of a Cumulonimbus capillatus cloud over Africa displaying an overshooting top, taken from the International Space Station\\r\\nFlanking line in front of a strong thunderstorm\\r\\nCumulonimbus storm cells can produce torrential rain of a convective nature (often in the form of a rain shaft) and flash flooding, as well as straight-line winds. Most storm cells die after about 20?minutes, when the precipitation causes more downdraft than updraft, causing the energy to dissipate. If there is enough solar energy in the atmosphere, however (on a hot summer's day, for example), the moisture from one storm cell can evaporate rapidlyresulting in a new cell forming just a few miles from the former one. This can cause thunderstorms to last for several hours. Cumulonimbus clouds can also bring dangerous winter storms (called \\"blizzards\\") which bring lightning, thunder, and torrential snow. However, cumulonimbus clouds are most common in tropical regions.[9]\\r\\nIn general, cumulonimbus require moisture, an unstable air mass, and a lifting force (heat) in order to form. Cumulonimbus typically go through three stages: the developing stage, the mature stage (where the main cloud may reach supercell status in favorable conditions), and the dissipation stage.[10] The average thunderstorm has a 24?km (15?mi) diameter. Depending on the conditions present in the atmosphere, these three stages take an average of 30 minutes to go through.[11]\\r\\nClouds form when the dewpoint of water is reached in the presence of condensation nuclei in the troposphere. The atmosphere is a dynamic system, and the local conditions of turbulence, uplift and other parameters give rise to many types of clouds. Various types of cloud occur frequently enough to have been categorized. Furthermore, some atmospheric processes can make the clouds organize in distinct patterns such as wave clouds or actinoform clouds. These are large-scale structures and are not always readily identifiable from a single point of view.","input":"What is the difference between cumulus and nimbus clouds?"},{"output":"Denmark","context":"","input":"What part of scandinavia did the vikings come from?"},{"output":"French colonists","context":"","input":"Who were the first european settlers of mississippi?"},{"output":"February 2, 1848","context":"The Treaty of Guadalupe Hidalgo (Tratado de Guadalupe Hidalgo in Spanish), officially entitled the Treaty of Peace, Friendship, Limits and Settlement between the United States of America and the Mexican Republic,[1] is the peace treaty signed on February 2, 1848, in the Villa de Guadalupe Hidalgo (now a neighborhood of Mexico City) between the United States and Mexico that ended the MexicanÿAmerican War (1846ÿ48). The treaty came into force on July 4, 1848.[2]\\r\\nWith the defeat of its army and the fall of its capital, Mexico entered into negotiations to end the war. The treaty called for the U.S. to pay $15 million to Mexico and to pay off the claims of American citizens against Mexico up to $3.25 million. It gave the United States the Rio Grande as a boundary for Texas, and gave the U.S. ownership of California and a large area comprising roughly half of New Mexico, most of Arizona, Nevada, and Utah, and parts of Wyoming and Colorado. Mexicans in those annexed areas had the choice of relocating to within Mexico's new boundaries or receiving American citizenship with full civil rights.[citation needed]\\r\\nThe U.S. Senate advised and consented to ratification of the treaty by a vote of 38ÿ14. The opponents of this treaty were led by the Whigs, who had opposed the war and rejected Manifest destiny in general, and rejected this expansion in particular. The amount of land gained by the United States from Mexico was increased as a result of the Gadsden Purchase of 1853, which ceded parts of present-day southern Arizona and New Mexico to the United States.\\r\\n\\r\\n\\r\\nThe peace talks were negotiated by Nicholas Trist, chief clerk of the US State Department, who had accompanied General Winfield Scott as a diplomat and President Polk's representative. Trist and General Scott, after two previous unsuccessful attempts to negotiate a treaty with General Jos Joaqun de Herrera, determined that the only way to deal with Mexico was as a conquered enemy. Nicholas Trist negotiated with a special commission representing the collapsed government led by Don Jos Bernardo Couto, Don Miguel de Atristain, and Don Luis Gonzaga Cuevas of Mexico.[3]\\r\\nAlthough Mexico ceded Alta California and Santa Fe de Nuevo Mxico, the text of the treaty[4] did not list territories to be ceded, and avoided the disputed issues that were causes of war: the validity of the 1836 secession of the Republic of Texas, Texas's unenforced boundary claims as far as the Rio Grande, and the 1845 annexation of Texas by the United States.\\r\\nInstead, Article V of the treaty simply described the new U.S.ÿMexico border. From east to west, the border consisted of the Rio Grande northwest from its mouth to the point Santa Fe de Nuevo Mexico (roughly 32 degrees north), as shown in the Disturnell map, then due west from this point to the 110th meridian west, then north along the 110th Meridian to the Gila River and down the river to its mouth. Unlike the New Mexico segment of the boundary, which depended partly on unknown geography, \\"in order to preclude all difficulty in tracing upon the ground the limit separating Upper from Lower California\\", a straight line was drawn from the mouth of the Gila to one marine league south of the southernmost point of the port of San Diego, slightly north of the previous Mexican provincial boundary at Playas de Rosarito.\\r\\nComparing the boundary in the AdamsÿOns Treaty to the Guadalupe Hidalgo boundary, Mexico conceded about 55% of its pre-war, pre-Texas territorial claims[5] and now has an area of 1,972,550?km2 (761,606 sq mi).\\r\\nIn the United States, the 1.36 million km2 (525,000 square miles) of the area between the Adams-Onis and Guadalupe Hidalgo boundaries outside the 1,007,935?km2 (389,166?sq?mi) claimed by the Republic of Texas is known as the Mexican Cession. That is to say, the Mexican Cession is construed not to include any territory east of the Rio Grande, while the territorial claims of the Republic of Texas included no territory west of the Rio Grande. The Mexican Cession included essentially the entirety of the former Mexican territory of Alta California, but only the western portion of Santa Fe de Nuevo Mexico, and includes all of present-day California, Nevada and Utah, most of Arizona, and western portions of New Mexico, Colorado, and Wyoming.\\r\\nArticles VIII and IX ensured safety of existing property rights of Mexican citizens living in the transferred territories. Despite assurances to the contrary, the property rights of Mexican citizens were often not honored by the U.S. in accordance with modifications to and interpretations of the Treaty.[6][7][8] The U.S. also agreed to assume $3.25 million (equivalent to $90.0 million today) in debts that Mexico owed to United States citizens.\\r\\nThe residents had one year to choose whether they wanted American or Mexican citizenship; Over 90% chose American citizenship. The others returned to Mexico (where they received land), or in some cases in New Mexico were allowed to remain in place as Mexican citizens.[9][10]\\r\\nArticle XII engaged the United States to pay, \\"In consideration of the extension acquired\\", 15 million dollars (equivalent to $420 million today),[11] in annual installments of 3 million dollars.\\r\\nArticle XI of the treaty was important to Mexico. It provided that the United States would prevent and punish raids by Indians into Mexico, prohibited Americans from acquiring property, including livestock, taken by the Indians in those raids, and stated that the U.S. would return captives of the Indians to Mexico. Mexicans believed that the United States had encouraged and assisted the Comanche and Apache raids that had devastated northern Mexico in the years before the war. This article promised relief to them [12]\\r\\nArticle XI, however, proved unenforceable. Destructive Indian raids continued despite a heavy U.S. presence near the Mexican border. Mexico filed 366 claims with the U.S. government for damages done by Comanche and Apache raids between 1848 and 1853.[13] In 1853, in the Treaty of Mesilla concluding the Gadsden Purchase, Article XI was annulled.[14]\\r\\nThe land that the Treaty of Guadalupe Hidalgo brought into the United States became, between 1845 and 1912, all or part of ten states: California (1850), Nevada (1864), Utah (1896), and Arizona (1912), as well as the whole of, depending upon interpretation, the entire state of Texas (1845), which then included part of Kansas (1861); Colorado (1876); Wyoming (1890); Oklahoma (1907); and New Mexico (1912). The remainder (the southern parts) of New Mexico and Arizona were peacefully purchased under the Gadsden Purchase, which was carried out in 1853. In this purchase the United States paid an additional $10 million (equivalent to $290 million today), for land intended to accommodate a transcontinental railroad. However, the American Civil War delayed construction of such a route, and it was not until 1881 that the Southern Pacific Railroad finally was completed, fulfilling the purpose of the acquisition.[15]\\r\\nMexico had claimed the area in question since winning its independence from the Spanish Empire in 1821 following the Mexican War of Independence. The Spanish Empire had conquered part of the area from the American Indian tribes over the preceding three centuries, but there remained rather powerful and independent indigenous nations within that northern region of Mexico. Most of that land was too dry (low rainfall) and too mountainous or hilly to support very much population until the advent of new technology following about 1880: means for damming and distributing water from the few rivers to irrigated farmland; the telegraph; the railroad; the telephone; and electrical power.\\r\\nAbout 80,000 Mexicans lived in the areas of California, New Mexico, Arizona, and Texas during the period of 1845 to 1850, and far fewer in Nevada, in southern and western Colorado, and in Utah.[16] On 1 March 1845, U.S. President John Tyler signed legislation to authorize the United States to annex the Republic of Texas, effective on 29 December 1845. The Mexican government, which had never recognized the Republic of Texas as an independent country, had warned that annexation would be viewed as an act of war. The United Kingdom and France, both of which recognized the independence of the Republic of Texas, repeatedly tried to dissuade Mexico from declaring war against its northern neighbor. British efforts to mediate the quandary proved fruitless ÿ in part because additional political disputes (particularly the Oregon boundary dispute) arose between Great Britain (as the sovereign of Canada) and the United States.\\r\\nBefore the outbreak of hostilities, President James K. Polk sent his envoy, John Slidell, on 10 November 1845 to Mexico with instructions to offer Mexico around $5 million for the territory of Nuevo Mxico and up to $40 million for Alta California.[17] The Mexican government dismissed Slidell, refusing to even meet with him.[18] Earlier in that year, Mexico had broken off diplomatic relations with the United States, based partly on its interpretation of the AdamsÿOns Treaty of 1819 (under which newly independent Mexico claimed it had inherited rights). In that agreement, the United States had supposedly \\"renounced forever\\" all claims to Spanish territory.[19][20]\\r\\nNeither side took any further action to avoid a war. Meanwhile, Polk settled a major territorial dispute with Britain with the Oregon Treaty, signed on 15 June 1846; this avoided a conflict with Great Britain, and hence gave the U.S. a free hand. After the Thornton Affair of 25ÿ26 April, when Mexican forces attacked an American unit in the disputed area with 11 Americans killed, 5 wounded and 49 captured, Congress passed and Polk signed a declaration of war into effect on 13 May 1846. The Mexican Congress responded with its war declaration on 7 July 1846.[citation needed]\\r\\nCalifornia and New Mexico were quickly occupied by American forces in the summer of 1846, and fighting there ended on[21] 13 January 1847 with the signing of the \\"Capitulation Agreement\\" at \\"Campo de Cahuenga\\" and end of the Taos Revolt. By the middle of September 1847, U.S. forces had successfully invaded central Mexico and occupied Mexico City.\\r\\nSome Eastern Democrats called for complete annexation of Mexico and claimed that some Mexican liberals would welcome this,[22] but President Polk's State of the Union address in December 1847 upheld Mexican independence and argued at length that occupation and any further military operations in Mexico were aimed at securing a treaty ceding California and New Mexico up to approximately the 32nd parallel north and possibly Baja California and transit rights across the Isthmus of Tehuantepec.[18]\\r\\nDespite its lengthy string of military defeats, the Mexican government was reluctant to agree to the loss of California and New Mexico. Even with its capital under enemy occupation, the Mexican government was inclined to consider factors such as the unwillingness of the U.S. administration to annex Mexico outright and what appeared to be deep divisions in domestic U.S. opinion regarding the war and its aims, which gave it reason to conclude that it was actually in a far better negotiating position than the military situation might have suggested. A further consideration was the Mexican government's opposition to slavery and its awareness of the well-known and growing sectional divide in the U.S. over the issue of slavery. It therefore made sense for Mexico to negotiate with a goal of pandering to Northern U.S. interests at the expense of Southern U.S. interests.\\r\\nThe Mexicans proposed peace terms that offered only sale of Alta California north of the 37th parallel north ÿ north of Santa Cruz, California and Madera, California and the southern boundaries of today's Utah and Colorado. This territory was already dominated by Anglo-American settlers, but perhaps more importantly from the Mexican point of view, it represented the bulk of pre-war Mexican territory north of the Missouri Compromise line of parallel 3630 north ÿ lands that, if annexed by the U.S., would have been presumed by Northerners to be forever free of slavery. The Mexicans also offered to recognize the U.S. annexation of Texas, but held to its demand of the Nueces River as a boundary.\\r\\nWhile the Mexican government could not reasonably have expected the Polk Administration to accept such terms, it would have had reason to hope that a rejection of peace terms so favorable to Northern interests might have the potential to provoke sectional conflict in the United States, or perhaps even a civil war that would fatally undermine the U.S. military position in Mexico. Instead, these terms combined with other Mexican demands (in particular, for various indemnities) only provoked widespread indignation throughout the U.S. without causing the sectional conflict the Mexicans were hoping for.\\r\\nJefferson Davis advised Polk that if Mexico appointed commissioners to come to the U.S., the government that appointed them would probably be overthrown before they completed their mission, and they would likely be shot as traitors on their return; so that the only hope of peace was to have a U.S representative in Mexico.[23] Nicholas Trist, chief clerk of the State Department under President Polk, finally negotiated a treaty with the Mexican delegation after ignoring his recall by President Polk in frustration with failure to secure a treaty.[24] Notwithstanding that the treaty had been negotiated against his instructions, given its achievement of the major American aim, President Polk passed it on to the Senate.[24]\\r\\nThe Treaty of Guadalupe Hidalgo was signed by Nicholas Trist (on behalf of the U.S.) and Luis G. Cuevas, Bernardo Couto and Miguel Atristain as plenipotentiary representatives of Mexico on 2 February 1848, at the main altar of the old Basilica of Guadalupe at Villa Hidalgo (within the present city limits) as U.S. troops under the command of Gen. Winfield Scott were occupying Mexico City.\\r\\nThe version of the treaty ratified by the United States Senate eliminated Article X,[25] which stated that the U.S. government would honor and guarantee all land grants awarded in lands ceded to the U.S. to citizens of Spain and Mexico by those respective governments. Article VIII guaranteed that Mexicans who remained more than one year in the ceded lands would automatically become full-fledged United States citizens (or they could declare their intention of remaining Mexican citizens); however, the Senate modified Article IX, changing the first paragraph and excluding the last two. Among the changes was that Mexican citizens would \\"be admitted at the proper time (to be judged of by the Congress of the United States)\\" instead of \\"admitted as soon as possible\\", as negotiated between Trist and the Mexican delegation.\\r\\nAn amendment by Jefferson Davis giving the U.S. most of Tamaulipas and Nuevo Le܇n, all of Coahuila and a large part of Chihuahua was supported by both senators from Texas (Sam Houston and Thomas Jefferson Rusk), Daniel S. Dickinson of New York, Stephen A. Douglas of Illinois, Edward A. Hannegan of Indiana, and one each from Alabama, Florida, Mississippi, Ohio, Missouri and Tennessee. Most of the leaders of the Democratic party, Thomas Hart Benton, John C. Calhoun, Herschel V. Johnson, Lewis Cass, James Murray Mason of Virginia and Ambrose Hundley Sevier were opposed and the amendment was defeated 44ÿ11.[26]\\r\\nAn amendment by Whig Sen. George Edmund Badger of North Carolina to exclude New Mexico and California lost 35ÿ15, with three Southern Whigs voting with the Democrats. Daniel Webster was bitter that four New England senators made deciding votes for acquiring the new territories.\\r\\nA motion to insert into the treaty the Wilmot Proviso (banning slavery from the acquired territories) failed 15ÿ38 on sectional lines.\\r\\nThe treaty was subsequently ratified by the U.S. Senate by a vote of 38 to 14 on 10 March 1848 and by Mexico through a legislative vote of 51 to 34 and a Senate vote of 33 to 4, on 19 May 1848. News that New Mexico's legislative assembly had just passed an act for organization of a U.S. territorial government helped ease Mexican concern about abandoning the people of New Mexico.[27] The treaty was formally proclaimed on 4 July 1848.[28]\\r\\nOn 30 May 1848, when the two countries exchanged ratifications of the treaty of Guadalupe Hidalgo, they further negotiated a three-article protocol to explain the amendments. The first article stated that the original Article IX of the treaty, although replaced by Article III of the Treaty of Louisiana, would still confer the rights delineated in Article IX. The second article confirmed the legitimacy of land grants pursuant to Mexican law.[29]\\r\\nThe protocol further noted that said explanations had been accepted by the Mexican Minister of Foreign Affairs on behalf of the Mexican Government,[29] and was signed in Santiago de Quertaro by A. H. Sevier, Nathan Clifford and Luis de la Rosa.\\r\\nThe U.S. would later go on to ignore the protocol on the grounds that the U.S. representatives had over-reached their authority in agreeing to it.[30]\\r\\nThe Treaty of Mesilla, which concluded the Gadsden purchase of 1854, had significant implications for the treaty of Guadalupe Hidalgo. Article II of the treaty annulled article XI of the treaty of Guadalupe Hidalgo, and article IV further annulled articles VI and VII of Guadalupe Hidalgo. Article V however reaffirmed the property guarantees of Guadalupe Hidalgo, specifically those contained within articles VIII and IX.[31]\\r\\nIn addition to the sale of land, the treaty also provided for the recognition of the Rio Grande as the boundary between the state of Texas and Mexico.[32] The land boundaries were established by a survey team of appointed Mexican and American representatives,[24] and published in three volumes as The United States and Mexican Boundary Survey. On 30 December 1853, the countries by agreement altered the border from the initial one by increasing the number of border markers from 6 to 53.[24] Most of these markers were simply piles of stones.[24] Two later conventions, in 1882 and 1889, further clarified the boundaries, as some of the markers had been moved or destroyed.[24] Photographers were brought in to document the location of the markers. These photographs are in Record Group 77, Records of the Office of the Chief Engineers, in the National Archives.\\r\\nThe southern border of California was designated as a line from the junction of the Colorado and Gila rivers westward to the Pacific Ocean, so that it passes one Spanish league south of the southernmost portion of San Diego Bay. This was done to ensure that the United States received San Diego and its excellent natural harbor, without relying on potentially inaccurate designations by latitude.[citation needed]\\r\\nThe treaty extended the choice of U.S. citizenship to Mexicans in the newly purchased territories, before many African Americans, Asians and Native Americans were eligible. If they chose to, they had to declare to the U.S. government within a year the Treaty was signed; otherwise, they could remain Mexican citizens, but they would have to relocate. [5] Between 1850 and 1920, the U.S. Census counted most Mexicans as racially \\"white\\".[33] Nonetheless, racially tinged tensions persisted in the era following annexation, reflected in such things as the Greaser Act in California, as tens of thousands of Mexican nationals suddenly found themselves living within the borders of the United States. Mexican communities remained segregated de facto from and also within other U.S. communities, continuing through the Mexican migration right up to the end of the 20th century throughout the Southwest.[citation needed]\\r\\nCommunity property rights in California are a legacy of the Mexican era. The Treaty of Guadalupe Hidalgo provided that the property rights of Mexican subjects would be kept inviolate. The early Californians felt compelled to continue the community property system regarding the earnings and accumulation of property during a marriage, and it became incorporated into the California constitution.[34]\\r\\nBorder disputes continued. The U.S.'s desire to expand its territory continued unabated and Mexico's economic problems persisted,[35] leading to the controversial Gadsden Purchase in 1854 and William Walker's Republic of Lower California filibustering incident in that same year.[citation needed] The Channel Islands of California and Farallon Islands are not mentioned in the Treaty.[36]\\r\\nThe border was routinely crossed by the armed forces of both countries. Mexican and Confederate troops often clashed during the American Civil War, and the U.S. crossed the border during the war of French intervention in Mexico. In March 1916 Pancho Villa led a raid on the U.S. border town of Columbus, New Mexico, which was followed by the Pershing expedition. The shifting of the Rio Grande would much later cause a dispute over the boundary between purchase lands and those of the state of Texas, called the Country Club Dispute.[citation needed] Controversy over community land grant claims in New Mexico persists to this day.[37]\\r\\nDisputes about whether to make all this new territory into free states or slave-holding states contributed heavily to the rise in North-South tensions that led to the American Civil War just over a decade later. The treaty was leaked to John Nugent before the U.S. Senate could approve it. Nugent published his article in the New York Herald and, afterward, was questioned by Senators. Nugent did not reveal his source.[citation needed]\\r\\nThe Treaty of Guadalupe Hidalgo led to the establishment in 1889 of the International Boundary and Water Commission to maintain the border, and pursuant to newer treaties to allocate river waters between the two nations, and to provide for flood control and water sanitation. Once viewed as a model of international cooperation, in recent decades the IBWC has been heavily criticized as an institutional anachronism, by-passed by modern social, environmental and political issues.[38]","input":"When was the treaty of guadalupe hidalgo signed?"},{"output":"May 1967","context":"Nigeria Security and Civil Defence corps (NSCDC) is a paramilitary institution that was established in May 1967 by the Federal Republic of Nigeria, with the act of National Assembly (Nigeria).[1] The act was amended in 2007, to enhance the statutory duties of the corp.[2] Nigerian Security and Civil Defence Corps is a para-military agency of the Government of the Federal Republic of Nigeria that is commissioned to provide measures against threat and any form of attack or disaster against the nation and its citizenry. The corps is statutorily empowered by lay Act No. 2 of 2003 and amended by Act 6 of 4th June 2007.\\r\\nThe Corps is empowered to institute legal proceedings by or in then and of the Attorney General of the Federation in accordance with the provisions of the constitution of the Federal Republic of Nigeria against any person or persons suspected to have committed an offence, maintain an armed squad in order to bear fire arms among others to strengthen the corps in the discharge of its statutory duties\\r\\nThe Nigeria Security and Civil Defence Corps was first introduced in May 1967 during the Nigerian Civil War within the then Federal Capital Territory of Lagos for the purpose of sensitization and protection of the civil populace. It was then known as Lagos Civil Defence Committee.\\r\\nIt later metamorphosed into the present day Nigeria Security and Civil Defence Corps in 1970. On inception, the Corps had the objective of carrying out some educational and enlightenment campaigns in and around the Federal Capital of Lagos to sensitize members of the civil populace on enemy attacks and how to save themselves from danger as most Nigerians living in and around Lagos territory then had little or no knowledge about war and its implications. Members of the Committee deemed it important to educate through electronic and print media on how to guide themselves during air raids, bomb attacks, identify bombs and how to dive into trenches during bomb blast.\\r\\nIn 1984, the Corps was transformed into a National security outfit and in 1988, there was a major re-structuring of the Corps that led to the establishment of Commands throughout the Federation, including Abuja, and the addition of special functions by the Federal Government. On 28th June 2003, an Act to give statutory backing to the NSCDC passed by the National Assembly was signed into law by Chief Olusegun Obasanjo, GCFR, the former president and Commander in chief of the Armed Forces, Federal Republic of Nigeria.\\r\\nThe primary function of the NSCDC is to protect lives and properties in conjunction with Nigeria police.[3] One of the crucial function of the corp is to protect pipelines from vandalism.[4] The agency also involves in crisis resolutions.[5] They protect the country","input":"When was nigeria security and civil defence corps established?"},{"output":"Rigveda","context":"Divisions\\r\\nSama vedic\\r\\nYajur vedic\\r\\nAtharva vedic\\r\\nVaishnava puranas\\r\\nShaiva puranas\\r\\nThe Vedas (/?ve?d?z/;[1] Sanskrit: ??? veda, \\"knowledge\\") are a large body of knowledge texts originating in the ancient Indian subcontinent. Composed in Vedic Sanskrit, the texts constitute the oldest layer of Sanskrit literature and the oldest scriptures of Hinduism.[2][3] Hindus consider the Vedas to be apauru?eya, which means \\"not of a man, superhuman\\"[4] and \\"impersonal, authorless\\".[5][6][7]\\r\\nVedas are also called ?ruti (\\"what is heard\\") literature,[8] distinguishing them from other religious texts, which are called sm?ti (\\"what is remembered\\"). The Veda, for orthodox Indian theologians, are considered revelations seen by ancient sages after intense meditation, and texts that have been more carefully preserved since ancient times.[9][10] In the Hindu Epic the Mahabharata, the creation of Vedas is credited to Brahma.[11] The Vedic hymns themselves assert that they were skillfully created by Rishis (sages), after inspired creativity, just as a carpenter builds a chariot.[10][note 1]\\r\\nThere are four Vedas: the Rigveda, the Yajurveda, the Samaveda and the Atharvaveda.[13][14] Each Veda has been subclassified into four major text types ÿ the Samhitas (mantras and benedictions), the Aranyakas (text on rituals, ceremonies, sacrifices and symbolic-sacrifices), the Brahmanas (commentaries on rituals, ceremonies and sacrifices), and the Upanishads (texts discussing meditation, philosophy and spiritual knowledge).[13][15][16] Some scholars add a fifth category ÿ the Upasanas (worship).[17][18]\\r\\nThe various Indian philosophies and denominations have taken differing positions on the Vedas. Schools of Indian philosophy which cite the Vedas as their scriptural authority are classified as \\"orthodox\\" (stika).[note 2] Other ?rama?a traditions, such as Lokayata, Carvaka, Ajivika, Buddhism and Jainism, which did not regard the Vedas as authorities, are referred to as \\"heterodox\\" or \\"non-orthodox\\" (nstika) schools.[20][21] Despite their differences, just like the texts of the ?rama?a traditions, the layers of texts in the Vedas discuss similar ideas and concepts.[20]\\r\\n\\r\\n\\r\\nThe Sanskrit word vda \\"knowledge, wisdom\\" is derived from the root vid- \\"to know\\". This is reconstructed as being derived from the Proto-Indo-European root *u?eid-, meaning \\"see\\" or \\"know\\".[22]\\r\\nThe noun is from Proto-Indo-European *u?eidos, cognate to Greek (?)?Ѵ? \\"aspect\\", \\"form\\" . Not to be confused is the homonymous 1st and 3rd person singular perfect tense vda, cognate to Greek (?)?Ѵϫ (w)oida \\"I know\\". Root cognates are Greek ?Ѵ?ϫ, English wit, etc., Latin vide \\"I see\\", etc.[23]\\r\\nThe Sanskrit term veda as a common noun means \\"knowledge\\".[24] The term in some contexts, such as hymn 10.93.11 of the Rigveda, means \\"obtaining or finding wealth, property\\",[25] while in some others it means \\"a bunch of grass together\\" as in a broom or for ritual fire.[26]\\r\\nA related word Vedena appears in hymn 8.19.5 of the Rigveda.[27] It was translated by Ralph T. H. Griffith as \\"ritual lore\\",[28] as \\"studying the Veda\\" by the 14th century Indian scholar Sayana, as \\"bundle of grass\\" by Max Mller, and as \\"with the Veda\\" by H.H. Wilson.[29]\\r\\nVedas are called Ma?ai or Vaymoli in parts of South India. Marai literally means \\"hidden, a secret, mystery\\".[30][31] In some south Indian communities such as Iyengars, the word Veda includes the Tamil writings of the Alvar saints, such as Divya Prabandham, for example Tiruvaymoli.[32]\\r\\nThe Vedas are among the oldest sacred texts.[33][34] The Samhitas date to roughly 1700ÿ1100 BC,[35] and the \\"circum-Vedic\\" texts, as well as the redaction of the Samhitas, date to c. 1000-500 BC, resulting in a Vedic period, spanning the mid 2nd to mid 1st millennium BC, or the Late Bronze Age and the Iron Age.[36] The Vedic period reaches its peak only after the composition of the mantra texts, with the establishment of the various shakhas all over Northern India which annotated the mantra samhitas with Brahmana discussions of their meaning, and reaches its end in the age of Buddha and Panini and the rise of the Mahajanapadas (archaeologically, Northern Black Polished Ware). Michael Witzel gives a time span of c. 1500 to c. 500-400 BC. Witzel makes special reference to the Near Eastern Mitanni material of the 14th century BC the only epigraphic record of Indo-Aryan contemporary to the Rigvedic period. He gives 150 BC (Pata?jali) as a terminus ante quem for all Vedic Sanskrit literature, and 1200 BC (the early Iron Age) as terminus post quem for the Atharvaveda.[37]\\r\\nTransmission of texts in the Vedic period was by oral tradition, preserved with precision with the help of elaborate mnemonic techniques. A literary tradition is traceable in post-Vedic times, after the rise of Buddhism in the Maurya period,[note 3] perhaps earliest in the Kanva recension of the Yajurveda about the 1st century BC; however oral tradition of transmission remained active. Witzel suggests the possibility of written Vedic texts towards the end of 1st millennium BCE.[39] Some scholars such as Jack Goody state that \\"the Vedas are not the product of an oral society\\", basing this view by comparing inconsistencies in the transmitted versions of literature from various oral societies such as the Greek, Serbia and other cultures, then noting that the Vedic literature is too consistent and vast to have been composed and transmitted orally across generations, without being written down.[40] However, adds Goody, the Vedic texts likely involved both a written and oral tradition, calling it a \\"parallel products of a literate society\\".[38][40]\\r\\nDue to the ephemeral nature of the manuscript material (birch bark or palm leaves), surviving manuscripts rarely surpass an age of a few hundred years.[41] The Sampurnanand Sanskrit University has a Rigveda manuscript from the 14th century;[42] however, there are a number of older Veda manuscripts in Nepal that are dated from the 11th century onwards.[43]\\r\\nThe Vedas, Vedic rituals and its ancillary sciences called the Vedangas, were part of the curriculum at ancient universities such as at Taxila, Nalanda and Vikramashila.[44][45][46][47]\\r\\nThe term \\"Vedic texts\\" is used in two distinct meanings:\\r\\nThe corpus of Vedic Sanskrit texts includes:\\r\\nThe Vedas (sruti) are different from Vedic era texts such as Shrauta Sutras and Gryha Sutras, which are smriti texts. Together, the Vedas and these Sutras form part of the Vedic Sanskrit corpus.[54][55][56]\\r\\nWhile production of Brahmanas and Aranyakas ceased with the end of the Vedic period, additional Upanishads were composed after the end of the Vedic period.[57]\\r\\nThe Brahmanas, Aranyakas, and Upanishads, among other things, interpret and discuss the Samhitas in philosophical and metaphorical ways to explore abstract concepts such as the Absolute (Brahman), and the soul or the self (Atman), introducing Vedanta philosophy, one of the major trends of later Hinduism. In other parts, they show evolution of ideas, such as from actual sacrifice to symbolic sacrifice, and of spirituality in the Upanishads. This has inspired later Hindu scholars such as Adi Shankara to classify each Veda into karma-kanda (???? ????, action/ritual-related sections) and jnana-kanda (????? ????, knowledge/spirituality-related sections).[17][58]\\r\\nThe texts considered \\"Vedic\\" in the sense of \\"corollaries of the Vedas\\" is less clearly defined, and may include numerous post-Vedic texts such as the later Upanishads and the Sutra literature. Texts not considered to be shruti are known as smriti (Sanskrit: sm?ti; \\"the remembered\\"), or texts of remembered traditions. This indigenous system of categorization was adopted by Max Mller and, while it is subject to some debate, it is still widely used. As Axel Michaels explains:[53]\\r\\nThese classifications are often not tenable for linguistic and formal reasons: There is not only one collection at any one time, but rather several handed down in separate Vedic schools; Upani?ads ... are sometimes not to be distinguished from ra?yakas...; Brhma?as contain older strata of language attributed to the Sa?hits; there are various dialects and locally prominent traditions of the Vedic schools. Nevertheless, it is advisable to stick to the division adopted by Max Mller because it follows the Indian tradition, conveys the historical sequence fairly accurately, and underlies the current editions, translations, and monographs on Vedic literature.\\"[53]\\r\\nThe Upanishads are largely philosophical works, some in dialogue form. They are the foundation of Hindu philosophical thought and its diverse traditions.[59][60] Of the Vedic corpus, they alone are widely known, and the central ideas of the Upanishads are at the spiritual core of Hindus.[59][61]\\r\\nThe four Vedas were transmitted in various ?khs (branches, schools).[62][63] Each school likely represented an ancient community of a particular area, or kingdom.[63] Each school followed its own canon. Multiple recensions are known for each of the Vedas.[62] Thus, states Witzel as well as Renou, in the 2nd millennium BC, there was likely no canon of one broadly accepted Vedic texts, no Vedic Scripture, but only a canon of various texts accepted by each school. Some of these texts have survived, most lost or yet to be found. Rigveda that survives in modern times, for example, is in only one extremely well preserved school of ??kalya, from a region called Videha, in modern north Bihar, south of Nepal.[64] The Vedic canon in its entirety consists of texts from all the various Vedic schools taken together.[63]\\r\\nEach of the four Vedas were shared by the numerous schools, but revised, interpolated and adapted locally, in and after the Vedic period, giving rise to various recensions of the text. Some texts were revised into the modern era, raising significant debate on parts of the text which are believed to have been corrupted at a later date.[65][66] The Vedas each have an Index or Anukramani, the principal work of this kind being the general Index or Sarvnukrama?ؐ.[67][68]\\r\\nProdigious energy was expended by ancient Indian culture in ensuring that these texts were transmitted from generation to generation with inordinate fidelity.[69] For example, memorization of the sacred Vedas included up to eleven forms of recitation of the same text. The texts were subsequently \\"proof-read\\" by comparing the different recited versions. Forms of recitation included the ja?-p?ha (literally \\"mesh recitation\\") in which every two adjacent words in the text were first recited in their original order, then repeated in the reverse order, and finally repeated in the original order.[70] That these methods have been effective, is testified to by the preservation of the most ancient Indian religious text, the Rigveda, as redacted into a single text during the Brahmana period, without any variant readings within that school.[70]\\r\\nThe Vedas were likely written down for the first time around 500 BC.[71] However, all printed editions of the Vedas that survive in the modern times are likely the version existing in about the 16th century AD.[72]\\r\\nThe canonical division of the Vedas is fourfold (turؐya) viz.,[73]\\r\\nOf these, the first three were the principal original division, also called \\"trayؐ vidy\\"; that is, \\"the triple science\\" of reciting hymns (Rigveda), performing sacrifices (Yajurveda), and chanting songs (Samaveda).[74][75] The Rigveda is the oldest work, which Witzel states are probably from the period of 1900 to 1100 BC. Witzel, also notes that it is the Vedic period itself, where incipient lists divide the Vedic texts into three (trayؐ) or four branches: Rig, Yajur, Sama and Atharva.[63]\\r\\nEach Veda has been subclassified into four major text types ÿ the Samhitas (mantras and benedictions), the Aranyakas (text on rituals, ceremonies such as newborn baby's rites of passage, coming of age, marriages, retirement and cremation, sacrifices and symbolic-sacrifices), the Brahmanas (commentaries on rituals, ceremonies and sacrifices), and the Upanishads (text discussing meditation, philosophy and spiritual knowledge).[13][15][16] The Upasanas (short ritual worship-related sections) are considered by some scholars[17][18] as the fifth part. Witzel notes that the rituals, rites and ceremonies described in these ancient texts reconstruct to a large degree the Indo-European marriage rituals observed in a region spanning the Indian subcontinent, Persia and the European area, and some greater details are found in the Vedic era texts such as the Grhya Stras.[76]\\r\\nOnly one version of the Rigveda is known to have survived into the modern era.[64] Several different versions of the Sama Veda and the Atharva Veda are known, and many different versions of the Yajur Veda have been found in different parts of South Asia.[77]\\r\\nWho really knows?\\r\\nWho can here proclaim it?\\r\\nWhence, whence this creation sprang?\\r\\nGods came later, after the creation of this universe.\\r\\nWho then knows whence it has arisen?\\r\\nWhether God's will created it, or whether He was mute;\\r\\nOnly He who is its overseer in highest heaven knows,\\r\\nThe Rigveda Samhita is the oldest extant Indic text.[79] It is a collection of 1,028 Vedic Sanskrit hymns and 10,600 verses in all, organized into ten books (Sanskrit: mandalas).[80] The hymns are dedicated to Rigvedic deities.[81]\\r\\nThe books were composed by poets from different priestly groups over a period of several centuries from roughly the second half of the 2nd millennium BC (the early Vedic period), starting with the Punjab (Sapta Sindhu) region of the northwest Indian subcontinent.[82] The Rigveda is structured based on clear principles ÿ the Veda begins with a small book addressed to Agni, Indra, and other gods, all arranged according to decreasing total number of hymns in each deity collection; for each deity series, the hymns progress from longer to shorter ones, but the number of hymns per book increases. Finally, the meter too is systematically arranged from jagati and tristubh to anustubh and gayatri as the text progresses.[63] In terms of substance, the nature of hymns shift from praise of deities in early books to Nasadiya Sukta with questions such as, \\"what is the origin of the universe?, do even gods know the answer?\\",[78] the virtue of Dna (charity) in society,[83] and other metaphysical issues in its hymns.[84]\\r\\nThere are similarities between the mythology, rituals and linguistics in Rigveda and those found in ancient central Asia, Iranian and Hindukush (Afghanistan) regions.[85]\\r\\nThe Samaveda Samhita[86] consists of 1549 stanzas, taken almost entirely (except for 75 mantras) from the Rigveda.[53][87] The Samaveda samhita has two major parts. The first part includes four melody collections (gna, ???) and the second part three verse books (rcika, ??????).[87] A melody in the song books corresponds to a verse in the arcika books. Just as in the Rigveda, the early sections of Samaveda typically begin with hymns to Agni and Indra but shift to the abstract. Their meters shift also in a descending order. The songs in the later sections of the Samaveda have the least deviation from the hymns derived from the Rigveda.[87]\\r\\nIn the Samaveda, some of the Rigvedic verses are repeated.[88] Including repetitions, there are a total of 1875 verses numbered in the Samaveda recension translated by Griffith.[89] Two major recensions have survived, the Kauthuma/Ranayaniya and the Jaiminiya. Its purpose was liturgical, and they were the repertoire of the udgt? or \\"singer\\" priests.[90]\\r\\nThe Yajurveda Samhita consists of prose mantras.[91] It is a compilation of ritual offering formulas that were said by a priest while an individual performed ritual actions such as those before the yajna fire.[91]\\r\\nThe earliest and most ancient layer of Yajurveda samhita includes about 1,875 verses, that are distinct yet borrow and build upon the foundation of verses in Rigveda.[92] Unlike the Samaveda which is almost entirely based on Rigveda mantras and structured as songs, the Yajurveda samhitas are in prose and linguistically, they are different from earlier Vedic texts.[93] The Yajur Veda has been the primary source of information about sacrifices during Vedic times and associated rituals.[94]\\r\\nThere are two major groups of texts in this Veda: the \\"Black\\" (Krishna) and the \\"White\\" (Shukla). The term \\"black\\" implies \\"the un-arranged, motley collection\\" of verses in Yajurveda, in contrast to the \\"white\\" (well arranged) Yajurveda.[95] The White Yajurveda separates the Samhita from its Brahmana (the Shatapatha Brahmana), the Black Yajurveda intersperses the Samhita with Brahmana commentary. Of the Black Yajurveda, texts from four major schools have survived (Maitrayani, Katha, Kapisthala-Katha, Taittiriya), while of the White Yajurveda, two (Kanva and Madhyandina).[96][97] The youngest layer of Yajurveda text is not related to rituals nor sacrifice, it includes the largest collection of primary Upanishads, influential to various schools of Hindu philosophy.[98][99]\\r\\nThe Artharvaveda Samhita is the text 'belonging to the Atharvan and Angirasa poets. It has about 760 hymns, and about 160 of the hymns are in common with the Rigveda.[100] Most of the verses are metrical, but some sections are in prose.[100] Two different versions of the text ÿ the Paippalda and the ?aunakؐya ÿ have survived into the modern times.[100][101] The Atharvaveda was not considered as a Veda in the Vedic era, and was accepted as a Veda in late 1st millennium BC.[102][103] It was compiled last,[104] probably around 900 BC, although some of its material may go back to the time of the Rigveda,[105] or earlier.[100]\\r\\nThe Atharvaveda is sometimes called the \\"Veda of magical formulas\\",[106] an epithet declared to be incorrect by other scholars.[107] The Samhita layer of the text likely represents a developing 2nd millennium BC tradition of magico-religious rites to address superstitious anxiety, spells to remove maladies believed to be caused by demons, and herbs- and nature-derived potions as medicine.[108][109] The text, states Kenneth Zysk, is one of oldest surviving record of the evolutionary practices in religious medicine and reveals the \\"earliest forms of folk healing of Indo-European antiquity\\".[110] Many books of the Atharvaveda Samhita are dedicated to rituals without magic, such as to philosophical speculations and to theosophy.[107]\\r\\nThe Atharva veda has been a primary source for information about Vedic culture, the customs and beliefs, the aspirations and frustrations of everyday Vedic life, as well as those associated with kings and governance. The text also includes hymns dealing with the two major rituals of passage ÿ marriage and cremation. The Atharva Veda also dedicates significant portion of the text asking the meaning of a ritual.[111]\\r\\nThe Brahmanas are commentaries, explanation of proper methods and meaning of Vedic Samhita rituals in the four Vedas.[112] They also incorporate myths, legends and in some cases philosophy.[112][51] Each regional Vedic shakha (school) has its own operating manual-like Brahmana text, most of which have been lost.[113] A total of 19 Brahmana texts have survived into modern times: two associated with the Rigveda, six with the Yajurveda, ten with the Samaveda and one with the Atharvaveda. The oldest dated to about 900 BC, while the youngest Brahmanas (such as the Shatapatha Brahmana), were complete by about 700 BC.[114][115] According to Jan Gonda, the final codification of the Brahmanas took place in pre-Buddhist times (ca. 600 BC).[116]\\r\\nThe substance of the Brahmana text varies with each Veda. For example, the first chapter of the Chandogya Brahmana, one of the oldest Brahmanas, includes eight ritual suktas (hymns) for the ceremony of marriage and rituals at the birth of a child.[117][118] The first hymn is a recitation that accompanies offering a Yajna oblation to Agni (fire) on the occasion of a marriage, and the hymn prays for prosperity of the couple getting married.[117][119] The second hymn wishes for their long life, kind relatives, and a numerous progeny.[117] The third hymn is a mutual marriage pledge, between the bride and groom, by which the two bind themselves to each other. The sixth through last hymns of the first chapter in Chandogya Brahmana are ritual celebrations on the birth of a child and wishes for health, wealth, and prosperity with a profusion of cows and artha.[117] However, these verses are incomplete expositions, and their complete context emerges only with the Samhita layer of text.[120]\\r\\nThe Aranyakas layer of the Vedas include rituals, discussion of symbolic meta-rituals, as well as philosophical speculations.[18][52]\\r\\nAranyakas, however, neither are homogeneous in content nor in structure.[52] They are a medley of instructions and ideas, and some include chapters of Upanishads within them. Two theories have been proposed on the origin of the word Aranyakas. One theory holds that these texts were meant to be studied in a forest, while the other holds that the name came from these being the manuals of allegorical interpretation of sacrifices, for those in Vanaprastha (retired, forest-dwelling) stage of their life, according to the historic age-based Ashrama system of human life.[121]\\r\\nThe Upanishads reflect the last composed layer of texts in the Vedas. They are commonly referred to as Vednta, variously interpreted to mean either the \\"last chapters, parts of the Vedas\\" or \\"the object, the highest purpose of the Veda\\".[122] The concepts of Brahman (Ultimate Reality) and tman (Soul, Self) are central ideas in all the Upanishads,[123][124] and \\"Know your tman\\" their thematic focus.[124][125] The Upanishads are the foundation of Hindu philosophical thought and its diverse traditions.[59][126] Of the Vedic corpus, they alone are widely known, and the central ideas of the Upanishads have influenced the diverse traditions of Hinduism.[59][127]\\r\\nAranyakas are sometimes identified as karma-kanda (ritualistic section), while the Upanishads are identified as jnana-kanda (spirituality section).[17][128] In an alternate classification, the early part of Vedas are called Samhitas and the commentary are called the Brahmanas which together are identified as the ceremonial karma-kanda, while Aranyakas and Upanishads are referred to as the jnana-kanda.[129]\\r\\nThe Vedangas developed towards the end of the vedic period, around or after the middle of the 1st millennium BC. These auxiliary fields of Vedic studies emerged because the language of the Vedas, composed centuries earlier, became too archaic to the people of that time.[130] The Vedangas were sciences that focused on helping understand and interpret the Vedas that had been composed many centuries earlier.[130]\\r\\nThe six subjects of Vedanga are phonetics (?ik?), poetic meter (Chandas), grammar (Vykara?a), etymology and linguistics (Nirukta), rituals and rites of passage (Kalpa), time keeping and astronomy (Jyoti?a).[131][132][133]\\r\\nVedangas developed as ancillary studies for the Vedas, but its insights into meters, structure of sound and language, grammar, linguistic analysis and other subjects influenced post-Vedic studies, arts, culture and various schools of Hindu philosophy.[134][135][136] The Kalpa Vedanga studies, for example, gave rise to the Dharma-sutras, which later expanded into Dharma-shastras.[130][137]\\r\\nPari?i??a \\"supplement, appendix\\" is the term applied to various ancillary works of Vedic literature, dealing mainly with details of ritual and elaborations of the texts logically and chronologically prior to them: the Samhitas, Brahmanas, Aranyakas and Sutras. Naturally classified with the Veda to which each pertains, Parisista works exist for each of the four Vedas. However, only the literature associated with the Atharvaveda is extensive.\\r\\nThe term upaveda (\\"applied knowledge\\") is used in traditional literature to designate the subjects of certain technical works.[139][140] Lists of what subjects are included in this class differ among sources. The Charanavyuha mentions four Upavedas:[141]\\r\\nSome post-Vedic texts, including the Mahabharata, the Natyasastra[144] and certain Puranas, refer to themselves as the \\"fifth Veda\\".[145] The earliest reference to such a \\"fifth Veda\\" is found in the Chandogya Upanishad in hymn 7.1.2.[146]\\r\\nLet drama and dance (Ntya, ?????) be the fifth vedic scripture. Combined with an epic story, tending to virtue, wealth, joy and spiritual freedom, it must contain the significance of every scripture, and forward every art. Thus, from all the Vedas, Brahma framed the Ntya Veda. From the Rig Veda he drew forth the words, from the Sama Veda the melody, from the Yajur Veda gesture, and from the Atharva Veda the sentiment.\\r\\n\\"Divya Prabandha\\", for example Tiruvaymoli, is a term for canonical Tamil texts considered as Vernacular Veda by some South Indian Hindus.[31][32]\\r\\nOther texts such as the Bhagavad Gita or the Vedanta Sutras are considered shruti or \\"Vedic\\" by some Hindu denominations but not universally within Hinduism. The Bhakti movement, and Gaudiya Vaishnavism in particular extended the term veda to include the Sanskrit Epics and Vaishnavite devotional texts such as the Pancaratra.[149]\\r\\nThe Puranas is a vast genre of encyclopedic Indian literature about a wide range of topics particularly myths, legends and other traditional lore.[150] Several of these texts are named after major Hindu deities such as Vishnu, Shiva and Devi.[151][152] There are 18 Maha Puranas (Great Puranas) and 18 Upa Puranas (Minor Puranas), with over 400,000 verses.[150]\\r\\nThe Puranas have been influential in the Hindu culture.[153][154] They are considered Vaidika (congruent with Vedic literature).[155] The Bhagavata Purana has been among the most celebrated and popular text in the Puranic genre, and is of non-dualistic tenor.[156][157] The Puranic literature wove with the Bhakti movement in India, and both Dvaita and Advaita scholars have commented on the underlying Vedanta themes in the Maha Puranas.[158]\\r\\nThe study of Sanskrit in the West began in the 17th century. In the early 19th century, Arthur Schopenhauer drew attention to Vedic texts, specifically the Upanishads. The importance of Vedic Sanskrit for Indo-European studies was also recognized in the early 19th century. English translations of the Samhitas were published in the later 19th century, in the Sacred Books of the East series edited by Mller between 1879 and 1910.[159] Ralph T. H. Griffith also presented English translations of the four Samhitas, published 1889 to 1899.\\r\\nVoltaire regarded Vedas to be exceptional, he remarked that:\\r\\nThe Veda was the most precious gift for which the West had ever been indebted to the East.[160][161]\\r\\nRigveda manuscripts were selected for inscription in UNESCO's Memory of the World Register in 2007.[162]","input":"What are the names of the four vedas?"},{"output":"three","context":"In molecular biology and genetics, GC-content (or guanine-cytosine content) is the percentage of nitrogenous bases on a DNA or RNA molecule that are either guanine or cytosine (from a possibility of four different ones, also including adenine and thymine in DNA and adenine and uracil in RNA).[1] This may refer to a certain fragment of DNA or RNA, or that of the whole genome. When it refers to a fragment of the genetic material, it may denote the GC-content of section of a gene (domain), single gene, group of genes (or gene clusters), or even a non-coding region. G (guanine) and C (cytosine) undergo a specific hydrogen bonding, whereas A (adenine) bonds specifically with T (thymine, in DNA) or U (uracil, in RNA).\\r\\nThe GC pair is bound by three hydrogen bonds, while AT and AU pairs are bound by two hydrogen bonds. To emphasize this difference in the number of hydrogen bonds, the base pairings can be represented as respectively GC versus A=T and A=U. DNA with low GC-content is less stable than DNA with high GC-content; however, the hydrogen bonds themselves do not have a particularly significant impact on stabilization, the stabilization is due mainly to interactions of base stacking.[2] In spite of the higher thermostability conferred to the genetic material, it has been observed that at least some bacteria species with DNA of high GC-content undergo autolysis more readily, thereby reducing the longevity of the cell per se.[3] Due to the thermostability given to the genetic materials in high GC organisms, it was commonly believed that the GC content played a necessary role in adaptation temperatures, a hypothesis that was refuted in 2001.[4] However, it has been shown that there is a strong correlation between the prokaryotic optimal growth at higher temperatures and the GC content of structured RNAs (such as ribosomal RNA, transfer RNA, and many other non-coding RNAs).[4][5] The AU base pairs are less stable than the GC base pairs previously attributed to GC bonds containing 3 hydrogen bonds and AU having only 2 hydrogen bonds, making high-GC-content RNA structures more resistant to the effects of high temperatures. More recently, it has been proved that the most stabilizing factor of thermal stability of double stranded nucleic acids is actually due to the base stackings of adjacent bases, rather than the number of hydrogen bonds between the bases.There is more favorable stacking energy for G:C pairs because of the relative positions of exocyclic groups than in the A:U pairs. Additionally, there is a correlation between the order in which the bases stack and thermal stability.[6]\\r\\nIn PCR experiments, the GC-content of primers are used to predict their annealing temperature to the template DNA. A higher GC-content level indicates a relatively higher melting temperature.\\r\\n\\r\\n\\r\\nGC content is usually expressed as a percentage value, but sometimes as a ratio (called G+C ratio or GC-ratio). GC-content percentage is calculated as[7]\\r\\nwhereas the AT/GC ratio is calculated as[8]\\r\\nThe GC-content percentages as well as GC-ratio can be measured by several means, but one of the simplest methods is to measure what is called the melting temperature of the DNA double helix using spectrophotometry. The absorbance of DNA at a wavelength of 260 nm increases fairly sharply when the double-stranded DNA separates into two single strands when sufficiently heated.[9] The most commonly used protocol for determining GC ratios uses flow cytometry for large number of samples.[10]\\r\\nIn alternative manner, if the DNA or RNA molecule under investigation has been sequenced then the GC-content can be accurately calculated by simple arithmetic or by using the free online GC calculator.\\r\\nGC ratios within a genome is found to be markedly variable. These variations in GC ratio within the genomes of more complex organisms result in a mosaic-like formation with islet regions called isochores.[11] This results in the variations in staining intensity in the chromosomes.[12] GC-rich isochores include in them many protein coding genes, and thus determination of ratio of these specific regions contributes in mapping gene-rich regions of the genome.[13][14]\\r\\nWithin a long region of genomic sequence, genes are often characterised by having a higher GC-content in contrast to the background GC-content for the entire genome. Evidence of GC ratio with that of length of the coding region of a gene has shown that the length of the coding sequence is directly proportional to higher G+C content.[15] This has been pointed to the fact that the stop codon has a bias towards A and T nucleotides, and, thus, the shorter the sequence the higher the AT bias.[16]\\r\\nGC content is found to be variable with different organisms, the process of which is envisaged to be contributed to by variation in selection, mutational bias, and biased recombination-associated DNA repair.[17] The species problem in prokaryotic taxonomy has led to various suggestions in classifying bacteria, and the ad hoc committee on reconciliation of approaches to bacterial systematics has recommended use of GC ratios in higher level hierarchical classification.[18] For example, the Actinobacteria are characterised as \\"high GC-content bacteria\\".[19] In Streptomyces coelicolor A3(2), GC content is 72%.[20] The GC-content of Yeast (Saccharomyces cerevisiae) is 38%,[21] and that of another common model organism, thale cress (Arabidopsis thaliana), is 36%.[22] Because of the nature of the genetic code, it is virtually impossible for an organism to have a genome with a GC-content approaching either 0% or 100%. A species with an extremely low GC-content is Plasmodium falciparum (GC% = ~20%),[23] and it is usually common to refer to such examples as being AT-rich instead of GC-poor.[24]","input":"How many hydrogen bonds form between g and c?"},{"output":"migrations","context":"Bantu peoples is used as a general label for the 300ÿ600 ethnic groups in Africa who speak Bantu languages.[1] They inhabit a geographical area stretching east and southward from Central Africa across the African Great Lakes region down to Southern Africa.[1] Bantu is a major branch of the NigerÿCongo language family spoken by most populations in Africa. There are about 650 Bantu languages by the criterion of mutual intelligibility,[2] though the distinction between language and dialect is often unclear, and Ethnologue counts 535 languages.[3]\\r\\nAround 3,000 years ago, speakers of the Proto-Bantu language group began a millennia-long series of migrations eastward from their homeland between West Africa and Central Africa, at the border of eastern Nigeria and Cameroon.[4] This Bantu expansion first introduced Bantu peoples to central, southern and southeastern Africa, regions they had previously been absent from. The proto-Bantu migrants in the process assimilated and/or displaced a number of earlier inhabitants that they came across, such as Pygmy and Khoisan populations in the centre and south, respectively. They also encountered some Afro-Asiatic outlier groups in the southeast who had been there for centuries, having migrated from Northeast Africa.[5][6]\\r\\nIndividual Bantu groups today often comprise millions of people. Among these are the Shona of Zimbabwe with 14.2 million people; the Luba of the Democratic Republic of the Congo, with over 13.5 million people; the Zulu of South Africa, with over 10 million people; the Tiv of central Nigeria and Cameroon, with almost 10 million people; the Sukuma of Tanzania, with around eight million people; and the Kikuyu of Kenya, with over six million people. Although only around five million individuals speak the Arabic-influenced Swahili language as their mother tongue,[7] it is used as a lingua franca by over 140 million people throughout Southeast Africa.[8] Swahili also serves as one of the official languages of the African Union.\\r\\n\\r\\n\\r\\nThe word Bantu, and its variations, means \\"people\\" or \\"humans\\". The root in Proto-Bantu is reconstructed as *-ntu. Versions of the word Bantu (that is, the root plus the class 2 noun class prefix *ba-) occur in all Bantu languages: for example, as watu in Swahili; bantu in Kikongo; anthu in Chichewa;batu in Lingala; bato in Kiluba; bato in Duala; abanto in Gusii; and? in Kamba and Kikuyu; abantu in Kirundi, Zulu, Xhosa, Runyakitara,[9] and Ganda; wandru in Shingazidja; abantru in Mpondo and Ndebele; b?tfu in Phuthi; bantfu in Swati; banu in Lala; vanhu in Shona and Tsonga; batho in Sesotho, Tswana and Northern Sotho; antu in Meru; andu in Embu; vandu in some Luhya dialects; vhathu in Venda; bhandu in nyakyusa and mbaityo in Tiv.\\r\\nCurrent scholarly understanding places the ancestral proto-Bantu homeland in West Africa near the present-day southwestern border of Nigeria and Cameroon c.?4,000 years ago (2000?B.C.), and regards the Bantu languages as a branch of the NigerÿCongo language family.[13] This view represents a resolution of debates in the 1960s over competing theories advanced by Joseph Greenberg and Malcolm Guthrie, in favor of refinements of Greenberg's theory. Based on wide comparisons including non-Bantu languages, Greenberg argued that Proto-Bantu, the hypothetical ancestor of the Bantu languages, had strong ancestral affinities with a group of languages spoken in Southeastern Nigeria. He proposed that Bantu languages had spread east and south from there, to secondary centers of further dispersion, over hundreds of years.\\r\\nUsing a different comparative method focused more exclusively on relationships among Bantu languages, Guthrie argued for a single Central African dispersal point spreading at a roughly equal rate in all directions. Subsequent research on loanwords for adaptations in agriculture and animal husbandry and on the wider NigerÿCongo language family rendered that thesis untenable. In the 1990s, Jan Vansina proposed a modification of Greenberg's ideas, in which dispersions from secondary and tertiary centers resembled Guthrie's central node idea, but from a number of regional centers rather than just one, creating linguistic clusters.[14]\\r\\nIt is unclear exactly when the spread of Bantu-speakers began from their core area as hypothesized c. 5,000 years ago (3000 B.C.). By 3,500 years ago (1500?B.C.) in the west, Bantu-speaking communities had reached the great Central African rain forest, and by 2,500 years ago (500?B.C.) pioneering groups had emerged into the savannahs to the south, in what are now the Democratic Republic of the Congo, Angola, and Zambia. Another stream of migration, moving east, by 3,000 years ago (1000?B.C.) was creating a major new population center near the Great Lakes of East Africa, where a rich environment supported a dense population. Movements by small groups to the southeast from the Great Lakes region were more rapid, with initial settlements widely dispersed near the coast and near rivers, due to comparatively harsh farming conditions in areas farther from water. Pioneering groups had reached modern KwaZulu-Natal in South Africa by A.D.?300 along the coast, and the modern Northern Province (encompassed within the former province of the Transvaal) by A.D.?500.[15]\\r\\nBefore the expansion of farming and herding peoples, including those speaking Bantu languages, Africa south of the equator was populated by neolithic hunting and foraging peoples. Some of them were ancestral to proto-Khoisan-speaking peoples, whose modern hunter-forager and linguistic descendants, the Khoekhoe and San, occupy the arid regions around the Kalahari desert. The Hadza and Sandawe populations in Tanzania comprise the other modern hunter-forager remnant in Africa of these proto-Khoisan-speaking peoples.\\r\\nOver a period of many centuries, most hunting-foraging peoples were displaced and absorbed by incoming Bantu-speaking communities, as well as by Ubangian, Nilotic, and Sudanic language-speakers in North Central and Eastern Africa. The Bantu expansion was a long series of physical migrations, a diffusion of language and knowledge out into and in from neighboring populations, and a creation of new societal groups involving inter-marriage among communities and small groups moving to communities and small groups moving to new areas.\\r\\nAfter their movements from their original homeland in West Africa, Bantus also encountered in East Africa peoples of Afro-Asiatic (mainly Cushitic) and Nilo-Saharan (mainly Nilotic and Sudanic) ancestral origin. As cattle terminology in use amongst the few modern Bantu pastoralist groups suggests, the Bantu migrants would acquire cattle from their new Cushitic neighbors. Linguistic evidence also indicates that Bantus likely borrowed the custom of milking cattle directly from Cushitic peoples in the area.[16] Later interactions between Bantu and Cushitic peoples resulted in Bantu groups with significant Cushitic ethnic admixture, such as the Tutsi of the African Great Lakes region; and culturo-linguistic influences, such as the Herero herdsmen of southern Africa.[17][18]\\r\\nOn the coastal section of East Africa, another mixed Bantu community developed through contact with Muslim Arab and Persian traders. The Swahili culture that emerged from these exchanges evinces many Arab and Islamic influences not seen in traditional Bantu culture, as do the many Afro-Arab members of the Bantu Swahili people. With its original speech community centered on the coastal parts of Zanzibar, Kenya, and Tanzania ÿ a seaboard referred to as the Swahili Coast ÿ the Bantu Swahili language contains many Arabic loan-words as a result of these interactions.[19]\\r\\nBetween the 14th and 15th centuries, Bantu-speaking states began to emerge in the Great Lakes region in the savannah south of the Central African rain forest. On the Zambezi river, the Monomatapa kings built the famous Great Zimbabwe complex, a civilisation of what are today referred to as the Shona people. From the 16th century onward, the processes of state formation amongst Bantu peoples increased in frequency. This was probably due to denser population (which led to more specialized divisions of labor, including military power, while making emigration more difficult); to increased interaction amongst Bantu-speaking communities with Chinese, European, Indonesian, and Arab traders on the coasts; to technological developments in economic activity; and to new techniques in the political-spiritual ritualization of royalty as the source of national strength and health.[20]\\r\\nKongo youth and adults in Kinshasa, Democratic Republic of the Congo\\r\\nA Kikuyu woman in Kenya\\r\\nA Makua mother and child in Mozambique\\r\\nBubi girls in Equatorial Guinea\\r\\nBetween the 14th and 15th centuries, Bantu states began to emerge in the Great Lakes region in the savanna south of the Central African rain-forest. In Southern Africa on the Zambezi river, the Monomatapa kings built the famous Great Zimbabwe complex, the largest of over 200 such sites in Southern Africa, such as Bumbusi in Zimbabwe and Manyikeni in Mozambique. From the 16th century onward, the processes of state formation among Bantu peoples increased in frequency. Some examples of such Bantu states include: in Central Africa, the Kingdom of Kongo,[21] Lunda Empire,[22] and Luba Empire[23] of Angola, the Republic of Congo, and the Democratic Republic of Congo; in the Great Lakes Region, the Buganda[24] and Karagwe[24] Kingdoms of Uganda and Tanzania; and in Southern Africa, the Mutapa Empire,[25] Rozwi Empire,[26] and the Danamombe, Khami, and Naletale Kingdoms of Zimbabwe and Mozambique.[25]\\r\\nToward the 18th and 19th centuries, the flow of Zanj (Bantu) slaves from Southeast Africa increased with the rise of the Omani Sultanate of Zanzibar, based in Zanzibar, Tanzania. With the arrival of European colonialists, the Zanzibar Sultanate came into direct trade conflict and competition with Portuguese and other Europeans along the Swahili Coast, leading eventually to the fall of the Sultanate and the end of slave trading on the Swahili Coast in the mid-19th century.\\r\\nIn the 1920s, relatively liberal South Africans, missionaries, and the small black intelligentsia began to use the term \\"Bantu\\" in preference to \\"Native\\" and more derogatory terms (such as \\"Kaffir\\") to refer collectively to Bantu-speaking South Africans. After World War II, the National Party governments adopted that usage officially, while the growing African nationalist movement and its liberal allies turned to the term \\"African\\" instead, so that \\"Bantu\\" became identified with the policies of apartheid. By the 1970s this so discredited \\"Bantu\\" as an ethno-racial designation that the apartheid government switched to the term \\"Black\\" in its official racial categorizations, restricting it to Bantu-speaking Africans, at about the same time that the Black Consciousness Movement led by Steve Biko and others were defining \\"Black\\" to mean all racially oppressed South Africans (Africans, Coloureds, and Indians).\\r\\nExamples of South African usages of \\"Bantu\\" include:","input":"What were the main reasons the bantu speaking tribes left central africa?"},{"output":"Jupiter","context":"The Solar System[a] is the gravitationally bound system comprising the Sun and the objects that orbit it, either directly or indirectly.[b] Of those objects that orbit the Sun directly, the largest eight are the planets,[c] with the remainder being significantly smaller objects, such as dwarf planets and small Solar System bodies. Of the objects that orbit the Sun indirectly, the moons, two are larger than the smallest planet, Mercury.[d]\\r\\nThe Solar System formed 4.6 billion years ago from the gravitational collapse of a giant interstellar molecular cloud. The vast majority of the system's mass is in the Sun, with the majority of the remaining mass contained in Jupiter. The four smaller inner planets, Mercury, Venus, Earth and Mars, are terrestrial planets, being primarily composed of rock and metal. The four outer planets are giant planets, being substantially more massive than the terrestrials. The two largest, Jupiter and Saturn, are gas giants, being composed mainly of hydrogen and helium; the two outermost planets, Uranus and Neptune, are ice giants, being composed mostly of substances with relatively high melting points compared with hydrogen and helium, called volatiles, such as water, ammonia and methane. All eight planets have almost circular orbits that lie within a nearly flat disc called the ecliptic.\\r\\nThe Solar System also contains smaller objects.[e] The asteroid belt, which lies between the orbits of Mars and Jupiter, mostly contains objects composed, like the terrestrial planets, of rock and metal. Beyond Neptune's orbit lie the Kuiper belt and scattered disc, which are populations of trans-Neptunian objects composed mostly of ices, and beyond them a newly discovered population of sednoids. Within these populations are several dozen to possibly tens of thousands of objects large enough that they have been rounded by their own gravity.[10] Such objects are categorized as dwarf planets. Identified dwarf planets include the asteroid Ceres and the trans-Neptunian objects Pluto and Eris.[e] In addition to these two regions, various other small-body populations, including comets, centaurs and interplanetary dust clouds, freely travel between regions. Six of the planets, at least four of the dwarf planets, and many of the smaller bodies are orbited by natural satellites,[f] usually termed \\"moons\\" after the Moon. Each of the outer planets is encircled by planetary rings of dust and other small objects.\\r\\nThe solar wind, a stream of charged particles flowing outwards from the Sun, creates a bubble-like region in the interstellar medium known as the heliosphere. The heliopause is the point at which pressure from the solar wind is equal to the opposing pressure of the interstellar medium; it extends out to the edge of the scattered disc. The Oort cloud, which is thought to be the source for long-period comets, may also exist at a distance roughly a thousand times further than the heliosphere. The Solar System is located in the Orion Arm, 26,000 light-years from the center of the Milky Way.\\r\\n\\r\\n\\r\\nFor most of history, humanity did not recognize or understand the concept of the Solar System. Most people up to the Late Middle AgesÿRenaissance believed Earth to be stationary at the centre of the universe and categorically different from the divine or ethereal objects that moved through the sky. Although the Greek philosopher Aristarchus of Samos had speculated on a heliocentric reordering of the cosmos, Nicolaus Copernicus was the first to develop a mathematically predictive heliocentric system.[11][12] In the 17th century, Galileo Galilei, Johannes Kepler, and Isaac Newton developed an understanding of physics that led to the gradual acceptance of the idea that Earth moves around the Sun and that the planets are governed by the same physical laws that governed Earth. The invention of the telescope led to the discovery of further planets and moons. Improvements in the telescope and the use of unmanned spacecraft have enabled the investigation of geological phenomena, such as mountains, craters, seasonal meteorological phenomena, such as clouds, dust storms and ice caps on the other planets.\\r\\nThe principal component of the Solar System is the Sun, a G2 main-sequence star that contains 99.86% of the system's known mass and dominates it gravitationally.[13] The Sun's four largest orbiting bodies, the giant planets, account for 99% of the remaining mass, with Jupiter and Saturn together comprising more than 90%. The remaining objects of the Solar System (including the four terrestrial planets, the dwarf planets, moons, asteroids, and comets) together comprise less than 0.002% of the Solar System's total mass.[g]\\r\\nMost large objects in orbit around the Sun lie near the plane of Earth's orbit, known as the ecliptic. The planets are very close to the ecliptic, whereas comets and Kuiper belt objects are frequently at significantly greater angles to it.[17][18] All the planets, and most other objects, orbit the Sun in the same direction that the Sun is rotating (counter-clockwise, as viewed from above Earth's north pole).[19] There are exceptions, such as Halley's Comet.\\r\\nThe overall structure of the charted regions of the Solar System consists of the Sun, four relatively small inner planets surrounded by a belt of mostly rocky asteroids, and four giant planets surrounded by the Kuiper belt of mostly icy objects. Astronomers sometimes informally divide this structure into separate regions. The inner Solar System includes the four terrestrial planets and the asteroid belt. The outer Solar System is beyond the asteroids, including the four giant planets.[20] Since the discovery of the Kuiper belt, the outermost parts of the Solar System are considered a distinct region consisting of the objects beyond Neptune.[21]\\r\\nMost of the planets in the Solar System have secondary systems of their own, being orbited by planetary objects called natural satellites, or moons (two of which, Titan and Ganymede, are larger than the planet Mercury), and, in the case of the four giant planets, by planetary rings, thin bands of tiny particles that orbit them in unison. Most of the largest natural satellites are in synchronous rotation, with one face permanently turned toward their parent.\\r\\nKepler's laws of planetary motion describe the orbits of objects about the Sun. Following Kepler's laws, each object travels along an ellipse with the Sun at one focus. Objects closer to the Sun (with smaller semi-major axes) travel more quickly because they are more affected by the Sun's gravity. On an elliptical orbit, a body's distance from the Sun varies over the course of its year. A body's closest approach to the Sun is called its perihelion, whereas its most distant point from the Sun is called its aphelion. The orbits of the planets are nearly circular, but many comets, asteroids, and Kuiper belt objects follow highly elliptical orbits. The positions of the bodies in the Solar System can be predicted using numerical models.\\r\\nAlthough the Sun dominates the system by mass, it accounts for only about 2% of the angular momentum.[22][23] The planets, dominated by Jupiter, account for most of the rest of the angular momentum due to the combination of their mass, orbit, and distance from the Sun, with a possibly significant contribution from comets.[22]\\r\\nThe Sun, which comprises nearly all the matter in the Solar System, is composed of roughly 98% hydrogen and helium.[24] Jupiter and Saturn, which comprise nearly all the remaining matter, are also primarily composed of hydrogen and helium.[25][26] A composition gradient exists in the Solar System, created by heat and light pressure from the Sun; those objects closer to the Sun, which are more affected by heat and light pressure, are composed of elements with high melting points. Objects farther from the Sun are composed largely of materials with lower melting points.[27] The boundary in the Solar System beyond which those volatile substances could condense is known as the frost line, and it lies at roughly 5 AU from the Sun.[5]\\r\\nThe objects of the inner Solar System are composed mostly of rock,[28] the collective name for compounds with high melting points, such as silicates, iron or nickel, that remained solid under almost all conditions in the protoplanetary nebula.[29] Jupiter and Saturn are composed mainly of gases, the astronomical term for materials with extremely low melting points and high vapour pressure, such as hydrogen, helium, and neon, which were always in the gaseous phase in the nebula.[29] Ices, like water, methane, ammonia, hydrogen sulfide, and carbon dioxide,[28] have melting points up to a few hundred kelvins.[29] They can be found as ices, liquids, or gases in various places in the Solar System, whereas in the nebula they were either in the solid or gaseous phase.[29] Icy substances comprise the majority of the satellites of the giant planets, as well as most of Uranus and Neptune (the so-called \\"ice giants\\") and the numerous small objects that lie beyond Neptune's orbit.[28][30] Together, gases and ices are referred to as volatiles.[31]\\r\\nThe distance from Earth to the Sun is 1 astronomical unit (150,000,000?km), or AU. For comparison, the radius of the Sun is 0.0047?AU (700,000?km). Thus, the Sun occupies 0.00001% (10?5?%) of the volume of a sphere with a radius the size of Earth's orbit, whereas Earth's volume is roughly one millionth (10?6) that of the Sun. Jupiter, the largest planet, is 5.2 astronomical units (780,000,000?km) from the Sun and has a radius of 71,000?km (0.00047?AU), whereas the most distant planet, Neptune, is 30?AU (4.5G109?km) from the Sun.\\r\\nWith a few exceptions, the farther a planet or belt is from the Sun, the larger the distance between its orbit and the orbit of the next nearer object to the Sun. For example, Venus is approximately 0.33 AU farther out from the Sun than Mercury, whereas Saturn is 4.3 AU out from Jupiter, and Neptune lies 10.5 AU out from Uranus. Attempts have been made to determine a relationship between these orbital distances (for example, the TitiusÿBode law),[32] but no such theory has been accepted. The images at the beginning of this section show the orbits of the various constituents of the Solar System on different scales.\\r\\nSome Solar System models attempt to convey the relative scales involved in the Solar System on human terms. Some are small in scale (and may be mechanicalcalled orreries)whereas others extend across cities or regional areas.[33] The largest such scale model, the Sweden Solar System, uses the 110-metre (361-ft) Ericsson Globe in Stockholm as its substitute Sun, and, following the scale, Jupiter is a 7.5-metre (25-foot) sphere at Arlanda International Airport, 40?km (25?mi) away, whereas the farthest current object, Sedna, is a 10-cm (4-in) sphere in Lule?, 912?km (567?mi) away.[34][35]\\r\\nIf the SunÿNeptune distance is scaled to 100 metres, then the Sun would be about 3?cm in diameter (roughly two-thirds the diameter of a golf ball), the giant planets would be all smaller than about 3?mm, and Earth's diameter along with that of the other terrestrial planets would be smaller than a flea (0.3?mm) at this scale.[36]\\r\\nDistances of selected bodies of the Solar System from the Sun. The left and right edges of each bar correspond to the perihelion and aphelion of the body, respectively, hence long bars denote high orbital eccentricity. The radius of the Sun is 0.7 million km, and the radius of Jupiter (the largest planet) is 0.07 million km, both too small to resolve on this image.\\r\\nThe Solar System formed 4.568 billion years ago from the gravitational collapse of a region within a large molecular cloud.[h] This initial cloud was likely several light-years across and probably birthed several stars.[37] As is typical of molecular clouds, this one consisted mostly of hydrogen, with some helium, and small amounts of heavier elements fused by previous generations of stars. As the region that would become the Solar System, known as the pre-solar nebula,[38] collapsed, conservation of angular momentum caused it to rotate faster. The centre, where most of the mass collected, became increasingly hotter than the surrounding disc.[37] As the contracting nebula rotated faster, it began to flatten into a protoplanetary disc with a diameter of roughly 200?AU[37] and a hot, dense protostar at the centre.[39][40] The planets formed by accretion from this disc,[41] in which dust and gas gravitationally attracted each other, coalescing to form ever larger bodies. Hundreds of protoplanets may have existed in the early Solar System, but they either merged or were destroyed, leaving the planets, dwarf planets, and leftover minor bodies.\\r\\nDue to their higher boiling points, only metals and silicates could exist in solid form in the warm inner Solar System close to the Sun, and these would eventually form the rocky planets of Mercury, Venus, Earth, and Mars. Because metallic elements only comprised a very small fraction of the solar nebula, the terrestrial planets could not grow very large. The giant planets (Jupiter, Saturn, Uranus, and Neptune) formed further out, beyond the frost line, the point between the orbits of Mars and Jupiter where material is cool enough for volatile icy compounds to remain solid. The ices that formed these planets were more plentiful than the metals and silicates that formed the terrestrial inner planets, allowing them to grow massive enough to capture large atmospheres of hydrogen and helium, the lightest and most abundant elements. Leftover debris that never became planets congregated in regions such as the asteroid belt, Kuiper belt, and Oort cloud. The Nice model is an explanation for the creation of these regions and how the outer planets could have formed in different positions and migrated to their current orbits through various gravitational interactions.\\r\\nWithin 50 million years, the pressure and density of hydrogen in the centre of the protostar became great enough for it to begin thermonuclear fusion.[42] The temperature, reaction rate, pressure, and density increased until hydrostatic equilibrium was achieved: the thermal pressure equalled the force of gravity. At this point, the Sun became a main-sequence star.[43] The main-sequence phase, from beginning to end, will last about 10 billion years for the Sun compared to around two billion years for all other phases of the Sun's pre-remnant life combined.[44] Solar wind from the Sun created the heliosphere and swept away the remaining gas and dust from the protoplanetary disc into interstellar space, ending the planetary formation process. The Sun is growing brighter; early in its main-sequence life its brightness was 70% that of what it is today.[45]\\r\\nThe Solar System will remain roughly as we know it today until the hydrogen in the core of the Sun has been entirely converted to helium, which will occur roughly 5 billion years from now. This will mark the end of the Sun's main-sequence life. At this time, the core of the Sun will collapse, and the energy output will be much greater than at present. The outer layers of the Sun will expand to roughly 260 times its current diameter, and the Sun will become a red giant. Because of its vastly increased surface area, the surface of the Sun will be considerably cooler (2,600 K at its coolest) than it is on the main sequence.[44] The expanding Sun is expected to vaporize Mercury and render Earth uninhabitable. Eventually, the core will be hot enough for helium fusion; the Sun will burn helium for a fraction of the time it burned hydrogen in the core. The Sun is not massive enough to commence the fusion of heavier elements, and nuclear reactions in the core will dwindle. Its outer layers will move away into space, leaving a white dwarf, an extraordinarily dense object, half the original mass of the Sun but only the size of Earth.[46] The ejected outer layers will form what is known as a planetary nebula, returning some of the material that formed the Sunbut now enriched with heavier elements like carbonto the interstellar medium.\\r\\nThe Sun is the Solar System's star and by far its most massive component. Its large mass (332,900 Earth masses)[47] produces temperatures and densities in its core high enough to sustain nuclear fusion of hydrogen into helium, making it a main-sequence star.[48] This releases an enormous amount of energy, mostly radiated into space as electromagnetic radiation peaking in visible light.[49]\\r\\nThe Sun is a G2-type main-sequence star. Hotter main-sequence stars are more luminous. The Sun's temperature is intermediate between that of the hottest stars and that of the coolest stars. Stars brighter and hotter than the Sun are rare, whereas substantially dimmer and cooler stars, known as red dwarfs, make up 85% of the stars in the Milky Way.[50][51]\\r\\nThe Sun is a population I star; it has a higher abundance of elements heavier than hydrogen and helium (\\"metals\\" in astronomical parlance) than the older population II stars.[52] Elements heavier than hydrogen and helium were formed in the cores of ancient and exploding stars, so the first generation of stars had to die before the Universe could be enriched with these atoms. The oldest stars contain few metals, whereas stars born later have more. This high metallicity is thought to have been crucial to the Sun's development of a planetary system because the planets form from the accretion of \\"metals\\".[53]\\r\\nThe vast majority of the Solar System consists of a near-vacuum known as the interplanetary medium. Along with light, the Sun radiates a continuous stream of charged particles (a plasma) known as the solar wind. This stream of particles spreads outwards at roughly 1.5 million kilometres per hour,[54] creating a tenuous atmosphere that permeates the interplanetary medium out to at least 100?AU (see ?Heliosphere).[55] Activity on the Sun's surface, such as solar flares and coronal mass ejections, disturb the heliosphere, creating space weather and causing geomagnetic storms.[56] The largest structure within the heliosphere is the heliospheric current sheet, a spiral form created by the actions of the Sun's rotating magnetic field on the interplanetary medium.[57][58]\\r\\nEarth's magnetic field stops its atmosphere from being stripped away by the solar wind.[59] Venus and Mars do not have magnetic fields, and as a result the solar wind is causing their atmospheres to gradually bleed away into space.[60] Coronal mass ejections and similar events blow a magnetic field and huge quantities of material from the surface of the Sun. The interaction of this magnetic field and material with Earth's magnetic field funnels charged particles into Earth's upper atmosphere, where its interactions create aurorae seen near the magnetic poles.\\r\\nThe heliosphere and planetary magnetic fields (for those planets that have them) partially shield the Solar System from high-energy interstellar particles called cosmic rays. The density of cosmic rays in the interstellar medium and the strength of the Sun's magnetic field change on very long timescales, so the level of cosmic-ray penetration in the Solar System varies, though by how much is unknown.[61]\\r\\nThe interplanetary medium is home to at least two disc-like regions of cosmic dust. The first, the zodiacal dust cloud, lies in the inner Solar System and causes the zodiacal light. It was likely formed by collisions within the asteroid belt brought on by gravitational interactions with the planets.[62] The second dust cloud extends from about 10?AU to about 40?AU, and was probably created by similar collisions within the Kuiper belt.[63][64]\\r\\nThe inner Solar System is the region comprising the terrestrial planets and the asteroid belt.[65] Composed mainly of silicates and metals, the objects of the inner Solar System are relatively close to the Sun; the radius of this entire region is less than the distance between the orbits of Jupiter and Saturn. This region is also within the frost line, which is a little less than 5 AU (about 700 million km) from the Sun.[66]\\r\\nThe four terrestrial or inner planets have dense, rocky compositions, few or no moons, and no ring systems. They are composed largely of refractory minerals, such as the silicates, which form their crusts and mantles, and metals, such as iron and nickel, which form their cores. Three of the four inner planets (Venus, Earth and Mars) have atmospheres substantial enough to generate weather; all have impact craters and tectonic surface features, such as rift valleys and volcanoes. The term inner planet should not be confused with inferior planet, which designates those planets that are closer to the Sun than Earth is (i.e. Mercury and Venus).\\r\\nAsteroids except for the largest, Ceres, are classified as small Solar System bodies[e] and are composed mainly of refractory rocky and metallic minerals, with some ice.[79][80] They range from a few metres to hundreds of kilometres in size. Asteroids smaller than one meter are usually called meteoroids and micrometeoroids (grain-sized), depending on different, somewhat arbitrary definitions.\\r\\nThe asteroid belt occupies the orbit between Mars and Jupiter, between 2.3 and 3.3?AU from the Sun. It is thought to be remnants from the Solar System's formation that failed to coalesce because of the gravitational interference of Jupiter.[81] The asteroid belt contains tens of thousands, possibly millions, of objects over one kilometre in diameter.[82] Despite this, the total mass of the asteroid belt is unlikely to be more than a thousandth of that of Earth.[16] The asteroid belt is very sparsely populated; spacecraft routinely pass through without incident.\\r\\nThe outer region of the Solar System is home to the giant planets and their large moons. The centaurs and many short-period comets also orbit in this region. Due to their greater distance from the Sun, the solid objects in the outer Solar System contain a higher proportion of volatiles, such as water, ammonia, and methane than those of the inner Solar System because the lower temperatures allow these compounds to remain solid.\\r\\nThe four outer planets, or giant planets (sometimes called Jovian planets), collectively make up 99% of the mass known to orbit the Sun.[g] Jupiter and Saturn are together over 400 times the mass of Earth and consist overwhelmingly of hydrogen and helium; Uranus and Neptune are far less massive (<20 Earth masses each) and are composed primarily of ices. For these reasons, some astronomers suggest they belong in their own category, \\"ice giants\\".[87] All four giant planets have rings, although only Saturn's ring system is easily observed from Earth. The term superior planet designates planets outside Earth's orbit and thus includes both the outer planets and Mars.\\r\\nThe centaurs are icy comet-like bodies whose orbits have semi-major axes greater than Jupiter's (5.5?AU) and less than Neptune's (30?AU). The largest known centaur, 10199 Chariklo, has a diameter of about 250?km.[94] The first centaur discovered, 2060 Chiron, has also been classified as comet (95P) because it develops a coma just as comets do when they approach the Sun.[95]\\r\\nComets are small Solar System bodies,[e] typically only a few kilometres across, composed largely of volatile ices. They have highly eccentric orbits, generally a perihelion within the orbits of the inner planets and an aphelion far beyond Pluto. When a comet enters the inner Solar System, its proximity to the Sun causes its icy surface to sublimate and ionise, creating a coma: a long tail of gas and dust often visible to the naked eye.\\r\\nShort-period comets have orbits lasting less than two hundred years. Long-period comets have orbits lasting thousands of years. Short-period comets are thought to originate in the Kuiper belt, whereas long-period comets, such as HaleÿBopp, are thought to originate in the Oort cloud. Many comet groups, such as the Kreutz Sungrazers, formed from the breakup of a single parent.[96] Some comets with hyperbolic orbits may originate outside the Solar System, but determining their precise orbits is difficult.[97] Old comets that have had most of their volatiles driven out by solar warming are often categorised as asteroids.[98]\\r\\nBeyond the orbit of Neptune lies the area of the \\"trans-Neptunian region\\", with the doughnut-shaped Kuiper belt, home of Pluto and several other dwarf planets, and an overlapping disc of scattered objects, which is tilted toward the plane of the Solar System and reaches much further out than the Kuiper belt. The entire region is still largely unexplored. It appears to consist overwhelmingly of many thousands of small worldsthe largest having a diameter only a fifth that of Earth and a mass far smaller than that of the Mooncomposed mainly of rock and ice. This region is sometimes described as the \\"third zone of the Solar System\\", enclosing the inner and the outer Solar System.[99]\\r\\nThe Kuiper belt is a great ring of debris similar to the asteroid belt, but consisting mainly of objects composed primarily of ice.[100] It extends between 30 and 50?AU from the Sun. Though it is estimated to contain anything from dozens to thousands of dwarf planets, it is composed mainly of small Solar System bodies. Many of the larger Kuiper belt objects, such as Quaoar, Varuna, and Orcus, may prove to be dwarf planets with further data. There are estimated to be over 100,000 Kuiper belt objects with a diameter greater than 50?km, but the total mass of the Kuiper belt is thought to be only a tenth or even a hundredth the mass of Earth.[15] Many Kuiper belt objects have multiple satellites,[101] and most have orbits that take them outside the plane of the ecliptic.[102]\\r\\nThe Kuiper belt can be roughly divided into the \\"classical\\" belt and the resonances.[100] Resonances are orbits linked to that of Neptune (e.g. twice for every three Neptune orbits, or once for every two). The first resonance begins within the orbit of Neptune itself. The classical belt consists of objects having no resonance with Neptune, and extends from roughly 39.4?AU to 47.7?AU.[103] Members of the classical Kuiper belt are classified as cubewanos, after the first of their kind to be discovered, (15760) 1992 QB1, and are still in near primordial, low-eccentricity orbits.[104]\\r\\nThe scattered disc, which overlaps the Kuiper belt but extends much further outwards, is thought to be the source of short-period comets. Scattered-disc objects are thought to have been ejected into erratic orbits by the gravitational influence of Neptune's early outward migration. Most scattered disc objects (SDOs) have perihelia within the Kuiper belt but aphelia far beyond it (some more than 150?AU from the Sun). SDOs' orbits are also highly inclined to the ecliptic plane and are often almost perpendicular to it. Some astronomers consider the scattered disc to be merely another region of the Kuiper belt and describe scattered disc objects as \\"scattered Kuiper belt objects\\".[109] Some astronomers also classify centaurs as inward-scattered Kuiper belt objects along with the outward-scattered residents of the scattered disc.[110]\\r\\nThe point at which the Solar System ends and interstellar space begins is not precisely defined because its outer boundaries are shaped by two separate forces: the solar wind and the Sun's gravity. The limit of the solar wind's influence is roughly four times Pluto's distance from the Sun; this heliopause, the outer boundary of the heliosphere, is considered the beginning of the interstellar medium.[55] The Sun's Hill sphere, the effective range of its gravitational dominance, is thought to extend up to a thousand times farther and encompasses the theorized Oort cloud.[112]\\r\\nThe heliosphere is a stellar-wind bubble, a region of space dominated by the Sun, which radiates at roughly 400?km/s its solar wind, a stream of charged particles, until it collides with the wind of the interstellar medium.\\r\\nThe collision occurs at the termination shock, which is roughly 80ÿ100?AU from the Sun upwind of the interstellar medium and roughly 200?AU from the Sun downwind.[113] Here the wind slows dramatically, condenses and becomes more turbulent,[113] forming a great oval structure known as the heliosheath. This structure is thought to look and behave very much like a comet's tail, extending outward for a further 40?AU on the upwind side but tailing many times that distance downwind; evidence from Cassini and Interstellar Boundary Explorer spacecraft has suggested that it is forced into a bubble shape by the constraining action of the interstellar magnetic field.[114]\\r\\nThe outer boundary of the heliosphere, the heliopause, is the point at which the solar wind finally terminates and is the beginning of interstellar space.[55] Voyager 1 and Voyager 2 are reported to have passed the termination shock and entered the heliosheath, at 94 and 84?AU from the Sun, respectively.[115][116] Voyager 1 is reported to have crossed the heliopause in August 2012.[117]\\r\\nThe shape and form of the outer edge of the heliosphere is likely affected by the fluid dynamics of interactions with the interstellar medium as well as solar magnetic fields prevailing to the south, e.g. it is bluntly shaped with the northern hemisphere extending 9?AU farther than the southern hemisphere.[113] Beyond the heliopause, at around 230 AU, lies the bow shock, a plasma \\"wake\\" left by the Sun as it travels through the Milky Way.[118]\\r\\nDue to a lack of data, conditions in local interstellar space are not known for certain. It is expected that NASA's Voyager spacecraft, as they pass the heliopause, will transmit valuable data on radiation levels and solar wind to Earth.[119] How well the heliosphere shields the Solar System from cosmic rays is poorly understood. A NASA-funded team has developed a concept of a \\"Vision Mission\\" dedicated to sending a probe to the heliosphere.[120][121]\\r\\n90377 Sedna (520 AU average) is a large, reddish object with a gigantic, highly elliptical orbit that takes it from about 76?AU at perihelion to 940?AU at aphelion and takes 11,400 years to complete. Mike Brown, who discovered the object in 2003, asserts that it cannot be part of the scattered disc or the Kuiper belt because its perihelion is too distant to have been affected by Neptune's migration. He and other astronomers consider it to be the first in an entirely new population, sometimes termed \\"distant detached objects\\" (DDOs), which also may include the object 2000 CR105, which has a perihelion of 45?AU, an aphelion of 415?AU, and an orbital period of 3,420 years.[122] Brown terms this population the \\"inner Oort cloud\\" because it may have formed through a similar process, although it is far closer to the Sun.[123] Sedna is very likely a dwarf planet, though its shape has yet to be determined. The second unequivocally detached object, with a perihelion farther than Sedna's at roughly 81 AU, is 2012 VP113, discovered in 2012. Its aphelion is only half that of Sedna's, at 400ÿ500 AU.[124][125]\\r\\nThe Oort cloud is a hypothetical spherical cloud of up to a trillion icy objects that is thought to be the source for all long-period comets and to surround the Solar System at roughly 50,000?AU (around 1?light-year (ly)), and possibly to as far as 100,000?AU (1.87?ly). It is thought to be composed of comets that were ejected from the inner Solar System by gravitational interactions with the outer planets. Oort cloud objects move very slowly, and can be perturbed by infrequent events, such as collisions, the gravitational effects of a passing star, or the galactic tide, the tidal force exerted by the Milky Way.[126][127]\\r\\nMuch of the Solar System is still unknown. The Sun's gravitational field is estimated to dominate the gravitational forces of surrounding stars out to about two light years (125,000 AU). Lower estimates for the radius of the Oort cloud, by contrast, do not place it farther than 50,000 AU.[128] Despite discoveries such as Sedna, the region between the Kuiper belt and the Oort cloud, an area tens of thousands of AU in radius, is still virtually unmapped. There are also ongoing studies of the region between Mercury and the Sun.[129] Objects may yet be discovered in the Solar System's uncharted regions.\\r\\nCurrently, the furthest known objects, such as Comet West, have aphelia around 70,000 AU from the Sun, but as the Oort cloud becomes better known, this may change.\\r\\nThe Solar System is located in the Milky Way, a barred spiral galaxy with a diameter of about 100,000 light-years containing about 100 billion stars.[130] The Sun resides in one of the Milky Way's outer spiral arms, known as the OrionÿCygnus Arm or Local Spur.[131] The Sun lies between 25,000 and 28,000 light-years from the Galactic Centre,[132] and its speed within the Milky Way is about 220?km/s, so that it completes one revolution every 225ÿ250 million years. This revolution is known as the Solar System's galactic year.[133] The solar apex, the direction of the Sun's path through interstellar space, is near the constellation Hercules in the direction of the current location of the bright star Vega.[134] The plane of the ecliptic lies at an angle of about 60 to the galactic plane.[i]\\r\\nThe Solar System's location in the Milky Way is a factor in the evolutionary history of life on Earth. Its orbit is close to circular, and orbits near the Sun are at roughly the same speed as that of the spiral arms.[136][137] Therefore, the Sun passes through arms only rarely. Because spiral arms are home to a far larger concentration of supernovae, gravitational instabilities, and radiation that could disrupt the Solar System, this has given Earth long periods of stability for life to evolve.[136] The Solar System also lies well outside the star-crowded environs of the galactic centre. Near the centre, gravitational tugs from nearby stars could perturb bodies in the Oort cloud and send many comets into the inner Solar System, producing collisions with potentially catastrophic implications for life on Earth. The intense radiation of the galactic centre could also interfere with the development of complex life.[136] Even at the Solar System's current location, some scientists have speculated that recent supernovae may have adversely affected life in the last 35,000 years, by flinging pieces of expelled stellar core towards the Sun, as radioactive dust grains and larger, comet-like bodies.[138]\\r\\nThe Solar System is in the Local Interstellar Cloud or Local Fluff. It is thought to be near the neighbouring G-Cloud but it is not known if the Solar System is embedded in the Local Interstellar Cloud, or if it is in the region where the Local Interstellar Cloud and G-Cloud are interacting.[139][140] The Local Interstellar Cloud is an area of denser cloud in an otherwise sparse region known as the Local Bubble, an hourglass-shaped cavity in the interstellar medium roughly 300 light-years (ly) across. The bubble is suffused with high-temperature plasma, that suggests it is the product of several recent supernovae.[141]\\r\\nThere are relatively few stars within ten light-years of the Sun. The closest is the triple star system Alpha Centauri, which is about 4.4 light-years away. Alpha Centauri A and B are a closely tied pair of Sun-like stars, whereas the small red dwarf, Proxima Centauri, orbits the pair at a distance of 0.2 light-year. In 2016, a potentially habitable exoplanet was confirmed to be orbiting Proxima Centauri, called Proxima Centauri b, the closest confirmed exoplanet to the Sun.[142] The stars next closest to the Sun are the red dwarfs Barnard's Star (at 5.9?ly), Wolf 359 (7.8?ly), and Lalande 21185 (8.3?ly).\\r\\nThe largest nearby star is Sirius, a bright main-sequence star roughly 8.6 light-years away and roughly twice the Sun's mass and that is orbited by a white dwarf, Sirius B. The nearest brown dwarfs are the binary Luhman 16 system at 6.6 light-years. Other systems within ten light-years are the binary red-dwarf system Luyten 726-8 (8.7?ly) and the solitary red dwarf Ross 154 (9.7?ly).[143] The closest solitary Sun-like star to the Solar System is Tau Ceti at 11.9 light-years. It has roughly 80% of the Sun's mass but only 60% of its luminosity.[144] The closest known free-floating planetary-mass object to the Sun is WISE 0855?0714,[145] an object with a mass less than 10 Jupiter masses roughly 7 light-years away.\\r\\nCompared to other planetary systems the Solar System stands out in lacking planets interior to the orbit of Mercury.[146][147] The known Solar System also lacks super-Earths (Planet Nine could be a super-Earth beyond the known Solar System).[146] Uncommonly, it has only small rocky planets and large gas giants; elsewhere planets of intermediate size are typicalboth rocky and gasso there is no \\"gap\\" as seen between the size of Earth and of Neptune (with a radius 3.8 times as large). Also, these super-Earths have closer orbits than Mercury.[146] This led to hypothesis that all planetary systems start with many close-in planets, and that typically a sequence of their collisions causes consolidation of mass into few larger planets, but in case of the Solar System the collisions caused their destruction and ejection.[148][149]\\r\\nThe orbits of Solar System planets are nearly circular. Compared to other systems, they have smaller orbital eccentricity.[146] Although there are attempts to explain it partly with a bias in the radial-velocity detection method and partly with long interactions of a quite high number of planets, the exact causes remain undetermined.[146][150]\\r\\nThis section is a sampling of Solar System bodies, selected for size and quality of imagery, and sorted by volume. Some omitted objects are larger than the ones included here, notably Eris, because these have not been imaged in high quality.\\r\\nSolar System?L Local Interstellar Cloud?L Local Bubble?L Gould Belt?L Orion Arm?L Milky Way?L Milky Way subgroup?L Local Group?L Virgo Supercluster?L Laniakea Supercluster?L PiscesÿCetus Supercluster Complex?L Observable universe?L Universe\\r\\nEach arrow (L) may be read as \\"within\\" or \\"part of\\".","input":"Which is the largest planet in solar system?"},{"output":"Benedict Arnold","context":"American Revolutionary War Continental Army:\\r\\nBritish Army\\r\\nThis monument was erected under the patronage of the State of Connecticut in the 55th year of the Independence of the U.S.A. in memory of the brave patriots massacred at Fort Griswold near this spot on the 6th of Sept. AD 1781, when the British, under the command of the Traitor Benedict Arnold, burnt the towns of New London and Groton and spread desolation and woe throughout the region.\\r\\nBenedict Arnold (January 14, 1741 [O.S. January 3, 1740][1][2]?ÿ June 14, 1801) was a general during the American Revolutionary War, who fought for the American Continental Army, and later famously defected to the British Army. While a general on the American side, he obtained command of the fortifications at West Point, New York (which after 1802 would become the site of the U.S. Military Academy), overlooking the cliffs at the Hudson River (upriver from British-occupied New York City), and planned to surrender them to British forces. This plan was exposed in September 1780. He was commissioned into the British Army as a brigadier general.\\r\\nArnold was born in Connecticut and was a merchant operating ships on the Atlantic Ocean when the war broke out in 1775. He joined the growing army outside Boston and distinguished himself through acts of intelligence and bravery. His actions included the Capture of Fort Ticonderoga in 1775, defensive and delaying tactics at the Battle of Valcour Island on Lake Champlain in 1776 (allowing American forces time to prepare New York's defenses), the Battle of Ridgefield, Connecticut (after which he was promoted to major general), operations in relief of the Siege of Fort Stanwix, and key actions during the pivotal Battles of Saratoga in 1777, in which he suffered leg injuries that halted his combat career for several years.\\r\\nDespite Arnold's successes, he was passed over for promotion by the Continental Congress, while other officers claimed credit for some of his accomplishments.[3] Adversaries in military and political circles brought charges of corruption or other malfeasance, but most often he was acquitted in formal inquiries. Congress investigated his accounts and concluded that he was indebted to Congress (he also had spent much of his own money on the war effort).[vague] Arnold was frustrated and bitter at this, as well as with the alliance with France and the failure of Congress to accept Britain's 1778 proposal to grant full self-governance in the colonies. He decided to change sides, and opened secret negotiations with the British. In July 1780, he was awarded command of West Point. His scheme was to surrender the fort to the British, but it was exposed when American forces captured British Major John Andr carrying papers which revealed the plot. Upon learning of Andr's capture, Arnold fled down the Hudson River to the British sloop-of-war Vulture, narrowly avoiding capture by the forces of George Washington, who had been alerted to the plot.\\r\\nArnold received a commission as a brigadier general in the British Army, an annual pension of S360, and a lump sum of over S6,000.[4] He led British forces on raids in Virginia and against New London and Groton, Connecticut before the war effectively ended with the American victory at Yorktown. In the winter of 1782, he moved to London with his second wife Margaret \\"Peggy\\" Shippen Arnold. He was well received by King George III and the Tories, but frowned upon by the Whigs. In 1787, he returned to the merchant business with his sons Richard and Henry in Saint John, New Brunswick. He returned to London to settle permanently in 1791, where he died ten years later.\\r\\nThe name \\"Benedict Arnold\\" quickly became a byword in the United States for treason or betrayal because he betrayed his countrymen by leading the British army in battle against the men whom he once commanded.[5] His earlier legacy is recalled in the ambiguous nature of some of the memorials that have been placed in his honor.\\r\\n\\r\\n\\r\\nBenedict Arnold was born a British subject, the second of six children to Benedict Arnold (1683ÿ1761) and Hannah Waterman King in Norwich, Connecticut Colony on January 14, 1741.[1][6] He was named after his great-grandfather Benedict Arnold, an early governor of the Colony of Rhode Islandas were his father and grandfather, as well as an older brother who died in infancy.[1] Only Benedict and his sister Hannah survived to adulthood; his other siblings succumbed to yellow fever in childhood.[7] His siblings were, in order of birth: Benedict (August 15, 1738?ÿ April 30, 1739), Hannah (December 9, 1742?ÿ August 11, 1803), Mary (June 4, 1745?ÿ September 10, 1753), Absolom (April 4, 1747?ÿ July 22, 1750), and Elizabeth (November 19, 1749?ÿ September 29, 1755). Arnold was a descendant of John Lothropp through his maternal grandmother, an ancestor of at least six U.S. presidents.[8]\\r\\nBenedict Arnold's father was a successful businessman, and the family moved in the upper levels of Norwich society. When he was ten, Arnold was enrolled in a private school in nearby Canterbury, with the expectation that he would eventually attend Yale. However, the deaths of his siblings two years later may have contributed to a decline in the family fortunes, since his father took up drinking. By the time that he was fourteen, there was no money for private education. His father's alcoholism and ill health kept him from training Arnold in the family mercantile business, but his mother's family connections secured an apprenticeship for him with her cousins Daniel and Joshua Lathrop, who operated a successful apothecary and general merchandise trade in Norwich.[9] His apprenticeship with the Lathrops lasted seven years.[10]\\r\\nArnold was very close to his mother, who died in 1759. His father's alcoholism worsened after her death, and the youth took on the responsibility of supporting his father and younger sister. His father was arrested on several occasions for public drunkenness, was refused communion by his church, and eventually died in 1761.[10]\\r\\nIn 1755, Benedict Arnold was attracted by the sound of a drummer and attempted to enlist in the provincial militia for service against the French, but his mother refused permission.[11] In 1757 when he was sixteen, he did enlist in the Connecticut militia, which marched off toward Albany and Lake George. The French had besieged Fort William Henry in northeastern New York, and their Indian allies had committed atrocities after their victory. Word of the siege's disastrous outcome led the company to turn around; Arnold served for 13 days.[12] A commonly accepted story that Arnold deserted from militia service in 1758[13] is based on uncertain documentary evidence.[14]\\r\\nBenedict Arnold established himself in business in 1762 as a pharmacist and bookseller in New Haven, Connecticut with the help of the Lathrops.[15] He was hardworking and successful, and was able to rapidly expand his business. In 1763, he repaid money borrowed from the Lathrops,[16] repurchased the family homestead that his father had sold when deeply in debt, and re-sold it a year later for a substantial profit. In 1764, he formed a partnership with Adam Babcock, another young New Haven merchant. They bought three trading ships, using the profits from the sale of his homestead, and established a lucrative West Indies trade.\\r\\nDuring this time, Benedict Arnold brought his sister Hannah to New Haven and established her in his apothecary to manage the business in his absence. He traveled extensively in the course of his business throughout New England and from Quebec to the West Indies, often in command of one of his own ships.[17] On one of his voyages, Arnold fought a duel in Honduras with a British sea captain who had called him a \\"damned Yankee, destitute of good manners or those of a gentleman\\".[18][19] The captain was wounded after the first exchange of gunfire, and apologized after Arnold threatened to aim to kill on the second.[20]\\r\\nThe Sugar Act of 1764 and the Stamp Act of 1765 severely curtailed mercantile trade in the colonies.[21] The latter act prompted Arnold to join the chorus of voices in opposition to those taxes, and also led to his entry into the Sons of Liberty, a secret organization that was not afraid to use violence to oppose implementation of those and other unpopular Parliamentary measures.[22] Arnold initially took no part in any public demonstrations but, like many merchants, continued to trade as if the Stamp Act did not exist, in effect becoming a smuggler in defiance of the act. Arnold also faced financial ruin, falling S16,000 in debt, with creditors spreading rumors of his insolvency to the point where he took legal action against them.[23] On the night of January 28, 1767, Arnold and members of his crew, watched by a crowd of Sons of Liberty, roughed up a man suspected of attempting to inform authorities of Arnold's smuggling. Arnold was convicted of a disorderly conduct charge and fined the relatively small amount of 50 shillings; publicity of the case and widespread sympathy for his view probably contributed to the light sentence.[24]\\r\\nOn February 22, 1767, Benedict Arnold married Margaret Mansfield, daughter of Samuel Mansfield, the sheriff of New Haven, an acquaintance that may have been made through the membership of both Mansfield and Arnold in the local Masonic Lodge.[25] Their son Benedict was born the following year,[26] and was followed by brothers Richard in 1769 and Henry in 1772.[25] Margaret died early in the revolution on June 19, 1775, while Arnold was at Fort Ticonderoga following its capture.[27] The household, even while she lived, was dominated by Arnold's sister Hannah. Arnold benefited from his relationship with Mansfield, who became a partner in his business and used his position as sheriff to shield Arnold from creditors.[28]\\r\\nBenedict Arnold was in the West Indies when the Boston Massacre took place on March 5, 1770. He wrote that he was \\"very much shocked\\" and wondered \\"good God, are the Americans all asleep and tamely giving up their liberties, or are they all turned philosophers, that they don't take immediate vengeance on such miscreants?\\"[29]\\r\\nBenedict Arnold began the war as a captain in Connecticut's militia, a position to which he was elected in March 1775. His company marched northeast the following month to assist in the siege of Boston that followed the outbreak of hostilities at Lexington and Concord. Arnold proposed to the Massachusetts Committee of Safety an action to seize Fort Ticonderoga in New York, which he knew was poorly defended. They issued him a colonel's commission on May 3, 1775, and he immediately rode off to the west, arriving at Castleton in the disputed New Hampshire Grants (present-day Vermont) in time to participate with Ethan Allen and his men in the capture of Fort Ticonderoga. He followed up that action with a bold raid on Fort Saint-Jean on the Richelieu River north of Lake Champlain. A Connecticut militia force arrived at Ticonderoga in June; Arnold had a dispute with its commander over control of the fort, and resigned his Massachusetts commission. He was on his way home from Ticonderoga when he learned that his wife had died earlier in June.[30]\\r\\nThe Second Continental Congress authorized an invasion of Quebec, in part on the urging of Arnoldbut he was passed over for command of the expedition. Arnold then went to Cambridge, Massachusetts and suggested to George Washington a second expedition to attack Quebec City via a wilderness route through present-day Maine. Arnold received a colonel's commission in the Continental Army for this expedition. He left Cambridge in September 1775 with 1,100 men. Arnold arrived before Quebec City in November, after a difficult passage in which 300 men turned back and another 200 died en route. He and his men were joined by Richard Montgomery's small army and participated in the December 31 assault on Quebec City in which Montgomery was killed and Arnold's leg was shattered. His chaplain Rev. Samuel Spring carried him to the makeshift hospital at the H?tel Dieu. Arnold was promoted to brigadier general for his role in reaching Quebec, and he maintained an ineffectual siege of the city until he was replaced by Major General David Wooster in April 1776.[31]\\r\\nBenedict Arnold then traveled to Montreal where he served as military commander of the city until forced to retreat by an advancing British army that had arrived at Quebec in May. He presided over the rear of the Continental Army during its retreat from Saint-Jean, where he was reported by James Wilkinson to be the last person to leave before the British arrived. He then directed the construction of a fleet to defend Lake Champlain, which was overmatched and defeated in the October 1776 Battle of Valcour Island. However, his actions at Saint-Jean and Valcour Island played a notable role in delaying the British advance against Ticonderoga until 1777.[32]\\r\\nDuring these actions, Benedict Arnold made a number of friends and a larger number of enemies within the army power structure and in Congress. He had established decent relationships with George Washington, commander of the army, as well as Philip Schuyler and Horatio Gates, both of whom had command of the army's Northern Department during 1775 and 1776.[33] However, an acrimonious dispute with Moses Hazen, commander of the 2nd Canadian Regiment, boiled over into a court martial of Hazen at Ticonderoga during the summer of 1776. Only action by Gates, then Arnold's superior at Ticonderoga, prevented his own arrest on countercharges leveled by Hazen.[34] He also had disagreements with John Brown and James Easton, two lower-level officers with political connections that resulted in ongoing suggestions of improprieties on his part. Brown was particularly vicious, publishing a handbill which claimed of Arnold, \\"Money is this man's God, and to get enough of it he would sacrifice his country\\".[35]\\r\\nGeneral Washington assigned Arnold to the defense of Rhode Island, following the British seizure of Newport in December 1776, where the militia were too poorly equipped to even consider an attack on the British.[36] Arnold took the opportunity to visit his children while near his home in New Haven, and he spent much of the winter socializing in Boston, where he unsuccessfully courted a young belle named Betsy Deblois.[37] In February 1777, he learned that he had been passed over by Congress for promotion to major general. Washington refused his offer to resign, and wrote to members of Congress in an attempt to correct this, noting that \\"two or three other very good officers\\" might be lost if they persisted in making politically motivated promotions.[38]\\r\\nBenedict Arnold was on his way to Philadelphia to discuss his future when he was alerted that a British force was marching toward a supply depot in Danbury, Connecticut. He organized the militia response, along with David Wooster and Connecticut militia General Gold S. Silliman. He led a small contingent of militia attempting to stop or slow the British return to the coast in the Battle of Ridgefield, and was again wounded in his left leg.\\r\\nBenedict Arnold continued on to Philadelphia, where he met with members of Congress about his rank. His action at Ridgefield, coupled with the death of Wooster due to wounds sustained in the action, resulted in Arnold's promotion to major general, although his seniority was not restored over those who had been promoted before him.[39] Amid negotiations over that issue, Arnold wrote out a letter of resignation on July 11, the same day that word arrived in Philadelphia, that Fort Ticonderoga had fallen to the British. Washington refused his resignation and ordered him north to assist with the defense there.[40]\\r\\nBenedict Arnold arrived in Schuyler's camp at Fort Edward, New York on July 24. On August 13, Schuyler dispatched him with a force of 900 to relieve the siege of Fort Stanwix, where he succeeded in the use of a ruse to lift the siege. Arnold had an Indian messenger sent into the camp of British Brigadier General Barry St. Leger with news that the approaching force was much larger and closer than it actually was; this convinced St. Leger's Indian support to abandon him, forcing him to give up the effort.[41]\\r\\nBenedict Arnold then returned to the Hudson, where General Gates had taken over command of the American army, which had by then retreated to a camp south of Stillwater.[42] He then distinguished himself in both Battles of Saratoga, even though General Gates removed him from field command after the first battle, following a series of escalating disagreements and disputes that culminated in a shouting match.[43] During the fighting in the second battle, Arnold operated against Gates' orders and took to the battlefield to lead attacks on the British defenses. He was again severely wounded in the left leg late in the fighting. Arnold himself said that it would have been better had it been in the chest instead of the leg.[44] Burgoyne surrendered ten days after the second battle, on October 17, 1777. In response to Arnold's valor at Saratoga, Congress restored his command seniority.[45] However, Arnold interpreted the manner in which they did so as an act of sympathy for his wounds, and not an apology or recognition that they were righting a wrong.[46]\\r\\nArnold spent several months recovering from his injuries. Rather than allowing his shattered left leg to be amputated, he had it crudely set, leaving it 2 inches (5?cm) shorter than the right. He returned to the army at Valley Forge in May 1778 to the applause of men who had served under him at Saratoga.[47] There he participated in the first recorded Oath of Allegiance along with many other soldiers, as a sign of loyalty to the United States.[48]\\r\\nThe British withdrew from Philadelphia, in June 1778, and Washington appointed Arnold military commander of the city.[49] Even before the Americans reoccupied Philadelphia, Arnold began planning to capitalize financially on the change in power there, engaging in a variety of business deals designed to profit from war-related supply movements and benefiting from the protection of his authority.[50] Such schemes were not exactly uncommon among American officers, but Arnold's schemes were sometimes frustrated by powerful local politicians such as Joseph Reed, who eventually amassed enough evidence to publicly air charges against him. Arnold demanded a court martial to clear the charges, writing to Washington in May 1779, \\"Having become a cripple in the service of my country, I little expected to meet [such] ungrateful returns\\".[51]\\r\\nArnold lived extravagantly in Philadelphia, and was a prominent figure on the social scene. During the summer of 1778, he met Peggy Shippen, the 18-year-old daughter of Judge Edward Shippen, a Loyalist sympathizer who had done business with the British while they occupied the city.[53] Peggy had been courted by British Major John Andr during the British occupation of Philadelphia.[54] Peggy and Arnold married on April 8, 1779.[55] Peggy and her circle of friends had found methods of staying in contact with paramours across the battle lines, despite military bans on communication with the enemy.[56] Some of this communication was effected through the services of Joseph Stansbury, a Philadelphia merchant.[57]\\r\\nAs early as 1778, there were signs that Arnold was unhappy with his situation and pessimistic about the country's future. On November 10, 1778, General Nathanael Greene wrote to General John Cadwalader, \\"I am told General Arnold is become very unpopular among you oweing to his associateing too much with the Tories.\\"[58] A few days later, Greene received a letter from Arnold, where Arnold lamented over the \\"deplorable\\" and \\"horrid\\" situation of the country at that particular moment, citing the depreciating currency, disaffection of the army, and internal fighting in Congress for the country's problems, while predicting \\"impending ruin\\" if things would not soon change.[59]\\r\\nSome time early in May 1779, Arnold met with Joseph Stansbury (whose testimony before a British commission apparently erroneously placed his meeting with Arnold in June). Stansbury said that he then \\"went secretly to New York with a tender of [Arnold's] services to Sir Henry Clinton.\\"[60] Stansbury ignored instructions from Arnold to involve no one else in the plot, and crossed the British lines and went to see Jonathan Odell in New York. Odell was a Loyalist working with William Franklin, the last colonial governor of New Jersey and the son of Benjamin Franklin. On May 9, Franklin introduced Stansbury to Major Andr, who had just been named the British spy chief.[61] This was the beginning of a secret correspondence between Arnold and Andr, sometimes using his wife Peggy as a willing intermediary, that culminated over a year later with Arnold's change of sides.[51]\\r\\nAndr conferred with General Clinton, who gave him broad authority to pursue Arnold's offer. Andr then drafted instructions to Stansbury and Arnold.[62] This initial letter opened a discussion on the types of assistance and intelligence that Arnold might provide, and included instructions for how to communicate in the future. Letters were to be passed through the women's circle that Peggy Arnold was a part of, but only Peggy would be aware that some letters contained instructions that were to be passed on to Andr, written in both code and invisible ink, using Stansbury as the courier.[63]\\r\\nBy July 1779, Benedict Arnold was providing the British with troop locations and strengths, as well as the locations of supply depots, all the while negotiating over compensation. At first, he asked for indemnification of his losses and S10,000, an amount that the Continental Congress had given Charles Lee for his services in the Continental Army.[64] General Clinton was pursuing a campaign to gain control of the Hudson River Valley, and was interested in plans and information on the defenses of West Point and other defenses on the Hudson River. He also began to insist on a face-to-face meeting, and suggested to Arnold that he pursue another high-level command.[65] By October 1779, the negotiations had ground to a halt.[66] Furthermore, Patriot mobs were scouring Philadelphia for Loyalists, and Arnold and the Shippen family were being threatened. Arnold was rebuffed by Congress and by local authorities in requests for security details for himself and his in-laws.[67]\\r\\nThe court martial began meeting on June 1, 1779 to consider the charges against Benedict Arnold, but it was delayed until December 1779 by General Clinton's capture of Stony Point, New York, throwing the army into a flurry of activity to react.[68] Several members on the panel of judges were ill-disposed toward Arnold over actions and disputes earlier in the war, yet Arnold was cleared of all but two minor charges on January 26, 1780.[69] Arnold worked over the next few months to publicize this fact; however, George Washington published a formal rebuke of his behavior in early April, just one week after he had congratulated Arnold on the March 19 birth of his son Edward Shippen Arnold:[70]\\r\\nThe Commander-in-Chief would have been much happier in an occasion of bestowing commendations on an officer who had rendered such distinguished services to his country as Major General Arnold; but in the present case, a sense of duty and a regard to candor oblige him to declare that he considers his conduct [in the convicted actions] as imprudent and improper.[71]\\r\\nShortly after Washington's rebuke, a Congressional inquiry into Arnold's expenditures concluded that he had failed to fully account for his expenditures incurred during the Quebec invasion, and that he owed the Congress some S1,000, largely because he was unable to document them.[72] A significant number of these documents had been lost during the retreat from Quebec. Angry and frustrated, Arnold resigned his military command of Philadelphia in late April.[73]\\r\\nEarly in April, Philip Schuyler had approached Arnold with the possibility of giving him the command at West Point. Discussions had not borne fruit between Schuyler and Washington by early June. Arnold reopened the secret channels with the British, informing them of Schuyler's proposals and including Schuyler's assessment of conditions at West Point. He also provided information on a proposed French-American invasion of Quebec that was to go up the Connecticut River (Arnold did not know that this proposed invasion was a ruse intended to divert British resources). On June 16, Arnold inspected West Point while on his way home to Connecticut to take care of personal business, and he sent a highly detailed report through the secret channel.[74] When he reached Connecticut, Arnold arranged to sell his home there and began transferring assets to London through intermediaries in New York. By early July, he was back in Philadelphia, where he wrote another secret message to Clinton on July 7 which implied that his appointment to West Point was assured and that he might even provide a \\"drawing of the works ... by which you might take [West Point] without loss\\".[75]\\r\\nMajor Andr returned victorious from the Siege of Charleston on June 18, and both he and General Clinton were immediately caught up in this news. Clinton was concerned that Washington's army and the French fleet would join in Rhode Island, and he again fixed on West Point as a strategic point to capture. Andr had spies and informers keeping track of Arnold to verify his movements. Excited by the prospects, Clinton informed his superiors of his intelligence coup, but failed to respond to Arnold's July 7 letter.[76]\\r\\nBenedict Arnold next wrote a series of letters to Clinton, even before he might have expected a response to the July 7 letter. In a July 11 letter, he complained that the British did not appear to trust him, and threatened to break off negotiations unless progress was made. On July 12, he wrote again, making explicit the offer to surrender West Point, although his price rose to S20,000 (in addition to indemnification for his losses), with a S1,000 down payment to be delivered with the response. These letters were delivered by Samuel Wallis, another Philadelphia businessman who spied for the British, rather than by Stansbury.[77]\\r\\nOn August 3, 1780, Arnold obtained command of West Point. On August 15, he received a coded letter from Andr with Clinton's final offer: S20,000 and no indemnification for his losses. Neither side knew for some days that the other was in agreement with that offer, due to difficulties in getting the messages across the lines. Arnold's letters continued to detail Washington's troop movements and provide information about French reinforcements that were being organized. On August 25, Peggy finally delivered to him Clinton's agreement to the terms.[78]\\r\\nArnold's command at West Point also gave him authority over the entire American-controlled Hudson River, from Albany down to the British lines outside New York City. While en route to West Point, Arnold renewed an acquaintance with Joshua Hett Smith, who had spied for both sides and who owned a house near the western bank of the Hudson about 15 miles south of West Point.[79]\\r\\nOnce Arnold established himself at West Point, he began systematically weakening its defenses and military strength. Needed repairs were never ordered on the chain across the Hudson. Troops were liberally distributed within Arnold's command area (but only minimally at West Point itself) or furnished to Washington on request. He also peppered Washington with complaints about the lack of supplies, writing, \\"Everything is wanting.\\"[80] At the same time, he tried to drain West Point's supplies so that a siege would be more likely to succeed. His subordinates, some long-time associates, grumbled about Arnold's unnecessary distribution of supplies and eventually concluded that he was selling them on the black market for personal gain.[80]\\r\\nOn August 30, Arnold sent a letter accepting Clinton's terms and proposing a meeting to Andr through yet another intermediary: William Heron, a member of the Connecticut Assembly whom he thought he could trust. In an ironic twist, Heron went into New York unaware of the significance of the letter and offered his own services to the British as a spy. He then took the letter back to Connecticut, suspicious of Arnold's actions, where he delivered it to the head of the Connecticut militia. General Parsons laid it aside, seeing a letter written as a coded business discussion. Four days later, Arnold sent a ciphered letter with similar content into New York through the services of the wife of a prisoner of war.[81] Eventually, a meeting was set for September 11 near Dobb's Ferry. This meeting was thwarted when British gunboats in the river fired on his boat, not being informed of his impending arrival.[82]\\r\\nBenedict Arnold and John Andr finally met on September 21 at the Joshua Hett Smith House. On the morning of September 22, the outpost at Verplanck's Point under command of Col. James Livingston fired on HMS Vulture, the ship that was intended to carry Andr back to New York. This action did sufficient damage that she retreated downriver, forcing Andr to return to New York overland. Arnold wrote out passes for Andr so that he would be able to pass through the lines, and also gave him plans for West Point.[83]\\r\\nMajor Andr was captured near Tarrytown on Saturday, September 23 by three Westchester militiamen named John Paulding, Isaac Van Wart, and David Williams.[84] The papers were found exposing the plot to capture West Point and sent to Gen. Washington, and Arnold's intentions came to light after Washington examined them.[85] Meanwhile, Andr convinced the unsuspecting Colonel John Jameson, to whom he was delivered, to send him back to Arnold at West Point. However, Major Benjamin Tallmadge, a member of the Culper Ring established under Washington's orders,[86] insisted that Jameson order the prisoner to be intercepted and brought back. Jameson reluctantly recalled the lieutenant who had been delivering Andr into Arnold's custody, but then sent the same lieutenant as a messenger to notify Arnold of Andr's arrest.[87]\\r\\nBenedict Arnold learned of Andr's capture the following morning, September 24, when he received Jameson's message that Andr was in his custody and that the papers which Andr was carrying had been sent to General Washington. Arnold received Jameson's letter while waiting for Washington, with whom he had planned to have breakfast.[88]\\r\\nBenedict Arnold hastened to the shore and ordered bargemen to row him downriver to where HMS Vulture was anchored, which then took him to New York.[89] From the ship, Arnold wrote a letter to Washington,[90] requesting that Peggy be given safe passage to her family in Philadelphia, a request that Washington granted.[91]\\r\\nWhen presented with evidence of Benedict Arnold's activities, it is reported that Washington remained calm. He did, however, investigate its extent, and suggested that he was willing to exchange Andr for Arnold during negotiations with General Clinton over the fate of Major Andr. Clinton refused this suggestion; after a military tribunal, Andr was hanged at Tappan, New York on October 2. Washington also infiltrated men into New York in an attempt to capture Arnold. This plan very nearly succeeded, but failed when Arnold changed living quarters prior to sailing for Virginia in December.[92]\\r\\nBenedict Arnold justified his actions in an open letter titled To the Inhabitants of America, published in newspapers in October 1780.[93] In the letter to Washington requesting safe passage for Peggy, he wrote, \\"Love to my country actuates my present conduct, however it may appear inconsistent to the world, who very seldom judge right of any man's actions.\\"[90]\\r\\nThe British gave Benedict Arnold a brigadier general's commission, with an annual income of several hundred pounds, but paid him only S6,315 plus an annual pension of S360 because his plot had failed.[4] In December 1780, Arnold led a force of 1,600 troops into Virginia under orders from Clinton, where he captured Richmond by surprise and then went on a rampage through Virginia, destroying supply houses, foundries, and mills.[94] This activity brought out Virginia's militia, led by Colonel Sampson Mathews, and Arnold eventually retreated to Portsmouth to either be evacuated or reinforced.[95]\\r\\nThe pursuing American army included the Marquis de Lafayette, who was under orders from Washington to hang Arnold summarily if he was captured. Reinforcements arrived in late March led by William Phillips (who served under Burgoyne at Saratoga), and Phillips led further raids across Virginia, including a defeat of Baron von Steuben at Petersburg, until his death of fever on May 12, 1781. Arnold commanded the army only until May 20, when Lord Cornwallis arrived with the southern army and took over. One colonel wrote to Clinton of Arnold, \\"there are many officers who must wish some other general in command.\\"[96] Cornwallis ignored advice proffered by Arnold to locate a permanent base away from the coast, advice that might have averted Cornwallis's later surrender at Yorktown.[96]\\r\\nOn his return to New York in June, Benedict Arnold made a variety of proposals for attacks on economic targets to force the Americans to end the war. Clinton was uninterested in most of Arnold's aggressive ideas, but finally authorized Arnold to raid the port of New London, Connecticut. On September 4, not long after the birth of his and Peggy's second son, Arnold's force of over 1,700 men raided and burned New London and captured Fort Griswold, causing damage estimated at $500,000.[97] British casualties were high; nearly one quarter of the force was killed or wounded. Clinton declared that he could ill afford any more such victories.[98]\\r\\nEven before Cornwallis's surrender in October, Benedict Arnold had requested permission from Clinton to go to England to give Lord George Germain his thoughts on the war in person.[99] When word of the surrender reached New York, Arnold renewed the request, which Clinton then granted. On December 8, 1781, Arnold and his family left New York for England.[100]\\r\\nIn London, Benedict Arnold aligned himself with the Tories, advising Germain and King George III to renew the fight against the Americans. In the House of Commons, Edmund Burke expressed the hope that the government would not put Arnold \\"at the head of a part of a British army\\" lest \\"the sentiments of true honour, which every British officer [holds] dearer than life, should be afflicted.\\"[91] To Arnold's detriment, the anti-war Whigs had gained the upper hand in Parliament, and Germain was forced to resign, with the government of Lord North falling not long after.[101]\\r\\nBenedict Arnold then applied to accompany General Carleton, who was going to New York to replace Clinton as commander-in-chief; this request went nowhere.[101] Other attempts all failed to gain positions within the government or the British East India Company over the next few years and he was forced to subsist on the reduced pay of non-wartime service.[102] His reputation also came under criticism in the British press, especially when compared to that of Major Andr, who was celebrated for his patriotism.\\r\\nOne critic said that Benedict Arnold was a \\"mean mercenary, who, having adopted a cause for the sake of plunder, quits it when convicted of that charge.\\"[101] In turning him down for an East India Company posting, George Johnstone wrote, \\"Although I am satisfied with the purity of your conduct, the generality do not think so. While this is the case, no power in this country could suddenly place you in the situation you aim at under the East India Company.\\"[103]\\r\\nIn 1785, Benedict Arnold and his son Richard moved to Saint John, New Brunswick, where they speculated in land and established a business doing trade with the West Indies. Arnold purchased large tracts of land in the Maugerville area, and acquired city lots in Saint John and Fredericton.[104] Delivery of his first ship the Lord Sheffield was accompanied by accusations from the builder that Arnold had cheated him; Arnold claimed that he had merely deducted the contractually agreed amount when the ship was delivered late.[105] After her first voyage, Arnold returned to London in 1786 to bring his family to Saint John. While there, he disentangled himself from a lawsuit over an unpaid debt that Peggy had been fighting while he was away, paying S900 to settle a S12,000 loan that he had taken while living in Philadelphia.[106] The family moved to Saint John in 1787, where Arnold created an uproar with a series of bad business deals and petty lawsuits.[107] The most serious of these was a slander suit which he won against a former business partner; and following this, townspeople burned him in effigy in front of his house, as Peggy and the children watched.[108] The family left Saint John to return to London in December 1791.[109]\\r\\nIn July 1792, Benedict Arnold fought a bloodless duel with the Earl of Lauderdale after the Earl impugned his honor in the House of Lords.[4] With the outbreak of the French Revolution, Arnold outfitted a privateer, while continuing to do business in the West Indies, even though the hostilities increased the risk. He was imprisoned by French authorities on Guadeloupe amid accusations of spying for the British, and narrowly eluded hanging by escaping to the blockading British fleet after bribing his guards. He helped organize militia forces on British-held islands, receiving praise from the landowners for his efforts on their behalf. He hoped that this work would earn him wider respect and a new command; instead, it earned him and his sons a land-grant of 15,000 acres (6,100?ha) in Upper Canada,[110] near present-day Renfrew, Ontario.[111]\\r\\nIn January 1801, Benedict Arnold's health began to decline.[91] He had suffered from gout since 1775,[112] and the condition attacked his unwounded leg to the point where he was unable to go to sea. The other leg ached constantly, and he walked only with a cane. His physicians diagnosed him as having dropsy, and a visit to the countryside only temporarily improved his condition. He died after four days of delirium on June 14, 1801, at the age of 60.[91] Legend has it that, when he was on his deathbed, he said, \\"Let me die in this old uniform in which I fought my battles. May God forgive me for ever having put on another,\\"[113] but this story may be apocryphal.[3] Arnold was buried at St. Mary's Church, Battersea in London, England.[114] As a result of a clerical error in the parish records, his remains were removed to an unmarked mass grave during church renovations a century later.[115] His funeral procession boasted \\"seven mourning coaches and four state carriages\\";[91] the funeral was without military honors.[116]\\r\\nBenedict Arnold left a small estate, reduced in size by his debts, which Peggy undertook to clear.[4][91] Among his bequests were considerable gifts to one John Sage, perhaps an illegitimate son or grandson.[117]\\r\\nBenedict Arnold's contributions to American independence are largely underrepresented in popular culture, while his name became synonymous with traitor, in the 19th century. The demonization of Arnold began immediately after his betrayal became public. Biblical themes were often invoked; Benjamin Franklin wrote that \\"Judas sold only one man, Arnold three millions\\", and Alexander Scammell described Arnold's actions as \\"black as hell\\".[118]\\r\\nIn his home town of Norwich someone scrawled the word \\"Traitor\\" next to his record of birth at City Hall. Additionally, the gravestones of all but his mother were destroyed.[119]\\r\\nEarly biographers attempted to describe Arnold's entire life in terms of treacherous or morally questionable behavior. The first major biography of Arnold was The Life and Treason of Benedict Arnold, published in 1832 by historian Jared Sparks; it was particularly harsh in showing how Arnold's treacherous character was allegedly formed out of childhood experiences.[120] George Canning Hill authored a series of moralistic biographies in the mid-19th century, and began his 1865 biography of Arnold: \\"Benedict, the Traitor, was born...\\".[121]\\r\\nSocial historian Brian Carso notes that, as the 19th century progressed, the story of Arnold's betrayal was portrayed with near-mythical proportions as a part of the national creation story. It was invoked again as sectional conflicts increased in the years before the American Civil War. Washington Irving used it as part of an argument against dismemberment of the union in his 1857 Life of George Washington, pointing out that the unity of New England and the southern states which led to independence was made possible in part by holding West Point.[122] Jefferson Davis and other southern secessionist leaders were unfavorably compared to Arnold, implicitly and explicitly likening the idea of secession to treason. Harper's Weekly published an article in 1861 describing Confederate leaders as \\"a few men directing this colossal treason, by whose side Benedict Arnold shines white as a saint.\\"[123]\\r\\nFictional invocations of Benedict Arnold's name carry strongly negative overtones.[citation needed] A moralistic children's tale entitled \\"The Cruel Boy\\" was widely circulated in the 19th century. It described a boy who stole eggs from birds' nests, pulled wings off insects, and engaged in other sorts of wanton cruelty, who then grew up to become a traitor to his country.[124] The boy is not identified until the end of the story, when his place of birth is given as Norwich, Connecticut, and his name is given as Benedict Arnold.[125] However, not all depictions of Arnold were so negative. Some theatrical treatments of the 19th century explored his duplicity, seeking to understand rather than demonize it.[126]\\r\\nCanadian historians have treated Benedict Arnold as a relatively minor figure. His difficult time in New Brunswick led historians to summarize it as full of \\"controversy, resentment, and legal entanglements\\" and to conclude that he was disliked by both Americans and Loyalists.[127] Historian Barry Wilson points out that Arnold's descendants ended up establishing deep roots in the country, becoming leading settlers in Upper Canada and later in lands further west, where they established settlements in Saskatchewan.[128] His descendants who adopted the Arnold surname are spread across Canada, most of all those of John Sage.[129] His long woollen British scarlet military jacket with a buff lining continues to be owned by descendants; as of 2001, it was held in Saskatchewan. It has reportedly been passed in each generation to the eldest male of the family.[130]\\r\\nDuring his marriage to Margaret Mansfield, Benedict Arnold had three sons, all of whom later served in the British Army:[131][132]\\r\\nand with Peggy Shippen, he raised a family also active in the British Army:\\r\\nThere is a memorial to Benedict Arnold on the Saratoga battlefield, now preserved within Saratoga National Historical Park, that does not mention his name, donated by Civil War General John Watts DePeyster. The inscription on the Boot Monument reads: \\"In memory of the most brilliant soldier of the Continental army, who was desperately wounded on this spot, winning for his countrymen the decisive battle of the American Revolution, and for himself the rank of Major General.\\"[133] The victory monument at Saratoga has four niches, three of which are occupied by statues of Generals Gates, Schuyler, and Morgan. The fourth niche is empty.[134]\\r\\nThere are plaques on the grounds of the United States Military Academy at West Point commemorating all of the generals who served in the Revolution. One plaque bears only a rank and a date but no name: \\"major general...born 1740\\".[2][120]\\r\\nA historical marker in Danvers, Massachusetts commemorates Benedict Arnold's 1775 expedition to Quebec.[135] There are also historical markers bearing his name at Wyman Lake Rest Area on US-201 north of Moscow, Maine, on the western bank of Lake Champlain, New York, and two in Skowhegan, Maine.[136]\\r\\nThe house where Benedict Arnold lived at 62 Gloucester Place in central London bears a plaque describing Arnold as an \\"American Patriot\\".[137] He was buried at St Mary's Church, Battersea, England which has a commemorative stained glass window added between 1976 and 1982.[138] The faculty club at the University of New Brunswick, Fredericton has a Benedict Arnold Room in which framed original letters written by Arnold hang on the walls.","input":"Who was a traitor in the revolutionary war?"},{"output":"commemorate military personnel who have died in war","context":"The remembrance poppy is an artificial flower that has been used since 1921 to commemorate military personnel who have died in war, and represents a common or field poppy, Papaver rhoeas. Inspired by the World War I poem \\"In Flanders Fields\\", and promoted by Moina Michael, they were first adopted by the American Legion to commemorate American soldiers killed in that war (1914ÿ1918). They were then adopted by military veterans' groups in parts of the British Empire.\\r\\nToday, they are mostly used in the United Kingdom, Canada, Australia and New Zealand, to commemorate their servicemen and women killed in all conflicts. There, small artificial poppies are often worn on clothing leading up to Remembrance Day/Armistice Day,[1] and poppy wreaths are often laid at war memorials. In Australia and New Zealand, they are also worn on Anzac Day.\\r\\nThe Royal British Legion's Poppy Appeal has caused some controversy, with someincluding British Army veteransarguing that it has become excessive, is being used to marshal support behind British military campaigns, and that public figures are pressured to wear poppies.\\r\\n\\r\\n\\r\\nThe remembrance poppy was inspired by the World War I poem \\"In Flanders Fields\\". Its opening lines refer to the many poppies that were the first flowers to grow in the churned-up earth of soldiers' graves in Flanders, a region of Belgium.[2] It is written from the point of view of the dead soldiers and, in the last verse, they call on the living to continue the conflict.[3] The poem was written by Canadian physician, Lieutenant Colonel John McCrae, on 3 May 1915 after witnessing the death of his friend, a fellow soldier, the day before. The poem was first published on 8 December 1915 in the London-based magazine Punch.\\r\\nIn 1918, Moina Michael, who had taken leave from her professorship at the University of Georgia to be a volunteer worker for the American YWCA, was inspired by the poem and published a poem of her own called \\"We Shall Keep the Faith\\".[4] In tribute to McCrae's poem, she vowed to always wear a red poppy as a symbol of remembrance for those who fought and helped in the war.[2] At a November 1918 YWCA Overseas War Secretaries' conference, she appeared with a silk poppy pinned to her coat and distributed 25 more to those attending. She then campaigned to have the poppy adopted as a national symbol of remembrance. At a conference in 1920, the National American Legion adopted it as their official symbol of remembrance.[2] At this conference, Frenchwoman Anna E. Gurin was inspired to introduce the artificial poppies commonly used today. In 1921 she sent her poppy sellers to London, where the symbol was adopted by Field Marshal Douglas Haig, a founder of the Royal British Legion. It was also adopted by veterans' groups in Canada, Australia and New Zealand.[2] James Fox notes that all of the countries who adopted the remembrance poppy were the \\"victors\\" of World War I.[3]\\r\\nToday, remembrance poppies are mostly used in the United Kingdom, Canada, Australia and New Zealandcountries which were formerly part of the British Empireto commemorate their servicemen and women killed in all conflicts. They are used to a lesser extent in the United States.\\r\\nIn Canada, the poppy is the official symbol of remembrance worn during the two weeks before 11 November, having been adopted in 1921. The Royal Canadian Legion, which has trademarked the image,[5] suggests that poppies be worn on the left lapel, or as near the heart as possible.[6]\\r\\nUntil 1996, poppies were made by disabled veterans in Canada, but they have since been made by a private contractor.[7] The Canadian poppies consist of two pieces of moulded plastic covered with flocking with a pin to fasten them to clothing. At first the poppies were made with a black centre. From 1980 to 2002, the centres were changed to green. Current designs are black only; this change caused confusion and controversy to those unfamiliar with the original design.[8] In 2007, sticker versions of the poppy were made for children, the elderly, and healthcare and food industry workers.[9]  Canada also issues a cast metal \\"Canada Remembers\\" pin featuring a gold maple leaf and two poppies, one representing the fallen and the other representing those who remained on the home front.[10]\\r\\nFollowing the installation of the Tomb of the Unknown Soldier at the National War Memorial in Ottawa in 2000, where the national Remembrance service is held, a new tradition formed spontaneously as attendees laid their poppies on the tomb at the end of the service. This tradition, while not part of the official program, has become widely practised elsewhere in the country, with others leaving cut flowers, photographs, or letters to the deceased.\\r\\nSince joining Canada in 1949, the remembrance poppy and Armistice Day commemorations have largely displaced Newfoundland's own commemorative floral emblem, the forget-me-not, and its own Memorial Day held on 1 July. Although in recent years the forget-me-not has had somewhat of a resurgence in Newfoundland's military commemorations,[11][12] the remembrance poppy is more common.\\r\\nIn Australia, remembrance poppies have been used since 1921 to commemorate Australian soldiers who died in war. On Remembrance Day (11 November) and Anzac Day (25 April) they are laid at war memorials, and are sold by the Returned and Services League of Australia (RSL) in return for donations.[13]\\r\\nIn New Zealand, remembrance poppies are most often worn on Anzac Day (25 April) to commemorate New Zealand soldiers who died in war. They are also worn on Remembrance Day, and are sold by the Royal New Zealand Returned and Services' Association (RSA) in return for donations. The RSA planned to hold its first Poppy Day appeal around the time of Armistice Day 1921, as other countries were doing. However, the ship carrying the poppies from France arrived in New Zealand too late, and so the association waited until Anzac Day 1922. This first Poppy Day appeal was a success. Most of the money raised went to needy soldiers and their families, while the rest went to the French Children's League to help relieve suffering in war-ravaged areas of northern France.\\r\\nThe popularity of Poppy Day grew and there were record collections during the Second World War. By 1945, 750,000 poppies were being distributed nationwide, which equated to half the population.[14]\\r\\nIn the United Kingdom, remembrance poppies are sold by The Royal British Legion (RBL). This is a charity providing financial, social, political and emotional support to those who have served or who are currently serving in the British Armed Forces, and their dependants. They are sold on the streets by volunteers in the weeks before Remembrance Day. The remembrance poppy is the trademark of The Royal British Legion.[15][16][17] The RBL state, \\"The red poppy is our registered mark and its only lawful use is to raise funds for the Poppy Appeal\\";[18] its yearly fundraising drive in the weeks before Remembrance Day. The RBL says these poppies are \\"worn to commemorate the sacrifices of our Armed Forces and to show support to those still serving today\\".[19] Other poppy merchandise is sold throughout the year as part of the ongoing fundraising.[20]\\r\\nIn England, Wales, and Northern Ireland, the poppies typically have two red paper petals mounted on a green plastic stem with a single green paper leaf and a prominent black plastic central boss. The stem has an additional branch used to anchor the poppy via a pin in the lapel or buttonhole. In Scotland, the poppies are curled and have four petals with no leaf. The yearly selling of poppies is a major source of income for the RBL in the UK. The poppy has no fixed price; it is sold for a donation or the price may be suggested by the seller. The black plastic center of the poppy was marked \\"Haig Fund\\" until 1994 but is now marked \\"Poppy Appeal\\".[21] A team of about 50 peoplemost of them disabled former British military personnelwork all year round to make millions of poppies at the Poppy Factory in Richmond.[22] Scottish poppies are made in the Lady Haig's Poppy Factory in Edinburgh.\\r\\nFor many years after World War I, poppies were worn only on Remembrance Day itself.[23] However, today the RBL's \\"Poppy Appeal\\" has a higher profile than any other charity appeal in the UK.[23] The poppies are widespread from late October until mid-November every year and are worn by the general public, politicians, the Royal Family and other public figures. It has become common to see large poppies on buses, tube trains and aeroplanes as well as on lampposts, billboards, public buildings and landmarks. Many newspapers and magazines show a poppy on their cover page, and some social network users add poppies to their avatars.[24] Each year, an official Poppy Appeal single has been released.[25] Celebrities have begun wearing expensive crystal-clad poppy brooches, or 'bling poppies', which are sold by the RBL.[26] There are thousands of poppy sellers on the streets and numerous fundraising events; such as concerts, fairs, marathons and competitions. There are also many other events to raise awareness. For example, in 2011, a Second World War plane dropped 6,000 poppies over the town of Yeovil in Somerset.[27] In 2014, the dry moat of the Tower of London was covered with 888,246 ceramic poppies ÿ one for each soldier of the British Empire killed in World War I.\\r\\nIn recent years, there has been growing controversy over the Poppy Appeal. Someincluding British Army veteranshave argued that the Poppy Appeal has become excessive and garish, that it is being used to marshal support behind British military campaigns, and that poppy wearing has become compulsory for public figures.[28][29] Channel 4 newsreader Jon Snow described it as \\"poppy fascism\\".[30] Columnist Dan O'Neill wrote that \\"presenters and politicians seem to compete in a race to be first ÿ poppies start sprouting in mid-October while the absence of a poppy is interpreted as absence of concern for the war dead, almost as an unpatriotic act of treachery\\".[31] Likewise, Jonathan Bartley of the religious think-tank Ekklesia said \\"public figures in Britain are urged, indeed in many cases, required, to wear ... the red poppy, almost as an article of faith. There is a political correctness about the red poppy\\".[32] Journalist Robert Fisk complained that the poppy has become a seasonal \\"fashion accessory\\" and that people were \\"ostentatiously wearing a poppy for social or work-related reasons, to look patriotic when it suited them\\".[33]Some far-right groups have used the poppy as a symbol of militant British nationalism, while some Muslims have begun to reject it as a symbol of Western imperialism.[3]\\r\\nIn 1997 and again in 2000 the Royal British Legion registered the Poppy under Intellectual Property Rights (1997 Case EU000557058)[34] and Trade Mark (2000 Trade Mark 2239583).[35]\\r\\nThe Royal British Legion also holds a yearly poppy appeal in Northern Ireland and in 2009 raised more than S1m.[36] However, the wearing of poppies in Northern Ireland is controversial.[3] It is seen by many as a political symbol[3][37] and a symbol of Britishness,[3][38][39] representing support for the British Army.[37] The poppy has long been the preserve of the unionist/loyalist community.[3][38] Loyalist paramilitaries (such as the UVF and UDA) have also used poppies to commemorate their own members who were killed in The Troubles.[40]\\r\\nMost Irish nationalists/republicans, and Irish Catholics, choose not to wear poppies;[37] they regard the Poppy Appeal as supporting soldiers who killed Irish civilians (for example on Bloody Sunday) and who colluded with illegal loyalist paramilitaries (for example the Glenanne gang) during The Troubles.[3][41][42][43][44][45] Irish nationalist groups, and victims' groups, have urged the BBC to end its policy that all presenters must wear poppies. They argue that it breaches impartiality and point out that political symbols are banned in workplaces in Northern Ireland. They also say that the BBC, as a publicly funded body, should broadly reflect the whole community.[43][46] Likewise, the director of Relatives for Justice has condemned the wearing of poppies by police officers in Catholic neighbourhoods, calling it \\"repugnant and offensive to the vast majority of people within our community, given the role of the British Army\\".[42] In the Irish Independent, it was claimed that \\"substantial amounts\\" of money raised from selling poppies are used \\"to build monuments to insane or inane generals or build old boys' clubs for the war elite\\".[44] However, on Remembrance Day 2010 the SDLPs Margaret Ritchie was the first leader of a nationalist party to wear one.[47]\\r\\nDuring World War I, all of Ireland was part of the United Kingdom and about 200,000 Irishmen fought in the British Army (see Ireland and World War I). Although the British Army is banned from actively recruiting in the Republic of Ireland,[48][49] a small number of its citizens still enlist.[50][51][52] The RBL thus has a branch in the Republic and holds a yearly Poppy Appeal there. The RBL also holds a wreath-laying ceremony at St Patrick's Cathedral, Dublin, which the President of Ireland has attended.[53]\\r\\nThe Republic has its own National Day of Commemoration in July for all Irish people who died in war. However, as in other non-Commonwealth countries, poppies are not often worn and are not part of the main commemorations.[54][55] This is partly due to the British Army's role in fighting against Irish independence, its activities during the War of Independence (for example the Burning of Cork)[56] and the British Army's role in Northern Ireland during the Troubles.\\r\\nIn the years following the War of Independence, the poppy was particularly controversial, with nationalists seeing it as a provocative symbol of British imperialism. In Dublin, British Legion marchers often had poppies snatched from their lapels, which led to street fights. In response, some poppy-wearers hid razor blades in their poppies.[57][58] \\"As the 1930s progressed, 'Poppy Day' lost much of its violent edge in Dublin, but the wearing of the symbol also became less commonplace in subsequent decades\\".[59]\\r\\nIn 2017, Taoiseach Leo Varadkar wore a \\"shamrock poppy\\" in the Dil, the first leader of Fine Gael to do so.[60]\\r\\nIn the United States, the Veterans of Foreign Wars conducted the first nationwide distribution of remembrance poppies before Memorial Day in 1922.[61] Today, the American Legion Auxiliary distributes crepe-paper poppies in exchange for donations around Memorial Day and Veterans Day.[62][63][64][65]\\r\\nIn Hong Kongwhich was formerly part of the British Empirethe poppy is worn by some participants on Remembrance Sunday each year.[66][67] It is not generally worn by the public, although The Royal British Legion's Hong Kong and China Branch sells poppies to the public in a few places in Hong Kong only.[68]\\r\\nSince 2014, the Ukrainians have worn the poppy as a symbol of the Victory over Nazism and commemoration of the victims of World War II. It has largely replaced the Ribbon of Saint George, which became associated with pro-Russian separatists and Russian military aggression. A poppy logo was designed by Serhiy Mishakin and contains the text: \\"1939-1945 Never Again\\".[69]\\r\\nIn parts of Pakistan, the 'Great War Company' hold a private ceremony each 11 November where red poppies are worn, by descendants of World War I veterans from the old British Indian Army.[70]\\r\\nIn Albania, government representatives, including Prime Minister Edi Rama, wore the Remembrance Poppy during the commemoration ceremonies for the 70th Anniversary of the Liberation of Albania.[71]\\r\\nSome people choose to wear white poppies as a pacifist alternative to the red poppy. The white poppy and white poppy wreaths were introduced by Britain's Co-operative Women's Guild in 1933.[72] Today, white poppies are sold by Peace Pledge Union or may be home-made.[73] The white poppy may be worn alone or alongside the red poppy. According to the Peace Pledge Union, it symbolizes remembrance of all casualties of war including civilian casualties, and non-British casualties, to stand for peace, and not to glamorize war.[74]\\r\\nTo commemorate animal victims of war, Animal Aid in Britain has issued a purple poppy, which can be worn alongside the traditional red one, as a reminder that both humans and animals have been ÿ and continue to be ÿ victims of war.[75][76] Recently, the purple poppy was replaced by a purple paw symbol that can be worn all year round. This was because people saw the poppy as implying animals had given their lives as heroes in the service of human beings. Animal Aid regards animals of having their lives taken by the abuse of humans in war, not given by the animals as could be the case with people who have the capacity to decide for themselves.[77]\\r\\nOn the 11th April 2017 a UK based animal charity Sasha Animal Foundation announced that it was to introduce its own Purple Poppy with a different design, stating: \\"We will be adhering to the stance that animals are victims of war and not heroes.\\"[78]\\r\\nIn 1993, The Royal British Legion complained that Cannon Fodder, a video game with an anti-war message, had planned to use a poppy on its cover. The Legion, along with some politicians, called it \\"offensive to millions\\" and \\"monstrous\\". The publisher was forced to change the cover before the game was released.\\r\\nIn 2010 a group of British Army veterans issued an open letter complaining that the Poppy Appeal had become excessive and garish, that it was being used to marshal support behind British military campaigns, and that people were being pressured into wearing poppies.[28] In 2014, the group protested by holding an alternative remembrance service: they walked to The Cenotaph under the banner \\"Never Again\\" with a wreath of white poppies to acknowledge civilians killed in war. Their tops bore the message \\"War is Organised Murder\\", a quote from Harry Patch, the last survivor of World War I.[79][80]\\r\\nA 2010 Remembrance Day ceremony in London was disrupted by members of the radical Islamist Muslims Against Crusades group, who were protesting against British Army actions in Afghanistan and Iraq. They burnt large poppies and chanted \\"British soldiers burn in hell\\" during the two-minute silence. Two of the men were arrested and charged for threatening behaviour. One was convicted and fined S50.[81] The same group planned to hold another protest in 2011,[82][83] but was banned by the Home Secretary the day before the planned protest.[84] In 2014, a campaign was begun to encourage Muslim women to wear poppy hijabs. Some criticized it as a \\"shrouded loyalty test\\" which implied that Muslims needed to prove their loyalty to Britain.[85][86][87]\\r\\nIn recent years, other people have been arrested in the UK for burning remembrance poppies. In November 2011 a number of people were arrested in Northern Ireland after a picture of two youths burning a poppy was posted on Facebook. The picture was reported to police by a member of the RBL.[88] The following year, a young Canterbury man was arrested for allegedly posting a picture of a burning poppy on Facebook, on suspicion of an offence under the Malicious Communications Act.[89]\\r\\nBritish Prime Minister David Cameron rejected a request from Chinese officials to remove his poppy during his visit to Beijing on Remembrance Day 2010. The poppy was deemed offensive because it was mistakenly assumed to be connected with the Anglo-Chinese Opium Wars of the 19th century, after which the Qing Dynasty was forced to tolerate the British opium trade in China and to cede Hong Kong to the UK.[90] However, Cameron wore a poppy in 2015 when he met Chinese President Xi Jinping in London.\\r\\nIn 2011 it was revealed that Kleshna, one of two businesses selling its own poppies on the RBL website, gives only 10% of its sales to charity. Kleshna sells crystal-clad poppy jewellery which has been worn by celebrities on television.[26]\\r\\nIn 2012 there was controversy when The Northern Whig public house in Belfast refused entry to a man wearing a remembrance poppy.[91] Although the owners apologised, the customer took the matter to court, supported by the Equality Commission for Northern Ireland (ECNI).[92] The case was significant for the decision supporting the view of the ECNI that \\"The poppy, although not directly linked to a specific religious belief or political opinion, would historically have been associated to a greater extent with the Protestant or unionist community in Northern Ireland\\".[93]\\r\\nIn the British media, public figures have been attacked for not wearing poppies. British journalist and newsreader Charlene White has faced racist and sexist abuse for not wearing a poppy on-screen. She explained \\"I prefer to be neutral and impartial on screen so that one of those charities doesn't feel less favoured than another\\".[94] Newsreader Jon Snow does not wear a poppy on-screen for similar reasons. He too was criticized and he condemned what he saw as \\"poppy fascism\\".[95] Well-known war-time journalist Robert Fisk published in November 2011 a personal account about the shifting nature of wearing a poppy, titled \\"Do those who flaunt the poppy on their lapels know that they mock the war dead?\\".[96] While all newsreaders in the UK are expected to wear the remembrance poppy, those on the BBC's international news service are told not to. The BBC say this is because the symbol is not widely recognized overseas. The Royal British Legion condemned this, insisting that the poppy is the \\"international symbol of remembrance\\".[97]\\r\\nIn the run-up to Remembrance Day, it has become common for UK football teams to play with artificial poppies sewn to their shirts, at the request of the Royal British Legion. This has caused some controversy.\\r\\nAt a Celtic v Aberdeen match in November 2010, a group of Celtic supporters, called the Green Brigade, unfurled a large banner in protest at the team wearing poppies. In a statement, it said: \\"Our group and many within the Celtic support do not recognise the British Armed Forces as heroes, nor their role in many conflicts as one worthy of our remembrance\\". It gave Operation Banner (Northern Ireland), the Afghanistan War and the Iraq War as examples.[98]\\r\\nNorthern Irish-born footballer James McClean, who has played for a number of English teams, has received death threats and abuse since 2012 for refusing to wear a poppy on his shirt during matches.[99] McClean said he does not wear one because the Poppy Appeal supports British soldiers who served in Northern Ireland, and believes it would disrespect those killed in his hometown on Bloody Sunday.[100]\\r\\nIn November 2011, it was proposed that the England football team should wear poppies on their shirts in a match against Spain. However, FIFA turned down the proposal, saying it would \\"open the door to similar initiatives\\" across the world, \\"jeopardising the neutrality of football\\".[101] FIFA's decision was attacked by Prince William[102] and Prime Minister David Cameron, who said he would back any player who ignored the ban.[101] Members of the English Defence League (EDL) held a protest on the roof of FIFA's headquarters in Zrich.[103] Instead, The Football Association came up with other ways to mark Remembrance Day; for example, the England players would wear poppies before kickoff and black armbands during the match, there would be a minute's silence, a poppy wreath would be set on the pitch during the national anthems, poppies would be sold in the stadium and would be shown on the scoreboards and advertising boards.[101] FIFA subsequently allowed the English, Scottish and Welsh teams to wear poppies on black armbands.[104]\\r\\nDuring the 2018 FIFA World Cup Qualifiers, the England, Scotland, Wales and Northern Ireland football teams were fined for displaying the poppy during matches. FIFA rules forbid the display of \\"political or religious symbols\\".[105][106][107] The decision was strongly criticised by Prime Minister Theresa May, and the Welsh and English football associations appealed against the fine, with the English Football Association threatening to bring the matter to the Court of Arbitration for Sport.[107][108][109]","input":"What does the poppy symbolize in northern ireland?"},{"output":"South Carolina","context":"\\r\\n\\r\\n1776\\r\\n\\r\\n1777\\r\\n\\r\\n1778\\r\\n\\r\\n1779\\r\\n\\r\\nThe Battle of Sullivan's Island or the Battle of Fort Sullivan was fought on June 28, 1776, during the American Revolutionary War. It took place near Charleston, South Carolina, during the first British attempt to capture the city from American forces. It is also sometimes referred to as the First Siege of Charleston, owing to a more successful British siege in 1780.\\r\\n\\r\\nThe British organized an expedition in early 1776 for operations in the rebellious southern colonies of North America. Delayed by logistical concerns and bad weather, the expedition reached the coast of North Carolina in May 1776. Finding conditions unsuitable for their operations, General Henry Clinton and Admiral Sir Peter Parker decided instead to act against Charleston. Arriving there in early June, troops were landed on Long Island (now called Isle of Palms), near Sullivan's Island where Colonel William Moultrie commanded a partially constructed fort, in preparation for a naval bombardment and land assault. General Charles Lee, commanding the southern Continental theater of the war,\\r\\nwould provide supervision.\\r\\n\\r\\nThe land assault was frustrated when the channel between the two islands was found to be too deep to wade, and the American defenses prevented an amphibious landing.  The naval bombardment had little effect due to the sandy soil and the spongy nature of the fort's palmetto log construction. Careful fire by the defenders wrought significant damage on the British fleet, which withdrew after an entire day's bombardment. The British withdrew their expedition force to New York, and did not return to South Carolina until 1780.\\r\\n\\r\\nWhen the American Revolutionary War broke out in 1775, the city of Charleston in the Province of South Carolina was a center of commerce in southern North America. The city's citizens joined other colonists in opposing the British parliament's attempts to tax them, and militia recruitment increased when word arrived of the April 1775 Battles of Lexington and Concord.[3] Throughout 1775 and into 1776, militia recruits arrived in the city from the colony's backcountry, the city's manufacturers and tradesmen began producing war materiel, and defensive fortifications began to take shape around the city.[4]\\r\\n\\r\\nBritish army forces in North America were primarily tied up with the Siege of Boston in 1775.  Seeking bases of operations where they had more control, the British planned an expedition to the southern colonies.  Major General Henry Clinton, then in Boston, was to travel to Cape Fear, North Carolina, where he would join with largely Scottish Loyalists raised in the North Carolina backcountry, and a force of 2,000 men from Ireland under the command of Major General Charles Cornwallis.[5]\\r\\n\\r\\nThe plan was beset by difficulties from the start. The Irish expedition, originally supposed to depart at the beginning of December 1775, was delayed by logistical difficulties, and its 2,500 troops did not depart until February 13, 1776, escorted by 11 warships under the command of Admiral Sir Peter Parker.[6][7] Clinton left Boston on January 20 with two companies of light infantry, and first stopped at New York City to confer with William Tryon, New York's royal governor.[8] Major General Charles Lee, sent by Major General George Washington to see to the defense of New York, coincidentally arrived there the same day as Clinton.[9] New York was at that time extremely tense; Patriot forces were beginning to disarm and evict Loyalists, and the British fleet anchored there was having difficulty acquiring provisions.[10] Despite this, Clinton made no secret that his final target was in the south. Lee observed that this was \\"certainly a droll way of proceeding; to communicate his full plan to the enemy is too novel to be credited.\\"[11] This was not even the first notice of the expedition to the colonists; a letter intercepted in December had already provided intelligence that the British were planning to go to the South.[10]\\r\\n\\r\\nClinton arrived at Cape Fear on March 12, expecting to find the European convoy already there. He met with the royal governors of North and South Carolina, Josiah Martin and William Campbell, and learned that the recruited Scottish Loyalists had been defeated at Moore's Creek Bridge two weeks earlier.[12] Clinton also received pleas for assistance from the royal governor of Georgia, James Wright, who had been arrested, and then escaped to a navy ship.[13]\\r\\n\\r\\nParker's fleet had an extremely difficult crossing. Battered by storms and high seas, the first ships of the fleet did not arrive at Cape Fear until April 18, and Cornwallis did not arrive until May 3. After several weeks there, in which the British troops raided Patriot properties, Clinton, Cornwallis and Parker concluded that Cape Fear was not a suitable base for further operations.[14] Parker had sent out some ships on scouting expeditions up and down the coast, and reports on the partially finished condition of the Charleston defenses were sufficiently promising that the decision was made to go there.[15]\\r\\n\\r\\nJohn Rutledge, recently elected president of the General Assembly that remained as the backbone of South Carolina's revolutionary government, organized a defense force under the command of 46-year-old Colonel William Moultrie, a former militiaman and Indian fighter.[16][17] These forces comprised three infantry regiments, two rifle regiments, and a small artillery regiment; they were augmented by three independent artillery companies, and the total force numbered about 2,000.[18] These forces were further augmented by the arrival of Continental regiments from North Carolina and Virginia (1,900 troops), as well as militia numbering 2,700 from Charleston and the surrounding backcountry.[18]\\r\\n\\r\\nMoultrie saw Sullivan's Island, a sandy spit of land at the entrance to Charleston Harbor extending north about 4 miles (6.4?km) long and a few hundred yards wide,[19] as a place well suited to build a fort that could protect the entrance from intruding enemy warships. A large vessel sailing into Charleston first had to cross Charleston Bar, a series of submerged shoals lying about 8 miles (13?km) southeast of the city, and then pass by the southern end of Sullivan's Island as it entered the channel to the inner harbor. Later it would also have to pass the northern end of James Island, where Fort Johnson commanded the southeastern approach to the city.[20] Moultrie and his 2nd South Carolina Regiment arrived on Sullivan's Island in March 1776, and began construction of a fortress built out of palmetto logs to defend the island and the channel into Charleston Harbor.[21] The construction moved slowly; Captain Peter Horry of the Patriot naval detachment described the site as \\"an immense pen 500 feet long, and 16 feet wide, filled with sand to stop the shot\\".[22]  The gun platforms were made of planks two inches thick and fastened with wooden spikes.[22]\\r\\n\\r\\nCongress had appointed General Lee to command the Continental Army troops in the southern colonies, and his movements by land shadowed those of Clinton's fleet as it sailed south. Lee wrote from Wilmington on June 1 that the fleet had sailed, but that he did not know whether it was sailing for Virginia or South Carolina. He headed for Charleston, saying \\"[I] confess I know not whether I shall go to or from the enemy.\\"[14] He arrived in Charleston shortly after the fleet anchored outside the harbor, and took command of the city's defenses.[14] He immediately ran into a problem: the South Carolina troops (militia or the colonial regiments) were not on the Continental line, and thus not formally under his authority. Some South Carolina troops resisted his instructions, and Rutledge had to intervene by proclaiming Lee in command of all South Carolina forces.[23]\\r\\n\\r\\nSquare-shaped Fort Sullivan consisted only of the completed seaward wall, with walls made from palmetto logs 20 feet (6.1?m) high and 16 feet (4.9?m) wide. The walls were filled with sand, and rose 10 feet (3.0?m) above the wooden platforms on which the artillery were mounted. A hastily erected palisade of thick planks helped guard the powder magazine and unfinished northern walls. An assortment of 31 cannon, ranging from 9- and 12-pounders to a few British 18-pounders and French 26-pounders, dotted the front and rear walls.[24] General Lee, when he had seen its unfinished state, had recommended abandoning the fort, calling it a \\"slaughter pen\\".[16] President Rutledge refused, and specifically ordered Colonel Moultrie to \\"obey [Lee] in everything, except in leaving Fort Sullivan\\".[25]  Moultrie's delaying tactics so angered Lee that he decided on June 27 that he would replace Moultrie; the battle began the next day before he could do so.[26] Lee did make plans for an orderly retreat to Haddrell's Point.[27]\\r\\n\\r\\nThe British fleet weighed anchor at Cape Fear on May 31, and arrived outside Charleston Harbor the next day.[28] Moultrie noticed a British scout boat apparently looking for possible landing points on nearby Long Island (now known as the Isle of Palms), just a few hundred yards from Sullivan's Island; troops were consequently sent to occupy the northern end of Sullivan's.[29] By June 8, most of the British fleet had crossed the bar and anchored in Five Fathom Hole, an anchorage between the bar and the harbor entrance.[30] With the fort on Sullivan's Island only half complete, Admiral Parker expressed confidence that his warships would easily breach its walls. Optimistically believing he would not even need Clinton's land forces, he wrote to Clinton that after the fort's guns were knocked out, he would \\"land seamen and marines (which I have practiced for the purpose) under the guns\\" and that they could \\"keep possession till you send as many troops as you think proper\\".[31]\\r\\n\\r\\nThe British fleet was composed of nine man-of-war ships: the flagship 50-gun Bristol, as well as the 50-gun Experiment and frigates Actaeon, Active, Solebay, Siren, Sphinx, Friendship and the bomb vessel Thunder, in total mounting nearly 300 cannon.  The army forces in the expedition consisted of the 15th, 28th, 33rd, 37th, 54th, and 57th Regiments of Foot, and part of the 46th.[32][33] On June 7, Clinton issued a proclamation calling on the rebel colonists to lay down their arms. However, the inexperienced defenders fired on the boat sent to deliver it (which was flying a truce flag), and it was not delivered until the next day.[16] That same day, Clinton began landing 2,200 troops on Long Island. The intent was that these troops would wade across the channel (now known as Breach Inlet) between Long and Sullivan's, which the British believed to be sufficiently shallow to do so, while the fleet bombarded Fort Sullivan.[34]\\r\\n\\r\\nGeneral Lee responded to the British landing with several actions. He began reinforcing positions on the mainland in case the British were intending to launch an attack directly on Charleston.[35] He also attempted to build a bridge of boats to provide an avenue of retreat for the fort's garrison, but this failed because there were not enough boats to bridge the roughly one mile (1.6?km) channel separating the island from Charleston; the unwillingness of Moultrie and Rutledge to support the effort may also have played a role.[36] The Americans also constructed an entrenchment at the northern end of Sullivan's Island, which was manned by more than 750 men and three small cannons,[37][38] and began to fortify a guard post at Haddrell's Point on the mainland opposite Fort Sullivan.[39]\\r\\n\\r\\nGeneral Clinton encountered the first major problem of the attack plan on June 17. An attempt to wade the channel between the two islands established that part of the channel was at least shoulder-deep, too deep for troops to cross even without the prospect of enemy opposition.[40] He considered using boats to ferry the troops across, but the Americans, with timely advice from General Lee, adopted a strong defensive position that was virtually impossible to bombard from ships or the Long Island position.[41] As a result, the British and American forces faced each other across the channel, engaging in occasional and largely inconsequential cannon fire at long range. Clinton reported that this meant that Admiral Parker would have \\"the glory of being defeated alone.\\"[23] The attack was originally planned for June 24, but bad weather and contrary wind conditions prompted Parker to call it off for several days.[31]\\r\\n\\r\\nOn the morning of June 28, Fort Sullivan was defended by Colonel Moultrie, commanding the 2nd South Carolina Regiment and a company of the 4th South Carolina Artillery, numbering 435 men.[18] At around 9:00 am that morning, a British ship fired a signal gun indicating all was ready for the attack.[42] Less than an hour later, nine warships had sailed into positions facing the fort. Thunder and Friendship anchored about 1.5 miles (2.4?km) from the fort while Parker took Active, Bristol, Experiment and Solebay to a closer position about 400 yards (370?m) from Sullivan's Island, where they anchored facing broadside to the fort. Each of these ships began to fire upon the fort when it reached its position, and the defenders returned the fire.[43] Although many of Thunder's shots landed in or near the fort, they had little effect; according to Moultrie, \\"We had a morass in the middle, that swallowed them up instantly, and those that fell in the sand in and about the fort, were immediately buried\\".[44] Thunder's role in the action was also relatively short-lived; she had anchored too far away from the fort, and the overloading of her mortars with extra powder to increase their range eventually led to them breaking out of their mounts.[45] Owing to shortage of gunpowder, Moultrie's men were deliberate in the pace of their gunfire, and only a few officers actually aimed the cannons. They also fired in small volleys, four cannon at a time. One British observer wrote, \\"Their fire was surprisingly well served\\" and it was \\"slow, but decisive indeed; they were very cool and took care not to fire except their guns were exceedingly well directed.\\"[43]\\r\\n\\r\\nGeneral Clinton began movements to cross over to the northern end of Sullivan's Island. Assisted by two sloops of war, the flotilla of longboats carrying his troops came under fire from Colonel William Thomson's defenses. Facing a withering barrage of grape shot and rifle fire, Clinton abandoned the attempt.[46]\\r\\n\\r\\nAround noon the frigates Sphinx, Syren, and Actaeon were sent on a roundabout route, avoiding some shoals, to take a position from which they could enfilade the fort's main firing platform and also cover one of the main escape routes from the fort.[43] However, all three ships grounded on an uncharted sandbar, and the riggings of Actaeon and Sphinx became entangled in the process.[45] The British managed to refloat Sphinx and Syren, but Acteon remained grounded, having moved too far onto the submerged sandbar. Consequently, none of these ships reached its intended position, a piece of good fortune not lost on Colonel Moultrie: \\"Had these three ships effected their purpose, they would have enfiladed us in such a manner, as to have driven us from our guns.\\"[44]\\r\\n\\r\\nAt the fort, Moultrie ordered his men to concentrate their fire on the two large man-of-war ships, Bristol and Experiment, which took hit after hit from the fort's guns. Chain shot fired at Bristol eventually destroyed much of her rigging and severely damaged both the main- and mizzenmasts.[47] One round hit her quarterdeck, slightly wounding Parker in the knee and thigh. The shot also tore off part of his britches, leaving his backside exposed.[48] By mid-afternoon, the defenders were running out of gunpowder, and their fire was briefly suspended. However, Lee sent more ammunition and gunpowder over from the mainland, and the defenders resumed firing at the British ships;[49] Lee even briefly visited the fort late in the day, telling Colonel Moultrie, \\"I see you are doing very well here, you have no occasion for me, I will go up to the town again.\\"[50] Admiral Parker eventually sought to destroy the fort's walls with persistent broadside cannonades. This strategy failed due to the spongy nature of the palmetto wood used in its constructions; the structure would quiver, and it absorbed the cannonballs rather than splintering.[51]  The exchange continued until around 9:00 pm, when darkness forced a cessation of hostilities, and the fleet finally withdrew out of range.[52]\\r\\n\\r\\nAt one point during the battle, the flag Moultrie had designed and raised over the fort was shot down. Sergeant William Jasper reportedly ran to the battlement and raised the flag again, holding it up and rallying the troops until a flag stand could be provided. He was credited by Moultrie with reviving the troops' spirits,[52] and later given commendations for bravery.[53] A painting of this event (pictured above) depicts Jasper's actions.\\r\\n\\r\\nCounting casualties, Parker reported 40 sailors killed and 71 wounded aboard Bristol, which was hit more than 70 times with much damage to the hull, yards, and rigging. Experiment was also badly damaged with 23 sailors killed and 56 wounded. Active and Solebay reported 15 casualties each.[2] The Americans reported their casualties at only 12 killed and 25 wounded.[1] The following morning, the British, unable to drag the grounded Acteon off the sandbar, set fire to the ship to prevent her from falling into enemy hands.[54] Patriots in small boats sailed out to the burning ship, fired some of its cannons at the British ships, took what stores and loot they could, and retreated shortly before the ship's powder magazine exploded.[52]\\r\\n\\r\\nThe British did not attempt to take the fort again. Within days of the battle, Charlestonians learned of the signing of the Declaration of Independence in Philadelphia.[53] The British troops were reembarked on their transports, and on July 21 the British fleet withdrew northward to help the main British army in its campaign against New York City. To add insult to injury, one of the British transports grounded off Long Island and was captured by Patriot forces.[55]\\r\\n\\r\\nThe British did not return to Charleston until 1780, when General Clinton successfully besieged the city and captured an entire army.[2] Until the South again became a focus of the war in late 1778, its states provided military supplies to the northern war effort and produced trade goods that brought in valuable hard currency to fund the war effort.[56]\\r\\n\\r\\nAdmiral Parker and General Clinton engaged in a war of words after the battle, each seeking to cast the blame on the other for the expedition's failures. Although Clinton was not blamed by the government, popular opinion held him responsible, and Parker was lauded for his personal bravery.[55]\\r\\n\\r\\nFort Sullivan was renamed Fort Moultrie shortly after the battle to honor Colonel William Moultrie for his successful defense of the fort and the city of Charleston.[57] Extensively modified in the years after the battle, it was supplanted by Fort Sumter as the principal defense of Charleston prior to the outbreak of the American Civil War.[58] In 1876, to celebrate the centennial, companies from Savannah, Augusta, Macon, Columbia, New York and Boston were invited to Charleston.[59] The site was turned over to the National Park Service in 1960, and is now part of Fort Sumter National Monument.[60][61]\\r\\n\\r\\nA small monument to the Battle of Sullivan's Island has been placed at the northeastern tip of the island, overlooking the inlet where General Clinton's soldiers had hoped to cross. The monument includes historical markers describing the events surrounding the engagement.\\r\\n\\r\\nOne iconic emblem of the battle was the flag designed by Colonel Moultrie. Commissioned by the colonial government, he designed a blue flag with a white crescent in the top left corner, which was flown at the fort during the battle.[26] Despite being shot down during the siege, it was seen as a symbol of this successful defense (and famously raised during victory). It came to be known as the Moultrie flag or Liberty Flag.  When Charleston (lost to the British in the 1780 siege) was reclaimed by American forces at the end of the war, the flag was returned to the city by General Nathanael Greene.[citation needed]\\r\\n\\r\\nBeginning on the first anniversary of this victory in 1777 Charlestonians and South Carolinians celebrate \\"Carolina Day\\" annually to commemorate this first major victory of American Forces over the British.  Each year local events include a parade in downtown Charleston and reenactments at Fort Moultrie on Sullivan's Island.[citation needed]","input":"Who won the battle of sullivan's island?"},{"output":"approximately 70,000 students","context":"Virginia Beach City Public Schools is the branch of the government of the city of Virginia Beach, Virginia responsible for public K-12 education. Like all public school systems in the state, it is legally classified as a school division instead of a school district. Although Virginia school divisions perform the functions of school districts in other U.S. states, they have no taxing authority, instead relying on appropriations from their local governments,\\r\\nThe school system is the second largest in Virginia, and among the 50 largest school systems in the United States (based on student enrollment). All of the division's 80+ schools are fully accredited in the Virginia Standards of Learning (SOL).[1]\\r\\nVirginia Beach City Public Schools currently serves approximately 70,000 students, and includes nearly 90 schools.[2]\\r\\nThe division has a fleet of nearly 800 school buses, which is serviced by two bus garages and is the second largest employer in the city, following Naval Air Station Oceana.","input":"How many students in virginia beach public schools?"},{"output":"nuclear membrane","context":"In cell biology, the nucleus (pl. nuclei; from Latin nucleus or nuculeus, meaning kernel or seed) is a membrane-enclosed organelle found in eukaryotic cells. Eukaryotes usually have a single nucleus, but a few cell types, such as mammalian red blood cells, have no nuclei, and a few others have many.\\r\\nCell nuclei contain most of the cell's genetic material, organized as multiple long linear DNA molecules in complex with a large variety of proteins, such as histones, to form chromosomes. The genes within these chromosomes are the cell's nuclear genome and are structured in such a way to promote cell function. The nucleus maintains the integrity of genes and controls the activities of the cell by regulating gene expressionthe nucleus is, therefore, the control center of the cell. The main structures making up the nucleus are the nuclear envelope, a double membrane that encloses the entire organelle and isolates its contents from the cellular cytoplasm, and the nuclear matrix (which includes the nuclear lamina), a network within the nucleus that adds mechanical support, much like the cytoskeleton, which supports the cell as a whole.\\r\\nBecause the nuclear membrane is impermeable to large molecules, nuclear pores are required to regulate nuclear transport of molecules across the envelope. The pores cross both nuclear membranes, providing a channel through which larger molecules must be actively transported by carrier proteins while allowing free movement of small molecules and ions. Movement of large molecules such as proteins and RNA through the pores is required for both gene expression and the maintenance of chromosomes. Although the interior of the nucleus does not contain any membrane-bound sub compartments, its contents are not uniform, and a number of sub-nuclear bodies exist, made up of unique proteins, RNA molecules, and particular parts of the chromosomes. The best-known of these is the nucleolus, which is mainly involved in the assembly of ribosomes. After being produced in the nucleolus, ribosomes are exported to the cytoplasm where they translate mRNA.\\r\\n\\r\\n\\r\\nThe nucleus was the first organelle to be discovered. What is most likely the oldest preserved drawing dates back to the early microscopist Antonie van Leeuwenhoek (1632ÿ1723). He observed a \\"lumen\\", the nucleus, in the red blood cells of salmon.[1] Unlike mammalian red blood cells, those of other vertebrates still contain nuclei.\\r\\nThe nucleus was also described by Franz Bauer in 1804[2] and in more detail in 1831 by Scottish botanist Robert Brown in a talk at the Linnean Society of London. Brown was studying orchids under microscope when he observed an opaque area, which he called the \\"areola\\" or \\"nucleus\\", in the cells of the flower's outer layer.[3]\\r\\nHe did not suggest a potential function. In 1838, Matthias Schleiden proposed that the nucleus plays a role in generating cells, thus he introduced the name \\"cytoblast\\" (cell builder). He believed that he had observed new cells assembling around \\"cytoblasts\\". Franz Meyen was a strong opponent of this view, having already described cells multiplying by division and believing that many cells would have no nuclei. The idea that cells can be generated de novo, by the \\"cytoblast\\" or otherwise, contradicted work by Robert Remak (1852) and Rudolf Virchow (1855) who decisively propagated the new paradigm that cells are generated solely by cells (\\"Omnis cellula e cellula\\"). The function of the nucleus remained unclear.[4]\\r\\nBetween 1877 and 1878, Oscar Hertwig published several studies on the fertilization of sea urchin eggs, showing that the nucleus of the sperm enters the oocyte and fuses with its nucleus. This was the first time it was suggested that an individual develops from a (single) nucleated cell. This was in contradiction to Ernst Haeckel's theory that the complete phylogeny of a species would be repeated during embryonic development, including generation of the first nucleated cell from a \\"monerula\\", a structureless mass of primordial mucus (\\"Urschleim\\"). Therefore, the necessity of the sperm nucleus for fertilization was discussed for quite some time. However, Hertwig confirmed his observation in other animal groups, including amphibians and molluscs. Eduard Strasburger produced the same results for plants in 1884. This paved the way to assign the nucleus an important role in heredity. In 1873, August Weismann postulated the equivalence of the maternal and paternal germ cells for heredity. The function of the nucleus as carrier of genetic information became clear only later, after mitosis was discovered and the Mendelian rules were rediscovered at the beginning of the 20th century; the chromosome theory of heredity was therefore developed.[4]\\r\\nThe nucleus is the largest cellular organelle in animal cells.[5] In mammalian cells, the average diameter of the nucleus is approximately 6 micrometres (m), which occupies about 10% of the total cell volume.[6] The viscous liquid within it is called nucleoplasm (or karyolymph), and is similar in composition to the cytosol found outside the nucleus.[7] It appears as a dense, roughly spherical or irregular organelle. The composition by dry weight of the nucleus is approximately: DNA 9%, RNA 1%, Histone Protein 11%, Residual Protein 14%, Acidic Proteins 65%.\\r\\nThe nuclear envelope, otherwise known as nuclear membrane, consists of two cellular membranes, an inner and an outer membrane, arranged parallel to one another and separated by 10 to 50 nanometres (nm). The nuclear envelope completely encloses the nucleus and separates the cell's genetic material from the surrounding cytoplasm, serving as a barrier to prevent macromolecules from diffusing freely between the nucleoplasm and the cytoplasm.[8] The outer nuclear membrane is continuous with the membrane of the rough endoplasmic reticulum (RER), and is similarly studded with ribosomes.[8] The space between the membranes is called the perinuclear space and is continuous with the RER lumen.\\r\\nNuclear pores, which provide aqueous channels through the envelope, are composed of multiple proteins, collectively referred to as nucleoporins. The pores are about 125 million daltons in molecular weight and consist of around 50 (in yeast) to several hundred proteins (in vertebrates).[5] The pores are 100?nm in total diameter; however, the gap through which molecules freely diffuse is only about 9?nm wide, due to the presence of regulatory systems within the center of the pore. This size selectively allows the passage of small water-soluble molecules while preventing larger molecules, such as nucleic acids and larger proteins, from inappropriately entering or exiting the nucleus. These large molecules must be actively transported into the nucleus instead. The nucleus of a typical mammalian cell will have about 3000 to 4000 pores throughout its envelope,[9] each of which contains an eightfold-symmetric ring-shaped structure at a position where the inner and outer membranes fuse.[10] Attached to the ring is a structure called the nuclear basket that extends into the nucleoplasm, and a series of filamentous extensions that reach into the cytoplasm. Both structures serve to mediate binding to nuclear transport proteins.[5]\\r\\nMost proteins, ribosomal subunits, and some DNAs are transported through the pore complexes in a process mediated by a family of transport factors known as karyopherins. Those karyopherins that mediate movement into the nucleus are also called importins, whereas those that mediate movement out of the nucleus are called exportins. Most karyopherins interact directly with their cargo, although some use adaptor proteins.[11] Steroid hormones such as cortisol and aldosterone, as well as other small lipid-soluble molecules involved in intercellular signaling, can diffuse through the cell membrane and into the cytoplasm, where they bind nuclear receptor proteins that are trafficked into the nucleus. There they serve as transcription factors when bound to their ligand; in the absence of a ligand, many such receptors function as histone deacetylases that repress gene expression.[5]\\r\\nIn animal cells, two networks of intermediate filaments provide the nucleus with mechanical support: The nuclear lamina forms an organized meshwork on the internal face of the envelope, while less organized support is provided on the cytosolic face of the envelope. Both systems provide structural support for the nuclear envelope and anchoring sites for chromosomes and nuclear pores.[6]\\r\\nThe nuclear lamina is composed mostly of lamin proteins. Like all proteins, lamins are synthesized in the cytoplasm and later transported to the nucleus interior, where they are assembled before being incorporated into the existing network of nuclear lamina.[12][13] Lamins found on the cytosolic face of the membrane, such as emerin and nesprin, bind to the cytoskeleton to provide structural support. Lamins are also found inside the nucleoplasm where they form another regular structure, known as the nucleoplasmic veil,[14] that is visible using fluorescence microscopy. The actual function of the veil is not clear, although it is excluded from the nucleolus and is present during interphase.[15] Lamin structures that make up the veil, such as LEM3, bind chromatin and disrupting their structure inhibits transcription of protein-coding genes.[16]\\r\\nLike the components of other intermediate filaments, the lamin monomer contains an alpha-helical domain used by two monomers to coil around each other, forming a dimer structure called a coiled coil. Two of these dimer structures then join side by side, in an antiparallel arrangement, to form a tetramer called a protofilament. Eight of these protofilaments form a lateral arrangement that is twisted to form a ropelike filament. These filaments can be assembled or disassembled in a dynamic manner, meaning that changes in the length of the filament depend on the competing rates of filament addition and removal.[6]\\r\\nMutations in lamin genes leading to defects in filament assembly cause a group of rare genetic disorders known as laminopathies. The most notable laminopathy is the family of diseases known as progeria, which causes the appearance of premature aging in its sufferers. The exact mechanism by which the associated biochemical changes give rise to the aged phenotype is not well understood.[17]\\r\\nThe cell nucleus contains the majority of the cell's genetic material in the form of multiple linear DNA molecules organized into structures called chromosomes. Each human cell contains roughly two meters of DNA. During most of the cell cycle these are organized in a DNA-protein complex known as chromatin, and during cell division the chromatin can be seen to form the well-defined chromosomes familiar from a karyotype. A small fraction of the cell's genes are located instead in the mitochondria.\\r\\nThere are two types of chromatin. Euchromatin is the less compact DNA form, and contains genes that are frequently expressed by the cell.[18] The other type, heterochromatin, is the more compact form, and contains DNA that is infrequently transcribed. This structure is further categorized into facultative heterochromatin, consisting of genes that are organized as heterochromatin only in certain cell types or at certain stages of development, and constitutive heterochromatin that consists of chromosome structural components such as telomeres and centromeres.[19] During interphase the chromatin organizes itself into discrete individual patches,[20] called chromosome territories.[21] Active genes, which are generally found in the euchromatic region of the chromosome, tend to be located towards the chromosome's territory boundary.[22]\\r\\nAntibodies to certain types of chromatin organization, in particular, nucleosomes, have been associated with a number of autoimmune diseases, such as systemic lupus erythematosus.[23] These are known as anti-nuclear antibodies (ANA) and have also been observed in concert with multiple sclerosis as part of general immune system dysfunction.[24] As in the case of progeria, the role played by the antibodies in inducing the symptoms of autoimmune diseases is not obvious.\\r\\nThe nucleolus is a discrete densely stained structure found in the nucleus. It is not surrounded by a membrane, and is sometimes called a suborganelle. It forms around tandem repeats of rDNA, DNA coding for ribosomal RNA (rRNA). These regions are called nucleolar organizer regions (NOR). The main roles of the nucleolus are to synthesize rRNA and assemble ribosomes. The structural cohesion of the nucleolus depends on its activity, as ribosomal assembly in the nucleolus results in the transient association of nucleolar components, facilitating further ribosomal assembly, and hence further association. This model is supported by observations that inactivation of rDNA results in intermingling of nucleolar structures.[25]\\r\\nIn the first step of ribosome assembly, a protein called RNA polymerase I transcribes rDNA, which forms a large pre-rRNA precursor. This is cleaved into the subunits 5.8S, 18S, and 28S rRNA.[26] The transcription, post-transcriptional processing, and assembly of rRNA occurs in the nucleolus, aided by small nucleolar RNA (snoRNA) molecules, some of which are derived from spliced introns from messenger RNAs encoding genes related to ribosomal function. The assembled ribosomal subunits are the largest structures passed through the nuclear pores.[5]\\r\\nWhen observed under the electron microscope, the nucleolus can be seen to consist of three distinguishable regions: the innermost fibrillar centers (FCs), surrounded by the dense fibrillar component (DFC), which in turn is bordered by the granular component (GC). Transcription of the rDNA occurs either in the FC or at the FC-DFC boundary, and, therefore, when rDNA transcription in the cell is increased, more FCs are detected. Most of the cleavage and modification of rRNAs occurs in the DFC, while the latter steps involving protein assembly onto the ribosomal subunits occur in the GC.[26]\\r\\nBesides the nucleolus, the nucleus contains a number of other non-membrane-delineated bodies. These include Cajal bodies, Gemini of coiled bodies, polymorphic interphase karyosomal association (PIKA), promyelocytic leukaemia (PML) bodies, paraspeckles, and splicing speckles. Although little is known about a number of these domains, they are significant in that they show that the nucleoplasm is not a uniform mixture, but rather contains organized functional subdomains.[30]\\r\\nOther subnuclear structures appear as part of abnormal disease processes. For example, the presence of small intranuclear rods has been reported in some cases of nemaline myopathy. This condition typically results from mutations in actin, and the rods themselves consist of mutant actin as well as other cytoskeletal proteins.[32]\\r\\nA nucleus typically contains between 1 and 10 compact structures called Cajal bodies or coiled bodies (CB), whose diameter measures between 0.2?m and 2.0?m depending on the cell type and species.[27] When seen under an electron microscope, they resemble balls of tangled thread[29] and are dense foci of distribution for the protein coilin.[33] CBs are involved in a number of different roles relating to RNA processing, specifically small nucleolar RNA (snoRNA) and small nuclear RNA (snRNA) maturation, and histone mRNA modification.[27]\\r\\nSimilar to Cajal bodies are Gemini of Cajal bodies, or gems, whose name is derived from the Gemini constellation in reference to their close \\"twin\\" relationship with CBs. Gems are similar in size and shape to CBs, and in fact are virtually indistinguishable under the microscope.[33] Unlike CBs, gems do not contain small nuclear ribonucleoproteins (snRNPs), but do contain a protein called survival of motor neuron (SMN) whose function relates to snRNP biogenesis. Gems are believed to assist CBs in snRNP biogenesis,[34] though it has also been suggested from microscopy evidence that CBs and gems are different manifestations of the same structure.[33] Later ultrastructural studies have shown gems to be twins of Cajal bodies with the difference being in the coilin component; Cajal bodies are SMN positive and coilin positive, and gems are SMN positive and coilin negative.[35]\\r\\nRAFA domains, or polymorphic interphase karyosomal associations, were first described in microscopy studies in 1991. Their function remains unclear, though they were not thought to be associated with active DNA replication, transcription, or RNA processing.[36] They have been found to often associate with discrete domains defined by dense localization of the transcription factor PTF, which promotes transcription of small nuclear RNA (snRNA).[37]\\r\\nPromyelocytic leukaemia bodies (PML bodies) are spherical bodies found scattered throughout the nucleoplasm, measuring around 0.1ÿ1.0?m. They are known by a number of other names, including nuclear domain 10 (ND10), Kremer bodies, and PML oncogenic domains. PML bodies are named after one of their major components, the promyelocytic leukemia protein (PML). They are often seen in the nucleus in association with Cajal bodies and cleavage bodies.[30] PML bodies belong to the nuclear matrix, an ill-defined super-structure of the nucleus proposed to anchor and regulate many nuclear functions, including DNA replication, transcription, or epigenetic silencing.[38] The PML protein is the key organizer of these domains that recruits an ever-growing number of proteins, whose only common known feature to date is their ability to be SUMOylated. Yet, pml-/- mice (which have their PML gene deleted) cannot assemble nuclear bodies, develop normally and live well, demonstrating that PML bodies are dispensable for most basic biological functions.[38]\\r\\nSpeckles are subnuclear structures that are enriched in pre-messenger RNA splicing factors and are located in the interchromatin regions of the nucleoplasm of mammalian cells. At the fluorescence-microscope level they appear as irregular, punctate structures, which vary in size and shape, and when examined by electron microscopy they are seen as clusters of interchromatin granules. Speckles are dynamic structures, and both their protein and RNA-protein components can cycle continuously between speckles and other nuclear locations, including active transcription sites. Studies on the composition, structure and behaviour of speckles have provided a model for understanding the functional compartmentalization of the nucleus and the organization of the gene-expression machinery[39] splicing snRNPs[40][41] and other splicing proteins necessary for pre-mRNA processing.[42] Because of a cell's changing requirements, the composition and location of these bodies changes according to mRNA transcription and regulation via phosphorylation of specific proteins.[43] The splicing speckles are also known as nuclear speckles (nuclear specks), splicing factor compartments (SF compartments), interchromatin granule clusters (IGCs), B snurposomes.[44] B snurposomes are found in the amphibian oocyte nuclei and in Drosophila melanogaster embryos. B snurposomes appear alone or attached to the Cajal bodies in the electron micrographs of the amphibian nuclei.[45] IGCs function as storage sites for the splicing factors.[46]\\r\\nDiscovered by Fox et al. in 2002, paraspeckles are irregularly shaped compartments in the nucleus' interchromatin space.[47] First documented in HeLa cells, where there are generally 10ÿ30 per nucleus,[48] paraspeckles are now known to also exist in all human primary cells, transformed cell lines, and tissue sections.[49] Their name is derived from their distribution in the nucleus; the \\"para\\" is short for parallel and the \\"speckles\\" refers to the splicing speckles to which they are always in close proximity.[48]\\r\\nParaspeckles are dynamic structures that are altered in response to changes in cellular metabolic activity. They are transcription dependent[47] and in the absence of RNA Pol II transcription, the paraspeckle disappears and all of its associated protein components (PSP1, p54nrb, PSP2, CFI(m)68, and PSF) form a crescent shaped perinucleolar cap in the nucleolus. This phenomenon is demonstrated during the cell cycle. In the cell cycle, paraspeckles are present during interphase and during all of mitosis except for telophase. During telophase, when the two daughter nuclei are formed, there is no RNA Pol II transcription so the protein components instead form a perinucleolar cap.[49]\\r\\nPerichromatin fibrils are visible only under electron microscope. They are located next to the transcriptionally active chromatin and are hypothesized to be the sites of active pre-mRNA processing.[46]\\r\\nClastosome\\r\\nClastosomes are small nuclear bodies (0.2-0.5?m) described as donut-shaped due to the peripheral capsule around these bodies.[28] This name is derived from the Greek klastos, broken and soma, body.[28] Clastosomes are not typically present in normal cells, making them hard to detect. They form under high proteolysis conditions within the nucleus and degrade once there is a decrease in activity or if cells are treated with proteasome inhibitors.[28][50] The scarcity of clastosomes in cells indicates that they are not required for proteasome function.[51] Osmotic stress has also been shown to cause the formation of clastosomes.[52] These nuclear bodies contain catalytic and regulatory sub-units of the proteasome and its substrates, indicating that clastosomes are sites for degrading proteins.[51]\\r\\nThe Clastosome would be an important addition to the Cell Nucleus Wiki page because it plays a role in cell function. With further research, we may discover that this nuclear body has a more influential job in cell function than what is already known.[28]\\r\\nThe nucleus provides a site for genetic transcription that is segregated from the location of translation in the cytoplasm, allowing levels of gene regulation that are not available to prokaryotes. The main function of the cell nucleus is to control gene expression and mediate the replication of DNA during the cell cycle.\\r\\nThe nucleus is an organelle found in eukaryotic cells. Inside its fully enclosed nuclear membrane, it contains the majority of the cell's genetic material. This material is organized as DNA molecules, along with a variety of proteins, to form chromosomes.\\r\\nThe nuclear envelope allows the nucleus to control its contents, and separate them from the rest of the cytoplasm where necessary. This is important for controlling processes on either side of the nuclear membrane. In most cases where a cytoplasmic process needs to be restricted, a key participant is removed to the nucleus, where it interacts with transcription factors to downregulate the production of certain enzymes in the pathway. This regulatory mechanism occurs in the case of glycolysis, a cellular pathway for breaking down glucose to produce energy. Hexokinase is an enzyme responsible for the first the step of glycolysis, forming glucose-6-phosphate from glucose. At high concentrations of fructose-6-phosphate, a molecule made later from glucose-6-phosphate, a regulator protein removes hexokinase to the nucleus,[53] where it forms a transcriptional repressor complex with nuclear proteins to reduce the expression of genes involved in glycolysis.[54]\\r\\nIn order to control which genes are being transcribed, the cell separates some transcription factor proteins responsible for regulating gene expression from physical access to the DNA until they are activated by other signaling pathways. This prevents even low levels of inappropriate gene expression. For example, in the case of NF-B-controlled genes, which are involved in most inflammatory responses, transcription is induced in response to a signal pathway such as that initiated by the signaling molecule TNF-ϫ, binds to a cell membrane receptor, resulting in the recruitment of signalling proteins, and eventually activating the transcription factor NF-B. A nuclear localisation signal on the NF-B protein allows it to be transported through the nuclear pore and into the nucleus, where it stimulates the transcription of the target genes.[6]\\r\\nThe compartmentalization allows the cell to prevent translation of unspliced mRNA.[55] Eukaryotic mRNA contains introns that must be removed before being translated to produce functional proteins. The splicing is done inside the nucleus before the mRNA can be accessed by ribosomes for translation. Without the nucleus, ribosomes would translate newly transcribed (unprocessed) mRNA, resulting in malformed and nonfunctional proteins.\\r\\nGene expression first involves transcription, in which DNA is used as a template to produce RNA. In the case of genes encoding proteins, that RNA produced from this process is messenger RNA (mRNA), which then needs to be translated by ribosomes to form a protein. As ribosomes are located outside the nucleus, mRNA produced needs to be exported.[56]\\r\\nSince the nucleus is the site of transcription, it also contains a variety of proteins that either directly mediate transcription or are involved in regulating the process. These proteins include helicases, which unwind the double-stranded DNA molecule to facilitate access to it, RNA polymerases, which bind to the DNA promoter to synthesize the growing RNA molecule, topoisomerases, which change the amount of supercoiling in DNA, helping it wind and unwind, as well as a large variety of transcription factors that regulate expression.[57]\\r\\nNewly synthesized mRNA molecules are known as primary transcripts or pre-mRNA. They must undergo post-transcriptional modification in the nucleus before being exported to the cytoplasm; mRNA that appears in the cytoplasm without these modifications is degraded rather than used for protein translation. The three main modifications are 5' capping, 3' polyadenylation, and RNA splicing. While in the nucleus, pre-mRNA is associated with a variety of proteins in complexes known as heterogeneous ribonucleoprotein particles (hnRNPs). Addition of the 5' cap occurs co-transcriptionally and is the first step in post-transcriptional modification. The 3' poly-adenine tail is only added after transcription is complete.\\r\\nRNA splicing, carried out by a complex called the spliceosome, is the process by which introns, or regions of DNA that do not code for protein, are removed from the pre-mRNA and the remaining exons connected to re-form a single continuous molecule. This process normally occurs after 5' capping and 3' polyadenylation but can begin before synthesis is complete in transcripts with many exons.[5] Many pre-mRNAs, including those encoding antibodies, can be spliced in multiple ways to produce different mature mRNAs that encode different protein sequences. This process is known as alternative splicing, and allows production of a large variety of proteins from a limited amount of DNA.\\r\\nThe entry and exit of large molecules from the nucleus is tightly controlled by the nuclear pore complexes. Although small molecules can enter the nucleus without regulation,[58] macromolecules such as RNA and proteins require association karyopherins called importins to enter the nucleus and exportins to exit. \\"Cargo\\" proteins that must be translocated from the cytoplasm to the nucleus contain short amino acid sequences known as nuclear localization signals, which are bound by importins, while those transported from the nucleus to the cytoplasm carry nuclear export signals bound by exportins. The ability of importins and exportins to transport their cargo is regulated by GTPases, enzymes that hydrolyze the molecule guanosine triphosphate to release energy. The key GTPase in nuclear transport is Ran, which can bind either GTP or GDP (guanosine diphosphate), depending on whether it is located in the nucleus or the cytoplasm. Whereas importins depend on RanGTP to dissociate from their cargo, exportins require RanGTP in order to bind to their cargo.[11]\\r\\nNuclear import depends on the importin binding its cargo in the cytoplasm and carrying it through the nuclear pore into the nucleus. Inside the nucleus, RanGTP acts to separate the cargo from the importin, allowing the importin to exit the nucleus and be reused. Nuclear export is similar, as the exportin binds the cargo inside the nucleus in a process facilitated by RanGTP, exits through the nuclear pore, and separates from its cargo in the cytoplasm.\\r\\nSpecialized export proteins exist for translocation of mature mRNA and tRNA to the cytoplasm after post-transcriptional modification is complete. This quality-control mechanism is important due to these molecules' central role in protein translation. Mis-expression of a protein due to incomplete excision of exons or mis-incorporation of amino acids could have negative consequences for the cell; thus, incompletely modified RNA that reaches the cytoplasm is degraded rather than used in translation.[5]\\r\\nDuring its lifetime, a nucleus may be broken down or destroyed, either in the process of cell division or as a consequence of apoptosis (the process of programmed cell death). During these events, the structural components of the nucleus? the envelope and lamina? can be systematically degraded. In most cells, the disassembly of the nuclear envelope marks the end of the prophase of mitosis. However, this disassembly of the nucleus is not a universal feature of mitosis and does not occur in all cells. Some unicellular eukaryotes (e.g., yeasts) undergo so-called closed mitosis, in which the nuclear envelope remains intact. In closed mitosis, the daughter chromosomes migrate to opposite poles of the nucleus, which then divides in two. The cells of higher eukaryotes, however, usually undergo open mitosis, which is characterized by breakdown of the nuclear envelope. The daughter chromosomes then migrate to opposite poles of the mitotic spindle, and new nuclei reassemble around them.\\r\\nAt a certain point during the cell cycle in open mitosis, the cell divides to form two cells. In order for this process to be possible, each of the new daughter cells must have a full set of genes, a process requiring replication of the chromosomes as well as segregation of the separate sets. This occurs by the replicated chromosomes, the sister chromatids, attaching to microtubules, which in turn are attached to different centrosomes. The sister chromatids can then be pulled to separate locations in the cell. In many cells, the centrosome is located in the cytoplasm, outside the nucleus; the microtubules would be unable to attach to the chromatids in the presence of the nuclear envelope.[59] Therefore, the early stages in the cell cycle, beginning in prophase and until around prometaphase, the nuclear membrane is dismantled.[14] Likewise, during the same period, the nuclear lamina is also disassembled, a process regulated by phosphorylation of the lamins by protein kinases such as the CDC2 protein kinase.[60] Towards the end of the cell cycle, the nuclear membrane is reformed, and around the same time, the nuclear lamina are reassembled by dephosphorylating the lamins.[60]\\r\\nHowever, in dinoflagellates, the nuclear envelope remains intact, the centrosomes are located in the cytoplasm, and the microtubules come in contact with chromosomes, whose centromeric regions are incorporated into the nuclear envelope (the so-called closed mitosis with extranuclear spindle). In many other protists (e.g., ciliates, sporozoans) and fungi, the centrosomes are intranuclear, and their nuclear envelope also does not disassemble during cell division.\\r\\nApoptosis is a controlled process in which the cell's structural components are destroyed, resulting in death of the cell. Changes associated with apoptosis directly affect the nucleus and its contents, for example, in the condensation of chromatin and the disintegration of the nuclear envelope and lamina. The destruction of the lamin networks is controlled by specialized apoptotic proteases called caspases, which cleave the lamin proteins and, thus, degrade the nucleus' structural integrity. Lamin cleavage is sometimes used as a laboratory indicator of caspase activity in assays for early apoptotic activity.[14] Cells that express mutant caspase-resistant lamins are deficient in nuclear changes related to apoptosis, suggesting that lamins play a role in initiating the events that lead to apoptotic degradation of the nucleus.[14] Inhibition of lamin assembly itself is an inducer of apoptosis.[61]\\r\\nThe nuclear envelope acts as a barrier that prevents both DNA and RNA viruses from entering the nucleus. Some viruses require access to proteins inside the nucleus in order to replicate and/or assemble. DNA viruses, such as herpesvirus replicate and assemble in the cell nucleus, and exit by budding through the inner nuclear membrane. This process is accompanied by disassembly of the lamina on the nuclear face of the inner membrane.[14]\\r\\nInitially, it has been suspected that immunoglobulins in general and autoantibodies in particular do not enter the nucleus. Now there is a body of evidence that under pathological conditions (e.g. lupus erythematosus) IgG can enter the nucleus.[62]\\r\\nMost eukaryotic cell types usually have a single nucleus, but some have no nuclei, while others have several. This can result from normal development, as in the maturation of mammalian red blood cells, or from faulty cell division.\\r\\nAn anucleated cell contains no nucleus and is, therefore, incapable of dividing to produce daughter cells. The best-known anucleated cell is the mammalian red blood cell, or erythrocyte, which also lacks other organelles such as mitochondria, and serves primarily as a transport vessel to ferry oxygen from the lungs to the body's tissues. Erythrocytes mature through erythropoiesis in the bone marrow, where they lose their nuclei, organelles, and ribosomes. The nucleus is expelled during the process of differentiation from an erythroblast to a reticulocyte, which is the immediate precursor of the mature erythrocyte.[63] The presence of mutagens may induce the release of some immature \\"micronucleated\\" erythrocytes into the bloodstream.[64][65] Anucleated cells can also arise from flawed cell division in which one daughter lacks a nucleus and the other has two nuclei.\\r\\nIn flowering plants, this condition occurs in sieve tube elements.\\r\\nMultinucleated cells contain multiple nuclei. Most acantharean species of protozoa[66] and some fungi in mycorrhizae[67] have naturally multinucleated cells. Other examples include the intestinal parasites in the genus Giardia, which have two nuclei per cell.[68] In humans, skeletal muscle cells, called myocytes and syncytium, become multinucleated during development; the resulting arrangement of nuclei near the periphery of the cells allows maximal intracellular space for myofibrils.[5] Multinucleated and binucleated cells can also be abnormal in humans; for example, cells arising from the fusion of monocytes and macrophages, known as giant multinucleated cells, sometimes accompany inflammation[69] and are also implicated in tumor formation.[70]\\r\\nA number of dinoflagellates are known to have two nuclei.[71] Unlike other multinucleated cells these nuclei contain two distinct lineages of DNA: one from the dinoflagellate and the other from a symbiotic diatom. The mitochondria and the plastids of the diatom somehow remain functional.\\r\\nAs the major defining characteristic of the eukaryotic cell, the nucleus' evolutionary origin has been the subject of much speculation. Four major hypotheses have been proposed to explain the existence of the nucleus, although none have yet earned widespread support.[72]\\r\\nThe first model known as the \\"syntrophic model\\" proposes that a symbiotic relationship between the archaea and bacteria created the nucleus-containing eukaryotic cell. (Organisms of the Archaea and Bacteria domain have no cell nucleus.[73]) It is hypothesized that the symbiosis originated when ancient archaea, similar to modern methanogenic archaea, invaded and lived within bacteria similar to modern myxobacteria, eventually forming the early nucleus. This theory is analogous to the accepted theory for the origin of eukaryotic mitochondria and chloroplasts, which are thought to have developed from a similar endosymbiotic relationship between proto-eukaryotes and aerobic bacteria.[74] The archaeal origin of the nucleus is supported by observations that archaea and eukarya have similar genes for certain proteins, including histones. Observations that myxobacteria are motile, can form multicellular complexes, and possess kinases and G proteins similar to eukarya, support a bacterial origin for the eukaryotic cell.[75]\\r\\nA second model proposes that proto-eukaryotic cells evolved from bacteria without an endosymbiotic stage. This model is based on the existence of modern planctomycetes bacteria that possess a nuclear structure with primitive pores and other compartmentalized membrane structures.[76] A similar proposal states that a eukaryote-like cell, the chronocyte, evolved first and phagocytosed archaea and bacteria to generate the nucleus and the eukaryotic cell.[77]\\r\\nThe most controversial model, known as viral eukaryogenesis, posits that the membrane-bound nucleus, along with other eukaryotic features, originated from the infection of a prokaryote by a virus. The suggestion is based on similarities between eukaryotes and viruses such as linear DNA strands, mRNA capping, and tight binding to proteins (analogizing histones to viral envelopes). One version of the proposal suggests that the nucleus evolved in concert with phagocytosis to form an early cellular \\"predator\\".[78] Another variant proposes that eukaryotes originated from early archaea infected by poxviruses, on the basis of observed similarity between the DNA polymerases in modern poxviruses and eukaryotes.[79][80] It has been suggested that the unresolved question of the evolution of sex could be related to the viral eukaryogenesis hypothesis.[81]\\r\\nA more recent proposal, the exomembrane hypothesis, suggests that the nucleus instead originated from a single ancestral cell that evolved a second exterior cell membrane; the interior membrane enclosing the original cell then became the nuclear membrane and evolved increasingly elaborate pore structures for passage of internally synthesized cellular components such as ribosomal subunits.[82]","input":"What is the outer layer of the nucleus called?"},{"output":"export-based","context":"","input":"What type of economy does latin america have?"}]`),I={name:"App",components:{PoemCard:C},data(){return{visibleCount:20,poemsData:M}},computed:{visiblePoems(){return this.poemsData.slice(0,this.visibleCount)},hasMorePoems(){return this.visibleCount<this.poemsData.length}},methods:{loadMore(){this.visibleCount+=20}}},P={class:"card-container"};function B(h,t,n,c,u,i){const m=p("PoemCard");return a(),o(l,null,[t[1]||(t[1]=e("section",null,[e("div",{class:"top-Banner"},[e("div",{class:"top-Banner-Title"},[e("div",{class:"top-Banner-Title-Text"},"🎉Q&A Life🥳")])])],-1)),e("section",null,[e("div",P,[(a(!0),o(l,null,g(i.visiblePoems,(r,f)=>(a(),y(m,{key:f,poem:r},null,8,["poem"]))),128))]),i.hasMorePoems?(a(),o("button",{key:0,class:"load-more-button",onClick:t[0]||(t[0]=(...r)=>i.loadMore&&i.loadMore(...r))},"See more")):w("",!0)])],64)}const x=d(I,[["render",B]]),D=JSON.parse('{"title":"","description":"","frontmatter":{"page":true},"headers":[],"relativePath":"qapage/26.md","filePath":"qapage/26.md"}'),F={name:"qapage/26.md"},R=Object.assign(F,{setup(h){return(t,n)=>(a(),o("div",null,[b(x)]))}});export{D as __pageData,R as default};
